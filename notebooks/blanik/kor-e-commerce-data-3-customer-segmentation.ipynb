{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# References\n1. [Customer Segmentation](https://www.kaggle.com/fabiendaniel/customer-segmentation)\n2. [Customer Segmentation](https://www.kaggle.com/miljan/customer-segmentation)","metadata":{}},{"cell_type":"markdown","source":"# 각 커널의 아이디어\n# 1. Customer Segmentation\n## 1.1 목표\n- 고객 세분화\n- 신규 고객이 군집에 속할지 예측하는 분류기 만들기\n\n## 1.2 작업 순서\n1. 사이트에서 판매하는 다양한 상품을 분석. 5가지 카테고리로 분류\n2. 10개월 동안 고객의 소비 습관을 분석하여 고객을 분류 ( 고객이 주로 구매하는 상품의 카테고리, 방문 횟수, 10개월 동안 소비한 금액 등 11가지 기준으로 분류 )\n3. 고객이 11개 중 어디에 포함되는지 예측하는 모델 개발\n4. 2개월치 데이터로 테스트\n\n## 1.3 전처리\n1. `CustomerID`가 null인 트랜잭션 제거\n2. 중복되는 트랜잭션 제거\n3. `Quantity` <= 0 or `Description` != 'Discount'인 트랜잭션 ( 취소 트랜잭션 )\n    - 대응하는 주문이 없으면 삭제\n    - 대응하는 주문이 있으면 취소 트랜잭션의 `Quantity`를 `QuantityCanceled`에 추가하고 취소 트랜잭션은 삭제\n    - 대응하는 주문이 2개 이상 있으면 마지막 취소 트랜잭션의 `Quantity`를 `QuantityCanceled`에 추가하고 취소 트랜잭션은 삭제\n\n## 1.4 상품 분류\n- 상품 Description으로부터 이름 추출\n    - nltk.pos_tag 를 통해 명사만을 추출\n    - SnowballStemmer로 접사(affix) 제거\n    - stemming된 명사를 root로 보며, 같은 root를 가지는 것들을 set에 추가 ( 'root': {'roota', 'rootb', 'rootc'} )\n    - 각 root에 해당하는 명사가 여러개인 경우, 길이가 가장 짧은 것을 선택\n    - 색상 (pink, blue, ...), 특수기호 ( +, / )가 포함되거나, 이름이 3글자 미만이거나, 이름이 포함되는 상품 수가 13개 미만인 것은 삭제\n- 상품 x 상품명 데이터프레임을 만든다\n    - 예를 들어, 0번 상품이 'flower', 'decoration'이고, 1번 상품이 'bag'이면 데이터프레임은 다음과 같다.\n    |   | flower | decoration | bag |\n    |---|--------|------------|-----|\n    | 0 | 1      | 1          | 0   |\n    | 1 | 0      | 0          | 1   |\n- 데이터프레임에 상품의 가격 범주를 원핫인코딩하여 추가\n- kmodes 라이브러리의 KModes는 Hamming's metric을 사용하여 군집화\n    - 하지만 kmodes는 kaggle에서 사용 불가\n    - 어쩔수 없이 KMeans, Euclidean distance를 사용해 군집화 ( 카테고리 변수를 군집화하는데 좋지 않다 )\n- Silhouette score가 가장 높은 것은 군집이 8개일 때였지만, 특정 군집에 속하는 상품의 수가 너무 적었다. 그래서 군집의 수를 5로 결정\n\n## 1.5 고객 분류\n- `CustomerID`, `InvoiceNo`로 그루핑해 다음을 집계\n    - `Basket Price`: 해당 `InvoiceNo`에 포함된 상품의 금액 합계\n    - `categ_0`, ..., `categ_4`: 군집 0, 1, 2, 3, 4에 해당하는 금액\n    - `InvoiceDate`: `InvoiceDate`의 평균\n- `InvoiceDate`가 2011-10-01 미만인 것은 training set, 나머지는 test set으로 활용\n- traing set을 `CustomerID`로 그루핑해 다음을 집계\n    - `count`, `min`, `max`, `mean`, `sum`: `Basket Price`의 수, 최소값, 최대값, 평균, 합\n    - `categ_0`, ..., `categ_4`: 군집 0, 1, 2, 3, 4에 해당하는 금액\n    - `FirstPurchase`, `LastPurchase`: 첫 구매, 마지막 구매로부터 지난 날짜\n- training set을 Standard Scaling\n- training set를 K-Means 클러스터링\n    - Silhouette score를 적용하여 군집의 수를 결정\n    - 군집 수는 11개이며, silhouette score는 0.216\n    - 여기에서 만든 군집을 지도학습의 라벨로 사용\n- 클러스터링이 잘 되었는지 확인하는 방법은 다음과 같다.\n    1. Report via the PCA: PCA components를 두개씩 짝지어서 시각화하여 군집들을 잘 구분하는지 확인\n    2. Silhouette score\n    3. Customers morphotype: 군집별 통계치를 비교하여 군집이 잘 되었는지 확인\n    4. Customers morphology: Radar Charts를 그려서 비교 ( 3과 비슷함 )\n\n## 1.6 고객 분류기 만들기\n- 첫 번째 방문과 동시에 바구니 내용을 설명하는 변수만 유지하고, 시간에 따른 바구니 가격 변동이나 방문 빈도와 관련된 변수는 제외\n- 사용한 분류기는 다음과 같다.\n    1. SVC\n    2. Logistic Regression\n    3. K-Nearest Neighbors\n    4. Decision Tree\n    5. Random Forest\n    6. AdaBoost Classifier\n    7. Gradient Boosting Classifier\n- Random Forest, Gradient Boosting Classifier, K-Nearest Neighbors을 soft voting하였음 ( 3개의 분류기는 테스트셋에서 가장 좋은 성능을 내는 것으로 선택됨 )\n- training precision은 91.27%\n- test precision은 76.48\n\n# 2. Customer Segmentation\n## 2.1 전처리\n- drop if `CustomerID` is null\n- `Quantity` <= 0 or `Description` != 'Discount'인 트랜잭션 ( 취소 트랜잭션 )\n    - 1번 커널과 동일\n- drop if `Quantity` < 0 & `StockCode` != 'D'\n- 문자열로만 이루어진 `StockCode` 삭제 ( ex. 'POST', 'D' )\n- Label Encoding `Country`\n\n## 2.2 Customer Segementation\n### 2.2.1 TotalPrice\n- `TotalPrice` = `UnitPrice` * (`Quantity` - `QuantityCanceled`)\n\n### 2.2.2 [RFM Analysis](https://www.kaggle.com/blanik/kor-e-commerce-data-2-rfm-analysis)\n- 4개 등급으로 나눔\n- 점수를 문자열로 간주하고 합침\n- '111'이 가장 좋은 고객\n\n### 2.2.3 Time Features\n- `Month`, `Weekday`, `Day`, `Hour`\n\n### 2.2.4 Product Categories\n- TfidfVectorizer 사용해 `Descripotion`을 벡터화 ( shape: (3871,1694) )\n    - stem_and_filter라는 함수 정의하여 analyzer로 사용 ( PorterStemmer로 접사 제거 )\n- TruncatedSVD로 TfidfVector 100차원으로 축소 ( shape: (3871,100) )\n- K-Means 적용하여 군집화\n    - Silhouette Score 비교하여 군집 성능 측정\n    - 군집의 수를 135개로 결정\n\n### 2.2.5 Customer Categories\n- `min`, `max`, `mean`, `min_recency`, `max_recency`, `frequency`, `monetary_value`, `quantity`, `country`\n    - (4335, 9)\n- 고객이 상품 군집별로 얼마나 썼는지 비율로 표현\n    - 위에서 상품 군집을 135개로 결정했으므로, 행렬은 (4335, 135) 이다.\n- 위에 있는 두 데이터프레임을 concat하여 (4335, 144) 행렬 만듦.\n- K-means clustering을 통해 군집화\n    - Silhouette score를 비교해 8개의 군집으로 만들기로 결정\n\n## 2.3 Interpreting the clusters\n### 2.3.1 TSNE\n- 2차원으로 차원축소를 시켜 시각화\n- 군집들이 서로 구분되는지 것을 확인\n\n### 2.3.2 통계치 비교\n- Cluster 2: high frequency with a lot of quantity (mean basket price of 513) bought on average and high monetary value (VIP clients)\n- Cluster 7 : very high purchase frequency with a mean basket price of 150 but good monetary value.\n- Cluster 4: very high basket price (huge quantity of products bought on average)\n- Cluster 0: good average customers\n- Cluster 6: good foreign customers\n- Cluster 1: almost lost customers\n- Cluster 5: highest monetary value but only one or two purchases over the year\n- Cluster 3: lost customers","metadata":{}},{"cell_type":"markdown","source":"# 참고자료 요약\n1. 전에 다뤘던 [RFM Analysis](https://www.kaggle.com/blanik/kor-e-commerce-data-2-rfm-analysis)는 Customer Segementation의 방법 중 하나로 보이며, 커널 2의 경우 실제로 segmentation을 할 때 RFM Analysis의 결과를 사용하기도 했다. RFM Analysis는 Recency, Frequency, Monetary만을 쓰는 반면, 여기서는 훨씬 다양한 정보를 사용해 고객을 분류한다.\n2. 두 커널 모두 상품을 군집화해 해당 군집에 해당하는 상품들에 돈을 얼마나 썼는지를 변수로 사용한다. 상품을 군집화하기 위해서는 텍스트 데이터를 벡터로 만들어야 하는데, 아이디어가 달랐다.\n    1. 커널 1: 상품명에 해당하는 것을 찾으려고 노력. 이후 원핫인코딩\n    2. 커널 2: TfidfVectorizer로 벡터화, TruncatedSVD로 차원 축소.\n3. 1번 커널의 상품 벡터는 sparse vector가 되었으며, 2번 커널의 상품 벡터는 dense vector가 되었다.\n    - 둘 다 K-Means를 사용하였으나, 1번 커널의 저자에 따르면 K-Means는 sparse vecotr(카테고리)를 군집화하는 데 좋지 않다고 한다.\n    - K-Means 대신 K-Modes를 사용하길 제안\n4. 고객 군집에 사용되는 features는 다음과 같다.\n    - Basket Price의 수, 최소값, 최대값, 평균, 합\n    - 상품 군집에 해당하는 금액\n    - 첫 구매, 마지막 구매로부터 지난 날짜\n    - min_recency, max_recency, frequency, monetary_value, quantity, country\n5. 1번 커널은 고객 군집화를 마친 후에 성능 평가를 다양한 방법으로 했다.\n6. 1번 커널은 고객이 어떤 군집에 속하는지 예측하는 분류기를 따로 만들었는데, 왜 만들었는지 모르겠다.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime, nltk, warnings\nimport matplotlib.cm as cm\nimport itertools\nfrom pathlib import Path\nfrom kmodes.kmodes import KModes\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_samples, silhouette_score\nfrom sklearn import preprocessing, model_selection, metrics, feature_selection\nfrom sklearn.model_selection import GridSearchCV, learning_curve\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import neighbors, linear_model, svm, tree, ensemble\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.decomposition import PCA\nfrom IPython.display import display, HTML\nimport plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode,iplot\ninit_notebook_mode(connected=True)\nwarnings.filterwarnings(\"ignore\")\nplt.rcParams[\"patch.force_edgecolor\"] = True\nplt.style.use('fivethirtyeight')\nmpl.rc('patch', edgecolor = 'dimgray', linewidth=1)\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-07-22T23:17:07.225392Z","iopub.execute_input":"2021-07-22T23:17:07.225852Z","iopub.status.idle":"2021-07-22T23:17:09.735783Z","shell.execute_reply.started":"2021-07-22T23:17:07.225746Z","shell.execute_reply":"2021-07-22T23:17:09.735022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-22T23:17:09.737026Z","iopub.execute_input":"2021-07-22T23:17:09.737439Z","iopub.status.idle":"2021-07-22T23:17:09.757541Z","shell.execute_reply.started":"2021-07-22T23:17:09.737409Z","shell.execute_reply":"2021-07-22T23:17:09.754935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. 데이터 로드","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/ecommerce-data/data.csv', \n                 dtype={'InvoiceNo': str, 'StockCode': str, 'Description': str, 'Quantity': int, 'UnitPrice': float, 'CustomerID': str, 'Country': str}, \n                 encoding='ISO-8859-1',\n                 parse_dates=['InvoiceDate'])\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-22T23:17:09.763949Z","iopub.execute_input":"2021-07-22T23:17:09.76431Z","iopub.status.idle":"2021-07-22T23:17:13.740143Z","shell.execute_reply.started":"2021-07-22T23:17:09.764279Z","shell.execute_reply":"2021-07-22T23:17:13.739011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-22T23:17:13.741703Z","iopub.execute_input":"2021-07-22T23:17:13.742041Z","iopub.status.idle":"2021-07-22T23:17:14.021934Z","shell.execute_reply.started":"2021-07-22T23:17:13.742008Z","shell.execute_reply":"2021-07-22T23:17:14.020853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-22T23:17:14.023214Z","iopub.execute_input":"2021-07-22T23:17:14.02352Z","iopub.status.idle":"2021-07-22T23:17:14.08824Z","shell.execute_reply.started":"2021-07-22T23:17:14.02349Z","shell.execute_reply":"2021-07-22T23:17:14.087228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.nunique().to_frame().transpose()","metadata":{"execution":{"iopub.status.busy":"2021-07-22T23:17:14.089506Z","iopub.execute_input":"2021-07-22T23:17:14.089815Z","iopub.status.idle":"2021-07-22T23:17:14.651215Z","shell.execute_reply.started":"2021-07-22T23:17:14.089785Z","shell.execute_reply":"2021-07-22T23:17:14.650123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. 간단한 데이터 전처리","metadata":{}},{"cell_type":"code","source":"df = df[\n    (df['Country'] == 'United Kingdom') &\n    (~df['CustomerID'].isnull()) &\n    (~df['InvoiceNo'].str.startswith('C')) &\n    (df['Quantity'] > 0) & \n    (df['UnitPrice'] > 0) & \n    (~df['StockCode'].str.isalpha()) &\n    (~df['StockCode'].str.contains('BANK|C2|DCGS|gift'))\n].reset_index(drop=True)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-22T23:17:14.652649Z","iopub.execute_input":"2021-07-22T23:17:14.653028Z","iopub.status.idle":"2021-07-22T23:17:15.781063Z","shell.execute_reply.started":"2021-07-22T23:17:14.652992Z","shell.execute_reply":"2021-07-22T23:17:15.780017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['TotalPrice'] = df['Quantity'] * df['UnitPrice']\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-22T23:17:15.783452Z","iopub.execute_input":"2021-07-22T23:17:15.783799Z","iopub.status.idle":"2021-07-22T23:17:15.804658Z","shell.execute_reply.started":"2021-07-22T23:17:15.783764Z","shell.execute_reply":"2021-07-22T23:17:15.803675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. 상품 군집화","metadata":{}},{"cell_type":"code","source":"is_noun = lambda pos: pos[:2] == 'NN'\n\ndef keywords_inventory(dataframe, col='Description'):\n    stemmer = nltk.stem.SnowballStemmer(\"english\")\n    keywords_roots  = dict()  # collect the words / root\n    keywords_select = dict()  # association: root <-> keyword\n    category_keys   = []\n    count_keywords  = dict()\n    icount = 0\n    for s in dataframe[col]:\n        if pd.isnull(s): continue\n        lines = s.lower()\n        tokenized = nltk.word_tokenize(lines)\n        nouns = [word for (word, pos) in nltk.pos_tag(tokenized) if is_noun(pos)] \n        \n        for t in nouns:\n            t = t.lower()\n            racine = stemmer.stem(t)\n            if racine in keywords_roots:\n                keywords_roots[racine].add(t)\n                count_keywords[racine] += 1                \n            else:\n                keywords_roots[racine] = {t}\n                count_keywords[racine] = 1\n    \n    for s in keywords_roots.keys():\n        if len(keywords_roots[s]) > 1:  \n            min_length = 1000\n            for k in keywords_roots[s]:\n                if len(k) < min_length:\n                    clef = k ; min_length = len(k)            \n            category_keys.append(clef)\n            keywords_select[s] = clef\n        else:\n            category_keys.append(list(keywords_roots[s])[0])\n            keywords_select[s] = list(keywords_roots[s])[0]\n            \n    print(\"Nb of keywords in variable '{}': {}\".format(col,len(category_keys)))\n    return category_keys, keywords_roots, keywords_select, count_keywords","metadata":{"execution":{"iopub.status.busy":"2021-07-22T23:17:15.806679Z","iopub.execute_input":"2021-07-22T23:17:15.80705Z","iopub.status.idle":"2021-07-22T23:17:15.819322Z","shell.execute_reply.started":"2021-07-22T23:17:15.807013Z","shell.execute_reply":"2021-07-22T23:17:15.818208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_products = pd.DataFrame(df['Description'].unique()).rename(columns = {0:'Description'})\ndf_products.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-22T23:17:15.820711Z","iopub.execute_input":"2021-07-22T23:17:15.821077Z","iopub.status.idle":"2021-07-22T23:17:15.89166Z","shell.execute_reply.started":"2021-07-22T23:17:15.821041Z","shell.execute_reply":"2021-07-22T23:17:15.89064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keywords, keywords_roots, keywords_select, count_keywords = keywords_inventory(df_products)","metadata":{"execution":{"iopub.status.busy":"2021-07-22T23:17:15.893033Z","iopub.execute_input":"2021-07-22T23:17:15.893381Z","iopub.status.idle":"2021-07-22T23:17:18.782235Z","shell.execute_reply.started":"2021-07-22T23:17:15.893345Z","shell.execute_reply":"2021-07-22T23:17:18.781123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_products = []\nfor k,v in count_keywords.items():\n    word = keywords_select[k]\n    if word in ['pink', 'blue', 'tag', 'green', 'orange']: continue\n    if len(word) < 3 or v < 13: continue\n    if ('+' in word) or ('/' in word): continue\n    list_products.append([word, v])\n\nlist_products.sort(key = lambda x:x[1], reverse = True)\nprint(list_products[:5])\nprint('mots conservés:', len(list_products))","metadata":{"execution":{"iopub.status.busy":"2021-07-22T23:17:18.785698Z","iopub.execute_input":"2021-07-22T23:17:18.786088Z","iopub.status.idle":"2021-07-22T23:17:18.79523Z","shell.execute_reply.started":"2021-07-22T23:17:18.786053Z","shell.execute_reply":"2021-07-22T23:17:18.794005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"liste_produits = df['Description'].unique()\nX = pd.DataFrame()\nfor key, occurence in list_products:\n    X.loc[:, key] = list(map(lambda x:int(key.upper() in x), liste_produits))\nX","metadata":{"execution":{"iopub.status.busy":"2021-07-22T23:17:18.796982Z","iopub.execute_input":"2021-07-22T23:17:18.797432Z","iopub.status.idle":"2021-07-22T23:17:20.141253Z","shell.execute_reply.started":"2021-07-22T23:17:18.797385Z","shell.execute_reply":"2021-07-22T23:17:20.140043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"threshold = [0, 1, 2, 3, 5, 10]\nlabel_col = []\nfor i in range(len(threshold)):\n    if i == len(threshold)-1:\n        col = '.>{}'.format(threshold[i])\n    else:\n        col = '{}<.<{}'.format(threshold[i],threshold[i+1])\n    label_col.append(col)\n    X.loc[:, col] = 0\n\nfor i, prod in enumerate(liste_produits):\n    prix = df[ df['Description'] == prod]['UnitPrice'].mean()\n    j = 0\n    while prix > threshold[j]:\n        j+=1\n        if j == len(threshold): break\n    X.loc[i, label_col[j-1]] = 1\nX","metadata":{"execution":{"iopub.status.busy":"2021-07-22T23:17:20.142852Z","iopub.execute_input":"2021-07-22T23:17:20.14327Z","iopub.status.idle":"2021-07-22T23:20:36.00982Z","shell.execute_reply.started":"2021-07-22T23:17:20.143233Z","shell.execute_reply":"2021-07-22T23:20:36.008578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"{:<8} {:<20} \\n\".format('gamme', 'nb. produits') + 20*'-')\nfor i in range(len(threshold)):\n    if i == len(threshold)-1:\n        col = '.>{}'.format(threshold[i])\n    else:\n        col = '{}<.<{}'.format(threshold[i],threshold[i+1])    \n    print(\"{:<10}  {:<20}\".format(col, X.loc[:, col].sum()))","metadata":{"execution":{"iopub.status.busy":"2021-07-22T23:20:36.011413Z","iopub.execute_input":"2021-07-22T23:20:36.011762Z","iopub.status.idle":"2021-07-22T23:20:36.022359Z","shell.execute_reply.started":"2021-07-22T23:20:36.011727Z","shell.execute_reply":"2021-07-22T23:20:36.020935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"실험결과는 아래와 같으며, 예상과 다르게 K-Means의 성능이 가장 좋았다.","metadata":{}},{"cell_type":"code","source":"# for n_clusters in range(3,10):\n#     kmeans = KMeans(init='k-means++', n_clusters = n_clusters, n_init=30, random_state=42)\n#     kmeans.fit(X)\n#     clusters = kmeans.predict(X)\n# #     kmodes = KModes(n_clusters=n_clusters, init='Cao', n_init=5, verbose=0, random_state=42)\n# #     clusters = kmodes.fit_predict(X)\n#     silhouette_avg = silhouette_score(X, clusters)\n#     print(\"For n_clusters =\", n_clusters, \"The average silhouette_score is :\", silhouette_avg)\n\n#     # K-Means\n#     # For n_clusters = 3 The average silhouette_score is : 0.102948308223902\n#     # For n_clusters = 4 The average silhouette_score is : 0.12811789850480998\n#     # For n_clusters = 5 The average silhouette_score is : 0.12699637806397684\n#     # For n_clusters = 6 The average silhouette_score is : 0.1574539201632419\n#     # For n_clusters = 7 The average silhouette_score is : 0.14819126448170802\n#     # For n_clusters = 8 The average silhouette_score is : 0.15185568045328124\n#     # For n_clusters = 9 The average silhouette_score is : 0.14261087252384386\n\n#     # K-Modes ( Huang )\n#     # For n_clusters = 3 The average silhouette_score is : 0.07598815097161264\n#     # For n_clusters = 4 The average silhouette_score is : 0.1056654702332311\n#     # For n_clusters = 5 The average silhouette_score is : 0.14918484477746594\n#     # For n_clusters = 6 The average silhouette_score is : 0.07704652533161353\n#     # For n_clusters = 7 The average silhouette_score is : 0.13678160470342732\n#     # For n_clusters = 8 The average silhouette_score is : 0.10737535417531055\n#     # For n_clusters = 9 The average silhouette_score is : 0.06458357446364324\n\n#     # K-Modes ( Cao )\n# #     For n_clusters = 3 The average silhouette_score is : 0.11613277588446597\n# #     For n_clusters = 4 The average silhouette_score is : 0.10393865789571573\n# #     For n_clusters = 5 The average silhouette_score is : 0.101405159342249\n# #     For n_clusters = 6 The average silhouette_score is : 0.09791048809026176\n# #     For n_clusters = 7 The average silhouette_score is : 0.09936970523007022\n# #     For n_clusters = 8 The average silhouette_score is : 0.0989687901831909\n# #     For n_clusters = 9 The average silhouette_score is : 0.0942020466189543","metadata":{"execution":{"iopub.status.busy":"2021-07-22T23:20:36.02403Z","iopub.execute_input":"2021-07-22T23:20:36.024409Z","iopub.status.idle":"2021-07-22T23:20:36.043409Z","shell.execute_reply.started":"2021-07-22T23:20:36.024375Z","shell.execute_reply":"2021-07-22T23:20:36.041957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_clusters = 6\nkmeans = KMeans(init='k-means++', n_clusters = n_clusters, n_init=30)\nkmeans.fit(X)\nclusters = kmeans.predict(X)\nsilhouette_avg = silhouette_score(X, clusters)\nprint(\"For n_clusters =\", n_clusters, \"The average silhouette_score is :\", silhouette_avg)","metadata":{"execution":{"iopub.status.busy":"2021-07-22T23:20:36.045039Z","iopub.execute_input":"2021-07-22T23:20:36.045409Z","iopub.status.idle":"2021-07-22T23:20:41.637505Z","shell.execute_reply.started":"2021-07-22T23:20:36.045365Z","shell.execute_reply":"2021-07-22T23:20:41.636337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.Series(clusters).value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-07-22T23:20:41.639072Z","iopub.execute_input":"2021-07-22T23:20:41.639492Z","iopub.status.idle":"2021-07-22T23:20:41.64968Z","shell.execute_reply.started":"2021-07-22T23:20:41.639454Z","shell.execute_reply":"2021-07-22T23:20:41.648772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def graph_component_silhouette(n_clusters, lim_x, mat_size, sample_silhouette_values, clusters):\n    plt.rcParams[\"patch.force_edgecolor\"] = True\n    plt.style.use('fivethirtyeight')\n    mpl.rc('patch', edgecolor = 'dimgray', linewidth=1)\n    #____________________________\n    fig, ax1 = plt.subplots(1, 1)\n    fig.set_size_inches(8, 8)\n    ax1.set_xlim([lim_x[0], lim_x[1]])\n    ax1.set_ylim([0, mat_size + (n_clusters + 1) * 10])\n    y_lower = 10\n    for i in range(n_clusters):\n        #___________________________________________________________________________________\n        # Aggregate the silhouette scores for samples belonging to cluster i, and sort them\n        ith_cluster_silhouette_values = sample_silhouette_values[clusters == i]\n        ith_cluster_silhouette_values.sort()\n        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n        y_upper = y_lower + size_cluster_i\n        cmap = cm.get_cmap(\"Spectral\")\n        color = cmap(float(i) / n_clusters)        \n        ax1.fill_betweenx(np.arange(y_lower, y_upper), 0, ith_cluster_silhouette_values,\n                           facecolor=color, edgecolor=color, alpha=0.8)\n        #____________________________________________________________________\n        # Label the silhouette plots with their cluster numbers at the middle\n        ax1.text(-0.03, y_lower + 0.5 * size_cluster_i, str(i), color = 'red', fontweight = 'bold',\n                bbox=dict(facecolor='white', edgecolor='black', boxstyle='round, pad=0.3'))\n        #______________________________________\n        # Compute the new y_lower for next plot\n        y_lower = y_upper + 10","metadata":{"execution":{"iopub.status.busy":"2021-07-22T23:20:41.651266Z","iopub.execute_input":"2021-07-22T23:20:41.651985Z","iopub.status.idle":"2021-07-22T23:20:41.669949Z","shell.execute_reply.started":"2021-07-22T23:20:41.651934Z","shell.execute_reply":"2021-07-22T23:20:41.668848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#____________________________________\n# define individual silouhette scores\nsample_silhouette_values = silhouette_samples(X, clusters)\n#__________________\n# and do the graph\ngraph_component_silhouette(n_clusters, [-0.07, 0.33], len(X), sample_silhouette_values, clusters)","metadata":{"execution":{"iopub.status.busy":"2021-07-22T23:20:41.671585Z","iopub.execute_input":"2021-07-22T23:20:41.672272Z","iopub.status.idle":"2021-07-22T23:20:42.459299Z","shell.execute_reply.started":"2021-07-22T23:20:41.672213Z","shell.execute_reply":"2021-07-22T23:20:42.45833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corresp = dict()\nfor key, val in zip (liste_produits, clusters):\n    corresp[key] = val \n    \ndf['categ_product'] = df.loc[:, 'Description'].map(corresp)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-22T23:20:42.463508Z","iopub.execute_input":"2021-07-22T23:20:42.465719Z","iopub.status.idle":"2021-07-22T23:20:42.551771Z","shell.execute_reply.started":"2021-07-22T23:20:42.465664Z","shell.execute_reply":"2021-07-22T23:20:42.550682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. 고객 군집화","metadata":{}},{"cell_type":"code","source":"for i in range(6):\n    col = 'categ_{}'.format(i)\n    df_temp = df[df['categ_product'] == i]\n    price_temp = df_temp['UnitPrice'] * df_temp['Quantity']\n    price_temp = price_temp.apply(lambda x:x if x > 0 else 0)\n    df.loc[:, col] = price_temp\n    df[col].fillna(0, inplace = True)\n\ndf[['InvoiceNo', 'Description', 'categ_product', 'categ_0', 'categ_1', 'categ_2', 'categ_3','categ_4', 'categ_5']][:5]","metadata":{"execution":{"iopub.status.busy":"2021-07-22T23:20:42.55307Z","iopub.execute_input":"2021-07-22T23:20:42.553374Z","iopub.status.idle":"2021-07-22T23:20:43.0565Z","shell.execute_reply.started":"2021-07-22T23:20:42.553345Z","shell.execute_reply":"2021-07-22T23:20:43.055472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp = df.groupby(by=['CustomerID', 'InvoiceNo'], as_index=False)['TotalPrice'].sum()\nbasket_price = temp.rename(columns = {'TotalPrice':'Basket Price'})\nbasket_price.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-22T23:20:43.060112Z","iopub.execute_input":"2021-07-22T23:20:43.060468Z","iopub.status.idle":"2021-07-22T23:20:43.185754Z","shell.execute_reply.started":"2021-07-22T23:20:43.060434Z","shell.execute_reply":"2021-07-22T23:20:43.184631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(6):\n    col = 'categ_{}'.format(i)\n    temp = df.groupby(by=['CustomerID', 'InvoiceNo'], as_index=False)[col].sum()\n    basket_price = pd.merge(basket_price, temp, how='left', on=['CustomerID', 'InvoiceNo'])\nbasket_price.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-22T23:20:43.187531Z","iopub.execute_input":"2021-07-22T23:20:43.187857Z","iopub.status.idle":"2021-07-22T23:20:43.901959Z","shell.execute_reply.started":"2021-07-22T23:20:43.187819Z","shell.execute_reply":"2021-07-22T23:20:43.900878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['InvoiceDate_int'] = df['InvoiceDate'].astype('int64')\ntemp = df.groupby(by=['CustomerID', 'InvoiceNo'], as_index=False)['InvoiceDate_int'].mean()\ndf.drop('InvoiceDate_int', axis = 1, inplace = True)\nbasket_price.loc[:, 'InvoiceDate'] = pd.to_datetime(temp['InvoiceDate_int'])\nbasket_price.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-22T23:20:43.903311Z","iopub.execute_input":"2021-07-22T23:20:43.903616Z","iopub.status.idle":"2021-07-22T23:20:44.067848Z","shell.execute_reply.started":"2021-07-22T23:20:43.903586Z","shell.execute_reply":"2021-07-22T23:20:44.0668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"basket_price = basket_price[basket_price['Basket Price'] > 0]\nbasket_price.sort_values('CustomerID', ascending = True)[:5]","metadata":{"execution":{"iopub.status.busy":"2021-07-22T23:20:44.069162Z","iopub.execute_input":"2021-07-22T23:20:44.069489Z","iopub.status.idle":"2021-07-22T23:20:44.114855Z","shell.execute_reply.started":"2021-07-22T23:20:44.06946Z","shell.execute_reply":"2021-07-22T23:20:44.113719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transactions_per_user=basket_price.groupby(by=['CustomerID'])['Basket Price'].agg(['count','min','max','mean','sum'])\ntransactions_per_user.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-22T23:20:44.116321Z","iopub.execute_input":"2021-07-22T23:20:44.116634Z","iopub.status.idle":"2021-07-22T23:20:44.14733Z","shell.execute_reply.started":"2021-07-22T23:20:44.116604Z","shell.execute_reply":"2021-07-22T23:20:44.146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(6):\n    col = 'categ_{}'.format(i)\n    transactions_per_user.loc[:,col] = basket_price.groupby(by=['CustomerID'])[col].sum() /\\\n                                            transactions_per_user['sum']*100\ntransactions_per_user.reset_index(drop=False, inplace=True)\ntransactions_per_user.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-22T23:20:44.148921Z","iopub.execute_input":"2021-07-22T23:20:44.149266Z","iopub.status.idle":"2021-07-22T23:20:44.2246Z","shell.execute_reply.started":"2021-07-22T23:20:44.149231Z","shell.execute_reply":"2021-07-22T23:20:44.223427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"last_date = basket_price['InvoiceDate'].max().date()\n\nfirst_registration = pd.DataFrame(basket_price.groupby(by=['CustomerID'])['InvoiceDate'].min())\nlast_purchase      = pd.DataFrame(basket_price.groupby(by=['CustomerID'])['InvoiceDate'].max())\n\ntest  = first_registration.applymap(lambda x:(last_date - x.date()).days)\ntest2 = last_purchase.applymap(lambda x:(last_date - x.date()).days)\n\ntransactions_per_user.loc[:, 'LastPurchase'] = test2.reset_index(drop = False)['InvoiceDate']\ntransactions_per_user.loc[:, 'FirstPurchase'] = test.reset_index(drop = False)['InvoiceDate']\ntransactions_per_user.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-22T23:20:44.226741Z","iopub.execute_input":"2021-07-22T23:20:44.227291Z","iopub.status.idle":"2021-07-22T23:20:44.324292Z","shell.execute_reply.started":"2021-07-22T23:20:44.227255Z","shell.execute_reply":"2021-07-22T23:20:44.323205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_cols = ['count','sum','categ_0','categ_1','categ_2','categ_3','categ_4','LastPurchase','FirstPurchase']\nselected_customers = transactions_per_user.copy(deep = True)\nX = transactions_per_user[list_cols]\nX.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-22T23:20:44.325607Z","iopub.execute_input":"2021-07-22T23:20:44.325966Z","iopub.status.idle":"2021-07-22T23:20:44.348039Z","shell.execute_reply.started":"2021-07-22T23:20:44.325931Z","shell.execute_reply":"2021-07-22T23:20:44.346971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = StandardScaler()\nscaled = scaler.fit_transform(X)\nprint('variables mean values: \\n' + 90*'-' + '\\n' , scaler.mean_)\nprint(scaled.shape)\nscaled","metadata":{"execution":{"iopub.status.busy":"2021-07-22T23:20:44.349593Z","iopub.execute_input":"2021-07-22T23:20:44.350254Z","iopub.status.idle":"2021-07-22T23:20:44.371943Z","shell.execute_reply.started":"2021-07-22T23:20:44.350201Z","shell.execute_reply":"2021-07-22T23:20:44.370817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for n_clusters in range(3,15):\n#     kmeans = KMeans(init='k-means++', n_clusters=n_clusters, n_init=30, random_state=42)\n#     kmeans.fit(scaled)\n#     clusters = kmeans.predict(scaled)\n#     silhouette_avg = silhouette_score(scaled, clusters)\n#     print(\"For n_clusters =\", n_clusters, \"The average silhouette_score is :\", silhouette_avg)\n    \n# # For n_clusters = 3 The average silhouette_score is : 0.168980794836066\n# # For n_clusters = 4 The average silhouette_score is : 0.16646738275106582\n# # For n_clusters = 5 The average silhouette_score is : 0.16905847610919267\n# # For n_clusters = 6 The average silhouette_score is : 0.18797777656498754\n# # For n_clusters = 7 The average silhouette_score is : 0.20331453020376275\n# # For n_clusters = 8 The average silhouette_score is : 0.21517828577313772\n# # For n_clusters = 9 The average silhouette_score is : 0.21650652070911072\n# # For n_clusters = 10 The average silhouette_score is : 0.2179063668184951\n# # For n_clusters = 11 The average silhouette_score is : 0.21252948253275006\n# # For n_clusters = 12 The average silhouette_score is : 0.18360864651539327\n# # For n_clusters = 13 The average silhouette_score is : 0.17171604192499632\n# # For n_clusters = 14 The average silhouette_score is : 0.19447194903284856","metadata":{"execution":{"iopub.status.busy":"2021-07-22T23:20:44.373025Z","iopub.execute_input":"2021-07-22T23:20:44.373482Z","iopub.status.idle":"2021-07-22T23:23:48.027826Z","shell.execute_reply.started":"2021-07-22T23:20:44.373448Z","shell.execute_reply":"2021-07-22T23:23:48.026966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_clusters = 10\nkmeans = KMeans(init='k-means++', n_clusters=n_clusters, n_init=30, random_state=42)\nkmeans.fit(scaled)\nclusters_clients = kmeans.predict(scaled)\nsilhouette_avg = silhouette_score(scaled, clusters_clients)\nprint('score de silhouette: {:<.3f}'.format(silhouette_avg))","metadata":{"execution":{"iopub.status.busy":"2021-07-22T23:23:48.029203Z","iopub.execute_input":"2021-07-22T23:23:48.029789Z","iopub.status.idle":"2021-07-22T23:24:13.620084Z","shell.execute_reply.started":"2021-07-22T23:23:48.029741Z","shell.execute_reply":"2021-07-22T23:24:13.61896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(pd.Series(clusters_clients).value_counts(), columns = ['nb. de clients']).T","metadata":{"execution":{"iopub.status.busy":"2021-07-22T23:24:13.621676Z","iopub.execute_input":"2021-07-22T23:24:13.622418Z","iopub.status.idle":"2021-07-22T23:24:13.641076Z","shell.execute_reply.started":"2021-07-22T23:24:13.622358Z","shell.execute_reply":"2021-07-22T23:24:13.640064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. 고객 군집화 결과 확인","metadata":{}},{"cell_type":"markdown","source":"## 5.1. Report via the PCA","metadata":{}},{"cell_type":"code","source":"pca = PCA(n_components=6, random_state=42)\nmatrix_3D = pca.fit_transform(scaled)\nmat = pd.DataFrame(matrix_3D)\nmat['cluster'] = pd.Series(clusters_clients)\nmat","metadata":{"execution":{"iopub.status.busy":"2021-07-22T23:24:13.644967Z","iopub.execute_input":"2021-07-22T23:24:13.64708Z","iopub.status.idle":"2021-07-22T23:24:13.785722Z","shell.execute_reply.started":"2021-07-22T23:24:13.647017Z","shell.execute_reply":"2021-07-22T23:24:13.784704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.patches as mpatches\n\nsns.set_style(\"white\")\nsns.set_context(\"notebook\", font_scale=1, rc={\"lines.linewidth\": 2.5})\n\nLABEL_COLOR_MAP = {0:'r', 1:'tan', 2:'b', 3:'k', 4:'c', 5:'g', 6:'deeppink', 7:'skyblue', 8:'darkcyan', 9:'orange'}\nlabel_color = [LABEL_COLOR_MAP[l] for l in mat['cluster']]\n\nfig = plt.figure(figsize = (12,10))\nincrement = 0\nfor ix in range(6):\n    for iy in range(ix+1, 6):   \n        increment += 1\n        ax = fig.add_subplot(4,3,increment)\n        ax.scatter(mat[ix], mat[iy], c= label_color, alpha=0.5) \n        plt.ylabel('PCA {}'.format(iy+1), fontsize = 12)\n        plt.xlabel('PCA {}'.format(ix+1), fontsize = 12)\n        ax.yaxis.grid(color='lightgray', linestyle=':')\n        ax.xaxis.grid(color='lightgray', linestyle=':')\n        ax.spines['right'].set_visible(False)\n        ax.spines['top'].set_visible(False)\n        \n        if increment == 12: break\n    if increment == 12: break\n\ncomp_handler = []\nfor i in range(n_clusters):\n    comp_handler.append(mpatches.Patch(color = LABEL_COLOR_MAP[i], label = i))\n\nplt.legend(handles=comp_handler, bbox_to_anchor=(1.1, 0.9), \n           title='Cluster', facecolor = 'lightgrey',\n           shadow = True, frameon = True, framealpha = 1,\n           fontsize = 13, bbox_transform = plt.gcf().transFigure)\n\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-07-22T23:24:13.78717Z","iopub.execute_input":"2021-07-22T23:24:13.787542Z","iopub.status.idle":"2021-07-22T23:24:18.280501Z","shell.execute_reply.started":"2021-07-22T23:24:13.787505Z","shell.execute_reply":"2021-07-22T23:24:18.279488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.2. Score de silhouette intra-cluster","metadata":{}},{"cell_type":"code","source":"sample_silhouette_values = silhouette_samples(scaled, clusters_clients)\n#__________________\n# and do the graph\ngraph_component_silhouette(n_clusters, [-0.15, 0.55], len(scaled), sample_silhouette_values, clusters_clients)","metadata":{"execution":{"iopub.status.busy":"2021-07-22T23:24:18.282092Z","iopub.execute_input":"2021-07-22T23:24:18.282697Z","iopub.status.idle":"2021-07-22T23:24:19.09556Z","shell.execute_reply.started":"2021-07-22T23:24:18.282643Z","shell.execute_reply":"2021-07-22T23:24:19.094321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.3. Customers morphotype","metadata":{}},{"cell_type":"code","source":"selected_customers.loc[:, 'cluster'] = clusters_clients\nselected_customers.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-22T23:24:19.097169Z","iopub.execute_input":"2021-07-22T23:24:19.097611Z","iopub.status.idle":"2021-07-22T23:24:19.122765Z","shell.execute_reply.started":"2021-07-22T23:24:19.097567Z","shell.execute_reply":"2021-07-22T23:24:19.121602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_df = pd.DataFrame()\nfor i in range(n_clusters):\n    test = pd.DataFrame(selected_customers[selected_customers['cluster'] == i].mean())\n    test = test.T.set_index('cluster', drop = True)\n    test['size'] = selected_customers[selected_customers['cluster'] == i].shape[0]\n    merged_df = pd.concat([merged_df, test])\n\nmerged_df.drop('CustomerID', axis = 1, inplace = True)\nprint('number of customers:', merged_df['size'].sum())\n\nmerged_df = merged_df.sort_values('sum')\nmerged_df","metadata":{"execution":{"iopub.status.busy":"2021-07-22T23:24:19.124477Z","iopub.execute_input":"2021-07-22T23:24:19.124953Z","iopub.status.idle":"2021-07-22T23:24:19.211692Z","shell.execute_reply.started":"2021-07-22T23:24:19.124883Z","shell.execute_reply":"2021-07-22T23:24:19.210763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 군집별 특성\n- 0: 매출이 양호한 고객\n- 1: 신규 고객\n- 2: categ_3\n- 3: 매출이 우수한 고객\n- 4: 이탈한 것으로 보이는 고객\n- 5: categ_2\n- 6: categ_1\n- 7: categ_4\n- 8: categ_0\n- 9: 매출이 아주 우수한 고객, categ_4","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}