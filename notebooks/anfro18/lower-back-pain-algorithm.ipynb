{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"858145c6-5614-e2a6-5c1c-e542c44cf7fe"},"source":"<h1>Lower Back Pain Classification Algorithm </h1>\n\n<p>This dataset contains the anthropometric measurements of the curvature of the spine to support the model towards a more accurate classification.\n<br />\nLower back pain affects around 80% of individuals at some point in their life. If this model becomes robust enough, then these measurements may soon become predictive and treatable measures. \n<br /> \n<a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.471.4845&rep=rep1&type=pdf\">This study</a> asserts the validity of the manual goniometer measurements as a valid clinical tool. </p>"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"404d4f99-505b-c6ba-0700-d42db0d9ef36"},"outputs":[],"source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\n\n# read data into dataset variable\ndata = pd.read_csv(\"../input/Dataset_spine.csv\")\n\n# Drop the unnamed column in place (not a copy of the original)#\ndata.drop('Unnamed: 13', axis=1, inplace=True)\n\n# Concatenate the original df with the dummy variables\ndata = pd.concat([data, pd.get_dummies(data['Class_att'])], axis=1)\n\n# Drop unnecessary label column in place. \ndata.drop(['Class_att','Normal'], axis=1, inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"21ed290e-b96d-fe40-a174-e572a7391358"},"outputs":[],"source":"data.info()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2771308d-d37a-fe21-5ba7-e2de782e9ee7"},"outputs":[],"source":"\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline"},{"cell_type":"markdown","metadata":{"_cell_guid":"779a9779-dd74-18ae-2ca8-e1d135bcfda8"},"source":"<h1>Exploratory Data Analysis </h1>"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6f8224da-58f4-5d4e-6723-21cf33cbf660"},"outputs":[],"source":"data.columns = ['Pelvic Incidence','Pelvic Tilt','Lumbar Lordosis Angle','Sacral Slope','Pelvic Radius', 'Spondylolisthesis Degree', 'Pelvic Slope', 'Direct Tilt', 'Thoracic Slope', 'Cervical Tilt','Sacrum Angle', 'Scoliosis Slope','Outcome']\ndata.drop(['Pelvic Radius','Direct Tilt','Thoracic Slope', 'Scoliosis Slope'], axis=1, inplace=True)\n\ncorr = data.corr()\n\n# Set up the matplot figure\nf, ax = plt.subplots(figsize=(12,9))\n\n#Draw the heatmap using seaborn\nsns.heatmap(corr, cmap='inferno')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"63607d0a-08e0-522a-99a2-124393a881fd"},"outputs":[],"source":"sns.residplot(x=\"Spondylolisthesis Degree\", y=\"Pelvic Incidence\", data=data, scatter_kws={\"s\":80})"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b9b14682-c73b-0fea-9832-62980aff1115"},"outputs":[],"source":"sns.lmplot(x=\"Spondylolisthesis Degree\", y=\"Pelvic Incidence\",hue=\"Outcome\", data=data, markers=[\"o\", \"x\"], palette=\"Set1\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fcccdf79-d649-8ccb-94c2-4254fcff905c"},"outputs":[],"source":"training = data.drop('Outcome', axis=1)\ntesting = data['Outcome']"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b747abd2-ec17-de05-149d-37a9ed8e510e"},"outputs":[],"source":"training.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"16dedd0c-65c5-1ab3-0bec-5a9a60a3ca6f"},"outputs":[],"source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.decomposition import PCA\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d3fdf108-3fd0-6379-24b6-c40b0cafa920"},"outputs":[],"source":"X_train, X_test, y_train, y_test = train_test_split(training, testing, test_size=0.33, random_state=22)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2c3e9583-bebe-437b-c7b1-7f6a7d9b783f"},"outputs":[],"source":"estimators = [('clf', LogisticRegression())]\n\npl = Pipeline(estimators)\n\npl.fit(X_train, y_train)\n\naccuracy = pl.score(X_test, y_test)\nprint(\"\\nAccuracy on sample data\",accuracy)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"522d3325-68d5-91cf-eed7-745e8a0d4681"},"outputs":[],"source":"ypred = pl.predict(X_test)\n\npl.score(X_test, y_test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6d583902-19d5-c24d-e75f-0a12c27a1dc5"},"outputs":[],"source":"pl.predict(X_test)\npl.score(X_test, y_test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"93a909bd-6169-a40c-ce1c-7424d49e1192"},"outputs":[],"source":"report = classification_report(y_test, ypred)\nprint(report)"},{"cell_type":"markdown","metadata":{"_cell_guid":"33d3be64-17bc-79fd-b886-f04bbf85325d"},"source":"<h1> That's it! </h1>\n<p> 88%+ prediction accuracy feels like a good start. To increase the accuracy of the model, feature engineering is a suitable solution - as well as creating new variables based on domain knowledge.</p>"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9c07b6ad-40d2-0f84-1f1e-89dac46a7cea"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}