{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfiles = list()\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        files.append(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Netflix Dataset Analysis","metadata":{}},{"cell_type":"code","source":"files[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import sys\n\n# def read_file(file):\n#     data = []\n#     with open(file, \"r\") as f:\n#         for line in f:\n#             data.append(line.split(','))\n#     return data\n\n# print(read_file(files[0])[1:])\n# npdata = np.array(read_file(files[0]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(npdata[0:10])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tvcount = 0 # select 'TV Show', count(type) from netflix where type = 'TV Show'\n# mvcount = 0 # select 'Movie', count(type) from netflix where type = 'Movie'\n\n# print(len(npdata))\n# for x in npdata:\n# #     print(x[1])\n#     if 'TV Show' in x:\n#         tvcount +=1\n#     elif 'Movie' in x:\n#         mvcount +=1\n\n# print(\"TV Show : \",tvcount)\n# print(\"Movies  : \",mvcount)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pddata = pd.read_csv(files[0], parse_dates = ['date_added'])\n(pddata.head(5))\n\n# # numerical cols\n# (pddata.describe())\n\n# (pddata.info())\n\n(pddata.tail(5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(pddata['type'].head(10))\n\nprint(pddata['type'].describe())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(pddata[pddata['type'] == 'Movie']['type'].count)  # select 'Movie', count(type) from netflix where type = 'Movie'\nprint(pddata[pddata['type'] == 'TV Show']['type'].count)  # select 'TV Show', count(type) from netflix where type = 'TV Show'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(pddata['director'][pddata['director'].isna()].index)\n\nprint(pddata.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pddata.iloc[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pddata.at[0,'type']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pd -> data structure [(1D)Series,(2D)DataFrame, (ND)Panel]\n# (2D)DataFrame Tabular/Formated DataStructure\n\n# for label, content in pddata.items():\n#     print(label,content)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pddata['rating'].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# select rating, count(*) as 'rating_count' from netflix group by rating\n# TV MA 2863\n# pddata.groupby('rating').describe()\n\nrating_data = pddata.groupby('rating')\n\nratings = rating_data.agg(np.size)['show_id']\nprint(len(pddata))\n\ntsize = len(pddata)\n\nfor label, content in ratings.items():\n    ratingc = int(content)\n    dataper = (ratingc / tsize) * 100\n    print(label, format(dataper, '0.2f'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get dummies categorical data into  the columns : values of data 0/1\nrating_data = pd.get_dummies(pddata['rating'])\nrating_data.head(10)\n\n# ['G','NC', .....]\n#     G   NC  ........\n# 0   1   0  0 0 0  \n# 1   0   1  0 0 0 \n\n\n\n# for lable in rating_data.columns:\n#     print(lable, rating_data[lable].sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pddata['director'][pddata['director'].isna()].index","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"directordata = pddata.drop(pddata['director'][pddata['director'].isna()].index)\nprint(directordata['director'].head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"director_counts = directordata.groupby('director').agg(np.size)['show_id']\ndirector_counts\n# for lable, content in director_counts.items():\n#     direc = int(content)\n#     dataper = (direc / tsize) * 100\n#     print(lable, format(dataper, '0.2f'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def split_genre(item):\n    return item.split(',')\n\ngenre = pddata['listed_in'].apply(split_genre)\n\nprint(genre)\n\n# not allow duplicate value\ndata_g = set()\n\nfor item in genre:\n    for g in item:\n        data_g.add(g.strip())\n\ngenere_list = list(data_g)\nprint(len(genere_list))\nprint(genere_list[0:5])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# genre = pd.get_dummies(genere_list) \n# genre.head(10)\n\nfor genr in genere_list:\n    pddata[genr] = np.zeros(len(pddata))\n\npddata[genere_list].tail(2)\nfor label, item in pddata['listed_in'].items():\n    for genr in genere_list:\n        if genr in item:\n            pddata.at[label, genr] = 1.0\npddata[genere_list].tail(2)\n\n\npddata[(pddata['type'] == 'TV Show') & (pddata['Comedies'] == 1)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generes = {}\nfor genr in genere_list:\n    generes[genr.strip()] = pddata[genr].sum()\nprint(generes)\npdgenre = pd.Series(data = generes , index = genere_list)\n\n\npdgenre","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# countrydata = pddata.drop(pddata['country'][pddata['country'].isnull()].index)\n\n# countrydata = pddata.drop(pddata['country'][pddata['country'].isna()].index)\n\ncountrydata = pddata['country'].dropna()\n\ndef split_country(item):\n    splidata = []\n    try:\n        splidata = item.split(',')\n    except:\n        splidata = np.nan\n    return splidata\n\n# inline function\n# lambda x : x > 10\n\npdcountry = countrydata.apply(split_country)\n\n\n# United States, India\nunique_country = set()\n\nfor items in pdcountry:\n    for item in items:\n        unique_country.add(item.strip())\n\nunique_country = list(unique_country)\n\nunique_country.remove('')\n\ncountry_list = {}\nfor items in countrydata:\n    for item in unique_country:\n        if item in items:\n            if item in country_list.keys():\n                country_list[item] += 1\n            else:\n                country_list[item] = 1\n\nprint(country_list)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for country in country_list:\n    pddata[country] = np.zeros(len(pddata))\n\npddata.drop(pddata['country'][pddata['country'].isna()].index, inplace = True)\n\nprint(len(pddata))\n# pddata[genere_list].tail(2)\nfor label, item in pddata['country'].items():\n    for country in country_list:\n        if country in item:\n            pddata.at[label, country] = 1.0\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pddata.drop(unique_country, axis=1)\n\npddata['United States'][pddata['type'] == 'TV Show'].sum()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pddata[unique_country][pddata['type'] == 'Movie'].sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Grouping Type with Duration\n\nduration = pddata['duration'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grouping_type_dur = pddata.groupby(['type','duration']).agg(np.size)\ngrouping_type_dur.rename(columns={\"show_id\": \"group_by_type_dur\"}, inplace= True)\n\ngrouping_type_dur.drop(grouping_type_dur.columns[1:],axis=1,inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grouping_type_dur.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grouping_type_dur[grouping_type_dur['group_by_type_dur'] > 50 ].loc['TV Show']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grouping_type_dur[grouping_type_dur['group_by_type_dur'] > 50 ].loc['Movie']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grouping_type_dur[grouping_type_dur['group_by_type_dur'] > 50 ].loc['TV Show'].sort_values('group_by_type_dur',ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grouping_type_dur[grouping_type_dur['group_by_type_dur'] > 50 ].loc['Movie'].sort_values('group_by_type_dur',ascending = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grouping_type_dur['season'] = np.zeros(len(grouping_type_dur))\ngrouping_type_dur['mint'] = np.zeros(len(grouping_type_dur))\n\ngrouping_type_dur","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grouping_type_dur.index\n\ngrouping_type_dur.reset_index(inplace=True)\ngrouping_type_dur.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(grouping_type_dur.head())\n\nfor index,item in grouping_type_dur['duration'].items():\n    if 'Seasons' in grouping_type_dur.at[index,'duration']:\n        grouping_type_dur.at[index, 'season'] = int(grouping_type_dur.at[index,'duration'].replace('Seasons','').strip())\n    elif 'Season' in grouping_type_dur.at[index,'duration']:\n        grouping_type_dur.at[index, 'season'] = int(grouping_type_dur.at[index,'duration'].replace('Season','').strip())\n    elif 'min' in grouping_type_dur.at[index,'duration']:\n        grouping_type_dur.at[index, 'mint'] = int(grouping_type_dur.at[index,'duration'].replace('min','').strip())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grouping_type_dur\n\nprint(int(grouping_type_dur.at[index,'duration'].replace('Seasons','').strip()))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grouping_type_dur[(grouping_type_dur['season'] >= 1) & (grouping_type_dur['season'] <= 3)].sum()\n\n# print(grouping_type_dur['group_by_type_dur'].sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grouping_type_dur[(grouping_type_dur['season'] == 1)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"season13 = grouping_type_dur[(grouping_type_dur['season'] >= 1) & (grouping_type_dur['season'] <= 3)].sum()['group_by_type_dur']\ntotal = grouping_type_dur[grouping_type_dur['type'] == 'TV Show']['group_by_type_dur'].sum()\n\nprint(format(season13/total, '.2%'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"season45 = grouping_type_dur[(grouping_type_dur['season'] > 3)].sum()['group_by_type_dur']\ntotal = grouping_type_dur[grouping_type_dur['type'] == 'TV Show']['group_by_type_dur'].sum()\n\nprint(format(season45/total, '.2%'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"titlegrp = pddata.groupby(['title']).agg(np.size)\n# print(titlegrp)\n\n# titlegrp[titlegrp['type'] == 'TV Show']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"titlegrp.drop(titlegrp.columns[1:],axis=1,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"titlegrp.sort_values('show_id',ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualisation with Matplotlib","metadata":{}},{"cell_type":"code","source":"import matplotlib\nimport matplotlib.pyplot as plt\n\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize= (16, 16))\n\n# category based graphs\nxdata = (pdgenre.index)[:10]\nydata = list(map(int,pdgenre.values[:10]))\nplt.plot(xdata,ydata)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# top 10 listed genre\ntop10genre = pdgenre.sort_values(ascending=True).head(10)\n\nx = top10genre.index\ny = top10genre.values\n\nplt.figure(figsize= (16, 16))\nplt.style.use('classic')\nplt.plot(x,y)\nplt.xlabel(\"Category\")\nplt.ylabel(\"Count\")\nplt.title(\"Category Vs Count\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# top 10 listed genre\ntop10genre = pdgenre.sort_values(ascending=True).head(10)\n\nx = top10genre.index\ny = top10genre.values\n\nyav = np.array(y).std()\n\nplt.figure(figsize= (16, 16))\nplt.style.use('default')\nfig, ax = plt.subplots()\nax.bar(x, y, 0.35, yerr=yav, label='Category')\nplt.xticks(x,rotation ='vertical')\n\nfig.set_figheight(20)\nfig.set_figwidth(20)\nplt.xlabel(\"Category\")\nplt.ylabel(\"Count\")\nplt.title(\"Category Vs Count\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(1, 3, figsize=(9, 3), sharey=True)\naxs[0].bar(x, y)\naxs[0].set_xticklabels(x,rotation ='vertical')\naxs[1].scatter(x, y)\naxs[1].set_xticklabels(x,rotation ='vertical')\naxs[2].plot(x, y)\naxs[2].set_xticklabels(x,rotation ='vertical')\n\nfig.suptitle('Categorical Plotting')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# country based graphs\n\ncountrydata = pd.Series(country_list)\nx = countrydata.sort_values(ascending=False).head(10).index\ny = countrydata.sort_values(ascending=False).head(10).values\n\n\n\nfig, axs = plt.subplots(1, 1, figsize=(16, 16), sharey=True)\nplt.style.use('classic')\nplt.xlabel(\"Category\")\nplt.ylabel(\"Count\")\nplt.title(\"Category Vs Count\")\naxs.pie(y, labels = x,autopct='%1.2f%%')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ustv = pddata['United States'][pddata['type'] == 'TV Show'].sum()\nusmv = pddata['United States'][pddata['type'] == 'Movie'].sum()\n\nprint(ustv,usmv)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 16))\nfig.subplots_adjust(wspace=0)\nplt.style.use('default')\nplt.xlabel(\"Category\")\nplt.ylabel(\"Count\")\nplt.title(\"Category Vs Count\")\nax1.pie(y, labels = x,autopct='%1.2f%%')\n\nusrange = [ustv,usmv]\ncolors = [[.1, .3, .5], [.1, .3, .3]]\nxpos = 0\nbottom = 0\nwidth = 0.35\n\nfor j in range(len(usrange)):\n    height = usrange[j]\n    ax2.bar(xpos, height, width, bottom=bottom, color=colors[j])\n    ypos = bottom + ax2.patches[j].get_height() / 2\n    bottom += height\n    ax2.text(xpos, ypos, \"%d%%\" % ((ax2.patches[j].get_height() * 100) /(ustv+usmv)),\n             ha='center')\n    \nax2.set_title('Type Based Data')\nax2.legend(('TV-Show', 'Movie'))\nax2.axis('off')\nax2.set_xlim(- 2.5 * width, 2.5 * width)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from wordcloud import WordCloud\n\nplt.subplots(figsize =(8,8))\nwordcloud = WordCloud(\n                            background_color = 'white',\n                            width = 512,\n                            height = 384\n                        ).generate(\" \".join(pddata['listed_in']))\n\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.savefig('graph.png')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"movie = pddata[pddata['type'] == 'Movie']\ntv = pddata[pddata['type'] == 'TV Show']\n\ndata = pddata[['type', 'release_year']]\ndata = data.value_counts().to_frame()\ndata.reset_index(level=[0,1], inplace=True)\ndata = data.rename(columns = {0:'count'})\ndata = pd.concat([data[data['type'] == 'Movie'][:10], data[data['type']== 'TV Show'][:10]])\n\nxmv = data[data['type'] == 'Movie'].sort_values(by=['release_year'],ascending=True)\nxtv = data[data['type'] == 'TV Show'].sort_values(by=['release_year'],ascending=True)\n\n\nfig, ax = plt.subplots()\nax.plot(xmv['release_year'], xmv['count'], label=\"Movie\")\nax.plot(xtv['release_year'], xtv['count'], label=\"TV Show\")\nax.legend()\n\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"catwithyear = pddata.groupby(['release_year']).agg(np.sum)[pdgenre.index]\ncatwithyear.sort_values(by=['release_year'],ascending=False)\n\ntop10cat = catwithyear[catwithyear.columns[:10]].sort_values(by=['release_year'],ascending=False)\n\nyear = top10cat.head(10).index\n\nfig, ax = plt.subplots()\n\nfor item in top10cat.head(10).columns[:10]:\n    #print(top10cat[item].values)\n    ax.plot(year, top10cat[item].values[:10], label=item)\n\nax.legend()\n\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"countryyear = pddata.groupby(['release_year']).agg(np.sum)[country_list.keys()]\ncountryyear.sort_values(by=['release_year'],ascending=False)\n\ntop10country = countryyear[countryyear.columns[:10]].sort_values(by=['release_year'],ascending=False)\n\nyear = top10country.head(10).index\n\nfig, ax = plt.subplots()\n\nfor item in top10country.head(10).columns[:10]:\n    #print(top10cat[item].values)\n    ax.plot(year, top10country[item].values[:10], label=item)\n\nax.legend()\n\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# top 10 Ratings\nratings = pddata['rating'].unique()\nratings\n\n\nratinglist = []\ndatalist = []\nfor rating in ratings:\n    rat = (pddata[pddata['rating'] == rating]['rating'].value_counts().values)\n    if bool(rat):\n        ratinglist.append(rating)\n        datalist.append(rat[0])\n\nplt.figure(figsize= (16, 16))\nplt.style.use('default')\nplt.bar(ratinglist,datalist,width=0.35)\nplt.xlabel(\"Ratings\")\nplt.ylabel(\"Count\")\nplt.title(\"Rating Vs Count\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# top 10 directors\nxdir = director_counts.sort_values(ascending=False)[:10].index\nydir = director_counts.sort_values(ascending=False)[:10].values\n\n\nplt.figure(figsize= (16, 16))\nplt.style.use('default')\nplt.bar(xdir,ydir,width=0.35)\nplt.xlabel(\"Director\")\nplt.ylabel(\"Count\")\nplt.title(\"Director Vs Count\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\n\n\n\nsns.heatmap(pddata[pdgenre.index[:10]].corr(),annot=True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ctlist = pd.Series(country_list)\nplt.figure(figsize= (16, 16))\n\nsns.heatmap(pddata[ctlist.index[:15]].corr(),annot=True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Recommendation system \n# user    moneyheist: Thriller\n# sumit    w : 1 visit count\n#          r : 4 rating count\n\n# market basket analysis -> Frequent Itemset Algorithm\n# sumit milk,butter,bread\n# sumit2 milk,bread,sugar\n# sumit3 bread,butter,jam\n\n\nctlist = pd.Series(country_list)\nplt.figure(figsize= (16, 16))\n\nsns.heatmap(pddata[pddata['type'] == 'TV Show'][ctlist.index[:15]].corr(),annot=True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ctlist = pd.Series(country_list)\nplt.figure(figsize= (16, 16))\n\nsns.heatmap(pddata[pddata['type'] == 'Movie'][ctlist.index[:15]].corr(),annot=True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ctlist = pd.Series(country_list)\nplt.figure(figsize= (16, 16))\n\nsns.heatmap(pddata[pddata['type'] == 'Movie'][pdgenre.index[:15]].corr(),annot=True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ctlist = pd.Series(country_list)\nplt.figure(figsize= (16, 16))\n\nsns.heatmap(pddata[pddata['type'] == 'TV Show'][pdgenre.index[:15]].corr(),annot=True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}