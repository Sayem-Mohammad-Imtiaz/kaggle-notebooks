{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"3a0c06f5-a2dd-67cc-4b2d-bb1c2bdc5044"},"source":"Lets try to predict the income that move can generate based on the director, actors, genre and budget.\nUnfortunately category encoders are not available in Kaggle."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"58143417-24b5-ce6a-57e3-95263918d382"},"outputs":[],"source":"from __future__ import print_function\n\nimport matplotlib.pyplot as plt\nimport os\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn import linear_model, pipeline\n#import category_encoders as ce\n\nfrom sklearn import preprocessing\nfrom collections import defaultdict\n\ndf = pd.read_csv(\"../input/movie_metadata.csv\")\ndf.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"8094ac1e-8231-1d1d-5740-9220cfb5e34e"},"source":"Lets remove NaNs and irrelevant columns"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"86d59f43-bcd9-0770-dc29-399c42d327e2"},"outputs":[],"source":"clean_data = df[df['director_name'].notnull() & df['duration'].notnull() & df['actor_2_name'].notnull() & df['genres'].notnull()\n               & df['actor_1_name'].notnull() & df['actor_3_name'].notnull() & df['plot_keywords'].notnull() & df['country'].notnull()\n               & df['title_year'].notnull() & df['budget'].notnull() & df['gross'].notnull()]\nx_list_pre = ['director_name','duration','actor_2_name', 'genres', 'actor_1_name', 'actor_3_name', \n          'country', 'title_year','budget','gross']\nx_list_enc = ['director_name','actor_2_name', 'actor_1_name', 'actor_3_name', \n          'country']\nx_list_add = ['duration','title_year','budget']\nx_list_train = ['director_name','duration','actor_2_name', 'genres', 'actor_1_name', 'actor_3_name', \n          'country', 'title_year','budget']"},{"cell_type":"markdown","metadata":{"_cell_guid":"3d65bdca-5a01-2f68-e385-18b7cb547cbc"},"source":"Lets get rid of the budget outliners"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7f8e5b81-ecc3-c97b-1e28-1393a166d57b"},"outputs":[],"source":"clean_data_slice = clean_data.ix[:,x_list_pre]\nmin_max=preprocessing.RobustScaler()\n\ne_data_minmax=min_max.fit_transform(clean_data_slice[['budget', 'gross']])\nclean_data_slice['budget'] = pd.DataFrame(e_data_minmax[:,0],index=clean_data_slice.index)\nclean_data_slice['gross'] = pd.DataFrame(e_data_minmax[:,1],index=clean_data_slice.index)\ncenter_data_slice = clean_data_slice[clean_data_slice['budget']<5]\ncenter_data_slice.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"be81a330-a43d-da98-e93a-c5c15de8e2a0"},"source":"First let's encode genres"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"eeeaffa7-ebf8-6f7b-fc33-cc73aeacf302"},"outputs":[],"source":"\nle = defaultdict(preprocessing.LabelEncoder) \ns = center_data_slice['genres'].str.split('|').apply(pd.Series, 1)\ndel center_data_slice['genres']\ns = s.fillna('')\n\ngenres_num = s.apply(lambda x: le[x.name].fit_transform(x))\ngenres_num.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"3cc89c16-6ff8-9ee2-90fb-7f0ddce4d663"},"source":"Then let's encode all categorical columns."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"37f7055c-495b-e6e2-2ac0-9553bf8f1734"},"outputs":[],"source":"    encode_slice=center_data_slice[x_list_enc]\n    encoded_data = encode_slice.apply(lambda x: le[x.name].fit_transform(x))\n    encoded_data = encoded_data.join(genres_num)\n    encoded_data.head()\n    #encoder = ce.BinaryEncoder(cols=['director_name', 'country', 'actor_2_name', 'actor_1_name', 'actor_3_name']) \n    # 0,33\n    #encoder = ce.HashingEncoder(cols=['director_name', 'country', 'actor_2_name', 'actor_1_name', 'actor_3_name']) \n    # 0,36\n    #encoder = ce.OneHotEncoder(cols=['director_name', 'country', 'actor_2_name', 'actor_1_name', 'actor_3_name']) \n    # 0,40\n    #\n    #encoder = ce.BackwardDifferenceEncoder(cols=['director_name', 'country','actor_2_name', 'actor_1_name', 'actor_3_name'])\n    #0.45\n    #encoder = ce.HelmertEncoder(cols=['director_name', 'country','actor_2_name', 'actor_1_name', 'actor_3_name'])\n    # 0.38\n    #encoder = ce.SumEncoder(cols=['director_name', 'country','actor_2_name', 'actor_1_name', 'actor_3_name'])\n    # 40%"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5c19e7f5-766c-abec-b6c5-fac5e8942484"},"outputs":[],"source":"encoded_data = encoded_data.join(clean_data_slice[x_list_add])\ny_data = center_data_slice['gross']\nencoded_data.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"e8468016-c0d3-0c7b-faca-1964c3670215"},"source":"Split data in training and test set"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"25cfe70d-5484-371c-2965-e7eaf9ec0ad2"},"outputs":[],"source":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(encoded_data, y_data, \n                                                    test_size=0.25, random_state=0)"},{"cell_type":"markdown","metadata":{"_cell_guid":"47a2f9dc-4c91-6007-20c5-f5b177257ede"},"source":"Get average of 3-fold cross-validation score using an SVC estimator"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c83b11f2-8d8b-0c31-1902-9567bef3daa2"},"outputs":[],"source":"n_folds = 3\n\nfrom sklearn.model_selection import KFold\n\n\n# We set random_state to ensure we get the same splits every time we run this.\nkf = KFold(n_splits=n_folds, random_state=1)\nkf = kf.get_n_splits(x_train)"},{"cell_type":"markdown","metadata":{"_cell_guid":"ad375592-8d09-1755-9263-1f70018c5402"},"source":"Let's try RandomForest"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c2a61f71-38d8-9ab3-d0e0-43e588b9af72"},"outputs":[],"source":"print ('Training Random Forest...')\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import cross_val_score\n\n\nclf_rf = RandomForestRegressor(n_estimators=1000,max_depth=10) \nclf_rf = clf_rf.fit( x_train, y_train )\nclassifier_score = clf_rf.score(x_test, y_test)\nprint ('The classifier accuracy score is {:.2f}'.format(classifier_score))\n# Get average of 3-fold cross-validation score \nscore = cross_val_score(clf_rf, x_test, y_test, cv=kf)\nprint ('The {}-fold cross-validation accuracy score for this classifier is {:.2f}'.format(n_folds, score.mean()))\n\nx_1=x_test['budget']\n\ny_1 = clf_rf.predict(x_test)\n\nplt.figure()\nplt.scatter(x_1, y_test, c=\"darkorange\", label=\"data\")\nplt.scatter(x_1, y_1, color=\"cornflowerblue\", label=\"max_depth=5\")\nplt.xlabel(\"data\")\nplt.ylabel(\"target\")\nplt.title(\"Random Forest Regression\")\nplt.legend()\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"17b3f59c-92c4-103e-d41c-fa40fc78338a"},"source":"There is a major problem with the predictions. Let's see if we can find any ideas looking at the smaller dataset."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"47dd20b3-0f06-b96a-fb0a-0e3de7cb535a"},"outputs":[],"source":"plt.figure()\nplt.scatter(x_1[:50], y_test[:50], c=\"darkorange\", label=\"data\")\nplt.scatter(x_1[:50], y_1[:50], color=\"cornflowerblue\", label=\"max_depth=5\")\nplt.xlabel(\"budget\")\nplt.ylabel(\"gross\")\nplt.title(\"Random Forest Regression\")\nplt.legend()\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"0e27862c-685b-5113-af82-c8149e61cff4"},"source":"Still the same :-("}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}