{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"hi, I see this data.\nsome people analysis method of clustering.\nbut i see this data which is claasification\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"pro=pd.read_csv('/kaggle/input/summer-products-and-sales-in-ecommerce-wish/summer-products-with-rating-and-performance_2020-08.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(pro.head(5))\nprint('''data's information''',pro.info())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"first, i chech number of null and delete columns which is 70% percentage of null. because i thint that it's too much to replace"},{"metadata":{"trusted":true},"cell_type":"code","source":"check=round(pro.isnull().sum()/pro.shape[0],1)\nprint(check)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_list=[x for x in check.index if check[x] == 1]\npro=pro.drop(drop_list,axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"and number of each column's unique  is 1   \nit says to me that it's the same condition.\nso it is not imfortant"},{"metadata":{"trusted":true},"cell_type":"code","source":"column=[]\nfor i in pro.columns:\n    print(i,len(pro[i].unique()))\n    if len(pro[i].unique()) ==1:\n        column.append(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(pro[column])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"before delete above column, check relation column \nfor example, When you buy clothes at an online shopping mall, there are two possible cases: a seasonal sale where you buy clothes for the season or when you buy winter clothes for the summer.\nThere may be people who buy goods.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(pro['theme'].unique())\npro['tags']=pro['tags'].str.contains('summer')\npro=pro.drop(column,axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"second, we distinguish each column' dytype, and \nif categorical column'null replace 'unknown'"},{"metadata":{"trusted":true},"cell_type":"code","source":"C=(pro.dtypes=='object')\nCate=list(C[C].index)\nInteger=(pro.dtypes=='int64')\nFloat=(pro.dtypes=='float64')\nNumer=list(Integer[Integer].index)+list(Float[Float].index)\npro[Cate]=pro[Cate].fillna('unknow')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"second_2,\nCategory data contain the same meaning, which standardizes it."},{"metadata":{"trusted":true},"cell_type":"code","source":"def size(x):\n    x=x.str.lower().tolist()\n    siz=['xxs','xs','s','m','l','xl','xxl','xxxl','xxxxl','xxxxxl','2xl','3xl','4xl','5xl']\n    stand_siz=['xxs','xs','s','m','l','xl','xxl','xxxl','xxxxl','xxxxxl']\n    for i in range(len(siz)):\n        for j in range(len(x)):\n            if x[j] == siz[i]:\n                x[j]=siz[i]\n\n    \n    for i in range(len(x)):\n        if x[i] in stand_siz:\n            pass\n        elif x[i]=='2xl':\n            x[i]='xxl'\n        elif x[i]=='3xl':\n            x[i]='xxxl'\n        elif x[i]=='4xl':\n            x[i]='xxxxl'\n        elif x[i]=='5xl':\n            x[i]='xxxxxl'\n        else:\n            x[i]='other'\n    return x\n\nColor_map  = {'NaN':'Unknown','Black':'black','black':'black','White':'white','white':'white','navyblue':'blue',\n             'lightblue':'blue','blue':'blue','skyblue':'blue','darkblue':'blue','navy':'blue','winered':'red',\n             'red':'red','rosered':'red','rose':'red','orange-red':'red','lightpink':'pink','pink':'pink',\n              'armygreen':'green','green':'green','khaki':'green','lightgreen':'green','fluorescentgreen':'green',\n             'gray':'grey','grey':'grey','brown':'brown','coffee':'brown','yellow':'yellow','purple':'purple',\n             'orange':'orange','beige':'beige'}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pro['product_variation_size_id']=size(pro['product_variation_size_id'])\npro['product_color']=pro['product_color'].map(Color_map)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(pro['product_variation_size_id'].unique())\nprint(pro['product_color'].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We're going to divide it into categories, but at least if the data in each column exceeds three-thirds, it's meaningless because it's already divided in the index. It also provides unnecessary size for one-hot encoding of data."},{"metadata":{"trusted":true},"cell_type":"code","source":"def check_unique(data):\n    column=data.columns\n    dic={}\n    for i in column:\n        unique=len(data[i].unique())\n        if unique>(data.shape[0])/3:\n            dic[i]=unique\n            \n    return dic","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pro=pro.drop(list(check_unique(pro[Cate])),axis=1)\npro['gap_price']=(pro['price']-pro['retail_price'])/pro['price']\npro=pro.drop(['price','retail_price'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"gap_price means between price and retail price percentage.\nThe reason I did this was to imply the meaning of the two columns by grouping them into one column."},{"metadata":{"trusted":true},"cell_type":"code","source":"pro=pro.drop(['rating_five_count','rating_four_count','rating_three_count','rating_two_count','rating_one_count'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The reason for erasing the above column is that information is already in the column called Rating, and the information that comes directly to consumers in selecting the product is the average score and the number of reviews. Some consumers look closely, but due to the nature of the product, there are many types and only information was selected intuitively in the purchase decision."},{"metadata":{"trusted":true},"cell_type":"code","source":"C=(pro.dtypes=='object')\nCate=list(C[C].index)\nInteger=(pro.dtypes=='int64')\nFloat=(pro.dtypes=='float64')\nNumer=list(Integer[Integer].index)+list(Float[Float].index)\n\npercentage25=pro.describe().loc['25%','units_sold']\npercentage50=pro.describe().loc['50%','units_sold']\npercentage75=pro.describe().loc['75%','units_sold']\nfor i in range(pro.shape[0]):\n    if pro.iloc[i,0]<percentage25:\n        pro.iloc[i,0]=0\n    elif (pro.iloc[i,0]>=percentage25) and (pro.iloc[i,0]<=percentage75):\n        pro.iloc[i,0]=1\n    else:\n        pro.iloc[i,0]=2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(pro[Numer].describe())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"i use box-plot concept. first, i say that this problem is classfication. so The reason why it sold so well is 2 as usual, 1 as usual, and if it doesn't sell abnormally, it's divided by 0."},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The reason why we put the number of members as the unit price of sales is simply to analyze our criteria based on sales volume."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(pro.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pro['product_color']=pro['product_color'].fillna('unknown')\npro['has_urgency_banner']=pro['has_urgency_banner'].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numer=pro[Numer]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(numer)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Based on earlier predictions from logistic,\nWe could see quite a few clusters in the rating and the rating count. Then I think we can get meaningful results from a marketing perspective if we focus on the rating and rating count."},{"metadata":{"trusted":true},"cell_type":"code","source":"group=[x for x in numer.columns if len(numer[x].unique())<=4]\nno_group=[x for x in numer.columns if len(numer[x].unique())>4]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import levene\nprint(pro)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The first assumption, normality, is that if you have more than 30 data, you have normality because of the central theorem.\nThe second is equal variableness, which is a levene hypothesis test, and if you reject the null hypothesis, use the Welch method."},{"metadata":{"trusted":true},"cell_type":"code","source":"gro=pro[group]\nrating=pro['rating']\nco_rating=pro['rating_count']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in group:\n    covar=pro.loc[:,['rating_count',i]]\n    unique=pro[i].unique()\n    ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}