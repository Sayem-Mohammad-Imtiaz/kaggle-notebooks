{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#read csv\ndata=pd.read_csv('/kaggle/input/league-of-legends-diamond-ranked-games-10-min/high_diamond_ranked_10min.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#data information\nprint(data.info())\nprint(data.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# is data balance?\n# yes  50vs50\nlose=data[data['blueWins']==0]\nwin=data[data['blueWins']==1]\nprint(win.shape[0]/(win.shape[0]+lose.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#My goal is to determine if the user can win based on the model I provided during the game.\n#In other words, only the information that can be obtained in the game is selected.\n# and gameid is not important in model \ndata=data.drop('gameId',axis=1)\ny=data['blueWins']\nX=data.drop(['blueWins','blueEliteMonsters','blueHeralds','blueTotalGold','blueTotalExperience',\n         'blueTotalJungleMinionsKilled','blueGoldDiff','blueExperienceDiff','blueTotalMinionsKilled',\n         'blueGoldPerMin','redWardsPlaced', 'redWardsDestroyed','redFirstBlood',\n         'redKills', 'redDeaths', 'redAssists',\n       'redEliteMonsters','redHeralds','redTotalGold', 'redTotalExperience','redTotalJungleMinionsKilled', 'redGoldDiff',\n       'redExperienceDiff','redGoldPerMin'],axis=1)\nX['CSPerdiff']=X['blueCSPerMin']-X['redCSPerMin']\nX['avgleveldiff']=X['blueAvgLevel']-X['redAvgLevel']\nX=X.drop(['blueCSPerMin','redCSPerMin','blueAvgLevel','redAvgLevel'],axis=1)\ncolumn=X.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix,classification_report\nfrom sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,make_scorer#정확도,민감도등\nfrom sklearn.metrics import roc_curve\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import GridSearchCV \n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test,y_train,y_test=\\\n    train_test_split(X,y,\n    test_size=0.4,\n    train_size=0.6,\n    random_state=12354,\n    shuffle=True)\n\nstdc=StandardScaler()\nX_train=stdc.fit_transform(X_train)\nX_test=stdc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#make model\nlogic=LogisticRegression(penalty='elasticnet',solver='saga',n_jobs=-1,l1_ratio=0.4)\nlogic.fit(X_train,y_train)\ny_pred=logic.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confmat=pd.DataFrame(confusion_matrix(y_test,y_pred),\nindex=['True[0]','True[1]'],\ncolumns=['Predict[0]','predict[1]'])\nprint(confmat)\nprint(classification_report(y_test,y_pred)) \n#accuarcy  71%","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking overfitting\nfrom sklearn.model_selection import KFold\nfold=KFold(n_splits=10)\ntrain_sizes,train_scores,test_scores=\\\n    learning_curve(estimator=logic,#수정\n    X=X_train,\n    y=y_train,\n    train_sizes=np.linspace(0.1,1.0,10),\n    n_jobs=-1,\n    cv=fold)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n\ntrain_mean=np.mean(train_scores,axis=1)\ntrain_std=np.std(train_scores,axis=1)\ntest_mean=np.mean(test_scores,axis=1)\n\ntest_std=np.std(test_scores,axis=1)\n\nplt.plot(train_sizes,train_mean,\ncolor='blue',marker='o',\nmarkersize=5,label='training accuracy')\n\nplt.fill_between(train_sizes,\ntrain_mean+train_std,\ntrain_mean-train_std,\nalpha=0.5,color='blue')\n\nplt.plot(train_sizes,test_mean,\ncolor='green',linestyle='--',\nmarker='s',markersize=5,\nlabel='validation accuracy')\nplt.fill_between(train_sizes,\ntest_mean+test_std,\ntest_mean-test_std,\nalpha=0.15,color='green')\n\nplt.grid()\nplt.xlabel('number of trainning samples')\nplt.ylabel('accuracy')\nplt.legend(loc='lower right')\nplt.ylim([0,1.03])\nplt.tight_layout()\nplt.show()\n\n# I was able to determine that there was no problem with overfit.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#roc_auc_score\nfpr,tpr,thresholds=roc_curve(y_test,logic.predict_proba(X_test)[:,1])\n\nplt.plot(fpr,tpr,'--',label='logic')\nplt.plot([0,1],[0,1],'-',label='50%')\nplt.plot([fpr],[tpr],'r-',ms=10)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cross_stfold=cross_validate(estimator=logic,X=X_train,y=y_train,cv=fold,n_jobs=-1,\n                          scoring=['accuracy','roc_auc'])\n\nprint(cross_stfold['test_accuracy'].mean())\n#72%\nprint(cross_stfold['test_accuracy'].std())\n# 2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import make_pipeline\n\nlogicpipe=make_pipeline(LogisticRegression(penalty='elasticnet',solver='saga'\n                                           ,l1_ratio=0.5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(logicpipe.get_params().keys())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param_l1_ratio=[0.1,0.2,0.3,0.4,0.5,0.6,0.7]\nparam_penalty=['elasticnet']\nparam_solver=['saga']\nparam_gid=[{'logisticregression__l1_ratio':param_l1_ratio,\n           'logisticregression__solver':param_solver}]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gs=GridSearchCV(estimator=logicpipe,param_grid=param_gid,scoring='accuracy',cv=fold,n_jobs=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gs.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(gs.cv_results_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(gs.best_score_.mean())\n# i find logic best params ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(gs.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new=gs.best_estimator_\ny_pred_gs=new.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confmat1=pd.DataFrame(confusion_matrix(y_test,y_pred_gs),\nindex=['True[0]','True[1]'],\ncolumns=['Predict[0]','predict[1]'])\nprint(confmat1)\nprint('Classification Report')\nprint(classification_report(y_test,y_pred_gs))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_sizes,train_scores,test_scores=\\\n    learning_curve(estimator=new,#수정\n    X=X_train,\n    y=y_train,\n    train_sizes=np.linspace(0.1,1.0,10),\n    n_jobs=-1,\n    cv=fold)\n\ntrain_mean=np.mean(train_scores,axis=1)\ntrain_std=np.std(train_scores,axis=1)\ntest_mean=np.mean(test_scores,axis=1)\n\ntest_std=np.std(test_scores,axis=1)\n\nplt.plot(train_sizes,train_mean,\ncolor='blue',marker='o',\nmarkersize=5,label='training accuracy')\n\nplt.fill_between(train_sizes,\ntrain_mean+train_std,\ntrain_mean-train_std,\nalpha=0.5,color='blue')\n\nplt.plot(train_sizes,test_mean,\ncolor='green',linestyle='--',\nmarker='s',markersize=5,\nlabel='validation accuracy')\nplt.fill_between(train_sizes,\ntest_mean+test_std,\ntest_mean-test_std,\nalpha=0.15,color='green')\n\nplt.grid()\nplt.xlabel('number of trainning samples')\nplt.ylabel('accuracy')\nplt.legend(loc='lower right')\nplt.ylim([0,1.03])#수정  y값의 범위\nplt.tight_layout()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's see what features in the best model \n#have the most probabilistic effect\nnew_logic=LogisticRegression(l1_ratio=0.7, penalty='elasticnet',\n                                    solver='saga',n_jobs=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_logic.fit(X_train,y_train)\nprint(\"weight {}\".format(new_logic.coef_))\nprint(\"max weight {}\".format(new_logic.coef_.max()))\n# max weight location is 3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"frame=pd.DataFrame(data=X_train,columns=column)\nprint(frame)\n#I found out that what's in the third column now has the most impact.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#But from a statistical perspective,\n#I wondered if I could get the same result.\n\nimport statsmodels.api as sm\n\nxts=StandardScaler()\nX=xts.fit_transform(X)\nlogit_mod=sm.Logit(y,X)\nresult=logit_mod.fit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(result.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(np.exp(result.params))\n#Just like the model, from the odds concept,\n#we could see that the killer had the most impact on winning the game.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}