{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install tensorflow==2.0.0-beta1 \nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.offline as py\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport plotly.figure_factory as ff\nimport re\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import GridSearchCV, KFold\nimport lightgbm as lgb\nimport statsmodels.api as sm\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\n%matplotlib inline\nsns.set()\npy.init_notebook_mode(connected=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir(\"../input\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/pmsm_temperature_data.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"exp_time_count = df.profile_id.value_counts().sort_values()\nexp_time_count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10, 12))\nsns.barplot(y=exp_time_count.index, x=exp_time_count.values, order=exp_time_count.index, orient=\"h\")\nplt.title(\"Experiment time per profile_id\", fontsize=16)\nplt.ylabel(\"Profile ID\",fontsize=14)\nplt.xlabel(\"Experiment time\", fontsize=14)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_20 = df[df.profile_id==20].drop(\"profile_id\", axis=1).reset_index(drop=True)\ndf_20.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"corr_matrix = df_20.corr()\nfigure = ff.create_annotated_heatmap(z=corr_matrix.values,\n                                     x=list(corr_matrix.columns),\n                                     y=list(corr_matrix.index), \n                                     annotation_text=np.round(corr_matrix.values, 2),\n                                    colorscale=\"YlOrRd\",\n                                    showscale=True)\nfigure[\"layout\"][\"yaxis\"].update({\"tickangle\": -45})\nfigure[\"layout\"][\"xaxis\"].update({\"tickangle\": -45})\npy.iplot(figure)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"list_cor = list(df_20.corr()[df_20.corr() >= 0.5].stack().index)\nfor elem in list_cor:\n    if elem[0] == elem[1]:\n        list_cor.pop(list_cor.index(elem))\nlist_cor","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"list(df_20.corr()[df_20.corr() <= -0.3].stack().index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# with sns.plotting_context(font_scale=12):\n#     sns.pairplot(df_20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_20.describe()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fig = tls.make_subplots(rows=1, cols=len(df_20.columns), horizontal_spacing=0.05)\nfor i, var in enumerate(df_20.columns):\n    fig.append_trace(go.Box(y=df_20[var].values, name=var), 1, i+1)\nfig[\"layout\"].update(height=400, width=2000)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create `exp_time` variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"group_df = df.groupby(by=\"profile_id\").cumcount()\ndf = pd.concat([df, group_df], axis=1)\ndf = df.rename(columns={0: \"time_idx\"})\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"exp_time\"] = df[\"time_idx\"]*0.5\ndf = df.drop(\"time_idx\", axis=1)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 8))\nsns.heatmap(df.drop(\"profile_id\", axis=1).corr(), annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_vars = re.findall(r\"stator_\\w*|torque|pm\", \" \".join(df.columns))\ntarget_df = df[target_vars]\nattr_df = df.drop(target_vars, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"attr_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Case Study (`torque`)"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_vars = [\"i_q\", \"i_d\", \"u_d\", \"u_q\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Univariate Analysis (`torque`)"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df[\"torque\"], bins=10, kde=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(nrows=1, ncols=len(corr_vars), figsize=(10, 6))\nfor i, var in enumerate(corr_vars):\n    sns.distplot(df[var], ax=ax[i], bins=8, kde=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Checking for autocorrelation"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_acf(df_20[\"torque\"], title=\"Auto correlation (Torque) for profile_id = 20\", lags=1250)\n_ = plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_pacf(df_20[\"torque\"], title=\" Partial auto correlation (Torque) for profile_id = 20\", lags=5)\n_ = plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A strong autocorrelation can be noticed between the series of the `torque` variable. Noticing that the PACF crosses the x axis at `lag = 5` and the ACF has a geometric decay, an AR(4) could be used to model the time series data (if it is __stationary__) "},{"metadata":{},"cell_type":"markdown","source":"### Multivariate Analysis (`torque`)"},{"metadata":{"trusted":true},"cell_type":"code","source":"vars_ = corr_vars[:]\nvars_.append(\"torque\")\n# sns.pairplot(vars=vars_, hue=\"profile_id\", data=df)\nsns.pairplot(vars=vars_, data=df)\n_ = plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_analysis = df[vars_]\ncorr_matrix = df_analysis.corr()\nfigure = ff.create_annotated_heatmap(z=corr_matrix.values,\n                                     x=list(corr_matrix.columns),\n                                     y=list(corr_matrix.index), \n                                     annotation_text=np.round(corr_matrix.values, 2),\n                                    colorscale=\"YlOrRd\",\n                                    showscale=True)\nfigure[\"layout\"][\"yaxis\"].update({\"tickangle\": -45})\nfigure[\"layout\"][\"xaxis\"].update({\"tickangle\": -45})\npy.iplot(figure)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## OLS (`torque`)"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(attr_df, target_df, test_size=.2, shuffle=True)\nprofile_train = X_train[\"profile_id\"]\nprofile_test = X_test[\"profile_id\"]\nX_train = X_train.drop(\"profile_id\", axis=1)\nX_test = X_test.drop(\"profile_id\", axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ols(target, corr_vars, add_const):\n    target_train = y_train[\"torque\"].values.reshape(-1, 1)\n    y_scaler = StandardScaler().fit(target_train)\n    target_train = y_scaler.transform(target_train)\n    var_train = X_train[corr_vars]\n    var_names = var_train.columns\n    x_scaler = StandardScaler().fit(var_train)\n    var_train = pd.DataFrame(x_scaler.transform(var_train), columns=var_names)\n    if add_const:\n        var_train = sm.add_constant(var_train)\n    model = sm.OLS(target_train, var_train, ).fit()\n    return model, y_scaler, x_scaler, var_names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model, _, _, _ = ols(\"torque\", corr_vars, True)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The p-value for the `const` variable is considerably high, meaning that the null hypothesis should be accepted, that is, it's coefficient is equal to 0. So we'll discard the `const` variable (constant) and fit the model again."},{"metadata":{"trusted":true},"cell_type":"code","source":"model, y_scaler, x_scaler, var_names = ols(\"torque\", corr_vars, False)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_20 = y_scaler.transform(df.loc[df[\"profile_id\"]==20, \"torque\"].values.reshape(-1, 1))\nX_20 = x_scaler.transform(df.loc[df[\"profile_id\"]==20, corr_vars])\nX_20 = pd.DataFrame(X_20, columns=var_names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_20 = sm.OLS(y_20, X_20).fit()\nmodel_20.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Choosing only one `profile_id`, the __Durbin-Watson__ test scored a considerable small value, suggesting there is a strong postive autocorrelation."},{"metadata":{"trusted":true},"cell_type":"code","source":"ols_params = model.params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"profiles = df[\"profile_id\"].unique()\nprofile_lens = {profile: df[df[\"profile_id\"]==profile].shape[0] for profile in profiles}\nprofile_series = pd.Series()\n\nfor profile_len in profile_lens.items():\n    profile_series.at[profile_len[0]] = profile_len[1]\nprofile_series.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yhat = lambda X: X[corr_vars[0]]*ols_params[0] - X[corr_vars[1]]*ols_params[1] \\\n    - X[corr_vars[2]]*ols_params[2] - X[corr_vars[3]]*ols_params[3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# trace1 = go.Scatter3d(x=df_sample[corr_vars[0]],\n#                      y=df_sample[corr_vars[1]],\n#                      z=yhat(df_sample),\n#                      mode=\"lines\",\n#                      name=\"Regression Line\")\n\n# trace2 = go.Scatter3d(x=df_sample[corr_vars[0]],\n#                      y=df_sample[corr_vars[1]],\n#                      z=df_sample[\"torque\"],\n#                      mode=\"markers\",\n#                      name=\"True Values\")\n\n# data=[trace1, trace2]\n\n# layout = go.Layout(title={\"text\": \"Regression (Torque)\"},\n#                   scene=go.layout.Scene(xaxis=go.layout.scene.XAxis(title=corr_vars[0]),\n#                                 yaxis=go.layout.scene.YAxis(title=corr_vars[1]),\n#                                 zaxis=go.layout.scene.ZAxis(title=\"Torque\")))\n\n# fig = go.Figure(data=data, layout=layout)\n\n# py.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"var_names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_scaled = y_scaler.transform(y_test[\"torque\"].values.reshape(-1, 1))\nX_test_scaled = pd.DataFrame(x_scaler.transform(X_test[corr_vars]), columns=var_names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mae = mean_absolute_error(y_test_scaled, yhat(X_test_scaled))\nmae","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mse = mean_squared_error(y_test_scaled, yhat(X_test_scaled))\nmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r2 = r2_score(y_test_scaled, yhat(X_test_scaled))\nr2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"error_df = y_scaler.inverse_transform(yhat(X_test_scaled)) - y_test[\"torque\"]\nerror_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(error_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The errors are mainly located close to 0, but it presents a considerable variance relative to the true values."},{"metadata":{"trusted":true},"cell_type":"code","source":"error_df_perc = error_df / y_test[\"torque\"] * 100\nerror_df_perc.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(error_df_perc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_scaled = x_scaler.transform(X_test[[\"i_q\", \"i_d\", \"u_d\", \"u_q\"]])\nvar_pca = PCA(n_components=1).fit(X_test_scaled)\nvar_pca.explained_variance_ratio_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample = df.sample(n=1000)\nsample_X_scaled = pd.DataFrame(x_scaler.transform(sample[corr_vars]), columns=var_names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_plot = var_pca.transform(sample[corr_vars]).ravel()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_plot = y_scaler.inverse_transform(yhat(sample_X_scaled).values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_true = sample[\"torque\"]","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"plt.plot(x_plot, y_plot, alpha=0.8)\nplt.scatter(x_plot, y_true, c=\"red\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### LightGBM (`torque`)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# kfold = KFold(n_splits=5).split(X=X_train, y=y_train[\"torque\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# params_grid = {\"num_leaves\": [10, 20, 30],\n#               \"learning_rate\": 0.1,\n#               \"n_estimators\": [100, 150],\n#               \"boosting_type\": [\"gbdt\", \"dart\"],\n#               \"reg_alpha\": [1, 1.2],\n#               \"reg_lambda\": [1, 1.2, 1.4]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# gbm = lgb.LGBMRegressor()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# gbm_cv = GridSearchCV(gbm, param_grid=params_grid,\n#                       cv=kfold, return_train_score=True,\n#                       scoring=\"neg_mean_squared_error\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# gbm_cv.fit(X_train, y_train[\"torque\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# gbm_cv.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# gbm_cv.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {'boosting_type': 'gbdt',\n         'learning_rate': 0.1,\n         'n_estimators': 150,\n         'num_leaves': 30,\n         'reg_alpha': 1,\n         'reg_lambda': 1.2}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_scaler = StandardScaler().fit(X_train)\nX_train_scaled = x_scaler.transform(X_train)\ny_train_scaled = y_scaler.transform(y_train[\"torque\"].values.reshape(-1, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# gbm = lgb.LGBMRegressor(**gbm_cv.best_params_)\ngbm = lgb.LGBMRegressor(**params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gbm.fit(X_train_scaled, y_train_scaled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x=gbm.feature_importances_, y=X_train.columns)\nplt.xlabel(\"Feature Importance\", fontsize=12)\nplt.ylabel(\"Label\", fontsize=12)\nplt.title(\"Feature Importance (Torque)\", fontsize=16)\n_ = plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As seem before in the correlation matrix and the OLS regression, the `i_q` variable is the most important predictor of `torque`."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_scaled = x_scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_gbm = y_scaler.inverse_transform(gbm.predict(X=X_test_scaled))\nmae = mean_absolute_error(y_test[\"torque\"], pred_gbm)\nmse = mean_squared_error(y_test[\"torque\"], pred_gbm)\nr2 = r2_score(y_test[\"torque\"], pred_gbm)\nprint(\"MAE: %f\" %mae)\nprint(\"MSE: %f\" %mse)\nprint(\"R2 Score: %f\" %r2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems that, the LightGBM has fitted well the data through bruteforce."},{"metadata":{"trusted":true},"cell_type":"code","source":"error_df = pd.Series(pred_gbm) - y_test[\"torque\"].reset_index(drop=True)\nerror_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(error_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca_x = PCA(n_components=1).fit(X_test_scaled)\npca_x.explained_variance_ratio_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lineplot(x=pca_x.transform(X_test_scaled).reshape(-1), y=pred_gbm, color=\"red\", alpha=0.8)\nsns.scatterplot(x=pca_x.transform(X_test_scaled).reshape(-1), y=y_test[\"torque\"], color=\"blue\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As can be observed in the graph above, the lightGBM model has fitted well the data."},{"metadata":{},"cell_type":"markdown","source":"### GRU (`torque`) using `profile_id = 20` for training"},{"metadata":{},"cell_type":"markdown","source":"The amount of timesteps will be equal to 60, representing 0.5 minute of experiment time."},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepare_series(profile_id, df, target_var, test_size, series_size):\n    df_profile = df[df[\"profile_id\"]==profile_id].drop(\"profile_id\", axis=1)\n    dependent_vars = re.findall(r\"stator_\\w*|pm|torque\", \" \".join(df.columns))\n    df_target = df_profile[target_var]\n    df_vars = df_profile.drop(dependent_vars, axis=1)\n    target_train = df_target.values[:int((1-test_size)*df_target.shape[0])][series_size-1:]\n    target_test = df_target.values[int((1-test_size)*df_target.shape[0]):][series_size-1:]\n    train = df_vars.values[:int((1-test_size)*df_vars.shape[0]), ...]\n    test = df_vars.values[int((1-test_size)*df_vars.shape[0]):, ...]\n    train_series = np.zeros(shape=(train.shape[0]-series_size+1, series_size, train.shape[-1]))\n    test_series = np.zeros(shape=(test.shape[0]-series_size+1, series_size, test.shape[-1]))\n    for i in range(train.shape[0]-series_size+1):\n        train_series[i, ...] = train[i:i+series_size, ...]\n    for i in range(test.shape[0]-series_size):\n        test_series[i, ...] = test[i:i+series_size, ...]\n        \n    return train_series, test_series, target_train, target_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gru_model = tf.keras.models.Sequential()\ngru_model.add(tf.keras.layers.GRU(units=60, \n                                  return_sequences=True, \n                                  use_bias=True, \n                                  input_shape=(60, X_train.shape[1]-1),\n                                  dropout=0.3))\n\ngru_model.add(tf.keras.layers.GRU(units=60, \n                                  return_sequences=False, \n                                  use_bias=True, \n                                  dropout=0.3,\n                                  activation=\"linear\"))\n\n\ngru_model.add(tf.keras.layers.Dense(units=1, activation=\"linear\", use_bias=True))\n\ngru_model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\", \"mse\"])\n\ngru_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_series, test_series, target_train, target_test = prepare_series(20, \n                                                                      df.drop(\"exp_time\", axis=1), \n                                                                      \"torque\", 0.3, 60)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_gru = gru_model.fit(x=train_series, y=target_train,\n                            batch_size=512, epochs=50, \n                            validation_data=(test_series, target_test), callbacks=[callback])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_gru.history.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = np.arange(len(history_gru.history[\"loss\"]))+1","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"trace1 = go.Scatter(x=epochs, y=history_gru.history[\"loss\"], mode=\"lines\", name=\"Train Loss (MSE)\")\n\ntrace2 = go.Scatter(x=epochs, y=history_gru.history[\"val_loss\"], mode=\"lines\", name=\"Validation Loss (MSE)\")\n\ndata = [trace1, trace2]\n\nlayout = go.Layout(title={\"text\": \"Loss Curves (GRU)\"},\n                  scene=go.layout.Scene(xaxis=go.layout.scene.XAxis(title=\"Epoch\"),\n                                       yaxis=go.layout.scene.YAxis(title=\"Mean Absolute Error (LOSS)\")))\n\nfig = go.Figure(data=data, layout=layout)\n\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_gru = gru_model.predict(test_series)\nmae = mean_absolute_error(target_test, pred_gru.reshape(-1))\nmse = mean_squared_error(target_test, pred_gru.reshape(-1))\nr2_gru = r2_score(target_test, pred_gru.reshape(-1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"MAE: %f\" %mae)\nprint(\"MSE: %f\" %mse)\nprint(\"R2 Score: %f\" %r2_gru)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"error = pred_gru.reshape(-1) - target_test\nprint(\"MAX error: %f\" %error.max())\nprint(\"MIN error: %f\" %error.min())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(error, kde=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### LSTM (`torque`) using `profile_id = 20` for training"},{"metadata":{"trusted":true},"cell_type":"code","source":"lstm_model = tf.keras.models.Sequential()\nlstm_model.add(tf.keras.layers.LSTM(units=60, \n                                  return_sequences=True, \n                                  use_bias=True, \n                                  input_shape=(60, X_train.shape[1]-1),\n                                  dropout=0.3))\n\nlstm_model.add(tf.keras.layers.LSTM(units=60, \n                                  return_sequences=False, \n                                  use_bias=True, \n                                  dropout=0.3,\n                                  activation=\"linear\"))\n\nlstm_model.add(tf.keras.layers.Dense(units=1, activation=\"linear\", use_bias=True))\n\nlstm_model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\", \"mse\"])\n\nlstm_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_series, test_series, target_train, target_test = prepare_series(20, \n                                                                      df.drop(\"exp_time\", axis=1), \n                                                                      \"torque\", 0.3, 60)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_lstm = lstm_model.fit(x=train_series, y=target_train,\n                             batch_size=512, epochs=50, \n                              validation_data=(test_series, target_test), callbacks=[callback])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = np.arange(len(history_lstm.history[\"loss\"]))+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trace1 = go.Scatter(x=epochs, y=history_lstm.history[\"loss\"], mode=\"lines\", name=\"Train Loss (MSE)\")\n\ntrace2 = go.Scatter(x=epochs, y=history_lstm.history[\"val_loss\"], mode=\"lines\", name=\"Validation Loss (MSE)\")\n\ndata = [trace1, trace2]\n\nlayout = go.Layout(title={\"text\": \"Loss Curves (LSTM)\"},\n                  scene=go.layout.Scene(xaxis=go.layout.scene.XAxis(title=\"Epoch\"),\n                                       yaxis=go.layout.scene.YAxis(title=\"Mean Absolute Error (LOSS)\")))\n\nfig = go.Figure(data=data, layout=layout)\n\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_lstm = lstm_model.predict(test_series)\nmae = mean_absolute_error(target_test, pred_lstm.reshape(-1))\nmse = mean_squared_error(target_test, pred_lstm.reshape(-1))\nr2_lstm = r2_score(target_test, pred_lstm.reshape(-1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"MAE: %f\" %mae)\nprint(\"MSE: %f\" %mse)\nprint(\"R2 Score: %f\" %r2_lstm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"error = pred_lstm.reshape(-1) - target_test\nprint(\"MAX error: %f\" %error.max())\nprint(\"MIN error: %f\" %error.min())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(error, kde=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training the models for all profile_id's"},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_and_evaluate_profiles(model, df, target_var):\n    mae_array = np.array([], dtype=np.float32)\n    mse_array = np.array([], dtype=np.float32)\n    error = np.array([], dtype=np.float32)\n    for profile in df[\"profile_id\"].unique():\n        train_series, test_series, target_train, target_test = prepare_series(profile, \n                                                                      df.drop(\"exp_time\", axis=1), \n                                                                      target_var, 0.3, 60)\n        prediction = model.predict(test_series).reshape(-1)\n        error = np.concatenate([error, prediction-target_test], axis=0)\n        r2 = r2_score(target_test, prediction).reshape(-1)\n        mae = mean_absolute_error(target_test, prediction).reshape(-1)\n        mse = mean_squared_error(target_test, prediction).reshape(-1)\n        mae_array = np.concatenate([mae_array, mae], axis=0)\n        mse_array = np.concatenate([mse_array, mse], axis=0)\n        print(\"Model fitted to profile: %d ----VAL STATS >> R2: %f | MAE: %f | MSE: %f\" %(profile, r2, mae, mse))\n    print(\"\\n---------------------------------\\n\")\n    print(\"Average MAE: %f\" %np.mean(mae_array))\n    print(\"Average MSE: %f\" %np.mean(mse_array))\n    return error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def steps_per_epoch(df, series_size, batch_size, test_size):\n    total_size_train, total_size_test = (0, 0)\n    for profile_id in df.profile_id.unique():\n        total_size_train += (1-test_size)*df[df[\"profile_id\"]==profile_id].shape[0] - series_size\n        total_size_test += test_size*df[df[\"profile_id\"]==profile_id].shape[0] - series_size\n    return total_size_train//batch_size, total_size_test//batch_size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_gen(series_size, test_size, target_var=\"torque\", df=df.drop(\"exp_time\", axis=1)):\n    dep_vars = re.findall(r\"stator_\\w*|pm|torque\", \" \".join(df.columns))\n    for profile_id in df.profile_id.unique():\n        train_len = int((1-test_size)*df[df[\"profile_id\"]==profile_id].shape[0]) - series_size\n        X_profile = df[df[\"profile_id\"]==profile_id].drop(dep_vars, axis=1).drop(\"profile_id\", axis=1).values\n        y_profile = df.loc[df[\"profile_id\"]==profile_id, target_var].values\n        for i in range(train_len):\n            X = X_profile[i:i+series_size, :]\n            y = np.array([y_profile[i+series_size-1]])\n            yield X, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_gen(series_size, test_size, target_var=\"torque\", df=df.drop(\"exp_time\", axis=1)):\n    dep_vars = re.findall(r\"stator_\\w*|pm|torque\", \" \".join(df.columns))\n    for profile_id in df.profile_id.unique():\n        test_begin = int((1-test_size)*df[df[\"profile_id\"]==profile_id].shape[0])\n        test_end = df[df[\"profile_id\"]==profile_id].shape[0] - series_size\n        X_profile = df[df[\"profile_id\"]==profile_id].drop(dep_vars, axis=1).drop(\"profile_id\", axis=1).values\n        y_profile = df.loc[df[\"profile_id\"]==profile_id, target_var].values\n        for i in range(test_begin, test_end+1):\n            X = X_profile[i:i+series_size, :]\n            y = np.array([y_profile[i+series_size-1]])\n            yield X, y","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### GRU Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"gru_model = tf.keras.models.Sequential()\ngru_model.add(tf.keras.layers.GRU(units=50, \n                                  return_sequences=True, \n                                  use_bias=True, \n                                  input_shape=(60, X_train.shape[1]-1),\n                                  dropout=0.3))\n\ngru_model.add(tf.keras.layers.GRU(units=50, \n                                  return_sequences=False, \n                                  use_bias=True, \n                                  dropout=0.3,\n                                  activation=\"linear\"))\n\n\ngru_model.add(tf.keras.layers.Dense(units=1, activation=\"linear\", use_bias=True))\n\ngru_model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\", \"mse\"])\n\ngru_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"steps_train_val = steps_per_epoch(df, series_size=60, batch_size=512, test_size=.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = tf.data.Dataset.from_generator(generator=train_gen,\n                                               output_types=(tf.float32, tf.float32),\n                                              args=([60, .3]))\ntrain_dataset = train_dataset.shuffle(500).batch(512).repeat(10)\n\ntest_dataset = tf.data.Dataset.from_generator(generator=test_gen,\n                                               output_types=(tf.float32, tf.float32),\n                                             args=([60, .3]))\ntest_dataset = test_dataset.shuffle(500).batch(512).repeat(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\nhistory_gru = gru_model.fit_generator(generator=train_dataset,\n                                 steps_per_epoch=int(steps_train_val[0]),\n                                 callbacks=[callback],\n                                 validation_data=test_dataset,\n                                 validation_steps=int(steps_train_val[1]),\n                                 epochs=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = np.arange(len(history_gru.history[\"loss\"]))+1\ntrace1 = go.Scatter(x=epochs, y=history_gru.history[\"loss\"], mode=\"lines\", name=\"Train Loss (MSE)\")\n\ntrace2 = go.Scatter(x=epochs, y=history_gru.history[\"val_loss\"], mode=\"lines\", name=\"Validation Loss (MSE)\")\n\ndata = [trace1, trace2]\n\nlayout = go.Layout(title={\"text\": \"Loss Curves (GRU)\"},\n                  scene=go.layout.Scene(xaxis=go.layout.scene.XAxis(title=\"Epoch\"),\n                                       yaxis=go.layout.scene.YAxis(title=\"Mean Absolute Error (LOSS)\")))\n\nfig = go.Figure(data=data, layout=layout)\n\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### `Profile_id = 20`"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_series, test_series, target_train, target_test = prepare_series(20, \n                                                                      df.drop(\"exp_time\", axis=1), \n                                                                      \"torque\", 0.3, 60)\ngru_model.evaluate(x=test_series, y=target_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_gru = gru_model.predict(x=test_series)\nmae = mean_absolute_error(target_test, pred_gru.reshape(-1))\nmse = mean_squared_error(target_test, pred_gru.reshape(-1))\nr2 = r2_score(target_test, pred_gru.reshape(-1))\nprint(\"MAE: %f\" %mae)\nprint(\"MSE: %f\" %mse)\nprint(\"R2 Score: %f\" %r2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### `Profile_id = 4`"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_series, test_series, target_train, target_test = prepare_series(4, \n                                                                      df.drop(\"exp_time\", axis=1), \n                                                                      \"torque\", 0.3, 60)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_gru = gru_model.predict(x=test_series)\nmae = mean_absolute_error(target_test, pred_gru.reshape(-1))\nmse = mean_squared_error(target_test, pred_gru.reshape(-1))\nr2 = r2_score(target_test, pred_gru.reshape(-1))\nprint(\"MAE: %f\" %mae)\nprint(\"MSE: %f\" %mse)\nprint(\"R2 Score: %f\" %r2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### ALL `profile_id`"},{"metadata":{"trusted":true},"cell_type":"code","source":"error_gru = predict_and_evaluate_profiles(gru_model, df, \"torque\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(error_gru)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### LSTM Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"lstm_model = tf.keras.models.Sequential()\nlstm_model.add(tf.keras.layers.LSTM(units=50, \n                                  return_sequences=True, \n                                  use_bias=True, \n                                  input_shape=(60, X_train.shape[1]-1),\n                                  dropout=0.3))\n\nlstm_model.add(tf.keras.layers.LSTM(units=50, \n                                  return_sequences=False, \n                                  use_bias=True, \n                                  dropout=0.3,\n                                  activation=\"linear\"))\n\nlstm_model.add(tf.keras.layers.Dense(units=1, activation=\"linear\", use_bias=True))\n\nlstm_model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\", \"mse\"])\n\nlstm_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = tf.data.Dataset.from_generator(generator=train_gen,\n                                               output_types=(tf.float32, tf.float32),\n                                              args=([60, .3]))\ntrain_dataset = train_dataset.shuffle(500).batch(512).repeat(10)\n\ntest_dataset = tf.data.Dataset.from_generator(generator=test_gen,\n                                               output_types=(tf.float32, tf.float32),\n                                             args=([60, .3]))\ntest_dataset = test_dataset.shuffle(500).batch(512).repeat(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\nhistory_lstm = lstm_model.fit_generator(generator=train_dataset,\n                                 steps_per_epoch=int(steps_train_val[0]),\n                                 callbacks=[callback],\n                                 validation_data=test_dataset,\n                                 validation_steps=int(steps_train_val[1]),\n                                 epochs=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = np.arange(len(history_lstm.history[\"loss\"]))+1\ntrace1 = go.Scatter(x=epochs, y=history_lstm.history[\"loss\"], mode=\"lines\", name=\"Train Loss (MSE)\")\n\ntrace2 = go.Scatter(x=epochs, y=history_lstm.history[\"val_loss\"], mode=\"lines\", name=\"Validation Loss (MSE)\")\n\ndata = [trace1, trace2]\n\nlayout = go.Layout(title={\"text\": \"Loss Curves (LSTM)\"},\n                  scene=go.layout.Scene(xaxis=go.layout.scene.XAxis(title=\"Epoch\"),\n                                       yaxis=go.layout.scene.YAxis(title=\"Mean Absolute Error (LOSS)\")))\n\nfig = go.Figure(data=data, layout=layout)\n\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### `Profile_id = 20`"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_series, test_series, target_train, target_test = prepare_series(20, \n                                                                      df.drop(\"exp_time\", axis=1), \n                                                                      \"torque\", 0.3, 60)\nlstm_model.evaluate(x=test_series, y=target_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_lstm = lstm_model.predict(x=test_series)\nmae = mean_absolute_error(target_test, pred_lstm.reshape(-1))\nmse = mean_squared_error(target_test, pred_lstm.reshape(-1))\nr2 = r2_score(target_test, pred_lstm.reshape(-1))\nprint(\"MAE: %f\" %mae)\nprint(\"MSE: %f\" %mse)\nprint(\"R2 Score: %f\" %r2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### `Profile_id = 4`"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_series, test_series, target_train, target_test = prepare_series(4, \n                                                                      df.drop(\"exp_time\", axis=1), \n                                                                      \"torque\", 0.3, 60)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_lstm = lstm_model.predict(x=test_series)\nmae = mean_absolute_error(target_test, pred_lstm.reshape(-1))\nmse = mean_squared_error(target_test, pred_lstm.reshape(-1))\nr2 = r2_score(target_test, pred_lstm.reshape(-1))\nprint(\"MAE: %f\" %mae)\nprint(\"MSE: %f\" %mse)\nprint(\"R2 Score: %f\" %r2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### ALL `profile_id`"},{"metadata":{"trusted":true},"cell_type":"code","source":"error_lstm = predict_and_evaluate_profiles(lstm_model, df, \"torque\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(error_lstm)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}