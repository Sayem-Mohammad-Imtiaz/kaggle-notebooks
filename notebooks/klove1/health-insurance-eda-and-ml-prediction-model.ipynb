{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# Load libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom matplotlib.pyplot import show\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import scale\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import metrics\nfrom sklearn.datasets import make_classification\nfrom matplotlib import pyplot as plt\nimport imblearn\nfrom sklearn.metrics import recall_score, precision_score, f1_score\nfrom sklearn.metrics import roc_auc_score\n\nfrom sklearn.datasets import make_classification\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_curve, roc_auc_score\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection  import train_test_split\nfrom sklearn import metrics\nfrom sklearn.metrics import *\nimport statsmodels.formula.api as smf\nimport random\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn import metrics, datasets, tree\n%matplotlib inline\n\nfrom sklearn.metrics import mean_squared_error\nimport math\n\nfrom imblearn.under_sampling import RandomUnderSampler\nimport imblearn\n\nfrom sklearn.preprocessing import scale\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn import metrics, datasets\nfrom sklearn.model_selection import GridSearchCV\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load data\nsample_df = pd.read_csv(\"../input/health-insurance-cross-sell-prediction/sample_submission.csv\", low_memory = False)\ntrain_df = pd.read_csv(\"../input/health-insurance-cross-sell-prediction/train.csv\", low_memory = False)\ntest_df = pd.read_csv(\"../input/health-insurance-cross-sell-prediction/test.csv\", low_memory = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.columns\n# predict variable = Response","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Integrate three datasets  (sample_df, train_df and test_df) into one for Explanatory Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Left join sample_df and test_df\ndf = sample_df.merge(test_df, on='id', how='left')\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Stack train_df and test_df + sample_df\ndf = pd.concat([train_df,df])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_response = df.loc[df['Response'] == 1]\ndf_no_response = df.loc[df['Response'] == 0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{},"cell_type":"markdown","source":"### Base (Univariate) EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a function for countplot\ndef get_graph(data, xname1, title):\n\n    sns.set(style=\"darkgrid\")\n    total = float(len(data)) \n    ax = sns.countplot(x = xname1, data = data)\n    ax.set_title(title)\n    for p in ax.patches:\n        height = p.get_height()\n        ax.text(p.get_x()+p.get_width()/2.,\n                height + 3,\n                '{:1.2f}'.format(height/total),\n                ha=\"center\") \n    show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_graph(df, \"Gender\", \"Gender\")","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\nax = sns.countplot(x = \"Age\", data = df)\nax.set_title(\"Age\")\nplt.xticks(rotation=90)\nplt.xticks(size=7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.distplot(df[\"Age\"])\nax.set_title(\"Age\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_graph(df, \"Driving_License\", \"Driving_License\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.countplot(x = \"Region_Code\", data = df)\nax.set_title(\"Region_Code\")\nplt.xticks(rotation=60)\nplt.xticks(size=7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.distplot(df[\"Region_Code\"])\nax.set_title(\"Region_Code\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_graph(df, \"Previously_Insured\", \"Previously_Insured\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_graph(df, \"Vehicle_Age\", \"Vehicle_Age\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_graph(df, \"Vehicle_Damage\", \"Vehicle_Damage\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.distplot(df[\"Annual_Premium\"])\nax.set_title(\"Annual_Premium\")\n# plt.xticks(rotation=90)\n# plt.xticks(size=7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nax = sns.distplot(df[\"Policy_Sales_Channel\"])\nax.set_title(\"Policy_Sales_Channel\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.boxplot(df[\"Policy_Sales_Channel\"])\nax.set_title(\"Policy_Sales_Channel\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nax = sns.distplot(df[\"Vintage\"])\nax.set_title(\"Vintage\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.boxplot(df[\"Vintage\"])\nax.set_title(\"Vintage\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_graph(df, \"Response\", \"Response\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Multi-variate EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a function for multi-variate countplot\ndef get_compare_graph_count(data, xname1, hname, title):\n\n    sns.set(style=\"darkgrid\")\n    total = float(len(data)) \n    ax = sns.countplot(x = xname1, hue = hname, data = data)\n    ax.set_title(title)\n    for p in ax.patches:\n        height = p.get_height()\n        ax.text(p.get_x()+(p.get_width()/2.),\n                height + 3,\n                '{:1.2f}'.format(height/total),\n                ha=\"center\") \n    show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_compare_graph_count(df, \"Gender\", \"Response\", \"Gender vs Response\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.boxplot(x=df[\"Response\"], y = df[\"Age\"])\nax.set_title(\"Age vs Response\")","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True)\nsns.distplot(df_response[\"Age\"],  ax=ax1)\nsns.distplot(df_response[\"Age\"],  ax=ax2)\nax1.set_title(\"Response Age\")\nax2.set_title(\"No Response Age\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_compare_graph_count(df, \"Driving_License\", \"Response\", \"Driving_License vs Response\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True)\nsns.distplot(df_response[\"Region_Code\"],  ax=ax1)\nsns.distplot(df_response[\"Region_Code\"],  ax=ax2)\nax1.set_title(\"Response Region_Code\")\nax2.set_title(\"No Response Region_Code\")","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"ax = sns.boxplot(x=df[\"Response\"], y = df[\"Annual_Premium\"])\nax.set_title(\"Annual_Premium vs Response\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True)\nsns.distplot(df_response[\"Annual_Premium\"],  ax=ax1)\nsns.distplot(df_response[\"Annual_Premium\"],  ax=ax2)\nax1.set_title(\"Response Annual_Premium\")\nax2.set_title(\"No Response Annual_Premium\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.boxplot(x=df[\"Response\"], y = df[\"Policy_Sales_Channel\"])\nax.set_title(\"Policy_Sales_Channel vs Response\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True)\nsns.distplot(df_response[\"Policy_Sales_Channel\"],  ax=ax1)\nsns.distplot(df_response[\"Policy_Sales_Channel\"],  ax=ax2)\nax1.set_title(\"Response Policy_Sales_Channel\")\nax2.set_title(\"No Response Policy_Sales_Channel\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_compare_graph_count(df, \"Previously_Insured\", \"Response\", \"Previously_Insured vs Response\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_compare_graph_count(df, \"Vehicle_Age\", \"Response\", \"Vehicle_Age vs Response\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_compare_graph_count(df, \"Vehicle_Damage\", \"Response\", \"Vehicle_Damage vs Response\")","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"ax = sns.boxplot(x=df[\"Response\"], y = df[\"Vintage\"])\nax.set_title(\"Vintage vs Response\")","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True)\nsns.distplot(df_response[\"Vintage\"],  ax=ax1)\nsns.distplot(df_response[\"Vintage\"],  ax=ax2)\nax1.set_title(\"Response Vintage\")\nax2.set_title(\"No Response Vintage\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## correlation test"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"d = df.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr1 = df[[\"Age\", \"Driving_License\", \"Region_Code\", \"Previously_Insured\", \"Annual_Premium\", \"Policy_Sales_Channel\", \"Vintage\", \"Response\"]]\nf = plt.figure(figsize=(19, 15))\nplt.matshow(corr1.corr(), fignum=f.number)\nplt.xticks(range(corr1.shape[1]), corr1.columns, fontsize=14, rotation=45)\nplt.yticks(range(corr1.shape[1]), corr1.columns, fontsize=14)\ncb = plt.colorbar()\ncb.ax.tick_params(labelsize=14)\nplt.title('Correlation Matrix', fontsize=16)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" Response - previously_insured: -0.341170\t\n \n Policy_Sales_Channel - Age: -0.577826"},{"metadata":{},"cell_type":"markdown","source":"## Cramer's V test for categorical variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import chi2_contingency\n\n# Cramer's V function\ndef cramer_v(x, y):\n    n = len(x)\n    ct = pd.crosstab(x, y) # crosstab\n    chi2 = chi2_contingency(ct)[0]\n    v = np.sqrt(chi2 / (n * (np.min(ct.shape) - 1)))\n    return v","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cramer_v(df['Gender'], df['Response'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cramer_v(df['Vehicle_Age'], df['Response'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cramer_v(df['Vehicle_Damage'], df['Response'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Chi-squared Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"table = pd.crosstab(df[\"Response\"], df[\"Gender\"])\n\nchi2, p, dof, expected = chi2_contingency(table.values)\nprint(\"chi-sqr stat: \",chi2,\"p-value:\" ,p)\nsns.countplot(x=\"Gender\", hue=\"Response\", data=df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"table = pd.crosstab(df[\"Response\"], df[\"Vehicle_Age\"])\n\nchi2, p, dof, expected = chi2_contingency(table.values)\nprint(\"chi-sqr stat: \",chi2,\"p-value:\" ,p)\nsns.countplot(x=\"Vehicle_Age\", hue=\"Response\", data=df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"table = pd.crosstab(df[\"Response\"], df[\"Vehicle_Damage\"])\n\nchi2, p, dof, expected = chi2_contingency(table.values)\nprint(\"chi-sqr stat: \",chi2,\"p-value:\" ,p)\nsns.countplot(x=\"Vehicle_Damage\", hue=\"Response\", data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Chi-squared test does not support strong correlation between gender and response"},{"metadata":{},"cell_type":"markdown","source":"### Outlier analysis - EDA shows that there is no outliers in this dataset"},{"metadata":{},"cell_type":"markdown","source":"## Create dummy variables for the Vehicle_Age, Vehicle_Damage and Gender"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = pd.get_dummies(df, columns=['Vehicle_Age'])\ndf1 = pd.get_dummies(df1, columns=['Vehicle_Damage'])\ndf1 = pd.get_dummies(df1, columns=['Gender'])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Drop id column - no information in the id col\n\nDrop Driving_License column - 1 for all rows"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = df1.drop(['id'], axis = 1)\ndf1 = df1.drop(['Driving_License'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df1.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classification Model construction using machine-learning algorithms"},{"metadata":{},"cell_type":"markdown","source":"### Decision Tree Classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df1.drop(['Response'], axis = 1)\ny = df1[[\"Response\"]]\n\n# Split data; 25% test size from the combined dataset\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size =.25,random_state=1234, stratify=y)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a model (object) for classification\ndtm = DecisionTreeClassifier()\n# Build a decision tree\ndtm.fit(X_train, y_train)\ny_pred = dtm.predict(X_test)\n\n# Build a confusion matrix and show the Classification Report\ncm = metrics.confusion_matrix(y_test,y_pred)\nprint('\\nConfusion Matrix','\\n',cm)\nprint('\\nClassification Report','\\n',metrics.classification_report(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a function for evaluation metrics\ndef print_result(cm, y_test, y_pred):\n    sensitivity = cm[0,0]/(cm[0,0]+cm[0,1])\n    specificity = cm[1,1]/(cm[1,0]+cm[1,1])\n    mse = mean_squared_error(y_test, y_pred)\n    rmse = math.sqrt(mse)\n\n    print ('Accuracy:', accuracy_score(y_test, y_pred))\n    print ('F1 score:', f1_score(y_test, y_pred))\n    print ('Recall(Specificity):', recall_score(y_test, y_pred))\n    print('Sensitivity : ', sensitivity )\n    print ('Precision:', precision_score(y_test, y_pred))\n    print('RMSE:', math.sqrt(mse))\n    print ('AUC:', roc_auc_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print_result(cm, y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a function for roc plotting\ndef plot_roc(y_test, y_pred, title):\n    false_positive_rate1, true_positive_rate1, threshold1 = roc_curve(y_test, y_pred)\n\n    plt.subplots(1, figsize=(4,4))\n    plt.title(title, fontsize = 15)\n    plt.plot(false_positive_rate1, true_positive_rate1)\n    plt.plot([0, 1], ls=\"--\")\n    plt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\n    plt.ylabel('True Positive Rate')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate', fontsize = 10)\n    plt.xlabel('False Positive Rate', fontsize = 10)\n    plt.show()\n    print ('AUC:', roc_auc_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc(y_test, y_pred, 'ROC Curve for DT Before Resampling')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Naive Bayesian Classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X,y,test_size =.25,random_state=1234, stratify=y)\n# Create NB model\ngnb = GaussianNB()\ngnb.fit(X_train, y_train)\ny_pred = gnb.predict(X_test)\n# Build a confusion matrix\ncm = metrics.confusion_matrix(y_test,y_pred)\nprint(metrics.classification_report(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print_result(cm, y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc(y_test, y_pred, 'ROC Curve for NB Before Resampling')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest Classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build a random forest classification model\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size =.25,random_state=1234, stratify=y)\nrfcm = RandomForestClassifier()\nrfcm.fit(X_train, y_train)\ny_pred = rfcm.predict(X_test)\n\n# Build a confusion matrix and show the Classification Report\ncm = metrics.confusion_matrix(y_test,y_pred)\nprint('\\nConfusion Matrix','\\n',cm)\nprint('\\nClassification Report','\\n',metrics.classification_report(y_test,y_pred))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build a confusion matrix and show the Classification Report\ncm = metrics.confusion_matrix(y_test,y_pred)\nprint('\\nConfusion Matrix','\\n',cm)\nprint('\\nClassification Report','\\n',metrics.classification_report(y_test,y_pred))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print_result(cm, y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc(y_test, y_pred, 'ROC Curve for RF Before Resampling')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Neual Network Classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalize the data\nXn = scale(X)\n# Split data\nXn_train, Xn_test = train_test_split(Xn, test_size =.25,random_state=1234, stratify=y)\ny_train_1, y_test_1 = train_test_split(y, test_size=.25, random_state=1234, stratify=y)\n\n# Create a model\nnnm = MLPClassifier()\n\nnnm = MLPClassifier(hidden_layer_sizes=(20,), max_iter=1000,activation='logistic')\n\n# Make predictions\nnnm.fit(Xn_train, y_train_1)\ny_pred_1 = nnm.predict(Xn_test)\n\n# Build a confusion matrix and show the Classification Report\ncm = metrics.confusion_matrix(y_test_1,y_pred_1)\nprint('\\nConfusion Matrix','\\n',cm)\nprint('\\nClassification Report','\\n',metrics.classification_report(y_test_1,y_pred_1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print_result(cm, y_test_1, y_pred_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc(y_test_1, y_pred_1, 'ROC Curve for NN Before Resampling')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model performance result analysis before resampling\n#### 1. Naive Bayesian model gives the highest ROC_AUC score 0.6495\n#### 2. Neural Network model performs poorly giving the lowest ROC_AUC score 0.5 (Note: Recall, Precision and F1 scores are 0)"},{"metadata":{},"cell_type":"markdown","source":"# Resampling - Undersample strategy"},{"metadata":{},"cell_type":"markdown","source":"### The Dataset is imbalanced (Response 0: 91% vs Response 1: 9%), so I am using resampling method to mitigate the data imbalance problem and to improve the model performance"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df1.drop(['Response'], axis = 1)\ny = df1[\"Response\"]\n# define undersample strategy\nx_train, x_test, y_train, y_test = train_test_split(X,y,test_size =.25,random_state=1234, stratify=y)\n\nrus = RandomUnderSampler(sampling_strategy='majority')\nx_train_rus, y_train_rus = rus.fit_sample(x_train, y_train.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Before RUS, counts of label '1': {}\".format(sum(y_train==1)))\nprint(\"Before RUS, counts of label '0': {} \\n\".format(sum(y_train==0)))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"After RUS, counts of label '1': {}\".format(sum(y_train_rus==1)))\nprint(\"After RUS, counts of label '0': {}\".format(sum(y_train_rus==0)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Decision Tree - After Undersampling"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create instance of Decision Tree Classifier\ndtm_rus = DecisionTreeClassifier()\n\n\n# Fit the instance with training data\ndtm_rus.fit(x_train_rus, y_train_rus)\n\n# Predict using the fitted model\ny_pred_dt_rus = dtm_rus.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build a confusion matrix and show the Classification Report\ncm_dt_rus = metrics.confusion_matrix(y_test,y_pred_dt_rus)\nprint('\\nConfusion Matrix DT RUS','\\n',cm_dt_rus)\nprint('\\nClassification Report DECISION TREE RUS','\\n',metrics.classification_report(y_test,y_pred_dt_rus))\nprint('--------------------------------------------------------------------------------')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print_result(cm_dt_rus, y_test, y_pred_dt_rus)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc(y_test, y_pred_dt_rus, 'ROC Curve for DT After Resampling')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest After Resampling"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a model (object) for classification\nrfcm_rus = RandomForestClassifier()\n\n# Build a random forest classification model\nrfcm_rus.fit(x_train_rus, y_train_rus)\n\ny_pred_rf_rus = rfcm_rus.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build a confusion matrix and show the Classification Report\ncm_rf_rus = metrics.confusion_matrix(y_test,y_pred_rf_rus)\nprint('\\nConfusion Matrix RF RUS','\\n',cm_rf_rus)\nprint('\\nClassification Report RF RUS','\\n',metrics.classification_report(y_test,y_pred_rf_rus))\nprint(\"---------------------------------------------------------------------------------------\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print_result(cm_rf_rus, y_test, y_pred_rf_rus)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc(y_test, y_pred_rf_rus, 'ROC Curve for RF After Resampling')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Naive Bayes After Resampling"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a model (object) for classification\nnb_rus = GaussianNB()\n\n# Build a random forest classification model\nnb_rus.fit(x_train_rus, y_train_rus)\ny_pred_nb_rus = nb_rus.predict(x_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build a confusion matrix and show the Classification Report\ncm_nb_rus = metrics.confusion_matrix(y_test,y_pred_nb_rus)\nprint('\\nConfusion Matrix NB RUS','\\n',cm_nb_rus)\nprint('\\nClassification Report NB RUS','\\n',metrics.classification_report(y_test,y_pred_nb_rus))\nprint(\"---------------------------------------------------------------------------------------\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print_result(cm_nb_rus, y_test, y_pred_nb_rus)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc(y_test, y_pred_nb_rus, 'ROC Curve for NB After Resampling')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Neural Network After Resampling"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalize the data\nXn = scale(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set the 'stratify' option 'y' to sample \nXn_train, Xn_test = train_test_split(Xn, test_size =.25,random_state=1234, stratify=y)\ny_train, y_test = train_test_split(y, test_size=.25, random_state=1234, stratify=y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define undersample strategy\nrus = RandomUnderSampler(sampling_strategy='majority')\nxn_train_rus, y_train_rus = rus.fit_sample(Xn_train, y_train.ravel())\n\nnnm_rus = MLPClassifier(hidden_layer_sizes=(20,), max_iter=1000,activation='logistic')\n# nnm_smote = MLPClassifier(hidden_layer_sizes=(20,), max_iter=1000,activation='logistic')\n\n# Make predictions\nnnm_rus.fit(xn_train_rus, y_train_rus)\n# nnm_smote.fit(xn_train_smote, y_train_smote)\n\ny_pred_nn_rus = nnm_rus.predict(Xn_test)\n# y_pred_nn_smote = nnm_smote.predict(Xn_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('\\n ** Performance Scores **')\n# Build a confusion matrix and show the Classification Report\ncm_nn_rus = metrics.confusion_matrix(y_test,y_pred_nn_rus)\nprint('\\nConfusion Matrix','\\n',cm_nn_rus)\nprint('\\nClassification Report Neural Network - RUS','\\n',metrics.classification_report(y_test,y_pred_nn_rus))\n\nprint(\"---------------------------------------------------------------------------------\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print_result(cm_nn_rus, y_test, y_pred_nn_rus)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc(y_test, y_pred_nn_rus, 'ROC Curve for NN After Resampling')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model performance analysis after resampling\n\n#### 1. Performance greatly improved in all four ML models.\n#### 2. Neural Network model performed the best after resampling - 0.78493\n#### 3. While sensitivity dropped a certain degree, recall, precision, and AUC greatly increased after resampling"},{"metadata":{},"cell_type":"markdown","source":"# The final model: The Neural Network after under-resampling with ROC_AUC score 0.78493"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}