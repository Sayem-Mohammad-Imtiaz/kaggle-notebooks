{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Car Price Prediction\n\n## Problem Statement\n\nA Chinese automobile company Geely Auto aspires to enter the US market by setting up their manufacturing unit there and producing cars locally to give competition to their US and European counterparts.\n\nThey have contracted an automobile consulting company to understand the factors on which the pricing of cars depends. Specifically, they want to understand the factors affecting the pricing of cars in the American market, since those may be very different from the Chinese market. The company wants to know:\n\n* Which variables are significant in predicting the price of a car\n* How well those variables describe the price of a car\n\nBased on various market surveys, the consulting firm has gathered a large data set of different types of cars across the America market.\n\n## Business goal\n\nWe are required to model the price of cars with the available independent variables. It will be used by the management to understand how exactly the prices vary with the independent variables. They can accordingly manipulate the design of the cars, the business strategy etc. to meet certain price levels. Further, the model will be a good way for management to understand the pricing dynamics of a new market."},{"metadata":{},"cell_type":"markdown","source":"## Variable information\n\n**symboling:** \tIts assigned insurance risk rating, A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe. (Categorical) \n\n**carname:**\tName of car make and model. (Categorical)\n\n**fueltype:**\tCar fuel type i.e. gas or diesel. (Categorical)\n\n**aspiration:**\tAspiration used in a car. Mode of air intake for the internal combustion engine i.e. natural (standard) or turbocharger. (Categorical)\n\n**doornumber:**\tNumber of doors in a car i.e. two or four. (Categorical)\n\n**carbody:**\tBody of car i.e. convertible or hardtop or hatchback or sedan or wagon. (Categorical)\n\n**drivewheel:**\tType of drive wheel. The wheel connected to the motor/engine transmission, which causes the vehicle to move i.e. Front-wheel drive or Rear-wheel drive or Four-wheel drive. (Categorical)\n\n**enginelocation:**\tLocation of car engine i.e. front or rear. (Categorical)\n\n**wheelbase:**\tLength of wheelbase of car. Wheelbase is the distance between centers of front and rear wheels. (Numeric)\n\n**carlength:**\tLength of car. (Numeric)\n\n**carwidth:**\tWidth of car. (Numeric)\n\n**carheight:**\tHeight of car. (Numeric)\n\n**curbweight:**\tThe weight of a car without occupants or baggage. (Numeric)\n\n**enginetype:**\tType of engine i.e. I, ohc, ohcf, ohcv, dohc, dohcv, rotor. (Categorical)\n\n**cylindernumber:**\tNumber of cylidners used inside the engine i.e. two - twelve. (Categorical)\n\n**enginesize:**\tEngine size, or the engine displacement in the car. Engine displacement is the swept volume of all the pistons inside the cylinders of a reciprocating engine in a single movement from top dead centre to bottom dead centre. (Numeric)\n\n**fuelsystem:**\tFuel system used in the car i.e. 1bbl, 2bbl, 4bbl, idi, mfi, mpfi, spdi, spfi. Fuel-system provided fuel-air mixture to the engine. (Categorical)\n\n**boreratio:**\tBore ratio of car. It is the ratio between cylinder bore diameter and piston stroke. (Numeric)\n\n**stroke:**     Stroke or volume inside the engine. It is the distance travelled by the piston in each cycle. (Numeric)\n\n**compressionratio:**\tCompression ratio of car. It is the ratio of the maximum to minimum volume in the cylinder of an internal combustion engine. (Numeric)\n\n**horsepower:**\tHorsepower of the engine. The power an engine produces is called horsepower. In mathematical terms, one horsepower is the power needed to move 550 pounds one foot in one second. (Numeric)\n\n**peakrpm:**\tRPM at which engine delivers peak horsepower. (Numeric)\n\n**citympg:**\tMileage in city. (Numeric)\n\n**highwaympg:**\tMileage on highway. (Numeric)\n\n**price:**      Price of car. (Numeric) (Dependent variable)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import r2_score, mean_squared_error\n\n# display settings\npd.set_option(\"display.max_rows\", None)\npd.set_option(\"display.max_columns\", None)\n\n# filterning warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Reading and understanding data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# reading data from csv and creating dataframe\ndf = pd.read_csv(\"../input/car-price-prediction/CarPrice_Assignment.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# displaying first 5 rows\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dropping the ID column as it will not be useful in predicting our dependent variable\ndf.drop(columns=\"car_ID\", inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dimensions of dataframe\nprint(\"No. of rows: {}\\tNo. of columns: {}\".format(*df.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# columns info\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# descriptive statistics\ndf.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"# % of missing values\n(df.isna().sum() / df.shape[0]) * 100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Missing values:**\n* There are no missing values observed."},{"metadata":{},"cell_type":"markdown","source":"### 1. Symboling"},{"metadata":{"trusted":true},"cell_type":"code","source":"# converting from numeric to categorical variable type\ndf[\"symboling\"] = df[\"symboling\"].astype(str)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. CarName"},{"metadata":{"trusted":true},"cell_type":"code","source":"# extracting make from the values\ndf[\"make\"] = df['CarName'].str.split(' ', expand=True)[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# unique values in make\ndf[\"make\"].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Correcting typo errors in make values:**\n\nmaxda = mazda\n\nNissan = nissan\n\nporcshce = porsche\n\ntoyouta = toyota\n\nvokswagen = vw = volkswagen"},{"metadata":{"trusted":true},"cell_type":"code","source":"# correcting the typo errors in make values\ndf[\"make\"] = df[\"make\"].replace({\"maxda\":\"mazda\",\n                               \"Nissan\":\"nissan\",\n                               \"porcshce\":\"porsche\",\n                               \"toyouta\":\"toyota\",\n                               \"vokswagen\":\"volkswagen\",\n                               \"vw\":\"volkswagen\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dropping the car name variable\ndf.drop(columns=\"CarName\", inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. Creating price category"},{"metadata":{"trusted":true},"cell_type":"code","source":"# categorizing price into standard and high-end\ndf[\"price_category\"] = df[\"price\"].apply(lambda x: \"standard\" if x <= 18500 else \"high-end\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating list of numeric and categorical columns\ncol_numeric = list(df.select_dtypes(exclude=\"object\"))\n\ncol_categorical = list(df.select_dtypes(include=\"object\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualizing the car make\nplt.figure(figsize=(15,6))\ndf[\"make\"].value_counts().sort_values(ascending=False).plot.bar()\nplt.xticks(rotation=90)\nplt.xlabel(\"Make\", fontweight=\"bold\")\nplt.ylabel(\"Count\", fontweight=\"bold\")\nplt.title(\"Countplot of Car Make\", fontweight=\"bold\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Insights:**\n\n* Toyota seems to be the most favourite make.\n* Mercury seems to be the least favourite make."},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualizing the other categorical variables\nplt.figure(figsize=(15,20))\nfor i,col in enumerate(col_categorical[:-2], start=1):\n    plt.subplot(5,2,i)\n    sns.countplot(df[col])\n    plt.xlabel(col, fontweight=\"bold\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Insights:**\n\n* `symboling`: A majority of auto makers are neither safe nor risky. Looks like there are more number of risky autos as compared to safe ones.\n* `fueltype`: Majority of the automobiles are gas fuel type.\n* `aspiration`: Majority of the automobiles use standard aspiration.\n* `doornumber`: Majority of the automobiles are 4 door models.\n* `carbody`: Sedan is the most common model, convertible is the least common model.\n* `drivewheel`: Forward wheel drive is the most common model, 4 wheel drive is the least common model.\n* `enginelocation`: Almost all the models are having engine location as front.\n* `enginetype`: Majority (almost all) of the models are having 'ohc' engine type.\n* `cylindernumber`: Majority (almost all) of the models are 4 cylinder models.\n* `fuelsystem`: Majority of the models are having 'mpfi' and '2bbl' fuel systems."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# pair plot to understand the correlation between the numeric variables (except price)\nsns.pairplot(df[col_numeric[:-1]])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# heatmap to visualize the pearson's correlation matrix between the numeric variables (except price)\nplt.figure(figsize=(12,8))\nsns.heatmap(df.drop(columns=\"price\").corr(), annot=True, cmap=\"RdYlGn\", square=True, mask=np.triu(df.drop(columns=\"price\").corr(), k=1))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Insights:**\n\n* Model specifications (`wheelbase`, `carlenght`, `carweight`, `carheight`, `crubweight`, `enginesize`, `boreratio`, `stroke`, `compressionratio`, `horsepower`) and performance metrics (`peakrpm`, `citympg`, `highwaympg`) are mostly negatively correlated."},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualizing our dependent variable for outliers and skewnwss\nplt.figure(figsize=(15,5))\n\nplt.subplot(1,2,1)\nsns.boxplot(df[\"price\"])\nplt.title(\"Boxplot for outliers detection\", fontweight=\"bold\")\n\nplt.subplot(1,2,2)\nsns.distplot(df[\"price\"])\nplt.title(\"Distribution plot for skewness\", fontweight=\"bold\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Insights:**\n\n* There are few outliers towards the higher price range, suggesting that there are few high price models.\n* The distribution of price is right skewed, maybe we should think about applying transformation methods.\n* Most of the models are within 5000 and 18000 price range."},{"metadata":{"trusted":true},"cell_type":"code","source":"# average price of each make\ndf.groupby(\"make\")[\"price\"].mean().sort_values(ascending=False).plot.bar(figsize=(12,6))\nplt.title(\"Average price of each make\", fontweight=\"bold\")\nplt.ylabel(\"Price\", fontweight=\"bold\")\nplt.xlabel(\"Make\", fontweight=\"bold\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Insights:**\n\n* `jaguar` make is having highest average price.\n* `chevrolet` make is having least average price."},{"metadata":{"trusted":true},"cell_type":"code","source":"# proportion of high-end models in each make\npd.crosstab(df[\"make\"], df[\"price_category\"], normalize=\"index\").plot.bar(stacked=True, figsize=(10,5))\nplt.xlabel(\"Make\", fontweight=\"bold\")\nplt.ylabel(\"Proportion\", fontweight=\"bold\")\nplt.title(\"Proportion of high-end models in each make\", fontweight=\"bold\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Insights:**\n\n* `buick`, `jaguar` and `porsche` are having only high-end models.\n* `bmw` is having 80% of their models as high-end.\n* `volvo` is having equal proportion of high-end and standard price models.\n* `audi`, `nissan` and `saab` are having less than 33% of models as high-end.\n* The rest (majority) of the car makers are having only standard price models."},{"metadata":{"trusted":true},"cell_type":"code","source":"# price analysis for each carbody type\nfig, ax = plt.subplots(1,2, figsize=(15,5))\n\npd.crosstab(df[\"carbody\"], df[\"price_category\"], normalize=\"index\").plot.bar(stacked=True, ax=ax[0])\nax[0].set(xlabel=\"Carbody type\", ylabel=\"Proportion\", title=\"Proportion of high-end models in each carbody type\")\n\ndf.groupby(\"carbody\")[\"price\"].mean().sort_values(ascending=False).plot.bar(ax=ax[1])\nax[1].set(xlabel=\"Carbody type\", ylabel=\"Average price\", title=\"Average price of models in each carbody type\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Insights:**\n\n* `hardtop` and `convertible` are having highest average price, and also high proportion of high-end price models."},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualizing distribution of price with the other categorical variables\nplt.figure(figsize=(15,20))\nfor i,col in enumerate(col_categorical[:-2], start=1):\n    plt.subplot(5,2,i)\n    sns.violinplot(data=df, x=col, y=\"price\", split=True, hue=\"price_category\")\n    plt.xlabel(col, fontweight=\"bold\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Insights:**\n\n* `price` and `symboling`, `fueltype`, `doornumber`, `carbody` doesn't seem to have much correlation.\n* Safest (symboling -2) seems to have only standard priced models.\n* `price` and `drivewheel` seems to have little correlation. All 4 wheel drive models are standard priced models.\n* `price` and `enginelocation` seems to have correlation. All the rear engine models are high-end models.\n* `price` and `enginetype` seems to have little correlation. While standard priced models are having all types of engines, high-end models are having 'dohc', 'ohc', 'ohcv' and 'ohcf' engine types.\n* `price` and `cylindernumber` seems to have correlation. As the number of cylinders increases price of the model increases.\n* `price` and `fuelsystem` seems to have little correlation. High-end models are having only 'idi' and 'mpfi' fuel systems."},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualizing distribution of price with continuous variables\ncol_numeric_pc = col_numeric.copy()\ncol_numeric_pc.append(\"price_category\")\nsns.pairplot(df[col_numeric_pc], hue=\"price_category\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# heatmap to visualize the pearson's correlation between price and other the numeric variables\nplt.figure(figsize=(12,8))\nsns.heatmap(df.corr(), annot=True, cmap=\"RdYlGn\", square=True, mask=np.triu(df.corr(), k=1))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Insights:**\n\n* `price` is having high positive correlation with `curbweight`, `enginesize`, `horsepower`.\n* `price` is having high negative correlation with `mpg`."},{"metadata":{},"cell_type":"markdown","source":"## Data preperation"},{"metadata":{},"cell_type":"markdown","source":"### Converting categorical variables into numeric\n\nApplying label encoding since I will be using a tree based model."},{"metadata":{"trusted":true},"cell_type":"code","source":"# converting categorical variables into numeric variables using label encoding\nle = LabelEncoder()\n\ndf_encoded = df.drop(columns=[\"price_category\"])\ndf_encoded[col_categorical[:-1]] = df_encoded[col_categorical[:-1]].apply(lambda col: le.fit_transform(col))\n\ndf_encoded.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Creating dependent and independent variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"# independent variables\nX = df_encoded.drop(columns=\"price\")\n\n# dependent variable\ny = df_encoded[\"price\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Splitting data into train test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# splitting into train and test data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model building"},{"metadata":{},"cell_type":"markdown","source":"### Decision tree regressor"},{"metadata":{},"cell_type":"markdown","source":"**Building base model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# building a base model\nbase_model = DecisionTreeRegressor()\nbase_model.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# scoring using test data\ny_pred = base_model.predict(X_test)\nprint(\"R-squared:\", r2_score(y_pred, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Hyperparameter tuning**"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# hyperparameter tuning for best model\nparameters = {\"max_depth\":list(range(1,15))}\n\nbase_model = DecisionTreeRegressor()\ncv_model = GridSearchCV(estimator=base_model, param_grid=parameters, scoring='r2', return_train_score=True, cv=5).fit(X_train,y_train)\n\npd.DataFrame(cv_model.cv_results_)#[[\"mean_test_score\",\"mean_train_score\"]]\n\n# train and test scores\nplt.plot(pd.DataFrame(cv_model.cv_results_)[\"param_max_depth\"], pd.DataFrame(cv_model.cv_results_)[\"mean_test_score\"], label=\"test score\")\nplt.plot(pd.DataFrame(cv_model.cv_results_)[\"param_max_depth\"], pd.DataFrame(cv_model.cv_results_)[\"mean_train_score\"], label=\"train score\")\nplt.title(\"Training vs. Test score\")\nplt.ylabel(\"R-squared\")\nplt.xlabel(\"Max depth\")\nplt.legend()\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observations:**\n- There is no improvement in training score after max depth 8, so we build our model with max depth 8."},{"metadata":{"trusted":true},"cell_type":"code","source":"# building final model\nmodel = DecisionTreeRegressor(max_depth=8)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nprint(\"R-squared:\", r2_score(y_pred, y_test))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}