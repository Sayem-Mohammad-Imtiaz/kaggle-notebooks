{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Predict the humidity and display the following results MSE,RMSE","metadata":{}},{"cell_type":"markdown","source":"# Import Libraries & Data\n","metadata":{"execution":{"iopub.execute_input":"2021-08-28T17:37:48.315055Z","iopub.status.busy":"2021-08-28T17:37:48.313702Z","iopub.status.idle":"2021-08-28T17:37:48.322748Z","shell.execute_reply":"2021-08-28T17:37:48.321244Z","shell.execute_reply.started":"2021-08-28T17:37:48.314978Z"}}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n##Preprocessing Imports\n\nfrom sklearn import preprocessing\n\n## Visualization Imports\nimport matplotlib.pyplot as plt\nfrom matplotlib.dates import DateFormatter\nimport seaborn as sns\n\n##Model Building Imports\nfrom sklearn.linear_model import LinearRegression,Ridge\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import train_test_split\n\n## Metrics Import\nfrom sklearn.metrics import mean_squared_error,max_error,confusion_matrix\n\n## Feature Selection Imports\nfrom sklearn.feature_selection import SelectKBest, f_regression,mutual_info_regression\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2021-08-28T17:07:13.838379Z","iopub.status.busy":"2021-08-28T17:07:13.837951Z","iopub.status.idle":"2021-08-28T17:07:13.852663Z","shell.execute_reply":"2021-08-28T17:07:13.851543Z","shell.execute_reply.started":"2021-08-28T17:07:13.838345Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Dataset \n> Use the Date Column 'Formatted Date' as the index column","metadata":{}},{"cell_type":"code","source":"weather_hourly = pd.read_csv('../input/weather-dataset/weatherHistory.csv',\n                             index_col=['Formatted Date'],\n                             na_values=['9999.99'])\nweather_hourly.index = weather_hourly.index.str.replace('\\+0200','')\nweather_hourly.index=pd.to_datetime(weather_hourly.index,format=\"%Y-%m-%d %H:%M:%S\", utc= True)\nweather_hourly.head(5)","metadata":{"execution":{"iopub.execute_input":"2021-08-28T17:07:13.926983Z","iopub.status.busy":"2021-08-28T17:07:13.926395Z","iopub.status.idle":"2021-08-28T17:07:14.873258Z","shell.execute_reply":"2021-08-28T17:07:14.872118Z","shell.execute_reply.started":"2021-08-28T17:07:13.926934Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Exploration & Visualization","metadata":{}},{"cell_type":"markdown","source":"##### Description of the dataset","metadata":{}},{"cell_type":"code","source":"weather_hourly.describe()","metadata":{"execution":{"iopub.execute_input":"2021-08-28T17:07:14.875733Z","iopub.status.busy":"2021-08-28T17:07:14.875064Z","iopub.status.idle":"2021-08-28T17:07:14.948338Z","shell.execute_reply":"2021-08-28T17:07:14.946939Z","shell.execute_reply.started":"2021-08-28T17:07:14.875679Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Shape of the dataset","metadata":{}},{"cell_type":"code","source":"weather_hourly.shape","metadata":{"execution":{"iopub.execute_input":"2021-08-28T17:07:14.951189Z","iopub.status.busy":"2021-08-28T17:07:14.950678Z","iopub.status.idle":"2021-08-28T17:07:14.957794Z","shell.execute_reply":"2021-08-28T17:07:14.956648Z","shell.execute_reply.started":"2021-08-28T17:07:14.951136Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Features of the Dataset","metadata":{}},{"cell_type":"code","source":"class color:\n   PURPLE = '\\033[95m'\n   CYAN = '\\033[96m'\n   DARKCYAN = '\\033[36m'\n   BLUE = '\\033[94m'\n   GREEN = '\\033[92m'\n   YELLOW = '\\033[93m'\n   RED = '\\033[91m'\n   BOLD = '\\033[1m'\n   UNDERLINE = '\\033[4m'\n   END = '\\033[0m'\n    \nprint(f'{color.BOLD} Features of the dataset{color.END}')\nprint(f'{color.BLUE} {weather_hourly.columns} {color.END}')\n\nprint(f'{color.BOLD} Categorical features of the dataset {color.END}')\ncategorical_features = weather_hourly.select_dtypes(include='object').columns\nprint(f'{color.BLUE} {categorical_features} {color.END}')\nprint(f'{color.BOLD} Continous features of the dataset {color.END}')\ncontinous_features = weather_hourly.select_dtypes(exclude='object').columns\nprint(f' {color.BLUE} {continous_features} {color.END}')\n\n","metadata":{"execution":{"iopub.execute_input":"2021-08-28T17:07:14.960535Z","iopub.status.busy":"2021-08-28T17:07:14.96006Z","iopub.status.idle":"2021-08-28T17:07:14.990059Z","shell.execute_reply":"2021-08-28T17:07:14.98882Z","shell.execute_reply.started":"2021-08-28T17:07:14.960488Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot Hourly Humidity","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,10))\nax.scatter(weather_hourly.index.values,\n          weather_hourly['Humidity'],\n          color='purple')\nax.set(xlabel='Date',ylabel='Humidity',title='Hourly Humidity')\nplt.show()","metadata":{"execution":{"iopub.execute_input":"2021-08-28T17:07:14.993448Z","iopub.status.busy":"2021-08-28T17:07:14.992764Z","iopub.status.idle":"2021-08-28T17:07:17.332848Z","shell.execute_reply":"2021-08-28T17:07:17.331806Z","shell.execute_reply.started":"2021-08-28T17:07:14.99339Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Correlation matrix for hourly data","metadata":{}},{"cell_type":"code","source":"#drop the `Loud Cover` column has it has only 0s\nweather_hourly_1 = None\nweather_hourly_1 = weather_hourly.drop(labels='Loud Cover',axis=1)\nweather_hourly_1.corr().style.background_gradient(cmap='Blues')","metadata":{"execution":{"iopub.execute_input":"2021-08-28T17:07:17.334558Z","iopub.status.busy":"2021-08-28T17:07:17.334234Z","iopub.status.idle":"2021-08-28T17:07:17.396763Z","shell.execute_reply":"2021-08-28T17:07:17.395669Z","shell.execute_reply.started":"2021-08-28T17:07:17.334524Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Resample Hourly Humidity to Daily Humidity\n* Plot Daily Humidity","metadata":{}},{"cell_type":"code","source":"weather_daily = weather_hourly.resample('D').aggregate('mean')\nfig, ax = plt.subplots(figsize=(10,10))\n\nax.scatter(weather_daily.index.values,\n          weather_daily['Humidity'], color='purple')\nax.set(xlabel='Date',ylabel='Humidity',title='Daily Humidity')\nplt.show()","metadata":{"execution":{"iopub.execute_input":"2021-08-28T17:07:17.398899Z","iopub.status.busy":"2021-08-28T17:07:17.398462Z","iopub.status.idle":"2021-08-28T17:07:17.672063Z","shell.execute_reply":"2021-08-28T17:07:17.670888Z","shell.execute_reply.started":"2021-08-28T17:07:17.398839Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Correlation matrix Weekly Sample","metadata":{}},{"cell_type":"code","source":"weather_daily_1 = weather_daily.drop(labels='Loud Cover',axis=1)\nweather_daily_1.corr().style.background_gradient(cmap='Blues')","metadata":{"execution":{"iopub.execute_input":"2021-08-28T17:07:17.676307Z","iopub.status.busy":"2021-08-28T17:07:17.675833Z","iopub.status.idle":"2021-08-28T17:07:17.711654Z","shell.execute_reply":"2021-08-28T17:07:17.710547Z","shell.execute_reply.started":"2021-08-28T17:07:17.67626Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Resample Daily Humidity to Weekly Humidity\n* Plot Weekly Humidity","metadata":{}},{"cell_type":"code","source":"weather_weekly = weather_daily.resample('W').aggregate('mean')\nfig, ax = plt.subplots(figsize=(10,10))\n\nax.scatter(weather_weekly.index.values,\n          weather_weekly['Humidity'], color='purple')\nax.set(xlabel='Date',ylabel='Humidity',title='Weekly Humidity')\nplt.show()","metadata":{"execution":{"iopub.execute_input":"2021-08-28T17:07:17.71408Z","iopub.status.busy":"2021-08-28T17:07:17.713748Z","iopub.status.idle":"2021-08-28T17:07:17.938492Z","shell.execute_reply":"2021-08-28T17:07:17.937686Z","shell.execute_reply.started":"2021-08-28T17:07:17.71404Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Correlation matrix Weekly Sample","metadata":{}},{"cell_type":"code","source":"weather_weekly_1 = weather_weekly.drop(labels='Loud Cover',axis=1)\nweather_weekly_1.corr().style.background_gradient(cmap='Blues')","metadata":{"execution":{"iopub.execute_input":"2021-08-28T17:07:17.941228Z","iopub.status.busy":"2021-08-28T17:07:17.940581Z","iopub.status.idle":"2021-08-28T17:07:17.977964Z","shell.execute_reply":"2021-08-28T17:07:17.976699Z","shell.execute_reply.started":"2021-08-28T17:07:17.941186Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Resampe Weekly Humidity to Monthly Humidity\n* Plot Monthly Humidity","metadata":{}},{"cell_type":"code","source":"weather_monthly = weather_weekly.resample('M').aggregate('mean')\nfig, ax = plt.subplots(figsize=(10,10))\n\nax.scatter(weather_monthly.index.values,\n          weather_monthly['Humidity'], color='purple')\nax.set(xlabel='Date',ylabel='Humidity',title='Monthly Humidity')\nplt.show()","metadata":{"execution":{"iopub.execute_input":"2021-08-28T17:07:17.979778Z","iopub.status.busy":"2021-08-28T17:07:17.979432Z","iopub.status.idle":"2021-08-28T17:07:18.207536Z","shell.execute_reply":"2021-08-28T17:07:18.206408Z","shell.execute_reply.started":"2021-08-28T17:07:17.979744Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Correlation Analysis Monthly Sample","metadata":{}},{"cell_type":"code","source":"weather_monthly.corr().style.background_gradient(cmap=\"Blues\")","metadata":{"execution":{"iopub.execute_input":"2021-08-28T17:07:18.209296Z","iopub.status.busy":"2021-08-28T17:07:18.208983Z","iopub.status.idle":"2021-08-28T17:07:18.251565Z","shell.execute_reply":"2021-08-28T17:07:18.250447Z","shell.execute_reply.started":"2021-08-28T17:07:18.209266Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### As we can see the column `Loud Cover` has all zeros , lets drop the columan and then visualize the correlation matrix","metadata":{}},{"cell_type":"code","source":"weather_monthly_1 = weather_monthly.drop(labels='Loud Cover',axis=1)\nweather_monthly_1.corr().style.background_gradient(cmap='Blues')","metadata":{"execution":{"iopub.execute_input":"2021-08-28T17:07:18.253172Z","iopub.status.busy":"2021-08-28T17:07:18.25285Z","iopub.status.idle":"2021-08-28T17:07:18.287332Z","shell.execute_reply":"2021-08-28T17:07:18.28606Z","shell.execute_reply.started":"2021-08-28T17:07:18.253142Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data PreProcessing & Cleanup\n","metadata":{}},{"cell_type":"markdown","source":"### Hourly Dataset","metadata":{}},{"cell_type":"markdown","source":"#### Check data quality","metadata":{}},{"cell_type":"code","source":"weather_hourly.isnull().sum()","metadata":{"execution":{"iopub.execute_input":"2021-08-28T17:07:18.289319Z","iopub.status.busy":"2021-08-28T17:07:18.288917Z","iopub.status.idle":"2021-08-28T17:07:18.33474Z","shell.execute_reply":"2021-08-28T17:07:18.333672Z","shell.execute_reply.started":"2021-08-28T17:07:18.289282Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Dataset is pretty clean with only 1 column 'Precip Type' having null values. \n> As part of the 1st iteration, lets drop this feature and proceed. In the later part we will include this feature and check if it helps in giving a better prediction of Humidity","metadata":{}},{"cell_type":"code","source":"def min_max(input_df):\n    max_series = input_df.max(numeric_only=True)\n    min_series = input_df.min(numeric_only=True)\n    min_max = pd.DataFrame(max_series).transpose().append(pd.DataFrame(min_series).transpose())\n    return min_max\n\nmin_max(weather_hourly)","metadata":{"execution":{"iopub.execute_input":"2021-08-28T17:07:18.336288Z","iopub.status.busy":"2021-08-28T17:07:18.335976Z","iopub.status.idle":"2021-08-28T17:07:18.361023Z","shell.execute_reply":"2021-08-28T17:07:18.360157Z","shell.execute_reply.started":"2021-08-28T17:07:18.336257Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weather_hourly[continous_features].columns","metadata":{"execution":{"iopub.execute_input":"2021-08-28T17:07:18.362735Z","iopub.status.busy":"2021-08-28T17:07:18.362421Z","iopub.status.idle":"2021-08-28T17:07:18.372933Z","shell.execute_reply":"2021-08-28T17:07:18.371758Z","shell.execute_reply.started":"2021-08-28T17:07:18.362705Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plotting the distribution","metadata":{}},{"cell_type":"code","source":"hist = weather_hourly.hist(grid=False,\n        legend=False,\n        figsize=(15, 8),\n        bins=100,\n        orientation='horizontal',\n        color='blue');\n","metadata":{"execution":{"iopub.execute_input":"2021-08-28T17:07:18.374801Z","iopub.status.busy":"2021-08-28T17:07:18.374407Z","iopub.status.idle":"2021-08-28T17:07:21.454596Z","shell.execute_reply":"2021-08-28T17:07:21.453798Z","shell.execute_reply.started":"2021-08-28T17:07:18.374768Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"_Steps Performed_\n* Drop the Precipe Type column\n* Drop the target column __Humidity__\n* The numerical ( continous ) features have values in different scale. e.g __Apparent Temperature__ values ranges between *39.34444*  and *-27.7166* while __Wind Speed__ values ranges between *359* and *0*. We use `StandardScalar` to perform normalization\n* The categorical columns are label encoded using `LabelEncoder`","metadata":{}},{"cell_type":"code","source":"class DataWrangler_Approach_A():\n    def __init__(self,df):\n        self.df = df\n        \n    def _get_numerical_columns(self):\n        return self.df.select_dtypes(include=['float64','int64']).columns\n        \n    def _get_categorical_columns(self):\n        return self.df.select_dtypes(include=['object']).columns\n    \n    def _remove_columns(self,labels):\n        self.df.drop(labels=labels,axis=1,inplace=True)\n\n    \n    def _drop_rows_with_null(self):\n        self.df.dropna(inplace=True,axis=1)\n    \n    def _scale_numerical_features(self):\n        scaler = preprocessing.StandardScaler()\n        numerical_cols = self._get_numerical_columns()\n        numerical_df = self.df.loc[:,numerical_cols]\n        self.df.drop(labels=numerical_cols, axis=1, inplace=True)\n        scaler.fit(numerical_df)\n        scaled_cols = scaler.transform(numerical_df)\n        self.df[numerical_cols] = scaled_cols\n    \n    def _label_encode_categories(self):\n        le = preprocessing.LabelEncoder()\n        categorical_cols = self._get_categorical_columns()\n        categorical_df = self.df.loc[:,categorical_cols]\n        categorical_df = categorical_df.apply(le.fit_transform)\n        self.df[categorical_cols] = categorical_df\n        \n    \n    def perform_wrangling(self):\n        #self._remove_columns(['Humidity'])\n        self._drop_rows_with_null()\n        self._scale_numerical_features()\n        self._label_encode_categories()\n        dropna=True\n        return (self.df,dropna)","metadata":{"execution":{"iopub.execute_input":"2021-08-28T17:07:21.456274Z","iopub.status.busy":"2021-08-28T17:07:21.455977Z","iopub.status.idle":"2021-08-28T17:07:21.468566Z","shell.execute_reply":"2021-08-28T17:07:21.46752Z","shell.execute_reply.started":"2021-08-28T17:07:21.456246Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_df = pd.read_csv('../input/weather-dataset/weatherHistory.csv',\n                             index_col=['Formatted Date'],\n                             na_values=['9999.99'])\nraw_df.index = raw_df.index.str.replace('\\+0200','')\nraw_df.index=pd.to_datetime(raw_df.index,format=\"%Y-%m-%d %H:%M:%S\", utc= True)\nraw_df.head(5)\ny = raw_df['Humidity']\nraw_df.drop(labels=['Loud Cover'],axis=1,inplace=True)\n(pre_processed_df, dropna) = DataWrangler_Approach_A(raw_df).perform_wrangling()\npre_processed_df.head()","metadata":{"execution":{"iopub.execute_input":"2021-08-28T17:07:21.470334Z","iopub.status.busy":"2021-08-28T17:07:21.469995Z","iopub.status.idle":"2021-08-28T17:07:22.765558Z","shell.execute_reply":"2021-08-28T17:07:22.764315Z","shell.execute_reply.started":"2021-08-28T17:07:21.4703Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pre_processed_df.corr().style.background_gradient(cmap='Blues')","metadata":{"execution":{"iopub.execute_input":"2021-08-28T17:07:22.766995Z","iopub.status.busy":"2021-08-28T17:07:22.766693Z","iopub.status.idle":"2021-08-28T17:07:22.835772Z","shell.execute_reply":"2021-08-28T17:07:22.834431Z","shell.execute_reply.started":"2021-08-28T17:07:22.766966Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop the target column\npre_processed_df.drop(labels=['Humidity'],axis=1,inplace=True)","metadata":{"execution":{"iopub.execute_input":"2021-08-28T17:07:22.837769Z","iopub.status.busy":"2021-08-28T17:07:22.837442Z","iopub.status.idle":"2021-08-28T17:07:22.848201Z","shell.execute_reply":"2021-08-28T17:07:22.846849Z","shell.execute_reply.started":"2021-08-28T17:07:22.837738Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def select_feature(feat_sel_func,k,**kwargs):\n    fs = SelectKBest(score_func=feat_sel_func,k=k)\n    fs.fit(kwargs.get('X_train'),kwargs.get('y_train'))\n    X_train_fs = fs.transform(kwargs.get('X_train'))\n    X_test_fs = fs.transform(kwargs.get('X_test'))\n    print(fs.pvalues_)\n    return X_train_fs,X_test_fs,fs","metadata":{"execution":{"iopub.execute_input":"2021-08-28T17:50:27.085989Z","iopub.status.busy":"2021-08-28T17:50:27.085578Z","iopub.status.idle":"2021-08-28T17:50:27.092742Z","shell.execute_reply":"2021-08-28T17:50:27.091636Z","shell.execute_reply.started":"2021-08-28T17:50:27.085952Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def select_feature_freg(**kwargs):\n    feat_count = kwargs['feature_count']\n#     X_train = kwargs.get('X_train')\n#     X_test = kwargs.get('X_test')\n#     print(f' X_train shape = {X_train.shape} X_test shape = {X_test.shape}')\n\n    X_train_fs, X_test_fs, fs = select_feature(f_regression,feat_count,\n                                               X_test=kwargs.get('X_test'),\n                                               X_train=kwargs.get('X_train'),\n                                               y_train=kwargs.get('y_train'))\n    mask = fs.get_support(indices=True)\n    features = [pre_processed_df.columns[index] for index in mask]\n    scores = [fs.scores_[index] for index in mask]\n    selected_feature_df = pd.DataFrame(X_train,columns=features)\n    if print_score:\n        for i in range(len(scores)):\n            print(f'Feature {selected_feature_df.columns[i]} score : {fs.scores_[i]}')\n    fig, ax = plt.subplots(figsize=(8,4))\n    ax.barh([selected_feature_df.columns[i] for i in range(len(features))], scores,height=0.4)\n    plt.tight_layout()\n    plt.show()\n    return X_train_fs, X_test_fs","metadata":{"execution":{"iopub.execute_input":"2021-08-28T17:50:52.991723Z","iopub.status.busy":"2021-08-28T17:50:52.991338Z","iopub.status.idle":"2021-08-28T17:50:53.00124Z","shell.execute_reply":"2021-08-28T17:50:53.000362Z","shell.execute_reply.started":"2021-08-28T17:50:52.991687Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def select_feature_mutualinfo(**kwargs):\n    feat_count=kwargs['feature_count']\n    X_train_fs, X_test_fs, fs = select_feature(mutual_info_regression,feat_count,\n                                               X_test=kwargs.get('X_test'),\n                                               X_train=kwargs.get('X_train'),\n                                               y_train=kwargs.get('y_train'))\n    mask = fs.get_support(indices=True)\n    features = [pre_processed_df.columns[index] for index in mask]\n    scores = [fs.scores_[index] for index in mask]\n    selected_feature_df = pd.DataFrame(X_train,columns=features)\n    if print_score:\n        for i in range(len(scores)):\n            print(f'Feature {selected_feature_df.columns[i]} score : {fs.scores_[i]}')\n    fig, ax = plt.subplots(figsize=(8,4))\n    ax.barh([selected_feature_df.columns[i] for i in range(len(features))],scores,height=0.4)\n    plt.tight_layout()\n    plt.show()\n    return X_train_fs,X_test_fs","metadata":{"execution":{"iopub.execute_input":"2021-08-28T17:07:22.881642Z","iopub.status.busy":"2021-08-28T17:07:22.881264Z","iopub.status.idle":"2021-08-28T17:07:22.897058Z","shell.execute_reply":"2021-08-28T17:07:22.89491Z","shell.execute_reply.started":"2021-08-28T17:07:22.88161Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def perform_linearreg(**kwargs):\n    X_train = kwargs['X_train']\n    y_train = kwargs['y_train']\n    X_test = kwargs['X_test']\n    y_test = kwargs['y_test']\n    reg = LinearRegression().fit(X_train, y_train)\n    score = reg.score(X_test, y_test)\n    y_pred = reg.predict(X_test)\n    print(f'Training dataset shape: {X_train.shape}')\n    print(f'Test dataset shape: {X_test.shape}')\n    print(f'{color.BOLD}Accuracy Score {color.END} {score:.4f}')\n    print(f'{color.BOLD}Mean squared error:{color.END} {mean_squared_error(y_test, y_pred):.4f}')\n    print(f'{color.BOLD}Root Mean squared error:{color.END} {mean_squared_error(y_test, y_pred,squared=False):.4f}')","metadata":{"execution":{"iopub.execute_input":"2021-08-28T17:07:22.899662Z","iopub.status.busy":"2021-08-28T17:07:22.898972Z","iopub.status.idle":"2021-08-28T17:07:22.92089Z","shell.execute_reply":"2021-08-28T17:07:22.920001Z","shell.execute_reply.started":"2021-08-28T17:07:22.899607Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def perform_ridgereg(**kwargs):\n    X_train = kwargs['X_train']\n    y_train = kwargs['y_train']\n    X_test = kwargs['X_test']\n    y_test = kwargs['y_test']\n    r_reg = Ridge(alpha=1.0,solver='svd').fit(X_train, y_train)\n    score = r_reg.score(X_test, y_test)\n    y_pred = r_reg.predict(X_test)\n    print(f'Training dataset shape: {X_train.shape}')\n    print(f'Test dataset shape: {X_test.shape}')\n    print(f'{color.BOLD}Accuracy Score {color.END} {score:.4f}')\n    print(f'{color.BOLD}Mean squared error:{color.END} {mean_squared_error(y_test, y_pred):.4f}')\n    print(f'{color.BOLD}Root Mean squared error:{color.END} {mean_squared_error(y_test, y_pred,squared=False):.4f}')","metadata":{"execution":{"iopub.execute_input":"2021-08-28T17:07:22.922246Z","iopub.status.busy":"2021-08-28T17:07:22.9219Z","iopub.status.idle":"2021-08-28T17:07:22.93913Z","shell.execute_reply":"2021-08-28T17:07:22.938063Z","shell.execute_reply.started":"2021-08-28T17:07:22.922213Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def perform_decisiontreereg(**kwargs):\n    X_train = kwargs['X_train']\n    y_train = kwargs['y_train']\n    X_test = kwargs['X_test']\n    y_test = kwargs['y_test']\n    dtree_reg = DecisionTreeRegressor(random_state=0).fit(X_train, y_train)\n    score = dtree_reg.score(X_test, y_test)\n    y_pred = dtree_reg.predict(X_test)\n    print(f'Training dataset shape: {X_train.shape}')\n    print(f'Test dataset shape: {X_test.shape}')\n    print(f'{color.BOLD}Accuracy Score {color.END} {score:.4f}')\n    print(f'{color.BOLD}Mean squared error:{color.END} {mean_squared_error(y_test, y_pred):.4f}')\n    print(f'{color.BOLD}Root Mean squared error:{color.END} {mean_squared_error(y_test, y_pred,squared=False):.4f}')\n    return dtree_reg","metadata":{"execution":{"iopub.execute_input":"2021-08-28T17:07:22.940768Z","iopub.status.busy":"2021-08-28T17:07:22.940424Z","iopub.status.idle":"2021-08-28T17:07:22.965258Z","shell.execute_reply":"2021-08-28T17:07:22.964046Z","shell.execute_reply.started":"2021-08-28T17:07:22.940736Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def perform_randomforestreg(**kwargs):\n    X_train = kwargs['X_train']\n    y_train = kwargs['y_train']\n    X_test = kwargs['X_test']\n    y_test = kwargs['y_test']\n    random_reg = RandomForestRegressor(n_estimators = 100, random_state=0).fit(X_train, y_train)\n    score = random_reg.score(X_test, y_test)\n    y_pred = random_reg.predict(X_test)\n    print(f'Training dataset shape: {X_train.shape}')\n    print(f'Test dataset shape: {X_test.shape}')\n    print(f'{color.BOLD}Accuracy Score {color.END} {score:.4f}')\n    print(f'{color.BOLD}Mean squared error:{color.END} {mean_squared_error(y_test, y_pred):.4f}')\n    print(f'{color.BOLD}Root Mean squared error:{color.END} {mean_squared_error(y_test, y_pred,squared=False):.4f}')\n    return random_reg","metadata":{"execution":{"iopub.execute_input":"2021-08-28T17:07:22.967018Z","iopub.status.busy":"2021-08-28T17:07:22.966555Z","iopub.status.idle":"2021-08-28T17:07:22.981579Z","shell.execute_reply":"2021-08-28T17:07:22.980286Z","shell.execute_reply.started":"2021-08-28T17:07:22.966973Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hourly Data Feature Selection","metadata":{}},{"cell_type":"markdown","source":"## Feature Selection\n* Train Test Split\n* Linear Reg with all features\n* f_regression feature selection\n* Linear regression with K best features\n* mutual_info_regression feature selection","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(pre_processed_df,y,random_state=42)\n\nfreg_feature_count = 6\nprint_score = False\nprint(f'{color.BLUE}Select {freg_feature_count} Best features using f_regression{color.END}')\nX_train_freg, X_test_freg = select_feature_freg(X_train=X_train,y_train=y_train,\n                                            X_test=X_test,feature_count=freg_feature_count,\n                                            print_score=print_score)\nminfo_feature_count = 6\nprint_score = False\nprint(f'{color.BLUE}Select {minfo_feature_count} Best features using mutual_info_regression{color.END}')\nX_train_mreg, X_test_mreg = select_feature_mutualinfo(X_train=X_train,y_train=y_train,\n                                            X_test=X_test,feature_count=minfo_feature_count,\n                                            print_score=print_score)","metadata":{"execution":{"iopub.execute_input":"2021-08-28T17:50:58.037187Z","iopub.status.busy":"2021-08-28T17:50:58.036603Z","iopub.status.idle":"2021-08-28T17:51:15.264703Z","shell.execute_reply":"2021-08-28T17:51:15.263629Z","shell.execute_reply.started":"2021-08-28T17:50:58.037134Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_selection import f_regression, mutual_info_regression\n\nraw_hourly = pd.read_csv('../input/weather-dataset/weatherHistory.csv',\n                             index_col=['Formatted Date'],\n                             na_values=['9999.99'])\nraw_hourly.index = raw_hourly.index.str.replace('\\+0200','')\nraw_hourly.index=pd.to_datetime(raw_hourly.index,format=\"%Y-%m-%d %H:%M:%S\", utc= True)\nraw_hourly.drop(labels=['Summary', 'Precip Type', 'Daily Summary','Loud Cover'],axis=1,inplace=True)\ny = raw_hourly['Humidity']\nraw_hourly.drop(labels='Humidity',axis=1, inplace=True)\nX_train, X_test, y_train, y_test = train_test_split(raw_hourly, y,random_state=42)\nf_test, _ = f_regression(X_train, y_train)\nf_test /= np.max(f_test)\n\nmi = mutual_info_regression(X_train, y_train)\nmi /= np.max(mi)\n\nplt.figure(figsize=(25, 15))\nfor i in range(6):\n    plt.subplot(3, 2, i + 1)\n    col = X_train.iloc[:,i]\n    plt.scatter(col, y_train, edgecolor='black', s=20)\n    #plt.xlabel(\"$x_{}$\".format(i + 1), fontsize=14)\n    plt.xlabel(f'{col[0:0].name}', fontsize=14)\n    if not i%2 > 0:\n        plt.ylabel(\"$y$\", fontsize=14)\n#     plt.title(\"F-test={:.2f}, MI={:.2f}\".format(f_test[i], mi[i]),\n#               fontsize=16)\n    plt.title(\"F-test={:.2f}\".format(f_test[i]),\n              fontsize=16)\n    \nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.execute_input":"2021-08-28T17:07:40.134451Z","iopub.status.busy":"2021-08-28T17:07:40.133969Z","iopub.status.idle":"2021-08-28T17:07:55.82552Z","shell.execute_reply":"2021-08-28T17:07:55.824033Z","shell.execute_reply.started":"2021-08-28T17:07:40.134402Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hourly Data Model Building","metadata":{}},{"cell_type":"markdown","source":"### Linear Regression","metadata":{}},{"cell_type":"code","source":"l_reg_allfeat = perform_linearreg(X_train=X_train,X_test=X_test,y_train=y_train,y_test=y_test)\nl_reg_freg = perform_linearreg(X_train=X_train_freg,X_test=X_test_freg,y_train=y_train,y_test=y_test)\nl_reg_minfo = perform_linearreg(X_train=X_train_mreg,X_test=X_test_mreg,y_train=y_train,y_test=y_test)\n","metadata":{"execution":{"iopub.execute_input":"2021-08-28T17:07:55.827553Z","iopub.status.busy":"2021-08-28T17:07:55.827241Z","iopub.status.idle":"2021-08-28T17:07:55.908785Z","shell.execute_reply":"2021-08-28T17:07:55.907656Z","shell.execute_reply.started":"2021-08-28T17:07:55.827523Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Random Forest Regression","metadata":{}},{"cell_type":"code","source":"print(f'{color.BLUE} RandomForest Regression using all features {color.END}')\nrandom_reg_allfeat = perform_randomforestreg(X_train=X_train,X_test=X_test,\n                                             y_train=y_train,y_test=y_test)\nprint(f'{color.BLUE} RandomForest Regression using 6 top features selected using `f_regression` {color.END}')\nrandom_reg_freg = perform_randomforestreg(X_train=X_train_freg,X_test=X_test_freg,\n                              y_train=y_train,y_test=y_test)\nprint(f'{color.BLUE} RandomForest Regression using 6 top features selected using `mutual_info_regression` {color.END}')\nrandom_reg_minfo = perform_randomforestreg(X_train=X_train_mreg,X_test=X_test_mreg,\n                                y_train=y_train,y_test=y_test)\n","metadata":{"execution":{"iopub.execute_input":"2021-08-28T17:07:55.910725Z","iopub.status.busy":"2021-08-28T17:07:55.910355Z","iopub.status.idle":"2021-08-28T17:10:01.940495Z","shell.execute_reply":"2021-08-28T17:10:01.939266Z","shell.execute_reply.started":"2021-08-28T17:07:55.910687Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### DecisionTree Regression","metadata":{}},{"cell_type":"code","source":"print(f'{color.BLUE} DecisionTree Regression using all features {color.END}')\ndtree_reg_allfeat = perform_decisiontreereg(X_train=X_train,\n                                            X_test=X_test,\n                                             y_train=y_train,\n                                            y_test=y_test)\nprint(dtree_reg_allfeat.feature_importances_)\nprint(f'{color.BLUE} DecisionTree Regression using 6 top features selected using `f_regression` {color.END}')\ndtree_reg_freg = perform_decisiontreereg(X_train=X_train_freg,\n                                         X_test=X_test_freg,\n                                         y_train=y_train,\n                                         y_test=y_test)\nprint(f'{color.BLUE} DecisionTree Regression using 6 top features selected using `mutual_info_regression` {color.END}')\ndtree_reg_minfo = perform_decisiontreereg(X_train=X_train_mreg,\n                                          X_test=X_test_mreg,\n                                          y_train=y_train,\n                                          y_test=y_test)\n","metadata":{"execution":{"iopub.execute_input":"2021-08-28T17:10:01.943617Z","iopub.status.busy":"2021-08-28T17:10:01.943084Z","iopub.status.idle":"2021-08-28T17:10:03.948213Z","shell.execute_reply":"2021-08-28T17:10:03.947003Z","shell.execute_reply.started":"2021-08-28T17:10:01.943562Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Daily Data Feature Selection","metadata":{}},{"cell_type":"code","source":"y_daily = weather_daily['Humidity']\n(pre_processed_daily_df, dropna) = DataWrangler_Approach_A(weather_daily).perform_wrangling()\npre_processed_daily_df.head()","metadata":{"execution":{"iopub.execute_input":"2021-08-28T17:10:03.950589Z","iopub.status.busy":"2021-08-28T17:10:03.950127Z","iopub.status.idle":"2021-08-28T17:10:03.986257Z","shell.execute_reply":"2021-08-28T17:10:03.984999Z","shell.execute_reply.started":"2021-08-28T17:10:03.950539Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Selection","metadata":{}},{"cell_type":"code","source":"X_train_daily, X_test_daily, y_train_daily, y_test_daily = train_test_split(\n    pre_processed_daily_df,\n    y_daily,random_state=42)\nprint(f'Shape of input X_train = {X_train_daily.shape} y_train = {y_train_daily.shape} X_test = {X_test_daily.shape} y_test = {y_test_daily.shape}')\nfreg_feature_count_daily = 6\nprint_score_daily = False\nprint(f'{color.BLUE}Select {freg_feature_count} Best features using f_regression{color.END}')\nX_train_freg_daily, X_test_freg_daily = select_feature_freg(X_train=X_train_daily,\n                                                            y_train=y_train_daily,\n                                                            X_test=X_test_daily,\n                                                            feature_count=freg_feature_count_daily,\n                                                            print_score=print_score_daily)\n\nprint(f'Shape of output X_train = {X_train_freg_daily.shape} y_train = {y_train_daily.shape} X_test = {X_test_freg_daily.shape} y_test = {y_test_daily.shape}')\nminfo_feature_count_daily = 6\nprint_score_daily = False\nprint(f'{color.BLUE}Select {minfo_feature_count} Best features using mutual_info_regression{color.END}')\nX_train_mreg_daily, X_test_mreg_daily = select_feature_mutualinfo(X_train=X_train_daily,\n                                                                  y_train=y_train_daily,\n                                                                  X_test=X_test_daily,\n                                                                  feature_count=freg_feature_count_daily,\n                                                                  print_score=print_score_daily)\nprint(f'Shape of output X_train = {X_train_mreg_daily.shape} y_train = {y_train_daily.shape} X_test = {X_test_mreg_daily.shape} y_test = {y_test_daily.shape}')","metadata":{"execution":{"iopub.execute_input":"2021-08-28T17:10:03.988119Z","iopub.status.busy":"2021-08-28T17:10:03.987784Z","iopub.status.idle":"2021-08-28T17:10:04.928769Z","shell.execute_reply":"2021-08-28T17:10:04.927961Z","shell.execute_reply.started":"2021-08-28T17:10:03.988086Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Daily Data Model Building","metadata":{}},{"cell_type":"markdown","source":"#### Linear Regression","metadata":{}},{"cell_type":"code","source":"\nl_reg_daily_allfeat = perform_linearreg(X_train=X_train_daily,\n                                        X_test=X_test_daily,\n                                        y_train=y_train_daily,\n                                        y_test=y_test_daily)\n\nl_reg_daily_freg = perform_linearreg(X_train=X_train_freg_daily,\n                                     X_test=X_test_freg_daily,\n                                     y_train=y_train_daily,\n                                     y_test=y_test_daily)\nl_reg_daily_minfo = perform_linearreg(X_train=X_train_mreg_daily,\n                                      X_test=X_test_mreg_daily,\n                                      y_train=y_train_daily,\n                                      y_test=y_test_daily)\n","metadata":{"execution":{"iopub.execute_input":"2021-08-28T17:10:04.930429Z","iopub.status.busy":"2021-08-28T17:10:04.930138Z","iopub.status.idle":"2021-08-28T17:10:04.960547Z","shell.execute_reply":"2021-08-28T17:10:04.959186Z","shell.execute_reply.started":"2021-08-28T17:10:04.9304Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Random Forest Regression","metadata":{}},{"cell_type":"code","source":"print(f'{color.BLUE} RandomForest Regression using all features {color.END}')\nrandom_reg_allfeat = perform_randomforestreg(X_train=X_train_daily,\n                                        X_test=X_test_daily,\n                                        y_train=y_train_daily,\n                                        y_test=y_test_daily)\nprint(f'{color.BLUE} RandomForest Regression using 6 top features selected using `f_regression` {color.END}')\nrandom_reg_freg = perform_randomforestreg(X_train=X_train_freg_daily,\n                                     X_test=X_test_freg_daily,\n                                     y_train=y_train_daily,\n                                     y_test=y_test_daily)\nprint(f'{color.BLUE} RandomForest Regression using 6 top features selected using `mutual_info_regression` {color.END}')\nrandom_reg_minfo = perform_randomforestreg(X_train=X_train_mreg_daily,\n                                      X_test=X_test_mreg_daily,\n                                      y_train=y_train_daily,\n                                      y_test=y_test_daily)\n","metadata":{"execution":{"iopub.execute_input":"2021-08-28T17:10:04.963604Z","iopub.status.busy":"2021-08-28T17:10:04.963088Z","iopub.status.idle":"2021-08-28T17:10:09.016572Z","shell.execute_reply":"2021-08-28T17:10:09.015687Z","shell.execute_reply.started":"2021-08-28T17:10:04.963552Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**From the above experiment it is evident that resampling the data to daily dataset, we are loosing a lot of information and hence the model accuracy goes down to zero, which makes the model unsable**","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}