{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport os\nimport tensorflow as tf\nfrom tensorflow.keras.utils import Sequence\nimport random\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2021-09-09T13:02:42.60668Z","iopub.execute_input":"2021-09-09T13:02:42.607034Z","iopub.status.idle":"2021-09-09T13:02:47.64616Z","shell.execute_reply.started":"2021-09-09T13:02:42.606999Z","shell.execute_reply":"2021-09-09T13:02:47.645053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_classes=23\nH=800\nW=1200\n\ndef read_image(x):\n    x = cv2.imread(x, cv2.IMREAD_COLOR)\n    x = cv2.resize(x, (W, H))\n    x = x/255.0\n    x = x.astype(np.float32)\n    return x\n\n\ndef read_mask(x):\n    x = cv2.imread(x, cv2.IMREAD_GRAYSCALE)\n    x = cv2.resize(x, (W, H))\n    x = x.astype(np.int32)\n    return x\n\n\ndef tf_dataset(x,y, batch=4):\n    dataset = tf.data.Dataset.from_tensor_slices((x,y)) # Dataset object from Tensorflow\n    dataset = dataset.shuffle(buffer_size=100) \n    dataset = dataset.map(preprocess) # Applying preprocessing to every batch in the Dataset object\n    dataset = dataset.batch(batch) # Determine atch-size\n    dataset = dataset.repeat()\n    dataset = dataset.prefetch(2) # Optimization\n    return dataset\n        \n\ndef preprocess(x,y):\n    def f(x,y):\n        x = x.decode()\n        y = y.decode()\n        image = read_image(x)\n        mask = read_mask(y)\n        return image, mask\n    \n    image, mask = tf.numpy_function(f,[x,y],[tf.float32, tf.int32])\n    mask = tf.one_hot(mask, num_classes, dtype=tf.int32)\n    image.set_shape([H, W, 3])    # In the Images, number of channels = 3. \n    mask.set_shape([H, W, num_classes])    # In the Masks, number of channels = number of classes. \n    return image, mask\n","metadata":{"execution":{"iopub.status.busy":"2021-09-09T13:02:47.651054Z","iopub.execute_input":"2021-09-09T13:02:47.651483Z","iopub.status.idle":"2021-09-09T13:02:47.670767Z","shell.execute_reply.started":"2021-09-09T13:02:47.651443Z","shell.execute_reply":"2021-09-09T13:02:47.669676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"root_dir = '../input/semantic-drone-dataset/dataset/semantic_drone_dataset'\nimg_path = root_dir + '/original_images/'\nmask_path = root_dir + '/label_images_semantic/'\n\nnames = list(map(lambda x: x.replace('.jpg', ''), os.listdir(img_path)))","metadata":{"execution":{"iopub.status.busy":"2021-09-09T13:02:47.676568Z","iopub.execute_input":"2021-09-09T13:02:47.679147Z","iopub.status.idle":"2021-09-09T13:02:47.739575Z","shell.execute_reply.started":"2021-09-09T13:02:47.679105Z","shell.execute_reply":"2021-09-09T13:02:47.738638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_trainval, X_test = train_test_split(names, test_size=0.1, random_state=19)\nX_train, X_val = train_test_split(X_trainval, test_size=0.2, random_state=19)\n\nprint(f\"Train Size : {len(X_train)} images\")\nprint(f\"Val Size   :  {len(X_val)} images\")\nprint(f\"Test Size  :  {len(X_test)} images\")\n\ny_train = X_train\ny_test = X_test\ny_val = X_val\n\nimg_train = [os.path.join(img_path, f\"{name}.jpg\") for name in X_train]\nmask_train = [os.path.join(mask_path, f\"{name}.png\") for name in y_train]\nimg_val = [os.path.join(img_path, f\"{name}.jpg\") for name in X_val]\nmask_val = [os.path.join(mask_path, f\"{name}.png\") for name in y_val]\nimg_test = [os.path.join(img_path, f\"{name}.jpg\") for name in X_test]\nmask_test = [os.path.join(mask_path, f\"{name}.png\") for name in y_test]","metadata":{"execution":{"iopub.status.busy":"2021-09-09T13:02:47.743812Z","iopub.execute_input":"2021-09-09T13:02:47.745877Z","iopub.status.idle":"2021-09-09T13:02:47.767742Z","shell.execute_reply.started":"2021-09-09T13:02:47.745834Z","shell.execute_reply":"2021-09-09T13:02:47.766953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size=3\n\ntrain_dataset = tf_dataset(img_train, mask_train, batch = batch_size)\nvalid_dataset = tf_dataset(img_val, mask_val, batch = batch_size)\n\ntrain_steps = len(img_train)//batch_size\nvalid_steps = len(img_val)//batch_size","metadata":{"execution":{"iopub.status.busy":"2021-09-09T13:02:47.771533Z","iopub.execute_input":"2021-09-09T13:02:47.773788Z","iopub.status.idle":"2021-09-09T13:02:49.426649Z","shell.execute_reply.started":"2021-09-09T13:02:47.773748Z","shell.execute_reply":"2021-09-09T13:02:49.425751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset.take(0)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T13:02:49.427914Z","iopub.execute_input":"2021-09-09T13:02:49.428265Z","iopub.status.idle":"2021-09-09T13:02:49.439295Z","shell.execute_reply.started":"2021-09-09T13:02:49.42823Z","shell.execute_reply":"2021-09-09T13:02:49.438498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_classes=23\nH=800\nW=1200\n\n\ndef test_dataset(x, batch=4):\n    dataset = tf.data.Dataset.from_tensor_slices(x)\n    dataset = dataset.map(preprocess_test)\n    dataset = dataset.batch(batch)\n    dataset = dataset.prefetch(2)\n    return dataset\n        \n\ndef preprocess_test(x):\n    def f(x):\n        x = x.decode()\n        image = read_image(x)\n        return image\n    \n    image = tf.convert_to_tensor(tf.numpy_function(f, [x] , [tf.float32]))\n    image = tf.reshape(image, (H, W, 3))    # In the Images, number of channels = 3.  \n    return image","metadata":{"execution":{"iopub.status.busy":"2021-09-09T13:02:49.441294Z","iopub.execute_input":"2021-09-09T13:02:49.442039Z","iopub.status.idle":"2021-09-09T13:02:49.449726Z","shell.execute_reply.started":"2021-09-09T13:02:49.441997Z","shell.execute_reply":"2021-09-09T13:02:49.448878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Model\nfrom keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n\n\ndef multi_unet_model(n_classes=23, IMG_HEIGHT=800, IMG_WIDTH=1200, IMG_CHANNELS=3):\n#Build the model\n    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n    s = inputs\n\n    #Contraction path\n    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n    c1 = Dropout(0.1)(c1)  # Original 0.1\n    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n    p1 = MaxPooling2D((2, 2))(c1)\n    \n    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n    c2 = Dropout(0.1)(c2)  # Original 0.1\n    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n    p2 = MaxPooling2D((2, 2))(c2)\n     \n    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n    c3 = Dropout(0.1)(c3)\n    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n    p3 = MaxPooling2D((2, 2))(c3)\n     \n    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n    c4 = Dropout(0.1)(c4)\n    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n     \n    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n    c5 = Dropout(0.3)(c5)\n    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n    \n    #Expansive path \n    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n    u6 = concatenate([u6, c4])\n    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n    c6 = Dropout(0.1)(c6)\n    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n     \n    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n    u7 = concatenate([u7, c3])\n    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n    c7 = Dropout(0.2)(c7)\n    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n     \n    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n    u8 = concatenate([u8, c2])\n    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n    c8 = Dropout(0.1)(c8)  # Original 0.1\n    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n     \n    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n    u9 = concatenate([u9, c1], axis=3)\n    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n    c9 = Dropout(0.1)(c9)  # Original 0.1\n    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n     \n    outputs = Conv2D(n_classes, (1, 1), activation='softmax')(c9)\n     \n    model = Model(inputs=[inputs], outputs=[outputs])\n    \n    #NOTE: Compile the model in the main program to make it easy to test with various loss functions\n    model.compile(optimizer='adam', loss=['categorical_crossentropy'], metrics=['accuracy'])\n    \n    model.summary()\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-09-09T13:02:49.45216Z","iopub.execute_input":"2021-09-09T13:02:49.45255Z","iopub.status.idle":"2021-09-09T13:02:49.523316Z","shell.execute_reply.started":"2021-09-09T13:02:49.452509Z","shell.execute_reply":"2021-09-09T13:02:49.522546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = multi_unet_model()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T13:02:49.524561Z","iopub.execute_input":"2021-09-09T13:02:49.524969Z","iopub.status.idle":"2021-09-09T13:02:50.271491Z","shell.execute_reply.started":"2021-09-09T13:02:49.52493Z","shell.execute_reply":"2021-09-09T13:02:50.270637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"es = tf.keras.callbacks.EarlyStopping(min_delta=0.001, patience=10)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T11:21:49.830753Z","iopub.execute_input":"2021-09-09T11:21:49.831086Z","iopub.status.idle":"2021-09-09T11:21:49.837668Z","shell.execute_reply.started":"2021-09-09T11:21:49.831055Z","shell.execute_reply":"2021-09-09T11:21:49.836683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_dataset,\n          steps_per_epoch=train_steps,\n          validation_data=valid_dataset,\n          validation_steps=valid_steps,\n          epochs=10 #just to check it works properly\n         )","metadata":{"execution":{"iopub.status.busy":"2021-09-09T12:20:15.569498Z","iopub.execute_input":"2021-09-09T12:20:15.569976Z","iopub.status.idle":"2021-09-09T13:01:04.387958Z","shell.execute_reply.started":"2021-09-09T12:20:15.569936Z","shell.execute_reply":"2021-09-09T13:01:04.385437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"version2.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-09-09T13:01:17.630317Z","iopub.execute_input":"2021-09-09T13:01:17.631308Z","iopub.status.idle":"2021-09-09T13:01:17.847629Z","shell.execute_reply.started":"2021-09-09T13:01:17.631257Z","shell.execute_reply":"2021-09-09T13:01:17.846649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model =  tf.keras.models.load_model('./version2.h5') ","metadata":{"execution":{"iopub.status.busy":"2021-09-09T13:03:20.043972Z","iopub.execute_input":"2021-09-09T13:03:20.044321Z","iopub.status.idle":"2021-09-09T13:03:20.579592Z","shell.execute_reply.started":"2021-09-09T13:03:20.044287Z","shell.execute_reply":"2021-09-09T13:03:20.578446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ds = tf_dataset(img_test, mask_test, batch = batch_size)\nmodel.evaluate(test_ds, steps=14)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T13:03:23.883366Z","iopub.execute_input":"2021-09-09T13:03:23.88375Z","iopub.status.idle":"2021-09-09T13:03:53.878462Z","shell.execute_reply.started":"2021-09-09T13:03:23.883714Z","shell.execute_reply":"2021-09-09T13:03:53.877425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = model.predict(test_dataset(img_test, batch = 1), steps=40)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T13:03:53.88346Z","iopub.execute_input":"2021-09-09T13:03:53.885805Z","iopub.status.idle":"2021-09-09T13:04:14.673883Z","shell.execute_reply.started":"2021-09-09T13:03:53.885756Z","shell.execute_reply":"2021-09-09T13:04:14.672914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = np.argmax(pred, axis=3)\nlabel = np.array([cv2.resize(cv2.imread(mask_path+img_test[i][-7:-4]+'.png')[:, :, 0], (1200, 800)) for i in range(predictions.shape[0])])\nlabel = label.flatten()\npredictions = predictions.flatten()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T13:04:14.676009Z","iopub.execute_input":"2021-09-09T13:04:14.676355Z","iopub.status.idle":"2021-09-09T13:04:24.096914Z","shell.execute_reply.started":"2021-09-09T13:04:14.676316Z","shell.execute_reply":"2021-09-09T13:04:24.095961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.metrics import confusion_matrix\ncolor_dict = pd.read_csv('../input/semantic-drone-dataset/class_dict_seg.csv')\ncm = confusion_matrix(label, predictions, labels=range(23))\ndf_cm = pd.DataFrame(cm,  columns=list(color_dict['name'])[:23])\ndf_cm","metadata":{"execution":{"iopub.status.busy":"2021-09-09T13:04:24.098501Z","iopub.execute_input":"2021-09-09T13:04:24.098838Z","iopub.status.idle":"2021-09-09T13:05:10.692503Z","shell.execute_reply.started":"2021-09-09T13:04:24.098801Z","shell.execute_reply":"2021-09-09T13:05:10.691612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def iou(cm, i):\n    return cm[i,i]/(sum(cm[i])+sum(cm[:,i])-cm[i,i])\n\nprint('MIoU: {0}%'.format(round(100*np.mean(np.nan_to_num(np.array([iou(cm, i) for i in range(23)]))), 4)))","metadata":{"execution":{"iopub.status.busy":"2021-09-09T13:05:10.693961Z","iopub.execute_input":"2021-09-09T13:05:10.694614Z","iopub.status.idle":"2021-09-09T13:05:10.704359Z","shell.execute_reply.started":"2021-09-09T13:05:10.694572Z","shell.execute_reply":"2021-09-09T13:05:10.703328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cmap = np.array(list(color_dict[[' r', ' g', ' b']].transpose().to_dict('list').values()))\npredictions = predictions.reshape(-1, 800, 1200)\nlabel = label.reshape(-1, 800, 1200)\n\ni = 18\nfig, ax = plt.subplots(3, 2, figsize=(15, 15))\nfor j in range(3):\n    ax[j, 0].imshow(cmap[predictions[i+j]])\n    ax[j, 1].imshow(cmap[label[i+j]])\n    ax[j, 0].set_title('Prediction')\n    ax[j, 1].set_title('Ground truth')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T13:05:10.706045Z","iopub.execute_input":"2021-09-09T13:05:10.706898Z","iopub.status.idle":"2021-09-09T13:05:12.037637Z","shell.execute_reply.started":"2021-09-09T13:05:10.706859Z","shell.execute_reply":"2021-09-09T13:05:12.036763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}