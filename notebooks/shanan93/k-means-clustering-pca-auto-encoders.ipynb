{"cells":[{"metadata":{"id":"M27qF7CTrBqc"},"cell_type":"markdown","source":"# UNDERSTAND THE PROBLEM STATEMENT "},{"metadata":{},"cell_type":"markdown","source":"- CUSTID: Identification of Credit Card holder \n- BALANCE: Balance amount left in customer's account to make purchases\n- BALANCE_FREQUENCY: How frequently the Balance is updated, score between 0 and 1 (1 = frequently updated, 0 = not frequently updated)\n- PURCHASES: Amount of purchases made from account\n- ONEOFFPURCHASES: Maximum purchase amount done in one-go\n- INSTALLMENTS_PURCHASES: Amount of purchase done in installment\n- CASH_ADVANCE: Cash in advance given by the user\n- PURCHASES_FREQUENCY: How frequently the Purchases are being made, score between 0 and 1 (1 = frequently purchased, 0 = not frequently purchased)\n- ONEOFF_PURCHASES_FREQUENCY: How frequently Purchases are happening in one-go (1 = frequently purchased, 0 = not frequently purchased)\n PURCHASES_INSTALLMENTS_FREQUENCY: How frequently purchases in installments are being done (1 = frequently done, 0 = not frequently done)\n- CASH_ADVANCE_FREQUENCY: How frequently the cash in advance being paid\n- CASH_ADVANCE_TRX: Number of Transactions made with \"Cash in Advance\"\n- PURCHASES_TRX: Number of purchase transactions made\n- CREDIT_LIMIT: Limit of Credit Card for user\n- PAYMENTS: Amount of Payment done by user\n- MINIMUM_PAYMENTS: Minimum amount of payments made by user  \n- PRC_FULL_PAYMENT: Percent of full payment paid by user\n- TENURE: Tenure of credit card service for user"},{"metadata":{"id":"zKmFmyaGunc7"},"cell_type":"markdown","source":"# IMPORT LIBRARIES AND DATASETS"},{"metadata":{"id":"S0Cx3743urFY","outputId":"47cbe3c1-a14d-46a8-ee5d-47d55ad5ba15","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler, normalize\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\n","execution_count":null,"outputs":[]},{"metadata":{"id":"tjIiJdM4u1IE","trusted":true},"cell_type":"code","source":"creditcard_df = pd.read_csv('../input/ccdata/CC GENERAL.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"id":"q4_wPDKCu5Uc","trusted":true},"cell_type":"code","source":"creditcard_df","execution_count":null,"outputs":[]},{"metadata":{"id":"hMq3-KWOx0e1","trusted":true},"cell_type":"code","source":"creditcard_df.info() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- 18 features with 8950 points "},{"metadata":{"id":"s0E9xPLdx2Ok","trusted":true},"cell_type":"code","source":"creditcard_df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Mean balance is $1564 \n= Balance frequency is frequently updated on average ~0.9\n- Purchases average is $1000\n- one off purchase average is ~$600\n- Average purchases frequency is around 0.5\n- average ONEOFF_PURCHASES_FREQUENCY, PURCHASES_INSTALLMENTS_FREQUENCY, and CASH_ADVANCE_FREQUENCY are generally low\n- Average credit limit ~ 4500\n- Percent of full payment is 15%\n- Average tenure is 11 years"},{"metadata":{"id":"MA5bKvr7KxI8","trusted":true},"cell_type":"code","source":"# Let's see who made one off purchase of $40761!\ncreditcard_df[creditcard_df['ONEOFF_PURCHASES'] == 40761.25]\n","execution_count":null,"outputs":[]},{"metadata":{"id":"RBiutRGLL9HH","trusted":true},"cell_type":"code","source":"creditcard_df['CASH_ADVANCE'].max()","execution_count":null,"outputs":[]},{"metadata":{"id":"FAIfPnCLLnjw","trusted":true},"cell_type":"code","source":"# Let's see who made cash advance of $47137!\n# This customer made 123 cash advance transactions!!\n# Never paid credit card in full\n\ncreditcard_df[creditcard_df['CASH_ADVANCE'] == 47137.211760000006]\n","execution_count":null,"outputs":[]},{"metadata":{"id":"LlszUhNNyrl_"},"cell_type":"markdown","source":"# VISUALIZE AND EXPLORE DATASET"},{"metadata":{"id":"ICj3NLbqqmve","trusted":true},"cell_type":"code","source":"# Let's see if we have any missing data, luckily we don't!\nsns.heatmap(creditcard_df.isnull(), yticklabels = False, cbar = False, cmap=\"Blues\")\n","execution_count":null,"outputs":[]},{"metadata":{"id":"70XopgWwMmHG","trusted":true},"cell_type":"code","source":"creditcard_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"id":"wboxbIPwT7Wi","trusted":true},"cell_type":"code","source":"# Fill up the missing elements with mean of the 'MINIMUM_PAYMENT' \ncreditcard_df.loc[(creditcard_df['MINIMUM_PAYMENTS'].isnull() == True), 'MINIMUM_PAYMENTS'] = creditcard_df['MINIMUM_PAYMENTS'].mean()\n","execution_count":null,"outputs":[]},{"metadata":{"id":"ciOq-cYxMw8P","trusted":true},"cell_type":"code","source":"# Fill up the missing elements with mean of the 'CREDIT_LIMIT' \ncreditcard_df.loc[(creditcard_df['CREDIT_LIMIT'].isnull() == True), 'CREDIT_LIMIT'] = creditcard_df['CREDIT_LIMIT'].mean()","execution_count":null,"outputs":[]},{"metadata":{"id":"H-c9kqOSUU1t","trusted":true},"cell_type":"code","source":" sns.heatmap(creditcard_df.isnull(), yticklabels = False, cbar = False, cmap=\"Blues\")","execution_count":null,"outputs":[]},{"metadata":{"id":"zFIXGFrucdCl","trusted":true},"cell_type":"code","source":"# Let's see if we have duplicated entries in the data\ncreditcard_df.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{"id":"onSLJRBtcohW","trusted":true},"cell_type":"code","source":"# Let's drop Customer ID since it has no meaning here \ncreditcard_df.drop(\"CUST_ID\", axis = 1, inplace= True)","execution_count":null,"outputs":[]},{"metadata":{"id":"PSzpvJgWcxnu","trusted":true},"cell_type":"code","source":"creditcard_df.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"QIw-jGI9NOCg","trusted":true},"cell_type":"code","source":"n = len(creditcard_df.columns)\nn","execution_count":null,"outputs":[]},{"metadata":{"id":"fIOb3930ONKS","trusted":true},"cell_type":"code","source":"creditcard_df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- distplot combines the matplotlib.hist function with seaborn kdeplot()\n- KDE Plot represents the Kernel Density Estimate\n- KDE is used for visualizing the Probability Density of a continuous variable. \n- KDE demonstrates the probability density at different values in a continuous variable. \n\n Mean of balance is $1500\n- 'Balance_Frequency' for most customers is updated frequently ~1\n- For 'PURCHASES_FREQUENCY', there are two distinct group of customers\n- For 'ONEOFF_PURCHASES_FREQUENCY' and 'PURCHASES_INSTALLMENT_FREQUENCY' most users don't do one off puchases or installment purchases frequently \n- Very small number of customers pay their balance in full 'PRC_FULL_PAYMENT'~0\n- Credit limit average is around $4500\n- Most customers are ~11 years tenure"},{"metadata":{"id":"rFmjikf6ONgu","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,50))\nfor i in range(len(creditcard_df.columns)):\n    plt.subplot(17, 1, i+1)\n    sns.distplot(creditcard_df[creditcard_df.columns[i]], kde_kws={\"color\": \"b\", \"lw\": 3, \"label\": \"KDE\"}, hist_kws={\"color\": \"g\"})\n    plt.title(creditcard_df.columns[i])\n\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"id":"bnGS8pC1UsN9","trusted":true},"cell_type":"code","source":"sns.pairplot(creditcard_df)\n# Correlation between 'PURCHASES' and ONEOFF_PURCHASES & INSTALMENT_PURCHASES \n# Trend between 'PURCHASES' and 'CREDIT_LIMIT' & 'PAYMENTS'\n","execution_count":null,"outputs":[]},{"metadata":{"id":"c6UiAqTkKD85","trusted":true},"cell_type":"code","source":"correlations = creditcard_df.corr()\n","execution_count":null,"outputs":[]},{"metadata":{"id":"zBy4m89a08Sj","trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(figsize = (20, 20))\nsns.heatmap(correlations, annot = True)\n\n# 'PURCHASES' have high correlation between one-off purchases, 'installment purchases, purchase transactions, credit limit and payments. \n# Strong Positive Correlation between 'PURCHASES_FREQUENCY' and 'PURCHASES_INSTALLMENT_FREQUENCY'\n","execution_count":null,"outputs":[]},{"metadata":{"id":"Y0GmpAjG3GiH"},"cell_type":"markdown","source":"# FIND THE OPTIMAL NUMBER OF CLUSTERS USING ELBOW METHOD"},{"metadata":{"id":"axr926Btjyux","trusted":true},"cell_type":"code","source":"# Let's scale the data first\nscaler = StandardScaler()\ncreditcard_df_scaled = scaler.fit_transform(creditcard_df)","execution_count":null,"outputs":[]},{"metadata":{"id":"9CJeasg4kHyP","trusted":true},"cell_type":"code","source":"creditcard_df_scaled.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"FK5ggiVPsJE9","trusted":true},"cell_type":"code","source":"creditcard_df_scaled","execution_count":null,"outputs":[]},{"metadata":{"id":"1_nb-D8H3cK-","trusted":true},"cell_type":"code","source":"scores_1 = []\n\nrange_values = range(1, 20)\n\nfor i in range_values:\n    kmeans = KMeans(n_clusters = i)\n    kmeans.fit(creditcard_df_scaled)\n    scores_1.append(kmeans.inertia_)\n\nplt.plot(scores_1, 'bx-')\nplt.title('Finding the right number of clusters')\nplt.xlabel('Clusters')\nplt.ylabel('Scores') \nplt.show()\n\n# From this we can observe that, 4th cluster seems to be forming the elbow of the curve. \n# However, the values does not reduce linearly until 8th cluster. \n# Let's choose the number of clusters to be 7.","execution_count":null,"outputs":[]},{"metadata":{"id":"m_jo7mJ4C8R9"},"cell_type":"markdown","source":"#  APPLY K-MEANS "},{"metadata":{"id":"qwzY8rj0uV-a","trusted":true},"cell_type":"code","source":"kmeans = KMeans(8)\nkmeans.fit(creditcard_df_scaled)\nlabels = kmeans.labels_","execution_count":null,"outputs":[]},{"metadata":{"id":"dShNNvg09zH3","trusted":true},"cell_type":"code","source":"kmeans.cluster_centers_.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"VEiPOUJv9iFK","trusted":true},"cell_type":"code","source":"\ncluster_centers = pd.DataFrame(data = kmeans.cluster_centers_, columns = [creditcard_df.columns])\ncluster_centers           ","execution_count":null,"outputs":[]},{"metadata":{"id":"9ogiZbsGBBl8","trusted":true},"cell_type":"code","source":"# In order to understand what these numbers mean, let's perform inverse transformation\ncluster_centers = scaler.inverse_transform(cluster_centers)\ncluster_centers = pd.DataFrame(data = cluster_centers, columns = [creditcard_df.columns])\ncluster_centers\n\n# First Customers cluster (Transactors): Those are customers who pay least amount of intrerest charges and careful with their money, Cluster with lowest balance ($104) and cash advance ($303), Percentage of full payment = 23%\n# Second customers cluster (revolvers) who use credit card as a loan (most lucrative sector): highest balance ($5000) and cash advance (~$5000), low purchase frequency, high cash advance frequency (0.5), high cash advance transactions (16) and low percentage of full payment (3%)\n# Third customer cluster (VIP/Prime): high credit limit $16K and highest percentage of full payment, target for increase credit limit and increase spending habits\n# Fourth customer cluster (low tenure): these are customers with low tenure (7 years), low balance \n","execution_count":null,"outputs":[]},{"metadata":{"id":"kCuHRqBIusm7","trusted":true},"cell_type":"code","source":"# Labels associated to each data point\nlabels.shape ","execution_count":null,"outputs":[]},{"metadata":{"id":"Ywcls4cvu2lh","trusted":true},"cell_type":"code","source":"labels.max()","execution_count":null,"outputs":[]},{"metadata":{"id":"NPQIMB7Fu9f3","trusted":true},"cell_type":"code","source":"labels.min()","execution_count":null,"outputs":[]},{"metadata":{"id":"kgLSvv-6vHSs","trusted":true},"cell_type":"code","source":"y_kmeans = kmeans.fit_predict(creditcard_df_scaled)\ny_kmeans\n","execution_count":null,"outputs":[]},{"metadata":{"id":"OfMaZqUOqdJB","trusted":true},"cell_type":"code","source":"# concatenate the clusters labels to our original dataframe\ncreditcard_df_cluster = pd.concat([creditcard_df, pd.DataFrame({'cluster':labels})], axis = 1)\ncreditcard_df_cluster.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"TYEhR6rvqwda","trusted":true},"cell_type":"code","source":"# Plot the histogram of various clusters\nfor i in creditcard_df.columns:\n    plt.figure(figsize = (35, 5))\n    for j in range(8):\n        plt.subplot(1,8,j+1)\n        cluster = creditcard_df_cluster[creditcard_df_cluster['cluster'] == j]\n        cluster[i].hist(bins = 20)\n        plt.title('{}    \\nCluster {} '.format(i,j))\n  \n    plt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"id":"UVTd7FYLNCAE"},"cell_type":"markdown","source":"#  APPLY PCA AND VISUALIZE THE RESULTS"},{"metadata":{"id":"RgFq3h993cIz","trusted":true},"cell_type":"code","source":"# Obtain the principal components \npca = PCA(n_components=2)\nprincipal_comp = pca.fit_transform(creditcard_df_scaled)\nprincipal_comp","execution_count":null,"outputs":[]},{"metadata":{"id":"ad3UQtPU0eHK","trusted":true},"cell_type":"code","source":"# Create a dataframe with the two components\npca_df = pd.DataFrame(data = principal_comp, columns =['pca1','pca2'])\npca_df.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"q7gsGkEZvkYd","trusted":true},"cell_type":"code","source":"# Concatenate the clusters labels to the dataframe\npca_df = pd.concat([pca_df,pd.DataFrame({'cluster':labels})], axis = 1)\npca_df.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"4KYt5SUrvneq","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nax = sns.scatterplot(x=\"pca1\", y=\"pca2\", hue = \"cluster\", data = pca_df, palette =['red','green','blue','pink','yellow','gray','purple', 'black'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"-wRQqOeB5Zh5"},"cell_type":"markdown","source":"# APPLY AUTOENCODERS "},{"metadata":{},"cell_type":"markdown","source":"### PERFORM DIMENSIONALITY REDUCTION USING AUTOENCODERS"},{"metadata":{"id":"LfGAnIVUv44L","trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, Dropout\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.initializers import glorot_uniform\nfrom keras.optimizers import SGD\n\nencoding_dim = 7\n\ninput_df = Input(shape=(17,))\n\n\n# Glorot normal initializer (Xavier normal initializer) draws samples from a truncated normal distribution \n\nx = Dense(encoding_dim, activation='relu')(input_df)\nx = Dense(500, activation='relu', kernel_initializer = 'glorot_uniform')(x)\nx = Dense(500, activation='relu', kernel_initializer = 'glorot_uniform')(x)\nx = Dense(2000, activation='relu', kernel_initializer = 'glorot_uniform')(x)\n\nencoded = Dense(10, activation='relu', kernel_initializer = 'glorot_uniform')(x)\n\nx = Dense(2000, activation='relu', kernel_initializer = 'glorot_uniform')(encoded)\nx = Dense(500, activation='relu', kernel_initializer = 'glorot_uniform')(x)\n\ndecoded = Dense(17, kernel_initializer = 'glorot_uniform')(x)\n\n# autoencoder\nautoencoder = Model(input_df, decoded)\n\n#encoder - used for our dimention reduction\nencoder = Model(input_df, encoded)\n\nautoencoder.compile(optimizer= 'adam', loss='mean_squared_error')\n","execution_count":null,"outputs":[]},{"metadata":{"id":"L7IYeT6Q05-Q","trusted":true},"cell_type":"code","source":"creditcard_df_scaled.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"Pd9qA2Chweye","trusted":true},"cell_type":"code","source":"autoencoder.fit(creditcard_df_scaled, creditcard_df_scaled, batch_size = 128, epochs = 25,  verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{"id":"zZ86PPLm1sTn","trusted":true},"cell_type":"code","source":"autoencoder.save_weights('autoencoder.h5')","execution_count":null,"outputs":[]},{"metadata":{"id":"0lL6Wv0e1scz","trusted":true},"cell_type":"code","source":"pred = encoder.predict(creditcard_df_scaled)","execution_count":null,"outputs":[]},{"metadata":{"id":"r_iqk31a2G-t","trusted":true},"cell_type":"code","source":"pred.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"jnHIsvgn2Omk","trusted":true},"cell_type":"code","source":"scores_2 = []\n\nrange_values = range(1, 20)\n\nfor i in range_values:\n    kmeans = KMeans(n_clusters= i)\n    kmeans.fit(pred)\n    scores_2.append(kmeans.inertia_)\n\nplt.plot(scores_2, 'b+-')\nplt.title('Finding right number of clusters')\nplt.xlabel('Clusters')\nplt.ylabel('scores') \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"EUvpOCwq48IM","trusted":true},"cell_type":"code","source":"plt.plot(scores_1, 'bx-', color = 'r')\nplt.plot(scores_2, 'bx-', color = 'g')","execution_count":null,"outputs":[]},{"metadata":{"id":"7JhXSa-j32rj","trusted":true},"cell_type":"code","source":"kmeans = KMeans(4)\nkmeans.fit(pred)\nlabels = kmeans.labels_\ny_kmeans = kmeans.fit_predict(creditcard_df_scaled)","execution_count":null,"outputs":[]},{"metadata":{"id":"utaeIFtD38X-","trusted":true},"cell_type":"code","source":"df_cluster_dr = pd.concat([creditcard_df, pd.DataFrame({'cluster':labels})], axis = 1)\ndf_cluster_dr.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"fhU84OJx4jFb","trusted":true},"cell_type":"code","source":"pca = PCA(n_components=2)\nprin_comp = pca.fit_transform(pred)\npca_df = pd.DataFrame(data = prin_comp, columns =['pca1','pca2'])\npca_df.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"RlSSorv65kao","trusted":true},"cell_type":"code","source":"pca_df = pd.concat([pca_df,pd.DataFrame({'cluster':labels})], axis = 1)\npca_df.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"G3aPOnO65ot-","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nax = sns.scatterplot(x=\"pca1\", y=\"pca2\", hue = \"cluster\", data = pca_df, palette =['red','green','blue','yellow'])\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}