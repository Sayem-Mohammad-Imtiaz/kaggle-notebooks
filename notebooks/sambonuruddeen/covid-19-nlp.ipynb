{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport re\nimport string\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\nfrom numpy import array\nfrom keras.preprocessing.text import one_hot\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Flatten\nfrom keras.layers.embeddings import Embedding\nfrom keras.preprocessing.text import Tokenizer\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**LOAD DATA**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#Get character encoding of the files\nfile = [\"../input/covid-19-nlp-text-classification/Corona_NLP_train.csv\", \"../input/covid-19-nlp-text-classification/Corona_NLP_test.csv\"]\nfor single in file:\n    with open(single) as f:\n        print(f.encoding)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/covid-19-nlp-text-classification/Corona_NLP_train.csv', encoding='latin-1')\ntest = pd.read_csv('/kaggle/input/covid-19-nlp-text-classification/Corona_NLP_test.csv', encoding='latin-1')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**EDA + VISUALIZATIONS**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Get summary of the training data\ntrain.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#display first rows of the training dataset\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Get summary of the testing data\ntest.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#display first rows of the testing dataset\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#combine the training and testing data t\nframes = [train, test]\ndata = pd.concat(frames)\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check for missing data \nmissing = data['Location'].isnull()\n\n\nprint(data[missing])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#replace missing data \ndata['Location'] = data['Location'].replace(np.nan, \"Unknown\")\n#test['Location'] = test['Location'].replace(np.nan, \"Unknown\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check again for missing data\ndata[data['Location'].isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check for duplicates in the data\ndups = data.duplicated()\ndata[dups]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for Locations distribution\nloc_dist = data['Location'].unique()\nprint(len(loc_dist))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#summary of the whole data\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sentiment Distribution","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot total negative vs total positive\npos  = len(data[data['Sentiment'] == 'Positive'])\next_pos = len(data[data['Sentiment'] == 'Extremely Positive'])\n\nneut =len(data[data['Sentiment'] == 'Neutral'])\n\nneg = len(data[data['Sentiment'] == 'Negative'])\next_neg = len(data[data['Sentiment'] == 'Extremely Negative'])\n\ntotal_positive = pos + ext_pos\ntotal_negative = neg + ext_neg\n\ntt_label = [\"Total Positive\", \"Neutral\", \"Total Negative\"]\ntt = [total_positive, neut, total_negative]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.bar(tt_label, tt)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot\nplt.pie(tt, labels=tt_label, autopct='%1.1f%%')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The charts above gives the summary of the whole data categorized into **3 classes**. \n\nThe **positive** column comprises of the *Positive* and *Extremely positive* sentiments which acounts for **43.6%** of the total data. \n\nThe **Negative** column, with **37.9%**, represents the total of the *Negative* and *Extremely Negative* sentiments, while the **Neutral** sentiments representing **18.5%** of the total data."},{"metadata":{"trusted":true},"cell_type":"code","source":"sentiment_count = data['Sentiment'].value_counts()\nsentiment_count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot\nplt.bar(sentiment_count.index,sentiment_count)\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot\nplt.pie(sentiment_count, labels=sentiment_count.index, autopct='%1.1f%%')\n#plt.legend('upper right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The plots above shows that Positive sentiments has the highest count at 27.5%, closely followed by the Negative sentiments data with 24.4% of the whole data. Neutral opininions occupy the center with about 18.5% of the records. Extremely Positive and Extremely Negative sentiments have values of 16.1% and 13.5% respectively."},{"metadata":{"trusted":true},"cell_type":"code","source":"#time series - start of date and end date - line plot frequency of positive and negative\nday_total = data['TweetAt'].unique()\nprint(day_total)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MODELS"},{"metadata":{},"cell_type":"markdown","source":"**Logistic Regresson**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#vectorizer:\nfrom sklearn.feature_extraction.text import CountVectorizer\nvectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\ntrain_matrix = vectorizer.fit_transform(train['OriginalTweet'])\ntest_matrix = vectorizer.transform(test['OriginalTweet'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train1 = train_matrix\nX_test1 = test_matrix\n#y_train = train['sentiment']\n#y_test = test['sentiment']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\n\nlab = train['Sentiment']\ny_train1 = le.fit_transform(lab)\ny_test1 = le.fit_transform(test['Sentiment'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#The model\nlr = LogisticRegression(max_iter=10000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Training the model\nlr.fit(X_train1,y_train1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Make predictions\npredictions1 = lr.predict(X_test1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(predictions1[:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Show the results of the predictions\nlab_names = test['Sentiment'].unique()\nlab_names[predictions1[:10]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# find accuracy, precision, recall:\nfrom sklearn.metrics import confusion_matrix,classification_report\nnew = np.asarray(y_test1)\nconfusion_matrix(predictions1,y_test1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(predictions1,y_test1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**LSTM**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Get Text data from the Tweet Column\ncorpus = data['OriginalTweet']\ncorpus","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#One-Hot Encoding of the labels\nsentiment = pd.get_dummies(data['Sentiment'])\nprint(sentiment)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(corpus))\nprint(len(sentiment))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Words Tokenization\nfrom nltk.tokenize import word_tokenize\n\nall_words = []\nfor sent in corpus:\n    tokenize_word = word_tokenize(sent)\n    for word in tokenize_word:\n        all_words.append(word)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Extract each word while ignoring duplicates\nunique_words = set(all_words)\nprint(len(unique_words))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nvocab_length = 101948\nembedded_sentences = [one_hot(sent, vocab_length) for sent in corpus]\n#print(embedded_sentences )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#count number of words\nword_count = lambda sentence: len(word_tokenize(sentence))\nlongest_sentence = max(corpus, key=word_count)\nlength_long_sentence = len(word_tokenize(longest_sentence))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fill the end of each sentence with '0' so that they all have same lenght\npadded_sentences = pad_sequences(embedded_sentences, length_long_sentence, padding='post')\nprint(padded_sentences)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(padded_sentences)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#divide the data into Training and Testing\n\nX_train,X_test, y_train, y_test = train_test_split(padded_sentences, sentiment, train_size=0.9, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Build the Model \nmodel = Sequential()\nmodel.add(Embedding(vocab_length, 20, input_length=length_long_sentence))\nmodel.add(LSTM(20, return_sequences=True))\nmodel.add(Dense(100, activation='relu'))\nmodel.add(Flatten())\nmodel.add(Dense(5, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#compile model and show summary\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train the model\n\nmodel.fit(X_train, y_train, epochs=15, steps_per_epoch=200, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Evaluate model performance\nloss, accuracy = model.evaluate(padded_sentences, sentiment, verbose=0)\nprint('Accuracy: %f' % (accuracy*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#make predictions\npredictions = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Store Predictions result\npred_result = (np.argmax(predictions[:20], axis=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Show result of predictions\nprint(lab_names[pred_result])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}