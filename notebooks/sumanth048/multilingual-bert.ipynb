{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_df = pd.read_csv('/kaggle/input/title-conference/title_conference.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_df.head(4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_df = input_df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_cat = []\nun_cat = set(selected_df['Conference'].values.tolist())\ni = 0\nfor z in un_cat:\n    num_cat.append(i)\n    i = i+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_dict = dict(zip(un_cat,num_cat))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cat(x):\n    return cat_dict[x]\n\nselected_df['label'] = selected_df['Conference'].apply(cat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_df['Title'][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install keras-bert","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom keras.utils import np_utils\nimport tensorflow as tf\nimport keras as keras\nimport keras.backend as K\nfrom keras.models import load_model\nfrom keras.layers.merge import concatenate\nfrom keras_bert import load_trained_model_from_checkpoint, load_vocabulary\nfrom keras_bert import Tokenizer\nfrom keras_bert import AdamWarmup, calc_train_steps\nfrom keras.layers import Input\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport gc\nimport transformers\nfrom kaggle_datasets import KaggleDatasets\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.stem.wordnet import WordNetLemmatizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SEQ_LEN = 128\nBATCH_SIZE = 32\nEPOCHS = 10\nLR = 1e-4\nimport os\npretrained_path = '/kaggle/input/bert-base-multilingual/multilingual_L-12_H-768_A-12/'\nconfig_path = os.path.join(pretrained_path, 'bert_config.json')\ncheckpoint_path = os.path.join(pretrained_path, 'bert_model.ckpt')\nvocab_path = os.path.join(pretrained_path, 'vocab.txt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"token_dict = load_vocabulary(vocab_path)\ntokenizer = Tokenizer(token_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert_data(test_df,DATA_COLUMN):\n    global tokenizer\n    indices = []\n    for i in tqdm(range(len(test_df))):\n        ids, segments = tokenizer.encode(test_df[DATA_COLUMN].iloc[i], max_len=SEQ_LEN)\n        indices.append(ids)\n    indices = np.array(indices)\n    return [indices, np.zeros_like(indices)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model():\n    from keras.layers.normalization import BatchNormalization\n    model = load_trained_model_from_checkpoint(\n        config_path,\n        checkpoint_path,\n        training=True,\n        trainable=True,\n        seq_len=SEQ_LEN,\n    )\n\n    inputs = model.inputs[:2]\n    dense = model.layers[-3].output\n    dense2 = keras.layers.Dense(10,activation='relu', kernel_initializer ='glorot_uniform')(dense)\n    dense3 = keras.layers.Dense(10,activation='relu', kernel_initializer ='glorot_uniform')(dense2)\n    outputs = keras.layers.Dense(1, activation='sigmoid', kernel_initializer='glorot_uniform',\n                                 name = 'real_output')(dense3)\n\n    \n\n    model = keras.models.Model(inputs, outputs)\n       \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cleansing(x):\n    quoteRemoval = x.replace('\"','')\n    spaceRemoval = re.sub(\"\\s\\s+\" , \" \", quoteRemoval)\n    stringRemoval = spaceRemoval.strip()\n    urlRemove = re.sub(r'http\\S+', '', stringRemoval)\n    specialChar = re.sub(r\"[^a-zA-Z]+\", ' ',urlRemove) \n    return specialChar\n\ndef recall_m(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n        recall = true_positives / (possible_positives + K.epsilon())\n        return recall\n\ndef precision_m(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n        precision = true_positives / (predicted_positives + K.epsilon())\n        return precision\n\ndef f1_m(y_true, y_pred):\n    precision = precision_m(y_true, y_pred)\n    recall = recall_m(y_true, y_pred)\n    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n\n\nselected_df['Title'] = selected_df['Title'].apply(cleansing)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = selected_df['Title'].values\nY = selected_df['label'].values\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.DataFrame(X_train, columns = ['Title'])\ndf_test = pd.DataFrame(X_test, columns = ['Title'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = convert_data(df_train,'Title')\nX_test = convert_data(df_test,'Title')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = build_model()\nmodel.summary()\ndecay_steps, warmup_steps = calc_train_steps(y_train.shape[0],batch_size=BATCH_SIZE,epochs=EPOCHS,)\nmodel.compile(AdamWarmup(decay_steps=decay_steps, warmup_steps=warmup_steps, lr=LR),loss='categorical_crossentropy',metrics=['acc',f1_m,precision_m, recall_m])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import *\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n                              patience=2, min_lr=1e-7, verbose=1)\nBERT = model.fit(\n        X,\n        y_train,\n        epochs=10,\n        batch_size=BATCH_SIZE,\n        validation_split=0.2,\n        callbacks=[reduce_lr]\n    )","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}