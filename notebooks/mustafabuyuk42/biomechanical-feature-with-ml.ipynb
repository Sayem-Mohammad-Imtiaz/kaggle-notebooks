{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Explanation"},{"metadata":{},"cell_type":"markdown","source":"In this kernel I compared classification methos which are consist of KNN,Logistic regression ,SVM,Naive Bayes,Desicion tree, Random Forest algorithms."},{"metadata":{},"cell_type":"markdown","source":"# Contents"},{"metadata":{},"cell_type":"markdown","source":"### 1) Data manipulation"},{"metadata":{},"cell_type":"markdown","source":"### 2) Normalization"},{"metadata":{},"cell_type":"markdown","source":"### 3) Visualization"},{"metadata":{},"cell_type":"markdown","source":"### 4) Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"### 5) Classification Algorithms"},{"metadata":{},"cell_type":"markdown","source":"### 6) Results and Conclusion"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1) Data Manipulation"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/column_2C_weka.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"A = data[data[\"class\"] == 'Abnormal']\nN = data[data[\"class\"] == 'Normal']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"A.drop([\"class\"],axis = 1,inplace = True)\nN.drop([\"class\"],axis = 1,inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2) Normalization"},{"metadata":{"trusted":true},"cell_type":"code","source":"A = (A-np.min(A))/(np.max(A)-np.min(A))\nN = (N-np.min(N))/(np.max(N)-np.min(N))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3) Visualize data"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(A.pelvic_incidence ,A[\"pelvic_tilt numeric\"] , color = 'red')\nplt.scatter(N.pelvic_incidence ,N[\"pelvic_tilt numeric\"] , color = 'green')\nplt.xlabel(\"pelvic tilt\")\nplt.ylabel(\"pelvic incidence\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = \"class\", data = data)\ndata[\"class\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4) Preprocessing "},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"class\"].replace([\"Normal\",\"Abnormal\"],[1,0],inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = data[\"class\"].values\nx_data = data.drop([\"class\"],axis = 1)\nx = (x_data-np.min(x_data))/(np.max(x_data)-np.min(x_data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split \nx_train,x_test,y_train, y_test = train_test_split(x,y,test_size = 0.33 ,random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_list =[]\ny_list =[]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5) Classification Algorithms"},{"metadata":{},"cell_type":"markdown","source":"## Logistic_regression (1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\nlr.fit(x_train,y_train)\nprediction = lr.predict(x_test)\nprint(\"Logistic regression score :\",lr.score(x_test,y_test))\nx_list.append(\"Logistic regression\")\ny_list.append(lr.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## KNN Classification (2)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nkn =KNeighborsClassifier(n_neighbors=4)\nkn.fit(x_train,y_train)\nprint(\"Knn classification score :\",kn.score(x_test,y_test))\nscore=[]\nfor i in range(1,20):\n    kn2 = KNeighborsClassifier(n_neighbors=i)\n    kn2.fit(x_train,y_train)\n    score.append(kn2.score(x_test,y_test))\nplt.plot(score)\nx_list.append(\"Knn classification\")\ny_list.append(kn.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Support vector machine classification (SVM) (3)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nsvm =SVC(random_state=1)\nsvm.fit(x_train,y_train)\nprint(\"svm score : \",svm.score(x_test,y_test))\nx_list.append(\"SVM\")\ny_list.append(svm.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Naive Bayes Classification (4)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb.fit(x_train,y_train)\nprint(\"Naive bayes score : \",nb.score(x_test,y_test))\nx_list.append(\"Naive Bayes Classification\")\ny_list.append(nb.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Desicion tree algorithm (5)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier()\ndt.fit(x_train,y_train)\nprint(\"desicion tree score : \",dt.score(x_test,y_test))\nx_list.append(\"Desicion tree\")\ny_list.append(dt.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random forest algorithm (6)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators=50 , random_state=1)\nrf.fit(x_train,y_train)\nprint(\"random forest score : \",rf.score(x_test,y_test))\nx_list.append(\"Random forest\")\ny_list.append(rf.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Evaluating  Models"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_true = y_test\ny_pred = rf.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_true,y_pred)\n\nf,ax = plt.subplots(figsize =(5,5))\nsns.heatmap(cm,annot=True,linewidths =0.5,linecolor = \"red\",fmt = \".0f\",ax = ax)\nplt.xlabel(\"y_pred\")\nplt.ylabel(\"y_true\")\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6) Results"},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = zip(x_list,y_list)\nmapped =list(scores)\ndf = pd.DataFrame(mapped,columns =[\"label\",\"result\"])\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df = df[\"result\"].sort_values(ascending = False).index.values\nsorted_df = df.reindex(new_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot figure\nplt.figure(figsize = (10,6))\nplt.plot(sorted_df.label,sorted_df.result)\nplt.xlabel(\"Score\")\nplt.ylabel(\"Algorithms\")\nplt.xticks(rotation = 90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7) Conclusion\nDesicion tree algorithm gives the highest results among the classification methods"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}