{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder\n\nimport os\n%matplotlib inline\npd.set_option('max_columns', None)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## A look at the data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"try:\n   df = pd.read_csv('../input/airbnb-boston/boston_listings.csv')\nexcept CParserError:\n    print(\"Something wrong the file\")\n\ndf.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop columns where more than 70% column is null\ndf = df.drop(columns = df.columns[df.isna().mean() > 0.70])\n#add location data not useful or all are none\ndrop_cols =  ['country_code', 'country', 'state','experiences_offered']\ndf = df.drop(columns = drop_cols)\ndf.head(1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Preprocessing","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Fixing the columns with money involved. Converting from string into integer.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#fixing price\ndf['price'] = df['price'].map(lambda p: int(p[1:-3].replace(\",\", \"\")))\n#If Fee type is nan that is then it is supposed that there are no charge for the service\ndf['cleaning_fee'] = df['cleaning_fee'].fillna('$0.00').map(lambda p: int(p[1:-3].replace(\",\", \"\")))\ndf['security_deposit'] = df['security_deposit'].fillna('$0.00').map(lambda p: int(p[1:-3].replace(\",\", \"\")))\ndf['extra_people'] = df['extra_people'].fillna('$0.00').map(lambda p: int(p[1:-3].replace(\",\", \"\")))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Amenities column can be an important feature in predicting price. \n\nWe'll encode the presence or absence of the various amenities our AirBnB homes offer into features. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#separating amenities\ndef amenities_separtor(x):\n    arr = x.split(',')\n    result = [s.replace('\"', '').replace(\"{\",\"\").replace('}', '') for s in arr]\n    return result\ndf['amenities'] = df['amenities'].apply(amenities_separtor)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Bar chart representing most common to rare amenities ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.Series(np.concatenate(df['amenities'])).value_counts().plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#All type of amenities\nall_amenities = np.unique(np.concatenate(df['amenities']))[1:]\nall_amenities","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating a list of features for amenities\namenity_list = np.array([df['amenities'].map(lambda amns: a in amns) for a in all_amenities])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#add columns to df\ndf = pd.concat([df,pd.DataFrame(amenity_list.T, columns=all_amenities)], axis =1)\ndf = df.drop(columns=['amenities'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A number of these features are boolean features, except that they are saved as strings of the form \"t\" or \"f\"","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#fixing which are saved as strings of the form \"t\" or \"f\".\nfor tf_feature in ['host_is_superhost', 'host_identity_verified', 'host_has_profile_pic',\n                   'is_location_exact', 'requires_license', 'instant_bookable',\n                   'require_guest_profile_picture', 'require_guest_phone_verification']:\n    df[tf_feature] = df[tf_feature].map(lambda s: False if s == \"f\" else True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Converting categorical features into dummy variables","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#create dummy variables\ncategorical_features = ['neighbourhood_cleansed', 'property_type', 'room_type', 'bed_type','cancellation_policy']\nfor feature in categorical_features:\n    df = pd.concat([df, pd.get_dummies(df[feature])], axis=1)\ndf = df.drop(columns =categorical_features)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, there are many columns to be dropped.\n\ncolumns_withtext: These are the columns with text data. Text data can be useful but due to time constrain will add it for future work.\n\ncolumns_withurl and columns_nouse: There feautres donnot impact the price.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#removing columns with text data for now\n# many could have been useful such as transit, notes, interaction, \ncolumns_withtext = ['summary','description','space','neighborhood_overview','notes','transit','interaction',  \n                    'house_rules','host_name','host_about','host_location','host_neighbourhood','street','neighbourhood','market',\n                   'smart_location','calendar_updated','calendar_last_scraped','first_review', 'last_review','access',\n                    'name', 'host_verifications', 'city', 'zipcode']\ncolumns_withurl = ['xl_picture_url','host_url','thumbnail_url','medium_url','host_picture_url','host_thumbnail_url',\n                  'picture_url','listing_url']\ncolumns_nouse = ['id', 'host_id','scrape_id','host_listings_count','last_scraped']\ndf = df.drop(columns = (columns_withtext + columns_withurl+ columns_nouse))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"'host_since' feature can be proportional to trust level of the host.\n\nConverting from string to date format. \nConverting to Ordinal format for to support for regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#converting string data to date time \ndf['host_since'] = df['host_since'].apply(lambda x: pd.to_datetime(x))\n#converting to ordinal form\nimport datetime as dt\ndf['host_since'] = df['host_since'].map(dt.datetime.toordinal)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Host behaviour can be an indicator of price. \n\nHence, converting response time into categorical.\nConverting response rate and acceptence rate into percentages.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#handling host_response_time, converting to numeric \ndef response_time_cat(x):\n    if x == 'within an hour' or x == 'within a few hours':\n        return 1\n    elif x == 'within a day':\n        return 0.5\n    return 0\n\ndf['host_response_time'] = df['host_response_time'].apply(response_time_cat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# replacing nan values with 0.0% and converting to float\ndf['host_response_rate'] = df['host_response_rate'].fillna('0%').map(lambda x: float(x.replace('%',''))/100)\ndf['host_acceptance_rate'] = df['host_acceptance_rate'].fillna('0%').map(lambda x: float(x.replace('%',''))/100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally, we need to handle remaining missing values.\n\nWe will use medians of respective columns to fill in the nans.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#columns with NaN values\nfor col in df.columns[df.isnull().mean() > 0]:\n    print(col + ' = {:.2f} %'.format(df[col].isnull().mean()*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#filling all the columns with median of respective column\nfor col in df.columns[df.isnull().any()]:\n    df[col] = df[col].fillna(df[col].median())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A final look at the data. We store our results into CSV for further use","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_csv('boston_listings_updated.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}