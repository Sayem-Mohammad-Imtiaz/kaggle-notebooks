{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n%matplotlib inline\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pylab as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this problem statement we r only going to solve Electric_Production.csv"},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.read_csv(\"/kaggle/input/time-series-datasets/Electric_Production.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we r gonna solve time series problem"},{"metadata":{},"cell_type":"markdown","source":"step1:we clearly see dtype of column DATE is object,we have to convert it into DATETIME"},{"metadata":{},"cell_type":"markdown","source":"step2:we have to remove the index,and made DATE as index"},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"DATE\"]=pd.to_datetime(train[\"DATE\"],infer_datetime_format=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train.set_index(['DATE'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Lets visulize our data(before that we should understand following terms)"},{"metadata":{},"cell_type":"markdown","source":"# Trend"},{"metadata":{},"cell_type":"markdown","source":"1-The increasing or decreasing value in the series"},{"metadata":{},"cell_type":"markdown","source":"2-we can take example of facebook"},{"metadata":{},"cell_type":"markdown","source":"3-Number of facebook users is increasing with time,so its a trend"},{"metadata":{},"cell_type":"markdown","source":"4-Number of people who uses Yahoo as their search engine are deacreasing,its also a trend but a decreasing trend"},{"metadata":{},"cell_type":"markdown","source":"5-Mathematical Curve-it can be linear or damped or exponential"},{"metadata":{},"cell_type":"markdown","source":"# Seasonality"},{"metadata":{},"cell_type":"markdown","source":"2-Lets understand by taking an example of icecream"},{"metadata":{},"cell_type":"markdown","source":"3-We all eats ice-cream mostly in summers"},{"metadata":{},"cell_type":"markdown","source":"4-Therefore the sales of icecreams is increases mostly in summers and then drop down in winter(that what we called seasonality)"},{"metadata":{},"cell_type":"markdown","source":"5-Mathematics curve-its mostly of a sin curve or a distorted sin curve"},{"metadata":{},"cell_type":"markdown","source":"# Trend with seasonality\n"},{"metadata":{},"cell_type":"markdown","source":"1-we can take example of ice cream sales"},{"metadata":{},"cell_type":"markdown","source":"2-World population is increasing every year(so its  trend)"},{"metadata":{},"cell_type":"markdown","source":"3-In summers ice creams sells more than winter(its a seasonality)"},{"metadata":{},"cell_type":"markdown","source":"4-so we can say that as time increasing ice cream sales also increasing because buyers are increasing and in summers it increases more due to seasonality effect"},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib.pylab import rcParams\nrcParams['figure.figsize']=10,6\ntrain.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We clearly see that their is an increasing trend and seasonality"},{"metadata":{},"cell_type":"markdown","source":"Now we will decompose the above visulization into trend and seasonality for more clear visulization"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nres= seasonal_decompose(train, model='multiplicative')\nres.plot()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Residual means Noise"},{"metadata":{},"cell_type":"markdown","source":"We clearly see their is a increasing trend"},{"metadata":{},"cell_type":"markdown","source":"Lets see the first 60 value of our data to understand seasonality more visually"},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"IPG2211A2N\"].iloc[:60]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"U can  also see that after every year at January the electric production increases"},{"metadata":{},"cell_type":"markdown","source":"so we can say that its a yearly seasonality"},{"metadata":{},"cell_type":"markdown","source":"# STEP3-REMOVE TREND TO MADE DATA STATIONARY"},{"metadata":{},"cell_type":"markdown","source":"# STATIONARITY"},{"metadata":{},"cell_type":"markdown","source":"1-Data didnt have any trend and seasonality"},{"metadata":{},"cell_type":"markdown","source":"2-In practical sense electric production is not increasing with time it is constant its does not have any seasonality effect"},{"metadata":{},"cell_type":"markdown","source":"3-Why requires?Just like data needs to be normalized,features needs to be scaled before sending to ML algorithms,similarly time series algorithms wants data to be stationary"},{"metadata":{},"cell_type":"markdown","source":"4-Mathematically-Means should be constant,standard deviation should be constant,auto-correlation should be same"},{"metadata":{},"cell_type":"markdown","source":"5-we r going to check it using adfuller test(p-value will be used as a distinguisher (if p-value>0.05=Non-Stationary,if p-value<0.05=Stationary)"},{"metadata":{},"cell_type":"markdown","source":"Lets do adfuller on our dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.stattools import adfuller","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def stest(x):\n    result = adfuller(x)\n    print(result[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stest(train.iloc[:,0].values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"0.18621>0.05 data is non stationary"},{"metadata":{},"cell_type":"markdown","source":"Lets make it stationary"},{"metadata":{},"cell_type":"markdown","source":"we will use differencing method for removing trend and seasonality"},{"metadata":{},"cell_type":"markdown","source":"For eg.:\nif our data is like:[1,2,3,4,5,6,7,8,9]"},{"metadata":{},"cell_type":"markdown","source":"If we subtract each two adjacent digit then our data will be:[2-1,4-3,5-4,6-5,7-6,8-7,9-8]:[1,1,1,1,1,1,1,1...]"},{"metadata":{},"cell_type":"markdown","source":"Point to remember:Removing trend didnot mean that we should make the value constant for whole interval,it only means that the MEAN should be same for sub-interval in a interval"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a=[]\na.append(train[\"IPG2211A2N\"].iloc[0])\nfor i in range(396):\n     z=train[\"IPG2211A2N\"].iloc[i+1]-train[\"IPG2211A2N\"].iloc[i]\n     a.append(z)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(a)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now lets go for adfuller test"},{"metadata":{"trusted":true},"cell_type":"code","source":"stest(a)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"0.0003875068"},{"metadata":{},"cell_type":"markdown","source":"clearly 0.05>0.0003875068"},{"metadata":{},"cell_type":"markdown","source":"Our Data is Stationary"},{"metadata":{"trusted":true},"cell_type":"code","source":"t=train[\"IPG2211A2N\"].to_dict()\nx={}\nl=0\nfor i,j in t.items():\n       x.update({i:a[l]})\n       l=l+1\n   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xe=pd.Series(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(xe)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ARIMA"},{"metadata":{},"cell_type":"markdown","source":"ARIMA-{AutoRegression}{Integrated}{Moving Average}"},{"metadata":{},"cell_type":"markdown","source":"Auto Regression=It simply means values at present time is dependent on which-which previous time instant"},{"metadata":{},"cell_type":"markdown","source":"m(t)=Am(t-1)+Bm(t-3)+Cm(t-4)+...."},{"metadata":{},"cell_type":"markdown","source":"In above eg. m(t) is present time and it clearly depends on lag of 1,lag of 3,lag of 4 time instant"},{"metadata":{},"cell_type":"markdown","source":"PACF=Partial auto correlation value is used to calculate AR value(when line is above blue region we will count those value and total will be our AR value for our ARIMA model)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\nplot=plot_pacf(xe,lags=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> AR=3(most significant values)"},{"metadata":{},"cell_type":"markdown","source":"Moving Average=It is calculated using Autocorrelation (when the line goes above blue region we will count them all the total will be our MA)"},{"metadata":{"trusted":true},"cell_type":"code","source":"acf_plot=plot_acf(xe,lags=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we are counting most significant line MA=3)"},{"metadata":{},"cell_type":"markdown","source":"Train/Test Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(xe)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain=xe[0:330]\nxtest=xe[330:397]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(xtrain)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.arima_model import ARIMA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xee=ARIMA(xtrain,order=(3,0,3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ttt=xee.fit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ttt.aic","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tt=ttt.forecast(steps=67)[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tt[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtest.values[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtest.size","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets compare our forecasted value but before that we have to convert those forecast value to their original format(to remove trend we have subtracted one value from other now we have to reverse that process to get original value back)"},{"metadata":{"trusted":true},"cell_type":"code","source":"xtest[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"qqq=[]\na=0\nfor i in range(330):\n    a=a+xtrain[i]\n    qqq.append(a)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"IPG2211A2N\"].iloc[335]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"qqq[329]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Great qqq[329]=101.14 we will use this value to find our forecast value and xtest value"},{"metadata":{"trusted":true},"cell_type":"code","source":"def pv(web):\n        qqq=[]\n        a=101.4\n        for i in range(67):\n            a=a+web[i]\n            qqq.append(a)\n        return qqq","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nqqqt=pv(xtest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"qqqt[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"qqqf=pv(tt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"qqqf[:5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"qqqt is our test data and qqqf is our forecast data now we are going to check accuracy using root mean squared error"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error \nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"error=mean_squared_error(qqqt,qqqf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.sqrt(error)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Great our model is performing good with just a 5% error"},{"metadata":{},"cell_type":"markdown","source":"# If u like this notebook plz UpVote it"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}