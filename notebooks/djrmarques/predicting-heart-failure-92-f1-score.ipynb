{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Heart Rate death prediction\nBinary Classification for predicting the Heart Rate failure. ","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport plotly.express as px\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Loading and Exploration","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/heart-failure-clinical-data/heart_failure_clinical_records_dataset.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Assert that there are no missing values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"assert not df.isna().any().any(), \"Missing values found\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Check if the label is balanced\nLuckily the label is not very unbalanced","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"DEATH_EVENT\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualize the scatter matrix\nThe axis labels are a bit messy, but it is possible to get more information by hovering. I am trying to see if there is some important information here, but at first glance there is not much.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter_matrix(df, color=\"DEATH_EVENT\")\nfig.update_traces(diagonal_visible=False)\nfig.update(layout_showlegend=False, layout_coloraxis_showscale=False)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualize continuous columns\nNot we will try to visualize the continuous variables, and see if we can create more features to make the decision boundary more clear. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_to_plot = [\"DEATH_EVENT\", \"serum_sodium\", \"serum_creatinine\", \"platelets\", \"creatinine_phosphokinase\", \"age\", \"ejection_fraction\", \"time\"]\ndf_to_plot = df[cols_to_plot].melt(id_vars=[\"DEATH_EVENT\"])\nfig = px.box(df_to_plot, color=\"DEATH_EVENT\", y=\"value\", facet_col=\"variable\")    \nfig.update_yaxes(matches=None)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating Features\nBased on the graph above, we can create thresholds for the features. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"age_th\"] = df[\"age\"].apply(lambda x: 0 if x < 65 else 1)\ndf[\"serum_sodium_th\"] = df[\"serum_sodium\"].apply(lambda x: 0 if x < 135 else 1)\ndf[\"serum_creatin_th\"] = df[\"serum_creatinine\"].apply(lambda x: 0 if x < 1.2 else 1)\ndf[\"time_th\"] = df[\"time\"].apply(lambda x: 0 if x < 95 else 1)\ndf[\"ejection_fraction_th\"] = df[\"ejection_fraction\"].apply(lambda x: 0 if x < 38 else 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Testing model testing\nNow we will create a pipeline for testing different models, perform grid search and select the best model\n\n## Metric used\nWe will use the f1_score metric for this task, since we want to access how well our model can identify the positive samples (deaths by hear failure)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline, make_pipeline\nfrom sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit\nfrom sklearn.preprocessing import StandardScaler, PolynomialFeatures\nfrom sklearn.metrics import f1_score\nfrom sklearn.decomposition import PCA\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_selection import SelectFromModel\nimport xgboost","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logistic Regression Baseline\nBuilding a linear baseline with Logistic Regression.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nlogistic_param_grid = {\"logisticregression__solver\": [\"liblinear\"], \"logisticregression__C\": np.arange(0.2, 1.6, 0.1)}\nlogreg_pipeline = make_pipeline(StandardScaler(), LogisticRegression())\nclf = GridSearchCV(logreg_pipeline, n_jobs=-1, cv=StratifiedShuffleSplit(5, random_state=10), param_grid=logistic_param_grid)\nclf.fit(df.drop(\"DEATH_EVENT\", axis=1), df[\"DEATH_EVENT\"])\nprint(\"F1 Score: \", clf.best_score_)\nprint(\"Best Params\", clf.best_params_)\nbest_clf = clf.best_estimator_  # This is the best estimator","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We got 85% F1 score. Let's see if the features we created were any good","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"weights = pd.Series(dict(zip(df.drop(\"DEATH_EVENT\", axis=1).columns, best_clf[1].coef_[0])))\nweights.sort_values().plot.bar(figsize=(20, 5))\nplt.xlabel(\"Feature\")\nplt.ylabel(\"Weight\")\nplt.title(\"Feature Importance\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" Some of the features we created, such as serum_creatin_th ended up being pretty good, other like age_th, not so much.\n \n Let's se if we can improve our outcome by creating polynomial features for our logistic regression","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Improving with XGBOOST\nNow we will try to improve our baseline with XGBOOST, this is a much more sofisticated and complex model than Logistic Regression.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\n# I used a bigger grid initially, but I reduced it now for the sake of speeding the process. Check previous commits\nxgboost_param_grid = {\n    'booster': ['gbtree'], \n    'colsample_bytree': [0.9], \n    'eta': [0.5], \n    'eval_metric': ['auc'], \n    'gamma': [0.0], \n    'lambda': [0.8], \n    'min_child_weight': [9], \n    'n_estimators': [600], \n    'subsample': [0.9]}\n\nclf = GridSearchCV(xgboost.XGBClassifier(), n_jobs=-1, cv=StratifiedShuffleSplit(5, random_state=10), param_grid=xgboost_param_grid)\nclf.fit(df.drop(\"DEATH_EVENT\", axis=1), df[\"DEATH_EVENT\"])\nprint(\"F1 Score: \", clf.best_score_)\nprint(\"Best Params\", clf.best_params_)\nbest_clf = clf.best_estimator_  # This is the best estimator","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We got 92% F1 score. Now let's take a look at feature importance","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"xgboost.plot_importance(best_clf)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"In this notebook we have built a notebook for predicting the death events by heart failure. We started out with a Logistic Regression Model and then improved upon it using XGBOOST. The results obtained were the following:\n\n- Logistic Regression: 84% F1 Score\n- XGBOOST: 92% F1 Score","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}