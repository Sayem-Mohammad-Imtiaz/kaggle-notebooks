{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Table of Contents\n- Overview\n- Import Packages\n- Import Datasets\n- Exploratory Data Analysis\n- Data Preprocessing\n- Model Development\n- Model Evaluation\n- Conclusion","metadata":{}},{"cell_type":"markdown","source":"## Overview\nIn this notebook I will use dataset House Sales in King County, USA to build a House Price Predictor. First I will import packages and import datasets, then I will do Exploratory Data Analysis and Data Preprocessing base on it, later I will build a deep and wide Model using TensorFlow Feature Columns and DenseFeatures, then I will train this Model, finally I will evaluate this Model.","metadata":{"execution":{"iopub.status.busy":"2021-07-27T16:03:43.867258Z","iopub.execute_input":"2021-07-27T16:03:43.867626Z","iopub.status.idle":"2021-07-27T16:03:43.873324Z","shell.execute_reply.started":"2021-07-27T16:03:43.867593Z","shell.execute_reply":"2021-07-27T16:03:43.872212Z"}}},{"cell_type":"markdown","source":"## Import Packages","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf \nfrom tensorflow import feature_column","metadata":{"execution":{"iopub.status.busy":"2021-07-28T13:55:15.549701Z","iopub.execute_input":"2021-07-28T13:55:15.550104Z","iopub.status.idle":"2021-07-28T13:55:15.554422Z","shell.execute_reply.started":"2021-07-28T13:55:15.550069Z","shell.execute_reply":"2021-07-28T13:55:15.553384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import Datasets","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/housesalesprediction/kc_house_data.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-07-28T13:55:17.970305Z","iopub.execute_input":"2021-07-28T13:55:17.970679Z","iopub.status.idle":"2021-07-28T13:55:18.039119Z","shell.execute_reply.started":"2021-07-28T13:55:17.970646Z","shell.execute_reply":"2021-07-28T13:55:18.038126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploratory Data Analysis","metadata":{}},{"cell_type":"markdown","source":"Now show first 5 rows and statistics infomation:","metadata":{}},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-28T13:55:20.085317Z","iopub.execute_input":"2021-07-28T13:55:20.085708Z","iopub.status.idle":"2021-07-28T13:55:20.119525Z","shell.execute_reply.started":"2021-07-28T13:55:20.085676Z","shell.execute_reply":"2021-07-28T13:55:20.118254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Show statistics info:","metadata":{}},{"cell_type":"code","source":"data.describe().transpose()","metadata":{"execution":{"iopub.status.busy":"2021-07-28T13:55:22.518671Z","iopub.execute_input":"2021-07-28T13:55:22.519129Z","iopub.status.idle":"2021-07-28T13:55:22.614519Z","shell.execute_reply.started":"2021-07-28T13:55:22.518996Z","shell.execute_reply":"2021-07-28T13:55:22.612862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Compute Correlation score**\n\nLet's Compute pairwise correlation of columns and see what's the most correlated features of price feature.","metadata":{"execution":{"iopub.status.busy":"2021-07-28T13:51:28.182645Z","iopub.execute_input":"2021-07-28T13:51:28.182986Z","iopub.status.idle":"2021-07-28T13:51:28.188004Z","shell.execute_reply.started":"2021-07-28T13:51:28.182956Z","shell.execute_reply":"2021-07-28T13:51:28.186935Z"}}},{"cell_type":"code","source":"data.corr()","metadata":{"execution":{"iopub.status.busy":"2021-07-28T13:55:32.280467Z","iopub.execute_input":"2021-07-28T13:55:32.280836Z","iopub.status.idle":"2021-07-28T13:55:32.347289Z","shell.execute_reply.started":"2021-07-28T13:55:32.280804Z","shell.execute_reply":"2021-07-28T13:55:32.346202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.corr()[\"price\"].sort_values(ascending=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T13:55:36.258584Z","iopub.execute_input":"2021-07-28T13:55:36.258975Z","iopub.status.idle":"2021-07-28T13:55:36.294666Z","shell.execute_reply.started":"2021-07-28T13:55:36.258937Z","shell.execute_reply":"2021-07-28T13:55:36.293704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's see type of different features. As we can see date column is object type, so Id and zipcode doesn't have relation to price of house, so we will remove these fields. \nMost of the feature are numeriacal features. However, we need to be noticed of following:\n- Date can indicate year, month, day information. We should cacluate how old the house is combined with yr_built and how many years since renovated combined with yr_renovated.\n- Id and zipcode is not corelated with price so we won't use them to predict house prices. \n- View, waterfront, condition, grade seems like a quantity but it's better to be treated as a category.\n- lat and long column is quantity, at the same time combining them can get a location information.\n","metadata":{"execution":{"iopub.status.busy":"2021-07-27T15:57:49.769968Z","iopub.execute_input":"2021-07-27T15:57:49.770347Z","iopub.status.idle":"2021-07-27T15:57:49.77493Z","shell.execute_reply.started":"2021-07-27T15:57:49.770314Z","shell.execute_reply":"2021-07-27T15:57:49.773702Z"}}},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-28T13:56:05.361857Z","iopub.execute_input":"2021-07-28T13:56:05.362269Z","iopub.status.idle":"2021-07-28T13:56:05.381768Z","shell.execute_reply.started":"2021-07-28T13:56:05.362232Z","shell.execute_reply":"2021-07-28T13:56:05.380913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing\nWe need to preprocess datasets in following ways:\n- Extract year information from date column\n- Caculate how long has it been since houses were built and renovated \n- Remove unnecessary columns\n- Create TensorFlow Feature Columns for Modeling\n- Train test split","metadata":{"execution":{"iopub.status.busy":"2021-07-27T16:25:46.826732Z","iopub.execute_input":"2021-07-27T16:25:46.827117Z","iopub.status.idle":"2021-07-27T16:25:46.831277Z","shell.execute_reply.started":"2021-07-27T16:25:46.827087Z","shell.execute_reply":"2021-07-27T16:25:46.829641Z"}}},{"cell_type":"markdown","source":"**Extract year information from date column**","metadata":{"execution":{"iopub.status.busy":"2021-07-28T05:42:31.737122Z","iopub.execute_input":"2021-07-28T05:42:31.737726Z","iopub.status.idle":"2021-07-28T05:42:31.745045Z","shell.execute_reply.started":"2021-07-28T05:42:31.737674Z","shell.execute_reply":"2021-07-28T05:42:31.743876Z"}}},{"cell_type":"code","source":"data[\"year\"] = data[\"date\"].apply(lambda date: int(date[0:4]))","metadata":{"execution":{"iopub.status.busy":"2021-07-28T13:56:08.803422Z","iopub.execute_input":"2021-07-28T13:56:08.803994Z","iopub.status.idle":"2021-07-28T13:56:08.830954Z","shell.execute_reply.started":"2021-07-28T13:56:08.803958Z","shell.execute_reply":"2021-07-28T13:56:08.830146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Caculate how long has it been since houses were built and renovated**","metadata":{}},{"cell_type":"code","source":"data[\"years_since_built\"] = data[\"year\"] - data[\"yr_built\"]\ndata[\"years_since_renovated\"] = data[\"year\"] - data[\"yr_renovated\"]","metadata":{"execution":{"iopub.status.busy":"2021-07-28T13:56:40.786132Z","iopub.execute_input":"2021-07-28T13:56:40.786695Z","iopub.status.idle":"2021-07-28T13:56:40.793643Z","shell.execute_reply.started":"2021-07-28T13:56:40.786659Z","shell.execute_reply":"2021-07-28T13:56:40.792841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Remove unnecessary columns**","metadata":{"execution":{"iopub.status.busy":"2021-07-27T16:44:25.985243Z","iopub.execute_input":"2021-07-27T16:44:25.985566Z","iopub.status.idle":"2021-07-27T16:44:26.01385Z","shell.execute_reply.started":"2021-07-27T16:44:25.985541Z","shell.execute_reply":"2021-07-27T16:44:26.012796Z"}}},{"cell_type":"code","source":"unnecessary_column_names = [\"id\", \"date\", \"zipcode\", \"yr_built\", \"yr_renovated\", \"year\"]\nfor column_name in unnecessary_column_names:\n    data.pop(column_name)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T13:57:00.369498Z","iopub.execute_input":"2021-07-28T13:57:00.369992Z","iopub.status.idle":"2021-07-28T13:57:00.379308Z","shell.execute_reply.started":"2021-07-28T13:57:00.369957Z","shell.execute_reply":"2021-07-28T13:57:00.378412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe().transpose()","metadata":{"execution":{"iopub.status.busy":"2021-07-28T13:57:03.566521Z","iopub.execute_input":"2021-07-28T13:57:03.567073Z","iopub.status.idle":"2021-07-28T13:57:03.645602Z","shell.execute_reply.started":"2021-07-28T13:57:03.567036Z","shell.execute_reply":"2021-07-28T13:57:03.644585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's calcuate correlation scores with price again:","metadata":{}},{"cell_type":"code","source":"data.corr()[\"price\"].sort_values(ascending=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T14:00:11.670296Z","iopub.execute_input":"2021-07-28T14:00:11.670667Z","iopub.status.idle":"2021-07-28T14:00:11.700615Z","shell.execute_reply.started":"2021-07-28T14:00:11.670636Z","shell.execute_reply":"2021-07-28T14:00:11.699658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Create TensorFlow Feature Columns","metadata":{"execution":{"iopub.status.busy":"2021-07-27T16:48:29.240865Z","iopub.execute_input":"2021-07-27T16:48:29.241168Z","iopub.status.idle":"2021-07-27T16:48:29.244814Z","shell.execute_reply.started":"2021-07-27T16:48:29.241142Z","shell.execute_reply":"2021-07-27T16:48:29.243968Z"}}},{"cell_type":"markdown","source":"Create numerical columns:","metadata":{}},{"cell_type":"code","source":"numerical_colunmn_names = [\n    'bedrooms',\n    'bathrooms',\n    'sqft_living',\n    'sqft_lot',\n    'floors',\n    'sqft_above',\n    \"sqft_basement\",\n    \"sqft_living15\",\n    \"sqft_lot15\",\n    \"years_since_built\",\n    \"years_since_renovated\",\n    \"long\",\n    \"lat\"\n]\nnumerical_colunmns = [feature_column.numeric_column(name, dtype=float) for name in numerical_colunmn_names]","metadata":{"execution":{"iopub.status.busy":"2021-07-28T14:10:39.750803Z","iopub.execute_input":"2021-07-28T14:10:39.751198Z","iopub.status.idle":"2021-07-28T14:10:39.756964Z","shell.execute_reply.started":"2021-07-28T14:10:39.751162Z","shell.execute_reply":"2021-07-28T14:10:39.755911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for column in numerical_colunmn_names:\n    data[column] = data[column].astype(float)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T14:10:42.333808Z","iopub.execute_input":"2021-07-28T14:10:42.334327Z","iopub.status.idle":"2021-07-28T14:10:42.343127Z","shell.execute_reply.started":"2021-07-28T14:10:42.334292Z","shell.execute_reply":"2021-07-28T14:10:42.342267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create categorical columns:","metadata":{}},{"cell_type":"code","source":"categorical_column_names = [\"waterfront\", \"condition\", \"grade\", \"view\"]\ncategorical_column_lists = [sorted(data[item].unique()) for item in categorical_column_names]\ncategorical_columns = [feature_column.indicator_column(feature_column.categorical_column_with_vocabulary_list(name, category)) for (name,category) in zip(categorical_column_names, categorical_column_lists)]","metadata":{"execution":{"iopub.status.busy":"2021-07-28T14:10:45.351146Z","iopub.execute_input":"2021-07-28T14:10:45.351625Z","iopub.status.idle":"2021-07-28T14:10:45.358697Z","shell.execute_reply.started":"2021-07-28T14:10:45.351592Z","shell.execute_reply":"2021-07-28T14:10:45.357856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create a crossed column about location combined with latitude and longitude:","metadata":{}},{"cell_type":"code","source":"min_lat, max_lat = data[\"lat\"].min(), data[\"lat\"].max()\nmin_long, max_long = data[\"long\"].min(), data[\"long\"].max()\nprint(min_lat, max_lat, min_long, min_long)\nnum_buckets = 8\nlatbuckets = np.linspace(start=min_lat, stop=max_lat, num=num_buckets).tolist()\nlonbuckets = np.linspace(start=min_long, stop=max_long, num=num_buckets).tolist()\nprint(latbuckets, lonbuckets)\nlat_column = feature_column.bucketized_column(\n    source_column=feature_column.numeric_column(\"lat\"), boundaries=latbuckets)\nlong_column = feature_column.bucketized_column(\n    source_column=feature_column.numeric_column(\"long\"), boundaries=lonbuckets)\nlocation_column = feature_column.crossed_column(\n    [lat_column, long_column], \n    hash_bucket_size=num_buckets * num_buckets\n)\nlocation_embedding_column = feature_column.embedding_column(categorical_column=location_column, dimension=3)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T14:10:53.497555Z","iopub.execute_input":"2021-07-28T14:10:53.49816Z","iopub.status.idle":"2021-07-28T14:10:53.511477Z","shell.execute_reply.started":"2021-07-28T14:10:53.498106Z","shell.execute_reply":"2021-07-28T14:10:53.510278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wide_columns = [\n    feature_column.indicator_column(location_column)\n] + categorical_columns\n\ndeep_columns = [location_embedding_column] + numerical_colunmns","metadata":{"execution":{"iopub.status.busy":"2021-07-28T14:10:56.212196Z","iopub.execute_input":"2021-07-28T14:10:56.212558Z","iopub.status.idle":"2021-07-28T14:10:56.217511Z","shell.execute_reply.started":"2021-07-28T14:10:56.212516Z","shell.execute_reply":"2021-07-28T14:10:56.215931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs = dict()\nfor item in numerical_colunmns:\n    inputs[item.key] = tf.keras.layers.Input(name=item.key, shape=(), dtype=\"float32\")\nfor item in categorical_columns:\n    inputs[item.categorical_column.key] = tf.keras.layers.Input(name=item.categorical_column.key, shape=(), dtype=\"int32\")","metadata":{"execution":{"iopub.status.busy":"2021-07-28T14:10:58.601937Z","iopub.execute_input":"2021-07-28T14:10:58.602364Z","iopub.status.idle":"2021-07-28T14:10:58.621343Z","shell.execute_reply.started":"2021-07-28T14:10:58.602329Z","shell.execute_reply":"2021-07-28T14:10:58.620182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs","metadata":{"execution":{"iopub.status.busy":"2021-07-28T14:11:01.005521Z","iopub.execute_input":"2021-07-28T14:11:01.005864Z","iopub.status.idle":"2021-07-28T14:11:01.012672Z","shell.execute_reply.started":"2021-07-28T14:11:01.005835Z","shell.execute_reply":"2021-07-28T14:11:01.01151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Train test split**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ndata_train, data_test = train_test_split(data, test_size=0.2, random_state=997)\ndata_train.to_csv(\"data_train.csv\",index=False)\ndata_test.to_csv(\"data_test.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T14:11:04.351746Z","iopub.execute_input":"2021-07-28T14:11:04.352143Z","iopub.status.idle":"2021-07-28T14:11:04.70819Z","shell.execute_reply.started":"2021-07-28T14:11:04.352107Z","shell.execute_reply":"2021-07-28T14:11:04.707366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Create TensorFlow Dataset**","metadata":{}},{"cell_type":"code","source":"def features_and_labels(row_data):\n    label = row_data.pop(\"price\")\n    features = row_data\n    return features, label\n\ndef create_dataset(pattern, epochs=1, batch_size=32, mode='eval'):\n    dataset = tf.data.experimental.make_csv_dataset(\n        pattern, batch_size\n    )\n    dataset = dataset.map(features_and_labels)\n    if mode == 'train':\n        dataset = dataset.shuffle(buffer_size=1000).repeat(epochs)\n    dataset = dataset.prefetch(1)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2021-07-28T14:11:06.689742Z","iopub.execute_input":"2021-07-28T14:11:06.69026Z","iopub.status.idle":"2021-07-28T14:11:06.696406Z","shell.execute_reply.started":"2021-07-28T14:11:06.690226Z","shell.execute_reply":"2021-07-28T14:11:06.695364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 100\ntrain_data = create_dataset(\"data_train.csv\", batch_size=batch_size, mode='train')\ntest_data = create_dataset(\"data_test.csv\", batch_size=batch_size, mode='eval').take(data_test.shape[0] // batch_size)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T14:11:09.129435Z","iopub.execute_input":"2021-07-28T14:11:09.129826Z","iopub.status.idle":"2021-07-28T14:11:09.378436Z","shell.execute_reply.started":"2021-07-28T14:11:09.129791Z","shell.execute_reply":"2021-07-28T14:11:09.377429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Development\nCreate a wide and deep Model using 2 DenseFeatures layers. One is deep layer to fit numerical data, another is wide layer to fit sparse and categorical data.","metadata":{"execution":{"iopub.status.busy":"2021-07-27T17:26:52.32617Z","iopub.execute_input":"2021-07-27T17:26:52.326524Z","iopub.status.idle":"2021-07-27T17:26:52.330818Z","shell.execute_reply.started":"2021-07-27T17:26:52.326498Z","shell.execute_reply":"2021-07-27T17:26:52.329461Z"}}},{"cell_type":"code","source":"def build_model():\n    deep = tf.keras.layers.DenseFeatures(deep_columns, name='deep_inputs')(inputs)\n    deep = tf.keras.layers.Dense(32, activation='relu')(deep)\n    deep = tf.keras.layers.Dense(32, activation='relu')(deep)\n    deep = tf.keras.layers.Dense(32, activation='relu')(deep)\n    wide = tf.keras.layers.DenseFeatures(wide_columns, name='wide_inputs')(inputs)\n    wide = tf.keras.layers.Dense(64, activation='relu')(wide)\n    combined = tf.keras.layers.concatenate(inputs=[deep, wide], name='combined')\n    output = tf.keras.layers.Dense(1)(combined)\n    model = tf.keras.Model(inputs=list(inputs.values()), outputs=output)\n    model.compile(optimizer=\"adam\", loss=\"mape\", metrics=[\"mse\", \"mae\", \"mape\"])\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-07-28T14:11:12.370447Z","iopub.execute_input":"2021-07-28T14:11:12.370826Z","iopub.status.idle":"2021-07-28T14:11:12.379776Z","shell.execute_reply.started":"2021-07-28T14:11:12.370791Z","shell.execute_reply":"2021-07-28T14:11:12.378995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = build_model()","metadata":{"execution":{"iopub.status.busy":"2021-07-28T14:11:14.916775Z","iopub.execute_input":"2021-07-28T14:11:14.917159Z","iopub.status.idle":"2021-07-28T14:11:15.238882Z","shell.execute_reply.started":"2021-07-28T14:11:14.917127Z","shell.execute_reply":"2021-07-28T14:11:15.23795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Plot the Model**","metadata":{}},{"cell_type":"code","source":"tf.keras.utils.plot_model(model, show_shapes=False, rankdir='LR')","metadata":{"execution":{"iopub.status.busy":"2021-07-28T14:11:16.759356Z","iopub.execute_input":"2021-07-28T14:11:16.759733Z","iopub.status.idle":"2021-07-28T14:11:17.076094Z","shell.execute_reply.started":"2021-07-28T14:11:16.759698Z","shell.execute_reply":"2021-07-28T14:11:17.075163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's train the Model for 400 epochs. Add an EarlyStopping layer so that it will stop after the Model stop imporving.","metadata":{}},{"cell_type":"code","source":"epochs = 400\nearly_stop = tf.keras.callbacks.EarlyStopping(patience=10)\nsteps_per_epoch = data_train.shape[0] // batch_size\nhistory = model.fit(\n    train_data, \n    steps_per_epoch=steps_per_epoch,\n    validation_data=test_data,\n    epochs=epochs,\n    callbacks=[early_stop],\n    verbose=2\n)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T14:11:21.907252Z","iopub.execute_input":"2021-07-28T14:11:21.90779Z","iopub.status.idle":"2021-07-28T14:13:28.966136Z","shell.execute_reply.started":"2021-07-28T14:11:21.907754Z","shell.execute_reply":"2021-07-28T14:13:28.965068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Evaluation","metadata":{}},{"cell_type":"markdown","source":"**Loss (Mean Squared Error) over time**","metadata":{}},{"cell_type":"code","source":"pd.DataFrame(history.history, columns=[\"loss\", \"val_loss\"]).plot()","metadata":{"execution":{"iopub.status.busy":"2021-07-28T14:13:39.745695Z","iopub.execute_input":"2021-07-28T14:13:39.746134Z","iopub.status.idle":"2021-07-28T14:13:39.99624Z","shell.execute_reply.started":"2021-07-28T14:13:39.746096Z","shell.execute_reply":"2021-07-28T14:13:39.995133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Mean Average Error over time**\n\nIt means that Mean Average Error of house prices this Model predict is about 100000 dollars.","metadata":{}},{"cell_type":"code","source":"pd.DataFrame(history.history, columns=[\"mae\", \"val_mae\"]).plot()","metadata":{"execution":{"iopub.status.busy":"2021-07-28T14:13:44.04064Z","iopub.execute_input":"2021-07-28T14:13:44.041006Z","iopub.status.idle":"2021-07-28T14:13:44.257145Z","shell.execute_reply.started":"2021-07-28T14:13:44.040973Z","shell.execute_reply":"2021-07-28T14:13:44.256337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Mean Average Percentage Error over time**","metadata":{"execution":{"iopub.status.busy":"2021-07-28T06:44:12.665179Z","iopub.execute_input":"2021-07-28T06:44:12.665591Z","iopub.status.idle":"2021-07-28T06:44:12.670976Z","shell.execute_reply.started":"2021-07-28T06:44:12.665556Z","shell.execute_reply":"2021-07-28T06:44:12.669797Z"}}},{"cell_type":"code","source":"pd.DataFrame(history.history, columns=[\"mape\", \"val_mape\"]).plot()","metadata":{"execution":{"iopub.status.busy":"2021-07-28T14:13:47.308808Z","iopub.execute_input":"2021-07-28T14:13:47.309375Z","iopub.status.idle":"2021-07-28T14:13:47.959709Z","shell.execute_reply.started":"2021-07-28T14:13:47.309326Z","shell.execute_reply":"2021-07-28T14:13:47.958728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Conclusion \n- The MAPE score of this Model is about 17%, it means that mean error this Model predicts are 17% of the acutal house prices.\n- The MAE score of this Model is about 106086.4609, which means that mean error this model predicts are 106086 dollars, which is still a sinificatn amount.\n- MAP / MAPE / MSE curves of this Model are very similar, so this Model does not overfit.\n- The most important features that can impact a house's prices are: Square footage of the home, overall grade given to the housing unit, Square footage of house apart from basement, Living room area in 2015, Number of bathrooms, whether it has been viewed, Square footage of the basement, Number of bedrooms, Latitude coordinate, whether house has a view to a waterfront.","metadata":{}}]}