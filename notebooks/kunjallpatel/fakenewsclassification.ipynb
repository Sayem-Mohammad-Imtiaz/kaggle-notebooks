{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-10T17:12:11.034675Z","iopub.execute_input":"2021-09-10T17:12:11.034953Z","iopub.status.idle":"2021-09-10T17:12:11.054688Z","shell.execute_reply.started":"2021-09-10T17:12:11.034926Z","shell.execute_reply":"2021-09-10T17:12:11.053544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's get both the data\nfake = pd.read_csv('/kaggle/input/fake-and-real-news-dataset/Fake.csv')\ntrue = pd.read_csv('/kaggle/input/fake-and-real-news-dataset/True.csv')","metadata":{"execution":{"iopub.status.busy":"2021-09-10T17:12:16.406348Z","iopub.execute_input":"2021-09-10T17:12:16.406635Z","iopub.status.idle":"2021-09-10T17:12:19.408294Z","shell.execute_reply.started":"2021-09-10T17:12:16.406608Z","shell.execute_reply":"2021-09-10T17:12:19.407263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fake news\nfake.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-10T17:12:36.263716Z","iopub.execute_input":"2021-09-10T17:12:36.264008Z","iopub.status.idle":"2021-09-10T17:12:36.286838Z","shell.execute_reply.started":"2021-09-10T17:12:36.263978Z","shell.execute_reply":"2021-09-10T17:12:36.285832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Real/True news\ntrue.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-10T17:12:47.935043Z","iopub.execute_input":"2021-09-10T17:12:47.935848Z","iopub.status.idle":"2021-09-10T17:12:47.948905Z","shell.execute_reply.started":"2021-09-10T17:12:47.935784Z","shell.execute_reply":"2021-09-10T17:12:47.947668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's insert a new column 'Real_or_Fake'.It will help when we combine both the tables in determining \n# Fake or Real news\nfake['Real_or_Fake'] = 'Fake'\ntrue['Real_or_Fake'] = 'Real'","metadata":{"execution":{"iopub.status.busy":"2021-09-10T17:13:00.683838Z","iopub.execute_input":"2021-09-10T17:13:00.684195Z","iopub.status.idle":"2021-09-10T17:13:00.695684Z","shell.execute_reply.started":"2021-09-10T17:13:00.68416Z","shell.execute_reply":"2021-09-10T17:13:00.694255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"news = pd.concat([true,fake],axis=0,ignore_index=True)\n\n# First 5 rows of the news table\nnews.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-10T17:13:12.724506Z","iopub.execute_input":"2021-09-10T17:13:12.724864Z","iopub.status.idle":"2021-09-10T17:13:12.745027Z","shell.execute_reply.started":"2021-09-10T17:13:12.724829Z","shell.execute_reply":"2021-09-10T17:13:12.74413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Count of real and fake news\nprint(news['Real_or_Fake'].value_counts())\n\nsns.countplot(x='Real_or_Fake',data=news)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T17:13:28.441203Z","iopub.execute_input":"2021-09-10T17:13:28.442361Z","iopub.status.idle":"2021-09-10T17:13:28.722436Z","shell.execute_reply.started":"2021-09-10T17:13:28.442301Z","shell.execute_reply":"2021-09-10T17:13:28.721384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's check if there is any null value in text column.\nnews['text'].isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-09-10T17:13:41.544213Z","iopub.execute_input":"2021-09-10T17:13:41.544608Z","iopub.status.idle":"2021-09-10T17:13:41.562646Z","shell.execute_reply.started":"2021-09-10T17:13:41.544575Z","shell.execute_reply":"2021-09-10T17:13:41.561436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's read one news\nnews['text'].iloc[33390]","metadata":{"execution":{"iopub.status.busy":"2021-09-10T17:13:55.918964Z","iopub.execute_input":"2021-09-10T17:13:55.919288Z","iopub.status.idle":"2021-09-10T17:13:55.926305Z","shell.execute_reply.started":"2021-09-10T17:13:55.919256Z","shell.execute_reply":"2021-09-10T17:13:55.925157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to remove the url\ndef remove_url(text):\n    text = text.split(' ')\n    text1 = ''\n    for word in text:\n        if ('.com' in word) or ('https' in word) or ('bit.ly' in word):\n            continue\n        else:\n            text1 += (word+' ')\n    return text1\n\n# Lets apply this on news text\nnews['text'] = news['text'].apply(remove_url)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T17:14:28.108824Z","iopub.execute_input":"2021-09-10T17:14:28.109171Z","iopub.status.idle":"2021-09-10T17:14:36.786981Z","shell.execute_reply.started":"2021-09-10T17:14:28.109133Z","shell.execute_reply":"2021-09-10T17:14:36.786011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's check if any news text is just an empty string\n\n# empty will hold the index of the empty string text\nempty = []\n\n# for loop to find the empty string\nfor i,title,text,*_ in news.itertuples():\n    if text.isspace() or text=='':\n        empty.append(i)\n        \n# number of rows with empty string as form of news text\nprint(f\"There are total {len(empty)} rows with empty string as news text\")","metadata":{"execution":{"iopub.status.busy":"2021-09-10T17:14:45.562545Z","iopub.execute_input":"2021-09-10T17:14:45.563577Z","iopub.status.idle":"2021-09-10T17:14:45.665651Z","shell.execute_reply.started":"2021-09-10T17:14:45.563522Z","shell.execute_reply":"2021-09-10T17:14:45.66496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's remove these empty strings\nnews.drop(empty,inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T17:14:57.516313Z","iopub.execute_input":"2021-09-10T17:14:57.516621Z","iopub.status.idle":"2021-09-10T17:14:57.538049Z","shell.execute_reply.started":"2021-09-10T17:14:57.516591Z","shell.execute_reply":"2021-09-10T17:14:57.537025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install beautifulsoup4","metadata":{"execution":{"iopub.status.busy":"2021-09-10T17:15:08.892664Z","iopub.execute_input":"2021-09-10T17:15:08.89298Z","iopub.status.idle":"2021-09-10T17:15:38.190236Z","shell.execute_reply.started":"2021-09-10T17:15:08.892951Z","shell.execute_reply":"2021-09-10T17:15:38.188766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's remove any HTML tags present in news text\n# We can use BeautifulSoup to do it\nfrom bs4 import BeautifulSoup\n\n# function to remove the HTML tags\ndef remove_html(text):\n    soup = BeautifulSoup(text)\n    text = soup.get_text()\n    \n    return text\n\n# Let's apply the above function on news text\nnews['text'] = news['text'].apply(remove_html)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T17:15:52.045057Z","iopub.execute_input":"2021-09-10T17:15:52.0454Z","iopub.status.idle":"2021-09-10T17:16:04.743986Z","shell.execute_reply.started":"2021-09-10T17:15:52.045359Z","shell.execute_reply":"2021-09-10T17:16:04.743251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's read some more news\nnews['text'][0][:50]","metadata":{"execution":{"iopub.status.busy":"2021-09-10T17:16:16.92538Z","iopub.execute_input":"2021-09-10T17:16:16.926499Z","iopub.status.idle":"2021-09-10T17:16:16.936098Z","shell.execute_reply.started":"2021-09-10T17:16:16.926445Z","shell.execute_reply":"2021-09-10T17:16:16.934927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"news['text'][6][:50]","metadata":{"execution":{"iopub.status.busy":"2021-09-10T17:16:29.072752Z","iopub.execute_input":"2021-09-10T17:16:29.07324Z","iopub.status.idle":"2021-09-10T17:16:29.080709Z","shell.execute_reply.started":"2021-09-10T17:16:29.073202Z","shell.execute_reply":"2021-09-10T17:16:29.079696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# WASHINGTON (Reuters) or SEATTLE/WASHINGTON (Reuters) are there at the begining of many news text.\n# Our model might learn that if these words are at the begining of the news text,they must belong to one category and might \n# not try to learn from the text that follows.\n\n# Let's go ahead and remove these words from the news text\n# we will split the text on the basis of (Reuters) and ignore the first part\n\n# function to perform the split\ndef split_news(text):\n    if '(Reuters)' in text:\n        text = text.split('(Reuters)')\n\n        return ' '.join(text[1:])\n    return text\n\n# Applying the above function on the news text\nnews['text'] = news['text'].apply(split_news)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T17:16:40.196378Z","iopub.execute_input":"2021-09-10T17:16:40.196682Z","iopub.status.idle":"2021-09-10T17:16:40.423731Z","shell.execute_reply.started":"2021-09-10T17:16:40.196653Z","shell.execute_reply":"2021-09-10T17:16:40.422793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's remove the punctuations from the news text\nimport string\n\npunctuations = string.punctuation\n\n# Lets add '\\n','\\n\\n' and ' ' in punctuations\npunctuations += '\\n \\n\\n'\n\n#function to remove the punctuations\ndef remove_punct(text):\n    text = text.split(' ')\n    text  = [word.lower() for word in text if word not in punctuations]\n    \n    return ' '.join(text)\n\n# applying the above function in news text\nnews['text'] = news['text'].apply(remove_punct)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T17:16:55.196373Z","iopub.execute_input":"2021-09-10T17:16:55.196702Z","iopub.status.idle":"2021-09-10T17:17:00.759539Z","shell.execute_reply.started":"2021-09-10T17:16:55.196674Z","shell.execute_reply":"2021-09-10T17:17:00.758583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = news['text']\ny = news['Real_or_Fake']\n\n# Lets do the one hot encoding to convet y\nencoded_y = pd.get_dummies(y,drop_first=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T17:17:17.0334Z","iopub.execute_input":"2021-09-10T17:17:17.033743Z","iopub.status.idle":"2021-09-10T17:17:17.046289Z","shell.execute_reply.started":"2021-09-10T17:17:17.033711Z","shell.execute_reply":"2021-09-10T17:17:17.045474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Libraries to split the data into train and test data,create maodel and evaluating the matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import LinearSVC\nfrom sklearn.metrics import accuracy_score,classification_report","metadata":{"execution":{"iopub.status.busy":"2021-09-10T17:17:31.286071Z","iopub.execute_input":"2021-09-10T17:17:31.286721Z","iopub.status.idle":"2021-09-10T17:17:31.746432Z","shell.execute_reply.started":"2021-09-10T17:17:31.28667Z","shell.execute_reply":"2021-09-10T17:17:31.745669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets split the data into train and test data. We will use 25% of the data as test data\nX_train,X_test,y_train,y_test = train_test_split(X,encoded_y.values.reshape(-1,),test_size=0.25,random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-10T17:17:45.251911Z","iopub.execute_input":"2021-09-10T17:17:45.252274Z","iopub.status.idle":"2021-09-10T17:17:45.272832Z","shell.execute_reply.started":"2021-09-10T17:17:45.252238Z","shell.execute_reply":"2021-09-10T17:17:45.271792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Naive_bayes model**","metadata":{}},{"cell_type":"code","source":"# creating a naive model\npipeline_naive = Pipeline([\n    ('vector',TfidfVectorizer(stop_words='english')),\n    ('classifier',MultinomialNB())\n])\n\n# training the model\npipeline_naive.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T17:17:57.099009Z","iopub.execute_input":"2021-09-10T17:17:57.099372Z","iopub.status.idle":"2021-09-10T17:18:13.018309Z","shell.execute_reply.started":"2021-09-10T17:17:57.099336Z","shell.execute_reply":"2021-09-10T17:18:13.01737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prediction\npredict_naive = pipeline_naive.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T17:18:26.172838Z","iopub.execute_input":"2021-09-10T17:18:26.173196Z","iopub.status.idle":"2021-09-10T17:18:31.301801Z","shell.execute_reply.started":"2021-09-10T17:18:26.173161Z","shell.execute_reply":"2021-09-10T17:18:31.300576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluating the naive model\nacc_naive = accuracy_score(y_test,predict_naive)\nprint(f'Naive model has {acc_naive.round(2)*100}% accuracy')\nprint('\\n')\nprint(classification_report(y_test,predict_naive))","metadata":{"execution":{"iopub.status.busy":"2021-09-10T17:18:46.646269Z","iopub.execute_input":"2021-09-10T17:18:46.646595Z","iopub.status.idle":"2021-09-10T17:18:46.678186Z","shell.execute_reply.started":"2021-09-10T17:18:46.646565Z","shell.execute_reply":"2021-09-10T17:18:46.676939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Logistic Regression Model**","metadata":{}},{"cell_type":"code","source":"# creating a logistic model\npipeline_logistic = Pipeline([\n    ('vector',TfidfVectorizer(stop_words='english')),\n    ('classifier',LogisticRegression())\n])\n\n# training the model\npipeline_logistic.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T17:19:03.405845Z","iopub.execute_input":"2021-09-10T17:19:03.406243Z","iopub.status.idle":"2021-09-10T17:19:22.702045Z","shell.execute_reply.started":"2021-09-10T17:19:03.406205Z","shell.execute_reply":"2021-09-10T17:19:22.701188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prediction\npredict_logistic = pipeline_logistic.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T17:19:33.466474Z","iopub.execute_input":"2021-09-10T17:19:33.466761Z","iopub.status.idle":"2021-09-10T17:19:38.256691Z","shell.execute_reply.started":"2021-09-10T17:19:33.466731Z","shell.execute_reply":"2021-09-10T17:19:38.255741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluating the logistic model\nacc_logistic = accuracy_score(y_test,predict_logistic)\nprint(f'LogisticRegression model has {acc_logistic.round(2)*100}% accuracy')\nprint('\\n')\nprint(classification_report(y_test,predict_logistic))","metadata":{"execution":{"iopub.status.busy":"2021-09-10T17:19:53.911342Z","iopub.execute_input":"2021-09-10T17:19:53.911675Z","iopub.status.idle":"2021-09-10T17:19:53.944937Z","shell.execute_reply.started":"2021-09-10T17:19:53.911643Z","shell.execute_reply":"2021-09-10T17:19:53.944047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**LinearSVC model**","metadata":{}},{"cell_type":"code","source":"# creating a LinearSVC model\npipeline_svc = Pipeline([\n    ('vector',TfidfVectorizer(stop_words='english')),\n    ('classifier',LinearSVC())\n])\n\n# training the model\npipeline_svc.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T17:20:06.727147Z","iopub.execute_input":"2021-09-10T17:20:06.727825Z","iopub.status.idle":"2021-09-10T17:20:22.346587Z","shell.execute_reply.started":"2021-09-10T17:20:06.727786Z","shell.execute_reply":"2021-09-10T17:20:22.345789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prediction\npredict_svc = pipeline_svc.predict(X_test)\n# Evaluating the LinearSVC model\nacc_svc = accuracy_score(y_test,predict_svc)\nprint(f'LinearSVC model has {acc_svc.round(2)*100}% accuracy')\nprint('\\n')\nprint(classification_report(y_test,predict_svc))","metadata":{"execution":{"iopub.status.busy":"2021-09-10T17:20:42.831494Z","iopub.execute_input":"2021-09-10T17:20:42.831864Z","iopub.status.idle":"2021-09-10T17:20:47.900148Z","shell.execute_reply.started":"2021-09-10T17:20:42.831832Z","shell.execute_reply":"2021-09-10T17:20:47.898782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's visualize the accuracy of all the three models\nmodels = {\n    'Naive':acc_naive,\n    'Logistic':acc_logistic,\n    'SVC':acc_svc\n}\n\nsns.set_style('darkgrid')\nplt.plot(models.keys(),models.values(),marker='*',color='blue',markeredgecolor='red',markeredgewidth=4)\nplt.xlabel('Models')\nplt.ylabel('Accuracy')","metadata":{"execution":{"iopub.status.busy":"2021-09-10T17:21:02.419638Z","iopub.execute_input":"2021-09-10T17:21:02.41994Z","iopub.status.idle":"2021-09-10T17:21:02.636338Z","shell.execute_reply.started":"2021-09-10T17:21:02.419908Z","shell.execute_reply":"2021-09-10T17:21:02.635253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}