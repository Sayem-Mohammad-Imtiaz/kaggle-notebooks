{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Gender Voice recognition using Tensorflow and Keras\n\nThis is my first Kernel for a Kaggle dataset. Will perform some exploratory data analysis and then move ahead with classification using Tensorflow and Keras.\n\nAlways happy to learn so please feel free to give feedback and thoughts! Thanks"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow.contrib.keras import models\nfrom tensorflow.contrib.keras import layers\nfrom tensorflow.contrib.keras import losses,optimizers,metrics\n\n%matplotlib inline\nsns.set_style('whitegrid')\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Read in data\n\nLook at standard description and information on dataset"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"voice = pd.read_csv('../input/voice.csv')\n\nprint(voice.columns)\nvoice.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"voice.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preprocessing 1\nThe above shows us that all the data is numerical except for the 'label' column. In order to train the neural netowrk we will need to change the labels to a numeric form. Let's do this by using Male == 0 and Female == 1."},{"metadata":{"trusted":true},"cell_type":"code","source":"voice = pd.get_dummies(voice)\nvoice.drop('label_male',axis=1,inplace=True)\nvoice.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# change label if you want\nvoice['label'] = voice['label_female']\nvoice.drop('label_female',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data exploration\n\nLet's begin exporing the data. First we can check for correlations."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=[16,9])\nmask = np.ones_like(voice.corr())\nmask[np.tril_indices_from(mask)] = False\nsns.heatmap(voice.corr(),mask=mask,vmin=-1,vmax=1,cmap='coolwarm',annot=True,linewidths=0.5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the correlation heatmap we can see a few things:\n1. *meanfun* seems to have the strongest correlation with the label\n2. Other feautures with correlations above abs(0.3) are *meanfreq, sd, Q25, IQR, sp.ent, sfm,* and * centroid*\n3. *Q75, skew, kurt* and *modindx* essentially have no correlation i.e. they are \"independent\" with regards to sex\n4. *centroid* and *meanfreq* are pefectly correlated as they are the same"},{"metadata":{},"cell_type":"markdown","source":"We can remove *centroid* as we dont want to train on the \"same\" feature twice"},{"metadata":{"trusted":true},"cell_type":"code","source":"voice.drop('centroid',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What would be cool is to check how seperable the label is for some of these higher correlation features. Can use some boxplots for this. Or if you want a massive pairplot. We will only do two boxplots here."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=[9,6])\nsns.boxplot(x='label',y='meanfreq',data=voice)\nplt.xticks([0,1],['male','female'])\nplt.xlabel(xlabel=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=[9,6])\nsns.boxplot(x='label',y='meanfun',data=voice)\nplt.xticks([0,1],['male','female'])\nplt.xlabel(xlabel=None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*meanfun* seems to be able to separate the data really well."},{"metadata":{},"cell_type":"markdown","source":"### Preprocessing 2\n\nNow onto the second part of preprocessing and separation of data from labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"voice_data = voice.drop('label',axis=1)\nvoice_label = voice['label']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Split the data into training and testing sets. For now just do training and testing but later split into 3: train, validation, and test."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(voice_data,voice_label,test_size=0.3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now scale the data for use in a neural network"},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler()\n# only train the scaler on the training data\nscaled_x_train = scaler.fit_transform(X_train)\nscaled_x_test = scaler.transform(X_test)\n\nprint('Scaled training data shape: ',scaled_x_train.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now start neural network model definition. We have 19 input features and we want our output to classify the data for either male or female. We therefore need two outputs using 'softmax' activation function. The hidden layers will use the standard 'relu' activation function."},{"metadata":{"trusted":true},"cell_type":"code","source":"dnn_keras_model = models.Sequential()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# can play around with the number of hidden layers but I found that one hidden layer was more than enough to give great metrics\ndnn_keras_model.add(layers.Dense(units=30,input_dim=19,activation='relu'))\n# dnn_keras_model.add(layers.Dense(units=30,activation='relu'))\ndnn_keras_model.add(layers.Dense(units=20,activation='relu'))\ndnn_keras_model.add(layers.Dense(units=10,activation='relu'))\ndnn_keras_model.add(layers.Dense(units=2,activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# compile model by selecting optimizer and loss function\ndnn_keras_model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train/fit the model\ndnn_keras_model.fit(scaled_x_train,y_train,epochs=50)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we can make our predictions with the test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = dnn_keras_model.predict_classes(scaled_x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Metric for ')\nprint('Classification report:')\nprint(classification_report(predictions,y_test))\nprint('\\n')\nprint('Confusion matrix:')\nprint(confusion_matrix(predictions,y_test))\nprint('\\n')\nprint('Accuracy score is {:6.3f}.'.format(accuracy_score(predictions,y_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So with the above setup, we are getting about 98% accuracy, precision and recall which is pretty good!"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}