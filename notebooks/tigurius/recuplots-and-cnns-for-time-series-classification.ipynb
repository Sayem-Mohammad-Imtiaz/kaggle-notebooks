{"cells":[{"metadata":{"_uuid":"e41fb2c7e38f4c9e893a4c224b48a942eaa4c6cd"},"cell_type":"markdown","source":"# **Recurrence plots and CNNs for time-series classification**\nIn this kernel we investigate how to use recurrence plots as pre-processing step for time-series, so we can classifiy them with convolutional neural nets. Since CNNs require images as inputs to be useful, one has to convert a time-series to an image. A typical approach is to convert the time-series to a spectrogram. This is disadvantageous since in a spectrogram it matters where an effect appears in contrast to CNNs where it is assumed that a feature is of the same kind, no matter where in the picture it is.\nThe usage of recurrence plots as visualization of the recurrence structure of a time-series is hence advantageous. \nIn this kernel we will investigate the notion of recurrence plots and how to use it for time-series classification. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom scipy.spatial.distance import pdist, squareform #scipy spatial distance\nimport sklearn as sk\nimport sklearn.metrics.pairwise\nimport matplotlib.pyplot as plt\nimport os\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Convolution2D, MaxPooling2D, LeakyReLU\nfrom keras import metrics\nfrom keras import backend as K\nimport time\nfrom skimage.transform import resize\n\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import to_categorical\nfrom keras.utils import np_utils\n","execution_count":62,"outputs":[]},{"metadata":{"_uuid":"7a030f7ddf1216b77f98208a6517438aed201239"},"cell_type":"markdown","source":"## Recurrence Plots\nRecurrence plots are a visualization tool for (multivariate) time-series. They are based on exploring the characteristic recurrent behaviour of a time-series. Let $q(t) \\in \\mathbb{R}^d$ be a multi-variate time-series. It's recurrence plot is defined as\n$$ RP_{i,j} = \\theta( \\epsilon - || q(i) - q(j) ||)$$\nwhere $\\epsilon$ is a threshold and $\\theta$ is the heaviside function.  "},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#modified from https://stackoverflow.com/questions/33650371/recurrence-plot-in-python\ndef recurrence_plot(s, eps=None, steps=None):\n    if eps==None: eps=0.1\n    if steps==None: steps=10\n    d = sk.metrics.pairwise.pairwise_distances(s)\n    d = np.floor(d / eps)\n    d[d > steps] = steps\n    #Z = squareform(d)\n    return d","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"9505a896442067737fc5aef0b0710d0680bc6d2a"},"cell_type":"markdown","source":"As a first example, we create the recurrence plot of a random time-series and a sinus series. Clearly the regular structure of the sinus is visible."},{"metadata":{"trusted":true,"_uuid":"27fefea87299d1ec6e0abf7bec2ea69c58c3376e"},"cell_type":"code","source":"fig = plt.figure(figsize=(15,14))\nrandom_series = np.random.random(1000)\nax = fig.add_subplot(1, 2, 1)\nax.imshow(recurrence_plot(random_series[:,None]))\nsinus_series = np.sin(np.linspace(0,24,1000))\nax = fig.add_subplot(1, 2, 2)\nax.imshow(recurrence_plot(sinus_series[:,None]));","execution_count":70,"outputs":[]},{"metadata":{"_uuid":"338e81aa80d6b5d2a45a9ba12f2d137fbbd191d7"},"cell_type":"markdown","source":"We investigate examples of the MotionSense data set.  We take for each of the activities - downstairs, upstairs, walking, jogging, sitting, and standing - a time-series of the first participant. "},{"metadata":{"trusted":true,"_uuid":"928f26b5648b577a31a6ba6f7910885e1cf2934e","scrolled":true},"cell_type":"code","source":"cols = [\"attitude.roll\",\"attitude.pitch\",\"attitude.yaw\",\"gravity.x\",\"gravity.y\",\"gravity.z\",\"rotationRate.x\",\"rotationRate.y\",\"rotationRate.z\",\"userAcceleration.x\", \"userAcceleration.y\", \"userAcceleration.z\"]\nfig = plt.figure(figsize=(15,14))\nax = fig.add_subplot(2, 3, 1)\nax.imshow(recurrence_plot(pd.read_csv(\"../input/A_DeviceMotion_data/A_DeviceMotion_data/wlk_15/sub_1.csv\")[cols].values,steps=1000))\nax.set_xlabel('Walking')\nax = fig.add_subplot(2, 3, 2)\nax.imshow(recurrence_plot(pd.read_csv(\"../input/A_DeviceMotion_data/A_DeviceMotion_data/sit_5/sub_1.csv\")[cols].values,steps=1000))\nax.set_xlabel('Sitting')\nax = fig.add_subplot(2, 3, 3)\nax.imshow(recurrence_plot(pd.read_csv(\"../input/A_DeviceMotion_data/A_DeviceMotion_data/jog_9/sub_1.csv\")[cols].values,steps=1000))\nax.set_xlabel('Jogging')\nax = fig.add_subplot(2, 3, 4)\nax.imshow(recurrence_plot(pd.read_csv(\"../input/A_DeviceMotion_data/A_DeviceMotion_data/dws_1/sub_1.csv\")[cols].values,steps=1000))\nax.set_xlabel('Downstairs')\nax = fig.add_subplot(2, 3, 5)\nax.imshow(recurrence_plot(pd.read_csv(\"../input/A_DeviceMotion_data/A_DeviceMotion_data/std_6/sub_1.csv\")[cols].values,steps=1000))\nax.set_xlabel('Standing')\nax = fig.add_subplot(2, 3, 6)\nax.imshow(recurrence_plot(pd.read_csv(\"../input/A_DeviceMotion_data/A_DeviceMotion_data/ups_3/sub_1.csv\")[cols].values,steps=1000))\nax.set_xlabel('Upstairs');","execution_count":71,"outputs":[]},{"metadata":{"_uuid":"cbf9fe13d2fecc4968c1f0d834ae9e2989dcbc4b"},"cell_type":"markdown","source":"The images look rather different for very different activities, while walking/jogging, upstairs/downstairs, and sitting/standing are similiar to each other. Hence we can expect that image classification tools allow to distinguish between the recurrence plots of different activities. Since walking/jogging, upstairs/downstairs, and sitting/standing differ not that much, it is expected that these will not be so easy distinguishable.  For learning purposes we summarize these activities into one class each.\nAs a next step, we have to pre-process all the data, i.e. convert all the time-series to recurrence-plots and scale them to equal sizes. \n\n"},{"metadata":{"trusted":true,"_uuid":"da5f88f32d1b17356c97bf7ce0607937f23465ee"},"cell_type":"code","source":"# convert folders to class labels\n# downstairs/upstairs = 0,walking/jogging  = 1, standing/sitting = 2\nclass_translate = {\"dws_1\" : 0, \"dws_2\" : 0, \"dws_11\" : 0,  \\\n                   \"ups_3\" : 0, \"ups_4\" : 0, \"ups_12\" : 0, \\\n                   \"wlk_7\" : 1, \"wlk_8\" : 1, \"wlk_15\" : 1, \\\n                   \"jog_9\" : 1, \"jog_16\" : 1, \\\n                   \"std_6\" : 2, \"std_14\" : 2, \\\n                   \"sit_5\" : 2, \"sit_13\": 2}\n\n#pre allocate arrays\nx_train = np.zeros((384,32,32))\ny_train = np.zeros(384)\nc = 0\nstart = time.time()\nfor i in class_translate.keys():    \n    print(\"Processing set \" + i)\n    for j in range(1,25):\n        dat = recurrence_plot(pd.read_csv(\"../input/A_DeviceMotion_data/A_DeviceMotion_data/\" + i +\"/\" + \"sub_\"+ str(j) + \".csv\")[cols].values, steps=100)\n        dat = resize(dat, (32,32),mode='constant')\n        x_train[c,:,:] = dat\n        y_train[c] = class_translate[i]\n        c = c + 1\nend = time.time()\nprint('Elapsed time:')\nprint(end - start)","execution_count":6,"outputs":[]},{"metadata":{"_uuid":"5cacdccc88ca7fd3995a55003c9b88956545c643"},"cell_type":"markdown","source":"## CNNs for Recurrence plots\nIn https://arxiv.org/pdf/1710.00886.pdf the usage of a convolutional net for classification of recurrence plots is proposed. "},{"metadata":{"trusted":true,"_uuid":"8dad30beca82ebecac44ebff418b146530bfea0c"},"cell_type":"code","source":"model = Sequential()\n \nmodel.add(Convolution2D(32, (3, 3), activation='relu', input_shape=(1,32,32), data_format='channels_first'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\nmodel.add(Convolution2D(32, (3, 3),activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25)) \nmodel.add(Flatten())\nmodel.add(Dense(64, activation='relu'))\n#model.add(LeakyReLU(alpha=0.03))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(3, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])","execution_count":55,"outputs":[]},{"metadata":{"_uuid":"ac2bf5fc0d8d8a7d1e17fc7cd0a144cae682ed28"},"cell_type":"markdown","source":"We normalize the data and save 10% for later evaluation of our model. "},{"metadata":{"trusted":true,"_uuid":"44261bb4d9a0e22846d82caa36a60b4bb5a99c0e"},"cell_type":"code","source":"#reshape to include depth\nX_train = x_train.reshape(x_train.shape[0], 1, 32,32)\n#convert to float32 and normalize to [0,1]\nX_train = X_train.astype('float32')\nX_train /= np.amax(X_train)\n# convert labels to class matrix, one-hot-encoding\nY_train = np_utils.to_categorical(y_train, 3)\n# split in train and test set\nX_train, x_test, Y_train, y_test = train_test_split(X_train, Y_train, test_size=0.1)","execution_count":16,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c97939f30bdc7aa815f957d706782deb088611b","scrolled":true},"cell_type":"code","source":"model.fit(X_train, Y_train, epochs=200, batch_size=16,shuffle=True)\n","execution_count":56,"outputs":[]},{"metadata":{"_uuid":"15405bf28883927265c672978c8f0719992e1976"},"cell_type":"markdown","source":"Let's make predictions on the test set and compare with the real values.  We get good results for a very simple model."},{"metadata":{"trusted":true,"_uuid":"6c01b53365486bf21ece7be8f7c7dceeef268790"},"cell_type":"code","source":"predictions= model.predict(x_test)\nrounded = [np.argmax(x) for x in predictions]\nprint(K.eval(metrics.categorical_accuracy(y_test, np_utils.to_categorical(rounded, 3))))\n","execution_count":59,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}