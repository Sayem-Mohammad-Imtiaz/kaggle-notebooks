{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Wald Confidence Intervals with Iowa Liquor Sales\n\nIn [a previous notebook](https://www.kaggle.com/residentmario/bootstrapping-and-cis-with-veteran-suicides) I described how to obtain a confidence interval for an estimate of an interval variable.\n\nIn this notebook, I'll examine the Wald Confidence Interval, the simplest method for generating a confidence interval for binomial trails.\n\nA Bernoulli trial occurs when you have a sequence of data points which can only take on two values: say, 0 and 1. Examples of Bernoulli trials include which of two different players will be the one to win a tennis match, or predicting whether or not a train is going to arrive in the next five minutes of waiting. Either something happens, or it doesn't happen. Usually 1 is denotated \"success\" and 0 \"failure\".\n\n## Derivation\n\nLet $p$ be the probability of success. Conversely, $q = 1 - p$ is the probability of failure. Let $X$ be the number of successes in $n$ trials.\n\nOur goal is to understand $p$. We will do this by constructing an estimator on $p$, $\\hat{p}$, using the observed properties of our model.\n\n$E[X]$ is the expectation of $X$: the expected number of succeses in $n$ trials. From there we have that:\n\n$$E[\\frac{X}{n}] = \\frac{1}{n}(np) = p$$\n\nIn other words, the expectation of the number of succeses over the number of trials is $p$, the underlying probability of success.\n\nSimilarly, $Var(\\frac{X}{n})$, the variance of the estimate, is given by:\n\n$$Var[\\frac{X}{n}] = \\left(\\frac{1}{n}\\right)^2 V[X] = \\frac{npq}{n^2} = \\frac{pq}{n}$$\n\nThe central limit theorem states that since $E[\\hat{p} = \\frac{X}{n}] = p$, with a large enough number of samples (~$n \\geq 30$), the error committed by $\\hat{p}$ will be normally distributed.\n\n(to see why this happens in more detail, refer to [the previous notebook](https://www.kaggle.com/residentmario/bootstrapping-and-cis-with-veteran-suicides))\n\nWe can normalize $\\hat{p}$ to arrive at a confidence interval.\n\n$$P\\left( -z_{\\alpha/2} < \\frac{\\hat{p} - p}{\\sqrt{pq/n}} < z_{\\alpha / 2} \\right) = 1 - \\alpha$$\n\nHere $z$ is the standardized z-score for how confident we want to be; since this is a two-sided interval for given confidence $\\alpha$ (e.g. $\\alpha$=0.95) we need to half the interval.\n\nThe boundaries for the confidence interval will be the endpoints, which will be:\n\n$$\\frac{\\hat{p} - p}{\\sqrt{pq/n}} = \\pm z_{\\alpha / 2}$$\n\nHence:\n\n$$p = \\hat{p} \\pm z_{\\alpha/2}\\sqrt{p(1-p)/n}$$\n\nThe \"Wald approximation\" is the introduction of additional error into this result by swapping out $p$ (an underlying statistic) for $\\hat{p}$, an estimate of $\\hat{p}$:\n\n$$p = \\hat{p} \\pm z_{\\alpha / 2}\\sqrt{\\hat{p}(1 - \\hat{p})/n}$$"},{"metadata":{},"cell_type":"markdown","source":"## Implementation"},{"outputs":[],"metadata":{"collapsed":true},"execution_count":null,"cell_type":"code","source":"import scipy.stats as st\nimport numpy as np\n\ndef wald_confidence_interval(X, c):\n    n = X.shape[0]\n    \n    p_hat = X.astype(int).sum() / n\n    z_score = st.norm.ppf(1 - ((1 - c) / 2))\n\n    additive_part = z_score * np.sqrt(p_hat * (1 - p_hat) / n)\n    \n    return (p_hat - additive_part, p_hat + additive_part)"},{"metadata":{},"cell_type":"markdown","source":"## Application\n\nLet's apply the Wald CI to a somewhat random but cute problem: given one million liquor sales in the state of Iowa (one mil. to keep the computation time decent), how well can we estimate what the probability of someone making an alcohol purchase on Christmas Day?"},{"outputs":[],"metadata":{"_uuid":"897b75b3b291cc2396c203e1231d39b5bdaf4e03","_cell_guid":"cee43793-a020-4c21-8d39-85170f6780a9","scrolled":true},"execution_count":null,"cell_type":"code","source":"import pandas as pd\nsales = pd.read_csv(\"../input/Iowa_Liquor_Sales.csv\")"},{"outputs":[],"metadata":{},"execution_count":null,"cell_type":"code","source":"_sales = (sales\n     .head(1000000)\n     .assign(n=0)\n     .groupby('Date')\n     .count()\n     .n\n     .to_frame()\n     .reset_index()\n     .pipe(lambda df: df.assign(Date=pd.to_datetime(df.Date)))\n     .pipe(lambda df: df.assign(Day=df.Date.dt.dayofyear))\n     .groupby('Day')\n     .mean()\n)\n\nchristmas_day_sales = _sales.loc[359, 'n']\nall_sales = _sales.n.round().sum()"},{"outputs":[],"metadata":{"collapsed":true},"execution_count":null,"cell_type":"code","source":"is_christmas_sale = np.array([True]*int(christmas_day_sales) + [False]*(1000000 - int(christmas_day_sales)))"},{"outputs":[],"metadata":{},"execution_count":null,"cell_type":"code","source":"wald_confidence_interval(is_christmas_sale, 0.95)"},{"metadata":{},"cell_type":"markdown","source":"We are 95% confident that the true proportion of alcohol sales that occur on Christmas Day is between ~0.00168 and ~0.00185.\n\nNote that this means that, as expected, the amount of alcohol that gets purchased on Christmas is *significantly less* than the amount that gets purchased on an average day of the year:"},{"outputs":[],"metadata":{},"execution_count":null,"cell_type":"code","source":"1/365"}],"nbformat_minor":1,"nbformat":4,"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"},"language_info":{"name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"nbconvert_exporter":"python","version":"3.6.3","file_extension":".py","mimetype":"text/x-python"}}}