{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/dogecoin-historical-data/DOGE-USD.csv\")\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.corr()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Date'] =  pd.to_datetime(df['Date'], infer_datetime_format=True)\ndf.set_index('Date',inplace=True)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dropna(inplace=True)\ndf.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Close column is our y feature (predicted feature). So we should make feature engineering to get higher corr values with y \n# We will take corr values between 0.8-0.2 due to Pearson Correlation Matrix but we can take Volume because its at the borderline\ndf[\"gap\"] = (df[\"High\"] - df[\"Low\"]) * df[\"Volume\"]\ndf[\"y\"] = df[\"High\"] / df[\"Volume\"]\ndf[\"z\"] = df[\"Low\"] / df[\"Volume\"]\ndf[\"a\"] = df[\"High\"] / df[\"Low\"]\ndf[\"b\"] = (df[\"High\"] / df[\"Low\"]) * df[\"Volume\"]\nabs(df.corr()[\"Close\"].sort_values(ascending=False))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df[[\"Close\",\"Volume\",\"gap\",\"a\",\"b\"]]\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!pip install pycaret \nfrom pycaret.regression import *\nexp_name = setup(data=df,target=\"Close\")\nbest_model = compare_models()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1 = create_model(\"gbr\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuned_model = tune_model(model1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Let's make Time Series Analysis too!","metadata":{}},{"cell_type":"code","source":"## I'm gonna analyze last 30 days because significant changes have occured in these 30 days \ndf2 = df.tail(30)\ndf2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!pip install pmdarima\nfrom pmdarima.arima import auto_arima\n\nmodel = auto_arima(df2[\"Close\"],df2.drop(\"Close\",axis=1),\n                      seasonal=True, m=1,\n                      start_d=0, D=None, \n                      start_q=0, start_p=0,\n                      trace=True,\n                      error_action='ignore',test=\"adf\",\n                      suppress_warnings=True)\n\nprint(model.summary())\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train= df2[:11]\ntest= df2[-19:]\n\nprint(train.shape, test.shape)\ntrain","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from statsmodels.tsa.statespace.sarimax import SARIMAX\nmodel= SARIMAX(endog=train[\"Close\"],exog = train.drop(\"Close\",axis=1), order=(2,1,1))\nresults=model.fit()\nprint(results.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start= 11\nend= 29\npredictions= results.predict(start=start, end=end,exog = test.drop(\"Close\",axis=1))\npredictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test[\"Close\"].plot(legend=True,figsize=(12,6))\npredictions.plot(label='TimeSeries',legend=True);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Well trends looks like same so I think there are similar speculations on the market compared to last month.","metadata":{}},{"cell_type":"markdown","source":"## Thanks for reviewing, feel free to comment!","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}