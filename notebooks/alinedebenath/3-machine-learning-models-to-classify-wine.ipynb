{"cells":[{"metadata":{},"cell_type":"markdown","source":"# <center>My first Machine Learning project : <br>3 machine learning models to classify red wine</center>"},{"metadata":{},"cell_type":"markdown","source":"<img src='https://hhp-blog.s3.amazonaws.com/2018/02/iStock-615737086-768x512.jpg'>"},{"metadata":{},"cell_type":"markdown","source":"### Librairies"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\nfrom sklearn.svm import LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\nfrom sklearn.preprocessing import StandardScaler\nfrom xgboost import XGBClassifier\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom matplotlib.colors import LinearSegmentedColormap\nfrom sklearn.decomposition import PCA","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Objective 1 : predict the quality score of the wine\n### Dataset import"},{"metadata":{"trusted":true},"cell_type":"code","source":"wine = pd.read_csv('../input/red-wine-quality-cortez-et-al-2009/winequality-red.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wine.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dataset exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"wine.info()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"wine['quality'].hist(figsize=(7,5), color=\"purple\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wine['quality'].value_counts(sort=False)/1599*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wine['quality'].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> The quality scores range from 3/10 to 8/10. The target distribution is skewed to the right.<br>\nThe mean is 5.65/10, the median is 6/10.\n96% of the wines have a score of 5/10 or more.<br>\nSo we can say that the wines in this dataset are favourably rated."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"wine_corr = wine.corr()\ncmap = LinearSegmentedColormap.from_list(\n    name='test', \n    colors=['black','red','pink','red','black'])\nmask = np.zeros_like(wine_corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\nf, ax = plt.subplots(figsize=(10, 8))\nsns.heatmap(wine_corr, xticklabels=wine_corr.columns, yticklabels=wine_corr.columns, cmap=cmap,linewidths = .5, annot=True, ax=ax, mask=mask, vmin=-1)\nb, t = plt.ylim()\nb += 0.5\nt -= 0.5\nplt.ylim(b, t)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Let's delete the \"free sulfur dioxide\" column because it looks like it's marginallly correlated to the target and this feature is already present in the \"total sulfur dioxide\" column.<br>\nThe same goes for the \"pH\" column which is also present in the fixed acidity (pH is a scale of acidity)"},{"metadata":{"trusted":true},"cell_type":"code","source":"wine.drop(columns=['free sulfur dioxide','pH'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> As the \"alcohol\" column seems the most correlated to the target, let's see the lineplot"},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(figsize=(10, 5))\nsns.lineplot(x=\"quality\", y=\"alcohol\", data=wine, color='purple')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Scalling"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = wine.drop(columns = ['quality'])\ny = wine['quality']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nX = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Machine learning models for classification"},{"metadata":{},"cell_type":"markdown","source":"#### Linear SVC"},{"metadata":{"trusted":true},"cell_type":"code","source":"linearsvc = LinearSVC(dual=False)\npred_svc=cross_val_predict(linearsvc, X, y, cv=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cmap2 = LinearSegmentedColormap.from_list(\n    name='test', \n    colors=['pink','red','purple'])\ncm = confusion_matrix(y, pred_svc)\nfig, ax = plot_confusion_matrix(conf_mat=cm, class_names=['3','4','5','6','7','8'],figsize=(10, 5), cmap=cmap2, colorbar=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Accuracy score :',accuracy_score(y, pred_svc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('F1 score:\\n',classification_report(y, pred_svc, digits=3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### RandomForest "},{"metadata":{},"cell_type":"markdown","source":"> Randomized search and Grid search to find the best hyperparameters"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"from time import time\nfrom scipy.stats import randint as sp_randint\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.datasets import load_digits\nfrom sklearn.ensemble import RandomForestClassifier\n\n# build a classifier\nclf = RandomForestClassifier(n_estimators=20)\n\n\n# Utility function to report best scores\ndef report(results, n_top=3):\n    for i in range(1, n_top + 1):\n        candidates = np.flatnonzero(results['rank_test_score'] == i)\n        for candidate in candidates:\n            print(\"Model with rank: {0}\".format(i))\n            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n                  results['mean_test_score'][candidate],\n                  results['std_test_score'][candidate]))\n            print(\"Parameters: {0}\".format(results['params'][candidate]))\n            print(\"\")\n\n\n# specify parameters and distributions to sample from\nparam_dist = {\"max_depth\": [1, 3, 5, None],\n              \"max_features\": sp_randint(1, 10),\n              \"min_samples_split\": sp_randint(2, 11),\n              \"bootstrap\": [True, False],\n              \"criterion\": [\"gini\", \"entropy\"]}\n\n# run randomized search\nn_iter_search = 20\nrandom_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n                                   n_iter=n_iter_search, cv=10, iid=False)\n\nstart = time()\nrandom_search.fit(X, y)\nprint(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n      \" parameter settings.\" % ((time() - start), n_iter_search))\nreport(random_search.cv_results_)\n\n# use a full grid over all parameters\nparam_grid = {\"max_depth\": [1, 3, 5, None],\n              \"max_features\": [2, 3, 9],\n              \"min_samples_split\": [2, 3, 10],\n              \"bootstrap\": [True, False],\n              \"criterion\": [\"gini\", \"entropy\"]}\n\n# run grid search\ngrid_search = GridSearchCV(clf, param_grid=param_grid, cv=10, iid=False)\nstart = time()\ngrid_search.fit(X, y)\n\nprint(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n      % (time() - start, len(grid_search.cv_results_['params'])))\nreport(grid_search.cv_results_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc = RandomForestClassifier(n_estimators=20, bootstrap=True, \ncriterion='gini', max_depth=5,max_features=3,min_samples_split=10)\npred_rfc=cross_val_predict(rfc, X, y, cv=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y, pred_rfc)\nfig, ax = plot_confusion_matrix(conf_mat=cm, class_names=['3','4','5','6','7','8'],figsize=(10, 5), cmap=cmap2, colorbar=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Accuracy score :',accuracy_score(y, pred_rfc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('F1 score:\\n',classification_report(y, pred_rfc, digits=3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### XGBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"xgboost = XGBClassifier(objective='multi:softmax', num_class=10, \n        n_jobs=-1,booster=\"gbtree\",tree_method = \"hist\",\n        grow_policy = \"depthwise\")\npred_xgboost=cross_val_predict(xgboost, X, y, cv=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y, pred_xgboost)\nfig, ax = plot_confusion_matrix(conf_mat=cm, class_names=['3','4','5','6','7','8'],figsize=(10, 5), cmap=cmap2, colorbar=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Accuracy score :',accuracy_score(y, pred_xgboost))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"print('F1 score :\\n',classification_report(y, pred_xgboost, digits=3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Predicted target distribution "},{"metadata":{"trusted":true},"cell_type":"code","source":"X['pred_svc'] = pred_svc\nX['pred_svc'].hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"linearsvc.fit(X, y)\nfeature=X.columns\nimportance= linearsvc.coef_\nfeat_imp = pd.DataFrame(importance, columns=X.columns)\nfeat_imp.plot(kind = \"bar\", figsize=(12,4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X['pred_rfc'] = pred_rfc\nX['pred_rfc'].hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc.fit(X, y)\nfeature=X.columns\nimportance=rfc.feature_importances_\nfeat_imp = pd.DataFrame(importance, feature, columns=['Importance'])\nfeat_imp.plot(kind = \"bar\", figsize=(12,4))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"X['pred_xgboost'] = pred_xgboost\nX['pred_xgboost'].hist()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"xgboost.fit(X, y)\nfeature=X.columns\nimportance=xgboost.feature_importances_\nfeat_imp = pd.DataFrame(importance, feature, columns=['Importance'])\nfeat_imp.plot(kind = \"bar\", figsize=(12,4))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Objective n°2 : predict if a wine is good or bad"},{"metadata":{},"cell_type":"markdown","source":"> Ths will allow us to have a better score"},{"metadata":{"trusted":true},"cell_type":"code","source":"wine = pd.read_csv('../input/red-wine-quality-cortez-et-al-2009/winequality-red.csv')\npd.set_option('mode.chained_assignment', None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data transformation : scalling the target to 0 (bad) and 1 (good)"},{"metadata":{"trusted":true},"cell_type":"code","source":"wine.quality[wine['quality']<=5]=0\nwine.quality[wine['quality']>5]=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wine.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Scalling et split"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = wine.drop(columns = ['quality'])\ny = wine['quality']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nX = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Machine learning models for classification"},{"metadata":{},"cell_type":"markdown","source":"#### Linear SVC "},{"metadata":{"trusted":true},"cell_type":"code","source":"linearsvc = LinearSVC(dual=False)\npred_svc=cross_val_predict(linearsvc, X, y, cv=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cmap2 = LinearSegmentedColormap.from_list(\n    name='test', \n    colors=['pink','red','purple'])\ncm = confusion_matrix(y, pred_svc)\nfig, ax = plot_confusion_matrix(conf_mat=cm, class_names=['0','1'],figsize=(10, 5), cmap=cmap2, colorbar=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Accuracy score :',accuracy_score(y, pred_svc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('F1 score :\\n',classification_report(y, pred_svc, digits=3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### RandomForest "},{"metadata":{"trusted":true},"cell_type":"code","source":"from time import time\nfrom scipy.stats import randint as sp_randint\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.datasets import load_digits\nfrom sklearn.ensemble import RandomForestClassifier\n\n# build a classifier\nclf = RandomForestClassifier(n_estimators=20)\n\n\n# Utility function to report best scores\ndef report(results, n_top=3):\n    for i in range(1, n_top + 1):\n        candidates = np.flatnonzero(results['rank_test_score'] == i)\n        for candidate in candidates:\n            print(\"Model with rank: {0}\".format(i))\n            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n                  results['mean_test_score'][candidate],\n                  results['std_test_score'][candidate]))\n            print(\"Parameters: {0}\".format(results['params'][candidate]))\n            print(\"\")\n\n\n# specify parameters and distributions to sample from\nparam_dist = {\"max_depth\": [1, 3, 5, None],\n              \"max_features\": sp_randint(1, 10),\n              \"min_samples_split\": sp_randint(2, 11),\n              \"bootstrap\": [True, False],\n              \"criterion\": [\"gini\", \"entropy\"]}\n\n# run randomized search\nn_iter_search = 20\nrandom_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n                                   n_iter=n_iter_search, cv=10, iid=False)\n\nstart = time()\nrandom_search.fit(X, y)\nprint(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n      \" parameter settings.\" % ((time() - start), n_iter_search))\nreport(random_search.cv_results_)\n\n# use a full grid over all parameters\nparam_grid = {\"max_depth\": [1, 3, 5, None],\n              \"max_features\": [2, 3, 9],\n              \"min_samples_split\": [2, 3, 10],\n              \"bootstrap\": [True, False],\n              \"criterion\": [\"gini\", \"entropy\"]}\n\n# run grid search\ngrid_search = GridSearchCV(clf, param_grid=param_grid, cv=10, iid=False)\nstart = time()\ngrid_search.fit(X, y)\n\nprint(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n      % (time() - start, len(grid_search.cv_results_['params'])))\nreport(grid_search.cv_results_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc = RandomForestClassifier(n_estimators=20, bootstrap=True, criterion='gini', max_depth=3,max_features=4,min_samples_split=10)\npred_rfc=cross_val_predict(rfc, X, y, cv=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y, pred_rfc)\nfig, ax = plot_confusion_matrix(conf_mat=cm, class_names=['0','1'],figsize=(10, 5), cmap=cmap2, colorbar=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Accuracy score :',accuracy_score(y, pred_rfc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('F1 score:\\n',classification_report(y, pred_rfc, digits=3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### XGBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"xgboost = XGBClassifier(objective='reg:squarederror', n_jobs=-1,\n                        booster=\"gbtree\",tree_method = \"hist\",\n                        grow_policy = \"depthwise\")\npred_xgboost=cross_val_predict(xgboost, X, y, cv=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y, pred_xgboost)\nfig, ax = plot_confusion_matrix(conf_mat=cm, class_names=['0','1'],figsize=(10, 5), cmap=cmap2, colorbar=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Accuracy score :',accuracy_score(y, pred_xgboost))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"print('F1 score :\\n',classification_report(y, pred_xgboost, digits=3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Predicted target distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"X['pred_svc'] = pred_svc\nX['pred_svc'].hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"linearsvc.fit(X, y)\nfeature=X.columns\nimportance= linearsvc.coef_\nfeat_imp = pd.DataFrame(importance, columns=feature)\nfeat_imp.plot(kind = \"bar\", figsize=(12,4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X['pred_rfc'] = pred_rfc\nX['pred_rfc'].hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc.fit(X, y)\nfeature=X.columns\nimportance=rfc.feature_importances_\nfeat_imp = pd.DataFrame(importance, feature, columns=['Importance'])\nfeat_imp.plot(kind = \"bar\", figsize=(12,4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X['pred_xgboost'] = pred_xgboost\nX['pred_xgboost'].hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgboost.fit(X, y)\nfeature=X.columns\nimportance=xgboost.feature_importances_\nfeat_imp = pd.DataFrame(importance, feature, columns=['Importance'])\nfeat_imp.plot(kind = \"bar\", figsize=(12,4))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> To conclude : as excepted, the objective n°2 has better scores, because the target has become binary.<br>\nThe general quality of the wines in this dataset is positively skewed but the algorithm Random Forest succeeded to rendera similar distribution, inspite of the low quantity of data"},{"metadata":{},"cell_type":"markdown","source":"# Thank you for reading, please leave a comment if you see a way to ameliorate my code, it's always fun to learn something new !"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}