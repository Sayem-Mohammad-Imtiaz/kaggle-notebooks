{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### <p style=\"background-color:#34bdeb;font-family:newtimeroman;color:#e3f8ff;font-size:150%; font-syle:bold;text-align:center;border-radius:20px 60px;\">Spam or Ham Classifier</p>\n![spam and ham classification using spacy](https://lionbridge.ai/wp-content/uploads/2020/08/2020-08-20_nlp_spam-detection.jpg)","metadata":{}},{"cell_type":"markdown","source":"\n### **There are numbers of way to build email classifier but in this notebook we will focus on how to create simple email classifier using one of the powerful  NLP libray SpaCy**\n\n#### **Why Spacy ?**\n* ##### **SpaCy is an open-source natural language processing library for Python. It is designed particularly for production use, and it can help us to build applications that process massive volumes of text efficiently.**\n* ##### **Another advantage of SpaCy is we can perform the various text manipulation operation very well with optimzed and minimal code**\n* ##### **Also you can create customized pipeline with different steps using SpaCy**","metadata":{}},{"cell_type":"markdown","source":"#### Want to learn more about SpaCy?\n[Click here to check the document](https://spacy.io/)","metadata":{}},{"cell_type":"markdown","source":" ","metadata":{}},{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import re\nimport nltk\nimport random\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport spacy\nfrom spacy.util import minibatch\nimport matplotlib.pyplot as plt\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline    \nfrom sklearn.model_selection import cross_val_score\nfrom matplotlib.colors import ListedColormap\nfrom sklearn.metrics import precision_score, recall_score, plot_confusion_matrix, classification_report, accuracy_score, f1_score, confusion_matrix\nfrom sklearn import metrics\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-08-21T12:29:36.531942Z","iopub.execute_input":"2021-08-21T12:29:36.532251Z","iopub.status.idle":"2021-08-21T12:29:36.542294Z","shell.execute_reply.started":"2021-08-21T12:29:36.532226Z","shell.execute_reply":"2021-08-21T12:29:36.540633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set_style('whitegrid')","metadata":{"execution":{"iopub.status.busy":"2021-08-21T12:29:36.625157Z","iopub.execute_input":"2021-08-21T12:29:36.62545Z","iopub.status.idle":"2021-08-21T12:29:36.629302Z","shell.execute_reply.started":"2021-08-21T12:29:36.62542Z","shell.execute_reply":"2021-08-21T12:29:36.628618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Load\n[Click here to download  the dataset](https://www.kaggle.com/uciml/sms-spam-collection-dataset)","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('../input/sms-spam-collection-dataset/spam.csv')","metadata":{"execution":{"iopub.status.busy":"2021-08-21T12:29:40.340127Z","iopub.execute_input":"2021-08-21T12:29:40.340657Z","iopub.status.idle":"2021-08-21T12:29:40.36248Z","shell.execute_reply.started":"2021-08-21T12:29:40.340628Z","shell.execute_reply":"2021-08-21T12:29:40.361153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# removing unused column and renaming columns based on requirements\ndata = data.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1).rename(columns={'v1': 'target', 'v2': 'text'})","metadata":{"execution":{"iopub.status.busy":"2021-08-21T12:29:40.584892Z","iopub.execute_input":"2021-08-21T12:29:40.585186Z","iopub.status.idle":"2021-08-21T12:29:40.591293Z","shell.execute_reply.started":"2021-08-21T12:29:40.58516Z","shell.execute_reply":"2021-08-21T12:29:40.589968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-21T12:29:42.730225Z","iopub.execute_input":"2021-08-21T12:29:42.730564Z","iopub.status.idle":"2021-08-21T12:29:42.739077Z","shell.execute_reply.started":"2021-08-21T12:29:42.730537Z","shell.execute_reply":"2021-08-21T12:29:42.738386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.target.value_counts(normalize=True)*100","metadata":{"execution":{"iopub.status.busy":"2021-08-21T12:29:43.525066Z","iopub.execute_input":"2021-08-21T12:29:43.52555Z","iopub.status.idle":"2021-08-21T12:29:43.533974Z","shell.execute_reply.started":"2021-08-21T12:29:43.525519Z","shell.execute_reply":"2021-08-21T12:29:43.532617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Class distribution","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(10, 6))\nf = sns.countplot(x = data['target'], palette=\"Blues_d\")\nplt.xlabel('Target Variable')\nplt.ylabel('Counts of each class')\nplt.title('Class distribution (%)')\nfor p in f.patches:\n    width = p.get_width()\n    height = p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(f'{round(height/data.shape[0], 2)*100} %', (x + width/2, y + height*1.01), ha='center')","metadata":{"execution":{"iopub.status.busy":"2021-08-21T12:29:59.665675Z","iopub.execute_input":"2021-08-21T12:29:59.666127Z","iopub.status.idle":"2021-08-21T12:29:59.852242Z","shell.execute_reply.started":"2021-08-21T12:29:59.666096Z","shell.execute_reply":"2021-08-21T12:29:59.851169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"background-color:#34bdeb;font-family:newtimeroman;color:#e3f8ff;font-size:150%; font-syle:bold;text-align:center;\">Create SpaCy text-categorization pipeline and model</p>","metadata":{}},{"cell_type":"code","source":"# create empty model\nnlp = spacy.blank(\"en\")\n\ntext_cls = nlp.create_pipe(\"textcat\", config={\"exclusive_classes\": True, \"architecture\": \"bow\"})\n\n# add pipeline in model we can add other steps in pipeline also but for now i am not adding tokenization, lemmetization, stop word removation etc. steps\nnlp.add_pipe(text_cls)\n\n# add your customer label in pipeline\ntext_cls.add_label('ham')\ntext_cls.add_label('spam')","metadata":{"execution":{"iopub.status.busy":"2021-08-21T12:30:04.825311Z","iopub.execute_input":"2021-08-21T12:30:04.825735Z","iopub.status.idle":"2021-08-21T12:30:05.190599Z","shell.execute_reply.started":"2021-08-21T12:30:04.825699Z","shell.execute_reply":"2021-08-21T12:30:05.189895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(data['text'], data['target'], test_size=0.3, random_state = 7)","metadata":{"execution":{"iopub.status.busy":"2021-08-21T12:30:05.193389Z","iopub.execute_input":"2021-08-21T12:30:05.193702Z","iopub.status.idle":"2021-08-21T12:30:05.201778Z","shell.execute_reply.started":"2021-08-21T12:30:05.193677Z","shell.execute_reply":"2021-08-21T12:30:05.200637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the train and test data for the spacy model\ntrain_lables = [{'cats': {'ham': label == 'ham',\n                          'spam': label == 'spam'}}  for label in y_train]\ntest_lables = [{'cats': {'ham': label == 'ham',\n                      'spam': label == 'spam'}}  for label in y_test]\n\n# Spacy model data\ntrain_data = list(zip(x_train, train_lables))\ntest_data = list(zip(x_test, test_lables))","metadata":{"execution":{"iopub.status.busy":"2021-08-21T12:30:05.204356Z","iopub.execute_input":"2021-08-21T12:30:05.204835Z","iopub.status.idle":"2021-08-21T12:30:05.225955Z","shell.execute_reply.started":"2021-08-21T12:30:05.204789Z","shell.execute_reply":"2021-08-21T12:30:05.224659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model, train_data, optimizer, batch_size, epochs=10):\n    losses = {}\n    random.seed(1)\n\n    for epoch in range(epochs):\n        random.shuffle(train_data)\n\n        batches = minibatch(train_data, size=batch_size)\n        for batch in batches:\n            # Split batch into texts and labels\n            texts, labels = zip(*batch)\n\n            # Update model with texts and labels\n            model.update(texts, labels, sgd=optimizer, losses=losses)\n        print(\"Loss: {}\".format(losses['textcat']))\n\n    return losses['textcat']","metadata":{"execution":{"iopub.status.busy":"2021-08-21T12:30:05.565356Z","iopub.execute_input":"2021-08-21T12:30:05.565655Z","iopub.status.idle":"2021-08-21T12:30:05.571179Z","shell.execute_reply.started":"2021-08-21T12:30:05.565627Z","shell.execute_reply":"2021-08-21T12:30:05.570377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = nlp.begin_training()\nbatch_size = 5\nepochs = 20\n\n# Training the model\ntrain_model(nlp, train_data, optimizer, batch_size, epochs)","metadata":{"execution":{"iopub.status.busy":"2021-08-21T12:30:05.725779Z","iopub.execute_input":"2021-08-21T12:30:05.726121Z","iopub.status.idle":"2021-08-21T12:31:30.266208Z","shell.execute_reply.started":"2021-08-21T12:30:05.726093Z","shell.execute_reply":"2021-08-21T12:31:30.264765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_predictions(model, texts):\n    # Use the model's tokenizer to tokenize each input text\n    docs = [model.tokenizer(text) for text in texts]\n\n    # Use textcat to get the scores for each doc\n    text_cls = model.get_pipe('textcat')\n    scores, _ = text_cls.predict(docs)\n\n    # From the scores, find the label with the highest score/probability\n    predicted_labels = scores.argmax(axis=1)\n    predicted_class = [text_cls.labels[label] for label in predicted_labels]\n\n    return predicted_class","metadata":{"execution":{"iopub.status.busy":"2021-08-21T12:31:30.267888Z","iopub.execute_input":"2021-08-21T12:31:30.268177Z","iopub.status.idle":"2021-08-21T12:31:30.274362Z","shell.execute_reply.started":"2021-08-21T12:31:30.26815Z","shell.execute_reply":"2021-08-21T12:31:30.273363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_predictions = get_predictions(nlp, x_train)\ntest_predictions = get_predictions(nlp, x_test)\ntrain_accuracy = accuracy_score(y_train, train_predictions)\ntest_accuracy = accuracy_score(y_test, test_predictions)\n\nprint(\"Train accuracy: {}\".format(train_accuracy))\nprint(\"Test accuracy: {}\".format(test_accuracy))","metadata":{"execution":{"iopub.status.busy":"2021-08-21T12:31:30.275668Z","iopub.execute_input":"2021-08-21T12:31:30.27594Z","iopub.status.idle":"2021-08-21T12:31:30.688162Z","shell.execute_reply.started":"2021-08-21T12:31:30.275914Z","shell.execute_reply":"2021-08-21T12:31:30.68679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cf_train_matrix = confusion_matrix(y_train, train_predictions)\nplt.figure(figsize=(10,8))\nsns.heatmap(cf_train_matrix, annot=True, fmt='d')\n\ncf_test_matrix = confusion_matrix(y_test, test_predictions)\nplt.figure(figsize=(10,8))\nsns.heatmap(cf_test_matrix, annot=True, fmt='d')","metadata":{"execution":{"iopub.status.busy":"2021-08-21T12:31:30.689734Z","iopub.execute_input":"2021-08-21T12:31:30.69005Z","iopub.status.idle":"2021-08-21T12:31:31.147213Z","shell.execute_reply.started":"2021-08-21T12:31:30.690025Z","shell.execute_reply":"2021-08-21T12:31:31.146327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"color:#42c5f5;font-size:150%; font-weight:bold; text-align:left;\">If you found this notebook useful, please do upvote.</p>\n<p style=\"color:#42c5f5;font-size:150%; font-weight:bold; text-align:left;\">If you have any suggestions or questions, feel free to comment!</p>\n<p style=\"color:#42c5f5;font-size:150%; font-weight:bold; text-align:left;\">Thanks Happy Learning !</p>","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}