{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Problem :\n\n**Classify pnemonia/ no-pnemonia from given chest x-ray images.There can be a seperate classifier for Images with pnemonia to sub-divide it into Viral-pnemonia and Bacterial-pnemonia, but I won't do that here because of heavy class imbalance.**","metadata":{}},{"cell_type":"markdown","source":"# Resources:\n* [ https://www.kaggle.com/amyjang/tensorflow-pneumonia-classification-on-x-rays ]\n* [ https://www.kaggle.com/rahulvv/image-classification-using-efficientnetb7 ]","metadata":{}},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"\nimport os,gc\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split as tts \n\nimport tensorflow as tf \nfrom tensorflow.keras.preprocessing.image import load_img,img_to_array,smart_resize\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import EfficientNetB7\nfrom tensorflow.keras import layers \nfrom tensorflow.keras import backend as K\nfrom tensorflow.io import decode_image\nfrom tensorflow.keras.metrics import AUC\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras import Model\n\n#supress warnings\nimport warnings \nwarnings.filterwarnings('ignore')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading data ","metadata":{}},{"cell_type":"code","source":"metadata=pd.read_csv('../input/coronahack-chest-xraydataset/Chest_xray_Corona_dataset_Summary.csv')\ndata=pd.read_csv('../input/coronahack-chest-xraydataset/Chest_xray_Corona_Metadata.csv')\n\n#train and test dir.\ntest_dir='../input/coronahack-chest-xraydataset/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/test'\ntrain_dir='../input/coronahack-chest-xraydataset/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/train'\n\nmetadata","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I will make a classifier that would classify between three classes,i.e normal,viral pnemonia and bacterial pnuemonia.","metadata":{}},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_sample_image(df,label,train_dir=train_dir):\n    fig,ax=plt.subplots(1,2,figsize=(18,9))\n    img_ids=df[df['Label_2_Virus_category'] == label].sample(2)\n    \n    print(f'{label.upper()}')\n    #image 1\n    img1=os.path.join(train_dir,img_ids['X_ray_image_name'].iloc[0])\n    img1=load_img(img1)\n    ax[0].imshow(img1)\n    \n    #image 2\n    img2=os.path.join(train_dir,img_ids['X_ray_image_name'].iloc[1])\n    img2=load_img(img2)\n    ax[1].imshow(img2)\n    \n    plt.tight_layout()\n    plt.title(f'{label}')\n    plt.show()\n    \nshow_sample_image(data,label='COVID-19')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_sample_image(data,label='COVID-19')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_sample_image(data,label='ARDS')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_sample_image(data,label='SARS')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# type\n\nplt.figure(figsize=(16,8))\nsns.countplot(data['Label'])\nplt.xlabel('Class')\nplt.xticks(rotation=30)\nplt.title('Class balance')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Setting variables and random seed**","metadata":{}},{"cell_type":"code","source":"img_size=(256,256)\nbatch_size=64\n\n#setting seed \ndef set_seed(seed):\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['PYTHONHASHSEED']=str(seed)\nset_seed(7)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Loading Images with Image Data generator**","metadata":{}},{"cell_type":"code","source":"#train_test_split\ntrain_df,valid_df=tts(data,test_size=0.1,random_state=7,stratify=data['Label'])\n    \ndef load_data(df):\n    #Image data generator :\n    \n#     train_set\n    train_gen=ImageDataGenerator(\n    width_shift_range=(0.1,0.2),\n    height_shift_range=(0.1,0.2),\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    vertical_flip=True,\n    fill_mode='nearest',\n    rescale=1./255)\n\n#     val_set\n    val_gen=ImageDataGenerator(rescale=1./255)\n    \n    #load_data\n    train=train_gen.flow_from_dataframe(dataframe=train_df,\n                                         directory=train_dir,\n                                         x_col='X_ray_image_name' ,\n                                         y_col='Label'  ,\n                                         target_size=img_size,\n                                         batch_size=batch_size,\n                                         class_mode='binary',\n                                         shuffle=True,\n                                         seed=7)\n    \n    val=val_gen.flow_from_dataframe(dataframe=valid_df,\n                                         directory=train_dir,\n                                         x_col='X_ray_image_name' ,\n                                         y_col='Label'  ,\n                                         target_size=img_size,\n                                         batch_size=batch_size,\n                                         class_mode='binary',\n                                         shuffle=True,\n                                         seed=7)\n    \n    return train,val\n\ntrain,val=load_data(data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Because there is heavy imbalance in target,I will use class weights argument in model training**","metadata":{}},{"cell_type":"code","source":"def class_weights(df,target_column):\n    '''Calculates target class weights to be used in case of imbalanced data. '''\n    \n    from sklearn.utils.class_weight import compute_class_weight\n    \n    return compute_class_weight('balanced',df[target_column].unique(),df[target_column])\n\n\n#compute class weights:\nweights=class_weights(train_df,'Label')\nweights={0:weights[0],1:weights[1]}\nprint(weights)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building Models","metadata":{}},{"cell_type":"code","source":"# Using efficientnet as base layer:\nbase=EfficientNetB7(weights='imagenet',include_top=False,)\nset_trainable=False\n    \n#freezing all layers before 'block7c_project_conv'\n\nfor layer in base.layers:\n    if layer.name == 'block7c_project_conv':\n        set_trainable=True\n    if set_trainable:\n        layer.trainable=True\n    else:\n        layer.trainable=False\n\n\ndef effnet(dense,dropout):  \n    inp=layers.Input(shape=(256,256,3))\n    #base layer\n    x=base(inp)\n    x=layers.MaxPooling2D()(x)\n    x=layers.Dropout(0.3)(x)\n    \n    #flatten output:\n    x=layers.Flatten()(x)\n        \n    for i in range(len(dense)):\n        x=layers.BatchNormalization()(x)\n        x=layers.Dense(dense[i],activation='relu')(x)\n        x=layers.Dropout(rate=drop[i])(x)\n    \n    x=layers.BatchNormalization()(x)\n    output=layers.Dense(1,activation='softmax')(x)\n    \n    #model\n    model=Model(inputs=inp,outputs=output)\n    \n    return model\n\n\n# plotting history:\ndef plot_history(history):\n    his=pd.DataFrame(history.history)\n    plt.style.use('Solarize_Light2')\n    plt.subplots(1,2,figsize=(16,8))\n    \n    #loss:\n    plt.subplot(1,2,1)\n    plt.plot(range(len(his)),his['loss'],color='g',label='training')\n    plt.plot(range(len(his)),his['val_loss'],color='r',label='validation')\n    plt.legend()\n    plt.title('Loss')\n    \n    #accuracy and AUC:\n    plt.subplot(1,2,2)\n#     plt.plot(range(len(his)),his['auc'],color='g',label='training')\n#     plt.plot(range(len(his)),his['val_auc'],color='r',label='validation')\n    \n    plt.plot(range(len(his)),his['accuracy'],color='steelblue',label='training')\n    plt.plot(range(len(his)),his['val_accuracy'],color='maroon',label='validation')\n    \n    \n    plt.legend()\n    plt.title('Accuracy')\n    \n\n    plt.show()                ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model2 EfficientNet B0 base:\ndense=[64]                # dense layers \ndrop=[0.5]                #dropout probabilities\nepochs2=30\n\n#model2\nmodel2=effnet(dense,drop)\n\n#compiling model:\n\nmodel2.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\n#reduce learning rate \nreduce_lr=ReduceLROnPlateau(patience=1,monitor='val_accuracy',\n                            factor=0.5,min_delta=1e-2,\n                            min_lr=1e-8,mode='max')\n\n#Early stopping:\nearly_stopping=EarlyStopping(min_delta=1e-3,patience=5,monitor='val_accuracy',\n                             mode='max',restore_best_weights=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model fitting:\n\nhistory2=model2.fit(train,validation_data=val,epochs=epochs2,class_weight=weights,\n                    steps_per_epoch=train.n//batch_size,validation_steps=val.n//batch_size,\n                    callbacks=[reduce_lr,early_stopping],verbose=0)\n\n#plotting learning curve:\n\nplot_history(history2)","metadata":{},"execution_count":null,"outputs":[]}]}