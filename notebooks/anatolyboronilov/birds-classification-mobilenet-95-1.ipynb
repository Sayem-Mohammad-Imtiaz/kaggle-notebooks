{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-02T14:19:01.3103Z","iopub.execute_input":"2021-09-02T14:19:01.310706Z","iopub.status.idle":"2021-09-02T14:19:46.178822Z","shell.execute_reply.started":"2021-09-02T14:19:01.310616Z","shell.execute_reply":"2021-09-02T14:19:46.177998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport matplotlib.pyplot as plt\nfrom IPython.display import Image, display\nimport random\nimport math\n\nimport tensorflow as tf\nfrom keras.preprocessing.image import load_img,img_to_array,ImageDataGenerator\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.utils import plot_model \nfrom tensorflow.keras.layers import Input, Dense, Dropout, Flatten, Activation,Concatenate\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.utils import to_categorical \nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\nfrom tensorflow.keras import backend, models\nfrom sklearn.metrics import confusion_matrix\n\nfrom tensorflow.keras.applications import VGG16, MobileNet\nfrom keras.applications.vgg16 import preprocess_input","metadata":{"execution":{"iopub.status.busy":"2021-09-02T14:19:46.180304Z","iopub.execute_input":"2021-09-02T14:19:46.180658Z","iopub.status.idle":"2021-09-02T14:19:51.186132Z","shell.execute_reply.started":"2021-09-02T14:19:46.18062Z","shell.execute_reply":"2021-09-02T14:19:51.185301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****Let's create Tenosrflow datasets****","metadata":{}},{"cell_type":"code","source":"image_size = (224, 224)\n\ntrain_path = '../input/100-bird-species/birds/train'\nvalid_path = '../input/100-bird-species/birds/valid'\ntest_path = '../input/100-bird-species/birds/test'","metadata":{"execution":{"iopub.status.busy":"2021-09-02T14:19:51.187952Z","iopub.execute_input":"2021-09-02T14:19:51.188283Z","iopub.status.idle":"2021-09-02T14:19:51.1948Z","shell.execute_reply.started":"2021-09-02T14:19:51.188247Z","shell.execute_reply":"2021-09-02T14:19:51.193977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will use diffirent Image Generators because we want to apply Data Augmentation techniques only to training dataset. This techniques are used in order to decrease overfiting of neural networks","metadata":{}},{"cell_type":"code","source":"default_datagen = ImageDataGenerator(rescale=1./255)","metadata":{"execution":{"iopub.status.busy":"2021-09-02T14:19:51.196304Z","iopub.execute_input":"2021-09-02T14:19:51.196678Z","iopub.status.idle":"2021-09-02T14:19:51.208345Z","shell.execute_reply.started":"2021-09-02T14:19:51.196644Z","shell.execute_reply":"2021-09-02T14:19:51.207553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"augmentation_datagen = ImageDataGenerator(rescale=1./255, \n                                          rotation_range=20,\n                                          width_shift_range=0.2,\n                                          height_shift_range=0.2,\n                                          zoom_range=0.2,\n                                          horizontal_flip=True,\n                                          fill_mode='nearest') ","metadata":{"execution":{"iopub.status.busy":"2021-09-02T14:19:51.20974Z","iopub.execute_input":"2021-09-02T14:19:51.210128Z","iopub.status.idle":"2021-09-02T14:19:51.218234Z","shell.execute_reply.started":"2021-09-02T14:19:51.210091Z","shell.execute_reply":"2021-09-02T14:19:51.217555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = augmentation_datagen.flow_from_directory(train_path,\n                                                      target_size=image_size)","metadata":{"execution":{"iopub.status.busy":"2021-09-02T14:19:51.219424Z","iopub.execute_input":"2021-09-02T14:19:51.219829Z","iopub.status.idle":"2021-09-02T14:19:53.490087Z","shell.execute_reply.started":"2021-09-02T14:19:51.219792Z","shell.execute_reply":"2021-09-02T14:19:53.489238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_data = default_datagen.flow_from_directory(valid_path,\n                                                      target_size=image_size)","metadata":{"execution":{"iopub.status.busy":"2021-09-02T14:19:53.491271Z","iopub.execute_input":"2021-09-02T14:19:53.491656Z","iopub.status.idle":"2021-09-02T14:19:53.693504Z","shell.execute_reply.started":"2021-09-02T14:19:53.491612Z","shell.execute_reply":"2021-09-02T14:19:53.692488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = default_datagen.flow_from_directory(test_path, \n                                                target_size=image_size)","metadata":{"execution":{"iopub.status.busy":"2021-09-02T14:19:53.695872Z","iopub.execute_input":"2021-09-02T14:19:53.696366Z","iopub.status.idle":"2021-09-02T14:19:53.897569Z","shell.execute_reply.started":"2021-09-02T14:19:53.696328Z","shell.execute_reply":"2021-09-02T14:19:53.896742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's have a look at and some random bird's species and their bird species bird species photos","metadata":{}},{"cell_type":"code","source":"train_dataset = tf.keras.preprocessing.image_dataset_from_directory(train_path)\nclass_names = train_dataset.class_names\n\nplt.figure(figsize=(12, 12))\nfor images, labels in train_dataset.take(1):\n  for i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(images[i].numpy().astype(\"uint8\"))\n    plt.title(class_names[labels[i]])\n    plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2021-09-02T14:19:53.899064Z","iopub.execute_input":"2021-09-02T14:19:53.899423Z","iopub.status.idle":"2021-09-02T14:20:00.781318Z","shell.execute_reply.started":"2021-09-02T14:19:53.899387Z","shell.execute_reply":"2021-09-02T14:20:00.780574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****Now we will use a base model with weights pretrained on Imagenet****","metadata":{}},{"cell_type":"code","source":"base_mobilenet = MobileNet(weights = 'imagenet',\n                           include_top = False,\n                           input_shape = (224,224,3))","metadata":{"execution":{"iopub.status.busy":"2021-09-02T14:20:00.782436Z","iopub.execute_input":"2021-09-02T14:20:00.782874Z","iopub.status.idle":"2021-09-02T14:20:01.655019Z","shell.execute_reply.started":"2021-09-02T14:20:00.78284Z","shell.execute_reply":"2021-09-02T14:20:01.65414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's freeze the weights of our base model","metadata":{}},{"cell_type":"code","source":"base_mobilenet.trainable = False ","metadata":{"execution":{"iopub.status.busy":"2021-09-02T14:20:01.656464Z","iopub.execute_input":"2021-09-02T14:20:01.656834Z","iopub.status.idle":"2021-09-02T14:20:01.664594Z","shell.execute_reply.started":"2021-09-02T14:20:01.656795Z","shell.execute_reply":"2021-09-02T14:20:01.663256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\n# We add the base model as a new layer\nmodel.add(base_mobilenet)\nmodel.add(Flatten()) \nmodel.add(Activation('relu'))\n# 275 - number of classes\nmodel.add(Dense(275)) \nmodel.add(Activation('softmax'))","metadata":{"execution":{"iopub.status.busy":"2021-09-02T14:20:01.666054Z","iopub.execute_input":"2021-09-02T14:20:01.666445Z","iopub.status.idle":"2021-09-02T14:20:01.856491Z","shell.execute_reply.started":"2021-09-02T14:20:01.666409Z","shell.execute_reply":"2021-09-02T14:20:01.855679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let's check the updated model summary. You can see the new layers from below. This layers add 13.8 million of new parametrs to train.","metadata":{}},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-09-02T14:20:01.857628Z","iopub.execute_input":"2021-09-02T14:20:01.857938Z","iopub.status.idle":"2021-09-02T14:20:01.872109Z","shell.execute_reply.started":"2021-09-02T14:20:01.857908Z","shell.execute_reply":"2021-09-02T14:20:01.871183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we want our learning rate to be adaptive\nopt = tf.keras.optimizers.SGD(lr=0.001,\n                              momentum=0.6,\n                              nesterov=True)\n\nmodel.compile(optimizer = opt,\n              loss = 'categorical_crossentropy',\n              metrics = ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-09-02T14:20:01.873327Z","iopub.execute_input":"2021-09-02T14:20:01.873988Z","iopub.status.idle":"2021-09-02T14:20:01.892989Z","shell.execute_reply.started":"2021-09-02T14:20:01.873949Z","shell.execute_reply":"2021-09-02T14:20:01.892269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    train_data, \n    steps_per_epoch = 600, \n    epochs = 12,\n    validation_data = validation_data,\n    validation_steps = 32,\n    verbose = 1,\n    callbacks=[EarlyStopping(monitor='val_accuracy',\n                             patience=3,\n                             restore_best_weights=True),\n               ReduceLROnPlateau(monitor='val_loss',\n                                 factor=0.7,\n                                 patience=2,\n                                 verbose=1)]\n) ","metadata":{"execution":{"iopub.status.busy":"2021-09-02T14:20:01.894088Z","iopub.execute_input":"2021-09-02T14:20:01.894431Z","iopub.status.idle":"2021-09-02T15:03:13.710715Z","shell.execute_reply.started":"2021-09-02T14:20:01.894396Z","shell.execute_reply":"2021-09-02T15:03:13.709786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The time of fiting was long enough but the validation accuracy was worth it","metadata":{}},{"cell_type":"code","source":"model.evaluate(test_data)","metadata":{"execution":{"iopub.status.busy":"2021-09-02T15:03:13.714211Z","iopub.execute_input":"2021-09-02T15:03:13.714481Z","iopub.status.idle":"2021-09-02T15:03:25.1229Z","shell.execute_reply.started":"2021-09-02T15:03:13.714453Z","shell.execute_reply":"2021-09-02T15:03:25.122134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy **94.4%** on test data is a high result. Given the fact that this neural network is the first in my life, I guess I've got the right be glad. If someone has feedback or some pieces of advice I'll be glad to hear from you","metadata":{}}]}