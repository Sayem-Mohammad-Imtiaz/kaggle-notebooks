{"cells":[{"metadata":{"_uuid":"bbe11d41356cc42aaa7930c0b2c2a8613bdf3c6b"},"cell_type":"markdown","source":"__Customer Churn using Telco Dataset__"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"# Libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8b3b99fa9d81a4313b26fcd1d08204069e0330eb"},"cell_type":"markdown","source":"The dataset contains the information of 7042 Customers and their churn value."},{"metadata":{"trusted":true,"_uuid":"9111cd5c1ac2949b664c1a46c734d1fa8828cd6d","_kg_hide-input":true,"scrolled":false},"cell_type":"code","source":"# The dataset contains the information of 7042 Customers and their churn value.\ndata = pd.read_csv('../input/WA_Fn-UseC_-Telco-Customer-Churn.csv')\ndata = data.drop(['customerID'], axis=1)\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a62ef2defb06519f85c2b97ad872bc4f652f7100","_kg_hide-input":true},"cell_type":"code","source":"# list(data)\ncategorical = [#'customerID',\n 'gender',\n 'SeniorCitizen',\n 'Partner',\n 'Dependents',\n #'tenure',\n 'PhoneService',\n 'MultipleLines',\n 'InternetService',\n 'OnlineSecurity',\n 'OnlineBackup',\n 'DeviceProtection',\n 'TechSupport',\n 'StreamingTV',\n 'StreamingMovies',\n 'Contract',\n 'PaperlessBilling',\n 'PaymentMethod',\n #'MonthlyCharges',\n #'TotalCharges',\n #'Churn'\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5f9b8c9d9df29bf00b7803eb07eea0e9258f4112"},"cell_type":"code","source":"# Churn summary\nprint(data.groupby('Churn').Churn.count())","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":false,"_kg_hide-input":true,"trusted":true,"_uuid":"f9fb407fdea60f4e3d1d565551c710d018f21a23"},"cell_type":"code","source":"data.SeniorCitizen = ['Yes' if sc == 1 else 'No' for sc in data.SeniorCitizen]\ndata.Churn = [1 if c == 'Yes' else 0 for c in data.Churn]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"38e731d83f36b28d5c70b9b32205e8711d12d400"},"cell_type":"markdown","source":"A first look into the disparity in churn rates for different categories in the data."},{"metadata":{"trusted":true,"_uuid":"17844a804d265e7190ee0c5b1b909972ae051c4a","_kg_hide-input":true,"_kg_hide-output":false},"cell_type":"code","source":"def perc(x):\n    return str(round(100*x,1))+'%'\nfig=plt.figure(figsize=(16,15))\nfig.suptitle('Churn rate by category',fontsize='x-large')\nfor i in range(0,len(categorical)):\n    category = categorical[i]\n    ax = fig.add_subplot(4,4,i+1)\n    group_churn = data.groupby(category).Churn.mean()\n    k = group_churn.keys()\n    v = group_churn.values\n    v2 = v/np.sum(v)\n    left = np.cumsum(v2)\n    plt.barh([1],v2[0],height=0.2,label=k[0]+': '+perc(v[0]))\n    for j in range(1,len(v)):\n        plt.barh([1],v2[j],left=left[j-1],height=0.2,label=k[j]+': '+perc(v[j]))\n    plt.ylim([0.4,1.6])\n    plt.xlim(-0.1,1.1)\n    plt.axis('off')\n    plt.legend()\n    plt.title(category)\nfig=plt.figure(figsize=(16,15))\nfig.suptitle('Disparities in Churn rates for each category',fontsize='x-large')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"02cb3e2cb593901bb0b45be5bebc6ae764d0d42f","_kg_hide-input":true},"cell_type":"code","source":"# Preprocessing and Dummy variables\n\ndata.TotalCharges = [0 if tc==' ' else float(tc) for tc in data.TotalCharges]\ndata = pd.get_dummies(data,columns=categorical, drop_first=True)\n\n# Dependent and Independent variables\nX = data.values\ny = data.Churn.values\n\n# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nscale = StandardScaler()\nX = scale.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1d7cc89270a08d276f94bfe902df400cc4f1942d"},"cell_type":"markdown","source":"__KNN with 2 Clusters__\n\nThe relation between the information for each customer can be visualised more easily after applying PCA. Doing so shows clearly separable clusters, with markedly different churn rates. "},{"metadata":{"trusted":true,"_uuid":"76b7a607d26ec6327c843917dc3a8bb6495f5d90","_kg_hide-input":true},"cell_type":"code","source":"from sklearn.decomposition import KernelPCA\nkpca=KernelPCA(n_components = 2,kernel = 'rbf')\nXpca = kpca.fit_transform(X)\n\nfrom sklearn.cluster import KMeans\nclusters = 2\nkmeans = KMeans(n_clusters = clusters,init = 'k-means++',max_iter=300,n_init=10,random_state=0)\ny_kmeans = kmeans.fit_predict(X)\ndata['Clusters'] = y_kmeans\n\nmean_values = data.groupby('Clusters')['Churn'].mean().values\nrate = [str(round(100*mean_values.min(),1))+'%',str(round(100*mean_values.max(),1))+'%']\ncolors = ['skyblue','tomato']\nif mean_values[0]>mean_values[1]:\n    colors = colors[::-1]\n    rate = rate[::1]\n    \nplt.rcParams['axes.facecolor'] = 'whitesmoke'\nplt.figure(figsize=(12,6))\n\nplt.subplot(1,2,1)\nplt.scatter(Xpca[data.Clusters==0][:,0],Xpca[data.Clusters==0][:,1],marker='.',color=colors[0],label='Churn rate = '+rate[0])\nplt.scatter(Xpca[data.Clusters==1][:,0],Xpca[data.Clusters==1][:,1],marker='.',color=colors[1],label='Churn rate = '+rate[1])\nplt.legend()\nplt.title('Churn by Cluster')\nplt.xlabel('PCA component 1')\nplt.ylabel('PCA component 2')\nplt.axis('equal')\n\nplt.subplot(1,2,2)\nplt.title('Cluster Size')\nplt.pie(data.groupby('Clusters')['Clusters'].count().values,colors = colors,autopct='%1.1f%%')\nplt.axis('equal')\nplt.show()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e26ab009953b79f9820a2d291492ba588444dff8"},"cell_type":"markdown","source":"__KNN with 5 Clusters__\n\nA better result can be achieved by breaking the customers into 5 groups, one of which has a significantly higher churn risk."},{"metadata":{"trusted":true,"_uuid":"fe203c73bc5ce37df50402c61d20155d151e8bb1","_kg_hide-input":true},"cell_type":"code","source":"clusters = 5\nkmeans = KMeans(n_clusters = clusters,init = 'k-means++',max_iter=300,n_init=10,random_state=0)\ny_kmeans = kmeans.fit_predict(X)\ndata['Clusters'] = y_kmeans\n\nX = scale.inverse_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"62106920c6aa7af13b8782f7366b626f42187d21","_kg_hide-input":true},"cell_type":"code","source":"plt.rcParams['axes.facecolor'] = 'silver'\nplt.figure(figsize=(12,6))\nplt.subplot(1,2,1)\n\ncolors = ['beige','palegoldenrod','orange','orangered','firebrick']\n\nmean_values = data.groupby('Clusters')['Churn'].mean().values\nrisk_sort = np.argsort(data.groupby('Clusters')['Churn'].mean().values)\n\nplt.bar(x=np.arange(0,clusters),height = (mean_values)[risk_sort],color= colors)\nplt.plot(np.arange(-1,clusters+1),np.full(clusters+2,data.Churn.mean()),'k--',label='Average Churn')\nplt.xlim([-.75,clusters-0.25])\nplt.tick_params(axis='x',which='both',bottom=False,top=False,labelbottom=False)\nplt.gca().set_yticklabels(['{:.0f}%'.format(x*100) for x in plt.gca().get_yticks()])\nplt.xlabel('Customer Clusters')\nplt.ylabel('Churn rate')\nplt.title('Churn by Cluster')\nplt.legend()\n\nplt.subplot(1,2,2)\nplt.title('Cluster Size')\nplt.pie(data.groupby('Clusters')['Clusters'].count().values[risk_sort],autopct='%1.1f%%',colors = colors)\nplt.axis('equal')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"12a5b5295354c997f0bce559be7d372a9b55afe6","_kg_hide-input":true,"scrolled":true},"cell_type":"code","source":"print('Risk Cluster size:\\t\\t',str(round(100*data.groupby('Clusters')['Churn'].count().values.max()/len(data),1))+'%')\nprint('Risk Cluster churn rate:\\t',str(round(100*mean_values.max(),1))+'%')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"de84a9adad45e73998d97680de37e9f62ef553de"},"cell_type":"markdown","source":"__Preditive Models__\n\n__Random Forest Classifier__"},{"metadata":{"trusted":true,"_uuid":"48be4992597b83724e3844bd57b0864dc327e00e"},"cell_type":"code","source":"# Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX = data.drop(columns=['Churn','Clusters']).values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)\n\n# RF Classifier\nfrom sklearn.ensemble import RandomForestClassifier\nrf_model = RandomForestClassifier(n_estimators=200)\nrf_model.fit(X_train,y_train)\n\n# Prediciton\ny_pred = rf_model.predict(X_test)\n\n# Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test,y_pred)\n\nprint('Model:\\t\\t\\tRandom Forest Classification')\nprint('Test Set Accuracy:\\t' ,str(round(100*np.trace(cm)/np.sum(cm),1))+'%')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"37adfeb8966cd8344e7783adee826763f4c3fd0e"},"cell_type":"markdown","source":"__XGBoost Classifier__"},{"metadata":{"trusted":true,"_uuid":"bcd3d4efed2872712a8eb9a725cf39421f0ebbb3"},"cell_type":"code","source":"# XGBoost Classifier\nfrom xgboost import XGBClassifier\nxgb_model = XGBClassifier()\nxgb_model.fit(X_train,y_train)\n\n# Prediciton\ny_pred = xgb_model.predict(X_test)\n\n# Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test,y_pred)\n\nprint('Model:\\t\\t\\tXGBoost Classification')\nprint('Test Set Accuracy:\\t' ,str(round(100*np.trace(cm)/np.sum(cm),1))+'%')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ee8ed9b64bd48e9fc5e0d2c34d5c9048f3ff5ad5"},"cell_type":"markdown","source":"__Artifical Neural Network Classifier__"},{"metadata":{"trusted":true,"_uuid":"d5582ff87514d1c2fe5c78b3c632bfdacfec5ea7"},"cell_type":"code","source":"# Scaling\nX_train = scale.fit_transform(X_train)\nX_test = scale.transform(X_test)\n\n# Creating the ANN\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nann_model = Sequential()\nann_model.add(Dense(activation=\"relu\", input_dim=30, units=15, kernel_initializer=\"uniform\"))\nann_model.add(Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\"))\nann_model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\nann_model.fit(X_train,y_train,batch_size=10,epochs=5)\n\n# Prediction\ny_pred = ann_model.predict(X_test) > 0.5\n\n# Confusion Matrix\ncm = confusion_matrix(y_test,y_pred)\n\nprint('\\nModel:\\t\\t\\tANN Classification')\nprint('Test Set Accuracy:\\t' ,str(round(100*np.trace(cm)/np.sum(cm),1))+'%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"59703031ff8f5cd98fd0810985784df9d2582c31"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}