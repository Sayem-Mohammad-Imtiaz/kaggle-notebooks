{"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.1","pygments_lexer":"ipython3","file_extension":".py","mimetype":"text/x-python","nbconvert_exporter":"python"},"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"}},"nbformat_minor":1,"cells":[{"source":"IIn this **breast cancer analysis** (using Wisconsin Diagnostic data), I have done **visual Exploratory data analysis** to understand the features that are good for classification for Malignant and Benign types of cancer, using **Random Forest Classifier** to predict the outcomes and determine the feature importances. ","metadata":{"_cell_guid":"12bd13ab-1e80-466a-82e7-b0932aba356e","_uuid":"86290a90699f1c6faa24959ae7867e1264bf1ff5"},"cell_type":"markdown"},{"source":"**Importing the necessary packages and reading the CSV File**","metadata":{"_cell_guid":"7db3fac9-3625-4209-abb2-107a6a06ed3a","_uuid":"17a95b74914afd27019872d81361e70c374d4484"},"cell_type":"markdown"},{"source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ncancer = pd.read_csv(\"../input/data.csv\")\ncancer.head()","metadata":{"scrolled":true,"_cell_guid":"1d302b6b-e7c8-45ab-9d1a-dc297ce56fe6","_uuid":"2dcca47c575ee3c36a41e86dc3c7c42a3d129617"},"execution_count":null,"cell_type":"code","outputs":[]},{"source":"**features overview**","metadata":{"_cell_guid":"9ab1f8cd-9c57-4be6-ae96-d85cac1f1e6b","_uuid":"6076495e4677a7950ff782d5b733cbe6cf08804a"},"cell_type":"markdown"},{"source":"1. ID - unique identification\n2. diagnosis - two values M-'Malignant' B-'Benign\n3. radius - mean of distances from center to points on the perimeter\n4. texture - standard deviation of gray-scale values\n5. perimeter\n6. area \n7. smoothness - local variation in radius lengths\n8. compactness - perimeter^2 / area - 1.0\n9. concavity - severity of concave portions of the contour\n10. concave points - number of concave portions of the contour\n11. symmetry\n12. fractal dimension - (coastline approximation) - 1","metadata":{"_cell_guid":"716891c1-e6ba-4f68-8d29-6f44d642d577","_uuid":"fcfd2cfe82800cd2db75e77ebfae7987c8cb6c86"},"cell_type":"markdown"},{"source":"**Basic Quantitative EDA** to get the count of the features, mean and other basic values to understand the data in a better way:","metadata":{"_cell_guid":"f6975ca0-48c0-45dd-87ac-836e9cae63b2","_uuid":"9e4adab134122fc6d84da6b6462a658864cdf5c3"},"cell_type":"markdown"},{"source":"cancer.describe()","metadata":{"scrolled":true,"_cell_guid":"e875f255-3f6c-4ef1-b7ad-91b6d5003212","_uuid":"ab93ebbbd685e36f5b7977db100ace676f59f246"},"execution_count":null,"cell_type":"code","outputs":[]},{"source":"We can see that **Unnamed:32** and **id** are of no use, and may interfere with our model in an improper manner, so we can drop these columns from our dataframe.","metadata":{"_cell_guid":"0e19304a-091e-4404-bd44-190ec8620364","_uuid":"41103c308c3eb9405dc5a86303dbc141722b6d6e"},"cell_type":"markdown"},{"source":"cancer.drop(['id','Unnamed: 32'], axis=1, inplace=True)\ncancer.columns","metadata":{"_cell_guid":"0632de0a-0d8d-4e31-9d97-b2f744978a07","_uuid":"7e5ca6f2409a6c1d96e194159e83fd31c5e42370"},"execution_count":null,"cell_type":"code","outputs":[]},{"source":"**checking for missing values** ","metadata":{"_cell_guid":"a79dbfb5-e807-4552-ad22-9fdc331126df","_uuid":"3982369f7dd83e49d6a9efdb1c16ebf6893de845"},"cell_type":"markdown"},{"source":"cancer.isnull().sum().sort_values(ascending=False)","metadata":{"_cell_guid":"b68ed7ea-78a8-45b3-9636-a8affa0d32dc","_uuid":"5fbbe430a083d5f90840758fc4ad628089d1ce80"},"execution_count":null,"cell_type":"code","outputs":[]},{"source":"From above. it can be concluded that there are **no missing values** in the dataframe, and we can begin working with the data now:","metadata":{"_cell_guid":"14e7dd65-58f0-4fe3-a537-f6432c1dd0df","_uuid":"8bdb1f98d6d053dca7b41b06602a050271eb530e"},"cell_type":"markdown"},{"source":"print('counts of Malignant and Benign \\n',cancer['diagnosis'].value_counts())\nsns.countplot(cancer['diagnosis'],palette=\"Blues\")\nplt.title('Distribution of Malignant & Benign')","metadata":{"_cell_guid":"375c6d7e-b8bc-4d09-bfd8-07bddc4c9cfa","_uuid":"735cb2bb6efa511c4676a6550cdc81340c7aacc3"},"execution_count":null,"cell_type":"code","outputs":[]},{"source":"Now, we split all the features according to **mean, standard error and worst** into different dataframes","metadata":{"_cell_guid":"2236a716-70f5-474d-b0c7-dba8cd5c29dd","_uuid":"9f12271643e716e8a4d037cfe125ecedb29c5fb9"},"cell_type":"markdown"},{"source":"features_mean = cancer[['diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean']]\nfeatures_se = cancer[['diagnosis','radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n       'fractal_dimension_se']]\nfeatures_worst = cancer[['diagnosis','radius_worst', 'texture_worst','perimeter_worst', 'area_worst', \n'smoothness_worst','compactness_worst', 'concavity_worst', 'concave points_worst','symmetry_worst',\n                   'fractal_dimension_worst']]","metadata":{"collapsed":true,"_cell_guid":"9c12cddf-84ba-4fc7-aa17-dfc02beef6f0","_uuid":"8e40d83054405a8fad071fffae4c225dc6cf1be0"},"execution_count":null,"cell_type":"code","outputs":[]},{"source":"**Visualisation**\n\nVisualising features for mean, standard error and worst types of features to understand the correlation between them and the distribution for classification of Malignant and Bengin types of cancer.","metadata":{"_cell_guid":"f28d99f9-eb5c-4e3f-9d25-d02150516175","_uuid":"99a47a4b6002b211b27bc338ad6b88268d949283"},"cell_type":"markdown"},{"source":"**Visualising fetaures for mean values**","metadata":{"_cell_guid":"12be00b3-8c0d-4f33-8c00-c1f21f44790e","_uuid":"c4730384752cf957a9b58bd38271a2dcfdee704f"},"cell_type":"markdown"},{"source":"mean_correlation = features_mean.corr()\nplt.figure(figsize=(8,8))\nsns.heatmap(mean_correlation,vmax=1,square=True,annot=True,cmap='Greens')","metadata":{"scrolled":true,"_cell_guid":"6058d962-2475-4e73-b3db-082cc86ad5da","_uuid":"2e256b915a45d9aab700af44160037141d392730"},"execution_count":null,"cell_type":"code","outputs":[]},{"source":"From the above **Heat map of mean values**  it can be concluded that **area_mean,perimeter_mean and radius_mean have correlation with each other** therefore one best feature can be used from them to predict and similar with **compactness_mean,concave points_mean and concavity_mean.**","metadata":{"_cell_guid":"1136d6e0-3bae-4be4-9da5-92dceddd7c38","_uuid":"8f747872e910b0dc45fe7b8cd58b39266ed6476f"},"cell_type":"markdown"},{"source":"plt.subplot(221)\nsns.violinplot(x='diagnosis',y='texture_mean',data=features_mean,palette=\"Greens\",inner=\"quartile\")\nplt.subplot(222)\nsns.violinplot(x='diagnosis',y='concavity_mean',data=features_mean,palette=\"Greens\",inner=\"quartile\")\nplt.subplot(223)\nsns.violinplot(x='diagnosis',y='radius_mean',data=features_mean,palette=\"Greens\",inner=\"quartile\")\nplt.subplot(224)\nsns.violinplot(x='diagnosis',y='fractal_dimension_mean',data=features_mean,palette=\"Greens\",inner=\"quartile\")\nplt.show()","metadata":{"scrolled":true,"_cell_guid":"e4ae24a3-bdae-464d-a11f-d10e6ca59b6f","_uuid":"3da1396aa75a44b6f5b9d80ee7714b003db67a63"},"execution_count":null,"cell_type":"code","outputs":[]},{"source":"From above **violin plots**, we find out that **texture_mean and concavity_mean** are good features for classification as they segregate better Malignant and Benign types but **fractal_dimension_mean**, one of the features, has almost a similar mean and a similar distribution, and hence is not a good parameter for classification.","metadata":{"_cell_guid":"3e479a80-5221-4f62-bd9f-aea2391926f4","_uuid":"8c8b90f5cd1617e78147f3e1bf326f94ea0b0f3e"},"cell_type":"markdown"},{"source":"**Visualising features for standard error values**","metadata":{"_cell_guid":"6a815db3-f6b2-4cf9-a98b-3e931aa3737a","_uuid":"66a008f0fead9a8012efa8fe0d7e4e1192e360fc"},"cell_type":"markdown"},{"source":"se_correlation = features_se.corr()\nplt.figure(figsize=(8,8))\nsns.heatmap(se_correlation,vmax=1,square=True,annot=True,cmap='Oranges')","metadata":{"_cell_guid":"64241885-4c2f-47da-9d3d-6c26d894e010","_uuid":"50b71c8521f6c61b4c23104f7670c93356a9b5a7"},"execution_count":null,"cell_type":"code","outputs":[]},{"source":"From the above **Heatmap** of the **standard error values**  it can be concluded that **area_se,perimeter_se and radius_se have correlation with each other**, which is also the case with **compactness_se,concave points_se and concavity_se.** and hence, one best feature can be used from them for further classification during prediction.  ","metadata":{"_cell_guid":"92b5ca87-29f3-4c6c-b57c-db1598e5f641","_uuid":"bd33f72b4d245a67e2aa19e37b1d42f1fb3683b7"},"cell_type":"markdown"},{"source":"plt.subplot(221)\nsns.violinplot(x='diagnosis',y='texture_se',data=features_se,palette=\"Oranges\",inner=\"quartile\")\nplt.subplot(222)\nsns.violinplot(x='diagnosis',y='concavity_se',data=features_se,palette=\"Oranges\",inner=\"quartile\")\nplt.subplot(223)\nsns.violinplot(x='diagnosis',y='radius_se',data=features_se,palette=\"Oranges\",inner=\"quartile\")\nplt.subplot(224)\nsns.violinplot(x='diagnosis',y='fractal_dimension_se',data=features_se,palette=\"Oranges\",inner=\"quartile\")\nplt.show()","metadata":{"_cell_guid":"3eecd4f1-3697-4983-b185-777a91fd5737","_uuid":"d8019aacb3e28268ffc14acd4d692abe1fc8951e"},"execution_count":null,"cell_type":"code","outputs":[]},{"source":"From above **violin plots , radius_se and concavity_se** are good features for classification as they segregate better Malignant and Benign types but **fractal_dimension_mean** has same mean and similar pattern for classification, and hence is not a good parameter to do so.","metadata":{"_cell_guid":"e423b078-914a-489e-823c-af77724d5cad","_uuid":"209dc8763f9949c8c23af012d2276f03781b11a5"},"cell_type":"markdown"},{"source":"**Visualising features for worst values**","metadata":{"_cell_guid":"a3f4ad3d-ec2f-4aff-b58b-8e475a98afec","_uuid":"4f589606f0bc0a3b00336e9e59c2b5e350665353"},"cell_type":"markdown"},{"source":"worst_correlation = features_worst.corr()\nplt.figure(figsize=(8,8))\nsns.heatmap(worst_correlation,vmax=1,square=True,annot=True,cmap='Reds')","metadata":{"scrolled":true,"_cell_guid":"63db0d69-47fe-4808-acc9-c4f42427ad38","_uuid":"a39bd77d2c37735b85a4a2e3107811f9ff7d181b"},"execution_count":null,"cell_type":"code","outputs":[]},{"source":"Similarly in the **Heatmap of worst values area, radius and perimeter**, we find out that they are intercorrelated with each other. A similar case arises with **compactness_worst, concavity_worst,concave points_worst**. This means that we can use one from each of the sets.","metadata":{"_cell_guid":"794d5153-ebf5-49e3-8c11-0315f4fc1755","_uuid":"d76d7b679dbd06516e733881d94e94c850e79d3d"},"cell_type":"markdown"},{"source":"plt.subplot(221)\nsns.violinplot(x='diagnosis',y='texture_worst',data=features_worst,palette=\"Reds\",inner=\"quartile\")\nplt.subplot(222)\nsns.violinplot(x='diagnosis',y='smoothness_worst',data=features_worst,palette=\"Reds\",inner=\"quartile\")\nplt.subplot(223)\nsns.violinplot(x='diagnosis',y='concavity_worst',data=features_worst,palette=\"Reds\",inner=\"quartile\")\nplt.subplot(224)\nsns.violinplot(x='diagnosis',y='concave points_worst',data=features_worst,palette=\"Reds\",inner=\"quartile\")\nplt.show()","metadata":{"_cell_guid":"c8f5d236-7cab-4f09-ae24-6c776ed41e0c","_uuid":"2a651c8579c13e125f648b819db45e7e38ffa29e"},"execution_count":null,"cell_type":"code","outputs":[]},{"source":"From the above plots, we find out that **concavity_worst and concave points_worst** have similar plots so we can use one of them. Along with that, we find out that **texture_se and radius_se** can be used for classification.","metadata":{"_cell_guid":"67d17c7a-f91e-402f-a071-8da162181ccf","_uuid":"ac9e2b6ad47c96451ad72f017e2c02f9812a87f4"},"cell_type":"markdown"},{"source":"Visualising and selecting best from **radius , area and perimeter** for classification using pairplots and swarmplots to see which of them seperates the types of cancer better than the others.","metadata":{"_cell_guid":"b621bc3f-c120-45d1-ad67-80748dc071bc","_uuid":"04a9d27a73e5b8dab7aad5eda4ed1bf7d35a0317"},"cell_type":"markdown"},{"source":"pairplot = cancer[['diagnosis','radius_worst','area_worst','perimeter_worst']]\nsns.pairplot(pairplot,hue='diagnosis',palette=\"Blues_d\")\nplt.show()","metadata":{"_cell_guid":"3e375e46-fe65-45c8-bb32-cbc759046d55","_uuid":"a6765f6cffa13ea64d6e24163b9356581cfeb488"},"execution_count":null,"cell_type":"code","outputs":[]},{"source":"plt.subplot(221)\nsns.swarmplot(x='diagnosis',y='area_worst',data=pairplot,palette=\"Blues_d\")\nplt.subplot(222)\nsns.swarmplot(x='diagnosis',y='radius_worst',data=pairplot,palette=\"Blues_d\")\nplt.subplot(223)\nsns.swarmplot(x='diagnosis',y='perimeter_worst',data=pairplot,palette=\"Blues_d\")\nplt.show()","metadata":{"_cell_guid":"f624253d-ace4-4b91-a988-1cd54a53cdc1","_uuid":"3db4d369689eb999faf42bd54cc3179ef29ab47c"},"execution_count":null,"cell_type":"code","outputs":[]},{"source":"We can use **radius** among them. This is because it it better classifies Malignant & Benign types, and both area aong with the perimeter depend on radius.","metadata":{"_cell_guid":"9c7a631b-ff2a-4184-9a13-685f837d5518","_uuid":"37598ea61c8fd9a8f8c1cbcc040bbca2d9fdb45e"},"cell_type":"markdown"},{"source":"plt.subplot(221)\nsns.swarmplot(x='diagnosis',y='compactness_worst',data=features_worst,palette=\"Blues_d\")\nplt.subplot(222)\nsns.swarmplot(x='diagnosis',y='concavity_worst',data=features_worst,palette=\"Blues_d\")\nplt.subplot(223)\nsns.swarmplot(x='diagnosis',y='concave points_worst',data=features_worst,palette=\"Blues_d\")\nplt.show()","metadata":{"_cell_guid":"3c724902-c208-4c6c-84ef-ff32be0fd4be","_uuid":"d9c1c79919fe2e9017d12f576da451029a806726"},"execution_count":null,"cell_type":"code","outputs":[]},{"source":"And from these plots we can clearly see that **concavity_worst** can be used for classification among these three.","metadata":{"_cell_guid":"21a207a7-4e64-4d93-bd24-9128c14a71f2","_uuid":"523d2b7bcc8bdb7457d5b6ab5da14d8b4a1eda83"},"cell_type":"markdown"},{"source":"**Feature selection**","metadata":{"_cell_guid":"7ced45f7-4fcc-4f00-bd82-aff999a184b6","_uuid":"1477c7a7018f8fac7d47c933f4fa387348eac5bf"},"cell_type":"markdown"},{"source":"selecting features based on above visualisation and correlations\n1. radius_mean \n2. texture_mean \n3. smoothness_mean\n4. concavity_mean \n5. symmetry_mean\n6. radius_se \n7. texture_se\n8. smoothness_se\n9. concavity_se \n10. symmetry_se\n11. radius_worst \n12. texture_worst\n13. smoothness_worst\n14. concavity_worst\n15. symmetry_worst","metadata":{"_cell_guid":"025ecae9-e64b-4677-a5f3-80c7c00d5199","_uuid":"3f0cc7dd59918cc334d6d6cb87b517ebf0723b4a"},"cell_type":"markdown"},{"source":"features_corr = cancer[['diagnosis','radius_mean', 'texture_mean', 'smoothness_mean', 'concavity_mean','symmetry_mean',\n       'radius_se', 'texture_se', 'smoothness_se','concavity_se', 'symmetry_se','radius_worst', 'texture_worst',\n       'smoothness_worst','concavity_worst','symmetry_worst']]\nfeatures_correlation = features_corr.corr()\nplt.figure(figsize=(10,10))\nsns.heatmap(features_correlation,vmax=1,square=True,annot=True,cmap='Blues')\nplt.show()","metadata":{"_cell_guid":"53170b6f-131b-4efd-9d6b-7d3ff77200aa","_uuid":"e341f6e70b9252b05e76a079e6eef9457b58cb44"},"execution_count":null,"cell_type":"code","outputs":[]},{"source":"For cross validation of the results we may use the train_test_split. And we are fitting the above selected features using **Random Forest Classifier**.","metadata":{"_cell_guid":"8bffd484-17a3-4c66-b906-46f863b0c61d","_uuid":"08d3a6c34ec4f049b8d5e1b674bee13563d85180"},"cell_type":"markdown"},{"source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\n\nfeatures_corr['diagnosis'] = [0 if x == 'B' else 1 for x in features_corr['diagnosis']]\nX = features_corr.drop(['diagnosis'],axis = 1 )\ny = features_corr.diagnosis\n\nX_train,X_test,y_train,y_test  = train_test_split(X,y,test_size=0.3,random_state=42)\nrfc = RandomForestClassifier(n_estimators=10)\nrfc.fit(X_train,y_train)\nprint('Accuracy score',rfc.score(X_test,y_test))","metadata":{"scrolled":true,"_cell_guid":"773f0ba0-fefb-43a8-a9cf-6c9a9880f507","_uuid":"e66d3896b799ee8b4f0c63a8b2e248ba732c6d1b"},"execution_count":null,"cell_type":"code","outputs":[]},{"source":"**Performance metrics** to check the model accuracy","metadata":{"_cell_guid":"7f180d23-b195-477e-ad21-55a930bff6c6","_uuid":"3504726a24edc9dcee749805f32b69ee92e6ae81"},"cell_type":"markdown"},{"source":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\n\ny_pred = rfc.predict(X_test)\nconfusion_matrix = confusion_matrix(y_test,y_pred)\nsns.heatmap(confusion_matrix,annot=True,fmt='')\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nprint('Classification Report')\nprint(classification_report(y_test,y_pred))\n\nfrom sklearn.model_selection import cross_val_score\nimport numpy as np\nrfc = RandomForestClassifier()\ncv_results = cross_val_score(rfc,X,y,cv=5)\nprint(cv_results)\nprint(\"Average 5-Fold CV Score: {}\".format(np.mean(cv_results)))","metadata":{"_cell_guid":"01eaeb41-ece6-4445-9bd4-6dc920a981cf","_uuid":"226791970903750af0fde5cb8a1d1bee6c4617e9"},"execution_count":null,"cell_type":"code","outputs":[]},{"source":"**ROC Curve** to check the accuracy and detect the performance of the model:","metadata":{"_cell_guid":"1282489d-9758-48f0-bd9a-ba3b3940a668","_uuid":"a5d72682fc6ed6002adacdea5daffd335f89c4b0"},"cell_type":"markdown"},{"source":"from sklearn.metrics import roc_curve\nrfc.fit(X_train,y_train)\ny_pred_prob  =  rfc.predict_proba(X_test)[:,1]\nfpr,tpr,thresholds = roc_curve(y_test,y_pred_prob)\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr,tpr,label='random forest')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.show()","metadata":{"_cell_guid":"7edc12c1-13f6-4fb4-a053-eff8bc73ee3f","_uuid":"380bef689f66c243bcd6ba843f853c357aa8393c"},"execution_count":null,"cell_type":"code","outputs":[]},{"source":"","metadata":{"_cell_guid":"1641e6bc-6f56-4f58-8cc5-730103259c29","_uuid":"f5e7c8fb89ff364783358cc5bdebf84bc0c6e56e"},"cell_type":"markdown"},{"source":"","metadata":{"_cell_guid":"85eda675-765c-4eb0-a5da-8f396528936a","_uuid":"0719b0f3df87af91ade47f373778466770dc945e"},"cell_type":"markdown"},{"source":"Now taking all the features of the dataset and fitting them using the **RandomForestClassifier**.","metadata":{"_cell_guid":"f7375f0e-c63e-444d-834c-82e2eb488bb8","_uuid":"99259c7a76e241bc0aa64e5da5bc7881359a735d"},"cell_type":"markdown"},{"source":"df = pd.read_csv(\"../input/data.csv\")\ndf['diagnosis'] = [0 if x == 'B' else 1 for x in df['diagnosis']]\ny = df.diagnosis        \nlist = ['Unnamed: 32','id','diagnosis']\nX = df.drop(list,axis = 1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\nforest = RandomForestClassifier()\nforest.fit(X_train,y_train)\nprint('train score',forest.score(X_train,y_train))\nprint('test score',forest.score(X_test,y_test))","metadata":{"_cell_guid":"02f9dc2a-be4f-44ba-aba2-98fb0871f27e","_uuid":"208bd6fc04aff17912c0ca4c496829a7b4866dc1"},"execution_count":null,"cell_type":"code","outputs":[]},{"source":"**Correlation of diagnosis** with other features sorted reverse (descending order), which tells us that the radius parameters relate to the classification better than their area counterparts.","metadata":{"_cell_guid":"74f18c2e-1d92-48a1-8f5a-0711b04b1b0f","_uuid":"2e2656ebdf5157fcb7413ddee3a868dde31c5998"},"cell_type":"markdown"},{"source":"corr=df.corr()['diagnosis']\ncorr[np.argsort(corr,axis=0)[::-1]]","metadata":{"_cell_guid":"c079d807-2287-42f2-b0ab-5d7330e407fa","_uuid":"d033fb2468202553aec92bf066c498fd99eb3bfd"},"execution_count":null,"cell_type":"code","outputs":[]},{"source":"Detecting **Feature Importances**, from which we conclude that the worst parameters classify better than the others:","metadata":{"_cell_guid":"07bf8146-5659-4499-8852-bf9673ca3b8a","_uuid":"892c444fe33260fd7f47b5d635bf2b289199753e"},"cell_type":"markdown"},{"source":"features = X.columns\nfor name, importance in zip(features, forest.feature_importances_):\n    print(name, \"=\", importance)\n\nimportances = forest.feature_importances_\nindices = np.argsort(importances)\n\nplt.title('Feature Importances')\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), features) ## removed [indices]\nplt.xlabel('Relative Importance')\nplt.show()","metadata":{"_cell_guid":"65290270-739e-4e2b-9e31-65738e1c26e8","_uuid":"5ca7f5f7b3dc2ffc9c344b9fa09c822491646e72"},"execution_count":null,"cell_type":"code","outputs":[]},{"source":"**Performance metrics**: classification_report, confusion_matrics and cross_val_score","metadata":{"_cell_guid":"51b65657-5505-49d9-b266-757083adcdab","_uuid":"f6c6bdfc54b6c65cbc771088bdcbfba0b28757b8"},"cell_type":"markdown"},{"source":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\ny_pred = forest.predict(X_test)\nconfusion_matrix = confusion_matrix(y_test,y_pred)\nsns.heatmap(confusion_matrix,annot=True,fmt='')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nprint('Classification Report')\nprint(classification_report(y_test,y_pred))\n\nfrom sklearn.model_selection import cross_val_score\nimport numpy as np\ncv_results = cross_val_score(forest,X,y,cv=5)\nprint(cv_results)\nprint(\"Average 5-Fold CV Score: {}\".format(np.mean(cv_results)))","metadata":{"_cell_guid":"33c8cabf-3964-480d-8bb6-e0d3ecc4ecf1","_uuid":"44a7e70e74d7fcbfad1b19c22868bac55311be38"},"execution_count":null,"cell_type":"code","outputs":[]},{"source":"**ROC Curve** for the model accuracy detection:","metadata":{"_cell_guid":"e5d58244-af00-43a2-9665-684a3bee2268","_uuid":"1b59a30d8f69733f380ae4d83747ca343ac1f2a0"},"cell_type":"markdown"},{"source":"from sklearn.metrics import roc_curve\nrfc.fit(X_train,y_train)\ny_pred_prob  =  forest.predict_proba(X_test)[:,1]\nfpr,tpr,thresholds = roc_curve(y_test,y_pred_prob)\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr,tpr,label='random forest')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.show()","metadata":{"_cell_guid":"7862a57c-608d-41ba-88bd-78cc9a14897b","_uuid":"0031f2527c8fe9250e16eed8488eee0d415b88b1"},"execution_count":null,"cell_type":"code","outputs":[]},{"source":"**Conclusion**\n From the above results we come to a conclusion that the methods employed here are prediction and implementation worthy, and give a better classification of the types of cancers: Benign and Malignant types. Hence,** taking the mean, standard deviation and worst values for radius, texture, smoothness, concavity and symmetry parameters was a good idea.**","metadata":{},"cell_type":"markdown"}],"nbformat":4}