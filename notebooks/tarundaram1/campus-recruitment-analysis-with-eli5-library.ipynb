{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Welcome to my Analysis**\n\nThank you for visiting my Kernel. I am a newbie to this field and very much interested to learn.\nDo analyze my work and feedback is very much appreciated.\n\nDo suggest different ways to improve so that I can learn the most.","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/factors-affecting-campus-placement/Placement_Data_Full_Class.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1 = data.fillna(0)\ndata1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nmy_label_Encoder = LabelEncoder()\n\ndata1['status'] = my_label_Encoder.fit_transform(data1['status'])\n\ndata1.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# \"1\" represent Male\n# \"0\" represent Female\ndata1['status'].value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nvalues = sns.countplot(data['status'],hue=data['gender'])\n\n\n\nfor total_count in values.patches:\n    height = total_count.get_height()\n    width=total_count.get_x()+total_count.get_width()/2.\n    values.text(total_count.get_x()+total_count.get_width()/2.,height + 3,'{:1.2f}'.format(height),ha=\"center\") \n\n\n    \ntotal_students = data1['gender'].value_counts()\nprint(\"Number of male and female\\n\",total_students)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"values = sns.countplot(data['status'],hue=data['degree_t'])\n\n# The below code is to see the total values of each bar on the top\nfor total_count in values.patches:\n    height = total_count.get_height()\n    width=total_count.get_x()+total_count.get_width()/2.\n    values.text(total_count.get_x()+total_count.get_width()/2.,height + 3,'{:1.2f}'.format(height),ha=\"center\")\n    \ndegrees = data1['degree_t'].value_counts()\nprint(\"Students with different degrees: \\n\",degrees)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"values = sns.countplot(data['status'],hue=data['specialisation'])\n\n# The below code is to see the total values of each bar on the top\nfor total_count in values.patches:\n    height = total_count.get_height()\n    width=total_count.get_x()+total_count.get_width()/2.\n    values.text(total_count.get_x()+total_count.get_width()/2.,height + 3,'{:1.2f}'.format(height),ha=\"center\") \n    \ntotal_students_specialisation = data1['specialisation'].value_counts()\nprint(\"Number of students in each specialisation\\n\",total_students_specialisation)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"values = sns.countplot(data['status'],hue=data['hsc_b'])\n\n# The below code is to see the total values of each bar on the top\nfor total_count in values.patches:\n    height = total_count.get_height()\n    width=total_count.get_x()+total_count.get_width()/2.\n    values.text(total_count.get_x()+total_count.get_width()/2.,height + 3,'{:1.2f}'.format(height),ha=\"center\") \n\nhsc_board = data1['hsc_b'].value_counts()\nprint(\"Number of students in different hsc boards\\n\",hsc_board)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.regplot(x='ssc_p',y='hsc_p',data=data1)\n\nprint(\"We can see the students perfomed well in ssc also performed well in hsc as well and students who did not perform well in ssc did not perform well in hsc but some performed well in hsc\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.regplot(x='hsc_p',y='degree_p',data=data1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.regplot(x='degree_p',y='mba_p',data=data1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x=\"status\", y=\"ssc_p\", data=data,kind=\"swarm\",hue='gender')\nsns.catplot(x=\"status\", y=\"hsc_p\", data=data,kind=\"swarm\",hue='gender')\nsns.catplot(x=\"status\", y=\"degree_p\", data=data,kind=\"swarm\",hue='gender')\nsns.catplot(x=\"status\", y=\"mba_p\", data=data,kind=\"swarm\",hue='gender')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that the people below 60% are mostly not placed.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x=\"status\", y=\"etest_p\", data=data,kind=\"swarm\",hue='gender')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = data1['status']\ndf = data1.drop(['salary','gender','degree_t','hsc_s','hsc_b','ssc_b','specialisation','workex','status'],axis=1)\nx = df\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split as tts\nfrom sklearn.metrics import accuracy_score as acc_score\nfrom sklearn.ensemble import RandomForestClassifier as rfc\n\nX_train,X_test,y_train,y_test = tts(x,y,test_size=0.33)\nmodel = rfc()\nmodel.fit(X_train,y_train)\nZ = model.predict(X_test)\nprint (acc_score(y_test,Z))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, This is the final accuracy score I got.\n\nFrom this data analysis,\n\nWe see students who got less percentage in ssc, continued the same in hsc and some in degree too.\nBut very little students who got less percentage in ssc did best in hsc and degree.\n\n 1. The \"MKT&Fin\" students with degree background \"Comm & Mgmt\" students got more placed. The students with degree backgound \"Sci & tech \" also perfomed well in placements with better placed percentage than Comm & Mgmt.\n\n 2. Although, The analysis also told us that ssc% and hsc% are also important for strong foundation. There are more students less than 60% in hsc_p and ssc_p who did not get placed. As we see there are only little students who performed well in etest_p and mba_p did not get placed.\n \n 3. The corporate intrested to hire students who preferred MKT&Fin specialisation though this specialisation has more students.\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import eli5\nfrom eli5.sklearn import PermutationImportance\nfeature_names = [i for i in data.columns if data[i].dtype in [np.int64]]\nperm = PermutationImportance(model, random_state=1).fit(X_test, y_test)\neli5.show_weights(perm, feature_names = X_test.columns.tolist())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[edit]\nThis concept is permutation importance\nThe values towards the top are the most important features, and those towards the bottom matter least.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}