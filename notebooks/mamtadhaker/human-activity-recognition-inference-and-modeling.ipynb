{"cells":[{"metadata":{"trusted":true,"_uuid":"e84b2d0af625d90c5a4f8ade1b8050dd3d037805"},"cell_type":"code","source":"import pandas as pd\n\n# To do linear algebra\nimport numpy as np\nfrom numpy import pi\n\n# To create plots\nfrom matplotlib.colors import rgb2hex\nfrom matplotlib.cm import get_cmap\nimport matplotlib.pyplot as plt\nfrom matplotlib.axes import Axes\n# To create nicer plots\nimport seaborn as sns\n\n# To create interactive plots\nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.graph_objs as go\ninit_notebook_mode(connected=True)\n\n# To get new datatypes and functions\nfrom collections import Counter\nfrom cycler import cycler\n\nfrom scipy.stats import norm,skew, probplot\nfrom scipy.optimize import curve_fit\n\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\n\nfrom lightgbm import LGBMClassifier\n\nfrom time import time\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import preprocessing\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.feature_selection import RFE\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import confusion_matrix\nimport scikitplot as skplt\nimport itertools\nfrom sklearn.model_selection import GridSearchCV\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#load dataset\ntrain_df = pd.read_csv('../input/train.csv')\ntest_df = pd.read_csv('../input/test.csv')\n\ntrain_df['Data'] = 'Train'\ntest_df['Data'] = 'Test'\n\ntt_df = pd.concat([train_df,test_df], axis = 0).reset_index(drop = True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3db54e083d3307e4c158d7737e1a46b57c2e890d"},"cell_type":"code","source":"#Check null values\ntrain_df.isnull().values.any()\ntest_df.isnull().values.any()\n# no null values in train and test data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c76633e3a004466ab323c045073157fb05d2ab5a"},"cell_type":"code","source":"tt_df['subject'] = '#' + tt_df['subject'].astype(str)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0ae1073229a7b4772eac43fdeac85a87889caa80"},"cell_type":"code","source":"tt_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c1ac07f1a03458babf0f1f74fe351c9de3453d92","scrolled":true},"cell_type":"code","source":"tt_df.columns.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7f9667ec5a830f8f3807f84d444c4a95f57e3934"},"cell_type":"code","source":"tt_df['Activity'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"11cf33766ec3d041b2dd6add09ea3707eea87c01"},"cell_type":"code","source":"label = tt_df.pop('Activity')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"63a565845b104e8497166118922a651ee172e7ee"},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dab48122809be310ab8b9e4d4f9fa711e40d4a46"},"cell_type":"code","source":"pd.DataFrame.from_dict(Counter([col.split('-')[0].split('(')[0] \n                                for col in tt_df.columns]), \n                       orient = 'index').rename(columns = {0:'count'}).sort_values('count',ascending=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"130929835617c18519dca976aed957f0c5dcb6a7"},"cell_type":"code","source":"print('Null values in DataFrme:{}\\n'.format(tt_df.isna().sum().sum()))\ntt_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7eb607b5186e3bd36d5e3ae410a301520c89cf66"},"cell_type":"code","source":"label_counts = label.value_counts()\n\nn = label_counts.shape[0]\ncolormap = get_cmap('viridis')\ncolors = [rgb2hex(colormap(col)) for col in np.arange(0,1.01,1/(n-1))]\n\ndata = go.Bar(x = label_counts.index,\n             y = label_counts,\n             marker = dict(color = colors))\n\nlayout = go.Layout(title = 'Smartphone Activity Label Distribution',\n                  xaxis = dict(title = 'Activity'),\n                  yaxis = dict(title = 'Count'))\n\nfig = go.Figure(data = [data], layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aeec2e9f50e28927fda10111b13f4730cfcdacf5"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2e8c7e1462431a2016253eb0e4ebe1731ec13a59"},"cell_type":"code","source":"tsne_data = tt_df.copy()\ndata_data = tsne_data.pop('Data')\nsubject_data = tsne_data.pop('subject')\n\n# Scale data\nscl = StandardScaler()\ntsne_data = scl.fit_transform(tsne_data)\n\n# Reduce dimensions (speed up)\npca = PCA(n_components=0.9, random_state=3)\ntsne_data = pca.fit_transform(tsne_data)\n\n# Transform data\ntsne = TSNE(random_state=3)\ntsne_transformed = tsne.fit_transform(tsne_data)\n\n\n# Create subplots\nfig, axarr = plt.subplots(2, 1, figsize=(15,10))\n\n### Plot Activities\n# Get colors\nn = label.unique().shape[0]\ncolormap = get_cmap('viridis')\ncolors = [rgb2hex(colormap(col)) for col in np.arange(0, 1.01, 1/(n-1))]\n\n# Plot each activity\nfor i, group in enumerate(label_counts.index):\n    # Mask to separate sets\n    mask = (label==group).values\n    axarr[0].scatter(x=tsne_transformed[mask][:,0], y=tsne_transformed[mask][:,1], c=colors[i], alpha=0.5, label=group)\naxarr[0].set_title('TSNE: Activity Visualisation')\naxarr[0].legend()\n\n\n### Plot Subjects\n# Get colors\nn = subject_data.unique().shape[0]\ncolormap = get_cmap('gist_ncar')\ncolors = [rgb2hex(colormap(col)) for col in np.arange(0, 1.01, 1/(n-1))]\n\n# Plot each participant\nfor i, group in enumerate(subject_data.unique()):\n    # Mask to separate sets\n    mask = (subject_data==group).values\n    axarr[1].scatter(x=tsne_transformed[mask][:,0], y=tsne_transformed[mask][:,1], c=colors[i], alpha=0.5, label=group)\n\naxarr[1].set_title('TSNE: Participant Visualisation')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"33a32a9ac288e3f82720318c3bef947d9ca06cae"},"cell_type":"code","source":"#Split training testing data\nenc = LabelEncoder()\nlabel_encoded = enc.fit_transform(label)\nX_train,X_test, y_train, y_test = train_test_split(tsne_data, label_encoded, random_state=3)\n\n#Create the model\nlgbm = LGBMClassifier(n_estimators = 500, random_state=3)\nlgbm = lgbm.fit(X_train, y_train)\n\n# Test the model\nscore = accuracy_score(y_true=y_test, y_pred=lgbm.predict(X_test))\nprint('Accuracy on testset:\\t{:.4f}\\n'.format(score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"10a376e06864ea10f6affd4d4b1812d9d25a738b"},"cell_type":"code","source":"#Store the data\ndata = []\n#Iterate over each activity\nfor activity in label_counts.index:\n    #Create dataset\n    act_data = tt_df[label==activity].copy()\n    act_data_data = act_data.pop('Data')\n    act_subject_data = act_data.pop('subject')\n    \n    #Scale data\n    scl = StandardScaler()\n    act_data = scl.fit_transform(act_data)\n    \n    #Reduce dimensions\n    pca = PCA(n_components=0.9,random_state=3)\n    act_data = pca.fit_transform(act_data)\n    \n    #Split training testing data\n    enc = LabelEncoder()\n    label_encoded = enc.fit_transform(act_subject_data)\n    X_train,X_test,y_train,y_test = train_test_split(act_data, label_encoded,random_state=3)\n    \n    #Fit basic model\n    print('Activity: {}'.format(activity))\n    lgbm = LGBMClassifier(n_estimators=500,random_state=3)\n    lgbm = lgbm.fit(X_train,y_train)\n    \n    score = accuracy_score(y_true=y_test, y_pred=lgbm.predict(X_test))\n    print('Accuracy on testset: \\t{:.4f}\\n'.format(score))\n    data.append([activity, score])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4dd2e7db4b88b0e1bfdfd2462cd3b8e4028bad72"},"cell_type":"code","source":"#Create duration datafrae\nduration_df = (tt_df.groupby([label,subject_data])['Data'].count().reset_index().groupby('Activity').agg({'Data':'mean'})*1.28).rename(columns = {'Data':'Seconds'})\nactivity_df = pd.DataFrame(data, columns=['Activity','Accuracy']).set_index('Activity')\nactivity_df.join(duration_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"07ef822b0b706fb412b2ad368810ea1bca1c57c7"},"cell_type":"code","source":"# Create dataset\ntsne_data = tt_df[label=='WALKING'].copy()\ndata_data = tsne_data.pop('Data')\nsubject_data = tsne_data.pop('subject')\n\n# Scale data\nscl = StandardScaler()\ntsne_data = scl.fit_transform(tsne_data)\n\n# Split training testing data\nenc = LabelEncoder()\nlabel_encoded = enc.fit_transform(subject_data)\nX_train, X_test, y_train, y_test = train_test_split(tsne_data, label_encoded, random_state=3)\n\n\n# Create model\nlgbm = LGBMClassifier(n_estimators=500, random_state=3)\nlgbm = lgbm.fit(X_train, y_train)\n\n# Get importances\nfeatures = tt_df.drop(['Data', 'subject'], axis=1).columns\nimportances = lgbm.feature_importances_\n\n# Sum importances\ndata = {'Gyroscope':0, 'Accelerometer':0}\nfor importance, feature in zip(importances, features):\n    if 'Gyro' in feature:\n        data['Gyroscope'] += importance\n    if 'Acc' in feature:\n        data['Accelerometer'] += importance\n        \n# Create dataframe and plot\nsensor_df = pd.DataFrame.from_dict(data, orient='index').rename(columns={0:'Importance'})\nsensor_df.plot(kind='barh', figsize=(14,4), title='Sensor Importance For Classifing Participants By Walking Style (Feature Importance Sum)')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e415aba4678205aa9037f37997e0eb7c12357e8c"},"cell_type":"markdown","source":"How Long Does The Participant Use The Staircase?"},{"metadata":{"trusted":true,"_uuid":"141d27cdfbdc8d8148fbf8a8eed21a20a5450e53"},"cell_type":"code","source":"# Group the data by participant and compute total duration of staircase walking\nmask = label.isin(['WALKING_UPSTAIRS', 'WALKING_DOWNSTAIRS'])\nduration_df = (tt_df[mask].groupby([label[mask], 'subject'])['Data'].count() * 1.28)\n\n# Create plot\nplot_data = duration_df.reset_index().sort_values('Data', ascending=False)\nplot_data['Activity'] = plot_data['Activity'].map({'WALKING_UPSTAIRS':'Upstairs', 'WALKING_DOWNSTAIRS':'Downstairs'})\n\nplt.figure(figsize=(15,5))\nsns.barplot(data=plot_data, x='subject', y='Data', hue='Activity')\nplt.title('Participants Compared By Their Staircase Walking Duration')\nplt.xlabel('Participants')\nplt.ylabel('Total Duration [s]')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8497726b71e432aee2e89119253b46cb67cb3b3a"},"cell_type":"markdown","source":"How Much Does The Up-/Downstairs Ratio Vary?"},{"metadata":{"trusted":true,"_uuid":"10089ce479fe562153196b728fc54d4bd65c89e1"},"cell_type":"code","source":"# Create data and plot\nplt.figure(figsize=(15,5))\nplot_data = ((duration_df.loc['WALKING_UPSTAIRS'] / duration_df.loc['WALKING_DOWNSTAIRS']) -1).sort_values(ascending=False)\nsns.barplot(x=plot_data.index, y=plot_data)\nplt.title('By What Percentage Is The Participant Faster In Walking Downstairs Than Upstairs?')\nplt.xlabel('Participants')\nplt.ylabel('Percent')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"907d18ddc95526d4321edd50b85a8b63fe6d4aaa"},"cell_type":"markdown","source":"Are There Conspicuities In The Staircase Walking Duration Distribution?"},{"metadata":{"trusted":true,"_uuid":"8fbd0d9bb584c01b401a5b667dccf2c400a27843"},"cell_type":"code","source":"def plotSkew(x):\n    # Fit label to norm\n    (mu, sigma) = norm.fit(x)\n    alpha = skew(x)\n\n    fig, axarr = plt.subplots(1, 2, figsize=(15,4))\n\n    # Plot label and fit\n    sns.distplot(x , fit=norm, ax=axarr[0])\n    axarr[0].legend(['$\\mu=$ {:.2f}, $\\sigma=$ {:.2f}, $\\\\alpha=$ {:.2f}'.format(mu, sigma, alpha)], loc='best')\n    axarr[0].set_title('Staircase Walking Duration Distribution')\n    axarr[0].set_ylabel('Frequency')\n\n    # Plot probability plot\n    res = probplot(x, plot=axarr[1])\n    plt.show()\n    \n    \nplotSkew(duration_df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9685ed020284506cc2716c685a858377c199d74f"},"cell_type":"markdown","source":"Is There A Unique Walking Style For Each Participant?"},{"metadata":{"trusted":true,"_uuid":"c48f2090263cd0d41cdc3befaac663e59a65507b"},"cell_type":"code","source":"fig, axarr = plt.subplots(5, 6, figsize=(15,6))\n\nfor person in range(0, 30):\n    # Get data\n    single_person = tt_df[(label=='WALKING') & (tt_df['subject']=='#{}'.format(person+1))].drop(['subject', 'Data'], axis=1)\n    # Scale data\n    scl = StandardScaler()\n    tsne_data = scl.fit_transform(single_person)\n    # Reduce dimensions\n    pca = PCA(n_components=0.9, random_state=3)\n    tsne_data = pca.fit_transform(tsne_data)\n    # Transform data\n    tsne = TSNE(random_state=3)\n    tsne_transformed = tsne.fit_transform(tsne_data)\n    \n    # Create plot\n    axarr[person//6][person%6].plot(tsne_transformed[:,0], tsne_transformed[:,1], '.-')\n    axarr[person//6][person%6].set_title('Participant #{}'.format(person+1))\n    axarr[person//6][person%6].axis('off')\n    \nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cbe08406c97ced329774f79aaf6f2c4e86637417"},"cell_type":"markdown","source":"How Long Does The Participant Walk?"},{"metadata":{"trusted":true,"_uuid":"066f2427b870c36d356fed685267e1b477cd94e1"},"cell_type":"code","source":"# Group the data by participant and compute total duration of walking\nmask = label=='WALKING'\nduration_df = (tt_df[mask].groupby('subject')['Data'].count() * 1.28)\n\n# Create plot\nplot_data = duration_df.reset_index().sort_values('Data', ascending=False)\n\nplt.figure(figsize=(15,5))\nsns.barplot(data=plot_data, x='subject', y='Data')\nplt.title('Participants Compared By Their Walking Duration')\nplt.xlabel('Participants')\nplt.ylabel('Total Duration [s]')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"41b84b9b45a131b560cf580bd956957cebab4d4c"},"cell_type":"markdown","source":"Is There A Unique Staircase Walking Style For Each Participant?"},{"metadata":{"trusted":true,"_uuid":"bb4d883690507a438831e47de80c201b99a47fe3"},"cell_type":"code","source":"# Create subplots\nfig, axarr = plt.subplots(10, 6, figsize=(15,15))\n\n# Iterate over each participant\nfor person in range(0, 30):\n    # Get data\n    single_person_up = tt_df[(label=='WALKING_UPSTAIRS') & (tt_df['subject']=='#{}'.format(person+1))].drop(['subject', 'Data'], axis=1)\n    single_person_down = tt_df[(label=='WALKING_DOWNSTAIRS') & (tt_df['subject']=='#{}'.format(person+1))].drop(['subject', 'Data'], axis=1)\n    # Scale data\n    scl = StandardScaler()\n    tsne_data_up = scl.fit_transform(single_person_up)\n    tsne_data_down = scl.fit_transform(single_person_down)\n    # Reduce dimensions\n    pca = PCA(n_components=0.9, random_state=3)\n    tsne_data_up = pca.fit_transform(tsne_data_up)\n    tsne_data_down = pca.fit_transform(tsne_data_down)\n    # Transform data\n    tsne = TSNE(random_state=3)\n    tsne_transformed_up = tsne.fit_transform(tsne_data_up)\n    tsne_transformed_down = tsne.fit_transform(tsne_data_down)\n    \n    # Create plot\n    axarr[2*person//6][2*person%6].plot(tsne_transformed_up[:,0], tsne_transformed_up[:,1], '.b-')\n    axarr[2*person//6][2*person%6].set_title('Up: Participant #{}'.format(person+1))\n    axarr[2*person//6][2*person%6].axis('off')\n    axarr[2*person//6][(2*person%6)+1].plot(tsne_transformed_down[:,0], tsne_transformed_down[:,1], '.g-')\n    axarr[2*person//6][(2*person%6)+1].set_title('Down: Participant #{}'.format(person+1))\n    axarr[2*person//6][(2*person%6)+1].axis('off')\n    \nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"228737deba826dda4bc5348dac30ec2858b0859a"},"cell_type":"markdown","source":"**Exploring Personal Information**\n"},{"metadata":{"_uuid":"0f5e66105324505f9693cbb209ee017834623010"},"cell_type":"markdown","source":""},{"metadata":{"trusted":true,"_uuid":"970ffbec6adbf49de729c8b2a66af95177be4c3e"},"cell_type":"code","source":"# Get data\ntsne_data = tt_df[label=='WALKING'].copy()\ndata_data = tsne_data.pop('Data')\nsubject_data = tsne_data.pop('subject')\n\n# Scale data\nscl = StandardScaler()\ntsne_data = scl.fit_transform(tsne_data)\n\n# Reduce dimensions\npca = PCA(n_components=0.9, random_state=3)\ntsne_data = pca.fit_transform(tsne_data)\n\n# Transform data\ntsne = TSNE(random_state=3)\ntsne_transformed = tsne.fit_transform(tsne_data)\n\n\n# Create subplots\nfig, axarr = plt.subplots(1, 1, figsize=(15,10))\n\n### Plot Subjects\n# Get colors\nn = subject_data.unique().shape[0]\ncolormap = get_cmap('gist_ncar')\ncolors = [rgb2hex(colormap(col)) for col in np.arange(0, 1.01, 1/(n-1))]\n\nfor i, group in enumerate(subject_data.unique()):\n    # Mask to separate sets\n    mask = (subject_data==group).values\n    axarr.scatter(x=tsne_transformed[mask][:,0], y=tsne_transformed[mask][:,1], c=colors[i], alpha=0.5, label=group)\n\naxarr.set_title('TSNE Walking Style By Participant')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2709a506cc3cd99484d25c1cae16120ed2cbcecc"},"cell_type":"markdown","source":"**Modelling**"},{"metadata":{"trusted":true,"_uuid":"21c276038d15434a8a2a7d179ed450885bad1896"},"cell_type":"code","source":"train_df=pd.read_csv(\"../input/train.csv\")\ntest_df=pd.read_csv(\"../input/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"13aa96fed420185c5cfda97db6d383337f5320d5"},"cell_type":"code","source":"#subject col is not useful hence dropped\nif('subject' in train_df.columns):\n    train_df.drop('subject', axis=1, inplace=True)\nif('subject' in test_df.columns):\n    test_df.drop('subject', axis=1, inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"80d06f1acf56e2ba1d4eebc493ae8f73ca8f141e"},"cell_type":"markdown","source":"Variable Encoding for classes"},{"metadata":{"trusted":true,"_uuid":"d8445bd1e2d2344743ea5a7a0abed2c439221183"},"cell_type":"code","source":"# Encoding target - converting non-numto num variable\nle = preprocessing.LabelEncoder()\nfor x in [train_df,  test_df]:\n    x['Activity'] = le.fit_transform(x.Activity)\n\n# Split into features and class\ndf_traindata, df_trainlabel = train_df.iloc[:,0:len(train_df.columns)-1],train_df.iloc[:,-1]\ndf_testdata, df_testlabel = test_df.iloc[:,0:len(test_df.columns)-1],test_df.iloc[:,-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7176047c47ec74d4a9588b91541413cb8f3f6ddb"},"cell_type":"code","source":"df_trainlabel.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"604fd34037107c12b5a8ce4ecdf4bec748dd9fea"},"cell_type":"code","source":"#Baseline Comparing model accuracy using all features accross classifiers\nclassifiers = [\n    DecisionTreeClassifier(),\n    RandomForestClassifier(),\n    KNeighborsClassifier(),\n    SVC(kernel=\"linear\"),\n    GaussianNB(),\n    LogisticRegression()\n    ]\n\n\n# Naive Train Accuracy\nalgo = []\nscores = []\nfor clf in classifiers:\n    algo.append(clf.__class__.__name__)\n    scores.append(cross_val_score(clf,df_traindata,df_trainlabel, cv=5).mean())\nwarnings.filterwarnings('ignore')\nNaivescore_df_Train = pd.DataFrame({'Algorithm': algo, 'Score': scores}).set_index('Algorithm')\n\n\n# Naive Test Accuracy\n\nalgo = []\nscores = []\n\nfor clf in classifiers:\n    clf = clf.fit(df_traindata, df_trainlabel)\n    y_pred = clf.predict(df_testdata)\n    algo.append(clf.__class__.__name__)\n    scores.append(accuracy_score(y_pred, df_testlabel))\nwarnings.filterwarnings('ignore')\nNaivescore_df_Test  = pd.DataFrame({'Algorithm': algo, 'Score': scores}).set_index('Algorithm')\n\n# Bar plot between Train and Test Accuracy\nfig = plt.figure(figsize=(5,5)) # Create matplotlib figure\n\nax = fig.add_subplot(111) # Create matplotlib axes\nax2 = ax.twinx() # Create another axes that shares the same x-axis as a\nwidth = .3\n\nNaivescore_df_Train.Score.plot(kind='bar',color='green',ax=ax,width=width, position=0)\nNaivescore_df_Test.Score.plot(kind='bar',color='red', ax=ax2,width = width,position=1)\n\nax.grid(None, axis=1)\nax2.grid(None)\n\nax.set_ylabel('Train')\nax2.set_ylabel('Test')\n\nax.set_xlim(-1,7)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"3e753945b5e8592efe3e87ca8712f761442c7d49"},"cell_type":"code","source":"# Feature selection using Random Forest Classifer\n# Bagged decision trees for feature importance - embedded method\nRtree_clf = RandomForestClassifier()\nRtree_clf = Rtree_clf.fit(df_traindata, df_trainlabel)\nmodel = SelectFromModel(Rtree_clf,prefit = True)\nRF_tree_featuresTrain = df_traindata.loc[:,model.get_support()]\nRF_tree_featuresTest = df_testdata.loc[:,model.get_support()]\n\n# Based on Feature Selection only 87 features were selected\n\n# Feature Importance\n# Important scores\n\nimportances = Rtree_clf.feature_importances_\nstd = np.std([tree.feature_importances_ for tree in Rtree_clf.estimators_],axis=0)\nindices = np.argsort(importances)[::-1]\nindices.shape\nindices = indices[:200]\n\n#Plot feature importances\n\nplt.figure(1, figsize=(14,13))\nplt.title('Feature importances')\nplt.xlabel('# of features')\nplt.ylabel('Importance score')\nplt.bar(range(200), importances[indices],color='r',yerr=std[indices],align='center')\nplt.xlim([0,200])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"41537705326b78399b29bb99072777c2f3c33940"},"cell_type":"code","source":"skplt.estimators.plot_learning_curve(Rtree_clf,RF_tree_featuresTrain,df_trainlabel)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7803c592b00fbb25251ff25d760c959031517619"},"cell_type":"code","source":"# Applying RFECV with svm classifier\nsvc=SVC(kernel=\"linear\")\nrfecv = RFECV(estimator=svc, step=1, cv=StratifiedKFold(2), # Stratified fold inorder to reduce bias\n              scoring='accuracy')\nrfetrain=rfecv.fit(RF_tree_featuresTrain, df_trainlabel)\nprint('Optimal number of features :', rfecv.n_features_)\n\n\n# Plot showing the Cross Validation score\nplt.figure()\nplt.xlabel(\"Number of features selected\")\nplt.ylabel(\"Cross validation score (nb of correct classifications)\")\nplt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"89d9f46d5ee38741364160e42066b9c5e49b882c"},"cell_type":"code","source":"#ApplyingRFE with optimal number of features\nrfe = RFE(estimator=svc, n_features_to_select=rfecv.n_features_, step=1)\nrfe = rfe.fit(RF_tree_featuresTrain, df_trainlabel)\n\nrfe_train=RF_tree_featuresTrain.loc[:,rfe.get_support()]\nrfe_test=RF_tree_featuresTest.loc[:,rfe.get_support()]\n\n#Checking the Accuracy after rfe\n# Train Accuracy\nprint(\"Train Accuracy:\", cross_val_score(svc,rfe_train,df_trainlabel, cv=5).mean())\n#Test Accuracy\nscv = svc.fit(rfe_train,df_trainlabel)\ny_pred = svc.predict(rfe_test)\nprint('Test Accuracy:', accuracy_score(y_pred,df_testlabel))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4ace6e8fabd7e81be2bd4e3b4cd8f67a46ed2277"},"cell_type":"markdown","source":"Applying Variance Threshold method to remove low variance variable"},{"metadata":{"trusted":true,"_uuid":"df66b45b76cbe77ff617c37c044085a6c342b593"},"cell_type":"code","source":"# Variance threshold\nselector = VarianceThreshold(0.95*(1-.95))\nvarsel=selector.fit(rfe_train)\nrfe_train.loc[:,varsel.get_support()].shape\n# 55\nvartrain = rfe_train.loc[:, varsel.get_support()]\nvartest = rfe_test.loc[:,varsel.get_support()]\n\n#Checking the Accuracy after Variance threshold\n# Train Accuracy\nprint('Train Accuracy:',cross_val_score(svc,vartrain,df_trainlabel,cv=5).mean())\n\n# Test Accuracy\nscv = svc.fit(vartrain, df_trainlabel)\ny_pred = scv.predict(vartest)\nprint(\"Test Accuracy:\", accuracy_score(y_pred, df_testlabel))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d834974f0afeae329f0678ac1e3f999de8e2cd56"},"cell_type":"markdown","source":"Dimension Reduction using PCA (Principal Component Analysis)"},{"metadata":{"trusted":true,"_uuid":"eef35c32a6e5e7753e9cbdc17f495b32935c98b1"},"cell_type":"code","source":"# PCA\npca = PCA(n_components=len(vartrain.columns))\npca_traindata = pca.fit(vartrain)\n\npca_traindata.explained_variance_\npca_traindata.n_components_\npcatrain = pca_traindata.transform(vartrain)\npcatest = pca_traindata.transform(vartest)\ncum_ratio = (np.cumsum(pca_traindata.explained_variance_ratio_))\n\n# Visualize PCA result\nplt.plot(np.cumsum(pca_traindata.explained_variance_ratio_))\nplt.xlabel('number of components')\nplt.ylabel('cumulative explained variance')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"62e25965cc195a0c09463c727de6d4c286e11b5d"},"cell_type":"markdown","source":"Applying PCA with number of components=21"},{"metadata":{"trusted":true,"_uuid":"42dc62eebfbedeaf3487a10ec6f5615f425a38df"},"cell_type":"code","source":"# 21 features - constant after that\npca = PCA(n_components = 21)\npca_traindata = pca.fit(vartrain)\n\npca_traindata.explained_variance_\npca_traindata.n_components_\npcatrain = pca_traindata.transform(vartrain)\npcatest = pca_traindata.transform(vartest)\n(np.cumsum(pca_traindata.explained_variance_ratio_))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ddc9a5868dd3cec70fb5b5f52b4477b368bf627c"},"cell_type":"markdown","source":"Visualizing top 2 principal components in scatter plot with data points segregated based on their activities"},{"metadata":{"trusted":true,"_uuid":"4517f35912268f1d03c8c0a1d4106eb08f7bcbd8"},"cell_type":"code","source":"# PCA in 2D projection\nskplt.decomposition.plot_pca_2d_projection(pca,vartrain,df_trainlabel)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"256005c4e388de1ff9dd7590cebd9450c63b7b91"},"cell_type":"markdown","source":"Accuracy check on Test and Train to see if it has increased"},{"metadata":{"trusted":true,"_uuid":"daf46b05f19c2904f1115f7f2b80217f84289248"},"cell_type":"code","source":"# Checking Accuracy after applying PCA\n\n# Train Accuracy\nprint('Train Accuracy:',cross_val_score(svc,pcatrain,df_trainlabel,cv=5).mean())\n\n# Test Accuracy\nscv = svc.fit(pcatrain, df_trainlabel)\ny_pred = scv.predict(pcatest)\nac_score = accuracy_score(y_pred, df_testlabel)\nprint('Test Accuracy:', accuracy_score(y_pred,df_testlabel))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9aeb8dc1670467a76519c234859f4d4fb4cfd576"},"cell_type":"markdown","source":"Confusion Matrix after applying PCA"},{"metadata":{"trusted":true,"_uuid":"2f045fde635be59c1ea9baa697c6b94daa999662"},"cell_type":"code","source":"# Confusion Matrixf\ncf_mat = confusion_matrix(df_testlabel,y_pred)\nprint('Accuracy: %f' %ac_score)\nactivities = le.classes_\n\n#Plotting Confusion matrix heatmap\ndef plot_confusion_matrix(cm,classes, normalize=False,\n                         title='Confusion matrix',\n                         cmap=plt.cm.Blues):\n    if normalize:\n        cm = cm.astype('float')/cm.sum(axis=1)[:,np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n    \n    print(cm)\n    \n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks= np.arange(len(classes))\n    plt.xticks(tick_marks,classes, rotation=45)\n    plt.yticks(tick_marks,classes)\n    \n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max()/2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()\n\nplot_confusion_matrix(cf_mat, classes=activities,title=\"Confusion Matrix for Test data\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"697cbbded758ab7c16f945c814cbf437984bb0ab"},"cell_type":"markdown","source":"Hyper Parameter Tuning- finding the best parameters and kernel"},{"metadata":{"trusted":true,"_uuid":"5a5be3c43c693adbfb951808f38754e25df080b1"},"cell_type":"code","source":"# Parameter Tuning \n\n# Perfromance tuning using GridScore\nparam_grid = [\n  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['linear']},\n  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n ]\nsvr = SVC()\nclf = GridSearchCV(svr, param_grid,cv=5)\nclf.fit(pcatrain,df_trainlabel)\nprint(clf.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f5ee53df4e297f4d70dd8365c6d8c0e5e9d823aa"},"cell_type":"markdown","source":"Train Test Accuracy check with best params and features"},{"metadata":{"trusted":true,"_uuid":"4b5fc77408b8006e96fdaab2aaef0b8e153f6bc7"},"cell_type":"code","source":"svr = SVC(kernel=\"rbf\",C=1000,gamma=0.001)\nprint(\"Train Accuracy:\",cross_val_score(svr,pcatrain,df_trainlabel, cv=5).mean())\n# Test Accuracy\nscv = svr.fit(pcatrain, df_trainlabel)\ny_pred = scv.predict(pcatest)\nprint(\"Test Accuracy:\",accuracy_score(y_pred, df_testlabel))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"731c9149db5cf52e1c97c77cb16b3c355b31b727"},"cell_type":"markdown","source":"With test and train accuracy almost equal to 90%, we are getting a maximum accuracy at this level."},{"metadata":{"trusted":true,"_uuid":"936e67db8130cb065e631106e7fdbe62359ae923"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}