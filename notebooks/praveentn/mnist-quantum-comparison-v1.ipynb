{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import Time\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torchvision\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n%matplotlib inline\n\n# Gets the GPU if there is one, otherwise the cpu\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Concentrating on the first 100 samples\nn_samples = 100\n\nX_train = datasets.MNIST(root='./kaggle/input', train=True, download=True,\n                         transform=None)\ntype(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Leaving only labels 0 and 1 \nidx = np.append(np.where(X_train.targets == 0)[0][:n_samples], \n                np.where(X_train.targets == 1)[0][:n_samples])\n\nX_train.data = X_train.data[idx]\nX_train.targets = X_train.targets[idx]\nprint(\"type(X_train.data): \", type(X_train.data))\n\nprint(\"X_train.data.shape: \", X_train.data.shape)\nprint(\"X_train.targets.shape: \", X_train.targets.shape)\n\nX_train_targets_numpy = X_train.targets.numpy()\nprint(\"type(X_train_targets_numpy), X_train_targets_numpy.shape: \", type(X_train_targets_numpy), X_train_targets_numpy.shape)\n\nprint(\"X_train_targets_numpy: \", X_train_targets_numpy)\n\nX_train_numpy = X_train.data.numpy()\n\nprint(\"type(X_train_numpy): \", type(X_train_numpy))\nprint(\"X_train_numpy.shape: \", X_train_numpy.shape)\n\nX_train_numpy = X_train_numpy.reshape((X_train_numpy.shape[0], -1), order='F')\nX_train_numpy = np.int64(X_train_numpy)\n\nprint(\"X_train_numpy.shape: \", X_train_numpy.shape)\n\ntrain_set = pd.DataFrame(X_train_numpy)\ntrain_set['label'] = X_train_targets_numpy\nprint(\"no. of train columns: \", len(train_set.columns))\n\nprint(\"train_set.dtypes: \", train_set.dtypes)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# shift column 'C' to first position \nfirst_column = train_set.pop('label') \n  \n# insert column using insert(position,column_name,first_column) function \ntrain_set.insert(0, 'label', first_column)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_samples = 50\n\nX_test = datasets.MNIST(root='./kaggle/input', train=False, download=True,\n                        transform=transforms.Compose([transforms.ToTensor()]))\n\nprint(type(X_test))\n\nidx = np.append(np.where(X_test.targets == 0)[0][:n_samples], \n                np.where(X_test.targets == 1)[0][:n_samples])\n\nX_test.data = X_test.data[idx]\nX_test.targets = X_test.targets[idx]\n\nX_test_targets_numpy = X_test.targets.numpy()\nprint(\"type(X_test_targets_numpy), X_test_targets_numpy.shape: \", type(X_test_targets_numpy), X_test_targets_numpy.shape)\n\nX_test_numpy = X_test.data.numpy()\nprint(\"type(X_test_numpy), X_test_numpy.shape: \", type(X_test_numpy), X_test_numpy.shape)\n\n\nX_test_numpy = X_test_numpy.reshape((X_test_numpy.shape[0], -1), order='F')\nX_test_numpy = np.int64(X_test_numpy)\nprint(\"X_test_numpy.shape: \", X_test_numpy.shape)\n\ntest_images = pd.DataFrame(X_test_numpy)\ntest_images['label'] = X_test_targets_numpy\nprint(\"no. of test columns: \", len(test_images.columns))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# shift column 'C' to first position \nfirst_column = test_images.pop('label') \n  \n# insert column using insert(position,column_name,first_column) function \ntest_images.insert(0, 'label', first_column)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_images.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set.dtypes.unique(), test_images.dtypes.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_set_csv = pd.read_csv(\"../input/mnist-in-csv/mnist_train.csv\")\n#train_set_csv.dtypes.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_set_csv.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_set_csv.label.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test_images_csv = pd.read_csv(\"../input/mnist-in-csv/mnist_test.csv\")\n#test_images_csv.dtypes.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_set = train_set_csv.loc[(train_set_csv[\"label\"] == 0) | (train_set_csv[\"label\"] == 1)]\n#train_set = train_set.head(200)\n#train_set.label.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test_images = test_images_csv.loc[(test_images_csv[\"label\"] == 0) | (test_images_csv[\"label\"] == 1)]\n#test_images = test_images.head(100)\n#test_images.label.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_images.label.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set.label.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Quick function that gets how many out of 'preds' match 'labels'\n# To be used much later\ndef get_num_correct(preds, labels):\n    #print(preds, labels)\n    #print(preds.argmax(dim=1).eq(labels).sum().item())\n    return preds.argmax(dim=1).eq(labels).sum().item()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the train set so there is also a validation set\ntrain_images, val_images, train_labels, val_labels = train_test_split(train_set.iloc[:, 1:], \n                                                                     train_set.iloc[:, 0], \n                                                                     test_size=0.2, random_state=23)\n\n# Reset indices so the Dataset can find them with __getitem__ easily\ntrain_images.reset_index(drop=True, inplace=True)\nval_images.reset_index(drop=True, inplace=True)\ntrain_labels.reset_index(drop=True, inplace=True)\nval_labels.reset_index(drop=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_images), len(val_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(train_labels), train_labels.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(val_labels), val_labels.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_columns', 28)\nval_images[-3:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images.shape, type(train_images), val_images.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_labels.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's just display a number as a dataframe for fun \n# (I think it looks cool, plus it led to something else I tried, mentioned in the last section)\npd.set_option('display.max_columns', 28)\npd.DataFrame(train_images.iloc[3, :].to_numpy().reshape(28, 28))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Some quick data visualization\n# (not a terribly exciting dataset)\n# First 25 images in training set\n# Note: label is above the image\n\nfig, ax = plt.subplots(nrows=5, ncols=5, figsize=(8,8))\nfig.subplots_adjust(hspace=.3)\nfor i in range(5):\n    for j in range(5):\n        ax[i][j].axis('off')\n        ax[i][j].imshow(train_images.iloc[[i+(j*5)], :].to_numpy().astype(np.uint8).reshape(28, 28), cmap='gray')\n        ax[i][j].set_title(train_labels[i+(j*5)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transformations\nIMG_SIZE = 28 # size of images in MNIST\n# Also the images only have one color channel\n# So 3D size = (1, 28, 28)\n\n# Transformations for the train\ntrain_trans = transforms.Compose(([\n    transforms.ToPILImage(),\n    transforms.RandomCrop(IMG_SIZE), \n    transforms.ToTensor(), # divides by 255\n  #  transforms.Normalize((0.5,), (0.5,))\n]))\n\n# Transformations for the validation & test sets\nval_trans = transforms.Compose(([\n    transforms.ToPILImage(),\n    transforms.ToTensor(), # divides by 255\n   # transforms.Normalize((0.1307,), (0.3081,))\n]))\n\n# did worse w/o RandomCrop, if someone can explain why \n# (or if I'm crazy and should try it again) \n# I'd love to hear about it in the comments","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Custom class for the MNIST dataset from Kaggle\n# Images come in a csv, not as actual images\n# Training set is split before given to this class\n\nclass MNISTDataSet(torch.utils.data.Dataset):\n    # images df, labels df, transforms\n    # uses labels to determine if it needs to return X & y or just X in __getitem__\n    def __init__(self, images, labels, transforms=None):\n        self.X = images\n        self.y = labels\n        self.transforms = transforms\n                    \n    def __len__(self):\n        return len(self.X)\n    \n    def __getitem__(self, i):\n        data = self.X.iloc[i, :] # gets the row\n        # reshape the row into the image size \n        # (numpy arrays have the color channels dim last)\n        data = np.array(data).astype(np.uint8).reshape(28, 28, 1) \n        \n        # perform transforms if there are any\n        if self.transforms:\n            data = self.transforms(data)\n        \n        # if !test_set return the label as well, otherwise don't\n        if self.y is not None: # train/val\n            return (data, self.y[i])\n        else: # test\n            return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"req_cols = list(test_images.columns)\nlen(req_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"req_cols.remove(\"label\")\nlen(req_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_images_no_label = test_images[req_cols]\ntest_images_no_label.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get datasets using the custom MNIST Dataset for the train, val, and test images\ntrain_set = MNISTDataSet(train_images, train_labels, train_trans)\nval_set = MNISTDataSet(val_images, val_labels, val_trans)\ntest_set = MNISTDataSet(test_images_no_label, None, val_trans)\n\n# Nice habit to get into\nnum_classes = 2 # 0-1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Network(nn.Module):\n    def __init__(self):\n        super(Network, self).__init__()\n        # image starts as (1, 28, 28)\n        # Formula to compute size of image after conv/pool\n        # (size-filter+2*padding / stride) + 1\n        #                      inputs         # of filters    filter size    \n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, stride=1, padding=2) # conv1\n        self.conv1_bn = nn.BatchNorm2d(num_features=32)\n        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=2) # conv2\n        self.conv2_bn = nn.BatchNorm2d(num_features=64)\n        self.conv3 = nn.Conv2d(in_channels=64, out_channels= 128, kernel_size=3, stride=1, padding=1) # conv3\n        self.conv3_bn = nn.BatchNorm2d(num_features=128)\n        \n        self.fc1 = nn.Linear(in_features=128*6*6, out_features=1024) # linear 1\n        self.fc1_bn = nn.BatchNorm1d(num_features=1024)\n        self.fc2 = nn.Linear(in_features=1024, out_features=512) # linear 2\n        self.fc2_bn = nn.BatchNorm1d(num_features=512)\n        self.fc3 = nn.Linear(in_features=512, out_features=256) # linear 3\n        self.fc3_bn = nn.BatchNorm1d(num_features=256)\n        self.fc4 = nn.Linear(in_features=256, out_features=64) # linear 4\n        self.fc4_bn = nn.BatchNorm1d(num_features=64)\n        self.out = nn.Linear(in_features=64, out_features=10) # output\n    \n    def forward(self, t):\n        t = F.relu(self.conv1_bn(self.conv1(t)))\n        t = F.max_pool2d(t, kernel_size=2, stride=2) # (1, 14, 14)\n        \n        t = F.relu(self.conv2_bn(self.conv2(t)))\n        t = F.max_pool2d(t, kernel_size=2, stride=2) # (1, 7, 7)\n        \n        t = F.relu(self.conv3_bn(self.conv3(t)))\n        t = F.max_pool2d(t, kernel_size=2, stride=1) # (1, 6, 6)\n        \n        t = F.relu(self.fc1_bn(self.fc1(t.reshape(-1, 128*6*6))))\n        t = F.relu(self.fc2_bn(self.fc2(t)))\n        t = F.relu(self.fc3_bn(self.fc3(t)))\n        t = F.relu(self.fc4_bn(self.fc4(t)))\n        t = self.out(t)\n        \n        return t","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = 0.001 # initial learning rate\nbatch_size = 100 # batch size\nepochs = 20 # number of epochs to run\n\nnetwork = Network().to(device) # put the model on device (hopefully a GPU!)\ntrain_dl = DataLoader(train_set, batch_size=batch_size, shuffle=True)\nval_dl = DataLoader(val_set, batch_size=batch_size, shuffle=False)\noptimizer = optim.Adam(network.parameters(), lr=lr)\n\nfor epoch in range(epochs):\n    print(\"Epoch: \", epoch+1)\n    epoch_loss = 0\n    epoch_correct = 0\n    network.train() # training mode\n    \n    # lessen the learning rate after 4 epochs (0,...,3)\n    if epoch == 4:\n        print(\" decreasing lr\")\n        optimizer = optim.Adam(network.parameters(), lr=0.00001)\n    \n    if epoch == 10: # not currently used\n        print(\" decreasing lr again\")\n        optimizer = optim.Adam(network.parameters(), lr=0.0000000000001)\n    \n    for images, labels in train_dl:\n        X, y = images.to(device), labels.to(device) # put X & y on device\n        y_ = network(X) # get predictions\n        \n        optimizer.zero_grad() # zeros out the gradients\n        loss = F.cross_entropy(y_, y) # computes the loss\n        loss.backward() # computes the gradients\n        optimizer.step() # updates weights\n        \n        epoch_loss += loss.item() * batch_size\n        epoch_correct += get_num_correct(y_, y)\n        \n    # Evaluation with the validation set\n    network.eval() # eval mode\n    val_loss = 0\n    val_correct = 0\n    with torch.no_grad():\n        for images, labels in val_dl:\n            X, y = images.to(device), labels.to(device) # to device\n            \n            preds = network(X) # get predictions\n            loss = F.cross_entropy(preds, y) # calculate the loss\n            \n            val_correct += get_num_correct(preds, y)\n            val_loss = loss.item() * batch_size\n    # Print the loss and accuracy for the validation set\n    print(\" Val Loss: \", val_loss)\n    print(\" Val Acc: \", (val_correct/len(val_images))*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use the validation set to make a confusion matrix\nnetwork.eval() # good habit I suppose\npredictions = torch.LongTensor().to(device) # Tensor for all predictions\n\n# Goes through the val set\n# Don't care about the associated labels\nfor images, _ in val_dl:\n    preds = network(images.to(device))\n    predictions = torch.cat((predictions, preds.argmax(dim=1)), dim=0)\n\npredictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predictions = [x if not x else 1 for x in predictions]\n# Make the confusion matrix\ncmt = torch.zeros(num_classes, num_classes, dtype=torch.int32)\nfor i in range(len(val_labels)):\n    cmt[val_labels[i], predictions[i]] += 1\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cmt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Time to get the network's predictions on the test set\n# Put the test set in a DataLoader\ntest_dl = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n\nnetwork.eval() # Safety first\npredictions = torch.LongTensor().to(device) # Tensor for all predictions\n\n# Go through the test set, saving the predictions in... 'predictions'\nfor images in test_dl:\n    preds = network(images.to(device))\n    predictions = torch.cat((predictions, preds.argmax(dim=1)), dim=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_true = test_images['label']\ny_pred = predictions.cpu().numpy()\n\nlen(y_true), len(y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_true, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}