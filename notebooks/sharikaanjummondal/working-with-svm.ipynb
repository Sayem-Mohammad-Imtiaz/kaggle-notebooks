{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/breast-cancer-wisconsin-data/data.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Knowing my data**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(columns=['Unnamed: 32','id'],inplace=True)  #dropping the columns that are not required at all\ndf.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['diagnosis'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# What does the column name depict?\n\n* Diagnosis (M = malignant, B = benign) \n* Radius (This is the mean distances from center to points on the perimeter) \n* Texture (This is the standard deviation of gray scale values) \n* Perimeter Area Smoothness (This is the local variation in radius lengths) \n* Compactness (This is the perimeter squared divided by the area and subtracted 1.0 from its value) (perimiter^2 / area - 10)\n* Concavity (Severity of convace portions of the contour ) \n* Concave points (Number of concave portions of the contour ) \n* Symmetry Fractal dimension (\"coastline approximation\" -1)\n\n*The mean, standard error and \"worst\" or largest which is actually the mean of the three largest values of these features were computed for each image, resulting in 30 features.* \n\n**This analysis aims to observe which features are most helpful in predicting malignant or benign cancer and to see general trends that may aid us in model selection and hyper parameter selection. The goal is to classify whether the breast cancer is benign or malignant.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Describing the head of the loaded dataframe \ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Defining my X and Y values**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.iloc[:,1:]\ny = df.iloc[:,0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Analysis**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Benign Vs Malignant\nvalue_count = df['diagnosis'].value_counts()  \nplt.figure()\n\n# Plotting the Count for the value counts in the diagnosis column\nvalue_count.plot(kind = \"bar\", color = \"blue\", rot=0)\nplt.ylabel(\"Counts\")\nplt.title(\"A bar chart showing the count of Benign Vs Malignant Labels\")\nplt.grid(True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Displaying a violin plot for all the features \nlabels = y \ninput_features = X\n\n# Normalizing the dataframe \ndata = (input_features - input_features.mean()) / (input_features.std())\ninput_features = pd.concat([y, data.iloc[:,:]], axis = 1)\n\ndata = pd.melt(input_features, id_vars = \"diagnosis\", var_name = \"features\", \n              value_name = \"value\")\n\n# Plotting the first Ten feature\nplt.figure(figsize = (18, 7))\nsns.violinplot(x = \"features\", y = \"value\", hue = \"diagnosis\", data = data, split = True, \n              inner = \"quart\")\nplt.xticks(rotation = 90)\nplt.grid(True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Displaying a Correlation matrix of all the features of the breast cancer dataset.\nf,ax = plt.subplots(figsize=(20, 18))\nsns.heatmap(X.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setting the figure of the Graph \nplt.figure(figsize=(18, 7))\n\n# Plotting a scatter plot of diagnosis against radius_mean\nplt.scatter(df['diagnosis'], df['radius_mean'])\n\n# Displaying the graph \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting a boxplot of the \"Area_mean\",\"area_se\" and \"area_worst\"\nboxplot = df.boxplot(column = [\"area_mean\",\"area_se\",\"area_worst\"], by=\"diagnosis\", \n                    layout = (3, 1), figsize=(19, 9))\n# Showing the boxplot\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting a boxplot of the means of different features\nboxplot = df.boxplot(column = [\"area_mean\",\"perimeter_mean\",\"compactness_mean\"], by=\"diagnosis\", \n                    layout = (3, 1), figsize=(19, 9))\n# Showing the boxplot\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting a boxplot of the means of different features\nboxplot = df.boxplot(column = [\"concave points_mean\",\"concavity_mean\",\"smoothness_mean\"], by=\"diagnosis\", \n                    layout = (3, 1), figsize=(19, 9))\n# Showing the boxplot\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting a boxplot of the means of different features\nboxplot = df.boxplot(column = [\"fractal_dimension_mean\",\"radius_mean\",\"symmetry_mean\",\"texture_mean\"], by=\"diagnosis\", \n                    layout = (4, 1), figsize=(19, 9))\n# Showing the boxplot\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Getting inside our model**\n\n**SVM**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating scaled set to be used in model to improve the results\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import Library of Support Vector Machine model\nfrom sklearn import svm\nfrom sklearn.model_selection import GridSearchCV\n\n# Create a Support Vector Classifier\nsvc = svm.SVC()\n\n# Hyperparameter Optimization\nparameters = [\n  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n]\n\n# Run the grid search\ngrid_obj = GridSearchCV(svc, parameters)\ngrid_obj = grid_obj.fit(X_train, y_train)\n\n# Set the svc to the best combination of parameters\nsvc = grid_obj.best_estimator_\n\n# Train the model using the training sets \nsvc.fit(X_train,y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prediction on test data\ny_pred = svc.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculating the accuracy\nfrom sklearn.metrics import accuracy_score\nacc_svm = round( accuracy_score(y_test, y_pred) * 100)\nprint( 'Accuracy of SVM model : ', acc_svm )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# The model is working at an accuracy of 97%\n\n**This notebook is a part of task on SVM**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}