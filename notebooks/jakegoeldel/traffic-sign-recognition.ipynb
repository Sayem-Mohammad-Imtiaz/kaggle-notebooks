{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Traffic Sign Recognition\n\nThis is a completed working classification network for the german traffic sign recognition database.\n\n**First We will load all the required libraries:**","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\n\n\"all set!\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-11T14:32:39.074421Z","iopub.execute_input":"2021-06-11T14:32:39.074979Z","iopub.status.idle":"2021-06-11T14:32:45.751858Z","shell.execute_reply.started":"2021-06-11T14:32:39.07493Z","shell.execute_reply":"2021-06-11T14:32:45.75103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading the data\n\nthe data is pre-split into training and testing data. It contains the following:\n- csv files for meta-data. All we care about from here is the class id, and path to the file.\n- The training images. These are organized by their type into different folders\n- The Test images. These are all together in the same folder.\n\n**Let's load the data:**","metadata":{}},{"cell_type":"code","source":"# Load the meta data\ntrain_data = pd.read_csv('/kaggle/input/gtsrb-german-traffic-sign/Train.csv')\ntest_data = pd.read_csv('/kaggle/input/gtsrb-german-traffic-sign/Test.csv')\n\n# Load the labels\ntrain_labels = train_data['ClassId']\ntest_labels = test_data['ClassId']\n\n# Load the images\ntrain_image_paths = train_data['Path'].apply(lambda x: '/kaggle/input/gtsrb-german-traffic-sign/' + x).tolist()\ntest_image_paths = test_data['Path'].apply(lambda x: '/kaggle/input/gtsrb-german-traffic-sign/' + x).tolist()\n\n# Test output to make sure we're all good\ntrain_images.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-11T14:39:34.252333Z","iopub.execute_input":"2021-06-11T14:39:34.252676Z","iopub.status.idle":"2021-06-11T14:45:20.261767Z","shell.execute_reply.started":"2021-06-11T14:39:34.252648Z","shell.execute_reply":"2021-06-11T14:45:20.260957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Now we'll load and create the actual images:**","metadata":{}},{"cell_type":"code","source":"# three things are happening in these lines:\n# 1. We are loading the images based of the file paths read in the previous cell.\n# 2. We are changing the images from cv2's default blue green red, to red green blue. \n# This doesn't change training, but if we were to view the images the colors would be wrong.\n# 3. scaling to 32 x 32 pixels. This will make training easier\ntrain_images = np.array([cv2.cvtColor(cv2.resize(cv2.imread(fname), (32, 32), interpolation = cv2.INTER_AREA), cv2.COLOR_BGR2RGB) for fname in train_image_paths])\ntest_images = np.array([cv2.cvtColor(cv2.resize(cv2.imread(fname), (32, 32), interpolation = cv2.INTER_AREA), cv2.COLOR_BGR2RGB) for fname in test_image_paths])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There's a couple more things we need to do, but we're almost ready.\n\n**Let's view an image to see how it looks:**","metadata":{}},{"cell_type":"code","source":"plt.figure()\nplt.imshow(train_images[101], cmap='gray')\nplt.colorbar()\nplt.grid(False)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-11T14:46:17.017928Z","iopub.execute_input":"2021-06-11T14:46:17.018431Z","iopub.status.idle":"2021-06-11T14:46:17.290663Z","shell.execute_reply.started":"2021-06-11T14:46:17.018387Z","shell.execute_reply":"2021-06-11T14:46:17.289774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It should be looking pretty good now, but the data isn't quite ready! This this model we will be using a grayscale image, so we need to convert to that. We are also going to want to scale the values down. Right now they are 0-255, but if we scale it to 0-1 it will train quite a bit faster.\n\n**Let's do both of those things now:**","metadata":{}},{"cell_type":"code","source":"train_images = np.sum(train_images/3, axis=3, keepdims=True)\ntrain_images = train_images / 255.0\n\ntest_images = np.sum(test_images/3, axis=3, keepdims=True)\ntest_images = test_images / 255.0","metadata":{"execution":{"iopub.status.busy":"2021-06-11T14:46:11.006894Z","iopub.execute_input":"2021-06-11T14:46:11.007358Z","iopub.status.idle":"2021-06-11T14:46:12.869006Z","shell.execute_reply.started":"2021-06-11T14:46:11.007324Z","shell.execute_reply":"2021-06-11T14:46:12.867901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training\n\nNow that the data is all ready, we can start training!\n\nFor this I am creating a convalutional nerual network with two convalutional layers, followed by two dense layers. Feel free to try different values for everything to see if you can get better results!\n\n**First we will need to create our model, then we will start training:**","metadata":{}},{"cell_type":"code","source":"# Create the model\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(filters = 6, kernel_size = (5, 5), strides=(1, 1), padding='valid', \n                        activation='relu', data_format = 'channels_last', input_shape = (32, 32, 1)),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.Conv2D(16, (5, 5), activation='relu'),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(43, activation='softmax')\n])\n\nmodel.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n\n# Train\nconv = model.fit(train_images, train_labels, batch_size=128, epochs=10, validation_data=(test_images, test_labels))","metadata":{"execution":{"iopub.status.busy":"2021-06-11T14:48:44.863996Z","iopub.execute_input":"2021-06-11T14:48:44.864529Z","iopub.status.idle":"2021-06-11T14:50:38.589387Z","shell.execute_reply.started":"2021-06-11T14:48:44.864482Z","shell.execute_reply":"2021-06-11T14:50:38.588411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Graph Accuracy and Loss to see how we did:\n\nacc = [conv.history['accuracy'], conv.history['val_accuracy']]\nloss = [conv.history['loss'], conv.history['val_loss']]\n\nepoch = range(10)\n\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nplt.plot(epoch, acc[0], label='Training Accuracy')\nplt.plot(epoch, acc[1], label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epoch, loss[0], label='Training Loss')\nplt.plot(epoch, loss[1], label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-11T14:50:44.531534Z","iopub.execute_input":"2021-06-11T14:50:44.531933Z","iopub.status.idle":"2021-06-11T14:50:44.845857Z","shell.execute_reply.started":"2021-06-11T14:50:44.531892Z","shell.execute_reply":"2021-06-11T14:50:44.844657Z"},"trusted":true},"execution_count":null,"outputs":[]}]}