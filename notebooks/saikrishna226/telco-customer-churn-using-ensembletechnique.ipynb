{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<span style=\"font-family: Arial; font-weight:bold;font-size:2.5em;color:#00b3e5;\">Ensemble Technique Project","metadata":{}},{"cell_type":"markdown","source":"**DOMAIN: Telecom**\n\n• **CONTEXT:** A telecom company wants to use their historical customer data to predict behaviour to retain customers. You can \nanalyse all relevant customer data and develop focused customer retention programs.\n\n• **DATA DESCRIPTION:** Each row represents a customer, each column contains customer’s attributes described on the column \nMetadata. The data set includes information about:\n\n• Customers who left within the last month – the column is called Churn.\n\n• Services that each customer has signed up for – phone, multiple lines, internet, online security, online backup, device \nprotection, tech support, and streaming TV and movies\n\n• Customer account information – how long they’ve been a customer, contract, payment method, paperless billing, monthly \ncharges, and total charges\n\n• Demographic info about customers – gender, age range, and if they have partners and dependents.\n\n• **PROJECT OBJECTIVE:** Build a model that will help to identify the potential customers who have a higher probability to churn. \nThis help the company to understand the pinpoints and patterns of customer churn and will increase the focus on strategising customer retention.","metadata":{}},{"cell_type":"code","source":"# Importing Libreries\nimport pandas as pd\nimport os\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom scipy import stats\n%matplotlib inline\nsns.set_style('darkgrid')\n%matplotlib inline\nfrom sklearn.preprocessing import MinMaxScaler\nfrom scipy.stats import zscore\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report\nfrom sklearn import model_selection\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:30.124236Z","iopub.execute_input":"2021-05-31T17:47:30.124807Z","iopub.status.idle":"2021-05-31T17:47:30.135542Z","shell.execute_reply.started":"2021-05-31T17:47:30.124756Z","shell.execute_reply":"2021-05-31T17:47:30.134744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"font-family: Arial; font-weight:bold;font-size:1.5em;color:#00b3e5;\"> 1.Importing datasets\n    \nThere are two datasets given\n    \n   1) TelcomCustomer-Churn_1.csv\n    \n   2) TelcomCustomer-Churn_2.csv","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.simplefilter(action='ignore', category=UserWarning)\nwarnings.simplefilter(action='ignore', category=DeprecationWarning)\ndf = pd.read_csv(\"../input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\ndf.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:30.138462Z","iopub.execute_input":"2021-05-31T17:47:30.138785Z","iopub.status.idle":"2021-05-31T17:47:30.197474Z","shell.execute_reply.started":"2021-05-31T17:47:30.13875Z","shell.execute_reply":"2021-05-31T17:47:30.19672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Shape and size of final dataset**","metadata":{}},{"cell_type":"code","source":"print(f\"Shape of final Dataset : {df.shape}\")\nprint(f\"Size of final Dataset : {df.size}\")","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:30.198751Z","iopub.execute_input":"2021-05-31T17:47:30.199147Z","iopub.status.idle":"2021-05-31T17:47:30.203571Z","shell.execute_reply.started":"2021-05-31T17:47:30.199108Z","shell.execute_reply":"2021-05-31T17:47:30.202905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Check any duplicate in data**","metadata":{}},{"cell_type":"code","source":"df[df.duplicated(keep = 'first')] #No Duplicates in the data","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:30.204766Z","iopub.execute_input":"2021-05-31T17:47:30.205015Z","iopub.status.idle":"2021-05-31T17:47:30.246817Z","shell.execute_reply.started":"2021-05-31T17:47:30.204991Z","shell.execute_reply":"2021-05-31T17:47:30.245987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Variable Descriptions:**\n\ngender --> Whether the customer is a male or a female\n\nSeniorCitizen --> Whether the customer is a senior citizen or not (1, 0)\n\nPartner --> Whether the customer has a partner or not (Yes, No)\n\nDependents --> Whether the customer has dependents or not (Yes, No)\n\ntenure --> Number of months the customer has stayed with the company\n\nPhoneService --> Whether the customer has a phone service or not (Yes, No)\n\nMultipleLines --> Whether the customer has multiple lines or not (Yes, No, No phone service)\n\nInternetService --> Customer’s internet service provider (DSL, Fiber optic, No)\n\nOnlineSecurity --> Whether the customer has online security or not (Yes, No, No internet service)\n\nOnlineBackup --> Whether the customer has online backup or not (Yes, No, No internet service)\n\nDeviceProtection --> Whether the customer has device protection or not (Yes, No, No internet service)\n\nTechSupport --> Whether the customer has tech support or not (Yes, No, No internet service)\n\nStreamingTV --> Whether the customer has streaming TV or not (Yes, No, No internet service)\n\nStreamingMovies --> Whether the customer has streaming movies or not (Yes, No, No internet service)\n\nContract --> The contract term of the customer (Month-to-month, One year, Two year)\n\nPaperlessBilling --> Whether the customer has paperless billing or not (Yes, No)\n\nPaymentMethod --> The customer’s payment method (Electronic check, Mailed check, Bank transfer (automatic), Credit card (automatic))\n\nMonthlyCharges --> The amount charged to the customer monthly\n\nTotalCharges --> The total amount charged to the customer\n\nChurn --> Whether the customer churned or not (Yes or No)","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-family: Arial; font-weight:bold;font-size:1.5em;color:#00b3e5;\"> 2.Data Cleansing","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:30.248021Z","iopub.execute_input":"2021-05-31T17:47:30.248314Z","iopub.status.idle":"2021-05-31T17:47:30.269971Z","shell.execute_reply.started":"2021-05-31T17:47:30.248286Z","shell.execute_reply":"2021-05-31T17:47:30.269149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" <span style=\"font-family: Arial; font-weight:bold;font-size:1.0em;color:#00b3e5;\">Missing value treatment","metadata":{}},{"cell_type":"code","source":"empty_cols=['customerID', 'gender', 'SeniorCitizen', 'Partner', 'Dependents',\n       'tenure', 'PhoneService', 'MultipleLines', 'InternetService',\n       'OnlineSecurity', 'OnlineBackup', 'DeviceProtection','TechSupport',\n       'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling',\n       'PaymentMethod', 'MonthlyCharges', 'TotalCharges', 'Churn']\nfor i in empty_cols:\n    df[i]=df[i].replace(\" \",np.nan)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:30.271757Z","iopub.execute_input":"2021-05-31T17:47:30.272287Z","iopub.status.idle":"2021-05-31T17:47:30.295674Z","shell.execute_reply.started":"2021-05-31T17:47:30.272253Z","shell.execute_reply":"2021-05-31T17:47:30.294622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:30.297225Z","iopub.execute_input":"2021-05-31T17:47:30.297502Z","iopub.status.idle":"2021-05-31T17:47:30.310917Z","shell.execute_reply.started":"2021-05-31T17:47:30.297477Z","shell.execute_reply":"2021-05-31T17:47:30.309799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observed 11 missing values in TotalCharges.**\n\n**Impute missing values with Mean.**","metadata":{}},{"cell_type":"markdown","source":"**Need to convert TotalObjects into float, because the values are continuous.**","metadata":{}},{"cell_type":"code","source":"df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"])","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:30.312541Z","iopub.execute_input":"2021-05-31T17:47:30.312989Z","iopub.status.idle":"2021-05-31T17:47:30.326395Z","shell.execute_reply.started":"2021-05-31T17:47:30.312949Z","shell.execute_reply":"2021-05-31T17:47:30.325319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.mean()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:30.328212Z","iopub.execute_input":"2021-05-31T17:47:30.328598Z","iopub.status.idle":"2021-05-31T17:47:30.457434Z","shell.execute_reply.started":"2021-05-31T17:47:30.328557Z","shell.execute_reply":"2021-05-31T17:47:30.456355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.fillna(df.mean(),inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:30.460508Z","iopub.execute_input":"2021-05-31T17:47:30.460863Z","iopub.status.idle":"2021-05-31T17:47:30.581989Z","shell.execute_reply.started":"2021-05-31T17:47:30.460828Z","shell.execute_reply":"2021-05-31T17:47:30.580789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Filled NaN values with mean of particular attribute, here the case is TotalCharges.**","metadata":{}},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:30.584077Z","iopub.execute_input":"2021-05-31T17:47:30.584394Z","iopub.status.idle":"2021-05-31T17:47:30.597533Z","shell.execute_reply.started":"2021-05-31T17:47:30.584364Z","shell.execute_reply":"2021-05-31T17:47:30.596299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Imputed missing values with Mean for TotalCharges.**","metadata":{}},{"cell_type":"code","source":"df_graph = df.copy() # This dataframe is used for preparing univariate and bivariate and multi variate.","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:30.599362Z","iopub.execute_input":"2021-05-31T17:47:30.599814Z","iopub.status.idle":"2021-05-31T17:47:30.611088Z","shell.execute_reply.started":"2021-05-31T17:47:30.599766Z","shell.execute_reply":"2021-05-31T17:47:30.609843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_graph.columns","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:30.612448Z","iopub.execute_input":"2021-05-31T17:47:30.612871Z","iopub.status.idle":"2021-05-31T17:47:30.622934Z","shell.execute_reply.started":"2021-05-31T17:47:30.612827Z","shell.execute_reply":"2021-05-31T17:47:30.621787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"font-family: Arial; font-weight:bold;font-size:1.0em;color:#00b3e5;\">Convert Categorical attributes to continuous.","metadata":{}},{"cell_type":"code","source":"col_obj = [c for c in df.columns if df[c].dtype == 'object'] # SeniorCitizen which is actually Object,but already the datatype is Int.\nfor col in col_obj:\n    uniques = sorted(df[col].unique())\n    print('{0:20s} {1:5d} \\t'.format(col,len(uniques)),uniques[:10])","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:30.624415Z","iopub.execute_input":"2021-05-31T17:47:30.6248Z","iopub.status.idle":"2021-05-31T17:47:30.651049Z","shell.execute_reply.started":"2021-05-31T17:47:30.624761Z","shell.execute_reply":"2021-05-31T17:47:30.650092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We are converting attributes having Yes=1, No=0 as an item into continuous.**","metadata":{}},{"cell_type":"code","source":"df.gender = [1 if each == \"Male\" else 0 for each in df.gender]\n\ncolumns_to_convert = ['Partner',\n                      'Dependents',\n                      'PhoneService',\n                      'PaperlessBilling',\n                      'Churn']\n\nfor item in columns_to_convert:\n    df[item] = [1 if each == \"Yes\" else 0 for each in df[item]]\n    \ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:30.652988Z","iopub.execute_input":"2021-05-31T17:47:30.653312Z","iopub.status.idle":"2021-05-31T17:47:30.705006Z","shell.execute_reply.started":"2021-05-31T17:47:30.653281Z","shell.execute_reply":"2021-05-31T17:47:30.703965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Converting categorical attributes, using get dummies from pandas, to continuous.**\n\n(**Pandas.get_dummies:** This method converts string columns into one-hot representation unless particular columns are specified.)\n\n(**OneHotEncoder:** It cannot process string values directly. If your input features are strings, then you should first map them into integers.)\n\nSo better is Get dummies, where we specify columns and convert dtype.","metadata":{}},{"cell_type":"code","source":"category_cols=['InternetService','Contract', 'PaymentMethod', 'OnlineSecurity','MultipleLines',\n                      'OnlineBackup',\n                      'DeviceProtection',\n                      'TechSupport',\n                      'StreamingTV',\n                      'StreamingMovies',]\n\nfor cc in category_cols:\n    dummies = pd.get_dummies(df[cc], drop_first=False)\n    dummies = dummies.add_prefix(\"{}#\".format(cc))\n    df.drop(cc, axis=1, inplace=True)\n    df = df.join(dummies)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:30.706286Z","iopub.execute_input":"2021-05-31T17:47:30.706543Z","iopub.status.idle":"2021-05-31T17:47:30.789556Z","shell.execute_reply.started":"2021-05-31T17:47:30.706518Z","shell.execute_reply":"2021-05-31T17:47:30.788423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Drop customer ID, because it doesn't influence on target variable.**","metadata":{}},{"cell_type":"code","source":"df.drop('customerID',axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:30.791741Z","iopub.execute_input":"2021-05-31T17:47:30.792159Z","iopub.status.idle":"2021-05-31T17:47:30.798762Z","shell.execute_reply.started":"2021-05-31T17:47:30.792117Z","shell.execute_reply":"2021-05-31T17:47:30.797243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.tail(1)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:30.800106Z","iopub.execute_input":"2021-05-31T17:47:30.800417Z","iopub.status.idle":"2021-05-31T17:47:30.823986Z","shell.execute_reply.started":"2021-05-31T17:47:30.800386Z","shell.execute_reply":"2021-05-31T17:47:30.822809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:30.825289Z","iopub.execute_input":"2021-05-31T17:47:30.825849Z","iopub.status.idle":"2021-05-31T17:47:30.832474Z","shell.execute_reply.started":"2021-05-31T17:47:30.825811Z","shell.execute_reply":"2021-05-31T17:47:30.831767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Examining correlation of \"Churn\" with other features**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,8))\ndf.corr()['Churn'].sort_values(ascending = False).plot(kind='bar')","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:30.833628Z","iopub.execute_input":"2021-05-31T17:47:30.833898Z","iopub.status.idle":"2021-05-31T17:47:31.461403Z","shell.execute_reply.started":"2021-05-31T17:47:30.833872Z","shell.execute_reply":"2021-05-31T17:47:31.460242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations**\n\nMonth to month contracts, absence of online security and tech support seem to be positively correlated with churn. While, tenure, two year contracts seem to be negatively correlated with churn.\n\nInterestingly, services such as Online security, streaming TV, online backup, tech support, etc. without internet connection seem to be negatively related to churn.\n\nPhoneService, Gender and MultipleLines#No phone service doesn't influence churn much.","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:31.462889Z","iopub.execute_input":"2021-05-31T17:47:31.463459Z","iopub.status.idle":"2021-05-31T17:47:31.482258Z","shell.execute_reply.started":"2021-05-31T17:47:31.463413Z","shell.execute_reply":"2021-05-31T17:47:31.481175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking Correlation Heatmap\nplt.figure(dpi = 540,figsize= (30,25))\nmask = np.triu(np.ones_like(df.corr()))\nsns.heatmap(df.corr(),mask = mask, fmt = \".2f\",annot=True,lw=1,cmap = 'plasma')\nplt.yticks(rotation = 0)\nplt.xticks(rotation = 90)\nplt.title('Correlation Heatmap')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:31.483581Z","iopub.execute_input":"2021-05-31T17:47:31.484182Z","iopub.status.idle":"2021-05-31T17:47:47.295362Z","shell.execute_reply.started":"2021-05-31T17:47:31.484138Z","shell.execute_reply":"2021-05-31T17:47:47.292102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We can observe that \"No Internet service\" in OnlineSecurity, OnlineBackup,DeviceProtection,    TechSupport,StreamingTV,StreamingMovies, highly correlated with other and all these are highly correlated with Internetservice#No.**\n\n**MultipleLines#No phone service and Phone service 100% negatively correlated**\n\n**Lets drop MultipleLines#No phone service and \"No Internet service\" in OnlineSecurity, OnlineBackup,DeviceProtection,TechSupport,StreamingTV,StreamingMovies keeping Internetservice#No**","metadata":{}},{"cell_type":"code","source":"df.drop(['OnlineSecurity#No internet service',\n         'OnlineBackup#No internet service',\n        'DeviceProtection#No internet service',\n        'StreamingTV#No internet service',\n        'TechSupport#No internet service',\n         'MultipleLines#No phone service',\n        'StreamingMovies#No internet service'], axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:47.297619Z","iopub.execute_input":"2021-05-31T17:47:47.298163Z","iopub.status.idle":"2021-05-31T17:47:47.307244Z","shell.execute_reply.started":"2021-05-31T17:47:47.29811Z","shell.execute_reply":"2021-05-31T17:47:47.306492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:47.308347Z","iopub.execute_input":"2021-05-31T17:47:47.308819Z","iopub.status.idle":"2021-05-31T17:47:47.343865Z","shell.execute_reply.started":"2021-05-31T17:47:47.308773Z","shell.execute_reply":"2021-05-31T17:47:47.342718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"font-family: Arial; font-weight:bold;font-size:1.5em;color:#00b3e5;\"> 3.Data Analysis and Visualization","metadata":{}},{"cell_type":"code","source":"df.describe().T","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:47.345161Z","iopub.execute_input":"2021-05-31T17:47:47.345419Z","iopub.status.idle":"2021-05-31T17:47:47.44136Z","shell.execute_reply.started":"2021-05-31T17:47:47.345394Z","shell.execute_reply":"2021-05-31T17:47:47.440366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"font-family: Arial; font-weight:bold;font-size:1.5em;color:#00b3e5;\"> Univariate and Bivariate Analysis","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,6))\nplt.subplot(1, 3, 1)\nplt.title('tenure')\nsns.histplot(df['tenure'],color='green',kde = True)\n\n# subplot 2\nplt.subplot(1, 3, 2)\nplt.title('MonthlyCharges')\nsns.histplot(df['MonthlyCharges'],color='blue',kde = True)\n\n# subplot 3\nplt.subplot(1, 3, 3)\nplt.title('TotalCharges')\nsns.histplot(df['TotalCharges'],color='red', kde = True)\n","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:47.442528Z","iopub.execute_input":"2021-05-31T17:47:47.442812Z","iopub.status.idle":"2021-05-31T17:47:48.204449Z","shell.execute_reply.started":"2021-05-31T17:47:47.442784Z","shell.execute_reply":"2021-05-31T17:47:48.203445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Tenure distribution looks better and density is more at lower and higher side.**\n\n**Customers whose monthly charges are more when considered less than 30. but most number of customer lies between 70-100.**\n\n**Customers who pay total charges more than 2000 are few.**","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 3)\nfig.set_figheight(5)\nfig.set_figwidth(18)\nsns.boxplot(x='Churn', y ='tenure', data=df, ax=ax[0])\nsns.boxplot(x='Churn', y ='MonthlyCharges', data= df, ax=ax[1])\nsns.boxplot(x='Churn', y='TotalCharges',data=df, ax=ax[2])\nax[0].set_title(\"Customer churn out based on tenure\",fontsize=15)\nax[1].set_title('Customer churn out based on MonthlyCharges',fontsize=15)\nax[2].set_title('Customer churn out based on TotalCharges',fontsize=15)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:48.205593Z","iopub.execute_input":"2021-05-31T17:47:48.205857Z","iopub.status.idle":"2021-05-31T17:47:48.732991Z","shell.execute_reply.started":"2021-05-31T17:47:48.205832Z","shell.execute_reply":"2021-05-31T17:47:48.73221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations :**\n\n**Customers opting for less tenure are more propable to churn.**\n\n**Customers whose monthly charges are more propable to churn.**\n\n**Customers who paying total charges less than 2000 are more probable to churn.**","metadata":{}},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:48.73398Z","iopub.execute_input":"2021-05-31T17:47:48.734351Z","iopub.status.idle":"2021-05-31T17:47:48.740231Z","shell.execute_reply.started":"2021-05-31T17:47:48.734324Z","shell.execute_reply":"2021-05-31T17:47:48.738922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns = ['gender', 'SeniorCitizen', 'Partner', 'Dependents',\n       'PhoneService', 'MultipleLines', 'InternetService',\n       'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',\n       'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling',\n       'PaymentMethod',]","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:48.741496Z","iopub.execute_input":"2021-05-31T17:47:48.74179Z","iopub.status.idle":"2021-05-31T17:47:48.755951Z","shell.execute_reply.started":"2021-05-31T17:47:48.74176Z","shell.execute_reply":"2021-05-31T17:47:48.754899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import copy\n\na = 10  # number of rows\nb = 3  # number of columns\nc = 1  # initialize plot counter\n\nfig = plt.figure(figsize=(20,80))\n\nfor i in range(len(columns)):\n    xx = copy.deepcopy(columns)\n    plt.subplot(a, b, c)\n    plt.title('{}'.format(i))\n    plt.xlabel(xx[i])\n    sns.countplot(x=xx[i], hue=\"Churn\", data=df_graph)\n    c = c + 1\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:48.757355Z","iopub.execute_input":"2021-05-31T17:47:48.757674Z","iopub.status.idle":"2021-05-31T17:47:51.153427Z","shell.execute_reply.started":"2021-05-31T17:47:48.757643Z","shell.execute_reply":"2021-05-31T17:47:51.152479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Observation :\n\nWe can observe gender churn out are same in male and female.\n\nCustomers churn out is more who dont have partner and dependents, having phone service, internet service with fiber optics, no online security, no online backup, no device protection, no tech support, streaming tv, streaming movies, having month-to-month contract, paperlessbilling, having electronic check in payment method.","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-family: Arial; font-weight:bold;font-size:1.5em;color:#00b3e5;\"> Multivariate Analysis","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(5, 2, sharex=True, figsize=(20, 10))\nfig.suptitle('Summary')\nsns.barplot(ax=axes[0, 0], x=\"tenure\", y=\"Contract\", hue=\"gender\", data=df_graph,orient=\"h\")\nsns.barplot(ax=axes[0, 1], x=\"tenure\", y=\"Contract\", hue=\"PaymentMethod\", data=df_graph,orient=\"h\")\nsns.barplot(ax=axes[1, 0], x=\"tenure\", y=\"StreamingMovies\", hue=\"gender\", data=df_graph,orient=\"h\")\nsns.barplot(ax=axes[1, 1], x=\"tenure\", y=\"StreamingMovies\", hue=\"Partner\", data=df_graph,orient=\"h\")\nsns.barplot(ax=axes[2, 0], x=\"MonthlyCharges\", y=\"InternetService\", hue=\"StreamingTV\", data=df_graph,orient=\"h\")\nsns.barplot(ax=axes[2, 1], x=\"tenure\", y=\"OnlineSecurity\", hue=\"DeviceProtection\", data=df_graph,orient=\"h\")\nsns.barplot(ax=axes[3, 0], x=\"tenure\", y=\"OnlineSecurity\", hue=\"InternetService\", data=df_graph,orient=\"h\")\nsns.barplot(ax=axes[3, 1], x=\"tenure\", y=\"Contract\", hue=\"PaperlessBilling\", data=df_graph,orient=\"h\")\nsns.barplot(ax=axes[4, 0], x=\"tenure\", y=\"Contract\", hue=\"SeniorCitizen\", data=df_graph,orient=\"h\")\nsns.barplot(ax=axes[4, 1], x=\"tenure\", y=\"InternetService\", hue=\"SeniorCitizen\", data=df_graph,orient=\"h\")","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:51.159242Z","iopub.execute_input":"2021-05-31T17:47:51.159578Z","iopub.status.idle":"2021-05-31T17:47:55.011751Z","shell.execute_reply.started":"2021-05-31T17:47:51.159545Z","shell.execute_reply":"2021-05-31T17:47:55.010592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the left to the right:\n\nNo significant info can be recorded with Contract , Gender and Tenure features, same behaviour between males and females.\n\nPayment methods : the favorite means of payments are Electronic Check, Bank transfer and credit card, Mailed check is the less used in all contracts types.\n\nNo significant info can be recorded with Internet Service , Gender and Tenure features, same behaviour between males and females.\n\nStreaming Movies : the most custmers that consume this service are partners\n\nOptic fiber is expensive. (I guess this is why customers are leaving out this product)\n\nSome people have device protection without online protection (weird , the company should tell them that it not necessery and they can be rewarded with a usefull service instead.. in order to gain customers trust :))\n\nInternet Service custmers with large tenure tend to make online Security.\n\nLarge tenure is significant whith paperless billing ( The company should prioritizee this mean of payment).","metadata":{}},{"cell_type":"markdown","source":"**Correlation of churn with respect to other features.**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,8))\ndf.corr()['Churn'].sort_values(ascending = False).plot(kind='bar')","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:55.014917Z","iopub.execute_input":"2021-05-31T17:47:55.015234Z","iopub.status.idle":"2021-05-31T17:47:55.486797Z","shell.execute_reply.started":"2021-05-31T17:47:55.015205Z","shell.execute_reply":"2021-05-31T17:47:55.485866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observation :**\n    \nThere are few variables showing positive impact on churn out. \n\nGender is not influencing the churn out, also checked in bivariate and multivariate, behaviour is same in male and female. \n\nThere are other variables showing negative impct on churn out.","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-family: Arial; font-weight:bold;font-size:2.0em;color:#00b3e5;\"> Hypothesis Testing","metadata":{}},{"cell_type":"markdown","source":"An assumption of few variables showing postive impact are true or not.\n\n**Does these variables have significant impact on churn.**\n\n**Chi square Test** to solve this assumption\n\nThe Chi-square test of independence determines whether there is a statistically significant relationship between categorical variables. It is a hypothesis test that answers the question—do the values of one categorical variable depend on the value of other categorical variables?\n\nThe Chi-square test of association evaluates relationships between categorical variables. Like any statistical hypothesis test, the Chi-square test has both a null hypothesis and an alternative hypothesis.\n\n**Null hypothesis:** There are no relationships between the categorical variables. If you know the value of one variable, it does not help you predict the value of another variable.\n\n**Alternative hypothesis:** There are relationships between the categorical variables. Knowing the value of one variable does help you predict the value of another variable.","metadata":{}},{"cell_type":"code","source":"['Contract#Month-to-month','OnlineSecurity#No','TechSupport#No','InternetService#Fiber optic',\n 'PaymentMethod#Electronic check','DeviceProtection#No','OnlineBackup#No', 'PaperlessBilling','SeniorCitizen',\n 'StreamingTV#No', 'StreamingTV#Yes','StreamingMovies#No', 'StreamingMovies#Yes']","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:55.488346Z","iopub.execute_input":"2021-05-31T17:47:55.488732Z","iopub.status.idle":"2021-05-31T17:47:55.49485Z","shell.execute_reply.started":"2021-05-31T17:47:55.488678Z","shell.execute_reply":"2021-05-31T17:47:55.494013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"var = ['Contract#Month-to-month','OnlineSecurity#No','TechSupport#No','InternetService#Fiber optic',\n 'PaymentMethod#Electronic check','DeviceProtection#No','OnlineBackup#No', 'PaperlessBilling','SeniorCitizen',\n 'StreamingTV#No', 'StreamingTV#Yes','StreamingMovies#No', 'StreamingMovies#Yes']\n# does these variables have positive impact on churn\nfor i in var:\n    df_var = pd.pivot_table(data=df,index='Churn',columns= i,aggfunc='size')\n    chi_sq_Stat, p_value, deg_freedom, exp_freq = stats.chi2_contingency(df_var)\n    print(\"{}Chi statistics of {}\".format('\\033[92m',i))\n    print('{} chi_sq_Stat: {}'.format('\\033[92m',chi_sq_Stat))\n    print('{} p_value: {}'.format('\\033[92m',p_value))\n    print('{} deg_freedom: {}'.format('\\033[92m',deg_freedom))\n    if p_value < 0.05:  # Setting our significance level at 5%\n        print('{} Rejecting Null Hypothesis.Means {} has significant impact on churn'.format('\\033[92m',i))\n    else:\n        print('{} Fail to Reject Null Hypothesis. Means {} has no significant impact on churn'.format('\\033[92m',i))\n    print('\\n')","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:55.496295Z","iopub.execute_input":"2021-05-31T17:47:55.496658Z","iopub.status.idle":"2021-05-31T17:47:55.606268Z","shell.execute_reply.started":"2021-05-31T17:47:55.496618Z","shell.execute_reply":"2021-05-31T17:47:55.60519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"font-family: Arial; font-weight:bold;font-size:1.0em;color:#00b3e5;\"> An aussumption of positive impact on churn is proved true, means they have a significant impact on churn.\n\n“Fiber_Optic” is on top position in terms of a positive impact on churn. While we would expect that this makes a customer stay, as it provides him with fast internet, our model says different. May be It because its expensive. ","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-family: Arial; font-weight:bold;font-size:1.5em;color:#00b3e5;\">4.Data pre-processing","metadata":{}},{"cell_type":"markdown","source":"**Distribution of Target Variable.**","metadata":{}},{"cell_type":"code","source":"count_no_churn = (df['Churn'] == 0).sum()\nprint(\"Number of customers who didn't churn:\",count_no_churn)\ncount_yes_churn = (df['Churn']==1).sum()\nprint(\"Number of customers who churnes:\",count_yes_churn)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:55.607671Z","iopub.execute_input":"2021-05-31T17:47:55.608107Z","iopub.status.idle":"2021-05-31T17:47:55.615583Z","shell.execute_reply.started":"2021-05-31T17:47:55.608064Z","shell.execute_reply":"2021-05-31T17:47:55.614775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20,8))\nwidth = len(df['Churn'].unique())+6\nfig.set_size_inches(width , 8)\nax=sns.countplot(data = df, x= 'Churn') \n\n\n\nfor p in ax.patches: \n    ax.annotate(str((np.round(p.get_height()/len(df)*100,decimals=2)))+'%', (p.get_x()+p.get_width()/2., p.get_height()), ha='center', va='center', xytext=(0, 10), textcoords='offset points')\n","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:55.616525Z","iopub.execute_input":"2021-05-31T17:47:55.616812Z","iopub.status.idle":"2021-05-31T17:47:55.750653Z","shell.execute_reply.started":"2021-05-31T17:47:55.616783Z","shell.execute_reply":"2021-05-31T17:47:55.749828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Imbalance in dataset:**\n\nAs we could see, our Target variable is not equally distributed, only 26.54% of customers have Churned. So, if our model is going to learn from this dataset and do the prediction chances are there that it might be biased towards the Majority class (In this case , customers who are not churned out) and ignore the minority class. Hence , we should try to balance our dataset to make our model learn and predict with being biased and treat both classes equally for better result.","metadata":{}},{"cell_type":"markdown","source":"**Balancing the Target Variable**\n\nSo I am going to balance the target variable with SMOTE (Synthetic Minority Oversampling Technique). With our training data created, I’ll up-sample minority sample( in our case the 'yes_churn' (customers who churn) sample using the SMOTE algorithm. At a high level, SMOTE:\n\n1.Works by creating synthetic samples from the minor class ( yes-churn) instead of creating copies.\n\n2.Randomly choosing one of the k-nearest-neighbors and using it to create a similar, but randomly tweaked, new observations.","metadata":{}},{"cell_type":"markdown","source":" **Segregate predictors vs target attributes.**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX = df.loc[:, df.columns != 'Churn']\ny = df.loc[:, df.columns == 'Churn']\nprint('Shape of X: {}'.format(X.shape))\nprint('Shape of y: {}'.format(y.shape))","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:55.751864Z","iopub.execute_input":"2021-05-31T17:47:55.752133Z","iopub.status.idle":"2021-05-31T17:47:55.762731Z","shell.execute_reply.started":"2021-05-31T17:47:55.752105Z","shell.execute_reply":"2021-05-31T17:47:55.761819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Standardization (Scaling) for numerical variables**","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\ncols_to_scale = [\"MonthlyCharges\",\"TotalCharges\",\"tenure\"]\nscaler=StandardScaler()\nX[cols_to_scale]=scaler.fit_transform(X[cols_to_scale])\nX.sample(5)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:55.763845Z","iopub.execute_input":"2021-05-31T17:47:55.764109Z","iopub.status.idle":"2021-05-31T17:47:55.802913Z","shell.execute_reply.started":"2021-05-31T17:47:55.764083Z","shell.execute_reply":"2021-05-31T17:47:55.801985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Training Data=70%, Test Data=30%**","metadata":{}},{"cell_type":"code","source":"\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n\nprint(\"Number transactions X_train dataset: \", X_train.shape)\nprint(\"Number transactions y_train dataset: \", y_train.shape)\nprint(\"Number transactions X_test dataset: \", X_test.shape)\nprint(\"Number transactions y_test dataset: \", y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:55.804273Z","iopub.execute_input":"2021-05-31T17:47:55.804659Z","iopub.status.idle":"2021-05-31T17:47:55.816881Z","shell.execute_reply.started":"2021-05-31T17:47:55.804619Z","shell.execute_reply":"2021-05-31T17:47:55.81585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#!pip install -U imbalanced-learn\n\nfrom imblearn.over_sampling import SMOTE\n\nsm = SMOTE(random_state=0)\nX_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n\nprint('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))\nprint('After OverSampling, the shape of train_y: {}'.format(y_train_res.shape))\n\n","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:55.818515Z","iopub.execute_input":"2021-05-31T17:47:55.819119Z","iopub.status.idle":"2021-05-31T17:47:56.130013Z","shell.execute_reply.started":"2021-05-31T17:47:55.819072Z","shell.execute_reply":"2021-05-31T17:47:56.128979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we have a perfect balanced data!I only **over-sampled on the training data**, because by oversampling only on the training data, **none of the information in the test data is being used to create synthetic observations**, therefore, no information will bleed from test data into the model training.","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-family: Arial; font-weight:bold;font-size:1.0em;color:#00b3e5;\">Check if the train and test data have similar statistical characteristics when compared with original data","metadata":{}},{"cell_type":"markdown","source":"**To check similar charecteristics, we will consider one sample from train data and another similar sample from test and compare them separetly with population of Original data.** \n\nTo do this we will do hypopthesis testing using one sample Z-Test.\n\n**z  tests** are a statistical way of testing a hypothesis when either:\n\nWe know the population variance, or\nWe do not know the population variance but our sample size is large n ≥ 30\n\nWe perform the **One-Sample Z test** when we want to compare a sample mean with the population mean.\n\nSE = Sd/np.sqrt(N)\nz_stat = (x_bar - mu)/SE\n\nwhere,\nX¯: mean of the sample.\n\nmu: mean of the population.\n\nSd: Standard deviation of the population.\n\nn: sample size.","metadata":{}},{"cell_type":"markdown","source":"**Lets consider MonthlyCharges attribute as a sample (its having positive impact and its numeric) to check similar charecteristics**","metadata":{}},{"cell_type":"markdown","source":"**Population from Original data**","metadata":{}},{"cell_type":"code","source":"Original = X['MonthlyCharges']\nmu = Original.mean()\nsigma = Original.std(ddof=0)\nprint(\"mu: \", mu, \", sigma:\", sigma)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:56.131622Z","iopub.execute_input":"2021-05-31T17:47:56.132276Z","iopub.status.idle":"2021-05-31T17:47:56.141227Z","shell.execute_reply.started":"2021-05-31T17:47:56.132233Z","shell.execute_reply":"2021-05-31T17:47:56.139831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Sample from Train data**","metadata":{}},{"cell_type":"code","source":"train = X_train['MonthlyCharges']\nX_bar = train.mean()\nn= X_train['MonthlyCharges'].size\nprint(\"X_Bar: \", X_bar, \", n:\", n)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:56.143318Z","iopub.execute_input":"2021-05-31T17:47:56.144116Z","iopub.status.idle":"2021-05-31T17:47:56.152892Z","shell.execute_reply.started":"2021-05-31T17:47:56.144071Z","shell.execute_reply":"2021-05-31T17:47:56.151768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Train and Test data is having similar charecteristics with Original data\n\n* H<sub>0</sub>: The sample from train or test data comes from the original  population, x_bar = &mu;.\n* H<sub>A</sub>: The sample from train or test data not comes from the original population, x_bar != (not equal) &mu;.","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\nz_critical = 1.96 # alpha level of 0.05 and two-tailed test\nSE = sigma/np.sqrt(n)\nz_stat = (X_bar - mu)/SE\nprint(z_stat)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:56.155136Z","iopub.execute_input":"2021-05-31T17:47:56.155821Z","iopub.status.idle":"2021-05-31T17:47:56.162276Z","shell.execute_reply.started":"2021-05-31T17:47:56.155778Z","shell.execute_reply":"2021-05-31T17:47:56.161571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Sample from Test Data**","metadata":{}},{"cell_type":"code","source":"test = X_test['MonthlyCharges']\nX_bar_Test = test.mean()\nn2= X_test['MonthlyCharges'].size\nprint(\"X_Bar: \", X_bar_Test, \", n:\", n2)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:56.163725Z","iopub.execute_input":"2021-05-31T17:47:56.164349Z","iopub.status.idle":"2021-05-31T17:47:56.178592Z","shell.execute_reply.started":"2021-05-31T17:47:56.164305Z","shell.execute_reply":"2021-05-31T17:47:56.176717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\nz_critical = 1.96 # alpha level of 0.05 and two-tailed test\nSE = sigma/np.sqrt(n2)\nz_stat = (X_bar_Test - mu)/SE\nprint(z_stat)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:56.180042Z","iopub.execute_input":"2021-05-31T17:47:56.180642Z","iopub.status.idle":"2021-05-31T17:47:56.188616Z","shell.execute_reply.started":"2021-05-31T17:47:56.180608Z","shell.execute_reply":"2021-05-31T17:47:56.18756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since z_stat is less than z_critical we accept the null hypothesis and reject the althernative. Statistically, we say the train and test  sample mean is no different than the population mean and thus the train and test sample is drawn from the population.\n\nWe can conclude that test and train have similar characteristics when compared with original data.","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-family: Arial; font-weight:bold;font-size:1.5em;color:#00b3e5;\">5.Model training, testing and tuning","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\n#!pip install catboost\nfrom catboost import CatBoostClassifier\n#!pip install xgboost\nfrom xgboost import XGBClassifier\n#!pip install lightgbm\nfrom lightgbm import LGBMClassifier\nfrom sklearn.linear_model import RidgeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split, GridSearchCV, RandomizedSearchCV,StratifiedKFold\nfrom sklearn.metrics import accuracy_score,confusion_matrix,roc_auc_score,ConfusionMatrixDisplay,precision_score,recall_score,f1_score,classification_report,roc_curve,plot_roc_curve,auc,precision_recall_curve,plot_precision_recall_curve,average_precision_score\nfrom sklearn.ensemble import VotingClassifier","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:56.189719Z","iopub.execute_input":"2021-05-31T17:47:56.189986Z","iopub.status.idle":"2021-05-31T17:47:56.685069Z","shell.execute_reply.started":"2021-05-31T17:47:56.189955Z","shell.execute_reply":"2021-05-31T17:47:56.684171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Ensemble Algorithms\nmodels = []\nmodels.append(['XGBClassifier',XGBClassifier(learning_rate=0.1,objective='binary:logistic',random_state=0,eval_metric='mlogloss')])\nmodels.append(['RandomForest',RandomForestClassifier(random_state=0)])\nmodels.append(['AdaBoostClassifier',AdaBoostClassifier()])\nmodels.append(['GBClassifier',GradientBoostingClassifier(n_estimators = 50, learning_rate = 0.1, random_state=0)])\nmodels.append(['LGBMClassifier',LGBMClassifier(random_state=0)])\nmodels.append(['CatBoostClassifier',CatBoostClassifier(learning_rate=0.1,loss_function= 'Logloss', eval_metric='AUC',random_state=0)])\nmodels.append(['BaggingClassifier', BaggingClassifier(n_estimators=50, max_samples= .7, bootstrap=True, oob_score=True, random_state=22)])\n\n# For hybrid model preparation\nHybrid = []\nHybrid.append(['RidgeClassifier',RidgeClassifier()])\nHybrid.append(['Logistic Regression',LogisticRegression(random_state=0)])\nHybrid.append(['SVM',SVC(random_state=0)])\nHybrid.append(['KNeigbors',KNeighborsClassifier()])\nHybrid.append(['GaussianNB',GaussianNB()])\nHybrid.append(['BernoulliNB',BernoulliNB()])\nHybrid.append(['DecisionTree',DecisionTreeClassifier(random_state=0)])","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:56.686538Z","iopub.execute_input":"2021-05-31T17:47:56.686964Z","iopub.status.idle":"2021-05-31T17:47:56.699889Z","shell.execute_reply.started":"2021-05-31T17:47:56.686933Z","shell.execute_reply":"2021-05-31T17:47:56.698812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Each model outcome is stored in the \"lst_2\" to prepare the table.** ","metadata":{}},{"cell_type":"code","source":"lst_1 = []\nfor m in range(len(models)):\n    lst_2 = []\n    model = models[m][1]\n    model.fit(X_train_res,y_train_res)\n    y_pred = model.predict(X_test)\n    y_train_pred = model.predict(X_train_res)\n    cm = confusion_matrix(y_test,y_pred)\n    accuracies = cross_val_score(estimator= model, X = X_train_res,y = y_train_res, cv=10)\n\n# k-fOLD Validation\n    roc = roc_auc_score(y_test,y_pred)\n    precision = precision_score(y_test,y_pred)\n    recall = recall_score(y_test,y_pred)\n    f1 = f1_score(y_test,y_pred)\n    print(models[m][0],':')\n    print(cm)\n    print('')\n    print('Train Accuracy Score: ',accuracy_score(y_train_res,y_train_pred))\n    print('')\n    print('Test Accuracy Score: ',accuracy_score(y_test,y_pred))\n    print('')\n    print('K-Fold Validation Mean Accuracy: {:.2f} %'.format(accuracies.mean()*100))\n    print('')\n    print('Standard Deviation: {:.2f} %'.format(accuracies.std()*100))\n    print('')\n    print('ROC AUC Score: {:.2f} %'.format(roc))\n    print('')\n    print('Precision: {:.2f} %'.format(precision))\n    print('')\n    print('Recall: {:.2f} %'.format(recall))\n    print('')\n    print('F1 Score: {:.2f} %'.format(f1))\n    print('')\n    print(classification_report(y_test, y_pred)) \n    print('-'*40)\n    print('')\n    lst_2.append(models[m][0])\n    lst_2.append(accuracy_score(y_train_res,y_train_pred)*100)\n    lst_2.append(accuracy_score(y_test,y_pred)*100)\n    lst_2.append(accuracies.mean()*100)\n    lst_2.append(accuracies.std()*100)\n    lst_2.append(roc)\n    lst_2.append(precision)\n    lst_2.append(recall)\n    lst_2.append(f1)\n    lst_1.append(lst_2)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:47:56.701366Z","iopub.execute_input":"2021-05-31T17:47:56.701751Z","iopub.status.idle":"2021-05-31T17:49:26.201618Z","shell.execute_reply.started":"2021-05-31T17:47:56.701684Z","shell.execute_reply":"2021-05-31T17:49:26.200754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Creating Hybrid model using other algorithms**","metadata":{}},{"cell_type":"code","source":"#Hybrid \nlst_3 = []\nHybrid_ensemble = VotingClassifier(Hybrid)\nHybrid_ensemble.fit(X_train_res,y_train_res)\ny_pred_Hyb = Hybrid_ensemble.predict(X_test)\ny_train_pred_Hyb = Hybrid_ensemble.predict(X_train_res)\ncm = confusion_matrix(y_test,y_pred_Hyb)\naccuracies = cross_val_score(estimator= Hybrid_ensemble, X = X_train_res,y = y_train_res, cv=10)\n\n# k-fOLD Validation\nroc = roc_auc_score(y_test,y_pred_Hyb)\nprecision = precision_score(y_test,y_pred_Hyb)\nrecall = recall_score(y_test,y_pred_Hyb)\nf1 = f1_score(y_test,y_pred_Hyb)\nprint('Hybrid_Model')\nprint(cm)\nprint('')\nprint('Train Accuracy Score: ',accuracy_score(y_train_res,y_train_pred_Hyb))\nprint('')\nprint('Test Accuracy Score: ',accuracy_score(y_test,y_pred_Hyb))\nprint('')\nprint('K-Fold Validation Mean Accuracy: {:.2f} %'.format(accuracies.mean()*100))\nprint('')\nprint('Standard Deviation: {:.2f} %'.format(accuracies.std()*100))\nprint('')\nprint('ROC AUC Score: {:.2f} %'.format(roc))\nprint('')\nprint('Precision: {:.2f} %'.format(precision))\nprint('')\nprint('Recall: {:.2f} %'.format(recall))\nprint('')\nprint('F1 Score: {:.2f} %'.format(f1))\nprint('-'*40)\nprint('')\nlst_3.append('Hybrid_model')\nlst_3.append(accuracy_score(y_train_res,y_train_pred_Hyb)*100)\nlst_3.append(accuracy_score(y_test,y_pred_Hyb)*100)\nlst_3.append(accuracies.mean()*100)\nlst_3.append(accuracies.std()*100)\nlst_3.append(roc)\nlst_3.append(precision)\nlst_3.append(recall)\nlst_3.append(f1)\nlst_1.append(lst_3)\n#final =pd.concat([lst_1,lst_3], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:49:26.203003Z","iopub.execute_input":"2021-05-31T17:49:26.203289Z","iopub.status.idle":"2021-05-31T17:49:55.368758Z","shell.execute_reply.started":"2021-05-31T17:49:26.20326Z","shell.execute_reply":"2021-05-31T17:49:55.367938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**All model results**","metadata":{}},{"cell_type":"code","source":"df2 = pd.DataFrame(lst_1,columns=['Model','Train_Accuracy','Test_Accuracy','K-Fold Mean Accuracy','Std.Deviation','ROC_AUC','Precision','Recall','F1 Score'])\n\ndf2.sort_values(by=['Recall','F1 Score'],inplace=True,ascending=False)\ndf2","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:49:55.369723Z","iopub.execute_input":"2021-05-31T17:49:55.370086Z","iopub.status.idle":"2021-05-31T17:49:55.389485Z","shell.execute_reply.started":"2021-05-31T17:49:55.370059Z","shell.execute_reply":"2021-05-31T17:49:55.388475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"font-family: Arial; font-weight:bold;font-size:1.5em;color:#00b3e5;\"> Best Model\n    \n**GBClassifier** is considerd as best model.Because,\n\n1) Recall which tells how many customer churn are predicted correctly with our model.So prediction of customer churn (Recall)  is most important parameter to decide the best model for this problem.so this model is having highest Recall. Ofcourse Adaboost having same value. \n    \n2)But GBClassifier having  more precision (how many predicted customer churn actually turned out to be positive), AUC percentage and F1_Score in comparision with Adaboost.\n\n\n\n    ","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-family: Arial; font-weight:bold;font-size:1.5em;color:#00b3e5;\">Tuning\n    \n**Hyperparameter tuning in GradientBoostingClassifier using Gridsearch.**","metadata":{}},{"cell_type":"code","source":"gb_clf = GradientBoostingClassifier(random_state=42)\nskfold = StratifiedKFold(n_splits=5)\nparam_grid = {\n              'n_estimators' : [25, 50 ,75, 100, 200],\n              'learning_rate': [0.005 ,0.05, 0.5, 1.5],\n              'max_depth': [2, 4, 6, 8],\n              'max_features': [10, 12, 17] \n              }\ngrid_gb_clf = GridSearchCV(gb_clf, param_grid, cv=skfold, scoring=\"accuracy\", n_jobs= -1, verbose = 1)\ngrid_gb_clf.fit(X_train_res,y_train_res)\n","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:49:55.390453Z","iopub.execute_input":"2021-05-31T17:49:55.390749Z","iopub.status.idle":"2021-05-31T17:56:16.430213Z","shell.execute_reply.started":"2021-05-31T17:49:55.390689Z","shell.execute_reply":"2021-05-31T17:56:16.42914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_gb_clf.best_params_","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:56:16.431803Z","iopub.execute_input":"2021-05-31T17:56:16.432411Z","iopub.status.idle":"2021-05-31T17:56:16.43946Z","shell.execute_reply.started":"2021-05-31T17:56:16.432364Z","shell.execute_reply":"2021-05-31T17:56:16.438411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Fitting GradientBoostingClassifier with best parameters.**","metadata":{}},{"cell_type":"code","source":"GBC_best=GradientBoostingClassifier(random_state=42,learning_rate = 0.05,\n max_depth = 8,max_features =12,n_estimators = 200)\n\nGBC_best.fit(X_train_res, y_train_res)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:56:16.440555Z","iopub.execute_input":"2021-05-31T17:56:16.44087Z","iopub.status.idle":"2021-05-31T17:56:19.864815Z","shell.execute_reply.started":"2021-05-31T17:56:16.440839Z","shell.execute_reply":"2021-05-31T17:56:19.864009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_GBC=GBC_best.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:56:19.866267Z","iopub.execute_input":"2021-05-31T17:56:19.866538Z","iopub.status.idle":"2021-05-31T17:56:19.895941Z","shell.execute_reply.started":"2021-05-31T17:56:19.866511Z","shell.execute_reply":"2021-05-31T17:56:19.895066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Evaluating GradientBoostingClassifier**\n","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\n\nconfusion_matrix_forest = confusion_matrix(y_test, y_pred_GBC)\nprint(confusion_matrix_forest)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:56:19.89712Z","iopub.execute_input":"2021-05-31T17:56:19.897425Z","iopub.status.idle":"2021-05-31T17:56:19.906586Z","shell.execute_reply.started":"2021-05-31T17:56:19.897397Z","shell.execute_reply":"2021-05-31T17:56:19.90557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\n\n#plotting a confusion matrix\nlabels = ['Not Churned', 'Churned']\nplt.figure(figsize=(7,5))\nax= plt.subplot()\nsns.heatmap(confusion_matrix_forest,cmap=\"Blues\",annot=True,fmt='.1f', ax = ax); #annot=True to annotate cells\n\n# labels, title and ticks\nax.set_xticklabels(labels)\nax.set_yticklabels(labels)\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \nax.set_title('Confusion Matrix Random Forests'); ","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:56:19.908081Z","iopub.execute_input":"2021-05-31T17:56:19.908353Z","iopub.status.idle":"2021-05-31T17:56:20.151145Z","shell.execute_reply.started":"2021-05-31T17:56:19.908327Z","shell.execute_reply":"2021-05-31T17:56:20.149955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_pred_GBC)) ","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:56:20.152654Z","iopub.execute_input":"2021-05-31T17:56:20.153061Z","iopub.status.idle":"2021-05-31T17:56:20.167408Z","shell.execute_reply.started":"2021-05-31T17:56:20.153019Z","shell.execute_reply":"2021-05-31T17:56:20.166241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Fine tuning using Random search.**","metadata":{}},{"cell_type":"code","source":"gb_clf = GradientBoostingClassifier(random_state=42)\nskfold = StratifiedKFold(n_splits=5)\nparam_grid = {\n              'n_estimators' : [25, 50 ,75, 100, 200],\n              'learning_rate': [0.005 ,0.05, 0.5, 1.5],\n              'max_depth': [2, 4, 6, 8],\n              'max_features': [10, 12, 17] \n              }\nrandom_gb_clf = RandomizedSearchCV(gb_clf, param_grid, cv=skfold, scoring=\"accuracy\", n_jobs= -1, verbose = 1)\nrandom_gb_clf.fit(X_train_res,y_train_res)\n","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:56:20.168952Z","iopub.execute_input":"2021-05-31T17:56:20.169318Z","iopub.status.idle":"2021-05-31T17:56:32.585591Z","shell.execute_reply.started":"2021-05-31T17:56:20.169277Z","shell.execute_reply":"2021-05-31T17:56:32.584752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_gb_clf.best_params_","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:56:32.588857Z","iopub.execute_input":"2021-05-31T17:56:32.589394Z","iopub.status.idle":"2021-05-31T17:56:32.596251Z","shell.execute_reply.started":"2021-05-31T17:56:32.589348Z","shell.execute_reply":"2021-05-31T17:56:32.595068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Fitting Gradiant Booster classifier with new parameeters.**","metadata":{}},{"cell_type":"code","source":"GBC_best_Rand=GradientBoostingClassifier(random_state=42,learning_rate = 0.05,\n max_depth = 8,max_features =10,n_estimators = 100)\n\nGBC_best_Rand.fit(X_train_res, y_train_res)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:56:32.597606Z","iopub.execute_input":"2021-05-31T17:56:32.598043Z","iopub.status.idle":"2021-05-31T17:56:34.206682Z","shell.execute_reply.started":"2021-05-31T17:56:32.597999Z","shell.execute_reply":"2021-05-31T17:56:34.205725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_GBCR=GBC_best_Rand.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:56:34.208098Z","iopub.execute_input":"2021-05-31T17:56:34.208466Z","iopub.status.idle":"2021-05-31T17:56:34.22939Z","shell.execute_reply.started":"2021-05-31T17:56:34.208426Z","shell.execute_reply":"2021-05-31T17:56:34.228358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Evaluating Gradiant booster classifier.**","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\n\nconfusion_matrix_Rand = confusion_matrix(y_test, y_pred_GBCR)\nprint(confusion_matrix_forest)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:56:34.232939Z","iopub.execute_input":"2021-05-31T17:56:34.23322Z","iopub.status.idle":"2021-05-31T17:56:34.242314Z","shell.execute_reply.started":"2021-05-31T17:56:34.233194Z","shell.execute_reply":"2021-05-31T17:56:34.241296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\n\n#plotting a confusion matrix\nlabels = ['Not Churned', 'Churned']\nplt.figure(figsize=(7,5))\nax= plt.subplot()\nsns.heatmap(confusion_matrix_Rand,cmap=\"Blues\",annot=True,fmt='.1f', ax = ax); #annot=True to annotate cells\n\n# labels, title and ticks\nax.set_xticklabels(labels)\nax.set_yticklabels(labels)\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \nax.set_title('Confusion Matrix Random Forests'); ","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:56:34.243489Z","iopub.execute_input":"2021-05-31T17:56:34.243802Z","iopub.status.idle":"2021-05-31T17:56:34.437455Z","shell.execute_reply.started":"2021-05-31T17:56:34.243775Z","shell.execute_reply":"2021-05-31T17:56:34.436614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_pred_GBCR)) ","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:56:34.438629Z","iopub.execute_input":"2021-05-31T17:56:34.439299Z","iopub.status.idle":"2021-05-31T17:56:34.452603Z","shell.execute_reply.started":"2021-05-31T17:56:34.439256Z","shell.execute_reply":"2021-05-31T17:56:34.451234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**After fine tuning using Gridsearch and Random search we can conclude that Grid search is showing better result in comparison with improved accuracy.**\n\n**But recall in base model is more with 73.96%, whereas using grid search it reduced to 64%.**\n\n**Lets try to improve with detail fine tuning using grid search**","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-family: Arial; font-weight:bold;font-size:1.0em;color:#00b3e5;\">Tuning n_estimators and Learning rate","metadata":{}},{"cell_type":"code","source":"p_test1 = {'learning_rate':[0.15,0.1,0.05,0.01,0.005,0.001], 'n_estimators':[100,250,500,750,1000,1250,1500,1750]}\n\ntuning = GridSearchCV(estimator =GradientBoostingClassifier(max_depth=4, min_samples_split=2, min_samples_leaf=1, subsample=1,max_features='sqrt', random_state=10), \n            param_grid = p_test1, scoring='accuracy',n_jobs=4,cv=5)\ntuning.fit(X_train_res,y_train_res)\ntuning.best_params_, tuning.best_score_","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:56:34.454078Z","iopub.execute_input":"2021-05-31T17:56:34.454726Z","iopub.status.idle":"2021-05-31T18:01:47.571531Z","shell.execute_reply.started":"2021-05-31T17:56:34.454662Z","shell.execute_reply":"2021-05-31T18:01:47.570763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"font-family: Arial; font-weight:bold;font-size:1.0em;color:#00b3e5;\">Tuning max_depth","metadata":{}},{"cell_type":"code","source":"p_test2 = {'max_depth':[2,3,4,5,6,7] }\ntuning = GridSearchCV(estimator =GradientBoostingClassifier(learning_rate=0.15,n_estimators=500, min_samples_split=2, min_samples_leaf=1, subsample=1,max_features='sqrt', random_state=10), \n            param_grid = p_test2, scoring='accuracy',n_jobs=4,cv=5)\ntuning.fit(X_train_res,y_train_res)\ntuning.best_params_, tuning.best_score_","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:01:47.572958Z","iopub.execute_input":"2021-05-31T18:01:47.573306Z","iopub.status.idle":"2021-05-31T18:02:20.194852Z","shell.execute_reply.started":"2021-05-31T18:01:47.573274Z","shell.execute_reply":"2021-05-31T18:02:20.19383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**First Evaluation of model with latest tuning parameters.**","metadata":{}},{"cell_type":"code","source":"List_1 = []\nList_final = []\nmodel1 = GradientBoostingClassifier(learning_rate=0.15, n_estimators=500,max_depth=7, min_samples_split=2, min_samples_leaf=1, subsample=1,max_features='sqrt', random_state=10)\nmodel1.fit(X_train_res,y_train_res)\npred=model1.predict(X_test)\npred_train=model1.predict(X_train_res)\nprint(classification_report(y_test, pred))\nroc = roc_auc_score(y_test,pred)\nprecision = precision_score(y_test,pred)\nrecall = recall_score(y_test,pred)\nf1 = f1_score(y_test,pred)\nList_1.append('First Evaluation')\nList_1.append(accuracy_score(y_train_res,pred_train)*100)\nList_1.append(accuracy_score(y_test,pred)*100)\nList_1.append(roc)\nList_1.append(precision)\nList_1.append(recall)\nList_1.append(f1)\nList_final.append(List_1)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:02:20.196189Z","iopub.execute_input":"2021-05-31T18:02:20.196572Z","iopub.status.idle":"2021-05-31T18:02:24.875097Z","shell.execute_reply.started":"2021-05-31T18:02:20.196532Z","shell.execute_reply":"2021-05-31T18:02:24.874019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**No improvement in the model.**","metadata":{}},{"cell_type":"markdown","source":"**Lets try to fine tune model with more parameters.**","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-family: Arial; font-weight:bold;font-size:1.0em;color:#00b3e5;\">Tuning Min sample split and min samples leaf","metadata":{}},{"cell_type":"code","source":"p_test3 = {'min_samples_split':[2,4,6,8,10,20,40,60,100], 'min_samples_leaf':[1,3,5,7,9]}\n\ntuning = GridSearchCV(estimator =GradientBoostingClassifier(learning_rate=0.15, n_estimators=500,max_depth=7, subsample=1,max_features='sqrt', random_state=10), \n            param_grid = p_test3, scoring='accuracy',n_jobs=4,cv=5)\ntuning.fit(X_train_res,y_train_res)\ntuning.best_params_, tuning.best_score_","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:02:24.876588Z","iopub.execute_input":"2021-05-31T18:02:24.876946Z","iopub.status.idle":"2021-05-31T18:07:24.959531Z","shell.execute_reply.started":"2021-05-31T18:02:24.876914Z","shell.execute_reply":"2021-05-31T18:07:24.958469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observed no improvment as min_samples_split=2, min_samples_leaf=1 are already in use**","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-family: Arial; font-weight:bold;font-size:1.0em;color:#00b3e5;\">Tuning Max features","metadata":{}},{"cell_type":"code","source":"p_test4 ={'max_features':[2,3,4,5,6,7]}\n\ntuning = GridSearchCV(estimator =GradientBoostingClassifier(learning_rate=0.15, n_estimators=500,max_depth=7,min_samples_split=2, min_samples_leaf=1, subsample=1, random_state=10), \n            param_grid = p_test4,scoring='accuracy',n_jobs=4,cv=5)\ntuning.fit(X_train_res,y_train_res)\ntuning.best_params_, tuning.best_score_","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:07:24.961483Z","iopub.execute_input":"2021-05-31T18:07:24.961781Z","iopub.status.idle":"2021-05-31T18:08:15.437372Z","shell.execute_reply.started":"2021-05-31T18:07:24.961754Z","shell.execute_reply":"2021-05-31T18:08:15.436456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Second Evaluation of model with latest Max Features.**","metadata":{}},{"cell_type":"code","source":"List_2 = []\nmodel1 = GradientBoostingClassifier(learning_rate=0.15, n_estimators=500,max_depth=7, min_samples_split=2, min_samples_leaf=1, subsample=1,max_features=4, random_state=10)\nmodel1.fit(X_train_res,y_train_res)\npred=model1.predict(X_test)\npred_train=model1.predict(X_train_res)\nprint(classification_report(y_test, pred))\nroc = roc_auc_score(y_test,pred)\nprecision = precision_score(y_test,pred)\nrecall = recall_score(y_test,pred)\nf1 = f1_score(y_test,pred)\nList_2.append('Second Evalution')\nList_2.append(accuracy_score(y_train_res,pred_train)*100)\nList_2.append(accuracy_score(y_test,pred)*100)\nList_2.append(roc)\nList_2.append(precision)\nList_2.append(recall)\nList_2.append(f1)\nList_final.append(List_2)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:08:15.438616Z","iopub.execute_input":"2021-05-31T18:08:15.438885Z","iopub.status.idle":"2021-05-31T18:08:19.733804Z","shell.execute_reply.started":"2021-05-31T18:08:15.438861Z","shell.execute_reply":"2021-05-31T18:08:19.732773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"font-family: Arial; font-weight:bold;font-size:1.0em;color:#00b3e5;\">Tuning Subsamples","metadata":{}},{"cell_type":"code","source":"p_test5 ={'subsample':[0.7,0.75,0.8,0.85,0.9,0.95,1]}\n\ntuning = GridSearchCV(estimator =GradientBoostingClassifier(learning_rate=0.15, n_estimators=500,max_depth=7,min_samples_split=2, min_samples_leaf=1, max_features=4, random_state=10), \n            param_grid = p_test5,scoring='accuracy',n_jobs=4,cv=5)\ntuning.fit(X_train_res,y_train_res)\ntuning.best_params_, tuning.best_score_","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:08:19.735093Z","iopub.execute_input":"2021-05-31T18:08:19.735351Z","iopub.status.idle":"2021-05-31T18:09:15.17405Z","shell.execute_reply.started":"2021-05-31T18:08:19.735327Z","shell.execute_reply":"2021-05-31T18:09:15.173167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Subsample = 1 is already in use, so improvemnt.**","metadata":{}},{"cell_type":"markdown","source":"**List the Result of model evalution with respect to base model**","metadata":{}},{"cell_type":"code","source":"# Add Base model data to final list to prepare the table\nList_3 = []\nList_3.append('Base')\nList_3.append(82.069729)\nList_3.append(76.053005)\nList_3.append(0.753775)\nList_3.append(0.530480)\nList_3.append(0.739602)\nList_3.append(0.617825)\nList_final.append(List_3)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:09:15.175482Z","iopub.execute_input":"2021-05-31T18:09:15.175794Z","iopub.status.idle":"2021-05-31T18:09:15.180382Z","shell.execute_reply.started":"2021-05-31T18:09:15.175765Z","shell.execute_reply":"2021-05-31T18:09:15.179768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Display and compare all the models**","metadata":{}},{"cell_type":"code","source":"df_final = pd.DataFrame(List_final,columns=['Model','Train_Accuracy','Test_Accuracy','ROC_AUC','Precision','Recall','F1 Score'])\n\ndf_final.sort_values(by=['Recall','F1 Score'],inplace=True,ascending=False)\ndf_final","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:09:15.181285Z","iopub.execute_input":"2021-05-31T18:09:15.181637Z","iopub.status.idle":"2021-05-31T18:09:15.206805Z","shell.execute_reply.started":"2021-05-31T18:09:15.1816Z","shell.execute_reply":"2021-05-31T18:09:15.20598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observation :**\n\nAfter fine tuning different hyperparameters,\n\n1) Able to improve the train accuracy but not test accuracy.\n\n2) Also there is no improvement in recall, precision, ROC and F1 score\n\n<span style=\"font-family: Arial; font-weight:bold;font-size:1.0em;color:#00b3e5;\">So Base model is our final model for future prediction, which able to predict customer churn with 76% accuracy and recall with 73.96%","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-family: Arial; font-weight:bold;font-size:1.5em;color:#00b3e5;\">Pickle the Base model for future prediction","metadata":{}},{"cell_type":"markdown","source":"What is pickle: \n\n    Pickling: It is a process where a Python object hierarchy is converted into a byte stream and dumps it into a file by using dump function.This character stream contains all the information necessary to reconstruct the object in another python script.\n    \n    pickle has two main methods. The first one is dump, which dumps an object to a file object and the second one is load, which loads an object from a file object.","metadata":{}},{"cell_type":"code","source":"# Final model (which is Base model)\n\nGBClassifier = GradientBoostingClassifier(n_estimators = 50, learning_rate = 0.1, random_state=0)\nGBClassifier.fit(X_train_res,y_train_res)\npred=GBClassifier.predict(X_test)\npred_train=GBClassifier.predict(X_train_res)\nprint(classification_report(y_test, pred))","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:09:15.208197Z","iopub.execute_input":"2021-05-31T18:09:15.208467Z","iopub.status.idle":"2021-05-31T18:09:15.896247Z","shell.execute_reply.started":"2021-05-31T18:09:15.20844Z","shell.execute_reply":"2021-05-31T18:09:15.89545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import pickle Package\n\nimport pickle","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:09:15.897548Z","iopub.execute_input":"2021-05-31T18:09:15.898106Z","iopub.status.idle":"2021-05-31T18:09:15.902556Z","shell.execute_reply.started":"2021-05-31T18:09:15.898066Z","shell.execute_reply":"2021-05-31T18:09:15.901486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the Modle to file in the current working directory\n\nPkl_Filename = \"Pickle_GBC_Model.pkl\"  \n\nwith open(Pkl_Filename, 'wb') as file:  \n    pickle.dump(GBClassifier, file)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:09:15.903901Z","iopub.execute_input":"2021-05-31T18:09:15.904266Z","iopub.status.idle":"2021-05-31T18:09:15.919185Z","shell.execute_reply.started":"2021-05-31T18:09:15.904229Z","shell.execute_reply":"2021-05-31T18:09:15.918197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the Model back from file\nwith open(Pkl_Filename, 'rb') as file:  \n    Pickle_GBC_Model = pickle.load(file)\n    \nPickle_GBC_Model","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-05-31T18:09:15.920638Z","iopub.execute_input":"2021-05-31T18:09:15.921045Z","iopub.status.idle":"2021-05-31T18:09:15.938172Z","shell.execute_reply.started":"2021-05-31T18:09:15.921003Z","shell.execute_reply":"2021-05-31T18:09:15.937052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"font-family: Arial; font-weight:bold;font-size:1.5em;color:#00b3e5;\">6.Conclusion","metadata":{}},{"cell_type":"markdown","source":"**1.GradientBoostingClassifier model performs the best , evidence from above results.**\n\n**2.GradientBoostingClassifier  model able to predict 74% customer churn.**\n\n**3.Observed no improvement with tuning hyperparameters.**\n\n**4.We may improve model performance by using other classification algorithms.**\n\n**5.Using hypothesis Testing,we can conclude that there are few attributes showing positive impact on customer churn.**\n\n**6.We have dropped customer ID(as it will not influence ) and few other attributes to avoid Multicollinearity problem, as they are higly correlated.**\n\nCompany must focus more on below points for customer retention\n\n1) Why month to month contract customers churn out is more.\n\n2) Why attributes with no internet service has negative impact on churn.\n\n3) Why customers with optic fiber internet showing positive impact on churn.\n","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-family: Arial; font-weight:bold;font-size:1.0em;color:#00b3e5;\">suggestions or improvements","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20,8))\nwidth = len(df['SeniorCitizen'].unique())+6\nfig.set_size_inches(width , 8)\nax=sns.countplot(data = df, x= 'SeniorCitizen') \n\n\n\nfor p in ax.patches: \n    ax.annotate(str((np.round(p.get_height()/len(df)*100,decimals=2)))+'%', (p.get_x()+p.get_width()/2., p.get_height()), ha='center', va='center', xytext=(0, 10), textcoords='offset points')\n","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:09:15.939774Z","iopub.execute_input":"2021-05-31T18:09:15.940151Z","iopub.status.idle":"2021-05-31T18:09:16.073639Z","shell.execute_reply.started":"2021-05-31T18:09:15.940112Z","shell.execute_reply":"2021-05-31T18:09:16.072532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We can see 84% of customers are not senior citizens and we also seen before, churn out is more from these customers. \nThere is no information of age or age group (teen, young, middle age).**\n\n**Information on age help us to perform better analysis and will increase the focus on particular group.** \n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}