{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-23T08:56:08.444254Z","iopub.execute_input":"2021-06-23T08:56:08.444639Z","iopub.status.idle":"2021-06-23T08:56:08.457804Z","shell.execute_reply.started":"2021-06-23T08:56:08.444605Z","shell.execute_reply":"2021-06-23T08:56:08.4567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"# Importing Data Set","metadata":{}},{"cell_type":"code","source":"haberman_data=pd.read_csv(\"/kaggle/input/habermans-survival-data-set/haberman.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-06-23T08:56:12.704061Z","iopub.execute_input":"2021-06-23T08:56:12.704649Z","iopub.status.idle":"2021-06-23T08:56:12.721778Z","shell.execute_reply.started":"2021-06-23T08:56:12.704597Z","shell.execute_reply":"2021-06-23T08:56:12.720934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Cleaning","metadata":{}},{"cell_type":"markdown","source":"## Printing the first 5 rows of the dataset","metadata":{}},{"cell_type":"code","source":"haberman_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-23T08:56:13.424823Z","iopub.execute_input":"2021-06-23T08:56:13.425321Z","iopub.status.idle":"2021-06-23T08:56:13.450046Z","shell.execute_reply.started":"2021-06-23T08:56:13.425274Z","shell.execute_reply":"2021-06-23T08:56:13.449023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Renaming Columns appropriately","metadata":{}},{"cell_type":"code","source":"haberman_data.columns=[\"Age\",\"Year\",\"Nodes\",\"Survival_Status\"]\nhaberman_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-23T08:56:13.943228Z","iopub.execute_input":"2021-06-23T08:56:13.943716Z","iopub.status.idle":"2021-06-23T08:56:13.954417Z","shell.execute_reply.started":"2021-06-23T08:56:13.943682Z","shell.execute_reply":"2021-06-23T08:56:13.953462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Finding missing values (if any)","metadata":{}},{"cell_type":"code","source":"print(\"The number of rows in the dataset are :\",len(haberman_data))","metadata":{"execution":{"iopub.status.busy":"2021-06-23T08:56:14.445322Z","iopub.execute_input":"2021-06-23T08:56:14.445681Z","iopub.status.idle":"2021-06-23T08:56:14.45081Z","shell.execute_reply.started":"2021-06-23T08:56:14.445647Z","shell.execute_reply":"2021-06-23T08:56:14.449714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"haberman_data.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-23T08:56:14.717927Z","iopub.execute_input":"2021-06-23T08:56:14.718426Z","iopub.status.idle":"2021-06-23T08:56:14.73731Z","shell.execute_reply.started":"2021-06-23T08:56:14.718395Z","shell.execute_reply":"2021-06-23T08:56:14.736209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"haberman_data.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-23T08:56:14.954574Z","iopub.execute_input":"2021-06-23T08:56:14.954959Z","iopub.status.idle":"2021-06-23T08:56:14.98758Z","shell.execute_reply.started":"2021-06-23T08:56:14.954927Z","shell.execute_reply":"2021-06-23T08:56:14.986716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"haberman_data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-23T08:56:15.200564Z","iopub.execute_input":"2021-06-23T08:56:15.200948Z","iopub.status.idle":"2021-06-23T08:56:15.211586Z","shell.execute_reply.started":"2021-06-23T08:56:15.200914Z","shell.execute_reply":"2021-06-23T08:56:15.210455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### 1.The number of rows in the dataset is equal to the count of the individual attribute entries (namely Age, Year, Nodes and Survival_Status) as shown above.\n##### 2. The constraint of the attributes (namely Age,Year,Nodes and Survival_Status) is non-null as shown in dataset.info()\n##### 3. The sum of all the null values in the attributes is zero.\n##### The above three conclusions prove that there is no missing data in the dataset","metadata":{}},{"cell_type":"markdown","source":"## Handling Categorical Data (if any)","metadata":{}},{"cell_type":"markdown","source":"##### There is no need of Label Encoding here because the class label (i.e., Survival_Status here) is already in machine-readable (numeric) form.","metadata":{}},{"cell_type":"markdown","source":"# Deciding if its Supervised or UnSupervised Machine Learning Task","metadata":{}},{"cell_type":"markdown","source":"##### The dataset consists of 4 attributes in which one is the class label (i.e., Survival_Status here). As the dataset is labelled,We are going to apply Supervised Machine Learning Algorithms.","metadata":{}},{"cell_type":"markdown","source":"# Deciding if Classification or Regression suits well","metadata":{}},{"cell_type":"markdown","source":"##### Survival_Status is the class label (in this case).\n##### It is either 1 if the person survived 5 years(or even longer) or 2 if the person died within 5 years.\n##### This shows that the test data should be mapped to either 1 or 2 (to know if the patient had survived or not) which is Binary Classification which also meant that the class label is discrete.","metadata":{}},{"cell_type":"markdown","source":"# Exploratory Data Analysis (EDA)","metadata":{}},{"cell_type":"code","source":"import seaborn as sb","metadata":{"execution":{"iopub.status.busy":"2021-06-23T08:56:17.260871Z","iopub.execute_input":"2021-06-23T08:56:17.261228Z","iopub.status.idle":"2021-06-23T08:56:17.265643Z","shell.execute_reply.started":"2021-06-23T08:56:17.261199Z","shell.execute_reply":"2021-06-23T08:56:17.264831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Understanding the relationship between features using Heatmap","metadata":{}},{"cell_type":"code","source":"sb.heatmap(haberman_data.corr(), annot=True , cmap=\"RdYlGn\",center=0.4)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T08:56:17.749316Z","iopub.execute_input":"2021-06-23T08:56:17.749666Z","iopub.status.idle":"2021-06-23T08:56:18.044384Z","shell.execute_reply.started":"2021-06-23T08:56:17.749633Z","shell.execute_reply":"2021-06-23T08:56:18.043176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Heatmap for Survived persons' data","metadata":{}},{"cell_type":"code","source":"data_survived=haberman_data[haberman_data[\"Survival_Status\"]==1]\nsb.heatmap(data_survived.corr(), annot=True , cmap=\"RdYlGn\",center=0.4)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T08:56:18.315941Z","iopub.execute_input":"2021-06-23T08:56:18.316311Z","iopub.status.idle":"2021-06-23T08:56:18.676256Z","shell.execute_reply.started":"2021-06-23T08:56:18.316277Z","shell.execute_reply":"2021-06-23T08:56:18.675495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Heatmap for not survived persons' data","metadata":{}},{"cell_type":"code","source":"data_not_survived=haberman_data[haberman_data[\"Survival_Status\"]==2]\nsb.heatmap(data_not_survived.corr(), annot=True , cmap=\"RdYlGn\",center=0.4)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T08:56:18.828108Z","iopub.execute_input":"2021-06-23T08:56:18.828669Z","iopub.status.idle":"2021-06-23T08:56:19.073473Z","shell.execute_reply.started":"2021-06-23T08:56:18.828611Z","shell.execute_reply":"2021-06-23T08:56:19.072547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### From the Heatmap, we observe almost no highly positive or negative correlations between our features and the target value.","metadata":{}},{"cell_type":"markdown","source":"## Spotting Outliers in the data using BoxPlot","metadata":{}},{"cell_type":"code","source":"sb.boxplot( y=haberman_data['Age'])","metadata":{"execution":{"iopub.status.busy":"2021-06-23T08:56:19.62527Z","iopub.execute_input":"2021-06-23T08:56:19.625655Z","iopub.status.idle":"2021-06-23T08:56:19.751328Z","shell.execute_reply.started":"2021-06-23T08:56:19.625619Z","shell.execute_reply":"2021-06-23T08:56:19.75049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"No outliers found in Attribute : Age","metadata":{}},{"cell_type":"code","source":"sb.boxplot( y=haberman_data['Year'])","metadata":{"execution":{"iopub.status.busy":"2021-06-23T08:56:20.140915Z","iopub.execute_input":"2021-06-23T08:56:20.141257Z","iopub.status.idle":"2021-06-23T08:56:20.262137Z","shell.execute_reply.started":"2021-06-23T08:56:20.141227Z","shell.execute_reply":"2021-06-23T08:56:20.261361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"No outliers found in Attribute : Year","metadata":{}},{"cell_type":"code","source":"sb.boxplot( y=haberman_data['Nodes'])","metadata":{"execution":{"iopub.status.busy":"2021-06-23T08:56:20.725554Z","iopub.execute_input":"2021-06-23T08:56:20.726057Z","iopub.status.idle":"2021-06-23T08:56:20.848564Z","shell.execute_reply.started":"2021-06-23T08:56:20.726025Z","shell.execute_reply":"2021-06-23T08:56:20.847696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Number of outliers found in Attribute : Nodes","metadata":{}},{"cell_type":"code","source":"sb.boxplot( y=haberman_data['Survival_Status'])","metadata":{"execution":{"iopub.status.busy":"2021-06-23T08:56:21.351953Z","iopub.execute_input":"2021-06-23T08:56:21.352303Z","iopub.status.idle":"2021-06-23T08:56:21.47549Z","shell.execute_reply.started":"2021-06-23T08:56:21.352273Z","shell.execute_reply":"2021-06-23T08:56:21.474442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"No Outliers found in Attribute : Survival_Status","metadata":{}},{"cell_type":"markdown","source":"### Generating BoxPlot for the entire dataset","metadata":{}},{"cell_type":"code","source":"haberman_data.boxplot()","metadata":{"execution":{"iopub.status.busy":"2021-06-23T08:56:22.306869Z","iopub.execute_input":"2021-06-23T08:56:22.307243Z","iopub.status.idle":"2021-06-23T08:56:22.493056Z","shell.execute_reply.started":"2021-06-23T08:56:22.307209Z","shell.execute_reply":"2021-06-23T08:56:22.492338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### As there are outliers in the attribute \"Nodes\", Let's begin to remove them before applying any algorithm.","metadata":{}},{"cell_type":"markdown","source":"### Outlier Removal","metadata":{}},{"cell_type":"markdown","source":"In outlier removal, all the nodes above the value of 10 are outliers as observed from the boxplot for Attribute : Nodes","metadata":{}},{"cell_type":"code","source":"outliers=haberman_data[haberman_data[\"Nodes\"]>10]\nprint(outliers)\nprint(\"The number of outliers in the Attribute : Nodes is :\",len(outliers))","metadata":{"execution":{"iopub.status.busy":"2021-06-23T08:56:23.429377Z","iopub.execute_input":"2021-06-23T08:56:23.42993Z","iopub.status.idle":"2021-06-23T08:56:23.440608Z","shell.execute_reply.started":"2021-06-23T08:56:23.429881Z","shell.execute_reply":"2021-06-23T08:56:23.439101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data=haberman_data[haberman_data[\"Nodes\"]<=10]\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2021-07-02T10:39:35.411429Z","iopub.execute_input":"2021-07-02T10:39:35.41189Z","iopub.status.idle":"2021-07-02T10:39:35.488202Z","shell.execute_reply.started":"2021-07-02T10:39:35.411798Z","shell.execute_reply":"2021-07-02T10:39:35.48681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Removing Class Label from the dataset to use it for training","metadata":{}},{"cell_type":"code","source":"class_label=train_data[\"Survival_Status\"]\ntrain_data.drop([\"Survival_Status\"],axis=1,inplace=True)\ntrain_data","metadata":{"execution":{"iopub.status.busy":"2021-06-23T08:56:24.249567Z","iopub.execute_input":"2021-06-23T08:56:24.250107Z","iopub.status.idle":"2021-06-23T08:56:24.271961Z","shell.execute_reply.started":"2021-06-23T08:56:24.250074Z","shell.execute_reply":"2021-06-23T08:56:24.271125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train,X_test,y_train,y_test=train_test_split(train_data,class_label)\nX_test","metadata":{"execution":{"iopub.status.busy":"2021-06-23T08:56:24.534269Z","iopub.execute_input":"2021-06-23T08:56:24.534607Z","iopub.status.idle":"2021-06-23T08:56:24.546614Z","shell.execute_reply.started":"2021-06-23T08:56:24.534577Z","shell.execute_reply":"2021-06-23T08:56:24.545902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Insights drawn from EDA on haberman_data","metadata":{}},{"cell_type":"markdown","source":"The data has no missing values and there is no need of Label Encoding. We have removed outliers and the features are independent of each other.","metadata":{}},{"cell_type":"markdown","source":"# 2. Modeling","metadata":{}},{"cell_type":"markdown","source":"# Trying different Supervised ML models (Classification) for this data ","metadata":{}},{"cell_type":"markdown","source":"## 1. Naive Bayes Classification ","metadata":{}},{"cell_type":"markdown","source":"### 1(a). Gaussian Naive Bayes Classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nmodel = GaussianNB().fit(X_train,y_train)\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\npred = model.predict(X_test)\nprint(classification_report(pred,y_test))\nprint(\"The accuracy in the case of Naive Bayes using Gaussian Naive Bayes Classifier is:\",accuracy_score(pred,y_test)*100)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T08:56:26.36718Z","iopub.execute_input":"2021-06-23T08:56:26.367661Z","iopub.status.idle":"2021-06-23T08:56:26.386839Z","shell.execute_reply.started":"2021-06-23T08:56:26.36763Z","shell.execute_reply":"2021-06-23T08:56:26.385997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1(b). Multinomial Naive Bayes Classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nmodel = MultinomialNB().fit(X_train,y_train)\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\npred = model.predict(X_test)\nprint(classification_report(pred,y_test))\nprint(\"The accuracy in the case of Naive Bayes using Multinomial Naive Bayes Classifier is:\",accuracy_score(pred,y_test)*100)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T08:56:28.651868Z","iopub.execute_input":"2021-06-23T08:56:28.652336Z","iopub.status.idle":"2021-06-23T08:56:28.67061Z","shell.execute_reply.started":"2021-06-23T08:56:28.652306Z","shell.execute_reply":"2021-06-23T08:56:28.669664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1(c). Bernoulli Naive Bayes Classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import BernoulliNB\nmodel = BernoulliNB().fit(X_train,y_train)\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\npred = model.predict(X_test)\nprint(classification_report(pred,y_test))\nacc1=accuracy_score(pred,y_test)*100\nprint(\"The accuracy in the case of Naive Bayes using Bernoulli Naive Bayes Classifier is:\",acc1)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T09:08:08.187165Z","iopub.execute_input":"2021-06-23T09:08:08.18753Z","iopub.status.idle":"2021-06-23T09:08:08.20768Z","shell.execute_reply.started":"2021-06-23T09:08:08.187497Z","shell.execute_reply":"2021-06-23T09:08:08.206613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The accuracy is comparatively high in the case of Bernoulli Naive Bayes Classifier","metadata":{}},{"cell_type":"markdown","source":"## 2. Logistic Regression","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression().fit(X_train,y_train)\npred2 = model.predict(X_test)\nacc2=accuracy_score(pred2,y_test)*100\nprint(\"The accuracy for Logistic Regression Model is:\",acc2)\nprint(classification_report(pred,y_test))","metadata":{"execution":{"iopub.status.busy":"2021-06-23T09:08:33.488545Z","iopub.execute_input":"2021-06-23T09:08:33.488908Z","iopub.status.idle":"2021-06-23T09:08:33.517706Z","shell.execute_reply.started":"2021-06-23T09:08:33.488873Z","shell.execute_reply":"2021-06-23T09:08:33.5168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. K-Nearest Neighbor","metadata":{}},{"cell_type":"markdown","source":"Website used : https://www.geeksforgeeks.org/k-nearest-neighbor-algorithm-in-python/","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=7)\nknn.fit(X_train, y_train)\npred=knn.predict(X_test)\nacc3=accuracy_score(pred,y_test)*100\nprint(\"The accuracy for KNN Model is:\",acc3)\nprint(classification_report(pred,y_test))","metadata":{"execution":{"iopub.status.busy":"2021-06-23T09:09:01.986449Z","iopub.execute_input":"2021-06-23T09:09:01.988926Z","iopub.status.idle":"2021-06-23T09:09:02.013164Z","shell.execute_reply.started":"2021-06-23T09:09:01.988877Z","shell.execute_reply":"2021-06-23T09:09:02.012238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Support Vector Machines (Classification)","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\nmodel = SVC().fit(X_train,y_train)\npred = model.predict(X_test)\nacc4=accuracy_score(pred,y_test)*100\nprint(\"The accuracy for Support Vector Classifier model is :\",acc4)\nprint(classification_report(pred,y_test))","metadata":{"execution":{"iopub.status.busy":"2021-06-23T09:09:21.123926Z","iopub.execute_input":"2021-06-23T09:09:21.12427Z","iopub.status.idle":"2021-06-23T09:09:21.143146Z","shell.execute_reply.started":"2021-06-23T09:09:21.124239Z","shell.execute_reply":"2021-06-23T09:09:21.142428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Decision Tree","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nmodel = DecisionTreeClassifier().fit(X_train,y_train)\npred = model.predict(X_test)\nacc5=accuracy_score(pred,y_test)*100\nprint(\"The accuracy for Decision Tree Classifier model is:\",acc5)\nprint(classification_report(pred,y_test))","metadata":{"execution":{"iopub.status.busy":"2021-06-23T09:09:44.560669Z","iopub.execute_input":"2021-06-23T09:09:44.561053Z","iopub.status.idle":"2021-06-23T09:09:44.577461Z","shell.execute_reply.started":"2021-06-23T09:09:44.561022Z","shell.execute_reply":"2021-06-23T09:09:44.576014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6. Random Forest","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier().fit(X_train,y_train)\npred = model.predict(X_test)\nacc6=accuracy_score(pred,y_test)*100\nprint(\"The accuracy for Random Forest Classifier Model is:\",acc6)\nprint(classification_report(pred,y_test)) ","metadata":{"execution":{"iopub.status.busy":"2021-06-23T09:09:57.941696Z","iopub.execute_input":"2021-06-23T09:09:57.942088Z","iopub.status.idle":"2021-06-23T09:09:58.150172Z","shell.execute_reply.started":"2021-06-23T09:09:57.94205Z","shell.execute_reply":"2021-06-23T09:09:58.148958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The features are more linear and independent. Hence, Naive Bayes, Logistic and SVM worked well.","metadata":{}},{"cell_type":"markdown","source":"# 3. Model Evaluation","metadata":{}},{"cell_type":"markdown","source":"# Comparing all the Machine Learning Models applied (Best Algorithm Analysis)","metadata":{}},{"cell_type":"markdown","source":"Website used : https://dibyendudeb.com/comparing-machine-learning-algorithms/","metadata":{}},{"cell_type":"markdown","source":"## Storing machine learning algorithms (MLA) in a variable","metadata":{}},{"cell_type":"code","source":"models = []\nmodels.append(('NB', BernoulliNB()))\nmodels.append(('LR', LogisticRegression()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('SVM', SVC()))\nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('RFC',RandomForestClassifier()))","metadata":{"execution":{"iopub.status.busy":"2021-06-23T09:10:01.915103Z","iopub.execute_input":"2021-06-23T09:10:01.915618Z","iopub.status.idle":"2021-06-23T09:10:01.921428Z","shell.execute_reply.started":"2021-06-23T09:10:01.915584Z","shell.execute_reply":"2021-06-23T09:10:01.920321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating a box plot to compare their accuracy","metadata":{}},{"cell_type":"markdown","source":"This part of code creates a box plot for all the models against their cross validation score.","metadata":{}},{"cell_type":"markdown","source":"### Importing required modules","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_squared_error,confusion_matrix, precision_score, recall_score, auc,roc_curve\nfrom sklearn import ensemble, linear_model, neighbors, svm, tree, neural_network\nfrom sklearn.linear_model import Ridge\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn import svm,model_selection, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n","metadata":{"execution":{"iopub.status.busy":"2021-06-23T09:55:39.82002Z","iopub.execute_input":"2021-06-23T09:55:39.820339Z","iopub.status.idle":"2021-06-23T09:55:39.825745Z","shell.execute_reply.started":"2021-06-23T09:55:39.820311Z","shell.execute_reply":"2021-06-23T09:55:39.824997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### K-Fold Cross Validation","metadata":{}},{"cell_type":"code","source":"# evaluate each model in turn\nimport random\nresults = []\nnames = []\nscoring = 'accuracy'\nfor name, model in models:\n    kfold = model_selection.KFold(n_splits=10, random_state=random.seed())\n    cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)\n# boxplot algorithm comparison\nfig = plt.figure()\nfig.suptitle('Comparison between different MLAs')\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-23T09:55:57.811817Z","iopub.execute_input":"2021-06-23T09:55:57.812283Z","iopub.status.idle":"2021-06-23T09:56:00.286035Z","shell.execute_reply.started":"2021-06-23T09:55:57.812252Z","shell.execute_reply":"2021-06-23T09:56:00.285097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Comparing the algorithms","metadata":{}},{"cell_type":"code","source":"MLA = [\n    linear_model.LogisticRegressionCV(),\n    ensemble.RandomForestClassifier(),\n    svm.SVC(probability=True),\n    tree.DecisionTreeClassifier(),\n    naive_bayes.BernoulliNB(),\n    naive_bayes.GaussianNB(),\n    naive_bayes.MultinomialNB(),\n    neighbors.KNeighborsClassifier(),\n    ]\n","metadata":{"execution":{"iopub.status.busy":"2021-06-23T09:03:36.129667Z","iopub.execute_input":"2021-06-23T09:03:36.130526Z","iopub.status.idle":"2021-06-23T09:03:36.137327Z","shell.execute_reply.started":"2021-06-23T09:03:36.130474Z","shell.execute_reply":"2021-06-23T09:03:36.13629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MLA_columns = []\nMLA_compare = pd.DataFrame(columns = MLA_columns)\n\nrow_index = 0\nfor alg in MLA:  \n    \n    predicted = alg.fit(X_train, y_train).predict(X_test)\n    MLA_name = alg.__class__.__name__\n    MLA_compare.loc[row_index,'Algorithm used'] = MLA_name\n    MLA_compare.loc[row_index, 'Train Accuracy'] = round(alg.score(X_train, y_train), 4)\n    MLA_compare.loc[row_index, 'Test Accuracy'] = round(alg.score(X_test, y_test), 4)\n    MLA_compare.loc[row_index, 'Precision'] = precision_score(y_test, predicted)\n    MLA_compare.loc[row_index, 'Recall'] = recall_score(y_test, predicted)\n    row_index+=1\n    \nMLA_compare.sort_values(by = ['Test Accuracy'], ascending = False, inplace = True)    \nMLA_compare","metadata":{"execution":{"iopub.status.busy":"2021-06-23T09:03:39.944144Z","iopub.execute_input":"2021-06-23T09:03:39.944716Z","iopub.status.idle":"2021-06-23T09:03:40.507002Z","shell.execute_reply.started":"2021-06-23T09:03:39.944664Z","shell.execute_reply":"2021-06-23T09:03:40.505872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating plot to show the train accuracy","metadata":{}},{"cell_type":"code","source":"\nplt.subplots(figsize=(13,5))\nsb.barplot(x=\"Algorithm used\", y=\"Train Accuracy\",data=MLA_compare,palette='hot',edgecolor=sb.color_palette('dark',7))\nplt.xticks(rotation=90)\nplt.title('Train Accuracy Comparison')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-23T09:03:43.893222Z","iopub.execute_input":"2021-06-23T09:03:43.893769Z","iopub.status.idle":"2021-06-23T09:03:44.114531Z","shell.execute_reply.started":"2021-06-23T09:03:43.893703Z","shell.execute_reply":"2021-06-23T09:03:44.113807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating plot to show the test accuracy","metadata":{}},{"cell_type":"code","source":"plt.subplots(figsize=(13,5))\nsb.barplot(x=\"Algorithm used\", y=\"Test Accuracy\",data=MLA_compare,palette='hot',edgecolor=sb.color_palette('dark',7))\nplt.xticks(rotation=90)\nplt.title('Test Accuracy Comparison')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-23T09:03:46.68824Z","iopub.execute_input":"2021-06-23T09:03:46.688772Z","iopub.status.idle":"2021-06-23T09:03:46.924385Z","shell.execute_reply.started":"2021-06-23T09:03:46.68871Z","shell.execute_reply":"2021-06-23T09:03:46.92365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating plots to compare precision","metadata":{}},{"cell_type":"code","source":"plt.subplots(figsize=(13,5))\nsb.barplot(x=\"Algorithm used\", y=\"Precision\",data=MLA_compare,palette='hot',edgecolor=sb.color_palette('dark',7))\nplt.xticks(rotation=90)\nplt.title('Precision Comparison')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-23T09:03:50.285486Z","iopub.execute_input":"2021-06-23T09:03:50.285981Z","iopub.status.idle":"2021-06-23T09:03:50.657134Z","shell.execute_reply.started":"2021-06-23T09:03:50.285948Z","shell.execute_reply":"2021-06-23T09:03:50.656088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating plots to compare Recall","metadata":{}},{"cell_type":"code","source":"plt.subplots(figsize=(13,5))\nsb.barplot(x=\"Algorithm used\", y=\"Recall\",data=MLA_compare,palette='hot',edgecolor=sb.color_palette('dark',7))\nplt.xticks(rotation=90)\nplt.title('Recall Comparison')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-23T08:57:16.286292Z","iopub.execute_input":"2021-06-23T08:57:16.286849Z","iopub.status.idle":"2021-06-23T08:57:16.504134Z","shell.execute_reply.started":"2021-06-23T08:57:16.286802Z","shell.execute_reply":"2021-06-23T08:57:16.503382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Comparing Accuracies using Pretty Table","metadata":{}},{"cell_type":"markdown","source":"Website Used : https://pypi.org/project/prettytable/","metadata":{}},{"cell_type":"code","source":"from prettytable import PrettyTable\nx = PrettyTable()","metadata":{"execution":{"iopub.status.busy":"2021-06-23T09:24:03.88037Z","iopub.execute_input":"2021-06-23T09:24:03.880895Z","iopub.status.idle":"2021-06-23T09:24:03.885004Z","shell.execute_reply.started":"2021-06-23T09:24:03.880846Z","shell.execute_reply":"2021-06-23T09:24:03.884102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x.field_names = [\"Machine Learning Algorithm\", \"Accuracy\"]\nx.add_row([\"Naive Bayes Classification\",acc1])\nx.add_row([\"Logistic Regression\",acc2])\nx.add_row([\"K-Nearest Neighbor\",acc3])\nx.add_row([\"Support Vector Machines\",acc4])\nx.add_row([\"Decision Tree\",acc5])\nx.add_row([\"Random Forest\",acc6])","metadata":{"execution":{"iopub.status.busy":"2021-06-23T09:25:16.02739Z","iopub.execute_input":"2021-06-23T09:25:16.027886Z","iopub.status.idle":"2021-06-23T09:25:16.032803Z","shell.execute_reply.started":"2021-06-23T09:25:16.027853Z","shell.execute_reply":"2021-06-23T09:25:16.032068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(x)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T09:24:05.55599Z","iopub.execute_input":"2021-06-23T09:24:05.556328Z","iopub.status.idle":"2021-06-23T09:24:05.561451Z","shell.execute_reply.started":"2021-06-23T09:24:05.556297Z","shell.execute_reply":"2021-06-23T09:24:05.560822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}