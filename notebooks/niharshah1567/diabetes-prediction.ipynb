{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2021-06-03T07:30:57.035949Z","iopub.execute_input":"2021-06-03T07:30:57.036337Z","iopub.status.idle":"2021-06-03T07:30:57.048088Z","shell.execute_reply.started":"2021-06-03T07:30:57.036303Z","shell.execute_reply":"2021-06-03T07:30:57.046969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/pima-indians-diabetes-database/diabetes.csv')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-03T07:30:57.04992Z","iopub.execute_input":"2021-06-03T07:30:57.050382Z","iopub.status.idle":"2021-06-03T07:30:57.076747Z","shell.execute_reply.started":"2021-06-03T07:30:57.050336Z","shell.execute_reply":"2021-06-03T07:30:57.075836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-03T07:30:57.078377Z","iopub.execute_input":"2021-06-03T07:30:57.078671Z","iopub.status.idle":"2021-06-03T07:30:57.096068Z","shell.execute_reply.started":"2021-06-03T07:30:57.078643Z","shell.execute_reply":"2021-06-03T07:30:57.094989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-03T07:30:57.097492Z","iopub.execute_input":"2021-06-03T07:30:57.09793Z","iopub.status.idle":"2021-06-03T07:30:57.143447Z","shell.execute_reply.started":"2021-06-03T07:30:57.097901Z","shell.execute_reply":"2021-06-03T07:30:57.142452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#REPLACE ALL ZERO WITH 'NAN'\ntrain_copy = train.copy(deep = True)\ntrain_copy[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] = train_copy[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']].replace(0,np.NaN)\n\n## showing the count of Nans\nprint(train_copy.isnull().sum())\n","metadata":{"execution":{"iopub.status.busy":"2021-06-03T07:30:57.144923Z","iopub.execute_input":"2021-06-03T07:30:57.14525Z","iopub.status.idle":"2021-06-03T07:30:57.161014Z","shell.execute_reply.started":"2021-06-03T07:30:57.145214Z","shell.execute_reply":"2021-06-03T07:30:57.159968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_copy.hist(figsize=(20,20))","metadata":{"execution":{"iopub.status.busy":"2021-06-03T07:30:57.162562Z","iopub.execute_input":"2021-06-03T07:30:57.162942Z","iopub.status.idle":"2021-06-03T07:30:59.143058Z","shell.execute_reply.started":"2021-06-03T07:30:57.162879Z","shell.execute_reply":"2021-06-03T07:30:59.142263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#REPLACE 'NAN' WITH THE DISTRIBUTION VALUES \ntrain_copy['Glucose'].fillna(train_copy['Glucose'].mean(), inplace = True)\ntrain_copy['BloodPressure'].fillna(train_copy['BloodPressure'].mean(), inplace = True)\ntrain_copy['SkinThickness'].fillna(train_copy['SkinThickness'].median(), inplace = True)\ntrain_copy['Insulin'].fillna(train_copy['Insulin'].median(), inplace = True)\ntrain_copy['BMI'].fillna(train_copy['BMI'].median(), inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T07:30:59.144328Z","iopub.execute_input":"2021-06-03T07:30:59.14459Z","iopub.status.idle":"2021-06-03T07:30:59.154175Z","shell.execute_reply.started":"2021-06-03T07:30:59.144564Z","shell.execute_reply":"2021-06-03T07:30:59.153117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#PLOT AFTER 'NAN' REMOVAL\ntrain_copy.hist(figsize=(20,20))","metadata":{"execution":{"iopub.status.busy":"2021-06-03T07:30:59.156494Z","iopub.execute_input":"2021-06-03T07:30:59.156826Z","iopub.status.idle":"2021-06-03T07:31:01.008902Z","shell.execute_reply.started":"2021-06-03T07:30:59.156796Z","shell.execute_reply":"2021-06-03T07:31:01.008093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_copy.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-03T07:31:01.010462Z","iopub.execute_input":"2021-06-03T07:31:01.010749Z","iopub.status.idle":"2021-06-03T07:31:01.016899Z","shell.execute_reply.started":"2021-06-03T07:31:01.010721Z","shell.execute_reply":"2021-06-03T07:31:01.015585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()","metadata":{"execution":{"iopub.status.busy":"2021-06-03T07:31:01.018188Z","iopub.execute_input":"2021-06-03T07:31:01.018486Z","iopub.status.idle":"2021-06-03T07:31:01.032894Z","shell.execute_reply.started":"2021-06-03T07:31:01.018456Z","shell.execute_reply":"2021-06-03T07:31:01.03164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#HEATMAP FOR TRAIN DATA\nplt.figure(figsize=(12,10)) \np=sns.heatmap(train_copy.corr(), annot=True,cmap ='RdYlGn')","metadata":{"execution":{"iopub.status.busy":"2021-06-03T07:31:01.034643Z","iopub.execute_input":"2021-06-03T07:31:01.03514Z","iopub.status.idle":"2021-06-03T07:31:01.764554Z","shell.execute_reply.started":"2021-06-03T07:31:01.03508Z","shell.execute_reply":"2021-06-03T07:31:01.763586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#SCALING THE DATA\nfrom sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\nX =  pd.DataFrame(sc_X.fit_transform(train_copy.drop([\"Outcome\"],axis = 1),),\n        columns=['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n       'BMI', 'DiabetesPedigreeFunction', 'Age'])","metadata":{"execution":{"iopub.status.busy":"2021-06-03T07:31:01.765927Z","iopub.execute_input":"2021-06-03T07:31:01.766245Z","iopub.status.idle":"2021-06-03T07:31:01.778199Z","shell.execute_reply.started":"2021-06-03T07:31:01.766214Z","shell.execute_reply":"2021-06-03T07:31:01.777038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-03T07:31:01.779968Z","iopub.execute_input":"2021-06-03T07:31:01.780343Z","iopub.status.idle":"2021-06-03T07:31:01.80131Z","shell.execute_reply.started":"2021-06-03T07:31:01.78031Z","shell.execute_reply":"2021-06-03T07:31:01.80026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = train_copy.Outcome","metadata":{"execution":{"iopub.status.busy":"2021-06-03T07:31:01.80266Z","iopub.execute_input":"2021-06-03T07:31:01.802958Z","iopub.status.idle":"2021-06-03T07:31:01.806955Z","shell.execute_reply.started":"2021-06-03T07:31:01.802929Z","shell.execute_reply":"2021-06-03T07:31:01.806037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#BUILDING LOGISTIC REGRESSION MODEL\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\n\n# Predict the labels of the test set: y_pred\ny_pred = logreg.predict(X_test)\n\n# Compute and print the confusion matrix and classification report\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-06-03T07:31:01.808283Z","iopub.execute_input":"2021-06-03T07:31:01.808572Z","iopub.status.idle":"2021-06-03T07:31:01.84526Z","shell.execute_reply.started":"2021-06-03T07:31:01.808545Z","shell.execute_reply":"2021-06-03T07:31:01.84401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ROC CURVE\nfrom sklearn.metrics import roc_curve\ny_pred_prob = logreg.predict_proba(X_test)[:,1]\n\n# Generate ROC curve values: fpr, tpr, thresholds\nfpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n\n# Plot ROC curve\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr, tpr)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-03T07:31:01.846531Z","iopub.execute_input":"2021-06-03T07:31:01.846813Z","iopub.status.idle":"2021-06-03T07:31:02.054857Z","shell.execute_reply.started":"2021-06-03T07:31:01.846786Z","shell.execute_reply":"2021-06-03T07:31:02.053872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import necessary modules\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import cross_val_score\n\n# Compute predicted probabilities: y_pred_prob\ny_pred_prob = logreg.predict_proba(X_test)[:,1]\n\n# Compute and print AUC score\nprint(\"AUC: {}\".format(roc_auc_score(y_test, y_pred_prob)))\n\n# Compute cross-validated AUC scores: cv_auc\ncv_auc = cross_val_score(logreg, X, y, cv=5,\nscoring='roc_auc')\n\n# Print list of AUC scores\nprint(\"AUC scores computed using 5-fold cross-validation: {}\".format(cv_auc))\n","metadata":{"execution":{"iopub.status.busy":"2021-06-03T07:31:02.056268Z","iopub.execute_input":"2021-06-03T07:31:02.056628Z","iopub.status.idle":"2021-06-03T07:31:02.126057Z","shell.execute_reply.started":"2021-06-03T07:31:02.056595Z","shell.execute_reply":"2021-06-03T07:31:02.124923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#HYPER PARAMETER TUNING WITH GridSearchCV\n# Import necessary modules\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\n\n# Setup the hyperparameter grid\nc_space = np.logspace(-5, 8, 15)\nparam_grid = {'C': c_space}\n\n# Instantiate a logistic regression classifier: logreg\nlogreg = LogisticRegression()\n\n# Instantiate the GridSearchCV object: logreg_cv\nlogreg_cv = GridSearchCV(logreg, param_grid, cv=5)\n\n# Fit it to the data\nlogreg_cv.fit(X, y)\n\n# Print the tuned parameters and score\nprint(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_)) \nprint(\"Best score is {}\".format(logreg_cv.best_score_))","metadata":{"execution":{"iopub.status.busy":"2021-06-03T07:31:02.127752Z","iopub.execute_input":"2021-06-03T07:31:02.128203Z","iopub.status.idle":"2021-06-03T07:31:02.851109Z","shell.execute_reply.started":"2021-06-03T07:31:02.128156Z","shell.execute_reply":"2021-06-03T07:31:02.849985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#HYPER PARAMETER TUNING WITH RandomizedSearchCV\n# Import necessary modules\nfrom scipy.stats import randint\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\n\n# Setup the parameters and distributions to sample from: param_dist\nparam_dist = {\"max_depth\": [3, None],\n              \"max_features\": randint(1, 9),\n              \"min_samples_leaf\": randint(1, 9),\n              \"criterion\": [\"gini\", \"entropy\"]}\n\n# Instantiate a Decision Tree classifier: tree\ntree = DecisionTreeClassifier()\n\n# Instantiate the RandomizedSearchCV object: tree_cv\ntree_cv = RandomizedSearchCV(tree, param_dist, cv=5)\n\n# Fit it to the data\ntree_cv.fit(X, y)\n\n# Print the tuned parameters and score\nprint(\"Tuned Decision Tree Parameters: {}\".format(tree_cv.best_params_))\nprint(\"Best score is {}\".format(tree_cv.best_score_))","metadata":{"execution":{"iopub.status.busy":"2021-06-03T07:31:02.852338Z","iopub.execute_input":"2021-06-03T07:31:02.85265Z","iopub.status.idle":"2021-06-03T07:31:03.178607Z","shell.execute_reply.started":"2021-06-03T07:31:02.852614Z","shell.execute_reply":"2021-06-03T07:31:03.177215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Hold-out set in practice I: Classification\n# Import necessary modules\nimport warnings\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\n\n# Create the hyperparameter grid\nc_space = np.logspace(-5, 8, 15)\nparam_grid = {'C': c_space, 'penalty': ['l1', 'l2']}\n\n# Instantiate the logistic regression classifier: logreg\nlogreg = LogisticRegression()\n\n# Create train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n\n# Instantiate the GridSearchCV object: logreg_cv\nlogreg_cv = GridSearchCV(logreg, param_grid, cv=5)\n\n# Fit it to the training data\nlogreg_cv.fit(X_train, y_train)\n\n# Print the optimal parameters and best score\nprint(\"Tuned Logistic Regression Parameter: {}\".format(logreg_cv.best_params_))\nprint(\"Tuned Logistic Regression Accuracy: {}\".format(logreg_cv.best_score_))\n","metadata":{"execution":{"iopub.status.busy":"2021-06-03T07:31:03.180134Z","iopub.execute_input":"2021-06-03T07:31:03.180555Z","iopub.status.idle":"2021-06-03T07:31:04.046811Z","shell.execute_reply.started":"2021-06-03T07:31:03.180508Z","shell.execute_reply":"2021-06-03T07:31:04.04567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. Tuned Logistic Regression Parameter: {'C': 0.05179474679231213, 'penalty': 'l2'}\n2. Tuned Logistic Regression Accuracy: 0.7695652173913043","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}