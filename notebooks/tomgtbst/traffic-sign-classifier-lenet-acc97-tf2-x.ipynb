{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport time\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n! pip install visualkeras\nimport visualkeras\n\n\nimport logging\nlogger = tf.get_logger()\nlogger.setLevel(logging.ERROR)\nprint(tf.test.is_gpu_available())\nprint(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Pre-process image size\nIMAGE_RES = 32\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n\n#Training parameters\nLEARNING_RATE = 0.001\nBATCH_SIZE = 64\nEPOCHS = 300","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"meta_df =  pd.read_csv('../input/gtsrb-german-traffic-sign/Meta.csv')\nn_classes = meta_df[\"ClassId\"].nunique()\nn_classes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_df = pd.read_csv('../input/gtsrb-german-traffic-sign/Train.csv',usecols=['ClassId', 'Path'])\ndata_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('../input/gtsrb-german-traffic-sign/Test.csv',usecols=['ClassId', 'Path'])\ntest_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dist = data_df['ClassId'].value_counts()\n\nplt.figure(figsize=(21, 8))\nplt.bar(dist.index, dist.values)\nplt.xlabel('Classes')\nplt.ylabel('Count of classes')\nplt.xticks(dist.index, rotation='vertical')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX = \"../input/gtsrb-german-traffic-sign/\" + data_df['Path'].values\ny = data_df['ClassId'].values\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.2, random_state = 42)\n\nX_test = \"../input/gtsrb-german-traffic-sign/\" + test_df['Path'].values\ny_test = test_df['ClassId'].values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_image(image):\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.image.resize(image, [IMAGE_RES, IMAGE_RES])\n    image /= 255.0  # normalize to [0,1] range\n\n    return image\n\ndef load_and_preprocess_image(path):\n    image = tf.io.read_file(path)\n    return preprocess_image(image)\n\ndef load_and_preprocess_from_path_label(path, label):\n    return load_and_preprocess_image(path), label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\ntrain_batches = train_ds.map(load_and_preprocess_from_path_label).batch(BATCH_SIZE).prefetch(1)\n\nvalid_ds = tf.data.Dataset.from_tensor_slices((X_valid, y_valid))\nvalidation_batches = valid_ds.map(load_and_preprocess_from_path_label).batch(BATCH_SIZE).prefetch(1)\n\ntest_data = tf.data.Dataset.from_tensor_slices((X_test, y_test))\ntest_batches = test_data.map(load_and_preprocess_from_path_label).batch(BATCH_SIZE).prefetch(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create new LeNet-5 model\nmodel = tf.keras.Sequential([\n    layers.experimental.preprocessing.RandomFlip(\"horizontal\", input_shape=(IMAGE_RES, IMAGE_RES, 3)),\n    layers.experimental.preprocessing.RandomRotation(0.2),\n    layers.Conv2D(6, kernel_size=(5, 5), strides=(1, 1), activation='relu',padding=\"valid\"),\n    layers.MaxPooling2D(pool_size=(2, 2),strides=(1, 1), padding='valid'),\n    layers.Conv2D(16, kernel_size=(5, 5), strides=(1, 1), activation='relu',padding=\"valid\"),\n    layers.MaxPooling2D(pool_size=(2, 2),strides=(1, 1), padding='valid'),\n    layers.Conv2D(32, kernel_size=(5, 5), strides=(1, 1), activation='relu',padding=\"valid\"),\n    layers.MaxPooling2D(pool_size=(2, 2),strides=(1, 1), padding='valid'),\n    layers.Conv2D(64, kernel_size=(5, 5), strides=(1, 1), activation='relu',padding=\"valid\"),\n    layers.MaxPooling2D(pool_size=(2, 2),strides=(1, 1), padding='valid'),\n    layers.Conv2D(128, kernel_size=(5, 5), strides=(1, 1), activation='relu',padding=\"valid\"),\n    layers.MaxPooling2D(pool_size=(2, 2),strides=(1, 1), padding='valid'),   \n    layers.Conv2D(256, kernel_size=(5, 5), strides=(1, 1), activation='relu',padding=\"valid\"),\n    layers.MaxPooling2D(pool_size=(2, 2),strides=(1, 1), padding='valid'), \n    layers.Flatten(),\n    layers.Dense(120, activation='relu',kernel_regularizer='l2'),\n    layers.Dense(84, activation='relu',kernel_regularizer='l2'),\n    layers.Dense(n_classes)\n])\n\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualkeras.layered_view(model, type_ignore=[layers.Flatten], legend=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=20)\n\nmodel.compile(\n    optimizer='adam',\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=['accuracy'])\n\nhistory = model.fit(train_batches, epochs=EPOCHS, validation_data=validation_batches, callbacks=[callback])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model on the validation set\nprint(\"Evaluate on validation data\")\nresults = model.evaluate(validation_batches)\nprint(\"validation loss, validation acc:\", results)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model on the test set\nprint(\"Evaluate on test data\")\nresults = model.evaluate(test_batches)\nprint(\"Test loss, test acc:\", results)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Saved Model\n# t = time.time()\n\n# export_path_sm = \"./save_model/LeNet/{}\".format(int(t))\n# print(export_path_sm)\n\n# tf.saved_model.save(model, export_path_sm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}