{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#ignoring warnings\nimport warnings\nwarnings.simplefilter('ignore')\n\n#importing neccesary modules\nimport sys\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-whitegrid')\nimport seaborn as sns\n\nimport sklearn\nfrom sklearn.linear_model import LinearRegression, SGDRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import BaggingRegressor, RandomForestRegressor\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom sklearn.externals import joblib\nfrom sklearn.model_selection import GridSearchCV, train_test_split\n\nimport xgboost\nfrom xgboost import XGBRegressor, DMatrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#python package version information\nprint('Python version:{}'.format(sys.version))\nprint('Numpy version:{}'.format(np.__version__))\nprint('Pandas version:{}'.format(pd.__version__))\nprint('MatlpotLib version:{}'.format(matplotlib.__version__))\nprint('Seaborn version:{}'.format(sns.__version__))\nprint('Sci-Kit Learn version:{}'.format(sklearn.__version__))\nprint('XGBoost version:{}'.format(xgboost.__version__))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eu = pd.read_csv('../input/eurusd-daily/eu.csv', index_col=0, parse_dates=True, skipinitialspace=True)\neu.drop('date', axis='columns', inplace=True)\neu.head(2)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"eu.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,6))\nplt.plot(eu.close)\nplt.title('Euro vs USD')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"#box plot for open, high, low , close\neu.drop('volume', axis=1).boxplot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#removing outliers above\nvol_cut_off = eu.volume.std()*3 + eu.volume.mean()\neu.volume[eu.volume > vol_cut_off] = vol_cut_off","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#removing ouliers below\nvol_cut_off =  eu.volume.mean() - eu.volume.std()*3\neu.volume[eu.volume < vol_cut_off] = vol_cut_off","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"#boxplot for volume\neu[['volume']].boxplot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_features(df):\n    \"\"\" Generate features for a stock/index/currency/commodity based on historical price and performance\n    Args:\n        df (dataframe with columns \"open\", \"close\", \"high\", \"low\", \"volume\")\n    Returns:\n        dataframe, data set with new features\n    \"\"\"\n    df_new = pd.DataFrame()\n    \n    # 6 original features\n    df_new['open'] = df['open']\n    df_new['open_1'] = df['open'].shift(1)\n    df_new['close_1'] = df['close'].shift(1)\n    df_new['high_1'] = df['high'].shift(1)\n    df_new['low_1'] = df['low'].shift(1)\n    df_new['volume_1'] = df['volume'].shift(1)\n    \n    # 50 original features\n    # average price\n    df_new['avg_price_5'] = df['close'].rolling(window=5).mean().shift(1)\n    df_new['avg_price_30'] = df['close'].rolling(window=21).mean().shift(1)\n    df_new['avg_price_90'] = df['close'].rolling(window=63).mean().shift(1)\n    df_new['avg_price_365'] = df['close'].rolling(window=252).mean().shift(1)\n    \n    # average price ratio\n    df_new['ratio_avg_price_5_30'] = df_new['avg_price_5'] / df_new['avg_price_30']\n    df_new['ratio_avg_price_905_'] = df_new['avg_price_5'] / df_new['avg_price_90']\n    df_new['ratio_avg_price_5_365'] = df_new['avg_price_5'] / df_new['avg_price_365']\n    df_new['ratio_avg_price_30_90'] = df_new['avg_price_30'] / df_new['avg_price_90']\n    df_new['ratio_avg_price_30_365'] = df_new['avg_price_30'] / df_new['avg_price_365']\n    df_new['ratio_avg_price_90_365'] = df_new['avg_price_90'] / df_new['avg_price_365']                                            \n    \n    \n    # average volume\n    df_new['avg_volume_5'] = df['volume'].rolling(window=5).mean().shift(1)\n    df_new['avg_volume_30'] = df['volume'].rolling(window=21).mean().shift(1)\n    df_new['avg_volume_90'] = df['volume'].rolling(window=63).mean().shift(1)\n    df_new['avg_volume_365'] = df['volume'].rolling(window=252).mean().shift(1)\n    \n    #average volume ratio\n    df_new['ratio_avg_volume_5_30'] = df_new['avg_volume_5'] / df_new['avg_volume_30']\n    df_new['ratio_avg_volumee_5_90'] = df_new['avg_volume_5'] / df_new['avg_volume_90']                                                   \n    df_new['ratio_avg_volume_5_365'] = df_new['avg_volume_5'] / df_new['avg_volume_365']\n    df_new['ratio_avg_volume_30_90'] = df_new['avg_volume_30'] / df_new['avg_volume_90']\n    df_new['ratio_avg_volume_30_365'] = df_new['avg_volume_30'] / df_new['avg_volume_365']\n    df_new['ratio_avg_volume_90_365'] = df_new['avg_volume_90'] / df_new['avg_volume_365']                                                 \n    \n    \n    # standard deviation of prices\n    df_new['std_price_5'] = df['close'].rolling(window=5).std().shift(1)\n    df_new['std_price_30'] = df['close'].rolling(window=21).std().shift(1)\n    df_new['std_price_90'] = df['close'].rolling(window=63).std().shift(1)                                               \n    df_new['std_price_365'] = df['close'].rolling(window=252).std().shift(1)\n    \n    # standard deviation ratio of prices \n    df_new['ratio_std_price_5_30'] = df_new['std_price_5'] / df_new['std_price_30']\n    df_new['ratio_std_price_5_90'] = df_new['std_price_5'] / df_new['std_price_90']\n    df_new['ratio_std_price_5_365'] = df_new['std_price_5'] / df_new['std_price_365']\n    df_new['ratio_std_price_30_90'] = df_new['std_price_30'] / df_new['std_price_90'] \n    df_new['ratio_std_price_30_365'] = df_new['std_price_30'] / df_new['std_price_365']                                               \n    df_new['ratio_std_price_90_365'] = df_new['std_price_90'] / df_new['std_price_365']                                                \n    \n    \n    # standard deviation of volumes\n    df_new['std_volume_5'] = df['volume'].rolling(window=5).std().shift(1)\n    df_new['std_volume_30'] = df['volume'].rolling(window=21).std().shift(1)\n    df_new['std_volume_90'] = df['volume'].rolling(window=63).std().shift(1)\n    df_new['std_volume_365'] = df['volume'].rolling(window=252).std().shift(1)\n    \n    #standard deviation ratio of volumes\n    df_new['ratio_std_volume_5_30'] = df_new['std_volume_5'] / df_new['std_volume_30']\n    df_new['ratio_std_volume_5_90'] = df_new['std_volume_5'] / df_new['std_volume_90']\n    df_new['ratio_std_volume_5_365'] = df_new['std_volume_5'] / df_new['std_volume_365']                                               \n    df_new['ratio_std_volume_30_90'] = df_new['std_volume_30'] / df_new['std_volume_90']\n    df_new['ratio_std_volume_30_365'] = df_new['std_volume_30'] / df_new['std_volume_365']\n    df_new['ratio_std_volume_90_365'] = df_new['std_volume_90'] / df_new['std_volume_365']                                               \n                                                   \n    # return\n    df_new['return_1'] = ((df['close'] - df['close'].shift(1)) / df['close'].shift(1)).shift(1)\n    df_new['return_5'] = ((df['close'] - df['close'].shift(5)) / df['close'].shift(5)).shift(1)\n    df_new['return_30'] = ((df['close'] - df['close'].shift(21)) / df['close'].shift(21)).shift(1)\n    df_new['return_90'] = ((df['close'] - df['close'].shift(63)) / df['close'].shift(63)).shift(1)                                                \n    df_new['return_365'] = ((df['close'] - df['close'].shift(252)) / df['close'].shift(252)).shift(1)\n    \n    #average of return\n    df_new['moving_avg_5'] = df_new['return_1'].rolling(window=5).mean()\n    df_new['moving_avg_30'] = df_new['return_1'].rolling(window=21).mean()\n    df_new['moving_avg_30'] = df_new['return_1'].rolling(window=63).mean()\n    df_new['moving_avg_365'] = df_new['return_1'].rolling(window=252).mean()\n    \n    # the target\n    df_new['close'] = df['close']\n    df_new = df_new.dropna(axis=0)\n    return df_new\n\ndata = generate_features(eu)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(data.corr())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### SEGREGATING TRAIN AND TEST DATA"},{"metadata":{"trusted":true},"cell_type":"code","source":"#import datetime module\nimport datetime\n\n#segregate data for training\nstart_train = datetime.datetime(1999, 1, 1,0,0)\nend_train = datetime.datetime(2017, 12, 31, 0, 0)\ndata_train = data.loc[start_train:end_train]\ndata_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"#segregate data for validation\nstart_test = datetime.datetime(2018, 1, 1, 0, 0)\nend_test = datetime.datetime(2019, 6, 7, 0, 0)\ndata_test = data.loc[start_test:end_test]\ndata_test.describe()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"X_train = data_train.drop('close', axis='columns')\ny_train = data_train.close\n\nX_test = data_test.drop('close', axis='columns')\ny_test = data_test.close\n\n#checking the shape of the train and test data\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### SCALING THE PREDICTOR DATA"},{"metadata":{"trusted":true},"cell_type":"code","source":"#initiating standard scaler\nscaler = StandardScaler()\n\n#fit the scaler in training features\nscaler.fit(X_train)\n\n#Rescale both sets using the trained scaler\nX_scaled_train = scaler.transform(X_train)\nX_scaled_test = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### LINEAR REGRESSION (LIN)"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlin = LinearRegression()\n\nlin.fit(X_scaled_train, y_train)\npredictions_lin = lin.predict(X_scaled_test)\n\nprint('RMSE: {0:.3f}'.format(mean_squared_error(y_test, predictions_lin)**0.5))\nprint('MAE: {0:.3f}'.format(mean_absolute_error(y_test, predictions_lin)))\nprint('R^2: {0:.3f}'.format(r2_score(y_test, predictions_lin)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dates = data_test.index.values\nplt.figure(figsize = (18,9))\nplt.style.use('seaborn-whitegrid')\nplot_truth, = plt.plot(dates, y_test)\nplot_lin, = plt.plot(dates, predictions_lin)\nplt.legend([plot_truth, plot_lin], ['Truth', 'Linear Regression'])\nplt.title('Gold price : Prediction vs Truth - Linear Regression')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### SGD REGRESSOR (SGD)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# First experiment with linear regression\n\n# SGD is very sensitive to data with features at different scales. Hence we need to do feature scaling before training.\n#search for the SGD-based linear regression with the optimal set of parameters. \nfrom sklearn.linear_model import SGDRegressor\n\nparam_grid = {\n    'penalty':['l1', 'l2', 'elasticnet'],\n    \"alpha\": [1e-5, 3e-5, 1e-4],\n    \"eta0\": [0.01, 0.03, 0.1],\n}\n\nsgd = SGDRegressor()\ngrid_search = GridSearchCV(sgd, param_grid, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1)\ngrid_search.fit(X_scaled_train, y_train)\n\nprint(grid_search.best_params_)\n\nsgd_best = grid_search.best_estimator_\n#print(grid_search.best_score_)\n\npredictions_sgd = sgd_best.predict(X_scaled_test)\n\n#evaluating the predictions\nprint('RMSE: {0:.3f}'.format(mean_squared_error(y_test, predictions_sgd)**0.5))\nprint('MAE: {0:.3f}'.format(mean_absolute_error(y_test, predictions_sgd)))\nprint('R^2: {0:.3f}'.format(r2_score(y_test, predictions_sgd)))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"dates = data_test.index.values\nplt.figure(figsize = (18,9))\nplot_truth, = plt.plot(dates, y_test)\nplot_sgd, = plt.plot(dates, predictions_sgd)\nplt.legend([plot_truth, plot_sgd], ['Truth', 'SGD'])\nplt.title('Gold price : Prediction vs Truth - SGD Regressor')\nplt.style.use('seaborn-whitegrid')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Extreme Gradient Boosting Regressor (XGB)"},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb = XGBRegressor()\n\ndata_dmatrix = DMatrix(data=X_train,\n                           label=y_train)\n\nxgb_param_grid = {'learning_rate': [0.001, 0.01, 0.1, 1],\n                  'n_estimators': [50, 100, 200, 300],\n                  'subsample': [0.3, 0.5, 0.7, 1]}\n\ngrid_search = GridSearchCV(estimator=xgb,    \n                        param_grid=xgb_param_grid,\n                        scoring='neg_mean_squared_error', \n                        cv=4, \n                        verbose=1,\n                       n_jobs=-1)\n\ngrid_search.fit(X_train, y_train) \n\nprint(\"Best parameters found: \",grid_search.best_params_)\n\nxgb_best = grid_search.best_estimator_\n\nxgb_best.fit(X_train,y_train)\npredictions_xgb = xgb_best.predict(X_test)\n\nprint('RMSE: {0:.3f}'.format(mean_squared_error(y_test, predictions_xgb)**0.5))\nprint('MAE: {0:.3f}'.format(mean_absolute_error(y_test, predictions_xgb)))\nprint('R^2: {0:.3f}'.format(r2_score(y_test, predictions_xgb)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dates = data_test.index.values\nplt.figure(figsize = (18,9))\nplot_truth, = plt.plot(dates, y_test)\nplot_xgb, = plt.plot(dates, predictions_xgb)\nplt.legend([plot_truth, plot_xgb], ['Truth', 'xgb'])\nplt.title('Gold price : Prediction vs Truth - XGB Regressor')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Bagging Regressor (BGR)"},{"metadata":{"trusted":true},"cell_type":"code","source":"BaggingRegressor?","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bgr = BaggingRegressor(base_estimator=lin, n_estimators=100, oob_score=True, n_jobs=-1)\n\nbgr.fit(X_scaled_train, y_train)\npredictions_bgr = bgr.predict(X_scaled_test)\n\nprint('OOB: {0:.3f}'.format(bgr.oob_score))\nprint('RMSE: {0:.3f}'.format(mean_squared_error(y_test, predictions_bgr)**0.5))\nprint('MAE: {0:.3f}'.format(mean_absolute_error(y_test, predictions_bgr)))\nprint('R^2: {0:.3f}'.format(r2_score(y_test, predictions_bgr)))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"dates = data_test.index.values\nplt.figure(figsize = (18,9))\nplot_truth, = plt.plot(dates, y_test)\nplot_bgr, = plt.plot(dates, predictions_bgr)\nplt.legend([plot_truth, plot_bgr], ['Truth', 'bgr'])\nplt.title('Gold price : Prediction vs Truth - BGR')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest Regressor (RF)"},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = {\n    \"max_depth\": [30, 50],\n    \"min_samples_split\": [5, 10, 20],\n\n}\n\nrf = RandomForestRegressor(n_estimators=100)\ngrid_search = GridSearchCV(rf, param_grid, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1)\ngrid_search.fit(X_train, y_train)\n\nprint(grid_search.best_params_)\n# print(grid_search.best_score_)\n\nrf_best = grid_search.best_estimator_\npredictions_rf = rf_best.predict(X_test)\n\nprint('RMSE: {0:.3f}'.format(mean_squared_error(y_test, predictions_rf)**0.5))\nprint('MAE: {0:.3f}'.format(mean_absolute_error(y_test, predictions_rf)))\nprint('R^2: {0:.3f}'.format(r2_score(y_test, predictions_rf)))\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"dates = data_test.index.values\nplt.figure(figsize = (18,9))\nplot_truth, = plt.plot(dates, y_test)\nplot_rf, = plt.plot(dates, predictions_rf)\nplt.legend([plot_truth, plot_rf], ['Truth', 'RF'])\nplt.title('Gold price : Prediction vs Truth - Random Forest')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mae_scoring = pd.Series({'LIN':mean_absolute_error(y_test, predictions_lin),\n                'SGD':mean_absolute_error(y_test, predictions_sgd),\n                'XGB':mean_absolute_error(y_test, predictions_xgb),\n                #'VTR':mean_absolute_error(y_test, predictions_vtr),\n                'BGR':mean_absolute_error(y_test, predictions_bgr),\n                'RFR':mean_absolute_error(y_test, predictions_rf)})\n\n#filtering the regressor with the least mean_absolute_error value\nfilter = mae_scoring.min()\nmae_min = mae_scoring[mae_scoring == mae_scoring.min()]\nprint('The model with the least mean_absolute_error:\\n',mae_min)\n\nplt.plot(mae_scoring, 'r')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Saving, Loading and Predicting with the BGR Model"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"#saving the BGR model with sklearn:joblib\njoblib.dump(bgr, 'bgr_eurusd_10062019.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#loading the saved model\nmodel = joblib.load('bgr_eurusd_10062019.pkl')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"#Visualizing the predictions and truth values\npred = model.predict(X_scaled_test)\nplt.figure(figsize=(15,7))\nplt.plot(y_test, 'r', label='Truth')\nplt.plot(y_test.index, pred, 'b', label='Predicted')\nplt.title(\"Bagging Regressor Model\")\nplt.xlabel('Date')\nplt.ylabel('Price')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plotting regression line\nplt.style.use('seaborn-whitegrid')\nplt.scatter(y_test, pred,color='blue')\nplt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', lw=3, label='Regression fit')\nfig = plt.gcf()\nfig.set_size_inches(10,5)\nplt.title(\"Regression Line for EURUSD\")\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"nbformat":4,"nbformat_minor":1}