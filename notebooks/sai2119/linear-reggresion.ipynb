{"cells":[{"metadata":{"id":"MJTKuA-wcayA"},"cell_type":"markdown","source":"## Import library python"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n\ndata = pd.read_csv(\"/kaggle/input/cardataset/data.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"id":"JtBSLDjBdWUB"},"cell_type":"markdown","source":"#**EDA**"},{"metadata":{"id":"DaudNTzmaWb8","outputId":"0a717fa7-e503-4b75-bdfa-d9227caf5dcc","trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"TpVOIP2hcUR8","outputId":"b19aefbc-c294-48ec-c52c-5a19c9adf2b9","trusted":true},"cell_type":"code","source":"data.tail()","execution_count":null,"outputs":[]},{"metadata":{"id":"zknc4o2Ta0OS","outputId":"f86c490e-f2b1-4e64-f4d0-3ce659cb766c","trusted":true},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{"id":"_qhgFkPVbKy2","outputId":"aaadf6a0-29a3-4449-ef40-b24eb2697736","trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"6zDHIh7pdnwx","outputId":"cf1be885-ebc6-4861-bccb-ea21627bb2c4","trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"id":"lrOdarX3k8jl","outputId":"51d45389-aebe-4ac1-e315-45e0f5c39314","trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"id":"EZOCsQAEnYwu"},"cell_type":"markdown","source":"# Dealing with NAN"},{"metadata":{"id":"5D5N81irbBWY","outputId":"0e5f69a4-6bb7-4860-db1c-59faaee7aab8","trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"id":"sipQTQLtbGnf","trusted":true},"cell_type":"code","source":"data.dropna(inplace=True,axis=0)","execution_count":null,"outputs":[]},{"metadata":{"id":"WQS9bhv7m99a","outputId":"318001b2-c7cb-4cc7-98eb-33fc500d9526","trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"id":"eIbbVbnyuYaK"},"cell_type":"markdown","source":"# Dealing Outlier "},{"metadata":{"id":"eesxrKEnnFCa","outputId":"4434228d-d367-4915-cbe0-2c42241113b7","trusted":true},"cell_type":"code","source":"sns.boxplot(data=data,orient='h',palette='Set2')","execution_count":null,"outputs":[]},{"metadata":{"id":"-i6dcok0oL46","trusted":true},"cell_type":"code","source":"data['new msrp'] = np.log1p(data.MSRP)\ndata.drop('MSRP', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"xBQ2CDzQqB7S","outputId":"69456629-abf6-4351-ec3b-92bdf313f791","trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"1sWU65ifoiKH","outputId":"878a2356-21cd-4346-9aab-1a42369843f4","trusted":true},"cell_type":"code","source":"sns.boxplot(data=data,orient='h',palette='Set2')","execution_count":null,"outputs":[]},{"metadata":{"id":"oH4XSQbHos97","outputId":"5f1eed57-0d5e-4503-804e-8260b25d11ee","trusted":true},"cell_type":"code","source":"q1, q3 = np.percentile(data['Popularity'],[25,75])\niqr = q3-q1\nwhisker = q3 + (1.5 * iqr)\nprint(whisker)","execution_count":null,"outputs":[]},{"metadata":{"id":"tv8As1LNrvEw","trusted":true},"cell_type":"code","source":"data['Popularity'] = data['Popularity'].clip(upper=whisker)","execution_count":null,"outputs":[]},{"metadata":{"id":"Xqy4-NqKsKWq","outputId":"71e0e452-5c92-4307-fcf7-c44472f6f977","trusted":true},"cell_type":"code","source":"sns.boxplot(data=data,orient='h',palette='Set2')","execution_count":null,"outputs":[]},{"metadata":{"id":"fJ6j7C2962RU"},"cell_type":"markdown","source":"# **creating Label Encoder for categorical variables**"},{"metadata":{"id":"frRRUoip5kIb","trusted":true},"cell_type":"code","source":"# For Label Encoder data types need to be cat \ncolumns_to_convert=['Make','Model','Engine Fuel Type','Transmission Type','Driven_Wheels','Market Category','Vehicle Size','Vehicle Style']\ndata[columns_to_convert] = data[columns_to_convert].astype('category')","execution_count":null,"outputs":[]},{"metadata":{"id":"lGh4v4K1MEZk","outputId":"d41ab526-a699-489e-f2dd-8b5c5a882b23","trusted":true},"cell_type":"code","source":"data.dtypes\n","execution_count":null,"outputs":[]},{"metadata":{"id":"Eknl6dHcKUJO","trusted":true},"cell_type":"code","source":" # Import label encoder\nfrom sklearn import preprocessing\n  \n# label_encoder object knows how to understand word labels.\nlabel_encoder = preprocessing.LabelEncoder()\n  \n# Encode labels in column 'species'.\nfor col in ['Make','Model','Engine Fuel Type','Transmission Type','Driven_Wheels','Market Category','Vehicle Size','Vehicle Style']: data[col] = label_encoder.fit_transform(data[col])\n","execution_count":null,"outputs":[]},{"metadata":{"id":"EGd6vLEq_By-","outputId":"0257f0a0-f452-4770-d1d0-2c2ccfd68902","trusted":true},"cell_type":"code","source":"data.head()\n","execution_count":null,"outputs":[]},{"metadata":{"id":"DVkw6C_B_Fmv","outputId":"af7956e7-5214-4166-ce10-1c6930431f40","trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"DVAfvr_zBhrp"},"cell_type":"markdown","source":"#correaltion\n\n\n\n"},{"metadata":{"id":"9r1yO4UjBfc8","outputId":"d68c6639-547a-4b66-c66a-3924433e00e9","trusted":true},"cell_type":"code","source":"import seaborn as sns\ncorrmat = data.corr()\ntop_corr_features = corrmat.index\nplt.figure(figsize=(13,13))\ng=sns.heatmap(data[top_corr_features].corr(),annot=True,cmap='rainbow',linewidths=3)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"0TtWuurOWbvy","outputId":"51f3e7c9-1e04-45b2-cdbb-ed7fc557fe2a","trusted":true},"cell_type":"code","source":"X = data.corr()\nX['new msrp'].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"id":"hbxwI2wodG55","outputId":"423bbadc-6ff2-4240-cf0b-672fadbb96a8","trusted":true},"cell_type":"code","source":"xy = ['new msrp','Engine HP','Year','Engine Cylinders']\ndata_ve = data[xy]\nNew_data = data.copy()\ndata_ve.head()\n","execution_count":null,"outputs":[]},{"metadata":{"id":"9cTqT-J_uwGw"},"cell_type":"markdown","source":"#*Decoupling target*"},{"metadata":{"id":"K7Xy430PzKze","outputId":"51df3f5d-20de-47c4-c9af-b95f7d5e9f77","trusted":true},"cell_type":"code","source":"data = data_ve\ntarget = \"new msrp\"\n\nX = data[data.columns.difference([target])]\ny = data['new msrp']\nprint(X.shape)\ny.shape\n\n","execution_count":null,"outputs":[]},{"metadata":{"id":"-KehroHN1sNB"},"cell_type":"markdown","source":"*Test-Train split*"},{"metadata":{"id":"UfR2ljKa1zQr","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=124421)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"hxMLVqfi4Bou"},"cell_type":"markdown","source":"Model Bulidling "},{"metadata":{"id":"747yWInY2tad","trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn import metrics\n\n","execution_count":null,"outputs":[]},{"metadata":{"id":"9NS1ZAOK4ihJ","outputId":"4d68f2f0-9116-4703-adf0-504c7c6e178d","trusted":true},"cell_type":"code","source":"linear = LinearRegression()\nlinear.fit(X_train, y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"hG2bb4Vd5HyI","outputId":"b33bdc7c-27fb-4e2f-c3c5-a0fba132ae84","trusted":true},"cell_type":"code","source":"#To retrieve the intercept:\nprint(linear.intercept_)\n#For retrieving the slope:\nprint(linear.coef_)","execution_count":null,"outputs":[]},{"metadata":{"id":"5hP7zlGtBkUq","outputId":"40e5d514-e685-4311-c71a-aec232bc9cbd","trusted":true},"cell_type":"code","source":"y_test_predict = linear.predict(X_test)\nprint(y_test_predict)\ny_train_predict= linear.predict(X_train)\ny_train_predict","execution_count":null,"outputs":[]},{"metadata":{"id":"JfFoeMgZB7wI","outputId":"e8c9fbbd-4626-4697-f9ec-b052d0c32b6a","trusted":true},"cell_type":"code","source":"df = pd.DataFrame({'Actual': y_test, 'Predicted':y_test_predict})\ndf","execution_count":null,"outputs":[]},{"metadata":{"id":"_EmfmCrf-AQR","outputId":"aaf28444-502a-4383-ef9b-9ee1dc168adf","trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error\n\nprint(mean_squared_error(y_train,y_train_predict))\nprint(mean_squared_error(y_test,y_test_predict))\n\nprint(r2_score(y_train,y_train_predict))\nprint(r2_score(y_test,y_test_predict))\n\nprint(mean_absolute_error(y_train,y_train_predict))\nprint(mean_absolute_error(y_test,y_test_predict))","execution_count":null,"outputs":[]},{"metadata":{"id":"eoY0um1M_W9h","outputId":"726722a0-f305-4a67-a2dc-7bde27a1a248","trusted":true},"cell_type":"code","source":"from sklearn import metrics\nprint(np.sqrt(metrics.mean_squared_error(y_train,y_train_predict)))\nprint(np.sqrt(metrics.mean_squared_error(y_test,y_test_predict)))\n","execution_count":null,"outputs":[]},{"metadata":{"id":"U0f0BjPRn6Xv"},"cell_type":"markdown","source":"# Inculding neg corr"},{"metadata":{"id":"Ugl8r1fGn8E5","outputId":"f5070e23-2b5d-461b-d5b7-be2aa1d07340","trusted":true},"cell_type":"code","source":"xyz = ['new msrp','Engine HP','Year','Engine Cylinders','Transmission Type','Engine Fuel Type','city mpg','Make','highway MPG','Market Category','Driven_Wheels']\ndata_all = New_data[xyz]\ndata_all.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"8nbVAfDcqF2i","outputId":"1db84637-82ef-44db-8bfd-0548cab591d4","trusted":true},"cell_type":"code","source":"# dcoupling\n\ndata = data_all\ntarget = \"new msrp\"\n\nX = data[data.columns.difference([target])]\ny = data['new msrp']\nprint(X.shape)\ny.shape\n\n\n\n#Train test spilt\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=124421)\n\n# Fitting\n\nlinear = LinearRegression()\nlinear.fit(X_train, y_train)\n# Predict\n\ny_test_predict = linear.predict(X_test)\nprint(y_test_predict)\ny_train_predict= linear.predict(X_train)\ny_train_predict\n\n#To retrieve the intercept:\nprint(linear.intercept_)\n#For retrieving the slope:\nprint(linear.coef_)\n\n\n#test vs pred\ndf1 = pd.DataFrame({'Actual': y_test, 'Predicted':y_test_predict})\ndf1\n#Metrics\nfrom sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error\nprint(\"MSE of Train =\", mean_squared_error(y_train,y_train_predict))\nprint('MSE of Test',mean_squared_error(y_test,y_test_predict) )\nprint('r2_score of Train ', r2_score(y_train,y_train_predict))\nprint('r2_score of Test ',r2_score(y_test,y_test_predict))\nprint('MAE of Train ',mean_absolute_error(y_train,y_train_predict) )\nprint('MAE of Test ',mean_absolute_error(y_test,y_test_predict))\n\n#metrics MSE\nfrom sklearn import metrics\nprint('sqrt MSE of Train',np.sqrt(metrics.mean_squared_error(y_train,y_train_predict)))\n\nprint('sqrt MSE of Test', np.sqrt(metrics.mean_squared_error(y_test,y_test_predict)))\n","execution_count":null,"outputs":[]},{"metadata":{"id":"SA37u4Mu0hh3"},"cell_type":"markdown","source":"# ols method"},{"metadata":{"id":"_EbUE-vI0hyO","outputId":"958c6f9b-1ac3-402d-b171-8f751862dd88","trusted":true},"cell_type":"code","source":"\nimport statsmodels.api as sm\n\nx_train = sm.add_constant(X_train)\nmodel = sm.OLS(y_train, x_train)\nresults = model.fit()\nprint (\"r2/variance : \", results.rsquared)","execution_count":null,"outputs":[]},{"metadata":{"id":"w66WZHACyRTX"},"cell_type":"markdown","source":"# Grid search"},{"metadata":{"id":"9fITKE6PyVrW","outputId":"3b4fe881-a346-4f3e-aecd-2e694cbf6602","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nmodel = LinearRegression()\nparameters = {'fit_intercept':[True,False], 'normalize':[True,False], 'copy_X':[True,False]}\ngrid = GridSearchCV(model,parameters, cv=None)\ngrid.fit(X_train, y_train)\nprint (\"r2 / variance : \", grid.best_score_)\nprint(\"Residual sum of squares: %.2f\" % np.mean((grid.predict(X_test) - y_test) ** 2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> # Decision Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\n#data\n\nvar = ['new msrp','Engine HP','Year','Engine Cylinders','Transmission Type','Engine Fuel Type','city mpg','Make','highway MPG','Market Category','Driven_Wheels']\ndata_for_decision_tree = New_data[var]\ndata_for_decision_tree.head()\n\n\n# dcoupling\n\ndata =data_for_decision_tree\ntarget = \"new msrp\"\n\nX = data[data.columns.difference([target])]\ny = data['new msrp']\n\n#Train test spilt\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=124421)\n\n# Fit regression model\nregr_1 = DecisionTreeRegressor(max_depth=4)\nregr_2 = DecisionTreeRegressor(max_depth=5)\nregr_1.fit(X_train, y_train)\nregr_2.fit(X_train, y_train)\n\n# predicting a new value \n\n# test the output by changing values\ny_pred1 = regr_1.predict(X_test)\ny_pred2 = regr_2.predict(X_test)\n# print the predicted price \nprint('Value for max depth 4 =',y_pred1) \nprint('Value for max depth 5 =',y_pred2) \nprint('mean_squared_error max depth 4 =',mean_squared_error(y_test,y_pred1))\nprint('r2_score max depth 4 =',r2_score(y_test,y_pred1))\nprint('mean_squared_error sqrt max depth 4 =',np.sqrt(metrics.mean_squared_error(y_test,y_pred1)))\nprint('mean_squared_error for max depth 5 =',mean_squared_error(y_test,y_pred2))\nprint('r2_score max depth 5 =',r2_score(y_test,y_pred2))\nprint('mean_squared_error sqrt max depth 5 =',np.sqrt(metrics.mean_squared_error(y_test,y_pred2)))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"# Hyperparameter tuning with GridSearchCV"},{"metadata":{"trusted":true},"cell_type":"code","source":"dtm = DecisionTreeRegressor()\n\nparam_grid = {\"criterion\": [\"mse\", \"mae\"],\n              \"min_samples_split\": [10, 20, 40],\n              \"max_depth\": [2, 6, 8,10],\n              \"min_samples_leaf\": [20, 40, 100],\n              \"max_leaf_nodes\": [5, 20, 100],\n              }\n\n## Comment in order to publish in kaggle.\n\ngrid_cv_dtm = GridSearchCV(dtm, param_grid, cv=5)\n\ngrid_cv_dtm.fit(X_train, y_train)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"R-Squared::{}\".format(grid_cv_dtm.best_score_))\nprint(\"Best Hyperparameters::\\n{}\".format(grid_cv_dtm.best_params_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random Forest for Reggresion"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting Random Forest Regression to the dataset \n# import the regressor \nfrom sklearn.ensemble import RandomForestRegressor \n  \n # create regressor object \nregressor = RandomForestRegressor(n_estimators = 100, random_state = 0) \n  \n# fit the regressor with x and y data \nregressor.fit(X_train, y_train)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predicting a new value \n\n# test the output by changing values\ny_pred = regressor.predict(X_test)\n# print the predicted price \nprint('Value for regressor predict=',y_pred1) \nprint('mean_squared_error regressor predict =',mean_squared_error(y_test,y_pred1))\nprint('r2_score regressor predict =',r2_score(y_test,y_pred1))\nprint('mean_squared_error regressor predict =',np.sqrt(metrics.mean_squared_error(y_test,y_pred1)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Hyperparameter tuning with GridSearchCV for Random Forest for Reggresion"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nrf = RandomForestRegressor(random_state = 42)\nfrom pprint import pprint\n# Look at parameters used by our current forest\nprint('Parameters currently in use:\\n')\npprint(rf.get_params())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"n_estimators = number of trees in the foreset\nmax_features = max number of features considered for splitting a node\nmax_depth = max number of levels in each decision tree\nmin_samples_split = min number of data points placed in a node before the node is split\nmin_samples_leaf = min number of data points allowed in a leaf node\nbootstrap = method for sampling data points (with or without replacement)"},{"metadata":{},"cell_type":"markdown","source":"Random Hyperparameter Grid"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(5, 110, num = 11)]\nmax_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4]\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\npprint(random_grid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use the random grid to search for best hyperparameters\n# First create the base model to tune\nrf = RandomForestRegressor()\n# Random search of parameters, using 3 fold cross validation, \n# search across 100 different combinations, and use all available cores\nrf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n# Fit the random search model\nrf_random.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_random.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(model,X_test, y_test):\n    predictions = model.predict(X_test)\n    errors = abs(predictions - y_test)\n    mape = 100 * np.mean(errors / y_test)\n    accuracy = 100 - mape\n    print('Model Performance')\n    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n    print('Accuracy = {:0.2f}%.'.format(accuracy))\n    \n    return accuracy\nbase_model = RandomForestRegressor(n_estimators = 10, random_state = 42)\nbase_model.fit(X_train, y_train)\nbase_accuracy = evaluate(base_model, X_test, y_test )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_random =  RandomForestRegressor(n_estimators= 1400,min_samples_split= 5,min_samples_leaf= 1,max_features= 'sqrt',max_depth= 78,bootstrap= False,  random_state=42, n_jobs = -1)\n\nrf_random.fit(X_train, y_train)\n\npredictions =rf_random.predict(X_test)\n# print the predicted price \nprint('Value for regressor predict=',predictions) \nprint('mean_squared_error regressor predict =',mean_squared_error(y_test,predictions))\nprint('r2_score regressor predict =',r2_score(y_test,predictions))\nprint('mean_squared_error regressor predict =',np.sqrt(metrics.mean_squared_error(y_test,predictions)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"grid based on the results of random search"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Create the parameter grid based on the results of random search \nparam_grid = {\n    'bootstrap': [True],\n    'max_depth': [80, 90, 100, 110],\n    'max_features': [2, 3],\n    'min_samples_leaf': [3, 4, 5],\n    'min_samples_split': [8, 10, 12],\n    'n_estimators': [100, 200, 300, 1000]\n}\n# Create a based model\nrf = RandomForestRegressor()\n# Instantiate the grid search model\ngrid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n                          cv = 3, n_jobs = -1, verbose = 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit the grid search to the data\ngrid_search.fit(X_train, y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_grid = grid_search.best_estimator_\ngrid_accuracy = evaluate(best_grid, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_random =  RandomForestRegressor(n_estimators= 1000,min_samples_split= 8,min_samples_leaf= 3,max_features= 3,max_depth= 110,bootstrap= True,  random_state=42, n_jobs = -1)\n\nrf_random.fit(X_train, y_train)\n\npredictions =rf_random.predict(X_test)\n# print the predicted price \nprint('Value for regressor predict=',predictions) \nprint('mean_squared_error regressor predict =',mean_squared_error(y_test,predictions))\nprint('r2_score regressor predict =',r2_score(y_test,predictions))\nprint('mean_squared_error regressor predict =',np.sqrt(metrics.mean_squared_error(y_test,predictions)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# XGBOOST"},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nfrom xgboost.sklearn import XGBRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Various hyper-parameters to tune\nxgb1 = XGBRegressor()\nparameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n              'objective':['reg:linear'],\n              'learning_rate': [.03, 0.05, .07], #so called `eta` value\n              'max_depth': [5, 6, 7],\n              'min_child_weight': [4],\n              'silent': [1],\n              'subsample': [0.7],\n              'colsample_bytree': [0.7],\n              'n_estimators': [500]}\n\nxgb_grid = GridSearchCV(xgb1,\n                        parameters,\n                        cv = 2,\n                        n_jobs = -1,\n                        verbose=True)\n\nxgb_grid.fit(X_train, y_train)\n\nprint(xgb_grid.best_score_)\nprint(xgb_grid.best_params_)","execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"car value prediction","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":4}