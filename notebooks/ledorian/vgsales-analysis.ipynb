{"cells":[{"metadata":{},"cell_type":"markdown","source":"Hello reader,\n\nI'm a data science beginner, and I used this dataset to train.  \n\nIn parallel to another notebook where I try to predict Sales from other features, I will focus here on learning new stuff on data analysis, such as data cleansing or interesting visualisations.  \n  \nFeel free to comment if you have any suggestion or advices.  \n\nThank you !"},{"metadata":{},"cell_type":"markdown","source":"**Todo**:\n* Split features in groups\n* Try PCA\n* Try a lot of visualisations"},{"metadata":{},"cell_type":"markdown","source":"## Packages"},{"metadata":{"collapsed":true},"source":"import pandas as pd\nimport sklearn as sk\nimport numpy as np\nimport matplotlib.pyplot as plt","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Import"},{"metadata":{"collapsed":true},"source":"df = pd.read_csv('../input/vgsales.csv')","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Discovery"},{"metadata":{"scrolled":true},"source":"df.head()","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"scrolled":true},"source":"df.dtypes","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true},"source":"col_quan = df.select_dtypes(exclude = ['object']).columns\ncol_qual = df.select_dtypes(include = ['object']).columns","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Qualitative data"},{"metadata":{"collapsed":true},"source":"df_qual = df[col_qual]","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{},"source":"print(\"Number of unique values in each qualitative variable\")\nprint(\"All:  {}\".format(len(df)))\nfor col in df_qual.columns:\n    nb_unique = len(df[col].unique())\n    print(\"{}: {}\".format(col[:4], nb_unique))","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Name\n\nMultiple games with the same name, let's check a bit more"},{"metadata":{},"source":"print(len(df[df[['Name']].duplicated()]))\nprint(len(df[df[['Name', 'Platform']].duplicated()]))\nprint(len(df[df[['Name', 'Platform', 'Year']].duplicated()]))\ndf[df[['Name', 'Platform', 'Year']].duplicated(keep=False)]","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, most 'Name' duplicate comes from games published on different Platforms.  \nThere are also a few that are on the same Platform , with different year info. (Probably remake)  \nLast two have same name, same date, and same platform. Those are clearly duplicates.  \n  \nHard to know if we should merge them by adding sales values or just forget about the smallest one.  \nHere is how to remove the smallest ones from our set."},{"metadata":{"collapsed":true},"source":"df = df.sort_values(['Global_Sales'], ascending=False)\ndf = df[~df[['Name', 'Platform', 'Year']].duplicated(keep='first')]","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Platform"},{"metadata":{},"source":"fig, ax = plt.subplots()\ndf_qual['Platform'].value_counts().plot(ax=ax, kind='bar')\nplt.show()","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's split them by categories (portable or not, console generation)"},{"metadata":{"collapsed":true},"source":"","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true},"source":"","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true},"source":"","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Quantitative data"},{"metadata":{"scrolled":false},"source":"df.describe()","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Rank**:\n- seems a bit off (max = 16600 for 16598 lines)\n  \n**Year**:\n- missing values !\n- aberrant value (max = 2020, dataset is from 2016-10-26)  \n  \n**Sales**:\n- in short : NA > EU > JP > Other (but other's repartition is a bit wider)\n- quantiles show a strange distribution. Will have to plot that to chech more.\n- Max values looks aberrantly far from 75% quantile."},{"metadata":{},"cell_type":"markdown","source":"### Year"},{"metadata":{},"source":"df[df.isnull().any(axis=1)]","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true},"source":"","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true},"source":"","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true},"source":"","execution_count":null,"cell_type":"code","outputs":[]}],"nbformat":4,"metadata":{"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","name":"python","codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","version":"3.6.1"},"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"}},"nbformat_minor":1}