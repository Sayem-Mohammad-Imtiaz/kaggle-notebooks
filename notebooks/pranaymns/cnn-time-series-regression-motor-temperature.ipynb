{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.utils.data\n\nfrom sklearn.preprocessing import MinMaxScaler\n\ntorch.manual_seed(2)\nnp.random.seed(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/electric-motor-temperature/pmsm_temperature_data.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col_list = df.columns.tolist()\nprofile_id = ['profile_id']\ntarget_list = ['pm', 'torque', 'stator_yoke', 'stator_tooth', 'stator_winding']\nfeature_list = [col for col in col_list if col not in target_list and col not in profile_id]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### As explained in the description the profile_id column in the data set corresponds to different measurement sessions. The most interesting target features given in description are rotor temperature('pm), stator temperatures('stator_*) and torque. \n##### All the other features are considered to be inputs features"},{"metadata":{"trusted":true},"cell_type":"code","source":"col_list = df.columns.tolist()\nprofile_id = ['profile_id']\ntarget_list = ['pm', 'torque', 'stator_yoke', 'stator_tooth', 'stator_winding']\nfeature_list = [col for col in col_list if col not in target_list and col not in profile_id]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### As profile id just indicates which measurement session the data belongs to, it can be treated as categorical variable, and also to make select data that is relevant to the session"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['profile_id'] = df.profile_id.astype('category', inplace=True)\ndf.profile_id.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dividing the data based on the profile id"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_dict = {}\nfor id_ in df.profile_id.unique():\n    df_dict[id_] = df[df['profile_id']==id_].reset_index(drop = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Since all the variables/features are measured over time and are time dependant. The later analysis is done assuming the data to be time series data.\n\n#### For this reason, the data is split into number of time sequences. The target value for a given sequence will be the value which is just after a given sequence."},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_sequences(features_df, target_df, sequence_length = 10):\n    \"\"\"Builds sequences from data and converts them into pytorch tensors\n        sequence_length - represents the number of samples to be considered in a sequence\n    \"\"\"\n    data_ = []\n    target_ = []\n    \n    for i in range(int(features_df.shape[0]/sequence_length)):\n        \n        data = torch.from_numpy(features_df.iloc[i:i+sequence_length].values)\n        target = torch.from_numpy(target_df.iloc[i+sequence_length+1].values)\n        \n        data_.append(data)\n        target_.append(target)\n        \n    data = torch.stack(data_)\n    target = torch.stack(target_)\n    \n    return data, target","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prof_ids = list(df_dict.keys())\ndf_dict.keys()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### Slecting a measurement profile to prepare the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Randomly selecting\n# idx = np.random.randint(len(list(df_dict.keys())))\n\n# prof_id = prof_ids[idx]\n# print('Selected profile -',prof_id)\n\n### OR ###\n# Manual Selection\nprof_id = 6\n\ncurr_df = df_dict[prof_id]\n\ncurr_df = curr_df.drop('profile_id', axis = 1)\ncolumns = curr_df.columns.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler()\n\ncurr_df = pd.DataFrame(scaler.fit_transform(curr_df), columns= columns)\ncurr_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Sequence length has to be selected prior to the model initialization\n\n##### As the sampling is done at 2 Hz, the sequence size can be >= 2. But, keeping in view the importance of speed of operation as the values are needed for other operations or control, it should be as small as possible to reduce the delay.\n\n##### Also, another point to be noted here is, if the sequence length is higher the prediction error is less. So there must be a trade off between the required error rate and speed (in this case the initial prediction). \n\n##### The delay in responce will be only at the beginning and the later predictions will not have the delay if real time operation is considered."},{"metadata":{"trusted":true},"cell_type":"code","source":"sequence_length = 3\n\nfeatures = curr_df[feature_list]\ntarget = curr_df[target_list][['pm']]\n\ndata, target = build_sequences(features, target, sequence_length=sequence_length)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Dividing the generated sequences into training and testing set"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test size the percentage of data to be used for testing\ntest_size = 0.05\n\nindices = torch.randperm(data.shape[0])\n\ntrain_indices = indices[:int(indices.shape[0] * (1-test_size))]\ntest_indices = indices[int(indices.shape[0] * (1-test_size)):]\n\nX_train, y_train = data[train_indices], target[train_indices]\nX_test, y_test = data[test_indices], target[test_indices]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### A Dataset class is needed for the data inorder to use the dataloader of Pytorch"},{"metadata":{"trusted":true},"cell_type":"code","source":"class PMSMDataset(torch.utils.data.dataset.Dataset):\n    \"\"\"Dataset with Rotor Temperature as Target\"\"\"\n    def __init__(self, data, target):\n        \n        self.data = data\n        self.target = target\n        \n    def __len__(self):\n        return self.data.shape[0]\n    \n    def __getitem__(self, idx):\n        return self.data[idx].unsqueeze(0), self.target[idx]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 10\n\npm_train_dataset = PMSMDataset(X_train, y_train)\npm_train_loader = torch.utils.data.dataloader.DataLoader(pm_train_dataset, batch_size= batch_size)\n\npm_test_dataset = PMSMDataset(X_test, y_test)\npm_test_loader = torch.utils.data.dataloader.DataLoader(pm_test_dataset, batch_size= 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### The network "},{"metadata":{"trusted":true},"cell_type":"code","source":"class Network(nn.Module):\n    def __init__(self, sequence_length, n_features):\n        super(Network, self).__init__()\n        \n        \n        self.conv1 = nn.Conv1d(1, 3, kernel_size=(sequence_length, n_features))\n        \n        self.lin_in_size = self.conv1.out_channels * int(((sequence_length - (self.conv1.kernel_size[0]-1) -1)/self.conv1.stride[0] +1))\n        \n#         print(self.lin_in_size)\n        \n        self.fc1 = nn.Linear(self.lin_in_size,30)\n        self.fc2 = nn.Linear(30, 1)\n        \n    def forward(self, x):\n        \n        x = F.relu(self.conv1(x))\n        x = x.view(-1, self.lin_in_size)\n        \n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        \n        return x","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Note that the same sequence length used to generate the data should be used to create the network"},{"metadata":{"trusted":true},"cell_type":"code","source":"n_features = X_train.shape[-1]\n\nnet = Network(sequence_length, n_features).double()\nnet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = 0.001\n\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(net.parameters(), lr=lr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"training_losses = []\nfor epoch in range(50):\n    running_loss = 0.0\n    batch_losses = []\n    for i, (data, target) in enumerate(pm_train_loader):\n\n        optimizer.zero_grad()\n\n        out = net(data)\n\n        loss = criterion(out, target)\n        batch_losses.append(loss.item())\n\n        loss.backward()\n        optimizer.step()            \n    training_losses.append(np.mean(batch_losses))\n    print(\"Epoch {}, loss {:.6f}\".format(epoch+1, training_losses[-1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(training_losses)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Testing"},{"metadata":{"trusted":true},"cell_type":"code","source":"losses = []\nbatch_losses = []\ntargets = []\noutputs = []\nwith torch.no_grad():\n    for i, (data, target) in enumerate(pm_test_loader):\n        out = net(data)\n        loss = criterion(out, target)\n#         print('Target : {:.4f}, Predicted Output : {:.4f}'.format(target.item(), out.item()))\n        \n        targets.append(target.item())\n        outputs.append(out.item())\n        \n        batch_losses.append(loss.item())\n    losses.append(np.mean(batch_losses))\nprint(\"Testing loss {:.6f}\".format(losses[-1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(13,7))\n# plt.scatter(np.arange(len(outputs)),outputs, c = 'b', s = 15, marker='*', label = 'predicted')\nplt.plot(np.arange(len(outputs)),outputs, alpha = 0.8, marker = '.',label = 'predicted' )\nplt.scatter(np.arange(len(targets)),targets, c = 'r', s = 15, label = 'true')\nplt.legend(loc='best')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}