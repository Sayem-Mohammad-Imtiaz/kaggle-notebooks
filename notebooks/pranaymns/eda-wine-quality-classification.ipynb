{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.chdir('/kaggle/input/red-wine-quality-cortez-et-al-2009/')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nfrom sklearn.model_selection import cross_val_score\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n\n%matplotlib inline\nplt.style.use('ggplot')\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_red = pd.read_csv(\"winequality-red.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df_red\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['quality'].value_counts(sort = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['quality'].hist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looks like the distribution is imbalanced, grouping them into three categories 'good', 'ok' and 'bad'"},{"metadata":{"trusted":true},"cell_type":"code","source":"def gen_labels(df):\n    labels = ['bad', 'ok', 'good']\n    \n    if 1 <= df.loc['quality'] <= 5:\n        label = labels[0]\n    elif 5 < df.loc['quality'] < 7:\n        label = labels[1]\n    elif 7 <= df.loc['quality']<= 10:\n        label = labels[2]\n        \n    return label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['label'] = df.apply(gen_labels, axis = 1)\n\ndf['label'] = df['label'].astype('category')\n\ndf['label'].value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### Taking too long\n# df['label'].hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('label').mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looks like the data is not easily distinguishable, we can further come to this conclusion by some swarm plots"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x='label', y='pH', hue='quality', data=df, kind = 'swarm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x='label', y='fixed acidity', hue='quality', data=df, kind = 'swarm')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before staring to build a model and start making predictions, standardizing and splitting the data into training and test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"def scale_and_split(df, test_sizre=0.3):\n    \n    target = df[['label']]\n    features = df.drop(['label', 'quality'], axis = 1)\n    labels = list(target.label.unique())\n    \n    scaler = StandardScaler()\n    features = scaler.fit_transform(features)\n    \n    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size = 0.3, random_state = 42)\n    \n    return X_train, X_test, y_train, y_test, labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate_model(model, df):\n    \n    X_train, X_test, y_train, y_test, labels = scale_and_split(df)\n    \n    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n    print('Cross validation score - ', scores.mean()*100)\n    \n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n\n    accuracy = accuracy_score(y_test, y_pred) \n    print('Test accuracy - ',accuracy*100)\n    print('Confusion Matrix -\\n', confusion_matrix(y_test, y_pred, labels))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression()\ndt = DecisionTreeClassifier(criterion='gini', max_depth=12, random_state=42)\nrc = RandomForestClassifier(n_estimators=100, max_depth=12 ,random_state=42)\n\nprint('\\nEvaluation results - Logistic Regression')\nevaluate_model(lr, df)\n\nprint('\\nEvaluation results - Decision Tree Classifier')\nevaluate_model(dt, df)\n\nprint('\\nEvaluation results - Random Forest Classifier')\nevaluate_model(rc, df)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As the data is imbalanced, upmpling the minority class might help increasing the performance of the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils import resample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_majority = df[df['label']!='good']\ndf_minority = df[df['label']=='good']\n \ndf_minority_upsampled = resample(df_minority, replace=True, n_samples=700, random_state=42)\n\ndf_upsampled = pd.concat([df_majority, df_minority_upsampled])\n\ndf_upsampled['label'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression()\ndt = DecisionTreeClassifier(criterion='gini', max_depth=12, random_state=42)\nrc = RandomForestClassifier(n_estimators=250, max_depth=12 ,random_state=42)\n\nprint('\\nEvaluation results on upsampled data - Logistic Regression')\nevaluate_model(lr, df_upsampled)\n\nprint('\\nEvaluation results on upsampled data - Decision Tree Classifier')\nevaluate_model(dt, df_upsampled)\n\nprint('\\nEvaluation results on upsampled data - Random Forest Classifier')\nevaluate_model(rc, df_upsampled)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is a significant improvement in the accuracy of decision tree classifier and random tree classifier after upsampling the minority class."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}