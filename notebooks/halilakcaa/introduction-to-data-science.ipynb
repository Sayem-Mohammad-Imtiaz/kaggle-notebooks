{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**1)DATAYI IMPORT ETMEK**\n* Burada data adında bir değişken tanımlayıp pandas kütüphanesinin read_csv komutu ile datamızı import ediyoruz.\n* Bundan sonra bu veri seti ile bir işlem yapmak istediğimizde data değişkenini kullanarak csv dosyamıza erişeceğiz"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data=pd.read_csv('../input/world-happiness/2019.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**DATA HAKKINDA GENEL BİR BİLGİYE SAHİP OLMAK**\n* Datamız ile ilgili önizleme yapmak, genel bir bilgi edinmek için \n> data.info()  ->  komutu kullanılabilir.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**VERİNİN İLK ÖNİZLEMESİNİ YAPMAK**\n* Veri hakkında bilgi sahibi olmak için, (tercih olarak) veri setimizin ilk 10 değerini görmek istiyorum.\n> Bunun için data.head  -> komutunu kullanacağız.\n* Fakat data.head dediğimiz zaman bize ilk 5 değeri getirecektir. Biz ise ilk 10 değeri istiyoruz.\n> Bunun için data.head(10) -> komutunu kullanacağız.\n* İlk kaç değeri göstermek istiyor isek, bunun sayısını parantez içindeki bölüme girebiliriz.\n> Örnek olarak data.head(7) -> komutunu kullanabiliriz."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**VERİNİN SON DEĞERİNE BAKMAK**\n* Eğer elimizdeki datanın son değerine bakmak istiyor isek\n> data.tail()  ->  komutundan faydalanıyoruz.\n* data.tail() yazdığımız zaman bize dafeault olarak son 5 değeri getirecektir. Eğer biz örnek olarak 10 değer istiyor isek, parantez içine 10 yazmamız gerekecektir.\n> data.tail(10)  -> komutundan faydalanıyoruz."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.tail(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Correlation Map\nf,ax = plt.subplots(figsize=(14,14))\nsns.heatmap(data.corr(), annot =True , linewidth=.5, fmt='.2f',ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" **DATA KOLONLARINI (SÜTUNLARINI) GÖRMEK**  <br>\nData sütunlarını görmek için \n> data.columns  -> komutu kullanılır."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**2) MATPLOTLIB** <br>\nMatplot is a python library that help us to plot data. The easiest and basic plots are line, scatter and histogram plots.\n\n* Line plot is better when x axis is time.\n* Scatter is better when there is correlation between two variables\n* Histogram is better when we need to see distribution of numerical data.\n* Customization: Colors,labels,thickness of line, title, opacity, grid, figsize, ticks of axis and linestyle"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Line Plot\ndata.rename(columns={\"GDP per capita\":\"GDPPerCapita\",\"Healthy life expectancy\":\"HealthyLifeExpectancy\",\"Social support\":\"SocialSupport\"},inplace=True)\n\ndata.GDPPerCapita.plot(kind = 'line', color = 'blue',label = 'GDPPerCapita',linewidth=1,alpha = 0.5,grid = True,linestyle = ':')\ndata.SocialSupport.plot(color = 'purple',label = 'SocialSupport',linewidth=1, alpha = 0.8,grid = True,linestyle = '-.')\nplt.legend(loc='upper right')     # legend = puts label into plot\nplt.xlabel=('x axis')              # label = name of label\nplt.ylabel=('y axis')\nplt.title=('Line Plot')            # title = title of plot\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scatter Plot\ndata.plot(kind='scatter',x='GDPPerCapita', y='HealthyLifeExpectancy',alpha=0.5,color='blue',title='Scatter Plot')\nplt.xlabel=('GDP per capita')\nplt.ylabel=('Healthy life expectancy')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Histogram Plot\ndata.GDPPerCapita.plot(kind='hist', bins=45,figsize=(15,15),title='GDP per capita Histogram Plot')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**3) PANDAS**"},{"metadata":{},"cell_type":"markdown","source":"* Comparison operator : A comparison operator in python, also called python relational operator, compares the values of two operands, and returns True or False based on whether the condition is met.\n* Boolean Operator : A boolean expression (or logical expression) evaluates to one of two states true or false. Python provides the boolean type that can be either set to False or True. Many functions and operations returns boolean objects.\n* Series : A Series is a one-dimensional object that can hold any data type such as integers, floats and strings.\n* DataFrame : A DataFrame is a two dimensional object that can have columns with potential different types. Different kind of inputs include dictionaries, lists, series, and even another DataFrame.It is the most commonly used pandas object."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Comparison Operator\nprint (3<2)\nprint (3!=5)\nprint (3==3)\nprint (5>4)\nprint (3<=1)\nprint (9>=6)\n\n#Boolean Operator\nprint (True and False)\nprint (True and True)\nprint (True or False)\nprint (True or True)\nprint (False or False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filtering Pandas Data Frame\na = data['Score']>7.000     # There are only 16 Country or region who have higher Score value than 7.000\ndata[a]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Score']>7.000","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filtering pandas with logical_and\n# There are only 3 Country or region who have higher Score value than 7.000 and higher SocialSupport value than 1.580\ndata[np.logical_and(data['Score']>7.000, data['SocialSupport']>1.580)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This is also same with previous code line. Therefore we can also use '&' for filtering.\ndata[(data['Score']>7.000) & (data['SocialSupport']>1.580)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**4) WHILE and FOR LOOPS**  <br>\n> We will learn most basic while and for loops\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Stay in loop if condition( i is not equal 7) is true\ni = 0\nwhile i !=7:\n    print(\"i is : \",i)\n    i+=1\nprint(i,\" is equal to 7\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Stay in loop if condition( i is not equal 9) is true\nlis = [11,24,38,49,52,66,78,81,93]\nfor i in lis:\n    print(\"i is: \",i)\nprint(\"\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Enumerate index and value of list\n# index : value = 0:1, 1:2, 2:3, 3:4, 4:5, 5:6, 6:7, 7:8, 8:9\nfor index, value in enumerate(lis):\n    print(index,\" : \",value)\nprint(\"\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For dictionaries\n# We can use for loop to achive key and value of dictionary. We learnt key and value at dictionary part.\ndictionary = {'Turkey':'Ankara', 'Uganda':'Kampala','Somalia':'Mogadishu','Romania':'Bucharest'}\nfor key,value in dictionary.items():\n    print(key,\" : \",value)\nprint(\"\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For pandas we can achieve index and value\nfor index,values in data [['Country or region']][0:2].iterrows():\n    print(index,\" : \",values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**In this part, you learn:**\n\n* how to import csv file\n* plotting line,scatter and histogram\n* basic dictionary features\n* basic pandas features like filtering that is actually something always used and main for being data scientist\n* While and for loops"},{"metadata":{},"cell_type":"markdown","source":"**USER DEFINED FUNCTION**<br>\n> What we need to know about functions <br>\n* docstrings: documentation for functions. Example: <br>\n for f(): <br>\n \"\"\"This is docstring for documentation of function f\"\"\" <br>\n* tuble: sequence of immutable python objects.<br>\ncant modify values <br>\ntuble uses paranthesis like tuble = (1,2,3) <br>\nunpack tuble into several variables like a,b,c = tuble\n"},{"metadata":{},"cell_type":"markdown","source":"Lets make some basic example1"},{"metadata":{"trusted":true},"cell_type":"code","source":"# example of what we learn above\ndef tuple_example1():\n    x=(1,2,3,4)\n    return x\na,b,c,d=tuple_example1() #eleman sayısı kadar değere atama yapmak zorundayız.\nprint(a,b,c,d)\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets make some basic example2"},{"metadata":{"trusted":true},"cell_type":"code","source":"# example of what we learn above\ndef tuple_example2():\n    a=(54,98,82,46,73,37)\n    return a\na,b,c,d,e,f = tuple_example2()\nprint(a,b,c,d,e,f)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets make some basic example3"},{"metadata":{"trusted":true},"cell_type":"code","source":"# example of what we learn above\ndef tuple_example3():\n    notlar=(65,98,7,45,25,14)\n    return notlar\na,b,c,d,e,f = tuple_example3()\nprint(a,b) # Değerlerin hepsini yazdırmak zorunda değliz. Sadece istediğimiz değereri yazdırma şansımız var.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets make some basic example4"},{"metadata":{"trusted":true},"cell_type":"code","source":"# example of what we learn above\ndef tuple_example4():\n    sayilar =(11,12,13)\n    return sayilar\na,_,_= tuple_example4()  #eğer 3 sayıya da atama yapmak istemiyor isek diğerlerinin yerine alt cizgi koyabiliriz. Başka yerlerde görür iseniz şaşırmayın..\nprint(a)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**SCOPE**<br>\nWhat we need to know about scope:<br>\n* Global: defined main body in script\n* Local: defined in a function\n* built in scope: names in predefined built in scope module such as print, len\n"},{"metadata":{},"cell_type":"markdown","source":"Lets make some basic example"},{"metadata":{"trusted":true},"cell_type":"code","source":"# guess print what\ndegisken = 1\ndef fonksiyon():\n    degisken = 5\n    return degisken\nprint(degisken) # degisken = 1 global scope\nprint(fonksiyon()) # degisken = 5 local scope\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# What if there is no local scope\ndegisken = 6\ndef fonksiyon():\n    sonuc = degisken * 5  # there is no local scope degisken\n    return sonuc\nprint(fonksiyon())  # it uses global scope degisken\n# First local scopesearched, then global scope searched, if two of them cannot be found lastly built in scope searched.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Example2\nx = 5\ndef islem():\n    sonuclar = x + 9\n    return sonuclar\nprint(islem())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# How can we learn what is built in scope\nimport builtins\ndir(builtins)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**NESTED FUNCTION**<br>\n* function inside function.\n* There is a LEGB rule that is search local scope, enclosing function, global and built in scopes, respectively."},{"metadata":{"trusted":true},"cell_type":"code","source":"#nested function\ndef fonksiyon():\n    \"\"\" return square of value \"\"\"\n    def add():\n        \"\"\" add two local variable \"\"\"\n        a = 4\n        b = 5\n        sonuc= a + b\n        return sonuc\n    \n    return add()**2\n\nprint(fonksiyon())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**DEFAULT and FLEXIBLE ARGUMENTS**<br><br>\n* Default argument example:<br>\n   def f(a, b=1):<br><br>\n> \"\"\" b = 1 is default argument\"\"\"  <br><br>\n* Flexible argument example:<br><br>\n>   def f(*args):<br><br>\n>   \"\"\" *args can be one or more\"\"\" <br><br>\n>    def f(** kwargs)<br><br>\n\"\"\" **kwargs is a dictionary\"\"\""},{"metadata":{},"cell_type":"markdown","source":"> lets write some code to practice"},{"metadata":{"trusted":true},"cell_type":"code","source":"# default arguments\ndef elemanlar(x,y=5,z=3):\n    sonuc= x + y + z\n    return sonuc\nprint(elemanlar(9))\n# what if we want to change default arguments\nprint(elemanlar(4,5,6))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Flexible Arguments *args\ndef fonksiyon(*args):\n    for i in args:\n        print(i)\nfonksiyon(2)\n\nprint(\"----------------------\")\n\n# Flexible arguments *args example 2\ndef fonksiyon2(*args):\n    for i in args:\n        print (i)\nfonksiyon2(1,2,3,4,5,6)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Flexible arguments **kwargs that is dictionary \ndef fonksiyon(**kwargs):\n    \"\"\" print key and value of dictionary\"\"\"\n    for key,value in kwargs.items():   # If you do not understand this part turn for loop part and look at dictionary in for loop\n        print(key,\" : \",value)\nfonksiyon(country = 'Turkey',capital = 'Ankara')\nfonksiyon(country = 'England', capital = 'France')\n        \n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** LAMBDA FUNCTION ** <br><br>\n> Faster way of writing function"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lambda function\nhesapla = lambda x: x**2\nprint(hesapla(5))\n\nprint(\"---------------\")\n\nhesapla2 = lambda a,b,c : a + b + c\nprint(hesapla2(4,5,6))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**ANONYMOUS FUNCTİON**<br><br>\n> Like lambda function but it can take more than one arguments.<br>\n* map(func,seq) : applies a function to all the items in a list\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"numara_listesi = [15,20,25,30,35]\nfonksiyon = map(lambda x:x**2,numara_listesi)\nprint(list(fonksiyon))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**ITERATORS**\n* iterable is an object that can return an iterator\n* iterable: an object with an associated iter() method<br>\n> example: list, strings and dictionaries\n* iterator: produces next value with next() method"},{"metadata":{"trusted":true},"cell_type":"code","source":"# iteration example\nisim = \"HELLO\"\nhecele = iter(isim)\nprint(next(hecele))\nprint(\"-----\")\nprint(*hecele)\nprint(\"-----\")\n\n# iteration example2\nisim2 = \"THATS ALL :D\"\nhecele2 = iter(isim2)\nprint(*hecele2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**zip(): zip lists**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# zip example\nliste1 = [1,2,3,4,5,6]\nliste2 = [10,11,12,13,14,15]\nzipli_liste = zip(liste1,liste2)\nprint(zipli_liste)\nzipi_cevir = list(zipli_liste)\nprint(zipi_cevir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# unzip example\nzipi_kaldır = zip(*zipi_cevir)\nzipli_liste1,zipli_liste2 = list(zipi_kaldır)  # unzip returns tuble\nprint(zipli_liste1)\nprint(zipli_liste2)\nprint(type(zipli_liste1))\nprint(type(list(zipli_liste1)))\nprint(type(list(zipli_liste2)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**LIST COMPREHENSİON**<br>\n<strong>**One of the most important topic of this kernel**<br></strong>\n> We use list comprehension for data analysis often.<br>\n> list comprehension: collapse for loops for building lists into a single line<br>\n> Ex: num1 = [1,2,3] and we want to make it num2 = [2,3,4]. This can be done with for loop. However it is unnecessarily long.<br>\n> We can make it one line code that is list comprehension.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Example of list comprehension\nliste1 = [1,2,3,4]\nliste2 = [i+1 for i in liste1]\nprint (liste2)\nprint(\"-------------------------------\")\ndöngü_listesi = [2,3,4,5,6,7,8,9]\nislem_listesi = [i+5/2 for i in döngü_listesi]\nprint (islem_listesi)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Conditionals on iterable\nliste1 = [5,10,15,6,8,4,9]\nliste2 = [i**2 if i==10 else i-5 if i<7 else i+7 for i in liste1]\nprint(liste2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**3.CLEANING DATA**"},{"metadata":{},"cell_type":"markdown","source":"**DIAGNOSE DATA for CLEANING**<br>\n> We need to diagnose and clean data before exploring.<br>\nUnclean data:\n* Column name inconsistency like upper-lower case letter or space between words\n* missing data\n* different language<br><br>\n> We will use head, tail, columns, shape and info methods to diagnose data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/world-happiness/2019.csv')\ndata.head(10)  # head shows first 10 rows","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.tail(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# columns gives column names of features\ndata.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# shape gives number of rows and columns in a tuble\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# info gives data type like dataframe, number of sample or row, number of feature or column, feature types and memory usage\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**EXPLORATORY DATA ANALYSIS**"},{"metadata":{},"cell_type":"markdown","source":"> value_counts(): Frequency counts\n<br>outliers: the value that is considerably higher or lower from rest of the data\n* Lets say value at 75% is Q3 and value at 25% is Q1.\n* Outlier are smaller than Q1 - 1.5(Q3-Q1) and bigger than Q3 + 1.5(Q3-Q1). (Q3-Q1) = IQR\n* We will use describe() method. Describe method includes:\n* count: number of entries\n* mean: average of entries\n* std: standart deviation\n* min: minimum entry\n* 25%: first quantile\n* 50%: median or second quantile\n* 75%: third quantile\n* max: maximum entry"},{"metadata":{},"cell_type":"markdown","source":"> **What is quantile?**\n<br>\n\n* 1,4,5,6,8,9,11,12,13,14,15,16,17\n* The median is the number that is in middle of the sequence. In this case it would be 11.\n\n* The lower quartile is the median in between the smallest number and the median i.e. in between 1 and 11, which is 6.\n\n* The upper quartile, you find the median between the median and the largest number i.e. between 11 and 17, which will be 14 according to the question above."},{"metadata":{"trusted":true},"cell_type":"code","source":"# For example lets look frequency of happy types\nprint(data[\"Country or region\"].value_counts(dropna=False))  #example 1\nprint(data[\"GDP per capita\"].value_counts(dropna = False))  # example 2\nprint(data[\"Healthy life expectancy\"].value_counts(dropna = False)) # example 3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For example max HP is 255 or min defense is 5\ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Score.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"GDP per capita\"].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**VISUAL EXPLORATORY DATA ANALYSIS**\n<br>\n* Box plots: visualize basic statistics like outliers, min/max or quantiles"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For example: compare attack of pokemons that are legendary  or not\n# Black line at top is max\n# Blue line at top is 75%\n# Red line is median (50%)\n# Blue line at bottom is 25%\n# Black line at bottom is min\n# There are no outliers\ndata.boxplot(column='Healthy life expectancy',by='Social support')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**TIDY DATA**\n<br>\n> We tidy data with melt(). Describing melt is confusing. Therefore lets make example to understand it."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Firstly I create new data from pokemons data to explain melt nore easily.\nnew_data = data.head(6)\nnew_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets melt\n# id_vars = what we do not wish to melt\n# value_vars = what we want to melt\nmelted= pd.melt(frame=new_data,id_vars='Country or region',value_vars=['Score','Healthy life expectancy'])\nmelted\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**PIVOTING DATA**\n> <br>Reverse of melting."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Index is name\n# I want to make that columns are variable\n# Finally values in columns are value\nmelted.pivot(index='Country or region',columns='variable',values='value')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**CONCATENATING DATA**\n> <br> We can concatenate two dataframe "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Firstly lets create 2 data frame\ndata1 = data.head(3)\ndata2 = data.tail(3)\nconc_data_row = pd.concat([data1,data2],axis=0,ignore_index=True) # # axis = 0 : adds dataframes in row\nconc_data_row\n\n# data_birlestir = pd.concat([data1,data2],axis=1,ignore_index=True)\n# data_birlestir\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1=data['Score'].head()\ndata2=data['Healthy life expectancy'].head()\ndata_concat=pd.concat([data1,data2],axis=0)\ndata_concat\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**DATA TYPES**\n<br>\n> There are 5 basic data types: object(string),booleab, integer, float and categorical.\nWe can make conversion data types like from str to categorical or from int to float\nWhy is category important:<br>\n* make dataframe smaller in memory\n* can be utilized for anlaysis especially for sklear(we will learn later)"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets convert object(str) to categorical and int to float.\ndata['Country or region'] = data['Country or region'].astype('category')\ndata['GDP per capita'] = data['GDP per capita'].astype('object')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# As you can see Country or region is converted from object to categorical\n# And GDP per capita ,s converted from int to object\ndata.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**MISSING DATA and TESTING WITH ASSERT**\n<br>\n> If we encounter with missing data, what we can do:\n* leave as is\n* drop them with dropna()\n* fill missing value with fillna()\n* fill missing values with test statistics like mean\n<br>\nAssert statement: check that you can turn on or turn off when you are done with your testing of the program"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets chech Type 2\ndata['Country or region'].value_counts(dropna=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Generosity'].value_counts(dropna=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Perceptions of corruption'].value_counts(dropna=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Social support'].value_counts(dropna=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Lets check with assert statement\n# Assert statement:\nassert 1==1 # return nothing because it is true","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# assert 25==100  ----> false\nassert 25==25   # -----> True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert data['Social support'].notnull().all()   # returns nothing because we drop nan values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert data ['Perceptions of corruption'].notnull().all()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Perceptions of corruption'].fillna('empty',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert data ['Perceptions of corruption'].notnull().all()  # returns nothing because we do not have nan values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# assert data.columns[1]=='Country or region'\n# assert data.columns[0]=='Overall rank'\n# assert data.columns[2]=='Score'\n# assert data.columns[3]=='GDP per capita'\n# assert data.columns[4]=='Social support'\n# assert data.columns[5]=='Healthy life expectancy'\n# assert data.columns[6]=='Freedom to make life choices'\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> In this part, you learn:\n* Diagnose data for cleaning\n* Exploratory data analysis\n* Visual exploratory data analysis\n* Tidy data\n* Pivoting data\n* Concatenating data\n* Data types\n* Missing data and testing with assert\n\n"},{"metadata":{},"cell_type":"markdown","source":"**4. PANDAS FOUNDATION**\n<br>"},{"metadata":{},"cell_type":"markdown","source":"**REVİEW of PANDAS**<br>\n> As you notice, I do not give all idea in a same time. Although, we learn some basics of pandas, we will go deeper in pandas\n* single column = series\n* NaN = not a number\n* dataframe.values = numpy<br>"},{"metadata":{},"cell_type":"markdown","source":"> **BUILDING DATA FRAMES FROM SCRATCH**<br>\n* We can build data frames from csv as we did earlier.\n* Also we can build dataframe from dictionaries \n  * zip() method: This function returns a list of tuples, where the i-th tuple contains the i-th element from each of the argument sequences or iterables.\n* Adding new column\n* Broadcasting: Create new column and assign a value to entire column"},{"metadata":{"trusted":true},"cell_type":"code","source":"# data frames from dictionary\ncountry = [\"İspanya\",\"Fransa\",\"Türkiye\",\"Somali\",\"Afrika\"]\npopulation = [\"11\",\"12\",\"10\",\"15\",\"11\"]\nlist_label = [\"country\",\"population\"]\nlist_column = [country,population]\nzipped = list(zip(list_label,list_column))\ndata_dict = dict(zipped)\ndf = pd.DataFrame(data_dict)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add new columns\ndf[\"capital\"]=[\"madrid\",\"paris\",\"ankara\",\"mogadişu\",\"cape Town\"]\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Broadcasting\ndf[\"income\"]=0         #Broadcasting entire column\ndf\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **VISUAL EXPLORATORY DATA ANALYSIS**<br>\n* Plot\n* Subplot\n* Histogram:\n  * bins: number of bins\n  * range(tuble): min and max values of bins\n  * normed(boolean): normalize or not\n  * cumulative(boolean): compute cumulative distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting all data \ndata1 = data.loc[:,[\"Score\",\"Social support\",\"Freedom to make life choices\"]]\ndata1.plot()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# subplots\ndata1.plot(subplots = True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# scatter plot\ndata1.plot(kind=\"scatter\",x = \"Social support\",y=\"Freedom to make life choices\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# hist plot\ndata1.plot(kind=\"hist\",y=\"Social support\",bins=15,range=(0,1),normed=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# histogram subplot with non cumulative and cumulative\nfig,axes=plt.subplots(nrows=2,ncols=1)\ndata1.plot(kind=\"hist\" , y=\"Social support\" , bins=20 , range=(0,1) , normed=True , ax=axes [0])\ndata1.plot(kind=\"hist\" , y=\"Social support\" , bins=20 , range=(0,1) , normed=True , ax=axes[1], cumulative=True)\nplt.savefig('graph.png')\nplt\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**STATISTICAL EXPLORATORY DATA ANALYSIS**\n> I already explained it at previous parts. However lets look at one more time.\n   * count: number of entries\n   * mean: average of entries\n   * std: standart deviation\n   * min: minimum entry\n   * 25%: first quantile\n   * 50%: median or second quantile\n   * 75%: third quantile\n   * max: maximum entry"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**INDEXING PANDAS TIME SERIES**<br>\n* > datetime = object\n* >  parse_dates(boolean): Transform date to ISO 8601 (yyyy-mm-dd hh:mm:ss ) format"},{"metadata":{"trusted":true},"cell_type":"code","source":"time_list=[\"2020-01-02\",\"2020-01-03\",\"2020-01-04\"]\nprint(type(time_list[1]))       # As you can see date is string\n# however we want it to be datetime object\ndate_time_object=pd.to_datetime(time_list)\nprint(type(date_time_object))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# In order to practice lets take head of happy data and add it a time list\ndata2=data.head()\ndate_list=[\"2020-01-01\",\"2020-01-02\",\"2020-01-03\",\"2020-01-04\",\"2020-01-05\"]\ndate_object=pd.to_datetime(date_list)\ndata2[\"date\"] = date_object\n# lets make date as index\ndata2=data2.set_index(\"date\")\ndata2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now we can select according to our date index\nprint(data2.loc[\"2020-01-05\"])\nprint(data2.loc[\"2020-01-01\":\"2020-01-05\"])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **RESAMPLING PANDAS TIME SERIES**<br>\n* Resampling: statistical method over different time intervals\n    * Needs string to specify frequency like \"M\" = month or \"A\" = year\n* Downsampling: reduce date time rows to slower frequency like from daily to weekly\n* Upsampling: increase date time rows to faster frequency like from daily to hourly\n* Interpolate: Interpolate values according to different methods like ‘linear’, ‘time’ or index’\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will use data2 that we create at previous part\ndata2.resample(\"A\").mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets resample with month\ndata2.resample(\"M\").mean()\n# As you can see there are a lot of nan because data2 does not include all months","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Or we can interpolate with mean()\ndata2.resample(\"M\").mean().interpolate(\"linear\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **MANIPULATING DATA FRAMES WITH PANDAS**<br>\n> * Indexing using square brackets\n* Using column attribute and row label\n* Using loc accessor\n* Selecting only some columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"data=pd.read_csv('../input/world-happiness/2019.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.index.names=['#']\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# indexing using square brackets\nprint(data[\"Country or region\"][1])\nprint(data[\"Country or region\"][23])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using column attribute and row label\ndata.Score[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using loc accessor\ndata.loc[1,[\"Score\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Selecting only some columns\ndata[[\"Score\",\"GDP per capita\"]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **SLICING DATA FRAME**<br>\n* Difference between selecting columns\n   * Series and data frames\n* Slicing and indexing series\n* Reverse slicing\n* From something to end   "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}