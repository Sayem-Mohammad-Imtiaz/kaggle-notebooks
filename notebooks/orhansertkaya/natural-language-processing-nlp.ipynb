{"cells":[{"metadata":{"_uuid":"7346e67499d9a00dd998f07f827fefbbaa0a790f"},"cell_type":"markdown","source":"# INTRODUCTION<br><br>\n**In this kernel, we will see Natural Language Processing(NLP).**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"### Import Data "},{"metadata":{"trusted":true,"_uuid":"55c9c1c04fdff1b3caa43360cf6c4107d9d0beb4"},"cell_type":"code","source":"# import twitter data\ndata = pd.read_csv(\"../input/gender-classifier-DFE-791531.csv\",encoding=\"latin1\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5568b807326ba6e77a145df77f2b5d3db3220c71"},"cell_type":"code","source":"data = pd.concat([data.gender,data.description],axis=1)\n\n#let's drop NaN values\ndata.dropna(axis=0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4e16dfc57c63f82d2cc144214eecdf1513981e20"},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3deff8f51f6d47d8b3d94af084d0380548460916"},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eee1cd412e68655cf49aea32884812249a9753bf"},"cell_type":"code","source":"data.gender = [1 if each == \"female\" else 0 for each in data.gender]\ndata.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9976f3ec86ac2c0044fec29ba60040c09edd7891"},"cell_type":"code","source":"data.description[4]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4a6706de5d839df851df94d365a91b07af9ad035"},"cell_type":"markdown","source":"### Regular Expression"},{"metadata":{"trusted":true,"_uuid":"dc1ce1b0524b4dc502a78373915e31add3aca563"},"cell_type":"code","source":"# regular expression RE =>> \"[^a-zA-Z]\"\nimport re\n\nfirst_description = data.description[4]\ndescription = re.sub(\"[^a-zA-Z]\",\" \",first_description)\ndescription = description.lower() #Year year are different words\ndescription","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"728a1a984c18d51f3fb3a82c35c879c1331391a5"},"cell_type":"markdown","source":"### Stopwords"},{"metadata":{"trusted":true,"_uuid":"df2ff835d44c1b28f2f526a7be90cbe189a0c8f3"},"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\n#remove irrelavent words for e.g. and,the ...\n\n#description = description.split()\ndescription = nltk.word_tokenize(description)\n#if we use word_tokenize instead of split it will be better\n#split() = shouldn't => shouldn't\n#word_tokenize() = shouldn't => shouldn't and n't separate as two word\ndescription = [word for word in description if not word in set(stopwords.words(\"english\"))]\ndescription","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"baf7ac67dd99d4862d05b6cb2843cb8581851529"},"cell_type":"markdown","source":"### Lemmatazation"},{"metadata":{"trusted":true,"_uuid":"d5327f3b78cf09fee2fa7be234853c119bcd6f47"},"cell_type":"code","source":"#Lemmatazation = loved => love\nimport nltk as nlp\n\nlemma = nlp.WordNetLemmatizer()\ndescription = [lemma.lemmatize(word) for word in description]\ndescription","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"65a2a1f65e76a45ee08d25679ddcb4a27966d537"},"cell_type":"code","source":"description = \" \".join(description)\ndescription","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dfc912fb19c632215d35352e53502ca2287a9149"},"cell_type":"markdown","source":"### Apply to All Description"},{"metadata":{"trusted":true,"_uuid":"a28c91ac696d580d821bc4aee40d860ba43f69e4"},"cell_type":"code","source":"description_list = []\nfor description in data.description:\n    description = re.sub(\"[^a-zA-Z]\",\" \",description)\n    description = description.lower()\n    description = nltk.word_tokenize(description)\n    #description = [ word for word in description if not word in set(stopwords.words(\"english\"))]\n    lemma = nlp.WordNetLemmatizer()\n    description = [lemma.lemmatize(word) for word in description]\n    description = \" \".join(description)\n    description_list.append(description)\n    \n#description_list","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a69d229dc6ae19d4bc78a6a87e0afea1a029483d"},"cell_type":"markdown","source":"### Bag of Words"},{"metadata":{"trusted":true,"_uuid":"a311d5f174ab11f38cf82623913f811f2c8a6d57"},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\n#we can define max_features \nmax_features = 1000\ncount_vectorizer = CountVectorizer(max_features=max_features,stop_words = \"english\")\n#count_vectorizer = CountVectorizer(stop_words = \"english\")\n\nsparce_matrix = count_vectorizer.fit_transform(description_list).toarray() # x\n\nprint(\"{} most common words: {}\".format(max_features,count_vectorizer.get_feature_names()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6d9484f080c638da7eff571b380195df8b2eef4f"},"cell_type":"markdown","source":"### Train and Test Split"},{"metadata":{"trusted":true,"_uuid":"736a349b318334b1d4f57045d883a3e4234a0b9e"},"cell_type":"code","source":"y = data.iloc[:,0].values   # male or female classes\nx = sparce_matrix\n# train test split\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.1, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"782d1f2b0e2cc5666b53646e67a5caf82e0b2496"},"cell_type":"markdown","source":"### Apply Naive Bayes Machine Learning Algorithm"},{"metadata":{"trusted":true,"_uuid":"ff47650b02e92473b676c2ca812f6561a629cbbb"},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\n\nnb = GaussianNB()\n\nnb.fit(x_train,y_train)\n\nprint(\"accuracy: \",nb.score(x_test,y_test))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7ee183271e64d6d1bb6c5e57ac85081ca777c8a3"},"cell_type":"code","source":"y_pred = nb.predict(x_test)\ny_true = y_test\n\nfrom sklearn.metrics import confusion_matrix\n\ncm_nb = confusion_matrix(y_true,y_pred)\n\nsns.heatmap(cm_nb,annot=True,cmap=\"RdPu\",fmt=\".0f\",cbar=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e93373995e666949e6ed874f9ade07323ca1bad9"},"cell_type":"markdown","source":"### Apply Random Forest Machine Learning Algorithm"},{"metadata":{"trusted":true,"_uuid":"8acc313de9b26f7b2e421dc25285069010121fa8"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(n_estimators = 100)\n\nrf.fit(x_train,y_train)\n\nprint(\"accuracy: \",rf.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fa005475ccbb24e2884a6ba8f9521d73d904be62"},"cell_type":"code","source":"y_pred = rf.predict(x_test)\ny_true = y_test\n\nfrom sklearn.metrics import confusion_matrix\n\ncm_rf = confusion_matrix(y_true,y_pred)\n\nsns.heatmap(cm_rf,annot=True,cmap=\"RdPu\",fmt=\".0f\",cbar=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5471a62f58e6bcba0cad51e758c59be7fb24a40e"},"cell_type":"markdown","source":"# Conclusion<br><br>\n**If you like it, Please upvote my kernel.**<br>\n**If you have any question, I will happy to hear it.**"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}