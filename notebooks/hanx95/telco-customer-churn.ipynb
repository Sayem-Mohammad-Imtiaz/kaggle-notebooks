{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing"},{"metadata":{"trusted":false},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df = pd.read_csv(\"../input/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Convert Totalcharges to numerical\ndf.TotalCharges = pd.to_numeric(df.TotalCharges, errors = 'coerce')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Check NULL value\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Replace NULL value as 0\ndf = df.fillna(value=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Remove CustomerID\ndf.drop(['customerID'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Convert all the Yes/No data to binary\ncolumns_yes_no = ['Churn','Partner','Dependents','PhoneService','PaperlessBilling','OnlineSecurity','OnlineBackup','DeviceProtection','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']\nfor item in columns_yes_no:\n    df[item].replace(to_replace = 'Yes',value=1,inplace=True)\n    df[item].replace(to_replace = 'No',value=0,inplace=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Convert all the categorical data to binary\ndf = pd.get_dummies(df)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.corr()['Churn'].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.drop(['gender_Female','gender_Male','PhoneService','MultipleLines_No phone service'],axis=1,inplace=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Training"},{"metadata":{"trusted":false},"cell_type":"code","source":"y = df['Churn'].values\ndropped = df.drop(columns=['Churn'])\nX = dropped","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Scale the data\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX = scaler.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn import model_selection\nX_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.3, random_state=24)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlog_reg = LogisticRegression(solver='liblinear')\nlog_reg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"log_reg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"log_reg.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn import neighbors\nknn = neighbors.KNeighborsClassifier(n_neighbors=10)\nknn.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"knn.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"knn.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrandomforest= RandomForestClassifier()\nrandomforest.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"randomforest.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"randomforest.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Evaluation"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Calculate Accuarcy Scores\ndef cal_evaluation(classifier, cm):\n    tn = cm[0][0]\n    fp = cm[0][1]\n    fn = cm[1][0]\n    tp = cm[1][1]\n    accuracy  = (tp + tn) / (tp + fp + fn + tn)\n    precision = tp / (tp + fp)\n    recall = tp / (tp + fn)\n    print (classifier)\n    print (\"Accuracy is: %0.4f\" % accuracy)\n    print (\"precision is: %0.4f\" % precision)\n    print (\"recall is: %0.4f\" % recall)\n\n# Print Confusion Matrices\ndef draw_confusion_matrices(confusion_matricies):\n    class_names = ['Stay','Churn']\n    for cm in confusion_matrices:\n        classifier, cm = cm[0], cm[1]\n        cal_evaluation(classifier, cm)\n        fig = plt.figure()\n        ax = fig.add_subplot(111)\n        cax = ax.matshow(cm, cmap=plt.get_cmap('Blues'))\n        plt.title('Confusion matrix of %s' % classifier)\n        fig.colorbar(cax)\n        ax.set_xticklabels([''] + class_names)\n        ax.set_yticklabels([''] + class_names)\n        plt.xlabel('Predicted')\n        plt.ylabel('Actually')\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"confusion_matrices = [\n    (\"Logistic Regression\", confusion_matrix(y_test,log_reg.predict(X_test))),\n    (\"K Nearest Neighbors\", confusion_matrix(y_test,knn.predict(X_test))),\n    (\"Random Forest\", confusion_matrix(y_test,randomforest.predict(X_test))),\n    ]\n\ndraw_confusion_matrices(confusion_matrices)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn import metrics\nfrom sklearn.metrics import roc_curve\nprobs = log_reg.predict_proba(X_test)\npreds = probs[:, 1]\nfpr_lr, tpr_lr, _ = roc_curve(y_test, preds)\nplt.figure(1)\nplt.plot([0, 1], [0, 1])\nplt.plot(fpr_lr, tpr_lr)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC curve - Logistic Regression')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"metrics.auc(fpr_lr,tpr_lr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"probs = knn.predict_proba(X_test)\npreds = probs[:, 1]\nfpr_lr, tpr_lr, _ = roc_curve(y_test, preds)\nplt.figure(1)\nplt.plot([0, 1], [0, 1])\nplt.plot(fpr_lr, tpr_lr)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC curve - K Nearest Neighbors')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"metrics.auc(fpr_lr,tpr_lr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"probs = randomforest.predict_proba(X_test)\npreds = probs[:, 1]\nfpr_lr, tpr_lr, _ = roc_curve(y_test, preds)\nplt.figure(1)\nplt.plot([0, 1], [0, 1])\nplt.plot(fpr_lr, tpr_lr)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC curve - Random Forest')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"metrics.auc(fpr_lr,tpr_lr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Based on the Confusion Matrix and AUC Value, we can conclude that Logistic Regression is the best model in this case."},{"metadata":{},"cell_type":"markdown","source":"# Feature Importance"},{"metadata":{"trusted":false},"cell_type":"code","source":"log_reg.coef_[0]\nprint (\"Top 10 important attributes in our Logistic Regression Model\")\nfor k,v in sorted(zip(map(lambda x: round(x, 3), log_reg.coef_[0]), \\\n                      dropped.columns), key=lambda k_v:(-abs(k_v[0]),k_v[1]))[0:10]:\n    print (v + \": \" + str(k))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}