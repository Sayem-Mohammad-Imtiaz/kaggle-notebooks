{"cells":[{"metadata":{"_uuid":"3f05ad94168c38d64755a68aca652eae626670b3"},"cell_type":"markdown","source":"# Background\n- I want to analyze the text with SpaCy.\n- The documentation of SpaCy is very helpful! You can check it! https://spacy.io/\\\n- I referred to this kernel, https://www.kaggle.com/enerrio/scary-nlp-with-spacy-and-keras. Thanks to [Aaron Marques](https://www.kaggle.com/enerrio)"},{"metadata":{"_uuid":"2eef01fa1c311135c9776b8a7c8b399ffd4b234f"},"cell_type":"markdown","source":"# Read dataset"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n#import os\n#print(os.listdir(\"../input\"))\nimport spacy\nimport random \nfrom collections import Counter #for counting\nimport seaborn as sns #for visualization\nimport matplotlib.pyplot as plt\n\nplt.style.use('seaborn')\nsns.set(font_scale=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fbb2e8b2e3b069ed49410231d4e68b3b71005a2c"},"cell_type":"code","source":"articles = pd.read_csv('../input/articles.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ce9ba2c4a476f18e91f609354357ed6609c832f6"},"cell_type":"markdown","source":"# Read text using spacy and extract tokens"},{"metadata":{"trusted":true,"_uuid":"f30c8eac6625531062dbb58e03ef583123e33067"},"cell_type":"code","source":"nlp = spacy.load('en')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5ad180171cf55f2d5de8b764099e44f310cadb72"},"cell_type":"markdown","source":"- The article is a bit long. Let's use some part of the article."},{"metadata":{"trusted":true,"_uuid":"d816f374572d8735ee52f71fd884907f06fefc9a"},"cell_type":"code","source":"doc = nlp(articles['text'][0][:500]) ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6bb350092b1d52f77b61cd4024868fd4b9cdd6eb"},"cell_type":"markdown","source":"## Store the informations of tokens"},{"metadata":{"trusted":true,"_uuid":"e2e5020001aa244d782a7afdd2fe0c7785bb05ad"},"cell_type":"code","source":"df_token = pd.DataFrame()\n\nfor i, token in enumerate(doc):\n    df_token.loc[i, 'text'] = token.text\n    df_token.loc[i, 'lemma'] = token.lemma_,\n    df_token.loc[i, 'pos'] = token.pos_\n    df_token.loc[i, 'tag'] = token.tag_\n    df_token.loc[i, 'dep'] = token.dep_\n    df_token.loc[i, 'shape'] = token.shape_\n    df_token.loc[i, 'is_alpha'] = token.is_alpha\n    df_token.loc[i, 'is_stop'] = token.is_stop","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cb26852a9b726d05a27d6bd686f9d80e30518303"},"cell_type":"code","source":"df_token","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d53c98f490f7cc8fcd0a3abf1fac616bbe6aa6d3"},"cell_type":"markdown","source":"- As you can see, the tokens and relevant information are extraced very easily."},{"metadata":{"_uuid":"fbb2d8a13b35f487d13b9a7300f43e632955eba1"},"cell_type":"markdown","source":"# Visualize the structure of sentence"},{"metadata":{"_uuid":"9e7de036d03f4816a4e57def276cb156041a7e98"},"cell_type":"markdown","source":"- Using displacy with keyword \"dep\",  we can visulize the structure of sentences easily."},{"metadata":{"trusted":true,"_uuid":"d7c9f0fcfcbc62c0bbe095574ddbc39ed5e750b8"},"cell_type":"code","source":"from spacy import displacy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"9f68a44acdecf4435e01fe06dc87103e91676f76"},"cell_type":"code","source":"sentence_spans = list(doc.sents)\ndisplacy.render(sentence_spans, style='dep', jupyter=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2c12d6b611c5399c451b2964bd542b78e0b4ad59"},"cell_type":"markdown","source":"- As you can see, sentences are well-divided."},{"metadata":{"_uuid":"da86abe84b1e703cc1bd66b98dcd0ff37eafdb8c"},"cell_type":"markdown","source":"# Find entity"},{"metadata":{"_uuid":"cce779df18b52a7f9991b0716ff5590971ee9e14"},"cell_type":"markdown","source":"- Spacy have built-in entity-types\n\n\n| Type | Description | \n|:--------|:--------|\n| PERSON | People, including fictional. | \n| NORP | Nationalities or religious or political groups. | \n| FAC | Buildings, airports, highways, bridges, etc. | \n| ORG | Companies, agencies, institutions, etc. | \n| GPE | Countries, cities, states. | \n| LOC | Non-GPE locations, mountain ranges, bodies of water. | \n| PRODUCT | Objects, vehicles, foods, etc. (Not services.) | \n| EVENT | Named hurricanes, battles, wars, sports events, etc. | \n| WORK_OF_ART | Titles of books, songs, etc. | \n| LAW | Named documents made into laws. | \n| LANGUAGE | Any named language. | \n| DATE | Absolute or relative dates or periods. | \n| TIME | Times smaller than a day. | \n| PERCENT | Percentage, including \"%\". | \n| MONEY | Monetary values, including unit. | \n| QUANTITY | Measurements, as of weight or distance. | \n| ORDINAL | \"first\", \"second\", etc. | \n| CARDINAL | Numerals that do not fall under another type | "},{"metadata":{"_uuid":"fa0230ed1692d3a10bd215690b4bd448eef461e3"},"cell_type":"markdown","source":"- You can see the tables, in this URL. https://spacy.io/usage/linguistic-features#section-named-entities\n- Ok, let's find the entities using SpaCy and visualize."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"spacy.displacy.render(doc, style='ent',jupyter=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3651d8ad4272a967801d35b861cb3ea422e63216"},"cell_type":"markdown","source":"# Authors "},{"metadata":{"trusted":true,"_uuid":"39fc41a219764128bfc677ecc4454b3c186f920d","scrolled":true},"cell_type":"code","source":"articles['author'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fb8b96b8ea0ee3f898d85c6fe10c93a73db951a4"},"cell_type":"markdown","source":"- As you can see, there are many authors. \n- Let's analyze the top 5 authors."},{"metadata":{"trusted":true,"_uuid":"c3252ea9899700dff8af1abcda21f169fd2edb34"},"cell_type":"code","source":"from nltk.corpus import stopwords\nimport string\nstopwords = stopwords.words('english')\npunctuations = string.punctuation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6165c9c0903efca7efa640cdf90c385a54609f2a"},"cell_type":"code","source":"# Define function to cleanup text by removing personal pronouns, stopwords, and puncuation\ndef cleanup_text(docs):\n    texts = []\n    counter = 1\n    for doc in docs:\n        if counter % 100 == 0:\n            print('Processed {} out of {}'.format(counter, len(docs)))\n        counter += 1\n        doc = nlp(doc, disable=['parser', 'ner'])\n        tokens = [tok.lemma_.lower().strip() for tok in doc if tok.lemma_ != '-PRON-']\n        tokens = [tok for tok in tokens if tok not in stopwords and tok not in punctuations]\n        tokens = ' '.join(tokens)\n        texts.append(tokens)\n    return pd.Series(texts)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"11bab5b050e664a3c0812ccc409695fa685476ab"},"cell_type":"markdown","source":"## Adam Geitgey"},{"metadata":{"trusted":true,"_uuid":"26ab600c4e15cdde36cb010ecaa9eb07bacd6493"},"cell_type":"code","source":"def make_barplot_for_author(Author):\n    author_text = [text for text in articles.loc[articles['author'] == Author]['text']]\n\n    author_clean = cleanup_text(author_text)\n    author_clean = ' '.join(author_clean).split()\n    author_clean = [word for word in author_clean if word not in '\\'s']\n    author_counts = Counter(author_clean)\n\n    NUM_WORDS = 25\n    author_common_words = [word[0] for word in author_counts.most_common(NUM_WORDS)]\n    author_common_counts = [word[1] for word in author_counts.most_common(NUM_WORDS)]\n\n    plt.figure(figsize=(15, 12))\n    sns.barplot(x=author_common_counts, y=author_common_words)\n    plt.title('Words that {} use frequently'.format(Author), fontsize=20)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3e914da2e6618e9b29336412118d9b3006eace6b"},"cell_type":"code","source":"Author = 'Adam Geitgey'\nmake_barplot_for_author(Author)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1c157ff5c57156a96dc185bdb90a65ab6718addc"},"cell_type":"markdown","source":"- Most frequent words are image and network. \n- Have he frequently written the articles about image for neural network?"},{"metadata":{"trusted":true,"_uuid":"129989d3f9b5f82dac59e752284ed90eca9c94e3"},"cell_type":"code","source":"for title in articles.loc[articles['author'] == 'Adam Geitgey']['title']:\n    print(title)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4530524a32371bc0b5eaa45b6138f271834fea33"},"cell_type":"markdown","source":"- Yes, as you can see, he has written many articles of the face recognition and image recognition using deep learning."},{"metadata":{"_uuid":"af89f4119e19ae407f47b64e893aa7f73421617c"},"cell_type":"markdown","source":"## Slav Ivanov"},{"metadata":{"trusted":true,"_uuid":"9b5e453ba2ff4aa53a85ceded703b1078b1b779d"},"cell_type":"code","source":"Author = 'Slav Ivanov'\nmake_barplot_for_author(Author)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"efaec54f14145a10675055706ccc089f5f690ad4"},"cell_type":"markdown","source":"- Most frequent words are gpu, use and cpu. \n- Because the 'network' is shown, we can think he wrote some articles about deep learing with GPU."},{"metadata":{"trusted":true,"_uuid":"28a97f0f4983035ca37cdba70383d93c05c57c6c"},"cell_type":"code","source":"for title in articles.loc[articles['author'] == 'Slav Ivanov']['title']:\n    print(title)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a6760bf93ce4cb5363b6e5712260ee45fa59ad16"},"cell_type":"markdown","source":"- Good! "},{"metadata":{"_uuid":"6dbb419570eaaeba9cdaa6ae9307bffab34e3c8d"},"cell_type":"markdown","source":"## Arthur Juliani"},{"metadata":{"trusted":true,"_uuid":"3fb72d8de9c2ab84ac49a1370957037abac19a00"},"cell_type":"code","source":"Author = 'Arthur Juliani'\nmake_barplot_for_author(Author)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d216773fca3c5e72b437ee7f002494fd72bd7cc4"},"cell_type":"markdown","source":"- Most frequent words are 'q', 'network' and 'action'. \n- There are some words which are relevant with Reinforcement learning.\n- Let's see the titles."},{"metadata":{"trusted":true,"_uuid":"19aed7d8a50c3c4f5adb300b4d8f27c22a44b23e"},"cell_type":"code","source":"for title in articles.loc[articles['author'] == 'Arthur Juliani']['title']:\n    print(title)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2e40cea0055506a5826fbcc285298587270dfd76"},"cell_type":"markdown","source":"- SpaCy works well!"},{"metadata":{"_uuid":"28f58e942fd730048c62cf966c950f79f5697da7"},"cell_type":"markdown","source":"## Milo Spencer-Harper"},{"metadata":{"trusted":true,"_uuid":"8ef2e12fc615a95cc7ed7fc4ca66d6f798d1f9e1"},"cell_type":"code","source":"Author = 'Milo Spencer-Harper'\nmake_barplot_for_author(Author)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b743e3a4e91b4a917e5265ddbb7f22dcb4a5f0a0"},"cell_type":"markdown","source":"- Top 3 words are neuron, neural and network. Is he author about deep learning?\n- Let's see the titles!"},{"metadata":{"trusted":true,"_uuid":"4dddca915ebd4e849e65d4013e197c234910e6fd"},"cell_type":"code","source":"for title in articles.loc[articles['author'] == 'Milo Spencer-Harper']['title']:\n    print(title)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"74616c88ab7056f66a827539419a9258f46a967a"},"cell_type":"markdown","source":"- Most of his articles deals the neural networks.\n- Using SpaCy, we can infer the main subject of articles."},{"metadata":{"_uuid":"f59d8e4f903a013839a1a7915c85f20aefcbff35"},"cell_type":"markdown","source":"## Dhruv Parthasarathy"},{"metadata":{"trusted":true,"_uuid":"ea1d112b981c4ff219bb4da85a5a9260a657320b"},"cell_type":"code","source":"Author = 'Dhruv Parthasarathy'\nmake_barplot_for_author(Author)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c474d3aff08aca5ee7499e06b40f51796a62f0e3"},"cell_type":"markdown","source":"# Spectial guest!"},{"metadata":{"_uuid":"4bd28d6723e137041de2db2e95f33a7e494a4241"},"cell_type":"markdown","source":"- Do you know the 'William Koehrsen'? I know 'William Koehrsen' because of his amazing kernels!\n- He is a kernel master, 8th ranker for now!\n- Let's find the words he likes."},{"metadata":{"trusted":true,"_uuid":"35ba9a2ae91ae9cb2637f8fade19a680e66f77a1"},"cell_type":"code","source":"Author = 'William Koehrsen'\nmake_barplot_for_author(Author)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"740c19e1915086ce507e91d8250ea2570ed80d65"},"cell_type":"markdown","source":"- Oh, feature is the most frequent used word!"},{"metadata":{"_uuid":"26b5e4a1350cea038353ef840c4f11acfc705946"},"cell_type":"markdown","source":"- As you know that, many his kernel deals the much stuff of features. Below are his kernels.\n- https://www.kaggle.com/willkoehrsen/introduction-to-manual-feature-engineering\n- https://www.kaggle.com/willkoehrsen/automated-feature-engineering-basics\n- https://www.kaggle.com/willkoehrsen/introduction-to-manual-feature-engineering-p2"},{"metadata":{"_uuid":"a188f51ea83e653166e142e73d0212561e7e4416"},"cell_type":"markdown","source":"- Using SpaCy, we can extract his JOB! because he is working in \"Feature Labs\". :)"},{"metadata":{"_uuid":"9812118ee4083729f0a552fc6fb378d6c652a735"},"cell_type":"markdown","source":"# Conclusion"},{"metadata":{"_uuid":"ec9d4ca2c90081abb95cf4abe12923d4a4878500"},"cell_type":"markdown","source":"- Tokenization using SpaCy works well. \n- How about using SpaCy?"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}