{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"pip install pomegranate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install graphviz","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install libgraphviz-dev","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install cgraph","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install pydot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install libcgraph","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install pydotplus","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"conda install pygraphviz","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install networkx","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder, StandardScaler, Normalizer\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn import metrics\nimport seaborn as sns\nfrom IPython.core.display import Image\nimport matplotlib.pyplot as plt\nfrom pomegranate import *\nfrom tqdm import tqdm\nimport graphviz\nimport pydotplus\nimport pygraphviz\nimport networkx as nx\n\nsns.set(color_codes=True)\nsns.set(rc={'figure.figsize':(5,5)})\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"# Assigning a name to the dataframe\noasis_longitudinal = pd.read_csv(\"../input/mri-and-alzheimers/oasis_longitudinal.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Looking at the first 5 rows of the dataframe\nprint(\"Longitudinal MRI Data in Nondemented and Demented Older Adults\")\noasis_longitudinal.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping rows containing NaN values as the Chow-Liu algorithm does not support NaN's and checking a few features for dimentionality\n\noasis_longitudinal = oasis_longitudinal.dropna()\n\nprint(oasis_longitudinal['Hand'].value_counts())\nprint(oasis_longitudinal['M/F'].value_counts())\nprint(oasis_longitudinal['SES'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oasis_longitudinal.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping unnecessary columns\nX = oasis_longitudinal.drop(['Subject ID', 'MRI ID', 'Hand'], axis=1)\ny = oasis_longitudinal['Group']\n\n# Encoding categorical columns\nle_group = LabelEncoder()\nle_mf = LabelEncoder()\n\nX['Group'] = le_group.fit_transform(X['Group'])\nX['M/F'] = le_mf.fit_transform(X['M/F'])\n\n# Normalizing columns with large ranges\ncols_to_norm = [\"MR Delay\", \"eTIV\", \"ASF\"]\nX[cols_to_norm] = Normalizer().fit_transform(X[cols_to_norm])\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Naming the nodes of the DAG\nstate_names = [\"Group\", \"Visit\", \"MR Delay\", \"Male / Female\", \"Age\", \"EDUC\", \"SES\", \"MMSE\", \"CDR\", \"eTIV\", \"nWBV\", \"ASF\"]\n\n# Generating a Chow-Liu BN from the dataset\nmodel_chow_liu = BayesianNetwork.from_samples(X_train, algorithm='chow-liu', state_names=state_names, name=\"Chow-Liu Bayesian Network DAG\", pseudocount=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the DAG\nplt.figure(figsize=(16,8))\nmodel_chow_liu.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1 = Male\n# 0 = Female\n\n# Testing what diagnosis individual 9 most likely has\n\n# The following are the observed conditions/ stats about the individual:\nobservations = {\"Visit\": 3,\n                \"Male / Female\": 1,\n                \"Age\": 85,\n                \"EDUC\": 12,\n                \"SES\": 4.0,\n                \"MMSE\": 30.0,\n                \"CDR\": 0.0,\n                \"nWBV\": 0.705}\n\n# Using the learned BN algorithm, the probability of being diagnosed with Dimentia is given, along with other features\nbeliefs = map( str, model_chow_liu.predict_proba( observations ) )\nprint (\"\\n\".join( \"{}\\t\\t{}\".format( state.name, belief ) for state, belief in zip( model_chow_liu.states, beliefs ) ))\n\n# 2 = Nondemented\n# 1 = Demented\n# 0 = Converted : subjects were characterized as nondemented at the time of their initial visit and were subsequently characterized as demented at a later visit.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Individual 9 has the highest chance of being nondemented at ~78%"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1 = Male\n# 0 = Female\n\n# Testing what diagnosis individual 148 most likely has\n\n# The following are the observed conditions/ stats about the individual:\nobservations = {\"Visit\": 2, \n                \"Male / Female\": 0,\n                \"Age\": 82,\n                \"EDUC\": 18,\n                \"SES\": 2.0,\n                \"MMSE\": 30.0,\n                \"CDR\": 0.0,\n                \"nWBV\": 0.690,\n               }\n\n# Using the learned BN algorithm, the probability of being diagnosed with Dimentia is given, along with other features\nbeliefs = map( str, model_chow_liu.predict_proba( observations ) )\nprint (\"\\n\".join( \"{}\\t\\t{}\".format( state.name, belief ) for state, belief in zip( model_chow_liu.states, beliefs ) ))\n\n# 2 = Nondemented\n# 1 = Demented\n# 0 = Converted : subjects were characterized as nondemented at the time of their initial visit and were subsequently characterized as demented at a later visit.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Individual 148 has the highest chance of being nondemented at ~97%"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}