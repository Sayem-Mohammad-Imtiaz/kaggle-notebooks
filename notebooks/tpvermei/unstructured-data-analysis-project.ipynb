{"cells":[{"metadata":{},"cell_type":"markdown","source":"* Import Libraries "},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib import pyplot\nimport seaborn as sns\n%matplotlib inline\n\n# Warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport sklearn \nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.tokenize import sent_tokenize\nfrom sklearn.model_selection import train_test_split\nfrom nltk.corpus import stopwords\nfrom sklearn import metrics\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import svm\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom nltk.tokenize import TreebankWordTokenizer\nfrom sklearn.feature_extraction.text import TfidfTransformer \nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.pipeline import Pipeline\nfrom nltk.stem import PorterStemmer\nfrom collections import Counter\nfrom wordcloud import WordCloud","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Read in the Data and check first 5 elements"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/sms-spam-collection-dataset/spam.csv\",encoding='latin-1')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Last columns seem to be unnecessary, check if there are values in there."},{"metadata":{"trusted":true},"cell_type":"code","source":"Sum = data.isnull().sum()\nPercentage = (data.isnull().sum()/data.isnull().count())\nvalues = pd.DataFrame([Sum,Percentage])\nprint(values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* More than 99% empty decide to remove columns \n* Rename columns \n* Other columns have no missing values "},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/sms-spam-collection-dataset/spam.csv\",encoding='latin-1')\ndata.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1, inplace = True)\ndata.columns =['label','text']\n\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colors = ['#ff9999','#66b3ff']\ndata[\"label\"].value_counts().plot(kind = 'pie',colors = colors ,explode = (0.1,0),autopct = '%1.1f%%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"13.4% of dataset are spam messages, other 86.6% are not"},{"metadata":{},"cell_type":"markdown","source":"* Most popular \"ham\" text: 'Sorry, I'll call later', recurse 30 times.\n* Most popular \"spam\" text= 'Please call our customer service representative ...', recurse 4 times."},{"metadata":{},"cell_type":"markdown","source":"TODO: Word Cloud "},{"metadata":{"trusted":true},"cell_type":"code","source":"stop_words = set(stopwords.words('english'))\nspam_text = data.loc[data['label'] == 'spam']\nham_text = data.loc[data['label'] == 'ham']\n\ncount_Ham = Counter(\" \".join(data[data['label']=='ham'][\"text\"]).split()).most_common(100)\ncommon_Ham = pd.DataFrame.from_dict(count_Ham)[0]\ncommon_ham = common_Ham.str.cat(sep=' ')\n\ncount_Spam = Counter(\" \".join(data[data['label']=='spam'][\"text\"]).split()).most_common(100)\ncommon_Spam = pd.DataFrame.from_dict(count_Spam)[0]\ncommon_spam = common_Spam.str.cat(sep=' ')\n\nwordcloud = WordCloud(stopwords=stop_words,background_color = \"white\")\nwordcloud.generate(common_ham)\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()\n\n\nwordcloud = WordCloud(stopwords=stop_words,background_color = \"white\")\nwordcloud.generate(common_spam)\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby(\"label\").describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Add variable length \n* Change spam to dummy -> spam = 1, ham = 0"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['length'] = data['text'].apply(len)\ndata =pd.get_dummies(data, columns=['label'], prefix = 'Dummy' ,drop_first = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"remove stopwords "},{"metadata":{"trusted":true},"cell_type":"code","source":"# stop  = stopwords.words('english')\n# data['text'].apply(lambda x: [item for item in x if item not in stop])\n# data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_sent = []\nfor text in data.text:\n    all_sent.append(text.lower())\n\ncommon_sent = nltk.FreqDist(all_sent).most_common(10)\ndisplay(common_sent)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=data['length'].values[:,None]\ny= data['Dummy_spam']\nX_train,X_test,y_train,y_test=train_test_split(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('seaborn-pastel')\ndata.hist(column='length',by='Dummy_spam',figsize=(10,5), bins=100, label = (\"Ham\",\"Spam\") )\nplt.xlim(-40,800)\nplt.ioff()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = []\nmodels.append(['LR', LogisticRegression(solver='lbfgs')])\nmodels.append(['SVM', svm.SVC(gamma='auto')])\nmodels.append(['RF', RandomForestClassifier(n_estimators=1000, max_depth=10)])\nmodels.append(['NN', MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(150, 10))])\nmodels.append(['KNN', KNeighborsClassifier()])\nmodels.append(['DTC', DecisionTreeClassifier()])\nmodels.append(['MNB', MultinomialNB(alpha=0.2)])\nmodels.append(['ABC', AdaBoostClassifier(n_estimators=100)])\nprint('Done')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Classification based on length of text"},{"metadata":{"trusted":true},"cell_type":"code","source":"results = []\nfor name, model in models:\n    wine_model = model\n    wine_model.fit(X_train, y_train)\n    pred = wine_model.predict(X_test)\n    acc = accuracy_score(y_test, pred)\n    precision = precision_score(y_test, pred, average=None)\n    recall = recall_score(y_test, pred, average= None)\n    error_Rate = 1- acc\n    cm = pd.DataFrame(metrics.confusion_matrix(y_test,pred),index=['ham','spam'],columns=['ham','spam'])\n    print('Model tested: {}'.format(name))\n    print('Confusion Matrix')\n    print(cm)\n    print('Accuracy= {}'.format(acc))\n    print('Error Rate= {}'.format(error_Rate))\n    print('Recall Rate= {}'.format(recall))\n    print(\"Precision Rate: {}\".format(precision))\n    print(metrics.classification_report(y_test,pred))\n    print()\n    results.append([name, precision])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"spam_text = data[data[\"Dummy_spam\"] == 1][\"text\"]\nham_text = data[data[\"Dummy_spam\"] == 0][\"text\"]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. Countvectorizer: \n    - TF-IDF Vectorizer: \n    - stopwords get removed \n    - Words NOT Stemmed"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data['text']\ny = data['Dummy_spam']\nX_train,X_test,y_train,y_test=train_test_split(X,y)\nresults2= []\n\nfor name, model in models:\n    text_clf=Pipeline([('tfidf',TfidfVectorizer(stop_words='english')),(name,model)])\n    text_clf.fit(X_train, y_train)\n    pred = text_clf.predict(X_test)\n    acc = accuracy_score(y_test, pred)\n    precision = precision_score(y_test, pred, average=None)\n    recall = recall_score(y_test, pred, average= None)\n    error_Rate = 1- acc\n    cm = pd.DataFrame(metrics.confusion_matrix(y_test,pred),index=['ham','spam'],columns=['ham','spam'])\n    print('Model tested: {}'.format(name))\n    print('Confusion Matrix')\n    print(cm)\n    print('Accuracy= {}'.format(acc))\n    print('Error Rate= {}'.format(error_Rate))\n    print('Recall Rate= {}'.format(recall))\n    print(\"Precision Rate: {}\".format(precision))\n    print(metrics.classification_report(y_test,pred))\n    print()\n    results2.append([name,precision])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = pd.DataFrame.from_items(results,orient='index', columns=['Accuracy length'])\ndf2 = pd.DataFrame.from_items(results2,orient='index', columns=['Accuracy words of bag'])\ndf = pd.concat([df1,df2],axis=1)\ndf.plot(kind='bar', figsize=(12,6), align='center')\nplt.xticks(np.arange(9), df.index)\nplt.ylabel('Accuracy Score')\nplt.title('Accuracy by Classifier')\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"occurrences to frequencies\nhttps://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html#from-occurrences-to-frequencies"},{"metadata":{},"cell_type":"markdown","source":"3. Countvectorizer: \n    - TF-IDF Vectorizer: \n    - stopwords get removed \n    - Words Stemmed"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_final_text(stemmed_text):\n    final_text=\" \".join([word for word in stemmed_text])\n    return final_text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stemmer = PorterStemmer()\ndata = pd.read_csv(\"../input/sms-spam-collection-dataset/spam.csv\",encoding='latin-1')\ndata.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1, inplace = True)\ndata.columns =['label','text']\ndata.text = data['text'].str.split()\ndata['stemmed_text'] = data['text'].apply(lambda x: [stemmer.stem(y) for y in x])\ndata['final_text']=data.stemmed_text.apply(lambda row : get_final_text(row))\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data['final_text']\ny = data['label']\nX_train,X_test,y_train,y_test=train_test_split(X,y)\nresults3= []\n\nfor name, model in models:\n    text_clf=Pipeline([('tfidf',TfidfVectorizer(stop_words='english')),(name,model)])\n    text_clf.fit(X_train, y_train)\n    pred = text_clf.predict(X_test)\n    acc = accuracy_score(y_test, pred)\n    precision = precision_score(y_test, pred, average=None)\n    recall = recall_score(y_test, pred, average= None)\n    error_Rate = 1- acc\n    cm = pd.DataFrame(metrics.confusion_matrix(y_test,pred),index=['ham','spam'],columns=['ham','spam'])\n    print('Model tested: {}'.format(name))\n    print('Confusion Matrix')\n    print(cm)\n    print('Accuracy= {}'.format(acc))\n    print('Error Rate= {}'.format(error_Rate))\n    print('Recall Rate= {}'.format(recall))\n    print(\"Precision Rate: {}\".format(precision))\n    print(metrics.classification_report(y_test,pred))\n    print()\n    results3.append([name,precision])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}