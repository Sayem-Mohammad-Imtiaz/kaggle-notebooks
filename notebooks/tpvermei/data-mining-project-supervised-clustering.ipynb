{"cells":[{"metadata":{},"cell_type":"markdown","source":"Data Mining Project\nFirst read in the data\nCurrently type refers to Red or white wine, change this to 0 or 1 and remove the original variable\nAdd classification from Very good to terrible wine "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd \nimport sklearn\nfrom sklearn.utils import shuffle \nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nwine = pd.read_csv(\"../input/wine-quality/winequalityN.csv\")\nwine = sklearn.utils.shuffle(wine)\n\n#change type to binary\nwine['type_bin'] = [0 if x == 'white' else 1 for x in wine.type]\nwine.drop(\"type\", axis= 1)\n\n# add classification in quality\nwine['quality_class'] = \"Very good\"\nwine['quality_class'][wine.quality <= 8] = 'Good'\nwine['quality_class'][wine.quality <= 7] = 'Average'\nwine['quality_class'][wine.quality <= 5] = 'Bad'\nwine['quality_class'][wine.quality <= 3] = 'Terrible'\n\nprint(\"Data loaded and variables added!\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check for null values. We notice that there are not that much null values and are not a high fraction of the features data.\nSo decide to remove the observations with null values "},{"metadata":{"trusted":true},"cell_type":"code","source":"Sum = wine.isnull().sum()\nPercentage = (wine.isnull().sum()/wine.isnull().count())\nvalues = pd.DataFrame([Sum,Percentage])\nvalues.rename(index={0: 'Sum', 1: 'Percentage'}, inplace=True)\nprint(values)\n\nwine.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check for correlation to decide which features to use.\nWe see a high correlation between total sulur dioxide and free sulfur dioxide\nBy doing a t-test we see which variable is a more significant predictor for quality."},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport seaborn as sns\nimport matplotlib.pyplot as plt\ncorr_matrix = wine.corr()\ndropSelf = np.zeros_like(corr_matrix)\ndropSelf[np.triu_indices_from(dropSelf)] = True\nsns.heatmap(corr_matrix, cmap=sns.diverging_palette(220, 10, as_cmap=True), annot=True, fmt=\".2f\", mask=dropSelf)\nplt.title('Correlation Matrix')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(wine, kind=\"scatter\", hue=\"quality_class\", palette=\"Set1\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The machine learning models that we will use and test against each other to see which is best."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn import svm\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeRegressor\nwine = pd.read_csv(\"../input/wine-quality/winequalityN.csv\")\nmodels = []\nmodels.append(['LR', LogisticRegression(solver='lbfgs', multi_class='multinomial')])\nmodels.append(['SVM', svm.SVC(decision_function_shape=\"ovo\")])\nmodels.append(['RF', RandomForestClassifier(n_estimators=1000, max_depth=10)])\nmodels.append(['NN', MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(150, 10))])\nmodels.append(['KNN', KNeighborsClassifier()])\nmodels.append(['DTC', DecisionTreeClassifier()])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Select the features.\n \n2. Scale the features and normalize them.\n\n*  Current problem can't use type as feature because it's a category even though a dummy variable should work?"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing \n\nfeaturesList = list(wine.columns)\nfeaturesNotSelected = ['quality', 'quality_class','type']\nfeatures = list(set(featuresList).difference(set(featuresNotSelected)))\nX_stand = preprocessing.scale(wine[features])\nX_normal = preprocessing.normalize(X_stand)\ny = wine['quality_class']\ntrain_X, val_X, train_y, val_y = train_test_split(X_normal, y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Test models, check for accuracy, precision_socre and recall_score to see which model performs best  "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nimport pandas as pd\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nresults = []\n\nfor name, wine_model in models:\n    wine_model.fit(train_X, train_y)\n    pred = wine_model.predict(val_X)\n    acc = accuracy_score(val_y, pred)\n    precision = precision_score(val_y, pred, average=None)\n    recall = recall_score(val_y, pred, average= None)\n    error_Rate = 1- acc\n    print('Model tested: {}'.format(name))\n    print('Accuracy= {}'.format(acc))\n    print('Error Rate= {}'.format(error_Rate))\n    print('Recall Rate= {}'.format(recall))\n    print(\"Precision Rate: {}\".format(precision))\n    print()\n    results.append((name, acc, precision, error_Rate, recall))\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}