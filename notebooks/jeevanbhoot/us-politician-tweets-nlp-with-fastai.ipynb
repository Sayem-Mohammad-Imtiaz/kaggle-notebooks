{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Introduction"},{"metadata":{},"cell_type":"markdown","source":"Imports"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom fastai import *\nfrom fastai.text.all import *\nfrom datetime import datetime\n\nset_seed(42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Set paths and create dataframes for the sentiment and US politicians datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"us_path = Path('../input/us-politicians-twitter-dataset')\nsent_path = Path('../input/sentiment140')\ntweets_path = Path('../input/ustweetssent')\n\n\nus_df = pd.read_csv(us_path/'dataset.csv', encoding='latin-1')\nsent_df = pd.read_csv(sent_path/'training.1600000.processed.noemoticon.csv', encoding='latin-1', header=None, names=['sentiment', 'ID', 'Date', 'Flag', 'User', 'text'])\ntweets_df = pd.read_csv(tweets_path/'us_tweets_sent_v2.csv', encoding='latin-1', parse_dates=['time'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Display the first 5 rows of each dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"us_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sent_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sent_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sent_df['sentiment'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The sentiment140 dataset (sent_df) has 1.6 million rows of data. When training with this set, the memory limit on Kaggle was reached, so a random sample of 800 000 tweets has been collected. Unwanted columns have been dropped and positive sentiment has been changed from a value of 4 to 1, and negative from 0 to -1."},{"metadata":{"trusted":true},"cell_type":"code","source":"sent_df_sample = sent_df.sample(n=800000)\nsent_df_sample = sent_df_sample.drop(axis=0, columns=['ID', 'Date', 'Flag', 'User'])\nsent_df_sample.loc[sent_df_sample.sentiment == 4, 'sentiment'] = 1\nsent_df_sample.loc[sent_df_sample.sentiment == 0, 'sentiment'] = -1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sent_df_sample['sentiment'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Language Model"},{"metadata":{},"cell_type":"markdown","source":"Train a Wikitext 103 language model on the sentiment tweets dataset. The language model will predict the next word of a sentence. The language model will then be trained as a sentiment classifier. This methodology is known as the ULMFit approach, and improves accuracy."},{"metadata":{"trusted":true},"cell_type":"code","source":"dls_lm = TextDataLoaders.from_df(sent_df_sample, text_col='text', is_lm=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dls_lm.show_batch(max_n=2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create model"},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = language_model_learner(dls_lm, AWD_LSTM, drop_mult=0.3, metrics=[accuracy, Perplexity()]).to_fp16()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fit for one epoch whilst frozen."},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(1, 2e-2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Unfreeze model and train for 4 epochs, which was found to be the optimal number from previous tests. Save weights."},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.unfreeze()\nlearn.fit_one_cycle(4, 2e-3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save_encoder('finetuned_800k')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Classification Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"dls_class = DataBlock(\n    blocks = (TextBlock.from_df('text', seq_len=dls_lm.seq_len, vocab=dls_lm.vocab), CategoryBlock),\n    get_x=ColReader('text'),\n    get_y=ColReader('sentiment'),\n    splitter=RandomSplitter()\n).dataloaders(sent_df_sample, bs=64)\n\ndls_class.show_batch(max_n=2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Copy weights to path where FastAI expects them '/models'"},{"metadata":{"trusted":true},"cell_type":"code","source":"if not os.path.exists('models'):\n        os.makedirs('models')\n!cp '../input/tweets-languagemodel/finetuned_comb4.pth' 'models/finetuned_comb4.pth'\n!cp '../input/tweets-languagemodel/classifier.pth' 'models/classifier.pth'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create model and load encoder weights from language model."},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = text_classifier_learner(dls_class, AWD_LSTM, drop_mult=0.5, metrics=accuracy).to_fp16()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.load_encoder('finetuned_800k')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(1, 2e-2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.freeze_to(-2)\nlearn.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.freeze_to(-3)\nlearn.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.unfreeze()\nlearn.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Final accuracy of 83.6% achieved. Ideally should be higher, especially when compared to models trained on IMDb datasets, but I have not been able to find a dataset of tweets with three labels of positive, negative and neutral, with an adequate size for training."},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save('classifier_800k')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.load('classifier')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Collecting Tweets from US Politicians"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install tweepy\nimport tweepy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"consumer_key = 'b5V0twlRbIFQTsf3ccLxdJTiT'\nconsumer_secret = 'TMro0NvOQh5jLCx6lP80Pl3qu08Iuyk2sGMV0HczDeW1LLqH8p'\naccess_key = '562242130-K6ka3D23C90CPAY48xMr1yGieJYakfnTAYtFuz1a'\naccess_secret = 'qh14ZTpwoRJ16OHwkDdidPI4K5KHGse4cAZxovHVR3ims'\nbearer_token = 'AAAAAAAAAAAAAAAAAAAAACkuLQEAAAAAswe%2Bwca72vNoYfQap0WCrYN7yHE%3DAbhtbxHkwcFiyV8m2wlSbinjZbWONsECVmg1qS22bpMtNaekPn'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\nauth.set_access_token(access_key, access_secret)\napi = tweepy.API(auth)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"us_tweets_df = pd.DataFrame(columns=['Twitter_username', 'text', 'time'])\nfor index, row in us_df.iterrows():\n    jsons = []\n    username = row['Twitter_username']\n    try:\n        new_jsons = api.user_timeline(screen_name=username, count=40, tweet_mode=\"extended\")\n    except tweepy.TweepError:\n        print(\"Failed to run the command on that user, Skipping...\")\n    jsons.extend(new_jsons)\n    tweets = [status.full_text for status in jsons]\n    times = [status.created_at for status in jsons]\n    for i in range(len(tweets)):\n        us_tweets_df = us_tweets_df.append({'Twitter_username': username, 'text': tweets[i], 'time': times[i]}, ignore_index=True)\nus_tweets_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"us_tweets_df.to_csv('us_tweets', encoding='utf-8', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Analysing tweets"},{"metadata":{},"cell_type":"markdown","source":"Applying inference to the newly collected dataset, with the pre-trained sentiment classifier."},{"metadata":{},"cell_type":"markdown","source":"Testing on a batch of 100 tweets, the model took about 16 seconds to classify them all. This suggests that it would take about 15000 seconds to classify all the tweets, or more than 4 hours - let's go..."},{"metadata":{"trusted":true},"cell_type":"code","source":"us_tweets_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_dl = dls_class.test_dl(us_tweets_df['text'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = learn.get_preds(dl=pred_dl)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Preds contains the final activations (/probabilities) for each class. The predicted class is found from the largest probability. \n0 = negative sentiment, 1 = positive sentiment."},{"metadata":{"trusted":true},"cell_type":"code","source":"us_tweets_df['sentiment'] = preds[0].argmax(dim=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"us_tweets_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"us_tweets_df['sentiment'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"us_tweets_df.to_csv('us_tweets_sent_v2.csv', encoding='utf-8', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"tweets_df = us_tweets_df: the DataFrame has been loaded from a csv in a new session, hence the new name."},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_df.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_df['date'] = tweets_df['time'].dt.date","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_df.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(tweets_df.date.min())\nprint(tweets_df.date.max())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_df['date'].iloc[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"compare_date = datetime.date(datetime(2020, 12, 1))\ncompare_date","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_df_21 = tweets_df.loc[tweets_df['date'] >= compare_date]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dates = tweets_df_21['date']\ndates = sorted(dates)\ndates = sorted(list(set(dates)))\ndates","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(20,10))\nax = fig.add_subplot(111)\nax.plot(tweets_df.groupby(tweets_df_21['date'])[\"sentiment\"].mean())\n#tweets_df.groupby(tweets_df_21['date'])[\"sentiment\"].mean().plot(figsize=(20,10))\nplt.xticks(dates[::5], rotation='60')\nplt.minorticks_on()\nplt.grid(b=True, which='major', color='#666666', linestyle='-')\nplt.grid(b=True, which='minor', color='#666666', linestyle=':')\nplt.xlabel('Date')\nplt.ylabel('Average Sentiment Score')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Both_DFs = pd.merge(tweets_df.set_index('Twitter_username', drop=True), us_df.set_index('Twitter_username', drop=True), left_index=True, right_index=True).dropna().reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Both_DFs.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Both_DFs['Political_party'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_x = Both_DFs.loc[(Both_DFs['Political_party'] == 'Democratic Party')|  \n                    (Both_DFs['Political_party'] == 'Republican Party')|\n                    (Both_DFs['Political_party'] == 'Green Party of the United States')|\n                   (Both_DFs['Political_party'] == 'Libertarian Party')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(20,10))\nax = fig.add_subplot(111)\ndf_x.groupby(df_x['Political_party'])[\"sentiment\"].mean().plot(kind='bar', rot=0, ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(20,10))\nax = fig.add_subplot(111)\nBoth_DFs.groupby(Both_DFs['Sex'])[\"sentiment\"].mean().plot(kind='bar', rot=0, ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(20,10))\nax = fig.add_subplot(111)\nBoth_DFs.groupby(Both_DFs['Age'])[\"sentiment\"].mean().plot(linestyle='', marker='o', rot=0, ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(20,10))\nax = fig.add_subplot(111)\nBoth_DFs.groupby(Both_DFs['Birthplace'])[\"sentiment\"].mean().plot(kind='bar', rot=0, ax=ax)\nplt.xticks(rotation='vertical')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from mpl_toolkits.basemap import Basemap","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from itertools import chain\n\ndef draw_map(m, scale=0.2):\n    # draw a shaded-relief image\n    m.shadedrelief(scale=scale)\n    \n    # lats and longs are returned as a dictionary\n    lats = m.drawparallels(np.linspace(-90, 90, 13))\n    lons = m.drawmeridians(np.linspace(-180, 180, 13))\n\n    # keys contain the plt.Line2D instances\n    lat_lines = chain(*(tup[1][0] for tup in lats.items()))\n    lon_lines = chain(*(tup[1][0] for tup in lons.items()))\n    all_lines = chain(lat_lines, lon_lines)\n    \n    # cycle through these lines and set the desired style\n    for line in all_lines:\n        line.set(linestyle='-', alpha=0.3, color='w')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"birthplace_sent = Both_DFs.groupby(Both_DFs['Birthplace'])[\"sentiment\"].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"birthplace_sent","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from geopy.geocoders import Nominatim\ngeolocator = Nominatim(user_agent='nlp')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def geolocate(city=None, country=None):\n    if city != None:\n        try:\n            loc = geolocator.geocode(str(city + ',' + country))\n            return (loc.latitude, loc.longitude)\n        except:\n            return np.nan\n    else:\n        try:\n            loc = geolocator.geocode(country)\n            return (loc.latitude, loc.longitude)\n        except:\n            return np.nan","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lat=[]\nlong=[]\nfor country in birthplace_sent.index:\n    coords = geolocate(country=country)\n    lat.append(coords[0])\n    long.append(coords[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(30, 15), edgecolor='w')\n\nm = Basemap(projection='cyl', resolution=None,\n            llcrnrlat=-90, urcrnrlat=90,\n            llcrnrlon=-180, urcrnrlon=180)\n\nm.scatter(long, lat, latlon=True, s=(birthplace_sent*70)**2,\n          cmap='Reds', alpha=0.5)\n\nfor a in [0.25, 0.5, 1]:\n    plt.scatter([], [], c='k', alpha=0.5, s=(a*70)**2,\n                label=str(a))\nplt.legend(scatterpoints=1, frameon=False,\n           labelspacing=5, loc='lower left', borderpad = 5);\n\ndraw_map(m)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}