{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom pandas import Series\nimport matplotlib.pyplot as plt # For visualization\nimport seaborn as sns # For data Visualization\nimport seaborn as seabornInstance \n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/nobel-laureates/archive.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check the columns\ndf.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check the data types\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's use value_counts() to determine the frequency of the values present in one particular column\nbc = df['Birth Country'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bc.head(15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So It shows US tops the list with 276 winners followed by UK and Germany","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's plot it \nsns.countplot(bc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's see how winners year wise disctributed\ndf[\"Year\"].plot.hist(bins = 100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note: As we know due to World war II there was no winners in 40's","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check the birth Cities\nbb = df['Birth City'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Top 15 cities with max nobel laureate\nbb.head(15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Again New York tops the list with 48 winners followed by Paris and London\nSome surprise names in top 10 list Hamburg and Milwaukee","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's plot it and than see\nsns.countplot(bb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# with normalize=True, the object returned contains the relative \n# frequencies of unique values (* 100 to get %ge)\nround(df['Birth Country'].value_counts(normalize=True) * 100,2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The result shows 29% winners from US followed by UK, Germany and France","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# extract a subset of the data from a DataFrame to display multiple columns, rows\ndf_cat = df[['Prize','Category','Sex','Birth Country']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cat.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's use value_counts() to determine the frequency of the values present in Sex column\ndf_cat['Sex'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df_cat['Sex'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check the percentage\n# with normalize=True, the object returned contains the relative \n# frequencies of unique values (* 100 to get %ge)\nround(df_cat['Sex'].value_counts(normalize=True) * 100,2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# crosstab() computes a simple cross-tabulation of two (or more) factors let's check for Sex\npd.crosstab(df_cat.Sex, df_cat.Category)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using isnull(), sum(), sort_values(), count() to get the total missing values and % missing for the features\n# I am using sort_values() and head() on the output because we don't need to see all features, many have no missing values\ntotal_missing = df.isnull().sum().sort_values(ascending=False)\ncol_pct_missing = round(df.isnull().sum()/df.isnull().count()*100, 1).sort_values(ascending=False)\nmissing_data = pd.concat([total_missing, col_pct_missing], axis=1, keys=['Total Missing', '% Missing'])\nmissing_data.head(7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check the Prize share\nc = sns.FacetGrid(df, col='Prize Share')\nc.map(plt.hist, 'Category', bins=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's see the Category by Sex\ng = sns.FacetGrid(df_cat, col='Sex')\ng.map(plt.hist, 'Category', bins=12)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check the winners by County of birth by Category\nl = sns.FacetGrid(df_cat, col='Category')\nl.map(plt.hist, 'Birth Country', bins=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Category by Birth Date\nm = sns.FacetGrid(df, col='Category')\nm.map(plt.hist, 'Birth Date', bins=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot distributions of winners by Death Country\na = sns.FacetGrid( df, hue = 'Death Country', aspect=4 )\na.map(sns.kdeplot, 'Year', shade= True )\na.set(xlim=(0 , df['Year'].max()))\na.add_legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check the winners over the years\ndf['Year'].plot(legend=True,figsize=(15,5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# How about winners by Category\nsns.countplot(df['Category'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Another way to see it\ndf[\"Category\"].value_counts(sort = False).plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Winners by Prize\nsns.countplot(df['Prize'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's check the comparison of sex, Category, and Year with the help of histogram\nh = sns.FacetGrid(df, row = 'Sex', col = 'Category', hue = 'Sex')\nh.map(plt.hist, 'Year', alpha = .75)\nh.add_legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check by Laureate Type\nsns.countplot(df['Laureate Type'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Another way\ndf[\"Laureate Type\"].value_counts(sort = False).plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check by Organization \non = df['Organization Name'].value_counts()\non.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Graph shows the top 5 Organizations (all Universities) with maximum number of winners","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(on)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's see Prize share distribution\ndf[\"Prize Share\"].value_counts(sort = False).plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's see winners by Birth City and Category\ndf.groupby([\"Birth City\", \"Category\"]).size()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"That's all I tried whatever learnt from Kaggle data Visualization so far. \nLove to hear feedback on the same to improve it further. ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}