{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(\"../input/eeg-ac-1/Dataset.csv\")\ntest_data = pd.read_csv(\"../input/eeg-ac-2/Test_Dataset.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import glob\nimport pandas as pd\n\n# get data file names\npath =r'../input/Alcoholics/SMNI_CMI_TRAIN/Train'\nfilenames = glob.glob(path + \"/*.csv\")\n\ndfs = []\nfor filename in filenames:\n    dfs.append(pd.read_csv(filename))\n\n# Concatenate all data into one DataFrame\nbig_frame = pd.concat(dfs, ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.unique(big_frame['name'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.unique(big_frame['name'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.unique(big_frame['name'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(pd.unique(big_frame['trial number']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head(),test_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = train_data.drop(['Unnamed: 0','nd','Y','X'],axis=1)\ntest_data = test_data.drop(['Unnamed: 0','nd','Y','X'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head(),test_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_10 = train_data[['FP1','FP2','F7','F3','FZ','F4','F8'\n                          ,'C3','CZ','C4','P3','PZ','P4',\n                          'O1','O2']]\n\ntest_data_10 = test_data[['FP1','FP2','F7','F3','FZ','F4','F8'\n                          ,'C3','CZ','C4','P3','PZ','P4',\n                          'O1','O2']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head(48642)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ctrl = train_data[0:48640]\nalch = train_data[48640:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ctrl.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"alch.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_mix = []\nfor a in range(468):\n    mix = ctrl[255*a:255*(a+1)]\n    all_mix.append(mix)\nk = pd.concat(all_mix)\nlenk","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mix = []\nfor a in range(468):\n    mix.append(ctrl[a*255:(a+1)*255])\n    mix.append(alch[a*255:(a+1)*255])\nbig = pd.concat(mix,ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"big.head(258)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"partial_train_data = train_data[0:100000]\nvalid_data = train_data[100000:]\n\npartial_train_targets = train_targets[0:100000]\nvalid_targets = train_targets[100000:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_Y[0:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data,train_targets = train_data.loc[:, train_data.columns!='Label'], train_data.Label\ntest_X,test_Y = test_data.loc[:, test_data.columns!='Label'], test_data.Label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils import shuffle\n\ntrain_data_sh,train_targets_sh = shuffle(train_data,train_targets,random_state = 9896)\ntest_data_sh,test_targets_sh = shuffle(test_X,test_Y,random_state = 9896)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(test_data_sh)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_targets_sh[0:20]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_10 = train_data[['FP1','FP2','F7','F3','FZ','F4','F8'\n                          ,'C3','CZ','C4','P3','PZ','P4',\n                          'O1','O2']]\n\ntest_data_10 = test_X[['FP1','FP2','F7','F3','FZ','F4','F8'\n                          ,'C3','CZ','C4','P3','PZ','P4',\n                          'O1','O2']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_10.shape, test_data_10.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras import optimizers, layers, models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder = LabelEncoder()\ntrain_targets_sh = encoder.fit_transform(train_targets_sh)\ntest_targets_sh = encoder.fit_transform(test_targets_sh)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_targets = encoder.fit_transform(train_targets)\ntest_targets = encoder.fit_transform(test_Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_targets_sh,test_targets_sh","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(valid_Y1+train_Y1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nnum_val_samples = len(train_data)/5\nnum_val_samples = int(num_val_samples)\nnum_val_samples","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_Y = pd.DataFrame(data=train_Y)\ntrain_Y.values\nlen(train_Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_X1 = train_X[0*k:1*k]\ntrain_X1 = train_X[1*k:4*k]\nvalid_Y1 = train_Y[0*k:1*k]\ntrain_Y1 = train_Y[1*k:4*k]\n#valid_Y1 = valid_Y1.to_numpy()\n#train_Y1 = train_Y1.to_numpy()\n\nvalid_X2 = train_X[1*k:2*k]\ntrain_X2 = train_X[0*k:1*k] + train_X[2*k:4*k]\nvalid_Y2 = train_Y[1*k:2*k]\ntrain_Y2 = train_Y[0*k:1*k].append(train_Y[2*k:4*k])\n\nvalid_X3 = train_X[2*k:3*k]\ntrain_X3 = train_X[0*k:2*k] + train_X[3*k:4*k]\nvalid_Y3 = train_Y[2*k:3*k]\ntrain_Y3 = train_Y[0*k:2*k].append(train_Y[3*k:4*k])\nvalid_Y3 = valid_Y3.to_numpy()\ntrain_Y3 = train_Y3.to_numpy()\n\nvalid_X4 = train_X[3*k:4*k]\ntrain_X4 = train_X[0*k:3*k] \nvalid_Y4 = train_Y[3*k:4*k]\ntrain_Y4 = train_Y[0*k:3*k] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc =0\ntotal_acc=0\nn=8\nmean_acc=0\ntotal_mean_acc=[]\n\nfor n in range(n):\n    print(\"at nodes = \",(n+1)*32)\n    total_acc=0\n    for i in range(4):\n        print('processing fold #', i+1)\n        val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n        val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n        partial_train_data = np.concatenate(\n        [train_data[:i * num_val_samples],\n        train_data[(i + 1) * num_val_samples:]],\n        axis=0)\n        partial_train_targets = np.concatenate(\n        [train_targets[:i * num_val_samples],\n        train_targets[(i + 1) * num_val_samples:]],axis=0)\n        model = models.Sequential()\n        model.add(layers.Dense((n+1)*32, activation=\"relu\", input_shape=(61,)))\n        model.add(layers.Dense(n+1*32,activation='relu'))\n        model.add(layers.Dense(1,activation ='sigmoid'))\n        model.compile(optimizer= 'adam',loss = 'binary_crossentropy',metrics = ['acc'])\n        model.fit(partial_train_data, partial_train_targets,epochs=5,verbose=0)\n        _,acc = model.evaluate(val_data,val_targets)\n        print(val_data.index)\n        total_acc +=acc\n        mean_acc = total_acc/4\n    print(\"Mean accuracy for \" ,(n+1)*32 ,mean_acc)\n    print(\"testing accuracy : \",model.evaluate(test_X,test_Y,verbose = 0))\n    total_mean_acc.append(mean_acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.shape,train_targets.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\npca = PCA(n_components=40)\nvectors = pca.fit_transform(train_data_sh)\nvectors_ts = pca.transform(test_data_sh)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\ntf.random.set_seed(2)\n\nopt = keras.optimizers.Adam(learning_rate=0.0001)\nmodel = models.Sequential()\nmodel.add(layers.Dense(512,activation ='relu',input_shape=(40,)))\nmodel.add(layers.Dense(1,activation = 'sigmoid'))\nmodel.compile(optimizer= opt,loss = 'binary_crossentropy',metrics = ['acc'])\nhistory = model.fit(vectors,train_targets_sh,epochs=20,validation_split=0.2,shuffle = True,batch_size = 32)\nmodel.evaluate(vectors_ts,test_targets_sh)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\ntf.random.set_seed(2)\n\nimport timeit\n\nstart = timeit.default_timer()\n\nmodel = models.Sequential()\nmodel.add(layers.Dense(64,activation ='relu',input_shape=(61,)))\nmodel.add(layers.Dropout(0.25))\nmodel.add(layers.Dense(256,activation = 'relu'))\nmodel.add(layers.Dropout(0.25))\nmodel.add(layers.Dense(256,activation = 'relu'))\nmodel.add(layers.Dropout(0.25))\nmodel.add(layers.Dense(1,activation ='sigmoid'))\nmodel.compile(optimizer= 'adam',loss = 'binary_crossentropy',metrics = ['acc'])\nhistory = model.fit(train_data_sh,train_targets_sh,epochs=250,validation_split = 0.35,shuffle=True,verbose = 1)\nmodel.evaluate(test_data_sh,test_targets_sh)\nmodel.save(\"EEG_model.h5\")\nstop = timeit.default_timer()\n\nprint('Time: ', stop - start)\n\nrecord =  history.history\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nepochs = np.arange(len(record['loss']))\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.title('Learning Curves')\nplt.plot(epochs+1,record['acc'],label = 'Train_acc')\nplt.plot(epochs+1,record['val_acc'],label = 'val_acc')\nplt.legend(loc='best')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = ['16','32','64','128']\ny = [90.77,90.93,90.98,90.2]\nplt.xlabel(\"Bactch Size\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Model performance on various Batch Size\")\nplt.bar(x,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = ['Adam','RMS-PROP','SGD','Adamax']\ny = [90.93,88.6,90.13,90.89]\nplt.xlabel(\"Optimizers\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Model performance on various optimizers\")\nplt.bar(x,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train_data_sh.values.reshape(119808,61,1)\ntype(test_data_sh)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr_10=train_data_10.values.reshape(119808,15,1)\nts_10=test_data_10.values.reshape(122880,15,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.DataFrame()\ntest = test_data_sh.values.reshape(122880,61,1)\ntype(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Conv1D, MaxPool1D, Dense, Flatten, Dropout\nfrom keras.optimizers import Adam\nimport tensorflow as tf\n\nimport timeit\nfrom tensorflow.keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import KFold,cross_val_score\n\nstart = timeit.default_timer()\n\nall_val_acc = []\nall_train_acc = []\n\nfor i in range(5):\n    print('processing fold #', i+1)\n    val_data = train_data_sh[i * num_val_samples: (i + 1) * num_val_samples]\n    val_targets = train_targets_sh[i * num_val_samples: (i + 1) * num_val_samples]\n    partial_train_data = np.concatenate(\n    [train_data[:i * num_val_samples],\n    train_data[(i + 1) * num_val_samples:]],\n    axis=0)\n    partial_train_targets = np.concatenate(\n    [train_targets[:i * num_val_samples],\n    train_targets[(i + 1) * num_val_samples:]],axis=0)\n\n    tf.random.set_seed(2)\n    print(val_data.index)\n    model_c = models.Sequential()\n    model_c.add(Conv1D(filters=64, kernel_size=5, activation='relu', input_shape=(61,1)))\n    model_c.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n    model_c.add(Dropout(0.2))\n    model_c.add(Flatten())\n    model_c.add(Dense(512, activation='relu'))\n    model_c.add(Dense(1, activation='sigmoid'))\n    model_c.compile(loss='binary_crossentropy', optimizer=Adam(0.00001), metrics=['accuracy'])\n    history = model_c.fit(train,train_targets_sh,epochs =100,validation_split=0.15)\n    record =  history.history\n    all_train_acc.append(record['accuracy'])\n    all_val_acc.append(record['val_accuracy'])\n\nstop = timeit.default_timer()\nprint('Time: ', stop - start)\n\nmodel_c.save(\"Conc_1d_EEG_Final.h5\")\nmodel_c.evaluate(test,test_targets_sh)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\nwith open(\"../input/tra-val-rec/train.txt\", \"r\") as fp:\n    all_train_acc = json.load(fp)\nwith open(\"../input/tra-val-rec/valid.txt\", \"r\") as fp:\n    all_valid_acc = json.load(fp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(all_valid_acc[0][2]+all_valid_acc[1][2]+all_valid_acc[2][2]+all_valid_acc[3][2]+all_valid_acc[4][2])/5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"val_acc = []\ntrain_acc = []\nc = 0\np = 0\nfor j in range(100):\n    for i in range(5):\n        c = c + all_train_acc[i][j]\n        p = p + all_valid_acc[i][j]\n    c/=5\n    p/=5\n    #print(c)\n    val_acc.append(p)\n    train_acc.append(c)\n    c=0\n    p=0\nval_acc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(k)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Conv1D, MaxPool1D, Dense, Flatten, Dropout\nfrom keras.optimizers import Adam\nimport tensorflow as tf\n\nimport timeit\n\nstart = timeit.default_timer()\n\ntf.random.set_seed(2)\n\nmodel_c = models.Sequential()\nmodel_c.add(Conv1D(filters=64, kernel_size=5, activation='relu', input_shape=(61,1)))\nmodel_c.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\nmodel_c.add(Dropout(0.2))\nmodel_c.add(Flatten())\nmodel_c.add(Dense(512, activation='relu'))\nmodel_c.add(Dense(1, activation='sigmoid'))\nmodel_c.compile(loss='binary_crossentropy', optimizer=Adam(0.00001), metrics=['accuracy'])\nhistory = model_c.fit(train,train_targets_sh,epochs =35,validation_split=0.15)\n\nstop = timeit.default_timer()\nprint('Time: ', stop - start)\n\nmodel_c.save(\"Conc_1d_EEG_Final.h5\")\nmodel_c.evaluate(test,test_targets_sh)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nv = int(len(test)/10)\nresults = []\nfor i in range(10):\n    loss,acc = model_c.evaluate(test[i*v:(i+1)*v],test_targets_sh[i*v:(i+1)*v])\n    results.append(round(acc,4))\n    #print(np.where(test[i*v:(i+1)*v]))\nprint(\"All 10 accuracies :\",results)\nprint(\"Average Accuracy for 35 Epochs :\",sum(results)/10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#record =  history.history\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nepochs = np.arange(len(train_acc))\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.title('Learning Curves')\nplt.plot(epochs+1,train_acc,label = 'Train_acc',marker='v',markevery=5)\nplt.plot(epochs+1,val_acc,label = 'val_acc',marker='o',markevery=5)\nplt.legend(loc='best')\nplt.grid()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_c.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model_c.predict_classes(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_score, f1_score, recall_score\nprint(\"Precision Score : \",precision_score(test_targets_sh,predictions))\nprint(\"F1-score Score : \",f1_score(test_targets_sh,predictions))\nprint(\"Recall Score : \",recall_score(test_targets_sh,predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = model.predict_classes(test_X[0:255])\na = []\nc = []\nfor i in results:\n    if i == 0:\n        a.append(i)\n    else:\n        c.append(i)\nif len(a) > len(c):\n    print('Alcholic')\nelse:\n    print(\"Control\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import load_model\nmodel = load_model(\"../input/eeg-model/EEG_model.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nprob = model_c.predict_proba(test)\nroc_auc_score(test_targets_sh,prob)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_recall_curve,auc\nprob_pr = model_c.predict_proba(test)\nprecision,recall,thrs = precision_recall_curve(test_targets_sh,prob_pr)\nauc(recall,precision)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title(\"AUC ROC Curve\")\nplt.plot(fpr,tpr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import auc, precision_recall_curve\n\n# calculate precision-recall curve\nprecision, recall, thresholds = precision_recall_curve(test_targets, prob)\nauc(recall,precision)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(test_targets_sh,predictions)\n\nimport matplotlib.pyplot as plt\nplt.imshow(cm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                        normalize=False,\n                        title='Confusion matrix',\n                        cmap = 'Blues'):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest',cmap=cmap)\n    plt.title(title)\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n            horizontalalignment=\"center\",\n            color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(67092) / (67902 + 6255)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import itertools\nimport numpy as np\n\ncm_plot_labels = ['Alchohlic','Control']\nplot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(test_targets_sh,predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nnodes = [32,64,96,128,160,192,224,256]\n\nplt.xlabel(\"Nodes\")\nplt.ylabel(\"Accuracies\")\nplt.title(\"K-Fold Mean Accuracies Graph per nodes\")\nplt.plot(nodes,total_mean_acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l = 0\nn = 10\n\nall_loss1 = []\nall_acc1 = []\nfor n in range(n):\n    print(\"at nodes = \",(n+1)*16)\n    model = models.Sequential()\n    model.add(layers.Dense((n+1)*16, activation=\"relu\", input_shape=(61,)))\n    #model.add(layers.Dense(n+1*32,activation='relu'))\n    model.add(layers.Dense(1,activation ='sigmoid'))\n    model.compile(optimizer= 'adam',loss = 'binary_crossentropy',metrics = ['acc'])\n    model.fit(train_X3,train_Y3,epochs=5,validation_data=(valid_X3,valid_Y3))\n    loss,acc = model.evaluate(test_X,test_Y)\n    all_loss1.append(loss)\n    all_acc1.append(acc)\nall_loss1,all_acc1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l = 0\nn = 10\n\nvalid_X = train_X[1*k:2*k]\nvalid_Y = train_Y[1*k:2*k]\n\nall_loss2 = []\nall_acc2 = []\nfor n in range(n):\n    print(\"at nodes = \",(n+1)*16)\n    model = models.Sequential()\n    model.add(layers.Dense((n+1)*16, activation=\"relu\", input_shape=(61,)))\n    #model.add(layers.Dense(n+1*32,activation='relu'))\n    model.add(layers.Dense(1,activation ='sigmoid'))\n    model.compile(optimizer= 'adam',loss = 'binary_crossentropy',metrics = ['acc'])\n    model.fit(train_X,train_Y,epochs=5,validation_data=(valid_X,valid_Y))\n    loss,acc = model.evaluate(test_X,test_Y)\n    all_loss2.append(loss)\n    all_acc2.append(acc)\nall_loss2,all_acc2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l = 0\nn = 10\n\nvalid_X = train_X[2*k:3*k]\nvalid_Y = train_Y[2*k:3*k]\n\nall_loss3 = []\nall_acc3 = []\nfor n in range(n):\n    print(\"at nodes = \",(n+1)*16)\n    model = models.Sequential()\n    model.add(layers.Dense((n+1)*16, activation=\"relu\", input_shape=(61,)))\n    #model.add(layers.Dense(n+1*32,activation='relu'))\n    model.add(layers.Dense(1,activation ='sigmoid'))\n    model.compile(optimizer= 'adam',loss = 'binary_crossentropy',metrics = ['acc'])\n    model.fit(train_X,train_Y,epochs=5,validation_data=(valid_X,valid_Y))\n    loss,acc = model.evaluate(test_X,test_Y)\n    all_loss3.append(loss)\n    all_acc3.append(acc)\nall_loss3,all_acc3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l = 0\nn = 10\n\nvalid_X = train_X[3*k:4*k]\nvalid_Y = train_Y[3*k:4*k]\n\nall_loss4 = []\nall_acc4 = []\nfor n in range(n):\n    print(\"at nodes = \",(n+1)*16)\n    model = models.Sequential()\n    model.add(layers.Dense((n+1)*16, activation=\"relu\", input_shape=(61,)))\n    #model.add(layers.Dense(n+1*32,activation='relu'))\n    model.add(layers.Dense(1,activation ='sigmoid'))\n    model.compile(optimizer= 'adam',loss = 'binary_crossentropy',metrics = ['acc'])\n    model.fit(train_X,train_Y,epochs=5,validation_data=(valid_X,valid_Y))\n    loss,acc = model.evaluate(test_X,test_Y)\n    all_loss4.append(loss)\n    all_acc4.append(acc)\nall_loss4,all_acc4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.title('Mean K-fold accuracy per nodes')\nplt.xlabel(\"nodes\")\nplt.ylabel(\"Mean K-fold accuracy\")\nplt.plot(nodes,total_mean_acc)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max(total_mean_acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer= 'adam',loss = 'binary_crossentropy',metrics = ['acc'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(train_X,train_Y,epochs=5,validation_data=(valid_X,valid_Y))\nacc, loss = model.evaluate(test_X,test_Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}