{"cells":[{"metadata":{},"cell_type":"markdown","source":"## This notebook will explore and analyze the heart failure dataset and use machine learning models to predict heart failure."},{"metadata":{"trusted":true},"cell_type":"code","source":"# import dependencies\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(rc={'figure.figsize':(8,6)})\nsns.set_palette(\"pastel\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First let's take a look at the dataset to get an idea of what the data look like, the features of the dataset, the variable types (numerical/categorical), missing values, and some summary statistics."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/heart-failure-clinical-data/heart_failure_clinical_records_dataset.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# number of rows, number of columns\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# check for missing values in the dataset\n\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# summary statistics\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First let's plot the distributions of the different variables, seperated out by numeric and categorical variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"# examine the distribution of the numeric variables\n\nfig = plt.figure(figsize = (18, 26)).tight_layout(h_pad=5.0, w_pad = 5.0)\n\nplt.subplot(421)\nplt.title('Age Distribution')\nsns.histplot(df.age)\n\nplt.subplot(422)\nplt.title('Serum Sodium Distribution')\nsns.histplot(df.serum_sodium)\n\nplt.subplot(423)\nplt.title('Creatinine Phospokinase Distribution')\nsns.histplot(df.creatinine_phosphokinase)\n\nplt.subplot(424)\nplt.title('Time Distribution')\nsns.histplot(df.time)\n\nplt.subplot(425)\nplt.title('Ejection Fraction Distribution')\nsns.histplot(df.ejection_fraction)\n\nplt.subplot(426)\nplt.title('Platelets Distribution')\nsns.histplot(df.platelets)\n\nplt.subplot(427)\nplt.title('Serum Creatinine Distribution')\nsns.histplot(df.serum_creatinine)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I notice the serum_creatinine and creatinine_phosphokinase features are heavily right-skewed, with serum_sodium left-skewed. Time does not follow a normal distribution. This will be important to keep in mind as we move forward. Now let's visualize the value counts of the categorical variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"# examine the distribution of the categorical variables\n\nfig = plt.figure(figsize = (16, 12)).tight_layout(pad=3.0)\n\nplt.subplot(231)\nplt.title('Sex Distribution')\nsns.countplot(df.sex)\n\nplt.subplot(232)\nplt.title('Anaemia Distribution')\nsns.countplot(df.anaemia)\n\nplt.subplot(233)\nplt.title('Diabetes Distribution')\nsns.countplot(df.diabetes)\n\nplt.subplot(234)\nplt.title('High Blood Pressure Distrubution')\nsns.countplot(df.high_blood_pressure)\n\nplt.subplot(235)\nplt.title('Smoking Distribution')\nsns.countplot(df.smoking)\n\nplt.subplot(236)\nplt.title('Death Distribution')\nsns.countplot(df.DEATH_EVENT)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I notice the number of survivors is roughly double the number of deaths in the sample.  The same is true for non-smokers vs smokers, and normal blood pressure vs high blood pressure."},{"metadata":{},"cell_type":"markdown","source":"I will now seperate the features into numerical and categorical variables, and will standardize the numerical variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cat = df[['anaemia', 'diabetes', 'high_blood_pressure', 'sex', 'smoking', 'DEATH_EVENT']]\ndf_num = df[['age', 'creatinine_phosphokinase', 'ejection_fraction', 'platelets', 'serum_creatinine', 'serum_sodium', 'time']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cat.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# converting age and platelets to integers for simplicity\n\ndf_num['age'] = [int(x) for x in df_num.age]\ndf_num['platelets'] = [int (x) for x in df_num.platelets]\ndf_num.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# scaling the numerical data via standardscaler\n\nsc = StandardScaler()\ndf_cols = df_num.columns\ndf_num_scaled = sc.fit_transform(df_num)\ndf_num_scaled = pd.DataFrame(df_num_scaled, columns = df_cols)\ndf_num_scaled.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# master dataframe (unscaled)\ndf_master = pd.concat([df_num, df_cat], axis=1)\ndf_master.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# master dataframe (scaled)\ndf_master_scaled = pd.concat([df_num_scaled, df_cat], axis=1)\ndf_master_scaled.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's take a look at any correlations that exist between the features by using a correlation matrix."},{"metadata":{"trusted":true},"cell_type":"code","source":"# heatmap to identify correlations between features\n\nfig = plt.figure(figsize = (12, 7))\nsns.heatmap(df_master_scaled.corr(), center=0, cmap='mako', robust=True, annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I note fairly significant correlations between death (our dependent variable), and the independent variables age, ejection fraction, serum_creatinine, serum_sodium, and time (which has the largest correlation).  Let's take a look."},{"metadata":{"trusted":true},"cell_type":"code","source":"median_death = df_master[df_master['DEATH_EVENT']==1]['age'].median()\nmedian_life = df_master[df_master['DEATH_EVENT']==0]['age'].median()\nprint(\"Median Age for Death: \", median_death, '\\nMedian age for Survivor: ', median_life, '\\nDifference: ', median_death-median_life)\n\nax = sns.violinplot(data=df_master, x='DEATH_EVENT', y='age')\nax.set_title('Age of Deaths vs Survivors', fontsize=20)\nax.set_xlabel('Death Status', fontsize=14)\nax.set_ylabel('Age', fontsize=14)\nax.set_xticklabels(['Survivor', 'Death'], fontsize=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The median age of deaths is roughly 5 years older than survivors (65 vs 60 yrs)"},{"metadata":{"trusted":true},"cell_type":"code","source":"female_deaths = len(df_master[(df_master['DEATH_EVENT']==1) & (df_master['sex']==0)])/len(df_master[df_master['sex']==0])\nmale_deaths = len(df_master[(df_master['DEATH_EVENT']==1) & (df_master['sex']==1)])/len(df_master[df_master['sex']==1])\nprint(\"Proportion of Female Deaths: \", female_deaths, '\\nProportion of Male Deaths: ', male_deaths, '\\nDifference: ', female_deaths-male_deaths)\n\nax = sns.countplot(data=df_master, x='sex', hue='DEATH_EVENT')\nax.set_title('Number of Deaths by Sex', fontsize=20)\nax.set_xlabel('Sex', fontsize=14)\nax.set_ylabel('Count', fontsize=14)\nax.set_xticklabels(['Female', 'Male'], fontsize=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Roughly the same proportion of males and females die of heart failure."},{"metadata":{"trusted":true},"cell_type":"code","source":"median_death = df_master[df_master['DEATH_EVENT']==1]['ejection_fraction'].median()\nmedian_life = df_master[df_master['DEATH_EVENT']==0]['ejection_fraction'].median()\nprint(\"Median Ejection Fraction for Death: \", median_death, '\\nMedian ejection Fraction for Survivors: ', median_life, '\\nDifference: ', median_death-median_life)\n\nax = sns.violinplot(data=df_master, x='DEATH_EVENT', y='ejection_fraction')\nax.set_title('Ejection Fraction Deaths vs Survivors', fontsize=20)\nax.set_xticklabels(['Survivor', 'Death'], fontsize=14)\nax.set_xlabel('Death Status', fontsize=14)\nax.set_ylabel('Ejection Fraction', fontsize=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems lower ejection fraction seems to be associated with greater chance of heart failure according to our sample data."},{"metadata":{"trusted":true},"cell_type":"code","source":"median_death = df_master[df_master['DEATH_EVENT']==1]['serum_creatinine'].median()\nmedian_life = df_master[df_master['DEATH_EVENT']==0]['serum_creatinine'].median()\nprint(\"Median Death: \", median_death, '\\nMedian Life: ', median_life, '\\nDifference: ', median_death-median_life)\n\nax = sns.violinplot(data=df_master, x='DEATH_EVENT', y='serum_creatinine')\nax.set_title('Serum Creatinine Deaths vs Survivors', fontsize=20)\nax.set_xticklabels(['Survivor', 'Death'], fontsize=14)\nax.set_ylabel('Serum Creatinine', fontsize=14)\nax.set_xlabel('Death Status', fontsize=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Serum creatinine levels seem to be very similar, though the deaths have many more outliers on the high end."},{"metadata":{"trusted":true},"cell_type":"code","source":"median_death = df_master[df_master['DEATH_EVENT']==1]['time'].median()\nmedian_life = df_master[df_master['DEATH_EVENT']==0]['time'].median()\nprint(\"Median Death: \", median_death, '\\nMedian Life: ', median_life, '\\nDifference: ', median_death-median_life)\n\nax = sns.violinplot(data=df_master, x='DEATH_EVENT', y='time')\nax.set_title('Time Deaths vs Survivors', fontsize=20)\nax.set_xticklabels(['Survivor', 'Death'], fontsize=14)\nax.set_ylabel('Time', fontsize=14)\nax.set_xlabel('Death Status', fontsize=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can clearly see the time variable is widely dispersed and does not follow a normal distribution especially for survivors. Now let's perform some multivariate analysis to see if there is anything interesting there."},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.scatterplot(x=df_master['serum_creatinine'], y=df_master['age'], hue=df_master['DEATH_EVENT'])\nax.set_title('Serum Creatinine vs Age', fontsize=20)\n#ax.set_xticklabels(['Survivor', 'Death'], fontsize=14)\nax.set_ylabel('Age', fontsize=14)\nax.set_xlabel('Serum Creatinine', fontsize=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Across all age levels we see a greater concentration of survivors having lower serum creatinine levels, with many deaths seeming to be associated with slightly greater levels of serum creatinine."},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.scatterplot(data=df_master, x='age', y='ejection_fraction', hue='DEATH_EVENT')\nax.set_title('Ejection Fraction vs Age', fontsize=20)\nax.set_ylabel('Age', fontsize=14)\nax.set_xlabel('Ejection Fraction', fontsize=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No clear trends here, though it seems there is a greater concentration of deaths at lower ejection fraction levels at all ages."},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.scatterplot(data=df_master, x='age', y='serum_sodium', hue='DEATH_EVENT')\nax.set_title('Serum Sodium vs Age', fontsize=20)\nax.set_ylabel('Age', fontsize=14)\nax.set_xlabel('Serum Sodium', fontsize=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.violinplot(data=df_master, x='sex', y='ejection_fraction', hue='DEATH_EVENT')\nax.set_title('Sex vs Ejection Fraction', fontsize=20)\nax.set_xticklabels(['Female', 'Male'], fontsize=12)\nax.set_ylabel('Ejection Fraction', fontsize=14)\nax.set_xlabel('Sex', fontsize=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It appears females overall have a slightly higher ejection fraction on average than males, slightly more notable in the deaths.  The female deaths have a more dispersed ejection fraction than male deaths. Lower ejection fraction appears slightly correlated to higher chance of heart failure, and this seems true for both males and females. Males seem to have lower overall ejection fraction than females in the sample."},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.FacetGrid(df, row='sex', col='diabetes')\ng.map(sns.countplot, 'DEATH_EVENT')\ng.set_axis_labels(\"Death Event\", \"Count\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The ratio of deaths/survivors for males without diabetes is roughly 2x, compared to ~2.5x for males with diabetes.  For females, the ratio of deaths/survivors is higher in people without diabetes vs with diabetes."},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing / Modeling"},{"metadata":{},"cell_type":"markdown","source":"I will first drop the variables that seem to be the least correlated to the dependent variable."},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_master_scaled.drop(['DEATH_EVENT', 'sex', 'anaemia', 'diabetes', 'high_blood_pressure', 'platelets', 'smoking'], axis=1)\ny = df[['DEATH_EVENT']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Split the data into training and testing sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import the models to be used\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nimport xgboost\n\n# Import the evaluation methodologies to be used\nfrom sklearn.metrics import classification_report, confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create a dictionary containing the various models (method borrowed from another Kaggle user - currently searching for original author to provide credit)\n\nmodel_list = dict()\nmodel_list['Decision Tree'] = DecisionTreeClassifier(class_weight={0:1,1:2})\nmodel_list['Random Forest'] = RandomForestClassifier(class_weight={0:1,1:2})\nmodel_list['Logreg'] = LogisticRegression()\nmodel_list['GradientBoost'] = GradientBoostingClassifier()\nmodel_list['AdaBoost'] = AdaBoostClassifier()\nmodel_list['XGBoost'] = xgboost.XGBClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# iterate through the models in the dictionary and fit the training data to each model\nfor model in model_list:\n    model_list[model].fit(X_train, y_train)\n    print(model + ' : fit')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# iterate through the models in the dictionary and print a classification report to evaluate the models\n\nprint(\"Train set prediction\")\nfor item in model_list:\n        \n    print(item)\n    model = model_list[item]\n    y_train_pred = model.predict(X_train)\n    print(confusion_matrix(y_train, y_train_pred))\n    print(classification_report(y_train, y_train_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# confusion matrix for the logistical regression\n\nmodel = model_list['Logreg']\ny_train_pred = model.predict(X_train)\narg_train = {'y_true':y_train, 'y_pred':y_train_pred}\nsns.heatmap(confusion_matrix(**arg_train), annot=True, cmap='mako')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# confusion matrix for the adaboost model\n\nmodel = model_list['AdaBoost']\ny_train_pred = model.predict(X_train)\narg_train = {'y_true':y_train, 'y_pred':y_train_pred}\nsns.heatmap(confusion_matrix(**arg_train), annot=True, cmap='mako')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now the testing set\n\nprint(\"Test set prediction\")\nfor item in model_list:\n        \n    print(\"                         \"+item)\n    model = model_list[item]\n    y_test_pred = model.predict(X_test)\n    print(confusion_matrix(y_test, y_test_pred))\n    print(classification_report(y_test, y_test_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# confusion matrices for each model in model_list\n\nfor item in model_list:\n        \n    #print(item)\n    model = model_list[item]\n    y_test_pred = model.predict(X_test)\n    ax = sns.heatmap(confusion_matrix(y_test, y_test_pred), annot=True, cmap='mako')\n    ax.set_title('Confusion Matrix: '+ item)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems the XGBoost model has the highest average recall score of the models with the test set, followed closely by the random forest and logistical regression models.  Now let's plot the feature importances for each model."},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot graph of feature importances\nfor item in model_list:\n        \n    if item is not \"Logreg\":\n        feat_importances = pd.Series(model_list[item].feature_importances_, index=X.columns)\n        ax = feat_importances.nlargest(10).plot(kind='barh')\n        ax.set_title('Feature Importances: '+ item)\n        plt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Time appears to be the most relevant feature in each of the models, significantly outweighing the other features in some of the models.  Creatinine phosphokinase and serum creatinine are much more important in the Adaboost model."},{"metadata":{},"cell_type":"markdown","source":"I hope you enjoyed my exploratory analysis and basic model development with the heart disease dataset.  There is quite a bit a bit more that can be done to further explore these data and improve the models, which I will likely explore in further revisions to this analysis.  Any feedback/suggestions to help improve my work would be greatly appreciated!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}