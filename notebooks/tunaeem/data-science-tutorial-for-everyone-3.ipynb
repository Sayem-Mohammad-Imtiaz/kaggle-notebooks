{"cells":[{"metadata":{"_uuid":"9df526bbceeb04348083c36c82469903e939e783"},"cell_type":"markdown","source":"**Data Science Tutorial For Everyone #3**\n\n**Cleaning Data:**\n\n* Diagnose data for cleaning\n* Exploratory data analysis\n* Visual exploratory data analysis\n* Tidy data\n* Pivoting data\n* Concatenating data\n* Data types\n* Missing data and testing with assert\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O\nimport matplotlib.pyplot as plt\nimport seaborn as sns  # visualization tool\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"**DIAGNOSE DATA for CLEANING**\n\nWe need to diagnose and clean data before exploring. \nUnclean data:\n\n* Column name inconsistency like upper-lower case letter or space between words\n* missing data\n* different language\n\nWe will use head, tail, columns, shape and info methods to diagnose data"},{"metadata":{"trusted":true,"_uuid":"f2e4c8770b50cf1905e05d6c2eed7e51b5c04b50"},"cell_type":"code","source":"data = pd.read_csv('../input/pokemon.csv')\ndata.head()  # head shows first 5 rows","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5291d9165cd38985174ae36ed6c20ecc85f4fe91"},"cell_type":"code","source":"# tail shows last 5 rows\ndata.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"027a91a987d13f3c9467050ad1394cdc2abbe188"},"cell_type":"code","source":"# columns gives column names of features\ndata.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"00dd8640bf51ed504350ce716973baad39badab0"},"cell_type":"code","source":"# shape gives number of rows and columns in a tuble\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3fcc1523a035a83f4467f71b5b83b466405d345c"},"cell_type":"code","source":"# info gives data type like dataframe, number of sample or row, number of feature or column, feature types and memory usage\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3d7edc651d11c298f6d33012dfbf7e8f328785dd"},"cell_type":"markdown","source":"**EXPLORATORY DATA ANALYSIS**\n\nvalue_counts(): Frequency counts \noutliers: the value that is considerably higher or lower from rest of the data\n\n* Lets say value at 75% is Q3 and value at 25% is Q1.\n* Outlier are smaller than Q1 - 1.5(Q3-Q1) and bigger than Q3 + 1.5(Q3-Q1). (Q3-Q1) = IQR \n* We will use describe() method. Describe method includes:\n* count: number of entries\n* mean: average of entries\n* std: standart deviation\n* min: minimum entry\n* 25%: first quantile\n* 50%: median or second quantile\n* 75%: third quantile\n* max: maximum entry\n\nWhat is quantile?\n\n* 1,4,5,6,8,9,11,12,13,14,15,16,17\n* The median is the number that is in middle of the sequence. In this case it would be 11.\n* The lower quartile is the median in between the smallest number and the median i.e. in between 1 and 11, which is 6.\n* The upper quartile, you find the median between the median and the largest number i.e. between 11 and 17, which will be 14 according to the question above."},{"metadata":{"trusted":true,"_uuid":"314b875aeaeb0277932a4541a3720be19850333e"},"cell_type":"code","source":"# For example lets look frequency of pokemom types\nprint(data['Type 1'].value_counts(dropna =False))  # if there are nan values that also be counted\n# As it can be seen below there are 112 water pokemon or 70 grass pokemon","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad1702661a87be7884b07e5d9b216aeadc81d0cd"},"cell_type":"code","source":"# For example max HP is 255 or min defense is 5\ndata.describe() #ignore null entries","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c025a3c2ad4d35a50f659d8e66189568303e2dae"},"cell_type":"markdown","source":"**VISUAL EXPLORATORY DATA ANALYSIS**\n\n* Box plots: visualize basic statistics like outliers, min/max or quantiles"},{"metadata":{"trusted":true,"_uuid":"4b71c51cb4bd1a190221af93e96c37bc724890d2"},"cell_type":"code","source":"# For example: compare attack of pokemons that are legendary  or not\n# Black line at top is max\n# Blue line at top is 75%\n# Red line is median (50%)\n# Blue line at bottom is 25%\n# Black line at bottom is min\n# There are no outliers\ndata.boxplot(column='Attack',by = 'Legendary')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c37af7a35b91344a62f8cb596747139af0401bdf"},"cell_type":"markdown","source":"**TIDY DATA**\n\nWe tidy data with melt(). Describing melt is confusing. Therefore lets make example to understand it."},{"metadata":{"trusted":true,"_uuid":"3dd16156e4b82e8d0ec351acc261ea803b9090e5"},"cell_type":"code","source":"# Firstly I create new data from pokemons data to explain melt nore easily.\ndata_new = data.head()    # I only take 5 rows into new data\ndata_new","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"08a6273bc25f1a2bbc2b8751d39390c3d10bae54"},"cell_type":"code","source":"# lets melt\n# id_vars = what we do not wish to melt\n# value_vars = what we want to melt\nmelted = pd.melt(frame=data_new,id_vars = 'Name', value_vars= ['Attack','Defense'])\nmelted","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e10ee4b8a1bc5c622b346c6c2b71155646ffa1de"},"cell_type":"markdown","source":"**PIVOTING DATA**\n\nReverse of melting."},{"metadata":{"trusted":true,"_uuid":"0e5adb1bc566d45628a2a5408a012ec85a80ac75"},"cell_type":"code","source":"# Index is name\n# I want to make that columns are variable\n# Finally values in columns are value\nmelted.pivot(index = 'Name', columns = 'variable',values='value')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3f0328c8c4607a87b29000be0644df45c5638f4d"},"cell_type":"markdown","source":"**CONCATENATING DATA**\n\nWe can concatenate two dataframe"},{"metadata":{"trusted":true,"_uuid":"674ff27cd93709a65cbfa6d1378ca8b7a34974ed"},"cell_type":"code","source":"# Firstly lets create 2 data frame\ndata1 = data.head()\ndata2= data.tail()\nconc_data_row = pd.concat([data1,data2],axis =0,ignore_index =True) # axis = 0 : adds dataframes in row\nconc_data_row","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"097d6469fb47ff0ebe8c28be4014d927fa5de0bb"},"cell_type":"code","source":"data1 = data['Attack'].head()\ndata2= data['Defense'].head()\nconc_data_col = pd.concat([data1,data2],axis =1) # axis = 1 : adds dataframes in row\nconc_data_col","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3637ea3da27155bf5d9b4ba31bf600ff2a94d35a"},"cell_type":"markdown","source":"**DATA TYPES**\n\nThere are 5 basic data types: object(string),booleab, integer, float and categorical. \nWe can make conversion data types like from str to categorical or from int to float \nWhy is category important:\n\n* make dataframe smaller in memory\n* can be utilized for anlaysis especially for sklear(we will learn later)\n"},{"metadata":{"trusted":true,"_uuid":"94ea2d08c715a0267bcfcadce0e2f7f7f4f4d21b"},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c36908ce9f169064fba5429cceca6abc0e7650ec"},"cell_type":"code","source":"# lets convert object(str) to categorical and int to float.\ndata['Type 1'] = data['Type 1'].astype('category')\ndata['Speed'] = data['Speed'].astype('float')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"862d8ad1668cee4e7aad4c1848496b92f22f3354"},"cell_type":"code","source":"# As you can see Type 1 is converted from object to categorical\n# And Speed ,s converted from int to float\ndata.dtypes","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c128de84b96a8b6ea495e947480b796ed1722e18"},"cell_type":"markdown","source":"**MISSING DATA and TESTING WITH ASSERT**\n\nIf we encounter with missing data, what we can do:\n\n* leave as is\n* drop them with dropna()\n* fill missing value with fillna()\n* fill missing values with test statistics like mean \n* Assert statement: check that you can turn on or turn off when you are done with your testing of the program"},{"metadata":{"trusted":true,"_uuid":"9597026a1f0a9635da25ba0fd23ebad522e69932"},"cell_type":"code","source":"# Lets look at does pokemon data have nan value\n# As you can see there are 800 entries. However Type 2 has 414 non-null object so it has 386 null object.\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fddfda28c0fa4178bb646a16124ad24975da9dc8"},"cell_type":"code","source":"# Lets chech Type 2\n# dropna = True : We drop non values\n# We want to see nan values  \ndata[\"Type 2\"].value_counts(dropna =False)\n# As you can see, there are 386 NAN value","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"17b209a5df9fee8912d1bfbcb5d06b50a53120c0"},"cell_type":"code","source":"# Lets drop nan values\ndata1=data   # also we will use data to fill missing value so I assign it to data1 variable\ndata1[\"Type 2\"].dropna(inplace = True)  # inplace = True means we do not assign it to new variable. Changes automatically assigned to data\n# So does it work ?","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9b8cb678ee4cb881c97e6e2576149fbb52eb4339"},"cell_type":"code","source":"#  Lets check with assert statement\n# Assert statement:\nassert 1==1 # return nothing because it is true","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7df78a78acf6db0736f1ce7c0e99106674bfc2fd"},"cell_type":"code","source":"# In order to run all code, we need to make this line comment\n# assert 1==2 # return error because it is false","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"05438eb99f89271be08c86aee9f970e79d78309b"},"cell_type":"code","source":"assert  data['Type 2'].notnull().all() # returns nothing because we drop nan values\n#  In 33, we dropped nan values and we are asking \"Are there nan values?\" here.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0b95c06c47381c45913b6505bf63cfd928efe143"},"cell_type":"code","source":"data[\"Type 2\"].fillna('empty',inplace = True) \n# if there are nan value, we are filling with \"empty\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bb78728c96844cdd5d2b9ac9fd4a6d7240c4c31e"},"cell_type":"code","source":"assert  data['Type 2'].notnull().all() # returns nothing because we do not have nan values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ddc3dc304f805539d88ec2211a798bf47e941f74"},"cell_type":"code","source":"# # With assert statement we can check a lot of thing. For example\n# assert data.columns[1] == 'Name'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"55c873a4c78d0a6f8277a9d96277bc8ca63b4a19"},"cell_type":"markdown","source":"**In this part, you learn:**\n\n* Diagnose data for cleaning\n* Exploratory data analysis\n* Visual exploratory data analysis\n* Tidy data\n* Pivoting data\n* Concatenating data\n* Data types\n* Missing data and testing with assert\n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}