{"nbformat_minor":1,"cells":[{"cell_type":"code","metadata":{"collapsed":true},"source":"import pandas as pd \nimport numpy as np \nfrom sklearn.model_selection import train_test_split \nfrom scipy.stats.stats import pearsonr\nfrom sklearn.linear_model import LogisticRegression \nfrom sklearn.model_selection import GridSearchCV\nimport sklearn.metrics \n\nimport matplotlib.pyplot as plt\n\ndef roc_auc(pred, act, plot=True, label = \"curve\"):\n    prob = pred/pred.max() #normalize\n    fpr, tpr, threshold = sklearn.metrics.roc_curve(act, prob, drop_intermediate=True)    \n    auc = sklearn.metrics.auc(fpr, tpr)\n\n    if plot:\n        plt.scatter(x=fpr, y=tpr, color='navy')\n        rcolor = tuple(np.random.rand(3,1)[:,0])\n        plt.plot(fpr, tpr, c=rcolor, lw=2, label=label + ' (AUC = %0.3f)' % auc)\n        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n        plt.xlim([0.0, 1.0])\n        plt.ylim([0.0, 1.05])\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        plt.title('ROC Curve')\n        plt.legend(loc=\"lower right\")\n        plt.show()\n\n    return auc\n\n### laptop\n#datain_dir = \"~/Data/diabetes/\"\n#datain_col_dir = '~/Data/diabetes/'\n#dataout_dir = '~/Data/diabetes/'\n\n### kaggle\n\ndatain_dir = '../input/diabetes/'\ndatain_col_dir = '../input/diabetes-readmissions-column-annotation/'\ndataout_dir = ''\n","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{},"source":"# Read in the data"},{"cell_type":"code","metadata":{},"source":"df_raw_all = pd.read_csv(datain_dir + 'diabetic_data.csv') \ndf_raw = df_raw_all.sample(10000)\ndf_raw = df_raw.replace('?', np.nan) \ndf_raw.shape","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{},"source":"# How many values are missing in patient records?"},{"cell_type":"code","metadata":{},"source":"pt_sparsity = df_raw.isnull().apply(sum, axis=1)\n%matplotlib inline\nmyhist = pt_sparsity.hist()","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{},"source":"No need to drop patients due to missing values. 3 out of 50 missing values is not bad at all.\n\n# Explore the variables, compile information about them"},{"cell_type":"code","metadata":{"collapsed":true},"source":"col_data = df_raw.apply(lambda s: set(s.unique()), axis=0).to_frame('uni_val')\ncol_data['nan_rat'] = df_raw.isnull().sum(axis=0)/len(df_raw)\ncol_data['n_uni_vals'] = col_data.uni_val.apply(len)\ncol_data['uni_vals_str'] = col_data[col_data.n_uni_vals<2000].uni_val.astype(str)\ncol_data = col_data.drop('uni_val', axis=1)\ncol_data['var_type'] = np.nan\ncol_data.to_csv(dataout_dir + \"columns_raw.csv\")","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{},"source":"# Manual annotation of columns\nI manually took columns_raw.csv and annotated columns based on whether they were ordered or categorical.  I saved my annotated file as columns.csv.  I will read this in later in the notebook."},{"cell_type":"code","metadata":{},"source":"col_data = pd.read_csv(datain_col_dir + \"columns.csv\", index_col=0)\ncol_data.sample(10)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{},"source":"#TODO recapture medical specialty\nspec_counts = df_raw.medical_specialty.value_counts()\nspec_counts.head(5).to_frame('num patients')","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{},"source":"spec_thresh = 5\nfor (spec, count) in spec_counts.head(spec_thresh).iteritems():\n    new_col = 'spec_' + str(spec)\n    df_raw[new_col] = (df_raw.medical_specialty == spec)\n    \ndf_raw.filter(regex='spec').sample(10)","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{},"source":"# Identify the most common diagnoses"},{"cell_type":"code","metadata":{},"source":"diag_counts = (df_raw.diag_1.value_counts() + df_raw.diag_2.value_counts() + df_raw.diag_3.value_counts()).sort_values(ascending=False)\ndiag_counts.head(10).to_frame('num patients w diag')","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{},"source":"# Generate boolean features for top N diagnoses"},{"cell_type":"code","metadata":{},"source":"diag_thresh = 10\nfor (icd9, count) in diag_counts.head(diag_thresh).iteritems():\n    new_col = 'diag_' + str(icd9)\n    df_raw[new_col] = (df_raw.diag_1 == icd9)|(df_raw.diag_2 == icd9)|(df_raw.diag_3 == icd9)\n    \ndf_raw.filter(regex='diag_').sample(10)","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{},"source":"# Clean the data"},{"cell_type":"code","metadata":{},"source":"df_raw.age.sample(10)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{},"source":"df_raw2 = pd.DataFrame(df_raw, copy=True) #preserve df_raw so I can rerun this step\ndf_raw2['age'] = df_raw2.age.str.extract('(\\d+)-\\d+')\n\nto_drop = col_data[col_data.var_type.str.contains('drop')].index\ndf_raw2.drop(to_drop, axis=1, inplace=True)\n\n#break out categorical variables into binaries\ncat_cols = col_data[col_data.var_type.str.contains('cat')].index\ndf_raw2 = pd.get_dummies(df_raw2, columns=cat_cols)\n\n#dropping these leaves up with one binary variable, ideal for simplicity\ndf_raw2.drop(['readmitted_<30','readmitted_>30'], axis=1, inplace=True)\n\n#cleaning up outcome variable\ndf_raw2['is_readmitted'] = (df_raw2.readmitted_NO == 0)\ndf_raw2.drop('readmitted_NO', axis=1, inplace=True)\n\n#ta daaaaaah, the data is ready to go\ndf = pd.DataFrame(df_raw2)\ndf.shape","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{},"source":"df.age.sample(10)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{},"source":"df.sample(15).sample(7, axis=1)","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{},"source":"# Examine outcome variable"},{"cell_type":"code","metadata":{},"source":"df.is_readmitted.value_counts()","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{},"source":"# Define this machine learning problem, impute, set aside test data"},{"cell_type":"code","metadata":{"collapsed":true},"source":"#partition training and test data, one balanced training set, all remaining for testing \noutcome_column = 'is_readmitted' \n\n#Imputing with outlying value since we are focusing on tree based methods\ndff = df.fillna(df.mean) # using mean rather than -9999 which I use for tree methods \n\n#%% Split data for validation\nX = dff.drop(outcome_column, axis=1) \ny = dff[outcome_column] \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0) ","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{},"source":"# One on one correlations"},{"cell_type":"code","metadata":{},"source":"##### SINGULAR LOGISTIC REGRESSION\ndef apply_pearsonr(col):\n    isnan = col.isnull()\n    xi = col[isnan==False].astype(float)\n    yi = y[isnan==False].astype(float)\n    (r,p) = pearsonr(xi,yi)\n    return (r,p)\n\nres = X.apply(apply_pearsonr).to_frame()\nres['r'] = res[0].apply(lambda x: x[0])\nres['p'] = res[0].apply(lambda x: x[1])\n\nres.drop(0, axis=1).sort_values('p').head(15)\n#TODO - apply bonferoni correction","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{},"source":"# Fit data to Logistic Regression model, using Lasso penalization and gridsearch"},{"cell_type":"code","metadata":{},"source":"C_params = [10**x for x in np.arange(-2.5,2.5,0.1)]\nparam_grid = {\n        'penalty':['l1'], #lasso only\n        'C':C_params\n}\n\nclf = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring='roc_auc', verbose=3, n_jobs=10)\nclf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{},"source":"clf.best_params_","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{},"source":"lr = clf.best_estimator_\nfeat_imp = pd.Series(index=X_train.columns, data=lr.coef_[0])\nfeat_imp.sort_values(ascending=False)","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{},"source":"This looks like noise, it doesn't have any similarity with important tree variables or with what I'd expect."},{"cell_type":"code","metadata":{},"source":"#REDO, with more stringent C value\nlr2 = LogisticRegression(C=.015, penalty='l1')\nlr2.fit(X_train, y_train)\nfeat_imp = pd.Series(index=X_train.columns, data=lr2.coef_[0])\nfeat_imp[feat_imp!=0].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{},"source":"# Assess prediction accuracy"},{"cell_type":"code","metadata":{},"source":"#%% assess accuracy\npred = lr.predict_proba(X_test)[:,1]\nfpr, tpr, threshold = sklearn.metrics.roc_curve(y_test, pred, drop_intermediate=True)    \ndf_res = pd.DataFrame(data={'fpr':fpr, 'tpr':tpr, 'threshold':threshold})\ndf_res = df_res[['threshold','fpr','tpr']]\nsklearn.metrics.auc(fpr, tpr)\nt=y.value_counts()[1]/y.value_counts().sum()\nsklearn.metrics.f1_score(y_test, pred>t)\nsklearn.metrics.accuracy_score(y_test, pred>t)\n\nroc_auc(pred, y_test)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{},"source":"pd.options.mode.chained_assignment = None\npred = lr.predict_proba(X_test)[:,1]\nfpr, tpr, threshold = sklearn.metrics.roc_curve(y_test, pred, drop_intermediate=True)    \ndf_res = pd.DataFrame(data={'fpr':fpr, 'tpr':tpr, 'threshold':threshold})\ndf_res = df_res[['threshold','fpr','tpr']]","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{},"source":"df_res['accuracy'] = df_res.threshold.apply(lambda t: sklearn.metrics.accuracy_score(y_test, pred>t))\ndf_res['precision'] = df_res.threshold.apply(lambda t: sklearn.metrics.precision_score(y_test, pred>t))\ndf_res['recall'] = df_res.threshold.apply(lambda t: sklearn.metrics.recall_score(y_test, pred>t))\ndf_res['f1'] = df_res.threshold.apply(lambda t: sklearn.metrics.f1_score(y_test, pred>t))\ndf_res['specificity'] = df_res.fpr.apply(lambda fpr: 1-fpr)\n\npt_opt = df_res[df_res.f1 == df_res.f1.max()].iloc[0]\npt_opt","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{},"source":"plt.rcParams[\"figure.figsize\"] = (20,6)\ndf_res.plot(x='threshold')","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true},"source":"","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"nbconvert_exporter":"python","version":"3.6.2","name":"python","mimetype":"text/x-python","codemirror_mode":{"version":3,"name":"ipython"},"pygments_lexer":"ipython3","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat":4}