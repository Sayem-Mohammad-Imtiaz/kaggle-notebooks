{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/sms-spam-collection-dataset/spam.csv', encoding='latin-1')\nprint(data.shape)\ndata.describe()\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data.isnull().sum())\nprint(data['Unnamed: 2'].unique())\nprint(data['Unnamed: 3'].unique())\nprint(data['Unnamed: 4'].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Doesn't look like any significant information in these three columns -> \"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"\nLet's drop them.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1, inplace=True)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.rename(columns={'v1': 'target', 'v2': 'text'}, inplace=True)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data exploration**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data[data['target'] == 'ham'].count())\nprint(data[data['target'] == 'spam'].count())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nplt.figure()\ndata['target'].hist()\nplt.title('Counts of spam and ham sms messages')\nplt.xlabel('Message type')\nplt.ylabel('Count')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looks like there is considerable imbalance in the target classes counts. Maybe to try to address that by upsampling/downsampling later.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.utils import resample\n\ndata['label'] = data['target'].map({ 'ham': 0, 'spam' : 1 })\n\n# split to test and train sets\nX = data['text']\ny = data['label']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n#upsampling\ndata_minority = data[data.label == 1]\ndata_majority = data[data.label == 0]\nprint(data_minority.shape)\nprint(data_majority.shape)\nmajority_samples = data_majority.shape[0]\n\nminority_upsampled = resample(data_minority, replace=True, n_samples=majority_samples, random_state=42)\ndata_upsampled = pd.concat([data_majority, minority_upsampled])\nprint(data_upsampled.shape)\nprint(data_upsampled['label'].value_counts())\n\nX_upsampled = data_upsampled['text']\ny_upsampled = data_upsampled['label']\nX_train_upsampled, X_test_upsampled, y_train_upsampled, y_test_upsampled = train_test_split(X_upsampled, y_upsampled, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import roc_auc_score\n\n\"\"\"\nHelper function for evaluating model performance.\nEven though we compute multiple metrics, we will use f1_score as the metric to decide model performance as it incorporates both precision and recall.\n\"\"\"\ndef evaluate(model, y_true, y_pred):\n    f1 = f1_score(y_true, y_pred)\n    cm = confusion_matrix(y_true, y_pred)\n    p = precision_score(y_true, y_pred)\n    r = recall_score(y_true, y_pred)\n    roc = roc_auc_score(y_true, y_pred)\n    print(\"Results for {0}:\\n\".format(model))\n    print(\"precision={0},\\nrecall={1},\\nf1_score={2},\\nroc_auc_score={3}\".format(p, r, f1, roc))\n    print(\"confusion matrix=\\n{0}\".format(cm))\n    print(\"\\n-----------------------------------------\\n\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"My notes-\nUse multiple classifiers and evaluate them. Then pick the one that performs best and use GridSearchCV to fine tune it. \n\nMethodology:\nUse multiple classifiers and evaluate them. Then pick the one that performs best and use GridSearchCV to fine tune it. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nimport time\n\n\ndef run_classification(X_train, X_test, y_train, y_test):\n    classifiers = {\n        'decision_tree' : DecisionTreeClassifier(),\n        'random_forest' : RandomForestClassifier(),\n        'svm' : SVC(),\n        'multinomial_nb' : MultinomialNB(),\n        'logistic_regression' : LogisticRegression()\n    }\n\n    for name, clf in classifiers.items():\n\n        pipeline = Pipeline([\n             ('count', CountVectorizer()),\n             ('tfidf', TfidfTransformer()),\n             (name, clf),\n        ])\n\n        parameters = {\n            'count__ngram_range': [(1, 1), (1, 2), (2, 2), (2, 3), (3, 3)],\n            'count__stop_words': ['english', None],\n            'tfidf__use_idf': (True, False),\n        }\n\n        grid = GridSearchCV(pipeline, parameters, cv=3, n_jobs=-1)\n        start = time.time()\n        grid.fit(X_train, y_train)\n        end = time.time()\n        print(\"Time to train {0}: {1}\".format(name, end - start))\n\n        y_pred = grid.predict(X_test)\n        evaluate(name, y_test, y_pred)\n        #break\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"run_classification(X_train, X_test, y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Based on f1_score, SVM performs the best on this dataset while MultinomialNB performs the worst due to its low recall score.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"run_classification(X_train_upsampled, X_test_upsampled, y_train_upsampled, y_test_upsampled)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Upsampling seems to increase the performance of all the models significantly. All models have a very high f1_score after upsampling the minority class. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}