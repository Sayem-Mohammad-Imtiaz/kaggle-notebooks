{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n%matplotlib inline\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport gc\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nimport lightgbm as lgb\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"INPUT_DIR = \"../input\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7de6be4335f6dd4b0409bf21a16f46ac353a0578"},"cell_type":"code","source":"df_train = pd.read_csv(os.path.join(INPUT_DIR, \"voice.csv\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"82c53dd0f74086be863f2ef04d786e6bc60b37c0"},"cell_type":"markdown","source":" ## explore the training set data"},{"metadata":{"trusted":true,"_uuid":"c25273b7574875695da33a89fd1734fb1dfd64d9"},"cell_type":"code","source":"df_train.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e321d5eddaf9263b36a1d84a5a557dba8dd3753f"},"cell_type":"code","source":"df_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6dd74a80a200a273146528eda85d9e13ce56ca43"},"cell_type":"code","source":"FEATURE_COLS = ['meanfreq', 'sd', 'median', 'Q25', 'Q75', 'IQR', 'skew', 'kurt',\n       'sp.ent', 'sfm', 'mode', 'centroid', 'meanfun', 'minfun', 'maxfun',\n       'meandom', 'mindom', 'maxdom', 'dfrange', 'modindx']\nTARGET_COL = 'label'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9045be1c608d29e6ca838b535b2290f74d4fffd8"},"cell_type":"code","source":"df_train.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"17f75d65c2bd26196a314df5cc2e64c2db5e9f58"},"cell_type":"code","source":"df_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b41f3ce61da476315a2827513884568c3e51ed0b"},"cell_type":"code","source":"df_train['label'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b8efaf18e297a2cd9a69e48acac2e3276c560a63"},"cell_type":"code","source":"df_train.hist(figsize=(15,15))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"47e23c18004ceab0e3f2c19b68f5c2d1af98ed9c"},"cell_type":"code","source":"corr = df_train.corr()\nsns.heatmap(corr, xticklabels=corr.columns.values, yticklabels=corr.columns.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c558576afd624eef710e6714744cee3e7c78a6b9"},"cell_type":"code","source":"for c in FEATURE_COLS:\n    plt.figure()\n    plt.hist(df_train[df_train[TARGET_COL] == 'male'][c], 10, alpha=0.5, label='male')\n    plt.hist(df_train[df_train[TARGET_COL] == 'female'][c], 10, alpha=0.5, label='female')\n    plt.legend(loc='upper right')\n    plt.title(c)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6ade18a2228eca398c04d1fa63e3e1eb72366696"},"cell_type":"code","source":"# change label to numeric\ndf_train['label'] = df_train['label'].map(lambda x: 1 if x == 'female' else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e051c0e0718c01dc9fe7880c1c929dc031035fe"},"cell_type":"markdown","source":"## LightGBM"},{"metadata":{"trusted":true,"_uuid":"4a1e29e996aaac7516476e5a5420c61ba7dc61ff"},"cell_type":"code","source":"def train_with_lgbm(df, FCOLS, DCOLS, TGT_COL):\n    print('training on columns {0}\\ntreating {1} as categorial'.format(FCOLS, DCOLS))\n    \n    X = np.array(df[FCOLS])\n    y = df[TGT_COL].values\n    \n    print(\"train dims: {0}\".format(X.shape))\n\n    X_1, X_test, y_1, y_test = train_test_split(X, y, test_size=0.2, random_state = 12)\n    X_train, X_valid, y_train, y_valid = train_test_split(X_1, y_1, test_size=0.2, random_state = 12)\n    del X, y, X_1, y_1; gc.collect();\n\n    # prepare lgb datasets\n    d_train = lgb.Dataset(X_train, label=y_train)\n    d_valid = lgb.Dataset(X_valid, label=y_valid) \n    watchlist = [d_train, d_valid]\n\n    # set model params\n    params = {\n        'objective': 'binary',\n        'is_unbalanced': False,\n        'boosting': 'gbdt',\n    #           'metric': 'rmse',\n    #           'metric': 'multi-logloss',\n        'num_leaves': 110,\n        'max_depth': 11,\n        'learning_rate': 0.01,\n        'bagging_fraction': 0.9,\n        'feature_fraction': 0.8,\n        'min_split_gain': 0.01,\n        'min_child_samples': 150,\n        'min_child_weight': 0.1,\n        'verbosity': -1,\n        'data_random_seed': 3,\n    }\n\n    model = lgb.train(\n        params,\n        train_set=d_train,\n        valid_sets=watchlist,\n        feature_name=FCOLS,\n        categorical_feature=DCOLS,\n        verbose_eval=100,\n        num_boost_round=10000,\n        early_stopping_rounds=200,\n    )\n\n    return model, X_test, y_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b1db9e37bab486571fa8bcabfa309b6a34cf6727"},"cell_type":"code","source":"model, X_test, y_test = train_with_lgbm(df_train, FEATURE_COLS, [], TARGET_COL)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d43e7ceccf8d48f928792ff9a3c08d4e8bbfe81"},"cell_type":"code","source":"def evaluate_model(model, X_test, y_test, FCOLS, is_multiclass, show_LGBM_feature_importance=False):\n#     pdb.set_trace()\n    if show_LGBM_feature_importance:\n        print(\"Feature Importance:\\n{0}\".format(pd.DataFrame(index=FCOLS, data=np.sort(model.feature_importance(importance_type='gain')))))\n\n    y_pred = model.predict(X_test)\n#     print(y_pred[0:10])\n    if is_multiclass:\n        # since multiclass predictions give us proba of each label...\n        y_pred = np.array([x.argmax() for x in y_pred])\n    else:\n        # since regression models give a continuous range\n        y_pred = np.array([int(round(x)) for x in y_pred])\n#     print(y_pred[0:10])\n\n    print('\\nConfusion Matrix:\\n{0}'.format(confusion_matrix(y_pred, y_test)))\n    print('\\nAccuracy:\\n{0}'.format(accuracy_score(y_pred, y_test)))\n\n\n    plt.hist([pd.Series(y_test),pd.Series(y_pred)], color=['r','b'])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d7cc69422127cf87988ef5cef0fc30beac27fd3"},"cell_type":"code","source":"evaluate_model(model, X_test, y_test, FEATURE_COLS, False, True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7352d953574129de4285efc21092cc33741364d8"},"cell_type":"markdown","source":"## TensorFlow"},{"metadata":{"trusted":true,"_uuid":"b8ddd489ccc8e75d9eb7c45473442da3caa1fb52"},"cell_type":"code","source":"def train_input_fn(features, labels, batch_size):\n    \"\"\"An input function for training\"\"\"\n    # Convert the inputs to a Dataset.\n    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n\n    # Shuffle, repeat, and batch the examples.\n    return dataset.shuffle(1000).repeat().batch(batch_size)\n\n\ndef eval_input_fn(features, labels=None, batch_size=100):\n    \"\"\"An input function for evaluation or prediction\"\"\"\n    features=dict(features)\n    if labels is None:\n        # No labels, use only features.\n        inputs = features\n    else:\n        inputs = (features, labels)\n\n    # Convert the inputs to a Dataset.\n    dataset = tf.data.Dataset.from_tensor_slices(inputs)\n\n    # Batch the examples\n    assert batch_size is not None, \"batch_size must not be None\"\n    dataset = dataset.batch(batch_size)\n\n    # Return the dataset.\n    return dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d05bbc61d0acce881e7a72864b138578a29ed1c"},"cell_type":"code","source":"def df_to_tf_train_test_split(df, feature_cols, label_col, split_size=0.2):\n\n    msk = np.random.rand(len(df)) < (1.0 - split_size)\n    df_trn = df.iloc[msk,:]\n    df_val = df.iloc[~msk,:]\n    \n    print(\"train dims: {0} | val dims: {1}\".format(df_trn.shape, df_val.shape))\n\n    X_train = {}\n    for idx, col in enumerate(feature_cols):\n        X_train[col] = df_trn[col].values\n\n    y_train = df_trn[label_col]    \n    \n    X_val = {}\n    for idx, col in enumerate(feature_cols):\n        X_val[col] = df_val[col].values\n    y_val = df_val[label_col]    \n\n    return X_train, y_train, X_val, y_val","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"73d1d23fc26c6be691063fa0ee86dcb01d307200"},"cell_type":"code","source":"def zscore(mean, std):\n    def normalizer(x):\n        return (x-mean)/std\n    return normalizer\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0400fd68dfd57f73f51650f2299c90652d9802d9"},"cell_type":"code","source":"def generate_feature_columns(df, feature_cols, discreet_cols, scalar_cols):\n    # Feature columns describe how to use the input.\n    tf_fcols = []\n    for col in df.columns:\n        if col in feature_cols:\n            if col in discreet_cols:\n#                 print(\"col {0} as cat\".format(col))\n                if df[col].nunique() > 1000:\n                    tf_fcols.append(\n                        tf.feature_column.indicator_column(\n                            tf.feature_column.categorical_column_with_hash_bucket(\n                                key=col, \n                                hash_bucket_size=10,\n                            )\n                        )\n                    )\n                else:\n                    tf_fcols.append(\n                        tf.feature_column.indicator_column(\n                            tf.feature_column.categorical_column_with_identity(\n                                key=col, \n                                num_buckets=df[col].nunique(),\n                                default_value=0,\n                            )\n                        )\n                    )\n            else:\n                if df[col].dtype == np.int64:\n#                     print(\"col {0} as {1}\".format(col, tf.int64))\n                    tf_fcols.append(tf.feature_column.numeric_column(\n                        key=col, \n                        dtype=tf.int64,\n                        normalizer_fn=zscore(df[col].mean(), df[col].std()),\n                    ))\n                else:\n#                     print(\"col {0} as {1}\".format(col, tf.float64))\n                    tf_fcols.append(tf.feature_column.numeric_column(\n                        key=col, \n                        dtype=tf.float64,\n                        normalizer_fn=zscore(df[col].mean(), df[col].std()),\n                    ))\n\n                    \n    return tf_fcols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8ac4ca6c74f26f2b23cc84f70b740504c47e63d8"},"cell_type":"code","source":"X_train, y_train, X_val, y_val = df_to_tf_train_test_split(df_train, FEATURE_COLS, TARGET_COL) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7dd29e9b4b0aa761b6459525fe5704659cd6c773"},"cell_type":"code","source":"tf_fcols = generate_feature_columns(df_train, FEATURE_COLS, [], FEATURE_COLS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e88a176463511524ea021ca6566c96b30d9ccf8c"},"cell_type":"code","source":"classifier = tf.estimator.DNNClassifier(\n    feature_columns=tf_fcols,\n    hidden_units=[27,9],\n    n_classes=2\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bbb249dbe5463559409520e39ce4613c217cb8dc"},"cell_type":"code","source":"# Train the Model.\nclassifier.train(\n    input_fn=lambda:train_input_fn(\n        X_train, \n        y_train, \n        100\n    ),\n    steps=10000\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7bb5c27126cc561f8235fab20173ba6ad8c87c99"},"cell_type":"code","source":"eval_result = classifier.evaluate(\n    input_fn=lambda:eval_input_fn(X_val, y_val, 100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0656877bd9a2ce58979de95f8bc6e2ce92e1c077"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}