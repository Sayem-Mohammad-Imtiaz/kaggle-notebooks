{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport re\nimport nltk\nfrom numpy import random\nimport wordcloud\nfrom matplotlib import pyplot as plt\nimport os\nfrom nltk.corpus import stopwords\nfrom nltk.corpus import wordnet\nfrom nltk.stem import PorterStemmer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score,confusion_matrix","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfTrain=pd.read_csv(\"../input/covid-19-nlp-text-classification/Corona_NLP_train.csv\",encoding='latin1')\ndfTrain","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed=random.randint(0,1000,1)[0]\ndef randomTweetsSelection(series,randomSeedSelection=True):\n    if randomSeedSelection:\n        random.seed(seed)\n    for i in random.randint(0,len(series),10):\n        print(f\"{i})\\t{series[i]}\\n\")\nrandomTweetsSelection(dfTrain.OriginalTweet)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfTrain.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spaceSplitData=dfTrain.OriginalTweet.apply(lambda x: re.split(\"`| |'\",x.lower()))\nrandomTweetsSelection(spaceSplitData)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stop = stopwords.words('english')\npreprocessedData=spaceSplitData.apply(lambda x:[i for i in x if i not in stop])\nfor i in ['@\\w+','(http)s?:[/\\w.]+','#\\w+','[\\n\\r\\t\\b\\f]','[^\\w\\s]']:\n    r = re.compile(i)\n    preprocessedData=preprocessedData.apply(lambda x:[r.sub(\"\", i) for i in x])\npreprocessedData=preprocessedData.apply(lambda x:[i for i in x if i!=\"\"])\nrandomTweetsSelection(preprocessedData)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word='us'\nfinalWord=PorterStemmer()\nprint(f\"Porter Stemmer: {finalWord.stem(word)}\")\nfrom nltk.stem.snowball import EnglishStemmer\nfinalWord=EnglishStemmer()\nprint(f\"Snowball Stemmer: {finalWord.stem(word)}\")\nfrom nltk.stem import WordNetLemmatizer\nfinalWord = WordNetLemmatizer()\nprint(f\"Word Net Lemmatizer: {finalWord.lemmatize(word,'v')}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def POSTags(x):\n    lemmatizerList=[]\n    finalWord = WordNetLemmatizer()\n    for word,tags in nltk.pos_tag(x):\n        if tags.startswith('J'):\n            lemmatizerList.append(finalWord.lemmatize(word,wordnet.ADJ))\n        elif tags.startswith('V'):\n            lemmatizerList.append(finalWord.lemmatize(word,wordnet.VERB))\n        elif tags.startswith('N'):\n            lemmatizerList.append(finalWord.lemmatize(word,wordnet.NOUN))\n        elif tags.startswith('R'):\n            lemmatizerList.append(finalWord.lemmatize(word,wordnet.ADV))\n        else:          \n            lemmatizerList.append(finalWord.lemmatize(word,random.choice([wordnet.ADJ,wordnet.VERB,wordnet.ADV])))\n    return lemmatizerList\npreprocessedData=preprocessedData.apply(POSTags)\nrandomTweetsSelection(preprocessedData)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wordCloudList=[]\nfor i in preprocessedData:\n    for j in i:\n        wordCloudList.append(j)\nwordCloudText=\" \".join(wordCloudList)\ncovidWordCloud = wordcloud.WordCloud(width = 800, height = 800,\n                background_color ='white',\n                stopwords = wordcloud.STOPWORDS,\n                min_font_size = 10).generate(wordCloudText)\n  \n# plot the WordCloud image                       \nplt.figure(figsize = (8, 8), facecolor = None)\nplt.imshow(covidWordCloud)\nplt.axis(\"off\")\nplt.tight_layout(pad = 0)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentenceFromTokens=preprocessedData.apply(lambda x:\" \".join(x))\ncv=CountVectorizer()\ncv.fit(sentenceFromTokens)\ncvTransformer=lambda:cv.transform(sentenceFromTokens).toarray()\nmnb=MultinomialNB()\nmnb.fit(cvTransformer(),dfTrain.Sentiment)\ndfTest=pd.read_csv(\"../input/covid-19-nlp-text-classification/Corona_NLP_test.csv\",encoding='latin1')\ndfTest","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfTest.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spaceSplitData=dfTest.OriginalTweet.apply(lambda x: re.split(\"`| |'\",x.lower()))\nstop = stopwords.words('english')\npreprocessedData=spaceSplitData.apply(lambda x:[i for i in x if i not in stop])\nfor i in ['@\\w+','(http)s?:[/\\w.]+','#\\w+','[\\n\\r\\t\\b\\f]','[^\\w\\s]']:\n    r = re.compile(i)\n    preprocessedData=preprocessedData.apply(lambda x:[r.sub(\"\", i) for i in x])\npreprocessedData=preprocessedData.apply(lambda x:[i for i in x if i!=\"\"])\npreprocessedData=preprocessedData.apply(POSTags)\nsentenceFromTokens=preprocessedData.apply(lambda x:\" \".join(x))\npred=mnb.predict(cvTransformer())\npred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_score(dfTest.Sentiment,pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_matrix(dfTest.Sentiment,pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}