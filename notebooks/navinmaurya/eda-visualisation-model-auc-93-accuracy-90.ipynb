{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# About this dataset\nAge : Age of the patient\n\nSex : Sex of the patient\n\nexang: exercise induced angina (1 = yes; 0 = no)\n\nca: number of major vessels (0-3)\n\ncp : Chest Pain type chest pain type\n\nValue 1: typical angina\nValue 2: atypical angina\nValue 3: non-anginal pain\nValue 4: asymptomatic\ntrtbps : resting blood pressure (in mm Hg)\n\nchol : cholestoral in mg/dl fetched via BMI sensor\n\nfbs : (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)\n\nrest_ecg : resting electrocardiographic results\n\nValue 0: normal\nValue 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)\nValue 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\nthalach : maximum heart rate achieved\n\ntarget : 0= less chance of heart attack 1= more chance of heart attack","metadata":{}},{"cell_type":"code","source":"import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV,KFold\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics  import accuracy_score,classification_report,roc_auc_score,plot_roc_curve,plot_precision_recall_curve\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=pd.read_csv('/kaggle/input/heart-attack-analysis-prediction-dataset/heart.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EXPLORATORY DATA ANALYSIS","metadata":{}},{"cell_type":"code","source":"data.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isnull().sum()#no missing value","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_var=['sex', 'cp','fbs', 'restecg', 'exng','slp', 'caa', 'thall' ]\ncontinuous_var=['age','chol','trtbps','thalachh','oldpeak',]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## UNIVARIATE ANALYSIS","metadata":{}},{"cell_type":"code","source":"for i in continuous_var:\n    ax = sns.boxplot(data[i])\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### as we can see that the data has some outliers but we will not remove it ,because we might loss some important data and it is a medical data","metadata":{}},{"cell_type":"markdown","source":"### VISUALISATION","metadata":{}},{"cell_type":"code","source":"sns.countplot(data=data,x='output')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### no of more chance ofheart attacked case is higher than less chance of heart attack","metadata":{}},{"cell_type":"code","source":"\nfor i in cat_var:\n    sns.countplot(data=data,x=data[i],hue='output')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"# 1-male has more percent  of heart cases than female                                                                            #2-person having chest pain atypical angina value has higher chance of getting heart attack                                     #3-fps value less than 120 has higher chance of heart attack\n# 4-rest_ecg having ST-T wave normality has higher chance of getting heart attack\n#5-exercise induced angina has less percent of heart attack chances\n#6-a person having zero major vessels has a higher probility of getting heart attack\n","metadata":{}},{"cell_type":"code","source":"for i in continuous_var:\n    plt.figure(figsize=(10,8))\n    sns.histplot(data=data,x=data[i],hue='output',kde=True)\n    plt.show()\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#1-person having age 30-50 and 70+ has more chance of getting heart attack\n#2-person having cholestrol 200+ has high chance of getting heart attack\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,15))\nsns.heatmap(data.corr(),annot=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_output=data.corr()['output'].sort_values(ascending=False)\ncorr_output","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8,8))\ncorr_output.plot(kind='bar',color='green')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### here we can see  how all varaible related to the output(+ correlation,-correlation)","metadata":{}},{"cell_type":"code","source":"sc=StandardScaler()\nscaled_cont=sc.fit_transform(data[continuous_var])\nscaled_cont=pd.DataFrame(scaled_cont,columns=continuous_var)\nscaled_data=pd.concat([scaled_cont,data[cat_var]],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=scaled_data\nY=data['output']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=.30,random_state=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logreg=Pipeline([('logistic',LogisticRegression())])\ndecision=Pipeline([('dt',DecisionTreeClassifier())])\nrandomforest=Pipeline([('rf',RandomForestClassifier())])\nnaivebayes=Pipeline([('nb',GaussianNB())])\nknn=Pipeline([('knn',KNeighborsClassifier())])\ngbc=Pipeline([('gbc',GradientBoostingClassifier())])\nadaboost=Pipeline([('adaboost',AdaBoostClassifier())])\nsgdclassifier=Pipeline([('SGDclassifier',SGDClassifier())])\nsvc=Pipeline([('svc',SVC())])\nmlpclass=Pipeline([('mlpc',MLPClassifier())])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mypipeline1=[logreg,decision,randomforest,naivebayes,knn,gbc,adaboost,sgdclassifier,svc,mlpclass]\n            ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy=0.0\nclassifier=0\npipeline=\"\"\npipelinedict1={0:'logistic',1:'dt',2:'rf',3:'nb',4:'knn',5:'gbc',6:'adaboost',7:'SGDclassifier',\n              8:'svc',9:'mlpc'}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in mypipeline1:\n    i.fit(x_train,y_train)\nmodel_score=[]\nmodel_name=[]\nfor i,j in enumerate(mypipeline1):\n    print(\"{} test accuracy: {}\".format(pipelinedict1[i],j.score(x_test,y_test)))\n    model_name.append(pipelinedict1[i])\n    model_score.append(j.score(x_test,y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8,8))\nplt.barh(model_name,model_score,color='red')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### as we can see that KNN has the highest accuracy among all classifier algorithms ,that is 83.51%","metadata":{}},{"cell_type":"markdown","source":"## TUNING THE PARAMETER TO GET BETTER ACCURACY","metadata":{}},{"cell_type":"code","source":"knn=KNeighborsClassifier()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_score=[]\ntrain_score=[]\nfor i in range(1,50):\n    knn=KNeighborsClassifier(n_neighbors=i)\n    knn.fit(x_train,y_train)\n    train_score.append(knn.score(x_train,y_train))\n    test_score.append(knn.score(x_test,y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nplt.plot(range(1,50),train_score,color='green')\nplt.plot(range(1,50),test_score,color='red')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### at n_neibhour=6,we are getting highest accuracy","metadata":{}},{"cell_type":"code","source":"knn1=KNeighborsClassifier(n_neighbors=6)\nknn1.fit(x_train,y_train)\nknn1.score(x_test,y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### here we have'nt got any improvement","metadata":{}},{"cell_type":"code","source":"knn2=KNeighborsClassifier(n_neighbors=6)\nrand_state=[]\naccuracy=[]\nfor i in range(1,150,1):\n    x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=.30,random_state=i)\n    knn2.fit(x_train,y_train)\n    accuracy.append(knn2.score(x_test,y_test))\n    rand_state.append(i)\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nplt.plot(rand_state,accuracy)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### here random_state in between 100-120 we,are getting highest accuracy","metadata":{}},{"cell_type":"code","source":"for i in range(len(rand_state)):\n    print(accuracy[i],rand_state[i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### at i=107(random_state) we are getting accuracy of 90.10%","metadata":{}},{"cell_type":"code","source":"x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=.30,random_state=107)\nknn2.fit(x_train,y_train)   ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knn2.score(x_test,y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_pred=knn2.predict(x_test)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_score(y_test,y_test_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### here we have got accuracy of our model to be 90.10%","metadata":{}},{"cell_type":"code","source":"\nplot_roc_curve(knn2,x_test,y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### here we have got AUC SCORE=.93 which indicate that  model is too good.","metadata":{}},{"cell_type":"code","source":"roc_auc_score(y_test,y_test_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ROC AUC SCORE =.90","metadata":{}},{"cell_type":"code","source":"plot_precision_recall_curve(knn2,x_test,y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### AVERAGE PRECISION SCORE IS-- AP=.93","metadata":{}},{"cell_type":"code","source":"print(classification_report(y_test,y_test_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}