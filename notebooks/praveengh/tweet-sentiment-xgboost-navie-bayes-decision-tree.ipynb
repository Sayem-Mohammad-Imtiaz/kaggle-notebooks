{"cells":[{"metadata":{},"cell_type":"markdown","source":"## IMPORT LIBRARIES..."},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sn\nimport re\nimport nltk\nfrom tqdm import tqdm\nimport scipy\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nfrom sklearn.model_selection import RandomizedSearchCV\n\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import roc_auc_score\nimport nltk\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#loading the data\ndf=pd.read_csv('../input/twitter-sentiment-analysis-hatred-speech/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.shape)   #check the shape of the data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['label'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can observe that there are more reviews with 0 label i.e. tweet is not racist/sexist.<br>\nSo our dataset is imbalanced"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_value_counts=df['label'].value_counts()\nprint(\"Racist tweets  = \",y_value_counts[1], \"with percentage \", (y_value_counts[1]*100)/(y_value_counts[0]+y_value_counts[1]),'%')\nprint(\"Not Racist tweets  = \",y_value_counts[0], \"with percentage \", (y_value_counts[0]*100)/(y_value_counts[0]+y_value_counts[1]),'%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets see the classes through bar graph\ndata=dict(racist=y_value_counts[1],not_racist=y_value_counts[0])\ncls=data.keys()\nvalue=data.values()\n\nplt.bar(cls,value,color='maroon',width=0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***From the bar graph we can clearly see that there are more not racist tweets than the racist tweets.***"},{"metadata":{},"cell_type":"markdown","source":"## Data Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"Since the data is in text format, we have to preprocess the data and clean the data to vectorize the data."},{"metadata":{},"cell_type":"markdown","source":"First we will replace the all blank spaces, - with underscore and convert all the letters to lower case."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['tweet']=df['tweet'].str.replace(' ','_')\ndf['tweet']=df['tweet'].str.replace('-','_')\ndf['tweet']=df['tweet'].str.lower()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def expand(sent):\n    \"This function will replace english short notations with full form\"\n    \n    sent=re.sub(r\"can't\", \"can not\",sent)\n    sent=re.sub(r\"won't\", \"will not\",sent)\n    \n    sent=re.sub(r\"n\\'t\", \" not\",sent)\n    sent=re.sub(r\"\\'re\", \" are\",sent)\n    sent=re.sub(r\"\\'m\",\" am\",sent)\n    sent=re.sub(r\"\\'s\",\" is\",sent)\n    sent=re.sub(r\"\\'ll\",\" will\",sent)\n    sent=re.sub(r\"\\'ve\",\" have\",sent)\n    sent=re.sub(r\"\\'d\",\" would\",sent)\n    sent=re.sub(r\"\\'t\", \" not\",sent)\n    \n    return sent\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://gist.github.com/sebleier/554280\n# we are removing the words from the stop words list: 'no', 'nor', 'not'\nstopwords= ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n            'won', \"won't\", 'wouldn', \"wouldn't\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_tweet(text):\n    \"function for preprocess the text data\"\n    \n    preprocessed_tweet=[]\n    \n    for sentence in tqdm(text):\n        sent=expand(sentence)\n        sent=sent.replace(\"\\\\r\",\" \")\n        sent=sent.replace(\"\\\\n\",\" \")\n        sent=sent.replace('\\\\\"',\" \")\n        sent=re.sub(\"[^A-Za-z0-9]+\",\" \",sent)\n        \n        # https://gist.github.com/sebleier/554280\n        sent=\" \".join(i for i in sent.split() if i.lower() not in stopwords)\n        preprocessed_tweet.append(sent.lower().strip())\n        \n    return preprocessed_tweet\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocessed_tweets=preprocess_tweet(df['tweet'].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['tweet']=preprocessed_tweets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"tweet\"][10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Now the text data is cleaned"},{"metadata":{},"cell_type":"markdown","source":"### Splitting data into train and test"},{"metadata":{"trusted":true},"cell_type":"code","source":"y=df['label']\nx=df.drop(['label'],axis=1)\n\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,stratify=y,random_state=40)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Vectorization..."},{"metadata":{},"cell_type":"markdown","source":"#### TFIDF for text data"},{"metadata":{"trusted":true},"cell_type":"code","source":"vect=TfidfVectorizer(min_df=10)\n\nvect.fit(x_train['tweet'].values)\n\ntrain_tweet=vect.transform(x_train['tweet'].values)\ntest_tweet=vect.transform(x_test['tweet'].values)\n\nprint(train_tweet.shape,y_train.shape)\nprint(test_tweet.shape,y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#calculating sentiment scores for train data\nx_train_sent=np.ndarray.tolist(x_train[\"tweet\"].values)\n\nsia=SentimentIntensityAnalyzer()\nps=[]\nfor i in range(len(x_train_sent)):\n    ps.append((sia.polarity_scores((x_train_sent[i]))))\n    \nx_train_polarity=np.array(ps)\nx_train_polarity=x_train_polarity.reshape(-1,1)\nx_train_polarity.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#storing only scores of sentiment\nx_t=[]\nfor i in range(len(x_train)):\n    for j in x_train_polarity[0][0]:\n        x_t.append(x_train_polarity[i][0][j])\nx_t=np.array(x_t)\nx_t=x_t.reshape(-1,4)\nx_t.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#calculating sentiment scores for test data\nx_test_sent=np.ndarray.tolist(x_test[\"tweet\"].values)\n\nsia=SentimentIntensityAnalyzer()\nps=[]\nfor i in range(len(x_test_sent)):\n    ps.append((sia.polarity_scores((x_test_sent[i]))))\n    \nx_test_polarity=np.array(ps)\nx_test_polarity=x_test_polarity.reshape(-1,1)\nx_test_polarity.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#storing only scores of sentiment\nx_tests=[]\nfor i in range(len(x_test)):\n    for j in x_test_polarity[0][0]:\n        x_tests.append(x_test_polarity[i][0][j])\nx_tests=np.array(x_tests)\nx_tests=x_tests.reshape(-1,4)\nx_tests.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Convert the vectors into scipy.sparse matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.sparse import hstack","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_tr=hstack((train_tweet,x_t))\nx_te=hstack((test_tweet,x_tests))\n\nprint(x_tr.shape)\nprint(x_te.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Now we are ready with the data.***"},{"metadata":{},"cell_type":"markdown","source":"### DecisionTreeClassifier()"},{"metadata":{"trusted":true},"cell_type":"code","source":"wt={0:1,1:5}            #since the data is imbalanced , we assign some more weight to class 1\n\nclf=DecisionTreeClassifier(class_weight=wt)\n\nparameters=dict(max_depth=[1,5,10,50],min_samples_split=[5,10,100,500])\n\nsearch=RandomizedSearchCV(clf,parameters,random_state=10)\nresult=search.fit(x_tr,y_train)\nresult.cv_results_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"search.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cls = DecisionTreeClassifier(max_depth=50,min_samples_split=5,random_state=10,class_weight=wt)\ncls.fit(x_tr,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_train=cls.predict(x_tr)\ny_pred_test=cls.predict(x_te)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_fpr,train_tpr,tr_treshold=roc_curve(y_train,y_pred_train)\ntest_fpr,test_tpr,te_treshold=roc_curve(y_test,y_pred_test)\n\ntrain_auc=auc(train_fpr,train_tpr)\ntest_auc=auc(test_fpr,test_tpr)\n\nplt.plot(train_fpr,train_tpr,label='Train AUC = '+str(train_auc))\nplt.plot(test_fpr,test_tpr,label='Test AUC = '+str(test_auc))\nplt.legend()\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.title(\"AUC_Curve\")\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***We got auc score= 0.7625***"},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_best_threshold(threshold, fpr, tpr):\n    \"\"\"it will give best threshold value that will give the least fpr\"\"\"\n    t = threshold[np.argmax(tpr*(1-fpr))]\n    \n    # (tpr*(1-fpr)) will be maximum if your fpr is very low and tpr is very high\n    print(\"the maximum value of tpr*(1-fpr)\", max(tpr*(1-fpr)), \"for threshold\", np.round(t,3))\n    \n    return t\n\ndef predict_with_best_t(proba, threshold):\n    \"\"\"this will give predictions based on best threshold value\"\"\"\n    predictions = []\n    for i in proba:\n        if i>=threshold:\n            predictions.append(1)\n        else:\n            predictions.append(0)\n    return predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#computing confusion matrix for set_1\n\nfrom sklearn.metrics import confusion_matrix\nbest_t = find_best_threshold(tr_treshold, train_fpr, train_tpr)\nprint(\"Train confusion matrix\")\nm_tr=(confusion_matrix(y_train, predict_with_best_t(y_pred_train, best_t)))\nprint(m_tr)\nprint(\"Test confusion matrix\")\nm_te=(confusion_matrix(y_test, predict_with_best_t(y_pred_test, best_t)))\nprint(m_te)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_pred_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## NAIVE BAYES"},{"metadata":{},"cell_type":"markdown","source":"### CountVectorizer()"},{"metadata":{"trusted":true},"cell_type":"code","source":"vec=CountVectorizer(min_df=10)\nvec.fit(x_train['tweet'].values)\n\nx_tr_count=vec.transform(x_train['tweet'].values)\nx_te_count=vec.transform(x_test['tweet'].values)\nx_tr_count.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_tr_data=hstack((x_tr_count,x_t))\nx_te_data=hstack((x_te_count,x_tests))\n\nx_trn=scipy.sparse.csr_matrix(x_tr_count)\nx_tst=scipy.sparse.csr_matrix(x_te_count)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mod = MultinomialNB()\nmod.fit(x_trn,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pred=mod.predict(x_trn)\ntest_pred=mod.predict(x_tst)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_fpr,train_tpr,tr_treshold=roc_curve(y_train,train_pred)\ntest_fpr,test_tpr,te_treshold=roc_curve(y_test,test_pred)\n\ntrain_auc=auc(train_fpr,train_tpr)\ntest_auc=auc(test_fpr,test_tpr)\n\nplt.plot(train_fpr,train_tpr,label='Train AUC = '+str(train_auc))\nplt.plot(test_fpr,test_tpr,label='Test AUC = '+str(test_auc))\nplt.legend()\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.title(\"AUC_Curve\")\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***TEST AUC = 0.8157***"},{"metadata":{"trusted":true},"cell_type":"code","source":"#get the summary of this model\n\nprint(classification_report(y_test, test_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## XGBOOST"},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Hyperparameter Tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"xg=XGBClassifier()\nparam=dict(max_depth=[4,6,8,10],n_estimators=[100,500,1000,1500])\nsearch=RandomizedSearchCV(xg,param,random_state=10)\nsrch=search.fit(x_tr,y_train)\nsrch.cv_results_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"srch.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n              importance_type='gain', interaction_constraints='',\n              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n              min_child_weight=1, missing=None, monotone_constraints='()',\n              n_estimators=500, n_jobs=8, num_parallel_tree=1, random_state=0,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n              tree_method='exact', validate_parameters=1, verbosity=None).fit(x_tr, y_train)\n\nprediction = xgb.predict(x_te) \n\nf1_score(y_test, prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_prediction=xgb.predict(x_tr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_fpr,train_tpr,tr_treshold=roc_curve(y_train,train_prediction)\ntest_fpr,test_tpr,te_treshold=roc_curve(y_test,prediction)\n\ntrain_auc=auc(train_fpr,train_tpr)\ntest_auc=auc(test_fpr,test_tpr)\n\nplt.plot(train_fpr,train_tpr,label='Train AUC = '+str(train_auc))\nplt.plot(test_fpr,test_tpr,label='Test AUC = '+str(test_auc))\nplt.legend()\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.title(\"AUC_Curve\")\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***TEST AUC = 0.7280***"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, prediction))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SUMMARY"},{"metadata":{},"cell_type":"markdown","source":"### DECISION TREE"},{"metadata":{},"cell_type":"markdown","source":"                   precision    recall  f1-score   support\n\n              0       0.97      0.95      0.96      5945\n              1       0.48      0.57      0.52       448\n\n    accuracy                               0.93      6393\n    macro avg          0.72      0.76      0.74      6393\n    weighted avg       0.93      0.93      0.93      6393\n"},{"metadata":{},"cell_type":"markdown","source":"### NAIVE BAYES"},{"metadata":{},"cell_type":"markdown","source":"                   precision    recall  f1-score   support\n\n              0       0.97      0.97      0.97      5945\n              1       0.63      0.66      0.64       448\n\n    accuracy                               0.95      6393\n    macro avg          0.80      0.82      0.81      6393\n    weighted avg       0.95      0.95      0.95      6393\n"},{"metadata":{},"cell_type":"markdown","source":"### XGBOOST"},{"metadata":{},"cell_type":"markdown","source":"                     precision    recall  f1-score   support\n\n               0       0.96      0.99      0.98      5945\n               1       0.77      0.47      0.58       448\n\n    accuracy                               0.95      6393\n    macro avg          0.87      0.73      0.78      6393\n    weighted avg       0.95      0.95      0.95      6393\n\n​"},{"metadata":{},"cell_type":"markdown","source":"|MODEL|TEST AUC|\n|----|----|\n|DECISION TREE|0.7625|\n|NAIVE BAYES|0.8157|\n|XGBOOST|0.7280|"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}