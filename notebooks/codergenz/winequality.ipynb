{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Quality of red wine\n\n**Dataset:** https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009?fbclid=IwAR3XVugl70idQBVCitRsa1ilR0A0ByzOA3WXSAbVCfx9Dk0GLzWMtplvvaM\n\n**Notebook's author: Danh Nguyễn**","metadata":{}},{"cell_type":"markdown","source":"### Table of Contents\n\n* [1. Problem defining](#chapter1)       \n* [2. Data collecting](#chapter2)\n\n\n* [3. Data processing](#chapter3)\n    * [3.1 Prepare a dataframe](#3.1)\n    * [3.2 Handle null values](#3.2)\n    * [3.3 Discretize dataset](#3.3)\n    * [3.4 Split train and test set](#3.4)\n    \n    \n* [4. Problem modeling](#chapter4)\n    * [4.1 Overview data and train set](#4.1)\n    * [4.2 Visualize data and train set](#4.2)\n    * [4.3 Bayesian network](#4.3)\n\n\n* [5. Training and Predicting](#chapter5)\n    * [5.1 Build Bayesian model](#5.1)\n    * [5.2 Predict by Bayesian model](#5.2)\n    * [5.3 Performance metrics](#5.3)\n    * [5.4 Adjust structures](#5.4)\n    * [5.5 Another model](#5.5)\n\n\n* [Future work](#futurework)\n\n* [Reference](#reference)","metadata":{}},{"cell_type":"markdown","source":"# 1. Problem defining <a class=\"anchor\" id=\"chapter1\"></a>\n\nPredicting the quality of wine by its property, using Bayesian model.\n\nThe observed features are: fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates, alcohol, and quality. The quality of wine have 6 classes from quality 3 to quality 8. We will discretize the values in these observed features into 5 classes and predict the quality of wine by Bayesian model.\n\nMoreover, linear regression model will be used to label the quality of wine and compare the result with the result by Bayesian model.","metadata":{}},{"cell_type":"markdown","source":"# 2. Data collecting <a class=\"anchor\" id=\"chapter2\"></a>","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-28T09:34:17.602113Z","iopub.execute_input":"2021-07-28T09:34:17.602455Z","iopub.status.idle":"2021-07-28T09:34:17.635102Z","shell.execute_reply.started":"2021-07-28T09:34:17.602374Z","shell.execute_reply":"2021-07-28T09:34:17.633924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import packages\n# Plot and image packages\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom IPython.display import Image\nfrom IPython import display\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\n!pip install pgmpy","metadata":{"execution":{"iopub.status.busy":"2021-07-28T09:34:17.636661Z","iopub.execute_input":"2021-07-28T09:34:17.63708Z","iopub.status.idle":"2021-07-28T09:34:28.390943Z","shell.execute_reply.started":"2021-07-28T09:34:17.637022Z","shell.execute_reply":"2021-07-28T09:34:28.389707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"../input/red-wine-quality-cortez-et-al-2009/winequality-red.csv\")\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-28T09:34:28.393449Z","iopub.execute_input":"2021-07-28T09:34:28.393805Z","iopub.status.idle":"2021-07-28T09:34:28.447563Z","shell.execute_reply.started":"2021-07-28T09:34:28.393769Z","shell.execute_reply":"2021-07-28T09:34:28.44654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Data processing <a class=\"anchor\" id=\"chapter3\"></a>","metadata":{}},{"cell_type":"markdown","source":"## 3.1 Preparing a data frame <a class=\"anchor\" id=\"3.1\"></a>","metadata":{}},{"cell_type":"code","source":"#Create dataframe\npd.DataFrame(data)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T09:34:28.449202Z","iopub.execute_input":"2021-07-28T09:34:28.449522Z","iopub.status.idle":"2021-07-28T09:34:28.479185Z","shell.execute_reply.started":"2021-07-28T09:34:28.449489Z","shell.execute_reply":"2021-07-28T09:34:28.477725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### **Note:** All features in this dataset are relevant to determine the quality of wine, therefore, all data should be used.","metadata":{}},{"cell_type":"markdown","source":"## 3.2 Handle null value <a class=\"anchor\" id=\"3.2\"></a>","metadata":{}},{"cell_type":"code","source":"#Check NaN and fill NaN\n#Check NaN:\ndata.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-07-28T09:34:28.482637Z","iopub.execute_input":"2021-07-28T09:34:28.4829Z","iopub.status.idle":"2021-07-28T09:34:28.492368Z","shell.execute_reply.started":"2021-07-28T09:34:28.482877Z","shell.execute_reply":"2021-07-28T09:34:28.491362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### **Note**: Because there is no NaN, so we don't need to fill NaN or drop NaN.","metadata":{}},{"cell_type":"markdown","source":"## 3.3 Discretize data <a class=\"anchor\" id=\"3.3\"></a>","metadata":{}},{"cell_type":"code","source":"#Discretize the data with 5 classes\ndef discretize(feature, nclass):\n    min_val = feature.min()\n    max_val = feature.max()\n    interval = (max_val - min_val)/nclass\n    i=0\n    for value in feature:\n        feature[i]=(feature[i]-min_val)//interval+1\n        if feature[i] == nclass + 1: feature[i] = nclass\n        i+=1\ni=0\ndiscreted5_data = data.copy()\nfor col in discreted5_data.drop(['quality'], axis=1):\n    discretize(discreted5_data.iloc[:,i], 5)\n    i+=1\ndiscreted5_data","metadata":{"execution":{"iopub.status.busy":"2021-07-28T09:34:28.494521Z","iopub.execute_input":"2021-07-28T09:34:28.494811Z","iopub.status.idle":"2021-07-28T09:34:34.727668Z","shell.execute_reply.started":"2021-07-28T09:34:28.494786Z","shell.execute_reply":"2021-07-28T09:34:34.726733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.4 Splitting train and test set <a class=\"anchor\" id=\"3.4\"></a>","metadata":{}},{"cell_type":"code","source":"#Split data into train and test set (80% train, 20% test)\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(discreted5_data.drop(['quality'], axis = 1), discreted5_data['quality'], test_size = 0.2, random_state = 42, stratify = discreted5_data['quality'])\ntrain_data = pd.concat([y_train, X_train], axis=1)\ntrain_data","metadata":{"execution":{"iopub.status.busy":"2021-07-28T09:34:34.728861Z","iopub.execute_input":"2021-07-28T09:34:34.729164Z","iopub.status.idle":"2021-07-28T09:34:35.005898Z","shell.execute_reply.started":"2021-07-28T09:34:34.729129Z","shell.execute_reply":"2021-07-28T09:34:35.004138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### **Note**: Train set has 1276 rows and 12 columns. All values (except quality) are splitted into 5 classes with respect to their feature.","metadata":{}},{"cell_type":"markdown","source":"# 4. Problem modeling <a class=\"anchor\" id=\"chapter4\"></a>","metadata":{}},{"cell_type":"markdown","source":"## 4.1 Overview data and train set <a class=\"anchor\" id=\"4.1\"></a>","metadata":{}},{"cell_type":"code","source":"#Overview the intitial dataset\ndata.describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-28T09:34:35.009258Z","iopub.execute_input":"2021-07-28T09:34:35.00958Z","iopub.status.idle":"2021-07-28T09:34:35.05132Z","shell.execute_reply.started":"2021-07-28T09:34:35.009545Z","shell.execute_reply":"2021-07-28T09:34:35.050153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Overview the discretized data\ndiscreted5_data.describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-28T09:34:35.053348Z","iopub.execute_input":"2021-07-28T09:34:35.05367Z","iopub.status.idle":"2021-07-28T09:34:35.093576Z","shell.execute_reply.started":"2021-07-28T09:34:35.053645Z","shell.execute_reply":"2021-07-28T09:34:35.092133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Overview the train set\ntrain_data.describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-28T09:34:35.096255Z","iopub.execute_input":"2021-07-28T09:34:35.096816Z","iopub.status.idle":"2021-07-28T09:34:35.145788Z","shell.execute_reply.started":"2021-07-28T09:34:35.096777Z","shell.execute_reply":"2021-07-28T09:34:35.145093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.2 Visualize dataset and train set <a class=\"anchor\" id=\"4.2\"></a>","metadata":{}},{"cell_type":"code","source":"#Write function for plotting distribution\ndef plot_distribution(dataset, titlename):\n    fig = plt.figure(figsize = (18, 10))\n    title = fig.suptitle(titlename, fontsize=24)\n    fig.subplots_adjust(top=.85, wspace=.6, hspace=.6)\n    i=0\n    for col in dataset:\n        ax = fig.add_subplot(3,4, i+1)\n        #ax.set_title(data.columns[i])\n        ax.set_xlabel(\"Value\")\n        ax.set_ylabel(\"Frequency\")\n        ax.tick_params(axis='both', which='major', labelsize=8.5)\n        ax = sns.distplot(dataset.iloc[:,i], color='red')\n        i+=1\n    plt.show()\n#Plotting distribution of the initial dataset\nplot_distribution(data,\"Distribution of features in the initial dataset\")","metadata":{"execution":{"iopub.status.busy":"2021-07-28T09:34:35.147156Z","iopub.execute_input":"2021-07-28T09:34:35.1477Z","iopub.status.idle":"2021-07-28T09:34:37.500548Z","shell.execute_reply.started":"2021-07-28T09:34:35.14766Z","shell.execute_reply":"2021-07-28T09:34:37.499328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plotting the distribution of the train dataset\nplot_distribution(train_data, \"Distribution of features in the train dataset\")","metadata":{"execution":{"iopub.status.busy":"2021-07-28T09:34:37.501978Z","iopub.execute_input":"2021-07-28T09:34:37.502592Z","iopub.status.idle":"2021-07-28T09:34:39.965664Z","shell.execute_reply.started":"2021-07-28T09:34:37.502552Z","shell.execute_reply":"2021-07-28T09:34:39.964743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### **Insight:** Some features are not in normal distribution, we could use log transformation to make them normally distributed","metadata":{}},{"cell_type":"code","source":"#PLotting heatmap of the intial dataset to see correlation between features\nplt.figure(figsize=(15,8))\nsns.heatmap(data.corr(), annot=True, linewidths=2)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T09:34:39.967227Z","iopub.execute_input":"2021-07-28T09:34:39.967501Z","iopub.status.idle":"2021-07-28T09:34:40.860264Z","shell.execute_reply.started":"2021-07-28T09:34:39.967472Z","shell.execute_reply":"2021-07-28T09:34:40.85915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plotting the top 10 highest correlated features with respect to wine quality\nplt.figure(figsize=(15,15))\ndata.corr().quality.apply(lambda x: abs(x)).sort_values(ascending=False).iloc[1:11][::-1].plot(kind='barh',color='pink') \nplt.title(\"Top 10 highly correlated properties with Quality\", size=20, pad=26)\nplt.xlabel(\"Correlation coefficient\")\nplt.ylabel(\"Property\")","metadata":{"execution":{"iopub.status.busy":"2021-07-28T09:34:40.861491Z","iopub.execute_input":"2021-07-28T09:34:40.86182Z","iopub.status.idle":"2021-07-28T09:34:41.101801Z","shell.execute_reply.started":"2021-07-28T09:34:40.861787Z","shell.execute_reply":"2021-07-28T09:34:41.10049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize the target (quality)\nsns.countplot(train_data.quality)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T09:34:41.103341Z","iopub.execute_input":"2021-07-28T09:34:41.103621Z","iopub.status.idle":"2021-07-28T09:34:41.235418Z","shell.execute_reply.started":"2021-07-28T09:34:41.103594Z","shell.execute_reply":"2021-07-28T09:34:41.234273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### **Note:** Quality mức 5, 6 nhiều hơn các mức còn lại => imbalanced data\n\n##### => Có thể sử dụng reversampling method để cải thiện imbalanced data","metadata":{}},{"cell_type":"markdown","source":"## 4.3 Bayesian network <a class=\"anchor\" id=\"4.3\"></a>","metadata":{}},{"cell_type":"markdown","source":"![Bayesian network for wine quality](https://media-exp3.licdn.com/dms/image/C4D12AQGIueUur0CPig/article-inline_image-shrink_1000_1488/0/1566703342795?e=1632355200&v=beta&t=ds0DR6_Y8VMg2AMKSDeH9aum5nKoQhubOq_-MXTpPZ0)","metadata":{}},{"cell_type":"markdown","source":"#### **Explanation:** Regarding to the network in the reference [2] and the correlations in the heatmap, we have this Bayesian network of wine quality.","metadata":{}},{"cell_type":"markdown","source":"# 5. Training and predicting <a class=\"anchor\" id=\"chapter5\"></a>","metadata":{}},{"cell_type":"markdown","source":"## 5.1 Build Bayesian model <a class=\"anchor\" id=\"5.1\"></a>","metadata":{}},{"cell_type":"code","source":"#Build Bayesian model from the network\nfrom pgmpy.models import BayesianModel\nmodel1 = BayesianModel([('volatile acidity', 'fixed acidity'), ('density','fixed acidity'), ('fixed acidity','citric acid'), ('pH','citric acid'), ('total sulfur dioxide','free sulfur dioxide'), ('residual sugar','quality'), ('chlorides','quality'), ('free sulfur dioxide','quality'), ('sulphates','quality'), ('alcohol','quality'), ('citric acid','quality')])","metadata":{"execution":{"iopub.status.busy":"2021-07-28T10:31:32.364719Z","iopub.execute_input":"2021-07-28T10:31:32.365667Z","iopub.status.idle":"2021-07-28T10:31:32.376431Z","shell.execute_reply.started":"2021-07-28T10:31:32.365608Z","shell.execute_reply":"2021-07-28T10:31:32.375088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Get cpds and add cpds to nodes\nfrom pgmpy.estimators import MaximumLikelihoodEstimator\nmodel1.fit(train_data, estimator = MaximumLikelihoodEstimator)\ndef get_and_add_cpds(model, df):\n    i=0\n    for col in df:\n        model.add_cpds(model.get_cpds(df.columns[i]))\n        i+=1\nget_and_add_cpds(model1, train_data)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T10:31:35.842973Z","iopub.execute_input":"2021-07-28T10:31:35.843364Z","iopub.status.idle":"2021-07-28T10:31:50.756088Z","shell.execute_reply.started":"2021-07-28T10:31:35.843332Z","shell.execute_reply":"2021-07-28T10:31:50.754907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Get conditional probability density at Chlorides, pH, Sulphates\ni=0\nprint(model1.get_cpds('chlorides'))\nprint(model1.get_cpds('pH'))\nprint(model1.get_cpds('sulphates'))","metadata":{"execution":{"iopub.status.busy":"2021-07-28T10:31:54.146083Z","iopub.execute_input":"2021-07-28T10:31:54.146395Z","iopub.status.idle":"2021-07-28T10:31:54.153954Z","shell.execute_reply.started":"2021-07-28T10:31:54.146369Z","shell.execute_reply":"2021-07-28T10:31:54.152463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.2 Predict quality by Bayesian model <a class=\"anchor\" id=\"5.2\"></a>","metadata":{}},{"cell_type":"code","source":"#Predict quality by using Bayesian model\ny_pred = model1.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T10:31:57.636457Z","iopub.execute_input":"2021-07-28T10:31:57.636767Z","iopub.status.idle":"2021-07-28T10:56:18.612565Z","shell.execute_reply.started":"2021-07-28T10:31:57.636741Z","shell.execute_reply":"2021-07-28T10:56:18.610325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.3 Performance metrics (precision & recall & confusion matrix) <a class=\"anchor\" id=\"5.3\"></a>","metadata":{}},{"cell_type":"markdown","source":"#### **Precision**: \n\n#### Precision is the ratio of correctly predicted positive observations to the total predicted positive observations. [3]\n\n#### Precision = TP/(TP+FP)\n\n#### **Recall**: \n\n#### Recall is the ratio of correctly predicted positive observations to the all observations in actual class. [3]\n\n#### Recall = TP/(TP+FN)\n\n#### **F1 score**: \n\n#### F1 Score is the weighted average of Precision and Recall.[3]\n\n#### F1 Score = 2*(Recall * Precision) / (Recall + Precision)\n\n#### The **root-mean-square deviation** (RMSD) or **root-mean-square error** (RMSE) is a frequently used measure of the differences between values (sample or population values) predicted by a model or an estimator and the values observed. [5]","metadata":{}},{"cell_type":"code","source":"#Evaluating model by using classification report and confusion matrix\nfrom sklearn.metrics import classification_report, confusion_matrix, mean_squared_error, roc_auc_score, roc_curve\ndef report_efficiency(true, pred):\n    print(classification_report(true, pred))\n    labels = np.unique(true)\n    cf_matrix=confusion_matrix(true,pred)\n    df_cfmatrix = pd.DataFrame(cf_matrix, index = labels, columns = labels)\n    print(df_cfmatrix)\n    print(\"RMSE: \" + str(mean_squared_error(true, pred)**0.5))\n    \nreport_efficiency(y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T10:56:46.334803Z","iopub.execute_input":"2021-07-28T10:56:46.335179Z","iopub.status.idle":"2021-07-28T10:56:46.357774Z","shell.execute_reply.started":"2021-07-28T10:56:46.335142Z","shell.execute_reply":"2021-07-28T10:56:46.356921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Accuracy = 0.56**\n#### **Root-mean-square error: 0.955**","metadata":{}},{"cell_type":"markdown","source":"## 5.4 Adjust some data structures <a class=\"anchor\" id=\"5.4\"></a>","metadata":{}},{"cell_type":"markdown","source":"#### **Note**: The normal distribution is the most important probability distribution in statistics because it fits many natural phenomena. For example, heights, blood pressure, measurement error, and IQ scores follow the normal distribution. It is also known as the Gaussian distribution and the bell curve. [4]\n\n#### => Use log transformation to make data normally distributed.\n","metadata":{}},{"cell_type":"code","source":"#Copy to a new dataframe\nadjusted_data = data.copy()","metadata":{"execution":{"iopub.status.busy":"2021-07-28T09:34:44.028734Z","iopub.execute_input":"2021-07-28T09:34:44.029171Z","iopub.status.idle":"2021-07-28T09:34:44.045044Z","shell.execute_reply.started":"2021-07-28T09:34:44.029131Z","shell.execute_reply":"2021-07-28T09:34:44.044097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Using log1p transformation to make skewed features normally distributed. Do not use log transformation, since the majority of values is nearly equal to zero.","metadata":{}},{"cell_type":"code","source":"#Log1p transformation\ndef log1p_transform(col):\n    return np.log1p(col)\ni=0\nfor col in adjusted_data.columns:\n    if col != 'quality' and col !='density' and col != 'pH':\n        adjusted_data[[col]] = adjusted_data[[col]].apply(log1p_transform, axis = 1)\n    i+=1\nplot_distribution(adjusted_data, \"Distribution of features in the adjusted dataset\")","metadata":{"execution":{"iopub.status.busy":"2021-07-28T09:34:44.046607Z","iopub.execute_input":"2021-07-28T09:34:44.046995Z","iopub.status.idle":"2021-07-28T09:34:48.576314Z","shell.execute_reply.started":"2021-07-28T09:34:44.046961Z","shell.execute_reply":"2021-07-28T09:34:48.57533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### **Insight**: Almost all skewed data have been handled and changed into normal distribution form.","metadata":{}},{"cell_type":"code","source":"#Discretize the adjusted dataset\ni=0\nfor col in adjusted_data.drop(['quality'], axis =1):\n    discretize(adjusted_data.iloc[:, i], 5)\n    i+=1\nadjusted_data","metadata":{"execution":{"iopub.status.busy":"2021-07-28T09:34:48.577228Z","iopub.execute_input":"2021-07-28T09:34:48.577511Z","iopub.status.idle":"2021-07-28T09:34:54.910208Z","shell.execute_reply.started":"2021-07-28T09:34:48.577488Z","shell.execute_reply":"2021-07-28T09:34:54.909436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Split the adjusted dataset into train and test set\ntrain2, test2 = train_test_split (adjusted_data, test_size = 0.2, random_state = 42)\nX_test2, y_test2 = test2.drop(['quality'], axis = 1), test2[['quality']]","metadata":{"execution":{"iopub.status.busy":"2021-07-28T09:34:54.911155Z","iopub.execute_input":"2021-07-28T09:34:54.911375Z","iopub.status.idle":"2021-07-28T09:34:54.918401Z","shell.execute_reply.started":"2021-07-28T09:34:54.911349Z","shell.execute_reply":"2021-07-28T09:34:54.917831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Build Bayesian model regarding to new train data\nmodel2 = BayesianModel([('volatile acidity', 'fixed acidity'), ('density','fixed acidity'), ('fixed acidity','citric acid'), ('pH','citric acid'), ('total sulfur dioxide','free sulfur dioxide'), ('residual sugar','quality'), ('chlorides','quality'), ('free sulfur dioxide','quality'), ('sulphates','quality'), ('alcohol','quality'), ('citric acid','quality')])\nmodel2.fit(train2, estimator = MaximumLikelihoodEstimator)\nget_and_add_cpds(model2, train2)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T09:34:54.920692Z","iopub.execute_input":"2021-07-28T09:34:54.921171Z","iopub.status.idle":"2021-07-28T09:35:03.715705Z","shell.execute_reply.started":"2021-07-28T09:34:54.921145Z","shell.execute_reply":"2021-07-28T09:35:03.714199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Predict based on the new training data\ny_pred2 = model2.predict(X_test2)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T09:35:03.717894Z","iopub.execute_input":"2021-07-28T09:35:03.718364Z","iopub.status.idle":"2021-07-28T10:03:31.577874Z","shell.execute_reply.started":"2021-07-28T09:35:03.718324Z","shell.execute_reply":"2021-07-28T10:03:31.576701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"report_efficiency(y_test2, y_pred2)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T10:03:31.579661Z","iopub.execute_input":"2021-07-28T10:03:31.579912Z","iopub.status.idle":"2021-07-28T10:03:31.600595Z","shell.execute_reply.started":"2021-07-28T10:03:31.579885Z","shell.execute_reply":"2021-07-28T10:03:31.598708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Accuracy: 0.42**\n#### **Root-mean-square error: 1.39**","metadata":{}},{"cell_type":"markdown","source":"##### **Insight**: Adjusting data structure by using log1p transformation do not improve the score, maybe since it make the discrete data changed badly.","metadata":{}},{"cell_type":"markdown","source":"## 5.5 Use another model to predict (Linear Regression) <a class=\"anchor\" id=\"5.5\"></a>","metadata":{}},{"cell_type":"markdown","source":"* Use log1p transformation to make the skewed dataset normally distributed.\n* Use linear regression model.\n* Change the predicted data into its nearest integer.\n* Evaluate by classification report, confusion matrix, and root-mean-square error","metadata":{}},{"cell_type":"code","source":"#Copy new dataset from the initial dataset and use log1p transform\nnew_data = data.copy()\ni=0\nfor col in new_data.columns:\n    if col != 'quality' and col !='density' and col != 'pH':\n        new_data[[col]] = new_data[[col]].apply(log1p_transform, axis = 1)\n    i+=1\nplot_distribution(new_data, \"Distribution of features in the new dataset\")","metadata":{"execution":{"iopub.status.busy":"2021-07-28T10:03:31.601781Z","iopub.execute_input":"2021-07-28T10:03:31.602022Z","iopub.status.idle":"2021-07-28T10:03:36.34439Z","shell.execute_reply.started":"2021-07-28T10:03:31.601997Z","shell.execute_reply":"2021-07-28T10:03:36.343336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Spit train and test set\nnX_train, nX_test,ny_train, ny_test = train_test_split(new_data.drop(['quality'], axis = 1), new_data[['quality']], test_size = 0.2, random_state = 42, stratify = new_data['quality'])","metadata":{"execution":{"iopub.status.busy":"2021-07-28T10:08:19.692545Z","iopub.execute_input":"2021-07-28T10:08:19.69307Z","iopub.status.idle":"2021-07-28T10:08:19.701312Z","shell.execute_reply.started":"2021-07-28T10:08:19.693045Z","shell.execute_reply":"2021-07-28T10:08:19.700408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Build linear regression model\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.pipeline import Pipeline\nLR = Pipeline([\n        ('lr',  LinearRegression())\n ])  \n\nLR.fit(nX_train,ny_train)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T10:09:38.021374Z","iopub.execute_input":"2021-07-28T10:09:38.021662Z","iopub.status.idle":"2021-07-28T10:09:38.086356Z","shell.execute_reply.started":"2021-07-28T10:09:38.021637Z","shell.execute_reply":"2021-07-28T10:09:38.085703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Predict by linear regression model\nny_pred = LR.predict(nX_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T10:09:43.096217Z","iopub.execute_input":"2021-07-28T10:09:43.096715Z","iopub.status.idle":"2021-07-28T10:09:43.102872Z","shell.execute_reply.started":"2021-07-28T10:09:43.096681Z","shell.execute_reply":"2021-07-28T10:09:43.102025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Change the predicted value into the nearest interger\ni=0\nfor value in ny_pred:\n    val = ny_pred[i] - ny_pred[i]//1\n    if val < 0.5:\n        ny_pred[i] = ny_pred[i]//1\n    else: ny_pred[i] = ny_pred[i]//1 + 1\n    i+=1","metadata":{"execution":{"iopub.status.busy":"2021-07-28T10:17:20.233155Z","iopub.execute_input":"2021-07-28T10:17:20.233521Z","iopub.status.idle":"2021-07-28T10:17:20.246415Z","shell.execute_reply.started":"2021-07-28T10:17:20.233488Z","shell.execute_reply":"2021-07-28T10:17:20.245082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Evaluation\nreport_efficiency(ny_test, ny_pred)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T10:16:57.808392Z","iopub.execute_input":"2021-07-28T10:16:57.808723Z","iopub.status.idle":"2021-07-28T10:16:57.828222Z","shell.execute_reply.started":"2021-07-28T10:16:57.808697Z","shell.execute_reply":"2021-07-28T10:16:57.826761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Accuracy: 0.6**\n#### **Root-mean-square error:  0.69**","metadata":{}},{"cell_type":"markdown","source":"##### **Insight**: Prediction results by using linear regression model is better than using Bayesian model, since the original dataset is not discrete.","metadata":{}},{"cell_type":"markdown","source":"# Future work <a class=\"anchor\" id=\"futurework\"></a>","metadata":{}},{"cell_type":"markdown","source":"* Using resampling methods (such as sklearn.utils.resample, stratified K-Fold, SMOTE) to handling imbalanced data\n* Using other models such as KNN, XgBoost, and LightGBM to improve the results.","metadata":{}},{"cell_type":"markdown","source":"# Reference <a class=\"anchor\" id=\"reference\"></a>","metadata":{}},{"cell_type":"markdown","source":"   #### [1] MaSSP pipeline notebook, by *Thanh Vuong*\n    \n   #### [2] Bayesian Networks with Continuous Distributions - Regression model to describe wine quality, by *Robson Fernandes* (via LinkedIn)\n   \n   #### [3] Accuracy, Precision, Recall & F1 Score: Interpretation of Performance Measures, by *Renuka Joshi*\n   \n   #### [4] Normal Distribution in Statistics, by *Jim Frost*\n   #### [5] Root-mean-square deviation, *via Wikipedia* ","metadata":{}}]}