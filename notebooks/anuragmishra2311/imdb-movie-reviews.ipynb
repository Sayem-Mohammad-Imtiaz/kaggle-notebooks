{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Importing Libraries"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport keras\nimport tensorflow as tf\nfrom collections import Counter\nimport tqdm as tqdm\nfrom keras.layers import LSTM,Bidirectional,Flatten,Conv1D,Dense,Dropout,Embedding,MaxPooling1D\nfrom keras.models import Sequential","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reading Data "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train=pd.read_csv('../input/imdb-dataset-sentiment-analysis-in-csv-format/Train.csv')\ndf_val=pd.read_csv('../input/imdb-dataset-sentiment-analysis-in-csv-format/Valid.csv')\ndf_test=pd.read_csv('../input/imdb-dataset-sentiment-analysis-in-csv-format/Test.csv')\n\ndf_train.shape,df_val.shape,df_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=df_train.text.values\nX_val=df_val.text.values\nX_test=df_test.text.values\n\nY_train=df_train.label.values\nY_val=df_val.label.values\nY_test=df_test.label.values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Understanding Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"length_of_individual_review_train=[len(i.split()) for i in X_train]\nlength_of_individual_review_val=[len(i.split()) for i in X_val]\nlength_of_individual_review_test=[len(i.split()) for i in X_test]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Histogram of Length of Reviews "},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(3)\nplt.figure(figsize=(10,10))\naxs[0].hist(length_of_individual_review_train)\naxs[1].hist(length_of_individual_review_val)\naxs[2].hist(length_of_individual_review_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Length of reviews in Training Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_review=pd.DataFrame()\ndf_review['train']=length_of_individual_review_train\ndf_review.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Length of Reviews in Val N Test Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_reviews=pd.DataFrame()\ndf_reviews['val']=length_of_individual_review_val\ndf_reviews['test']=length_of_individual_review_test\ndf_reviews.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp=' '.join(X_train)\nwords_count=Counter(temp.split())\nwords_count=sorted(words_count.values(),reverse=True)\nwords_count","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Looking at all distinct Characters present in reviews\n\nExcept alphanumeric characters, we can pass rest of characters as filter to our Tokenizer object"},{"metadata":{"trusted":true},"cell_type":"code","source":"temp=' '.join(X_train)\ntemp=temp.lower()\nfor i in sorted(set(temp)):\n    print(i,end='')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Tokenizing"},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab_size=15000\nembedding_dimension=32\nmax_length=120\nturnc='post'\noov_tok='<OOV>'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer=Tokenizer(filters='''!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~¡¢£¤¦§¨«­®°³´·º»½¾¿ßàáâãäåæçèéêëìíîïðñòóôõöøùúûüýþğıōżאגויכלמןר–‘’“”…″₤★、''',\n                   num_words=vocab_size,\n                   oov_token=oov_tok)\n\ntokenizer.fit_on_texts(X_train)\n\nword_index=tokenizer.word_index\n\nX_train_sequences=tokenizer.texts_to_sequences(X_train)\n\nX_train_padded=pad_sequences(X_train_sequences,\n                            maxlen=max_length,\n                            padding='post',\n                            truncating=turnc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_sequences=tokenizer.texts_to_sequences(X_test)\nX_test_padded=pad_sequences(X_test_sequences,\n                            maxlen=max_length,\n                            padding='post',\n                           truncating=turnc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_val_sequences=tokenizer.texts_to_sequences(X_val)\nX_val_padded=pad_sequences(X_val_sequences,\n                            maxlen=max_length,\n                           padding='post',\n                           truncating=turnc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential([\n    Embedding(vocab_size, embedding_dimension, input_length=max_length),\n    Dropout(0.3),\n    Bidirectional(LSTM(120,return_sequences=False)),\n    Dropout(0.2),\n    Dense(1, activation='sigmoid')\n])\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history=model.fit(X_train_padded,Y_train,epochs=4,validation_data=(X_val_padded,Y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(X_test_padded,Y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_padded[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predicting from Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_case_1=['lovely movie']\ntokenizer.fit_on_texts(test_case_1)\np=tokenizer.texts_to_sequences(test_case_1)\ntest_case_1=pad_sequences(p,maxlen=120)\nmodel.predict_classes(test_case_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_case_2=['boring movie']\ntokenizer.fit_on_texts(test_case_2)\np=tokenizer.texts_to_sequences(test_case_2)\ntest_case_2=pad_sequences(p,maxlen=120)\nmodel.predict_classes(test_case_2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thank you "},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}