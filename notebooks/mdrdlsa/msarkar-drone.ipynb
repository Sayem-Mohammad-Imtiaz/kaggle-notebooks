{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\n#for building and training the U-Net model\nfrom tensorflow.keras.layers import Conv2D, Input, Concatenate, MaxPooling2D, Conv2DTranspose\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.models import Model\n\nprint(\"Loaded all libraries\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_fpath='../input/semantic-drone-dataset/dataset/semantic_drone_dataset/label_images_semantic/'\ntrain_masks_fpath='../input/semantic-drone-dataset/RGB_color_image_masks/RGB_color_image_masks/'\n\n#test_fpath='../input/3d_images/'\n#test_masks_fpath='../input/3d_masks/'\nprint(os.listdir('../input/semantic-drone-dataset/dataset/semantic_drone_dataset/label_images_semantic/'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"No. of images =\",len(os.listdir(train_fpath)))\nprint(\"No. of image masks =\",len(os.listdir(train_masks_fpath)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#1 example let's pick image id 'ID_0066_Z_0141'\ndef plot_img_and_mask(id):\n    img = cv2.imread(train_fpath + id + '.png')\n    img_mask = cv2.imread(train_masks_fpath + id + '.png')\n    plt.figure(figsize=(10,10))\n    plt.subplot(1,3,1,title='Actual image')\n    plt.imshow(img)\n    plt.subplot(1,3,3,title='Image mask')\n    plt.imshow(img_mask)\n    \nplot_img_and_mask('173')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_img_and_mask('173')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def initialize_img_data(folder):\n    lst=[]\n    for image in os.listdir(folder):\n    #load image in grayscale\n        img=cv2.imread(folder+\"/\"+image,cv2.IMREAD_GRAYSCALE) \n        #convert to array\n        img_array=Image.fromarray(img)\n        # divide by 255\n        resize_img=img_array.resize((128,128))\n        norm_img=np.array(resize_img)/255\n        # expand dimensions\n        img_array=norm_img.reshape((128,128,1))\n    \n        lst.append(img_array)\n    return lst\n\nX=initialize_img_data(train_fpath)\ny=initialize_img_data(train_masks_fpath)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(os.listdir(train_fpath)),len(X),len(y))\nprint(X[0].shape,y[0].shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nplt.subplot(1,3,1,title='Actual image')\nplt.imshow(X[10],cmap='gray')\n\nplt.subplot(1,3,3,title='Image mask')\nplt.imshow(y[10],cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=np.array(X)\ny=np.array(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train=X[:200]\ny_train=y[:200]\n\nx_test=X[200:]\ny_test=y[200:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs=Input(shape=(128,128,1))\n\nc1=Conv2D(8,(3,3), activation='relu', padding='same')(inputs)\nc1=Conv2D(8,(3,3), activation='relu', padding='same')(c1)\np1=MaxPooling2D((2,2))(c1)\n\nc2=Conv2D(16,(3,3), activation='relu', padding='same')(p1)\nc2=Conv2D(16,(3,3), activation='relu', padding='same')(c2)\np2=MaxPooling2D((2,2))(c2)\n\nc3=Conv2D(32,(3,3), activation='relu', padding='same')(p2)\nc3=Conv2D(32,(3,3), activation='relu', padding='same')(c3)\np3=MaxPooling2D((2,2))(c3)\n\nc4=Conv2D(64,(3,3), activation='relu', padding='same')(p3)\nc4=Conv2D(64,(3,3), activation='relu', padding='same')(c4)\np4=MaxPooling2D((2,2))(c4)\n\nc5=Conv2D(128,(3,3), activation='relu', padding='same')(p4)\nc5=Conv2D(128,(3,3), activation='relu', padding='same')(c5)\n\nu6=Conv2DTranspose(64,(2,2), strides=(2,2), padding='same')(c5)\nu6=Concatenate()([u6,c4])  #optional\nc6=Conv2D(64,(3,3), activation='relu', padding='same')(u6)\nc6=Conv2D(64,(3,3), activation='relu', padding='same')(c6)\n\nu7=Conv2DTranspose(32,(2,2), strides=(2,2), padding='same')(c6)\nu7=Concatenate()([u7,c3])  #optional\nc7=Conv2D(32,(3,3), activation='relu', padding='same')(u7)\nc7=Conv2D(32,(3,3), activation='relu', padding='same')(c7)\n\nu8=Conv2DTranspose(16,(2,2), strides=(2,2), padding='same')(c7)\nu8=Concatenate()([u8,c2])  #optional\nc8=Conv2D(16,(3,3), activation='relu', padding='same')(u8)\nc8=Conv2D(16,(3,3), activation='relu', padding='same')(c8)\n\nu9=Conv2DTranspose(8,(2,2), strides=(2,2), padding='same')(c8)\nu9=Concatenate()([u9,c1])  #removed,axis=3\nc9=Conv2D(8,(3,3), activation='relu', padding='same')(u9)\nc9=Conv2D(8,(3,3), activation='relu', padding='same')(c9)\n\noutputs=Conv2D(1,(1,1), activation='sigmoid')(c9)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=Model(inputs=[inputs], outputs=[outputs])\nmodel.compile(optimizer='adam', loss='binary_crossentropy')\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import plot_model\nplot_model(model,to_file='model.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"early_stop=EarlyStopping(patience=5)\ncheck_point=ModelCheckpoint('model.hdf5',save_best_only=True)\nmodel.fit(x_train, y_train, epochs=200, callbacks=[early_stop, check_point])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(1, figsize=(15, 9))\nn=0\nfor i in range(4):\n    n+=1\n    r=[i]\n    plt.subplot(2,2,n)\n    plt.subplots_adjust(hspace=0.5,wspace=0.5)\n    #plt.imshow(x_test[r[0]],  cmap=\"gray\") \n    plt.imshow(x_test[r[0]], alpha=0.5, cmap=\"Oranges\") \n    \nplt.suptitle(\" images and the masks predictedby U-Net model highlighted in RED\") \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(1, figsize=(15, 9))\nn=0\nfor i in range(4):\n    n+=1\n    r=[i]\n    plt.subplot(2,2,n)\n    plt.subplots_adjust(hspace=0.5,wspace=0.5)\n    #plt.imshow(x_test[r[0]],  cmap=\"gray\") \n    plt.imshow(y_test[r[0]], alpha=0.5, cmap=\"Oranges\") \n    \nplt.suptitle(\"images and the masks predictedby U-Net model highlighted in RED\") \nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}