{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Case Study: Expanding Our Candy Brand\n\nFrom an entrepreneurial point of view, let's try to answer the following questions with this notebook.\n\n* Which ingredients influence the selection of a candy and how strong is it? / How strong are features correlated?\n* What are the most important ingredients? / What features can describe the whole feature space sufficiently?\n* What are the ingredients for a recipe that maximizes the selection? / Which feature values maximize the target variable?\n\n###### Table of contents\n\n1. [Exploratory Data Analysis](#eda)\n    1. [Interesting Questions](#questions)\n    2. [Feature Engineering](#feat_eng)\n    3. [Distributions](#distributions)\n    4. [Feature Correlation](#corr)\n    5. [Principal Component Analysis (PCA)](#pca)\n2. [Predictive Analysis - Linear Regression](#pred_ana)\n    1. [Training + Single Metric Evaluation](#train_eval)\n    2. [Learning Curve + Cross Validation](#curve_cross)\n3. [Recommendation](#recomm)\n    1. [Dicussion and Outlook](#disc_out)\n    2. [Conclusion and Final Recommendation](#conclusion)"},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis <a name=\"eda\"/>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# general\nimport os\n\n# visualization and plots\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# for the data\nimport pandas as pd\nimport numpy as np\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\n# predictive models\nfrom sklearn.linear_model import LinearRegression\n\n# evaluation\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import learning_curve\n\n# warnings\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# globals\nBASE_DIR = '../input/the-ultimate-halloween-candy-power-ranking'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# read the data set\ncandy_df = pd.read_csv(os.path.join(BASE_DIR, 'candy-data.csv'))\n\n# take a quick look at the data\ncandy_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# scale winpercent between 0 and 1\ncandy_df.winpercent = candy_df.winpercent/100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### Observations\nHere you can see a rough overview how the features are distributed.\n\n* *sugarpercent*, *pricepercent* and *winpercent* are the only continuous features. The rest are boolean features.\n* Distribution of the continuous features do not seem skewed because the distance between the 75% and 25% to the 50% quantile are more or less the same."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Overview with information of the dataset\ncandy_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### Observations\n* No missing values, which is a perfect situation. Otherwise missing values can be substituted by e.g. the mean. It is possible to drop the according columns/rows, too.\n* Feature *competitorname* is a categorial feature that needs to be transformed if used in a predictive model (OneHotEncoding, LabelEncoding)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# How many different competitors are there?\nlen(candy_df.competitorname.unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"85 unique competitors. This would make the columns grow in case of OneHotEncoding. Also, there is no ranking or order in it that you could encode with labels. Thus, let's drop it."},{"metadata":{},"cell_type":"markdown","source":"### Interesting Questions <a name=\"questions\"/>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# sort candies by winpercent\ncandy_sorted_win = candy_df.sort_values(by=['winpercent'], ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# What are the top 10 candies with the highest winpercent?\ncandy_sorted_win.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# What are the flop 10 candies with lowest winpercent?\ncandy_sorted_win.tail(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### Observations\n* In the top 10\n    * All instances have *chocolate* but are not *fruity*\n    * The second place has almost no sugar\n    * All are soft\n* In the flop 10\n    * There is no *chocolate*, *nougat* and *crispedricewafer*\n    * All of them are no bar candies\n\nSide note: *competitorname* has signs (Ã•) that you might want to substitute. However, here the column will be dropped."},{"metadata":{"trusted":true},"cell_type":"code","source":"# sort candies by sugar\ncandy_sorted_sugar = candy_df.sort_values(by=['sugarpercent'], ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# How did candies with the highest sugar perform?\ncandy_sorted_sugar.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# How did candies with the lowest sugar perform?\ncandy_sorted_sugar.tail(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### Observations\n* Both seem to perform rather mediocre.\n* Highest sugar\n    * No *caramel*, *nougat* and *crispedricewafer*\n    * Only no bar candies\n* Lowest sugar\n    * No *caramel*, *nougat* and *crispedricewafer*\n    * Only no bar candies"},{"metadata":{"trusted":true},"cell_type":"code","source":"# sort candies by price\ncandy_sorted_price = candy_df.sort_values(by=['pricepercent'], ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# How did candies with the highest price perform?\ncandy_sorted_price.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# How did candies with the lowest price perform?\ncandy_sorted_price.tail(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### Observations\n* Pricy candies looks like to perform better.\n* There is no nougat in both cases.\n* In both cases the candy is either with chocolate or fruity.\n* Highest 10 *pricepercent*\n    * Almost no *peanutyalmondy*\n    * A lot of chocolate\n* Lowest 10 *pricepercent*\n    * Less sugar compared to the higher priced\n    * Only soft candies\n    * Pixie Sticks and Root Beer Barrels have none of the mentioned ingredients"},{"metadata":{},"cell_type":"markdown","source":"### Feature Engineering <a name=\"feat_eng\"/>\nLet's see if we can combine features and highlight other properties. Note that the feature you like to predict is excluded. Otherwise, it would cause data leackage. Also, be cautios to do something like this in a real application."},{"metadata":{},"cell_type":"markdown","source":"#### Sweet but economic\nLet this be candies that are sweet but have a low price. If *sugarpercent* is high and *pricepercent* is low then the value will be high."},{"metadata":{"trusted":true},"cell_type":"code","source":"# divide sugarpercent by pricepercent\ncandy_df[\"sweetbyprice\"] = candy_df.sugarpercent / candy_df.pricepercent\n\nsweetbyprice_mean = np.mean(candy_df.sweetbyprice)\nsweetbyprice_std = np.std(candy_df.sweetbyprice)\n\nprint(sweetbyprice_mean, sweetbyprice_std)\n\n# normalize\ncandy_df.sweetbyprice = (candy_df.sweetbyprice - sweetbyprice_mean) / sweetbyprice_std","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Chocolate and Fruity\nLet this be candies that are both chocolate and fruity.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# muliply for AND function\ncandy_df[\"chocolateAndFruity\"] = candy_df.chocolate * candy_df.fruity","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Distributions <a name=\"distributions\"/>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_dists(df, start, end, grid_x, grid_y):\n    \"\"\"\n    Function to plot distributions of columns of a dataframe.\n    \n    @params:\n    - df: pandas DataFrame\n    - start: Integer that indicates starting index\n    - end: Integer that indicates ending index\n    - grid_x: Integer and matplotlib subplots rows\n    - grid_y: Integer and matplotlib subplots columns\n    \"\"\"\n    f, axes = plt.subplots(grid_x, grid_y, figsize=(grid_x*4,grid_y*5), sharex=False, sharey=False)\n    \n    for r in range(0, grid_x):\n        for c in range(0, grid_y):\n            if start >= end:\n                axes[r,c].set_visible(False)\n            else:\n                sns.distplot(df.iloc[:,start], ax=axes[r, c], bins=10, kde=False)\n                start += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_cols = candy_df.shape[1]\n\n# leave competitorname out\nplot_dists(candy_df, 1, n_cols, 4, 4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### Observations\n\n* The features *caramel*, *peanutyalymondy*, *nougat*, *crispedricewafer*, *hard* and *bar* tend to have around 7-8 more negative for 1-2 positive occurances.  \n* For the *chocolate*, *fruity* and *pluribus* feature there is almost a 50:50 relation.  \n* The continuous feature *winpercent* seems to be more or less normal distributed.\n* There are not many cost efficient candies.\n* There are not many candies that are sweet but cheap."},{"metadata":{},"cell_type":"markdown","source":"### Feature Correlation <a name=\"corr\"/>\nLet's see how each features are correlated and influence each other. In other words, which properties influence the selection of a candy."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop competitorname\ncandy_data = candy_df.drop(columns=['competitorname'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# set figure size\nplt.figure(figsize=(15, 15))\ncorr_heat = sns.heatmap(candy_data.corr(), vmin=-1, vmax=1, center=0, annot=True, fmt=\".1g\", cmap=\"coolwarm\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### What about correlated features?\nHere you can see the influence of between each features. It is interesting to see how features affect the winpercent which is the target variable. To see the influence of features on the target the row to look at is the third to the last. Ideally you want features that are independent. Features that are (highly) correlated, result into high variance or in other words an unstable decision on new data.  \nHow can correlated features be handled?\n\n* keep one and delete the others\n* combine them and map their dependency\n* reduce the dimension/number of features\n\n#### Observations\n\n* *chocolate* has a positive effect on the target.\n* *fruity* has a negative effect on the target.\n* *chocolate* and *fruity* are highly negative correlated.\n* Small positive influence between *sugarpercent* and *pricepercent*.\n* *cost_efficiency* has almost no influence on the target.\n\nNote that the data does not explain if *pricepercent* is influenced e.g by the quality of the ingredients.  \nAccording to the heatmap a first recommendation could be a soft, non fruity, one-bar candy with chocolate, caramel, nougat, nuts (peanuts, almonds, ..) and some crunch (cookies, waffles, ...).  \n\n"},{"metadata":{},"cell_type":"markdown","source":"### Principal Component Analysis <a name=\"pca\"/>\nLetâ€™s do a short PCA to again verify more important features and how much they explain\nthe data. In this case doing a PCA to reduce the dimension (number of features) is not trivial.\nOriginally the analysis is ment to be for continuous features, not (binary) categorial. Remember\nthat the dataset has binary categorial features like chocolate and more. However, it is still useful to gain further insights on the contribution of features in the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"# split data into X and y\n# note: candy_data is without the competitorsname feature\nX = candy_data.drop(columns=[\"winpercent\"])\ny = candy_data.winpercent","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# values need to be scaled before the analysis\nstand_scal = StandardScaler()\nX_scaled = stand_scal.fit_transform(X)\n\n# pca\npca = PCA(random_state=123)\nX_pca = pca.fit_transform(X_scaled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# init plot\nfig, ax = plt.subplots(1, 2, sharey=True)\nfig.set_size_inches(15, 5)\n\n\n# pexplained variance ratio as bar chart\nax[0].bar([i for i in range(1,len(pca.explained_variance_ratio_) + 1)], height = pca.explained_variance_ratio_)\nax[0].set_xlabel('Number of PCA component')\nax[0].set_ylabel('Explained Variance Ratio')\n\n# cummulative explained variance ratio as bar chart\ncummulative_exp_var = np.cumsum(pca.explained_variance_ratio_)\nax[1].bar([i for i in range(1,len(cummulative_exp_var) + 1)], height = cummulative_exp_var)\nax[1].set_xlabel('Number of PCA component')\nax[1].set_ylabel('Cumulative Explained Variance Ratio')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# which features contribute the most or are more important for each component?\npca_components = pca.components_\n\n# transpose for better usage\n# now the rows represents the features\npca_comp_t = np.transpose(pca_components)\n\nfeatures = X.columns\nn_features = len(features)\npca_idxs = np.arange(1, len(features)+1)\nx_labels = [\"PCA {}\".format(i) for i in range(1, n_features + 1)]\nbar_width = 0.8\n\n# define subplots dimension\nn_rows = 4\nn_cols = 4\n\nfig, ax = plt.subplots(n_rows, n_cols, sharex=False, sharey=True)\nfig.set_size_inches(40, 40)\n\nrects = []\nindex = 0\n\n# iterate through subplots\nfor r in range(n_rows):\n    for c in range(n_cols):\n        if index >= n_features:\n            ax[r,c].set_visible(False)\n        else:\n            # draw the bar chart\n            rect = ax[r,c].bar(pca_idxs, pca_comp_t[index], bar_width)\n            ax[r,c].set_xticks(pca_idxs)\n            ax[r,c].set_xticklabels(x_labels)\n            ax[r,c].set_ylabel('Contibution')\n            ax[r,c].set_xlabel(features[index])\n            index += 1\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### Observations\n* To explain at least 95% of the variance 9 PCA components are recquired. Thus, reducing the dimension of the feature space does not come along with a substantial benefit.\n* *bar* has the highest positive and *fruity* the highest negative contribution in PCA1\n* *cost_efficiency* has the highest positive and *pricepercent* the highest negative contribution in PCA2"},{"metadata":{},"cell_type":"markdown","source":"## Predictive Analysis - Linear Regression <a name=\"pred_ana\"/>\nA predictive analysis is important if you want to have an idea how much the new candy is accepted or not. It is not perfect but it minimizes the risk of going through development, marketing and production of a new candy.  \nYou can choose from multiple models but let's do a Linear Regression. You can decide further if it sufficiently models the data or not. Dependant on that you can choose a more complex model."},{"metadata":{},"cell_type":"markdown","source":"### Training + Single Metric Evaluation <a name=\"train_eval\"/>\nA Linear Regression model is trained and evaluated only with one metric - Root Mean Squared Error (RMSE). There are different metrics to choose from, but a RMSE is fine."},{"metadata":{"trusted":true},"cell_type":"code","source":"# split data further into training and testing/validation set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check if the distributions are similar after the split\ntraining_data = pd.concat([X_train, y_train], axis=1)\ntesting_data = pd.concat([X_test, y_test], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Is the data distributed more or less the same after the split?"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_dists(training_data, 0, training_data.shape[1], 4, 4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_dists(testing_data, 0, testing_data.shape[1], 4, 4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With 85 instances the dataset is really small. So it is difficult to split the data such that models are trained/tested on data that is representative. According to the plots of the distributions, a 20% split looks fine. A Machine Learning convention is to use 10% - 30% of the data for the test set."},{"metadata":{"trusted":true},"cell_type":"code","source":"# train a linear regression model\nlin_reg = LinearRegression()\nlin_reg.fit(X_train, y_train)\n\npredictions = lin_reg.predict(X_test)\n\n# the root mean squared error of the test set\nrmse = np.sqrt(mean_squared_error(predictions, y_test))\nprint(\"RMSE: \", rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The coefficients of the Linear Regression model show how each feature contributes to the output."},{"metadata":{"trusted":true},"cell_type":"code","source":"# coefficients of the linear regression\nlin_reg.coef_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The coefficients are ordered like the features, thus *chocolate* has a coefficient of 0.21, *fruity* 0.1, etc...  \nThe coefficient of 0.21 is the highest and this is expected because *chocolate* has the biggest influence on the target as seen in the heatmap.  \nMaximizing the target means maximizing the equation of the Linear Regression. So, in case of a binary feature you choose to include it (1) if the coefficient is positive or exclude it (0) if it is negative. In case of a continuous feature you want to go as near as possible to 0 for a negative coefficient and 1 for a positive coefficient.  \n\nFinally, you can come up with a constellation that has the highest winpercent."},{"metadata":{"trusted":true},"cell_type":"code","source":"# to maximize the equation let's choose\n# ... the nearest possible values for 0 or 1\nchoc = 1\nfruit = 0\ncaramel = 1\nnuts = 1\nnougat = 0\ncrispy = 1\nhard = 0\nbar = 0\nplural = 0\nsugar_percent_val = 0.99\nprice_percent_val = 0.2\nsweet_by_price_val = ((sugar_percent_val / price_percent_val) - sweetbyprice_mean) / sweetbyprice_std\nchocFruit = 0\n\n# feature values that maximizes the outcome of the Linear Regression\nbest_feat_values = np.array([choc, fruit, caramel, nuts, nougat, crispy, hard, bar, plural, sugar_percent_val, price_percent_val, sweet_by_price_val, chocFruit])\nbest_winpercent = np.dot(lin_reg.coef_, best_feat_values) + lin_reg.intercept_\nbest_winpercent","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With this constellation the Linear Regression predicts a winpercent of 84.64%, higher than the first place of the data, 84.18%."},{"metadata":{},"cell_type":"markdown","source":"### Learning Curve + Cross Validation <a name=\"curve_cross\"/>\nA learning curve is plotted to see how the model behaves. It gives insights e.g. if the model is too complex or if more training data is needed."},{"metadata":{"trusted":true},"cell_type":"code","source":"#calculate learning curve\ndef calc_learning_curve(X, y, train_sizes = np.linspace(0.1, 1., 5), cv=10, shuffle=False):\n    \"\"\"\n    calculates the learning curve\n    \n    @params:\n    - X: pandas DataFrame with shape [n_samples, n_features]\n    - y: pandas Series with shape [n_samples, 1]\n    - train_sizes: numpy array with values that contain the different training sizes\n    - cv: int, number of k-fold cross validation\n    - shuffle: boolean if training data is shuffled before split\n    \n    @ return:\n    - train_sizes: numpy array with values that contain the different training sizes\n    - train_scores: numpy array with cross validation scores\n    - test_scores: numpy array with cross validation scores\n    \"\"\"\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator=LinearRegression(),\n        X = X,\n        y = y,\n        train_sizes = train_sizes,\n        cv = cv,\n        scoring = \"neg_mean_squared_error\",\n        return_times = False,\n        shuffle = shuffle,\n        random_state = 123\n    )\n\n    train_scores = np.sqrt(-1 * train_scores)\n    test_scores = np.sqrt(-1 * test_scores)\n    \n    return train_sizes, train_scores, test_scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot learning curve\ndef plot_learning_curve(train_sizes, train_scores, test_scores):\n    \"\"\"\n    plots a learning curve\n    \n    @params:\n    @ return:\n    - train_sizes: numpy array with values that contain the different training sizes\n    - train_scores: numpy array with cross validation scores\n    - test_scores: numpy array with cross validation scores\n    \"\"\"\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n\n    plt.figure(figsize=(15,10))\n    plt.plot(train_sizes, train_scores_mean, label='Training Error', color='b')\n    plt.plot(train_sizes, test_scores_mean, label='Testing Error', color='r')\n\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                         train_scores_mean + train_scores_std, alpha=0.1,\n                         color=\"b\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                         test_scores_mean + test_scores_std, alpha=0.1,\n                         color=\"r\")\n\n\n    plt.title('Linear Regression - Learning Curve')\n    plt.xlabel('Training Set Size')\n    plt.ylabel('RMSE')\n    plt.legend(loc=\"best\")\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Shuffle before training"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_sizes, train_scores, test_scores = calc_learning_curve(X, y, shuffle=True)\nplot_learning_curve(train_sizes, train_scores, test_scores)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Observations\n* Both train and testing curves flatten more or less at the same speed and seem to intersect at around 75 training examples - 68 with 20% test size.\n* Much more training examples should not result into a much better score because the curves are about to intersect.\n* Looking at the curves there is no big sign of high bias (fast flattening test error) or variance (large remaining gab between curves)\n* The learning curve is expected to have higher deviation at the beginning because the fit is not well with few training examples. It is expected that it drops with more training examples, too."},{"metadata":{},"cell_type":"markdown","source":"## Recommendation <a name=\"recomm\"/>\n\nIn order to maximize this selection chance, you need to derive the values of the Linear Regression model that maximize the output.  \nHere is a table that maps the features to the coefficients of the trained Linear Regression model with the best values for the features:\n\n| Feature | Coefficient | Best Feature Value |\n|----------|:-------------:|---:|\n| chocolate | 0.21148295 | 1 |\n| fruity | 0.09599222 | 0 |\n| caramel | 0.00292705 | 1 |\n| peanutyalmondy | 0.069123 | 1 |\n| nougat | -0.00937832 | 0 |\n| crispedricewafer | 0.08260203 | 1 |\n| hard | -0.07228368 | 0 |\n| bar | -0.01970207 | 0 |\n| pluribus | -0.05246864 | 0 |\n| sugarpercent | 0.1301698 | 0.99 |\n| pricepercent | -0.14166532 | 0.2 |\n| sweetbyprice | -0.02571 | 0.9797313623732542 |\n| chocolateAndFruity | -0.18310419 | 0 |\n\n### Conclusion <a name=\"disc_out\"/>\n\nWith the best feature values, you get a *winpercent* of 84.74%. You should interpret those as indicators that a sweet and cost efficient candy is preferred. The data is really simplistic. It tells nothing about the quality of the ingredients. Features like *sugarpercent_squared* and *pricepercent_squared* could be included. A more complex model can also be used to model non linear relations. However, the current data does not show clear evidence of a more complex relation. Thus, a Linear Regression suffices. It could be beneficial to include more information about the ingredients into future datasets to potentially obtain a more detailed optimal recipe."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}