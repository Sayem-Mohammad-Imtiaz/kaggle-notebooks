{"cells":[{"metadata":{},"cell_type":"raw","source":"Bu veri seti yer alan film bilgileri hakkında tahminleme yapmaktadır.","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"-> Seçilen veri seti import edildi ve içindeki veriler okutuldu.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nmovie=pd.read_csv(\"../input/imdb-extensive-dataset/IMDb movies.csv\")\nmovie.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movie.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"-> Veri setindeki satır sayısı,veri tipi ve değişken isimleri öğrenilerek dataset hakkında genel bilgiye sahip olundu.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Satir Sayisi\nprint(\"Satır Sayısı:\\n\",movie.shape[0:])\n\n# Sutun Adlari\nprint(\"Sütun Adlari:\\n\",movie.columns.tolist())\n\n# Veri Tipleri\nprint(\"Veri Tipleri:\\n\",movie.dtypes)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"-> Dataset üzerinde analiz , modelleme yapabilmek için eksik veri sayısı kontrolü yapıldı.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Eksik veri sayıları ve veri setindeki oranları \nimport matplotlib.pyplot as plt\nimport seaborn as sns\npd.concat([movie.isnull().sum(), 100 * movie.isnull().sum()/len(movie)], \n              axis=1).rename(columns={0:'Missing Records', 1:'Percentage (%)'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"-> Dram türü için \"Puanlama, Film Süresi, Film Yılı ve Ortalama Puan\" bilgileri arasındaki ilişkiyi gözlemleyebilmek adına korelasyon grafiği oluşturuldu.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dram türü için korelasyon grafiği\ndrama=movie.copy()\ndrama_values = (drama['genre'] == 'Drama').astype(int)\nfields = list(drama.columns[:-4])\ncorrelations = drama[fields].corrwith(drama_values)\ncorrelations.sort_values(inplace=True)\ncorrelations\nax = correlations.plot(kind='bar')\nax.set(ylim=[-1, 1], ylabel='Drama Correlation');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"-> Suç türü için \"Puanlama, Film Süresi, Film Yılı ve Ortalama Puan\" arasındaki ilişkiyi gözlemleyebilmek adına korelasyon grafiği oluşturuldu.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Suç türü için korelasyon grafiği\ncrime=movie.copy()\ncrime_values = (drama['genre'] == 'Crime').astype(int)\nfields = list(drama.columns[:-4])  \ncorrelations = drama[fields].corrwith(crime_values)\ncorrelations.sort_values(inplace=True)\ncorrelations\nax = correlations.plot(kind='bar')\nax.set(ylim=[-1, 1], ylabel='Crime Correlation');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"-> Veri setin içerisinden belirli alanlar seçilerek yeni bir veriseti oluşturuldu. Sonra dataframedeki sürekli değişkenler için describe metodu ile \"count,mean ,min ,max\" değerleri öğrenildi.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Veri seti içerisinden belli alanlar seçilerek yeni bir veriseti oluşturuldu.\n\ndf1=pd.Series(movie['duration'],name=\"duration\")\ndf2=pd.Series(movie['votes'],name=\"votes\")\ndf_movie=pd.concat([df1,df2], axis=1)\ndf_movie.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"-> Aykırı değer gözlemi yapabilmek adına sürekli değişkenler için boxplotlar oluşturuldu. Aykırı değer analizi ile değişkenler içerisindeki değerlerin ortalama ile mi seyrettiği yoksa büyük farklılıkların mı olduğu sonucuna varırız. Buradan değerler arasında büyük farklılıklar olduğunu gözlemliyoruz.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\ndf_movie.boxplot(column=['duration','votes'])\n\nfig,axs=plt.subplots(2,2) \naxs[0, 0].boxplot(df_movie['duration'])\naxs[0, 0].set_title('duration')\n\naxs[0, 1].boxplot(df_movie['votes'])\naxs[0, 1].set_title('votes')\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"-> Oluşturulan dataframe'in histogram grafiği incelenmiştir.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Histogram grafiği\nfrom matplotlib import pyplot\ndf_movie.hist()\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"-> Oluşturulan dataframe'in yıla ve aldığı puanlamaya göre dağılım grafiği matrisi elde edilmiştir.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scatter Plot Matrix\nfrom pandas.plotting import scatter_matrix\nscatter_matrix(df_movie)\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"-> Amerikada izlenen filmler için \"Film Yılı, Film Süresi, Ortalama Puanı, Metascoru, Puanı, Kullanıcı Yorumları\" bilgileri arasındaki ilişkiyi gözlemleyebilmek adına korelasyon grafiği oluşturuldu.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Amerikada izlenen filmler için korelasyon grafiği\nus=movie.copy()\ny = (us['country'] == 'USA').astype(int)\nfields = list(us.columns[:-1])  # everything except \"country name\"\ncorrelations = us[fields].corrwith(y)\ncorrelations.sort_values(inplace=True)\ncorrelations\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = correlations.plot(kind='bar')\nax.set(ylim=[-1, 1], ylabel='USA Correlation');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"-> Aykırı değer gözlemi yapabilmek adına sürekli değişkenler için boxplotlar oluşturuldu. Aykırı değer analizi ile değişkenler içerisindeki değerlerin ortalama ile mi seyrettiği yoksa büyük farklılıkların mı olduğu sonucuna varırız. Burada Puan değerleri hariç diğer değerlerin ortalama seyrettiğini gözlemliyoruz.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\nmovie.boxplot(column=['year','duration','avg_vote','metascore','votes','reviews_from_users'])\n\nfig,axs=plt.subplots(2,3) \naxs[0, 0].boxplot(movie['year'])\naxs[0, 0].set_title('Film Yılı')\n\naxs[0, 1].boxplot(movie['duration'])\naxs[0, 1].set_title('Film Süresi')\n\naxs[0, 2].boxplot(movie['avg_vote'])\naxs[0, 2].set_title('Film Hakkında Yapılan Ortalama Oy Sayısı')\n\naxs[1, 0].boxplot(movie['metascore'])\naxs[1, 0].set_title('Metascore')\n\naxs[1, 1].boxplot(movie['votes'])\naxs[1, 1].set_title('Film Hakkında Yapılan Oylama Sayısı')\n\naxs[1, 2].boxplot(movie['reviews_from_users'])\naxs[1, 2].set_title('Film Hakkında Kullanıcı Yorumları')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"-> Oluşturulan dataframe için 'votes ,duration' değişkenleri üzerinden 'votes'(Film Puanlanması) üzerine tahminleme yapıldı.\n\n-> Veri modellemeden önce normalize edildi.Bunu yaparken MinMaxScaler kullanıldı.\n\nBu yöntemde, bir grup verinin içerisindeki en büyük ve en küçük değerler ele alınır. Diğer bütün veriler, bu değerlere göre normalleştirilir.\n\n-> Yapılan tahminleme sonucunda 3 algoritma kullanıldı. Bunlar;\n* Lineer Regresyon\n* Decision Tree Classifier\n* Naive Bayes -Gaussian Yöntemi\n\n-> Bunlardan doğruluk değeri yüksek olup MSE değeri düşük olarak en iyi tahmini yapıp en yakın sonucu veren algoritma Lineer Regresyon oldu.\n   İkinci en yakın tahmini yapan ise, Decision Tree Classifier (Karar Ağaçları Sınıflandırıcısı) oldu.\n   \n-> Veriler modellemeye hazır hale getirildikten sonra algoritmalar uygulandı ve tahmin sonuçları da birden farklı başarı değeri ile kıyaslandı.\n    Başarı kıyaslamaları ise;\n* Karışıklık Matrisi (Confusion Matrix)   \n* Sınıflandırma Raporlamaları (Classification Report)\n* Ortalama Kare Hatası (MSE)  ile yapıldı.\n\n->Modelleme yaparken denenen değerler arasında test boyutu için 0.3, random state için 0 ile en iyi sonuca ulaşıldı. Test boyutu ve random state büyüdükçe doğruluk değeri düşüp hata oranı büyüdü. Bunun yanında, dataframe boyutu, eğitim verisi boyutu ve test verisi boyutu gösterildi.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Film süresine göre oylamanın nasıl olduğu hakkında bilgi almak için veri eğitildi.\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\n\nX = df_movie\ny = df_movie['votes']\n\nmms = MinMaxScaler()\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.3, random_state=0)\nX_train = mms.fit_transform(X_train) \nX_test= mms.fit_transform(X_test)\n\nprint(\"Dataframe boyutu: \",df_movie.shape)\nprint(\"Eğitim verisi boyutu: \",X_train.shape, y_train.shape)\nprint(\"Test verisi boyutu: \",X_test.shape,y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# type error için target typesı \"Label Encoder\" ile  multiclassa çevirdim.(Target=Y_train)\nfrom sklearn import preprocessing\nfrom sklearn import utils\n\nlab_enc = preprocessing.LabelEncoder()\nencoded = lab_enc.fit_transform(y)\nprint(utils.multiclass.type_of_target(y))\nprint(utils.multiclass.type_of_target(y_train.astype('int')))\nprint(utils.multiclass.type_of_target(encoded))\n\nlab_enc = preprocessing.LabelEncoder()\nY_train = lab_enc.fit_transform(y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom sklearn    import metrics, svm\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn import  linear_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Her bir modelin doğruluk değeri ,sınıflandırma raporu , karışıklık matrisi ve MSE(Ortalama Kare Hata Regresyon Oranı) değerlerini hesaplamak için import edildi.\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lineer Regresyon\nprint(\"\\nLineer Regresyon\")\nlm = linear_model.LinearRegression()\nmodel = lm.fit(X_train, Y_train)\ny_true1 , y_pred1 =y_test,lm.predict(X_test)\nprint(\"\\nTahmin değerleri: \",y_pred1)\nplt.scatter(y_true1, y_pred1,c='blue')\nplt.scatter(y_true1, y_test,c='pink')\nplt.xlabel(\"True Values\")\nplt.ylabel(\"Predictions\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lineer Regresyon\n#predictions multiclass olduğundan y_validation da multiclassa dönüştürüldü\nencoded_v = lab_enc.fit_transform(y_true1)\nutils.multiclass.type_of_target(y_true1.astype('int'))\nypred1= lab_enc.fit_transform(y_pred1)\nutils.multiclass.type_of_target(ypred1.astype('int'))\nconf=confusion_matrix(encoded_v, ypred1)\nprint(\"\\nConfusion matrix :\\n\",conf)\nprint(\"Accuracy score(Doğruluk değeri):\\n\",accuracy_score(encoded_v, ypred1))\nprint(\"\\nClassification Report:\\n\",classification_report(encoded_v, ypred1))\nprint(\"MSE:\",mean_squared_error(encoded_v, ypred1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Decision Tree Classifier\nprint(\"Decision Tree Classifier\")\nclf = DecisionTreeClassifier()\nclf.fit(X_train, Y_train)\ny_true5 , y_pred5=y_test,clf.predict(X_test)\nprint(\"\\nTahmin değerleri: \",y_pred5)\nplt.scatter(y_true5, y_pred5,c='orange')\nplt.scatter(y_true5, y_test,c='purple')\nplt.xlabel(\"True Values\")\nplt.ylabel(\"Predictions\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predictions multiclass olduğundan y_validation da multiclassa dönüştürüldü\nencoded_v4 = lab_enc.fit_transform(y_true5)\nutils.multiclass.type_of_target(y_true5.astype('int'))\nypred5= lab_enc.fit_transform(y_pred5)\nutils.multiclass.type_of_target(ypred5.astype('int'))\nconf=confusion_matrix(encoded_v4, ypred5)\nprint(\"\\nConfusion matrix :\\n\",conf)\nprint(\"Accuracy score(Doğruluk değeri):\\n\",accuracy_score(encoded_v4, ypred5))\nprint(\"\\nClassification Report:\\n\",classification_report(encoded_v4, ypred5))\nprint(\"MSE:\",mean_squared_error(encoded_v4, ypred5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# GaussianNB\nprint(\"GaussianNB\")\nclf = GaussianNB()\nclf.fit(X_train, Y_train)\ny_true3 , y_pred3=y_test,clf.predict(X_test)\nprint(\"\\nTahmin değerleri: \",y_pred3)\nplt.scatter(y_true3, y_pred3,c='pink')\nplt.scatter(y_true3, y_test,c='orange')\nplt.xlabel(\"True Values\")\nplt.ylabel(\"Predictions\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# GaussianNB\n#predictions multiclass olduğundan y_validation da multiclassa dönüştürüldü\nencoded_v2 = lab_enc.fit_transform(y_true3)\nutils.multiclass.type_of_target(y_true3.astype('int'))\nypred3= lab_enc.fit_transform(y_pred3)\nutils.multiclass.type_of_target(ypred3.astype('int'))\nconf=confusion_matrix(encoded_v2, ypred3)\nprint(\"\\nConfusion matrix :\\n\",conf)\nprint(\"Accuracy score(Doğruluk değeri):\\n\",accuracy_score(encoded_v2, ypred3))\nprint(\"\\nClassification Report:\\n\",classification_report(encoded_v2, ypred3))\nprint(\"MSE:\",mean_squared_error(encoded_v2, ypred3))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}