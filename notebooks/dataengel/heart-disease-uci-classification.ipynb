{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import the general libraries\n\nimport os \nimport pandas as pd \nimport sklearn \nimport matplotlib.pyplot as plt\n\n# Import all specific modules\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.svm import SVC\nfrom sklearn.svm import LinearSVC\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.decomposition import IncrementalPCA\nfrom sklearn.linear_model import LogisticRegression \nfrom sklearn.preprocessing import StandardScaler \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import KernelPCA\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import accuracy_score\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Verify the dataset path \n\nos.listdir('../input/heart-disease-uci')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import the dataset\n\ndf_heart = pd.read_csv('../input/heart-disease-uci/heart.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Show the dataset\n\ndf_heart.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the dataset without target row\n\ndf_heart_features = df_heart.drop(['target'], axis=1)\ndf_heart_features.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a df just with target row\n\ndf_target = df_heart['target']\ndf_target.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We gonna normalize the data\n\ndf_heart_features = StandardScaler().fit_transform(df_heart_features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cut train test and test split \n\nX_train, X_test, y_train, y_test = train_test_split(df_heart_features, df_target, test_size=0.3, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We gonna review the size\n\nprint(\" X_train size: \" ,X_train.shape)\nprint(\" y_train size: \" ,y_train.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Config to apply pca \n\npca = PCA(n_components = 3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we fit pca for own train data\n\npca.fit(X_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We are the same with IPCA and we add batch_size to keep training slowly and combine with the final result\n\nipca = IncrementalPCA(n_components=3, batch_size=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we fit ipca for own train data \n\nipca.fit(X_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''We are going to graph what the pca automatically generated for me on the x-axis, against the y-axis, \nthe value of the importance in each of these components, so we can identify which ones are really important \nfor our model'''\n\nplt.plot(range(len(pca.explained_variance_)), pca.explained_variance_ratio_)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We gonna config the logistic regression \n\nregLog = LogisticRegression(solver='lbfgs')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We gonna config the train data of PCA\n\ndf_train = pca.transform(X_train)\ndf_test = pca.transform(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We send data at logistic regression\n\nregLog.fit(df_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We gonna calcula the score\n\nprint(\"Score PCA: \", regLog.score(df_test, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We gonna config the train data of IPCA\n\ndf_train = ipca.transform(X_train)\ndf_test = ipca.transform(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We send data at logistic regression\n\nregLog.fit(df_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We gonna calcula the score\n\nprint(\"SCORE IPCA: \", regLog.score(df_test, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Apply a kernel PCA","metadata":{}},{"cell_type":"code","source":"# Apply polynomial kernel function\nkpca = KernelPCA(n_components=4, kernel='poly' )\n    \n# Fit the data\nkpca.fit(X_train)\n \n# Apply the algoritm to test and train dataset\ndt_train = kpca.transform(X_train)\ndt_test = kpca.transform(X_test)\n \n# Apply logistic regression later reduce the dimensionality\nlogistic = LogisticRegression(solver='lbfgs')\n \n# Train the model\nlogistic.fit(dt_train, y_train)\n \n# Print the results\nprint(\"SCORE KPCA: \", logistic.score(dt_test, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Apply All Clasifiers","metadata":{}},{"cell_type":"code","source":"knn_class = KNeighborsClassifier().fit(X_train, y_train)\nknn_prediction = knn_class.predict(X_test)\nprint('='*64)\nprint('SCORE con KNN: ', accuracy_score(knn_prediction, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"estimators = {\n        'LogisticRegression' : LogisticRegression(),\n        'SVC' : SVC(),\n        'LinearSVC' : LinearSVC(),\n        'SGD' : SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=5),\n        'KNN' : KNeighborsClassifier(),\n        'DecisionTreeClf' : DecisionTreeClassifier(),\n        'RandomTreeForest' : RandomForestClassifier(random_state=0)\n    }\nfor name, estimator in estimators.items():\n    bag_class = BaggingClassifier(base_estimator=estimator, n_estimators=50).fit(X_train, y_train)\n    bag_predict = bag_class.predict(X_test)\n    print('='*64)\n    print('SCORE Bagging with {} : {}'.format(name, accuracy_score(bag_predict, y_test)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Boosting","metadata":{}},{"cell_type":"code","source":"# Definimos nuestro clasificador, definimos 50 arbole y le agregamos el ajuste\n# Define the classifier, define 50 threes and add the fit\nboost = GradientBoostingClassifier(n_estimators=50).fit(X_train, y_train)\n\n# Generate the predictions \nboost_pred = boost.predict(X_test)\nprint(\"=\"*64)\nprint(\"GradientBoostingClassifier: \", accuracy_score(boost_pred, y_test)) \n\nestimators = range(10, 200, 10)\ntotal_accuracy = []\nfor i in estimators:\n    boost = GradientBoostingClassifier(n_estimators=i).fit(X_train, y_train)\n    boost_pred = boost.predict(X_test)\n\n    total_accuracy.append(accuracy_score(y_test, boost_pred))\n    \nplt.plot(estimators, total_accuracy)\nplt.xlabel('Estimators')\nplt.ylabel('Accuracy')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}