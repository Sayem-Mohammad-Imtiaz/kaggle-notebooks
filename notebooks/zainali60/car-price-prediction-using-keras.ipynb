{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Loading data and cheking five rows \ndf_car=pd.read_csv(\"../input/car-price-prediction/CarPrice_Assignment.csv\")\ndf_car.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=df_car.iloc[:,:-1]\ny=df_car.iloc[:,-1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.drop(X.select_dtypes(include='object'),axis=1,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Shape of input ==> X :{X.shape}\\nShape of output ==> Y :{y.shape} \")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train=X.sample(frac=0.7, replace=True, random_state=1,axis=0)\ny_train=y.sample(frac=0.7, replace=True, random_state=1,axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test=X.sample(frac=0.3, replace=True, random_state=1,axis=0)\ny_test=y.sample(frac=0.3, replace=True, random_state=1,axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"shape of training data is :{X_train.shape}\\nshape of training label is :{y_train.shape}\\nshape of testing data is :{X_test.shape}\\nshape of testing label is :{y_test.shape}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train=np.asarray(X_train).astype(\"float32\")\nX_test=np.asarray(X_test).astype(\"float32\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean = X_train.mean(axis=0)\nX_train-= mean\nstd = X_train.std(axis=0)\nX_train/= std\nX_test-= mean\nX_test/= std","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_mean = y_train.mean(axis=0)\ny_train-= y_mean\ny_std = y_train.std(axis=0)\ny_train/= y_std\ny_test-= y_mean\ny_test/= y_std","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_x=X_train[:50]\npartial_x_train=X_train[50:]\nval_y=y_train[:50]\npartial_y_train=y_train[50:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom keras import models,layers,optimizers,losses\nnetwork=models.Sequential()\nnetwork.add(layers.Dense(10,activation=\"relu\" ,input_shape=(X_train.shape[1],)))\nnetwork.add(layers.Dropout(0.2))\nnetwork.add(layers.Dense(8,activation=\"relu\"))\n#network.add(layers.Dropout(0.2))\nnetwork.add(layers.Dense(6,activation=\"relu\"))\nnetwork.add(layers.Dense(1))\nnetwork.compile(optimizer=\"rmsprop\",loss=\"mse\",metrics=[\"mae\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"network.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history=network.fit(partial_x_train, partial_y_train,epochs=45, batch_size=1, verbose=1,validation_data=(val_x,val_y))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.plot(epochs, loss,\"go\",label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.grid()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"network.evaluate(X_test,y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_1=network.predict(X_test)\nresult_1[4]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y=result_1\ny1=range(62)\nx=y_test\nplt.scatter(x, y1, label= \"Actual price\", color= \"green\", marker= \"*\", s=100)\nplt.scatter(y, y1, label= \"Predicted Price\", color= \"yellow\", marker= \"^\", s=100)\nplt.xlabel('Price')\nplt.ylabel('Rows')\nplt.title('Actual price vs predicted price!')\nplt.legend()\nplt.grid()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}