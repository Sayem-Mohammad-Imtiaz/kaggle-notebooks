{"cells":[{"metadata":{},"cell_type":"markdown","source":"<hr/>\n\n# Emergency 911 Calls - Exploratory Data Analysis\n**[by Tomas Mantero](https://www.kaggle.com/tomasmantero)**\n<hr/>\n\n### Table of Contents\n* **1. [Introduction](#ch1)**\n* **2. [Dataset](#ch2)**\n    * 2.1 Imports\n    * 2.2 Get the Data\n    * 2.3 Analyze by Describing Data\n* **3. [Creating New Features](#ch3)**\n* **4. [Exploratory Data Analysis (EDA)](#ch4)**\n* **5. [Overall 911 Emregency Calls](#ch5)**\n* **6. [Feature Engineering](#ch6)**\n* **7. [Heatmap](#ch7)**\n* **8. [Clustermap](#ch8)**\n* **9. [References](#ch9)**"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"ch1\"></a>\n# 1. Introduction \n<hr/>\n\nOne of the objectives of this notebook is to **show step-by-step how to analyze and visualize the dataset to better understand 911 calls and what originates them.** Moreover, we are going to explain most of the concepts used so that you understand why we are using them. \n\nIf you have a question or feedback, do not hesitate to write and if you like this kernel,<b><font color='green'> please upvote! </font></b>\n\nThe following questions will be answered throughout the Kernel:\n* ***Which features are available in the dataset?***\n* ***How many rows and columns does the dataset have?***\n* ***Which features are categorical?***\n* ***Which features are numerical?***\n* ***Which features contain blank, null or empty values?***\n* ***What are the data types for various features?***\n* ***How many zip codes does the dataset have?***\n* ***What are the top 5 zip codes for 911 calls?***\n* ***What are the top 5 townships (twp) for 911 calls?***\n* ***How many unique title of emergency codes are there?***\n* ***What is the most common Reason for a 911 call based off of this new column?***\n\n\n\n<img src=\"https://images.pexels.com/photos/3584101/pexels-photo-3584101.jpeg?auto=compress&cs=tinysrgb&h=750&w=1260\" title=\"source: www.pexels.com\" width=\"600\" height=\"600\"/>\n<br>"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"ch2\"></a>\n# 2. Dataset\n<hr/>\n\n* This dataset contains emergency calls from Montgomery County, PA. \n* It includes calls from 2015 to 2020. \n\n***Montgomery County***\n\nMontgomery County, locally also referred to as Montco, is a county located in the Commonwealth of Pennsylvania. As of the 2010 census, the population was 799,874, making it the third-most populous county in Pennsylvania, after Philadelphia and Allegheny Counties. The county seat is Norristown. Montgomery County is very diverse, ranging from farms and open land in Upper Hanover to densely populated rowhouse streets in Cheltenham.\n\n***911 Calls***\n\nCreated by Congress in 2004 as the 911 Implementation and Coordination Office (ICO), the National 911 Program is housed within the National Highway Traffic Safety Administration at the U.S. Department of Transportation and is a joint program with the National Telecommunication and Information Administration in the Department of Commerce.\n\n***Feature Columns***\n    \n* **lat:** String variable, Latitude\n* **lng:** String variable, Longitude\n* **desc:** String variable, Description of the Emergency Call\n* **zip:** String variable, ZIP Code\n* **title:** String variable, Title of Emergency\n* **timeStamp:** String variable, Date and time of the call, YYYY-MM-DD HH:MM:SS\n* **twp:** String variable, Township\n* **addr:** String variable, General Address\n* **e:** String variable, Dummy variable, Index column (always 1)"},{"metadata":{},"cell_type":"markdown","source":"## 2.1 Imports"},{"metadata":{"trusted":true},"cell_type":"code","source":"# data analysis and wrangling\nimport pandas as pd\nimport numpy as np\nimport random as rnd\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.2 Get the Data\nThe Python Pandas packages helps us work with our datasets. We start by acquiring the datasets into Pandas DataFrames."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/montcoalert/911.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.3 Analyze by describing data\nPandas also helps describe the datasets answering following questions early in our project.\n\n***Which features are available in the dataset?***"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print(df.columns.values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***How many rows and columns does the dataset have?***"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('Rows     :',df.shape[0])\nprint('Columns  :',df.shape[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Which features are categorical?***\n\n* Categorical: desc, zipcode, title, twp, addr, e.\n\n***Which features are numerical?***\n\n* Continous: lat, lng.\n* Discrete: timeStamp."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# preview the data\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dropping column e"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop('e',axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Which features contain blank, null or empty values?***\n\nWe can check for missing values with pandas isnull(). This indicates whether values are missing or not. Then we can sum all the values to check every column.\n* There are 80492 missing values in the dataset. \n* For the purpose of this notebook it is not necessary to drop or fill the missing values, as we will only do a visual alanlizis."},{"metadata":{"trusted":true},"cell_type":"code","source":"# missing values\nprint('Missing values:',df.isnull().values.sum())\n\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***What are the data types for various features?***\n\nThree features are floats and five are objects. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***How many zip codes does the dataset have?***"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['zip'].nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***What are the top 5 zip codes for 911 calls?***"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df_zip = pd.DataFrame(df['zip'].value_counts().head(5))\ndf_zip.rename(columns = {'zip':'Top 5'}, inplace = True)\ndf_zip.style.background_gradient(cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**What are the top 5 townships (twp) for 911 calls?**"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df_twp = pd.DataFrame(df['twp'].value_counts().head(5))\ndf_twp.rename(columns = {'twp':'Top 5'}, inplace = True)\ndf_twp.style.background_gradient(cmap='Greens')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***How many unique title of emergency codes are there?***"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['title'].nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"ch3\"></a>\n# 3. Creating new features\n<hr/>"},{"metadata":{},"cell_type":"markdown","source":"### Reason feature\nIn the titles column there are \"Reasons/Departments\" specified before the title code. These are **EMS, Fire, and Traffic.** We are going to use `.apply()` with a custom lambda expression to create a new column called \"Reason\" that contains this string value.\n\nFor example, if the title column value is *EMS: BACK PAINS/INJURY* , the Reason column value would be *EMS.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['reason'] = df['title'].apply(lambda title: title.split(':')[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Title_code feature\nUsing the same method from above, we are going to create a column with just the title code. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df['title_code'] = df['title'].apply(lambda title: title.split(':')[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"ch4\"></a>\n# 4. Exploratory Data Analysis (EDA)\n<hr/>"},{"metadata":{},"cell_type":"markdown","source":"**What is the most common Reason for a 911 call based off of this new column?**\n* The number one reason for 911 calls are Emergency Medical Services.\n* Almost half of the reasons are for EMS."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df['reason'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1,2, figsize=(15, 5))\n\nsns.countplot(x='reason', data=df, order=df['reason'].value_counts().index, ax=axes[0])\naxes[0].set_title('Common Reasons for 911 Calls', size=13)\naxes[0].set(xlabel='Reason', ylabel='Count')\n\ndf['reason'].value_counts().plot.pie(autopct='%1.1f%%',ax=axes[1],shadow=True)\naxes[1].set(xlabel='', ylabel='')\n\nsns.despine(bottom=False, left=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"ch5\"></a>\n# 5. Overall 911 Emregency Calls\n<hr/>\n\nThe barcahrt shows the **top 10 emergency calls** from all the categories.\n* Vehicle accidents are the number one reason people call 911. \n* Disabled vehicle and fire alarm are in second and third place. "},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(figsize=(10, 5))\nsns.countplot(y='title', data=df, order=df['title'].value_counts().index, palette='prism')\nsns.despine(bottom=False, left=True)\naxes.set_ylim([9, 0])\naxes.set_title('Overall 911 Emregency Calls', size=15)\naxes.set(xlabel='Number of 911 Calls', ylabel='')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Traffic 911 Emergency Calls\n* The most common emergency titles are vehicle accident, disable vehicle and road obstruction."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df[df['reason']=='Traffic'].groupby('title_code').count()['lat'].sort_values(ascending=True).plot(kind='barh', figsize=(10, 5), color='darkblue')\nplt.xlabel('Number of 911 Calls')\nplt.ylabel('')\nplt.title('Traffic 911 Emergency Calls', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fire 911 Emergency Calls\n* The most common emergency titles are fire alarm, vehicle accident and fire investigation."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df[df['reason']=='Fire'].groupby('title_code').count()['lat'].sort_values(ascending=True).tail(10).plot(kind='barh', figsize=(10, 5), color='darkred')\nplt.xlabel('Number of 911 Calls')\nplt.ylabel('')\nplt.title('Fire 911 Emergency Calls', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### EMS 911 Emergency Calls\n* The most common emergency titles are fall victim, respiratory emergency and cardiac emergency."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df[df['reason']=='EMS'].groupby('title_code').count()['lat'].sort_values(ascending=True).tail(10).plot(kind='barh', figsize=(10, 5), color='darkgreen')\nplt.xlabel('Number of 911 Calls')\nplt.ylabel('')\nplt.title('EMS 911 Emergency Calls', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"ch6\"></a>\n# 6. Feature Engineering\n<hr/>"},{"metadata":{},"cell_type":"markdown","source":"### TimeStamp feature\nWe are going to use [pd.to_datetime](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.to_datetime.html) to convert the timeStamp column from string to DateTime object. Then we use `.apply()` to create 3 new columns called Hour, Month, and Day of Week."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['timeStamp'] = pd.to_datetime(df['timeStamp'])\n\ndf['Hour'] = df['timeStamp'].apply(lambda time: time.hour)\ndf['Month'] = df['timeStamp'].apply(lambda time: time.month)\ndf['Day of Week'] = df['timeStamp'].apply(lambda time: time.dayofweek)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Notice how the Day of Week is an integer 0-6. Let's map the actual string names to the day of the week:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# dictionary string names\ndmap = {0:'Mon',1:'Tue',2:'Wed',3:'Thu',4:'Fri',5:'Sat',6:'Sun'}\n\ndf['Day of Week'] = df['Day of Week'].map(dmap)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###  Weekly and monthly calls\n* It looks like friday is the day with more calls during the week. \n* Regarding the monthly calls, looks like during the first semester there are more calls."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1,2, figsize=(15,5))\n\nsns.countplot(x='Day of Week', data=df, palette='viridis', ax=axes[0])\naxes[0].set_title('Weekly Calls', size=15)\n\nsns.countplot(x='Month', data=df, hue='reason', palette='viridis', ax=axes[1])\naxes[1].set_title('Monthly Calls', size=15)\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0)\n\nsns.despine(bottom=False, left=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Date feature\nCreate a new column called 'Date' that contains the date from the timeStamp column."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Date'] = df['timeStamp'].apply(lambda t: t.date())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now groupby this Date column with the count() aggregate and create a plot of counts of 911 calls by reason."},{"metadata":{},"cell_type":"markdown","source":"### Traffic"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df[df['reason']=='Traffic'].groupby('Date').count()['lat'].plot(figsize=(15,5), color='darkblue')\nplt.title('Traffic', fontsize=15)\nsns.despine(bottom=False, left=True)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fire"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df[df['reason']=='Fire'].groupby('Date').count()['lat'].plot(figsize=(15,5), color='darkred')\nplt.title('Fire', fontsize=15)\nsns.despine(bottom=False, left=True)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### EMS"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df[df['reason']=='EMS'].groupby('Date').count()['lat'].plot(figsize=(15,5), color='darkgreen')\nplt.title('EMS', fontsize=15)\nsns.despine(bottom=False, left=True)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"ch7\"></a>\n# 7. Heatmap\n<hr/>\nNow let's move on to creating heatmaps with seaborn and our data. We'll first need to restructure the dataframe so that the columns become the Hours and the Index becomes the Day of the Week. There are lots of ways to do this, but I would recommend trying to combine groupby with an unstack method.\n* In the heatmap we can see that during 14:00 and 17:00 hours there are more calls. \n* Friday and Wednesday have more calls.\n* Apparently during Sunday the calls drop."},{"metadata":{"trusted":true},"cell_type":"code","source":"dayHour = df.groupby(by=['Day of Week', 'Hour']).count()['reason'].unstack()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.heatmap(dayHour, cmap='viridis', linewidths=0.05)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"ch8\"></a>\n# 8. Clustermap\n<hr/>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.clustermap(dayHour, cmap='viridis', linewidths=0.05)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"ch9\"></a>\n# 9. References\n---\n* [An Introduction to Statistical Learning with Applications in R](http://faculty.marshall.usc.edu/gareth-james/ISL/) - This book provides an introduction to statistical learning methods.\n* [Python for Data Science and Machine Learning Bootcamp](https://www.udemy.com/course/python-for-data-science-and-machine-learning-bootcamp/) - Use Python for Data Science and Machine Learning."},{"metadata":{},"cell_type":"markdown","source":"# Feedback\n* **Your feedback is much appreciated**\n* **<b><font color='green'>Please UPVOTE if you LIKE this notebook</font></b>**\n* **Comment if you have any doubts or you found any errors in the notebook**"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}