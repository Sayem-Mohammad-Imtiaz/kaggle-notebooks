{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"import pandas as pd \nimport numpy as np\nimport string, re\nimport nltk\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer,HashingVectorizer, CountVectorizer\nfrom sklearn import naive_bayes,metrics, linear_model,svm, grid_search\nimport time,random\nimport operator\nfrom tabulate import tabulate\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.linear_model import RidgeClassifier\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import PassiveAggressiveClassifier\nfrom sklearn.naive_bayes import BernoulliNB, MultinomialNB\nfrom sklearn.neighbors import KNeighborsClassifier\n\nstop_list = nltk.corpus.stopwords.words('english')\nlemmatizer = nltk.stem.WordNetLemmatizer()\npunctuation = list(string.punctuation)\nstop_list = stop_list + punctuation +[\"rt\", 'url']\n\ndata = pd.read_csv(\"../input/Sentiment.csv\")\nclassifier =[]\ndef preprocess(tweet):\n    if type(tweet)!=type(2.0):\n        tweet = tweet.lower()\n        tweet = \" \".join(tweet.split('#'))\n        tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet)\n        tweet = re.sub('((www\\.[^\\s]+)|(https://[^\\s]+))','URL',tweet)\n        tweet = re.sub(\"http\\S+\", \"URL\", tweet)\n        tweet = re.sub(\"https\\S+\", \"URL\", tweet)\n        tweet = re.sub('@[^\\s]+','AT_USER',tweet)\n        tweet = tweet.replace(\"AT_USER\",\"\")\n        tweet = tweet.replace(\"URL\",\"\")\n        tweet = tweet.replace(\".\",\"\")\n        tweet = tweet.replace('\\\"',\"\")\n        tweet = tweet.replace('&amp',\"\")\n        tweet  = \" \".join([word for word in tweet.split(\" \") if word not in stop_list])\n        tweet  = \" \".join([word for word in tweet.split(\" \") if re.search('^[a-z]+$', word)])\n        tweet = \" \".join([lemmatizer.lemmatize(word) for word in tweet.split(\" \")])\n        tweet = re.sub('[\\s]+', ' ', tweet)\n        tweet = tweet.strip('\\'\"')\n    else:\n        tweet=''\n    return tweet\n\ndata['processed_text'] = data.text.apply(preprocess)\ncategories = data.sentiment.unique()\ncategories  = categories.tolist()\n\nx = data.processed_text.values\ny = data.sentiment.values"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"x_train, x_test, y_train, y_test = train_test_split( x, y, test_size=0.33 )\n\ndef benchmark(clf,xtrain,ytrain,xtest,ytest,categories,vec_name):\n    print('_' * 80)\n    print(\"Training on \"+ vec_name +\" : \")\n    print(clf)\n    clf.fit(xtrain, ytrain)\n    pred = clf.predict(xtest)\n    score = metrics.accuracy_score(ytest, pred)\n    print(\"Accuracy:   %0.3f\" % score)\n    print(\"Confusion Matrix:\\n\",confusion_matrix(pred, y_test),\"\\n\")\n    print(\"Classification Report:\\n\",metrics.classification_report(y_test, pred, target_names=categories))\n    print('_' * 80)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"vec_name = ['Count Vectorizer','Bigram Count Vectorizer','Hashing Vectorizer','Tfidf Vectorizer']\n# loop = True \n# while loop :\n#     print(\"\"\"\n#     0 - > Count Vectorizer\n#     1 - > Bigram Count Vectorizer\n#     2 - > Hashing Vectorizer\n#     3 - > Tfidf Vectorizer\n#     \"\"\")\n#     ans = int(input(\"Choose Vectorizer: \"))\n#     if ans not in range(4):\n#         print(\"Wrong Input, Try again!\")\n#         loop =True\n#     else:\n#         vec_index = ans\n#         loop = False\n\n# Vectorizer Definitions\nvectorizer=[]\nvectorizer.append(CountVectorizer(min_df = 0.01,max_df = 0.5, stop_words = 'english', analyzer='word'))\nvectorizer.append(CountVectorizer(ngram_range=(1, 2),token_pattern=r'\\b\\w+\\b', min_df=1))\nvectorizer.append(HashingVectorizer(stop_words='english', non_negative=True))\nvectorizer.append(TfidfVectorizer(min_df = 0.01, max_df = 0.5, sublinear_tf = True,stop_words = 'english'))\n\nvec_index = 1\nx_train_vec = vectorizer[vec_index].fit_transform(x_train)\nx_test_vec = vectorizer[vec_index].transform(x_test)\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"alpha=[ float(1)/float((10**exponent)) for exponent in range(-2, 5)]\ncompare_alphas = []\n\nif (vec_index !=2):\n    feature_names = vectorizer[vec_index].get_feature_names()\n\nx_train_vec = vectorizer[vec_index].fit_transform(x_train)\nx_test_vec = vectorizer[vec_index].transform(x_test)\n    \nprint('_' * 80)\nfor i in alpha: \n    mnb = naive_bayes.MultinomialNB(alpha = i)\n    mnb.fit(x_train_vec, y_train)\n    y_pred = mnb.predict(x_test_vec)\n    compare_alphas.append((i,mnb.score(x_test_vec,y_test)))\n    print('Multinomial Naive Bayes on '+ vec_name[vec_index] +' for alpha = '+ str(i) +' : ',\n         round(metrics.accuracy_score(y_test, y_pred),5))\n\ncompare_alphas = sorted(compare_alphas, key=lambda x: x[1],reverse=True)\nalpha = compare_alphas[0][0]\nmnb = naive_bayes.MultinomialNB(alpha = alpha)\nclassifier.append(mnb)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"alpha=[ float(1)/float((10**exponent)) for exponent in range(-2, 5)]\ncompare_alphas = []\nprint('_' * 80)\nfor i in alpha: \n    bnb = BernoulliNB(alpha = i)\n    bnb.fit(x_train_vec, y_train)\n    y_pred = bnb.predict(x_test_vec)\n    compare_alphas.append((i,bnb.score(x_test_vec,y_test)))\n    print('Bernoulli Naive Bayes on '+vec_name[vec_index] +' for alpha = '+ str(i) +' : ',\n         round(metrics.accuracy_score(y_test, y_pred),5))\n\ncompare_alphas = sorted(compare_alphas, key=lambda x: x[1],reverse=True)\nalpha = compare_alphas[0][0]\nbnb = BernoulliNB(alpha= alpha)\nclassifier.append(bnb)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"C =[ float(1)/float((10**exponent)) for exponent in range(-4, 5)]\ncompare_C = []\nprint('_' * 80)\nfor i in C:\n    logit = linear_model.LogisticRegression(multi_class='multinomial'\\\n                                                  ,solver='newton-cg',C=i)\n    logit.fit(x_train_vec, y_train)\n    y_pred = logit.predict(x_test_vec)\n    compare_C.append((i,logit.score(x_test_vec,y_test)))\n    print('Logistic Regression on '+vec_name[vec_index] +' C = '+str(i)+' : ', \n          round(metrics.accuracy_score(y_test, y_pred),5))\n\n\ncompare_C = sorted(compare_C, key=lambda x: x[1],reverse=True)\nC = compare_C[0][0]    \nlogit= linear_model.LogisticRegression(multi_class='multinomial'\\\n                                                  ,solver='newton-cg',C=C)\nclassifier.append(logit)\n\n\nrfc = RandomForestClassifier(n_estimators=100)\nclassifier.append(rfc)\nridgeClf = RidgeClassifier(tol=1e-2, solver=\"sag\")\nclassifier.append(ridgeClf)\nperceptron = Perceptron(n_iter=50,alpha=100)\nclassifier.append(perceptron)\npassive_aggressive = PassiveAggressiveClassifier(n_iter=50)\nclassifier.append(passive_aggressive)\nkNN = KNeighborsClassifier(n_neighbors=10)\nclassifier.append(kNN)\n\nfor clf in classifier:\n    benchmark(clf,x_train_vec,y_train,x_test_vec,y_test,categories,  vec_name[vec_index])"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}