{"cells":[{"metadata":{},"cell_type":"markdown","source":"# PREDICTING MNIST DIGITS"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# READ THE DATA"},{"metadata":{"trusted":true},"cell_type":"code","source":"#read the data\n\nX_raw = pd.read_csv('../input/mnist-in-csv/mnist_train.csv')\nX_raw.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = X_raw.drop('label', axis = 1)\ny_labels = X_raw['label']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_labels.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert to 3d numpy array\nX_images = X.to_numpy().reshape(-1,28,28) \nprint(X_images.shape)\nprint(X_images.dtype)\nprint(X_images.min())   \nprint(X_images.max())\n\nX_images = X_images[:5,:,:]\nprint(X_images.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  PLOT A SAMPLE"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\n# pick a sample to plot\nsample = 2\n\nfor row_im in X_images[sample]:\n    print(row_im.tolist())\nplt.imshow(X_images[sample], cmap='Greys')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Change pixels below threshold to 0"},{"metadata":{"trusted":true},"cell_type":"code","source":"threshold = 100\n\nX_images[X_images <= threshold] = 0\n\nfor row_im in X_images[sample]:\n    print(row_im.tolist())\nplt.imshow(X_images[sample], cmap='Greys')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# FIND FIRST AND LAST NON-ZERO ROWS AND COLUMNS FOR CROPPING"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#dark_rows returns a 2d array where rows are images and colums are true or false\n\n# X_images>0 converts value to true if value>0 for each element (true equals 1 in python)\ndark_rows = np.sum(X_images > 0, axis = 2) # returns sums along each row for each image \ndark_rows = dark_rows != 0      # convert to bool\nprint('Dark rows: ', dark_rows)    \n\n# X_images>0 converts value to true if value>0 for each element (true equals 1 in python)\ndark_cols = np.sum(X_images > 0, axis = 1) # returns sums along each col for each image \ndark_cols = dark_cols != 0      # convert to bool\nprint('\\nDark columns: ', dark_cols)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nindices_rows_first = list()\nindices_rows_last = list()\n\nfor row in dark_rows:\n    x = np.where(row)[0][0] #np.where(bool matrix) returns a tuple with row and column indices eg.((row indices),(col indices))\n                                # for non zero values                         \n    indices_rows_first.append(x)    # indexing to [0][0] gives first index from rows\n    \n    y = np.where(row)[0][-1]          #[0][-1] gives last index from rows\n    indices_rows_last.append(y)\n\nfirst_dark_row_indices = np.asarray(indices_rows_first)\nlast_dark_row_indices = np.asarray(indices_rows_last)\n    \n    \n    \n# similar for columns     \nindices_cols_first = list()\nindices_cols_last = list()\n\nfor row in dark_cols:\n    x = np.where(row)[0][0]                                            \n    indices_cols_first.append(x)    \n    \n    y = np.where(row)[0][-1]\n    indices_cols_last.append(y)\n\nfirst_dark_col_indices = np.asarray(indices_cols_first)\nlast_dark_col_indices = np.asarray(indices_cols_last)\n\n\nprint('First dark row indices: ', first_dark_row_indices)\nprint('First dark column indices: ', first_dark_col_indices)\nprint('Last dark row indices: ', last_dark_row_indices)\nprint('Last dark column indices: ', last_dark_col_indices)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CROPPING AND RESIZING"},{"metadata":{"trusted":true},"cell_type":"code","source":"from skimage.transform import resize\n\ncrop_size = 20  # assuming 20x20 cropped image\n\n# create an empty images array similar to X_images to store new images\nimages_resized = np.empty((X_images.shape[0], crop_size, crop_size), dtype = X_images.dtype)\n\n\nfor counter,img in enumerate(X_images):\n        \n    # resize using resize function from skimage.transform and store them to images_resized    \n    images_resized[counter] = resize(img[first_dark_row_indices[counter]:(last_dark_row_indices[counter] + 1), \n                                    first_dark_col_indices[counter]:(last_dark_col_indices[counter] + 1)],\n                                    (crop_size,crop_size), preserve_range = True)\n    \n        \nprint(images_resized.shape)   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# NEW IMAGE VS OLD IMAGE SAMPLE COMPARISION"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(X_images[sample], cmap='Greys')\nplt.show()\n\n\n#plt.imshow(images_resized[sample], cmap='Greys')\n#plt.show()\n\n# apply thresholding again\nimages_resized[images_resized <= threshold] = 0\n\nplt.imshow(images_resized[sample], cmap='Greys')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# FUNCTION FOR PROCESSING DATA"},{"metadata":{},"cell_type":"markdown","source":"We could have just made a big function to process data for both training and evaluation\nbut I wanted to output what happens after each step for intuition. Lets write a function to do the processing."},{"metadata":{"trusted":true},"cell_type":"code","source":"def process_raw_images(X_raw):\n    X = X_raw.drop('label', axis = 1)\n    y = X_raw['label']\n    \n    X_images = X.to_numpy().reshape(-1,28,28) \n    \n    threshold = 100\n    X_images[X_images <= threshold] = 0\n    \n    \n    dark_rows = np.sum(X_images > 0, axis = 2) \n    dark_rows = dark_rows != 0      \n   \n    dark_cols = np.sum(X_images > 0, axis = 1) \n    dark_cols = dark_cols != 0     \n    \n    \n    indices_rows_first = list()\n    indices_rows_last = list()\n\n    for row in dark_rows:\n        x = np.where(row)[0][0] \n        indices_rows_first.append(x)    \n    \n        y = np.where(row)[0][-1]          \n        indices_rows_last.append(y)\n\n    first_dark_row_indices = np.asarray(indices_rows_first)\n    last_dark_row_indices = np.asarray(indices_rows_last)\n      \n    indices_cols_first = list()\n    indices_cols_last = list()\n\n    for row in dark_cols:\n        x = np.where(row)[0][0]                                            \n        indices_cols_first.append(x)    \n    \n        y = np.where(row)[0][-1]\n        indices_cols_last.append(y)\n\n    first_dark_col_indices = np.asarray(indices_cols_first)\n    last_dark_col_indices = np.asarray(indices_cols_last)\n    \n    \n    \n    crop_size = 20\n    \n    images_resized = np.empty((X_images.shape[0], crop_size, crop_size), dtype = X_images.dtype)\n    \n    for counter,img in enumerate(X_images):  \n        images_resized[counter] = resize(img[first_dark_row_indices[counter]:(last_dark_row_indices[counter] + 1), \n                                    first_dark_col_indices[counter]:(last_dark_col_indices[counter] + 1)],\n                                    (crop_size,crop_size), preserve_range = True)\n        \n    # apply thresholding again\n    images_resized[images_resized <= threshold] = 0\n    \n    return images_resized ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# TEST MODELS ON THE PROCESSED DATA"},{"metadata":{"trusted":true},"cell_type":"code","source":"RawData = pd.read_csv('../input/mnist-in-csv/mnist_train.csv')\nX_resized = process_raw_images(RawData)\n\ny = RawData['label']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# flatten data from 3 dimensions to 2 dimensions\nX_resized_flat = X_resized.reshape(X_resized.shape[0], -1)\n\n# create training and validation data\nfrom sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split(X_resized_flat, y, train_size=0.8, test_size=0.2, random_state=0)\n\n# create random forest model and check accuracy on validation data\nfrom sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier()\nmodel.fit(X_train, y_train)\npredictions = model.predict(X_valid)\naccuracy = np.mean(predictions == y_valid)\n\nprint(accuracy)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}