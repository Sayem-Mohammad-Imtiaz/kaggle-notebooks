{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom textblob import TextBlob\n\nimport nltk\nfrom nltk import pos_tag\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.stem import LancasterStemmer, WordNetLemmatizer\nimport re, string, unicodedata\n#import inflect\n\nimport spacy\n#nltk.download('stopwords')\n\nimport nltk.data\n\nimport os\nimport matplotlib.pyplot as plt\nimport matplotlib\nmatplotlib.style.use('ggplot')\n#from __future__ import unicode_literals\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dataset and removing reviews having less then 5 words"},{"metadata":{"trusted":true},"cell_type":"code","source":"Amazon_Meta_Data = pd.read_csv('../input/amazon-reviews-unlocked-mobile-phones/Amazon_Unlocked_Mobile.csv',nrows=50000, encoding='utf-8')\n\n#------- Counting words in reviews ---------\nword_counts = []\nfor review in Amazon_Meta_Data['Reviews']:\n    count=0\n    for word in str(review).split():\n        count +=1\n    word_counts.append(count)\nAmazon_Meta_Data['words_counts'] = word_counts\n\n# Discarding rows having less then 5 words of review.\nAmazon_Meta_Data=Amazon_Meta_Data.loc[Amazon_Meta_Data['words_counts'] >=5]\n\nAmazon_Meta_Data.head()\n#Amazon_Meta_Data.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Function for preprocessing on data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def remove_non_ascii(words):\n    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n    new_words = []\n    for word in words:\n        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n        new_words.append(new_word)\n    return new_words\n\ndef to_lowercase(words):\n    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n    new_words = []\n    for word in words:\n        new_word = word.lower()\n        new_words.append(new_word)\n    return new_words\n\ndef remove_punctuation(words):\n    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n    new_words = []\n    for word in words:\n        new_word = re.sub(r'[^\\w\\s]', '', word)\n        if new_word != '':\n            new_words.append(new_word)\n    return new_words\n\ndef replace_numbers(words):\n    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n    p = inflect.engine()\n    new_words = []\n    for word in words:\n        if word.isdigit():\n            new_word = p.number_to_words(word)\n            new_words.append(new_word)\n        else:\n            new_words.append(word)\n    return new_words\n\ndef remove_stopwords(words):\n    \"\"\"Remove stop words from list of tokenized words\"\"\"\n    new_words = []\n    for word in words:\n        if word not in stopwords.words('english'):\n            new_words.append(word)\n    return new_words\n\ndef stem_words(words):\n    \"\"\"Stem words in list of tokenized words\"\"\"\n    stemmer = LancasterStemmer()\n    stems = []\n    for word in words:\n        stem = stemmer.stem(word)\n        stems.append(stem)\n    return stems\n\ndef lemmatize_verbs(words):\n    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n    lemmatizer = WordNetLemmatizer()\n    lemmas = []\n    for word in words:\n        lemma = lemmatizer.lemmatize(word, pos='v')\n        lemmas.append(lemma)\n    return lemmas\n\ndef normalize(words):\n    words = remove_non_ascii(words)\n    words = to_lowercase(words)\n    words = remove_punctuation(words)\n    #words = replace_numbers(words)\n    words = remove_stopwords(words)\n    return words\n\n#Steemming and Lemmatization\ndef stem_and_lemmatize(words):\n    stems = stem_words(words)\n    lemmas = lemmatize_verbs(words)\n    return stems, lemmas\n\n#stems, lemmas = stem_and_lemmatize(words)\n#print('Stemmed:\\n', stems)\n#print('\\nLemmatized:\\n', lemmas)\n\n\n# ---------------   Cleaning   ------------------\ndef clean_text(text):\n    wording = nltk.word_tokenize(text)\n    words = normalize(wording)\n    string_text = ' '.join(words)\n    return string_text\n\n#----------------------  extract Sentences  -------------------------    \ndef sentances(text):\n    sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n    return sent_detector.tokenize(text.strip())\n\n\n# ---------------   Sentiment   ------------------\ndef get_text_sentiment(text):\n    # create TextBlob object of passed text \n    analysis = TextBlob(clean_text(text)) \n    # set sentiment \n    if analysis.sentiment.polarity > 0: \n        return 'positive'\n    elif analysis.sentiment.polarity == 0: \n        return 'neutral'\n    else: \n        return 'negative'    \n    \n#---------------------- TextBlob Feature Extractions -----------------\n#Function to extract features from text\ndef textBlob_feature_extraction(text): \n        blob = TextBlob(text)\n        return blob.noun_phrases","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentences = []\nsentiment_sent =[]\nproduct_name =[]\nfor products,reviews in zip(Amazon_Meta_Data[\"Product Name\"], Amazon_Meta_Data[\"Reviews\"]): \n    for sent in sentances(reviews):\n        sentiment_sent.append(get_text_sentiment(sent))\n        sentences.append(sent)\n        product_name.append(products)\n\nall_products_dataset = pd.DataFrame()\nall_products_dataset[\"products\"] = product_name\nall_products_dataset[\"reviews_sentences\"] =  sentences\nall_products_dataset[\"sentiment\"] = sentiment_sent\n\n#Removing Neural sentences\nall_products_dataset = all_products_dataset.loc[(all_products_dataset['sentiment'] != 'neutral')]\n\n# Text Cleaning of sentences\ncleaned_reviews =[]\nfor reviews in all_products_dataset[\"reviews_sentences\"]:\n    cleaned_reviews.append(clean_text(reviews))\n    \n#inserting Cleaned reviews sentences to our dataset\nall_products_dataset.insert(2, 'cleaned_reviews_sentences ', cleaned_reviews)\n\n#Extracting Features From Reviews Sentences\nfeatures = []\nfor reviews in cleaned_reviews:\n    features.append(textBlob_feature_extraction(reviews))\n\nall_products_dataset['texblob_features_extraction']=features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Products features and their counts"},{"metadata":{"trusted":true},"cell_type":"code","source":"prod_features_counts = {}\nfor prod,feature_list, in zip(all_products_dataset['products'],all_products_dataset['texblob_features_extraction']):\n    for feature in feature_list:\n        if prod in prod_features_counts:\n            if feature in prod_features_counts[prod]:\n                prod_features_counts[prod][feature] += 1\n            else:\n                prod_features_counts[prod][feature] = 1 \n        else:\n            prod_features_counts[prod]={}\n\n#Extracting feature count form feartures\ndist_products =[]\ndist_feature_count= []\nfor key, value in prod_features_counts.items() :\n    dist_products.append(key)\n    dist_feature_count.append(value)\n    \n#----------------- Features Counts Dataset ------------------\nproducts_features_details = pd.DataFrame()\nproducts_features_details['products'] = dist_products\nproducts_features_details['feature with count'] = dist_feature_count\nproducts_features_details.head(10)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Positive reviews products features count"},{"metadata":{"trusted":true},"cell_type":"code","source":"positive_products_dataset = all_products_dataset.loc[(all_products_dataset['sentiment'] == 'positive')]\n\npositive_features_counts = {}\nfor prod,feature_list, in zip(positive_products_dataset['products'],positive_products_dataset['texblob_features_extraction']):\n    for feature in feature_list:\n        if prod in positive_features_counts:\n            if feature in positive_features_counts[prod]:\n                positive_features_counts[prod][feature] += 1\n            else:\n                positive_features_counts[prod][feature] = 1 \n        else:\n            positive_features_counts[prod]={}\n\n#Extracting feature count form feartures\ndist_products =[]\ndist_feature_count= []\nfor key, value in positive_features_counts.items() :\n    dist_products.append(key)\n    dist_feature_count.append(value)\n    \n#----------------- Features Counts Dataset ------------------\npositive_features_details = pd.DataFrame()\npositive_features_details['products'] = dist_products\npositive_features_details['feature with count'] = dist_feature_count\npositive_features_details.head(10)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Negative reviews products features count"},{"metadata":{"trusted":true},"cell_type":"code","source":"negative_products_dataset = all_products_dataset.loc[(all_products_dataset['sentiment'] == 'negative')]\n\nnegative_features_counts = {}\nfor prod,feature_list, in zip(negative_products_dataset['products'],negative_products_dataset['texblob_features_extraction']):\n    for feature in feature_list:\n        if prod in negative_features_counts:\n            if feature in negative_features_counts[prod]:\n                negative_features_counts[prod][feature] += 1\n            else:\n                negative_features_counts[prod][feature] = 1 \n        else:\n            negative_features_counts[prod]={}\n            \n#Extracting feature count form feartures\ndist_products =[]\ndist_feature_count= []\nfor key, value in negative_features_counts.items() :\n    dist_products.append(key)\n    dist_feature_count.append(value)\n    \n#----------------- Features Counts Dataset ------------------\nnegative_features_details = pd.DataFrame()\nnegative_features_details['products'] = dist_products\nnegative_features_details['feature with count'] = dist_feature_count\nnegative_features_details.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Removing Rows having null features\n#all_products_dataset = all_products_dataset.loc[(all_products_dataset.astype(str)['texblob_features_extraction'] != '[]')]\n#all_products_dataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Matching and Ranking Products"},{"metadata":{"trusted":true},"cell_type":"code","source":"#user_specification = input(\"Search Here\")\nuser_specification = 'good phone with good battery life and affordable price '\nuser_specification_sentiment = get_text_sentiment(user_specification)\nuser_specification_features = textBlob_feature_extraction(user_specification)\nfor feature in user_specification_features:\n    print(feature)\n    \n    \n#Assiging weights to products with max matching \nprod_weight = {}\nif(user_specification_sentiment == 'positive'):\n    for prod in positive_features_counts:\n        for feature in user_specification_features:\n            if prod in prod_weight:\n                if feature in positive_features_counts[prod]:\n                    prod_weight[prod] = prod_weight[prod]+ positive_features_counts[prod][feature]                    \n            else:\n                if feature in positive_features_counts[prod]:\n                    prod_weight[prod] = positive_features_counts[prod][feature]\n\n\ndist_feature =[]\ndist_feature_count= []                    \nfor key, value in prod_weight.items() :\n    dist_feature.append(key)\n    dist_feature_count.append(value)\n    \nrank_products = pd.DataFrame()\nrank_products['product'] =dist_feature\nrank_products['weight'] =dist_feature_count\nrank_products= rank_products.sort_values(by ='weight' , ascending=False)\nrank_products             ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#user_specification = input(\"Search Here\")\nuser_specification = 'good battery life and affordable price and fast processing'\nuser_specification_sentiment = get_text_sentiment(user_specification)\nuser_specification_features = textBlob_feature_extraction(user_specification)\nfor feature in user_specification_features:\n    print(feature)\n    \n    \n#Assiging weights to products with max matching \nprod_weight = {}\nif(user_specification_sentiment == 'positive'):\n    for prod in positive_features_counts:\n        for feature in user_specification_features:\n            if prod in prod_weight:\n                if feature in positive_features_counts[prod]:\n                    prod_weight[prod] = prod_weight[prod]+ positive_features_counts[prod][feature]                    \n            else:\n                if feature in positive_features_counts[prod]:\n                    prod_weight[prod] = positive_features_counts[prod][feature]\n\n\ndist_feature =[]\ndist_feature_count= []                    \nfor key, value in prod_weight.items() :\n    dist_feature.append(key)\n    dist_feature_count.append(value)\n    \nrank_products = pd.DataFrame()\nrank_products['product'] =dist_feature\nrank_products['weight'] =dist_feature_count\nrank_products= rank_products.sort_values(by ='weight' , ascending=False)\nrank_products             ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#user_specification = input(\"Search Here\")\nuser_specification = 'I need a phone with good price and good camera result '\nuser_specification_sentiment = get_text_sentiment(user_specification)\nuser_specification_features = textBlob_feature_extraction(user_specification)\nfor feature in user_specification_features:\n    print(feature)\n    \n    \n#Assiging weights to products with max matching \nprod_weight = {}\nif(user_specification_sentiment == 'positive'):\n    for prod in positive_features_counts:\n        for feature in user_specification_features:\n            if prod in prod_weight:\n                if feature in positive_features_counts[prod]:\n                    prod_weight[prod] = prod_weight[prod]+ positive_features_counts[prod][feature]                    \n            else:\n                if feature in positive_features_counts[prod]:\n                    prod_weight[prod] = positive_features_counts[prod][feature]\n\n\ndist_feature =[]\ndist_feature_count= []                    \nfor key, value in prod_weight.items() :\n    dist_feature.append(key)\n    dist_feature_count.append(value)\n    \nrank_products = pd.DataFrame()\nrank_products['product'] =dist_feature\nrank_products['weight'] =dist_feature_count\nrank_products= rank_products.sort_values(by ='weight' , ascending=False)\nrank_products             ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"user_specification = input(\"Search Here\")\n#user_specification = 'I need a phone with good price and good camera result '\nuser_specification_sentiment = get_text_sentiment(user_specification)\nuser_specification_features = textBlob_feature_extraction(user_specification)\nfor feature in user_specification_features:\n    print(feature)\n    \n    \n#Assiging weights to products with max matching \nprod_weight = {}\nif(user_specification_sentiment == 'positive'):\n    for prod in positive_features_counts:\n        for feature in user_specification_features:\n            if prod in prod_weight:\n                if feature in positive_features_counts[prod]:\n                    prod_weight[prod] = prod_weight[prod]+ positive_features_counts[prod][feature]                    \n            else:\n                if feature in positive_features_counts[prod]:\n                    prod_weight[prod] = positive_features_counts[prod][feature]\n\n\ndist_feature =[]\ndist_feature_count= []                    \nfor key, value in prod_weight.items() :\n    dist_feature.append(key)\n    dist_feature_count.append(value)\n    \nrank_products = pd.DataFrame()\nrank_products['product'] =dist_feature\nrank_products['weight'] =dist_feature_count\nrank_products= rank_products.sort_values(by ='weight' , ascending=False)\nrank_products             ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}