{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true,"collapsed":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport plotly.offline as py\nimport plotly.graph_objs as go\npy.init_notebook_mode(connected=True)\nimport spacy\nimport re\nfrom pprint import pprint\n\nimport os\nprint(os.listdir(\"../input\"))\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"data = pd.read_csv('../input/mbti_1.csv')\npersonalities = {'I':'Introversion', 'E':'Extroversion', 'N':'Intuition', \n        'S':'Sensing', 'T':'Thinking', 'F': 'Feeling', \n        'J':'Judging', 'P': 'Perceiving'}\ndata.head()","execution_count":3,"outputs":[]},{"metadata":{"_uuid":"7dc651f78347f961a24cd6a0b279900182e623be"},"cell_type":"markdown","source":"#### EDA"},{"metadata":{"trusted":true,"_uuid":"24c198c12f9575cfd83472dd372fbd104fc87477","collapsed":true},"cell_type":"code","source":"posts_len = data['posts'].apply(len)\nranges = pd.cut(posts_len, 10, labels=np.arange(1, 11)) # split length into ranges (1-1000, 1001-2000)\ncnt = ranges.value_counts()\n\nplt.figure(figsize=(10,5))\nsns.barplot(cnt.index, cnt.values)\nplt.xlabel('x1000 words')\nplt.ylabel('no of examples')\nplt.title('no of examples in each range of post length')\n\nprint('Average post length: ', posts_len.mean()) # can be used to decide the no of features we should consider","execution_count":3,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bd85b91cb6ad8c74efae019635e4100c46ee2700","collapsed":true},"cell_type":"code","source":"cnt = data.groupby(['type'])['posts'].count()\npie = go.Pie(labels=cnt.index, values=cnt.values)\nfig = go.Figure(data=[pie])\npy.iplot(fig)","execution_count":3,"outputs":[]},{"metadata":{"_uuid":"544d5f89d3ca5f9208ba7c3be9414481019f0850"},"cell_type":"markdown","source":"cleaning up the post column"},{"metadata":{"trusted":true,"_uuid":"837b0cdd93e00e9f22ae71431e82b5ae5dfe1add","collapsed":true},"cell_type":"code","source":"def replace_symbols(text):\n    text = re.sub('\\|\\|\\|', ' ', text)\n    text = re.sub('https?\\S+', '<URL>', text)\n    return text\n\ndata['cleaned_posts'] = data['posts'].apply(replace_symbols)","execution_count":4,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f34438023face1357e198925ad2f288cf94ad556","collapsed":true},"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS\n\nSTOPWORDS.add('URL') # words to not consider\nlabels = data['type'].unique()\nrow, col = 4, 4\nwc = WordCloud(stopwords=STOPWORDS)\n\nfig, ax = plt.subplots(4, 4, figsize=(20,15))\n\nfor i in range(4):\n    for j in range(4):\n        cur_type = labels[i*col+j]\n        cur_ax = ax[i][j]\n        df = data[data['type'] == cur_type]\n        wordcloud = wc.generate(df['cleaned_posts'].to_string())\n        cur_ax.imshow(wordcloud)\n        cur_ax.axis('off')\n        cur_ax.set_title(cur_type)","execution_count":6,"outputs":[]},{"metadata":{"_uuid":"96ccce2d199dd48fb73df1172fdc639ac32176b0"},"cell_type":"markdown","source":"#### prepare data for training"},{"metadata":{"trusted":true,"_uuid":"616063b4449cc091b35680f039abb0d53dd83913","collapsed":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import f1_score # better metric due to small frequence of date for few types\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import cross_validate","execution_count":5,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a55a4b8ab9f65197b433b235556d30c36f357b8","collapsed":true},"cell_type":"code","source":"type_enc = LabelEncoder()\ntype_enc.fit(data['type'])\ntype_enc.classes_","execution_count":6,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fbfe17470e6e8ca47ec44df65435db88507210d4","collapsed":true},"cell_type":"code","source":"nlp = spacy.load('en_core_web_sm')","execution_count":6,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c23c61a78d06513c1a07a0ee355f2dc9fed5bdcb"},"cell_type":"code","source":"def tokenizer(text): # slowed the traning heavily\n    doc = nlp(text)\n    # preprocess during tokenizing\n    tokens = [token.lemma_ for token in doc \n              if not (token.is_stop or token.is_digit or token.is_quote or token.is_space\n                     or token.is_punct or token.is_bracket)]    \n    return tokens\n\ntfidf = TfidfVectorizer(stop_words='english', max_features=5000)","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"e1d956c76910b4361b0ec47ed0d1f01fc2566748"},"cell_type":"markdown","source":"#### try different models"},{"metadata":{"trusted":true,"_uuid":"6e330ac5fa3b5b3cda04de095edd2c66b849f5f4","collapsed":true},"cell_type":"code","source":"clf = LogisticRegression()\n\npipe_lr = Pipeline([('tfidf', tfidf), ('lgr', clf)])","execution_count":24,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"24f21790c81a2715c3be457917f61921bbec7dd3"},"cell_type":"code","source":"kfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)","execution_count":25,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a4d6d81e2c04c6168acd4fd5ed366510c725755a","scrolled":true,"collapsed":true},"cell_type":"code","source":"scoring = {'acc': 'accuracy', 'f1': 'f1_micro'}\nresult = cross_validate(pipe_lr, data['cleaned_posts'], type_enc.transform(data['type']), scoring=scoring,\n                        cv=kfolds, n_jobs=-1, verbose=1)","execution_count":26,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a5ab59afe82c8ebb54436b23782ffe38c5add1b0","scrolled":false,"collapsed":true},"cell_type":"code","source":"print('Logistic regression model performance:')\npprint(result)\n\nfor key in result:\n    print(key + ' : ', result[key].mean())","execution_count":27,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5db26531068ce30b5171531c62b45ae22bf2c266","collapsed":true},"cell_type":"code","source":"clf = RandomForestClassifier(n_estimators=200, n_jobs=-1, max_depth=20)\n\npipe_rf = Pipeline([('tfidf', tfidf), ('rf', clf)])","execution_count":52,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"db0b9acb661257488378eaaf708832a9e9dcf17a","collapsed":true},"cell_type":"code","source":"scoring = {'acc': 'accuracy', 'f1': 'f1_micro'}\nresult = cross_validate(pipe_rf, data['cleaned_posts'], type_enc.transform(data['type']), scoring=scoring,\n                        cv=kfolds, n_jobs=-1, verbose=1)","execution_count":53,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c0faff2475000854bed926246c799d11ec91334","collapsed":true},"cell_type":"code","source":"print('Random forest model performance:')\npprint(result)\n\nfor key in result:\n    print(key + ' : ', result[key].mean())","execution_count":54,"outputs":[]},{"metadata":{"_uuid":"b78cec888fef07fec3c07c10d1c5abfe04b95da2"},"cell_type":"markdown","source":"none of the models give good results and all tree based classifiers overfit heavily"},{"metadata":{"_uuid":"0f08638d1cbaeccdeed87199dd2da5340e8c6a8e"},"cell_type":"markdown","source":"ANNs"},{"metadata":{"trusted":true,"_uuid":"6b9e1413a2b66bbe760dda187e7cf7c4cc6bda07","collapsed":true},"cell_type":"code","source":"import tensorflow as tf\nfrom sklearn.model_selection import train_test_split","execution_count":8,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a2a21fbb2227496e0c0733ede8d7f7e50935fc6f","collapsed":true},"cell_type":"code","source":"X = tfidf.fit_transform(data['cleaned_posts']).toarray()\nY = type_enc.transform(data['type'])\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5fe3948652d4a7dabb6413b1e825b2f2132869ab","collapsed":true},"cell_type":"code","source":"# def input_fn(features, labels, batch_size):\n#     dataset = tf.data.Dataset.from_tensor_slices(({'x': features}, labels))\n#     return dataset.repeat().batch(batch_size)\n\n# feature_cols = [tf.feature_column.numeric_column(key='x', shape=[5000])]","execution_count":9,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5b4fa690e24b5a77f5304c5cc695a56ff96f8ced"},"cell_type":"code","source":"def get_inp_fn(dataset, targets, num_epochs=None, shuffle=True):\n    return tf.estimator.inputs.numpy_input_fn(\n        x={'x': dataset},\n        y=np.array(targets).astype(np.int32),\n        num_epochs=num_epochs,\n        shuffle=shuffle\n    )\n\nfeature_cols = [tf.feature_column.numeric_column('x', shape=[5000])]","execution_count":10,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d194e9382cfeb4bfa89d7e3e29acb86f23b640a","collapsed":true},"cell_type":"code","source":"# run_config = tf.estimator.RunConfig(save_summary_steps=None, save_checkpoints_secs=None)\n# run_config = tf.estimator.RunConfig(keep_checkpoint_max=1, save_summary_steps=None, \n#                                     save_checkpoints_steps=1000, save_checkpoints_secs=None)\n\nclf = tf.estimator.DNNClassifier(\n    feature_columns=feature_cols,\n    hidden_units=[1024, 512],\n    n_classes=16,\n    optimizer='Adam',\n    dropout=0.2\n)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e487353b41bfb7a8e1becae18592579e8336eb8a","collapsed":true},"cell_type":"code","source":"# clf.train(input_fn=lambda: input_fn(X_train, Y_train, 64), steps=1000)\nclf.train(input_fn=get_inp_fn(X_train, Y_train), steps=2000)","execution_count":17,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a17d4a4c1624c72985e7815dcde345c044da09d6","collapsed":true},"cell_type":"code","source":"# clf.evaluate(input_fn=lambda: input_fn(X_train, Y_train, 64))\nresult = clf.evaluate(input_fn=get_inp_fn(X_train, Y_train, 1, False))\nprint('Train set evaluation:')\npprint(result)\n\nresult = clf.evaluate(input_fn=get_inp_fn(X_test, Y_test, 1, False))\nprint('Test set evaluation:')\npprint(result)","execution_count":18,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6249973a86e5e2d76dd6e22eab27688abd2ee268"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}