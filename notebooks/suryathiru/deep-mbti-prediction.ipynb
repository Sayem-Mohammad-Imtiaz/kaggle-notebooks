{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport re\nfrom pprint import pprint\n\nimport os\nprint(os.listdir(\"../input\"))\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":16,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/mbti-type/mbti_1.csv')\npersonalities = {'I':'Introversion', 'E':'Extroversion', 'N':'Intuition', \n        'S':'Sensing', 'T':'Thinking', 'F': 'Feeling', \n        'J':'Judging', 'P': 'Perceiving'}\ndata.head()","execution_count":17,"outputs":[]},{"metadata":{"_uuid":"544d5f89d3ca5f9208ba7c3be9414481019f0850"},"cell_type":"markdown","source":"cleaning up the post column"},{"metadata":{"trusted":true,"_uuid":"837b0cdd93e00e9f22ae71431e82b5ae5dfe1add","collapsed":true},"cell_type":"code","source":"def replace_symbols(text):\n    text = re.sub('\\|\\|\\|', ' ', text)\n    text = re.sub('https?\\S+', '<URL>', text)\n    return text\n\ndata['cleaned_posts'] = data['posts'].apply(replace_symbols)","execution_count":18,"outputs":[]},{"metadata":{"_uuid":"6cb1b007786bf307b19902115140af47b2b10c4f"},"cell_type":"markdown","source":"#### RNNs"},{"metadata":{"trusted":true,"_uuid":"616063b4449cc091b35680f039abb0d53dd83913","collapsed":true},"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv1D, MaxPooling1D, Dropout, LSTM, Bidirectional, BatchNormalization\nfrom keras.layers.embeddings import Embedding\nfrom keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.utils import class_weight\nimport gensim","execution_count":19,"outputs":[]},{"metadata":{"_uuid":"1ace71ffba9a6f5ebd58b125377278bacdb4dad9"},"cell_type":"markdown","source":"Load the glove vectors"},{"metadata":{"trusted":true,"_uuid":"10ee0c16bfe4f7936ce8216f122a25ba6b5c80c3"},"cell_type":"code","source":"# covert the glove model to word2vec format\nfrom gensim.scripts.glove2word2vec import glove2word2vec\n\nglove_dir = '../input/glove-global-vectors-for-word-representation/'\nglove_input_file = 'glove.6B.100d.txt'\nword2vec_output_file = 'glove.word2vec'\nglove2word2vec(glove_dir + glove_input_file, word2vec_output_file)","execution_count":20,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e04864e2e3c896a04e98b8a74661fdeb790b5f1e"},"cell_type":"code","source":"# load the vectors\nfrom gensim.models import KeyedVectors\nglovec_model = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)\n# TEST MODEL: calculate: (king - man) + woman = ?\nresult = glovec_model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\nprint(result)","execution_count":21,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"492d2d56d643777362eb0a624d93a21522e3053d","collapsed":true},"cell_type":"code","source":"glovec_weights = glovec_model.wv.syn0\nvocab_size, embedding_size = glovec_weights.shape","execution_count":22,"outputs":[]},{"metadata":{"_uuid":"a0638c09a6db2387afdf7bf3705067e49a066d43"},"cell_type":"markdown","source":"preprocess text"},{"metadata":{"trusted":true,"_uuid":"3d6b0e8bb7cfa389eecc1b32c4b1cf7758ccc02b","collapsed":true},"cell_type":"code","source":"# convert to glove index\ndef word2idx(word):\n    idx = glovec_model.wv.vocab.get(word)\n    if not idx:\n        return None\n    return idx.index\n\ndef idx2word(idx):\n    return glovec_model.wv.index2word[idx]\n\ndef convert_text(doc):\n    return [word2idx(word) for word in doc]\n\n# data['encoded_posts'] = data['cleaned_posts'].apply(convert_text)","execution_count":23,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bfad3d93a4dd1aa68dcb29f5cbd27a71c2d01a77"},"cell_type":"code","source":"tok = Tokenizer()\ntok.fit_on_texts(data['cleaned_posts'])\ndocs = tok.texts_to_sequences(data['cleaned_posts'])\n\nMAX_LEN = 1000\npadded = pad_sequences(docs, maxlen=MAX_LEN, padding='post')\n\nvocab_size = len(tok.word_index) + 1 # vocab size from data\nprint(vocab_size)\n# generate embedding matrix\nembedding_matrix = np.zeros((vocab_size, embedding_size))\nfor word, i in tok.word_index.items():\n    idx = word2idx(word)\n    if idx is not None:\n        emb_vec = glovec_weights[idx]        \n        embedding_matrix[i] = emb_vec\n        \nembedding_matrix.shape","execution_count":24,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c50fa67e9423248bbb09651310c43436c49de668"},"cell_type":"code","source":"le = LabelEncoder()\n\nX, Y = padded, le.fit_transform(data['type'])\nX.shape, Y.shape","execution_count":25,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cab67c250ac6c2eb9d6795dfcfb82785a806db05"},"cell_type":"code","source":"# handle imbalance in dataset\nclass_weights = class_weight.compute_class_weight('balanced', np.unique(Y), Y)\nclass_weights = dict(enumerate(class_weights))\nclass_weights","execution_count":26,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"94b05188defbf3d8e5cfc57a277385f13576d984"},"cell_type":"code","source":"def create_RNN():\n    model = Sequential()\n    model.add(Embedding(vocab_size, embedding_size, weights=[embedding_matrix], trainable=False, input_length=MAX_LEN))\n    model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n    model.add(MaxPooling1D(pool_size=2))\n    model.add(BatchNormalization())\n    model.add(LSTM(units=32, dropout=0.2, recurrent_dropout=0.2))\n    model.add(BatchNormalization())\n    model.add(Dense(16, activation='softmax'))\n    model.compile(Adam(0.1), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    return model","execution_count":27,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4382cc917dc2152f9cbac622501dea41e0019281"},"cell_type":"code","source":"rnn = create_RNN()\nrnn.summary()","execution_count":28,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"4cc112703471cb1c0908f2ffb9b765242bdd9c51"},"cell_type":"code","source":"callbacks = [EarlyStopping(min_delta=0.001, verbose=1)]","execution_count":29,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"891fb813521f8ee58a8cc5c73fadeae226e7b52a"},"cell_type":"code","source":"model_info = rnn.fit(X, Y, validation_split=0.15, batch_size=64, epochs=5, callbacks=callbacks)#, class_weight=class_weights)","execution_count":36,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"35258b78275083cc71adb88d78cee5856e7336e6"},"cell_type":"code","source":"def plot_model_history(model_history):\n    fig, axs = plt.subplots(1,2,figsize=(15,5))\n    # summarize history for accuracy\n    axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n    axs[0].set_title('Model Accuracy')\n    axs[0].set_ylabel('Accuracy')\n    axs[0].set_xlabel('Epoch')\n    axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n    axs[0].legend(['train', 'val'], loc='best')\n    # summarize history for loss\n    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n    axs[1].set_title('Model Loss')\n    axs[1].set_ylabel('Loss')\n    axs[1].set_xlabel('Epoch')\n    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n    axs[1].legend(['train', 'val'], loc='best')\n    \nplot_model_history(model_info)","execution_count":37,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b3aa641495e7369f4364aff83262230d665f1eaa"},"cell_type":"code","source":"import keras.backend as K\n\nprint(len(rnn.layers))\nout = K.function([rnn.inputs[0], K.learning_phase()], [rnn.layers[1].output])\nprint(out([X[:2],0]), X[:2])","execution_count":38,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a8326985cc9ef23356638c930d86a25a07240bb"},"cell_type":"code","source":"!rm glove.word2vec\n!du -ahd 1","execution_count":33,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ab5a8af2bfd205301834be930cba2d0396f820a6","collapsed":true},"cell_type":"code","source":"model_dir = 'mbit_rnn_model.json'\nweights_dir = 'mbit_rnn_weights.h5'\n\nmodel_json = rnn.to_json()\nwith open(model_dir, 'w') as file:\n    file.write(model_json)\n\nrnn.save_weights(weights_dir)","execution_count":34,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad4bf36fdfa0fff754f7f7af77344a44b1f20be2"},"cell_type":"code","source":"!du -ahd 1","execution_count":35,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}