{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport cv2\n\nimport os\nprint(os.listdir(\"../input\"))\n\nMI = pd.read_csv(\"../input/ptbdb_abnormal.csv\") \nHC = pd.read_csv(\"../input/ptbdb_normal.csv\") \n\nnew_column_name = ['label']\nfor num in range(MI.shape[1]-1):\n    tem = 'dim' + str(num)\n    new_column_name.append(tem)\nMI.columns = new_column_name    \n\ncolumn_name = ['label']\nfor num in range(HC.shape[1]-1):\n    tem = 'dim' + str(num)\n    column_name.append(tem)\nHC.columns = column_name\nimport keras","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_MI=MI.iloc[0:7000]\ntest_MI=MI.iloc[7000:9000]\ntrain_HC=HC.iloc[0:2500]\ntest_HC=HC.iloc[2500:3500]\ntrain=[train_MI,train_HC]\ntrain=pd.concat(train,sort=True)\ntest=[test_MI,test_HC]\ntest=pd.concat(test,sort=True)\n\nytrain=list(range(9500))\nytest=list(range(3000))\nfor i in range(9500): ytrain[i] = 1 if i<=7000 else 0\nfor j in range(3000): ytest[j] = 1 if j<=2000 else 0        \nytrain = keras.utils.np_utils.to_categorical(ytrain)\nytest = keras.utils.np_utils.to_categorical(ytest)\n\ntrain=np.asarray(train)\ntrain=train.reshape(9500, 188, 1)\n\ntest=np.asarray(test)\ntest=test.reshape(3000, 188, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(3): plt.plot(MI.iloc[i])\nplt.show()\nfor i in range(3): plt.plot(HC.iloc[i])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.keras.backend.clear_session()\n\ninput_ = tf.keras.Input(shape=(188,1))\nx = tf.keras.layers.Conv1D(100, 5)(input_)\nx = tf.keras.layers.Conv1D(100, 5, activation='relu')(x)\nx = tf.keras.layers.MaxPooling1D(2)(x)\nx = tf.keras.layers.Conv1D(100, 5, activation='relu')(x)\nx = tf.keras.layers.Conv1D(160, 5, activation='relu')(x)\nx = tf.keras.layers.MaxPooling1D(2)(x)\nx = tf.keras.layers.Conv1D(100, 5, activation='relu')(x)\nx = tf.keras.layers.Conv1D(100, 5, activation='relu')(x)\nx = tf.keras.layers.GlobalAveragePooling1D()(x)\nx = tf.keras.layers.Dropout(0.2)(x)\nx = tf.keras.layers.Dense(20, activation='relu')(x)\noutput_ = tf.keras.layers.Dense(2, activation='softmax')(x)\nmodel = tf.keras.Model(inputs=input_,outputs=output_,)\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ytrain.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(train, ytrain, validation_data=(test, ytest), epochs=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow.keras.backend as K\n\ndef gradcam(model, x, index, layer_name):\n    # 取得影像的分類類別\n    preds = model.predict(x)\n    pred_class = np.argmax(preds[index])\n    \n    # 取得影像分類名稱\n    #pred_class_name = imagenet_utils.decode_predictions(preds)[0][0][1]\n    \n    # 預測分類的輸出向量\n    pred_output = model.output[:, pred_class]\n    \n    # 最後一層 convolution layer 輸出的 feature map\n    # ResNet 的最後一層 convolution layer\n    last_conv_layer = model.get_layer(layer_name)\n    \n    # 求得分類的神經元對於最後一層 convolution layer 的梯度\n    grads = K.gradients(pred_output, last_conv_layer.output)[0]\n    \n    # 求得針對每個 feature map 的梯度加總\n    #pooled_grads = K.sum(grads, axis=(0, 1, 2))\n    pooled_grads = K.sum(grads, axis=(0, 1))\n    \n    # K.function() 讓我們可以藉由輸入影像至 `model.input` 得到 `pooled_grads` 與\n    # `last_conv_layer[0]` 的輸出值，像似在 Tensorflow 中定義計算圖後使用 feed_dict\n    # 的方式。\n    iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[index]])\n    \n    # 傳入影像矩陣 x，並得到分類對 feature map 的梯度與最後一層 convolution layer 的 \n    # feature map\n    pooled_grads_value, conv_layer_output_value = iterate([x])\n    \n    # 將 feature map 乘以權重，等於該 feature map 中的某些區域對於該分類的重要性\n    for i in range(pooled_grads_value.shape[0]):\n        conv_layer_output_value[:, i] *= (pooled_grads_value[i])\n        \n    # 計算 feature map 的 channel-wise 加總\n    heatmap = np.sum(conv_layer_output_value, axis=-1)\n    \n    return heatmap, pred_class","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def heatmap_():\n    heatmap_2d = np.expand_dims(heatmap,1)\n    heatmap_2d = cv2.resize(heatmap_2d, (100,188))\n\n    figure = plt.figure(figsize=(80,4))\n    ax = figure.add_subplot(111)\n    x = np.arange(0, 188, 1)\n    ax.plot(x, data*100)\n    ax.imshow(np.transpose(heatmap_2d), cmap=\"Oranges\", extent=[0, 188, -10, 120])\n    ax.autoscale(False)\n    ax.set_xlim(0, 187)\n    ax.set_ylim(-10, 110)\n    ax.set_title(title)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, layer in enumerate(model.layers):\n    print(i, layer.name, layer.output_shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def heatmap_3x():\n    def preprocess_heatmap(heatmap):\n        heatmap_2d = np.expand_dims(heatmap,1)\n        heatmap_2d = cv2.resize(heatmap_2d, (100,188))\n        heatmap_2d = np.transpose(heatmap_2d)\n        return heatmap_2d\n\n    fig, ax = plt.subplots(1,len(name_list)+1,figsize=(20,4))\n    x = np.arange(0, 188, 1)\n    Collect_attention = list()\n    for i in range(1,len(name_list)+1):\n        ax[i].plot(x, data*100)\n        heatmap_2d = preprocess_heatmap(Collect_heatmap[i-1])\n        Collect_attention.append(heatmap_2d[0])\n        ax[i].imshow(heatmap_2d, cmap=\"Oranges\", extent=[0, 188, -10, 120])\n        ax[i].set_xlim(0, 187)\n        ax[i].set_ylim(-10, 110)\n        ax[i].set_title(name_list[i-1])\n    ax[0].plot(x, data, label=\"ECG\")\n    for i in range(len(name_list)):\n        ax[0].set_title(title)\n        ax[0].plot(x, Collect_attention[i]/np.max(Collect_attention[i]), label=name_list[i])\n        ax[0].set_ylim(-0.2, 1)\n    ax[0].legend()\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(20):\n    Collect_heatmap = list()\n    index = np.random.randint(0,len(test))\n    name_list = [\"conv1d_1\", \"conv1d_3\", \"conv1d_5\"]\n    for name in name_list:\n        heatmap, pred_class = gradcam(model, test, index, name)\n        Collect_heatmap.append(heatmap)\n    data = test[index]\n    if int(ytest[index][0]): title = \"HC\"\n    else: title = \"MI\"\n    heatmap_3x()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}