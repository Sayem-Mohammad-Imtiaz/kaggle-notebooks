{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\nIn this notebook I lay out my analysis of the [Daily Temperature of Major Cities](https://www.kaggle.com/sudalairajkumar/daily-temperature-of-major-cities) dataset which contains the average daily temperatures (in Fahrenheit degrees) for 157 U.S. and 167 international cities.\n\nFirst, we will go through a simple data cleaning process and, then, we will gather interesting insights by exploring the dataset over a period of 20 years (from 2000 to 2019).\n\nPlease feel free to leave your thoughts and feedbacks in the comment section below. As a beginner, I would love constructive criticism to help me and other newbies grow! :) ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\nsns.set_style('darkgrid')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/daily-temperature-of-major-cities/city_temperature.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Cleaning Process\n\nWe start off by renaming all columns to lowercase letters.","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df = df.rename(columns={\n    'Region': 'region',\n    'Country': 'country',\n    'State': 'state',\n    'City': 'city',\n    'Month': 'month',\n    'Day': 'day',\n    'Year': 'year',\n    'AvgTemperature': 'avg_temp'\n})\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We check the columns characterizing the dataset, while keeping an eye out for any missing values or data artifacts.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.region.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.country.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.country.isna().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.state.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.city.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.city.isna().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.avg_temp.isna().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.day.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df[df.day == 0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A `day` value equal to `0` looks like an invalid value. Therefore, we drop the rows containing it.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[df.day != 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.year.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df[df.year.isin([200, 201])])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We do the same for the `year` values equal to `200` and `201`.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[~df.year.isin([200, 201])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.avg_temp.value_counts().nlargest(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The `avg_temp` column appears to contain some kind of measurement error, namely a value equal to `-99.0`.\n\nAs a matter of fact, according to [this link](http://academic.udayton.edu/kissock/http/Weather/source.htm), it is used to symbolize a missing measurement!\n\nThus, we compute its relative frequency for each city as to determine the **relevance of the error value**.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"grouped_freqs = df.groupby('city').avg_temp.value_counts(normalize=True)\ngrouped_freqs.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted_freqs_df = grouped_freqs.unstack(level='avg_temp').sort_values(by=-99., ascending=False)\nsorted_freqs_df[-99.].head(15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We notice how the first 5 cities are the ones being the most affected by the missing measurements.\n\nIn light of what we have just discovered, let's only keep the rows corresponding to the cities having a relative frequency of the missing measurements $\\leq 10 \\%$.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cities_to_remove = sorted_freqs_df[sorted_freqs_df[-99.] > .1][-99.].index.to_list()\nprint(f'We are going to remove the following cities:\\n\\n{\", \".join(cities_to_remove)}.')\ndf = df[~df.city.isin(cities_to_remove)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Replace the missing measurements with something more appropriate.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.avg_temp = df.avg_temp.replace(-99., np.nan)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that we have the NaN in place, it would be interesting to determine the **top-10 cities having the highest number of missing temperature measurements for an entire month**.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# We first compute the counts of the temperatures values...\ngroupby_filter = [df.year, df.month, 'city']\ntemp_counts_df = df.groupby(groupby_filter).avg_temp.value_counts(dropna=False).unstack()\n# Then, we select the rows whose NaN column equals 31.\n# These are the rows corresponding to a missing temperature measurement\n# for the combination of year/month/city.\nmissing_series = temp_counts_df.loc[temp_counts_df[np.nan] == 31.][np.nan]\n# Finally, we replace all the 31 values with 1\n# in order to compute the total number of occurrences\n# of missing temperature measurements, for each city.\noutages_series = missing_series.replace(31., 1).unstack('city').sum().nlargest(10)\n# Do some cleanup...\ndel temp_counts_df\n# And the plotting of the cities\n# against the total number of occurrences of this event for the overall dataset.\nfig, ax = plt.subplots(figsize=(12,10))\noutages_series.sort_values().plot(kind='barh', rot=30, ax=ax)\nax.set_title('Cities having the highest no. of missing temperature measurements for 31 days straight.')\nax.set_xlabel('Number of occurrences')\nax.yaxis.label.set_visible(False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since there are several cities missing entire months' worth of temperature data, I believe that there are two possible ways to proceed:\n\n* Drop all the rows having missing temperature readings, OR;\n* \"Forward\" propagate the last non-null temperature value until the next non-null value. \n\nI decided on the latter.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.avg_temp = df.avg_temp.fillna(method='ffill')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We convert Fahrenheit to Celsius, just for fun.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"to_celsius_equation = (df.avg_temp - 32) * 5 / 9\ndf = df.assign(avg_temp_c=np.round(to_celsius_equation, 2)).drop(columns='avg_temp')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And we finalize the cleaning process by merging `year`, `month` and `day` columns into a new `date` column.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"datetime_series = pd.to_datetime(df[['year', 'month', 'day']])\ndf['date'] = datetime_series\ndf = df.drop(columns=['year', 'month', 'day'])\ndf = df.set_index('date')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Analysis\n\n## Mean yearly regional temperature trend from 2000 to 2019\nWe begin the analysis by visualizing the mean yearly temperature trend from 2000 to 2019, for each region.","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"last_twenty_years_df = df[(df.index.year >= 2000) & (df.index.year <= 2019)]\nregion_year_filter = ['region', pd.Grouper(freq='Y')]\nlast_twenty_years_region_temp = last_twenty_years_df.groupby(region_year_filter).avg_temp_c \\\n                                                    .mean()                                 \\\n                                                    .unstack('region')\nlast_twenty_years_region_temp.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# I had to override the Matplotlib's tick_values method of the YearLocator class\n# because the date interval I'm analyzing (i.e. 2000 to 2019)\n# cannot be drawn correctly using the default YearLocator.\n#\n# The implementation is very similar to the default YearLocator.\n# In fact, the most relevant change is on the following line:\n# ymax = self.base.ge(vmax.year) * self.base.step + self.base.step\n# There, I've added the term self.base.step\n\nclass OddIntervalYearLocator(mdates.YearLocator):\n    def tick_values(self, vmin, vmax):\n        ymin = self.base.le(vmin.year) * self.base.step\n        ymax = self.base.ge(vmax.year) * self.base.step + self.base.step\n        ticks = [vmin.replace(year=ymin, **self.replaced)]\n        while True:\n            dt = ticks[-1]\n            if dt.year >= ymax:\n                return mdates.date2num(ticks)\n            year = dt.year + self.base.step\n            ticks.append(dt.replace(year=year, **self.replaced))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_yearly_temperature(df, fig_title, fig_size, marker_type=None):\n    fig, ax = plt.subplots(figsize=fig_size)\n    if marker_type is None:\n        sns.lineplot(data=df, markers=True, markersize=10, dashes=False, ax=ax)\n        # Force legend position when there are multiple lines on the plot\n        ax.legend(loc='center left')\n    else:\n        sns.lineplot(data=df, marker='o', markersize=10, ax=ax)\n    ax.set_title(fig_title)\n    ax.set_ylabel('Temperature (Celsius)')\n    ax.xaxis.label.set_visible(False)\n    # Draw a major tick every 2 years\n    ax.xaxis.set_major_locator(OddIntervalYearLocator(base=2, month=12, day=31))\n    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_yearly_temperature(last_twenty_years_region_temp[['Europe', 'Middle East', 'Africa']],\n                        fig_title='Mean yearly temperature (2000 - 2019) - EMEA',\n                        fig_size=(12, 10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"other_df = last_twenty_years_region_temp[['North America', 'South/Central America & Carribean',\n                                          'Asia', 'Australia/South Pacific']]\nplot_yearly_temperature(other_df,\n                        fig_title='Mean yearly temperature (2000 - 2019) - Other regions',\n                        fig_size=(12, 10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We notice how Africa, Middle East and South/Central America & Carribean are undergoing a bumpy but steady increase of the average temperature per year. On the other hand, Europe and Asia remain somewhat constant.\n\n## Mean yearly Earth's temperature trend from 2000 to 2019\nThe next visualization focuses on the average Earth's temperature trend over the same time period we just saw. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_yearly_temperature(last_twenty_years_df.groupby(pd.Grouper(freq='Y')).avg_temp_c.mean(),\n                        fig_title='Mean yearly temperature (2000 - 2019) - Earth',\n                        fig_size=(10, 5),\n                        marker_type='o')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As expected, the average Earth's temperature is alarmingly increasing and, during the last two decades, it appears that there has been an increase of $\\sim 0.5$ Celsius degree of the average Earth's temperature.\n\n## Top-10 cities having the highest/lowest mean temperature from 2000 to 2019\n\nWe now shift our attention to the top-10 cities having the highest/lowest mean temperature from 2000 to 2019.","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"last_twenty_years_df.groupby('city').avg_temp_c.mean().nlargest(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"last_twenty_years_df.groupby('city').avg_temp_c.mean().nsmallest(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Hottest days in India\nFinally, we highlight the hottest days in the major cities of India. As you may know, India has several of the world's hottest places. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"last_twenty_years_df.query('country == \"India\"').groupby('city').avg_temp_c \\\n                    .agg(hottest_day='idxmax', avg_temp_c='max')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}