{"cells":[{"metadata":{},"cell_type":"markdown","source":"### **Objective**\n\nThe aim is to estimate whether a bank's customers leave the bank or not. The event that defines the customer abandonment is the closing of the customer's bank account.\n\n### **Details about the dataset:**\n\nIt consists of 10000 observations and 12 variables. Independent variables contain information about customers. Dependent variable refers to customer abandonment status.\n\n### **Variables:**\n\n*RowNumber* — corresponds to the record (row) number and has no effect on the output. This column will be removed.\n\n*CustomerID* — contains random values and has no effect on customer leaving the bank. This column will be removed.\n\n*Surname* — the surname of a customer has no impact on their decision to leave the bank. This column will be removed.\n\n*CreditScore* — can have an effect on customer churn, since a customer with a higher credit score is less likely to leave the bank.\n\n*Geography* — a customer’s location can affect their decision to leave the bank. We’ll keep this column.\n\n*Gender* — it’s interesting to explore whether gender plays a role in a customer leaving the bank. We’ll include this column, too.\n\n*Age* — this is certainly relevant, since older customers are less likely to leave their bank than younger ones.\n\n*Tenure* — refers to the number of years that the customer has been a client of the bank. Normally, older clients are more loyal and less likely to leave a bank.\n\n*Balance* — also a very good indicator of customer churn, as people with a higher balance in their accounts are less likely to leave the bank compared to those with lower balances.\n\n*NumOfProducts* — refers to the number of products that a customer has purchased through the bank.\n\n*HasCrCard* — denotes whether or not a customer has a credit card. This column is also relevant, since people with a credit card are less likely to leave the bank. (0=No,1=Yes)\n\n*IsActiveMember* — active customers are less likely to leave the bank, so we’ll keep this. (0=No,1=Yes)\n\n*EstimatedSalary* — as with balance, people with lower salaries are more likely to leave the bank compared to those with higher salaries.\n\n*Exited* — whether or not the customer left the bank. This is what we have to predict. (0=No,1=Yes)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## **Data Analysis**","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Installation of required libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.linear_model import LogisticRegression  \nfrom sklearn.neighbors import KNeighborsClassifier  \nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier \nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score, GridSearchCV\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) \nwarnings.filterwarnings(\"ignore\", category=FutureWarning) \nwarnings.filterwarnings(\"ignore\", category=UserWarning) \n\n%config InlineBackend.figure_format = 'retina'\n\n#To display all columns and rows:\npd.set_option('display.max_columns', None); pd.set_option('display.max_rows', None);\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/predicting-churn-for-bank-customers/Churn_Modelling.csv\", index_col=0)\ndf.columns = map(str.lower, df.columns)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#The size of the data set was examined. It consists of 10000 observation units and 13 variables.\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Descriptive statistics of the data set accessed.\ndf.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#The average of the age variable according to the gender variable was examined.\ndf.groupby(\"gender\").agg({\"age\": \"mean\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#The average of the dependent variable according to the gender variable was examined.\ndf.groupby(\"gender\").agg({\"exited\": \"mean\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#The average of the dependent variable according to the geography variable was examined.\ndf.groupby(\"geography\").agg({\"exited\": \"mean\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#The frequency of the dependent variable has been reached.\ndf[\"exited\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Access to those who left us through the dependent variable. (exited == 1)\nchurn = df[df[\"exited\"] == 1]\nchurn.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Who left most than the gender variable?\nchurn.groupby(\"gender\").agg({\"exited\": \"count\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Which country has left us the most?\nchurn.groupby(\"geography\").agg({\"exited\": \"count\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Access to those who do not leave us on the dependent variable. (exited == 0)\nnon_churn = df[df[\"exited\"] == 0]\nnon_churn.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Which country does not leave the most?\nnon_churn.groupby(\"geography\").agg({\"exited\": \"count\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Unique observation units were examined. Surname variable will be examined.\ndf.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#What are the most commonly used surnames?\ndf.groupby('surname')['surname'].count().sort_values(ascending=False).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#The most commonly used surname was examined and observed to be non-multiplexing.\ndf[df[\"surname\"] == \"Smith\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#They were grouped by gender variable and looked at how many years on average they were clients.\ndf.groupby([\"gender\", \"exited\"]).agg({\"tenure\" : \"mean\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Min, mean and max values ​​of all variables were taken according to the dependent variable.\ndf.groupby(\"exited\").agg([\"min\",\"mean\",\"max\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Isactivemember is grouped according to the hascrcard variables and the dependent variable is examined.\ndf.groupby([\"isactivemember\", \"hascrcard\"]).agg({\"exited\" : \"count\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#The dependent variable was studied according to the gender variable and age range variable.\ndf[\"NewAge\"] = pd.qcut(df['age'], 5)\ndf.groupby([\"gender\",\"NewAge\" ])[\"exited\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#How many people whose balance is 0 leave?\ndf[(df[\"balance\"] == 0) & (df[\"exited\"] == 1)].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Access to the correlation of the data set was provided. What kind of relationship is examined between the variables. \n#If the correlation value is> 0, there is a positive correlation. While the value of one variable increases, the value of the other variable also increases.\n#Correlation = 0 means no correlation.\n#If the correlation is <0, there is a negative correlation. While one variable increases, the other variable decreases. \n#When the correlations are examined, there are 1 variables that act as a positive correlation to the exited dependent variable.\n#This variable is Age. As this increases, the Result variable increases.\ndf.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Data Visualization**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#The distribution of the dependent variable in the dataset is plotted as pie and columns graphs.\nf,ax=plt.subplots(1,2,figsize=(18,8))\ndf['exited'].value_counts().plot.pie(explode=[0,0.1],autopct='%1.1f%%',ax=ax[0],shadow=True)\nax[0].set_title('dağılım')\nax[0].set_ylabel('')\nsns.countplot('exited',data=df,ax=ax[1])\nax[1].set_title('exited')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotted the categorical variables on the basis of the graph of the column according to the dependent variable.\nfig, axarr = plt.subplots(2, 2, figsize=(20, 12))\nsns.countplot(x='geography', hue = 'exited',data = df, ax=axarr[0][0])\nsns.countplot(x='gender', hue = 'exited',data = df, ax=axarr[0][1])\nsns.countplot(x='hascrcard', hue = 'exited',data = df, ax=axarr[1][0])\nsns.countplot(x='isactivemember', hue = 'exited',data = df, ax=axarr[1][1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#The distribution of the dependent variable according to the gender variable is plotted in the pie chart.\nimport plotly.express as px\nfig = px.pie(df, values =df.groupby(\"gender\")[\"exited\"].value_counts(), names = [\"Female,0\",\"Female 1\",\"Male,0\",\"Male,1\"])\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dependent variable was plotted according to age and geography variable.\nimport plotly.express as px\nfig = px.bar(df,y = \"exited\", x = \"age\" , color = \"geography\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Correlation Matrix\nf, ax = plt.subplots(figsize= [20,15])\nsns.heatmap(df.corr(), annot=True, fmt=\".2f\", ax=ax, cmap = \"magma\" )\nax.set_title(\"Correlation Matrix\", fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Boxplot graph for outlier observation analysis\nfig, axarr = plt.subplots(3, 2, figsize=(20, 12))\nsns.boxplot(y='creditscore',x = 'exited', hue = 'exited',data = df, ax=axarr[0][0])\nsns.boxplot(y='age',x = 'exited', hue = 'exited',data = df , ax=axarr[0][1])\nsns.boxplot(y='tenure',x = 'exited', hue = 'exited',data = df, ax=axarr[1][0])\nsns.boxplot(y='balance',x = 'exited', hue = 'exited',data = df, ax=axarr[1][1])\nsns.boxplot(y='numofproducts',x = 'exited', hue = 'exited',data = df, ax=axarr[2][0])\nsns.boxplot(y='estimatedsalary',x = 'exited', hue = 'exited',data = df, ax=axarr[2][1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Data Preprocessing**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### **Missing and Outlier Observation Analysis**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Missing Observation Analysis\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Outlier Observation Analysis\nfor feature in df[['creditscore','tenure', 'balance','estimatedsalary']]:\n    \n    Q1 = df[feature].quantile(0.25)\n    Q3 = df[feature].quantile(0.75)\n    IQR = Q3-Q1\n    lower = Q1- 1.5*IQR\n    upper = Q3 + 1.5*IQR\n    \n    if df[(df[feature] > upper)].any(axis=None):\n        print(feature,\"Yes\")\n    else:\n        print(feature, \"No\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Feature Engineering**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"NewAGT\"] = df[\"age\"] - df[\"tenure\"]\ndf[\"CreditsScore\"] = pd.qcut(df['creditscore'], 10, labels = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\ndf[\"AgeScore\"] = pd.qcut(df['age'], 8, labels = [1, 2, 3, 4, 5, 6, 7, 8])\ndf[\"BalanceScore\"] = pd.qcut(df['balance'].rank(method=\"first\"), 10, labels = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\ndf[\"EstSalaryScore\"] = pd.qcut(df['estimatedsalary'], 10, labels = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\ndf[\"NewEstimatedSalary\"] = df[\"estimatedsalary\"] / 12 \ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **One Hot Encoding**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.get_dummies(df, columns =[\"geography\", \"gender\"], drop_first = True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop([\"customerid\",\"surname\",\"NewAge\"], axis = 1)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Scaling**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_df = df[[\"geography_Germany\", \"geography_Spain\", \"gender_Male\", \"hascrcard\",\"isactivemember\"]]\ncat_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df[\"exited\"]\nX = df.drop([\"exited\",\"geography_Germany\", \"geography_Spain\", \"gender_Male\", \"hascrcard\",\"isactivemember\"], axis = 1)\ncols = X.columns\nindex = X.index\nX.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import RobustScaler\ntransformer = RobustScaler().fit(X)\nX = transformer.transform(X)\nX = pd.DataFrame(X, columns = cols, index = index)\nX = pd.concat([X,cat_df], axis = 1)\nX.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Train-Test Separation & Balancing**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Train-Test Separation\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=12345)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Because it's an unstable data set, we're going to increase the number of samples.\n#References: https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.combine.SMOTETomek.html\nfrom imblearn.combine import SMOTETomek\n\nsmk = SMOTETomek()\n# Oversample training  data\nX_train, y_train = smk.fit_sample(X_train, y_train)\n\n# Oversample validation data\nX_test, y_test = smk.fit_sample(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Modelling**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"models = []\nmodels.append(('LR', LogisticRegression(random_state = 12345)))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier(random_state = 12345)))\nmodels.append(('RF', RandomForestClassifier(random_state = 12345)))\nmodels.append(('SVM', SVC(gamma='auto', random_state = 12345)))\nmodels.append(('XGB', GradientBoostingClassifier(random_state = 12345)))\nmodels.append((\"LightGBM\", LGBMClassifier(random_state = 12345)))\nmodels.append((\"CatBoost\", CatBoostClassifier(random_state = 12345, verbose = False)))\n\n# evaluate each model in turn\nresults = []\nnames = []","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Accuracy Score**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for name, model in models:\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n        accuracy = accuracy_score(y_test, y_pred)\n        msg = \"%s: (%f)\" % (name, accuracy)\n        print(msg)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Variable Importance Levels of All Models**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"models2 = []\nmodels2.append(('CART', DecisionTreeClassifier( random_state = 12345)))\nmodels2.append(('RF', RandomForestClassifier( random_state = 12345)))\nmodels2.append(('XGB', GradientBoostingClassifier( random_state = 12345)))\nmodels2.append((\"LightGBM\", LGBMClassifier( random_state = 12345)))\nmodels2.append((\"CatBoost\", CatBoostClassifier(random_state = 12345, verbose = False)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for name, model in models2:\n        base = model.fit(X_train,y_train)\n        y_pred = base.predict(X_test)\n        acc_score = accuracy_score(y_test, y_pred)\n        feature_imp = pd.Series(base.feature_importances_,\n                        index=X.columns).sort_values(ascending=False)\n\n        sns.barplot(x=feature_imp, y=feature_imp.index)\n        plt.xlabel('Değişken Önem Skorları')\n        plt.ylabel('Değişkenler')\n        plt.title(name)\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Model Tuning**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Hyperparameters have previously been obtained with the help of GridSearchCV.\nmodels = []\nmodels.append(('XGB', GradientBoostingClassifier(random_state = 12345,learning_rate = 0.05, max_depth = 5, min_samples_split = 2, n_estimators = 500, subsample = 0.8)))\nmodels.append((\"LightGBM\", LGBMClassifier(random_state = 12345,  learning_rate = 0.05, max_depth = 3, n_estimators = 1000)))\nmodels.append((\"CatBoost\", CatBoostClassifier(random_state = 12345, verbose = False, depth = 10, iterations = 1000, l2_leaf_reg = 5, learning_rate = 0.01)))\n\n#Evaluate each model in turn\nresults = []\nnames = []\n\nfor name, model in models:\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n        accuracy = accuracy_score(y_test, y_pred)\n        msg = \"%s: (%f)\" % (name, accuracy)\n        print(msg)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Model Tuning Variable Importance Level**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"models2 = []\nmodels2.append((\"LightGBM\", LGBMClassifier(random_state = 12345,  learning_rate = 0.05, max_depth = 3, n_estimators = 1000)))\n\n#Evaluate each model in turn\nresults = []\nnames = []\n\nfor name, model in models2:\n        base = model.fit(X_train,y_train)\n        y_pred = base.predict(X_test)\n        acc_score = accuracy_score(y_test, y_pred)\n        feature_imp = pd.Series(base.feature_importances_,\n                        index=X.columns).sort_values(ascending=False)\n\n        sns.barplot(x=feature_imp, y=feature_imp.index)\n        plt.xlabel('Değişken Önem Skorları')\n        plt.ylabel('Değişkenler')\n        plt.title(name)\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Confusion Matrix**\n\n![](https://miro.medium.com/max/2102/1*fxiTNIgOyvAombPJx5KGeA.png)","attachments":{},"execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import  accuracy_score, f1_score, precision_score,confusion_matrix, recall_score, roc_auc_score\ny_pred = model.predict(X_test)\ncm_xgb = confusion_matrix(y_test, y_pred=y_pred)\n\nTP = cm_xgb[1, 1]\nTN = cm_xgb[0, 0]\nFP = cm_xgb[0, 1]\nFN = cm_xgb[1, 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import rc,rcParams\ndef plot_confusion_matrix(cm, classes,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n\n    plt.rcParams.update({'font.size': 19})\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title,fontdict={'size':'16'})\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45,fontsize=12,color=\"blue\")\n    plt.yticks(tick_marks, classes,fontsize=12,color=\"blue\")\n    rc('font', weight='bold')\n    fmt = '.1f'\n    thresh = cm.max()\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"red\")\n\n    plt.ylabel('True label',fontdict={'size':'16'})\n    plt.xlabel('Predicted label',fontdict={'size':'16'})\n    plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import itertools\nplot_confusion_matrix(confusion_matrix(y_test, y_pred=y_pred), classes=['Non Churn','Churn'],\n                      title='Confusion matrix')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tn, fp, fn, tp = cm_xgb.ravel()\nprint(\"True Negatives: \",tn)\nprint(\"False Positives: \",fp)\nprint(\"False Negatives: \",fn)\nprint(\"True Positives: \",tp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_pred = pd.DataFrame(data=[],columns=[\"y_test\"])\ndf_pred[\"y_pred\"] = y_pred\ndf_pred[\"y_test\"] = y_test\ndf_pred.index = df_pred.index + 1\ndf_pred.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FP_predicts_indexes = [] \nTP_predicts_indexes=[]\nFN_predict_indexes =[]\nTN_predicts_indexes  = []\nfor index, row in df_pred.iterrows():\n    if row['y_test'] == 0 and row['y_pred'] == 1:\n        FP_predicts_indexes.append(row.name)\n    elif row['y_test'] == 1 and row['y_pred'] == 1:\n        TP_predicts_indexes.append(row.name)\n    elif row['y_test'] == 0 and row['y_pred'] == 0:\n        TN_predicts_indexes.append(row.name)\n    elif row['y_test'] == 1 and row['y_pred'] == 0:\n        FN_predict_indexes.append(row.name)\n        \ndf_pred.loc[TN_predicts_indexes,\"prediction_result\"] = \"TN\"\ndf_pred.loc[TP_predicts_indexes,\"prediction_result\"] = \"TP\"\ndf_pred.loc[FP_predicts_indexes,\"prediction_result\"] = \"FP\"\ndf_pred.loc[FN_predict_indexes,\"prediction_result\"] = \"FN\"\ndf_pred.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_pred[df_pred[\"prediction_result\"] == \"FP\"].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_pred[df_pred[\"prediction_result\"] == \"FN\"].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **ROC Curve**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"lbgm_tuned = model\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, precision_recall_curve, roc_curve, auc, average_precision_score\ny_pred_prob = lbgm_tuned.predict_proba(X_test)[:,1]\nfig, ax = plt.subplots()\nfpr, tpr, thresholds_roc = roc_curve(y_test, y_pred_prob)\nroc_auc = auc(fpr,tpr)\nax.plot(fpr,tpr, label = \" area = {:0.2f}\".format(roc_auc))\nax.plot([0,1], [0,1], 'r', linestyle = \"--\", lw = 2)\nax.set_xlabel(\"False Positive Rate\", fontsize = 10)\nax.set_ylabel(\"True Positive Rate\", fontsize = 10)\nax.set_title(\"ROC Curve\", fontsize = 18)\nax.legend(loc = 'best')\n\nclose_default = np.argmin(np.abs(thresholds_roc - 0.5))\nax.plot(fpr[close_default], tpr[close_default], 'o', markersize = 8)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Reporting**\n\nThe aim of this study was to create classification models for the churn dataset and to predict whether a person abandons us by creating models and to obtain maximum accuracy score in the established models. The work done is as follows:\n\n1) Churn Data Set read.\n\n2) With Exploratory Data Analysis; The data set's structural data were checked. The types of variables in the dataset were examined. Size information of the dataset was accessed. Descriptive statistics of the data set were examined. It was concluded that there were no missing observations and outliers in the data set.\n\n4) During Model Building; Logistic Regression, KNN, SVM, CART, Random Forests, XGBoost, LightGBM, CatBoost like using machine learning models Accuracy Score were calculated. Later XGBoost, LightGBM, CatBoost hyperparameter optimizations optimized to increase Accuracy score.\n\n5) Result; The model created as a result of LightGBM hyperparameter optimization became the model with the maxium Accuracy Score. (0.9122)","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}