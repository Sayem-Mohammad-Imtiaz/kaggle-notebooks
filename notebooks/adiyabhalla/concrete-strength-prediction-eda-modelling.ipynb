{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Packages "},{"metadata":{"trusted":false},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nsns.set(color_codes = True)\nimport matplotlib.pyplot as plt\n%matplotlib inline \nimport warnings \nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA || Deliverable 1"},{"metadata":{"trusted":false},"cell_type":"code","source":"data = pd.read_csv(\"concrete.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(data.head(10))\ndata.info()\ndata.isna().sum() \n\n# Observation and inference:\n\n# All numerical varaibles \n# no  missing  values in the data \n# zeros are the cases where the value of that ingredient is actually zero ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# 5 point summary statistics  \ndata.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# observations:\n\"\"\"\ncement > no outlier as max is under 75th percentle+ 1.5 IQR\nslag > high variance and seems outliers \nAsh >  high variance\nwater > seems outliers  \nsuperplastic > high variance and seems outliers \ncoarseagg > seems like a normal distribution\nfineagg > normal like distribution but outliers \nAge > high variance and outliers \nStrength > normal distribution \n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# checking above observations \n# outliers in data \ndata.plot(kind=\"box\", figsize =[15,8])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# except cement , Ash and coarseagg all variables seems to have outliers as observed intially \n# Checking no of outliers in the data \nq3 = data.quantile(0.75)\nq1 = data.quantile(0.25)\niqr = q3-q1\nout = ((data.iloc[:]<(q1-1.5*iqr))|(data.iloc[:]>(q3+1.5*iqr))).sum(axis=0)\nout_df = pd.DataFrame(out,index=data.columns,columns=[\"No of outliers\"])\nout_df['Percentage Outliers'] = round(out_df[\"No of outliers\"]*100/len(data),2)\nout_df[\"Percentage Outliers\"].sum() # 8.64% data in outlier \nout_df\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Univariae Analysis "},{"metadata":{"trusted":false},"cell_type":"code","source":"#Density distribution of variables \nplt.subplots(figsize = [18,8])\nax= sns.kdeplot(data= data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"col_names = data.columns\nfrom scipy.stats import zscore\nscaled_data = data.apply(zscore)\nf,ax = plt.subplots(nrows=3,ncols=3,figsize =(22,12))\nfor i,ax,j in zip(scaled_data.columns,ax.flatten(),col_names):\n    sns.distplot(scaled_data[i],ax=ax,label=j,rug=True)\n    ax.axvline(x=scaled_data[i].mean(),color=\"green\")\n    ax.axvline(x=scaled_data[i].median(),color=\"red\")\n    ax.text(x=scaled_data[i].mean(),y=0.5,s=\"Mean-Green \\n Median-Red\")\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# observations :\n\n\"\"\"\ncement > near normal distribution, mean ahead of median to right side,right skewed. \n\nSlag> multi modal distribution, mean is ahead of median to right side,right skewed  .\n\nAsh > multimode distribution, highly right skeweed  and no outliers as we already oserved. \n\nWater > not a normal distribution, seems left skewed. \n\nSuperplastic> multi gaussian distribution with one high peaked and one low,outliers and skewness. \n\ncoarseagg > not a normal distribution , mean and median coincide could be slightly skewed. \n\nfineagg > near normal distiribution,mean and median almost equal.\n\nAge > Outliers present in the variable and distribution is right skewed. \n\nStrength>  seems to be normally distributed \n\"\"\"\n# Inference : \n\"\"\"\nslag, Ash and superplastic seems multi gausians, will perform clustering for further analysis,suspect 2-6 clusters \n\nthere is skewness and outlier in the predictor variables.\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# checking the skewness based on above observation \ndata.skew()\n# Age is highly right skewed.\n# slag and superplastic are right skewed. \n# cement, Ash and strenght are slightly right skewed \n# fine and coarseagg are slightly left skewed \n# expected water to be left skewed however it is slightly right skewed. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# pair plot to check the dependency or correlation among the predictor variables \nfrom scipy.stats import zscore\nscaled_data = pd.DataFrame(data=data.apply(zscore),columns=list(data.columns))\nsns.pairplot(scaled_data,diag_kind=\"kde\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# observations: \n\"\"\"\ncement is distributed in groups across age.\ncement seems to be in an independent/non linear relationship wiht : fineagg, coarseagg, water,superplastic, ash, slag  \ncement seems to have strong correlation with strength.\n\nslag is distributed in groups across age.\nSlag seems to be divided into groups for each variable , one group is linear and the other one is a cloud\nslag vs strength > is a could, could be a weak prodictor \n\nAsh seems to be divided in groups for each variable, one group is linear where as other is a cloud\nAsh vs Strength > 2 groups for strength one is lienar and other is a cloud\n\ncoarseagg and fineagg vs strength is a cloud, could be weak predictors \n\nwater seems to be in an range bound cloud disribution with all variables \nwater vs Strength > seems to be range bound (spread across a particular range) \n\nsuperplastic distribution is divided into groups, one group is constant values across all variable while the other one is a cloud\nsuperplastic vs strength > superplastic seems to be positively correlated with strength \n\nAll variables are distributed in age groups \nAge vs strength > strength is maximum for a particular age range \n\n# Target Variable \n\nStrength is more for a lower age range.\nslag and water coarse and fineagg are forming a cloud with strength so does \nAge and ash is dirtibuted in groups for different strength \n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Based on above observation checking the correlation in the data \ncorr = data.corr()\nplt.subplots(figsize=(12,7))\nsns.heatmap(corr,annot=True,cmap=\"YlOrRd\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"corr_sorted =corr.unstack().sort_values(kind=\"quicksort\",ascending=False)\nprint(corr_sorted[corr_sorted!=1].head(10))\nprint(corr_sorted[corr_sorted!=1].tail(10))\n\n# Strong Negative correlation between superplastic and water\n# strong positive correlation between strength and cement","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"\"\"\"\nup till now we see strength is correlated with cement, cement seems to be a strog predictor.  \nNo evidence yet but Age seems to be strong factor in concrete strength.\nsuperplastic and water are negatively correlated. \nslag, Ash and superplastic are multi gaussians.\n\nthere is skewness and outlier in the predictor variables.\n\nOutlier Treatment > will test imputing outliers with mean , median and (10,90||25,75) percentile combination.\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Multi variate analysis "},{"metadata":{"trusted":false},"cell_type":"code","source":"# strength vs Age, water and cement \nplt.subplots(figsize=[20,12])\nsns.scatterplot(x= data.cement,y=data.strength,hue=data.water,size=data.age,sizes=(100,500),palette=\"rocket_r\")\nfig =plt.figure(figsize=[20,12])\nax=plt.axes(projection=\"3d\")\nax.scatter3D(xs=data.cement,ys=data.strength,zs=data.water,c=data.age,cmap=\"rocket_r\")\nax.set_xlabel(\"cement\")\nax.set_ylabel(\"strength\")\nax.set_zlabel('water')\nax.view_init(15,120)\n\n# Samples with lower water quantity have higher strength. \n# All high water samples have a restricted strength to  50\n# All high strength samples are of lower age than 80  \n# majority of the data lies in mean+-2 std i.e strength between 3 to 67 Mpa\n# as the water is increasing the strength is decreasing and maximum stregth is from samples having less water \n# very few samples with high strength, and all these smaples are below  age 80 \n# all samples above age 160 days are below strength 60. \n# cement quantity for maximum strength lies in the range 200 -500 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# strength vs superplastic and Age \nplt.subplots(figsize=(20,12))\nsns.scatterplot(x=data.superplastic,y=data.strength,hue=data.age,size=data.age,sizes=(100,500),palette=\"rocket_r\");\nfig =plt.figure(figsize=[20,12])\nax=plt.axes(projection=\"3d\")\nax.scatter3D(xs=data.superplastic,ys=data.strength,zs=data.age,c=data.age,cmap=\"rocket_r\")\nax.set_xlabel(\"Superplastic\")\nax.set_ylabel(\"strength\")\nax.set_zlabel('Age')\nax.view_init(15,120)\n\n# for one group superplastic is contanst for different age and strength rises linearly \n# for other group higher strength is for age less than 80 and superplastic in range 5-15\n# superplastic seems not to be a good predictor","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# strength vs slag and age \nplt.subplots(figsize=(20,12))\nsns.scatterplot(x=data.slag,y=data.strength,hue=data.age,size=data.age,sizes=(100,500),palette=\"rocket_r\");\n\nfig =plt.figure(figsize=[20,12])\nax=plt.axes(projection=\"3d\")\nax.scatter3D(xs=data.slag,ys=data.strength,zs=data.age,c=data.age,cmap=\"rocket_r\")\nax.set_xlabel(\"slag\")\nax.set_ylabel(\"strength\")\nax.set_zlabel('Age')\nax.view_init(15,120)\n\n# As slag is multiguassian, one group is constant and in the other group \n# higher strength samples have less age, i.e. below 80 and higher age samples have strength restricted to 60\n# does not seems to be strong predictor ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# strength vs Age and Ash \nfig =plt.figure(figsize=[20,12])\nax=plt.axes(projection=\"3d\")\nax.scatter3D(xs=data.age,ys=data.strength,zs=data.ash,c=data.age,cmap=\"rocket_r\")\nax.set_xlabel(\"Age\")\nax.set_ylabel(\"strength\")\nax.set_zlabel('Ash')\nax.view_init(15,120)\n\n# Data is divided in groups: \n# higher strength samples have less age, i.e. below 80 and higher age samples have strength restricted to 60\n# does not seems to be strong predictor ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# strength vs Age and water\nfig = plt.figure(figsize=[15,110])\nax = plt.axes(projection=\"3d\")\nax.scatter3D(data.age,data.strength,data.water,c=data.age,cmap=\"rocket_r\")\nax.set_xlabel(\"Age\")\nax.set_ylabel(\"Strength\")\nax.set_zlabel(\"Water\")\nax.view_init(15,100)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# strength vs superplastic, age and water \nfig = plt.figure(figsize=(15,10))\nax = plt.axes(projection=\"3d\")\nax.scatter3D(data.water,data.strength,data.superplastic,c=data.age,cmap=\"PuBu_r\")\nax.set_xlabel('water')\nax.set_ylabel('strength')\nax.set_zlabel(\"superplastic\")\nax.view_init(10,120)\nplt.show","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Outlier Treatment method testing"},{"metadata":{"trusted":false},"cell_type":"code","source":"# making a copy of the data to test the best method for outlier treatment \ndata2 = data.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# outlier treatment / imputation \n# choosing Age first as it has the most outlier \n\n# Iteration 1 : imputing it with upper and lower whisker value \nAge_1 = data2.age\niqr = Age_1.quantile(0.75)-Age_1.quantile(0.25)\nupp_whs = Age_1.quantile(0.75)+1.5*iqr\nlow_whs = Age_1.quantile(0.25)-1.5*iqr \nAge_1 = np.array(Age_1)\nupp_whs_dp = np.where(Age_1>upp_whs)\nlow_whs_dp = np.where(Age_1<low_whs)\nAge_1[upp_whs_dp] = pd.Series(Age_1).quantile(0.75)\nAge_1[low_whs_dp]=pd.Series(Age_1).quantile(0.25)\n\n# Iteration 2 : imputing with mean \nAge_2 = data2.age\niqr = Age_2.quantile(0.75)-Age_2.quantile(0.25)\nupp_whs = Age_2.quantile(0.75)+1.5*iqr\nlow_whs = Age_2.quantile(0.25)-1.5*iqr \nAge_2 = np.array(Age_2)\nupp_whs_dp = np.where(Age_2>upp_whs)\nlow_whs_dp = np.where(Age_2<low_whs)\nAge_2[upp_whs_dp] = pd.Series(Age_2).mean()\nAge_2[low_whs_dp]=pd.Series(Age_2).mean()\n\n# Iteration 3 : imputing with median \nAge_3 = data2.age\niqr = Age_3.quantile(0.75)-Age_3.quantile(0.25)\nupp_whs = Age_3.quantile(0.75)+1.5*iqr\nlow_whs = Age_3.quantile(0.25)-1.5*iqr \nAge_3 = np.array(Age_3)\nupp_whs_dp = np.where(Age_3>upp_whs)\nlow_whs_dp = np.where(Age_3<low_whs)\nAge_3[upp_whs_dp] = pd.Series(Age_3).median()\nAge_3[low_whs_dp]=pd.Series(Age_3).median()\n\n# Distribution Plot of the variable\nf,((ax1,ax2,ax3),(ax4,ax5,ax6),(ax7,ax8,ax9),(ax10,ax11,ax12))=plt.subplots(nrows=4,ncols=3,figsize = [17,14])\n# Raw Data distribution \nsns.kdeplot(data.age,ax=ax1)\nax1.axvline(x=data.age.mean(),color=\"green\")\nax1.axvline(x=data.age.median(),color=\"red\")\nax1.axvline(x=0,color=\"orange\")\nsns.boxplot(data.age,ax=ax2)\nsns.histplot(data.age,ax=ax3)\nax3.axvline(x=data.age.mean(),color=\"green\")\nax3.axvline(x=data.age.median(),color=\"red\")\nax3.axvline(x=0,color=\"orange\")\n\n# Age after outlier treatment with quantiles(75,25)\n\nsns.kdeplot(Age_1,ax=ax4,legend=\"Quantile imputing\")\nax4.axvline(x=Age_1.mean(),color=\"green\")\nax4.axvline(x=pd.Series(Age_1).median(),color=\"red\")\nax4.axvline(x=0,color=\"orange\")\nsns.boxplot(Age_1,ax=ax5)\nsns.histplot(Age_1,ax=ax6)\nax6.axvline(x=Age_1.mean(),color=\"green\")\nax6.axvline(x=pd.Series(Age_1).median(),color=\"red\")\nax6.axvline(x=0,color=\"orange\")\n#plt.xlabel(\"Age after outlier treatment with quantiles(75,25) \")\nplt.legend()\n\n# Age after outlier treatment with mean value \n\nsns.kdeplot(Age_2,ax=ax7)\nax7.axvline(x=Age_2.mean(),color=\"green\")\nax7.axvline(x=pd.Series(Age_2).median(),color=\"red\")\nax7.axvline(x=0,color=\"orange\")\nsns.boxplot(Age_2,ax=ax8)\nsns.histplot(Age_2,ax=ax9)\nax9.axvline(x=Age_2.mean(),color=\"green\")\nax9.axvline(x=pd.Series(Age_2).median(),color=\"red\")\nax9.axvline(x=0,color=\"orange\")\n#plt.xlabel(\"Age after outlier treatment with mean value \")\n\n# Age after outlie treatment with median value \n\nsns.kdeplot(Age_3,ax=ax10)\nax10.axvline(x=Age_3.mean(),color=\"green\")\nax10.axvline(x=pd.Series(Age_3).median(),color=\"red\")\nax10.axvline(x=0,color=\"orange\")\nsns.boxplot(Age_3,ax=ax11)\nsns.histplot(Age_3,ax=ax12)\nax12.axvline(x=Age_3.mean(),color=\"green\")\nax12.axvline(x=pd.Series(Age_3).median(),color=\"red\")\nax12.axvline(x=0,color=\"orange\")\n\nplt.tight_layout()\n\n# Infrences \n\n# Iteration 1 : tried replacing upper ouliers with 75th percentile and lower with 25th percentile, multimodes are generated however\n# outliers are treated by this particluar method for Age. \n# Iteration 2 : replacing with mean value increased the outlier, it required second iteration and \n# is creating more outliers and peaking the distribution. \n# Iteration 3 : similar behavious as that of iteration 2\n\n#Below Plots \n# row 1: raw data distribution \n# row 2: Distribution after Imputing outlier values with quantile values (75 and 25) for upper and lower outliers respectively\n# row 3: Distribution after imputing outlier values with mean value (2 iterations performed to eliminate the outlier)\n# row 4: Distribution after imputing outlier with median value \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# superplastic \n\n# Iteration 1: imputing with mean 9.2 , median 9.4\nsuperplastic = data2.superplastic\nprint(\"standard deviation raw\", superplastic.std())\niqr = superplastic.quantile(0.75)-superplastic.quantile(0.25)\nupp_wsh = superplastic.quantile(0.75)+1.5*iqr\nprint(\"upper whisker value superplastic\", upp_wsh)\nlow_wsh = superplastic.quantile(0.25)-1.5*iqr\nprint(\"lower whisker value superplastic\", low_wsh)\nsuperplastic = np.array(superplastic)\nupp_wsh_dp = np.where(superplastic>upp_wsh)\nprint(\"upper whisker data points\", superplastic[upp_wsh_dp].shape)\nlow_wsh_dp = np.where(superplastic<low_wsh)\nprint(\"lower whisker data points\", superplastic[low_wsh_dp].shape)\n\n# imputation \nsuperplastic[upp_wsh_dp] =pd.Series(superplastic).mean() \nsuperplastic[low_whs_dp]= pd.Series(superplastic).mean()\nprint(\"standard deviation after iteration 2 \",superplastic.std())\n\n\n# Iteration 2: imputing with 75th percentile and 25th percentile \nsuperplastic_quant = data2.superplastic\nprint(\"standard deviation raw\", superplastic_quant.std())\niqr = superplastic_quant.quantile(0.75)-superplastic_quant.quantile(0.25)\nupp_wsh = superplastic_quant.quantile(0.75)+1.5*iqr\nprint(\"upper whisker value superplastic_quant\", upp_wsh)\nlow_wsh = superplastic_quant.quantile(0.25)-1.5*iqr\nprint(\"lower whisker value superplastic_quant\", low_wsh)\nsuperplastic_quant = np.array(superplastic_quant)\nupp_wsh_dp = np.where(superplastic_quant>upp_wsh)\nprint(\"upper whisker data points\", superplastic_quant[upp_wsh_dp].shape)\nlow_wsh_dp = np.where(superplastic_quant<low_wsh)\nprint(\"lower whisker data points\", superplastic_quant[low_wsh_dp].shape)\n\n# imputation \nprint(\"75th percentile superplastic\", pd.Series(superplastic_quant).quantile(0.75))\nprint(\"25th percentile superplastic\", pd.Series(superplastic_quant).quantile(0.25))\nsuperplastic_quant[upp_wsh_dp] = pd.Series(superplastic_quant).quantile(0.75) \nsuperplastic_quant[low_wsh_dp]= pd.Series(superplastic_quant).quantile(0.25)\nprint(\"standard deviation after Iteration 2 \",superplastic_quant.std())\n\n# Raw distibution of superplastic \nf,((ax1,ax2),(ax3,ax4),(ax5,ax6)) = plt.subplots(nrows=3,ncols=2,figsize=[17,15])\nsns.kdeplot(data.superplastic,ax=ax1)\nax1.axvline(x=data.superplastic.mean(),color=\"red\")\nax1.axvline(x=data.superplastic.median(),color=\"green\")\nsns.boxplot(data.superplastic,ax=ax2)\n\n# distribution after treating outliers iteration 1 (mean ) \nsns.kdeplot(superplastic,ax=ax3)\nax3.axvline(x=superplastic.mean(),color=\"red\")\nax3.axvline(x=pd.Series(superplastic).median(),color=\"green\")\nsns.boxplot(superplastic,ax=ax4)\nplt.xlabel(\"Superplalstic after treating outliers iteration 1\")\n\n# distribution after treating outliers iteration 2 (25,75 quantile)\nsns.kdeplot(superplastic_quant,ax=ax5)\nax5.axvline(x=superplastic_quant.mean(),color=\"red\")\nax5.axvline(x=pd.Series(superplastic_quant).median(),color=\"green\")\nsns.boxplot(superplastic_quant,ax=ax6)\nplt.xlabel(\"Superplalstic after treating outliers iteration 2 \")\nplt.show()\n\n\n# outliers are removed, by both the methods \n# Standard deviation is reduced when imputed, however its less reduced with quantile imputing  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# water outlier treatment \noutlier_up = data.water.loc[data.water>data.water.quantile(0.75)+1.5*(data.water.quantile(0.75)-data.water.quantile(0.25))]\noutlier_low = data.water.loc[data.water<data.water.quantile(0.25)-1.5*(data.water.quantile(0.75)-data.water.quantile(0.25))]\nprint(\"upper whisker value\",data.water.quantile(0.75)+1.5*(data.water.quantile(0.75)-data.water.quantile(0.25)))\nprint(\"lower whisker value\",data.water.quantile(0.25)-1.5*(data.water.quantile(0.75)-data.water.quantile(0.25)))\nprint(\"Upper outliers water\", outlier_up)\nprint(\"lower outliers water\",outlier_low)\nprint(\"std raw distribution\",data.water.std())\n\n# Iteration 1: imputing with 75th and 25th quantile \nwater_1 = data2.water\nwater_1[outlier_up.index] = water_1.quantile(0.75)\nwater_1[outlier_low.index] = water_1.quantile(0.25)\nprint(\"std iteration 1\", water_1.std())\n\n# Iteration 2: imputing with mean \nwater_2 = data2.water\nwater_2[outlier_up.index] = water_2.mean()\nwater_2[outlier_low.index] = water_2.mean()\nprint(\"std iteration 2\", water_2.std())\n\n# iteration3 : imputing with median \n\nwater_3 = data2.water\nwater_3[outlier_up.index] = water_3.median()\nwater_3[outlier_low.index] = water_3.median()\nprint(\"std iteration 3\", water_3.std())\n\n# water > normal distribution but outliers \nf,((ax1,ax2),(ax3,ax4),(ax5,ax6),(ax7,ax8)) = plt.subplots(nrows=4,ncols=2,figsize=[25,15])\nsns.kdeplot(x=data.water,ax=ax1)\nax1.axvline(x=data.water.mean(),color=\"red\")\nax1.axvline(x=data.water.median(),color=\"green\")\nsns.boxplot(data.water,ax=ax2)\n\n# distribution after outlier treatment iteration 1 quantile imputing \nsns.kdeplot(water_1,ax=ax3)\nax3.axvline(x=water_1.mean(),color=\"red\")\nax3.axvline(x=water_1.median(),color=\"green\")\nsns.boxplot(water_1,ax=ax4)\n\n# distribution after outlier treatment iteration 2 mean imputing\nsns.kdeplot(water_2,ax=ax5)\nax5.axvline(x=water_2.mean(),color=\"red\")\nax5.axvline(x=water_2.median(),color=\"green\")\nsns.boxplot(water_2,ax=ax6)\n\n# distribution after outlier treatment iteration 1  median imputing\nsns.kdeplot(water_3,ax=ax7)\nax7.axvline(x=water_3.mean(),color=\"red\")\nax7.axvline(x=water_3.median(),color=\"green\")\nsns.boxplot(water_3,ax=ax8)\n\n\n# distribution after outlier treatment does not differ from original raw data distribution \n# outliers are treated with both the method, however std is reduced less with quantile imputing ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# slag outlier treatment \noutlier_up = data.slag.loc[data.slag>data.slag.quantile(0.75)+1.5*(data.slag.quantile(0.75)-data.slag.quantile(0.25))]\noutlier_low = data.slag.loc[data.slag<data.slag.quantile(0.25)-1.5*(data.slag.quantile(0.75)-data.slag.quantile(0.25))]\nprint(\"upper whisker value\",data.slag.quantile(0.75)+1.5*(data.slag.quantile(0.75)-data.slag.quantile(0.25)))\nprint(\"lower whisker value\",data.slag.quantile(0.25)-1.5*(data.slag.quantile(0.75)-data.slag.quantile(0.25)))\nprint(\"Upper outliers slag\", outlier_up)\nprint(\"lower outliers slag\",outlier_low)\nprint(\"std raw distribution\",data.slag.std())\n\n# Iteration 1: imputing with 75th and 25th quantile \nslag_1 = data2.slag\nslag_1[outlier_up.index] = slag_1.quantile(0.75)\nslag_1[outlier_low.index] = slag_1.quantile(0.25)\nprint(\"std iteration 1\", slag_1.std())\n\n# Iteration 2: imputing with mean \nslag_2 = data2.slag\nslag_2[outlier_up.index] = slag_2.mean()\nslag_2[outlier_low.index] = slag_2.mean()\nprint(\"std iteration 2\", slag_2.std())\n\n# iteration3 : imputing with median \n\nslag_3 = data2.slag\nslag_3[outlier_up.index] = slag_3.median()\nslag_3[outlier_low.index] = slag_3.median()\nprint(\"std iteration 3\", slag_3.std())\n\n# slag > normal distribution but outliers \nf,((ax1,ax2),(ax3,ax4),(ax5,ax6),(ax7,ax8)) = plt.subplots(nrows=4,ncols=2,figsize=[25,15])\nsns.kdeplot(x=data.slag,ax=ax1)\nax1.axvline(x=data.slag.mean(),color=\"red\")\nax1.axvline(x=data.slag.median(),color=\"green\")\nsns.boxplot(data.slag,ax=ax2)\n\n# distribution after outlier treatment iteration 1 quantile imputing \nsns.kdeplot(slag_1,ax=ax3)\nax3.axvline(x=slag_1.mean(),color=\"red\")\nax3.axvline(x=slag_1.median(),color=\"green\")\nsns.boxplot(slag_1,ax=ax4)\n\n# distribution after outlier treatment iteration 2 mean imputing\nsns.kdeplot(slag_2,ax=ax5)\nax5.axvline(x=slag_2.mean(),color=\"red\")\nax5.axvline(x=slag_2.median(),color=\"green\")\nsns.boxplot(slag_2,ax=ax6)\n\n# distribution after outlier treatment iteration 1  median imputing\nsns.kdeplot(slag_3,ax=ax7)\nax7.axvline(x=slag_3.mean(),color=\"red\")\nax7.axvline(x=slag_3.median(),color=\"green\")\nsns.boxplot(slag_3,ax=ax8)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# fineagg \noutlier_up = data.fineagg.loc[data.fineagg>data.fineagg.quantile(0.75)+1.5*(data.fineagg.quantile(0.75)-data.fineagg.quantile(0.25))]\noutlier_low = data.fineagg.loc[data.fineagg<data.fineagg.quantile(0.25)-1.5*(data.fineagg.quantile(0.75)-data.fineagg.quantile(0.25))]\nprint(\"upper whisker value\",data.fineagg.quantile(0.75)+1.5*(data.fineagg.quantile(0.75)-data.fineagg.quantile(0.25)))\nprint(\"lower whisker value\",data.fineagg.quantile(0.25)-1.5*(data.fineagg.quantile(0.75)-data.fineagg.quantile(0.25)))\nprint(\"Upper outliers fineagg\", outlier_up)\nprint(\"lower outliers fineagg\",outlier_low)\nprint(\"std raw distribution\",data.fineagg.std())\nsns.boxplot(data.fineagg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data.fineagg.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Iteration 1: imputing with 75th and 25th quantile \nfineagg_1 = data2.fineagg\nfineagg_1[outlier_up.index] = fineagg_1.quantile(0.90)\nfineagg_1[outlier_low.index] = fineagg_1.quantile(0.10)\nprint(\"std iteration 1\", fineagg_1.std())\n\n# Iteration 2: imputing with mean \nfineagg_2 = data2.fineagg\nfineagg_2[outlier_up.index] = fineagg_2.mean()\nfineagg_2[outlier_low.index] = fineagg_2.mean()\nprint(\"std iteration 2\", fineagg_2.std())\n\n# iteration3 : imputing with median \n\nfineagg_3 = data2.fineagg\nfineagg_3[outlier_up.index] = fineagg_3.median()\nfineagg_3[outlier_low.index] = fineagg_3.median()\nprint(\"std iteration 3\", fineagg_3.std())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# fineagg > normal distribution but outliers \nf,((ax1,ax2),(ax3,ax4),(ax5,ax6),(ax7,ax8)) = plt.subplots(nrows=4,ncols=2,figsize=[25,15])\nsns.kdeplot(x=data.fineagg,ax=ax1)\nax1.axvline(x=data.fineagg.mean(),color=\"red\")\nax1.axvline(x=data.fineagg.median(),color=\"green\")\nsns.boxplot(data.fineagg,ax=ax2)\n\n# distribution after outlier treatment iteration 1 quantile imputing \nsns.kdeplot(fineagg_1,ax=ax3)\nax3.axvline(x=fineagg_1.mean(),color=\"red\")\nax3.axvline(x=fineagg_1.median(),color=\"green\")\nsns.boxplot(fineagg_1,ax=ax4)\n\n# distribution after outlier treatment iteration 2 mean imputing\nsns.kdeplot(fineagg_2,ax=ax5)\nax5.axvline(x=fineagg_2.mean(),color=\"red\")\nax5.axvline(x=fineagg_2.median(),color=\"green\")\nsns.boxplot(fineagg_2,ax=ax6)\n\n# distribution after outlier treatment iteration 1  median imputing\nsns.kdeplot(fineagg_3,ax=ax7)\nax7.axvline(x=fineagg_3.mean(),color=\"red\")\nax7.axvline(x=fineagg_3.median(),color=\"green\")\nsns.boxplot(fineagg_3,ax=ax8)\n\n# when imputing with quantile and mean/median, more outliers are generated i.e. the new outliers are previous minimum data points \n# as with imputation std is reduced hence new points are outliers now.","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# strength \noutlier_up = data.strength.loc[data.strength>data.strength.quantile(0.75)+1.5*(data.strength.quantile(0.75)-data.strength.quantile(0.25))]\noutlier_low = data.strength.loc[data.strength<data.strength.quantile(0.25)-1.5*(data.strength.quantile(0.75)-data.strength.quantile(0.25))]\nprint(\"upper whisker value\",data.strength.quantile(0.75)+1.5*(data.strength.quantile(0.75)-data.strength.quantile(0.25)))\nprint(\"lower whisker value\",data.strength.quantile(0.25)-1.5*(data.strength.quantile(0.75)-data.strength.quantile(0.25)))\nprint(\"Upper outliers strength\", outlier_up)\nprint(\"lower outliers strength\",outlier_low)\nprint(\"std raw distribution\",data.strength.std())\n\n# Iteration 1: imputing with 75th and 25th quantile \nstrength_1 = data2.strength\nstrength_1[outlier_up.index] = strength_1.quantile(0.75)\nstrength_1[outlier_low.index] = strength_1.quantile(0.25)\nprint(\"std iteration 1\", strength_1.std())\n\n# Iteration 2: imputing with mean \nstrength_2 = data2.strength\nstrength_2[outlier_up.index] = strength_2.mean()\nstrength_2[outlier_low.index] = strength_2.mean()\nprint(\"std iteration 2\", strength_2.std())\n\n# iteration3 : imputing with median \n\nstrength_3 = data2.strength\nstrength_3[outlier_up.index] = strength_3.median()\nstrength_3[outlier_low.index] = strength_3.median()\nprint(\"std iteration 3\", strength_3.std())\n\n# strength > normal distribution but outliers \nf,((ax1,ax2),(ax3,ax4),(ax5,ax6),(ax7,ax8)) = plt.subplots(nrows=4,ncols=2,figsize=[25,15])\nsns.kdeplot(x=data.strength,ax=ax1)\nax1.axvline(x=data.strength.mean(),color=\"red\")\nax1.axvline(x=data.strength.median(),color=\"green\")\nsns.boxplot(data.strength,ax=ax2)\n\n# distribution after outlier treatment iteration 1 quantile imputing \nsns.kdeplot(strength_1,ax=ax3)\nax3.axvline(x=strength_1.mean(),color=\"red\")\nax3.axvline(x=strength_1.median(),color=\"green\")\nsns.boxplot(strength_1,ax=ax4)\n\n# distribution after outlier treatment iteration 2 mean imputing\nsns.kdeplot(strength_2,ax=ax5)\nax5.axvline(x=strength_2.mean(),color=\"red\")\nax5.axvline(x=strength_2.median(),color=\"green\")\nsns.boxplot(strength_2,ax=ax6)\n\n# distribution after outlier treatment iteration 1  median imputing\nsns.kdeplot(strength_3,ax=ax7)\nax7.axvline(x=strength_3.mean(),color=\"red\")\nax7.axvline(x=strength_3.median(),color=\"green\")\nsns.boxplot(strength_3,ax=ax8)\n\n# new data points are emerging out of with both the types of imputation ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Methods are working for different variables as listed below \n'''\nAge > qunatile imputing worked, while mean and median generates more outliers \n\nwater >  both methods worked\n\nsuperplastic > both method worked \n\nslag > both  method worked \n\nfineagg > with both method lower outlier is genrated and these new outlier value are closer to mean hence not imputing further  \n\ntarget variabele\n\nstrength > not all outliers are eliminated by both the methods with new data points becoming outliers now.  \n\nchoosing 25th and 75th percentile for imputation. \n\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# outlier impuation \ndata3 = data.copy()\ndata3.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data3.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data3.plot(kind=\"box\",figsize=(12,8))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# imputing the upper and lower outlier with 75th and 25th Quantile respectivly \ncol_names = list(data3.columns)\nfor i in col_names:\n    q3 = data3[i].quantile(0.75)\n    q1 = data3[i].quantile(0.25)\n    iqr = q3-q1\n    low_out = data3[i].loc[data3[i]<(q1-1.5*iqr)]\n    up_out= data3[i].loc[data3[i]>(q3+1.5*iqr)]\n    data3[i][up_out.index] = q3\n    if len(low_out) != 0 :\n        data3[i][low_out.index]=q1","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data3.plot(kind=\"box\", figsize=(12,8))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"col_names = data3.columns\nf,ax = plt.subplots(nrows=3,ncols=3,figsize =(22,12))\nfor i,ax,j in zip(data3.columns,ax.flatten(),col_names):\n    sns.boxplot(data3[i],ax=ax)\n    # ax.text(x=data[i].mean(),y=0.001,s=j)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# all outliers seem treated, distribution after treatment aldready discussed above ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n# Feature Engineering || Deliverable 2 \n\n# Refrences \n\nhttps://link.springer.com/referenceworkentry/10.1007%2F978-1-4419-0851-3_121\n\nhttps://buildingresearch.com.np/services/ct/ct2.php\n\nhttps://theconstructor.org/concrete/compressive-strength-concrete-cube-test/1561/\n\nhttps://en.wikipedia.org/wiki/Compressive_strength\n    "},{"metadata":{},"cell_type":"markdown","source":"### understanding after EDA : \n\nStrong strength predictors> cement , Age, seems strong predictors \n\ncement >>> cement is strong predictor cement quantity for maximum strength lies in the range 200 -500\n\nwater >>> Samples with lower water quantity have higher strength, all high water samples have a restricted strength to  50\n\nAge >>> higher strength is for age less than 80 very few samples with high strength, and all these smaples are below  age 80 \nall samples above age 160 days are below strength 60. \n\n\n\ncoarseagg, fineagg, superplasic, slag, ash\n\ncoarseagg and fineagg vs strength is a cloud, could be weak predictors \n\nslag, Ash and superplastic are multi gaussians\n\nslag vs strength > is a could, could be a weak prodictor \n\nAsh vs Strength > 2 groups for strength one is lienar and other is a cloud\n### -----------------------------------------------------------------------------------------------------------------------------\n\ncompressive strength of a cement : compressive strength resists being pushed together.\n\ncompressive strength of a cement depends upon below factors based on below refrences \n\nwater / cement ratio\n\ncement / sand ratio\n\nType and grading of sand \n\nmanner of mixing \n\nsize and shape of specimen\n\nAge of the specimen/ sample, cement gains strength over time ( we already saw above) \n"},{"metadata":{},"cell_type":"markdown","source":"### Addition of features \n\nbased on above factors, creating 2 more features as per the given data i.e. \n\nwater/cement ration and cement to sand ratio which in our data set will be cement/fineagg \n\n\nstrength is inversely proportional to water/cement ration lower the ration more the strength i.e. more the cement\n\nwith an optimal quantity of water will lead to better strength.\n\ncement/fineagg ration while preparing the concrete should be 1:2,\n\nwe can check if there is any deviation from this usual process, also we can also "},{"metadata":{"trusted":false},"cell_type":"code","source":"data3[\"w_c_ratio\"]= data3.water/data3.cement\ndata3['c_f_ratio']= data3.cement/data3.fineagg\ndata3.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# checking c/f ration\nplt.subplot(1,2,1)\ndata3['w_c_ratio'].plot(kind=\"box\")\nplt.subplot(1,2,2)\ndata3['c_f_ratio'].plot(kind=\"box\")\n# both new features seems to have outlier where as the c/f ration has more outliers than w/c ration. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.subplots(figsize=(12,6))\nplt.subplot(1,2,1)\nsns.distplot(data3[\"w_c_ratio\"])\nplt.subplot(1,2,2)\nsns.distplot(data3['c_f_ratio'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data3['c_f_ratio'].describe()\n# the distribution of this feature is between 0.07 to 0.67 with a mean of 0.37\n# which means on average the ration of cement to sand is 1 to 3 where as the ideal situation is 1:2 i.e. 0.50\ndata3['c_f_ratio'].loc[(data3['c_f_ratio']>0.50)] # 182 cases where ratio is greater than 0.50\n# remaining cases is where ration is less than 0.50 wehre cement is added more than usual to improve the strength of concrete.","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# data > original data \n# data2> Analysing the data \n# data3> all existing variables (w/o outlier)+ 2 new added features (w outlier)\n# for treating outlier of the 2 newly added feature\ndata4 = data3.copy() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# treating outlier of the new features \nq1 = data4['w_c_ratio'].quantile(0.25)\nq3 = data4['w_c_ratio'].quantile(0.75)\niqr= q3-q1\nout_w_c= data4['w_c_ratio'].loc[data4['w_c_ratio']>data4['w_c_ratio'].quantile(0.75)+1.5*iqr]# 16 outliers \nq1 = data4['c_f_ratio'].quantile(0.25)\nq3 = data4['c_f_ratio'].quantile(0.75)\niqr= q3-q1\nout_c_f= data4['c_f_ratio'].loc[data4['c_f_ratio']>data4['c_f_ratio'].quantile(0.75)+1.5*iqr] # 32 outliers ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# imputing with 75th percentile  \ndata4['c_f_ratio'].iloc[out_c_f.index] = data4['c_f_ratio'].quantile(0.75)\ndata4['w_c_ratio'].iloc[out_w_c.index] = data4['w_c_ratio'].quantile(0.75)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.subplot(1,2,1)\ndata4['w_c_ratio'].plot(kind=\"box\")\nplt.subplot(1,2,2)\ndata4['w_c_ratio'].plot(kind=\"kde\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.subplot(1,2,1)\ndata4['c_f_ratio'].plot(kind=\"box\")\nplt.subplot(1,2,2)\ndata4['c_f_ratio'].plot(kind=\"kde\")\n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"col_names = data4.columns\nf,ax = plt.subplots(nrows=3,ncols=4,figsize =(22,12))\nfor i,ax,j in zip(data4.columns,ax.flatten(),col_names):\n    sns.boxplot(data4[i],ax=ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### checking the important components, leveraging PCA. "},{"metadata":{"trusted":false},"cell_type":"code","source":"from scipy.stats import zscore\ndata_pca = data4.apply(zscore)\nx = data_pca.drop(\"strength\",axis=1)\nfrom scipy.stats import zscore\ncov_mat = np.cov(x,rowvar=False)\ncov_mat","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.decomposition import PCA\n# chossing 10 principal components intially \npca = PCA(n_components=10)\npca.fit(x)\n#eigen values magnituge / length of eign vectors \nprint(\"Eigne values:\\n\", pca.explained_variance_)\n# eigen vectors direction\nprint(\"Eigen vectors:\\n\",pca.components_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# percentage of variance explained by each eigen vector \nplt.plot(np.cumsum(pca.explained_variance_ratio_))\nplt.ylabel(\"cumulative variation explained\")\nplt.xlabel(\"Eigen Value\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(\"percentage of variance explained by each eigen vector\\n\",pca.explained_variance_ratio_)\nplt.bar(list(range(1,11)),pca.explained_variance_ratio_,alpha=0.5)\nplt.ylabel(\"Variation explained\")\nplt.xlabel(\"Eigen Value\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"cum_var_exp = np.cumsum(pca.explained_variance_ratio_)\npd.DataFrame(cum_var_exp,index=range(1,11),columns=['Cumulative variance explained'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# from above plots its conclusive that 6 principal components explains more than 95 percent of the variation.\n# proceeding with 6 components \npca6 = PCA(n_components=6)\npca6.fit(x)\n#eigen values magnituge / length of eign vectors \nprint(\"Eigne values:\\n\", pca6.explained_variance_)\n# eigen vectors direction\nprint(\"Eigen vectors:\\n\",pca6.components_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# preparing data for further use during model building \nxpca6 = pca6.transform(x)\ny = data_pca.strength\nfrom sklearn.model_selection import train_test_split\nxpca_train,xpca_test, ypca_train,ypca_test = train_test_split(xpca6,y,test_size=0.30,random_state=1)\nprint(xpca_train.shape)\nprint(xpca_test.shape)\nprint(ypca_train.shape)\nprint(ypca_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Decision Tree Regressor"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Buidling a decision tree regressor to check the important features in the data set \n# Training the model on the original data set\n\nx= data.drop(\"strength\",axis=1)\ny = data.strength\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.3, random_state=78)\nmodel_dt_org = DecisionTreeRegressor(max_depth=5,random_state=97)\nmodel_dt_org.fit(x_train,y_train)\nprint(\"score on train set\",model_dt_org.score(x_train,y_train))\nprint(\"score on test set\", model_dt_org.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"feature_df = pd.DataFrame({\"features\": x_train.columns,\n                          \"Feature importance\": model_dt_org.feature_importances_})\nfeature_df.sort_values(by=\"Feature importance\",axis=0, ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Age cement and water are important features, lets plot the tree and check the split \nfig = plt.figure(figsize=(25,20),dpi= 300)\n_=plot_tree(model_dt_org,feature_names=x_train.columns, filled=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Building a decision tree regressor to find out feature importance on the data set with increased features \nx = data4.drop(\"strength\", axis=1)\ny = data4.strength\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,random_state= 1)\nprint(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\nmodel_dt = DecisionTreeRegressor(random_state= 0, max_depth=5)\nmodel_dt.fit(x_train,y_train)\nypred_train= model_dt.predict(x_train)\nypred_test = model_dt.predict(x_test)\nprint(\"Score on train set\", model_dt.score(x_train,y_train))\nprint(\"score on test set\", model_dt.score(x_test,y_test))\nimp_features = pd.DataFrame({\"Features\":x.columns,\"Feature_importance\":model_dt.feature_importances_})\nimp_features.sort_values(by=\"Feature_importance\",axis=0,ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"\"\"\"\nthe model has a train accuracy of 83 , its underfitting / we can say high bias.\nwe have a low variance in the model  as there is not a huge difference between train and test accuracy \nalso after adding features and treating outliers the overall accuracy of the model is increased, however Dt is not affected \nby outliers \"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# plotting the tree \nfrom sklearn.tree import plot_tree\nfeatures = x.columns\nplt.subplots(nrows = 1,ncols = 1,figsize = (10, 10), dpi=300)\nplot_tree(model_dt,filled=True,feature_names=features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# builing the model on the reduced feature data set \nmodel_dt_pca = DecisionTreeRegressor(random_state=12,max_depth=5)\nmodel_dt_pca.fit(xpca_train,ypca_train)\nprint(\"train set accuracy\",model_dt_pca.score(xpca_train,ypca_train))\nprint(\"test set accuracy\",model_dt_pca.score(xpca_test,ypca_test))\n# the model on reduced feature is underfitting the training data and there seems to be high variance as well ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### K means  clustering. "},{"metadata":{"trusted":false},"cell_type":"code","source":"# After the pair plot Analysis, intially expected 2-6 clusters.  \n# plotting an elbow plot for 8 clusters \n\nfrom scipy.stats import zscore\ndata3 = data3.apply(zscore)  # scaling \nclusters =range(2,9)\nwss = []\nmean_distortion = []\nlabels = []\nfor c in clusters:\n    model_kmeans = KMeans(n_clusters=c,init=\"k-means++\")\n    model_kmeans.fit(data3)\n    wss.append(model_kmeans.inertia_)\n    mean_distortion.append(sum(np.min(cdist(data3,model_kmeans.cluster_centers_,\"euclidean\"),axis=1))/data3.shape[0])\n    labels.append(model_kmeans.labels_)\n    \n    \nplt.subplots(figsize=(12,6))\nplt.subplot(1,2,1)\nplt.plot(clusters,wss,\"b-o\")\nplt.xlabel(\"within cluster sum of square error\" )\nplt.subplot(1,2,2)\nplt.plot(clusters,mean_distortion,\"b-o\")\nplt.xlabel(\"mean distortion\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# from above elbow plots working with 3 clusters first \ndata_c3 = data3.copy()\nmodel_c3 = KMeans(n_clusters=3, init=\"k-means++\")\nmodel_c3.fit(data_c3)\nprediction = model_c3.predict(data_c3)\ndata_c3['GROUP'] = prediction\ncentroids = model_c3.cluster_centers_\ncentroids_df = pd.DataFrame(centroids,columns=list(data3.columns))\nprint(\"Cluster centroids\")\ncentroids_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data_c3.boxplot(by=\"GROUP\" ,figsize=[18,18]);\n\n# Age has outliers in group 1  \n# Ash has outlier in grooup 0 \n# c/f ration has outliers in all groups \n# cement has outliers in group 0 \n# coarseagg no outliers \n# fineagg has outliers in group 1 and 2 lower outlier  \n# slag group 0 has outliers \n# strength only group 0 has outliers \n# superplastic group 0 and 2 has outliers \n# w/c ratio group 0 and 1 has outliers\n# water group 0 and 1 has outliers ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"\"\"\"\nanalysing variables at cluster level.\nstrength vs variable \nThe more horizontal the line is, the more weak the independent variable is in predicting the target variable\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"for i in data_c3.columns:\n    sns.lmplot(x=i,y=\"strength\",data=data_c3,hue=\"GROUP\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# 3 cluster analysis \n\"\"\"\n# strength vs cement \n# G0 (blue) and G1 ( orange) seems to have a positive relation where as the G2 ( green) is somewhat flat \n# cement seems to be good predictor for overall 3 clusters \n\n# strength vs slag \n# All 3 groups seeem flat lines, slag does not seems to be a good predictor for all 3 groups\n\n# strength vs Ash\n# G0(blue) seems to be in positive relation where as other 2 groups have flat lines.\n# ash is not a good predictor for all 3 clusters \n\n# strength vs water \n# G0(blue) showing a positive relation ship with strength where as other 2 as negative \n# water is only positive for 1 cluster, may not be good predictor for all clusters \n\n# strength vs superplastic \n# G0 and G1 ( blue and orange) shows positive relationship where as the G2( green) shows negative \n# 2 positive 1 negative , superplastic may not be a good predictor for all 3 clusters \n\n# strength vs coarseagg\n# G0( blue) is negative and G1(orange) is slight positive, G2( green) flat line \n# coarseagg not a good predictor for all 3 clusters \n\n# strength vs fineagg\n# G0(blue) negative relationship \n# G1(orange) and G2(green) are also flat lines\n# fine agg seems a week predictor for all 3 clusters \n\n# strength vs Age\n# all 3 clusters represents strong relationship with strength \n\n# strength vs w/c ration\n# all 3 clusters are negatively correlated with the ration,\n# seems like a strong predictor\n\n# strength vs c/f ration\n# all 3 clusters represents strong positive correlation \n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# silhouette score of above model \nfrom sklearn.metrics import silhouette_score\nscore_3 = silhouette_score(data_c3,model_c3.labels_,metric='euclidean')\nscore_3","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# K-means clustering with 4 clusters \ndata_c4 = data3.copy()\nmodel_c4 = KMeans(n_clusters=4, init=\"k-means++\")\nmodel_c4.fit(data_c4)\nprediction = model_c4.predict(data_c4)\ndata_c4['GROUP'] = prediction\ncentroids = model_c4.cluster_centers_\ncentroids_df_4 = pd.DataFrame(centroids,columns=list(data3.columns))\nprint(\"Cluster centroids\")\ncentroids_df_4","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data_c4.boxplot(by=\"GROUP\" ,figsize=[18,18]);\n\n# outliers can be observed in the different groups  \n# Age> G0 has outliers , in 3 clusters Age had outlier in group 1 \n# Ash >G2 and G3 has outliers , earlier it was G0 \n# C/f ratio had outliers in all groups but in this case G0 does not have any outliers \n# cement > G0 and G2 have outliers, previously cement had in G0 \n# coarseagg > except G3 all groups has outlier previously there were no outliers in any of the group \n# fineagg > earlier fine agg had outliers in all groups not in case of 4 clusters, no outliers\n# slag> earlier G0 had outliers now G2 and G3 has huge outliers \n# strength >  only one group has outlier i.e. G2 earlier it was G0 \n# superplastic> all 4 clusters have outliers \n# w/c ratio > only G3 has outliers earlier it was G0 and G1 \n# water > earlier G0 and G1 now, G0 and G3 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"for i in data_c4.columns:\n    sns.lmplot(x=i,y=\"strength\",data=data_c4,hue=\"GROUP\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# understanding the relationship of variables in 4 clusters \n\n# 4 cluster analysis \n\n# G0: Blue\n# G1: Orange\n# G2: green\n# G3: red\n\n# strength vs cement \n# G0 (blue) , G2 ( green), G3(red) seems to have a positive correlation\n# G1 ( orange) seems to be flat\n# cement seems to be good predictor for 3 clusters \n\n# strength vs slag \n# G0 ( blue) seems to be a differentiated group , \n# where as G2 and G3  are mostly similar \n# G1 is flat\n# slag seems to be only good predictor for G0 group , overall a weak predictor \n\n# strength vs Ash\n# 2 groups positive relation G0 and G2 \n# 2 groups negative relation G1 and G3\n# previously in 3 clusters ash was only in positive relation with 1 group and flat for other groups\n# ash is not a good predictor for all 4 clusters however represents positive relation with 1 or 2 groups. \n\n# strength vs water \n# G0 and G1 are flat lines\n# G2 is a positive relation \n# G3 is a negative relation \n# water alone seems not to be good predictor for all the clusters \n\n# strength vs superplastic \n# G0 seems only to be in a positive relation with lesser residual.\n# remaining 3 does not seems to be good predictors \n# overall superplastic seems to be aa weak predictor for the strength of the concrete\n\n# strength vs coarseagg\n# coarseagg seems not a good predictor for all 4 clusters \n\n# strength vs fineagg\n# fine agg seems a week predictor for all 4 clusters \n\n# strength vs Age\n# all 4 clusters represents strong relationship with strength\n# age is strong predictor of cement strength \n\n# strength vs w/c ration\n# all 4 clusters are negatively correlated with the ration,\n# seems like a strong predictor. \n\n# strength vs c/f ration\n# all 4 clusters seems to show positive.   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# silhoutte score for the clusters above \nfrom sklearn.metrics import silhouette_score\nscore_4 = silhouette_score(data_c4,model_c4.labels_,metric='euclidean')\nscore_4","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# 5 clusters , K-means clustering. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data_c5 = data3.copy()\nmodel_c5 = KMeans(n_clusters=5, init=\"k-means++\")\nmodel_c5.fit(data_c5)\nprediction = model_c5.predict(data_c5)\ndata_c5['GROUP'] = prediction\ncentroids = model_c5.cluster_centers_\ncentroids_df_5 = pd.DataFrame(centroids,columns=list(data3.columns))\nprint(\"Cluster centroids\")\ncentroids_df_5","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data_c5.boxplot(by=\"GROUP\" ,figsize=[18,18]);","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"for i in data_c5.columns:\n    sns.lmplot(x=i,y=\"strength\",data=data_c5,hue=\"GROUP\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"score_5 = silhouette_score(data_c5, model_c5.labels_,metric=\"euclidean\")\nscore_5","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data_c6 = data3.copy()\nmodel_c6 = KMeans(n_clusters=6, init=\"k-means++\")\nmodel_c6.fit(data_c6)\ndata_c6['GROUP'] = prediction\nscore_6 = silhouette_score(data_c6,model_c6.labels_,metric=\"euclidean\")\nscore_6","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### looking at the silhoutte score and above cluster analysis, most attributes seems to be a weak predictor.\n#### so far from the analysis 4 clusters look good but except cement we do not see any good predictor  "},{"metadata":{},"cell_type":"markdown","source":"# Model building || Deliverable 3 "},{"metadata":{"trusted":false},"cell_type":"code","source":"# Model building considering linear regression as starting point, basis on its performance, will try other model.\n# Next will try polynomial regression algorithm with different degree of freedom.\n\n#Linear Regression\n#SVR\n#Ridge Regression\n#Lasso Regression#=\n#Polynomial Regression\n#Decision Tree\n#Random Forest\n#Bagging\n#Ada Boost\n#Gradient Boost","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Model1: Linear Regression \n# building on the original data set \nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso\ndata_lr = data.apply(zscore)\nx = data_lr.drop('strength',axis=1)\ny = data_lr.strength\nx_train, x_test, y_train, y_test = train_test_split(x,y,random_state= 123, test_size=0.30)\nprint(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model_lr_1 = LinearRegression()\nmodel_lr_1.fit(x_train,y_train)\nprint(\"score on train set\", model_lr_1.score(x_train,y_train))\nprint(\"score on test set\", model_lr_1.score(x_test,y_test))\nprint(\"co-efficients\",model_lr_1.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#  model is underfitting / high bias but low variance\n# fitting the model on outliers treated data and added features data \ndata4=data4.apply(zscore) # scaling\nx = data4.drop('strength',axis=1)\ny = data4.strength\nx_train, x_test, y_train, y_test = train_test_split(x,y,random_state= 456, test_size=0.30)\nmodel_lr_2 = LinearRegression()\nmodel_lr_2.fit(x_train,y_train)\nprint(\"score on train set\", model_lr_2.score(x_train,y_train))\nprint(\"score on test set\", model_lr_2.score(x_test,y_test))\nprint(\"co-efficients\",model_lr_2.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# after removing outliers and additng features model score is increased \n# however we still have underfitting proble/ high bias and variance is also incresed \n# checking on the reduced dimensions \nmodel_lr_3 = LinearRegression()\nmodel_lr_3.fit(xpca_train,ypca_train)\nprint(\"score on train set\", model_lr_3.score(xpca_train,ypca_train))\nprint(\"score on test set\", model_lr_3.score(xpca_test,ypca_test))\nprint(\"co-efficients\",model_lr_3.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Underfitting and low variance for the reduced feature data set ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Model2 : Ridge Regression \n# on the raw data \ndata_rd = data.apply(zscore)\nx = data_rd.drop('strength',axis=1)\ny = data_rd.strength\nx_train, x_test, y_train, y_test = train_test_split(x,y,random_state= 123, test_size=0.30)\nprint(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model_rd_1 = Ridge(alpha=0.3)\nmodel_rd_1.fit(x_train,y_train)\nprint(\"score on train set\", model_rd_1.score(x_train,y_train))\nprint(\"score on test set\", model_rd_1.score(x_test,y_test))\nprint(\"co-efficients\",model_rd_1.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# fitting the model with outliers treated and features added \nx = data4.drop('strength',axis=1)\ny = data4.strength\nx_train, x_test, y_train, y_test = train_test_split(x,y,random_state= 456, test_size=0.30)\nmodel_rd_2 = Ridge(alpha=10)\nmodel_rd_2.fit(x_train,y_train)\nprint(\"score on train set\", model_rd_2.score(x_train,y_train))\nprint(\"score on test set\", model_rd_2.score(x_test,y_test))\nprint(\"co-efficients\",model_rd_2.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model_rd_3 = Ridge(alpha=0.5)\nmodel_rd_3.fit(xpca_train,ypca_train)\nprint(\"score on train set\", model_rd_3.score(xpca_train,ypca_train))\nprint(\"score on test set\", model_rd_3.score(xpca_test,ypca_test))\nprint(\"co-efficients\",model_rd_3.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# scores are similar for linear and ridge regression at alpha in the range 1 to 100\n# Model3 : Lasso Regularization \n# on the raw data \ndata_la = data.apply(zscore)\nx = data_la.drop('strength',axis=1)\ny = data_la.strength\nx_train, x_test, y_train, y_test = train_test_split(x,y,random_state= 123, test_size=0.30)\nmodel_la_1 = Lasso(alpha=0.001)\nmodel_la_1.fit(x_train,y_train)\nprint(\"score on train set\", model_la_1.score(x_train,y_train))\nprint(\"score on test set\", model_la_1.score(x_test,y_test))\nprint(\"co-efficients\",model_la_1.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# only 3 important features, Cement Age and coarseagg\n# fitting the model with outliers treated and features added \nx = data4.drop('strength',axis=1)\ny = data4.strength\nx_train, x_test, y_train, y_test = train_test_split(x,y,random_state= 456, test_size=0.30)\nmodel_la_2 = Lasso(alpha=0.01)\nmodel_la_2.fit(x_train,y_train)\nprint(\"score on train set\", model_la_2.score(x_train,y_train))\nprint(\"score on test set\", model_la_2.score(x_test,y_test))\nprint(\"co-efficients\",model_la_2.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# important features are cement, slag, water , superplastic, age, water , superplastic, and 2 new features , alpha = 0.1\n# important features, all alpha = 0.01\n# Model accuracy increased but still the  model is underfitting / high bias, high variance \n# testing the model on the reduced features / pCA data \n\nmodel_la_3 = Ridge(alpha=0.01)\nmodel_la_3.fit(xpca_train,ypca_train)\nprint(\"score on train set\", model_la_3.score(xpca_train,ypca_train))\nprint(\"score on test set\", model_la_3.score(xpca_test,ypca_test))\nprint(\"co-efficients\",model_la_3.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Model4 : Polynomial regression \nfrom sklearn.preprocessing import PolynomialFeatures\n\n# fitting on the original data \n\ndata_py = data.apply(zscore)\nx = data_py.drop('strength',axis=1)\ny = data_py.strength\nx_train, x_test, y_train_poly, y_test_poly = train_test_split(x,y,random_state= 123, test_size=0.30)\npoly = PolynomialFeatures(degree=2,interaction_only=True)\nx_train_poly = poly.fit_transform(x_train) \nx_test_poly = poly.fit_transform(x_test)\nmodel_py_1 = LinearRegression()\nmodel_py_1.fit(x_train_poly,y_train_poly)\nmodel_py_1_scoretrain = model_py_1.score(x_train_poly,y_train_poly)\nmodel_py_1_scoretest =  model_py_1.score(x_test_poly,y_test_poly)\nprint(\"score on train set\",model_py_1_scoretrain )\nprint(\"score on test set\", model_py_1_scoretest)\nprint(\"co-efficients\",model_py_1.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# model is underfitting however very lias variance in the model.\n# 37 features\n\n# preparing on the outliers treated and added features data \n\nx = data4.drop('strength',axis=1)\ny = data4.strength\nx_train, x_test, y_train, y_test = train_test_split(x,y,random_state= 456, test_size=0.30)\npoly = PolynomialFeatures(degree=2,interaction_only=True)\nx_train_poly = poly.fit_transform(x_train) \nx_test_poly = poly.fit_transform(x_test)\nmodel_py_2 = LinearRegression()\nmodel_py_2.fit(x_train_poly,y_train)\nmodel_py_2_scoretrain = model_py_2.score(x_train_poly,y_train)\nmodel_py_2_scoretest = model_py_2.score(x_test_poly,y_test)\nprint(\"score on train set\", model_py_2_scoretrain)\nprint(\"score on test set\", model_py_2_scoretest)\nprint(\"co-efficients\",model_py_2.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# better fiiting but varinace is increased ,\n# 56 features \n# fitting on the reduced feature data set \nxpca_train_poly = poly.fit_transform(xpca_train)\nxpca_test_poly = poly.fit_transform(xpca_test)\nmodel_py_3 = LinearRegression()\nmodel_py_3.fit(xpca_train_poly,ypca_train)\nmodel_py_3_scoretrain =  model_py_3.score(xpca_train_poly,ypca_train)\nmodel_py_3_scoretest = model_py_3.score(xpca_test_poly,ypca_test)\nprint(\"score on train set\",model_py_3_scoretrain)\nprint(\"score on test set\", model_py_3_scoretest)\nprint(\"co-efficients\",model_py_3.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# no better results on the reduced features data set \n\n# Model5 : SVR support vector regressor \n# applying on the original data \nfrom sklearn.svm import SVR\ndata_svr = data.apply(zscore)\nx = data_svr.drop('strength',axis=1)\ny = data_svr.strength\nx_train, x_test, y_train, y_test = train_test_split(x,y,random_state= 123, test_size=0.30)\nmodel_svr_1 = SVR()\nmodel_svr_1.fit(x_train,y_train)\nprint(\"score on train set\", model_svr_1.score(x_train,y_train))\nprint(\"score on test set\", model_svr_1.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# so far best score among all the models, data is fitting better but still underfit , high variance \n# checking on the outlier treated data \nx = data4.drop('strength',axis=1)\ny = data4.strength\nx_train, x_test, y_train, y_test = train_test_split(x,y,random_state= 456, test_size=0.30)\nmodel_svr_2 = SVR()\nmodel_svr_2.fit(x_train,y_train)\nprint(\"score on train set\", model_svr_2.score(x_train,y_train))\nprint(\"score on test set\", model_svr_2.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# better results , data seems to fit better than as compared to original data, however there is high variance \n# high variance resvrtes to more complexity, however we have just built a basic SVM regressor \n\n# testing on the reduced feature data set \nmodel_svr_3 = SVR()\nmodel_svr_3.fit(xpca_train,ypca_train)\nprint(\"score on train set\", model_svr_3.score(xpca_train,ypca_train))\nprint(\"score on test set\", model_svr_3.score(xpca_test,ypca_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# lesser variance as compared to previous model \n# Model6 : Randomforest regressor \n\nfrom sklearn.ensemble import RandomForestRegressor\ndata_rf = data.apply(zscore)\nx = data_rf.drop('strength',axis=1)\ny = data_rf.strength\nx_train, x_test, y_train, y_test = train_test_split(x,y,random_state= 123, test_size=0.30)\nmodel_rf_1 = RandomForestRegressor(random_state=25,n_estimators=50)\nmodel_rf_1.fit(x_train,y_train)\nprint(\"score on train set\", model_rf_1.score(x_train,y_train))\nprint(\"score on test set\", model_rf_1.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# low bais high variance zone.\n# fitting on the created data set with features and removed outliers\nx = data4.drop('strength',axis=1)\ny = data4.strength\nx_train, x_test, y_train, y_test = train_test_split(x,y,random_state= 456, test_size=0.30)\nmodel_rf_2 = RandomForestRegressor(random_state=12,n_estimators=50)\nmodel_rf_2.fit(x_train,y_train)\nprint(\"score on train set\", model_rf_2.score(x_train,y_train))\nprint(\"score on test set\", model_rf_2.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# no change in performance as compared to previoys \n# testing on the reduced feature data set \n\nmodel_rf_3 = RandomForestRegressor(n_estimators=50,random_state=78)\nmodel_rf_3.fit(xpca_train,ypca_train)\nprint(\"score on train set\", model_rf_3.score(xpca_train,ypca_train))\nprint(\"score on test set\", model_rf_3.score(xpca_test,ypca_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# again low bais but high variance in the model \n# Model 7 : Bagging Regressor \n\n# on Raw data \nfrom sklearn.ensemble import BaggingRegressor\ndata_bgr = data.apply(zscore)\nx = data_bgr.drop('strength',axis=1)\ny = data_bgr.strength\nx_train, x_test, y_train, y_test = train_test_split(x,y,random_state= 123, test_size=0.30)\nmodel_bgr_1 = BaggingRegressor(random_state=95,n_estimators=100)\nmodel_bgr_1.fit(x_train,y_train)\nprint(\"score on train set\", model_bgr_1.score(x_train,y_train))\nprint(\"score on test set\", model_bgr_1.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#low bais , high variance \n# fitiing on featured data \ndata4 = data4.apply(zscore)\nx = data4.drop('strength',axis=1)\ny = data4.strength\nx_train, x_test, y_train, y_test = train_test_split(x,y,random_state= 748, test_size=0.30)\nmodel_bgr_2 = BaggingRegressor(random_state=4,n_estimators=50)\nmodel_bgr_2.fit(x_train,y_train)\nprint(\"score on train set\", model_bgr_2.score(x_train,y_train))\nprint(\"score on test set\", model_bgr_2.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# outlier treatment have no random forest regressor and bagging regressor \n# on the reduced feature data set \nmodel_bgr_3 = BaggingRegressor(n_estimators=100,random_state=75)\nmodel_bgr_3.fit(xpca_train,ypca_train)\nprint(\"score on train set\", model_bgr_3.score(xpca_train,ypca_train))\nprint(\"score on test set\", model_bgr_3.score(xpca_test,ypca_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# reduced feature data has very high variance \n# Model 8 : Adaboost Regressor.\n# on the raw data, \nfrom sklearn.ensemble import AdaBoostRegressor\ndata_ada = data.apply(zscore)\nx = data_ada.drop('strength',axis=1)\ny = data_ada.strength\nx_train, x_test, y_train, y_test = train_test_split(x,y,random_state= 123, test_size=0.30)\nmodel_ada_1 = AdaBoostRegressor(random_state=96,n_estimators=100)\nmodel_ada_1.fit(x_train,y_train)\nprint(\"score on train set\", model_ada_1.score(x_train,y_train))\nprint(\"score on test set\", model_ada_1.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# high bais but low variance \n# checking on the featured data \ndata4 = data4.apply(zscore)\nx = data4.drop('strength',axis=1)\ny = data4.strength\nx_train, x_test, y_train, y_test = train_test_split(x,y,random_state= 748, test_size=0.30)\nmodel_ada_2 = AdaBoostRegressor(random_state=35,n_estimators=100)\nmodel_ada_2.fit(x_train,y_train)\nprint(\"score on train set\", model_ada_2.score(x_train,y_train))\nprint(\"score on test set\", model_ada_2.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# high bias , variance reduced as compared to previous model \n# on the reduced feature data set \n\nmodel_ada_3 = AdaBoostRegressor(n_estimators=50,random_state=47)\nmodel_ada_3.fit(xpca_train,ypca_train)\nprint(\"score on train set\", model_ada_3.score(xpca_train,ypca_train))\nprint(\"score on test set\", model_ada_3.score(xpca_test,ypca_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# no better performance on reduced featured data set \n# Model 9 : Gradient Boosting Regressor \n\n# on the raw data \nfrom sklearn.ensemble import GradientBoostingRegressor\ndata_gbm = data.apply(zscore)\nx = data_gbm.drop('strength',axis=1)\ny = data_gbm.strength\nx_train, x_test, y_train, y_test = train_test_split(x,y,random_state= 123, test_size=0.30)\nmodel_gbm_1 =GradientBoostingRegressor(random_state=75,n_estimators=50)\nmodel_gbm_1.fit(x_train,y_train)\nprint(\"score on train set\", model_gbm_1.score(x_train,y_train))\nprint(\"score on test set\", model_gbm_1.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# best scores so far, low bias and a low variance and a better score on the test set \n\n# checking on the added feature data set \ndata4 = data4.apply(zscore)\nx = data4.drop('strength',axis=1)\ny = data4.strength\nx_train, x_test, y_train, y_test = train_test_split(x,y,random_state= 748, test_size=0.30)\nmodel_gbm_2 = GradientBoostingRegressor(random_state=53,n_estimators=100)\nmodel_gbm_2.fit(x_train,y_train)\nprint(\"score on train set\", model_gbm_2.score(x_train,y_train))\nprint(\"score on test set\", model_gbm_2.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# we can tune this model further . \n\n# checking on the reduced feature data set.\nmodel_gbm_3 = GradientBoostingRegressor(n_estimators=100,random_state=147)\nmodel_gbm_3.fit(xpca_train,ypca_train)\nprint(\"score on train set\", model_gbm_3.score(xpca_train,ypca_train))\nprint(\"score on test set\", model_gbm_3.score(xpca_test,ypca_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# no better performance on the reduced feature data set \n# comparing the performance of all the built models and than further evaluating to hypertune them \nscaled_data = data.apply(zscore)\nx1= scaled_data.drop(\"strength\",axis=1)\ny1= scaled_data.strength\nx1_train,x1_test,y1_train,y1_test = train_test_split(x1,y1,random_state=1)\ndata4= data4.apply(zscore)\nx2= data4.drop(\"strength\",axis=1)\ny2= data4.strength\nx2_train,x2_test,y2_train,y2_test = train_test_split(x2,y2,random_state=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"models = [\"Linear Regression\",\"Ridge Regression\",\"Lasso Regression\",\"Polynomial Regression\",\"SVR\",\"Randomfoest\",\n         \"Bagging Regressor\",\"adaboost Regressor\",\"Gradientboost regressor\"]\na_train = {\"Train score rawdata\": [model_lr_1.score(x1_train,y1_train),model_rd_1.score(x1_train,y1_train), \n                                            model_la_1.score(x1_train,y1_train), model_py_1_scoretrain,\n                                           model_svr_1.score(x1_train,y1_train), model_rf_1.score(x1_train,y1_train),\n                                           model_bgr_1.score(x1_train,y1_train), model_ada_1.score(x1_train,y1_train),\n                                           model_gbm_1.score(x1_train,y1_train)],\n            \"Test score rawdata\":[model_lr_1.score(x1_test,y1_test),model_rd_1.score(x1_test,y1_test),\n                                         model_la_1.score(x1_test,y1_test), model_py_1_scoretest,\n                                         model_svr_1.score(x1_test,y1_test), model_rf_1.score(x1_test,y1_test),\n                                         model_bgr_1.score(x1_test,y1_test), model_ada_1.score(x1_test,y1_test),\n                                         model_gbm_1.score(x1_test,y1_test)],\n            \"Train score featuredata\":[model_lr_2.score(x2_train,y2_train),model_rd_2.score(x2_train,y2_train),\n                                              model_la_2.score(x2_train,y2_train), model_py_2_scoretrain,\n                                              model_svr_2.score(x2_train,y2_train), model_rf_2.score(x2_train,y2_train),\n                                              model_bgr_2.score(x2_train,y2_train), model_ada_2.score(x2_train,y2_train),\n                                              model_gbm_2.score(x2_train,y2_train)],\n            \"Test score featuredata\":[model_lr_2.score(x2_test,y2_test),model_rd_2.score(x2_test,y2_test),\n                                              model_la_2.score(x2_test,y2_test), model_py_2_scoretest,\n                                              model_svr_2.score(x2_test,y2_test), model_rf_2.score(x2_test,y2_test),\n                                              model_bgr_2.score(x2_test,y2_test), model_ada_2.score(x2_test,y2_test),\n                                              model_gbm_2.score(x2_test,y2_test)],\n            \"Train score PCA data\":[model_lr_3.score(xpca_train,ypca_train),model_rd_3.score(xpca_train,ypca_train),\n                                     model_la_3.score(xpca_train,ypca_train), model_py_3_scoretrain,\n                                     model_svr_3.score(xpca_train,ypca_train), model_rf_3.score(xpca_train,ypca_train),\n                                     model_bgr_3.score(xpca_train,ypca_train),model_ada_3.score(xpca_train,ypca_train),\n                                     model_gbm_3.score(xpca_train,ypca_train)],\n            'Test score PAC data':[model_lr_3.score(xpca_test,ypca_test),model_rd_3.score(xpca_test,ypca_test),\n                                    model_la_3.score(xpca_test,ypca_test),model_py_3_scoretest,\n                                    model_svr_3.score(xpca_test,ypca_test),model_rf_3.score(xpca_test,ypca_test),\n                                    model_bgr_3.score(xpca_test,ypca_test), model_ada_3.score(xpca_test,ypca_test),\n                                    model_gbm_3.score(xpca_test,ypca_test)]}\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"compare_df=pd.DataFrame(a_train,index=models)\ncompare_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# so far we observe the GBM as the best performing model on the outlier treated data with added features ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Hypertuning || Deliverable 4"},{"metadata":{"trusted":false},"cell_type":"code","source":"# using Gridsearch CV to find the best parameter for GBR\nfrom sklearn.model_selection import GridSearchCV\nestimator=GradientBoostingRegressor()\ngrid ={'n_estimators':[100,200,300,400,500,600],\n       'learning_rate':[.001,0.01,.1],\n       'max_depth':[1,2,3,4,5],\n        'subsample':[.5,.75,1],\n       'random_state':[1]}\nsearch=GridSearchCV(estimator=estimator,param_grid=grid,scoring='neg_mean_squared_error',n_jobs=1,cv=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# best parameter for GBR on raw data \nsearch.fit(x1_train,y1_train)\nsearch.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# building the GBM model with the above parameters \ngbm_1 = GradientBoostingRegressor(learning_rate=0.1,max_depth=5,n_estimators=400,random_state=1,subsample=1)\ngbm_1.fit(x1_train,y1_train)\nprint(\"score on the train set\", gbm_1.score(x1_train,y1_train))\nprint(\"score on the test set\",gbm_1.score(x1_test,y1_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# score comparison after model tuning\n# score is increased from 91 on train to 99 on train, \n# score is increased from 87 on test to 92 on test ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# best parameter for GBM on outliers treated and feature data \nsearch.fit(x2_train,y2_train)\nsearch.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"gbm_2 = GradientBoostingRegressor(learning_rate=0.1,max_depth=5,n_estimators=200,random_state=1,subsample=1)\ngbm_2.fit(x2_train,y2_train)\nprint(\"score on the train set\", gbm_2.score(x2_train,y2_train))\nprint(\"score on the test set\",gbm_2.score(x2_test,y2_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# score comparison after model tuning\n# score is increased from 94 on train to 99 on train, \n# score is increased from 90 on test to 92 on test ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# model performance range at 95% confidemce \n# Leveraging cross validation to estimate the performance on the unseen data \n\nfrom sklearn.model_selection import cross_val_score\ncv_scores = cross_val_score(gbm_2,x2,y2,cv=10)\ncv_scores_mean = cv_scores.mean()\ncv_scores_std = cv_scores.std()\nprint(\"cross validation scores\", cv_scores)\nprint(\" Accuracy : %.3f%%(%.3f%%)\"% (cv_scores_mean*100, cv_scores_std*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The accuracy of the Gradient Boost model \n\n#### ---------------------------------------------------------------------------------------------------------------------------------\n#### in the production environment is expected to be 92.84% (+-) standard deviation (2.805%)\n#### For 95% confidence level  the model accuracy in the production environment is\n#### expected to be in the range of 92.84% (+-) 2 * standard deviation i.e. [87.23, 98.45] \n#### ---------------------------------------------------------------------------------------------------------------------------------"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}