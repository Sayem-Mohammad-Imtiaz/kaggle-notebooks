{"cells":[{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"conda install -c conda-forge librosa","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"import warnings                        # To ignore any warnings\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline\n%pylab inline\nimport os\nimport pandas as pd\nimport librosa\nimport librosa.display\nimport glob \nimport matplotlib.pyplot as plt\n%config InlineBackend.figure_format = 'retina'\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import tensorflow as tf; print(\"Tensorflow version.... \",tf.__version__)\nimport keras ; print(\"Keras version... \", keras.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"INPUT_DIR = \"/kaggle/input/heartbeat-sounds\"\n\nSAMPLE_RATE = 16000\n\nMAX_SOUND_CLIP_DURATION = 12","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pwd\n!ls -all ../input","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"set_a = pd.read_csv(INPUT_DIR+'/set_a.csv')\nset_a.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"set_a_timing = pd.read_csv(INPUT_DIR+'/set_a_timing.csv')\nset_a_timing.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"set_b = pd.read_csv(INPUT_DIR+'/set_b.csv')\nset_b.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"frames = [set_a, set_b]\ntrain_ab = pd.concat(frames)\ntrain_ab","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nb_classes = train_ab.label.unique()\n\nprint(\"number of training examples : \", train_ab.shape[0],\" Number of classes : \",len(nb_classes))\nprint(nb_classes)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*nan labeled examples are \"unlabeled\" test files*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ab[train_ab.label == 'nan'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ab.label.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ab.groupby(['label','dataset']).count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Visualize data distribution by class","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"category_group = train_ab.groupby(['label','dataset']).count()\nplot = category_group.unstack().reindex(category_group.unstack().sum(axis=1).sort_values().index)\\\n        .plot(kind='bar', stacked=False, title=\"Number of Audio Samples per Category\", figsize=(16,5))\n\nplot.set_xlabel('class')\nplot.set_ylabel('samples count')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"minimum samples per class :\", min(train_ab.label.value_counts()))\nprint(\"maximum samples per class :\",max(train_ab.label.value_counts()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# *Lets visit each class of labels one by one*","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**a) NORMAL**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"normal_file = INPUT_DIR+'/set_a/normal__201105021654.wav'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import IPython.display as ipd\nipd.Audio(normal_file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.io import wavfile\nrate, signal = wavfile.read(normal_file)\nprint(\"Sampling Rate. \",rate)\nprint(\"Total samples  \",signal.shape[0])\nprint(\"Duration in seconds. \",signal.shape[0]/rate)\nprint(signal)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,5))\nplt.plot(signal, '-',)\nplt.title('Normal')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using **LIBROSA**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"signal1, rate1 = librosa.load(normal_file, duration=5)   #default sampling rate is 22 HZ\ndur=librosa.get_duration(signal1)\nprint(\"Duration in seconds. \",librosa.get_duration(signal1))\nprint(signal1.shape, rate1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,3))\nlibrosa.display.waveplot(signal1)\nplt.title(\"Normal\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**b) Murmur**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"murmur_file = INPUT_DIR+'/set_a/murmur__201108222236.wav'\nipd.Audio(murmur_file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"signal2, rate2 = librosa.load(murmur_file, duration=5)   #default sampling rate is 22 HZ\ndur=librosa.get_duration(signal2)\nprint(\"Duration in seconds. \",librosa.get_duration(signal2))\nprint(signal2.shape, rate2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,3))\nlibrosa.display.waveplot(signal2)\nplt.title(\"murmur\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**c) Extrasystole**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"extrasystole_file = INPUT_DIR+'/set_b/extrastole__198_1308141739338_B1.wav'\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ipd.Audio(extrasystole_file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"signal3, rate3 = librosa.load(extrasystole_file, duration=5)   #default sampling rate is 22 HZ\ndur=librosa.get_duration(signal3)\nprint(\"Duration in seconds. \",librosa.get_duration(signal3))\nprint(signal3.shape, rate3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,5))\nlibrosa.display.waveplot(signal3)\nplt.title('Extrasystole')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**d) Artifact**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"artifact_file = INPUT_DIR+'/set_a/artifact__201012172012.wav'\nipd.Audio(artifact_file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"signal4, rate4 = librosa.load(artifact_file, duration=5)   #default sampling rate is 22 HZ\ndur=librosa.get_duration(signal4)\nprint(\"Duration in seconds. \",librosa.get_duration(signal4))\nprint(signal4.shape, rate4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,3))\nlibrosa.display.waveplot(signal4)\nplt.title(\"Artifact\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**e) Extra Heart Sound**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"extrahls_file = INPUT_DIR+'/set_a/extrahls__201101070953.wav'\nipd.Audio(extrahls_file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"signal5, rate5 = librosa.load(extrahls_file, duration=5)\nprint(\"Duration \",librosa.get_duration(signal5))\nprint(signal5.shape, rate5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,3))\nlibrosa.display.waveplot(signal5, sr = rate5)\nplt.title(\"Extra Heart Sound\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"normal_file\nsignal, rate = librosa.load(normal_file)\nmfcc = librosa.feature.mfcc(y=signal, sr = rate)\nprint(mfcc.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"S = librosa.feature.melspectrogram(y=signal, sr=rate, n_mels=128,fmax=8000)\nlog_S=librosa.feature.mfcc(S=librosa.power_to_db(S))\nprint (log_S)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mfcc = librosa.feature.mfcc(y = signal, sr = rate, n_mfcc = 40)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(mfcc.reshape([-1,1]).shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"40*345","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualizing MFCC series \n\nmel frequency cepstral coefficients (mfcc) which is by far the best way to numerically represent audio signal for ML related tasks","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize(12,3))\nlibrosa.display.specshow(mfcc, x_axis='time')\nplt.colorbar()\nplt.title(\"MFCC\")\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m_slaney = librosa.feature.mfcc(y=signal, sr=rate, dct_type=2)\nplt.figure(figsize=(12,3))\n\nm_htk = librosa.feature.mfcc(y=signal, sr=rate, dct_type=3)\nplt.subplot(3,1,1)\nlibrosa.display.specshow(m_slaney, x_axis='time')\nplt.title(\"dct_type = 2\")\nplt.colorbar()\nplt.subplot(3,1,3)\nlibrosa.display.specshow(m_htk, x_axis='time')\nplt.title(\"dct_type = 3\")\nplt.colorbar()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**LOADING DATA**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ab","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of training examples : \",train_ab.shape[0], \" Number of classes : \", train_ab.label.nunique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def audio_norm(data):\n    max_data = max(data)\n    min_data = min(data)\n    data = (data-min_data)/(max_data-min_data+0.0001)\n    return data-0.5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_file_data (folder_name,file_names, duration=12, sr=16000):\n    input_length=sr*duration\n    # function to load files and extract features\n    # file_names = glob.glob(os.path.join(folder, '*.wav'))\n    data = []\n    for file_name in file_names:\n        try:\n            sound_file=folder_name+file_name\n            print (\"load file \",sound_file)\n            # use kaiser_fast technique for faster extraction\n            X, sr = librosa.load( sound_file, sr=sr, duration=duration,res_type='kaiser_fast') \n            dur = librosa.get_duration(y=X, sr=sr)\n            # pad audio file same duration\n            if (round(dur) < duration):\n                print (\"fixing audio lenght :\", file_name)\n                y = librosa.util.fix_length(X, input_length)                \n            #normalized raw audio \n            X = audio_norm(X)            \n            # extract normalized mfcc feature from data\n            mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sr, n_mfcc=40).T,axis=0)             \n        except Exception as e:\n            print(\"Error encountered while parsing file: \", file)        \n        feature = np.array(mfccs).reshape([-1,1])\n        data.append(feature)\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\n\nCLASSES = ['artifact','murmur','normal']\nNB_CLASSES = len(CLASSES)\n\nlabel_to_int = {k:v for v,k in enumerate(CLASSES)}\nprint(label_to_int)\nprint(\" \")\n\nint_to_label = {v:k for v,k in enumerate(CLASSES)}\nprint(int_to_label)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Loading dataset a","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import os, fnmatch\n\nA_folder = INPUT_DIR+'/set_a/'\n\nA_artifact_files = fnmatch.filter(os.listdir(INPUT_DIR+'/set_a/'),'artifact*.wav')\nA_artifact_sounds = load_file_data(folder_name=A_folder, file_names=A_artifact_files, duration=MAX_SOUND_CLIP_DURATION)\nA_artifact_labels = [0 for items in A_artifact_files]\n\nA_normal_files = fnmatch.filter(os.listdir(INPUT_DIR+'/set_a/'), 'normal*.wav')\nA_normal_sounds = load_file_data(folder_name = A_folder, file_names = A_normal_files, duration=MAX_SOUND_CLIP_DURATION)\nA_normal_labels = [2 for items in A_normal_files]\n\nA_extrahls_files = fnmatch.filter(os.listdir(INPUT_DIR+'/set_a/'), 'extrahls*.wav')\nA_extrahls_sounds = load_file_data(folder_name=A_folder, file_names=A_extrahls_files, duration=MAX_SOUND_CLIP_DURATION)\nA_extrahls_labels = [1 for items in A_extrahls_files]\n\nA_murmur_files= fnmatch.filter(os.listdir(INPUT_DIR+'/set_a/'), 'murmur*.wav')\nA_murmur_sounds = load_file_data(folder_name=A_folder, file_names=A_murmur_files, duration=MAX_SOUND_CLIP_DURATION)\nA_murmur_labels = [1 for items in A_murmur_files]\n\nA_unlabelledtest_files = fnmatch.filter(os.listdir(INPUT_DIR+'/set_a/'), 'Aunlabelledtest*.wav')\nA_unlabelledtest_sounds = load_file_data(folder_name=A_folder, file_names=A_unlabelledtest_files, duration=MAX_SOUND_CLIP_DURATION)\nA_unlabelledtest_labels = [-1 for items in A_unlabelledtest_files]\n\nprint(\"loaded dataset-a\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Loading Dataset-b","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nB_folder = INPUT_DIR+'/set_b/'\n\n\nB_normal_files = fnmatch.filter(os.listdir(INPUT_DIR+'/set_b/'), 'normal*.wav')\nB_normal_sounds = load_file_data(folder_name = B_folder, file_names = B_normal_files, duration=MAX_SOUND_CLIP_DURATION)\nB_normal_labels = [2 for items in B_normal_files]\n\nB_extrastole_files = fnmatch.filter(os.listdir(INPUT_DIR+'/set_b/'), 'extrastole*.wav')\nB_extrastole_sounds = load_file_data(folder_name=B_folder, file_names=B_extrastole_files, duration=MAX_SOUND_CLIP_DURATION)\nB_extrastole_labels = [1 for items in B_extrastole_files]\n\nB_murmur_files= fnmatch.filter(os.listdir(INPUT_DIR+'/set_b/'), 'murmur*.wav')\nB_murmur_sounds = load_file_data(folder_name=B_folder, file_names=B_murmur_files, duration=MAX_SOUND_CLIP_DURATION)\nB_murmur_labels = [1 for items in B_murmur_files]\n\nB_unlabelledtest_files = fnmatch.filter(os.listdir(INPUT_DIR+'/set_b/'), 'Bunlabelledtest*.wav')\nB_unlabelledtest_sounds = load_file_data(folder_name=B_folder, file_names= B_unlabelledtest_files, duration=MAX_SOUND_CLIP_DURATION)\nB_unlabelledtest_labels = [-1 for items in B_unlabelledtest_files]\n\nprint(\"loaded dataset-b\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Combining set-a   set-b","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x_data = np.concatenate((A_artifact_sounds, A_normal_sounds, A_extrahls_sounds, A_murmur_sounds,\n                        B_normal_sounds,B_murmur_sounds, B_extrastole_sounds))\ny_data = np.concatenate((A_artifact_labels, A_normal_labels, A_extrahls_labels, A_murmur_labels,\n                        B_normal_labels,B_murmur_labels, B_extrastole_labels))\n\nx_unlabelled = np.concatenate((A_unlabelledtest_sounds, B_unlabelledtest_sounds))\ny_unlabelled = np.concatenate((A_unlabelledtest_labels, B_unlabelledtest_labels))\n\nprint(\"Combined data size : \",len(x_data), \" and unlabelled \",len(x_unlabelled))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seed = 1000\n\nx_train, x_val, y_train, y_val = train_test_split(x_data, y_data, train_size=0.8,random_state=seed, shuffle=True)\n# x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, train_size=0.9, random_state = seed, shuffle=True)\n\ny_train = np.array(keras.utils.to_categorical(y_train, len(CLASSES)))\n# y_test = np.array(keras.utils.to_categorical(y_test, len(CLASSES)))\ny_val = np.array(keras.utils.to_categorical(y_val, len(CLASSES)))\ny_unlabelled = np.array(keras.utils.to_categorical(y_unlabelled, len(CLASSES)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_unlabelled.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\"label shape: \", y_data.shape)\nprint (\"data size of the array: : %s\" % y_data.size)\nprint (\"length of one array element in bytes: \", y_data.itemsize)\nprint (\"total bytes consumed by the elements of the array: \", y_data.nbytes)\nprint (y_data[1])\nprint (\"\")\nprint (\"audio data shape: \", x_data.shape)\nprint (\"data size of the array: : %s\" % x_data.size)\nprint (\"length of one array element in bytes: \", x_data.itemsize)\nprint (\"total bytes consumed by the elements of the array: \", x_data.nbytes)\n#print (x_data[1])\nprint (\"\")\nprint (\"training data shape: \", x_train.shape)\nprint (\"training label shape: \", y_train.shape)\nprint (\"\")\nprint (\"validation data shape: \", x_val.shape)\nprint (\"validation label shape: \", y_val.shape)\n# print (\"\")\n# print (\"test data shape: \", x_test.shape)\n# print (\"test label shape: \", y_test.shape)\nprint(\"\")\nprint (\"unlabelled data shape: \", x_unlabelled.shape)\nprint (\"unlabelled label shape: \", y_unlabelled.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**BUILDING MODEL**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install livelossplot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten, LSTM\nfrom keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint,TensorBoard,ProgbarLogger\nfrom keras.utils import np_utils\nfrom sklearn import metrics \nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nfrom sklearn.preprocessing import LabelEncoder\nimport itertools\nfrom keras.layers import TimeDistributed, SpatialDropout1D, Bidirectional\n\nfrom livelossplot import PlotLossesKeras","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Bidirectional(LSTM(units=64, dropout=0.2, return_sequences=True), input_shape=(40,1)))\nmodel.add(Bidirectional(LSTM(units=32, dropout=0.2, return_sequences=False)))\nmodel.add(Dense(len(CLASSES), activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='Adam', \n             metrics=['acc'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_patience = 12\nmax_epochs = 100\nmax_batch = 32\n\nearly_stopping = EarlyStopping(monitor='val_accuracy', patience = max_patience, verbose=0, mode='max', restore_best_weights=False)\n\ncallbacks=[ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n                              patience=5, min_lr=0.00001),\n          early_stopping,\n         PlotLossesKeras()]\n\nprint(\"training started..\")\nhistory = model.fit(x_train, y_train,\n                   batch_size=max_batch,\n                   epochs=max_epochs,\n                   verbose=1,\n                   validation_data=(x_val, y_val),\n                   callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model Evaluation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"score = model.evaluate(x_train, y_train, verbose=0) \nprint (\"model train data score       : \",round(score[1]*100) , \"%\")\n\n# score = model.evaluate(x_test, y_test, verbose=0) \n# print (\"model test{split} data score : \",round(score[1]*100) , \"%\")\n\nscore = model.evaluate(x_val, y_val, verbose=0) \nprint (\"model validation data score  : \", round(score[1]*100), \"%\")\n\nscore = model.evaluate(x_unlabelled, y_unlabelled, verbose=0) \nprint (\"model unlabeled data score   : \", round(score[1]*100), \"%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}