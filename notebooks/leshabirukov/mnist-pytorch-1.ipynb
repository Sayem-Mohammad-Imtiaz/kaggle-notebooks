{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-25T15:03:03.11393Z","iopub.execute_input":"2021-07-25T15:03:03.114395Z","iopub.status.idle":"2021-07-25T15:03:03.122966Z","shell.execute_reply.started":"2021-07-25T15:03:03.114362Z","shell.execute_reply":"2021-07-25T15:03:03.121829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Basic Imports","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nimport matplotlib.pyplot as plt\nfrom collections import OrderedDict","metadata":{"execution":{"iopub.status.busy":"2021-07-25T15:03:03.124491Z","iopub.execute_input":"2021-07-25T15:03:03.124779Z","iopub.status.idle":"2021-07-25T15:03:03.136688Z","shell.execute_reply.started":"2021-07-25T15:03:03.124752Z","shell.execute_reply":"2021-07-25T15:03:03.135891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset class\nFrom https://www.kaggle.com/pinocookie/pytorch-dataset-and-dataloader\n\nload image as ndarray type (Height * Width * Channels)\nbe carefull for converting dtype to np.uint8 [Unsigned integer (0 to 255)]\nin this example, i don't use ToTensor() method of torchvision.transforms\nso you can convert numpy ndarray shape to tensor in PyTorch (H, W, C) --> (C, H, W)","metadata":{}},{"cell_type":"code","source":"class DatasetMNIST(torch.utils.data.Dataset):\n    \n    def __init__(self, file_path, transform=None):\n        self.data = pd.read_csv(file_path)\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        image = self.data.iloc[index, 1:].values.astype(np.uint8).reshape((28, 28, 1))\n        label = self.data.iloc[index, 0]\n        \n        if self.transform is not None:\n            #print(\"---\")\n            image = self.transform(image)\n            \n        return image, label","metadata":{"execution":{"iopub.status.busy":"2021-07-25T15:03:03.138238Z","iopub.execute_input":"2021-07-25T15:03:03.138547Z","iopub.status.idle":"2021-07-25T15:03:03.148207Z","shell.execute_reply.started":"2021-07-25T15:03:03.13852Z","shell.execute_reply":"2021-07-25T15:03:03.147422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Setup key parameters","metadata":{}},{"cell_type":"code","source":"lRate   = 1.0\nlGamma  = 0.7\nlEpochs = 1#5\nlog_interval = 100","metadata":{"execution":{"iopub.status.busy":"2021-07-25T15:03:03.149428Z","iopub.execute_input":"2021-07-25T15:03:03.149689Z","iopub.status.idle":"2021-07-25T15:03:03.158926Z","shell.execute_reply.started":"2021-07-25T15:03:03.149665Z","shell.execute_reply":"2021-07-25T15:03:03.157968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Net","metadata":{}},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.net = nn.Sequential( OrderedDict([\n            ('conv1', nn.Conv2d( 1,  8, 3, 2) ),\n            ('relu1', nn.ReLU() ),\n            ('conv2', nn.Conv2d( 8,  16, 3, 2) ),\n            ('relu2', nn.ReLU() ),\n            ('conv3', nn.Conv2d( 16,  32, 3, 2) ),\n            ('relu3', nn.ReLU() ),\n            #('maxpl', nn.MaxPool2d( 2 ) ),\n            ('flatt', nn.Flatten() ),\n            ('fc3'  , nn.Linear( 128, 10) ),\n            #('relu3', nn.ReLU() ),\n            #('fc4'  , nn.Linear( 64, 10) ),\n            #('relu4', nn.ReLU() ),\n        ]))\n        self.firstRun= 1;\n    \n    def forward(self, x):\n        for layer in self.net:\n            if self.firstRun == 1:\n                print( x.shape )\n            x = layer(x)\n        output = F.log_softmax(x, dim=1)\n        self.firstRun= 0;\n        return output","metadata":{"execution":{"iopub.status.busy":"2021-07-25T15:03:03.160219Z","iopub.execute_input":"2021-07-25T15:03:03.160539Z","iopub.status.idle":"2021-07-25T15:03:03.171124Z","shell.execute_reply.started":"2021-07-25T15:03:03.16051Z","shell.execute_reply":"2021-07-25T15:03:03.170094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loaders","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cpu\")\nthe_kwargs = {'num_workers': 1, 'shuffle': True, }\nthe_transform = transforms.Compose([\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.1307,), (0.3081,)),\n                       ])\ntrain_loader = torch.utils.data.DataLoader(\n        DatasetMNIST('../input/mnist-in-csv/mnist_train.csv', the_transform),\n        batch_size=64, **the_kwargs)\n\n\ntest_set = DatasetMNIST('../input/mnist-in-csv/mnist_test.csv', the_transform)\n\ntest_loader = torch.utils.data.DataLoader(\n        test_set, batch_size=1000, **the_kwargs)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T15:13:41.173437Z","iopub.execute_input":"2021-07-25T15:13:41.173826Z","iopub.status.idle":"2021-07-25T15:13:45.95495Z","shell.execute_reply.started":"2021-07-25T15:13:41.173797Z","shell.execute_reply":"2021-07-25T15:13:45.953796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare Learning","metadata":{}},{"cell_type":"code","source":"model = Net().to(device)\noptimizer = optim.Adadelta(model.parameters(), lr=lRate)\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=lGamma )","metadata":{"execution":{"iopub.status.busy":"2021-07-25T15:03:07.91883Z","iopub.execute_input":"2021-07-25T15:03:07.919109Z","iopub.status.idle":"2021-07-25T15:03:07.958922Z","shell.execute_reply.started":"2021-07-25T15:03:07.919073Z","shell.execute_reply":"2021-07-25T15:03:07.958051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Main Scripts","metadata":{}},{"cell_type":"code","source":"def train(model, device, train_loader, optimizer, epoch):\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        data, target = data.to(device), target.to(device)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.nll_loss(output, target)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % log_interval == 0:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.item()))\n\n\ndef test(model, device, test_loader):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n            correct += pred.eq(target.view_as(pred)).sum().item()\n\n    test_loss /= len(test_loader.dataset)\n\n    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))","metadata":{"execution":{"iopub.status.busy":"2021-07-25T15:03:07.960659Z","iopub.execute_input":"2021-07-25T15:03:07.960919Z","iopub.status.idle":"2021-07-25T15:03:07.972058Z","shell.execute_reply.started":"2021-07-25T15:03:07.960893Z","shell.execute_reply":"2021-07-25T15:03:07.970821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Learning","metadata":{}},{"cell_type":"code","source":"for epoch in range(1, lEpochs + 1):\n    train(model, device, train_loader, optimizer, epoch)\n    test(model, device, test_loader)\n    scheduler.step()","metadata":{"execution":{"iopub.status.busy":"2021-07-25T15:03:07.974072Z","iopub.execute_input":"2021-07-25T15:03:07.97462Z","iopub.status.idle":"2021-07-25T15:03:47.047561Z","shell.execute_reply.started":"2021-07-25T15:03:07.97458Z","shell.execute_reply":"2021-07-25T15:03:47.046176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sample Mistakes","metadata":{}},{"cell_type":"code","source":"(smplStd,ansStd) = next(iter(test_loader))\nlst  = F.nll_loss( model(smplStd), ansStd, reduction='none' )\nbads = smplStd[ torch.nonzero( lst>1 ) ]\nbads = bads.reshape( (-1, 1, 28, 28) )\nbedA = model(bads.reshape(-1,1,28,28))\nabc = torch.argmax(bedA, dim=1)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T15:03:47.049507Z","iopub.execute_input":"2021-07-25T15:03:47.049951Z","iopub.status.idle":"2021-07-25T15:03:48.162085Z","shell.execute_reply.started":"2021-07-25T15:03:47.049901Z","shell.execute_reply":"2021-07-25T15:03:48.160994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Show Some Mistakes","metadata":{}},{"cell_type":"code","source":"for j in range (2):\n    for i in range (8):\n      if bads.size()[0] > i +j*8 :\n        plt.subplot(2,8, i +j*8+1)\n        plt.imshow( bads[i +j*8].reshape(28,28), cmap=\"gray_r\")\n        bedaE = enumerate( bedA[i +j*8] )\n        print( ansStd[ torch.nonzero( lst>1 ) ][i +j*8], abc[i +j*8] ) ","metadata":{"execution":{"iopub.status.busy":"2021-07-25T15:03:48.163706Z","iopub.execute_input":"2021-07-25T15:03:48.164098Z","iopub.status.idle":"2021-07-25T15:03:49.719808Z","shell.execute_reply.started":"2021-07-25T15:03:48.164052Z","shell.execute_reply":"2021-07-25T15:03:49.718948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Result Export\nfrom https://www.kaggle.com/furkanuysl/digit-recognizer-cnn-99","metadata":{}},{"cell_type":"code","source":"test= test_set.data\ntotal_samples = test.shape[0]\nprint(test.shape)\n#test.head()\ntest = test.values.reshape(-1,(28*28 +1)) [:,1:].reshape(-1,1,28,28)\nmodel.eval()\ny_pred_test = model( torch.Tensor(test))\nprediction = np.argmax(y_pred_test.detach().numpy(), axis = 1)\n\n# create submission DataFrame\nsubmission = pd.DataFrame({'ImageId' : range(1, total_samples+1), 'Label' : list(prediction)})\nsubmission.head(10)\nprint (submission.shape)\nsubmission.to_csv(\"submission.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T15:32:48.533274Z","iopub.execute_input":"2021-07-25T15:32:48.533694Z","iopub.status.idle":"2021-07-25T15:32:48.824725Z","shell.execute_reply.started":"2021-07-25T15:32:48.533662Z","shell.execute_reply":"2021-07-25T15:32:48.823595Z"},"trusted":true},"execution_count":null,"outputs":[]}]}