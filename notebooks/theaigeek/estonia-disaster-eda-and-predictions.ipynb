{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Predicting Estonia Disaster Survival using Machine Learning","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## First, let's import the data and explore our problem definition","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nest_dis = pd.read_csv(\"../input/passenger-list-for-the-estonia-ferry-disaster/estonia-passenger-list.csv\") #est_dis indicates Estonia Disaster, however you can use **df** if it's confusing\nest_dis","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###  By exploring the data, we can say the problem we gonna explore is  **Binary Classification**\n\n**What is Binary Classification**\n\nBinary classification is to classify objects into two groups based on some features","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Second,Some EDA\nEDA stands for Exploratory Data Analysis ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking top 5 rows of our data\nest_dis.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking how many passenger survived(1) and non-survived(0)\nest_dis.Survived.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking whether any missing data\nest_dis.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Our data don't have any missing values**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#let's find out survival percentage\nsurv_percnt = est_dis.Survived.value_counts()[1]/len(est_dis)*100\nprint('Percentage of survived passengers: ' \"{:.2f}\".format(surv_percnt)+'%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Now, let's find out the number of total passengers and crew members**\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"est_dis.Category.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**P** stands for Passenger\n\n**C** stands for Crew Members","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now, let's check total number of male and females\nest_dis.Sex.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualize our data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Checking Survivability by sex wise**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(est_dis.Sex, est_dis.Survived)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"survivedBySex = est_dis.groupby('Sex')['Survived'].mean()\nsurvivedBySex","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plotting Survivability sex wise\n%matplotlib inline\nplt.style.use('seaborn-whitegrid')\nfig , ax = plt.subplots(figsize=(10,6))\nax = survivedBySex.plot.bar()\nax.set(xlabel='Sex',\n      ylabel='Survived',\n      title='Survival rate by Sex');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Checking survivability age-wise** ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"survivedByAge = est_dis.groupby('Age')['Survived'].mean()\nsurvivedByAge","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#The above information wasn't so helpful but if we plot these data, it may make sense\nfig, ax = plt.subplots(figsize=(10,6))\nax = survivedByAge.plot.bar()\nax.set(xlabel='Age',\n      ylabel='Survived',\n      title='Survival rate Age wise');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**let's visualize data category wise**\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"survivedByCategory = est_dis.groupby('Category')['Survived'].mean()\nsurvivedByCategory","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's plot the above data\nfig, ax = plt.subplots(figsize=(10,6))\nax = survivedByCategory.plot.bar()\nax.set(xlabel='Category',\n      ylabel='Survived',\n      title='Survival Category wise');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plotting survivability against country**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"survivedByCountry = est_dis.groupby('Country')['Survived'].mean()\nsurvivedByCountry","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,6))\nax = survivedByCountry.plot.bar()\nax.set(xlabel='Country',\n      ylabel='Survived',\n      title='Survival Country wise');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Third, Fitting our data into a model\n**We have done enough EDA, let proceeeds forward to modelling**\n\nas it's a classification problem we will first evaluate score on KNN(K nearest neighbors), RandomForestClassifier and LogisticRegression.\n\nwhich one have better score, we will proceed with that model and hypertune parameters ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#let's drop Firstname, lastname, PassengerId columns\nest_dis.drop(['PassengerId','Firstname','Lastname'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"est_dis.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"est_dis.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`Country` `Sex` `Survived` columns not in integers, we need to convert them to integers before moving forward","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#using labelencoder to convert all strings into integers in the dataframe\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nfor item in list(est_dis.columns):\n    if est_dis[item].dtype=='object':\n        est_dis[item]= le.fit_transform(est_dis[item])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"est_dis.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Now all columns converted to integers, let's split our data into train, test model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#splitting data into X and y\nX = est_dis.drop('Survived', axis=1)\ny = est_dis['Survived']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,\n                                                test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing all the models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#putting all the models in a dictionary\nmodels = {\"LogisticRegression\":LogisticRegression(),\n         \"KNeighboursClassifier\": KNeighborsClassifier(),\n         \"RandomForestClassifier\":RandomForestClassifier()}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating a function to fit our data in models and evaluate score\ndef fit_score(models,X_train,X_test,y_train,y_test):\n    np.random.seed(40) #so our results can be reproducable\n    evaluate = {} #this empty list will contain our evaluated score\n    for name, model in models.items():\n        model.fit(X_train,y_train) #fitting trained data in a model\n        evaluate[name]= model.score(X_test,y_test) #evaluate score on test data\n    return evaluate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluate= fit_score(models=models,\n                   X_train=X_train,\n                   X_test=X_test,\n                   y_train=y_train,\n                   y_test=y_test)\nevaluate","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**as `LogisticRegression` gives slightly better result than other models, we will hypertune parameters of `Logistic Regression ` and try to improve our model**\n\nyou can also hypertune parameters of other models for better result but here i'm going with `Logistic Regression`","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Fourth, Hypertuning parameters of `Logistic regression` and evaluate `accuracy` score","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Different logistic Regression parameters\nparam_grid = {\"C\": np.logspace(-4,4,20),\n               \"solver\":[\"liblinear\"]}\nfrom sklearn.model_selection import GridSearchCV\nnp.random.seed(55)\ngrid_log_reg = GridSearchCV(LogisticRegression(),\n                           param_grid=param_grid,\n                           cv=5,\n                           verbose=True)\ngrid_log_reg.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_log_reg.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_log_reg.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**There is a slight improvement after hypertuning**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}