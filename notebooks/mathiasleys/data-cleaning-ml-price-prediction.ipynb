{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Data Preparation"},{"metadata":{},"cell_type":"markdown","source":"## Imports"},{"metadata":{"trusted":false},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline \n\nfrom shapely.geometry import Point\nimport geopandas as gpd\nfrom geopandas import GeoDataFrame\n\nimport sklearn\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_absolute_percentage_error\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.cluster import KMeans","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df = pd.read_csv('vehicles.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Exploration"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"x = (df.groupby(['manufacturer'],as_index = False).count().sort_values('price', ascending = False))['manufacturer'].tolist()\ny = (df.groupby(['manufacturer'],as_index = False).count().sort_values('price', ascending = False))['price'].tolist()\nfig = plt.figure(figsize=(15,10))\nplt.xticks(rotation = 90)\nplt.bar(x, y, width=1)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"#Information about the categorical variables\n\nprint(df[\"paint_color\"].unique())\nprint(df[\"condition\"].unique())\nprint(df[\"type\"].unique())\nprint(df[\"fuel\"].unique())\nprint(df[\"cylinders\"].unique())\nprint(df[\"title_status\"].unique())\nprint(df[\"type\"].unique())\nprint(df[\"drive\"].unique())\nprint(df[\"transmission\"].unique())","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"df.isnull().sum().sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"#a lot of locations that don't make sense (i.e. on Antarctica or in the ocean) \n#User can drop a pin anywhere in the world => lat & long values are unreliable\n#Use 'state' and/or 'region' instead of lat & long for location\n\ngeometry = [Point(xy) for xy in zip(df['long'], df['lat'])]\ngdf = GeoDataFrame(df, geometry=geometry)   \n\nworld = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\ngdf.plot(ax=world.plot(figsize=(10, 6)), marker='o', color='red', markersize=5);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Cleaning"},{"metadata":{},"cell_type":"markdown","source":"### Dropping columns/instances"},{"metadata":{"trusted":false},"cell_type":"code","source":"#drop columns that don't add any value to our analysis\n\ndf.drop(['Unnamed: 0', 'id', 'url', 'region_url', 'lat', 'long', 'VIN', 'image_url',\n         'description', 'geometry', 'posting_date'], axis = 1, inplace = True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#keep only 'clean' cars & missing values\n#missing, parts only, etc. cars don't fit the goal of our analysis\n\ndf = df[((df['title_status'] != 'missing') & (df['title_status'] != 'parts only') \n    & (df['title_status'] != 'salvage') & (df['title_status'] != 'rebuilt')\n   & (df['title_status'] != 'lien'))]\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#delete unrealistically over-/underpriced cars (over $500k or under $100)\n#sometimes prices are $0 or $123456789 because the owner wants to agree on the price in person\n\ndf = df[((df['price'] < 500000) & (df['price'] > 100))]\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"starting_year = 1960\nx = (df.groupby(['year'],as_index = False).count())['year'].tolist()\ny = (df.groupby(['year'],as_index = False).count())['price'].tolist()\nfig = plt.figure(figsize=(10,5))\nplt.bar(x, y, width=1)\nplt.axvline(starting_year, color = 'red')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#delete cars built before 1960 (outliers)\n\ndf = df[df['year'] > 1960]\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#delete top 1% of odometer values (outliers)\n\ntop1 = np.nanpercentile(df['odometer'], 99)\nprint('the top 1% mileage is', top1, 'miles')\ndf = df[df['odometer'] < top1]\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#size is perfect multicollinear with car model => drop size column\n\ndf.drop('size', axis = 1, inplace = True)\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#delete unknown fuel, transmission and title_status instances\n\ndf.dropna(subset = ['fuel', 'transmission', 'title_status'], axis = 0, inplace = True)\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#delete all instances with unknown manufacturer\n\ndf = df[~df['manufacturer'].isnull()]\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#delete all instances with unknown model\n\ndf = df[~df['model'].isnull()]\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Replacing missing values with placeholders "},{"metadata":{"trusted":false},"cell_type":"code","source":"#replace missing condition values with 'not specified'\n\ndf['condition'].fillna('not specified', inplace = True)\ndf['condition'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#replace missing color with 'unknown'\n\ndf['paint_color'].fillna('unknown', inplace = True)\ndf['paint_color'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Cleaning car model values and reducing the number of categories"},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"#first word is most important for 'model': many car model categories refer to the same model but are written differently \n#(i.e. 'f150 good condition' and 'F - 150 four wheel drive' refer to the same model: f150)\n#=> keep only first word and remove spaces, special characters, uppercase letters, etc.\n\n#delete instances with a model that appears less than 150 times => reduce amount of categories by omitting uncommon types\n\nmodel_list = df['model'].tolist()\nmodel_list = map(str, model_list)\nmodel_list = [x.lower().strip() for x in model_list]\nmy_list = [car_model.split()[0] for car_model in model_list]\nmy_list = [x.replace(' ', '').replace('-', '').replace('/', '') for x in my_list]\n\ndf['car_model'] = my_list\ndf['car_model'] = df['manufacturer'] + \" \" + df['car_model']\n\nnew_car_models = (df.groupby(['car_model'], as_index= False).count())[['manufacturer', 'car_model', 'price']]\nnew_car_models = new_car_models.rename(columns={'price': 'count'})\nonly_common_models = new_car_models[new_car_models['count'] > 150]\n\nprint('total car models: ', len(new_car_models['count']))\nprint('remaining car models: ', len(only_common_models['count']))\nprint('decreasing ', round((1-len(only_common_models['count'])/len(new_car_models['count'])) * 100, 2),'% of the number of car models')\nprint()\nprint('total instances: ', len(df['price']))\nprint('remaining instances: ', sum(only_common_models['count']))\nprint('removing ', round((1-sum(only_common_models['count'])/len(df['price'])) * 100, 2),'% of the instances')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"#150 seems like the reasonable choice w.r.t. trade-off reducing categories vs keeping enough data\n\nremoved_models_list = []\nremoved_instances_list = []\n\nfor i in range(0,1000):\n    only_common_models_v2 = new_car_models[new_car_models['count']>i]\n    models_removed = 1-len(only_common_models_v2['count'])/len(new_car_models['count'])\n    instances_removed = 1-sum(only_common_models_v2['count'])/len(df['price'])\n    \n    removed_models_list.append(models_removed)\n    removed_instances_list.append(instances_removed)\n\nfig = plt.figure(figsize=(7,7))\nplt.plot(removed_models_list, label = 'Percentage of unqiue models removed')\nplt.plot(removed_instances_list, label = 'Percentage of instances removed')\nplt.axvline(150 , color = 'red', label = 'Cut-off')\nplt.ylabel('Percentage Remaining')\nplt.xlabel('Car model frequency cut-off')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#committing car model cleaning to original dataframe\n\ndf = df[df['car_model'].isin(only_common_models['car_model'].tolist())]\ndf.drop('model', axis = 1, inplace = True)\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Replacing missing values with reasonable proxies"},{"metadata":{"trusted":false},"cell_type":"code","source":"#replace missing number of cylinders with median of car model & delete 'other'\n\ndf = df[df['cylinders'] != 'other']\ndftest = df.copy()\ntest = df[df['cylinders'].notnull()].copy()\ntest['cylinders'] = [int(cyl.split()[0]) for cyl in test['cylinders']]\nmed = test.groupby('car_model')['cylinders'].median()\nmerged = pd.merge(dftest, med, on = 'car_model', how = 'left')\nmerged['cylinders_y'].fillna(med.median(), inplace = True)\nmerged['cylinders_x'].fillna(merged['cylinders_y'], inplace = True)\n\nli = []\nfor cyl in merged['cylinders_x']:\n    if type(cyl) == str:\n        li.append(cyl)\n    else:\n        li.append(str(int(cyl)) + \" cylinders\")\n\ndf['cylinders'] = li\ndf['cylinders'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#replace drive with mode drive of car model\n\ndftest = df.copy()\ntest = df[df['drive'].notnull()].copy()\nmode = test.groupby('car_model')['drive'].agg(pd.Series.mode)\nmerged = pd.merge(dftest, mode, on = 'car_model', how = 'left')\nmerged['drive_x'].fillna(merged['drive_y'], inplace = True)\n\ndf['drive'] = merged['drive_x'].tolist()\ndf['drive'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#replace type with mode type of car model\n\ndftest = df.copy()\ntest = df[df['type'].notnull()].copy()\nmode = test.groupby('car_model')['type'].agg(pd.Series.mode)\nfor i in mode.index:\n    if type(mode[i]) != str:\n        mode[i] = mode[i][0]\nmerged = pd.merge(dftest, mode, on = 'car_model', how = 'left')\nmerged['type_x'].fillna(merged['type_y'], inplace = True)\n\ndf['type'] = merged['type_x'].tolist()\ndf['type'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#all the missing values are handled\n\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Handling price outliers"},{"metadata":{"trusted":false},"cell_type":"code","source":"#get rid of overpriced cars: overpriced = more than 3 times the average for this model\n\ndf = df[df['price'] < (3 * df.groupby('car_model')['price'].transform('mean'))]\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dropping columns with redundant information"},{"metadata":{"trusted":false},"cell_type":"code","source":"#get rid of 'title_status' since it is 'clean' for every instance\n\ndf.drop('title_status', axis = 1, inplace = True)\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#region & state contain same information (certain region is always in the same state)\n\ndf.drop('region', axis = 1, inplace = True)\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Making a backup and saving the data"},{"metadata":{"trusted":false},"cell_type":"code","source":"clean = df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.to_csv('clean.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Engineering/Selection"},{"metadata":{},"cell_type":"markdown","source":"### Creating modeling and k-fold cross validation functions"},{"metadata":{"trusted":false},"cell_type":"code","source":"#creates model as defined in 'reg' and returns test & train evaluation metrics\n#default is 80/20 train-test split: industry standard\n\ndef updateModel(datafr, test_percentage = 0.2, seed = 7):\n    \n    #train-test split\n    X = datafr.drop('price', axis = 1)\n    y = datafr['price']\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_percentage, random_state = seed)\n    X_train = pd.get_dummies(X_train, drop_first = True)\n    X_test = pd.get_dummies(X_test, drop_first = True)\n    \n    #feature scaling\n    sc = StandardScaler()\n    X_train = sc.fit_transform(X_train)\n    X_test = sc.transform(X_test)\n    \n    #making model + predicting\n    reg.fit(X_train, y_train)\n    y_pred_test = reg.predict(X_test)\n    y_pred_train = reg.predict(X_train)\n    \n    #computing test & train metrics\n    test_metrics = {'r2': round(r2_score(y_test, y_pred_test) * 100, 2),\n           'mae': round(mean_absolute_error(y_test, y_pred_test), 2),\n           'mse': round(mean_squared_error(y_test, y_pred_test), 2),\n           'mape': round(mean_absolute_percentage_error(y_test, y_pred_test) * 100, 2)\n           }\n    train_metrics = {'r2': round(r2_score(y_train, y_pred_train) * 100, 2),\n           'mae': round(mean_absolute_error(y_train, y_pred_train), 2),\n           'mse': round(mean_squared_error(y_train, y_pred_train), 2),\n           'mape': round(mean_absolute_percentage_error(y_train, y_pred_train) * 100, 2)\n           }\n    \n    return {'test_metrics': test_metrics,\n            'train_metrics': train_metrics}","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#creates model as defined in 'reg' and returns k fold cross validation metrics\n#default is 5-fold CV: industry standard & default scoring is MAE because of easy interpretation\n\ndef get_kCVscores(datafr, k = 5, scoring = 'neg_mean_absolute_error'):\n    X = datafr.drop('price', axis = 1)\n    X = pd.get_dummies(X, drop_first = True)\n    y = datafr['price']\n    return (cross_val_score(reg, X, y, cv = k, scoring = scoring) * (-1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#K-means clustering function\ndef k_means_clustering(datafr, k):\n    df_to_return = datafr.copy()\n    df_with_dummies = pd.get_dummies(datafr, drop_first = True)\n    km = KMeans(n_clusters = k)\n    df_to_return['cluster'] = km.fit_predict(df_with_dummies)\n    \n    return df_to_return","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Baseline Linear Regression before feature engineering"},{"metadata":{"trusted":false},"cell_type":"code","source":"reg = LinearRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#initial linear regression model\n\ninit_metrics = updateModel(df)\ndef print_metrics(metrics):\n    print('test performance:', metrics['test_metrics'])\n    print('initial test performance:', init_metrics['test_metrics'])\n    print()\n    print('train performance:', metrics['train_metrics'])\n    print('initial train performance:', init_metrics['train_metrics'])\n    print()\n    print('change in test MAE:', round((init_metrics['test_metrics']['mae'] - metrics['test_metrics']['mae']) / \n      (init_metrics['test_metrics']['mae']) * 100, 2), '%')\nprint_metrics(init_metrics)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reasonably poor performance but no sign of overfitting"},{"metadata":{},"cell_type":"markdown","source":"### Grouping states into North-East, Mid-West, South and West"},{"metadata":{"trusted":false},"cell_type":"code","source":"regions_dict = {\"state\": [\"al\",\"ak\",\"az\",\"ar\",\"ca\",\"co\",\"ct\",\"de\",\"dc\",\"fl\",\"ga\",\"hi\",\"id\",\"il\",\"in\",\"ia\",\"ks\",\"ky\",\"la\",\"me\",\"md\",\"ma\",\"mi\",\"mn\",\"ms\",\"mo\",\"mt\",\"ne\",\"nv\",\"nh\",\"nj\",\"nm\",\"ny\",\"nc\",\"nd\",\"oh\",\"ok\",\"or\",\"pa\",\"ri\",\"sc\",\"sd\",\"tn\",\"tx\",\"ut\",\"vt\",\"va\",\"wa\",\"wv\",\"wi\",\"wy\"], \n         \"region\": [\"south\",\"west\",\"west\",\"south\",\"west\",\"west\",\"north-east\",\"south\",\"south\",\"south\",\"south\",\"west\",\"west\",\"mid-west\",\"mid-west\",\"mid-west\",\"mid-west\",\"south\",\"south\",\"north-east\",\"south\",\"north-east\",\"mid-west\",\"mid-west\",\"south\",\"mid-west\",\"west\",\"mid-west\",\"west\",\"north-east\",\"north-east\",\"west\",\"north-east\",\"south\",\"mid-west\",\"mid-west\",\"south\",\"west\",\"north-east\",\"north-east\",\"south\",\"mid-west\",\"south\",\"south\",\"west\",\"north-east\",\"south\",\"west\",\"south\",\"mid-west\",\"west\"]}\ndfState = pd.merge(df, pd.DataFrame(regions_dict), on = 'state', how = 'left').drop('state', axis = 1)\ndfState","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#new metrics\n\nbinned_states_metrics = updateModel(dfState)\nprint_metrics(binned_states_metrics)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"almost no difference => let's try just removing region & state altogether"},{"metadata":{},"cell_type":"markdown","source":"### Dropping 'state' variable"},{"metadata":{"trusted":false},"cell_type":"code","source":"dfDropState = df.drop('state', axis = 1)\ndfDropState","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#new metrics\n\ndrop_state_metrics = updateModel(dfDropState)\nprint_metrics(drop_state_metrics)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"test MAE became (marginally) worse, so let's keep the 'state' feature"},{"metadata":{},"cell_type":"markdown","source":"### Excluding car_model (many categories)"},{"metadata":{"trusted":false},"cell_type":"code","source":"dfNoCarModel = df.drop('car_model', axis = 1)\ndfNoCarModel","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"no_car_model_metrics = updateModel(dfNoCarModel)\nprint_metrics(no_car_model_metrics)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"even though 'car_model' has many categories, it still clearly provides useful information"},{"metadata":{},"cell_type":"markdown","source":"### Binning 'year' variable"},{"metadata":{"trusted":false},"cell_type":"code","source":"dfBinnedYear = df.copy()\ndfBinnedYear['year'] = pd.cut(df['year'], 3, labels = ['vintage', 'medium age', 'recent'])\ndfBinnedYear","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"binned_year_metrics = updateModel(dfBinnedYear)\nprint_metrics(binned_year_metrics)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"performance became significantly worse"},{"metadata":{},"cell_type":"markdown","source":"### Creating feature 'age'"},{"metadata":{"trusted":false},"cell_type":"code","source":"dfAge = df.copy()\ndfAge['age'] = [2021 - x for x in df['year'].tolist()]\ndfAge.drop('year', axis=1, inplace = True)\ndfAge","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"age_metrics = updateModel(dfAge)\nprint_metrics(age_metrics)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"performance became marginally worse => let's not include 'age'"},{"metadata":{},"cell_type":"markdown","source":"### Creating categories for 'age'"},{"metadata":{"trusted":false},"cell_type":"code","source":"#we can clearly see a U-shaped pricing behavior in function of car age\n#in addition, we can identify age categories with similar pricing behavior\n\ndfAgeCat = dfAge.copy()\nthresholds = [50,40,30,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1]\ngroups = ['over 50','40-49','30-39','15-29','14','13','12','11','10','9','8','7','6','5','4','3','2','1']\n\nx = (dfAgeCat.groupby(['age'],as_index = False).mean())['age'].tolist()\ny = (dfAgeCat.groupby(['age'],as_index = False).mean())['price'].tolist()\nfig = plt.figure(figsize=[10,5])\nplt.ylabel('Mean price')\nplt.xlabel('Age (years)')\nplt.bar(x, y, width=1)\nfor t in thresholds:\n    plt.axvline(t-0.5, color = 'red')\n\nplt.axvline(-0.5, color = 'red')\nplt.axvline(60.5, color = 'red')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"arr = np.array(dfAgeCat['age'].tolist())\nfor t in thresholds:\n    prevArr = arr\n    arr = np.where(prevArr >= t, -t, prevArr)\n    \nprevArr = arr\ndfAgeCat['age_group'] = np.where(prevArr >= 0, 'new', prevArr).tolist()\n\nfor i in range(len(thresholds)):\n     toReplace = str(float(-thresholds[i]))\n     dfAgeCat['age_group'].replace(toReplace, groups[i], inplace =  True)\n\ndfAgeCat.drop('age', axis=1, inplace=True)    \nprint(dfAgeCat['age_group'].unique())\ndfAgeCat","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"age_cat_metrics = updateModel(dfAgeCat)\nprint_metrics(age_cat_metrics)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"despite the fact that including 'age' decreased performance, including age categories clearly improved performance without any sign of overfitting"},{"metadata":{},"cell_type":"markdown","source":"### Price vs features analysis"},{"metadata":{"trusted":false},"cell_type":"code","source":"dfPlots = dfAge.copy()\nfor feat in dfAgeCat.drop(['price','odometer','car_model','age_group'], axis = 1).columns:\n    print(feat)\n    x = (dfPlots.groupby(feat, as_index = False).mean()).sort_values(by = ['price'])[feat]\n    y = (dfPlots.groupby(feat, as_index = False).mean()).sort_values(by = ['price'])['price']\n    fig = plt.figure(figsize=[10,5])\n    plt.xlabel(feat)\n    plt.ylabel('Mean price')\n    plt.xticks(rotation = 90)\n    plt.bar(x, y, width=1)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Condition as a numerical feature"},{"metadata":{"trusted":false},"cell_type":"code","source":"dfCondition = df.copy()\n\ndfCondition['condition'].replace('new', 6, inplace =  True)\ndfCondition['condition'].replace('like new', 5, inplace =  True)\ndfCondition['condition'].replace('excellent', 4, inplace =  True)\ndfCondition['condition'].replace('good', 3, inplace =  True)\ndfCondition['condition'].replace('fair', 2, inplace =  True)\ndfCondition['condition'].replace('salvage', 1, inplace =  True)\ndfCondition['condition'].replace('not specified', 3, inplace =  True)\n\ndfCondition['condition'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"condition_metrics = updateModel(dfCondition)\nprint_metrics(condition_metrics)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"no significant effect on performance"},{"metadata":{},"cell_type":"markdown","source":"### Color categories"},{"metadata":{"trusted":false},"cell_type":"code","source":"dfColors = df.copy()\ndfColors['paint_color'].replace(['unknown', 'blue', 'silver', 'grey', 'green', 'custom', 'yellow', 'brown', 'purple'], 'other_colors', inplace =  True)\ndfColors['paint_color'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"color_metrics = updateModel(dfColors)\nprint_metrics(color_metrics)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"no significant effect on performance"},{"metadata":{},"cell_type":"markdown","source":"### Miles per year"},{"metadata":{"trusted":false},"cell_type":"code","source":"dfMPY = dfAge.copy()\nMPY_temp = []\n\ndfMPY['miles_per_year'] = [dfMPY['odometer'][i]/(dfMPY['age'][i]+0.001) for i in dfMPY.index.tolist()]\ndfMPY.drop(['odometer', 'age'], axis=1, inplace=True)\ndfMPY","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"MPY_metrics = updateModel(dfMPY)\nprint_metrics(MPY_metrics)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"significant negative impact on performance"},{"metadata":{},"cell_type":"markdown","source":"### Excluding number of cylinders"},{"metadata":{"trusted":false},"cell_type":"code","source":"dfNoCyl = df.drop('cylinders', axis = 1)\ndfNoCyl","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"no_cyl_metrics = updateModel(dfNoCyl)\nprint_metrics(no_cyl_metrics)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"marginal negative impact on performance"},{"metadata":{},"cell_type":"markdown","source":"### Excluding 'type'"},{"metadata":{"trusted":false},"cell_type":"code","source":"dfNoType = df.drop('type', axis = 1)\ndfNoType","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"no_type_metrics = updateModel(dfNoType)\nprint_metrics(no_type_metrics)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"no significant effect on performance"},{"metadata":{},"cell_type":"markdown","source":"### Committing feature engineering changes to df"},{"metadata":{"trusted":false},"cell_type":"code","source":"#only creating age_groups had a positive impact on performance\n#dropping 'type' and binning 'state' into regions had no real impact on performance but made the model more interpretable\n\ndf = dfAgeCat\ndf = pd.merge(df, pd.DataFrame(regions_dict), on = 'state', how = 'left').drop('state', axis = 1)\ndf.drop('type', axis = 1, inplace = True)\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Creation"},{"metadata":{},"cell_type":"markdown","source":"### Linear Regression"},{"metadata":{"trusted":false},"cell_type":"code","source":"reg = LinearRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#linear regression model on the feature engineered df\n\ninitLR = updateModel(df)\nprint_metrics(initLR)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Feature engineering had a clear positive impact on performance without a sign of overfitting"},{"metadata":{},"cell_type":"markdown","source":"### Feature Importance"},{"metadata":{"trusted":false},"cell_type":"code","source":"cols = pd.get_dummies(df, drop_first = True).columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"importance = reg.coef_\n\ntemp = pd.DataFrame({'feat n°': [x for x in range(len(importance))],'importance': importance})\ntemp = temp.sort_values('importance')\nworst10 = temp[:10]\nbest10 = temp[-10:]\nbest10['feat'] = cols[best10['feat n°']]\nworst10['feat'] = cols[worst10['feat n°']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.xticks(rotation = 90)\nplt.bar(best10['feat'], best10['importance'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.xticks(rotation = 90)\nplt.bar(worst10['feat'], worst10['importance'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest Regressor"},{"metadata":{"trusted":false},"cell_type":"code","source":"#20-tree RF\n\nreg = RandomForestRegressor(n_estimators = 20, random_state = 7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"initRF = updateModel(df)\nprint_metrics(initRF)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"kcv = get_kCVscores(df)\nkcv","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print('Cross validated MAE mean:', kcv.mean())\nprint('Cross validated MAE standard deviation:', kcv.std())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#100-tree RF\n\nreg = RandomForestRegressor(n_estimators = 100, random_state = 7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"init100RF = updateModel(df)\nprint_metrics(init100RF)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"the 20-tree random forest drastically outperforms the linear regression"},{"metadata":{},"cell_type":"markdown","source":"however, cross validation clearly signals an overfitting problem"},{"metadata":{},"cell_type":"markdown","source":"### Boosted Tree Regressor"},{"metadata":{"trusted":false},"cell_type":"code","source":"reg = GradientBoostingRegressor(n_estimators = 50, learning_rate = 0.1, max_depth = 1, random_state = 7, loss = 'ls')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"initBoost = updateModel(df)\nprint_metrics(initBoost)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Boosted Tree performs significantly worse than linear regression"},{"metadata":{},"cell_type":"markdown","source":"### Neural Network"},{"metadata":{"trusted":false},"cell_type":"code","source":"reg = MLPRegressor()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"initNN = updateModel(df)\nprint_metrics(initNN)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Better than LR but not better than RF"},{"metadata":{},"cell_type":"markdown","source":"### Clustering"},{"metadata":{"trusted":false},"cell_type":"code","source":"#Elbow plot values\ndistortions = []\ndf_with_dummies = pd.get_dummies(df.copy(), drop_first = True)\n\nK = range(1,10)\nfor k in K:\n    km = KMeans(n_clusters=k)\n    km.fit(df_with_dummies)\n    distortions.append(km.inertia_)\n\n#Plotting\nplt.figure(figsize=(16,8))\nplt.plot(K, distortions, 'bx-')\nplt.xlabel('k')\nplt.ylabel('Distortion')\nplt.title('Elbow Method to determine the optimal k value')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_clustering_k2 = k_means_clustering(df, 2)\ndf_clustering_k2","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_clustering_k3 = k_means_clustering(df, 3)\ndf_clustering_k3","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"pd.get_dummies(df_clustering_k2, drop_first = True).groupby(['cluster']).median()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"interpretation: cluster 0 are more expensive cars with low mileage while cluster 1 are cheap cars with a lot of mileage"},{"metadata":{"trusted":false},"cell_type":"code","source":"pd.get_dummies(df_clustering_k3, drop_first = True).groupby(['cluster']).median()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"interpretation: analogous but with an extra 'medium priced' category"},{"metadata":{"trusted":false},"cell_type":"code","source":"reg = LinearRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_to_use = pd.get_dummies(df_clustering_k2, drop_first = True)\nk = 2\nprint('For k = ', k)\n\nlist_of_results = []\nfor i in range(k):\n    cluster_df = (df_to_use[df_to_use['cluster']==i]).copy()\n    res = updateModel(cluster_df)\n    print_metrics(res)\n    list_of_results.append(res)\n\nclust_k2_LR_results = list_of_results","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_to_use = pd.get_dummies(df_clustering_k3, drop_first = True)\nk = 3\nprint('For k = ', k)\n\nlist_of_results = []\nfor i in range(k):\n    cluster_df = (df_to_use[df_to_use['cluster']==i]).copy()\n    res = updateModel(cluster_df)\n    print_metrics(res)\n    list_of_results.append(res)\n\nclust_k3_LR_results = list_of_results","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"K=2 seems to improve performance the most and the clusters are also more interpretable"},{"metadata":{"trusted":false},"cell_type":"code","source":"reg = RandomForestRegressor(n_estimators = 20, random_state = 7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_to_use = pd.get_dummies(df_clustering_k2, drop_first = True)\nk = 2\nprint('For k = ', k)\n\nlist_of_results = []\nfor i in range(k):\n    cluster_df = (df_to_use[df_to_use['cluster']==i]).copy()\n    res = updateModel(cluster_df)\n    print_metrics(res)\n    list_of_results.append(res)\n\nclust_k2_RF_results = list_of_results","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print_metrics(initRF)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Final Model"},{"metadata":{"trusted":false},"cell_type":"code","source":"dfFinal = df_clustering_k2.copy()\ndfFinal","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"finalPerformance = clust_k2_RF_results\nprint('Cluster 1:')\nprint_metrics(finalPerformance[0])\nprint()\nprint('Cluster 2:')\nprint_metrics(finalPerformance[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"finalModel = reg\nreg","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"finalClusters = df_clustering_k2.copy()\npd.get_dummies(finalClusters, drop_first = True).groupby(['cluster']).median()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"dfFinal.to_csv('final')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}