{"cells":[{"metadata":{"_uuid":"cbc9a763442901e25ff9953fb46933aaeed887c8"},"cell_type":"markdown","source":"### Importing the Libraries"},{"metadata":{"trusted":true,"_uuid":"7d8a5918e83f66499242e882542dcdc53b1586b2"},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport warnings\nwarnings.simplefilter(\"ignore\")\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d00b94b39bde86e9365a7c96d643cab0b06a4eab"},"cell_type":"markdown","source":"### Importing the Dataset"},{"metadata":{"trusted":true,"_uuid":"a87abff39477cf8d90d2f515b4387b191e55b16f"},"cell_type":"code","source":"train=pd.read_csv(\"../input/mushrooms.csv\")\ntrain.describe().T\n\nfrom sklearn.preprocessing import LabelEncoder\nEncoder_X = LabelEncoder() \nfor col in train.columns:\n    train[col] = Encoder_X.fit_transform(train[col])\nEncoder_y=LabelEncoder()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"196beada86981a3e89fb5761d38f8dab19388f4a"},"cell_type":"markdown","source":"# Poisonous = 1\n# Eatable = 0"},{"metadata":{"_uuid":"c90e29825b60d26fdcebc0eb9eae1819ca0604c6"},"cell_type":"markdown","source":"### Classifiers list"},{"metadata":{"trusted":true,"_uuid":"82d82f09c6d27582ce4a295779b34ad87dcd97cd"},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n#from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC,LinearSVC,SVR\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.linear_model import PassiveAggressiveClassifier,Perceptron,LogisticRegression\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.linear_model import LogisticRegression,SGDClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neural_network import MLPClassifier,MLPRegressor,BernoulliRBM\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis,QuadraticDiscriminantAnalysis\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.pipeline import make_pipeline, make_union\nfrom sklearn.linear_model import ElasticNetCV, LassoLarsCV\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.semi_supervised import LabelPropagation\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.base import BaseEstimator,TransformerMixin, ClassifierMixin\nfrom sklearn.svm import LinearSVR,SVC\nfrom sklearn.utils import check_array\n\n\nclass StackingEstimator(BaseEstimator, TransformerMixin):\n    \n    def __init__(self, estimator):\n        self.estimator = estimator\n\n    def fit(self, X, y=None, **fit_params):\n        self.estimator.fit(X, y, **fit_params)\n        return self\n    def transform(self, X):\n        X = check_array(X)\n        X_transformed = np.copy(X)\n        # add class probabilities as a synthetic feature\n        if issubclass(self.estimator.__class__, ClassifierMixin) and hasattr(self.estimator, 'predict_proba'):\n            X_transformed = np.hstack((self.estimator.predict_proba(X), X))\n\n        # add class prodiction as a synthetic feature\n        X_transformed = np.hstack((np.reshape(self.estimator.predict(X), (-1, 1)), X_transformed))\n\n        return X_transformed\n    \nClassifiers = [\n               #Perceptron(n_jobs=-1),\n               #SVR(kernel='rbf',C=1.0, epsilon=0.2),\n               CalibratedClassifierCV(LinearDiscriminantAnalysis(), cv=4, method='sigmoid'),    \n               OneVsRestClassifier( SVC(    C=50,kernel='rbf',gamma=1.4, coef0=1,cache_size=3000,)),\n               KNeighborsClassifier(10),\n               DecisionTreeClassifier(),\n               RandomForestClassifier(n_estimators=200),\n               ExtraTreesClassifier(n_estimators=250,random_state=0), \n               OneVsRestClassifier(ExtraTreesClassifier(n_estimators=10)) , \n               MLPClassifier(alpha=0.510,activation='logistic'),\n               LinearDiscriminantAnalysis(),\n               #OneVsRestClassifier(GaussianNB()),\n               AdaBoostClassifier(),\n               #GaussianNB(),\n               QuadraticDiscriminantAnalysis(),\n               SGDClassifier(average=True,max_iter=100),\n               XGBClassifier(max_depth=5, base_score=0.005),\n               LogisticRegression(C=1.0,multi_class='multinomial',penalty='l2', solver='saga',n_jobs=-1),\n               LabelPropagation(n_jobs=-1),\n               LinearSVC(),\n               #MultinomialNB(alpha=.01),    \n                   make_pipeline(\n                    StackingEstimator(estimator=LassoLarsCV(normalize=True)),\n                    StackingEstimator(estimator=GradientBoostingRegressor(learning_rate=0.001, loss=\"huber\", max_depth=3, max_features=0.55, min_samples_leaf=18, min_samples_split=14, subsample=0.7)),\n                    AdaBoostClassifier()\n                ),\n\n              ]\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0e7052ca80fc5472abf84c356d5cf61cc5b1d9e5"},"cell_type":"markdown","source":"## Function\n### find relevant feature > SVD \n"},{"metadata":{"trusted":true,"_uuid":"0f5bbcc4cb5feb0741b98602c0f52fc2856935d1"},"cell_type":"code","source":"def klasseer(e_,mtrain,mtest,veld,idvld,thres,probtrigger):\n    # e_ total matrix without veld, \n    # veld the training field\n    #thres  threshold to select features\n    label = mtrain[veld]\n    # select features find most relevant ifo threshold\n    clf = ExtraTreesClassifier(n_estimators=100)\n    ncomp=e_.shape[1]-2\n    model = SelectFromModel(clf, prefit=True,threshold =(thres)/100)\n       # SVD\n    from sklearn.decomposition import TruncatedSVD\n    svd = TruncatedSVD(n_components=ncomp, n_iter=7, random_state=42)\n    e_=svd.fit_transform(e_)\n    \n       #tsne not used\n    from sklearn.manifold import TSNE\n    #e_=TSNE(n_components=3).fit_transform(e_)\n    #from sklearn.metrics.pairwise import cosine_similarity\n    \n       #robustSVD not used\n    #A_,e1_,e_,s_=robustSVD(e_,140)\n    clf = clf.fit( e_[:len(mtrain)], label)\n    New_features = model.transform( e_[:len(mtrain)])\n    Test_features= model.transform(e_[-len(mtest):])\n    pd.DataFrame(New_features).plot.scatter(x=0,y=1,c=mtrain[veld]+1)\n    pd.DataFrame(np.concatenate((New_features,Test_features))).plot.scatter(x=0,y=1,c=['r' for x in range(len(mtrain))]+['g' for x in range(len(mtest))])    \n\n    print('Model with threshold',thres/100,New_features.shape,Test_features.shape,e_.shape)\n    print('____________________________________________________')\n    \n    Model = []\n    Accuracy = []\n    for clf in Classifiers:\n        #train\n        fit=clf.fit(New_features,label)\n        pred=fit.predict(New_features)\n        Model.append(clf.__class__.__name__)\n        Accuracy.append(accuracy_score(mtrain[veld],pred))\n        #predict\n        sub = pd.DataFrame({idvld: mtest[idvld],veld: fit.predict(Test_features)})\n        sub.plot(x=idvld,kind='kde',title=clf.__class__.__name__ +str(( mtrain[veld]==pred).mean()) +'prcnt') \n        sub2=pd.DataFrame(pred,columns=[veld])\n        #estimate sample if  accuracy\n        if veld in mtest.columns:\n            print( clf.__class__.__name__ +str(round( accuracy_score(mtrain[veld],pred),2)*100 )+'prcnt accuracy versus unknown',(sub[veld]==mtest[veld]).mean() )\n        #write results\n        klassnaam=clf.__class__.__name__+\".csv\"\n        sub.to_csv(klassnaam, index=False)\n        if probtrigger:\n            pred_prob=fit.predict_proba(Test_features)\n            sub=pd.DataFrame(pred_prob)\n    return sub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"16c4c10978741180e1093dbe59195b90974ed36a"},"cell_type":"code","source":"train=train.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b1d9b2646ed64a3d471f8d21bb2bb3ee9e9068ed"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(train.drop('class',axis=1),train['class'], test_size=0.3, random_state=42)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bb7d00c252f5f6c11149bb3ac488c5cbc80f3542"},"cell_type":"markdown","source":"## the training distribution \n### a little bit less poisoness"},{"metadata":{"trusted":true,"_uuid":"504bf244045fd81e4b6dd656696e7240b072c6a6"},"cell_type":"code","source":"train['class'].plot(kind='kde') \npd.DataFrame(y_test)['class'].plot(kind='kde')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"25fc7c7202f73af6dc49052a4e30f018bae570aa"},"cell_type":"markdown","source":"## the prediction accuracy for different classifiers\n\n### usually once your data is good, the results doesn't differ very much...\n\nwith threshold 3, we squeeze with SVD  the data to 50% of the features, what is enough to find a relevant classification method, obtaining >99% accuracy for the test sample\n\n"},{"metadata":{"trusted":true,"_uuid":"a8fcdcebfba129c460f3800362f7566c1e210716"},"cell_type":"code","source":"totaal=(X_train.append(X_test)).fillna(0).values\n\nsubx=klasseer(totaal,(X_train.T.append(y_train.T)).T,(X_test.T.append(y_test.T)).T,'class','index',3,False)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3e2550684d2a88d45c9da8968c997c6fe166d3d6"},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}