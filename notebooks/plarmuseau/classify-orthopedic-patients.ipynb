{"cells":[{"metadata":{"_uuid":"1d63e95be97880b09b9c09d00dbbcd31efaf2c17"},"cell_type":"markdown","source":"# Problem is very easy to solve...\n"},{"metadata":{"_cell_guid":"a5b3e280-001d-49bc-93a8-feab2935f502","_uuid":"493ce48bd929d9dae9497816b63d1071ec95042d","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nimport seaborn as sns\n%matplotlib inline\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", '../input']).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"d7eab569-f12a-4b96-a11d-36adbf4eb848","_uuid":"28253f8228fa4898bb4153addf92d6fed10167c2","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/column_2C_weka.csv\")\ndf.head()","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"6170250d-82d4-443d-97f3-1fe50f91d39e","_uuid":"dc893e1dbb98fe97d84cb9613d4798c9e4aca87f","trusted":true},"cell_type":"code","source":"df.describe().T","execution_count":4,"outputs":[]},{"metadata":{"_cell_guid":"73026f74-0f0d-41b4-88d5-21f450c62300","_uuid":"7bd943fd86008e007a7df6dd12ec75e5cf668dc5","collapsed":true,"trusted":true},"cell_type":"code","source":"X = df.drop(\"class\", axis=1)\ny = df[\"class\"]","execution_count":5,"outputs":[]},{"metadata":{"_cell_guid":"3a5c04f5-b930-43cd-b84a-7d124f4b5587","_uuid":"01d0e21581fede7cc67c70c8aee01addd41c4f06","collapsed":true,"trusted":true},"cell_type":"code","source":"le = LabelEncoder()\nle.fit(y)\ny = le.transform(y)\ndf1 = X\ndf1['class'] = y","execution_count":6,"outputs":[]},{"metadata":{"_cell_guid":"2be9cefc-a45b-4ff5-b151-fb1600710dc3","_uuid":"85c957baf5658f6147b48d6e68a583dc8ced1410","trusted":true},"cell_type":"code","source":"df3C = pd.read_csv(\"../input/column_3C_weka.csv\")\ndf3C.head()","execution_count":11,"outputs":[]},{"metadata":{"_cell_guid":"06673f39-f614-4ae1-981d-ce1fb098f645","_uuid":"63f9044849a4205cf3919bf8ba51211c0093c92c","trusted":true},"cell_type":"code","source":"df3C.info()","execution_count":12,"outputs":[]},{"metadata":{"_cell_guid":"8199e6e0-e399-4bd1-b5ef-49564f272c2e","_uuid":"37e51ecebd2d5fcff4fc46b0104eb8d71b17b697","collapsed":true,"trusted":true},"cell_type":"code","source":"X3C = df3C.drop(\"class\", axis=1)\ny3C = df3C[\"class\"]","execution_count":13,"outputs":[]},{"metadata":{"_cell_guid":"8a6b30e4-2446-41fb-a75a-fbcb2f08ef73","_uuid":"145a623625d4549c740863d9df1ab5d0b7ea9d80","collapsed":true,"trusted":true},"cell_type":"code","source":"le3C = LabelEncoder()\nle3C.fit(y3C)\ny3C = le3C.transform(y3C)\ndf3C1 = X3C\ndf3C1['class'] = y3C","execution_count":14,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8f1539eecba2c4776aa27e62d3c76f396b243709"},"cell_type":"code","source":"def Klasseer(Mtrain,Mtest,Mlabel,klas,rank,start):\n    #data preparation\n    #print(Mtotal)\n    #Mtotal=Mtotal.fillna(-1)\n    #print(Mtotal)\n    #Mtrain=Mtotal[Mtotal[labelveld]!=-1]\n    #Mtest=Mtotal[Mtotal[labelveld]==-1]\n    #Mtest=Mtest.drop(labelveld,axis=1)\n    Mlabel=pd.DataFrame( Mlabel,columns=['label'] )  #[:len(Mtrain)]\n    #Mlabel=Mlabel.fillna(-1)  \n    labelveld='label'\n    print('shapes train',Mtrain.shape,'label',Mlabel.shape,'test',Mtest.shape)\n\n    \n    #totalA=Mtrain.append(Mtest)\n    totalA=np.concatenate((Mtrain,Mtest), axis=0)\n    predictionA=pd.DataFrame(Mlabel,columns=[labelveld])    \n    #totalA=totalA.drop(labelveld,axis=1)\n    #print(totalA.shape,predictionA.shape)\n    #print(prediction)\n    #faze 1\n    # dimmension reduction\n    from scipy.spatial.distance import cosine\n    from sklearn.metrics.pairwise import cosine_similarity\n    from sklearn.decomposition import TruncatedSVD\n    from sklearn.preprocessing import Normalizer\n    from sklearn.pipeline import make_pipeline\n    from sklearn.model_selection import train_test_split\n    from sklearn.metrics import accuracy_score, log_loss\n    from sklearn.neighbors import KNeighborsClassifier\n    from sklearn.svm import SVC, LinearSVC, NuSVC\n    from sklearn.tree import DecisionTreeClassifier\n    from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier,ExtraTreesClassifier\n    from sklearn.naive_bayes import GaussianNB\n    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n    from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n    from sklearn.linear_model import OrthogonalMatchingPursuit,RANSACRegressor,LogisticRegression,ElasticNetCV,HuberRegressor, Ridge, Lasso,LassoCV,Lars,BayesianRidge,SGDClassifier,LogisticRegressionCV,RidgeClassifier,Perceptron\n\n    import seaborn as sns\n    import matplotlib.pyplot as plt\n    \n    \n    for ira in range(rank-start,rank+1):\n        print('****20% sample test==',ira)\n        #Ulsa = lsa.fit_transform(Mtrain.values/255)  #train version\n        #print(total)\n        if ira!=0:\n            if ira<len(totalA.T):\n                print(\"lsa dimmension reduction\")                \n                svd = TruncatedSVD(ira)\n                normalizer = Normalizer(copy=False)\n                lsa = make_pipeline(svd, normalizer)\n                UlsA = lsa.fit_transform(totalA) #total version\n                explained_variance = svd.explained_variance_ratio_.sum()\n                print(\"Explained variance of the SVD step knowledge transfer: {}%\".format(\n                    int(explained_variance * 100)))            \n            else:\n                print(\"no reduction\")\n                UlsA=totalA\n        else:\n            print(\"3D-SVD dimmension reduction\")\n            u,s,vh=np.linalg.svd(totalA)\n            print(u.shape, s.shape, vh.shape)\n            UlsA=np.reshape(u, (len(totalA),28*28))            \n        #    UlsA = totalA\n        #    print(\"no LSA reduction\")\n        print('ulsa',UlsA.shape)\n\n\n        #faze2\n        #training model\n\n        #sample\n        samlen=int(len(Mlabel)/1)\n        X_train, X_test, y_train, y_test = train_test_split(UlsA[:samlen], Mlabel[:samlen],stratify=Mlabel[:samlen], test_size=0.25)\n        print(\"test on 20% sample\")\n        \n        if klas=='Logi':\n            classifiers = [\n    #    SVC(kernel=\"rbf\", C=0.025, probability=True),  20%\n    #    NuSVC(probability=True),\n                LogisticRegression(),\n                 ]\n        if klas=='Quad':\n            classifiers = [\n                QuadraticDiscriminantAnalysis(),\n                 ]           \n        if klas=='Rand':\n            classifiers = [\n                RandomForestClassifier(84),\n                 ]               \n        if klas=='Extr':\n            classifiers = [\n                ExtraTreesClassifier(verbose=1,n_jobs=3),\n                 ]             \n        if klas=='Adab':\n            classifiers = [\n                AdaBoostClassifier(),\n                 ]            \n        if klas=='Deci':\n            classifiers = [\n                DecisionTreeClassifier(),\n                 ]\n        if klas=='Grad':\n            classifiers = [\n                GradientBoostingClassifier(),\n                 ]            \n        if klas=='KNN':\n            classifiers = [\n                KNeighborsClassifier(n_jobs=4),  \n                 ]            \n        if klas=='Line':\n            classifiers = [\n                LinearDiscriminantAnalysis(), \n                 ]  \n        if klas=='Gaus':\n            classifiers = [\n                GaussianNB(),\n                 ] \n        if klas=='Perc':\n            classifiers = [\n                Perceptron(),\n                 ]      \n        if klas=='Elas':\n            classifiers = [\n                ElasticNet(random_state=0),\n                 ]                 \n    # Logging for Visual Comparison\n        log_cols=[\"Classifier\", \"Accuracy\", \"Log Loss\"]\n        log = pd.DataFrame(columns=log_cols)\n    \n        for clf in classifiers:\n            clf.fit(X_train,y_train)\n            name = clf.__class__.__name__\n        \n            print(\"=\"*30)\n            print(name)\n            \n            #print('****Results****')\n            train_predictions = clf.predict(X_test)\n            acc = accuracy_score(y_test, train_predictions)\n            print(\"Accuracy: {:.4%}\".format(acc))\n        \n            train_predictions = clf.predict_proba(X_test)\n            ll = log_loss(y_test, train_predictions)\n            print(\"Log Loss: {}\".format(ll))\n            \n            log_entry = pd.DataFrame([[name, acc*100, ll]], columns=log_cols)\n            log = log.append(log_entry)\n    \n        print(\"=\"*30)\n\n    print('*** train complete set==',UlsA[:len(Mlabel)].shape)\n     \n    clf.fit(UlsA[:len(Mlabel)],Mlabel)\n    #on complete trainset\n\n    #pr2=pd.DataFrame(clf.predict_proba(Ulsa),index=list(range(0,len(Ulsa),1)))\n\n    predictionA=pd.DataFrame(clf.predict(UlsA),columns=['pred'],index=range(0,len(UlsA)))\n    predictionA[labelveld]=Mlabel \n    print('predict',predictionA.shape)\n    predictionA.fillna(-1)\n    predictionA['diff']=0\n    predictionA['next']=Mlabel\n    #abs(prediction[labelveld]-prediction['pred\n    collist=sorted( Mlabel.label.unique() )\n\n    print(collist)\n    if klas=='Logi':\n        predictionA[collist] = pd.DataFrame(clf.predict_log_proba(UlsA))\n    if klas!='Logi':\n        print(UlsA.shape)\n        temp=pd.DataFrame(clf.predict_proba(UlsA))\n        print(temp.shape)\n        predictionA[collist]=temp\n    \n    from sklearn.metrics import classification_report, confusion_matrix\n    true_labels=predictionA[labelveld][:len(Mtrain)].values.astype('float32')\n    predicted_labels = predictionA['pred'][:len(Mtrain)].values.astype('float32')\n\n    cm = confusion_matrix(true_labels, predicted_labels,labels=collist)\n    print(classification_report(true_labels, predicted_labels))\n    print(\"Confusion matrix\")\n    print(cm)\n    \n    corr=predictionA.drop(['pred','diff'],axis=1).corr()\n    f, ax = plt.subplots(figsize=(10, 8))\n    sns.heatmap(abs(corr), mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True), square=True, ax=ax)\n    predictionA=predictionA.fillna('0')\n    #print('Prediction',prediction.head())\n    pred2=predictionA.drop(['pred',labelveld,'diff','next'],axis=1)\n    \n    print(predictionA.shape)\n\n\n    return predictionA #['next']","execution_count":17,"outputs":[]},{"metadata":{"_uuid":"fa0def105d5be62f699f8fedce032d8b7b605b17"},"cell_type":"markdown","source":"# Solved with\n\n*** Gradientboost\n* Extratrees\n* Randomforest\n* Adaboost\n* GaussianNB\n* DecisionTree**\n"},{"metadata":{"trusted":true,"_uuid":"7665286c8b067b12a08b0ce8f75fcf1829d25505"},"cell_type":"code","source":"Klasseer(X3C,X3C,y3C,'KNN',7,0) \nKlasseer(X3C,X3C,y3C,'Grad',7,0)\nKlasseer(X3C,X3C,y3C,'Extr',7,0)\nKlasseer(X3C,X3C,y3C,'Rand',7,0)\nKlasseer(X3C,X3C,y3C,'Adab',7,0) \nKlasseer(X3C,X3C,y3C,'Gaus',7,0)\nKlasseer(X3C,X3C,y3C,'Deci',7,0) \nKlasseer(X3C,X3C,y3C,'Logi',7,0)\nKlasseer(X3C,X3C,y3C,'Line',7,0) \n#Klasseer(X3C,X3C,y3C,'Quad',7,0) ","execution_count":21,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}