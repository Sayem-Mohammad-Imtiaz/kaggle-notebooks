{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import glob\nimport imageio\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport glob\nimport PIL\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nimport time\n\nfrom IPython import display\n\ntf.__version__","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"datasetDirectory  = \"/kaggle/input/best-artworks-of-all-time/\"\nresized = datasetDirectory + \"resized/resized/\"\nartist = \"Andy_Warhol\"                                                                #Change for a different directory\nimageDirectory = glob.glob(datasetDirectory+\"resized/resized/{}*.jpg\".format(artist))\nnum_paintings = len(imageDirectory)\nprint(\"Number of Paintings by {}: {}\".format(artist, num_paintings))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Although these images have been resized to similar sizes, we must further resize them so they are able to go through the GAN\n#Another approach is using Spatial Pyramid Pooling\n#Find average height and width of all images in dataset\ntW = 0\ntH = 0\nfor i in imageDirectory:\n    image = PIL.Image.open(i)\n    width,height = image.size\n    tW += width\n    tH += height\navg_width = round(tW/(num_paintings))\navg_height = round(tH/(num_paintings))\nprint(\"Average Width of Images\", avg_width)\nprint(\"Average Heigth of Images\", avg_height)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def decodeImage(i, scale = False):\n    \"\"\"\n    Decodes an image, by loading the jpg from the directory, decoding the jpg into a uint8 tensor (RGB channels), then converting to a float32 tensor\n    \"\"\"\n    img = tf.io.read_file(i)\n    img = tf.io.decode_jpeg(img, channels=3)\n    img = tf.image.convert_image_dtype(img, tf.float32)\n    if(scale):\n        img = tf.image.resize(img, [avg_width,avg_height])  \n    return img\n\ndef showImage(i):\n    \"\"\"\n    Shows image, converts float32 tensor to uint8 tensor, then to a numpy array to display\n    \"\"\"\n    i = tf.image.convert_image_dtype(i, tf.uint8)\n    i = PIL.Image.fromarray(i.numpy())\n    display.display(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#SANITY CHECK\nfor i in range(3):\n    showImage(decodeImage(imageDirectory[i]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Convert list of directories to a Dataset of tensor32\ndirSet = tf.data.Dataset.from_tensor_slices(imageDirectory)\nimageSet = dirSet.map(decodeImage)\n\n#More image prepreocessing\n\nBATCH_SIZE = 10\nBUFFER_SIZE = 40          #We won't use this if we are taking the Spatial Pyramid Approach\nimageSet = imageSet.shuffle(BUFFER_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#SANITY CHECK\nfor i in imageSet.take(2):\n    showImage(i)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we need to actually design and build the Generator and Discriminator Models"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import Dense, LeakyReLU, BatchNormalization, Reshape, Conv2DTranspose\n\n#Since the artworks have a variable size, the random input will be scaled by some factor to give the final dimensions of the generated artwork\n\n\nclass GeneratorNetwork(tf.keras.Model):\n    \n    def __init__(self):\n        super(GeneratorNetwork, self).__init__()\n        \n        self.dA = Dense(50*50*1024)\n        self.bA = BatchNormalization()\n        self.actA = LeakyReLU()\n        \n        self.shaped = Reshape((50,50,1024))\n        \n        self.conv1 = Conv2DTranspose(512, (5,5), strides = (1,1),  padding='same', use_bias=False)  \n        self.b1 = BatchNormalization()\n        self.act1 = LeakyReLU()\n        \n        self.conv2 = Conv2DTranspose(256, (5,5), strides = (2,2),  padding='same', use_bias=False)  \n        self.b2 = BatchNormalization()\n        self.act2 = LeakyReLU()\n        \n        self.conv3 = Conv2DTranspose(128, (5,5), strides = (2,2),  padding='same', use_bias=False)  \n        self.b3 = BatchNormalization()\n        self.act3 = LeakyReLU()\n        \n        self.conv4 = Conv2DTranspose(64, (5,5), strides = (2,2),  padding='same', use_bias=False)  \n        self.b4 = BatchNormalization()\n        self.act4 = LeakyReLU()\n        \n        self.conv5 = Conv2DTranspose(3, (5,5), strides = (1,1),  padding='same', use_bias=False)  \n        self.b5 = BatchNormalization()\n        self.act5 = LeakyReLU()\n    \n    \n    def call(self, x):\n        \n        x = self.dA(x) \n        x = self.bA(x) \n        x = self.actA(x) \n        \n        x = self.shaped(x) \n        \n        x = self.conv1(x) \n        x = self.b1(x) \n        x = self.act1(x) \n        \n        x = self.conv2(x) \n        x = self.b2(x) \n        x = self.act2(x) \n        \n        x = self.conv3(x) \n        x = self.b3(x) \n        x = self.act3(x) \n        \n        x = self.conv4(x) \n        x = self.b4(x) \n        x = self.act4(x) \n        \n        x = self.conv5(x) \n        x = self.b5(x) \n        x = self.act5(x) \n    \n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generator = GeneratorNetwork()\n\nnoise = tf.random.normal([1, 100])\ngenerated_image = generator(noise, training=False)\n\nplt.imshow(generated_image[0, :, :, 1], cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, Dropout, LeakyReLU, Concatenate, SeparableConv2D\n\nACT = 'Leakyelu'\n\nstride =1\n\nclass DiscriminatorNetwork(tf.keras.Model):\n    \n    def __init__(self):\n        super(DiscriminatorNetwork, self).__init__()\n        \n        #Primary Convolutional Layers\n        self.conv1 = Conv2D(64,(3,3), stride, padding='same', input_shape= (None,None,3))\n        self.conv2 = Conv2D(64,(3,3), stride, padding='same' )\n        self.conv3 = Conv2D(64,(3,3), stride, padding='same')\n        self.act1 =  LeakyReLU()\n        #self.pool1 = MaxPool2D(pool_size =(2,2))\n        \n        self.conv4 = SeparableConv2D(128,(3,3), stride, padding='same')\n        self.conv5 = SeparableConv2D(128,(3,3), stride, padding='same')\n        self.conv6 = SeparableConv2D(128,(3,3), stride, padding='same')\n        self.act2 =  LeakyReLU()\n        #self.pool2 = MaxPool2D(pool_size = (2,2))\n        \n        self.conv7 = SeparableConv2D(256,(3,3), 2, padding='same')\n        self.conv8 = SeparableConv2D(256,(3,3), 2, padding='same')\n        self.conv9 = SeparableConv2D(256,(3,3), 2, padding='same')\n        self.act3 =  LeakyReLU()\n        self.pool3 = MaxPool2D(pool_size = (2,2))\n        \n        self.conv10 = SeparableConv2D(512,(3,3), stride, padding='same')\n        self.conv11 = SeparableConv2D(512,(3,3), stride, padding='same')\n        self.conv12 = SeparableConv2D(512,(3,3), stride, padding='same')\n        self.act4 =  LeakyReLU()\n        #self.pool4 = MaxPool2D(pool_size = (2,2))\n        \n        #Spatial Pyramid Layers\n        self.pyramid1 = MaxPool2D(pool_size = (1,1))\n        self.pyramid2 = Flatten()\n        self.pyramid3 = MaxPool2D(pool_size = (2,2))\n        self.pyramid4 = Flatten()\n        self.pyramid5 = MaxPool2D(pool_size = (4,4))\n        self.pyramid6 = Flatten()\n        \n        self.pyramidConcat = Concatenate()\n        \n        #Fully Connected Layers\n        self.dense1 = Dense(1024, activation='relu')\n        self.drop1 = Dropout(0.7)\n        self.dense2 = Dense(512, activation='relu')\n        self.drop2 = Dropout(0.5)\n        self.denseOUT = Dense(1)\n        \n    \n    def call(self, x):\n        \n        \n        #Primary Convolutional Layers\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.conv3(x)\n        x = self.act1(x)\n        #x = self.pool1(x)\n        \n        \n        x = self.conv4(x)\n        x = self.conv5(x)\n        x = self.conv6(x)\n        x = self.act2(x)\n        #x = self.pool2(x)\n        \n        \n        x = self.conv7(x)\n        x = self.conv8(x)\n        x = self.conv9(x)\n        x = self.act3(x)\n        x = self.pool3(x)\n        \n        \n        x = self.conv10(x)\n        x = self.conv11(x)\n        x = self.conv12(x)\n        x = self.act4(x)\n        #x = self.pool4(x)\n        \n        #Spatial Pyramid Layers\n        a = self.pyramid1(x)\n        a = self.pyramid2(a)\n        \n        b = self.pyramid3(x)\n        b = self.pyramid4(b)\n        \n        c = self.pyramid5(x)\n        c = self.pyramid6(c)\n\n        out = self.pyramidConcat([a,b,c])\n        \n        #Fully Connected Layers\n        \n        out = self.dense1(out)\n        out = self.drop1(out)\n        out = self.dense2(out)\n        out = self.drop2(out)\n        out = self.denseOUT(out)\n        \n        return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discriminator = DiscriminatorNetwork()\ndecision = discriminator(generated_image)\nprint (decision)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generator = GeneratorNetwork()\ndiscriminator = DiscriminatorNetwork()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, we define the loss and optmizer functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Loss functions using cross entropy\n# TODO: Loss functions based off Wasserstein Loss\n\nLEARNING_RATE  = 0.001\n\ncr = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n\n\"\"\"\ndef discriminator_loss(real, fake):\n    critic_loss =  -1 * (real - fake)     #Add -1 to make a minimization problem\n    return critic_loss\n\ndef generator_loss(fake):\n    return -1 *fake\n\n\"\"\"\ndef disc_loss(real, fake):\n    real_l  = cr(tf.ones_like(real), real)   #Compares tensor of ones to real output  (closer real is to 1, lower the loss)\n    fake_l  = cr(tf.zeroes_like(fake), fake)   #Compares tensor of zeros to real output  (closer fake is to zero, lower the loss)\n    return real_l + fake_l\n\ndef gen_loss(fake):\n    return cr(tf.ones_like(fake), fake) #Closer the fake is to 1, lower the loss (means that the discriminator thinks the fakes are real)\n\n\ndisc_opt = tf.keras.optimizers.Adam(LEARNING_RATE)\ngen_opt = tf.keras.optimizers.Adam(LEARNING_RATE)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create checkpoints for saving model\ncheckpoint_dir = './training_chckpts'\ncheckpoint_pref = os.path.join(checkpoint_dir, \"ckpt\")\ncheckpoint = tf.train.Checkpoint(gen_opt=gen_opt,\n                                 disc_opt=disc_opt,\n                                 generator=generator,\n                                 discriminator=discriminator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS = 50\nnoise_dim = 100\nexamples = 3\n\n#Seed to monitor generate image during training\nseed = tf.random.normal([examples, noise_dim])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create training functions of generator and discriminator\n@tf.function\ndef train_stepGenerator(images):\n    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n\n    with tf.GradientTape() as tape:\n      generated_images = generator(noise, training=True)\n      critique = discriminator(generated_images, training=True)\n      loss = gen_loss(critique)\n\n    grads = tape.gradient(loss, generator.trainable_variables)\n    gen_opt.apply_gradients(zip(grads, generator.trainable_variables))\n    \n@tf.function\ndef train_stepDiscriminator(images):\n    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n\n    with tf.GradientTape() as tape:\n      generated_images = generator(noise, training=True)\n      critique = discriminator(generated_images, training=True)\n      loss = disc_loss(image, critique)\n\n    grads = tape.gradient(loss, discriminator.trainable_variables)\n    disc_opt.apply_gradients(zip(grads, discriminator.trainable_variables))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epoch = EPOCHS\nfor i in range(epoch):\n    start = time.time()\n    \n    #Even epoch\n    if(epoch % 2 == 0):\n        for image in imageSet:\n            train_stepGenerator(image)\n    else:\n        for images in imageSet:\n            train_stepDiscriminator(image)\n            \n    if (epoch + 1) % 10 == 0:\n      checkpoint.save(file_prefix = checkpoint_prefix)\n    \n    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n    \n    display.clear_output(wait=True)\n    for i in range(len(seed)):\n        showImage(generator(seed[i]))\n    ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}