{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom pandas.plotting import scatter_matrix\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"covid19_india_df = pd.read_csv(\"/kaggle/input/covid19-in-india/covid_19_india.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"covid19_india_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"covid19_india_df.count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"covid19_india_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Cleaning\n**Lets clean the data covid19_india_df. Replacing -(hyphen) with 0(zero)**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#covid19_india_df['ConfirmedIndianNational'] = covid19_india_df['ConfirmedIndianNational'].replace('-',0)\n#covid19_india_df['ConfirmedIndianNational'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Cleaning the whole dataset whereever there is - replace it with 0**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"covid19_india_df = covid19_india_df.replace('-',0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"covid19_india_df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Rename the State/UnionTerritory column to State_UnionTerritory**\n\n* We can rename the column using the df.rename command. \n* Here the arguments are (columns = {'old_column_name' : 'new_column_name'}","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"covid19_india_df.rename(columns = {\"State/UnionTerritory\" : \"State_UnionTerritory\"}, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# **df.shape**\n\nThis method will return the shape tuple of 2 where first value repersents the number of rows and 2nd value repersents the number of columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"covid19_india_df.shape\ndf_rows,df_col = covid19_india_df.shape\nprint(\"There are total %d records in the datset\" %(df_rows))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Describe method in the pandas**\n\nIn order to get quick overview of the data, we use thed esscribe method. this methods will perform the various statistics functions on the columns having values either in float or integer.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"covid19_india_df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Attributes of df.describe() function\nNow in order to include the other columns as well we use additonal attributes of the describe function","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"covid19_india_df.info()\ncovid19_india_df.describe(include = ['object'])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Sorting the dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"type(covid19_india_df.Sno)\n# Sno is of type series and we can perform sorting operation on the series datatype columns only.\ncovid19_india_df.Sno.sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Filtering from a dataset covid19_india_df\n\nSuppose we want only those rows where the confirmed cases are maximum","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"covid19_india_df[covid19_india_df['State_UnionTerritory'] == 'Kerala'].Confirmed.max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"States_df = covid19_india_df.State_UnionTerritory.unique()\nStates_df\nprint(\"there are total %d states and UT\" %(len(States_df)))\nmax1 = 0\nfor states in States_df:\n    #print(covid19_india_df[covid19_india_df['State_UnionTerritory'] == states].ConfirmedIndianNational.max())\n    #print(states)\n    max1= covid19_india_df[covid19_india_df['State_UnionTerritory'] == states].Confirmed.max()\n    print(\"Maximum confirmed cases in %s are %d\" %(states, max1))\n    #print(\"Maximum confirmed cases are %d\" %(max1))\n \n#len(max1)\n#covid19_india_df[covid19_india_df.Confirmed.isin(max1)]\n\n    \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Group by based on state_unionterritory","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\ncovid19_india_df.groupby('State_UnionTerritory').Confirmed.max().sort_values().plot(kind = 'bar', title = 'Total Confirmed Cases', legend = True, figsize = (20,10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Aggregate function in pandas\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"covid19_india_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"covid19_india_df.Deaths.astype('float')\n\n#covid19_india_df.groupby('State_UnionTerritory').Deaths.agg(['min','max','mean','std'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Replacing # from the data of dataframe","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"covid19_india_df['State_UnionTerritory'] = covid19_india_df['State_UnionTerritory'].str.replace('#','')\n\n#round(covid19_india_df[covid19_india_df['State_UnionTerritory'] == 'Dadar Nagar Haveli'].Confirmed.std(),2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating a new datafrmae by performing some operations on the existing dataframe\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n#covid19_india_df[covid19_india_df.Confirmed == covid19_india_df[covid19_india_df['State_UnionTerritory'] == 'Punjab'].Confirmed.max()]\nstates_std = []\nstate_std = 0\nctr = 0\nprint(len(States_df))\nfor states in States_df:\n    #print(states)\n    state_std = round(covid19_india_df[covid19_india_df['State_UnionTerritory'] == states].Confirmed.std(),2)\n    ctr = ctr + 1\n    #if not state_std:\n     #   print(states,state_std)\n    states_std.append((states,state_std))\n#print(round(covid19_india_df[covid19_india_df['State_UnionTerritory'] == 'Punjab'].Confirmed.std()))\n#print(np.var(covid19_india_df[covid19_india_df['State_UnionTerritory'] == 'Punjab'].Confirmed))\n#states_std\nprint(len(states_std))\nprint(ctr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"states_std = np.array(states_std)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"states_std_df = pd.DataFrame(states_std, columns = ('States_UT','Standard_Deviation'))\n#states_std_df.rename(columns = {'0': 'States_UT','1' : 'Standard_Deviation'}, inplace= True)\nstates_std_df['Standard_Deviation'] = states_std_df['Standard_Deviation'].str.replace('nan','0.0')\n#states_std_df['Standard_Deviation'] = round(int(states_std_df['Standard_Deviation']))\n#type(states_std_df['Standard_Deviation'])\nprint(\"before datatype\")\n#states_std_df.dtypes\n#convert_dt = {'Standard_Deviation' : float }\n#states_std_df.astype(convert_dt)\nprint(\"After datatype\")\nstates_std_df.dtypes\nstates_std_df['Standard_Deviation'] = states_std_df['Standard_Deviation'].apply(pd.to_numeric)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"states_std_df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"states_std_df.Standard_Deviation.sort_values().index\nstates_std_df.iloc[states_std_df.Standard_Deviation.sort_values().index]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filenames","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Lets Explore the ICMR testing lab csv","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ICMR_testing_lab_df = pd.read_csv('/kaggle/input/covid19-in-india/ICMRTestingLabs.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ICMR_testing_lab_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ICMR_testing_lab_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**This dataset has details of all the lab along with their address and type**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nICMR_testing_lab_df.groupby(['state','type']).lab.count().sort_values().plot(kind = 'bar', figsize=(50,20), fontsize = '30')\n#ICMR_testing_lab_df.groupby(['state']).type.count().plot(kind = 'bar', figsize=(50,20), fontsize = '20',stacked = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Lets explore the statewsie testing data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"state_testing_df = pd.read_csv(r'/kaggle/input/covid19-in-india/StatewiseTestingDetails.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"state_testing_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Lets look at the data and findout which all columns have null data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"state_testing_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"state_testing_df.fillna(0,inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"state_testing_df.isnull().sum()\n#Null Values have been removed from the datframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"punjab_data = state_testing_df.loc[state_testing_df.State == 'Punjab',:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"punjab_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nx1 = punjab_data.Date\ny1 = punjab_data.TotalSamples\n\ny2 = punjab_data.Positive\n\nplt.figure(figsize = (30,10))\nplt.plot(x1,y1)\nplt.plot(x1,y2)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"punjab_data.set_index('Date').head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\npunjab_data.sort_values(by = 'Date').head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l = 0\ndaily_samples = []\nfor index,row in punjab_data.sort_values(by = 'Date').iterrows():\n    #print(l)\n    #print('row.TotalSamples ' + str(row.TotalSamples) + '-----' + str(l))\n    l = int(row.TotalSamples) - l\n    #l = row.TotalSamples\n    daily_samples.append(l)\n    l = int(row.TotalSamples)\n#daily_samples","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(daily_samples)\ndaily_samples = pd.Series(daily_samples, index = punjab_data.index, name = 'DailySamples')\ndaily_samples.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"punjab_data.count()\npd.concat([punjab_data,daily_samples], axis = 1).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ind = 0\ndaily_positive = []\ndaily_negative = []\nfor index,row in punjab_data.sort_values(by='Date').iterrows():\n    if ind == 0:\n        daily_positive.append(row.Positive)\n        daily_negative.append(row.Negative)\n    else:\n        daily_positive.append(row.Positive - punjab_data.loc[ind,'Positive'])\n        daily_negative.append(row.Negative - punjab_data.loc[ind,'Negative'])\n    ind = index\ndaily_positive = pd.Series(daily_positive,index = punjab_data.index, name = 'DailyPositive')\ndaily_negative = pd.Series(daily_negative,index = punjab_data.index, name = 'DailyNegative')\npunjab_data = pd.concat([punjab_data,daily_samples,daily_positive,daily_negative], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"punjab_data.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scatter_matrix(punjab_data[['DailySamples','DailyPositive','DailyNegative']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#punjab_data.head()\nfig, ax = plt.subplots(figsize = (20,10))\n#fig.figure(figsize = (30,10))\nprint(fig)\nfig = (500,400)\nprint(ax)\n#plt.legend(True)\n#ax = fig.add_axes([0,0,1,1])\nax.plot(punjab_data.Date,punjab_data.DailySamples,'b*')#,punjab_data.DailyPositive,punjab_data.DailyNegative))\nax.plot(punjab_data.Date,punjab_data.DailySamples,'b',label = 'Daily Samples')#,punjab_data.DailyPositive,punjab_data.DailyNegative))\nax.plot(punjab_data.Date,punjab_data.DailyPositive,'g-', label = 'Daily Positive')\nax.plot(punjab_data.Date,punjab_data.DailyPositive,'g*')\n#ax.plot(punjab_data.Date,punjab_data.DailyNegative,color = 'r', label = 'Daily Negative')\nax.plot(punjab_data.DailySamples.mean(),'r')#,punjab_data.DailyPositive,punjab_data.DailyNegative))\nax.legend()\nplt.title('Daily testing vs Daily positive', size = (30))\nplt.xlabel('Dates',size = (20))\nplt.ylabel('Daily tests', size= (20))\nprint(fig)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}