{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# Unsupervised Learning\n* Unsupervised learning: It uses data that has unlabeled and uncover hidden patterns from unlabeled data. Example, there are heart disease data that do not have labels. You do not know which heart disease target is 1 or 0.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/heart-disease-uci/heart.csv\")\ndata\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# K-Means\n"},{"metadata":{},"cell_type":"markdown","source":"* As you know  heart disease data is labeled (supervised) data. It has target variables. In order to work on unsupervised learning, lets drop target variables and to visualize just consider chol and thalach."},{"metadata":{"trusted":true},"cell_type":"code","source":"# As you can see there is no labels in data\n# we need to import matplot library.\nimport matplotlib.pyplot as plt\nplt.scatter(data[\"chol\"],data[\"thalach\"])\nplt.xlabel(\"chol\")\nplt.ylabel(\"thalach\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# KMeans Clustering\ndata2 = data.loc[:,[\"chol\",\"thalach\"]]\nfrom sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters = 2) # we choose 2 cluster in our data.\nkmeans.fit(data2)\nlabels = kmeans.predict(data2)\nplt.scatter(data[\"chol\"],data[\"thalach\"],c = labels)\nplt.xlabel(\"chol\")\nplt.xlabel(\"thalach\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluating of Clustering\n* We cluster data in two groups. Okey well is that correct clustering? In order to evaluate clustering we will use cross tabulation table.\n\n* There are two clusters that are 0 and 1 (1 = male, 0 = female)\n* First class female(0) includes 62 0 and 54 1 patients.\n* Second class male(1) includes 76 0 and 111 1 patiens."},{"metadata":{"trusted":true},"cell_type":"code","source":"# cross tabulation table\ndf = pd.DataFrame({'labels':labels,\"target\":data[\"target\"]})\nct = pd.crosstab(df['labels'],df[\"target\"])\nprint(ct)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* inertia: how spread out the clusters are distance from each sample\n* lower inertia means more clusters\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# inertia\ninertia_list = np.empty(14)\nfor i in range(1,14):\n    kmeans = KMeans(n_clusters=i)\n    kmeans.fit(data2)\n    inertia_list[i] = kmeans.inertia_\nplt.plot(range(0,14),inertia_list,\"-o\")\nplt.xlabel(\"Number of cluster\")\nplt.ylabel(\"Inertia\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Standardization\n* Standardization (or Z-score normalization) is the process of rescaling the features.\n* Do not forget standardization as pre-processing.\n* As we already have visualized data so you got the idea. Now we can use all features for clustering.\n* We can use pipeline like supervised learning."},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/heart-disease-uci/heart.csv\")\ndata3 = data.drop(\"target\",axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\nscalar = StandardScaler()\nkmeans = KMeans(n_clusters = 2)\npipe = make_pipeline(scalar,kmeans)\npipe.fit(data3)\nlabels = pipe.predict(data3)\ndf = pd.DataFrame({\"labels\":labels,\"target\":data[\"target\"]})\nct = pd.crosstab(df[\"labels\"],df[\"target\"])\nprint(ct)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Hierarchy\n* It has two different variations: Agglomerative (from part to whole) and Divisive (from whole to part).\n* A dendrogram is a tree diagram that shows relationships between similar datasets or a hierarchical cluster. It gives information about how many clusters we will create.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.cluster.hierarchy import linkage, dendrogram\n\nmerg = linkage(data,method = \"ward\")\ndendrogram(merg,leaf_rotation = 90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# HC\nfrom sklearn.cluster import AgglomerativeClustering\nhiyerartical_cluster = AgglomerativeClustering(n_clusters = 2,affinity=\"euclidean\", linkage = \"ward\")\ncluster = hiyerartical_cluster.fit_predict(data)\n\ndata[\"label\"] = cluster\nplt.scatter(data.chol[data.label == 0 ],data.thalach[data.label == 0],color = \"red\")\nplt.scatter(data.chol[data.label == 1 ],data.thalach[data.label == 1],color = \"green\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see it's same graphic with K-Means Clustering."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}