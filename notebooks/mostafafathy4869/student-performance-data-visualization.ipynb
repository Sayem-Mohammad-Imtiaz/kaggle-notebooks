{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"4d8d5161-c771-4fa7-8154-301e2578b360","_cell_guid":"2ba88453-f307-43db-b2bf-48048aca027c","_kg_hide-input":true,"_kg_hide-output":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport seaborn as sns\n\n%matplotlib inline\nmpl.style.use('seaborn')\nmpl.rcParams[\"figure.facecolor\"] ='#f6f5f5'","metadata":{"_uuid":"b24a2b4d-2137-4f3e-a605-b5a5344987df","_cell_guid":"75fe8b19-6cbf-4de2-abb5-4be1e7ec8929","_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#reading raw data\ndata_raw = pd.read_csv('/kaggle/input/student-performance-data-set/student-por.csv')\n#creating deep copy\ndf = data_raw.copy(deep=True)\n\n#printing shape of the data and data info\nprint('Data Shape:',df.shape)\nprint(df.info())\ndisplay(df.head())","metadata":{"_uuid":"50003d76-c138-4ecf-b570-8b231a8a258c","_cell_guid":"0773366a-e431-4e5c-933f-308b66fa8d9c","_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#taking alook on the catagorical columns\nprint('Catagorical Column\\'s Values\\n')\nfor col in df.select_dtypes(exclude=np.number).columns:\n    unique = df[col].unique()\n    print('-'*7,f'columns {col}','-'*7)\n    print(f'There are {len(unique)} Unique values')\n    print(f'5 of which are: {unique[:5]}\\n')\n    \n#Numeric data statistics\nprint('-'*15,'\\nNumeric Data Statistics\\033[1;0m')\ndisplay(df.select_dtypes(include=np.number).describe())\nprint('-'*15,'\\nPearson\\'s Correlation')\nplt.figure(figsize=(15,8))\nsns.heatmap(df.select_dtypes(include=np.number).corr(),annot=True)","metadata":{"_uuid":"88e0b8c8-3575-41de-b908-58f56762ae42","_cell_guid":"5b29e03e-3d71-47fe-a7b2-4349b1d8f0fe","_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The Data we have consists of 649 Entry and 33 Columns, Most of the columns are catagorical of ordinal variables, More information taken from dataset [link](https://www.kaggle.com/larsen0966/student-performance-data-set)**\n\n**Columns:**\n* **School:** student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira)\n* **Sex:** student's sex (binary: 'F' - female or 'M' - male)\n* **Age:** student's age (numeric: from 15 to 22)\n* **Address:** student's home address type (binary: 'U' - urban or 'R' - rural)\n* **Famsize:** family size (binary: 'LE3' - less or equal to 3 or 'GT3' - greater than 3)\n* **Pstatus:** parent's cohabitation status (binary: 'T' - living together or 'A' - apart)\n* **Medu:** mother's education (numeric: 0 - none, 1 - primary education (4th grade), 2 â€“ 5th to 9th grade, 3 â€“ secondary education or 4 â€“ higher education)\n* **Fedu:** father's education (numeric: 0 - none, 1 - primary education (4th grade), 2 â€“ 5th to 9th grade, 3 â€“ secondary education or 4 â€“ higher education)\n* **Mjob:** mother's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')\n* **Fjob:** father's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')\n* **Reason:** reason to choose this school (nominal: close to 'home', school 'reputation', 'course' preference or 'other')\n* **Guardian:** student's guardian (nominal: 'mother', 'father' or 'other')\n* **Traveltime:** home to school travel time (numeric: 1 - <15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - >1 hour)\n* **Studytime:** weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours)\n* **Failures:** number of past class failures (numeric: n if 1<=n<3, else 4)\n* **Schoolsup:** extra educational support (binary: yes or no)\n* **Famsup:** family educational support (binary: yes or no)\n* **Paid:** extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)\n* **Activities:** extra-curricular activities (binary: yes or no)\n* **Nursery:** attended nursery school (binary: yes or no)\n* **Higher:** wants to take higher education (binary: yes or no)\n* **Internet:** Internet access at home (binary: yes or no)\n* **Romantic:** with a romantic relationship (binary: yes or no)\n* **Famrel:** quality of family relationships (numeric: from 1 - very bad to 5 - excellent)\n* **Freetime:** free time after school (numeric: from 1 - very low to 5 - very high)\n* **Goout:** going out with friends (numeric: from 1 - very low to 5 - very high)\n* **Dalc:** workday alcohol consumption (numeric: from 1 - very low to 5 - very high)\n* **Walc:** weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)\n* **Health:** current health status (numeric: from 1 - very bad to 5 - very good)\n* **Absences:** number of school absences (numeric: from 0 to 93)\n* **G1:** first period grade (numeric: from 0 to 20)\n* **G2:** second period grade (numeric: from 0 to 20)\n* **G3:** final grade (numeric: from 0 to 20, output target)","metadata":{"_uuid":"8d469217-f0fb-4e21-a28a-2e9c94606282","_cell_guid":"0fc76965-39b5-4dc3-8c42-b7b20bcfd428","_kg_hide-input":false,"trusted":true}},{"cell_type":"markdown","source":"# Data Visualization","metadata":{"_uuid":"553698cb-3726-4b31-bd9d-f7445f086c6a","_cell_guid":"19dc6892-c847-408a-887a-d995a10f54a1","trusted":true}},{"cell_type":"markdown","source":"First to ease things alittle bit I'll divide columns into 3 list for Catagorical, Numerical, Continous data","metadata":{"_uuid":"c31073b4-774e-44ea-954a-fa60cbfe24ff","_cell_guid":"d9f6c51c-0e74-42a4-b898-478eb41a9c01","_kg_hide-input":true,"trusted":true}},{"cell_type":"code","source":"#creating catagorical columns list and numeric columns list\ncat_columns = ['school','sex','address','famsize','Pstatus','Mjob','Fjob','reason','guardian',\n               'schoolsup','famsup','paid','activities','nursery','higher','internet','romantic']\nnum_columns = ['Medu','Fedu','traveltime','studytime','famrel','freetime','goout','Dalc','Walc','health']\ncont_columns = ['age','failures','absences','G1','G2','G3']","metadata":{"_uuid":"c862c84b-9d48-4640-899f-1bfd29b98805","_cell_guid":"c6f0b2e8-d448-4527-936e-0447bbe294c1","_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# I-Univariat Data Visualization","metadata":{"_uuid":"338d0bb7-4503-4944-9872-9585f57aceab","_cell_guid":"9b867446-1412-4b87-804f-51df156908f6","trusted":true}},{"cell_type":"code","source":"def ncols_calculator(cols,nrows=3):\n    '''\n    Takes a list of columns and numbers row plots\n    \n    returns number of cols to be used in matplotlib.pyplot.subplots()\n    and how many axes will be remained that need to be deleted\n    '''\n    n = len(cols)\n    ncols = n//nrows\n    if ncols*nrows < n:\n        ncols+=1\n    axdel = ncols*nrows-n\n    return ncols,axdel\n\n\ndef bar_matrix(df,cols,nrows=3,annot=True,title='You Forget Your Title!'):\n    '''\n    df --> DataFrame\n    cols --> List of Columns name to be plotted\n    nrows --> number of nrows to split figure subplots default is 3\n    annot --> Boolean to decide whether percentage of each bar annotation is desired\n    title --> Figure title to be displayed\n    \n    Functions is designed to create one plot using\n    sns.countplot for catagorical datatype columns\n    \n    '''\n    ncols,axdel = ncols_calculator(cols)\n    fig,axes = plt.subplots(ncols,nrows,figsize=(nrows*4,ncols*3),constrained_layout=True)\n    plt.suptitle(f'{title}',size=20, fontweight='bold', fontfamily='serif')\n    axes=axes.ravel()\n    if axdel >0:\n        for ax in range(1,axdel+1):\n            axes[-ax].remove()\n    for i in range(len(cols)):\n        #creating plotting data information\n        ax = axes[i]\n        col = cols[i]\n        #creating plot\n        sns.countplot(x=col,data=df,color=sns.color_palette()[0],ax=ax)\n        #adjusting plot\n        ax.set_xlabel(\"\")\n        ax.set_title(col+'_Column')\n        ax.set_ylim(0,max(ax.get_ylim())+max(ax.get_ylim())/8)\n        #writing percentage over each bar\n        if annot==True:\n            for p in ax.patches:\n                x = p.get_x()+0.2\n                y = p.get_height()+1\n                percentage = '{:.1f}%'.format(100*p.get_height()/df.shape[0])\n                ax.annotate(percentage,(x,y))\n                \ndef hist_violin(df,cols,title='You Forget Your Title!'):\n    '''\n    df --> DataFrame\n    cols --> List of Columns name to be plotted\n    title --> Figure title to be displayed\n    \n    Functions is designed to create two plots using\n    sns.histplot and sns.violinplot for continuous datatype columns\n    \n    '''\n    ncols = len(cols)\n    fig,axes = plt.subplots(ncols,2,figsize=(12,ncols*2),constrained_layout=True)\n    fig.suptitle(f'{title}',size=20, fontweight='bold', fontfamily='serif')\n    #axes=axes.ravel()\n    for i in range(len(cols)):\n        ax = axes[i][0]\n        col = cols[i]\n        sns.histplot(x=col,data=df,color=sns.color_palette()[0],ax=ax,kde=True)\n        #ax.set_xlabel(\"\")\n        ax.set_title(col+'_Distribution')\n        ax = axes[i][1]\n        sns.violinplot(x=col,data=df,color=sns.color_palette()[0],ax=ax)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n**In This Section I'll try to explore each column individually to understand it's properties**","metadata":{"_uuid":"d2a8426a-6e47-4d32-b50e-c3ea7e444e1b","_cell_guid":"75f1f438-963e-4cab-9330-3239b4953764","trusted":true}},{"cell_type":"markdown","source":"For catagorical columns I'll be creatin **countplot** and annot each bar percentage over it","metadata":{"_uuid":"98046fe1-0689-406b-99f7-3cb67b07db4f","_cell_guid":"92ce3312-900a-486b-9b06-82d42eb16bed","trusted":true}},{"cell_type":"code","source":"bar_matrix(df,cat_columns,annot=True,title='Catagorical Features Proportion')","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I'll treat this numeric data as catagorical data as it is considered ordinal catagroical data but represented using numbers\nSo Iusing countplot for each column and using annotation to calculate each bar percentage","metadata":{"_uuid":"f169d683-e046-4635-bd8c-3e6c2fffce85","_cell_guid":"f0a6e440-2288-406a-a487-a63d03284e20","trusted":true}},{"cell_type":"code","source":"bar_matrix(df,num_columns,annot=True,title='Ordinal Features Proportion')","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here the data is discrete so, I'll treat it different. To learn more about continuse data I will creat multiple plot for each column each has\ndifferent information which we can learn from\n\nI'll be Creating:\n* kernel density estimate\n* Violin Plot","metadata":{"_uuid":"3b6b9d81-b7de-4f14-a2c8-806d3f176ed8","_cell_guid":"400d46e1-470d-46d3-917c-f218c1a14167","trusted":true}},{"cell_type":"code","source":"hist_violin(df,cont_columns,title='Continues Features Distribution')","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We can see that G1 and G2 has very similar distributions while G3 has a slightly different distribution**","metadata":{"_uuid":"4e465a2e-1aa3-4e4f-86da-3ccf263d1a34","_cell_guid":"9fc15fde-1253-4be3-a84b-46bf9a2af998","trusted":true}},{"cell_type":"markdown","source":"# Bivariant Visualization","metadata":{"_uuid":"b803363a-5e01-48f4-b227-58f12851e204","_cell_guid":"68cca671-70b8-4a53-bb23-4dafcd89ebc2","trusted":true}},{"cell_type":"markdown","source":"##### In this section my goal is to explore relationships of 2 columns with each other, our main focus are the exam result so I'll focus more in the relation ship of different columns with exam results,","metadata":{"_uuid":"7cbaaacf-fe74-42c4-8d32-88d14fd8b972","_cell_guid":"978cb101-fb98-4cbf-9369-24dfb8cf894c","trusted":true}},{"cell_type":"markdown","source":"**for simplicity sake I'll merge G1 and G2 into one column so I can explore relationships between the column and both exams at the same time**\n\n**Also I will be adding Father and Mother's Education levels to one column**","metadata":{"_uuid":"e439b477-a8c3-4796-84e4-c24ed1f2bd1b","_cell_guid":"749db70e-2e1a-4248-8e33-630073c1353d","trusted":true}},{"cell_type":"code","source":"#Creating different copy of the main dataframe to do my adjustment on it.\nbi_df = df.copy()\nbi_df['G1&G2'] = round((bi_df['G1'] + bi_df['G2'])/2,1)\nbi_df['MFedu'] = bi_df['Medu'] + bi_df['Fedu']\n\nbi_df.drop(labels=['G1','G2','Medu','Fedu'],inplace=True,axis=1)\n\n#Updating my list of columns after the adjustments\nbi_cat_columns = ['school','sex','address','famsize','Pstatus','Mjob','Fjob','reason','guardian',\n               'schoolsup','famsup','paid','activities','nursery','higher','internet','romantic']\nbi_num_columns = ['traveltime','studytime','famrel','freetime','goout','Dalc','Walc','health','MFedu']\nbi_cont_columns = ['age','failures','absences','G3']","metadata":{"_uuid":"27463607-94ee-4777-8de7-8faad232da0b","_cell_guid":"c9536785-2924-4a1b-9f72-06d0ef6c25ef","_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"First, I'll explore G1&G2 score distribution for different columns","metadata":{"_uuid":"d80117e1-6f8b-4dfd-bcf4-7f3289afed3f","_cell_guid":"eb5f8635-8fbd-4f2f-9421-e26136c73c52","trusted":true}},{"cell_type":"code","source":"fig,axes = plt.subplots(9,3,figsize=(12,30),constrained_layout=True)\nfig.suptitle('G1&G2 Distribution for each feature value',size=20, fontweight='bold', fontfamily='serif')\naxes=axes.ravel()\naxes[-1].remove()#removing non plotted axis\n\nfor i in range(len(bi_cat_columns+bi_num_columns)):\n    #Creating plotting data variables\n    ax = axes[i]\n    col = (bi_cat_columns+bi_num_columns)[i]\n    #plotting function\n    sns.kdeplot(x='G1&G2',data=bi_df,hue=col,ax=ax,shade=True,palette=sns.color_palette('bright')[:len(bi_df[col].unique())])\n    #Adjusting plot\n    ax.set_xlabel(\"\")\n    ax.set_title(col+'_Column')","metadata":{"_uuid":"470221c2-df31-4cda-9cd1-b076555cf470","_cell_guid":"be949f3f-4887-43cd-909b-85e7124577b1","_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Comparing exam score mean for each columns","metadata":{}},{"cell_type":"code","source":"fig,axes = plt.subplots(9,3,figsize=(12,30),constrained_layout=True)\nfig.suptitle('G1&G2 Mean Value For Different Feature',size=20, fontweight='bold', fontfamily='serif')\naxes=axes.ravel()\naxes[-1].remove()\nfor i in range(len(bi_cat_columns+bi_num_columns)):\n    #Creating plotting data variables\n    ax = axes[i]\n    col = (bi_cat_columns+bi_num_columns)[i]\n    plot_data = bi_df.groupby(col).mean()\n    #plotting function\n    sns.barplot(y='G1&G2', x=plot_data.index, data=plot_data, ax=ax, color=sns.color_palette('bright')[9])\n    #Adjusting plot\n    ax.set_xlabel(\"\")\n    ax.set_title(col+'_Column')\n    ax.set_ylim(0,max(ax.get_ylim())+max(ax.get_ylim())/8)\n    #writing percentage over each bar\n    for p in ax.patches:\n        x = p.get_x()+0.2\n        y = round(p.get_height())\n        ax.annotate(y,(x,y+0.5))","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### We can see some distribution difference from the exam score distribution, for example:\n* **The exam mean value seems to have a inverse relationship with alcoholic consumption**\n* **The exam mean increases with increasing study time and score distribution tend to shift slightly to the right**\n* **The exam mean increases from other student if Mother of Father works as a teacher and score distribution tend to shift slightly to the right**\n* **The distribution health shift to left (score decreases) if health of the student is worse**\n* **The exam mean is worst if the guardian of the student is other than father or mother, there are some difference between guardian being the father and the mother, but the entries of father being the guardian is significantly smaller than the mother as most students have there mother as guardian**\n","metadata":{}},{"cell_type":"markdown","source":"# Multivariant Visualization","metadata":{"_uuid":"e521a16c-9313-42dd-990f-8c52b066bfb4","_cell_guid":"1071e87f-bc4c-4324-a940-1d7557febff1","jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"##### In this section my goal is to explore relationships of multiple columns with each other","metadata":{}},{"cell_type":"code","source":"#Creating different copy of the main dataframe to do my adjustment on it.\nmu_df = df.copy()\nmu_df['G1&G2'] = round((mu_df['G1'] + mu_df['G2'])/2,1)\nmu_df['MFedu'] = mu_df['Medu'] + mu_df['Fedu']\n\nmu_df.drop(labels=['G1','G2','Medu','Fedu'],inplace=True,axis=1)\n\n#Updating my list of columns after the adjustments\nmu_cat_columns = ['school','sex','address','famsize','Pstatus','Mjob','Fjob','reason','guardian',\n               'schoolsup','famsup','paid','activities','nursery','higher','internet','romantic']\nmu_num_columns = ['traveltime','studytime','famrel','freetime','goout','Dalc','Walc','health','MFedu']\nmu_cont_columns = ['age','failures','absences','G3']\n\ndef exam_mean_facetgrid(df,face_column,x_col,mean_col='G1&G2',title='Forgotten!!'):\n    '''\n    df --> DataFrame\n    face_column --> column name to be used in the FacetGrid main split\n    x_col --> x-axis column name to be plotted in the FacetGrid object\n    mean_col --> y-axis column name which where the mean value will be plottedd\n    title --> Figure title to be displayed \n    \n    Functions is designed to create sns.FacetGrid object with df and face_column as parameters\n    then map plt.bar func with x_col and mean_col to the FacetGrid object.\n    '''\n    plot_data = df.groupby([x_col,face_column]).mean()[mean_col].reset_index()\n    g=sns.FacetGrid(data=plot_data,col=face_column,margin_titles=True)\n    g.map(plt.bar,x_col,mean_col)\n    g.fig.subplots_adjust(top=0.8)\n    g.fig.suptitle(f'{title}',size=12, fontweight='bold', fontfamily='serif')","metadata":{"_uuid":"c4b09d57-7c8e-4a0d-b519-0f58c420d51d","_cell_guid":"96bc2bac-c302-4885-9569-38a5789c39d6","_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**I'm curious how studytime and freetime affect student's score in exam, So I will create FacetGrid for different studytime value with x-axis for freetime value and y-axis equal to student's mean**","metadata":{}},{"cell_type":"code","source":"exam_mean_facetgrid(df=mu_df, face_column='studytime', x_col='freetime',title='Change on G1&G2 Mean Vale with respect to different Freetime and Studytime for students')","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Studing the exam means for different study time and free time is interesting, taking that if study time of 4 (which mean >10 hours) and have less free time do better in the exam than student's that study as much but has more free time which can infere one of 2 explanation:**\n* As the value 4 is a little vague so the students don't study as much may be the students that have less free time may study more than students have more free time\n* Students that have less free time may have hobbies or do activities which improve there performan","metadata":{}},{"cell_type":"code","source":"#for col in mu_num_columns+mu_cat_columns:\n#    if col == 'studytime':\n#        continue\n#    exam_mean_facetgrid(mu_df,'studytime',col)\n\nexam_mean_facetgrid(mu_df,x_col='studytime',face_column='Dalc',title='Change on G1&G2 Mean Vale with respect to different Studytime and Workday Alcohol Consumbtion for students')\nexam_mean_facetgrid(mu_df,x_col='studytime',face_column='Walc',title='Change on G1&G2 Mean Vale with respect to different Studytime and Weekend Alcohol Consumbtion for students')","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**As we have seen before that the exam score is inversely relation to alcoholic consumption we can investigate more about that relation with the above 2 plots which compare students mean score and studytime with alcoholic consumptions in weekdays and weekends.**\n\n* **We can see that the heighest exam mean value were achived with the lowest weekday alcohol consumption (1&2). While the weekend consuption doesn't have strong trend we can see that the scores increases with studytime for same weekends alcohol consumption group**","metadata":{}},{"cell_type":"markdown","source":"#####  This data only has 649 rows which are considered too low to infer any global trends but fortunately, it has some strong trends within itself that we have discovered through our analysis and maybe there are more still hidden within the data. Feel free to tell me what you think and to explore the data from where I stopped\n","metadata":{}}]}