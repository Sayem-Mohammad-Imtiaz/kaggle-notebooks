{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/intenttask/intent_train.csv')\ndata = data.dropna()\ncheck = pd.read_csv('/kaggle/input/intenttask/intent_check.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\nfrom keras.models import Sequential, load_model\nfrom keras.layers.core import Dense\nfrom keras.layers import Conv1D, Input, Embedding\nfrom keras.layers.pooling import GlobalMaxPooling1D\nfrom keras.utils import to_categorical\nfrom keras.callbacks import LearningRateScheduler, ModelCheckpoint, EarlyStopping\nfrom keras.models import load_model\nfrom keras.initializers import lecun_uniform\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\n\n\nlabel_lst = sorted(data['label'].value_counts().index.to_list())\ndecoder = dict(enumerate(label_lst))\nencoder = dict((j, i) for i, j in enumerate(label_lst))\n\nX, Y = data['text'], to_categorical(data['label'].replace(encoder))\nX_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2)\n\nmax_words = 1000\nkeras_tokenizer = Tokenizer(num_words=max_words, char_level=True)\nkeras_tokenizer.fit_on_texts(X_train.tolist())\n\nX_train = keras_tokenizer.texts_to_matrix(X_train)\nX_val = keras_tokenizer.texts_to_matrix(X_val)\n\ninit = lecun_uniform(seed=42)\nmodel = Sequential()\nmodel.add(Embedding(10150, 100, input_length=1000))\nmodel.add(Conv1D(128, 5, activation='relu', init=init))\nmodel.add(GlobalMaxPooling1D())\nmodel.add(Dense(80, activation='relu'))\nmodel.add(Dense(30, activation='relu'))\nmodel.add(Dense(14, activation='sigmoid'))\nmodel.compile(\n#     optimizer=SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True),\n    optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=['accuracy'])\n\nhistory = model.fit(X_train, Y_train,\n                    epochs=4,\n                    validation_data=(X_val, Y_val),\n                    batch_size=64,\n                    shuffle=True,\n                    callbacks=[\n                        ModelCheckpoint('model.hd5', save_best_only=True),\n                        EarlyStopping(monitor='val_loss', min_delta=0.001, patience=10),\n                    ])\nmodel.save_weights('weights.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import load_model\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.models import Sequential, load_model\nfrom keras.layers.core import Dense\nfrom keras.layers import Conv1D, Input, Embedding\nfrom keras.layers.pooling import GlobalMaxPooling1D\nfrom keras.utils import to_categorical\nfrom keras.callbacks import LearningRateScheduler, ModelCheckpoint, EarlyStopping\nfrom keras.models import load_model\nfrom keras.initializers import lecun_uniform\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport numpy as np\n\n\ndef get_model():\n    model = Sequential()\n    model.add(Embedding(10150, 100, input_length=1000))\n    model.add(Conv1D(128, 5, activation='relu', init=init))\n    model.add(GlobalMaxPooling1D())\n    model.add(Dense(80, activation='relu'))\n    model.add(Dense(30, activation='relu'))\n    model.add(Dense(14, activation='sigmoid'))\n    return model\n\ndecoder = {\n    0: 'FAQ - интернет',\n    1: 'FAQ - тарифы и услуги',\n    2: 'SIM-карта и номер',\n    3: 'Баланс',\n    4: 'Личный кабинет',\n    5: 'Мобильные услуги',\n    6: 'Мобильный интернет',\n    7: 'Оплата',\n    8: 'Роуминг',\n    9: 'Устройства',\n    10: 'запрос обратной связи',\n    11: 'мобильная связь - зона обслуживания',\n    12: 'мобильная связь - тарифы',\n    13: 'тарифы - подбор'\n}\n\n\nmodel = get_model()\nmodel.load_weights('weights.h5')\nmodel.compile(\n    optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)\n# check = pd.read_csv('/kaggle/input/intent_check.csv')\n# keras_tokenizer = Tokenizer(num_words=1000, char_level=False, mode='tfidf')\ntokenized_check = keras_tokenizer.texts_to_matrix(check['text'].tolist())\ncheck['label'] = pd.Series(np.argmax(model.predict(tokenized_check), axis=1)).replace(decoder)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.concat([pd.Series(np.argmax(model.predict(X_val), axis=1)).replace(decoder), pd.Series(np.argmax(Y_val, axis=1)).replace(decoder)], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}