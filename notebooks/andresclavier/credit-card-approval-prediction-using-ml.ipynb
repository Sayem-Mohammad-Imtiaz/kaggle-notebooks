{"cells":[{"metadata":{},"cell_type":"markdown","source":"<font size=5 >Credit Card Approval Prediction Using Sklearn</font>","execution_count":null},{"metadata":{"toc":true},"cell_type":"markdown","source":"<h1>Table of Content<span class=\"tocSkip\"></span></h1>\n<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Feature-Engineering\" data-toc-modified-id=\"Feature-Engineering-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Feature Engineering</a></span><ul class=\"toc-item\"><li><span><a href=\"#Response-Variable\" data-toc-modified-id=\"Response-Variable-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Response Variable</a></span></li><li><span><a href=\"#Features\" data-toc-modified-id=\"Features-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Features</a></span><ul class=\"toc-item\"><li><span><a href=\"#Binary-Features\" data-toc-modified-id=\"Binary-Features-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Binary Features</a></span><ul class=\"toc-item\"><li><span><a href=\"#Gender\" data-toc-modified-id=\"Gender-1.2.1.1\"><span class=\"toc-item-num\">1.2.1.1&nbsp;&nbsp;</span>Gender</a></span></li><li><span><a href=\"#Having-a-car-or-not\" data-toc-modified-id=\"Having-a-car-or-not-1.2.1.2\"><span class=\"toc-item-num\">1.2.1.2&nbsp;&nbsp;</span>Having a car or not</a></span></li><li><span><a href=\"#Having-house-reality-or-not\" data-toc-modified-id=\"Having-house-reality-or-not-1.2.1.3\"><span class=\"toc-item-num\">1.2.1.3&nbsp;&nbsp;</span>Having house reality or not</a></span></li><li><span><a href=\"#Having-a-phone-or-not\" data-toc-modified-id=\"Having-a-phone-or-not-1.2.1.4\"><span class=\"toc-item-num\">1.2.1.4&nbsp;&nbsp;</span>Having a phone or not</a></span></li><li><span><a href=\"#Having-an-email-or-not\" data-toc-modified-id=\"Having-an-email-or-not-1.2.1.5\"><span class=\"toc-item-num\">1.2.1.5&nbsp;&nbsp;</span>Having an email or not</a></span></li><li><span><a href=\"#Having-a-Work-Phone-or-not\" data-toc-modified-id=\"Having-a-Work-Phone-or-not-1.2.1.6\"><span class=\"toc-item-num\">1.2.1.6&nbsp;&nbsp;</span>Having a Work Phone or not</a></span></li></ul></li><li><span><a href=\"#Continuous-Variables\" data-toc-modified-id=\"Continuous-Variables-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Continuous Variables</a></span><ul class=\"toc-item\"><li><span><a href=\"#Children-Numbers\" data-toc-modified-id=\"Children-Numbers-1.2.2.1\"><span class=\"toc-item-num\">1.2.2.1&nbsp;&nbsp;</span>Children Numbers</a></span></li><li><span><a href=\"#Annual-Income\" data-toc-modified-id=\"Annual-Income-1.2.2.2\"><span class=\"toc-item-num\">1.2.2.2&nbsp;&nbsp;</span>Annual Income</a></span></li><li><span><a href=\"#Age\" data-toc-modified-id=\"Age-1.2.2.3\"><span class=\"toc-item-num\">1.2.2.3&nbsp;&nbsp;</span>Age</a></span></li><li><span><a href=\"#Working-Years\" data-toc-modified-id=\"Working-Years-1.2.2.4\"><span class=\"toc-item-num\">1.2.2.4&nbsp;&nbsp;</span>Working Years</a></span></li><li><span><a href=\"#Famliy-Size\" data-toc-modified-id=\"Famliy-Size-1.2.2.5\"><span class=\"toc-item-num\">1.2.2.5&nbsp;&nbsp;</span>Famliy Size</a></span></li></ul></li><li><span><a href=\"#Categorical-Features\" data-toc-modified-id=\"Categorical-Features-1.2.3\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>Categorical Features</a></span><ul class=\"toc-item\"><li><span><a href=\"#Income-Type\" data-toc-modified-id=\"Income-Type-1.2.3.1\"><span class=\"toc-item-num\">1.2.3.1&nbsp;&nbsp;</span>Income Type</a></span></li><li><span><a href=\"#Occupation-Type\" data-toc-modified-id=\"Occupation-Type-1.2.3.2\"><span class=\"toc-item-num\">1.2.3.2&nbsp;&nbsp;</span>Occupation Type</a></span></li><li><span><a href=\"#House-Type\" data-toc-modified-id=\"House-Type-1.2.3.3\"><span class=\"toc-item-num\">1.2.3.3&nbsp;&nbsp;</span>House Type</a></span></li><li><span><a href=\"#Education\" data-toc-modified-id=\"Education-1.2.3.4\"><span class=\"toc-item-num\">1.2.3.4&nbsp;&nbsp;</span>Education</a></span></li><li><span><a href=\"#Marriage-Condition\" data-toc-modified-id=\"Marriage-Condition-1.2.3.5\"><span class=\"toc-item-num\">1.2.3.5&nbsp;&nbsp;</span>Marriage Condition</a></span></li></ul></li></ul></li><li><span><a href=\"#IV、WOE：Concept-and-Application\" data-toc-modified-id=\"IV、WOE：Concept-and-Application-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>IV、WOE：Concept and Application</a></span></li></ul></li><li><span><a href=\"#Algorithms\" data-toc-modified-id=\"Algorithms-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Algorithms</a></span><ul class=\"toc-item\"><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Logistic Regression</a></span></li><li><span><a href=\"#Decision-Tree\" data-toc-modified-id=\"Decision-Tree-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Decision Tree</a></span></li><li><span><a href=\"#Random-Forest\" data-toc-modified-id=\"Random-Forest-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Random Forest</a></span></li><li><span><a href=\"#SVM\" data-toc-modified-id=\"SVM-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>SVM</a></span></li><li><span><a href=\"#LightGBM\" data-toc-modified-id=\"LightGBM-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>LightGBM</a></span></li><li><span><a href=\"#Xgboost\" data-toc-modified-id=\"Xgboost-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Xgboost</a></span></li><li><span><a href=\"#Keras-Neural-Networks\" data-toc-modified-id=\"Keras-Neural-Networks-2.7\"><span class=\"toc-item-num\">2.7&nbsp;&nbsp;</span>Keras Neural Networks</a></span></li></ul></li></ul></div>","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"%matplotlib inline\n%config InlineBackend.figure_format = 'svg'","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import pandas as pd    \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pylab import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data = pd.read_csv(\"../input/application_record.csv\", encoding = 'utf-8') \nrecord = pd.read_csv(\"../input/credit_record.csv\", encoding = 'utf-8')  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.set_style('white') ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Response Variable","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# find all users' account open month.\nbegin_month=pd.DataFrame(record.groupby([\"ID\"])[\"MONTHS_BALANCE\"].agg(min))\nbegin_month=begin_month.rename(columns={'MONTHS_BALANCE':'begin_month'}) \nnew_data=pd.merge(data,begin_month,how=\"left\",on=\"ID\") #merge to record data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Generally, users in risk should be in 3%, thus I choose users who overdue for more than 60 days as target risk users. Those samples are marked as '1', else are '0'.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"record['dep_value'] = None\nrecord['dep_value'][record['STATUS'] =='2']='Yes' \nrecord['dep_value'][record['STATUS'] =='3']='Yes' \nrecord['dep_value'][record['STATUS'] =='4']='Yes' \nrecord['dep_value'][record['STATUS'] =='5']='Yes' ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"cpunt=record.groupby('ID').count()\ncpunt['dep_value'][cpunt['dep_value'] > 0]='Yes' \ncpunt['dep_value'][cpunt['dep_value'] == 0]='No' \ncpunt = cpunt[['dep_value']]\nnew_data=pd.merge(new_data,cpunt,how='inner',on='ID')\nnew_data['target']=new_data['dep_value']\nnew_data.loc[new_data['target']=='Yes','target']=1\nnew_data.loc[new_data['target']=='No','target']=0","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(cpunt['dep_value'].value_counts())\ncpunt['dep_value'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Features","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"+ rename ","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"new_data.rename(columns={'CODE_GENDER':'Gender','FLAG_OWN_CAR':'Car','FLAG_OWN_REALTY':'Reality',\n                         'CNT_CHILDREN':'ChldNo','AMT_INCOME_TOTAL':'inc',\n                         'NAME_EDUCATION_TYPE':'edutp','NAME_FAMILY_STATUS':'famtp',\n                        'NAME_HOUSING_TYPE':'houtp','FLAG_EMAIL':'email',\n                         'NAME_INCOME_TYPE':'inctp','FLAG_WORK_PHONE':'wkphone',\n                         'FLAG_PHONE':'phone','CNT_FAM_MEMBERS':'famsize',\n                        'OCCUPATION_TYPE':'occyp'\n                        },inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"new_data.dropna()\nnew_data = new_data.mask(new_data == 'NULL').dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ivtable=pd.DataFrame(new_data.columns,columns=['variable'])\nivtable['IV']=None\nnamelist = ['FLAG_MOBIL','begin_month','dep_value','target','ID']\n\nfor i in namelist:\n    ivtable.drop(ivtable[ivtable['variable'] == i].index, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"+ Define `calc_iv` function to [calculate](https://www.kaggle.com/puremath86/iv-woe-starter-for-python) Information Value and WOE Value","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Binary Features","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.set_style(\"whitegrid\") ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Calculate information value\ndef calc_iv(df, feature, target, pr=False):\n    lst = []\n    df[feature] = df[feature].fillna(\"NULL\")\n\n    for i in range(df[feature].nunique()):\n        val = list(df[feature].unique())[i]\n        lst.append([feature,                                                        # Variable\n                    val,                                                            # Value\n                    df[df[feature] == val].count()[feature],                        # All\n                    df[(df[feature] == val) & (df[target] == 0)].count()[feature],  # Good (think: Fraud == 0)\n                    df[(df[feature] == val) & (df[target] == 1)].count()[feature]]) # Bad (think: Fraud == 1)\n\n    data = pd.DataFrame(lst, columns=['Variable', 'Value', 'All', 'Good', 'Bad'])\n    data['Share'] = data['All'] / data['All'].sum()\n    data['Bad Rate'] = data['Bad'] / data['All']\n    data['Distribution Good'] = (data['All'] - data['Bad']) / (data['All'].sum() - data['Bad'].sum())\n    data['Distribution Bad'] = data['Bad'] / data['Bad'].sum()\n    data['WoE'] = np.log(data['Distribution Good'] / data['Distribution Bad'])\n    \n    data = data.replace({'WoE': {np.inf: 0, -np.inf: 0}})\n\n    data['IV'] = data['WoE'] * (data['Distribution Good'] - data['Distribution Bad'])\n\n    data = data.sort_values(by=['Variable', 'Value'], ascending=[True, True])\n    data.index = range(len(data.index))\n\n    if pr:\n        print(data)\n        print('IV = ', data['IV'].sum())\n\n    iv = data['IV'].sum()\n    print('This variable\\'s IV is:',iv)\n    print(df[feature].value_counts())\n    return iv, data","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def convert_dummy(df, feature,rank=0):\n    pos = pd.get_dummies(df[feature], prefix=feature)\n    mode = df[feature].value_counts().index[rank]\n    biggest = feature + '_' + str(mode)\n    pos.drop([biggest],axis=1,inplace=True)\n    df.drop([feature],axis=1,inplace=True)\n    df=df.join(pos)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def get_category(df, col, binsnum, labels, qcut = False):\n    if qcut:\n        localdf = pd.qcut(df[col], q = binsnum, labels = labels) # quantile cut\n    else:\n        localdf = pd.cut(df[col], bins = binsnum, labels = labels) # equal-length cut\n        \n    localdf = pd.DataFrame(localdf)\n    name = 'gp' + '_' + col\n    localdf[name] = localdf[col]\n    df = df.join(localdf[name])\n    df[name] = df[name].astype(object)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        \n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Gender","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"new_data['Gender'] = new_data['Gender'].replace(['F','M'],[0,1])\nprint(new_data['Gender'].value_counts())\niv, data = calc_iv(new_data,'Gender','target')\nivtable.loc[ivtable['variable']=='Gender','IV']=iv\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Having a car or not","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"new_data['Car'] = new_data['Car'].replace(['N','Y'],[0,1])\nprint(new_data['Car'].value_counts())\niv, data=calc_iv(new_data,'Car','target')\nivtable.loc[ivtable['variable']=='Car','IV']=iv\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Having house reality or not","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"new_data['Reality'] = new_data['Reality'].replace(['N','Y'],[0,1])\nprint(new_data['Reality'].value_counts())\niv, data=calc_iv(new_data,'Reality','target')\nivtable.loc[ivtable['variable']=='Reality','IV']=iv\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Having a phone or not","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"new_data['phone']=new_data['phone'].astype(str)\nprint(new_data['phone'].value_counts(normalize=True,sort=False))\nnew_data.drop(new_data[new_data['phone'] == 'nan' ].index, inplace=True)\niv, data=calc_iv(new_data,'phone','target')\nivtable.loc[ivtable['variable']=='phone','IV']=iv\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Having an email or not","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"print(new_data['email'].value_counts(normalize=True,sort=False))\nnew_data['email']=new_data['email'].astype(str)\niv, data=calc_iv(new_data,'email','target')\nivtable.loc[ivtable['variable']=='email','IV']=iv\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Having a Work Phone or not","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"new_data['wkphone']=new_data['wkphone'].astype(str)\niv, data = calc_iv(new_data,'wkphone','target')\nnew_data.drop(new_data[new_data['wkphone'] == 'nan' ].index, inplace=True)\nivtable.loc[ivtable['variable']=='wkphone','IV']=iv\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Continuous Variables","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Children Numbers","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"new_data.loc[new_data['ChldNo'] >= 2,'ChldNo']='2More'\nprint(new_data['ChldNo'].value_counts(sort=False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"iv, data=calc_iv(new_data,'ChldNo','target')\nivtable.loc[ivtable['variable']=='ChldNo','IV']=iv\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"new_data = convert_dummy(new_data,'ChldNo')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Annual Income\nbins the data based on sample quantiles","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"new_data['inc']=new_data['inc'].astype(object)\nnew_data['inc'] = new_data['inc']/10000 \nprint(new_data['inc'].value_counts(bins=10,sort=False))\nnew_data['inc'].plot(kind='hist',bins=50,density=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"new_data = get_category(new_data,'inc', 3, [\"low\",\"medium\", \"high\"], qcut = True)\niv, data = calc_iv(new_data,'gp_inc','target')\nivtable.loc[ivtable['variable']=='inc','IV']=iv\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"new_data = convert_dummy(new_data,'gp_inc')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Age\nBucketing Continuous Variables","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"new_data['Age']=-(new_data['DAYS_BIRTH'])//365\t\nprint(new_data['Age'].value_counts(bins=10,normalize=True,sort=False))\nnew_data['Age'].plot(kind='hist',bins=20,density=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"new_data = get_category(new_data,'Age',5, [\"lowest\",\"low\",\"medium\",\"high\",\"highest\"])\niv, data = calc_iv(new_data,'gp_Age','target')\nivtable.loc[ivtable['variable']=='DAYS_BIRTH','IV'] = iv\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"new_data = convert_dummy(new_data,'gp_Age')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Working Years\n+ Equal-length Bucketing","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"new_data['worktm']=-(new_data['DAYS_EMPLOYED'])//365\t\nnew_data[new_data['worktm']<0] = np.nan \nnew_data['DAYS_EMPLOYED']\nnew_data['worktm'].fillna(new_data['worktm'].mean(),inplace=True) \nnew_data['worktm'].plot(kind='hist',bins=20,density=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"new_data = get_category(new_data,'worktm',5, [\"lowest\",\"low\",\"medium\",\"high\",\"highest\"])\niv, data=calc_iv(new_data,'gp_worktm','target')\nivtable.loc[ivtable['variable']=='DAYS_EMPLOYED','IV']=iv\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"new_data = convert_dummy(new_data,'gp_worktm')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Famliy Size","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"new_data['famsize'].value_counts(sort=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"new_data['famsize']=new_data['famsize'].astype(int)\nnew_data['famsizegp']=new_data['famsize']\nnew_data['famsizegp']=new_data['famsizegp'].astype(object)\nnew_data.loc[new_data['famsizegp']>=3,'famsizegp']='3more'\niv, data=calc_iv(new_data,'famsizegp','target')\nivtable.loc[ivtable['variable']=='famsize','IV']=iv\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"new_data = convert_dummy(new_data,'famsizegp')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Categorical Features","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Income Type","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"print(new_data['inctp'].value_counts(sort=False))\nprint(new_data['inctp'].value_counts(normalize=True,sort=False))\nnew_data.loc[new_data['inctp']=='Pensioner','inctp']='State servant'\nnew_data.loc[new_data['inctp']=='Student','inctp']='State servant'\niv, data=calc_iv(new_data,'inctp','target')\nivtable.loc[ivtable['variable']=='inctp','IV']=iv\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"new_data = convert_dummy(new_data,'inctp')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Occupation Type","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"new_data.loc[(new_data['occyp']=='Cleaning staff') | (new_data['occyp']=='Cooking staff') | (new_data['occyp']=='Drivers') | (new_data['occyp']=='Laborers') | (new_data['occyp']=='Low-skill Laborers') | (new_data['occyp']=='Security staff') | (new_data['occyp']=='Waiters/barmen staff'),'occyp']='Laborwk'\nnew_data.loc[(new_data['occyp']=='Accountants') | (new_data['occyp']=='Core staff') | (new_data['occyp']=='HR staff') | (new_data['occyp']=='Medicine staff') | (new_data['occyp']=='Private service staff') | (new_data['occyp']=='Realty agents') | (new_data['occyp']=='Sales staff') | (new_data['occyp']=='Secretaries'),'occyp']='officewk'\nnew_data.loc[(new_data['occyp']=='Managers') | (new_data['occyp']=='High skill tech staff') | (new_data['occyp']=='IT staff'),'occyp']='hightecwk'\nprint(new_data['occyp'].value_counts())\niv, data=calc_iv(new_data,'occyp','target')\nivtable.loc[ivtable['variable']=='occyp','IV']=iv\ndata.head()         ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"new_data = convert_dummy(new_data,'occyp')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### House Type","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"iv, data=calc_iv(new_data,'houtp','target')\nivtable.loc[ivtable['variable']=='houtp','IV']=iv\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"new_data = convert_dummy(new_data,'houtp')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Education","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"new_data.loc[new_data['edutp']=='Academic degree','edutp']='Higher education'\niv, data=calc_iv(new_data,'edutp','target')\nivtable.loc[ivtable['variable']=='edutp','IV']=iv\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"new_data = convert_dummy(new_data,'edutp')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"####  Marriage Condition","execution_count":null},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"new_data['famtp'].value_counts(normalize=True,sort=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"iv, data=calc_iv(new_data,'famtp','target')\nivtable.loc[ivtable['variable']=='famtp','IV']=iv\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"new_data = convert_dummy(new_data,'famtp')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## IV、WOE：Concept and Application","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Weight of Evidence(WoE):  \n\n$$wo{e_i} = \\ln {{{P_{yi}}} \\over {{P_{ni}}}} = \\ln {{{y_i}/{y_s}} \\over {{n_i}/{n_s}}}$$\n$wo{e_i}$ is the I category's WOE value. ${{P_{yi}}}$ is the proportion of the positive samples in this category to all positive samples.   ${{P_{ni}}}$ is the ratio of negative samples (${{n_i}}$) in this class to all negative samples (${{n_s}}$).\n\nInformation Value (IV):  \n$$I{V_i} = ({P_{yi}} - {P_{ni}}) \\times wo{e_i}$$  \nThe IV values of the various types are the difference between the conditional positive rate and the conditional negative rate multiplied by the WOE value of the variable. The total IV value of the variable can be understood as the weighted sum of the conditional positive rate and the conditional negative rate difference:\n$$IV = \\sum\\limits_i^n {I{V_i}} $$  \n\nThe IV value measures the variable's ability to predict.\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Relationship between IV value and predictive power\n\n| IV| Ability to predict | \n|:------|:------:| \n| <0.02 | Almost no predictive power | \n|0.02~0.1 |weak predictive power|\n|0.1~0.3|Moderate predictive power|\n|0.3~0.5|Strong predictive power|\n|>0.5|Predictive power is too strong, need to check variables| ","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"ivtable=ivtable.sort_values(by='IV',ascending=False)\nivtable.loc[ivtable['variable']=='DAYS_BIRTH','variable']='agegp'\nivtable.loc[ivtable['variable']=='DAYS_EMPLOYED','variable']='worktmgp'\nivtable.loc[ivtable['variable']=='inc','variable']='incgp'\nivtable","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Algorithms","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"+ Split Dataset","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"new_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"Y = new_data['target']\nX = new_data[['Gender','Reality','ChldNo_1', 'ChldNo_2More','wkphone',\n              'gp_Age_high', 'gp_Age_highest', 'gp_Age_low',\n       'gp_Age_lowest','gp_worktm_high', 'gp_worktm_highest',\n       'gp_worktm_low', 'gp_worktm_medium','occyp_hightecwk', \n              'occyp_officewk','famsizegp_1', 'famsizegp_3more',\n       'houtp_Co-op apartment', 'houtp_Municipal apartment',\n       'houtp_Office apartment', 'houtp_Rented apartment',\n       'houtp_With parents','edutp_Higher education',\n       'edutp_Incomplete higher', 'edutp_Lower secondary','famtp_Civil marriage',\n       'famtp_Separated','famtp_Single / not married','famtp_Widow']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"+ Using Synthetic Minority Over-Sampling Technique(`SMOTE`) to overcome sample imbalance problem.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"Y = Y.astype('int')\nfrom imblearn.over_sampling import SMOTE\nX_balance,Y_balance = SMOTE().fit_sample(X,Y)\nX_balance = pd.DataFrame(X_balance, columns = X.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#conda install -c conda-forge imbalanced-learn","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#?SMOTE.fit_sample","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"+ After over sampling, the number between 1 and 0 is balanced. It can be seen from the confusion matrix.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_balance,Y_balance, \n                                                    stratify=Y_balance, test_size=0.3,\n                                                    random_state = 10086)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logistic Regression   \n\n$$\\log ({p \\over {1 - p}}) = {\\beta _0} + {\\beta _1}{x_1} +  \\cdot  \\cdot  \\cdot  + {\\beta _q}{x_q}$$","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.linear_model import LogisticRegression\n\nlogit = LogisticRegression(random_state=0, solver='lbfgs')\nclf = logit.fit(X_train, y_train)\ny_predict = clf.predict(X_test)\nprint('Accuracy Score is',accuracy_score(y_test, y_predict))\nprint(pd.DataFrame(confusion_matrix(y_test,y_predict)))\n\nsns.set_style(\"white\") \nclass_names = ['0','1']\nplot_confusion_matrix(confusion_matrix(y_test,y_predict),\n                      classes= class_names, normalize = True, \n                      title='Normalized Confusion Matrix: Logistic Regression')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Decision Tree","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier()\ndtfit = dt.fit(X_train, y_train)\ny_predict = dtfit.predict(X_test)\nprint('Accuracy Score is',accuracy_score(y_test, y_predict))\nprint(pd.DataFrame(confusion_matrix(y_test,y_predict)))\n\nplot_confusion_matrix(confusion_matrix(y_test,y_predict),\n                      classes=class_names, normalize = True, \n                      title='Normalized Confusion Matrix: CART')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest   \n\n\n\n<center>\n    <img style=\"border-radius: 0.3125em;\n    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n    src=\"https://d1rwhvwstyk9gu.cloudfront.net/2019/03/Random-Forest-Algorithm.jpg\">\n    <br>\n    <div style=\"color:orange; border-bottom: 1px solid #d9d9d9;\n    display: inline-block;\n    color: #999;\n    padding: 2px;\">Random Forest</div>\n</center>","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators=50)\nrffit = rf.fit(X_train, y_train)\ny_predict = rffit.predict(X_test)\nprint('Accuracy Score is',accuracy_score(y_test, y_predict))\nprint(pd.DataFrame(confusion_matrix(y_test,y_predict)))\n\nplot_confusion_matrix(confusion_matrix(y_test,y_predict),\n                      classes=class_names, normalize = True, \n                      title='Normalized Confusion Matrix: Ramdom Forests')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SVM\n\n\n<center>\n    <img style=\"border-radius: 0.3125em;\n    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n    src=\"https://i.loli.net/2019/11/13/fryWG5al7OPHDiA.gif\">\n    <br>\n    <div style=\"color:orange; border-bottom: 1px solid #d9d9d9;\n    display: inline-block;\n    color: #999;\n    padding: 2px;\">Support Vector Machine</div>\n</center>","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn import svm\nmodel = svm.SVC(kernel='linear', C = 1)\nsvmc = model.fit(X_train, y_train)\ny_predict = svmc.predict(X_test)\nprint('Accuracy Score is',accuracy_score(y_test, y_predict))\nprint(pd.DataFrame(confusion_matrix(y_test,y_predict)))\n\nplot_confusion_matrix(confusion_matrix(y_test,y_predict),\n                      classes=class_names, normalize = True, \n                      title='Normalized Confusion Matrix: SVM')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## LightGBM","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"I use Python API of LightGBM","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"from lightgbm import LGBMClassifier\nlgb = LGBMClassifier()\nlgbfit = lgb.fit(X_train, y_train)\ny_predict = lgbfit.predict(X_test)\nprint('Accuracy Score is',accuracy_score(y_test, y_predict))\nprint(pd.DataFrame(confusion_matrix(y_test,y_predict)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Showing important features:","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"import seaborn as sns\ndef plot_importance(classifer, x_train, point_size = 25):\n    '''plot feature importance'''\n    values = sorted(zip(x_train.columns, classifer.feature_importances_), key = lambda x: x[1] * -1)\n    imp = pd.DataFrame(values,columns = [\"Name\", \"Score\"])\n    imp.sort_values(by = 'Score',inplace = True)\n    sns.scatterplot(x = 'Score',y='Name', linewidth = 0,\n                data = imp,s = point_size, color='red').set(\n    xlabel='importance', \n    ylabel='features')\n    \nplot_importance(lgb, X_train,20)   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"lgb.booster_.feature_importance(importance_type='gain')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Xgboost","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"from xgboost import XGBClassifier\nxgb = XGBClassifier()\nxgbfit = xgb.fit(X_train, y_train)\ny_predict = xgbfit.predict(X_test)\nprint('Accuracy Score is',accuracy_score(y_test, y_predict))\nprint(pd.DataFrame(confusion_matrix(y_test,y_predict)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plot_importance(xgb, X_train, 20)   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Keras Neural Networks\n\nI use `add` to stack neural networks layers, the last one of them is activated by sigmoid function, which supports binary classification.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"from keras import models\nfrom keras import layers\nmodel = models.Sequential()\nmodel.add(layers.Dense(64, activation = 'relu', input_shape=(X_train.shape[1],)))\nmodel.add(layers.Dense(32, activation = 'relu'))\nmodel.add(layers.Dense(32, activation = 'relu'))\nmodel.add(layers.Dense(1, activation = 'sigmoid'))\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from keras import optimizers\nmodel.compile(optimizer=optimizers.RMSprop(lr=0.001),\n    loss='binary_crossentropy',\n    metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"history = model.fit(X_train, y_train,\n    epochs = 64,\n    batch_size = 128,\n    validation_data = (X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"history_dict = history.history\nloss_values = history_dict['accuracy']\nval_loss_values = history_dict['val_accuracy']\nepochs = range(1, len(loss_values) + 1)\ncv_info = pd.DataFrame({'epochs':epochs,'loss_values':loss_values,'val_loss_values':val_loss_values})\n\ncv_info = pd.melt(cv_info, id_vars=['epochs'], value_vars=['loss_values', 'val_loss_values'])\n\nfrom plotnine import *\n\n(\nggplot(cv_info,aes('epochs','value',color = 'variable')) +\ngeom_line() +\ngeom_point() +\nlabs(y = 'accuracy')\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The plot shows how classification accuracy value varies across every epochs of training. The validation and train accuracy have no big difference.\n\n","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}