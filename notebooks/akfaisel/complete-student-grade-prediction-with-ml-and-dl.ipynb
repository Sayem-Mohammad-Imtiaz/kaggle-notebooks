{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 1. Exploratory Data Analysis"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/student-grade-prediction/student-mat.csv\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum().any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are no null values in the dataset"},{"metadata":{},"cell_type":"markdown","source":"> ### Compare the two schools GP & MS with the score G3 "},{"metadata":{"trusted":true},"cell_type":"code","source":"sc_gp = data[data['school']=='GP']['G3'].value_counts()\nsc_ms = data[data['school']=='MS']['G3'].value_counts()\nsc_df = pd.DataFrame([sc_gp, sc_ms], index=['School GP', 'School MS'])\nsc_df = sc_df.T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lineplot(data=sc_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above lineplot, School GP is outperforming School MS"},{"metadata":{},"cell_type":"markdown","source":"### Compare Age and Sex with G3"},{"metadata":{"trusted":true},"cell_type":"code","source":"fg, axs = plt.subplots(1, 2, figsize=(20,5))\n\naxs[0].set_title('Distribution of Age & Sex wrt Score G3')\nsns.barplot(x='age', y='G3', hue='sex', data=data, ax=axs[0])\n\naxs[1].set_title('Distribution of count of Age & Sex')\nsns.countplot(x='age', hue='sex', data=data, ax=axs[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We do not get much information from Age and Sex"},{"metadata":{},"cell_type":"markdown","source":"### Compare family (father & mother) eduction with G3"},{"metadata":{"trusted":true},"cell_type":"code","source":"fam_edu = data['Fedu'] + data['Medu']\nsns.swarmplot(x=fam_edu, y='G3', data=data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Students having good family education background are performing better."},{"metadata":{},"cell_type":"markdown","source":"### Compare travel and study time with G3"},{"metadata":{"trusted":true},"cell_type":"code","source":"fg, axs = plt.subplots(1, 2, figsize=(20,5))\n\naxs[0].set_title('Travel time wrt Score G3')\nsns.swarmplot(x='traveltime', y='G3', data=data, ax=axs[0])\n\naxs[1].set_title('Study time wrt Score G3')\nsns.swarmplot(x='studytime', y='G3', data=data, ax=axs[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Students living near the school have scoring better than the far students.\n* Students having more weekly study time (over 10hrs) are getting better score."},{"metadata":{},"cell_type":"markdown","source":"### Compare other features\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"fg, axs = plt.subplots(3,3, figsize=(20,15))\n\naxs[0,0].set_title('School Support vs G3')\nsns.swarmplot(x='schoolsup', y='G3', data=data, ax=axs[0,0])\naxs[0,0].set_xlabel('School Support')\n\naxs[0,1].set_title('Family Support vs G3')\nsns.swarmplot(x='famsup', y='G3', data=data, ax=axs[0,1])\naxs[0,1].set_xlabel('Family Support')\n\naxs[0,2].set_title('Paid for extra class vs G3')\nsns.swarmplot(x='paid', y='G3', data=data, ax=axs[0,2])\naxs[0,2].set_xlabel('Extra paid')\n\naxs[1,0].set_title('Extra-curricular activities vs G3')\nsns.swarmplot(x='activities', y='G3', data=data, ax=axs[1,0])\naxs[1,0].set_xlabel('Extra-curricular activities')\n\naxs[1,1].set_title('Nursery vs G3')\nsns.swarmplot(x='nursery', y='G3', data=data, ax=axs[1,1])\naxs[1,1].set_xlabel('Nursery')\n\naxs[1,2].set_title('Higher Education vs G3')\nsns.swarmplot(x='higher', y='G3', data=data, ax=axs[1,2])\naxs[1,2].set_xlabel('Higher Education')\n\naxs[2,0].set_title('Internet Access vs G3')\nsns.swarmplot(x='internet', y='G3', data=data, ax=axs[2,0])\naxs[2,0].set_xlabel('Internet Access')\n\naxs[2,1].set_title('Romantic Relation vs G3')\nsns.swarmplot(x='romantic', y='G3', data=data, ax=axs[2,1])\naxs[2,1].set_xlabel('Romantic Relation')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Students who doesn't have school support are showing negative trend.\n* Students who paid for extra classes are showing negative trend.\n* Students who went to nursery schools are performing better.\n* Students who with to proceed with higher eduction are performing better.\n* Students having internet access are performing better.\n* Students having no romantic relation are performing better."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets check the alcohol consumption\nalc = data['Dalc'] + data['Walc']\nsns.swarmplot(x=alc, y='G3', data=data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Students having more alcohol consumption has performing very poor."},{"metadata":{},"cell_type":"markdown","source":"### Probability Distribution of Grades"},{"metadata":{"trusted":true},"cell_type":"code","source":"fg, axs = plt.subplots(1, 3, figsize=(20, 5))\ng1 = sns.distplot(data['G1'], ax=axs[0])\ng2 = sns.distplot(data['G2'], ax=axs[1])\ng3 = sns.distplot(data['G3'], ax=axs[2])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Compare G1 and G2 with G3"},{"metadata":{"trusted":true},"cell_type":"code","source":"fg, axs = plt.subplots(2,2, figsize=(20,10))\nb1 = sns.lineplot(x='G1', y='G3', data=data, ax=axs[0,0])\nb2 = sns.scatterplot(x='G1', y='G3', data=data, ax=axs[0,1])\nb3 = sns.lineplot(x='G2', y='G3', data=data, ax=axs[1,0])\nb4 = sns.scatterplot(x='G2', y='G3', data=data, ax=axs[1,1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is a linear relation between G1&G3 and G2&G3"},{"metadata":{},"cell_type":"markdown","source":"### Students count"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='G3', data=data, order=data['G3'].value_counts().index)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Majority of the sudents has scored 10 in G3\n* Nearly 40 students has failed in G3"},{"metadata":{},"cell_type":"markdown","source":"# 2. Feature Engineering\nIn feature engineering, we convert the text values to numerical values to be readble by Machine Learning Algorithms."},{"metadata":{},"cell_type":"markdown","source":"### 2.1 Convert to numerical"},{"metadata":{"trusted":true},"cell_type":"code","source":"#school\nsch_map = {'GP':1, 'MS':2}\ndata['school'] = data['school'].map(sch_map)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sex\nsex_map = {'F':1, 'M':2}\ndata['sex'] = data['sex'].map(sex_map)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#address\nfmap = {'U':1, 'R':2}\ndata['address'] = data['address'].map(fmap)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#famsize\nfmap = {'LE3':1, 'GT3':2}\ndata['famsize'] = data['famsize'].map(fmap)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Pstatus\nfmap = {'T':1, 'A':2}\ndata['Pstatus'] = data['Pstatus'].map(fmap)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Mjob and Fjob\nfmap = {'services':1, 'at_home':2, 'teacher':3, 'health':4, 'other':5}\ndata['Mjob'] = data['Mjob'].map(fmap)\ndata['Fjob'] = data['Fjob'].map(fmap)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#reason\nfmap = {'course':1, 'home':2, 'reputation':3, 'other':4}\ndata['reason'] = data['reason'].map(fmap)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#guardian\nfmap = {'mother':1, 'father':2, 'other':3}\ndata['guardian'] = data['guardian'].map(fmap)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#schoolsup famsup paid\nfmap = {'yes':1, 'no':0}\ndata['schoolsup'] = data['schoolsup'].map(fmap)\ndata['famsup'] = data['famsup'].map(fmap)\ndata['paid'] = data['paid'].map(fmap)\ndata['activities'] = data['activities'].map(fmap)\ndata['nursery'] = data['nursery'].map(fmap)\ndata['higher'] = data['higher'].map(fmap)\ndata['internet'] = data['internet'].map(fmap)\ndata['romantic'] = data['romantic'].map(fmap)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.2 Feature Selection"},{"metadata":{},"cell_type":"markdown","source":"There are 33 columns in the dataset and this is going to be cumbersome for training our model. Let's train with best 15 columns only"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data.iloc[:, :32]\ny = data.iloc[:, -1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest, chi2\n\nk_best = SelectKBest(score_func=chi2, k=15)\nk_best.fit(X, y)\n\ndf_score = pd.Series(data=k_best.scores_, index=X.columns)\ndf_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_score.nlargest(15).plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the plot, absense, G2, G1 and failures are having best scores"},{"metadata":{},"cell_type":"markdown","source":"From the feature selection score, let us define X"},{"metadata":{},"cell_type":"markdown","source":"### 2.3 Heatmap correlation"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25, 10))\nsns.heatmap(data.corr(), annot=True, cmap='YlGnBu')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.corr()['G3'].nlargest(15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the heatmap plot, G1 & G2 are highly correlated with G3\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data[df_score.nlargest(15).index]\ny = data['G3']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.4 Splitting data into train and test"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, KFold, cross_val_score\n\nk_fold = KFold(n_splits=10, random_state=10, shuffle=True)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Machine Learning Algorithm"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import GradientBoostingRegressor\n\nfrom sklearn.metrics import mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.1 Find the scores"},{"metadata":{"trusted":true},"cell_type":"code","source":"classifiers = {\n    'Linear Regression' : LinearRegression(),\n    'Lasso': Lasso(),\n    'Ridge': Ridge(),\n    'ElasticNet': ElasticNet(),\n    'RandromForest': RandomForestRegressor(n_estimators=100),\n    'GradientBoost': GradientBoostingRegressor(n_estimators=100),\n    'SVM' : SVR()\n}\n\nfor key, clf in classifiers.items():\n    #clf.fit(X_train, y_train)\n    score = cross_val_score(clf, X_train, y_train, cv=k_fold, scoring='neg_mean_squared_error')\n    rmse = np.sqrt(-score)\n    rmse_score = round(np.mean(rmse), 2)\n    print('RMSE score with CV of {0} is {1}'.format(key, rmse_score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above, GradientBoostRegressor is giving lesser error 1.66 with CV compared to other algorithms"},{"metadata":{},"cell_type":"markdown","source":"### 3.2 Hyper parameter tuning using GridSearchCV"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nclf = GradientBoostingRegressor()\nparams = {\n    'min_samples_split':[5,9,13],'max_leaf_nodes':[3,5,7,9],'max_features':[4,5,6,7]\n}\ngs = GridSearchCV(estimator=clf, param_grid=params, cv=k_fold, scoring='neg_mean_squared_error')\ngs.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gs.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.sqrt(-gs.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gb_clf = gs.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gb_clf.fit(X_train, y_train)\ny_predict = gb_clf.predict(X_test)\n\nmse = mean_squared_error(y_test, y_predict)\nrmse = np.sqrt(mse)\nrmse","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"GradientBoostingRegressor is giving RMSE of **1.89** with hyper parameter tuning"},{"metadata":{},"cell_type":"markdown","source":"# 4. Deep Learning with Keras"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras import backend\ndef build_regressor():\n    regressor = Sequential()\n    \n    regressor.add(Dense(units=15, input_dim=15, activation='relu'))\n    regressor.add(Dense(units=32, activation='relu'))\n    regressor.add(Dense(units=1))\n    \n    regressor.compile(optimizer='adam', loss='mean_squared_error',  metrics=['mae'])\n    return regressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.wrappers.scikit_learn import KerasRegressor\nregressor = KerasRegressor(build_fn=build_regressor, batch_size=20, epochs=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scale the train and test data before training the model\nfrom sklearn.preprocessing import StandardScaler\n\nss = StandardScaler()\nX_train = ss.fit_transform(X_train)\ny_train = ss.fit_transform(np.array(y_train).reshape(-1, 1))\n\nX_test = ss.fit_transform(X_test)\ny_test = ss.fit_transform(np.array(y_test).reshape(-1,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results=regressor.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = regressor.predict(X_test)\nmse = mean_squared_error(y_test, y_pred)\nrmse = np.sqrt(mse)\nrmse","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RMSE error from Keras is 0.58 but this error is nearly 1.96 in Machine Learning\n\n**RMSE:\nKeras: 0.58\nML: 1.96**"},{"metadata":{},"cell_type":"markdown","source":"I'm a beginner to Data Science. If you like my kernal, please support me by Upvoting it.\n\nThanks in advance."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}