{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport sklearn\nimport pandas_profiling as pp\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.metrics import accuracy_score, classification_report, roc_curve,precision_recall_curve, auc,confusion_matrix\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.svm import SVC\nfrom sklearn.impute import KNNImputer\n\nfrom xgboost import XGBClassifier\n\nfrom catboost import CatBoostClassifier","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv')\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop('id', axis=1)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['bmi'].fillna(df['bmi'].mean(), inplace = True) #Filled empty bmi with mean value","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sizes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels =df['stroke'].value_counts(sort = True).index\nsizes = df['stroke'].value_counts(sort = True)\n\ncolors = [\"lightblue\",\"red\"]\nexplode = (0.05,0) \n \nplt.figure(figsize=(7,7))\nplt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=90,)\n\nplt.title('Number of stroke in the dataset')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_smote","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sizes = y_smote.value_counts(sort = True)\ncolors = [\"lightblue\",\"red\"]\nexplode = (0.05,0) \n \nplt.figure(figsize=(7,7))\nplt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=90,)\n\nplt.title('Number of stroke in the dataset')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#****************\nen_df = df.copy()\nen_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"smoke_to_int = {\n    'never smoked': 0,\n    'formerly smoked': 1,\n    'smokes': 2,\n    'Unknown': -1\n}\nen_df['smoking_status'] = [smoke_to_int[s] for s in en_df['smoking_status']]\nen_df.head()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"work_to_int = {\n    'Private': 1,\n    'Self-employed': 2,\n    'Govt_job': 3,\n    'children': 4,\n    'Never_worked': 0\n}\nen_df['work_type'] = [work_to_int[s] for s in en_df['work_type']]\nen_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"en_df['gender'] = [int(m) for m in en_df['gender'] == 'Female']\nen_df['Residence_type'] = [int(r) for r in en_df['Residence_type'] == 'Urban']\nen_df['ever_married'] = [int(b) for b in en_df['ever_married'] == 'Yes']\nen_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  Using Lable encoding\n#le = LabelEncoder()\n#en_df = df.apply(le.fit_transform)\n#en_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pp.ProfileReport(en_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_hist(col, bins=30, title=\"\",xlabel=\"\",ax=None):\n    sns.distplot(col, bins=bins,ax=ax)\n    ax.set_title(f'Histogram of {title}',fontsize=20)\n    ax.set_xlabel(xlabel)\n    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(1,3,figsize=(11,7),constrained_layout=True)\nplot_hist(df.bmi,\n          title='Bmi',\n          xlabel=\"Level of the BMI\",\n          ax=axes[0])\nplot_hist(df.age,\n          bins=30,\n          title='Age',\n          xlabel='Age',\n          ax=axes[1])\nplot_hist(df.avg_glucose_level,\n          title='Serum Creatinine', \n          xlabel='Level of serum creatinine in the blood (mg/dL)',\n          ax=axes[2])\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.catplot(y=\"work_type\", hue=\"stroke\", kind=\"count\",\n            palette=\"pastel\", edgecolor=\".6\",\n            data=df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.catplot(y=\"smoking_status\", hue=\"stroke\", kind=\"count\",\n            palette=\"pastel\", edgecolor=\".6\",\n            data=df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(17,7))\nsns.catplot(x=\"gender\", y=\"stroke\", hue=\"heart_disease\", palette=\"pastel\", kind=\"bar\", data=df)\nsns.catplot(x=\"gender\", y=\"stroke\", hue=\"Residence_type\", palette=\"pastel\", kind=\"bar\", data=df)\nsns.catplot(x=\"gender\", y=\"stroke\", hue=\"hypertension\", palette=\"pastel\", kind=\"bar\", data=df)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len_data = len(df)\nlen_w = len(df[df[\"gender\"]==\"Male\"])\nlen_m = len_data - len_w\n\nmen_stroke = len(df.loc[(df[\"stroke\"]==1)&(df['gender']==\"Male\")])\nmen_no_stroke = len_m - men_stroke\n\nwomen_stroke = len(df.loc[(df[\"stroke\"]==1) & (df['gender']==\"Female\")])\nwomen_no_stroke = len_w - women_stroke\n\nlabels = ['Men with stroke','Men healthy','Women with stroke','Women healthy']\nvalues = [men_stroke, men_no_stroke, women_stroke, women_no_stroke]\n\nfig = go.Figure(data=[go.Pie(labels=labels, values=values,textinfo='label+percent',hole=0.4)])\nfig.update_layout(\n    title_text=\"Distribution of stroke EVENT according to their gender\")\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features=['gender', 'age', 'hypertension', 'heart_disease', 'ever_married',\n       'work_type', 'Residence_type',\n       'smoking_status']\nfrom matplotlib.offsetbox import AnchoredText\ncorrelation_table = []\nfor cols in features:\n    y = en_df[\"stroke\"]\n    x = en_df[cols]\n    corr = np.corrcoef(x, y)[1][0]\n    dict ={\n        'Features': cols,\n        'Correlation coefficient' : corr,\n        'Feat_type': 'numerical'\n    }\n    correlation_table.append(dict)\ndF1 = pd.DataFrame(correlation_table)\nfig = plt.figure(figsize=(10,6), facecolor='#EAECEE')\nax = sns.barplot(x=\"Correlation coefficient\", y=\"Features\", \n                     data=dF1.sort_values(\"Correlation coefficient\", ascending=False),\n                     palette='viridis', alpha=0.75)\nax.grid()\n#ax.set_title(\"Correlation of numerical features with Target\", fontsize=20, y=1.05)\n\ntitle =  'Correlation features with target'\nsub_title = 'In comparison with categorical features \\\n\\nnumericals are less correlated with target.'\n\nplt.gcf().text(0.05, 1.02, title, fontsize=24)\n#plt.gcf().text(0.05, 0.9, sub_title, fontsize=14)\n\nat1 = AnchoredText(sub_title,\n                   loc='lower left', frameon=True,\n                   bbox_to_anchor=(-0.1, 1.01),\n                   bbox_transform=ax.transAxes,\n                   #prop=dict(size=8),\n                   )\nat1.patch.set_boxstyle(\"round,pad=0.,rounding_size=0.2\")\nax.add_artist(at1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(16,8))\nsns.heatmap(en_df.corr(),cmap=\"Blues\");","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesClassifier\n\nX = en_df[features]\ny = en_df['stroke']\nforest = ExtraTreesClassifier(n_estimators=250,\n                              random_state=0)\nforest.fit(X, y)\nimportances = forest.feature_importances_\nstd = np.std([tree.feature_importances_ for tree in forest.estimators_],\n             axis=0)\nindices = np.argsort(importances)[::-1]\n\n# Print the feature ranking\nprint(\"Feature ranking:\")\n\nfor f in range(X.shape[1]):\n    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n\n    \n    \n# Plot the impurity-based feature importances of the forest\nplt.figure()\n\nplt.title(\"Feature importances\")\nsns.barplot(x=np.array(features)[indices], y=importances[indices], palette=\"deep\",yerr=std[indices])\nplt.xticks(range(X.shape[1]), np.array(features)[indices],rotation=60)\nplt.xlim([-1, X.shape[1]])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#en_df_imputed = en_df\n#imputer = KNNImputer(n_neighbors=4, weights=\"uniform\")\n#imputer.fit_transform(en_df_imputed)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#en_df_imputed.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#en_df_imputed.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# ## drop target variable for training\n# X = en_df.drop([\"stroke\"],axis = 1)\n# y = en_df.pop(\"stroke\")\n\n# ## data split\n# X_train, X_test,y_train,y_test = train_test_split(X, y,test_size=0.2,random_state=1)\n\n# ## SMOTE oversampling\n# SMOTE_oversample = SMOTE(random_state=1)\n# X_train,y_train = SMOTE_oversample.fit_resample(X_train, y_train.ravel())\nmodels_score = []\n\ndef plot_cm(cm,title):\n    z = cm\n    x = ['No stroke', 'stroke']\n    y = x\n    # change each element of z to type string for annotations\n    z_text = [[str(y) for y in x] for x in z]\n\n    # set up figure \n    fig = ff.create_annotated_heatmap(z, x=x, y=y, annotation_text=z_text, colorscale='deep')\n\n    # add title\n    fig.update_layout(title_text='<i><b>Confusion matrix {}</b></i>'.format(title),\n                      #xaxis = dict(title='x'),\n                      #yaxis = dict(title='x')\n                     )\n\n    # add custom xaxis title\n    fig.add_annotation({'font':{'color':\"black\",'size':14},\n                            'x':0.5,\n                            'y':-0.10,\n                            'showarrow':False,\n                            'text':\"Predicted value\",\n                            'xref':\"paper\",\n                            'yref':\"paper\"})\n    \n    fig.add_annotation({'font':{'color':\"black\",'size':14},\n                            'x':-0.15,\n                            'y':0.5,\n                            'showarrow':False,\n                            'text':\"Real value\",\n                            'textangle':-90,\n                            'xref':\"paper\",\n                            'yref':\"paper\"})\n\n\n    # adjust margins to make room for yaxis title\n    fig.update_layout(margin={'t':50, 'l':20},width=750,height=750)\n    \n\n\n    # add colorbar\n    fig['data'][0]['showscale'] = True\n    fig.show()\n\n    \n\nX , y = en_df[features],en_df[\"stroke\"]\n#data split to Training Set and Test Set\nx_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\nsm = SMOTE()\nx_smote, y_smote = sm.fit_resample(x_train,y_train)\n\ny_smote.value_counts()\nsns.histplot(y_smote)\n\n# labels =en_df['stroke'].value_counts(sort = True).index\n# sizes = en_df['stroke'].value_counts(sort = True)\n\n# colors = [\"lightblue\",\"red\"]\n# explode = (0.05,0) \n \n# plt.figure(figsize=(7,7))\n# plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=90,)\n\n# plt.title('Number of stroke in the dataset')\n# plt.show()\n\n# create object model\nbest_score = 0\nbest_model = None\nfor critetion in ['gini', 'entropy']:\n    for i in range(10, 301, 20):\n        RF_model = RandomForestClassifier(n_estimators=i, criterion=criterion)\n\n        # fit the model\n        RF_model.fit(x_train,y_train)\n\n        # model score\n        predict_train_RF = RF_model.predict(x_train)\n        predict_test_RF = RF_model.predict(x_test)\n        RF_test_score = RF_model.score(x_test,y_test)\n        if RF_test_score > best_score:\n            best_model = RF_model\n\n\n# accuracy score\nRF_train_score = RF_model.score(x_train,y_train)\n\ncm_model = confusion_matrix(y_test, predict_test_RF)\n\nprint(\"Random Forest model\")\nprint(cm_model)\nprint('Validation Acuuracy: ',accuracy_score(y_test,predict_test_RF))\nprint('Training Accuracy: ',accuracy_score(y_train, predict_train_RF))\nplot_cm(cm_model,title=\"Random Forest model\") #print Confusion Matrix \n\nmodels_score.append(accuracy_score(y_test,predict_test_RF))\n\n\n\n\n#----------------------------------------------\n\n\n\n# # create object model\n# SVC_model = SVC()\n\n# # fit the model\n# SVC_model.fit(x_train,y_train)\n\n# # model score\n# predict_train_SVC = SVC_model.predict(x_train)\n# predict_test_SVC = SVC_model.predict(x_test)\n\n# # accuracy score\n# SVM_train_score = SVC_model.score(x_train,y_train)\n# SVM_test_score = SVC_model.score(x_test,y_test)\n\n# cm_model1 = confusion_matrix(y_test, predict_test_SVC)\n\n# print(\"SVC model\")\n# print(cm_model1)\n# print('Validation Acuuracy: ',accuracy_score(y_test, predict_test_SVC))\n# print('Training Accuracy: ',accuracy_score(y_train, predict_train_SVC))\n# plot_cm(cm_model1,title=\"SVC model\") #print Confusion Matrix \n\n# models_score.append(accuracy_score(y_test,predict_test_SVC))\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def plot_cm(cm,title):\n#     z = cm\n#     x = ['No stroke', 'stroke']\n#     y = x\n#     # change each element of z to type string for annotations\n#     z_text = [[str(y) for y in x] for x in z]\n\n#     # set up figure \n#     fig = ff.create_annotated_heatmap(z, x=x, y=y, annotation_text=z_text, colorscale='deep')\n\n#     # add title\n#     fig.update_layout(title_text='<i><b>Confusion matrix {}</b></i>'.format(title),\n#                       #xaxis = dict(title='x'),\n#                       #yaxis = dict(title='x')\n#                      )\n\n#     # add custom xaxis title\n#     fig.add_annotation({'font':{'color':\"black\",'size':14},\n#                             'x':0.5,\n#                             'y':-0.10,\n#                             'showarrow':False,\n#                             'text':\"Predicted value\",\n#                             'xref':\"paper\",\n#                             'yref':\"paper\"})\n    \n#     fig.add_annotation({'font':{'color':\"black\",'size':14},\n#                             'x':-0.15,\n#                             'y':0.5,\n#                             'showarrow':False,\n#                             'text':\"Real value\",\n#                             'textangle':-90,\n#                             'xref':\"paper\",\n#                             'yref':\"paper\"})\n\n\n#     # adjust margins to make room for yaxis title\n#     fig.update_layout(margin={'t':50, 'l':20},width=750,height=750)\n    \n\n\n#     # add colorbar\n#     fig['data'][0]['showscale'] = True\n#     fig.show()\n\n\n\n# def hist_score(score):\n#     models_names = [\n#     'Random Forest Classifier',\n#     'SVM']\n\n#     plt.rcParams['figure.figsize']=20,8\n#     sns.set_style('darkgrid')\n#     ax = sns.barplot(x=models_names, y=score, palette = \"inferno\", saturation =2.0)\n#     plt.xlabel('Classifier Models', fontsize = 20 )\n#     plt.ylabel('% of Accuracy', fontsize = 20)\n#     plt.title('Accuracy of different Classifier Models on test set', fontsize = 20)\n#     plt.xticks(fontsize = 12, horizontalalignment = 'center', rotation = 8)\n#     plt.yticks(fontsize = 12)\n#     for i in ax.patches:\n#         width, height = i.get_width(), i.get_height()\n#         x, y = i.get_xy() \n#         ax.annotate(f'{round(height,2)}%', (x + width/2, y + height*1.02), ha='center', fontsize = 'x-large')\n#     plt.show()\n\n# def run_exp_on_feature(x_train,y_train,x_test,y_test):\n#     #x_train,x_test,y_train,y_test = train_test_split(features,labels, test_size=0.2, random_state=23)\n#     models= [['Random Forest Classifier ',RandomForestClassifier()],\n#             ['SVM ',SVC()]]\n# # n_estimators=estimators, criterion = criterion, random_state = 42\n# # for criterion in criterions:\n# #   for estimator in estimators:\n# #     models.append(randomforest(critertion=criterion, estimators=estimators)\n\n#     models_score = []\n#     for name,model in models:\n\n#         model = model\n# #         for i in range(10):\n#         model.fit(x_train,y_train)\n            \n#         model_pred = model.predict(x_test)\n#         cm_model = confusion_matrix(y_test, model_pred)\n#         print(cm_model)\n#         models_score.append( (y_test,model.predict(x_test)))\n\n#         print(name)\n#         print('Validation Acuuracy: ',accuracy_score(y_test,model.predict(x_test)))\n#         print('Training Accuracy: ',accuracy_score(y_train,model.predict(x_train)))\n#         print('############################################')\n#         plot_cm(cm_model,title=name+\"model\")\n#         fpr, tpr, thresholds = roc_curve(y_test, model_pred)\n        \n#     return models_score\n\n# models_score = run_exp_on_feature(x_train,y_train,x_test,y_test)\n\n# hist_score(models_score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split as tts\nimport tensorflow as tf\nfrom sklearn.metrics import accuracy_score\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#SPLITTING THE DATA INTO TRAINING AND TESTING DATA\nx_train,x_test,y_train,y_test_ann=tts(x,y,test_size=0.2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#CREATING ARTIFICIAL NEURAL NETWORK MODEL[ANN]\nann=tf.keras.Sequential()\n\nann.add(tf.keras.layers.Dense(units=25,activation='relu'))\n\nann.add(tf.keras.layers.Dense(units=25,activation='relu'))\n\nann.add(tf.keras.layers.Dense(units=1,activation='sigmoid'))\n\nann.compile('adam','binary_crossentropy',metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TRAINING ANN MODEL\nresult=ann.fit(x_train,y_train,epochs=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#CREATING CONFUSION MATRIX FOR THE ACTUAL AND PREDICTED VALUE\nfrom sklearn.metrics import confusion_matrix\ny_pred=[]\nfor i in ann.predict(x_test):\n    if i>0.5:\n        y_pred.append(1)\n    if i<0.5:\n        y_pred.append(0)\nconfusion_matrix(y_test_ann,y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ACCURACY SCORE FOR TESTING DATA\naccuracy=accuracy_score(y_test_ann,y_pred)\nprint('accuracy: ', accuracy)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models_score.append(accuracy_score(y_test_ann,y_pred))\n\ndef hist_score(score):\n    models_names = [\n    'Random Forest Classifier',\n    'SVM',\n    'ANN']\n\n    plt.rcParams['figure.figsize']=20,8\n    sns.set_style('darkgrid')\n    ax = sns.barplot(x=models_names, y=score, palette = \"inferno\", saturation =2.0)\n    plt.xlabel('Classifier Models', fontsize = 20 )\n    plt.ylabel('% of Accuracy', fontsize = 20)\n    plt.title('Accuracy of different Classifier Models on test set', fontsize = 20)\n    plt.xticks(fontsize = 12, horizontalalignment = 'center', rotation = 8)\n    plt.yticks(fontsize = 12)\n    for i in ax.patches:\n        width, height = i.get_width(), i.get_height()\n        x, y = i.get_xy() \n        ax.annotate(f'{round(height,2)}%', (x + width/2, y + height*1.02), ha='center', fontsize = 'x-large')\n    plt.show()\n    \nhist_score(models_score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from imblearn.over_sampling import SMOTE\n\n\n# X , y = en_df[features],en_df[\"stroke\"] #en_df_imputed[features],en_df_imputed[\"stroke\"]\n# x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=23)\n# sm = SMOTE()\n# X_res, y_res = sm.fit_resample(x_train,y_train)\n\n\n\n# def hist_score(score):\n#     models_names = [\n#     'Random Forest Classifier',\n#     'SVM',\n#     'ANN']\n\n#     plt.rcParams['figure.figsize']=20,8\n#     sns.set_style('darkgrid')\n#     ax = sns.barplot(x=models_names, y=score, palette = \"inferno\", saturation =2.0)\n#     plt.xlabel('Classifier Models', fontsize = 20 )\n#     plt.ylabel('% of Accuracy', fontsize = 20)\n#     plt.title('Accuracy of different Classifier Models on test set', fontsize = 20)\n#     plt.xticks(fontsize = 12, horizontalalignment = 'center', rotation = 8)\n#     plt.yticks(fontsize = 12)\n#     for i in ax.patches:\n#         width, height = i.get_width(), i.get_height()\n#         x, y = i.get_xy() \n#         ax.annotate(f'{round(height,2)}%', (x + width/2, y + height*1.02), ha='center', fontsize = 'x-large')\n#     plt.show()\n    \n\n# def run_exp_on_feature(x_train,y_train,x_test,y_test):\n#     #x_train,x_test,y_train,y_test = train_test_split(features,labels, test_size=0.2, random_state=23)\n#     models= [['Random Forest Classifier ',RandomForestClassifier()],\n#             ['SVM ',SVC()]]\n\n#     models_score = []\n#     for name,model in models:\n\n#         model = model\n#         model.fit(x_train,y_train)\n#         model_pred = model.predict(x_test)\n#         cm_model = confusion_matrix(y_test, model_pred)\n#         #print(cm_model)\n#         models_score.append(accuracy_score(y_test,model.predict(x_test)))\n\n#         fpr, tpr, thresholds = roc_curve(y_test, model_pred)\n        \n#     return models_score\n\n\n# models_score = run_exp_on_feature(x_train,y_train,x_test,y_test)\n\n# models_score.append(accuracy_score(y_test_ann,y_pred))\n\n# hist_score(models_score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}