{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import confusion_matrix\n\nfrom sklearn.utils import resample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils.np_utils import to_categorical\nfrom keras.layers import Convolution1D, MaxPool1D, Dense, Input, Flatten\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.models import Model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"root = '/kaggle/input/heartbeat/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(root+'mitbih_train.csv', header=None)\ntest_df = pd.read_csv(root+'mitbih_test.csv', header=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ['N': 0, 'S': 1, 'V': 2, 'F': 3, 'Q': 4]\n\n-N : Non-ecotic beats (normal beat) -S : Supraventricular ectopic beats -V : Ventricular ectopic beats -F : Fusion Beats -Q : Unknown Beats","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class_dist = train_df[187].astype(int).value_counts()\nclass_dist","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_dist.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 7))\np = class_dist.plot(kind='pie',\n                    labels=['N','S','V','F','Q'],\n                    autopct='%1.1f%%')\np.add_artist(plt.Circle((0,0), 0.7, color='white'))\nplt.title('Class Distribution')\nplt.legend()\nplt.show()\nplt.savefig('Origial Class Distribution.PNG')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_df_new\ndf_0 = train_df[train_df[187]==0].sample(n=20000, random_state=8)\ndf_1 = resample(train_df[train_df[187]==1], n_samples=20000,replace=True,\n                                           random_state=8)\ndf_2 = resample(train_df[train_df[187]==2], n_samples=20000,replace=True,\n                                           random_state=8)\ndf_3 = resample(train_df[train_df[187]==3], n_samples=20000,replace=True,\n                                           random_state=8)\ndf_4 = resample(train_df[train_df[187]==4], n_samples=20000,replace=True,\n                                           random_state=8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df_new = pd.concat([df_0, df_1, df_2, df_3, df_4])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 7))\np = train_df_new[187].value_counts().plot(kind='pie',\n                    labels=['N','S','V','F','Q'],\n                    autopct='%1.1f%%')\np.add_artist(plt.Circle((0,0), 0.7, color='white'))\nplt.title('Class Distribution: Post Random-Sampling')\nplt.legend()\nplt.show()\nplt.savefig('post random sampling class dist.PNG')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c = train_df_new.groupby(187, group_keys=False)\\\n        .apply(lambda train_df_new: train_df_new.sample(1))\nc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(5, 1, figsize=(16, 11))\n\nleg = iter(['N', 'S', 'V', 'F', 'U'])\ncolors = iter(['skyblue', 'red', 'lightgreen', 'orange', 'black'])\nfor i, ax in enumerate(axes.flatten()):\n    ax.plot(c.iloc[i, :186].T, color=next(colors))\n    ax.legend(next(leg))\nplt.title('Sample of different heart-beat types')\nplt.show()\nplt.savefig('heart beat sample.PNG')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_hist(class_num, min_val = 5, size = 70, title=''):\n    img = train_df_new.loc[train_df_new[187]==class_num].values\n    img = img[:, min_val: size]\n    img_flatten = img.flatten()\n\n    final1 = np.arange(min_val, size)\n    for _ in range(img.shape[0]-1):\n        tempo1 = np.arange(min_val, size)\n        final1 = np.concatenate((final1, tempo1))\n    print(len(final1))\n    print(len(img_flatten))\n    plt.hist2d(final1, img_flatten, bins=(80, 80), cmap=plt.cm.jet)\n    plt.title('2D Histogram- '+title)\n\n    plt.show()\n    plt.savefig('2D Histogram- '+title+'.PNG')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_hist(0, title='Normal Heart Beat')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_hist(1, 5, 50, title='Supraventricular ectopic beats')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_hist(2, 30, 70, title='Ventricular ectopic beats')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_hist(3, 20, 58, title='Fusion beats')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_hist(4, 15, 70, title='Unknown beats')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_gaussian_noise(signal):\n    noise = np.random.normal(0, 0.05, 186)\n    return signal+noise","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14, 7))\ntempo = c.iloc[0, :186]\nbruiter = add_gaussian_noise(tempo)\n\n# tempo\nplt.subplot(2,1,1)\nplt.plot(tempo)\n\nplt.title('ECG: BEFORE Gaussion noise additon')\n\n#bruiter\nplt.subplot(2,1,2)\nplt.plot(bruiter)\n\nplt.title('ECG: AFTER Gaussion noise additon')\n\n\nplt.show()\nplt.savefig('ECG Gaussian noise transformation.PNG')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data prepapration : Labels\ntarget_train = train_df_new[187]\ntarget_test = test_df[187]\n\ny_train = to_categorical(target_train)\ny_test = to_categorical(target_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data prepapration : Features\nX_train = train_df_new.iloc[:,:186].values[:,:, np.newaxis]\nX_test = test_df.iloc[:,:186].values[:,:, np.newaxis]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(X_train, y_train, X_test, y_test):\n    \n    # input signal image shape\n    im_shape = (X_train.shape[1], 1)\n    \n    # Input layer\n    inputs_cnn = Input(shape = (im_shape),\n                       name='inputs_cnn')\n    \n    # Block 1\n    conv1_1 = Convolution1D(64, (6), activation='relu',\n                            input_shape=im_shape)(inputs_cnn)\n    conv1_1 = BatchNormalization()(conv1_1)\n    \n    pool1 = MaxPool1D(pool_size=(3), strides=(2),\n                            padding='same')(conv1_1)\n    \n    # Block 2\n    conv2_1 = Convolution1D(64, (3), activation='relu',\n                            input_shape=im_shape)(pool1)\n    conv2_1 = BatchNormalization()(conv2_1)\n    \n    pool2 = MaxPool1D(pool_size=(3), strides=(2),\n                    padding='same')(conv2_1)\n\n    # Block 3\n    conv3_1 = Convolution1D(64, (3), activation='relu',\n                            input_shape=im_shape)(pool2)\n    conv3_1 = BatchNormalization()(conv3_1)\n    \n    pool3 = MaxPool1D(pool_size=(3), strides=(2),\n                            padding='same')(conv3_1)\n    # Flatten\n    flatten = Flatten()(pool3)\n    \n    # Dense Block\n    dense1 = Dense(64, activation='relu')(flatten)\n    dense2 = Dense(32, activation='relu')(dense1)\n    \n    # Output Block\n    output = Dense(5, activation='softmax', name='output')(dense2)\n    \n    # compile model\n    model = Model(inputs= inputs_cnn, outputs= output)\n    model.compile(optimizer='adam', loss='categorical_crossentropy',\n                 metrics=['accuracy'])\n    \n    callbacks = [EarlyStopping(monitor='val_loss', patience=8),\n                ModelCheckpoint(filepath='best_model.h5',\n                                monitor='val_loss',\n                                save_best_only=True)]\n    # training\n    print('Training...')\n    history=model.fit(X_train, y_train, epochs=40, batch_size=32,\n                      validation_data=(X_test, y_test),\n                      callbacks=callbacks)\n    \n    model.load_weights('best_model.h5')\n    \n    return (model, history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate_model(history, X_test, y_test, model):\n    scores = model.evaluate((X_test), y_test, verbose=0)\n    print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n    \n    print(history)\n    fig1, ax_acc = plt.subplots()\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.title('Model - Accuracy')\n    plt.legend(['Training', 'Validation'], loc='lower right')\n    plt.show()\n    \n    fig2, ax_loss = plt.subplots()\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.title('Model - Loss')\n    plt.legend(['Training', 'Validation'], loc='upper right')\n    plt.show()\n    plt.savefig('step evalutaion.PNG')\n    target_names = [str(i) for i in range(5)]\n    \n    y_true = []\n    for element in y_test:\n        y_true.append(np.argmax(element))\n    prediction_proba = model.predict(X_test)\n    prediction = np.argmax(prediction_proba, axis=1)\n    cnf_matrix = confusion_matrix(y_true, prediction)\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model, history = train_model(X_train, y_train, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluate_model(history, X_test, y_test, model)\ny_pred = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.arange(len(y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_clean = np.zeros_like(y_pred)\nfor idx, i in enumerate(np.argmax(y_pred,axis=1)):\n    y_pred_clean[idx][i] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_pred_clean))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"conf_matrix = confusion_matrix(np.argmax(y_test, axis=1), np.argmax(y_pred_clean, axis=1))\nprint(conf_matrix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 7))\nsns.heatmap(np.corrcoef(conf_matrix))\nplt.title('Confusion Matrix Corrleation-Coefficient')\nplt.savefig('Confusion Matrix Correlation Coefficient.png')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}