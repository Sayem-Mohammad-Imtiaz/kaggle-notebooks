{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport pandas as pd\nprint(os.listdir(\"../input\"))\nimport matplotlib.pyplot as plt\n# Any results you write to the current directory are saved as output.\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Import the Dataset**\n\nThe dataset will be treated as a normal text file. Each row will be divided by the use of \"\\n\" escape and every sample will be extracted by the use of \",\" separator in the split function. Also, Genres datas will be converted from string to int (0 is male, 1 is female)."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data=pd.read_csv('../input/Mall_Customers.csv')\n#read csv for analysis\n   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Dataframe visualization**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Data Cleaning**\nAt this point, we can start to clean the data. First of all removing all no-meaning value e.g. 0 values"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndata.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see there are not null values in all columns. Let's check data type in order to remove wrong values"},{"metadata":{"trusted":true},"cell_type":"code","source":"#data type control\ndata.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The result shows that every column has only a single value type. "},{"metadata":{},"cell_type":"markdown","source":"# Exploration Data Analysis\n\nAt this point we can check the correlation among columns in order to find useful patterns. First of all we need to drop the colum Customer ID that has not meanining in our analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"data=data.drop(['CustomerID'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(data.corr(),annot=True,fmt='.1f')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"At this point, we can see that each variable appear related only with itself. Let's visualize the data. "},{"metadata":{"trusted":true},"cell_type":"code","source":"       fig,axs = plt.subplots(3,figsize=(15,15) ,sharey=True)\n       # the histogram of the data\n       axs[0].hist(data.iloc[:,1])\n       axs[0].set_xlabel('Age')\n       axs[0].set_ylabel('No. of Customers')\n       axs[1].hist(data.iloc[:,2])\n       axs[1].set_xlabel('Annual Income')\n       axs[1].set_ylabel('No. of Customers')\n       axs[2].hist(data.iloc[:,3])\n       axs[2].set_xlabel('Spending Score')\n       axs[2].set_ylabel('No. of Customers')\n       plt.tight_layout()\n       plt.show()\n       ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = 'Man', 'woman'\nunique, counts = np.unique(data.iloc[:,0], return_counts=True)\nidx=dict(zip(unique, counts))\nsizes = [idx['Male'],idx['Female']]\ncolors = ['blue', 'pink']   \n# Plot\nplt.pie(sizes, labels=labels, colors=colors,autopct='%1.1f%%', shadow=True, startangle=140)\n       \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#total age\nprint(\"##### Anlysis on Total Age #####\")\nprint(\"Max :\",max(data.iloc[:,1]))\nprint(\"Min :\",min(data.iloc[:,1]))\nprint(\"Mean :\",np.mean(data.iloc[:,1]))\nprint(\"Std :\",np.std(data.iloc[:,1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Male age\nprint(\"##### Anlysis on Male Age #####\")\ntemp=[]\nindex=np.where(data.iloc[:,0]==\"Male\")\nindex[0]\nfor i in index[0]:\n    temp.append(data.iloc[i,1])\ntemp\nprint(\"Max :\",max(temp))\nprint(\"Min :\",min(temp))\nprint(\"Mean \",np.mean(temp))\nprint(\"Std :\",np.std(temp))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Female age\nprint(\"##### Anlysis on Female Age #####\")\ntemp=[]\nindex=np.where(data.iloc[:,0]==\"Female\")\nindex[0]\nfor i in index[0]:\n    temp.append(data.iloc[i,1])\ntemp\nprint(\"Max :\",max(temp))\nprint(\"Min :\",min(temp))\nprint(\"Mean :\",np.mean(temp))\nprint(\"Std :\",np.std(temp))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#total Annual Income\nprint(\"##### Anlysis on Total Annual Income #####\")\nprint(\"Max :\",max(data.iloc[:,2]))\nprint(\"Min :\",min(data.iloc[:,2]))\nprint(\"Mean :\",np.mean(data.iloc[:,2]))\nprint(\"Std :\",np.std(data.iloc[:,2]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Male Annual Income\nprint(\"##### Anlysis on Male Annual Income #####\")\ntemp=[]\nindex=np.where(data.iloc[:,0]==\"Male\")\nindex[0]\nfor i in index[0]:\n    temp.append(data.iloc[i,2])\ntemp\nprint(\"Max :\",max(temp))\nprint(\"Min :\",min(temp))\nprint(\"Mean :\",np.mean(temp))\nprint(\"Std :\",np.std(temp))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Female Annual Income\nprint(\"##### Anlysis on Female Annual Income #####\")\ntemp=[]\nindex=np.where(data.iloc[:,0]==\"Female\")\nindex[0]\nfor i in index[0]:\n    temp.append(data.iloc[i,2])\ntemp\nprint(\"Max :\",max(temp))\nprint(\"Min :\",min(temp))\nprint(\"Mean :\",np.mean(temp))\nprint(\"Std :\",np.std(temp))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#total Spending Score (1-100)\nprint(\"##### Anlysis on Total Spending Score (1-100) #####\")\nprint(\"Max :\",max(data.iloc[:,3]))\nprint(\"Min :\",min(data.iloc[:,3]))\nprint(\"Mean :\",np.mean(data.iloc[:,3]))\nprint(\"Std :\",np.std(data.iloc[:,3]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Male Spending Score (1-100)\nprint(\"##### Anlysis on Male Spending Score (1-100) #####\")\ntemp=[]\nindex=np.where(data.iloc[:,0]==\"Male\")\nindex[0]\nfor i in index[0]:\n    temp.append(data.iloc[i,3])\ntemp\nprint(\"Max :\",max(temp))\nprint(\"Min :\",min(temp))\nprint(\"Mean :\",np.mean(temp))\nprint(\"Std :\",np.std(temp))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Male Spending Score (1-100)\nprint(\"##### Anlysis on Female Spending Score (1-100) #####\")\ntemp=[]\nindex=np.where(data.iloc[:,0]==\"Female\")\nindex[0]\nfor i in index[0]:\n    temp.append(data.iloc[i,3])\ntemp\nprint(\"Max :\",max(temp))\nprint(\"Min :\",min(temp))\nprint(\"Mean :\",np.mean(temp))\nprint(\"Std :\",np.std(temp))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.plotting.scatter_matrix(data,figsize=(10,10))\nplt.figure()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(0,len(data.iloc[:,0])):\n    if data.iloc[i,0]==\"Male\":\n        data.iloc[i,0]=0\n    elif data.iloc[i,0]==\"Female\":\n        data.iloc[i,0]=1\n\ndata","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Dimensionality Reduction**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\npca=PCA().fit(data)\nprint(pca.explained_variance_ratio_)\nprint()\nprint(data.columns.values.tolist())\nprint(pca.components_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First two components seem to cover around 86% of the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"cumulative=np.cumsum(pca.explained_variance_ratio_)\nplt.step([i for i in range(len(cumulative))],cumulative)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This plot too shows that 85% of the data can be expressed by the first two principal components.\n\nSo, I will apply PCA to the data with number of components = 2.\n\nThe reduced data can be seen on the plotting below."},{"metadata":{"trusted":true},"cell_type":"code","source":"pca=PCA(n_components=2)\npca.fit(data)\nreduced_data=pca.transform(data)\ninverse_data=pca.inverse_transform(reduced_data)\nplt.scatter(reduced_data[:,0],reduced_data[:,1],label='reduced')\nplt.xlabel('First Principal Component')\nplt.ylabel('Second Principal Component')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reduced_data=pd.DataFrame(reduced_data,columns=['Dim1','Dim2'])\nreduced_data[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Algorithms**"},{"metadata":{},"cell_type":"markdown","source":"KMEANS"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\nsse={}\nfor i in range(2,11):\n    kmeans=KMeans(n_clusters=i,random_state=0)\n    result=kmeans.fit_predict(reduced_data)\n    sse[i] = kmeans.inertia_ # Inertia: Sum of distances of samples to their closest cluster center\n\n    plt.subplot(5,2,i-1)\n    plt.scatter(reduced_data.Dim1.values,reduced_data.Dim2.values,c=result)\n    plt.title(str(i)+' Clusters, SSE :'+ str(sse[i]))\n    fig,ax=plt.gcf(),plt.gca()\n    fig.set_size_inches(10,10)\n    plt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\nplt.plot(list(sse.keys()), list(sse.values()))\nplt.xlabel(\"Number of cluster\")\nplt.ylabel(\"SSE\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"5 cluster is the best division made in the dataset."},{"metadata":{},"cell_type":"markdown","source":"**DBSCAN**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import DBSCAN\n\nplot_id=0\nfor eps in np.arange(0.03,0.9,0.03):\n    for min_samples in range(3,9):\n        plot_id+=1\n        cl=DBSCAN(eps=eps,min_samples=min_samples)\n        result=cl.fit_predict(reduced_data)\n        n_clusters=len([c for c in list(set(result)) if c!=-1])\n        plt.subplot(6,4,plot_id)\n        plt.scatter(reduced_data.Dim1.values.tolist(),\n                   reduced_data.Dim2.values.tolist(),\n                   \n                   c=result)\n        fig,ax=plt.gcf(),plt.gca()\n        fig.set_size_inches(15,20)\n        plt.title('eps: ' + str(eps)+', min_smp: ' + str(min_samples)+',\\n# of clusters: ' + str(n_clusters))\n        plt.tight_layout()\nplt.show()\n    \n    \n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Hierarchical Clustering\n**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.cluster.hierarchy import linkage, dendrogram\nfrom scipy.cluster.hierarchy import fcluster\n\nmethods=['ward','single','complete','average','weighted','centroid','median']\n\nplot_id=0\nfor method in methods:\n    cl=linkage(reduced_data,method=method)\n    \n    for sw in ['dendrogram','clusters']:\n        if sw=='dendrogram':\n            plot_id+=1\n            plt.subplot(7,2,plot_id)\n            plt.title(method)\n            fig,ax=plt.gcf(),plt.gca()\n            dn=dendrogram(cl,truncate_mode='level',p=15)\n            plt.tight_layout()\n            fig.set_size_inches(10,15)\n        else:\n            plot_id+=1\n            labels=fcluster(cl,2,criterion='maxclust')\n            plt.subplot(7,2,plot_id)\n            plt.title(method)\n            plt.scatter(reduced_data.Dim1.values.tolist(),\n                       reduced_data.Dim2.values.tolist(),\n                                             c=labels)\nplt.show()            ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}