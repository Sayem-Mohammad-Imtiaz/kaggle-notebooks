{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\n#print(os.listdir(\"../input\"))\ncredit_data=pd.read_csv(\"../input/CC GENERAL.csv\")\ncredit_data.shape\ncredit_data.isnull().sum()\ncredit_data.dtypes\ncredit_data.drop(['CUST_ID'], axis=1, inplace=True)\nfrom sklearn.preprocessing import Imputer\nmean_imputer=Imputer(strategy='mean')\nimputed_credit_data=pd.DataFrame(mean_imputer.fit_transform(credit_data),columns=credit_data.columns)\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"imputed_credit_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nstandardizer=StandardScaler()\nstd_x=standardizer.fit_transform(imputed_credit_data)\nstd_credit_data=pd.DataFrame(std_x,columns=imputed_credit_data.columns)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"std_credit_data.describe","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"from sklearn.cluster import KMeans\nkmeans_object=KMeans(n_clusters=5,random_state=1234)\nkmeans_cluster=kmeans_object.fit_predict(std_credit_data)\nkmeans_object.labels_\ncluster_centroids = pd.DataFrame(standardizer.inverse_transform(kmeans_object.cluster_centers_),columns=credit_data.columns)\ncluster_centroids"},{"metadata":{"trusted":true},"cell_type":"code","source":"wss={}\nfor k in range(1,20):\n    kmeans_loop=KMeans(n_clusters=k,n_init=30,n_jobs=2,random_state=1000,verbose=0).fit(std_credit_data)\n    clusters = kmeans_loop.labels_\n    wss[k] = kmeans_loop.inertia_ # Inertia: Sum of squared distances of samples to their closest cluster center\nwss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wss.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wss.values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.figure()\n# %matplotlib notebook\n\nplt.plot(wss.keys(),wss.values(),marker='o')\n\n# plt.plot(list(wss.keys()),list(wss.values()))\nplt.grid()\nplt.xlabel('Number of clusters')\nplt.ylabel('Total within sum of squares')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from __future__ import print_function\n\n# from sklearn.datasets import make_blobs\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_samples, silhouette_score\n\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport numpy as np\n\n# plt.figure()\n\nprint(__doc__)\n\n### Just change this to your dataframe\nX_matrix = std_credit_data.as_matrix()\n\nrange_n_clusters = [3, 4, 5, 6, 7, 8, 9, 10, 11]\n\nfor n_clusters in range_n_clusters:\n    # Create a subplot with 1 row and 1 column\n    fig, (ax1) = plt.subplots(1, 1)\n    fig.set_size_inches(9, 5)\n\n    # The 1st subplot is the silhouette plot\n    # The silhouette coefficient can range from -1, +1 \n    \n    ax1.set_xlim([-0.25, .5])\n    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n    # plots of individual clusters, to demarcate them clearly.\n    \n    ax1.set_ylim([0, len(X_matrix) + (n_clusters + 1) * 10])\n\n    # Initialize the clusterer with n_clusters value and a random generator\n    # seed of 10 for reproducibility.\n    clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n    cluster_labels = clusterer.fit_predict(X_matrix)\n\n    # The silhouette_score gives the average value for all the samples.\n    # This gives a perspective into the density and separation of the formed\n    # clusters\n    silhouette_avg = silhouette_score(X_matrix, cluster_labels)\n\n    # Compute the silhouette scores for each sample\n    sample_silhouette_values = silhouette_samples(X_matrix, cluster_labels)\n\n    y_lower = 10\n    for i in range(n_clusters):\n        # Aggregate the silhouette scores for samples belonging to\n        # cluster i, and sort them\n        ith_cluster_silhouette_values = \\\n            sample_silhouette_values[cluster_labels == i]\n\n        ith_cluster_silhouette_values.sort()\n\n        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n        y_upper = y_lower + size_cluster_i\n\n        color = cm.nipy_spectral(float(i) / n_clusters)\n        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n                          0, ith_cluster_silhouette_values,\n                          facecolor=color, edgecolor=color, alpha=0.7)\n\n        # Label the silhouette plots with their cluster numbers at the middle\n        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n\n        # Compute the new y_lower for next plot\n        y_lower = y_upper + 10  # 10 for the 0 samples\n\n    ax1.set_title(\"The silhouette plot for the various clusters\")\n    ax1.set_xlabel(\"The silhouette coefficient values\")\n    ax1.set_ylabel(\"Cluster label\")\n\n    # The vertical line for average silhouette score of all the values\n    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n\n    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n\n    plt.suptitle((\"For %d clusters, silhouette avg coeff = %f \" % (n_clusters,silhouette_avg)),\n                 fontsize=14, fontweight='bold')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_kmeans = KMeans(n_clusters=3, random_state=1240)\nbest_kmeans.fit(std_credit_data)\nbest_kmeans_labels = best_kmeans.predict(std_credit_data)\nkmeans_results=pd.DataFrame(best_kmeans_labels)\nkmeans_results.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}