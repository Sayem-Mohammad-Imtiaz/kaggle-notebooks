{"cells":[{"metadata":{},"cell_type":"markdown","source":"Can we with some degree of acuracy predict which category or genre a book is from the title alone?"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport spacy\nnlp = spacy.load('en')\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Read data out into pandas dataframes\nraw_data_df = pd.read_csv('/kaggle/input/goodreads-10k-dataset-integrated/books_updated.csv')\n# we will take only the original tite, and tags column\ncolumns = ['original_title', 'tag_name']\ndf = raw_data_df[columns].copy()\n# we will remove any rows which have nan values or empty strings in the original title or tag names\ndf['original_title'].replace('', np.nan, inplace=True)\ndf['tag_name'].replace('', np.nan, inplace=True)\ndf.dropna(inplace=True) \ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get unique tag values\nunique_tags = [val.strip() for sublist in df['tag_name'].dropna().str.split(\",\").tolist() for val in sublist]\nprint(f'No. of unique tags {len(unique_tags)}, first 10 entries {unique_tags[0:10]}')\n# print count for each unique tag\ntags_summary = pd.DataFrame(unique_tags,columns=['tag_name']).value_counts().reset_index().rename(columns={0:'count'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tags_summary[0:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test = pd.DataFrame(unique_tags,columns=['tag_name'])\n# sns.countplot(x='tag_name',data=test[0:50])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We need to remove those that are not genres such as audio, toread etc 'fiction', 'fantasy', 'nonfiction',\nto_remove = ['library','audio', 'books', 'audiobook', 'read', 'tobuy', 'ebook', 'ya', 'ownedbooks', 'default', 'readin', 'kindle', 'bookclub', 'series', 'booksiown', 'owned', 'currentlyreading', 'favourites', 'favorites', 'ebooks', 'childrens', 'toread', 'audiobooks']\n# ya here I will assume is young adult and merge, same for childrens and children\nindex_names = []\nfor tag in to_remove:\n    indexes = (tags_summary[tags_summary['tag_name'] == tag ].index)\n    for index in indexes:\n        index_names.append(index)\n\ntags_summary.drop(index_names, inplace = True)\ngenres_as_list = tags_summary['tag_name'][0:30].tolist()\nprint(genres_as_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30,4))\nplt.bar('tag_name', 'count', data=tags_summary[50:150])\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now we can create a column for each genre and then assign a value if the book has been tagged as that genre\nfor genre in genres_as_list:\n    \n    df[genre] = df['tag_name'].map(lambda x: 1 if (genre in x) else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# great now we can remove the tag name column\ndf.drop(['tag_name'], axis=1, inplace=True)\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_data(df, split=0.9):\n    \n    # Shuffle data\n    train_data = df.sample(frac=1, random_state=7)\n    \n    texts = train_data['original_title']\n    y = train_data.drop(['original_title'], axis=1) # this leaves us with all the other columns\n    labels = y.to_dict('records')\n    split = int(len(train_data) * split)\n    \n    train_labels = [{\"cats\": labels} for labels in labels[:split]]\n    val_labels = [{\"cats\": labels} for labels in labels[split:]]\n    \n    return texts[:split], train_labels, texts[split:], val_labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_texts, train_labels, val_texts, val_labels = load_data(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Texts from training data\\n------')\nprint(train_texts[:2])\nprint('\\nLabels from training data\\n------')\nprint(train_labels[:2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create the TextCategorizer with exclusive classes and \"bow\" architecture\ntextcat = nlp.create_pipe(\n              \"textcat\",\n              config={\n                \"architecture\": \"bow\"})\n\n# Add the TextCategorizer to the empty model\nnlp.add_pipe(textcat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add labels to text classifier\nfor genre in genres_as_list:\n    textcat.add_label(genre)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from spacy.util import minibatch\nimport random\n\ndef train(model, train_data, optimizer):\n    losses = {}\n    random.seed(1)\n    random.shuffle(train_data)\n    \n    batches = minibatch(train_data, size=8)\n    for batch in batches:\n        # train_data is a list of tuples [(text0, label0), (text1, label1), ...]\n        # Split batch into texts and labels\n        texts, labels = zip(*batch)\n        \n        # Update model with texts and labels\n        model.update(texts, labels, sgd=optimizer, losses=losses)\n        \n    return losses","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fix seed for reproducibility\nspacy.util.fix_random_seed(1)\nrandom.seed(1)\n\n# This may take a while to run!\noptimizer = nlp.begin_training()\ntrain_data = list(zip(train_texts, train_labels))\nlosses = train(nlp, train_data, optimizer)\nprint(losses['textcat'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text = \"The girl with the dragon tattoo\"\ndoc = nlp(text)\nprint(doc.cats)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(nlp, texts): \n    # Use the model's tokenizer to tokenize each input text\n    docs = [nlp.tokenizer(text) for text in texts]\n    \n    # Use textcat to get the scores for each doc\n    textcat = nlp.get_pipe('textcat')\n    scores, _ = textcat.predict(docs)\n    # From the scores, find the class with the highest score/probability\n    predicted_class = scores.argmax(axis=1)\n    \n    return predicted_class","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"texts = val_texts[34:38]\npredictions = predict(nlp, texts)\n\nfor p, t in zip(predictions, texts):\n    print(f\"{textcat.labels[p]}: {t} \\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"texts = val_texts\npredictions = predict(nlp, texts)\n\ntrue_classes = [max(each['cats'], key=each['cats'].get) for each in val_labels] # this only takes one of the genres (the first on with 1)\n\ndef get_accuracry(predictions, true_classes):\n    correct_predictions = []\n\n    for p, c in zip(predictions, true_classes):\n        if textcat.labels[p] == c:\n            correct_predictions.append(1)\n        else:\n            correct_predictions.append(0)\n    \n    return sum(correct_predictions) / len(correct_predictions)\n\n\nprint(f'Accuracy: {get_accuracry(predictions, true_classes)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(model, texts, labels):\n    \"\"\" Returns the accuracy of a TextCategorizer model. \n    \n        Arguments\n        ---------\n        model: ScaPy model with a TextCategorizer\n        texts: Text samples, from load_data function\n        labels: True labels, from load_data function\n    \n    \"\"\"\n    # Get predictions from textcat model (using your predict method)\n    predicted_class = predict(model, texts)\n    # From labels, get the true class as a list of integers (POSITIVE -> 1, NEGATIVE -> 0)\n    # true_class = [max(each['cats'], key=each['cats'].get) for each in labels]\n    true_class = []\n    for label in labels:\n        true_classes_per_label = []\n        for cat in label['cats']:\n            if label['cats'][cat] == 1:\n                true_classes_per_label.append(cat)\n        true_class.append(true_classes_per_label)\n            \n    # A boolean or int array indicating correct predictions\n    correct_predictions = []\n    for p, c in zip(predicted_class, true_class):\n        correct_predictions.append(textcat.labels[p] in c)\n        \n    # The accuracy, number of correct predictions divided by all predictions\n    accuracy = sum(correct_predictions) / len(correct_predictions)\n    \n    return accuracy","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"TODO: clean rows that do not match**** any of the categories"},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = evaluate(nlp, val_texts, val_labels)\nprint(f\"Accuracy: {accuracy:.4f}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# doc = nlp(train_texts[0])\n\n# print(f\"Token \\t\\tLemma \\t\\tStopword\".format('Token', 'Lemma', 'Stopword'))\n# print(\"-\"*40)\n# for token in doc:\n#     print(f\"{str(token)}\\t\\t{token.lemma_}\\t\\t{token.is_stop}\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}