{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Pima Indians Diabetes"},{"metadata":{},"cell_type":"markdown","source":"# Breakdown of this notebook:\n1. **Importing Libraries**\n2. **Loading the dataset:** Load the data and import the libraries\n3. **Data Cleaning:** <br>\n - Deleting redundant columns.\n - Renaming the columns.\n - Dropping duplicates.\n - Cleaning individual columns.\n - Remove the NaN values from the dataset\n - Some Transformations\n3. **Traininig the Model**\n4. **Generate a Classification Report**"},{"metadata":{},"cell_type":"markdown","source":"<h3>Importing Libraries</h3>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import sys\nimport pandas as pd\nimport numpy as np\nimport sklearn\nimport matplotlib\nimport keras\n\nprint('Python: {}'.format(sys.version))\nprint('Pandas: {}'.format(pd.__version__))\nprint('Numpy: {}'.format(np.__version__))\nprint('Sklearn: {}'.format(sklearn.__version__))\nprint('Matplotlib: {}'.format(matplotlib.__version__))\n\n\nimport matplotlib.pyplot as plt\nfrom pandas.plotting import scatter_matrix","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Loading the Dataset**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df=pd.read_csv(\"../input/diabetes.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Describe the dataset\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**DataFrame where the Glucose concentration of a patient is pulled to 0**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['Glucose'] == 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Removing the Duplicates**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.duplicated().sum()\ndf.drop_duplicates(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Preprocess the data, mark zero values as NaN and drop**"},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n\nfor col in columns:\n    df[col].replace(0, np.NaN, inplace=True)\n    \ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Drop rows with missing values**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dropna(inplace=True)\n\n# summarize the number of rows and columns in df\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training the Model"},{"metadata":{},"cell_type":"markdown","source":"**Convert dataframe to numpy array**"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = df.values\nprint(dataset.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Split into input (X) and an output (Y)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = dataset[:,0:8]\nY = dataset[:, 8].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X.shape)\nprint(Y.shape)\nprint(Y[:5])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Normalize the data using sklearn StandardScaler**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler().fit(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(scaler)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Transform and display the training data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_standardized = scaler.transform(X)\n\ndata = pd.DataFrame(X_standardized)\ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Import necessary sklearn and keras packages**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV, KFold\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.optimizers import Adam","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Do a grid search for the optimal batch size and number of epochs**"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# Define a random seed\nseed = 6\nnp.random.seed(seed)\n\n# Start defining the model\ndef create_model():\n    # create model\n    model = Sequential()\n    model.add(Dense(8, input_dim = 8, kernel_initializer='normal', activation='relu'))\n    model.add(Dense(4, input_dim = 8, kernel_initializer='normal', activation='relu'))\n    model.add(Dense(1, activation='sigmoid'))\n    \n    # compile the model\n    adam = Adam(lr = 0.01)\n    model.compile(loss = 'binary_crossentropy', optimizer = adam, metrics = ['accuracy'])\n    return model\n\n# create the model\nmodel = KerasClassifier(build_fn = create_model, verbose = 1)\n\n# define the grid search parameters\nbatch_size = [10, 20, 40]\nepochs = [10, 50, 100]\n\n# make a dictionary of the grid search parameters\nparam_grid = dict(batch_size=batch_size, epochs=epochs)\n\n# build and fit the GridSearchCV\ngrid = GridSearchCV(estimator = model, param_grid = param_grid, cv = KFold(random_state=seed), verbose = 10)\ngrid_results = grid.fit(X_standardized, Y)\n\n# summarize the results\nprint(\"Best: {0}, using {1}\".format(grid_results.best_score_, grid_results.best_params_))\nmeans = grid_results.cv_results_['mean_test_score']\nstds = grid_results.cv_results_['std_test_score']\nparams = grid_results.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print('{0} ({1}) with: {2}'.format(mean, stdev, param))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Do a grid search to find the optimal number of neurons in each hidden layer**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# import necessary packages\n\n# Define a random seed\nseed = 6\nnp.random.seed(seed)\n\n# Start defining the model\ndef create_model(neuron1, neuron2):\n    # create model\n    model = Sequential()\n    model.add(Dense(neuron1, input_dim = 8, kernel_initializer= 'uniform', activation= 'linear'))\n    model.add(Dense(neuron2, input_dim = neuron1, kernel_initializer= 'uniform', activation= 'linear'))\n    model.add(Dense(1, activation='sigmoid'))\n    \n    # compile the model\n    adam = Adam(lr = 0.001)\n    model.compile(loss = 'binary_crossentropy', optimizer = adam, metrics = ['accuracy'])\n    return model\n\n# create the model\nmodel = KerasClassifier(build_fn = create_model, epochs = 100, batch_size = 20, verbose = 0)\n\n# define the grid search parameters\nneuron1 = [4, 8, 16]\nneuron2 = [2, 4, 8]\n\n# make a dictionary of the grid search parameters\nparam_grid = dict(neuron1 = neuron1, neuron2 = neuron2)\n\n# build and fit the GridSearchCV\ngrid = GridSearchCV(estimator = model, param_grid = param_grid, cv = KFold(random_state=seed), refit = True, verbose = 10)\ngrid_results = grid.fit(X_standardized, Y)\n\n# summarize the results\nprint(\"Best: {0}, using {1}\".format(grid_results.best_score_, grid_results.best_params_))\nmeans = grid_results.cv_results_['mean_test_score']\nstds = grid_results.cv_results_['std_test_score']\nparams = grid_results.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print('{0} ({1}) with: {2}'.format(mean, stdev, param))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Generate predictions with optimal hyperparameters**"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = grid.predict(X_standardized)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_pred.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_pred[:5])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Generate a classification report</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, accuracy_score\n\nprint(accuracy_score(Y, y_pred))\nprint(classification_report(Y, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" # <font color='green'>Please upvote if you found this helpful :)</font>"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}