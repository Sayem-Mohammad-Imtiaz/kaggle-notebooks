{"cells":[{"metadata":{},"cell_type":"markdown","source":"# German Credit Risk Analysis"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#importing the libraries\nimport pandas as pd\nimport numpy as np \nimport seaborn as sns \nimport matplotlib.pyplot as plt\n\nfrom IPython.display import display","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_columns', 100)\npd.set_option('display.max_rows', 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"credit_df = pd.read_csv('../input/german-credit-data-with-risk/german_credit_data.csv')\ncredit_df = credit_df.iloc[:, 1:]\ncredit_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"credit_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"credit_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (credit_df.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reading and understanding Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking for number of unique values in each column\ncredit_df.nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Separating out numeric and categorical variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"credit_df_numeric = credit_df.select_dtypes(include=['int64'])\ncredit_df_numeric.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"credit_df_categorical = credit_df.select_dtypes(include=['object'])\ncredit_df_categorical.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Changing datatype of job from numeric to object"},{"metadata":{"trusted":true},"cell_type":"code","source":"credit_df['Job'] = credit_df['Job'].astype(object)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"credit_df_numeric = credit_df.select_dtypes(include=['int64'])\ncredit_df_numeric.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"credit_df_categorical = credit_df.select_dtypes(include=['object'])\ndel credit_df_categorical['Risk']\ncredit_df_categorical.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"credit_categorical_col = credit_df_categorical.columns\ncredit_numeric_col = credit_df_numeric.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (credit_categorical_col)\nprint (credit_numeric_col)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"def showLabels(ax, d=None):\n    plt.margins(0.2, 0.2)\n    rects = ax.patches\n    i = 0\n    locs, labels = plt.xticks() \n    counts = {}\n    if not d is None:\n        for key, value in d.items():\n            counts[str(key)] = value\n\n    # For each bar: Place a label\n    for rect in rects:\n        # Get X and Y placement of label from rect.\n        y_value = rect.get_height()\n        x_value = rect.get_x() + rect.get_width() / 2\n\n        # Number of points between bar and label. Change to your liking.\n        space = 5\n        # Vertical alignment for positive values\n        va = 'bottom'\n\n        # If value of bar is negative: Place label below bar\n        if y_value < 0:\n            # Invert space to place label below\n            space *= -1\n            # Vertically align label at top\n            va = 'top'\n\n        # Use Y value as label and format number with one decimal place\n        if d is None:\n            label = \"{:.1f}%\".format(y_value)\n        else:\n            try:\n                label = \"{:.1f}%\".format(y_value) + '\\n' + str(counts[str(labels[i].get_text())])\n            except:\n                label = \"{:.1f}%\".format(y_value)\n        \n        i = i+1\n\n        # Create annotation\n        plt.annotate(\n            label,                      # Use `label` as label\n            (x_value, y_value),         # Place label at end of the bar\n            xytext=(0, space),          # Vertically shift label by `space`\n            textcoords=\"offset points\", # Interpret `xytext` as offset in points\n            ha='center',                # Horizontally center label\n            va=va)                      # Vertically align label differently for\n                                        # positive and negative values.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_distribution(dataframe, col):\n    plt.figure(figsize=(15,5))\n    plt.subplot(1, 2, 1)\n    ax = sns.histplot(dataframe[col])\n    plt.subplot(1, 2, 2)\n    sns.boxplot(x=dataframe[col], y=dataframe['Risk'], data=dataframe)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_percentages(dataframe, by, sortbyindex=False):\n    plt.subplot(1, 2, 1)\n    values = (credit_df[by].value_counts(normalize=True)*100)\n    if sortbyindex:\n        values = values.sort_index()\n    ax = values.plot.bar(color=sns.color_palette('husl', 16))\n    ax.set_ylabel('% in dataset', fontsize=16)\n    ax.set_xlabel(by, fontsize=12)\n    showLabels(ax)\n    plt.subplot(1, 2, 2)\n    values = (credit_df.loc[credit_df['Risk']=='bad'][by].value_counts(normalize=True)*100)\n    if sortbyindex:\n        values = values.sort_index()\n    ax = values.plot.bar(color=sns.color_palette('husl', 16))\n    ax.set_ylabel('% of bad risks ou', fontsize=16)\n    showLabels(ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plotRiskStatus(dataframe, by, risk='bad'):\n    grp = dataframe.groupby(['Risk',by])[by].count()\n    cnt = dataframe.groupby(by)[by].count()\n    #print(grp)\n    percentages = grp.unstack() * 100 / cnt.T\n    #print(percentages)\n    ax = percentages.loc[risk].plot.bar(color=sns.color_palette('husl', 16))\n    ax.set_ylabel('% of ' + risk + ' risks')\n    showLabels(ax, grp[risk].to_dict())\n    plt.margins(0.2, 0.2)\n    plt.tight_layout()\n    return ax","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grp = credit_df.groupby(['Risk','Sex'])['Sex'].count()\ngrp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in credit_categorical_col:\n    plt.figure(figsize=(15,10))\n    plot_percentages(credit_df, col)\n    plt.figure(figsize=(15,10))\n    plotRiskStatus(credit_df, col)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Some insights for categorical variables:**\n1. There are more males than females in the dataset. Out of the total percentage of bad risks, there are more male incidents. But out of the total females in the dataset there are more % of bad risks."},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in credit_numeric_col:\n    plt.figure(figsize=(15,10))\n    plot_distribution(credit_df, col)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Cleaning"},{"metadata":{},"cell_type":"markdown","source":"Handling missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"round(credit_df.isnull().sum().sort_values(ascending=False)/len(credit_df.index)*100, 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since close to 40% rows are null we can add them into a new category None"},{"metadata":{"trusted":true},"cell_type":"code","source":"credit_df['Checking account'] = credit_df['Checking account'].fillna('None')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"round(credit_df.isnull().sum().sort_values(ascending=False)/len(credit_df.index)*100, 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We now drop the rows where saving accounts are null"},{"metadata":{"trusted":true},"cell_type":"code","source":"credit_df.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"round(credit_df.isnull().sum().sort_values(ascending=False)/len(credit_df.index)*100, 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"credit_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Handling outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in credit_numeric_col:\n    q1 = credit_df[column].quantile(0.1)\n    q3 = credit_df[column].quantile(0.9)\n    iqr = q3 - q1\n    \n    #Excluding everything outside the interquantile range\n    credit_df = credit_df[(credit_df[column] >= q1 - 1.5*iqr) & \n                      (credit_df[column] <= q3 + 1.5*iqr)] \n    print(credit_df.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Adding dummy columns for categorical variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"binary_var = ['Sex']\n\nfor col in binary_var:\n    ulist = credit_df[col].unique()\n    credit_df[col] = credit_df[col].map({ulist[0] : 1, ulist[1] : 0})\n    \ncredit_df['Risk'] = credit_df['Risk'].map({'good' : 0, 'bad' : 1})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"credit_categorical_col = list(credit_categorical_col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"credit_categorical_col.remove('Sex')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"credit_df_dummies = pd.get_dummies(credit_df[credit_categorical_col], drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"credit_df_dummies.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"credit_df.drop(credit_categorical_col, axis=1, inplace=True)\ncredit_df = pd.concat((credit_df, credit_df_dummies), axis = 1)\ncredit_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"credit_df_fe = credit_df.copy()\ncredit_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can combine credit amount and duration to a variable credit/month"},{"metadata":{"trusted":true},"cell_type":"code","source":"credit_df_fe['credit_per_month'] = credit_df_fe['Credit amount'] / credit_df_fe['Duration']\ncredit_df_fe.drop(['Credit amount', 'Duration'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"credit_df_fe.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = credit_df_fe.pop('Risk')\nX = credit_df_fe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Scaling"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col = X.columns\nindex = X.index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = pd.DataFrame(scaler.fit_transform(X_train), columns = col)\nX_test = pd.DataFrame(scaler.transform(X_test), columns = col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Class imbalance"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"print(\"Number of churners before sampling: \", sum(y_train==1))\nprint(\"Number of non-churners before sampling: \", sum(y_train==0))\nprint(\"Churn rate before sampling: \", sum(y_train==1)/len(y_train)*100)"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"#performing SMOTE\nfrom imblearn.over_sampling import SMOTE\nsm = SMOTE(random_state=100)\nX_train_res, y_train_res = sm.fit_sample(X_train, y_train)"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"print(\"Shape of X_train = \", X_train_res.shape)\nprint(\"Shape of y_train = \", y_train_res.shape)\n\nprint(\"Number of churners after sampling: \", sum(y_train_res==1))\nprint(\"Number of non-churners after sampling: \", sum(y_train_res==0))\nprint(\"Churn rate after sampling: \", sum(y_train_res==1)/len(y_train_res)*100)"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Modelling"},{"metadata":{"trusted":true},"cell_type":"code","source":"#import libraries for modeling\nimport sklearn.preprocessing\nfrom sklearn import metrics\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getModelMetrics(actual=False, pred=False):\n    confusion = confusion_matrix(actual, pred)\n    \n    TP = confusion[1,1]\n    FP = confusion[0,1]\n    TN = confusion[0,0]\n    FN = confusion[1,0]\n    \n    print(\"Roc_auc_score : {}\".format(metrics.roc_auc_score(actual,pred)))\n    # Sensitivity\n    print('Sensitivity/Recall : {}'.format(TP / float(TP+FN)))\n    # specificity\n    print('Specificity: {}'.format(TN / float(TN+FP)))\n    # false postive rate - predicting churn when customer has not churned\n    print('False Positive Rate: {}'.format(FP/ float(TN+FP)))\n    # positive predictive value \n    print('Positive predictive value: {}'.format(TP / float(TP+FP)))\n    # Negative predictive value\n    print('Negative Predictive value: {}'.format(TN / float(TN+ FN)))\n    # sklearn precision score value \n    print('sklearn precision score value: {}'.format(metrics.precision_score(actual, pred )))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_accuracies(scores,param):\n    # plotting accuracies with max_depth\n    plt.figure()\n    plt.plot(scores[\"param_\"+param], \n    scores[\"mean_train_score\"], \n    label=\"training accuracy\")\n    plt.plot(scores[\"param_\"+param], \n    scores[\"mean_test_score\"], \n    label=\"test accuracy\")\n    plt.xlabel(param)\n    plt.ylabel(\"f1\")\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predictRiskWithCutOff(model,X,y,prob):\n    # Funtion to predict the churn using the input probability cut-off\n    \n    # predict\n    pred_probs = model.predict_proba(X)[:,1]\n    \n    y_df= pd.DataFrame({'risk':y, 'risk_Prob':pred_probs})\n\n    y_df['final_predicted'] = y_df.churn_Prob.map( lambda x: 1 if x > prob else 0)\n    # Let's see the head\n    getModelMetrics(y_df.churn,y_df.final_predicted)\n    return y_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def findOptimalCutoff(df):\n    #Function to find the optimal cutoff for classifing as churn/non-churn\n    # Let's create columns with different probability cutoffs \n    numbers = [float(x)/10 for x in range(10)]\n    for i in numbers:\n        df[i] = df.churn_Prob.map( lambda x: 1 if x > i else 0)\n    #print(df.head())\n    \n    # Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\n    cutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\n    from sklearn.metrics import confusion_matrix\n    \n    # TP = confusion[1,1] # true positive \n    # TN = confusion[0,0] # true negatives\n    # FP = confusion[0,1] # false positives\n    # FN = confusion[1,0] # false negatives\n    \n    num = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n    for i in num:\n        cm1 = metrics.confusion_matrix(df.churn, df[i] )\n        total1=sum(sum(cm1))\n        accuracy = (cm1[0,0]+cm1[1,1])/total1\n        \n        speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n        sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n        cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\n    print(cutoff_df)\n    # Let's plot accuracy sensitivity and specificity for various probabilities.\n    cutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Logistic Regression**"},{"metadata":{"trusted":true},"cell_type":"code","source":"logisticModel = LogisticRegression(verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logisticModel.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred = logisticModel.predict(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"getModelMetrics(y_train, y_train_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_pred = logisticModel.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"getModelMetrics(y_test, y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Not so great for logistic Regression"},{"metadata":{},"cell_type":"markdown","source":"**SVM**"},{"metadata":{"trusted":true},"cell_type":"code","source":"svmLin = SVC(C=1, kernel='linear')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svmLin.fit(X_train, y_train)\ny_train_pred = svmLin.predict(X_train)\ngetModelMetrics(y_train, y_train_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hyper parameter tuning for SVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\"C\" : [0.1, 1, 50]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svmLin1 = SVC(kernel='linear')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_cv = GridSearchCV(estimator = svmLin1,\n                       param_grid = params,\n                       scoring = 'recall',\n                       cv = 3,\n                       verbose = 5,\n                       n_jobs = 8,\n                       return_train_score=True)\nmodel_cv.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_accuracies(model_cv.cv_results_, 'C')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_cv.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svm_final = SVC(C=50, kernel='linear')\n\n#fit on train model\nsvm_final.fit(X_train, y_train)\n\n# predict on train\ny_pred = svm_final.predict(X_train)\ngetModelMetrics(y_train,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predict on test\ny_pred = svm_final.predict(X_test)\ngetModelMetrics(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Linear kernel is having a hard time"},{"metadata":{"trusted":true},"cell_type":"code","source":"svmNonLin = SVC(kernel='rbf')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_cv = GridSearchCV(estimator = svmNonLin,\n                       param_grid = params,\n                       scoring = 'recall',\n                       cv = 3,\n                       verbose = 5,\n                       n_jobs = 8,\n                       return_train_score=True)\nmodel_cv.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_cv.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_accuracies(model_cv.cv_results_, 'C')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svm_final = SVC(C=1, kernel='rbf')\n\n#fit on train model\nsvm_final.fit(X_train, y_train)\n\n# predict on train\ny_train_pred = svm_final.predict(X_train)\ngetModelMetrics(y_train,y_train_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_pred = svm_final.predict(X_test)\ngetModelMetrics(y_test,y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that model is overfitting even in SVM. I think we should get more features to explain the variance on the dataset and generalize the whole data.\n\nDo let me know if there is any other way of avoiding overfitting"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}