{"cells":[{"metadata":{},"cell_type":"markdown","source":"Machine learning briefly; It is a scientific technique where computers learn how to solve a problem without programming.\n- Simple Lineer Regression\n- Multiple Lineer Regression\n- Polynomial  Lineer Regression\n- Decision Tree Regression\n- Random Forest Regression\n- Support Vector Regression (SVR)\n- XGBoost Regression\n- Lasso Regression\n- Ridge Regression\n- ElasticNet Regression\n- K-Nearest Neighbors Regression (KNN)\n- Gradient Boosting Machines (GBM)\n- LightGBM Regression\n- CatBoost","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Preapare Data","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Import The Necessary Packages\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n\nfrom sklearn import metrics\nfrom sklearn import linear_model\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.model_selection import GridSearchCV\n\nfrom plotly.offline import init_notebook_mode,iplot\nimport plotly.graph_objs as go\ninit_notebook_mode(connected=True)\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = \"../input/housesalesprediction/kc_house_data.csv\"\ndf = pd.read_csv(data)\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Data Shape: \", df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(17,14))\nsns.heatmap(df.corr(), annot=True, linewidth=0.5, linecolor=\"Black\", fmt=\"1.1f\")\nplt.title(\"Attributes Correlation\", fontsize=28)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist1 = [go.Histogram(x=df.grade,marker=dict(color='rgb(102, 0, 102)'))]\nhistlayout1 = go.Layout(title=\"Grade Counts of Houses\",xaxis=dict(title=\"Grades\"),yaxis=dict(title=\"Counts\"))\nhistfig1 = go.Figure(data=hist1,layout=histlayout1)\niplot(histfig1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist2 = [go.Histogram(x=df.yr_built,xbins=dict(start=np.min(df.yr_built),size=1,end=np.max(df.yr_built)),marker=dict(color='rgb(0,102,0)'))]\n\nhistlayout2 = go.Layout(title=\"Built Year Counts of Houses\",xaxis=dict(title=\"Years\"),yaxis=dict(title=\"Built Counts\"))\n\nhistfig2 = go.Figure(data=hist2,layout=histlayout2)\n\niplot(histfig2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"v21 = [go.Box(y=df.bedrooms,name=\"Bedrooms\",marker=dict(color=\"rgba(51,0,0,0.9)\"),hoverinfo=\"name+y\")]\nv22 = [go.Box(y=df.bathrooms,name=\"Bathrooms\",marker=dict(color=\"rgba(0,102,102,0.9)\"),hoverinfo=\"name+y\")]\nv23 = [go.Box(y=df.floors,name=\"Floors\",marker=dict(color=\"rgba(204,0,102,0.9)\"),hoverinfo=\"name+y\")]\n\nlayout2 = go.Layout(title=\"Bedrooms,Bathrooms and Floors\",yaxis=dict(range=[0,13])) #I hate 33 bedroom\n\nfig2 = go.Figure(data=v21+v22+v23,layout=layout2)\niplot(fig2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\n\ndataplus = df[np.logical_and(df.grade >= 7,df.yr_built >= 2000)] \n#list lat and long\nlats = list(dataplus.lat.values)\nlongs = list(dataplus.long.values)\n\nfig = px.scatter_mapbox(lat=lats, lon=longs, zoom=10, height=500)\nfig.update_layout(mapbox_style=\"open-street-map\")\nfig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models_and_scores = []","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Simple Linear Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df[['sqft_living']].values\ny = df.price.values\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y ,test_size=0.2,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\nlr = LinearRegression()\nlr.fit(X_train, y_train)\ny_pred = lr.predict(X_test)\n\nmodel_score = lr.score(X_test,y_test)\nr_square = metrics.r2_score(y_test, y_pred)\nmse = metrics.mean_squared_error(y_test, y_pred)\nmae = metrics.median_absolute_error(y_test, y_pred)\nev = metrics.explained_variance_score(y_test, y_pred)\n\nprint(\"Model Score            : \", model_score*100)\nprint(\"R Square               : \", r_square*100)\nprint(\"Mean Squared Error     : \", mse)\nprint(\"Root Mean Squared Error: \", mse**(1/2))\nprint(\"Median Absolute Error  : \", mae)\nprint(\"Explained Variance     : \", ev)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Multiple Linear Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df = df[['sqft_living15','lat','sqft_basement', 'sqft_above', 'grade','view','sqft_basement', 'sqft_living', 'bathrooms', 'floors', 'waterfront','yr_built']]\nX = new_df.values\ny = df.price.values\n\nX_train, X_test, y_train, y_test = train_test_split(X, y ,test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"multi_lr_model = LinearRegression() # model\n\nmulti_lr_model.fit(X_train, y_train) # fit\n\ny_pred = multi_lr_model.predict(X_test) # prediction\n\nmodel_score = multi_lr_model.score(X_test,y_test)\nr_square = metrics.r2_score(y_test, y_pred)\nmse = metrics.mean_squared_error(y_test, y_pred)\nmae = metrics.median_absolute_error(y_test, y_pred)\nev = metrics.explained_variance_score(y_test, y_pred)\nmodels_and_scores.append([\"Multiple Linear\",r_square])\n\nprint(\"Model Score            : \", model_score*100)\nprint(\"R Square               : \", r_square*100)\nprint(\"Mean Squared Error     : \", mse)\nprint(\"Root Mean Squared Error: \", mse**(1/2))\nprint(\"Median Absolute Error  : \", mae)\nprint(\"Explained Variance     : \", ev)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Polynomial Linear Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X1 = [1,2,3,5,6,7,8,9,10,12,13,14,15,16,18,19,21,22]\ny1 = [100,90,80,60,60,55,60,65,70,70,75,76,78,79,90,99,99,100]\n\nmymodel = np.poly1d(np.polyfit(X1, y1, 3))\nmyline = np.linspace(1, 22, 100)\n\nplt.scatter(X1, y1)\nplt.plot(myline, mymodel(myline))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"speed = mymodel(17)\nprint(speed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Decision Tree Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df = df[['sqft_living15','lat','sqft_basement', 'sqft_above', 'grade','view','sqft_basement', 'sqft_living', 'bathrooms', 'floors', 'waterfront','yr_built']]\nX = new_df.values\ny = df.price.values\n\nX_train, X_test, y_train, y_test = train_test_split(X, y ,test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\n\ndtr = DecisionTreeRegressor(random_state=42)\ndtr.fit(X_train, y_train)\ny_pred = dtr.predict(X_test)\n\nmodel_score = dtr.score(X_test,y_test)\nr_square = metrics.r2_score(y_test, y_pred)\nmse = metrics.mean_squared_error(y_test, y_pred)\nmae = metrics.median_absolute_error(y_test, y_pred)\nev = metrics.explained_variance_score(y_test, y_pred)\n\nprint(\"Model Score            : \", model_score*100)\nprint(\"R Square               : \", r_square*100)\nprint(\"Mean Squared Error     : \", mse)\nprint(\"Root Mean Squared Error: \", mse**(1/2))\nprint(\"Median Absolute Error  : \", mae)\nprint(\"Explained Variance     : \", ev)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model Tuning\nparam_grid = {\n    'max_depth': list(np.arange(1,30)),\n    'min_samples_split': list(np.arange(1,10))\n}\n\ndtr_model = DecisionTreeRegressor(random_state=42)\ndtr_cv_model = GridSearchCV(dtr_model, param_grid, cv=10, n_jobs=-1, verbose=2)\ndtr_cv_model.fit(X_train, y_train)\nprint(\"Best Params: \", dtr_cv_model.best_params_)\nprint(\"Best Score : \", dtr_cv_model.best_score_)\n\ny_pred = dtr_cv_model.predict(X_test)\n\nr_square = metrics.r2_score(y_test, y_pred)\nmse = metrics.mean_squared_error(y_test, y_pred)\nmae = metrics.median_absolute_error(y_test, y_pred)\nev = metrics.explained_variance_score(y_test, y_pred)\nmodels_and_scores.append(['Decision Tree', dtr_cv_model.best_score_])\n\nprint(\"R Square               : \", r_square*100)\nprint(\"Mean Squared Error     : \", mse)\nprint(\"Root Mean Squared Error: \", mse**(1/2))\nprint(\"Median Absolute Error  : \", mae)\nprint(\"Explained Variance     : \", ev)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = ['sqft_living15','lat','sqft_basement', 'sqft_above', 'grade','view','sqft_basement', 'sqft_living', 'bathrooms', 'floors', 'waterfront','yr_built']\n\nImportance = pd.DataFrame({\n    'Importance': dtr_cv_model.best_estimator_.feature_importances_*100}, index=columns)\nImportance.sort_values(by=\"Importance\", axis=0, ascending=True).plot(kind=\"barh\", color=\"b\")\nplt.xlabel(\"Variable Importance\")\nplt.gca().legend_ = None","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df = df[['sqft_living15','lat','sqft_basement', 'sqft_above', 'grade','view','sqft_basement', 'sqft_living', 'bathrooms', 'floors', 'waterfront','yr_built']]\nX = new_df.values\ny = df.price.values\n\nX_train, X_test, y_train, y_test = train_test_split(X, y ,test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\n\nrfr = RandomForestRegressor(random_state=42)\nrfr.fit(X_train, y_train)\ny_pred = rfr.predict(X_test)\n\nmodel_score = rfr.score(X_test,y_test)\nr_square = metrics.r2_score(y_test, y_pred)\nmse = metrics.mean_squared_error(y_test, y_pred)\nmae = metrics.median_absolute_error(y_test, y_pred)\nev = metrics.explained_variance_score(y_test, y_pred)\n\nprint(\"Model Score            : \", model_score*100)\nprint(\"R Square               : \", r_square*100)\nprint(\"Mean Squared Error     : \", mse)\nprint(\"Root Mean Squared Error: \", mse**(1/2))\nprint(\"Median Absolute Error  : \", mae)\nprint(\"Explained Variance     : \", ev)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model Tuning\nparam_grid = {\n    'max_depth': [1,5,10,30,50,100]\n}\n\nrfr_model = RandomForestRegressor(random_state=42)\nrfr_cv_model = GridSearchCV(rfr_model, param_grid, cv=10, n_jobs=-1, verbose=2)\nrfr_cv_model.fit(X_train, y_train)\nprint(\"Best Params: \", rfr_cv_model.best_params_)\nprint(\"Best Score : \", rfr_cv_model.best_score_)\n\ny_pred = rfr_cv_model.predict(X_test)\n\nr_square = metrics.r2_score(y_test, y_pred)\nmse = metrics.mean_squared_error(y_test, y_pred)\nmae = metrics.median_absolute_error(y_test, y_pred)\nev = metrics.explained_variance_score(y_test, y_pred)\nmodels_and_scores.append(['Random Forest', rfr_cv_model.best_score_])\n\n\nprint(\"R Square               : \", r_square*100)\nprint(\"Mean Squared Error     : \", mse)\nprint(\"Root Mean Squared Error: \", mse**(1/2))\nprint(\"Median Absolute Error  : \", mae)\nprint(\"Explained Variance     : \", ev)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = ['sqft_living15','lat','sqft_basement', 'sqft_above', 'grade','view','sqft_basement', 'sqft_living', 'bathrooms', 'floors', 'waterfront','yr_built']\n\nImportance = pd.DataFrame({\n    'Importance': rfr_cv_model.best_estimator_.feature_importances_*100}, index=columns)\nImportance.sort_values(by=\"Importance\", axis=0, ascending=True).plot(kind=\"barh\", color=\"b\")\nplt.xlabel(\"Variable Importance\")\nplt.gca().legend_ = None","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Support Vector Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df = df[['sqft_living15','lat','sqft_basement', 'sqft_above', 'grade','view','sqft_basement', 'sqft_living', 'bathrooms', 'floors', 'waterfront','yr_built']]\nX = new_df.values\ny = df.price.values\n\nX_train, X_test, y_train, y_test = train_test_split(X, y ,test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVR\n\nsvr = SVR(kernel='linear')\nsvr.fit(X_train, y_train)\ny_pred = svr.predict(X_test)\n\nmodel_score = svr.score(X_test,y_test)\nr_square = metrics.r2_score(y_test, y_pred)\nmse = metrics.mean_squared_error(y_test, y_pred)\nmae = metrics.median_absolute_error(y_test, y_pred)\nev = metrics.explained_variance_score(y_test, y_pred)\n\nprint(\"Model Score            : \", model_score*100)\nprint(\"R Square               : \", r_square*100)\nprint(\"Mean Squared Error     : \", mse)\nprint(\"Root Mean Squared Error: \", mse**(1/2))\nprint(\"Median Absolute Error  : \", mae)\nprint(\"Explained Variance     : \", ev)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model Tuning\nparam_grid = {\n    'C': [0.1, 0.5, 1, 5]\n}\n\nsvr = SVR(kernel='linear')\nsvr_cv_model = GridSearchCV(svr, param_grid, cv=5, n_jobs=-1, verbose=2)\nsvr_cv_model.fit(X_train, y_train)\nprint(\"Best Params: \", svr_cv_model.best_params_)\nprint(\"Best Score : \", svr_cv_model.best_score_)\n\ny_pred = svr_cv_model.predict(X_test)\n\nr_square = metrics.r2_score(y_test, y_pred)\nmse = metrics.mean_squared_error(y_test, y_pred)\nmae = metrics.median_absolute_error(y_test, y_pred)\nev = metrics.explained_variance_score(y_test, y_pred)\nmodels_and_scores.append(['SVM', svr_cv_model.best_score_])\n\nprint(\"R Square               : \", r_square*100)\nprint(\"Mean Squared Error     : \", mse)\nprint(\"Root Mean Squared Error: \", mse**(1/2))\nprint(\"Median Absolute Error  : \", mae)\nprint(\"Explained Variance     : \", ev)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# XGBoost","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df = df[['sqft_living15','lat','sqft_basement', 'sqft_above', 'grade','view','sqft_basement', 'sqft_living', 'bathrooms', 'floors', 'waterfront','yr_built']]\nX = new_df.values\ny = df.price.values\n\nX_train, X_test, y_train, y_test = train_test_split(X, y ,test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBRegressor\n\nxgb = XGBRegressor(n_estimators=100, learning_rate=0.08, gamma=0, subsample=0.75,\n                           colsample_bytree=1, max_depth=7)\nxgb.fit(X_train,y_train)\ny_pred = xgb.predict(X_test)\n\nmodel_score = xgb.score(X_test,y_test)\nr_square = metrics.r2_score(y_test, y_pred)\nmse = metrics.mean_squared_error(y_test, y_pred)\nmae = metrics.median_absolute_error(y_test, y_pred)\nev = metrics.explained_variance_score(y_test, y_pred)\n\nprint(\"Model Score            : \", model_score*100)\nprint(\"R Square               : \", r_square*100)\nprint(\"Mean Squared Error     : \", mse)\nprint(\"Root Mean Squared Error: \", mse**(1/2))\nprint(\"Median Absolute Error  : \", mae)\nprint(\"Explained Variance     : \", ev)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model Tuning\nparam_grid = {\n    'learning_rate': [0.1, 0.01, 0.5],\n    'max_depth': [2,3,5],\n    'n_estimators': [100, 200, 300],\n    'colsample_bytree': [0.4, 0.7, 1]\n}\n\nxgb_model = XGBRegressor()\nxgb_cv_model = GridSearchCV(xgb_model, param_grid, cv=5, n_jobs=-1, verbose=2)\nxgb_cv_model.fit(X_train, y_train)\nprint(\"Best Params: \", xgb_cv_model.best_params_)\nprint(\"Best Score : \", xgb_cv_model.best_score_)\n\ny_pred = xgb_cv_model.predict(X_test)\n\nr_square = metrics.r2_score(y_test, y_pred)\nmse = metrics.mean_squared_error(y_test, y_pred)\nmae = metrics.median_absolute_error(y_test, y_pred)\nev = metrics.explained_variance_score(y_test, y_pred)\nmodels_and_scores.append(['XGB', xgb_cv_model.best_score_])\n\nprint(\"R Square               : \", r_square*100)\nprint(\"Mean Squared Error     : \", mse)\nprint(\"Root Mean Squared Error: \", mse**(1/2))\nprint(\"Median Absolute Error  : \", mae)\nprint(\"Explained Variance     : \", ev)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = ['sqft_living15','lat','sqft_basement', 'sqft_above', 'grade','view','sqft_basement', 'sqft_living', 'bathrooms', 'floors', 'waterfront','yr_built']\n\nImportance = pd.DataFrame({\n    'Importance': xgb_cv_model.best_estimator_.feature_importances_*100}, index=columns)\nImportance.sort_values(by=\"Importance\", axis=0, ascending=True).plot(kind=\"barh\", color=\"b\")\nplt.xlabel(\"Variable Importance\")\nplt.gca().legend_ = None","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Lasso Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df = df[['sqft_living15','lat','sqft_basement', 'sqft_above', 'grade','view','sqft_basement', 'sqft_living', 'bathrooms', 'floors', 'waterfront','yr_built']]\nX = new_df.values\ny = df.price.values\n\nX_train, X_test, y_train, y_test = train_test_split(X, y ,test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Lasso\n\nlass = Lasso()\nlass.fit(X_train, y_train)\ny_pred = lass.predict(X_test)\n\nmodel_score = lass.score(X_test,y_test)\nr_square = metrics.r2_score(y_test, y_pred)\nmse = metrics.mean_squared_error(y_test, y_pred)\nmae = metrics.median_absolute_error(y_test, y_pred)\nev = metrics.explained_variance_score(y_test, y_pred)\n\nprint(\"Model Score            : \", model_score*100)\nprint(\"R Square               : \", r_square*100)\nprint(\"Mean Squared Error     : \", mse)\nprint(\"Root Mean Squared Error: \", mse**(1/2))\nprint(\"Median Absolute Error  : \", mae)\nprint(\"Explained Variance     : \", ev)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"# Model Tuning\nfrom sklearn.linear_model import LassoCV\n\nalphas = 10**np.linspace(10,-1,100)*0.5\n\nlass_cv_model = LassoCV(alphas=alphas, cv=10, n_jobs=-1, verbose=2, max_iter=100000)\nlass_cv_model.fit(X_train, y_train)\n\ny_pred = lass_cv_model.predict(X_test)\n\nr_square = metrics.r2_score(y_test, y_pred)\nmse = metrics.mean_squared_error(y_test, y_pred)\nmae = metrics.median_absolute_error(y_test, y_pred)\nev = metrics.explained_variance_score(y_test, y_pred)\nmodels_and_scores.append(['Lasso', r_square])\n\nprint(\"R Square               : \", r_square*100)\nprint(\"Mean Squared Error     : \", mse)\nprint(\"Root Mean Squared Error: \", mse**(1/2))\nprint(\"Median Absolute Error  : \", mae)\nprint(\"Explained Variance     : \", ev)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"R Square               :  68.4670734001445 <br>\nMean Squared Error     :  47670441712.02933 <br>\nRoot Mean Squared Error:  218335.6171402855 <br>\nMedian Absolute Error  :  89123.50729138404 <br>\nExplained Variance     :  0.6847409925653468 ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Ridge Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df = df[['sqft_living15','lat','sqft_basement', 'sqft_above', 'grade','view','sqft_basement', 'sqft_living', 'bathrooms', 'floors', 'waterfront','yr_built']]\nX = new_df.values\ny = df.price.values\n\nX_train, X_test, y_train, y_test = train_test_split(X, y ,test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Ridge\n\nridge = Ridge()\nridge.fit(X_train, y_train)\ny_pred = ridge.predict(X_test)\n\nmodel_score = ridge.score(X_test,y_test)\nr_square = metrics.r2_score(y_test, y_pred)\nmse = metrics.mean_squared_error(y_test, y_pred)\nmae = metrics.median_absolute_error(y_test, y_pred)\nev = metrics.explained_variance_score(y_test, y_pred)\nmodels_and_scores.append(['Ridge', r_square])\n\nprint(\"Model Score            : \", model_score*100)\nprint(\"R Square               : \", r_square*100)\nprint(\"Mean Squared Error     : \", mse)\nprint(\"Root Mean Squared Error: \", mse**(1/2))\nprint(\"Median Absolute Error  : \", mae)\nprint(\"Explained Variance     : \", ev)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ElasticNet Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df = df[['sqft_living15','lat','sqft_basement', 'sqft_above', 'grade','view','sqft_basement', 'sqft_living', 'bathrooms', 'floors', 'waterfront','yr_built']]\nX = new_df.values\ny = df.price.values\n\nX_train, X_test, y_train, y_test = train_test_split(X, y ,test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import ElasticNet\n\nelasticN = ElasticNet()\nelasticN.fit(X_train, y_train)\ny_pred = elasticN.predict(X_test)\n\nmodel_score = elasticN.score(X_test,y_test)\nr_square = metrics.r2_score(y_test, y_pred)\nmse = metrics.mean_squared_error(y_test, y_pred)\nmae = metrics.median_absolute_error(y_test, y_pred)\nev = metrics.explained_variance_score(y_test, y_pred)\nmodels_and_scores.append(['ElasticNet', r_square])\n\nprint(\"Model Score            : \", model_score*100)\nprint(\"R Square               : \", r_square*100)\nprint(\"Mean Squared Error     : \", mse)\nprint(\"Root Mean Squared Error: \", mse**(1/2))\nprint(\"Median Absolute Error  : \", mae)\nprint(\"Explained Variance     : \", ev)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## K-Nearest Neighbors Regression (KNN)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df = df[['sqft_living15','lat','sqft_basement', 'sqft_above', 'grade','view','sqft_basement', 'sqft_living', 'bathrooms', 'floors', 'waterfront','yr_built']]\nX = new_df.values\ny = df.price.values\n\nX_train, X_test, y_train, y_test = train_test_split(X, y ,test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)\n\nknn = KNeighborsClassifier(n_neighbors=11)\nknn.fit(X_train, y_train)\ny_pred = knn.predict(X_test)\n\nmodel_score = knn.score(X_test,y_test)\nr_square = metrics.r2_score(y_test, y_pred)\nmse = metrics.mean_squared_error(y_test, y_pred)\nmae = metrics.median_absolute_error(y_test, y_pred)\nev = metrics.explained_variance_score(y_test, y_pred)\nmodels_and_scores.append(['KNN', r_square])\n\nprint(\"Model Score            : \", model_score*100)\nprint(\"R Square               : \", r_square*100)\nprint(\"Mean Squared Error     : \", mse)\nprint(\"Root Mean Squared Error: \", mse**(1/2))\nprint(\"Median Absolute Error  : \", mae)\nprint(\"Explained Variance     : \", ev)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Gradient Boosting Machines (GBM)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df = df[['sqft_living15','lat','sqft_basement', 'sqft_above', 'grade','view','sqft_basement', 'sqft_living', 'bathrooms', 'floors', 'waterfront','yr_built']]\nX = new_df.values\ny = df.price.values\n\nX_train, X_test, y_train, y_test = train_test_split(X, y ,test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\n\ngbm = GradientBoostingRegressor(random_state=42)\ngbm.fit(X_train, y_train)\ny_pred = gbm.predict(X_test)\n\nmodel_score = gbm.score(X_test,y_test)\nr_square = metrics.r2_score(y_test, y_pred)\nmse = metrics.mean_squared_error(y_test, y_pred)\nmae = metrics.median_absolute_error(y_test, y_pred)\nev = metrics.explained_variance_score(y_test, y_pred)\n\nprint(\"Model Score            : \", model_score*100)\nprint(\"R Square               : \", r_square*100)\nprint(\"Mean Squared Error     : \", mse)\nprint(\"Root Mean Squared Error: \", mse**(1/2))\nprint(\"Median Absolute Error  : \", mae)\nprint(\"Explained Variance     : \", ev)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model Tuning\n\"\"\"\nparam_grid = {\n    'learning_rate': [0.001, 0.01, 0.1],\n    'max_depth': [3,5,8],\n    'n_estimators': [100,200,500],\n    'subsample': [1, 0.5, 0.8 ],\n    'loss': ['ls', 'lad', 'quantile']\n}\n\"\"\"\nparam_grid = {\n    'learning_rate': [0.001, 0.01],\n    'max_depth': [3,5],\n    'n_estimators': [150,200,250],\n    'subsample': [1, 0.5]\n}\n\ngbm_model = GradientBoostingRegressor(random_state=42)\ngbm_cv_model = GridSearchCV(gbm_model, param_grid, cv=10, n_jobs=-1, verbose=2)\ngbm_cv_model.fit(X_train, y_train)\nprint(\"Best Params: \", gbm_cv_model.best_params_)\nprint(\"Best Score : \", gbm_cv_model.best_score_)\n\ny_pred = gbm_cv_model.predict(X_test)\n\nr_square = metrics.r2_score(y_test, y_pred)\nmse = metrics.mean_squared_error(y_test, y_pred)\nmae = metrics.median_absolute_error(y_test, y_pred)\nev = metrics.explained_variance_score(y_test, y_pred)\nmodels_and_scores.append(['GBM',  gbm_cv_model.best_score_])\n\nprint(\"Model Score            : \", model_score*100)\nprint(\"R Square               : \", r_square*100)\nprint(\"Mean Squared Error     : \", mse)\nprint(\"Root Mean Squared Error: \", mse**(1/2))\nprint(\"Median Absolute Error  : \", mae)\nprint(\"Explained Variance     : \", ev)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = ['sqft_living15','lat','sqft_basement', 'sqft_above', 'grade','view','sqft_basement', 'sqft_living', 'bathrooms', 'floors', 'waterfront','yr_built']\n\nImportance = pd.DataFrame({\n    'Importance': gbm_cv_model.best_estimator_.feature_importances_*100}, index=columns)\nImportance.sort_values(by=\"Importance\", axis=0, ascending=True).plot(kind=\"barh\", color=\"b\")\nplt.xlabel(\"Variable Importance\")\nplt.gca().legend_ = None","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## LightGBM","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df = df[['sqft_living15','lat','sqft_basement', 'sqft_above', 'grade','view','sqft_basement', 'sqft_living', 'bathrooms', 'floors', 'waterfront','yr_built']]\nX = new_df.values\ny = df.price.values\n\nX_train, X_test, y_train, y_test = train_test_split(X, y ,test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from lightgbm import LGBMRegressor\n\nlgbm = LGBMRegressor(random_state=42)\nlgbm.fit(X_train, y_train)\ny_pred = lgbm.predict(X_test)\n\nmodel_score = lgbm.score(X_test,y_test)\nr_square = metrics.r2_score(y_test, y_pred)\nmse = metrics.mean_squared_error(y_test, y_pred)\nmae = metrics.median_absolute_error(y_test, y_pred)\nev = metrics.explained_variance_score(y_test, y_pred)\n\nprint(\"Model Score            : \", model_score*100)\nprint(\"R Square               : \", r_square*100)\nprint(\"Mean Squared Error     : \", mse)\nprint(\"Root Mean Squared Error: \", mse**(1/2))\nprint(\"Median Absolute Error  : \", mae)\nprint(\"Explained Variance     : \", ev)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model Tuning\nparam_grid = {\n    \"learning_rate\": [0.01, 0.1, 0.5, 1],\n    \"n_estimators\": [20, 40, 100, 500, 1000],\n    \"max_depth\": [-1,1,3,5]\n}\n\nlgbm_model = LGBMRegressor(random_state=42)\nlgbm_cv_model = GridSearchCV(lgbm_model, param_grid, cv=10, n_jobs=-1, verbose=2)\nlgbm_cv_model.fit(X_train, y_train)\nprint(\"Best Params: \", lgbm_cv_model.best_params_)\nprint(\"Best Score : \", lgbm_cv_model.best_score_)\n\ny_pred = lgbm_cv_model.predict(X_test)\n\nr_square = metrics.r2_score(y_test, y_pred)\nmse = metrics.mean_squared_error(y_test, y_pred)\nmae = metrics.median_absolute_error(y_test, y_pred)\nev = metrics.explained_variance_score(y_test, y_pred)\nmodels_and_scores.append(['LightGBM',  lgbm_cv_model.best_score_])\n\nprint(\"Model Score            : \", model_score*100)\nprint(\"R Square               : \", r_square*100)\nprint(\"Mean Squared Error     : \", mse)\nprint(\"Root Mean Squared Error: \", mse**(1/2))\nprint(\"Median Absolute Error  : \", mae)\nprint(\"Explained Variance     : \", ev)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = ['sqft_living15','lat','sqft_basement', 'sqft_above', 'grade','view','sqft_basement', 'sqft_living', 'bathrooms', 'floors', 'waterfront','yr_built']\n\nImportance = pd.DataFrame({\n    'Importance': lgbm_cv_model.best_estimator_.feature_importances_*100}, index=columns)\nImportance.sort_values(by=\"Importance\", axis=0, ascending=True).plot(kind=\"barh\", color=\"b\")\nplt.xlabel(\"Variable Importance\")\nplt.gca().legend_ = None","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## CatBoost","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"from catboost import CatBoostRegressor\n\ncatb = CatBoostRegressor(random_state=42)\ncatb.fit(X_train, y_train)\ny_pred = catb.predict(X_test)\n\nmodel_score = catb.score(X_test,y_test)\nr_square = metrics.r2_score(y_test, y_pred)\nmse = metrics.mean_squared_error(y_test, y_pred)\nmae = metrics.median_absolute_error(y_test, y_pred)\nev = metrics.explained_variance_score(y_test, y_pred)\n\nprint(\"Model Score            : \", model_score*100)\nprint(\"R Square               : \", r_square*100)\nprint(\"Mean Squared Error     : \", mse)\nprint(\"Root Mean Squared Error: \", mse**(1/2))\nprint(\"Median Absolute Error  : \", mae)\nprint(\"Explained Variance     : \", ev)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model Score            :  81.43669400244507 <br>\nR Square               :  81.43669400244507 <br>\nMean Squared Error     :  28063395693.283432 <br>\nRoot Mean Squared Error:  167521.3290697141 <br>\nMedian Absolute Error  :  48228.138245502836 <br>\nExplained Variance     :  0.8144066661447161","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model Tuning\nparam_grid = {\n    \"iterations\": [200, 500, 1000],\n    'learning_rate': [0.01, 0.1],\n    \"depth\": [3,6,8]\n}\n\ncatb_model = LGBMRegressor(random_state=42)\ncatb_cv_model = GridSearchCV(catb_model, param_grid, cv=10, n_jobs=-1, verbose=2)\ncatb_cv_model.fit(X_train, y_train)\nprint(\"Best Params: \", catb_cv_model.best_params_)\nprint(\"Best Score : \", catb_cv_model.best_score_)\n\ny_pred = catb_cv_model.predict(X_test)\n\nr_square = metrics.r2_score(y_test, y_pred)\nmse = metrics.mean_squared_error(y_test, y_pred)\nmae = metrics.median_absolute_error(y_test, y_pred)\nev = metrics.explained_variance_score(y_test, y_pred)\nmodels_and_scores.append(['CatBoost',  catb_cv_model.best_score_])\n\nprint(\"Model Score            : \", model_score*100)\nprint(\"R Square               : \", r_square*100)\nprint(\"Mean Squared Error     : \", mse)\nprint(\"Root Mean Squared Error: \", mse**(1/2))\nprint(\"Median Absolute Error  : \", mae)\nprint(\"Explained Variance     : \", ev)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## And Finally - Comparison","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"models, scores = [], []\n\nfor x in models_and_scores:\n    models.append(x[0])\n    scores.append(x[1])\n\nplt.figure(figsize=(15,10))\nax = sns.barplot(x=scores, y=models, palette=\"Blues_d\")\nax.set_title(\"Models And Scores - Comparison\")\nax.set_ylabel(\"Models\")\nax.set_ylabel(\"Scores\")\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}