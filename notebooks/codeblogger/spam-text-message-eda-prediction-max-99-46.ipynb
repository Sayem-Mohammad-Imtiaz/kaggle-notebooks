{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"# Introduction \nWe will apply machine learning to this dataset with a total of 5572 messages. We will guess that the message received as a result of this application came from a man or a woman.\n\n\nContent:\n1. [Load and Check Data](#1)\n1. [Veriable Description](#2)\n1. [Categorical Variable](#3)\n1. [Missing Value](#4)\n1. [Cleaning](#5)\n    - [Regular Expression](#6)\n    - [Convert to lowercase](#7)\n    - [Split](#8)\n    - [Stopwords](#9)\n    - [Lemmatization](#10)\n1. [Bag Of Words](#11)\n1. [Modelling](#12)\n    - [Train Test Split](#13)\n    - [Naive Bayes](#14)\n    - [Simple Logistic Regression](#15)\n    - [KNN](#16)"},{"metadata":{},"cell_type":"markdown","source":"# Load and Check Data <a id=\"1\"></a>"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nplt.style.use(\"seaborn-whitegrid\")\nimport seaborn as sns\nfrom collections import Counter\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ndata = pd.read_csv(\"/kaggle/input/spam-text-message-classification/SPAM text message 20170820 - Data.csv\")\ndata.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Veriable Description <a id=\"2\"></a>\nThe data set consists of 2 columns.\n- Category: Indicates whether there is spam.\n- Message: Message post."},{"metadata":{},"cell_type":"markdown","source":"# Categorical Variable <a id=\"3\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def bar_plot(variable):\n    var = data[variable]\n    varValue = var.value_counts()\n    \n    # visualize\n    plt.figure(figsize=(9,3))\n    plt.bar(varValue.index, varValue)\n    plt.xticks(varValue.index,varValue.index.values)\n    plt.ylabel(\"Count\")\n    plt.title(variable)\n    plt.show()\n    print(\"{}: \\n{}\".format(variable,varValue))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bar_plot(\"Category\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As seen above, there are 4825 normal messages and 747 spam messages."},{"metadata":{},"cell_type":"markdown","source":"Let's look at the average length of normal and spam messages."},{"metadata":{"trusted":true},"cell_type":"code","source":"ham_message_length = []\nspam_message_length = []\nfor i in data.values:\n    if(i[0] == \"ham\"):\n        ham_message_length.append(len(i[1]))\n    else:\n        spam_message_length.append(len(i[1]))\n        \n# average\nham_average = sum(ham_message_length)/len(ham_message_length)\nspam_average = sum(spam_message_length)/len(spam_message_length)\nprint(\"ham_average: \", ham_average)\nprint(\"spam_average: \", spam_average)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(9,3))\nplt.bar([\"ham_average\",\"spam_average\"], [ham_average,spam_average])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Missing Value <a id=\"4\"></a>\nFirst of all, let's check if there is a missing value."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As can be seen from the above values, there is no missing data in this data set."},{"metadata":{},"cell_type":"markdown","source":"## Cleaning <a id=\"5\"></a>\nFirst, to apply machine learning to the dataset, we equal normal messages to 1 and spam messages to 0."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport re\nfrom nltk.corpus import stopwords\nimport nltk as nlp\nfrom sklearn.feature_extraction.text import CountVectorizer ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Category = [1 if each == \"ham\" else 0 for each in data.Category]\ndf = data\ndata","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Regular Expression <a id=\"6\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# for example\n\nexample = data.Message[0]\nprint(\"before: \", example)\n\nexample = re.sub(\"[^a-zA-Z]\",\" \",example)\nprint(\"after:\", example)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's apply the above example to all data."},{"metadata":{"trusted":true},"cell_type":"code","source":"regularExpressionMessages = []\nfor message in data[\"Message\"]:\n    message = re.sub(\"[^a-zA-Z]\",\" \",message)\n    regularExpressionMessages.append(message)\n\ndata[\"Message\"] = regularExpressionMessages\ndata","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Convert to lowercase <a id=\"7\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# for example\n\nexample = data.Message[0]\nprint(\"before: \", example)\n\nexample = example.lower()\nprint(\"after:\", example)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's apply the above example to all data."},{"metadata":{"trusted":true},"cell_type":"code","source":"lowercaseMessages = []\nfor message in data[\"Message\"]:\n    message = message.lower()\n    lowercaseMessages.append(message)\n\ndata[\"Message\"] = lowercaseMessages\ndata","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Split <a id=\"8\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# for example\n\nexample = data.Message[0]\nprint(\"before: \", example)\n\nexample = nlp.word_tokenize(example)\nprint(\"after:\", example)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's apply the above example to all data."},{"metadata":{"trusted":true},"cell_type":"code","source":"splitMessages = []\nfor message in data[\"Message\"]:\n    message = nlp.word_tokenize(message)\n    splitMessages.append(message)\n\ndata[\"Message\"] = splitMessages\ndata","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Stopwords <a id=\"9\"></a>\nHere it is:\n- It is to delete words that will not be useful for us while machine learning .\n- \"the\",\"in\", \"at\" like words can be given as examples."},{"metadata":{"trusted":true},"cell_type":"code","source":"# for example\n\nprint(\"before: \", data[\"Message\"][0] )\n\nmessage1 = [message for message in data[\"Message\"][0] if not message in set(stopwords.words(\"english\"))]\nprint(\"after: \", message1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's apply the above example to all data."},{"metadata":{"trusted":true},"cell_type":"code","source":"stopwordsMessages = []\nfor i in data[\"Message\"]:\n    i = [message for message in i if not message in set(stopwords.words(\"english\"))]\n    stopwordsMessages.append(i)\n\ndata[\"Message\"] = stopwordsMessages\ndata","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Lemmatization <a id=\"10\"></a>\nNow we need to find the roots of the separated words."},{"metadata":{"trusted":true},"cell_type":"code","source":"# for example\n\nexample = data.Message[6]\nprint(\"before: \", example)\n\nlemma = nlp.WordNetLemmatizer()\nexample = [ lemma.lemmatize(word) for word in example]\nprint(\"after:\", example)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"example = \" \".join(example)\nprint(\"example: \", example)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Like the example above, we can combine all the words and make them a sentence. In this way, we can now start machine learning."},{"metadata":{"trusted":true},"cell_type":"code","source":"joinMessages = []\nfor message in data[\"Message\"]:\n    message = \" \".join(message)\n    joinMessages.append(message)\n\ndata[\"Message\"] = joinMessages\ndata","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Bag Of Words <a id=\"11\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# for example\nsentence1 = \"I am coming from school\"\nsentence2 = \"I am coming from Istanbul today\"\n\nfrom sklearn.feature_extraction.text import CountVectorizer \ncount_vectorizer = CountVectorizer(max_features=5, stop_words=\"english\")\nsparce_matrix = count_vectorizer.fit_transform([sentence1,sentence2]).toarray()\nsparce_matrix","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's apply the above example to all data."},{"metadata":{"trusted":true},"cell_type":"code","source":"count_vectorizer = CountVectorizer(max_features=10000, stop_words=\"english\")\nsparce_matrix = count_vectorizer.fit_transform(np.array(data[\"Message\"])).toarray()\nsparce_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sparce_matrix.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# text classification\n\ny = data.iloc[:,0].values\nx = sparce_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Modelling <a id=\"12\"></a>\n## Train Test Split <a id=\"13\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=42)\n\nprint(\"x_train\",x_train.shape)\nprint(\"x_test\",x_test.shape)\nprint(\"y_train\",y_train.shape)\nprint(\"y_test\",y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Naive Bayes <a id=\"14\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\n\nnb = GaussianNB()\nnb.fit(x_train,y_train)\n\nprint(\"Accuracy: \", nb.score(x_test,y_test)*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Simple Logistic Regression <a id=\"15\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg = LogisticRegression()\nlogreg.fit(x_train,y_train)\nacc_log_train = round(logreg.score(x_train,y_train)*100,2)\nacc_log_test = round(logreg.score(x_test,y_test)*100,2)\nprint(\"Training Accuracy: %{}\".format(acc_log_train))\nprint(\"Testing Accuracy: %{}\".format(acc_log_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# KNN <a id=\"16\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors = 3)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('With KNN (K=3) accuracy is: ',knn.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SVM <a id=\"17\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\nsvm = SVC(random_state=1)\nsvm.fit(x_train,y_train)\n\nprint(\"accuracy of svm algo: \", svm.score(x_test,y_test)*100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decision Tree Regression <a id=\"18\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\ndt = DecisionTreeClassifier(random_state=42)\ndt.fit(x_train,y_train)\n\nprint(\"Decision Tree Score: \", dt.score(x_test,y_test)*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}