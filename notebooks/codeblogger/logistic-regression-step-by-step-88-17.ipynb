{"cells":[{"metadata":{},"cell_type":"markdown","source":"Logistic Regression is a Machine Learning classification algorithm that is used to predict the probability of a categorical dependent variable. In logistic regression, the dependent variable is a binary variable that contains data coded as 1 (yes, success, etc.) or 0 (no, failure, etc.). In other words, the logistic regression model predicts P(Y=1) as a function of X.\n\n# Logistic Regression Assumptions\n* Binary logistic regression requires the dependent variable to be binary.\n* For a binary regression, the factor level 1 of the dependent variable should represent the desired outcome.\n* Only the meaningful variables should be included.\n* The independent variables should be independent of each other. That is, the model should have little or no multicollinearity.\n* The independent variables are linearly related to the log odds.\n* Logistic regression requires quite large sample sizes. <br>\n\nKeeping the above assumptions in mind, let’s look at our dataset."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn import preprocessing\nimport matplotlib.pyplot as plt \nplt.rc(\"font\", size=14)\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import accuracy_score, mean_squared_error, confusion_matrix, classification_report\nimport seaborn as sns\nsns.set(style=\"white\")\nsns.set(style=\"whitegrid\", color_codes=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/biomechanical-features-of-orthopedic-patients/column_2C_weka.csv\")\ndata","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The data set has 310 rows and 7 different columns. These columns are:\n* pelvic incidence\n* pelvic tilt\n* lumbar lordosis angle\n* sacral slope\n* pelvic radius\n* grade of spondylolisthesis\n* class\n\nLet's get information about the values ​​in the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"class\"].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We examined its statistical values. But such is not just data analysis with numbers. Now let's try to better understand the dataset with some visuals.\n\n# Data Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"class\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(y=\"class\", data=data, palette=\"hls\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def localSubplot(data,feature):\n    fig, ax = plt.subplots(nrows=1,ncols=2,figsize=(12,6))\n    \n    data[feature].value_counts().plot(kind=\"bar\",ax=ax[0])\n    data[feature].value_counts().plot.pie(autopct=\"%1.1f%%\",ax=ax[1])\n    \n    plt.tight_layout()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"localSubplot(data=data,feature=\"class\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.hist(bins=10, density=True, figsize= (12,8))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(nrows=2, ncols=3, figsize=(12,8))\nax = ax.flatten()\ncol_names = data.drop('class',axis=1).columns.values\n\nfor i,col_name in enumerate(col_names):\n    sns.distplot(a=data[col_name], ax=ax[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr= data.corr()\nfig, ax=plt.subplots(1,1,figsize=(12,8))\nsns.heatmap(corr, annot=True, linewidth=5, ax=ax);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression - Model Tuning\n\n## Method 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"class\"] = [ 1 if each == \"Abnormal\" else 0 for each in data[\"class\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data.loc[:, data.columns != 'class']\ny = data.loc[:, data.columns == 'class']\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state=42)\nlg = LogisticRegression().fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy: \",lg.score( X_test,y_test)*100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Method 2"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = lg.predict(X)\nprint(classification_report(y,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = lg.predict(X_test)\nprint(\"Accuracy: \",accuracy_score(y_test,y_pred)*100)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}