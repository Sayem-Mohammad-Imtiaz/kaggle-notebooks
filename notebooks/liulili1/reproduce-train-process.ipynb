{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport sys\nsys.path.insert(0,'../input/timm-pytorch-image-models/pytorch-image-models-master')\nimport timm\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset,DataLoader\nfrom torch.utils.data.sampler import SubsetRandomSampler, RandomSampler, SequentialSampler\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nimport albumentations as A","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# some hyperparameters"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_path = '../input/issm2020-ai-challenge/semTrain/semTrain'\nepoch = 10\nimg_image = 384\nmodel_name = 'tf_efficientnet_b4'\nfold = 5\nclass_num = 10 \ndevice = 'cuda'\nbatch_size = 15\nval_batch_size = 3\nexperience = True","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# make dataset\ntrain_data = []\nfor target in os.listdir(train_path):\n    for image in os.listdir(os.path.join(train_path,target)):\n        train_data.append([os.path.join(train_path,target,image),int(target)-1])\ndf_train = pd.DataFrame(train_data,columns=['image','target'],index=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create dataset\nclass IssmDataset(Dataset):\n    def __init__(self, df, mode='train',transform=None):\n        self.df = df\n        self.mode = mode\n        self.transform = transform\n    def __len__(self):\n        return len(self.df)\n    def __getitem__(self,index):\n        row = self.df.iloc[index]\n        img,label = row.image, row.target\n        img = cv2.imread(img)\n        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n        if self.transform:\n            img = self.transform(image=img)['image'].astype(np.float32)\n        else:\n            img = img.astype(np.float32)\n        img = img.transpose(2,0,1)\n        data = torch.tensor(img).float()\n        if self.mode == 'test':\n            return data\n        else:\n            return data, torch.tensor(label).long()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #test\n# checkset = df_train.reset_index(drop=True)\n# cdataset = IssmDataset(checkset)\n# from pylab import rcParams\n# rcParams['figure.figsize'] = 15,10\n# for i in range(3):\n#     _,pos = plt.subplots(1,4)\n#     for j in range(4):\n#         idx = np.random.randint(len(cdataset))\n#         img, label = cdataset[idx]\n#         # print(img)\n#         img /= 255\n#         pos[j].imshow(img.transpose(0,1).transpose(1,2))\n#         pos[j].set_title(label)\n#         pos[j].axis('off')\n#         # plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transform = A.Compose([\n    A.VerticalFlip(p=0.5),\n    A.HorizontalFlip(p=0.5),\n    A.RandomBrightness(limit=0.05,p=0.5),\n    A.ShiftScaleRotate(shift_limit=0.1,scale_limit=0.1,p=0.3),\n    A.OneOf([\n        A.MotionBlur(blur_limit=5),\n        A.MedianBlur(blur_limit=5),\n        A.GaussianBlur(blur_limit=5,sigma_limit=0.1),\n        A.GaussNoise(var_limit=(5.0, 30.0)),\n    ], p=0.5),\n    A.OneOf([\n        A.OpticalDistortion(distort_limit=1.0),\n        A.GridDistortion(num_steps=5, distort_limit=1.),\n        A.ElasticTransform(alpha=3),\n    ], p=0.5),\n    A.Resize(img_image,img_image),\n    A.Cutout(max_h_size=int(img_image * 0.1), max_w_size=int(img_image * 0.1), num_holes=2, p=0.7),    \n    A.Normalize()\n    ])\n\ntest_transform = A.Compose([\n    A.Resize(img_image,img_image),\n    A.Normalize()]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #test\n# checkset = df_train.reset_index(drop=True)\n# cdataset = IssmDataset(checkset,transform=train_transform)\n# from pylab import rcParams\n# rcParams['figure.figsize'] = 15,10\n# for i in range(3):\n#     _,pos = plt.subplots(1,4)\n#     for j in range(4):\n#         idx = np.random.randint(len(cdataset))\n#         img, label = cdataset[idx]\n#         # img = cv2.cvtColor(img,cv2.COLOR_RGB2BGR)\n#         # print(img)\n#         # img /= 255\n#         pos[j].imshow(img.transpose(0,1).transpose(1,2))\n#         pos[j].set_title(label)\n#         pos[j].axis('off')\n#         # plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model(model_name, out_features, drop_rate=0.5):\n    model = timm.create_model(model_name, pretrained=True)\n    model.drop_rate = drop_rate\n    model.classifier = nn.Linear(model.classifier.in_features,out_features)\n    return model\n\neff_model = get_model(model_name,10)\neff_model.to(device)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class LabelSmoothLoss(nn.Module):\n    def __init__(self, smoothing=0.0):\n        super(LabelSmoothLoss, self).__init__()\n        self.smoothing = smoothing\n    \n    def forward(self, input, target):\n        log_prob = F.log_softmax(input, dim=-1)\n        weight = input.new_ones(input.size()) * \\\n            self.smoothing / (input.size(-1) - 1.)\n        weight.scatter_(-1, target.unsqueeze(-1), (1. - self.smoothing))\n        loss = (-weight * log_prob).sum(dim=-1).mean()\n        return loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = optim.SGD(eff_model.parameters(),lr=0.01,momentum=0.9)\nschduler = CosineAnnealingLR(optimizer, T_max=epoch)\n# criterion = nn.CrossEntropyLoss() \ncriterion = LabelSmoothLoss()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_one_epoch(model,optimizer,criterion,data_loader):\n    print('run No.{} epoches, lr = {}'.format(epoch,optimizer.param_groups[0]['lr']))\n    model.train()\n    train_loss = []\n    for data,label in data_loader:\n        optimizer.zero_grad()\n        data,label = data.to(device),label.to(device)\n        pred = model(data)\n        loss = criterion(pred, label)\n        loss.backward()\n        optimizer.step()\n        loss_np = loss.detach().cpu().numpy()\n        train_loss.append(loss_np)\n        average_loss = sum(train_loss[-100:])/min(len(train_loss),100)\n        print('average loss = {}, loss = {}'.format(average_loss, loss))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def val_epoch(model,optimizer,criterion,data_loader):\n    model.eval()\n    loss_sum = []\n    with torch.no_grad():\n        for data,label in data_loader:\n            data,label = data.to(device),label.to(device)\n            pred = model(data)\n            loss = criterion(pred, label)\n            loss_np = loss.detach().cpu().numpy()\n            loss_sum.append(loss_np)\n            average_loss = sum(loss_sum)/len(loss_sum)\n        print('average loss = {}'.format(average_loss))\n        \n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# cross validation "},{"metadata":{"trusted":true},"cell_type":"code","source":"def preparedata(train_idx,val_idx,df=df_train):\n    train_=df_train.loc[train_idx,:].reset_index(drop=True)\n    val_=df_train.loc[val_idx,:].reset_index(drop=True)\n    train_ds = IssmDataset(train_,'train',train_transform)\n    val_ds = IssmDataset(val_,'test',test_transform)\n    train_loader = DataLoader(train_ds,batch_size=batch_size,shuffle=True,num_workers=4)\n    val_loader = DataLoader(val_ds,batch_size=val_batch_size,shuffle=False,num_workers=4)\n    return train_loader,val_loader","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nkf = StratifiedKFold(n_splits=fold,shuffle=False)\nfor train_index , test_index in kf.split(df_train.image,df_train.target):\n    train_loader,val_loader = preparedata(train_index,test_index)\n    if not experience: \n        train_one_epoch(eff_model,optimizer,criterion,train_loader)\n        val_epoch(eff_model,optimizer,criterion,val_loader)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}