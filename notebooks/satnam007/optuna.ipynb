{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Optuna","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn import ensemble\nfrom sklearn import metrics\nfrom sklearn import model_selection\nfrom sklearn import preprocessing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import optuna\n\nfrom functools import partial\nfrom skopt import space\nfrom skopt import gp_minimize\nfrom hyperopt.pyll.base import scope #for the format int","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/mobile-price-classification/train.csv')\nX  = df.drop('price_range', axis = 1).values\ny  = df['price_range'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def optimize(trials, x, y):\n    criterion     = trials.suggest_categorical(\"criterion\", [\"gini\", \"entropy\"])\n    n_estimators  = trials.suggest_int(\"n_estimators\", 20, 2000)\n    max_depth     = trials.suggest_int(\"max_depth\", 3, 25)\n    max_features  = trials.suggest_uniform(\"max_features\", 0.1, 1.0)\n    \n    model  = ensemble.RandomForestClassifier(\n        n_estimators = n_estimators,\n        max_depth    = max_depth,\n        max_features = max_features,\n        criterion    = criterion\n    )\n    kf     = model_selection.StratifiedKFold(n_splits = 5)\n    \n    accuracies = []\n    for idx in kf.split(X=x, y=y):\n        train_idx, test_idx = idx[0], idx[1]\n        \n        xtrain = x[train_idx]\n        ytrain = y[train_idx]\n        xtest = x[test_idx]\n        ytest = y[test_idx]\n        \n        model.fit(xtrain, ytrain)\n        preds = model.predict(xtest)\n        fold_acc = metrics.accuracy_score(ytest, preds)\n        \n        accuracies.append(fold_acc)\n    \n    return -1*np.mean(accuracies)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimization_func = partial(optimize, x = X, y = y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# direction = \"minimize\" bcz we are multiplying np.mean(accuracies) with -1\n# direction = \"maximize\" if  we are multiplying np.mean(accuracies) with 1\n\nstudy = optuna.create_study(direction = \"minimize\")\nstudy.optimize(optimization_func, n_trials = 15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"https://optuna.org/","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":" print(study.best_trial)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = ensemble.RandomForestClassifier(criterion ='entropy', max_depth = 16, \n                                        max_features = 0.8356537680916444, n_estimators = 1383, n_jobs=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nscore = cross_val_score(classifier,X,y, cv=10)\nprint('scores\\n',score)\nprint('\\ncv values', score.shape)\nprint('\\nScore_Mean', score.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}