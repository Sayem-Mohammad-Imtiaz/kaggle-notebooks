{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Reconhecedor de Placas de Sinalização de Trânsito\n### PSI3571 - Práticas em Reconhecimento de Padrões, Modelagem e Inteligência Computacional\n\nAtividade da P2 da disciplina PSI3571","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Setup","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport math\n\nimport cv2\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nimport seaborn as sns\n\nfrom skimage import exposure\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.layers import Activation\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Dense\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_state = 3571\n\nnp.random.seed(random_state)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# link = 'GTSRB/Final_Training/Images/' # Local\nlink = '../input/gtsrb-german-traffic-sign/' # Kaggle","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Descrição","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Observando a descrição do dataset, é possível encontrar a relação entre os valores numéricos de ```ClassId``` e as descrições das placas com classificação e tipo de cada placa.\n\nA informação de tipo é importante pois placas de mesmo tipo têm forma similar. Por exemplo, placas do tipo ```prohibitory``` são circulares e com borda vermelha, enquanto placas do tipo ```danger``` são triangulares e também com borda vermelha. Já as placas ```mandatory``` são placas circulares e preenchidas em azul. Por fim, as placas identificada como ```other``` possuem formas distintas.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"GTSRBInfo = pd.DataFrame({\n    0:  { 'Type': 'prohibitory',  'Label': \"speed limit 20\"                         },\n    1:  { 'Type': 'prohibitory',  'Label': \"speed limit 30\"                         },\n    2:  { 'Type': 'prohibitory',  'Label': \"speed limit 50\"                         },\n    3:  { 'Type': 'prohibitory',  'Label': \"speed limit 60\"                         },\n    4:  { 'Type': 'prohibitory',  'Label': \"speed limit 70\"                         },\n    5:  { 'Type': 'prohibitory',  'Label': \"speed limit 80\"                         },\n    6:  { 'Type': 'other',        'Label': \"restriction ends 80\"                    },\n    7:  { 'Type': 'prohibitory',  'Label': \"speed limit 100\"                        },\n    8:  { 'Type': 'prohibitory',  'Label': \"speed limit 120\"                        },\n    9:  { 'Type': 'prohibitory',  'Label': \"no overtaking\"                          },\n    10: { 'Type': 'prohibitory',  'Label': \"no overtaking (trucks)\"                 },\n    11: { 'Type': 'danger',       'Label': \"priority at next intersection\"          },\n    12: { 'Type': 'other',        'Label': \"priority road\"                          },\n    13: { 'Type': 'other',        'Label': \"give way\"                               },\n    14: { 'Type': 'other',        'Label': \"stop\"                                   },\n    15: { 'Type': 'prohibitory',  'Label': \"no traffic both ways\"                   },\n    16: { 'Type': 'prohibitory',  'Label': \"no trucks\"                              },\n    17: { 'Type': 'other',        'Label': \"no entry\"                               },\n    18: { 'Type': 'danger',       'Label': \"danger\"                                 },\n    19: { 'Type': 'danger',       'Label': \"bend left\"                              },\n    20: { 'Type': 'danger',       'Label': \"bend right\"                             },\n    21: { 'Type': 'danger',       'Label': \"bend\"                                   },\n    22: { 'Type': 'danger',       'Label': \"uneven road\"                            },\n    23: { 'Type': 'danger',       'Label': \"slippery road\"                          },\n    24: { 'Type': 'danger',       'Label': \"road narrows\"                           },\n    25: { 'Type': 'danger',       'Label': \"construction\"                           },\n    26: { 'Type': 'danger',       'Label': \"traffic signal\"                         },\n    27: { 'Type': 'danger',       'Label': \"pedestrian crossing\"                    },\n    28: { 'Type': 'danger',       'Label': \"school crossing\"                        },\n    29: { 'Type': 'danger',       'Label': \"cycles crossing\"                        },\n    30: { 'Type': 'danger',       'Label': \"snow\"                                   },\n    31: { 'Type': 'danger',       'Label': \"animals\"                                },\n    32: { 'Type': 'other',        'Label': \"restriction ends\"                       },\n    33: { 'Type': 'mandatory',    'Label': \"go right\"                               },\n    34: { 'Type': 'mandatory',    'Label': \"go left\"                                },\n    35: { 'Type': 'mandatory',    'Label': \"go straight\"                            },\n    36: { 'Type': 'mandatory',    'Label': \"go right or straight\"                   },\n    37: { 'Type': 'mandatory',    'Label': \"go left or straight\"                    },\n    38: { 'Type': 'mandatory',    'Label': \"keep right\"                             },\n    39: { 'Type': 'mandatory',    'Label': \"keep left\"                              },\n    40: { 'Type': 'mandatory',    'Label': \"roundabout\"                             },\n    41: { 'Type': 'other',        'Label': \"restriction ends (overtaking)\"          },\n    42: { 'Type': 'other',        'Label': \"restriction ends (overtaking (trucks))\" },\n}).T\n\n# Adiciona ClassId como coluna da tabela\nGTSRBInfo.index.name = 'ClassId'\nGTSRBInfo.reset_index(inplace=True)\n\n# Transforma Label em valor categórico\nGTSRBInfo['Label'] = GTSRBInfo.Label.astype('category')\n\n# Transforma Type em valor categórico e ordena de acordo com a quantidade de dados\nTypes = GTSRBInfo.Type.value_counts().index\nGTSRBInfo['Type'] = GTSRBInfo.Type.astype('category').cat.reorder_categories(Types)\nGTSRBInfo['TypeId'] = GTSRBInfo.Type.cat.codes\n\nGTSRBInfo","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plotTrafficSigns(dataset, imRead=lambda classe: plt.imread(classe.Path), maxCols=5, random_state=None):\n    for Type in Types:\n        classes = dataset[dataset.Type == Type]\n        classLabels = classes.ClassId.unique()\n\n        nRows = math.ceil(classLabels.size / maxCols)\n        nCols = min(classLabels.size, maxCols)\n\n        fig, axs = plt.subplots(\n            nrows = nRows,\n            ncols = nCols,\n            figsize = (4*nCols, 3*nRows + 2),\n        )\n\n        for i, pos in enumerate(np.ndindex(axs.shape)):\n            try:\n                classe = dataset[dataset.ClassId == classLabels[i]].sample(1, random_state=random_state).iloc[0]\n\n                axs[pos].imshow(imRead(classe))\n                axs[pos].set_title(\"{}: {}\".format(classe.ClassId, classe.Label))\n\n            except:\n                pass\n\n            axs[pos].axis('off')\n\n        fig.suptitle(Type.capitalize(), fontsize='xx-large')\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apenas no kaggle\nmetaRead = lambda classe: plt.imread(\"../input/gtsrb-german-traffic-sign/Meta/{}.png\".format(classe.ClassId))\n                                     \nplotTrafficSigns(dataset=GTSRBInfo, imRead=metaRead)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"sns.countplot(\n    x='Type',\n    data=GTSRBInfo,\n).set_title('Quantidade de placas de cada formato')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Carregando o dataset","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Vamos primeiramente carregar o dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\n# # Concatena os diferentes .csv em um único DataFrame (Apenas local)\n# fileName = lambda i: link + \"{0:05d}/GT-{0:05d}.csv\".format(int(i))\n# GTSRB = pd.concat((pd.read_csv(fileName(i), delimiter = ';') for i in GTSRBInfo.ClassId), ignore_index = True)\n\n# # Corrige o caminho das figuras\n# GTSRB.Filename = GTSRB.ClassId.map(lambda ID: link + \"{:05d}/\".format(ID)) + GTSRB.Filename\n\n# Carrega o .csv único disponível (Apenas no Kaggle)\nGTSRB = pd.read_csv(link + \"Train.csv\")\nGTSRB.Path = link + GTSRB.Path\n\n# União do dataset e das descrições\nGTSRB = GTSRB.merge(GTSRBInfo, on=\"ClassId\")\n\n# Cria lista ordenada das placas disponíveis\nLabels = GTSRB.Label.value_counts().index\n\nGTSRB.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GTSRB.sample(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Análise dos dados","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Informações sobre as figuras","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Inicialmente, vamos observar dados relativos aos valores de ```Height``` e ```Width``` das figuras disponíveis. Aqui pode-se notar que as figuras não são necessariamente quadradas e que possuem tamanhos distintos, variando, em cada eixo, de 25 pixels a até mais de 200 pixels.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"GTSRB[['Width', 'Height']].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(1, 2, figsize=(15, 5), sharex=True)\n\nsns.distplot(\n    GTSRB.Width,\n    bins=25,\n    kde=False,\n    color='red',\n    ax=axs[0],\n)\naxs[0].set_title(\"Distribuição de valores de largura (em px)\")\naxs[0].set_xlabel(\"Largura\")\naxs[0].set_ylabel(\"Frequência\")\n\nsns.distplot(\n    GTSRB.Height,\n    bins=25,\n    kde=False,\n    color='blue',\n    ax=axs[1]\n)\naxs[1].set_title(\"Distribuição de valores de altura (em px)\")\naxs[1].set_xlabel(\"Altura\")\naxs[1].set_ylabel(\"Frequência\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Outra informação relacionada é a largura e a altura efetivamente úteis em cada imagem:  \n\n$$H_{efet} = |Y_2 - Y_1|$$\n$$W_{efet} = |X_2 - X_1|$$","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"H_efet = (GTSRB['Roi.Y2'] - GTSRB['Roi.Y1']).abs()\nW_efet = (GTSRB['Roi.X2'] - GTSRB['Roi.X1']).abs()\n\nW_efet.name = 'Largura efetiva'\nH_efet.name = 'Altura efetiva'\n\npd.concat([W_efet, H_efet], axis=1, names=['a', 'b']).describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(1, 2, figsize=(15, 5), sharex=True)\n\nsns.distplot(\n    W_efet,\n    bins=25,\n    kde=False,\n    color='red',\n    ax=axs[0]\n)\naxs[0].set_title(\"Distribuição de valores de largura útil (em px)\")\naxs[0].set_ylabel(\"Frequência\")\n\nsns.distplot(\n    H_efet,\n    bins=25,\n    kde=False,\n    color='blue',\n    ax=axs[1]\n)\naxs[1].set_title(\"Distribuição de valores de altura útil (em px)\")\naxs[1].set_ylabel(\"Frequência\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Informações sobre as placas disponíveis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Outra informação relevante se dá sobre a quantidade de dados disponíveis para cada placa:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(\n    x='Type',\n    data=GTSRB,\n).set_title(\"Quantidade de exemplos para cada tipo de placa\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 5))\nplt.xticks(rotation=90)\n\nLabelsType = GTSRBInfo.set_index('Label').loc[Labels].TypeId\npalette = np.asarray(sns.color_palette())[LabelsType]\n\nsns.countplot(\n    x='Label',\n    data=GTSRB,\n    palette=palette,\n    order=Labels,\n).set_title(\"Quantidades de exemplos para cada placa\")\n\nplt.legend(handles=[\n    mpatches.Patch(color=barColor, label=barType)\n    for barColor, barType\n    in zip(sns.color_palette(), Types)\n])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualização das placas","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Vamos agora observar um exemplo de cada placa presente no dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plotTrafficSigns(GTSRB, random_state=random_state)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tratamento dos dados","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Agora que já pudemos observar os dados disponíveis, faremos alguns tratamentos para possibilitar o uso das imagens pelo modelo e para obtermos melhores resultados.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Data Augmentation","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Como nossos conjunto de dados não possui tantas imagens, uma prática recomendada nos próprios [exemplos do keras](https://keras.io/examples/vision/image_classification_from_scratch/) é a de usar a técnica de *data augmentation*. Através dela, podemos gerar novas imagens a partir das imagens presentes no dataset através da aplicação de pequenas transformações, como por exemplos pequenas rotações ou translações da imagem original, conforme definiremos abaixo.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataAugmentation = {\n    'rotation_range': 10,\n    'zoom_range': 0.15,\n    'width_shift_range': 0.1,\n    'height_shift_range': 0.1,\n    'shear_range': 0.15,\n}\n\nimageGenerator = ImageDataGenerator(**dataAugmentation)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tratamento e leitura das imagens","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Neste item definiremos uma série de tratamentos sobre cada imagem que será carregada, para que elas possam ser corretamente mapeadas para as entradas da rede neural e para que os resultados do modelo sejam melhores. Os tratamentos feitos serão:\n\n1. Redimensionar imagens para um mesmo tamanho  \n   O objetivo aqui é que todas as imagens tenham o mesmo número de valores para que eles possam ser mapeados na entrada da rede neural.\n\n1. Normalizar o contraste nas figuras  \n   O objetivo é tornar os detalhes das placas mais nítidos e mais distintos de elementos de fundo.\n\n1. A região de interesse, onde de fato a placa se encontra, não necessariamente equivale a toda a área da imagem. (TODO)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"imageShape = {\n    'height': 32,\n    'width': 32,\n    'depth': 3,\n}\n\ndef imageTreatment(image):\n    treatedImage = cv2.resize(image, (imageShape['width'], imageShape['height']))\n    treatedImage = exposure.equalize_adapthist(treatedImage, clip_limit=0.1)\n    # Corte?\n\n    return treatedImage","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nImages = GTSRB.Path.map(plt.imread).map(imageTreatment)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Visualização dos resultados do tratamento","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plotTrafficSigns(GTSRB, imRead=lambda classe: Images[classe.name], random_state=random_state)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Codificação das classes de saída","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Nesta etapa faremos um procedimento adicional para que os dados possam ser utilizados pelo nosso modelo de rede neural:\n   \n1. Aplicação de One-Hot Encoding nos valores de `Label`, usados como saída do modelo\n   Este tratamento é necessário pois a rede neural só é capaz de fornecer resultados de ponto flutuante em um pequeno intervalo e estes valores estão associados à intensidade da ativação de um determinado neurônio. Assim, uma maneira de obter um resultado melhor é utilizando a técnica de One-Hot Encoding e realizar a classificação com base no neurônio de saída que ficou ativo com maior intensidade.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"oneHotLabels = pd.get_dummies(GTSRB.Label)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Divisão em dados de treinamento e de validação","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Ainda antes de iniciarmos o treinamento, vamos dividir o dataset em um conjunto de dados especifiamente para treinamento e outro conjunto de dados para validação dos resultados. Assim, poderemos observar a qualidade do classificador com base em métricas de interesse e com dados que não foram utilizados anteriormente.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(\n    np.stack(Images),\n    oneHotLabels,\n    test_size=0.10,\n    random_state=random_state\n)\n\nprint(\"Dados de treinamento: {:5d}/{}\".format(len(X_train), len(GTSRB)))\nprint(\"Dados de validação:   {:5d}/{}\".format(len(X_val), len(GTSRB)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Treinamento - Classificação","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Agora que já temos todos os dados carregadores e que já observamos as informações que temos disponíveis, vamos iniciar o treinamento de um modelo para a classificação de placas de trânsito, ou seja, dada uma imagem de uma placa, o modelo deve nos fornecer o correto valor de `ClassId`.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Definição do modelo","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Vamos primeiramente criar um modelo baseado em Redes Neurais utilizando o `Keras`. Nesta etapa será criada a **Rede Neural** e definiremos quais serão as camadas desta rede.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"nClasses = Labels.size\ninputShape = (imageShape['height'], imageShape['width'], imageShape['depth'])\n\nTrafficSignNet = Sequential()\n\n# Primeira camada: Convolucional -> BatchNormalization -> MaxPooling\nTrafficSignNet.add(Conv2D(8, (5, 5), padding=\"same\", input_shape=inputShape))\nTrafficSignNet.add(Activation(\"relu\"))\nTrafficSignNet.add(BatchNormalization(axis=-1))\nTrafficSignNet.add(MaxPooling2D(pool_size=(2, 2)))\n\n# Segunda camada: Convolucional -> Relu -> BatchNormalization -> Convolucional -> Relu -> BatchNormalization -> MaxPooling\nTrafficSignNet.add(Conv2D(16, (3, 3), padding=\"same\"))\nTrafficSignNet.add(Activation(\"relu\"))\nTrafficSignNet.add(BatchNormalization(axis=-1))\nTrafficSignNet.add(Conv2D(16, (3, 3), padding=\"same\"))\nTrafficSignNet.add(Activation(\"relu\"))\nTrafficSignNet.add(BatchNormalization(axis=-1))\nTrafficSignNet.add(MaxPooling2D(pool_size=(2, 2)))\n\n# Terceira camada: Convolucional -> Relu -> BatchNormalization -> Convolucional -> Relu -> BatchNormalization -> MaxPooling\nTrafficSignNet.add(Conv2D(32, (3, 3), padding=\"same\"))\nTrafficSignNet.add(Activation(\"relu\"))\nTrafficSignNet.add(BatchNormalization(axis=-1))\nTrafficSignNet.add(Conv2D(32, (3, 3), padding=\"same\"))\nTrafficSignNet.add(Activation(\"relu\"))\nTrafficSignNet.add(BatchNormalization(axis=-1))\nTrafficSignNet.add(MaxPooling2D(pool_size=(2, 2)))\n\n# Quarta camada: Flatten -> Relu -> BatchNormalization -> DropOut\nTrafficSignNet.add(Flatten())\nTrafficSignNet.add(Dense(128))\nTrafficSignNet.add(Activation(\"relu\"))\nTrafficSignNet.add(BatchNormalization())\nTrafficSignNet.add(Dropout(0.5))\n\n# Quinta camada: Flatten -> Relu -> BatchNormalization -> DropOut\nTrafficSignNet.add(Flatten())\nTrafficSignNet.add(Dense(128))\nTrafficSignNet.add(Activation(\"relu\"))\nTrafficSignNet.add(BatchNormalization())\nTrafficSignNet.add(Dropout(0.5))\n\n# Sexta camada: Softmax\nTrafficSignNet.add(Dense(nClasses))\nTrafficSignNet.add(Activation(\"softmax\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Por fim, vamos definir os pesos de acordo com o número de elementos de cada classe. Esta abordagem é usada por conta do desbalanceamento no número de imagens disponíveis para cada classe no dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"classTotals = y_train.sum(axis=0)\nclassWeights = classTotals.max() / classTotals\n\nclassWeight = {\n    i: classWeight\n    for i, classWeight in enumerate(classWeights)\n}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Treinamento do modelo","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Com o modelo definido, vamos agora compilá-lo e vamos também adicionar o optimizador Adam.\n\nDepois disso, vamos treinar este modelo com base nos dados de treinamento que temos disponíveis.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"numEpochs = 30\nlearningRate = 1e-3\n\nTrafficSignNet.compile(\n    loss=\"categorical_crossentropy\",\n    optimizer=Adam(lr=learningRate, decay=(learningRate/(0.5 * numEpochs))),\n    metrics=[\"accuracy\"]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nbatchSize = 64\n\nH = TrafficSignNet.fit_generator(\n    imageGenerator.flow(X_train, y_train, batch_size=batchSize),\n    validation_data=(X_val, y_val),\n    steps_per_epoch=(len(X_train) // batchSize),\n    epochs=numEpochs,\n    class_weight=classWeight,\n    verbose=True\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(np.arange(numEpochs), H.history['accuracy'], label='train_acc')\nplt.plot(np.arange(numEpochs), H.history['val_accuracy'], label='val_acc')\nplt.title(\"Acurácia ao longo do treinamento.\")\nplt.xlabel(\"Época\")\nplt.ylabel(\"Acurácia\")\nplt.legend(loc=\"lower right\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Desempenho do modelo","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Vamos primeiramente observar o desempenho do modelo com base nos dados de validação.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = TrafficSignNet.predict(X_val, batch_size=batchSize)\n\nreport = classification_report(\n    np.asarray(y_val).argmax(axis=1),\n    predictions.argmax(axis=1),\n    target_names=y_val.columns\n)\n\nprint(report)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Resultados para os dados de teste","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Por fim, vamos realizar a classificação dos dados de teste e, então, vamos observar a qualidade da classificação feita.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"GTSRBTest = pd.read_csv(link + \"Test.csv\")\nGTSRBTest.Path = link + GTSRBTest.Path\n\n# União do dataset e das descrições\nGTSRBTest = GTSRBTest.merge(GTSRBInfo, on=\"ClassId\")\n\nGTSRBTest.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imagesTest = GTSRBTest.Path.map(plt.imread).map(imageTreatment)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictionsTest = TrafficSignNet.predict(np.stack(imagesTest), batch_size=batchSize)\ny_test = pd.get_dummies(GTSRBTest.Label)\n\nreportTest = classification_report(\n    np.asarray(y_test).argmax(axis=1),\n    predictionsTest.argmax(axis=1),\n    target_names=y_test.columns\n)\n\nprint(reportTest)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Matriz de confusão","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(22, 12))\n\nsns.heatmap(\n    confusion_matrix(predictionsTest.argmax(axis=1), np.asarray(y_test).argmax(axis=1)),\n    cmap=plt.cm.RdYlGn_r,\n    xticklabels=y_test.columns,\n    yticklabels=y_test.columns,\n    annot=True,\n    fmt='g'\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualização de classificações incorretas","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"wrongPredicted = GTSRBTest.copy()\nwrongPredicted.Label = wrongPredicted.Label.astype(str) + '\\n' + \"Res: \" + y_test.columns[predictionsTest.argmax(axis=1)].astype(str)\n\nplotTrafficSigns(\n    wrongPredicted[predictionsTest.argmax(axis=1) != np.asarray(y_test).argmax(axis=1)],\n    imRead=lambda classe: imagesTest[classe.name],\n    random_state=random_state\n)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}