{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nfrom scipy import stats\nfrom scipy.stats import norm\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing Data\nraw_data=pd.read_csv('../input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=raw_data.copy()\ndata","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The id column is not relevant\ndata.drop(columns=['id'],inplace=True) \ndata","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Descriptive Analytics","metadata":{}},{"cell_type":"code","source":"data.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Handling Missing Values","metadata":{}},{"cell_type":"code","source":"def draw_missing_data_table(data):\n    total = data.isnull().sum().sort_values(ascending=False)\n    percent = (data.isnull().sum()/data.isnull().count()).sort_values(ascending=False)\n    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    return missing_data\ndraw_missing_data_table(data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Imputing the missing values with the mean\ndata=data.fillna(np.mean(data['bmi']))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Classifying data into numerical and categorical variables.\ndata_numerical=data[['age','avg_glucose_level','bmi']]\ndata_categorical=data[['gender', 'hypertension', 'heart_disease', 'ever_married','work_type', 'Residence_type', \n                       'smoking_status', 'stroke']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Skewness and kurtosis\ns_k=[]\nfor i in data_numerical.columns:\n    s_k.append([i,data_numerical[i].skew(),data_numerical[i].kurt()])\nskew_kurt=pd.DataFrame(s_k,columns=['Columns','Skewness','Kurtosis'])\nskew_kurt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Analysis with Stroke","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(20,13))\ngs = fig.add_gridspec(3,3)\ngs.update(wspace=0.4, hspace=0.4)\n# adding figures\nax0 = fig.add_subplot(gs[0,0])\nax1 = fig.add_subplot(gs[0,1])\nax2 = fig.add_subplot(gs[1,0])\nax3 = fig.add_subplot(gs[1,1])\nax4 = fig.add_subplot(gs[2,0])\nax5 = fig.add_subplot(gs[2,1])\naxes=[ax0,ax1,ax2,ax3,ax4,ax5]\nbackground_color = '#f6f5f7'\nfor i in axes:\n    i.set_facecolor(background_color)\nfig.patch.set_facecolor(background_color) \n#https://www.geeksforgeeks.org/kde-plot-visualization-with-pandas-and-seaborn/\nsns.kdeplot(ax=ax0,x=data.loc[data['stroke']==1]['age'],color='crimson',label='Stroke',shade=True)\nsns.kdeplot(ax=ax0,x=data.loc[data['stroke']==0]['age'],color='coral',label='No Stroke',shade=True)\nax0.legend(loc = 'upper left')\nax0.grid(linestyle='--', axis='y')\n\nax1.text(0.5,0.5,'Distribution of Age wrt Stroke',horizontalalignment = 'center',verticalalignment = 'center',fontsize = 18,fontfamily='serif')\n\nsns.kdeplot(ax=ax2,x=data.loc[data['stroke']==1]['avg_glucose_level'],color='crimson',label='Stroke',shade=True)\nsns.kdeplot(ax=ax2,x=data.loc[data['stroke']==0]['avg_glucose_level'],color='coral',label='No Stroke',shade=True)\nax2.legend(loc = 'upper right')\nax2.grid(linestyle='--', axis='y')\n\nax3.text(0.5,0.5,'Distribution of Glucose level\\n wrt Stroke',horizontalalignment = 'center',verticalalignment = 'center',fontsize = 18,fontfamily='serif')\n\n\nsns.kdeplot(ax=ax4,x=data.loc[data['stroke']==1]['bmi'],color='crimson',label='Stroke',shade=True)\nsns.kdeplot(ax=ax4,x=data.loc[data['stroke']==0]['bmi'],color='coral',label='No Stroke',shade=True)\nax4.legend(loc = 'upper right')\nax4.grid(linestyle='--', axis='y')\n\nax5.text(0.5,0.5,'Distribution of BMI\\n wrt Stroke',horizontalalignment = 'center',verticalalignment = 'center',fontsize = 18,fontfamily='serif')\n# removing labels\n\naxes1=[ax1,ax3,ax5]\nfor i in axes1:\n    i.spines[\"bottom\"].set_visible(False)\n    i.spines[\"left\"].set_visible(False)\n    i.set_xlabel(\"\")\n    i.set_ylabel(\"\")\n    i.set_xticklabels([])\n    i.set_yticklabels([])\n    i.tick_params(left=False, bottom=False)\n# removing spines of figures\nfor i in [\"top\",\"left\",\"right\"]:\n    ax0.spines[i].set_visible(False)\n    ax1.spines[i].set_visible(False)\n    ax2.spines[i].set_visible(False)\n    ax3.spines[i].set_visible(False)\n    ax4.spines[i].set_visible(False)\n    ax5.spines[i].set_visible(False)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Preprocessing","metadata":{}},{"cell_type":"code","source":"# Convert Marrital Status, Residence and Gender into 0's and 1's\ndata['gender']=data['gender'].apply(lambda x : 1 if x=='Male' else 0) \ndata[\"Residence_type\"] = data[\"Residence_type\"].apply(lambda x: 1 if x==\"Urban\" else 0)\ndata[\"ever_married\"] = data[\"ever_married\"].apply(lambda x: 1 if x==\"Yes\" else 0)\n# Removing the observations that have smoking type unknown. \ndata=data[data['smoking_status']!='Unknown']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# One Hot encoding smoking_status, work_type\ndata_dummies = data[['smoking_status','work_type']]\ndata_dummies=pd.get_dummies(data_dummies)\ndata.drop(columns=['smoking_status','work_type'],inplace=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_stroke=data['stroke']\ndata.drop(columns=['stroke'],inplace=True)\ndata=data.merge(data_dummies,left_index=True, right_index=True,how='left')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Splitting the data into training and testing sets.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(data,data_stroke,test_size=0.25,random_state=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Standardizing our training and testing data.\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nx_train = scaler.fit_transform(x_train)\nx_test = scaler.transform(x_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training the Models","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import plot_confusion_matrix","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nmd = LogisticRegression()\nmd.fit(x_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = md.predict(x_test)\ny_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score, roc_auc_score,accuracy_score,confusion_matrix, precision_recall_curve, auc, roc_curve, recall_score, classification_report \nclassification_report = classification_report(y_test, y_pred)\nprint(classification_report)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sklearn.metrics as mt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" auc= mt.accuracy_score(y_test, y_pred)\nauc","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}