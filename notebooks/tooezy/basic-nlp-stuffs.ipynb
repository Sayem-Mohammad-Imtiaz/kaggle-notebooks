{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport nltk\n#nltk.download('wordnet')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/Womens Clothing E-Commerce Reviews.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb879ef2723a854d6f38f6fd98d9b7ef44249df0"},"cell_type":"code","source":"sns.countplot(data[\"Recommended IND\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"db84988e6fb44bc5a92099849aca52eca5e4f105"},"cell_type":"code","source":"data = data.drop((data[data[\"Review Text\"].isnull()]).index)\nlabel1 = data[data[\"Recommended IND\"] == 1].iloc[:5000] # may not be good method i don't know for sure \nlabel0 = data[data[\"Recommended IND\"] == 0]\ndata = pd.concat([label0,label1], axis=0)\ndata = data[[\"Recommended IND\",\"Review Text\" ]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"38db99ac57bf8e49708f70d7af394c3f8080915b"},"cell_type":"code","source":"sns.countplot(data[\"Recommended IND\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"504bff4ef74b658e149985cb771267d8c5e9c715"},"cell_type":"code","source":"import re\ndef clean_and_tokenize(review):\n    text = review.lower()\n    \n    tokenizer = nltk.tokenize.TreebankWordTokenizer()\n    tokens = tokenizer.tokenize(text)\n    \n    stemmer = nltk.stem.WordNetLemmatizer()\n    text = \" \".join(stemmer.lemmatize(token) for token in tokens)\n    text = re.sub(\"[^a-z']\",\" \", text)\n    return text\ndata[\"Review Text\"] = data[\"Review Text\"].apply(clean_and_tokenize)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c1032b6646e89c69be118ca0c66c5ddfcddd3c76"},"cell_type":"code","source":"x_data = data[\"Review Text\"]\ny= data[\"Recommended IND\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"15540f5407aca0872253359e0e5bc53bce85b36c"},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\n\ncount_vectorizer = CountVectorizer(max_features=5000,ngram_range=(1, 2), stop_words = \"english\")\n\nfeatures = count_vectorizer.fit_transform(x_data)\ncount_vec_x = pd.DataFrame(\n    features.todense(),\n    columns=count_vectorizer.get_feature_names()\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6497c89df663b64880d874440a54f072f9e28a0e"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train_cv, x_test_cv, y_train_cv, y_test_cv = train_test_split(count_vec_x,y, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"300db27f7a962b2d738ffc663b112f47a158dc76"},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb.fit(x_train_cv,y_train_cv)\nprint(\"Score:\", nb.score(x_test_cv,y_test_cv))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6a23c07f6d0bccbcd3228a4a2ec9948befe2f346"},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression()\nlr.fit(x_train_cv,y_train_cv)\nprint(\"Score: \", lr.score(x_test_cv,y_test_cv))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9abdac0568457484eba560fa7b7aa89a73f7d6fe"},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n# using default tokenizer in TfidfVectorizer\ntfidf = TfidfVectorizer(min_df=2, max_df=0.5, ngram_range=(1, 2),max_features=5000,stop_words = \"english\")\nfeatures2 = tfidf.fit_transform(x_data)\ntfidf_x = pd.DataFrame(\n    features2.todense(),\n    columns=tfidf.get_feature_names()\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"27a7fa9e560d16d3df86eecac70035b529df45de"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train_tfidf, x_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(tfidf_x,y, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a2472b296906a055662d0ce412768e98e740ccd8"},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb.fit(x_train_tfidf,y_train_tfidf)\nprint(\"Score:\", nb.score(x_test_tfidf,y_test_tfidf))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1adb67cd6212b2a313c70c58ba82a72e5804fb78"},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression()\nlr.fit(x_train_tfidf,y_train_tfidf)\nprint(\"Score: \", lr.score(x_test_tfidf,y_test_tfidf))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}