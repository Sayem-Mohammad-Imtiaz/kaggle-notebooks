{"cells":[{"metadata":{},"cell_type":"markdown","source":"Задание к лабораторной работе:\n1. Выберите набор данных для проведения регрессионного анализа -  \n   https://www.kaggle.com/slehkyi/extended-football-stats-for-european-leagues-xg\n2. Проведите регрессионный анализ данных из выбранного набора.\n"},{"metadata":{},"cell_type":"markdown","source":"Построим графики взаимного распределения совместных величин."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# %% [code]\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nnp.set_printoptions(precision=2) # количество знаков после запятой\n# встраивание рисунков\n%matplotlib inline\ndf = pd.read_csv('../input/extended-football-stats-for-european-leagues-xg/understat.com.csv', encoding='utf-8', index_col=False, parse_dates=[0])\ndf = df[['wins','draws','loses', 'scored']]\ndf.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"В датасете использовались такие данные как: position (позиция), team (команда), amount of matches played (количество сыгранных матчей), wins (победы), draws (ничьи), loses (поражения), goals scored (забитые голы), goals missed (пропущенные голы), points (очки)."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Построим графики взаимного распределения совместных величин. Среднее значение по этому параметру - "},{"metadata":{"trusted":true},"cell_type":"code","source":"g=sns.pairplot(df[['wins','draws','loses', 'scored']])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"График распределения величин. На пересечении - график совместных распределений. На диагонали - гистограммы."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Рисование регрессии от одной переменной к целевой.\nplt.figure(figsize=(20,5))\nfor i, col in enumerate(['wins','draws','loses']):\n    plt.subplot(1,3,i+1)\n    x=df[col]\n    y=df.scored\n    plt.plot(x,y,'o') # отображение в виде кружков\n    plt.plot(np.unique(x), np.poly1d(np.polyfit(x,y,1))(np.unique(x)),color='r') # нахождение регрессии с помощью многочлена (polyfit)\n    plt.title(col)\n    plt.xlabel(col)\n    plt.ylabel('scored')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Разбиваем выборку с помощью train_test_split"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ny=df['scored']\nx=df.drop('scored',axis=1)\n\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.33,random_state=0) # test_size - размер тестовой выборки;","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Обучаем SGDRegressor - линейную регрессию."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_validate\nfrom sklearn.model_selection import learning_curve, GridSearchCV\nfrom sklearn import  linear_model, metrics\nregr=linear_model.SGDRegressor(random_state=42) # создание регрессора\nregr.fit(x_train,y_train) # передаем обучающую выборку в модель (в переменную regr), т.е. обучаем модель\ny_pred=regr.predict(x_test) # предсказание на основе x_test\n\nprint(metrics.mean_absolute_error(y_test,y_pred)) # абсолютная средняя ошибка","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Абсолютная средняя ошибка примерно равна 16.9 "},{"metadata":{},"cell_type":"markdown","source":"Сопоставляем данные:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_test[0:10].tolist()) # 10 изначальных значений\nprint(list(map(lambda x:\"{:2e}\".format(x),y_pred[0:10]))) # возвращение 10 предсказанных значений","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Нормируем величины, т.е. приводим к одинаковой размерности, чтобы размерность величин меньше влияла на метод градиентного спуска.\nfrom sklearn.preprocessing import StandardScaler # preprocessing - предподготовка данных\nscaler=StandardScaler()\nscaler.fit(x_train,y_train) # обучение на обучающих выборках\nscaled_train_data=scaler.transform(x_train) # трансформируем x_train\nscaled_test_data=scaler.transform(x_test) # трансформируем x_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"regr.fit(scaled_train_data,y_train) # обучение линейной регрессии\ny_scaled_pred=regr.predict(scaled_test_data) # новое предсказание с нормированными данными\nprint(metrics.mean_absolute_error(y_test,y_scaled_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Отличие 5 реальных данных от 5 предсказанных.\nprint(y_test.values[:5])\nprint(y_scaled_pred[:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Построение графика.\n# Чем лучше регрессия, тем более диагональным будет график.\nimport matplotlib.pyplot as plt\ny_pred=regr.predict(x_test)\nplt.scatter(y_test,y_scaled_pred,color=\"m\")\nplt.xlabel(\"Scores: $Y_i$\")\nplt.ylabel(\"Predicted scores: $\\hat{Y}_i$\")\nplt.title(\"Scores vs Predicted scores: $Y_i$ vs $\\hat{Y}_i$\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Нормализация и обучение линейной регрессии в кратком виде.\nfrom sklearn.pipeline import Pipeline\npipe=Pipeline(steps=[('scaling',scaler),('regression',regr)])\npipe.fit(x_train,y_train)\nprint(metrics.mean_absolute_error(y_test,pipe.predict(x_test))) # метрика абсолютной ошибки","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Метапараметры модуля Pipeline"},{"metadata":{"trusted":true},"cell_type":"code","source":"pipe.get_params().keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Подбор параметров при которых обучение происходит лучше всего.\nfrom sklearn.model_selection import GridSearchCV\n\nparameters_grid={\n    'regression__loss':['huber','squared_loss',],\n    'regression__n_iter_no_change':[ 5,10,20],\n    'regression__penalty':['l1','l2','none'],\n    'regression__alpha':[0.0001,0.001,0.1],\n}\n# на основе значений формируется многомерная сетка\ngrid_cv=GridSearchCV(pipe,parameters_grid,scoring='neg_mean_absolute_error',cv=4)\n# выборка на этих данных какие значения будут лучше\ngrid_cv.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(-1*grid_cv.best_score_) # лучшая оценка grid_cv\nprint(grid_cv.best_params_) # лучшие параметры grid_cv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Построение графика с улучшенными значениями.\nplt.scatter(y_test,pipe.predict(x_test),color=\"b\",alpha=0.6)\nplt.xlabel(\"Scores: $Y_i$\")\nplt.ylabel(\"Predicted scores: $\\hat{Y}_i$\")\nplt.title(\"Scores vs Predicted scores: $Y_i$ vs $\\hat{Y}_i$\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Какого-то качественного скачка в сторону улучшения модели не произошло."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Сравниваем графики.\nplt.scatter(y_test,pipe.predict(x_test),color=\"b\",alpha=0.6)\nplt.scatter(y_test,grid_cv.best_estimator_.predict(x_test),color=\"r\",alpha=0.6)\nplt.xlabel(\"Scores: $Y_i$\")\nplt.ylabel(\"Predicted scores: $\\hat{Y}_i$\")\nplt.title(\"Scores vs Predicted scores: $Y_i$ vs $\\hat{Y}_i$\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Построение графика методом Пирсона.\nx_corr=x_train.corr(method=\"pearson\") # коэффициента корреляции x_corr\nmask=np.zeros_like(x_corr) # маска\nmask[np.triu_indices_from(mask)]=True\nfig,ax=plt.subplots(figsize=(10,8))\nfig=sns.heatmap(x_corr,cmap=\"RdYlGn_r\",mask=mask) # тепловая карта корреляции\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Сильная отрицательная корреляция у параметров loses и wins. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Удаление параметра loses\nx_train_dropped=x_train.drop('loses',axis=1)\nx_test_dropped=x_test.drop('loses',axis=1)\ngrid_cv_drpd=grid_cv\ngrid_cv_drpd.fit(x_train_dropped,y_train)\nprint(-1*grid_cv_drpd.best_score_) # вывод новой ошибки и нового лучшего параметра\nprint(grid_cv_drpd.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Графики сравнения.\nplt.scatter(y_test,pipe.predict(x_test),color=\"b\",alpha=0.6)\nplt.scatter(y_test,grid_cv.best_estimator_.predict(x_test_dropped),color=\"r\",alpha=0.6)\nplt.xlabel(\"Scores: $Y_i$\")\nplt.ylabel(\"Predicted scores: $\\hat{Y}_i$\")\nplt.title(\"Scores vs Predicted scores: $Y_i$ vs $\\hat{Y}_i$\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Наблюдаем небольшие изменения."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Возьмем другую модель для обучения - модель регрессии при помощи случайного леса.\nfrom sklearn.ensemble import RandomForestRegressor\n\nrfr=RandomForestRegressor(random_state=42)\nrfr.fit(x_train,y_train)\nrf_predict=rfr.predict(x_test)\nprint(metrics.mean_absolute_error(y_test,rf_predict))\n\ngrid_cv=GridSearchCV(pipe,parameters_grid,scoring='neg_mean_absolute_error',cv=4)\ngrid_cv.fit(x_train,y_train)\nplt.scatter(y_test,rf_predict,color=\"r\",alpha=0.6)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}