{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # for data visualisation purposes\nfrom sklearn.tree import DecisionTreeClassifier ,plot_tree\nfrom sklearn.metrics import accuracy_score\nimport category_encoders as ce\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-29T07:03:47.979753Z","iopub.execute_input":"2021-06-29T07:03:47.980205Z","iopub.status.idle":"2021-06-29T07:03:47.992591Z","shell.execute_reply.started":"2021-06-29T07:03:47.980172Z","shell.execute_reply":"2021-06-29T07:03:47.991647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Gather Data\n#### Find Data:\nFind appropriate data in csv format, cointaining numeric values to make it easier for the coding process.\nI chose this data set because:\n - It included lots of numeric values.\n - It included a large selection of features.\n - The data set was also easy to comprehend and easy to use.\n \n \n#### Add Data To Notebook:\nOnce the desired data set has been found add it to the notebook, \nto do this you have to:\n1. Go into the data set and copy its title.\n2. Then go into the notebook you want the data in.\n3. On the top right hand side of screen there is an icon which reads 'Add data'.\n4. Press on the add data icon and search with the title for the desired data set.\n\n\nThe data set should apear in the data section on the top right of the screen.\n\n#### Why I chose the data set.\nI chose this data set because it was mostly numerical data and it apeared to be simple and easy to use.","metadata":{}},{"cell_type":"code","source":"#Collect data to use in for the training and testing data to base the prediction model off.\ntrain_file_path = '../input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv'\n#Create a data frame\ndata = pd.read_csv(train_file_path)\n#View the data set columns which will apear below once it runs.\ndata.describe(include='all')","metadata":{"execution":{"iopub.status.busy":"2021-06-29T07:03:47.994278Z","iopub.execute_input":"2021-06-29T07:03:47.994713Z","iopub.status.idle":"2021-06-29T07:03:48.080607Z","shell.execute_reply.started":"2021-06-29T07:03:47.994675Z","shell.execute_reply":"2021-06-29T07:03:48.079391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare The Data\n#### Choose what to find:\nIn prediction tree classifiers we are trying to find out if a feature has a specific value or not. \nIn the data set I am using we are trying to find out whether someone has heart desease or not so our predicted target will be 'heart desease' however, there are other options to chose from such as 'gender' which would also work.\n\n#### Select Features And Eliminate Others:\nSelecting feaures can improve mean absolute error by eliminating irrelevent features, for example in this data set the feature 'work type' is irrelevant to what we are trying to find out. But other reasons to not use features might include features have missing values and non numerical values. \n\nTo do this you Select features which are going to help improve and make it easier for coding and the rest will be discarded.\n\n\n#### Why we do this.\nWe want to prepare data because it will improve accuracy by removing outliers and null values.","metadata":{}},{"cell_type":"code","source":"#prepare data\n#Choose the features which you want - the most important and useful ones.\nselected_columns = ['gender', 'age', 'hypertension', 'heart_disease']\n\n#create the new training set which will have the chosen features.\nprepared_data = data[selected_columns]\n\n# Drop rows (axis=0) that contain missing values - we do not want these as they will be unreliable.\nprepared_data = prepared_data.dropna(axis=0)\n\n#Check and view the new data set to ensure that everything is ok and working as it should.\nprepared_data.describe(include='all')","metadata":{"execution":{"iopub.status.busy":"2021-06-29T07:03:48.082788Z","iopub.execute_input":"2021-06-29T07:03:48.083253Z","iopub.status.idle":"2021-06-29T07:03:48.117831Z","shell.execute_reply.started":"2021-06-29T07:03:48.083191Z","shell.execute_reply":"2021-06-29T07:03:48.116534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split data into training and testing data\nfor our data we want to spplit the data into training and testing data.\n\n#### Training data\nWe use training data to train the predicter and fit the predictions to the data.\n\n#### Testing data\nWe use testing data to see how good the predictions are, this is done by seeing how accurate the predictions are to feature values for.\n\n#### Why we do this.\nSo we can expose model to different data which can improve accuracy and we can use data to compare predictions with.","metadata":{}},{"cell_type":"code","source":"# Separate out the prediction target\ny = prepared_data.heart_disease\n\n# Drop the target column from the original dataframe and we will now use the rest as our feature data\nX = prepared_data.drop('heart_disease', axis=1)\n\n# View data\nX.head()\n#y.head()\ny.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-29T07:03:48.119442Z","iopub.execute_input":"2021-06-29T07:03:48.11974Z","iopub.status.idle":"2021-06-29T07:03:48.12838Z","shell.execute_reply.started":"2021-06-29T07:03:48.11971Z","shell.execute_reply":"2021-06-29T07:03:48.127255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# One Hot Encode\nMachine learning most of the time only works with numerical data.\nOur data has values such as 'Nan' which we dont want.\nTo eliminate this and convert it to numerical data we one hot encode it. \nThis makes everything in binary making 0 meaning that it does not fit the catagory and 1 does.","metadata":{}},{"cell_type":"code","source":"# One hot encode the features chosen above 3which it will only do for features with numeric values.\none_hot_X = pd.get_dummies(X)\n\none_hot_X.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-29T07:03:48.129692Z","iopub.execute_input":"2021-06-29T07:03:48.130019Z","iopub.status.idle":"2021-06-29T07:03:48.158348Z","shell.execute_reply.started":"2021-06-29T07:03:48.12999Z","shell.execute_reply":"2021-06-29T07:03:48.157318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Choosing/Training A Model\nNow that we have made the data set to be useable by the model we need to train and make predictions.\nIn this model we want to see if someone has heart desease or not. To do this we make it so desease is 1 and heart ok is 0. \n\nHyperparameters I set max depth to 3 so there wouldnt be overfitting.d","metadata":{}},{"cell_type":"code","source":"# Make a decision tree classifier with a depth of 3 for simple viewing.\n# Changing the max depth will change how big or small the tree is.\nheart_disease = DecisionTreeClassifier(max_depth=3)\n\n# Using one hot encoded data to train the dataset.\nheart_disease.fit(one_hot_X, y)\n\n# Plot the tree.\nplt.figure(figsize = (20,10))\nplot_tree(heart_disease,\n          feature_names=one_hot_X.columns,\n          class_names=['Heart ok', 'heart disease'],\n          filled=True)\nplt.show()\n# The values are 0 for heart ok and 1 for heart desease.","metadata":{"execution":{"iopub.status.busy":"2021-06-29T07:03:48.159825Z","iopub.execute_input":"2021-06-29T07:03:48.160204Z","iopub.status.idle":"2021-06-29T07:03:49.134057Z","shell.execute_reply.started":"2021-06-29T07:03:48.160172Z","shell.execute_reply":"2021-06-29T07:03:49.133121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As shown above all the predictions are heart ok. \nThis is obviously not ideal since every prediction is the same.\nThis may be due to many factors but the most likely is that the data set did not include enough features and a more appropriate data set could have been used instead in order to avoid this.","metadata":{}},{"cell_type":"markdown","source":"# Evaluate and tune hyperparameters\nNow that we have a functioning, we can how accurate its first predictions are.\n\n#### Why we do this\nWe do this because it gives us a good indication of how accurate it is.","metadata":{}},{"cell_type":"code","source":"print(\"Making predictions for the first 5 people in the training set.\")\n\n# View the first predictions displayed on a list form\npred = heart_disease.predict(one_hot_X)\n\nprint(\"The predictions are:\")\n\n# Merge target values and predictions back with our original features to see how well the predictions went.\nX['Heart ok'] = y\nX['Predicted'] = pred\n\nX.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-29T07:03:49.136204Z","iopub.execute_input":"2021-06-29T07:03:49.136781Z","iopub.status.idle":"2021-06-29T07:03:49.156158Z","shell.execute_reply.started":"2021-06-29T07:03:49.136738Z","shell.execute_reply":"2021-06-29T07:03:49.155181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Find how accurate the model is\nTo find out how accurate the model is we find out accuracy score which compares predicitons and data. This helps us visualise how close our predictions where to the validation data. The higher the score the more accurate the lower the score the higher the error. Ideally the score would be as high as possible.\n\nWe do this basically because it tells us whether our predictions where succesful or not.","metadata":{}},{"cell_type":"code","source":"#Find out the accuracy score.\nacc_svc = accuracy_score(pred, y)\nprint(acc_svc)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T07:03:49.157484Z","iopub.execute_input":"2021-06-29T07:03:49.157787Z","iopub.status.idle":"2021-06-29T07:03:49.162921Z","shell.execute_reply.started":"2021-06-29T07:03:49.157758Z","shell.execute_reply":"2021-06-29T07:03:49.162068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion\nAs shown the accuracy score was extremely high, at first this looked positive but after review of the prediction model all the predictions where 'heart ok' which means that infact the data set is possibly not offering enough information to make a more realist prediction. To do this a better data set could have been used.","metadata":{}}]}