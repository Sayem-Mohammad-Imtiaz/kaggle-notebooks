{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"../input/pima-indians-diabetes-database/diabetes.csv\")\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#We'll replace values of some features that has value '0'. This may represent missing values. \ncolumn = ['Glucose','BloodPressure','SkinThickness','Insulin','BMI']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imputer = SimpleImputer(missing_values = 0, strategy = 'mean')\ndata[column] = imputer.fit_transform(data[column])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#splitting dataset into dependent variable and independent variable\n\nx = data.iloc[:,0:8]\ny = data.iloc[:,8]\n\n# splitting the data into Training & Testing data sets in the ratio of 8:2 for both dependent and independent variables\n\nfrom sklearn.model_selection import train_test_split\n\nx_train,x_test,y_train,y_test = train_test_split(x,y, test_size = 0.2 , random_state = 42)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Standardising the data\n\nfrom sklearn.preprocessing import StandardScaler\nscale= StandardScaler()\nx_train = scale.fit_transform(x_train)\nx_test = scale.fit_transform(x_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Optimal K value for KMeans\n\nfrom sklearn.cluster import KMeans\ndistortions = []\nK = range(1,40)\nfor k in K:\n    kmeanModel = KMeans(n_clusters=k)\n    kmeanModel.fit(data)\n    distortions.append(kmeanModel.inertia_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(16,8))\nplt.plot(K, distortions, 'bx-')\nplt.xlabel('k')\nplt.ylabel('Distortion')\nplt.title('The Elbow Method showing the optimal k')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#using k-NearestNeighbors algorithm to train the model on training dataset\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import f1_score\n\nclassifier = KNeighborsClassifier(n_neighbors= 11, p= 2, metric= 'euclidean')\nclassifier.fit(x_train,y_train)\n\n# Predicting values based on trained model\ny_pred = classifier.predict(x_test)\n\n# Calculating the metrics for our classification model and the accuracy for the predicted values\nprint(confusion_matrix(y_test, y_pred))\nprint(f1_score(y_test,y_pred))\nprint(accuracy_score(y_test,y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}