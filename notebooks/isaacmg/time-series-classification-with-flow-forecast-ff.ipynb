{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Time Series Classification with Flow Forecast (FF)\n\n[Flow Forecast is a deep learning for time series forecasting, classification, and anomaly detection library built in PyTorch](https://github.com/AIStream-Peelout/flow-forecast). In this notebook we will go over how to use Flow Forecast for time series classification. We will be working with the human activity recognition dataset on Kaggle.","metadata":{}},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n!git clone https://github.com/AIStream-Peelout/flow-forecast.git -b 1_classification_support_full\nos.chdir('flow-forecast')\n!pip install -r  requirements.txt\n!python setup.py develop\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"WANDB_KEY\")\nos.environ[\"WANDB_API_KEY\"] = secret_value_0\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from flood_forecast.trainer import train_function","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing\n\nLike with all things machine learning we will have to do some basic data preprocessing to get the data in Flow Forecast (FF) format. Here we will simply add a column called \"labels.\" This column will consist of encoded labels of activities in the dataset.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv(\"../../input/human-activity-recognition-with-smartphones/train.csv\")\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nlabels = le.fit_transform(df[\"Activity\"])\ndf[\"labels\"] = labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.to_csv(\"train.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../../input/human-activity-recognition-with-smartphones/train.csv\")\nlabels = le.transform(df[\"Activity\"])\ndf[\"labels\"] = labels\ndf.to_csv(\"test.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training the Model","metadata":{}},{"cell_type":"markdown","source":"So these parameters will be very similar to the forcasting parameters. The main difference here is the parameters that are classification specific:\n\n- `dataset_params.n_classes`: The number of classes in your multi-label classification problem.\n- `model_params.output_dim`: This should match the `n_classes` parameter supplied to the data-loader\n- `dataset_params.sequence_length`: The length of your time series sequences that you pass to the model\n\nThe rest of the parameters should follow the normal FF format:","metadata":{}},{"cell_type":"code","source":"the_config = {                 \n   \"model_name\": \"CustomTransformerDecoder\",\n   \"n_targets\": 12,\n   \"model_type\": \"PyTorch\",\n    \"model_params\": {\n      \"n_time_series\":19,\n      \"seq_length\":26,\n      \"output_seq_length\": 1, \n      \"output_dim\":12,\n      \"n_layers_encoder\": 6\n     }, \n    \"dataset_params\":\n    { \"class\": \"GeneralClassificationLoader\",\n      \"n_classes\": 9,\n       \"training_path\": \"train.csv\",\n       \"validation_path\": \"train.csv\",\n       \"test_path\": \"test.csv\",\n       \"sequence_length\":26,\n       \"batch_size\":4,\n       \"forecast_history\":26,\n       \"train_end\": 4500,\n       \"valid_start\":4501,\n       \"valid_end\": 7000,\n       \"target_col\": [\"labels\"],\n       \"relevant_cols\": [\"labels\"] + df.columns.tolist()[:19],\n       \"scaler\": \"StandardScaler\", \n       \"interpolate\": False\n    },\n\n    \"training_params\":\n    {\n       \"criterion\":\"CrossEntropyLoss\",\n       \"optimizer\": \"Adam\",\n       \"optim_params\":\n       {},\n       \"lr\": 0.3,\n       \"epochs\": 4,\n       \"batch_size\":4\n    },\n    \"GCS\": False,\n   \n    \"wandb\": {\n       \"name\": \"flood_forecast_circleci\",\n       \"tags\": [\"dummy_run\", \"circleci\", \"multi_head\", \"classification\"],\n       \"project\": \"repo-flood_forecast\"\n    },\n   \"forward_params\":{},\n   \"metrics\":[\"CrossEntropyLoss\"]\n}\n    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_function(\"PyTorch\", the_config)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"the_config","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns.tolist()[:19]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}