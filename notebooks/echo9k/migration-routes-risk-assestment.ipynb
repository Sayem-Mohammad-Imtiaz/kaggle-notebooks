{"cells":[{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Data wranggling\nimport pandas as pd     # Data processing, CSV file I/O (e.g. pd.read_csv)\nimport datetime as date # To manipulate Dates\nimport re               # To manipulate regular expressions\nfrom datetime import datetime as dt\n\n# Maths\nimport numpy as np      # linear algebra\nfrom scipy import stats # Scientific and technical computing  | Statistics module\n\n# Ploting libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the \"../input/\" directory.\n# Running this will list the files in the input directory\n\n%xmode Plain\nprint(\"Set up completed\")\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploring our data\nWe will try to find some relations between cause of death, time"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"data_raw = pd.read_csv('../input/missing-migrants-project/MissingMigrants-Global-2019-03-29T18-36-07.csv', index_col=['Web ID'],\\\n                       parse_dates = [2], infer_datetime_format = True)\n# data_raw.drop(columns=['Reported Year', 'Reported Month'], inplace = True)\ndata_raw.rename({'Region of Incident': 'Region'}, axis = 1, inplace = True)\ndata_raw.index.names = ['id']\n\ndata_raw.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_raw.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### How much missing data do we have?\nFrom the quick exploration of we notice that some columns have several missing values, this can lead to incorrect conclusions.\n<br><br>\nLet's check the value of each column creating a table to check the proportion of missing values in each variable to consider it later in our analisies."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"\"\"\"Let's create a temporal DataFrame for the\n   Null observations of the Original DataFrame data_raw\"\"\"\n# Our Temporal DF\nNull_Observations = data_raw.isnull()\n\n# Comparing the total count of rows vs the not NULL observations.\nMissing_Data = pd.concat([Null_Observations.sum().sort_values(ascending = False),\n                         round((100*Null_Observations.sum()/Null_Observations.count())\\\n                                .sort_values(ascending = False),2)],\n                        axis=1, keys=['Observations Missing', 'Missing (%)'])\n# Deleates our temporal\ndel Null_Observations\n# Shows our resoult table\nMissing_Data[Missing_Data['Observations Missing']>0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Reagrouping cause of death in more general groups"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"CoD_serie = data_raw['Cause of Death'].str.lower()        # Causes of Death â€” Lower case.\n\n# Counts the frecuency of each unique value, show series as table, creates a new numberic index,\n# Correct column names, show a slice of the table:\nCoD_serie.value_counts()\\\n        .to_frame()\\\n        .reset_index()\\\n        .rename(index=str, columns={\"index\": \"Cause of Death\",\\\n                                    \"Cause of Death\": \"Count\"})\\\n        .iloc[:101:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The clasifications of death in this dataset are just too many to examine and some of them are repeated or considered different by python because of small differences like capital letters or typhos. To solve this let's grouping the causes of death in more general groups."},{"metadata":{},"cell_type":"markdown","source":"### Classifications"},{"metadata":{},"cell_type":"markdown","source":"In order to reduce the different types of death in at most 10 group. I had to group them in more general groups.\n<br> You can take a look of this changes with the CSV file that I in the Karnel or talking a look to the variable classifications.\n<br>\n<br>Here a glimpse of the 66 substitutions sliced every 8 unique values."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# The patterns I looked for and the substitution are shown in a CSV file.\n# Which includes the following rows.\n# [replacement]    The value to substitue on the row.\n# [pattern]        With the pattern to find in each row\n\n# Read the file in a variable called 'classifications'\nclassifications = pd.read_csv('../input/missinmigrants-causesofdeatclassification/MissinMigrants-COD_Classifications.csv')\nd = {classifications.pattern[i] : classifications.replacement[i] for i in range(classifications.shape[0])}\n\n# Let's take a look at 'classifications'\nclassifications.iloc[::8]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def like_function(x):\n    \"\"\"This function takes a Series of values and maps the dictionary d into the series using it's key.\n    This is simmilar to map a dictionary with str.contains\"\"\"\n    k_val = \"Unknown\"\n    for key in d:\n        if key in x:\n            k_val = d[key]\n            break\n    return k_val","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apply like_function to substitue the causes of death\ncod_reduced = CoD_serie.apply(like_function)\n\n# Count of classifications\ndata_raw['Cause of Death'] = cod_reduced\ntemp.value_counts().to_frame()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We only need to substitue this changes in the original data_raw table.\n<br> To test the resoult let's agregate the count of deaths per **Cause of death** with the new classification."},{"metadata":{},"cell_type":"markdown","source":"We reduced significantly the causes of death to make it easier to process and understand."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_raw['Cause of Death'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Analitics"},{"metadata":{},"cell_type":"markdown","source":"**Seaborn** is useful examining relationships between different variables, has very good visual tools, are some of the reasons why I choos it as my main tool for this data set"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"g = sns.factorplot(data=data_raw.dropna(subset=['Number Dead']),\n                   x='Region',\n                   aspect=1.5,\n                   kind=\"count\")\ng.set_xticklabels(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The US-Mexico Border is where **more incidents** are taking place. This means only the number of single reports, not the actual number of people affected in this region.\n<br><br>\nWe can take a closer look at the data to know the **number of deaths** by region, and thus the **mean** deaths per incident."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Create a summary of the cuatitative statistics grouped by region\nIncidents_By_Region = data_raw.drop('Source Quality', axis=1).groupby(['Region']).agg('sum')\n\n# Create the 'Count Incidents' columns to count the number of incidents per region.\nIncidents_By_Region['Count Incidents'] = data_raw['Region']\\\n                                        .value_counts(dropna=False)\n\n# Creates an attribute 'Average per incident' which calculates how many people where found dead in average per region.\nIncidents_By_Region['Average per incident'] = Incidents_By_Region['Number Dead']/Incidents_By_Region['Count Incidents']\n\n# Let's change the order of this new column so it's the first.\ncols = Incidents_By_Region.columns.tolist()\ncols = cols[:1] + cols[-2:] + cols[1:-2] # The new column order will be [1,-2, -1, 2:-3]\n\nIncidents_By_Region = Incidents_By_Region[cols]\nIncidents_By_Region = Incidents_By_Region.reset_index()\n\nIncidents_By_Region.sort_values('Count Incidents', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"By agregating the number of deaths by region we notice that the amount of casualities are more in other regions because of the average deaths per incident.\nLet's find out if there is any correlation between the number of incidents and the mumber of deaths."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"sns.set(rc={'figure.figsize':(30,10)})\n\n# Regression values\nslope, intercept, r_value, p_value, std_err = stats.linregress(Incidents_By_Region['Count Incidents'],Incidents_By_Region['Number Dead'])\n# Textbox on the scatterplot\nlr_text =(\"\\\ny = %(s).2fx + %(i).2f\\n\\\nr = %(r).2f \\n\\\np = %(p)f\\n\\\nse = %(se).3f\" % {'s': slope,\\\n                'i': intercept,\\\n                'r': r_value,\\\n                'p': p_value,\\\n                'se': std_err})\n\n# Scatter plot\nplt.subplot(1,2,1)\nsns.scatterplot(x='Count Incidents', y='Number Dead',\\\n                data=Incidents_By_Region,\\\n                marker = '+',\\\n                hue= 'Region')\n\nsns.regplot(x='Count Incidents', y='Number Dead',\\\n            data=Incidents_By_Region)\n# Textbox\nplt.text(0, 1500, lr_text)\n\n\n\n\n# Histogram\nplt.subplot(1,2,2)\nsns.stripplot(x='Region', y='Number Dead',\\\n                data=data_raw.dropna(subset=['Number Dead']),\\\n                jitter=True,\\\n             hue=\"Region\")\nplt.xticks(rotation=75)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Statistically speaking the number of incidents and the number of deaths shares a **strong correlation. R= 0.8**. <br><br>\nOn the other hand, the scatter plot reveals that this is not a reality that the Mediterranean and the US-Mexico border share since the Mediterranean is one of the most dangerous migration routes having 6114.0 reported deaths and 984 incidents with a mean of 6.2 deaths per incident. The US-Mexico Border has a total of 1941.0 deaths, becoming the third place, but also has the highest number of incidents in 1337, thus a mean of 1.45; with this information we could argue that the US-MX border is the safest[1] migration route, but we would require additional information regarding the total attempts of migration each year. \n[1] If we consider the mean deths per incident to be a measure of success."},{"metadata":{},"cell_type":"markdown","source":"\nThis strip plot looks odd most of our incidents are around 5 persons per incident, with the exception of Central Asia with only one case of 52 persons missing leaving it's mean at 52.\n\nFurthermore, according to this, some incidents are over 100 missing persons. Two over 200, and one over 700 people. This is outrageous, let's investigate further"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"data_raw[data_raw['Number Dead'] == data_raw['Number Dead'].max()]['URL']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"![Migrant boat captain arrested as survivors of sinking reach Italy](https://i.ibb.co/b7v88dX/Capture.png)\n\n> Police make two arrests as 27 survivors from sinking that killed 800 are brought to Catania on board Italian coastguard ship <\n\n[https://www.theguardian.com/world/2015/apr/21/survivors-800-migrant-boat-disaster-reach-italy-catania](http://)"},{"metadata":{},"cell_type":"markdown","source":"The loss of so many people this is a tragedy, no doubt. Unfortunately, it happened, thus this observation is correct, we can do something similar to other points we want to verify."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"sns.set(rc={'figure.figsize':(40,10)})\ng =sns.swarmplot(x='Region', y='Number Dead', hue='Cause of Death', data=data_raw)\n\n#g.set_yscale('log')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"data_raw.pivot_table(index='Reported Year',\n                     columns='Cause of Death',\n                     aggfunc={'Reported Year': np.sum}).plot(figsize=(16.1, 10), kind='bar')\nplt.title('Total Dead and Missing by Sex and Age')\nplt.ylabel('Deaths by cause')\nplt.xlabel('Year of event')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In contrast with the first bar plot in which showed US-Mexican border as the region with more incidents, we can notice now how it's actually very dispersed in a matter of a number of deaths per incident.\n\nThis is a persistent difference between regions, the probable cause is because of the way migrants travel. For example, in the US-Mexican people most often will have to walk and maybe get lost in contrast to traveling on a boat through the Mediterranean where a single boat accident can cause the loss of several lives.\n\nMoreover, a quick exploration of the ratios of deaths between males, women and children can reveal how often families travel together."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"data_raw[['Region','Number Dead']]\\\n        .groupby(['Region']).sum().sort_values('Number Dead', ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Draw a nested barplot to show survival for class and sex\ng = sns.catplot(x='Region', y='Number Dead',\n                data=Incidents_By_Region,\n                height=6, kind=\"bar\")\n\ng.despine(left=True)\nplt.xticks(rotation=75)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"GeoLoc = pd.DataFrame(columns=['Latitud', 'Longitud'])\nGeoLoc['Latitud'], GeoLoc['Longitud'] = data_raw['Location Coordinates'].str.split(', ').str\nGeoLoc.Latitud = GeoLoc.Latitud.astype(float)\nGeoLoc.Longitud = GeoLoc.Longitud.astype(float)\nGeoLoc.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Time series\nTo understand what might be causing so many lost during this exodus we could find useful to visualize the dates where most lives were lost. <br>\nFor this end we can agregate the total number of incidents per region by month.<br>\n<br>\nWe can use a pivot table to accomplish two of the three Tidy Data principles:\n* Columns represent separate variables\n* Rows represent individual observations\n* Observational units form tables\n\nTidy data is a standard representation of data better suit for data analisis.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_raw.pivot_table(index='Reported Year',\n                     columns='Region',\n                     aggfunc={'Reported Year': np.sum}).plot(figsize=(20, 10), kind='bar')\nplt.xlabel('Year')\nplt.ylabel('Death count')\nplt.title('Deaths by year separated by region', fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DaM_by_DR = data_raw.groupby(['Reported Year', 'Region']).sum().reset_index()\nsns.lineplot(x=\"Reported Year\", y=\"Number Dead\", hue='Region', data=DaM_by_DR.reset_index())\nplt.xlabel('Year')\nplt.ylabel('Death count')\nplt.title('Lineplot separated by region')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}