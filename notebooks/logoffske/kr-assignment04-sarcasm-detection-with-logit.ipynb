{"cells":[{"metadata":{"_uuid":"3f6c2bfe6b2e26c92357e896a1511195d836956e"},"cell_type":"markdown","source":"\n## [mlcourse.ai](https://mlcourse.ai) - Open Machine Learning Course\n\nAuthor: [Yury Kashnitsky](https://www.linkedin.com/in/festline/). All content is distributed under the [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) license."},{"metadata":{"_uuid":"cb01ca96934e5c83a36a2308da9645b87a9c52a0"},"cell_type":"markdown","source":"## <center> Assignment 4 (demo)\n### <center>  Sarcasm detection with logistic regression\n    \n**Same assignment as a [Kaggle Kernel](https://www.kaggle.com/kashnitsky/a4-demo-sarcasm-detection-with-logit) + [solution](https://www.kaggle.com/kashnitsky/a4-demo-sarcasm-detection-with-logit-solution).**\n\n\nWe'll be using the dataset from the [paper](https://arxiv.org/abs/1704.05579) \"A Large Self-Annotated Corpus for Sarcasm\" with >1mln comments from Reddit, labeled as either sarcastic or not. A processed version can be found on Kaggle in a form of a [Kaggle Dataset](https://www.kaggle.com/danofer/sarcasm).\n\nSarcasm detection is easy. \n<img src=\"https://habrastorage.org/webt/1f/0d/ta/1f0dtavsd14ncf17gbsy1cvoga4.jpeg\" />"},{"metadata":{"_uuid":"23a833b42b3c214b5191dfdc2482f2f901118247","trusted":true},"cell_type":"code","source":"!cd ../input/sarcasm","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ffa03aec57ab6150f9bec0fa56cd3a5791a3e6f4","trusted":true},"cell_type":"code","source":"# some necessary imports\nimport os\nimport numpy as np\nimport pandas as pd\nimport json\nimport string\n\nfrom IPython.display import Image\n\nfrom nltk.util import ngrams\nimport re\n\nfrom scipy.sparse import hstack\nfrom sklearn import preprocessing, metrics, ensemble, naive_bayes, linear_model, model_selection\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n\nfrom wordcloud import WordCloud, STOPWORDS\nfrom collections import defaultdict\n\nimport lightgbm as lgb\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\ncolor = sns.color_palette()\n\n%matplotlib inline\npd.options.mode.chained_assignment = None\npd.options.display.max_rows = 100","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b23e4fc7a1973d60e0c6da8bd60f3d921542a856","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/sarcasm/train-balanced-sarcasm.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4dc7b3787afa46c7eb0d0e33b0c41ab9821c4a27","trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0a7ed9557943806c6813ad59c3d5ebdb403ffd78","trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6472f52fb5ecb8bb2a6e3b292678a2042fcfe34c"},"cell_type":"markdown","source":"Some comments are missing, so we drop the corresponding rows."},{"metadata":{"_uuid":"97b2d85627fcde52a506dbdd55d4d6e4c87d3f08","trusted":true},"cell_type":"code","source":"train_df.dropna(subset=['comment'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9d51637ee70dca7693737ad0da1dbb8c6ce9230b"},"cell_type":"markdown","source":"We notice that the dataset is indeed balanced"},{"metadata":{"_uuid":"addd77c640423d30fd146c8d3a012d3c14481e11","trusted":true},"cell_type":"code","source":"train_df['label'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5b836574e5093c5eb2e9063fefe1c8d198dcba79"},"cell_type":"markdown","source":"We split data into training and validation parts."},{"metadata":{"trusted":true},"cell_type":"code","source":"training_df, testing_df = train_test_split(train_df, random_state=17)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c200add4e1dcbaa75164bbcc73b9c12ecb863c96","trusted":true},"cell_type":"code","source":"train_texts = training_df['comment'] \nvalid_texts = testing_df['comment']\ny_train = training_df['label']\ny_valid = testing_df['label']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7f0f47b98e49a185cd5cffe19fcbe28409bf00c0"},"cell_type":"markdown","source":"## Tasks:\n1. Analyze the dataset, make some plots. This [Kernel](https://www.kaggle.com/sudalairajkumar/simple-exploration-notebook-qiqc) might serve as an example\n2. Build a Tf-Idf + logistic regression pipeline to predict sarcasm (`label`) based on the text of a comment on Reddit (`comment`).\n3. Plot the words/bigrams which a most predictive of sarcasm (you can use [eli5](https://github.com/TeamHG-Memex/eli5) for that)\n4. (optionally) add subreddits as new features to improve model performance. Apply here the Bag of Words approach, i.e. treat each subreddit as a new feature.\n"},{"metadata":{},"cell_type":"markdown","source":"Lets draw a wordcloud with the most used words."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"def plot_wordcloud(text, mask=None, max_words=200, max_font_size=100, figure_size=(24.0,16.0), \n                   title = None, title_size=40, image_color=False):\n    stopwords = set(STOPWORDS)\n    more_stopwords = {'one', 'br', 'Po', 'th', 'sayi', 'fo', 'Unknown'}\n    stopwords = stopwords.union(more_stopwords)\n\n    wordcloud = WordCloud(background_color='black',\n                    stopwords = stopwords,\n                    max_words = max_words,\n                    max_font_size = max_font_size, \n                    random_state = 42,\n                    width=800, \n                    height=400,\n                    mask = mask)\n    wordcloud.generate(str(text))\n    \n    plt.figure(figsize=figure_size)\n    if image_color:\n        image_colors = ImageColorGenerator(mask);\n        plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\");\n        plt.title(title, fontdict={'size': title_size,  \n                                  'verticalalignment': 'bottom'})\n    else:\n        plt.imshow(wordcloud);\n        plt.title(title, fontdict={'size': title_size, 'color': 'black', \n                                  'verticalalignment': 'bottom'})\n    plt.axis('off');\n    plt.tight_layout()  \n    \nplot_wordcloud(train_df[\"comment\"], max_words=800, title=\"Word Cloud of Comments\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will be using logistic regression with bag of words so lets find out the most used n-grams in this set."},{"metadata":{"trusted":true},"cell_type":"code","source":"train1_df = train_df[train_df[\"label\"]==1]\ntrain0_df = train_df[train_df[\"label\"]==0]\n\ndef generate_ngrams(s, n_gram:int):\n    #Generate a list of n-grams from the input data \n    \n    s = s.lower()\n    s = re.sub(r'[0-9-,.$\"!?+\\s]', ' ', s)\n    tokens = [token for token in s.split(\" \") if token != \"\" if token not in STOPWORDS if len(token) > 1]\n    output = list(ngrams(tokens, n_gram))\n    \n    #clean duplicate n-grams in case dimension is > 1 e,g: (fake, fake)\n    if n_gram > 1:\n        full_output = [i for i in output if i[0] != i[1]]\n    else:\n        return output\n    return full_output\n\ndef count_ngrams(train_df, n_gram:int):\n    #We count the n-grams repetitions in specific feature\n    #train_df - DataFrame\n    \n    freq_dict = defaultdict(int)\n    for sent in train_df['comment']:\n        for word in generate_ngrams(sent, n_gram):\n            freq_dict[word] += 1\n    \n    #check commutations (donald, trump) <-> (trump, donald) if n-gram > 1\n    final_dict = defaultdict(int)\n    if n_gram > 1:\n        for key, value in freq_dict.items():\n            if (key[1], key[0]) in final_dict.keys() or (key[0], key[1]) in final_dict.keys():\n                pass\n            else:\n                final_dict[key] = value \n    else:\n        final_dict = freq_dict\n    \n    fd_sorted = pd.DataFrame(sorted(final_dict.items(), key=lambda x: x[1])[::-1])\n    fd_sorted.columns = [\"word\", \"wordcount\"]\n    return fd_sorted\n\ndef ngram_compare_plot(x1, x2, y1, y2, barcolor:str):\n    #Create a plot to compare words used in sarcastic comments and non-saracstic comments\n    \n    fig, axes = plt.subplots(ncols=2, figsize=(16,26), sharey=False)\n    \n    axes[0].xaxis.tick_top()   \n    axes[0].invert_yaxis()\n    axes[0].patch.set_facecolor('black')\n    axes[0].barh([' '.join(list(y)) for y in y1], x1, align = 'center', zorder=10, color = barcolor)\n    axes[0].set(title='Frequent words in sarcastic comments')\n    \n    axes[1].xaxis.tick_top() \n    axes[1].invert_yaxis()\n    axes[1].patch.set_facecolor('black')\n    axes[1].barh([' '.join(list(y)) for y in y2], x2, align = 'center', zorder=10, color = barcolor)\n    axes[1].set(title='Frequent words in non-sarcastic comments')\n \n    \n    for ax in axes.flat:\n        ax.margins(0.01)\n        ax.grid(True)\n    \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ngrams1_sarcasm = count_ngrams(train1_df, n_gram=1)\ntrain_ngrams1_nosarcasm = count_ngrams(train0_df, n_gram=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ngram_compare_plot(list(train_ngrams1_sarcasm['wordcount'][:50].values), \\\n                   list(train_ngrams1_nosarcasm['wordcount'][:50].values), \\\n                   list(train_ngrams1_sarcasm['word'][:50].values), \\\n                   list(train_ngrams1_nosarcasm['word'][:50].values), 'teal')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ngrams2_sarcasm = count_ngrams(train1_df, n_gram=2)\ntrain_ngrams2_nosarcasm = count_ngrams(train0_df, n_gram=2)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"ngram_compare_plot(list(train_ngrams2_sarcasm['wordcount'][:50].values), \\\n                   list(train_ngrams2_nosarcasm['wordcount'][:50].values), \\\n                   list(train_ngrams2_sarcasm['word'][:50].values), \\\n                   list(train_ngrams2_nosarcasm['word'][:50].values), 'salmon')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Now lets find if comment upvotes, downvotes and scores show any reaction to sarcasm in comments.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['has_downvote'] = train_df['downs'].apply(lambda x: 'Yes' if x == -1 else 'No')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8))\nscores = sns.countplot(x='has_downvote', hue='label', data=train_df)\n\nplt.legend(title='Downvote influence on label', loc='upper right', labels=['Not sarcasm', 'Sarcasm'])\nplt.xlabel('Has a downvote')\nplt.show(scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['score_negative'] = train_df['score'].apply(lambda x: 'Yes' if x < 0 else 'No')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8))\nscores = sns.countplot(x='score_negative', hue='label', data=train_df)\n\nplt.legend(title='Score influence on label', loc='upper right', labels=['Not sarcasm', 'Sarcasm'])\nplt.xlabel('Is the comment score negative?')\nplt.show(scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['downvotes_more'] = (train_df['downs'].abs() >= train_df['ups'].abs())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['downvotes_more'] = train_df['downvotes_more'].apply(lambda x: 'Yes' if x == True else 'No')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8))\nupvotes = sns.countplot(x='downvotes_more', hue='label', data=train_df)\n\n\nplt.legend(title='Downvotes influence on label', loc='upper left', labels=['Not sarcasm', 'Sarcasm'])\nplt.xlabel('More downvotes than upvotes')\nplt.show(scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['upvotes_more3'] = train_df['ups'].apply(lambda x: 'Yes' if x > 0 else 'No')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8))\nscores = sns.countplot(x='upvotes_more3', hue='label', data=train_df)\n\nplt.legend(title='Upvote influence on label', loc='upper right', labels=['Not sarcasm', 'Sarcasm'])\nplt.xlabel('More than 3 upvotes')\nplt.show(scores)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We can see that if score is negative the post is more inclined to have sarcastic content, hence we leave it as our feature**"},{"metadata":{},"cell_type":"markdown","source":"## 2.1 Engineering our features"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['score_negative'] = train_df['score'].apply(lambda x: '1' if x < 0 else '0')\ntraining_df['score_negative'] = training_df['score'].apply(lambda x: '1' if x < 0 else '0')\ntesting_df['score_negative'] = testing_df['score'].apply(lambda x: '1' if x < 0 else '0')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['author'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[train_df['author'] == 'Biffingston']['label'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mlist = ['author', 'score', 'ups', 'downs', 'date', \\\n         'created_utc', 'downvotes_more', 'upvotes_more3', 'has_downvote', 'parent_comment']\ntrain_df.drop(mlist, 1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.2 Training the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def text_format(s):\n    s = s.lower()\n    s = re.sub(r'[0-9-,.$\"!?+\\s]', ' ', s)\n    output = str(s)\n    return output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_texts.apply(lambda x: text_format(x));\nvalid_texts.apply(lambda x: text_format(x));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"misc = ['author', 'score', 'ups', 'downs', 'date', 'created_utc']\ntraining_df.drop(misc, 1, inplace=True)\ntesting_df.drop(misc, 1, inplace=True)\nscore_negative = train_df['score_negative']\nscore_negative_train, score_negative_test = train_test_split(score_negative, random_state=17) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_negative.shape, score_negative_test.shape, score_negative_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"subreddits = train_df['subreddit']\ntrain_subreddits, valid_subreddits = train_test_split(subreddits, random_state=17)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf_idf_texts  = TfidfVectorizer(max_features=50000, min_df=2, ngram_range=(1,2))\ntf_idf_subreddits = TfidfVectorizer(ngram_range=(1, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nX_train_texts = tf_idf_texts.fit_transform(train_texts)\nX_valid_texts = tf_idf_texts.transform(valid_texts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_texts.shape, X_valid_texts.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nX_train_subreddits = tf_idf_subreddits.fit_transform(train_subreddits)\nX_valid_subreddits = tf_idf_subreddits.transform(valid_subreddits)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = hstack([X_train_texts, X_train_subreddits])\nX_valid = hstack([X_valid_texts, X_valid_subreddits])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logit = LogisticRegression(C=1, n_jobs=4, solver='lbfgs', \n                           random_state=17, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_train_reshaped = score_negative_train.values.reshape((len(score_negative_train.values), 1))\nscore_test_reshaped = score_negative_test.values.reshape((len(score_negative_test.values), 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_training = hstack([X_train, score_train_reshaped.astype(float)])\nX_validation = hstack([X_valid, score_test_reshaped.astype(float)])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"logit.fit(X_training, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nvalid_pred = logit.predict(X_validation)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(y_valid, valid_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logit.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nvalid_pred = logit.predict(X_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(y_valid, valid_pred)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":4}