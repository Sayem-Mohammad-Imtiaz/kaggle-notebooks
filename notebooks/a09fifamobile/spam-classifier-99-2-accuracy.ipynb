{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os, re\nfrom collections import Counter\nimport nltk\nfrom nltk.stem import PorterStemmer, WordNetLemmatizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, StackingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/sms-spam-collection-dataset/spam.csv', encoding='latin')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1)\ndata.columns = ['class', 'emails']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['class'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['emails'][data['class']== 'spam']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"code to see the most frequently used words in spam emails","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"spam_mails = ''\nfor s in data['emails'][data['class']== 'spam']:\n    spam_mails += s\nspam_mails_1 = re.sub(r'[^a-zA-Z]', ' ', spam_mails).lower()\nwords = re.findall(r'\\w+', spam_mails_1)\nwords = [word for word in words if word not in set(nltk.corpus.stopwords.words('english'))]\nCounter(words).most_common(30)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"code to compare the length of spam and ham emails","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"length = []\nfor i in range(data.shape[0]):\n    length.append(len(data['emails'][i]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.insert(2, 'len', pd.Series(length, name='length'))\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"spam_data = data[data['class']== 'spam']\nham_data = data[data['class']== 'ham']\nplt.figure(figsize=(8, 6))\nsns.distplot(spam_data['len'], label='spam')\nsns.distplot(ham_data['len'], label='ham')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we can see that in our dataset the spam emails are longer than the ham emails","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x_data = data['emails']\ny_data = data['class']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Text Preprocessing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_data(x):\n    st = PorterStemmer()\n    wnl = WordNetLemmatizer()\n    cleaned_sent = []\n    for i in range(len(x)):\n        sent = re.sub(r'[^a-zA-Z]', ' ', x[i])\n        sent = sent.lower().split()\n        sent = [wnl.lemmatize(word) for word in sent if word not in set(nltk.corpus.stopwords.words('english'))]\n        sent = [st.stem(w) for w in sent]\n        sent = ' '.join(sent)\n        cleaned_sent.append(sent)\n    for i in range(len(cleaned_sent)):\n                   x[i] = cleaned_sent[i]\n                       \n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"x_data = clean_data(x_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder = LabelEncoder()\ny_data = encoder.fit_transform(y_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# converting emails to vectors\ncv = CountVectorizer(analyzer='word', max_features=5000, token_pattern=r'\\w+')\nx_trans = cv.fit_transform(x_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x_trans, y_data, test_size=0.2, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Models Training","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# function to check models performence\ndef model(model, x_train, x_test, y_train, y_test):\n    model.fit(x_train, y_train)\n    y_pred = model.predict(x_test)\n    print(confusion_matrix(y_true=y_test, y_pred=y_pred))\n    print(classification_report(y_true=y_test, y_pred=y_pred))\n    print(f'accuracy_score :{accuracy_score(y_true=y_test, y_pred=y_pred)}\\nroc_auc_score :{roc_auc_score(y_test, y_pred)}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"training and checking the accuracy of models","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model(RandomForestClassifier(random_state=0), x_train, x_test, y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model(AdaBoostClassifier(random_state=0), x_train, x_test, y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model(MultinomialNB(),x_train, x_test, y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model(LogisticRegression(C=10, random_state=0), x_train, x_test, y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model(SVC(C=100),x_train, x_test, y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stacking_model = StackingClassifier(estimators=[('lgr', LogisticRegression(C=10, random_state=0)), ('rdf', RandomForestClassifier(random_state=0)), ('mnb',MultinomialNB())], final_estimator=LogisticRegression(random_state=0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model(stacking_model,x_train, x_test, y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = ['RandomForestClassifier', 'AdaBoostClassifier', 'MultinomialNB', 'LogisticRegression', 'SVC', 'StackingClassifier']\naccuracy = ['0.97578', '0.96053', '0.98565', '0.9856', '0.97578', '0.99192']\nmodels = pd.DataFrame(models, columns=['model'])\nmodels.insert( 1, 'accuracy', pd.Series(accuracy))\nmodels","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}