{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/weather-dataset-rattle-package/weatherAUS.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import the libraries for data cleaning and data visualising\nimport numpy as np\nimport scipy as sp\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nimport operator\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#a quick look at the data\ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Finding the null count of each feature and removing the features with less data\ndata.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Removing the feature which contain more null values\ndata = data.drop(columns = ['Sunshine','Evaporation','Cloud3pm','Cloud9am'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#let's see the correlation between all the columns\ndata_correlate = data.corr()\nplt.figure(figsize = (15,15))\nsns.heatmap(data_correlate, linewidth = 3, linecolor = 'black')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Risk_MM can influnence the output. So droping that column too and date and location too.\ndata = data.drop(columns = ['Date', 'Location', 'RISK_MM'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now looking at the columns\nprint(data.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting the RainToday and RainTomorrow data into binary\ndata['RainToday'].replace('No', 0, inplace = True)\ndata['RainToday'].replace('Yes', 1, inplace = True)\ndata['RainTomorrow'].replace('No', 0, inplace = True)\ndata['RainTomorrow'].replace('Yes', 1, inplace = True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Removing all the null values \ndata = data.dropna(axis = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Some columns needs to be changed into numeical values as they are categorical\nnon_numerical = ['WindGustDir', 'WindDir3pm', 'WindDir9am']\ndata = pd.get_dummies(data, columns= non_numerical)\nrain_index = data.columns.get_loc('RainTomorrow')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_1 = data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#standardizing the data.\nfrom sklearn import preprocessing\nstandardizing = preprocessing.MinMaxScaler()\nstandardizing.fit(data_1)\ndata_standard = standardizing.transform(data_1)\ndata_standard = pd.DataFrame(data_standard, index=data_1.index, columns=data_1.columns)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_standard.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now on of the most important part. Feature selection\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nX = data_standard.loc[:,data_standard.columns!='RainTomorrow']\nY = data_standard[['RainTomorrow']]\nselector = SelectKBest(chi2, k=3)\nselector.fit(X, Y)\nX_new = selector.transform(X)\nprint(X.columns[selector.get_support(indices=True)]) #top 3 columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#the classification data:\ndata_classification = data_standard[['Rainfall', 'Humidity3pm', 'RainToday', 'RainTomorrow']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Spliting up the data:\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(data_standard[['Rainfall', 'Humidity3pm', 'RainToday']],data_standard['RainTomorrow'],test_size=0.25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now let sstart analysing different models:","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#1. Adaboost classifier:\nfrom sklearn.ensemble import AdaBoostClassifier\nadaboost_classifier = AdaBoostClassifier(n_estimators = 100)\nadaboost_classifier.fit(X_train, y_train)\nadaboost_classifier_pred = adaboost_classifier.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nadaboost_classifier_score = accuracy_score(y_test, adaboost_classifier_pred)\nprint('The accuracy score obtained by adaboost classifier is:', adaboost_classifier_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Bagging Classifer\nfrom sklearn.ensemble import BaggingClassifier\nbagging_classifier = BaggingClassifier()\nbagging_classifier.fit(X_train, y_train)\nbagging_classifier_pred = bagging_classifier.predict(X_test)\nbagging_classifier_score = accuracy_score(y_test, bagging_classifier_pred)\nprint('the accuracy score of this bagging classifier is:', bagging_classifier_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#3. Extra Trees classifiers\nfrom sklearn.ensemble import ExtraTreesClassifier\nextra_trees_classifier = ExtraTreesClassifier(n_estimators = 100)\nextra_trees_classifier.fit(X_train, y_train)\nextra_trees_classifier_pred = extra_trees_classifier.predict(X_test)\nextra_trees_classifier_score = accuracy_score(y_test, extra_trees_classifier_pred)\nprint('The accuracy obtained from extra trees classifiers is:', extra_trees_classifier_score)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#4. Gradient boosting classifier:\nfrom sklearn.ensemble import GradientBoostingClassifier\ngradient_boosting_classifier = GradientBoostingClassifier()\ngradient_boosting_classifier.fit(X_train, y_train)\ngradient_boosting_classifier_pred = gradient_boosting_classifier.predict(X_test)\ngradient_boosting_classifier_score = accuracy_score(y_test, gradient_boosting_classifier_pred)\nprint('The accuracy score obtained from gradient boosting classifier:', gradient_boosting_classifier_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#5.Random forest classifier:\nfrom sklearn.ensemble import RandomForestClassifier\nrandom_forest_classifier = RandomForestClassifier()\nrandom_forest_classifier.fit(X_train, y_train)\nrandom_forest_classifier_pred = random_forest_classifier.predict(X_test)\nrandom_forest_classifier_score = accuracy_score(y_test, random_forest_classifier_pred)\nprint('the accuracy score obtain from random forest classifier is :', random_forest_classifier_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#6 logistic regression;\nfrom sklearn.linear_model import LogisticRegression\nlogistic_regression = LogisticRegression()\nlogistic_regression.fit(X_train, y_train)\nlogistic_regression_pred = logistic_regression.predict(X_test)\nlogistic_regression_score = accuracy_score(y_test, logistic_regression_pred)\nprint('The accuracy score obtained from logistic regression is :', logistic_regression_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#7 passive aggressive classifier:\nfrom sklearn.linear_model import PassiveAggressiveClassifier\npassive_aggressive_classifier = PassiveAggressiveClassifier(C = 1.0, fit_intercept = True, max_iter = 1000)\npassive_aggressive_classifier.fit(X_train, y_train)\npassive_aggressive_classifier_pred = passive_aggressive_classifier.predict(X_test)\npassive_aggressive_classifier_score = accuracy_score(y_test, passive_aggressive_classifier_pred)\nprint('The accuracy score is:', passive_aggressive_classifier_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#8.Ridge classifier;\n# first using ridgeclassifierCV to find the alpha value\nfrom sklearn.linear_model import RidgeClassifierCV\nridge_classifier_cv = RidgeClassifierCV(alphas=(0.01, 0.1, 1.0, 10.0, 100.0), fit_intercept=True,\n                                        normalize=False, scoring=None, cv=None,\n                                        class_weight=None, store_cv_values=False)\nridge_classifier_cv.fit(X_train, y_train)\nridge_alpha = ridge_classifier_cv.alpha_\nprint('Obtained alpha value:', ridge_alpha)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import RidgeClassifier\nridge_classifier = RidgeClassifier(alpha = ridge_alpha, fit_intercept = True)\nridge_classifier.fit(X_train, y_train)\nridge_classifier_pred = ridge_classifier.predict(X_test)\nridge_classifier_score = accuracy_score(y_test, ridge_classifier_pred)\nprint('The accuracy score obtained is:', ridge_classifier_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#9. SGD classifier:\nfrom sklearn.linear_model import SGDClassifier\nsgd_classifier = SGDClassifier(alpha=0.0001,\n                               l1_ratio=0.15, fit_intercept=True, max_iter=1000,\n                               tol=0.001, shuffle=True)\nsgd_classifier.fit(X_train, y_train)\nsgd_classifier_pred = sgd_classifier.predict(X_test)\nsgd_classifier_score = accuracy_score(y_test, sgd_classifier_pred)\nprint('the accuracy score calculated is:', sgd_classifier_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#10. Bernoulli's Naive-Bayes:\nfrom sklearn.naive_bayes import BernoulliNB\nbernoulli_nb = BernoulliNB(alpha=1.0, binarize=0.0, fit_prior=True,class_prior=None)\nbernoulli_nb.fit(X_train, y_train)\nbernoulli_nb_pred = bernoulli_nb.predict(X_test)\nbernoulli_nb_score = accuracy_score(y_test, bernoulli_nb_pred)\nprint('the score obtained is:', bernoulli_nb_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#11. Gaussian's Naive-Bayes:\nfrom sklearn.naive_bayes import GaussianNB\ngaussian_nb = GaussianNB(var_smoothing=1e-09)\ngaussian_nb.fit(X_train, y_train)\ngaussian_nb_pred = gaussian_nb.predict(X_test)\ngaussian_nb_score = accuracy_score(y_test, gaussian_nb_pred)\nprint('the score obtained is:', gaussian_nb_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#12. Multinomial Naive-Bayes:\nfrom sklearn.naive_bayes import MultinomialNB\nmultinomial_nb =  MultinomialNB()\nmultinomial_nb.fit(X_train, y_train)\nmultinomial_nb_pred = multinomial_nb.predict(X_test)\nmultinomial_nb_score = accuracy_score(y_test, multinomial_nb_pred)\nprint('the score obtained is:', multinomial_nb_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#13.complement naive bayes:\nfrom sklearn.naive_bayes import ComplementNB\ncomplement_nb =  ComplementNB()\ncomplement_nb.fit(X_train, y_train)\ncomplement_nb_pred = complement_nb.predict(X_test)\ncomplement_nb_score = accuracy_score(y_test, complement_nb_pred)\nprint('the score obtained is:', complement_nb_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#14. K nearest neighbors:\nfrom sklearn.neighbors import KNeighborsClassifier\nk_neighbors = KNeighborsClassifier(n_neighbors=10)\nk_neighbors.fit(X_train, y_train)\nk_neighbors_pred = k_neighbors.predict(X_test)\nk_neighbors_score = accuracy_score(y_test, k_neighbors_pred)\nprint('the score obtained is:', k_neighbors_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#15. Linear support vector machine classification:\nfrom sklearn.svm import LinearSVC\nlinear_svc = LinearSVC(loss='squared_hinge', dual=True, tol=0.0001,\n                        C=1.0, multi_class='ovr', fit_intercept=True, intercept_scaling=1,\n                        class_weight=None, verbose=0, random_state=None, max_iter=1000)\nlinear_svc.fit(X_train, y_train)\nlinear_svc_pred = linear_svc.predict(X_test)\nlinear_svc_score = accuracy_score(y_test, linear_svc_pred)\nprint('the score obtained is:',linear_svc_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}