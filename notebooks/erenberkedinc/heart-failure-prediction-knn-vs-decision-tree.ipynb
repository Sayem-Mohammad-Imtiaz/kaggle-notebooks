{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Import Libraries**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport plotly.express as px\nfrom sklearn.model_selection import train_test_split, cross_val_predict,cross_validate\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.ensemble import IsolationForest","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data Preprocessing**","metadata":{}},{"cell_type":"code","source":"#Exploring the Data\ndata = pd.read_csv('/kaggle/input/heart-failure-clinical-data/heart_failure_clinical_records_dataset.csv')\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Missing Values\ndata.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Feature Selection**","metadata":{}},{"cell_type":"code","source":"X = data.iloc[:,0:20]  #independent columns\ny = data.iloc[:,-1]    #target column i.e price range\nfrom sklearn.ensemble import ExtraTreesClassifier\nimport matplotlib.pyplot as plt\nmodel = ExtraTreesClassifier()\nmodel.fit(X,y)\nprint(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n#plot graph of feature importances for better visualization\nfeat_importances = pd.Series(model.feature_importances_, index=X.columns)\nfeat_importances.nlargest(10).plot(kind='barh')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Features = ['time','ejection_fraction','serum_creatinine']\nx = data[Features]\ny = data[\"DEATH_EVENT\"]\n\n# Train Test split\ntrain_x, test_x,train_y,test_y = train_test_split(x,y, test_size=0.2, random_state=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Model 1: KNN**","metadata":{}},{"cell_type":"code","source":"#KNN Finding the Best K\nfrom sklearn.neighbors import KNeighborsClassifier\nmisclassified = []\nfor i in range(1, 30):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(train_x,train_y)\n    pred_i = knn.predict(test_x)\n    misclassified.append((test_y != pred_i).sum())\nprint(\"Misclassified = \", misclassified)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#knn\nKNN_classifier = KNeighborsClassifier(n_neighbors=11)\nKNN_classifier.fit(train_x, train_y)\nprediction =  KNN_classifier.predict(test_x)\naccuracy_score = accuracy_score(test_y,prediction)\nprint(\"accuracy_score without outlier KNN=11 :\",accuracy_score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Printing KNN Accuracy and Confusion Matrix\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(test_y, prediction)\nac = accuracy_score(test_y, prediction)\n\nax= plt.subplot()\nsns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells\n\n# labels, title and ticks\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \nax.set_title('Confusion Matrix'); \nax.xaxis.set_ticklabels(['Heart Not Failed', 'Heart Fail']); ax.yaxis.set_ticklabels(['Heart Not Failed', 'Heart Fail']);\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Model 2: Decision Tree Classifier**","metadata":{}},{"cell_type":"code","source":"#Finding the Best Max Leaf Node Value\nfrom sklearn.tree import DecisionTreeClassifier\n#from sklearn.metrics import confusion_matrix, accuracy_score\nlist1 = []\nfor leaves in range(2,10):\n    classifier = DecisionTreeClassifier(max_leaf_nodes = leaves, random_state=0, criterion='entropy')\n    classifier.fit(train_x, train_y)\n    y_pred = classifier.predict(test_x)\n    list1.append(accuracy_score(test_y,y_pred))\n#print(mylist)\nplt.plot(list(range(2,10)), list1)\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Decision Tree Classifier\nclassifier = DecisionTreeClassifier(max_leaf_nodes = 2, random_state=0, criterion='entropy')\nclassifier.fit(train_x, train_y)\ny_pred = classifier.predict(test_x)\n#from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(test_y, y_pred)\nac = accuracy_score(test_y, y_pred)\nprint(\"Dec Tree Classifier acc without outlier:\",ac)\nprint(\"Confusion Matrix:\",cm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plotting Confusion Matrix\n#cm = confusion_matrix(test_y, prediction)\n#ac = accuracy_score(test_y, prediction)\n\nax= plt.subplot()\nsns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells\n\n# labels, title and ticks\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \nax.set_title('Confusion Matrix'); \nax.xaxis.set_ticklabels(['Heart Not Failed', 'Heart Fail']); ax.yaxis.set_ticklabels(['Heart Not Failed', 'Heart Fail']);","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}