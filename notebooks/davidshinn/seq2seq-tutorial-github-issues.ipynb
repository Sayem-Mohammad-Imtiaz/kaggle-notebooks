{"cells":[{"metadata":{"_uuid":"77282ca6f97a7740db9f87619452f0a87c03f595","_cell_guid":"a11e8844-b449-4bef-aed7-46687dac4452","trusted":false,"collapsed":true},"cell_type":"code","source":"import pandas as pd\npd.set_option('display.max_colwidth', 500)\nfrom sklearn.model_selection import train_test_split\nfrom ktext.preprocess import processor","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"52eee747b23516cb801b5922cd9cc81ebc3731f4","_cell_guid":"617564a3-b52b-4fff-a067-67736855eaa9"},"cell_type":"markdown","source":"## Read Data And Preview","outputs":[],"execution_count":null},{"metadata":{"collapsed":true,"_uuid":"99be74c506654cbd98fcef466e8c458b1f1026d3","_cell_guid":"6274092b-29bd-4c75-9dea-7206f4fe1fed","trusted":false},"cell_type":"code","source":"traindf, testdf = train_test_split(pd.read_csv('../input/github_issues.csv').sample(n=40000), \n                                   test_size=.10)\ntrain_body_raw = traindf.body.tolist()\ntrain_title_raw = traindf.issue_title.tolist()\ntraindf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"404a096f706e71370c8a610635b7c0a5f93dc138","_cell_guid":"0c57efcc-1db4-45c0-93ef-026877e8b611"},"cell_type":"markdown","source":"Isssue Body and Title are stored in seperate lists.  Lets inspect the issue title list:","outputs":[],"execution_count":null},{"metadata":{"collapsed":true,"_uuid":"5f6b13cd6759e37ce6a83f0f943a8c93cf906a64","_cell_guid":"4959d954-2952-4033-85d9-5daf389c89ed","trusted":false},"cell_type":"code","source":"# Preview what is in this list\ntrain_title_raw[0]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ccd61e51938f17e9681859976f71a12b0fca0e50","_cell_guid":"f8e524d0-ed7b-46bb-ba38-8b33f5cedb75"},"cell_type":"markdown","source":"## Use `ktext` to pre-process data","outputs":[],"execution_count":null},{"metadata":{"collapsed":true,"_uuid":"d773fec2ced563f35c42b54644e2b01a84baf58c","_cell_guid":"1967292a-1611-46bf-a171-89bf80b94e03","trusted":false},"cell_type":"code","source":"num_encoder_tokens = 6000\nbody_pp = processor(keep_n=num_encoder_tokens, padding_maxlen=60)\ntrain_body_vecs = body_pp.fit_transform(train_body_raw)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"42cb7e0db7a9501e5cae6055db7c7ec01d8136b1","_cell_guid":"2c75a0fc-b262-45e6-b3a9-d65182b551f4"},"cell_type":"markdown","source":"**Look at one example of processed issue bodies**","outputs":[],"execution_count":null},{"metadata":{"collapsed":true,"_uuid":"aea9a11ab6da2fbb4e985ea764513b569087550c","_cell_guid":"f8aeb6bf-9d97-4dfd-b42a-3604bc4c18d8","trusted":false},"cell_type":"code","source":"max(body_pp.id2token.keys())","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"49a378a782f6ee4aabbfe5518f4c942d006c1c15","_cell_guid":"9e56021c-fed6-42b4-b768-afbe5aab5f27","trusted":false},"cell_type":"code","source":"print('\\noriginal string:\\n', train_body_raw[0], '\\n')\nprint('after pre-processing:\\n', train_body_vecs[0], '\\n')","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"42fbc4f0c32651f0baefd87d2e7050526d4bb4b3","_cell_guid":"0513217d-3ce1-412a-8f76-afe0a98604d0","trusted":false},"cell_type":"code","source":"# Instantiate a text processor for the titles, with some different parameters\n#  append_indicators = True appends the tokens '_start_' and '_end_' to each\n#                      document\n#  padding = 'post' means that zero padding is appended to the end of the \n#             of the document (as opposed to the default which is 'pre')\nnum_decoder_tokens=4500\ntitle_pp = processor(append_indicators=True, keep_n=num_decoder_tokens, \n                     padding_maxlen=12, padding ='post')\n\n# process the title data\ntrain_title_vecs = title_pp.fit_transform(train_title_raw)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"00414a474ad8c0d3e283c704d30e653b5549e5da","_cell_guid":"4ec20e49-d1e6-40f6-acfa-00e5780dd8ed","trusted":false},"cell_type":"code","source":"max(title_pp.id2token.keys())","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"0105ab4ca68e285d66507862fe4a6274b59b0591","_cell_guid":"9c4d8488-ce1a-48a0-a595-3d78dfc07a85","trusted":false},"cell_type":"code","source":"def load_encoder_inputs(vectorized_body):\n    encoder_input_data = vectorized_body\n    doc_length = encoder_input_data.shape[1]\n    print(f'Shape of encoder input: {encoder_input_data.shape}')\n    return encoder_input_data, doc_length\n\n\ndef load_decoder_inputs(vectorized_title):\n    # For Decoder Input, you don't need the last word as that is only for prediction\n    # when we are training using Teacher Forcing.\n    decoder_input_data = vectorized_title[:, :-1]\n\n    # Decoder Target Data Is Ahead By 1 Time Step From Decoder Input Data (Teacher Forcing)\n    decoder_target_data = vectorized_title[:, 1:]\n\n    print(f'Shape of decoder input: {decoder_input_data.shape}')\n    print(f'Shape of decoder target: {decoder_target_data.shape}')\n    return decoder_input_data, decoder_target_data","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"36379ebefdbccefe0e32d6a4e08e66209016ed92","_cell_guid":"a254d40a-0b1b-475b-89d1-85d955e6806f","trusted":false},"cell_type":"code","source":"import numpy as np\nencoder_input_data, doc_length = load_encoder_inputs(train_body_vecs)\ndecoder_input_data, decoder_target_data = load_decoder_inputs(train_title_vecs)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"7d7e1e0b22944efc2d2a80bdc49a951cebd7d7ed","_cell_guid":"3f75ad26-9513-4e0d-831c-e32055d81205","trusted":false},"cell_type":"code","source":"np.max(encoder_input_data.flatten())","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"5a6560ad29713d4f396763c84205ab0ba77195c3","_cell_guid":"aad7fdea-b331-4f28-b472-62127b838324","trusted":false},"cell_type":"code","source":"from keras.models import Model\nfrom keras.layers import Input, LSTM, GRU, Dense, Embedding, Bidirectional, BatchNormalization\nfrom keras import optimizers","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"e01a2f2122c42f232c60391452c11c26d00f20b3","_cell_guid":"e3c2fd45-6325-484c-87e3-c97146911a62","trusted":false},"cell_type":"code","source":"#arbitrarly set latent dimension for embedding and hidden units\nlatent_dim = 100\n\n##### Define Model Architecture ######\n\n########################\n#### Encoder Model ####\nencoder_inputs = Input(shape=(doc_length,), name='Encoder-Input')\n\n# Word embeding for encoder (ex: Issue Body)\nx = Embedding(num_encoder_tokens+2, latent_dim, name='Body-Word-Embedding', mask_zero=False)(encoder_inputs)\nx = BatchNormalization(name='Encoder-Batchnorm-1')(x)\n\n# Intermediate GRU layer (optional)\n#x = GRU(latent_dim, name='Encoder-Intermediate-GRU', return_sequences=True)(x)\n#x = BatchNormalization(name='Encoder-Batchnorm-2')(x)\n\n# We do not need the `encoder_output` just the hidden state.\n_, state_h = GRU(latent_dim, return_state=True, name='Encoder-Last-GRU')(x)\n\n# Encapsulate the encoder as a separate entity so we can just \n#  encode without decoding if we want to.\nencoder_model = Model(inputs=encoder_inputs, outputs=state_h, name='Encoder-Model')\n\nseq2seq_encoder_out = encoder_model(encoder_inputs)\n\n########################\n#### Decoder Model ####\ndecoder_inputs = Input(shape=(None,), name='Decoder-Input')  # for teacher forcing\n\n# Word Embedding For Decoder (ex: Issue Titles)\ndec_emb = Embedding(num_decoder_tokens+2, latent_dim, name='Decoder-Word-Embedding', mask_zero=False)(decoder_inputs)\ndec_bn = BatchNormalization(name='Decoder-Batchnorm-1')(dec_emb)\n\n# Set up the decoder, using `decoder_state_input` as initial state.\ndecoder_gru = GRU(latent_dim, return_state=True, return_sequences=True, name='Decoder-GRU')\ndecoder_gru_output, _ = decoder_gru(dec_bn, initial_state=seq2seq_encoder_out)\nx = BatchNormalization(name='Decoder-Batchnorm-2')(decoder_gru_output)\n\n# Dense layer for prediction\ndecoder_dense = Dense(num_decoder_tokens+2, activation='softmax', name='Final-Output-Dense')\ndecoder_outputs = decoder_dense(x)\n\n########################\n#### Seq2Seq Model ####\n\n#seq2seq_decoder_out = decoder_model([decoder_inputs, seq2seq_encoder_out])\nseq2seq_Model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n\n\nseq2seq_Model.compile(optimizer=optimizers.Nadam(lr=0.001), loss='sparse_categorical_crossentropy')","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"6ede1ab46b1a0dded0b98baf03a8a6acf0476378","_cell_guid":"c39cee27-88b4-42db-8c95-a679ae0bb024","trusted":false},"cell_type":"code","source":"from keras.callbacks import CSVLogger, ModelCheckpoint\n\nscript_name_base = 'tutorial_seq2seq'\ncsv_logger = CSVLogger('{:}.log'.format(script_name_base))\nmodel_checkpoint = ModelCheckpoint('{:}.epoch{{epoch:02d}}-val{{val_loss:.5f}}.hdf5'.format(script_name_base),\n                                   save_best_only=True)\n\nbatch_size = 100\nepochs = 1\nhistory = seq2seq_Model.fit([encoder_input_data, decoder_input_data], np.expand_dims(decoder_target_data, -1),\n          batch_size=batch_size,\n          epochs=epochs,\n          validation_split=0.10, callbacks=[csv_logger, model_checkpoint])","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"1e6acb8c0f8266334a4c1f00256b887787e3fa57","_cell_guid":"df1e6ee6-e4da-49fc-bd44-c1bdb1031499","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"version":"3.6.4","codemirror_mode":{"version":3,"name":"ipython"},"nbconvert_exporter":"python","mimetype":"text/x-python","file_extension":".py","name":"python","pygments_lexer":"ipython3"}},"nbformat":4,"nbformat_minor":1}