{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Use LDA model in Gensim package\nimport pandas as pd\nimport nltk\nfrom gensim.models import Phrases\nfrom nltk.corpus import stopwords\nfrom gensim.corpora import Dictionary\nfrom gensim.models import LdaModel\nimport pyLDAvis.gensim","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df=pd.read_csv('../input/515k-hotel-reviews-data-in-europe/Hotel_Reviews.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"positive=df.Positive_Review.tolist()\nnegative=df.Negative_Review.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.tokenize import RegexpTokenizer\ntokenizer=RegexpTokenizer(r'\\w+')\n\n# tokenize\nfor idx in range(len(positive)):\n    positive[idx]=positive[idx].lower()\n    positive[idx]=tokenizer.tokenize(positive[idx])\n    \n# tokenize\nfor idx in range(len(negative)):\n    negative[idx]=negative[idx].lower()\n    negative[idx]=tokenizer.tokenize(negative[idx])\n\n    # remove the tokens whose length is one and which is a number\npositive=[[token for token in pos if len(token)>1] for pos in positive]\npositive=[[token for token in pos if not token.isnumeric()] for pos in positive]\n\nnegative=[[token for token in neg if len(token)>1] for neg in negative]\nnegative=[[token for token in neg if not token.isnumeric()] for neg in negative]\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Romove stopwords\nstpwd=set(stopwords.words('english'))\npositive=[[token for token in pos if token not in stpwd] for pos in positive]\nnegative=[[token for token in neg if token not in stpwd ] for neg in negative]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lemmatize\nfrom nltk.stem.wordnet import WordNetLemmatizer\n\nlemmatizer=WordNetLemmatizer()\npositive=[[lemmatizer.lemmatize(token) for token in pos] for pos in positive]\nnegative=[[lemmatizer.lemmatize(token) for token in neg] for neg in negative]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#find the bigram \nbigram_pos=Phrases(positive,min_count=20)\nbigram_neg=Phrases(negative,min_count=20)\n\nfor idx in range(len(positive)):\n    for token in bigram_pos[positive[idx]]:\n        if '_' in token:\n            positive[idx].append(token)\n            \n    for token in bigram_neg[negative[idx]]:\n        if '_' in token:\n            negative[idx].append(token)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove rare and ramdom tokens\ndictionary_positive=Dictionary(positive)\ndictionary_negative=Dictionary(negative)\n\ndictionary_positive.filter_extremes(no_below=20, no_above=0.5)\ndictionary_negative.filter_extremes(no_below=20, no_above=0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bag-of-words representation of the documents.\ncorpus_positive= [dictionary_positive.doc2bow(pos) for pos in positive]\ncorpus_negative=[dictionary_negative.doc2bow(neg) for neg in negative]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_topics=10\nchunksize=2000\npasses=20\niterations=400\neval_every=None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = dictionary_positive[0] \nid2word_positive = dictionary_positive.id2token \n\nmodel_positive = LdaModel(\n    corpus=corpus_positive,\n    id2word=id2word_positive,\n    chunksize=chunksize,\n    alpha='auto',\n    eta='auto',\n    iterations=iterations,\n    num_topics=num_topics,\n    passes=passes,\n    eval_every=eval_every\n)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outputfile_pos = f'model_positive{num_topics}.gensim'\nmodel_positive.save(outputfile_pos)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = dictionary_negative[0] \nid2word_negative = dictionary_negative.id2token \n\nmodel_negative = LdaModel(\n    corpus=corpus_negative,\n    id2word=id2word_negative,\n    chunksize=chunksize,\n    alpha='auto',\n    eta='auto',\n    iterations=iterations,\n    num_topics=num_topics,\n    passes=passes,\n    eval_every=eval_every\n)\n\noutputfile_neg = f'model_negative{num_topics}.gensim'\nmodel_negative.save(outputfile_neg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_topics_pos = model_positive.top_topics(corpus_positive)\ntop_topics_neg =  model_negative.top_topics(corpus_negative)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#display the result\npos_display= pyLDAvis.gensim.prepare(model_positive,corpus_positive,dictionary_positive,sort_topics=True)\npyLDAvis.display(pos_display)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#display the result\nneg_display= pyLDAvis.gensim.prepare(model_negative,corpus_negative,dictionary_negative,sort_topics=True)\npyLDAvis.display(neg_display)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}