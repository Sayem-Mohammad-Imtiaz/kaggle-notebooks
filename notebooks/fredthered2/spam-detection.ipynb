{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nfrom nltk.corpus import stopwords\nfrom nltk import word_tokenize\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import wordcloud\nimport string","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sms = pd.read_csv('/kaggle/input/sms-spam-collection-dataset/spam.csv',encoding='ISO-8859-1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sms.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sms.columns=['label','text','A','B','C']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sms.drop(['A','B','C'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sms.head(6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sms.groupby('label').describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.value_counts(sms['label'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=sms['label'],data=sms)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sms['label']=sms['label'].map({'ham':0,'spam':1}).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sms.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"PREPROCESSING OF DATA"},{"metadata":{"trusted":true},"cell_type":"code","source":"sms.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stop_words=set(stopwords.words(\"english\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sms['text'].iloc[5571]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#words","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def text_preprocess(text):\n    words=text.lower().split()\n    actual_list=[]\n    for word in words:\n        if word not in stop_words:\n            if word not in string.punctuation:\n                actual_list.append(word)\n    return(' '.join(actual_list))            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sms['text'].head().apply(text_preprocess)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Quick Look at the words using Word Cloud\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_ham  = sms[sms['label'] == 0].copy()\ndata_spam = sms[sms['label'] == 1].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_wordcloud(data_spam_or_ham, header):\n    text = ' '.join(data_spam_or_ham['text'].astype(str).tolist())\n    stopwords = set(wordcloud.STOPWORDS)\n    \n    fig_wordcloud = wordcloud.WordCloud(stopwords=stopwords,background_color='lightgrey',\n                    colormap='viridis', width=800, height=600).generate(text)\n    \n    plt.figure(figsize=(12,6), frameon=True)\n    plt.imshow(fig_wordcloud)  \n    plt.axis('off')\n    plt.title(header, fontsize=20 )\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_wordcloud(data_spam, \"SPAM Words\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_wordcloud(data_ham, \"HAM Words\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"markdown","source":"FEATURE EXTRACTION"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nCnt_Vector = CountVectorizer(analyzer=text_preprocess)\nSMS_TEXTS=Cnt_Vector.fit_transform(sms['text'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(SMS_TEXTS, sms['label'], test_size=0.20, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create and train the naive Bayes classifier\n# The multinomial Naive Bayes classifier is suitable for classification with discrete features .We shall explore others as we go ahead\n\nfrom sklearn.naive_bayes import MultinomialNB\nclassifier = MultinomialNB().fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate the model on the training data set\n\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\npred = classifier.predict(X_train)\nprint(classification_report(y_train, pred))\nprint()\nprint('Confusion Matrix:\\n',confusion_matrix(y_train, pred))\nprint()\nprint('Model Accuracy : ',accuracy_score(y_train, pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Evaluate the model on the test data set\n\npred = classifier.predict(X_test)\nprint(classification_report(y_test, pred))\nprint()\nprint('Confusion Matrix:\\n',confusion_matrix(y_test, pred))\nprint()\nprint('Model Accuracy : ',accuracy_score(y_test, pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Things to do: Verifying other algrithms to see if they work better.Using a TFIDF vectorizer instead of countvectorizer"},{"metadata":{"trusted":true},"cell_type":"code","source":"test=['Your number as 10000']\nx = Cnt_Vector.transform(test)\nclassifier.predict(x)[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}