{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Churn prediction \nis one of the most popular Big Data use cases in business. It consists of detecting customers who are likely to cancel a subscription to a service.\n\nAlthough originally a telcom giant thing, this concerns businesses of all sizes, including startups. Now, thanks to prediction services and APIs, predictive analytics are no longer exclusive to big players that can afford to hire teams of data scientists.\n\nAs an example of how to use churn prediction to improve your business, let’s consider businesses that sell subscriptions. This can be telecom companies, SaaS companies, and any other company that sells a service for a monthly fee.\n\nThere are three possible strategies those businesses can use to generate more revenue: acquire more customers, upsell existing customers, or increase customer retention. All the efforts made as part of one of the strategies have a cost, and what we’re ultimately interested in is the return on investment: the ratio between the extra revenue that results from these efforts and their cost[[**1**](https://neilpatel.com/blog/improve-by-predicting-churn/#:~:text=Churn%20prediction%20is%20one%20of,a%20subscription%20to%20a%20service.&text=This%20can%20be%20telecom%20companies,service%20for%20a%20monthly%20fee.)]","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"![](https://miro.medium.com/max/844/1*MyKDLRda6yHGR_8kgVvckg.png)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"In this study, we tried to predict Customer Churn using Random Forest and Naive Bayesian classifier.\n\nVariable Prediction:\n1.    CustomerID                   \n1.   MonthlyRevenue             \n1.     MonthlyMinutes            \n1.     TotalRecurringCharge      \n1.     DirectorAssistedCalls      \n1.     OverageMinutes             \n1.    RoamingCalls              \n1.    PercChangeMinutes         \n1.     PercChangeRevenues        \n1.    DroppedCalls               \n1.    BlockedCalls               \n1.    UnansweredCalls           \n1.    CustomerCareCalls         \n1.    ThreewayCalls             \n1.    ReceivedCalls              \n1.    OutboundCalls              \n1.    InboundCalls              \n1.    PeakCallsInOut            \n1.   OffPeakCallsInOut          \n1.   DroppedBlockedCalls        \n1.    CallForwardingCalls        \n1.    CallWaitingCalls           \n1.    MonthsInService           \n1.   UniqueSubs               \n1.    ActiveSubs                \n1.   ServiceArea                \n1.   Handsets                  \n1.   HandsetModels              \n1.    CurrentEquipmentDays      \n1.   AgeHH1                     \n1.    AgeHH2                    \n1.    ChildrenInHH              \n1.    HandsetRefurbished         \n1.   HandsetWebCapable          \n1.    TruckOwner                 \n1.   RVOwner                   \n1.    Homeownership            \n1.    BuysViaMailOrder           \n1.    RespondsToMailOffers       \n1.    OptOutMailings            \n1.   NonUSTravel               \n1.    OwnsComputer              \n1.    HasCreditCard             \n1.   RetentionCalls            \n1.    RetentionOffersAccepted    \n1.   NewCellphoneUser         \n1.    NotNewCellphoneUser       \n1.    ReferralsMadeBySubscriber  \n1.    IncomeGroup                \n1.   OwnsMotorcycle           \n1.   AdjustmentsToCreditRating  \n1.    HandsetPrice               \n1.    MadeCallToRetentionTeam    \n1.   CreditRating               \n1.    PrizmCode                 \n1.    Occupation                \n1.   MaritalStatus              ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"import library","execution_count":null},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pylab as pl\nimport pandas as pd\nimport matplotlib.pyplot as plt \n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.utils import shuffle\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix,classification_report\nfrom sklearn.model_selection import cross_val_score, GridSearchCV\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"read dataset","execution_count":null},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/datasets-for-churn-telecom/cell2celltrain.csv\")\ntest = pd.read_csv(\"../input/datasets-for-churn-telecom/cell2cellholdout.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()\ntrain[0:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Churn : Yes:1 , No:0\nChurn = {'Yes': 1,'No': 0} \n  \n# traversing through dataframe \n# values where key matches \ntrain.Churn = [Churn[item] for item in train.Churn] \nprint(train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Handling missing data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Some might quibble over our usage of missing. By “missing” we simply mean NA (“not available”) or “not present for whatever reason”. Many data sets simply arrive with missing data, either because it exists and was not collected or it never existed.\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Any missing sample in training set:\",train.isnull().values.any())\nprint(\"Any missing sample in test set:\",test.isnull().values.any(), \"\\n\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we handling missing value filled by zero rather than dropping NA values. Another technique of handling missing value in addition to filled by a single number like zero, or it might be some sort of imputation or interpolation from the good values. You could do this in-place using the isnull() method as a mask, but because it is such a common operation Pandas provides the fillna() method, which returns a copy of the array with the null values replaced.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# for column\n#train['MonthlyRevenue'].fillna((train['MonthlyRevenue'].median()), inplace=True)\n# for column\ntrain['MonthlyRevenue'] = train['MonthlyRevenue'].replace(np.nan, 0)\n\n# for whole dataframe\ntrain = train.replace(np.nan, 0)\n\n# inplace\ntrain.replace(np.nan, 0, inplace=True)\n\nprint(train)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for column\n#train['MonthlyMinutes'].fillna((train['MonthlyMinutes'].median()), inplace=True)\ntrain['MonthlyMinutes'] = train['MonthlyMinutes'].replace(np.nan, 0)\n\n# for whole dataframe\ntrain = train.replace(np.nan, 0)\n\n# inplace\ntrain.replace(np.nan, 0, inplace=True)\n\nprint(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for column\n#train['TotalRecurringCharge'].fillna((train['TotalRecurringCharge'].median()), inplace=True)\ntrain['TotalRecurringCharge'] = train['TotalRecurringCharge'].replace(np.nan, 0)\n\n# for whole dataframe\ntrain = train.replace(np.nan, 0)\n\n# inplace\ntrain.replace(np.nan, 0, inplace=True)\n\nprint(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for column\n#train['DirectorAssistedCalls'].fillna((train['DirectorAssistedCalls'].median()), inplace=True)\ntrain['DirectorAssistedCalls'] = train['DirectorAssistedCalls'].replace(np.nan, 0)\n\n# for whole dataframe\ntrain = train.replace(np.nan, 0)\n\n# inplace\ntrain.replace(np.nan, 0, inplace=True)\n\nprint(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ndef FunLabelEncoder(df):\n    for c in df.columns:\n        if df.dtypes[c] == object:\n            le.fit(df[c].astype(str))\n            df[c] = le.transform(df[c].astype(str))\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = FunLabelEncoder(train)\ntrain.info()\ntrain.iloc[235:300,:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = FunLabelEncoder(test)\ntest.info()\ntest.iloc[235:300,:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = test.drop(columns=['Churn'],\n\n                 axis=1)\ntest = test.dropna(how='any')\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Frequency distribution of classes\"\ntrain_outcome = pd.crosstab(index=train[\"Churn\"],  # Make a crosstab\n                              columns=\"count\")      # Name the count column\n\ntrain_outcome","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Distribution of Churn\ntrain.Churn.value_counts()[0:30].plot(kind='bar')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plotting Heatmap\nHeatmap can be defined as a method of graphically representing numerical data where individual data points contained in the matrix are represented using different colors. \nThe colors in the heatmap can denote the frequency of an event, the performance of various metrics in the data set, and so on. Different color schemes are selected by varying businesses to present the data they want to be plotted on a heatmap [[2](https://vwo.com/blog/heatmap/)].","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train[['CustomerID','MonthlyRevenue','MonthlyMinutes','TotalRecurringCharge','DirectorAssistedCalls','OverageMinutes',\n         'RoamingCalls','PercChangeMinutes','PercChangeRevenues','DroppedCalls','BlockedCalls','UnansweredCalls','CustomerCareCalls',\n         'ThreewayCalls','ReceivedCalls','OutboundCalls','InboundCalls','PeakCallsInOut','OffPeakCallsInOut','DroppedBlockedCalls','CallForwardingCalls'\n         ,'CallWaitingCalls','MonthsInService','UniqueSubs','ActiveSubs','ServiceArea','Handsets','HandsetModels',              \n'CurrentEquipmentDays','AgeHH1','AgeHH2','ChildrenInHH','HandsetRefurbished','HandsetWebCapable','TruckOwner','RVOwner','Homeownership','BuysViaMailOrder','RespondsToMailOffers','OptOutMailings',          \n'NonUSTravel','OwnsComputer','HasCreditCard','RetentionCalls','RetentionOffersAccepted','NewCellphoneUser',          \n'NotNewCellphoneUser','ReferralsMadeBySubscriber','IncomeGroup','OwnsMotorcycle','AdjustmentsToCreditRating', \n'HandsetPrice','MadeCallToRetentionTeam','CreditRating','PrizmCode','Occupation','MaritalStatus','Churn']] #Subsetting the data\ncor = train.corr() #Calculate the correlation of the above variables\nsns.heatmap(cor, square = True) #Plot the correlation as heat map","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see above, we obtain the heatmap of correlation among the variables. The color palette in the side represents the amount of correlation among the variables. The lighter shade represents a high correlation. Here appear important variables (customer churn behavior):\n1. TotalRecurringCharge\n1. RoamingCalls\n1. DroppedCalls\n1. CustomerCareCalls\n1. OutboundCalls\n1. OffPeakCallsInOut\n1. CallWaitingCalls\n1. ActiveSubs\n1. HandsetModels\n1. AgeHH2\n1. HandsetWebCapable\n1. Homeownership\n1. OptOutMailings\n1. HasCreditCard\n1. NewCellphoneUser\n1. IncomeGroup\n1. HandsetPrice\n1. PrizmCode","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# SPLITING DATA","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Data for training and testing\nTo select a set of training data that will be input in the Machine Learning algorithm, to ensure that the classification algorithm training can be generalized well to new data. For this study using a sample size of 30%, assumed it ideal ratio between training and testing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nY = train['Churn']\nX = train.drop(columns=['Churn'])\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=9)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('X train shape: ', X_train.shape)\nprint('Y train shape: ', Y_train.shape)\nprint('X test shape: ', X_test.shape)\nprint('Y test shape: ', Y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. Random forest classification\n\nBased on the previous classification method, random forest is a supervised learning algorithm that creates a forest randomly. This forest, is a set of decision trees, most of the times trained with the bagging method. The essential idea of bagging is to average many noisy but approximately impartial models, and therefore reduce the variation. Each tree is constructed using the following algorithm:\n\n* Let $N$ be the number of test cases, $M$ is the number of variables in the classifier.\n* Let $m$ be the number of input variables to be used to determine the decision in a given node; $m<M$.\n* Choose a training set for this tree and use the rest of the test cases to estimate the error.\n* For each node of the tree, randomly choose $m$ variables on which to base the decision. Calculate the best partition of the training set from the $m$ variables.\n\nFor prediction a new case is pushed down the tree. Then it is assigned the label of the terminal node where it ends. This process is iterated by all the trees in the assembly, and the label that gets the most incidents is reported as the prediction. We define the number of trees in the forest in 100. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\n# We define the model\nrfcla = RandomForestClassifier(n_estimators=100,random_state=9,n_jobs=-1)\n\n# We train model\nrfcla.fit(X_train, Y_train)\n\n# We predict target values\nY_predict5 = rfcla.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The confusion matrix\nrfcla_cm = confusion_matrix(Y_test, Y_predict5)\nf, ax = plt.subplots(figsize=(5,5))\nsns.heatmap(rfcla_cm, annot=True, linewidth=0.7, linecolor='black', fmt='g', ax=ax, cmap=\"BuPu\")\nplt.title('Random Forest Classification Confusion Matrix')\nplt.xlabel('Y predict')\nplt.ylabel('Y test')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test score\nscore_rfcla = rfcla.score(X_test, Y_test)\nprint(score_rfcla)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Naive bayes classification\n\nThe naive Bayesian classifier is a probabilistic classifier based on Bayes' theorem with strong independence assumptions between the features. Thus, using Bayes theorem $\\left(P(X|Y)=\\frac{P(Y|X)P(X)}{P(Y)}\\right)$, we can find the probability of $X$ happening, given that $Y$ has occurred. Here, $Y$ is the evidence and $X$ is the hypothesis. The assumption made here is that the presence of one particular feature does not affect the other (the predictors/features are independent). Hence it is called naive. In this case we will assume that we assume the values are sampled from a Gaussian distribution and therefore we consider a Gaussian Naive Bayes.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\n\n# We define the model\nnbcla = GaussianNB()\n\n# We train model\nnbcla.fit(X_train, Y_train)\n\n# We predict target values\nY_predict3 = nbcla.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The confusion matrix\nnbcla_cm = confusion_matrix(Y_test, Y_predict3)\nf, ax = plt.subplots(figsize=(5,5))\nsns.heatmap(nbcla_cm, annot=True, linewidth=0.7, linecolor='black', fmt='g', ax=ax, cmap=\"BuPu\")\nplt.title('Naive Bayes Classification Confusion Matrix')\nplt.xlabel('Y predict')\nplt.ylabel('Y test')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test score\nscore_nbcla = nbcla.score(X_test, Y_test)\nprint(score_nbcla)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Comparison of classification techniques","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Test score\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Testscores = pd.Series([score_rfcla,score_nbcla, ], \n                        index=['Random Forest Score','Naive Bayes Score' ]) \nprint(Testscores)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ROC Curve\nis a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve\n# Random Forest Classification\nY_predict5_proba = rfcla.predict_proba(X_test)\nY_predict5_proba = Y_predict5_proba[:, 1]\nfpr, tpr, thresholds = roc_curve(Y_test, Y_predict5_proba)\nplt.subplot(331)\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr,tpr, label='ANN')\nplt.xlabel('fpr')\nplt.ylabel('tpr')\nplt.title('ROC Curve Random Forest')\nplt.grid(True)\nplt.subplots_adjust(top=2, bottom=0.08, left=0.10, right=1.4, hspace=0.45, wspace=0.45)\nplt.show()\n\n# Naive Bayes Classification\nY_predict3_proba = nbcla.predict_proba(X_test)\nY_predict3_proba = Y_predict3_proba[:, 1]\nfpr, tpr, thresholds = roc_curve(Y_test, Y_predict3_proba)\nplt.subplot(332)\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr,tpr, label='ANN')\nplt.xlabel('fpr')\nplt.ylabel('tpr')\nplt.title('ROC Curve Naive Bayes')\nplt.grid(True)\nplt.subplots_adjust(top=2, bottom=0.08, left=0.10, right=1.4, hspace=0.45, wspace=0.45)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Random Forest perform better than Naive Bayes. Random Forest can handle categorical features very well and it can handle high dimensional spaces as well as a large number of training examples. I guess Naive Bayes is not good enough to represent complex behavior.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}