{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# Purpose\n\nI am going to go through the [task submissions](https://www.kaggle.com/mdabbert/ultimate-ufc-dataset/tasks?taskId=1285) for UFC 251 and see what set of predictions was the most profitable (if any!)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Submissions\n\nThere are 3 submissions.\n\n1. The dummy file (gives each fighter a .5 probability of winning.  Therefore will bet every underdog with greater than +100 odds.)\n\n2. shortlikeafox's (my!) submission.  A GaussianNB model with 18 features chosen through a systematic process of feature set testing.\n\n3. yeahhhhhboi's submission.  Here is the description from his dataset: \"Still working on a regression to obtain a p value including various other datasets, these choices are derrived from comparing ratios of TKO/KO win/loss and submission win/loss against their opponents (from sherdog), comparing the 540 metric from fightmatrix.com, and weighing UFC wins larger than other MMA bouts included in their win loss record. Still very crude but I want to see how things pan out tomorrow. I cannot wait to see this historic fight card tomorrow, good luck on your bets!\"","attachments":{},"execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Open All Submissions and add to a list","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#This will help us keep track of the submissions\nsub_name_list = ['dummy', 'shortlikeafox', 'yeahhhhhboi']\nscore_list = [] #We can keep the scores here\n\n#Put the submissions in dataframe form and add to a list.\nsub_list = []\ntemp_df = pd.read_csv(\"/kaggle/input/ufc251dummysubmission/ufc-251-dummy.csv\")\nsub_list.append(temp_df)\ntemp_df = pd.read_csv(\"/kaggle/input/ufc-251-actual-submission/ufc-251-actual-submission.csv\")\nsub_list.append(temp_df)\ntemp_df = pd.read_csv(\"/kaggle/input/ufc-251-submission/ufc-251-submission.csv\")\nsub_list.append(temp_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Open the csv that contains fight results and odds","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"results_df = pd.read_csv(\"/kaggle/input/ultimate-ufc-dataset/most-recent-event.csv\")\n\n#We only need the fighter names, odds, and winner\n\nresults_df = results_df[['R_fighter', 'B_fighter', 'R_ev', 'B_ev', 'Winner']]\ndisplay(results_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Iterate the submissions and see how everyone did!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Returns a specific bet EV based on winning_ev and probability.\ndef get_bet_ev(ev, prob):\n    \n    return(ev*prob - (1-prob)*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Used to determine the bet of each fight.  We will use probabilities and the ev to \n#determine profitable bets\ndef get_bet(R_prob, B_prob, R_ev, B_ev):\n    red_ev = get_bet_ev(R_ev, R_prob)\n    blue_ev = get_bet_ev(B_ev, B_prob)\n    if red_ev > 0:\n        return('Red')\n    if blue_ev > 0:\n        return('Blue')\n    \n    return 'None'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_profit(winner, bet, R_ev, B_ev):\n    if bet == 'None':\n        return 0\n    if (bet == 'Blue' and winner == 'Blue'):\n        return B_ev\n    if (bet == 'Red' and winner == 'Red'):\n        return R_ev\n    else:\n        return (-100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's make a helper function to make this easier\n\ndef get_score(sub, results):\n#    display(sub)\n#    display(results)\n    #Let's merge the two dataframes\n    merge_df = pd.merge(sub, results)\n    #display(merge_df)\n    #We can get the proper bet by using a lambda function\n    merge_df['Bet'] = merge_df.apply(lambda x: get_bet(x['R_prob'],x['B_prob'],x['R_ev'],x['B_ev']), axis=1)\n    merge_df['Profit'] = merge_df.apply(lambda x: get_profit(x['Winner'], x['Bet'], x['R_ev'], x['B_ev']), axis=1)\n    display(merge_df)\n    return(sum(merge_df['Profit']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission \\#1: Dummy Submission\n\nThese are the results for the dummy submission.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"z = 0\nscore_list.append(get_score(sub_list[z], results_df))\nprint(f\"{sub_name_list[z]}'s bets saw a total profit of {score_list[z]}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dummy only bets on underdogs that have odds greater than +100.  This was not a good night for the underdogs.  This submission won 2 out of 12 bets and abstained from one fight.  The total return for this model was -741 units.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Submission \\#2: shortlikeafox's Submission","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"z = 1\nscore_list.append(get_score(sub_list[z], results_df))\nprint(f\"{sub_name_list[z]}'s bets saw a total profit of {score_list[z]}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"shortlikeafox won 8 bets out of 12 for a profit of 36.34 units.  The late added fight of Tybura / Grishin was never updated to this dataset so that's why there is a fight missing from the dataframe.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Submission \\#3: yeahhhhhboi's Submission ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"z = 2\nscore_list.append(get_score(sub_list[z], results_df))\nprint(f\"{sub_name_list[z]}'s bets saw a total profit of {score_list[z]}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"yeahhhhhboi saw a profit of 9.12 units on 8 winning bets out of 13 fights.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Final Results\n\n* dummy: -741 units\n* shortlikeafox: +36.34 units\n* yeahhhhhboi: + 9.12 units\n\nshortlikeafox is the winner!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}