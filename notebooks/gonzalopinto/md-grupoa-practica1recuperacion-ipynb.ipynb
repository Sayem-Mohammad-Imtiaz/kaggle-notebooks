{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Práctica 1: Análisis exploratorio de datos, preprocesamiento y validación de modelos de clasificación\n\n### Minería de Datos: Curso académico 2020-2021\n\n### Integrantes:\n\n* Gonzalo Pinto Perez\n* Yeremi Martin Huaman Torres","metadata":{}},{"cell_type":"markdown","source":"# 1. Preliminares","metadata":{}},{"cell_type":"markdown","source":"Para empezar vamos a cargar las librerias que utilizaremos durante el desarrollo de la práctica","metadata":{}},{"cell_type":"code","source":"# Third party\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import *\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.impute import *\nfrom sklearn.ensemble import RandomForestClassifier\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn import FunctionSampler\nfrom imblearn.pipeline import make_pipeline\nfrom scipy.stats import shapiro\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.metrics import *\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport plotly.express as px\nimport ipywidgets as widgets\nfrom sklearn.compose import make_column_selector, make_column_transformer\n\n\n\n\n# Importamos nuestro propio fichero de utilidades\nimport md_grupoa_practica1extra_ficheroutilidad as utils\n\n","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:36.955683Z","iopub.execute_input":"2021-05-28T10:37:36.956163Z","iopub.status.idle":"2021-05-28T10:37:36.965142Z","shell.execute_reply.started":"2021-05-28T10:37:36.95613Z","shell.execute_reply":"2021-05-28T10:37:36.964274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## *1.1 Variables globales*","metadata":{}},{"cell_type":"markdown","source":"Fijamos la semilla que utilizaremos:","metadata":{}},{"cell_type":"code","source":"seed = 27912","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:36.966586Z","iopub.execute_input":"2021-05-28T10:37:36.967139Z","iopub.status.idle":"2021-05-28T10:37:36.983072Z","shell.execute_reply.started":"2021-05-28T10:37:36.967095Z","shell.execute_reply":"2021-05-28T10:37:36.981885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Fijamos el tamaño del conjunto de entrenamiento:","metadata":{}},{"cell_type":"code","source":"train_size = 0.7","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:36.984473Z","iopub.execute_input":"2021-05-28T10:37:36.984856Z","iopub.status.idle":"2021-05-28T10:37:36.994229Z","shell.execute_reply.started":"2021-05-28T10:37:36.984812Z","shell.execute_reply":"2021-05-28T10:37:36.993485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## *1.2 Funciones auxiliares*","metadata":{}},{"cell_type":"markdown","source":"Estas son las funciones axiliares que hemos creado para esta práctica y que hemos añadido a nuestro utils","metadata":{}},{"cell_type":"code","source":"#Funcion para realizar gráficos de caja\ndef plot_boxplot(data):\n    \n    var = data.columns\n    data = widgets.fixed(data)\n\n    widgets.interact(_plot_boxplot, data=data, var=var)\n\n#Función auxiliar para gráficos de caja    \ndef _plot_boxplot(data, var):\n    return data[var].iplot(kind=\"box\")\n\n#Función para calcular el porcentaje de ceros en variables que no deberían de tener ceros\ndef ZeroCount(Data, param):\n    for s in param:\n        aux=Data[s]\n        zeros=aux.astype(bool).sum(axis=0)\n        totalval=np.product(aux.shape)\n        result= (1-(zeros/totalval)) * 100    \n        #print(result)\n        print(f\"El porcentaje de ceros en la variable {s} es del {result:.2f}% \")\n        \n\n#Función para calcular el porcentaje de valores nulos en variables\ndef MissingValuesCount(Data, param):\n    Nan= Data.isnull().sum()\n    for s in param:\n        Aux =Data[s]\n        TotalVal= np.product(Aux.shape)\n        NanSum = Aux.isnull().sum()\n        result= (NanSum/TotalVal)*100  \n        print(f\"El porcentaje de valores nulos en la variable {s} es del {result:.2f}% \")\n\n\n#Función para eliminar outliers\ndef outlier_rejection(X, y, seed):\n    model = IsolationForest(random_state=seed)\n    model.fit(X)\n    y_pred = model.predict(X)\n    return X[y_pred == 1], y[y_pred == 1]\n\n\n#Función para realizar la evaluacion de bases de datos medicas\ndef EvaluationWClassRepo(model,\n             X_train, X_test,\n             y_train, y_test):\n    \n    clf = model.fit(X_train, y_train)\n    \n    y_pred = clf.predict(X_test)\n\n    accuracy = accuracy_score(y_test, y_pred)\n    \n    d = dict(enumerate(yTitanic.cat.categories))\n    a=\"% s\" % d.get(0)\n    b=\"% s\" % d.get(1)\n    labels=[a,b]\n    print(classification_report(y_test, y_pred, target_names=labels))\n    \n    disp = plot_confusion_matrix(clf, X_test, y_test)\n    \n    accuracy= accuracy*100\n\n    disp.ax_.set_title(f\" Tasa de precisión = {accuracy:.2f}\"+\"%\")\n    \n","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:36.99567Z","iopub.execute_input":"2021-05-28T10:37:36.995946Z","iopub.status.idle":"2021-05-28T10:37:37.012977Z","shell.execute_reply.started":"2021-05-28T10:37:36.995918Z","shell.execute_reply":"2021-05-28T10:37:37.012208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Acceso y almacenamiento de datos","metadata":{}},{"cell_type":"markdown","source":"## *2.1 Breast cancer Winsconsin*","metadata":{}},{"cell_type":"markdown","source":"La base de datos Breast cancer Winscosin es el resultado del análisis de una imagen digitalizada de un aspirado con aguja fina (FNA) de una masa mamaria. El análisis se realiza teniendo en cuenta las distitnas variables que maneja la base de datos las cuales son:\n\n1. ID number: Es un número creciente que servirá de identificador para cada uno de los casos de la base de datos.\n2. Diagnosis: Variable que guardará el resultado del análisis de la masa mamaria. Si tiene el valor B en caso de que la masa sea benignea y M en caso de que la masa sea maligna. Esta variable será la que tomemos como variable predictora.\n3. radius: Variable real que guardará la media de las distancias desde el centro hasta los puntos del perímetro de la masa.\n4. texture: Variable real que guardará la desviación estándar de los valores de la escala de grises de la masa.\n5. perimeter: Variable real que guardará el perímetro de la masa.\n6. area: Variable real que guardará el perímetro de la masa.\n7. smoothness: Variable real que guardará la variación local en longitudes de radio de la masa.\n8. compactness: Variable real resultante de la operación perimeter^2 / area - 1.0 (los valores de la variables son los de la masa)\n9. concavity: Variable real que representa la severidad de las porciones cóncavas del contorno de la masa.\n10. concave points: Variable real que represente el numero de porciones cóncavas  del controno de la masa.\n11. symmetry: Variable real que representa la simetria de la masa.\n12. fractal dimension (\"coastline approximation\" - 1): Variable real que representa la aproximación de la linea costera de la masa\n\nLas dos primeras variables son variables de información y el resto son variables que se computan para cada caso de masa mamaria analizada. Para estas últimas variables habrá tres tipos para cada uno de los casos:\n\n    -Variable_mean: Guardará el valor medio de la variable.\n    -Variable_se: Guardará el error estándar de la variable.\n    -Variable_worst: Guardará el peor valor (media de los tres valores más grandes) de la variable.\n\nComo conclusion la base de datos se utilizará en nuestro estudio para generar un modelo que prediga según unos valores si la masa mamaria analiza es B (Benigna) o M (Maligna)\n","metadata":{}},{"cell_type":"markdown","source":"Cargamos la base de datos Breast cancer wisconsin  tratando la variable id como indice y la variable diagnosis como variable objetivo. Finalmente mostramos una muestra del conjunto de datos cargados","metadata":{}},{"cell_type":"code","source":"filepathWisconsin = \"../input/breast-cancer-wisconsin-data/data.csv\"\nindexWisconsin = \"id\"\ntargetWisconsin = \"diagnosis\"\ndataWisconsin = utils.load_data(filepathWisconsin, indexWisconsin, targetWisconsin)\ndataWisconsin.sample(5, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:37.014037Z","iopub.execute_input":"2021-05-28T10:37:37.014479Z","iopub.status.idle":"2021-05-28T10:37:37.058821Z","shell.execute_reply.started":"2021-05-28T10:37:37.014447Z","shell.execute_reply":"2021-05-28T10:37:37.058071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Si realizamos una observación de este muestra podemos darnos cuenta de que destaca una variable llamada Unnamed 32 ya que en la muestra todos los sus valores son nulos (NaN). Si nos descargamos el fichero .csv de la base de datos Breast Cancer Wisconsin, podemos observar que esta variable es ruido ya que se ha introducido por error a la hora de cargar el conjunto de datos pues en el fichero se ha introducido una coma de más y al cargarlo esa coma la toma como otra variable, para ser exactos como la variable Unnamed32.\nPor ello lo que vamos a hacer a continuación es eliminar dicha columna (mediante el método de pandas drop) del conjunto de datos dataWisconsin y enseñaremos otra muestra de dicho conjunto de datos para confirmar si se han borrado correctamente.","metadata":{}},{"cell_type":"code","source":"dataWisconsin = dataWisconsin.drop(dataWisconsin.columns[31], axis = 'columns')\ndataWisconsin.sample(5, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:37.05972Z","iopub.execute_input":"2021-05-28T10:37:37.060206Z","iopub.status.idle":"2021-05-28T10:37:37.088574Z","shell.execute_reply.started":"2021-05-28T10:37:37.060172Z","shell.execute_reply":"2021-05-28T10:37:37.087585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"En el siguiente paso dividimos el conjunto de datos en dos subconjuntos, uno con las variables predictoras (X) y otro con las variables objetivo (Y). Después mostramos una muestra (sample) de los subconjuntos creados.","metadata":{}},{"cell_type":"code","source":"(XWisconsin, yWisconsin) = utils.divide_dataset(dataWisconsin, target=\"diagnosis\")","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:37.090115Z","iopub.execute_input":"2021-05-28T10:37:37.090528Z","iopub.status.idle":"2021-05-28T10:37:37.101839Z","shell.execute_reply.started":"2021-05-28T10:37:37.090485Z","shell.execute_reply":"2021-05-28T10:37:37.100782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"XWisconsin.sample(5, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:37.103617Z","iopub.execute_input":"2021-05-28T10:37:37.104028Z","iopub.status.idle":"2021-05-28T10:37:37.134549Z","shell.execute_reply.started":"2021-05-28T10:37:37.103983Z","shell.execute_reply":"2021-05-28T10:37:37.133406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yWisconsin.sample(5, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:37.136021Z","iopub.execute_input":"2021-05-28T10:37:37.136691Z","iopub.status.idle":"2021-05-28T10:37:37.151681Z","shell.execute_reply.started":"2021-05-28T10:37:37.136558Z","shell.execute_reply":"2021-05-28T10:37:37.150273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A continuación vamos a dividir nuestros subconjunto de datos en otros dos:\n*  uno que sirva como muestra de entrenemiento (XWisconsin_train y yWisconsin_train) (70% del subconjunto inicial)\n*  el otro que sirva como muestra de prueba (XWisconsin_test y yWisconsin_test) (30% del subconjunto incial)\n\nEsta división la realizaremos con el método train_test_split.\n\nFinalmente mostraremos una muestra de cada uno de los subconjuntos obtenidos de forma aleatoria (utilizando la semilla que hemos definido al principio de la práctica).","metadata":{}},{"cell_type":"code","source":"(XWisconsin_train, XWisconsin_test, yWisconsin_train, yWisconsin_test) = train_test_split(XWisconsin, yWisconsin,\n                                                      stratify=yWisconsin,\n                                                      random_state=seed,\n                                                      train_size=train_size)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:37.15315Z","iopub.execute_input":"2021-05-28T10:37:37.153829Z","iopub.status.idle":"2021-05-28T10:37:37.167932Z","shell.execute_reply.started":"2021-05-28T10:37:37.153793Z","shell.execute_reply":"2021-05-28T10:37:37.1666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"XWisconsin_train.sample(5, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:37.169166Z","iopub.execute_input":"2021-05-28T10:37:37.169716Z","iopub.status.idle":"2021-05-28T10:37:37.200233Z","shell.execute_reply.started":"2021-05-28T10:37:37.169682Z","shell.execute_reply":"2021-05-28T10:37:37.199466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"XWisconsin_test.sample(5, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:37.201576Z","iopub.execute_input":"2021-05-28T10:37:37.202037Z","iopub.status.idle":"2021-05-28T10:37:37.234917Z","shell.execute_reply.started":"2021-05-28T10:37:37.202006Z","shell.execute_reply":"2021-05-28T10:37:37.233997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yWisconsin_train.sample(5, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:37.236324Z","iopub.execute_input":"2021-05-28T10:37:37.236621Z","iopub.status.idle":"2021-05-28T10:37:37.251039Z","shell.execute_reply.started":"2021-05-28T10:37:37.236593Z","shell.execute_reply":"2021-05-28T10:37:37.249592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yWisconsin_test.sample(5, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:37.252351Z","iopub.execute_input":"2021-05-28T10:37:37.252815Z","iopub.status.idle":"2021-05-28T10:37:37.263556Z","shell.execute_reply.started":"2021-05-28T10:37:37.252771Z","shell.execute_reply":"2021-05-28T10:37:37.262782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## *2.2 Pima Indians diabetes*","metadata":{}},{"cell_type":"markdown","source":"La base de datos Pima Indians diabetes tiene el objetivo de predecir de forma diagnóstica si un paciente tiene o no diabetes, basándose en ciertas mediciones ya realizadas e incluidas en la base de datos. Algunas restricciones se han establecido en la seleccion de las instacias para la base de datos. En particular, todos los pacientes son mujeres con al menos 21 años con herencia del pueblo Pima (que és un grupo de indígenas de Estados Unidos que viven en Arizona). Las distitnas variables que maneja la base de datos son las siguientes:\n\n1. Pregnancies: Número entero que indica el número de veces que ha estado embarazada la paciente.\n2. Glucose: Número entero que indica la concentración de glucosa en plasma de la paciente tras 2 horas de que se la haya realizado una prueba oral de tolerancia a la glucosa.\n3. BloodPresure: Número entero que indica la presión arterial diastólica de la paciente en mm/hg.\n4. SkinThickness: Número entero que indica el espesor del pliegue cutáneo del triceps de la paciente en mm\n5. Insulin: Número real que indica el suelo insulino tras 2 horas de la paciente en mu U/ml\n6. BMI: Número entero que indica el índice de masa corporal de la paciente dado por la divisón del peso en kg entre la altura en metros al cuadrado\n7. DiabetesPedigreeFunction: Número real que indica el resultado de la función de pedigree de la función.\n8. Age: Número entero que indica la edad del paciente.\n9. Outcome: Número categórico numérico que puede tener los valores 1 o 0. Esta variable tomará el valor 1 en el caso de que la paciente tenga diabetes y tomará el valor 0 en el caso de que la paciente no tenga diabetes.\n\nLa variable objetivo de este problema sería outcome, mientras que el resto serán variables predictoras.\nComo conclusión, recordar que nuestra base de datos tendrá la finalidad de que en base a los valores de las variables predictoras, intentará diagnosticar si un paciente tiene diabetes o no \"rellenando\" el valor de la variable objetivo Outcome.\n\n","metadata":{}},{"cell_type":"markdown","source":"Lo primero que vamos a hacer es cargar la base de datos utilizando Outcome como variable objetivo y como la base de datos carece de una variable que se pueda utilizar como índice, no utilizaremos ninguna variable (None) como variable indice ya que en ese caso, el método load_data generá un indice de forma automática.","metadata":{}},{"cell_type":"code","source":"filepath = \"../input/pima-indians-diabetes-database/diabetes.csv\"\nindexDiabetes = None\ntargetDiabetes = \"Outcome\"\ndataDiabetes = utils.load_data(filepath, indexDiabetes, targetDiabetes)\ndataDiabetes.sample(5, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:37.264587Z","iopub.execute_input":"2021-05-28T10:37:37.264987Z","iopub.status.idle":"2021-05-28T10:37:37.289402Z","shell.execute_reply.started":"2021-05-28T10:37:37.264953Z","shell.execute_reply":"2021-05-28T10:37:37.288715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"En el siguiente paso dividimos el conjunto de datos en dos subconjuntos, uno con las variables predictoras (X) y otro con las variables objetivo (Y). Después mostramos una muestra (sample) de los subconjuntos creados.","metadata":{}},{"cell_type":"code","source":"(XDiabetes, yDiabetes) = utils.divide_dataset(dataDiabetes, target=\"Outcome\")","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:37.290293Z","iopub.execute_input":"2021-05-28T10:37:37.290564Z","iopub.status.idle":"2021-05-28T10:37:37.295835Z","shell.execute_reply.started":"2021-05-28T10:37:37.290538Z","shell.execute_reply":"2021-05-28T10:37:37.29474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"XDiabetes.sample(5, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:37.296981Z","iopub.execute_input":"2021-05-28T10:37:37.297392Z","iopub.status.idle":"2021-05-28T10:37:37.316112Z","shell.execute_reply.started":"2021-05-28T10:37:37.297351Z","shell.execute_reply":"2021-05-28T10:37:37.31539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yDiabetes.sample(5, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:37.317159Z","iopub.execute_input":"2021-05-28T10:37:37.317537Z","iopub.status.idle":"2021-05-28T10:37:37.332876Z","shell.execute_reply.started":"2021-05-28T10:37:37.317509Z","shell.execute_reply":"2021-05-28T10:37:37.331915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A continuación vamos a dividir nuestros subconjunto de datos en otros dos:\n*  uno que sirva como muestra de entrenemiento (XDiabetes_train y yDiabetes_train) (70% del subconjunto inicial)\n*  el otro que sirva como muestra de prueba (XDiabetes_test y yDiabetes_test) (30% del subconjunto incial)\n\nEsta división la realizaremos con el método train_test_split.\n\nFinalmente mostraremos una muestra de cada uno de los subconjuntos obtenidos de forma aleatoria (utilizando la semilla que hemos definido al principio de la práctica).","metadata":{}},{"cell_type":"code","source":"(XDiabetes_train, XDiabetes_test, yDiabetes_train, yDiabetes_test) = train_test_split(XDiabetes, yDiabetes,\n                                                      stratify=yDiabetes,\n                                                      random_state=seed,\n                                                      train_size=train_size)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:37.334235Z","iopub.execute_input":"2021-05-28T10:37:37.334547Z","iopub.status.idle":"2021-05-28T10:37:37.348691Z","shell.execute_reply.started":"2021-05-28T10:37:37.334517Z","shell.execute_reply":"2021-05-28T10:37:37.347755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"XDiabetes_train.sample(5, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:37.349899Z","iopub.execute_input":"2021-05-28T10:37:37.350172Z","iopub.status.idle":"2021-05-28T10:37:37.36755Z","shell.execute_reply.started":"2021-05-28T10:37:37.350146Z","shell.execute_reply":"2021-05-28T10:37:37.366876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"XDiabetes_test.sample(5, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:37.36849Z","iopub.execute_input":"2021-05-28T10:37:37.368876Z","iopub.status.idle":"2021-05-28T10:37:37.387085Z","shell.execute_reply.started":"2021-05-28T10:37:37.368847Z","shell.execute_reply":"2021-05-28T10:37:37.386008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yDiabetes_train.sample(5, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:37.388187Z","iopub.execute_input":"2021-05-28T10:37:37.38847Z","iopub.status.idle":"2021-05-28T10:37:37.40164Z","shell.execute_reply.started":"2021-05-28T10:37:37.388422Z","shell.execute_reply":"2021-05-28T10:37:37.400588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yDiabetes_test.sample(5, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:37.40321Z","iopub.execute_input":"2021-05-28T10:37:37.403632Z","iopub.status.idle":"2021-05-28T10:37:37.416201Z","shell.execute_reply.started":"2021-05-28T10:37:37.403591Z","shell.execute_reply":"2021-05-28T10:37:37.41554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## *2.3 Titanic*","metadata":{}},{"cell_type":"markdown","source":"La base de datos Titanic es una base de datos que recoge ciertas características en sus variables sobre los distintos pasajeros del único y famoso viaje del Titanic. Dichas variables son las siguientes:\n\n1. PassengerId: Variable numérica entera creciente que actuará de indice de los distintos casos de la base de datos.\n2. Survived: Variable categórica numérica que servirá de variable objetico y que podrá tener los valores 0 o 1, 0 en el caso de que el pasajero no sobrevivierá en el viaje y 1 en el caso de que el pasajero sobreviviera. \n3. Pclass: Variable categórica numérica que servirá para indicar la clase del pasajero. La variable podrá tener los valores 1,2 o 3; 1 en el caso de que el pasajero se alojase en primera clase, 2 en el caso de que el pasajero se alojase en segunda clase y 3 en el caso de que el pasajero se alojase en tercera clase.\n4. Name: Variable string de valores únicos que tendrá el valor del nombre de los distintos pasajeros de los casos de la base de datos.\n5. Sex: Variable categórica que servirá para indicar el género del pasajero. La variable podrña tener los valores male o female, male en el caso de que el género del pasajero sea masculilno y female en el caso de que el género del pasajero sea femenino.\n6. Age: Variale entera que servirá para indicar la edad del pasajero.\n7. SibSp: Variable entera que servirá para indicar el número de hermanos (hermano, hermana, hermanastro o hermanastra) o de parejas (marido o mujer, las prometidas y amantes se ignoraron) que tiene el pasajero en el viaje.\n8. pArch: Variable entera que servirá para indicar el número de parientes que tiene el pasajero en el viaje (madre, padre, hija, hijo, hijastra, hijastro)\n9. Ticket: Variable string de valores único que servirá para indicar el número de billete que tiene el pasajero. \n10. Fare: Variable real que servirá para indicar la tarifa por la que ha pagado el pasajero por su billete.\n11. Cabin: Variable string que servirá para indicar la cabina en la que viajaba el pasajero durante el viaje.\n12. Embarked: Variable categórica que podrá tomar los valores C, Q o S en caso de que el pasajero embarcase en los puertos de Cherbourg, Queenstown o Southampton respectivamente.\n\n\nLa variable que usaremos como variable objetivo será Survived, la variable que usaremos como indice será PassengerId y el resto serán variables predictoras.\nComo conclusión, decir que esta base de datos se utilizará en nuestro estudio para generar modelos que prediga si un pasajero sobrevivirá al viaje o no dependiendo de ciertas características (que serán los valores de las variables predictoras).","metadata":{}},{"cell_type":"markdown","source":"Cargamos la base de datos, pero al tener esta implicita tres archivos .csv utilizaremos únicamente el fichero train.csv pues es el único que posee todas las variables predictoras que reccogen las características de los pasajeros. Utilizaremos la variable PassenferId como índice y Survived como variable predictora y para cargar la base de datos utilizaremos el método del utils load_data.","metadata":{}},{"cell_type":"code","source":"indexTitanic=\"PassengerId\"\ntargetTitanic=\"Survived\" \nfilepathTitanic=\"../input/titanic/train.csv\"\ndataTitanic = utils.load_data(filepathTitanic, indexTitanic, targetTitanic)\ndataTitanic.sample(5, random_state=seed)\n","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:37.417743Z","iopub.execute_input":"2021-05-28T10:37:37.417994Z","iopub.status.idle":"2021-05-28T10:37:37.451274Z","shell.execute_reply.started":"2021-05-28T10:37:37.417969Z","shell.execute_reply":"2021-05-28T10:37:37.450618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"En el siguiente paso dividimos el conjunto de datos en dos subconjuntos, uno con las variables predictoras (X) y otro con las variables objetivo (Y). Después mostramos una muestra (sample) de los subconjuntos creados.","metadata":{}},{"cell_type":"code","source":"(XTitanic, yTitanic) = utils.divide_dataset(dataTitanic, target=\"Survived\")","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:37.452158Z","iopub.execute_input":"2021-05-28T10:37:37.452518Z","iopub.status.idle":"2021-05-28T10:37:37.457312Z","shell.execute_reply.started":"2021-05-28T10:37:37.452488Z","shell.execute_reply":"2021-05-28T10:37:37.456646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"XTitanic.sample(5, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:37.458168Z","iopub.execute_input":"2021-05-28T10:37:37.4584Z","iopub.status.idle":"2021-05-28T10:37:37.480643Z","shell.execute_reply.started":"2021-05-28T10:37:37.458376Z","shell.execute_reply":"2021-05-28T10:37:37.479352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yTitanic.sample(5, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:37.482113Z","iopub.execute_input":"2021-05-28T10:37:37.482513Z","iopub.status.idle":"2021-05-28T10:37:37.494645Z","shell.execute_reply.started":"2021-05-28T10:37:37.482481Z","shell.execute_reply":"2021-05-28T10:37:37.49366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A continuación vamos a dividir nuestros subconjunto de datos en otros dos:\n*  uno que sirva como muestra de entrenemiento (XTitanic_train y yTitanic_train) (70% del subconjunto inicial)\n*  el otro que sirva como muestra de prueba (XTitanic_test y yTitanic_test) (30% del subconjunto incial)\n\nEsta división la realizaremos con el método train_test_split.\n\nFinalmente mostraremos una muestra de cada uno de los subconjuntos obtenidos de forma aleatoria (utilizando la semilla que hemos definido al principio de la práctica).","metadata":{}},{"cell_type":"code","source":"(XTitanic_train, XTitanic_test, yTitanic_train, yTitanic_test) = train_test_split(XTitanic, yTitanic,\n                                                      stratify=yTitanic,\n                                                      random_state=seed,\n                                                      train_size=train_size)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:37.49592Z","iopub.execute_input":"2021-05-28T10:37:37.496267Z","iopub.status.idle":"2021-05-28T10:37:37.508404Z","shell.execute_reply.started":"2021-05-28T10:37:37.496237Z","shell.execute_reply":"2021-05-28T10:37:37.507383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"XTitanic_train.sample(5, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:37.510022Z","iopub.execute_input":"2021-05-28T10:37:37.510384Z","iopub.status.idle":"2021-05-28T10:37:37.527057Z","shell.execute_reply.started":"2021-05-28T10:37:37.510345Z","shell.execute_reply":"2021-05-28T10:37:37.526166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"En estas dos muestra que hemos obtenido ya podemos observar valores nulos (NaN) en algunas variables que es un dato que vamos a tener que tener en cuenta a la hora de realizar el análisis exploratorio y el psoterior preprocesamiento de datos.","metadata":{}},{"cell_type":"code","source":"XTitanic_test.sample(5, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:37.528346Z","iopub.execute_input":"2021-05-28T10:37:37.528975Z","iopub.status.idle":"2021-05-28T10:37:37.548483Z","shell.execute_reply.started":"2021-05-28T10:37:37.528934Z","shell.execute_reply":"2021-05-28T10:37:37.547333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yTitanic_train.sample(5, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:37.551839Z","iopub.execute_input":"2021-05-28T10:37:37.552133Z","iopub.status.idle":"2021-05-28T10:37:37.562315Z","shell.execute_reply.started":"2021-05-28T10:37:37.552104Z","shell.execute_reply":"2021-05-28T10:37:37.561477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yTitanic_test.sample(5, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:37.563403Z","iopub.execute_input":"2021-05-28T10:37:37.563792Z","iopub.status.idle":"2021-05-28T10:37:37.577418Z","shell.execute_reply.started":"2021-05-28T10:37:37.563765Z","shell.execute_reply":"2021-05-28T10:37:37.576532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Preeliminares del analisis exploratiro**\n\n","metadata":{}},{"cell_type":"markdown","source":"Antes de empezar el analisis exploratorio obtendremos los conjuntos de entrenamiento y de test para todas las bases de datos sobre las que realizaremos el análisis exploratorio. Para ello volvemos a unir (usando el método join_dataset del fichero utils) los conjuntos de variables predictoras con la variable clase de los subconjuntos de entrenamiento y de test de todas las bases de datos.","metadata":{}},{"cell_type":"code","source":"dataWisconsin_test= utils.join_dataset(XWisconsin_test,yWisconsin_test)\ndataWisconsin_train= utils.join_dataset(XWisconsin_train,yWisconsin_train)\n\ndataDiabetes_test= utils.join_dataset(XDiabetes_test,yDiabetes_test)\ndataDiabetes_train= utils.join_dataset(XDiabetes_train,yDiabetes_train)\n\ndataTitanic_test= utils.join_dataset(XTitanic_test,yTitanic_test)\ndataTitanic_train= utils.join_dataset(XTitanic_train,yTitanic_train)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:37.578412Z","iopub.execute_input":"2021-05-28T10:37:37.578879Z","iopub.status.idle":"2021-05-28T10:37:37.592642Z","shell.execute_reply.started":"2021-05-28T10:37:37.57884Z","shell.execute_reply":"2021-05-28T10:37:37.591619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Analisis exploratorio","metadata":{}},{"cell_type":"markdown","source":"## *3.1 Breast cancer Winsconsin*","metadata":{}},{"cell_type":"markdown","source":"### **Descripción del conjunto**\n\nTendremos que tener conocimento de:\n* Numeros de casos\n* Tipos de variables","metadata":{}},{"cell_type":"markdown","source":"Primero mostramos el número de casos y variables del conjunto de datos de entrenamiento con el metodo .shape","metadata":{}},{"cell_type":"code","source":"dataWisconsin_train.shape","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:37.593781Z","iopub.execute_input":"2021-05-28T10:37:37.594466Z","iopub.status.idle":"2021-05-28T10:37:37.599146Z","shell.execute_reply.started":"2021-05-28T10:37:37.594415Z","shell.execute_reply":"2021-05-28T10:37:37.598225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Podemos observar que el conjunto de datos tiene 398 casos y 31 variables,siendo estas quizas demasiadas para que se reprensenten con claridad en algunos de los gráficos que vamos a utilizar","metadata":{}},{"cell_type":"code","source":"dataWisconsin_train.info(memory_usage=False)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:37.600235Z","iopub.execute_input":"2021-05-28T10:37:37.600575Z","iopub.status.idle":"2021-05-28T10:37:37.617513Z","shell.execute_reply.started":"2021-05-28T10:37:37.600545Z","shell.execute_reply":"2021-05-28T10:37:37.616306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Donde podemos observar que cada de las 31 variables que hay 30 son del tipo real y una que es del tipo categorico (Que es la variable que usaremos como variable objetivo, diagnosis)","metadata":{}},{"cell_type":"markdown","source":"A continuación mostramos los distitnos valores que pueden tomar nuestras variables categóricas con el método .categories:","metadata":{}},{"cell_type":"code","source":"yWisconsin_train.cat.categories","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:37.618589Z","iopub.execute_input":"2021-05-28T10:37:37.618834Z","iopub.status.idle":"2021-05-28T10:37:37.623736Z","shell.execute_reply.started":"2021-05-28T10:37:37.618809Z","shell.execute_reply":"2021-05-28T10:37:37.623004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Podemos observar que diagnosis es una variable categórica que puede tomar el valor B en caso de que el resultado del diagnosis de la masa del paciente sea benigna y M en casao de que el resultado del diagnosis de la masa del paciente sea maligno.","metadata":{}},{"cell_type":"markdown","source":"### **Visualización de las variables**","metadata":{}},{"cell_type":"markdown","source":"Vamos a empezar realizando un histograma sobre el conjunto de datos de entrenamiento:","metadata":{}},{"cell_type":"code","source":"utils.plot_histogram(dataWisconsin_train)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:37.624813Z","iopub.execute_input":"2021-05-28T10:37:37.625255Z","iopub.status.idle":"2021-05-28T10:37:37.865009Z","shell.execute_reply.started":"2021-05-28T10:37:37.625219Z","shell.execute_reply":"2021-05-28T10:37:37.864214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Tras observar el histograma que hemos obtenido sobre el conjunto de datos de entrenamiento, podemos sacar las siguientes conclusiones:\n* La primera conclusión que podemos sacar esque cada una de las variables perteneciente a un grupo (mean, se o worst) poseen una distribución similar, con alguna excepción. Por ejemplo, las variables del grupo del valor medio (mean), tienen una distribución normal con tendencia central en forma de campana de gauss, a excepción, de las variables area_mean, compactness_mean, concavity_mean y concave points_mean, que tienen una distribución con tendencia exponencial decreciente. Por otra parte, las variables del grupo del error medio (se) poseen una distribución exponencial decreciente apreciable en todas las variables del grupo. Finalmente, las variables del grupo del peor valor (worst) tienen una distribución normal con tenencia central en forma de campana de gauss, a excepción, de las variables area_worstm compactness_worst, concavity_worts y fractal dimension_worst.\n* La segunda conclusión que podemos sacar esque entre las 31 variables, no hemos observado que haya presencia de datos no válidos ni indicios de outliers. No obstante; durante la realización de este análisis exploratorio realizaremos un diagrama de caja para cada una de las variables para analizar de forma más detallada la presencia de outliers.","metadata":{}},{"cell_type":"markdown","source":"A continuacion vamos a realizar un diagrama de barras:","metadata":{}},{"cell_type":"code","source":"utils.plot_barplot(dataWisconsin_train)\nB,M= yWisconsin_train.value_counts()\nprint('Numero de masas benigneas: ',B)\nprint('Numero de masas malignas : ',M)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:37.865913Z","iopub.execute_input":"2021-05-28T10:37:37.866259Z","iopub.status.idle":"2021-05-28T10:37:37.944932Z","shell.execute_reply.started":"2021-05-28T10:37:37.866232Z","shell.execute_reply":"2021-05-28T10:37:37.943646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Observamos que en nuestro conjunto de datos entrenamientos hay más casos en el que el diagnóstico final fue benigneo(250)que en el que el diagnóstico final fue maligno (148), esto quiere decir que el problema está desbalanceado.","metadata":{}},{"cell_type":"markdown","source":"Continuaremos con el análisis exploratorio realizando un diagrama de puntos:","metadata":{}},{"cell_type":"code","source":"utils.plot_pairplot(dataWisconsin_train, target=\"diagnosis\")","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:37.947017Z","iopub.execute_input":"2021-05-28T10:37:37.947597Z","iopub.status.idle":"2021-05-28T10:37:38.103443Z","shell.execute_reply.started":"2021-05-28T10:37:37.947544Z","shell.execute_reply":"2021-05-28T10:37:38.102254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lo único que podemos observar es lo que hemos mencionado al principio de este análisis, al ser 30 variables predictoras, algunas representaciones gráficas pueden no verse con claridad y este es un ejemplo. Por ello lo que vamos a hacer es dividir el diagrama de puntos entre tres, uno para cada uno de los tres tipos que pueden tener las variables predictoras: mean, se y worst.","metadata":{}},{"cell_type":"code","source":"mean_train = dataWisconsin_train.iloc[:,[0,1,2,3,4,5,6,7,8,9,30]]\nse_train = dataWisconsin_train.iloc[:,[10,11,12,13,14,15,16,17,18,19,30]]\nworst_train = dataWisconsin_train.iloc[:,[20,21,22,23,24,25,26,27,28,29,30]]\nutils.plot_pairplot(mean_train, target=\"diagnosis\")","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:38.104961Z","iopub.execute_input":"2021-05-28T10:37:38.105506Z","iopub.status.idle":"2021-05-28T10:37:38.203836Z","shell.execute_reply.started":"2021-05-28T10:37:38.105464Z","shell.execute_reply":"2021-05-28T10:37:38.202632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"utils.plot_pairplot(se_train, target=\"diagnosis\")","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:38.205357Z","iopub.execute_input":"2021-05-28T10:37:38.205753Z","iopub.status.idle":"2021-05-28T10:37:38.293734Z","shell.execute_reply.started":"2021-05-28T10:37:38.205715Z","shell.execute_reply":"2021-05-28T10:37:38.292589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"utils.plot_pairplot(worst_train, target=\"diagnosis\")","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:38.295177Z","iopub.execute_input":"2021-05-28T10:37:38.295578Z","iopub.status.idle":"2021-05-28T10:37:38.378044Z","shell.execute_reply.started":"2021-05-28T10:37:38.295538Z","shell.execute_reply":"2021-05-28T10:37:38.376996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Respecto a estas graficas podemas darnos cuenta que las variables radius_mean, perimeter_mean, area_mean estan muy relacionados, obviamente eso puede ser por que para obtener el perimetro y el area es necesario saber el radio. Puede que sea factible descartar estas variables y quedarnos con solo radio ya que al estar muy relacionados dicha eliminación no afectaría negativamente a la generación de modelos y consideramos que es mejor eliminar 3 variables que una para tener menos variables que gestionar durante el proceso de modelado.\nTambién podemos observar que la mejor forma de realizar una discretización óptima sería utilizando dos contenedores y quizas la mejor estrategia sería utilizar KMeans, pero hay tantos casos que no se puede estar seguro a simple vista.","metadata":{}},{"cell_type":"markdown","source":"Para comprobar algunas de las conclusiones que hemos realizado en el apartado anterior vamos a generar una matriz de correlación:","metadata":{}},{"cell_type":"markdown","source":"Al igual que para el gráfico anterior vamos a realizar tres matrices distintas una para cada uno de los tipos que pueden tener las variables predictoras; mean,se y worst.","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots()\nsns.heatmap(mean_train.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:38.37934Z","iopub.execute_input":"2021-05-28T10:37:38.379663Z","iopub.status.idle":"2021-05-28T10:37:38.874709Z","shell.execute_reply.started":"2021-05-28T10:37:38.379632Z","shell.execute_reply":"2021-05-28T10:37:38.873381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots()\nsns.heatmap(se_train.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:38.876204Z","iopub.execute_input":"2021-05-28T10:37:38.876631Z","iopub.status.idle":"2021-05-28T10:37:39.570522Z","shell.execute_reply.started":"2021-05-28T10:37:38.876589Z","shell.execute_reply":"2021-05-28T10:37:39.569236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots()\nsns.heatmap(worst_train.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:39.572137Z","iopub.execute_input":"2021-05-28T10:37:39.572528Z","iopub.status.idle":"2021-05-28T10:37:40.056565Z","shell.execute_reply.started":"2021-05-28T10:37:39.572488Z","shell.execute_reply":"2021-05-28T10:37:40.055477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Las conclusiones que podemos sacar es que existe cierta relación entre las variables del conjunto de variables radius_mean, perimeter_mean y area_mean y entre las variables del conjunto de variables concavity_mean, concave points_mean y concavity_mean. Además de que existe cierta relación entre estos dos conjuntos de variables, por lo tanto durante el preprocesamiento deberiamos de tener en cuenta estas conclusiones y decidir si tenemos en cuenta estas variables para modelar el problema.","metadata":{}},{"cell_type":"markdown","source":"Diagrama de caja","metadata":{}},{"cell_type":"code","source":"utils.plot_boxplot(dataWisconsin_train)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:40.058361Z","iopub.execute_input":"2021-05-28T10:37:40.058771Z","iopub.status.idle":"2021-05-28T10:37:40.136248Z","shell.execute_reply.started":"2021-05-28T10:37:40.058723Z","shell.execute_reply":"2021-05-28T10:37:40.135498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Las conclusiones que podemos sacar de estos diagramas de caja esque se indentifican la presencia de outliers en distintas variables (se puede ver claramente por ejemplo en los diagramas de caja de las variables radius_se y area_worst),por lo que se probará a utilizar un estimador que elimine los outliers para comprobar si mejora los resultados de los distintos modelos.","metadata":{}},{"cell_type":"markdown","source":"## *3.2 Pima Indians diabetes*","metadata":{}},{"cell_type":"markdown","source":"### **Descripción del conjunto**\n\nTendremos que tener conocimento de:\n* Numeros de casos\n* Tipos de variables","metadata":{}},{"cell_type":"markdown","source":"Primero mostramos el número de casos y variables del conjunto de datos de entrenamiento con el metodo .shape","metadata":{}},{"cell_type":"code","source":"dataDiabetes_train.shape","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:40.137651Z","iopub.execute_input":"2021-05-28T10:37:40.138218Z","iopub.status.idle":"2021-05-28T10:37:40.143843Z","shell.execute_reply.started":"2021-05-28T10:37:40.138182Z","shell.execute_reply":"2021-05-28T10:37:40.143025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"El número de casos del conjunto de datos es 537 mientras que el número de variables es 9","metadata":{}},{"cell_type":"markdown","source":"A continuación mostramos el tipo de cada una de las variables del conjunto de datos con el método .info:","metadata":{}},{"cell_type":"code","source":"dataDiabetes_train.info(memory_usage=False)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:40.144878Z","iopub.execute_input":"2021-05-28T10:37:40.145569Z","iopub.status.idle":"2021-05-28T10:37:40.167768Z","shell.execute_reply.started":"2021-05-28T10:37:40.145245Z","shell.execute_reply":"2021-05-28T10:37:40.165952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Donde podemos observar que de las 9 variables, todas son de tipo entero excepto tres; BMI y DiabetesPedigreeFunction que son de tipo real (dato que tendremos que tener en cuenta si las modificamos en el preprocesamiento), y Outcome que es de tipo categórico y es la variable que tomaremos como variable objetivo.","metadata":{}},{"cell_type":"markdown","source":"A continuación mostramos los distitnos valores que pueden tomar nuestras variables categóricas con el método .categories:","metadata":{}},{"cell_type":"code","source":"yDiabetes.cat.categories","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:40.169228Z","iopub.execute_input":"2021-05-28T10:37:40.169659Z","iopub.status.idle":"2021-05-28T10:37:40.184512Z","shell.execute_reply.started":"2021-05-28T10:37:40.169621Z","shell.execute_reply":"2021-05-28T10:37:40.183477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Podemos observar que la variable Outcome es una variable categórica numérica que puede tomar los valores 0 o 1 en caso negativo o afirmativo de que el paciente tenga diabetes respectivamente.","metadata":{}},{"cell_type":"markdown","source":"### **Visualización de las variables**","metadata":{}},{"cell_type":"markdown","source":"Vamos a empezar realizando un histograma sobre el conjunto de datos de entrenamiento:","metadata":{}},{"cell_type":"code","source":"utils.plot_histogram(dataDiabetes_train)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:40.186041Z","iopub.execute_input":"2021-05-28T10:37:40.186708Z","iopub.status.idle":"2021-05-28T10:37:40.305557Z","shell.execute_reply.started":"2021-05-28T10:37:40.186664Z","shell.execute_reply":"2021-05-28T10:37:40.304604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Si observamos la gráficas podemos observar dos detalles importantes:\n* Lo primero es que no todas las variables tienen una distribución normal con tendencia central en forma de campana de gauss, solamente las variables SkinThickness, BMI, BloodPresure y Glucose; mientras que el resto de variables( Age, Pregnancies, Insulin y DiabetesPedigreeFunction) poseen una distribución con tendencia exponencial decreciente. De hecho en ciertas variables como DiabetesPedigreeFunction o Insulin, en sus gráficas podemos empezar a apreciar la aparición de outliers que comprobaremos más tarde con los gráficos de caja.\n* Lo segundo es que en las gráficas se puede observar como ciertas variables toman valores perdidos, es decir toman el valor 0 cuando según la lógica de los valores que pueden tomar dichas variables sería imposible que dichas variables tuvisen como valor un 0. Dichas variables son Glucose (un paciente no puede tener 0 de glucosa), BloodPresure (un paciente no puede tener 0 de presión sanguínea), SkinThickness (la piel de un paciente debe de tener grosor), Insulin (un paciente ha de tener insulina) y BMI (el índice de masa corporal de una persona no puede ser 0).","metadata":{}},{"cell_type":"markdown","source":"A continuación vamos a obtener el porcentaje de ceros que tienen estas variables con el método del fichero de utilidad ZeroCount y así comproboremos la cantida de ruido que tienen estas variables y si vale la pena tener estas variables en cuenta para el preprocesamiento:","metadata":{}},{"cell_type":"code","source":"param=[\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\"]\n\nutils.ZeroCount(dataDiabetes_train,param)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:40.306901Z","iopub.execute_input":"2021-05-28T10:37:40.307462Z","iopub.status.idle":"2021-05-28T10:37:40.317009Z","shell.execute_reply.started":"2021-05-28T10:37:40.307398Z","shell.execute_reply":"2021-05-28T10:37:40.315975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"La conclusión que podemos sacar esque el porcentaje de ruido que tienen variables como BloodPresure, Glucose o BMI es aceptable, mientras que el de las variables Insulin y SkinThickness (48.60% y 29.24% de ruido respectivamente) es tan alto que lo más recomendable esque no las tengamos en cuenta para generar nuestro modelos.","metadata":{}},{"cell_type":"markdown","source":"A continuacion vamos a realizar un diagrama de barras:","metadata":{}},{"cell_type":"code","source":"utils.plot_barplot(dataDiabetes_train)\nS,N= yDiabetes_train.value_counts()\nprint('Numero de Diabetes: ',S)\nprint('Numero de no Diabbetes: ',N)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:40.318562Z","iopub.execute_input":"2021-05-28T10:37:40.318823Z","iopub.status.idle":"2021-05-28T10:37:40.399839Z","shell.execute_reply.started":"2021-05-28T10:37:40.318797Z","shell.execute_reply":"2021-05-28T10:37:40.399125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Podemos observar que en nuestro conjunto de datos hay más casos en los que la variable objetivo Outcome indicaba que el paciente tenia diabetes (350) que en los que la variable Outcome indicaba que el paciente no tenia diabaetes (187). Al haber tanta diferencia entre el número de los casos en los que el paciente tiene o no diabetes podemos decir que el problema está desbalanceado.","metadata":{}},{"cell_type":"markdown","source":"Continuaremos con el análisis exploratorio realizando un diagrama de puntos:","metadata":{}},{"cell_type":"code","source":"utils.plot_pairplot(dataDiabetes_train, target=\"Outcome\")","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:40.400737Z","iopub.execute_input":"2021-05-28T10:37:40.400961Z","iopub.status.idle":"2021-05-28T10:37:40.48482Z","shell.execute_reply.started":"2021-05-28T10:37:40.400938Z","shell.execute_reply":"2021-05-28T10:37:40.48404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Podemos observar que hay ciertas variables muy relacionadas entre si, como Age y Pregnancies, Glucose y Age o Glucose e Insulin; por lo que quizas en procesos posteriores deberiamos eliminar alguno de los miembros de estos pares de variables. Tambíen podemos darnos cuenta de que si realizamos una discretización quizas deberíamos de realizarla con 3 contenedores, el problema, esque los datos están tan juntos que en principio no podemos definir ninguna estrategia de discretización correcta para este conjunto de datos.","metadata":{}},{"cell_type":"markdown","source":"Para comprobar algunas de las conclusiones que hemos realizado en el apartado anterior vamos a generar una matriz de correlación:","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots()\nsns.heatmap(dataDiabetes_train.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:40.485966Z","iopub.execute_input":"2021-05-28T10:37:40.486482Z","iopub.status.idle":"2021-05-28T10:37:40.861893Z","shell.execute_reply.started":"2021-05-28T10:37:40.486393Z","shell.execute_reply":"2021-05-28T10:37:40.860577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Al observar la matriz nos podemos dar cuenta de que el par de variables Glucose-Age y Glucose-Insulin están relacionados pero no lo suficiente para eliminar una de estas variables en el preproceasmiento; no obsatne, el par de variables Age-Pregnancies es el más relacionado del conjunto de datos y quizas deberiamos de eliminar una de estas variables durante el preprocesamiento.","metadata":{}},{"cell_type":"markdown","source":"Para acabar el análisis exploratorio vamos a realizar un diagrama de caja para comprobar si podrían haber outliers en las variables del conjunto de datos:","metadata":{}},{"cell_type":"code","source":"utils.plot_boxplot(dataDiabetes_train)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:40.86314Z","iopub.execute_input":"2021-05-28T10:37:40.863453Z","iopub.status.idle":"2021-05-28T10:37:40.931218Z","shell.execute_reply.started":"2021-05-28T10:37:40.863411Z","shell.execute_reply":"2021-05-28T10:37:40.930352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Las conclusiones que podemos sacar de los distintos diagramas de cajas esque en las variables se aprecian cierta cantidad de valores que están demasiado distanciados de la mediana, notándose sobre todo en los diagramas de las variables Insulin y SkinThickness, por lo que se justifica el uso de un estimador para eliminar outliers para modelar este conjunto de datos.","metadata":{}},{"cell_type":"markdown","source":"## *3.3 Titanic*","metadata":{}},{"cell_type":"markdown","source":"### **Descripción del conjunto**\n\nTendremos que tener conocimento de:\n* Numeros de casos\n* Tipos de variables","metadata":{}},{"cell_type":"markdown","source":"Primero mostramos el número de casos y variables del conjunto de datos de entrenamiento con el metodo .shape","metadata":{}},{"cell_type":"code","source":"dataTitanic_train.shape","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:40.932533Z","iopub.execute_input":"2021-05-28T10:37:40.932776Z","iopub.status.idle":"2021-05-28T10:37:40.938129Z","shell.execute_reply.started":"2021-05-28T10:37:40.932751Z","shell.execute_reply":"2021-05-28T10:37:40.937215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Podemos observar que el número de casos es 623 y el número de variables es 11.","metadata":{}},{"cell_type":"markdown","source":"A continuación mostramos el tipo de cada una de las variables del conjunto de datos con el método .info:","metadata":{}},{"cell_type":"code","source":"dataTitanic_train.info(memory_usage=False)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:40.939523Z","iopub.execute_input":"2021-05-28T10:37:40.939779Z","iopub.status.idle":"2021-05-28T10:37:40.956957Z","shell.execute_reply.started":"2021-05-28T10:37:40.939754Z","shell.execute_reply":"2021-05-28T10:37:40.955906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Si observamos el tipo de cada una de las variables podemos darnos cuenta de que 3 son de tipo entero, que 2 son de tipo real (dato que quizas deberiamos de tener en cuenta más adelante en el preprocesamiento), 1 es de tipo categórico (que será la variable que tomaremos como variable objetivo) y  5 son de tipo objeto, lo cual significará un inconveniente para la representación de datos pues no aparecerán en nuestras gráficas y también deberemos de replantearnos si estas variables objeto influirán numéricamente en la creación de nuestros modelos finales.","metadata":{}},{"cell_type":"markdown","source":"A continuación mostramos los distitnos valores que pueden tomar nuestras variables categóricas con el método .categories:","metadata":{}},{"cell_type":"code","source":"yTitanic.cat.categories","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:40.958378Z","iopub.execute_input":"2021-05-28T10:37:40.958696Z","iopub.status.idle":"2021-05-28T10:37:40.964814Z","shell.execute_reply.started":"2021-05-28T10:37:40.958668Z","shell.execute_reply":"2021-05-28T10:37:40.963807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Podemos observar que survived se trata de una variable numérica categórica que podrá tomar los valores 0 o 1 en caso negativo o afirmativo de que el pasajero sobreviviese al viaje respectivamente.","metadata":{}},{"cell_type":"markdown","source":"### **Visualización de las variables**","metadata":{}},{"cell_type":"markdown","source":"Vamos a empezar realizando un histograma sobre el conjunto de datos de entrenamiento:","metadata":{}},{"cell_type":"code","source":"utils.plot_histogram(dataTitanic_train)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:40.966013Z","iopub.execute_input":"2021-05-28T10:37:40.966394Z","iopub.status.idle":"2021-05-28T10:37:41.063784Z","shell.execute_reply.started":"2021-05-28T10:37:40.966364Z","shell.execute_reply":"2021-05-28T10:37:41.063012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Las conclusiones que podemos obtener del siguiente histograma son las siguientes:\n* A pesar de tener 11 variables, solo 5 aparecen en nuestro histograma, por lo tanto debemos de analizar porque las otras 6 no aparecen. Name, ticket y Cabin no aparecen debido a que son variables de tipo string y sus valores no se pueden representar en este tipo de gráficos, además de que consideramos que sus valores no aportan mucho a este tipo de problemas al ser variables de tipo string (y en el caso de Name y ticket también valores únicos) y por lo tanto no los tendremos en cuenta para desarrollar los estimadores para generar los modelos de esta base de datos. Sex y embarked no aparecen al ser variables categóricas no numéricas, por lo tanto para poder ser tenidas en cuenta a la hora de generar nuestros modelos primero tenemos que modificarlas para convertirlas en variables categóricas numéricas en el preprocesamiento.Finalmente Surivived no aparece al ser la variable objetivo.\n* De las variables que representadas solo Age posee un distribución normal con tendecia central en forma de campana de gauss, mientras que Pclass posee una distribución con tendencia exponencial creciente y el resto de variables (Sibsp, Parch y Fare) poseen una distribución con tendencia exponencial decreciente.\n* Al ver simplemente el histograma podemos darnos cuenta de indicios de outliers en la variable Fare,sin embargo, habrá que esperar a observar los diagramas de cajas para observar si el resto de variables poseen outliers.\n* No hemos observado que haya variables con valores no válidos durante la observación del histograma.","metadata":{}},{"cell_type":"markdown","source":"Al realizar la carga de datos y enseñar una muestra de los datos cargados, pudimos observar qeu habias ciertas variables con valores nulos (NaN) y como no hemos podido observar en el histograma que variables poseen dichos valores nulos, vamos a recurrir al método isnull().sum para que se nos muestren todas las variables con valores nulos.","metadata":{}},{"cell_type":"code","source":"dataTitanic_train.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:41.064995Z","iopub.execute_input":"2021-05-28T10:37:41.065238Z","iopub.status.idle":"2021-05-28T10:37:41.073228Z","shell.execute_reply.started":"2021-05-28T10:37:41.065214Z","shell.execute_reply":"2021-05-28T10:37:41.072222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Se nos muestra que las variables con valores nulos son Age, Embarked y Cabin. Los valores nulos de las variables Age y Embarked los arreglaremos durante el preprocesamiento ya que al ser variables categóricas no numéricas las tendremos que convertir a variables categóricas numéricas y los valores nulos asumiremos que es un error de quien haya redactado la base de datos y quería poner el valor más frecuente. Los valores de la variable Cabin son distintos, ya que al tratarse de una variable de tipo string no la ibamos a tener en cuenta ya a la hora de generar los modelos. Sin embargo vamos a recurrir al método MissignValuesCount para comprobar si el porcentaje de valores nulos (ruido) es tan grande que no deberíamos de tener en cuenta estas variables durante el preprocesamiento.","metadata":{}},{"cell_type":"code","source":"param=[\"Age\",\"Embarked\",\"Cabin\"]\nutils.MissingValuesCount(dataTitanic_train,param)\n","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:41.074509Z","iopub.execute_input":"2021-05-28T10:37:41.074756Z","iopub.status.idle":"2021-05-28T10:37:41.090174Z","shell.execute_reply.started":"2021-05-28T10:37:41.074731Z","shell.execute_reply":"2021-05-28T10:37:41.089204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"El porcentaje de valores nulos las dos variables que ya pensabamos arreglar durante el preprocesamiento (Age y Embarked) es tan inferior (menos del 20%) que las seguiremos teniendo en cuenta durante el preprocesamiento, mientras que el porcentaje de Cabin (que era una variable que no ibamos a tener en cuenta por el tipo de variable que era) es tan alto que la hubiesemos tenido que eliminar del proceso de generación de modelos aunque el tipo de la variable no hubiese sido de tipo string.","metadata":{}},{"cell_type":"markdown","source":"A continuacion vamos a realizar un diagrama de barras:","metadata":{}},{"cell_type":"code","source":"utils.plot_barplot(dataTitanic_train)\nD,S= yTitanic_train.value_counts()\nprint('Numero de supervivientes: ',S)\nprint('Numero de muertos: ',D)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:41.091779Z","iopub.execute_input":"2021-05-28T10:37:41.092055Z","iopub.status.idle":"2021-05-28T10:37:41.178215Z","shell.execute_reply.started":"2021-05-28T10:37:41.092022Z","shell.execute_reply":"2021-05-28T10:37:41.177078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Según este diagrama podemos observar que en el conjunto de datos de entrenamiento hay más casos en los que el viajero no sobrevivió (el valor de la variable Survived sería 0) que casos en los que el viajero sobrevivió (el valor de la variable Survived sería 1) por lo que podemos indicar que el problema está desbalanceado.","metadata":{}},{"cell_type":"markdown","source":"Continuaremos con el análisis exploratorio realizando un diagrama de puntos:","metadata":{}},{"cell_type":"code","source":"utils.plot_pairplot(dataTitanic_train, target=\"Survived\")","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:41.179674Z","iopub.execute_input":"2021-05-28T10:37:41.179935Z","iopub.status.idle":"2021-05-28T10:37:41.282605Z","shell.execute_reply.started":"2021-05-28T10:37:41.179909Z","shell.execute_reply":"2021-05-28T10:37:41.281534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Podemos observar que este gráfico representa las variables que antes no se nos han mostrado, y en principio no vemos ningún par de variables muy relacionados entre sí. Lo que si que vemos con más claridad esque si realizamos una discretización lo mejor será utilizar una estrategia kmeans y con 2 contenedores ya que los casos con el mismo valor en la variable objetivo survived se encuentran más agrupados y más separados de los casos con distinto valor en la variable objetivo.","metadata":{}},{"cell_type":"markdown","source":"Para comprobar algunas de las conclusiones que hemos realizado en el apartado anterior vamos a generar una matriz de correlación:","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots()\nsns.heatmap(dataTitanic_train.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:41.283749Z","iopub.execute_input":"2021-05-28T10:37:41.284002Z","iopub.status.idle":"2021-05-28T10:37:41.496296Z","shell.execute_reply.started":"2021-05-28T10:37:41.283977Z","shell.execute_reply":"2021-05-28T10:37:41.495276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Las conclusiones que podemos sacar de esta matriz esque no sólo no hay ningún par de variables muy relacionados entre sí, sino que aunque hay variables que están muy poco relacionadas entre si (con valores negativos en la matriz de correlación) tampoco hay ningún par de variables que supere el -0.5 como coecifiente de correlación. Por lo tanto podemos decir que ninguna de las variables del conjunto de datos es prescindible para realizar el posterior modelado del problema","metadata":{}},{"cell_type":"markdown","source":"Para acabar el análisis exploratorio vamos a realizar un diagrama de caja para comprobar si podrían haber outliers en las variables del conjunto de datos:","metadata":{}},{"cell_type":"code","source":"utils.plot_boxplot(dataTitanic_train)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:41.497811Z","iopub.execute_input":"2021-05-28T10:37:41.498196Z","iopub.status.idle":"2021-05-28T10:37:41.578666Z","shell.execute_reply.started":"2021-05-28T10:37:41.498156Z","shell.execute_reply":"2021-05-28T10:37:41.577717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Las conclusiones que podemos sacar de estos gráficos esque ciertas variables tienen demasiados valores alejados de la mediana, estas variables son Sex, SibSp, Parch y Fare, siendo los diagramas de Fare y SibSp donde más se notas. Por ello consideramos que está justificado el uso de un estimador que elimine los valores outliers durante el modelado del problema.","metadata":{}},{"cell_type":"code","source":"def _filter_categorical_data(data):\n    \"\"\"Filter the categorical data.\"\"\"\n    return data.select_dtypes(include=\"category\")\n\ndef _plot_barplot(data, var):\n    \"\"\"Plot univariate distribution of the categorical variable.\"\"\"\n    # Count the relative frequency of unique values\n    count = data[var].value_counts(normalize=True)\n\n    return count.iplot(kind=\"bar\")\n\ndef Pruebaplot_barplot(data):\n    \"\"\"Plot univariate distribution of the categorical data.\"\"\"\n    #categorical_data = _filter_categorical_data(data)\n\n    # Add a dropdown widget to select\n    # the categorical feature to plot\n    var = data.columns\n    data = widgets.fixed(data)\n\n    widgets.interact(_plot_barplot, data=data, var=var)\n","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:41.579781Z","iopub.execute_input":"2021-05-28T10:37:41.580038Z","iopub.status.idle":"2021-05-28T10:37:41.586453Z","shell.execute_reply.started":"2021-05-28T10:37:41.580013Z","shell.execute_reply":"2021-05-28T10:37:41.585278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Prueba\n#Sex Farea\nNotcat = dataTitanic_train.iloc[:,[3,7,10]]\n#Pclass Sex Sibsp Parch\nCat = dataTitanic_train.iloc[:,[0,2,4,5,7,10]]\nPruebaplot_barplot(Cat)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:41.587756Z","iopub.execute_input":"2021-05-28T10:37:41.588034Z","iopub.status.idle":"2021-05-28T10:37:41.664547Z","shell.execute_reply.started":"2021-05-28T10:37:41.588009Z","shell.execute_reply":"2021-05-28T10:37:41.663716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Preprocesamiento de datos","metadata":{}},{"cell_type":"markdown","source":"En esta parte aplicaremos el preprocesamiento en base a las modificaciones que hemos visto que necesita el conjunto de datos durante el análisis exploratorio.","metadata":{}},{"cell_type":"markdown","source":"Empezamos el preprocesamiento definiendo el estimador que hara uso de la función outlier_rejection del fichero de utilidad utils para eliminar outliers. Este estimador se utilizará posteriormente en la generación de modelos aplicandosé al conjunto de datos.","metadata":{}},{"cell_type":"code","source":"#Estimador para eliminar outliers\nOutlierRejection = FunctionSampler(func=utils.outlier_rejection, kw_args={\"seed\":seed})","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:41.665742Z","iopub.execute_input":"2021-05-28T10:37:41.66601Z","iopub.status.idle":"2021-05-28T10:37:41.669847Z","shell.execute_reply.started":"2021-05-28T10:37:41.665983Z","shell.execute_reply":"2021-05-28T10:37:41.669094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## *4.1 Breast cancer Winsconsin*","metadata":{}},{"cell_type":"markdown","source":"Como hemos concluido en el análisis exploratorio, de los dos conjuntos de variables perimeter_mean-area_mean-radio mean y concavepoints_mean-compactness_mean-concavity_mean están muy relacionadas las variables dentro del conjunto y un conjunto de variables con el otro, por lo tanto para el preprocesamiento, vamos a generar un estimador que elimine todos los tipos (mean,se y worst) de dos variables de cada uno de los conjuntos de variables del conjunto de datos, para ello hemos elegido arbitrariamente que las variables que eliminaremos del primer conjunto de datos serán area y perimeter y del segundo serán concave y compactness.\nPara la generación del estimador vamos a utilizar el método make_column_transformer de la libreria sklearn.compose y vamos a indicar como parámetro tranformador 'drop' para que elimine la lista de variables de las que hemos hablado con anterior y hemos indicado que para el resto de variables simplemente no las toque igualando el parámetro remainder como 'passthrough'.","metadata":{}},{"cell_type":"code","source":"preproceserWinsconsin = make_column_transformer(('drop',['perimeter_mean','area_mean','perimeter_se','area_se','perimeter_worst','area_worst','concave points_mean','compactness_mean',\n          'concave points_se','compactness_se','concave points_worst','compactness_worst']),\n                                                remainder='passthrough')\n","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:41.67117Z","iopub.execute_input":"2021-05-28T10:37:41.671537Z","iopub.status.idle":"2021-05-28T10:37:41.683416Z","shell.execute_reply.started":"2021-05-28T10:37:41.671504Z","shell.execute_reply":"2021-05-28T10:37:41.682449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Como dato aclaratorio, también podriamos haber generado el estimador utilizando el transformador 'passthrough' y seleccionado todas las variables con las que nos queremos quedar sin igualar el parámetro remainder a passthrough, pues esto hará que las variables que no le especifiquemos las borrará del conjunto de datos; básicamente es hacer el proceso que hemos hecho con el estimador al revés.","metadata":{}},{"cell_type":"markdown","source":"## *4.2 Pima Indians diabetes*","metadata":{}},{"cell_type":"markdown","source":"Como hemos indicado en el preprocesamiento de esta base de datos lo que tendremos que hacer será sustituir los valores cero de las variables Glucose, BloodPressure y BMI, eliminar una variable del par de variables Age y Pregnancies por su alto coeficiente de correlación, eliminación de las variables Insulin y SkinThickness por la cantidad de valores perdidos que tienen y dejar el resto de variables igual.\n\nPara la sustitución de valores cero de las variables Glucose, BloodPressure y BMI utilizaremos el estimador SimpleImputer pero teniendo en cuenta que BMI se trata de una variable real y que las otras dos se tratan de variables enteras, tendremos que generar un estimador para cada tipo de variable modificando la estrategia de búsqueda, pues aunque lo normal es utilizar la media para la sustitución de valores ruidosos, al ser Glucose y BloodPresure enteros, no se puede introducir de repente un valor con decimales (la media podría tener o no decimales) por ello el simpleImputer que afectará a las variables enteras utilizará la estrategia \"most_frequent\" sustituyendo los ceros por el valor más frequente que claramente será de tipo entero y sin decimales. Ambos SimpleImputer (de enteros y decimales) los \"combinaremos\" con un método make_column_transformer donde le pasaremos a cada estimador las variables correspondientes asignándolas al parámetro pattern del make_column_selector. Para dejar al resto de variables igual simplemente declararemos las variables que no se deben de tocar en un parámetro aparte y se introducirán en el make_column_transformer pero en vez de pasarle un estimador como parámetro introduciremos el valor 'passthrough' que simplemente dejará igual a las variables. Finalmente si queremos eliminar las variables que hemos acordado en el análisis exploratorio bastará con no incluirlas en el make_colum_transformer.","metadata":{}},{"cell_type":"code","source":"#Variables para sustituir ceros\nfeatures1 = 'Glucose|BloodPressure'\nfeatures2 = 'BMI'\n#Variables que no hay que tocar\nfeatures3 = 'DiabetesPedigreeFunction|Age'\n\n#Estimador para integuers\nreplace0Integer_Estimator = make_pipeline(SimpleImputer(strategy=\"most_frequent\",missing_values=0 ))\n#Estimador para reales\nreplace0Float_Estimator = make_pipeline(SimpleImputer(strategy=\"mean\",missing_values=0 ))\n\npreproceserDiabetes = make_column_transformer(\n    (replace0Integer_Estimator, make_column_selector(pattern= features1)),\n    (replace0Float_Estimator, make_column_selector(pattern= features2)),\n     ('passthrough', make_column_selector(pattern= features3)))\n\n","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:41.684351Z","iopub.execute_input":"2021-05-28T10:37:41.684786Z","iopub.status.idle":"2021-05-28T10:37:41.696139Z","shell.execute_reply.started":"2021-05-28T10:37:41.684758Z","shell.execute_reply":"2021-05-28T10:37:41.695184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## *4.3 Titanic*","metadata":{}},{"cell_type":"markdown","source":"El preprocesamineto del conjunto de datos de la base de datos Titanic es algo complicado por ello vamos a dividir la explicación en tres distintas partes:\n* Primero, tenemos que tratar las variables que hemos detectado que son categóricas puras y que también tienen valores nulos durante el análisis exploratorio, dichas variables son Sex y Embarked. Para ello crearemos un pipeline con dos estimadores, uno primero que será SimpleImputer que sustituirá los valores perdidos (NaN) usando la estrategia 'most_frequent' (que es la recomendable para variables categóricas puras) y otro OneHotEncoder que conviertirá las variables categóricas puras en categóricas numéricas.\n* Después tenemos que tratar las variables categóricas numéricas y las que contienen valores perdidos (NaN), que serán las variables Age, SibSp, Parch, Fare y Pclass. Para ello crearemos un pipeline con dos estimadores, uno primero que será SimpleImputer que sustituirá los valores perdidos (NaN) usando la estrategia 'median' que sustituirá los valores perdidos por la mediana de los valores de la variable (esto es así porque dentro de las variables tenemos una mezcla de variables enteras y reales y debido a esta mezcla no podemos recurrir ni a la media ni a la moda, 'most frequent', entonces recurriremos a la mediana) y el otro estimador será un StandarScaler que intentará estandarizar las características.\n* Finalmente estos dos estimadores los juntaremos en un método_make_column_tranformer donde introduciremos las dos pipelines generadas con sus corresponientes conjuntos de variables, y para eliminar las variables que hemos acordado eliminar del conjunto de datos durante el análisis exploratorio (Name, Ticket y Cabin) simplemente no las introduciremos en ninguno de los dos conjuntos de variables.","metadata":{}},{"cell_type":"code","source":"#Primer pipeline categoricos: Imputas y encoder\n#Segundo pipeline para numerico categoricos si hay valores perdidos media\n#Las variables que no aportan al modelo directamente no se meten\n\n#Variables categoricas y con valores perdidos\nfeaturesCat='Sex| Embarked'\n#Variables numerico categoricos y variables con valores peridos\nfeaturesR0 = 'Age|SibSp|Parch|Fare|Pclass'\n\n\n\n#Pipeline para las variables categóricas puras que se encargara de imputar los valores nulos y realizar un encoder\nCat_Estimator = make_pipeline(SimpleImputer(strategy='most_frequent'),\n                                    OneHotEncoder(handle_unknown='ignore'))\n\n#Pipeline para numéricos y numéricos categóricos que se encarga de eliminar los valores nulos\nNum_Estimator = make_pipeline(SimpleImputer(strategy='median'), StandardScaler())\n\n\npreproceserTitanic = make_column_transformer(\n    (Cat_Estimator, make_column_selector(pattern=featuresCat)),\n    (Num_Estimator, make_column_selector(pattern=featuresR0))\n    \n)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:41.697221Z","iopub.execute_input":"2021-05-28T10:37:41.697728Z","iopub.status.idle":"2021-05-28T10:37:41.712877Z","shell.execute_reply.started":"2021-05-28T10:37:41.697698Z","shell.execute_reply":"2021-05-28T10:37:41.712086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Algoritmos de clasificación","metadata":{}},{"cell_type":"markdown","source":"En esta parte generaremos los modelos que vamos a evaluar y las pipelines que saldrán como resultado de aplicar a dichos modelos los estimadores que hemos creado en el apartado anterior (que también evaluaremos posteriormente).","metadata":{}},{"cell_type":"markdown","source":"Los modelos que evaluaremos serán el modelo zero_r y el modelo de arbol de decision que usará la semilla que estamos durante todo el problema.","metadata":{}},{"cell_type":"code","source":"#Generación del modelo zero_r\nzero_r_model = DummyClassifier(strategy=\"most_frequent\")\n#Generación del modelo de árbol de decision\ntree_model = DecisionTreeClassifier(random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:41.713856Z","iopub.execute_input":"2021-05-28T10:37:41.714232Z","iopub.status.idle":"2021-05-28T10:37:41.732013Z","shell.execute_reply.started":"2021-05-28T10:37:41.714205Z","shell.execute_reply":"2021-05-28T10:37:41.730935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## *5.1 Breast cancer Winsconsin*","metadata":{}},{"cell_type":"markdown","source":"Para empezar generamos los distintos discretizadores que aplicaremos al modelo de árbol de decisión. Como hemos mencionado en el análisis exploratorio utilizaremos 2 contenedores y probaremos todas las estrategias al no tener claro del todo cual hay que utilizar.","metadata":{}},{"cell_type":"code","source":"discretizerUWinsconsin = KBinsDiscretizer(n_bins=2, strategy=\"uniform\")\ndiscretizerQWinsconsin = KBinsDiscretizer(n_bins=2, strategy=\"quantile\")\ndiscretizerKWinsconsin = KBinsDiscretizer(n_bins=2, strategy=\"kmeans\")\n","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:41.733636Z","iopub.execute_input":"2021-05-28T10:37:41.734116Z","iopub.status.idle":"2021-05-28T10:37:41.744973Z","shell.execute_reply.started":"2021-05-28T10:37:41.734085Z","shell.execute_reply":"2021-05-28T10:37:41.743907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A continuación le aplicaremos al modelo de árbol de decisión el estimador con el preprocesamiento que hemos desarrolado en el apartado anterior. No se lo aplicamos al modelo zeroR porque no le afectaria. Tambien le aplicamos el estimador al árbol de decisión discretizado con 2 contenedores y todas las posibles estrategias de discretización.","metadata":{}},{"cell_type":"code","source":"\n#Modelo de árbol de decisón con eliminación de variables predictoras muy relacionadas\npreprocess_treemodel_Winsconsin=make_pipeline(preproceserWinsconsin, tree_model)\n\n#Modelo de árbol de decisión con tres tipos de discretizaciones y con eliminación\n# de variable predictoras muy relacionadas\npreprocess_treemodel_discretizeU_Winsconsin=make_pipeline(preproceserWinsconsin,discretizerUWinsconsin,tree_model)\npreprocess_treemodel_discretizeQ_Winsconsin=make_pipeline(preproceserWinsconsin,discretizerQWinsconsin,tree_model)\npreprocess_treemodel_discretizeK_Winsconsin=make_pipeline(preproceserWinsconsin,discretizerKWinsconsin,tree_model)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:41.746078Z","iopub.execute_input":"2021-05-28T10:37:41.746519Z","iopub.status.idle":"2021-05-28T10:37:41.763614Z","shell.execute_reply.started":"2021-05-28T10:37:41.746487Z","shell.execute_reply":"2021-05-28T10:37:41.762368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finalmente hemos generado cuatro pipelines extra, que son las mismas cuatro pipelines anteriores pero añadiéndoles un estimador que elimina outliers. Este estimador lo hemos añadido en cuatro pipelines extra aparte en vez de integrarlo todo junto porque sabemos que el proceso de eliminación de outliers puede generar sobreajuste y empeorar los resultados de la evaluación; por lo tanto vamos a evaluar tanto las pipelines sin eliminación de outliers como las que si que lo hacen y comparar los resultados obtenidos en el siguiente apartado.","metadata":{}},{"cell_type":"code","source":"\n#Modelo de árbol de decisón con eliminación de variables predictoras muy relacionadas \n#eliminación de outliers\nextra_preprocess_treemodel_Winsconsin=make_pipeline(OutlierRejection, preproceserWinsconsin, tree_model)\n\n#Modelo de árbol de decisión con tres tipos de discretizaciones y con eliminación\n# de variable predictoras muy relacionadas y eliminación de outliers\nextra_preprocess_treemodel_discretizeU_Winsconsin=make_pipeline(preproceserWinsconsin,OutlierRejection,discretizerUWinsconsin,tree_model)\nextra_preprocess_treemodel_discretizeQ_Winsconsin=make_pipeline(preproceserWinsconsin,OutlierRejection,discretizerQWinsconsin,tree_model)\nextra_preprocess_treemodel_discretizeK_Winsconsin=make_pipeline(preproceserWinsconsin,OutlierRejection,discretizerKWinsconsin,tree_model)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:41.765024Z","iopub.execute_input":"2021-05-28T10:37:41.765415Z","iopub.status.idle":"2021-05-28T10:37:41.777196Z","shell.execute_reply.started":"2021-05-28T10:37:41.765367Z","shell.execute_reply":"2021-05-28T10:37:41.776522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## *5.2 Pima Indians diabetes*","metadata":{}},{"cell_type":"markdown","source":"Para empezar generamos los distintos discretizadores que aplicaremos al modelo de árbol de decisión. Como hemos mencionado en el análisis exploratorio utilizaremos 3 contenedores y probaremos todas las estrategias al no tener claro del todo cual hay que utilizar","metadata":{}},{"cell_type":"code","source":"discretizerUDiabetes = KBinsDiscretizer(n_bins=3, strategy=\"uniform\")\ndiscretizerQDiabetes = KBinsDiscretizer(n_bins=3, strategy=\"quantile\")\ndiscretizerKDiabetes = KBinsDiscretizer(n_bins=3, strategy=\"kmeans\")","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:41.778575Z","iopub.execute_input":"2021-05-28T10:37:41.778965Z","iopub.status.idle":"2021-05-28T10:37:41.792612Z","shell.execute_reply.started":"2021-05-28T10:37:41.77893Z","shell.execute_reply":"2021-05-28T10:37:41.791542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A continuación le aplicaremos al modelo de árbol de decisión el estimador con el preprocesamiento que hemos desarrolado en el apartado anterior. No se lo aplicamos al modelo zeroR porque no le afectaria. Tambien le aplicamos el estimador al árbol de decisión discretizado con 3 contenedores y todas las posibles estrategias de discretización.","metadata":{}},{"cell_type":"code","source":"#Modelo de árbol de decisión con sustitución de ceros\npreprocess_treemodel_Diabetes=make_pipeline(preproceserDiabetes, tree_model)\n\n#Modelo de árbol de decisión con tres tipos de discretizaciones y sustitución de ceros\npreprocess_treemodel_discretizeU_Diabetes=make_pipeline(preproceserDiabetes,discretizerUDiabetes,tree_model)\npreprocess_treemodel_discretizeQ_Diabetes=make_pipeline(preproceserDiabetes,discretizerQDiabetes,tree_model)\npreprocess_treemodel_discretizeK_Diabetes=make_pipeline(preproceserDiabetes,discretizerKDiabetes,tree_model)\n","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:41.793756Z","iopub.execute_input":"2021-05-28T10:37:41.794235Z","iopub.status.idle":"2021-05-28T10:37:41.805701Z","shell.execute_reply.started":"2021-05-28T10:37:41.7942Z","shell.execute_reply":"2021-05-28T10:37:41.80474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finalmente hemos generado cuatro pipelines extra, que son las mismas cuatro pipelines anteriores pero añadiéndoles un estimador que elimina outliers. Este estimador lo hemos añadido en cuatro pipelines extra aparte en vez de integrarlo todo junto porque sabemos que el proceso de eliminación de outliers puede generar sobreajuste y empeorar los resultados de la evaluación; por lo tanto vamos a evaluar tanto las pipelines sin eliminación de outliers como las que si que lo hacen y comparar los resultados obtenidos en el siguiente apartado.","metadata":{}},{"cell_type":"code","source":"\n#Modelo de árbol de decisión con sustitución de ceros y eliminación de outliers\nextra_preprocess_treemodel_Diabetes=make_pipeline(preproceserDiabetes,OutlierRejection, tree_model)\n\n#Modelo de árbol de decisión con tres tipos de discretizaciones, sustitución de ceros y eliminación de outliers\nextra_preprocess_treemodel_discretizeU_Diabetes=make_pipeline(preproceserDiabetes,OutlierRejection,discretizerUDiabetes,tree_model)\nextra_preprocess_treemodel_discretizeQ_Diabetes=make_pipeline(preproceserDiabetes,OutlierRejection,discretizerQDiabetes,tree_model)\nextra_preprocess_treemodel_discretizeK_Diabetes=make_pipeline(preproceserDiabetes,OutlierRejection,discretizerKDiabetes,tree_model)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:41.807128Z","iopub.execute_input":"2021-05-28T10:37:41.807725Z","iopub.status.idle":"2021-05-28T10:37:41.8233Z","shell.execute_reply.started":"2021-05-28T10:37:41.80769Z","shell.execute_reply":"2021-05-28T10:37:41.822413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## *5.3 Titanic*","metadata":{}},{"cell_type":"markdown","source":"Para empezar generamos los distintos discretizadores que aplicaremos al modelo de árbol de decisión. Como hemos mencionado en el análisis exploratorio utilizaremos 2 contenedores y probaremos todas las estrategias al no tener claro del todo cual hay que utilizar","metadata":{}},{"cell_type":"code","source":"discretizerUTitanic = KBinsDiscretizer(n_bins=2, strategy=\"uniform\")\ndiscretizerQTitanic = KBinsDiscretizer(n_bins=2, strategy=\"quantile\")\ndiscretizerKTitanic = KBinsDiscretizer(n_bins=2, strategy=\"kmeans\")","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:41.824367Z","iopub.execute_input":"2021-05-28T10:37:41.824801Z","iopub.status.idle":"2021-05-28T10:37:41.837511Z","shell.execute_reply.started":"2021-05-28T10:37:41.824771Z","shell.execute_reply":"2021-05-28T10:37:41.836502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A continuación le aplicaremos al modelo de árbol de decisión el estimador con el preprocesamiento que hemos desarrolado en el apartado anterior. No se lo aplicamos al modelo zeroR porque no le afectaria. Tambien le aplicamos el estimador al árbol de decisión discretizado con 3 contenedores y todas las posibles estrategias de discretización.","metadata":{}},{"cell_type":"code","source":"#El preprocesamiento al que nos referiremos a continuación consistará de dos partes, una en la eliminación conversión de \n#categóricas y la sustitución de sus valores anómalos por un 0 y la otra en la sutitución de los valores anómalos del resto\n#de variables y la estandarización de estas variables\n\n#Modelo de árbol de decisión con preprocesamiento\npreprocess_treemodel_Titanic = make_pipeline(preproceserTitanic, tree_model)\n\n#Modelo de árbol de decisión con preprocesamiento y con tres tipos de discretizaciones\npreprocess_treemodel_discretizeU_Titanic=make_pipeline(preproceserTitanic,discretizerUTitanic,tree_model)\npreprocess_treemodel_discretizeQ_Titanic=make_pipeline(preproceserTitanic,discretizerQTitanic,tree_model)\npreprocess_treemodel_discretizeK_Titanic=make_pipeline(preproceserTitanic,discretizerKTitanic,tree_model)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:41.838557Z","iopub.execute_input":"2021-05-28T10:37:41.83899Z","iopub.status.idle":"2021-05-28T10:37:41.853761Z","shell.execute_reply.started":"2021-05-28T10:37:41.838959Z","shell.execute_reply":"2021-05-28T10:37:41.852595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finalmente hemos generado cuatro pipelines extra, que son las mismas cuatro pipelines anteriores pero añadiéndoles un estimador que elimina outliers. Este estimador lo hemos añadido en cuatro pipelines extra aparte en vez de integrarlo todo junto porque sabemos que el proceso de eliminación de outliers puede generar sobreajuste y empeorar los resultados de la evaluación; por lo tanto vamos a evaluar tanto las pipelines sin eliminación de outliers como las que si que lo hacen y comparar los resultados obtenidos en el siguiente apartado.","metadata":{}},{"cell_type":"code","source":"\n#Modelo de árbol de decisión con preprocesamiento y eliminaciónde outliers\nextra_preprocess_treemodel_Titanic=make_pipeline(preproceserTitanic,OutlierRejection, tree_model)\n\n#Modelo de árbol de decisión con preprocesamiento, con tres tipos de discretizaciones \n#y eliminación de outliers\nextra_preprocess_treemodel_discretizeU_Titanic=make_pipeline(preproceserTitanic,OutlierRejection,discretizerUDiabetes,tree_model)\nextra_preprocess_treemodel_discretizeQ_Titanic=make_pipeline(preproceserTitanic,OutlierRejection,discretizerQDiabetes,tree_model)\nextra_preprocess_treemodel_discretizeK_Titanic=make_pipeline(preproceserTitanic,OutlierRejection,discretizerKDiabetes,tree_model)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:41.8555Z","iopub.execute_input":"2021-05-28T10:37:41.856236Z","iopub.status.idle":"2021-05-28T10:37:41.871215Z","shell.execute_reply.started":"2021-05-28T10:37:41.856187Z","shell.execute_reply":"2021-05-28T10:37:41.870144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. Evaluacion de modelos","metadata":{}},{"cell_type":"markdown","source":"El proceso de evaluación de modelos lo realizaremos siguiendo los siguientes paso para cada uno de los subapartados siguientes (uno para cada uno de las bases de datos que hemos tratado):\n1. Mencion de la métrica que utilizaremos para elegir el mejor modelo de los evaluados en base a la base de datos que utilizaremos\n2. Mostrar el resultado de la evaluación sobre el conjunto de datos corresponiente de los dos modelos sin inclusión de estimadores extra ,el resultado de la evaluación sobre el conjunto de datos correspondiente de las 4 pipelines resultado de aplicarle al árbol de decisión la discretización y el preprocesamiento y el resultado de la evaluación sobre el conjunto de datos correspondiente de 4 pipelines resultado de añadirle a las cuatro pipelines anteriores un estimador de eliminación de outliers. La evalución se realizará utilizando la función del fichero de utilidad utils EvaluationWClassRepo\n3. Redacción de una pequeña conclusión que haga referencia al mejor resultado obtenido y las consecuencias supone dicho resultado.","metadata":{}},{"cell_type":"markdown","source":"## *6.1 Breast cancer Winsconsin*","metadata":{}},{"cell_type":"markdown","source":"Teniendo en cuenta que la base de datos Breast cancer winsconsin surge de un problema médico y por ello, la métrica normalmente utilizada para estos problemas y la que tenemos que emplear para la evaluación es el recall o tasa de verdaderos positivos. Dicha tasa la podemos ver en la estructura classsification report que generará el método EvalutationWClassRepo. \nFinalmente, al utilizarse la base de datos para predecir el resultado del análisis de una masa mamaria, consideraremos que dicho análisis da positivo si el diagnóstico es maligno,es decir; la tasa de veraderos positivos se observará teniendo en cuenta que un positivo quiere decir que la masa mamaria es maligna.","metadata":{}},{"cell_type":"markdown","source":"> ### *Modelos sin preprocesamiento*","metadata":{}},{"cell_type":"code","source":"utils.EvaluationWClassRepo(zero_r_model,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:41.872582Z","iopub.execute_input":"2021-05-28T10:37:41.873417Z","iopub.status.idle":"2021-05-28T10:37:42.034686Z","shell.execute_reply.started":"2021-05-28T10:37:41.873359Z","shell.execute_reply":"2021-05-28T10:37:42.033576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"utils.EvaluationWClassRepo(tree_model,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:42.036163Z","iopub.execute_input":"2021-05-28T10:37:42.036571Z","iopub.status.idle":"2021-05-28T10:37:42.192534Z","shell.execute_reply.started":"2021-05-28T10:37:42.036527Z","shell.execute_reply":"2021-05-28T10:37:42.191493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ### *Modelos con el preprocesamiento desarrollado anteriormente*","metadata":{}},{"cell_type":"code","source":"utils.EvaluationWClassRepo(preprocess_treemodel_Winsconsin,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:42.194033Z","iopub.execute_input":"2021-05-28T10:37:42.194412Z","iopub.status.idle":"2021-05-28T10:37:42.350258Z","shell.execute_reply.started":"2021-05-28T10:37:42.194372Z","shell.execute_reply":"2021-05-28T10:37:42.349452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"utils.EvaluationWClassRepo(preprocess_treemodel_discretizeU_Winsconsin,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:42.351464Z","iopub.execute_input":"2021-05-28T10:37:42.351721Z","iopub.status.idle":"2021-05-28T10:37:42.560272Z","shell.execute_reply.started":"2021-05-28T10:37:42.351695Z","shell.execute_reply":"2021-05-28T10:37:42.559482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"utils.EvaluationWClassRepo(preprocess_treemodel_discretizeQ_Winsconsin,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:42.561684Z","iopub.execute_input":"2021-05-28T10:37:42.561956Z","iopub.status.idle":"2021-05-28T10:37:42.743248Z","shell.execute_reply.started":"2021-05-28T10:37:42.561926Z","shell.execute_reply":"2021-05-28T10:37:42.742187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"utils.EvaluationWClassRepo(preprocess_treemodel_discretizeK_Winsconsin,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)\n","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:42.744418Z","iopub.execute_input":"2021-05-28T10:37:42.744758Z","iopub.status.idle":"2021-05-28T10:37:42.967708Z","shell.execute_reply.started":"2021-05-28T10:37:42.7447Z","shell.execute_reply":"2021-05-28T10:37:42.966945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ### *Modelos con el preprocesamiento extra*","metadata":{}},{"cell_type":"code","source":"EvaluationWClassRepo(extra_preprocess_treemodel_Winsconsin,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:42.968994Z","iopub.execute_input":"2021-05-28T10:37:42.969497Z","iopub.status.idle":"2021-05-28T10:37:43.323997Z","shell.execute_reply.started":"2021-05-28T10:37:42.969456Z","shell.execute_reply":"2021-05-28T10:37:43.322952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"utils.EvaluationWClassRepo(extra_preprocess_treemodel_discretizeU_Winsconsin,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:43.32541Z","iopub.execute_input":"2021-05-28T10:37:43.325807Z","iopub.status.idle":"2021-05-28T10:37:43.678984Z","shell.execute_reply.started":"2021-05-28T10:37:43.325765Z","shell.execute_reply":"2021-05-28T10:37:43.678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"utils.EvaluationWClassRepo(extra_preprocess_treemodel_discretizeQ_Winsconsin,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:43.680054Z","iopub.execute_input":"2021-05-28T10:37:43.680297Z","iopub.status.idle":"2021-05-28T10:37:44.045439Z","shell.execute_reply.started":"2021-05-28T10:37:43.680272Z","shell.execute_reply":"2021-05-28T10:37:44.044383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"utils.EvaluationWClassRepo(extra_preprocess_treemodel_discretizeK_Winsconsin,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:44.046545Z","iopub.execute_input":"2021-05-28T10:37:44.046834Z","iopub.status.idle":"2021-05-28T10:37:44.469228Z","shell.execute_reply.started":"2021-05-28T10:37:44.046805Z","shell.execute_reply":"2021-05-28T10:37:44.468309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ### *Conclusiones*","metadata":{}},{"cell_type":"markdown","source":"Las conclusiones que hemos obtenido tras analizar los resultados de la evaluación de modelos son las siguientes:\n* Los dos mejores modelos son el modelo del árbol de decisión con el preprocesamiento básico y sin discretizar y el modelo del árbol de decisión con el preprocesamiento básico y con una discretización de igual frecuencia. Ambos tienen una tasa de verdaderos positivos del 0.94.\n* Si tenemos en cuenta la tasa de verdaderos positivos media (La media de la tasa de verdaderos positivos para positivo benigneo y positivo maligno) el mejor modelo sería el árbol de decisión con el preprocesamiento básico y sin discretizar con un tasa de verdaderos positivos media del 0.94.\n* En general hemos obtenido una tasa de verdaderos positivos alta para todos nuestros modelos (el más bajo sin contar el modelo ZeroR ha sido 0.64).\n* La eliminación de outliers solo ha sobreajustado el modelo para este conjunto de datos ya que todos los modelos que han eliminado outliers han tenido peores resultados que su contraparte sin eliminación de outliers.\n* La mejor discretización para el modelo de árboles de decisión es la de igual frecuencia, eliminado o no outliers.","metadata":{}},{"cell_type":"markdown","source":"## *6.2 Pima Indians diabetes*","metadata":{}},{"cell_type":"markdown","source":"Teniendo en cuenta que la base de datos Pima Indians diabetes surge de un problema médico y por ello, la métrica normalmente utilizada para estos problemas y la que tenemos que emplear para la evaluación es el recall o tasa de verdaderos positivos. Dicha tasa la podemos ver en la estructura classsification report que generará el método EvalutationWClassRepo. Finalmente, al utilizarse la base de datos para predecir de forma diagnóstica si un paciente tiene diabete o no, consideraremos que dicho análisis da positivo si la variable objetivo Outcome tiene el valor 1, es decir; la tasa de verdaderos positivos se observará teniendo en cuenta que un positivo quiere decir que el paciente tiene diabetes.","metadata":{}},{"cell_type":"markdown","source":"> ### *Modelos sin preprocesamiento*","metadata":{}},{"cell_type":"code","source":"utils.EvaluationWClassRepo(zero_r_model,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:44.47235Z","iopub.execute_input":"2021-05-28T10:37:44.47265Z","iopub.status.idle":"2021-05-28T10:37:44.623691Z","shell.execute_reply.started":"2021-05-28T10:37:44.472621Z","shell.execute_reply":"2021-05-28T10:37:44.622677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"utils.EvaluationWClassRepo(tree_model,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:44.625035Z","iopub.execute_input":"2021-05-28T10:37:44.625366Z","iopub.status.idle":"2021-05-28T10:37:44.779334Z","shell.execute_reply.started":"2021-05-28T10:37:44.625334Z","shell.execute_reply":"2021-05-28T10:37:44.778359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ### *Modelos con el preprocesamiento desarrollado anteriormente*","metadata":{}},{"cell_type":"code","source":"utils.EvaluationWClassRepo(preprocess_treemodel_Diabetes,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:44.781582Z","iopub.execute_input":"2021-05-28T10:37:44.781844Z","iopub.status.idle":"2021-05-28T10:37:44.956037Z","shell.execute_reply.started":"2021-05-28T10:37:44.781818Z","shell.execute_reply":"2021-05-28T10:37:44.955105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"utils.EvaluationWClassRepo(preprocess_treemodel_discretizeU_Diabetes,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:44.957157Z","iopub.execute_input":"2021-05-28T10:37:44.957403Z","iopub.status.idle":"2021-05-28T10:37:45.338722Z","shell.execute_reply.started":"2021-05-28T10:37:44.957378Z","shell.execute_reply":"2021-05-28T10:37:45.337639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"utils.EvaluationWClassRepo(preprocess_treemodel_discretizeQ_Diabetes,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:45.341857Z","iopub.execute_input":"2021-05-28T10:37:45.342165Z","iopub.status.idle":"2021-05-28T10:37:45.52545Z","shell.execute_reply.started":"2021-05-28T10:37:45.342135Z","shell.execute_reply":"2021-05-28T10:37:45.524404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"utils.EvaluationWClassRepo(preprocess_treemodel_discretizeK_Diabetes,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:45.526708Z","iopub.execute_input":"2021-05-28T10:37:45.526977Z","iopub.status.idle":"2021-05-28T10:37:45.789696Z","shell.execute_reply.started":"2021-05-28T10:37:45.526949Z","shell.execute_reply":"2021-05-28T10:37:45.788962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ### *Modelos con el preprocesamiento extra*","metadata":{}},{"cell_type":"code","source":"utils.EvaluationWClassRepo(extra_preprocess_treemodel_Diabetes,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:45.790815Z","iopub.execute_input":"2021-05-28T10:37:45.791235Z","iopub.status.idle":"2021-05-28T10:37:46.19231Z","shell.execute_reply.started":"2021-05-28T10:37:45.791206Z","shell.execute_reply":"2021-05-28T10:37:46.191365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"utils.EvaluationWClassRepo(extra_preprocess_treemodel_discretizeU_Diabetes,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:46.193558Z","iopub.execute_input":"2021-05-28T10:37:46.193951Z","iopub.status.idle":"2021-05-28T10:37:46.570885Z","shell.execute_reply.started":"2021-05-28T10:37:46.193922Z","shell.execute_reply":"2021-05-28T10:37:46.569918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"utils.EvaluationWClassRepo(extra_preprocess_treemodel_discretizeQ_Diabetes,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:46.57204Z","iopub.execute_input":"2021-05-28T10:37:46.572302Z","iopub.status.idle":"2021-05-28T10:37:46.944676Z","shell.execute_reply.started":"2021-05-28T10:37:46.572273Z","shell.execute_reply":"2021-05-28T10:37:46.943692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"utils.EvaluationWClassRepo(extra_preprocess_treemodel_discretizeK_Diabetes,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:46.946445Z","iopub.execute_input":"2021-05-28T10:37:46.946831Z","iopub.status.idle":"2021-05-28T10:37:47.344413Z","shell.execute_reply.started":"2021-05-28T10:37:46.94679Z","shell.execute_reply":"2021-05-28T10:37:47.343464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ### *Conclusiones*","metadata":{}},{"cell_type":"markdown","source":"Las conclusiones que hemos obtenido tras analizar los resultados de la evaluación de modelos son las siguientes:\n* El mejor modelo que hemos obtenido ha sido el modelo del árbol de decisión sin discretización y con el preprocesamiento básico con una tasa de verdaderos positivos de 0.60.\n* En general la tasa de veraderos positivos que hemos obtenidos de todos los modelos es bastante baja, siendo la más alta 0.6.\n* La eliminación de outliers ha sobreajustado casi todos los modelos dando en la mayoría peores resultados para la tasa de verdaderos positivos, expecto para el modelo  de árbol de decisión con discretización basado en K medians cuya tasas de verdaderos positivos es 0.52 cuando se eliminan outliers y 0.43 sin la eliminación de outliers.\n* En el caso de la discretización, lo más recomendable es no realizar una discretización a este conjunto de datos si usamos como modelo un árbol de decisión, sin embargo la discretización que mejores resultados ha dado sin eliminación de outliers es la de igual frecuencia (con una tasa de verdaderos positivos de 0.58) y con eliminación de outliers es la basada en K medians (con una tasa de verdaderos positivos de 0.52). No obstante; están ambas por debajo del modelo del árbol de decisión sin discretizar con o sin eliminación de outliers.\n","metadata":{}},{"cell_type":"markdown","source":"## *6.3 Titanic*","metadata":{}},{"cell_type":"markdown","source":"Teniendo en cuenta que la base de datos Titanic surge de un problema estadístico normal y corriente basado en el número de supervivientes de una tragedia, en este caso la tragedia del hundimiento del titanic, la métrica que utilizaremos para evaluar la calidad de los modelos generados podría ser o recall o precission ya que accuracy funciona mál con problemas desbalanceados y este lo está. Así que si tenemos que elegir alguna de las dos métricas, podemos optar por utilizar como métrica la puntuación F1 que combina las métricas de recall y preccision.\n\nFinalmente, al utilizarse la base de datos para predecir si un viajero sobrevivió al Titanic dependiendo de ciertas caracterísitcas del viaje de este, consideraremos que dicha predicción es positiva si la variable objetivo Survived tiene el valor 1.","metadata":{}},{"cell_type":"markdown","source":"> ### *Modelos sin preprocesamiento*","metadata":{}},{"cell_type":"code","source":"utils.EvaluationWClassRepo(zero_r_model,\n               XTitanic_train, XTitanic_test,\n               yTitanic_train, yTitanic_test)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:47.346041Z","iopub.execute_input":"2021-05-28T10:37:47.346523Z","iopub.status.idle":"2021-05-28T10:37:47.498003Z","shell.execute_reply.started":"2021-05-28T10:37:47.34648Z","shell.execute_reply":"2021-05-28T10:37:47.49701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Debido a que los datos originales que estamos manjeando poseen variables categóricas, no podemos evaluar el modelo árbol de decisión para nuestros datos sin aplcarle anteriormente un preprocesamiento. Por eso pasamos directamente a evaluar los modelos de árbol de decisión aplicándoles el preprocesamiento.","metadata":{}},{"cell_type":"markdown","source":"> ### *Modelos con el preprocesamiento desarrollado anteriormente*","metadata":{}},{"cell_type":"code","source":"utils.EvaluationWClassRepo(preprocess_treemodel_Titanic,\n               XTitanic_train, XTitanic_test,\n               yTitanic_train, yTitanic_test)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:47.499745Z","iopub.execute_input":"2021-05-28T10:37:47.500072Z","iopub.status.idle":"2021-05-28T10:37:47.669526Z","shell.execute_reply.started":"2021-05-28T10:37:47.50004Z","shell.execute_reply":"2021-05-28T10:37:47.668571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nutils.EvaluationWClassRepo(preprocess_treemodel_discretizeU_Titanic,\n               XTitanic_train, XTitanic_test,\n               yTitanic_train, yTitanic_test)\n","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:47.670881Z","iopub.execute_input":"2021-05-28T10:37:47.67125Z","iopub.status.idle":"2021-05-28T10:37:47.846336Z","shell.execute_reply.started":"2021-05-28T10:37:47.671207Z","shell.execute_reply":"2021-05-28T10:37:47.845286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"utils.EvaluationWClassRepo(preprocess_treemodel_discretizeQ_Titanic,\n               XTitanic_train, XTitanic_test,\n               yTitanic_train, yTitanic_test)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:47.847766Z","iopub.execute_input":"2021-05-28T10:37:47.848119Z","iopub.status.idle":"2021-05-28T10:37:48.026336Z","shell.execute_reply.started":"2021-05-28T10:37:47.848089Z","shell.execute_reply":"2021-05-28T10:37:48.025576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"utils.EvaluationWClassRepo(preprocess_treemodel_discretizeK_Titanic,\n               XTitanic_train, XTitanic_test,\n               yTitanic_train, yTitanic_test)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:48.02775Z","iopub.execute_input":"2021-05-28T10:37:48.028018Z","iopub.status.idle":"2021-05-28T10:37:48.27183Z","shell.execute_reply.started":"2021-05-28T10:37:48.02799Z","shell.execute_reply":"2021-05-28T10:37:48.271065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ### *Modelos con el preprocesamiento extra*","metadata":{}},{"cell_type":"code","source":"utils.EvaluationWClassRepo(extra_preprocess_treemodel_Titanic,\n               XTitanic_train, XTitanic_test,\n               yTitanic_train, yTitanic_test)\n","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:48.27297Z","iopub.execute_input":"2021-05-28T10:37:48.273257Z","iopub.status.idle":"2021-05-28T10:37:48.646114Z","shell.execute_reply.started":"2021-05-28T10:37:48.27323Z","shell.execute_reply":"2021-05-28T10:37:48.645014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"utils.EvaluationWClassRepo(extra_preprocess_treemodel_discretizeU_Titanic,\n               XTitanic_train, XTitanic_test,\n               yTitanic_train, yTitanic_test)\n","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:48.647582Z","iopub.execute_input":"2021-05-28T10:37:48.647969Z","iopub.status.idle":"2021-05-28T10:37:49.022692Z","shell.execute_reply.started":"2021-05-28T10:37:48.647927Z","shell.execute_reply":"2021-05-28T10:37:49.02144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"utils.EvaluationWClassRepo(extra_preprocess_treemodel_discretizeQ_Titanic,\n               XTitanic_train, XTitanic_test,\n               yTitanic_train, yTitanic_test)\n","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:49.02415Z","iopub.execute_input":"2021-05-28T10:37:49.024562Z","iopub.status.idle":"2021-05-28T10:37:49.410064Z","shell.execute_reply.started":"2021-05-28T10:37:49.024517Z","shell.execute_reply":"2021-05-28T10:37:49.40888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"utils.EvaluationWClassRepo(extra_preprocess_treemodel_discretizeK_Titanic,\n               XTitanic_train, XTitanic_test,\n               yTitanic_train, yTitanic_test)\n","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:37:49.41241Z","iopub.execute_input":"2021-05-28T10:37:49.412769Z","iopub.status.idle":"2021-05-28T10:37:49.951073Z","shell.execute_reply.started":"2021-05-28T10:37:49.412739Z","shell.execute_reply":"2021-05-28T10:37:49.950361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ### *Conclusiones*","metadata":{}},{"cell_type":"markdown","source":"Las conclusiones que hemos obtenido tras analizar los resultados de la evaluación de modelos son las siguientes:\n* El mejor modelo que hemos obtenido ha sido el modelo del árbol de decisión con discretización con estrategia de igual anchura y con eliminación de outliers con un valor de f1 de 0.71.\n* En general el valor f1 obtenido ha sido muy dispar, teniendo la mayoria de modelos resultados muy normales, pero estando presentes otros modelos con valores muy malos como el modelo de árbol de decisión con discretización en igual frecuencia y eliminación de outliers que ha tenido un valor de f1 de 0.38 mientras que el modelo con mejor valor ha sido el modelo del árbol de decisión con discretización con estregia de igual anchura y con eliminación de outliers con un valor muy bueno de f1 0.71.\n* La eliminación de outliers ha sobreajustado casi todos los modelos dando en la mayoría peores resultados para el valor de f1, expecto para el modelo de árbol de decisión con discretización con estregia de igual anchura y con eliminación de outliers con un valor muy bueno de f1 0.71.\n* En el caso de la discretización, lo más recomendable es realizar una discretización con estrategia basada en k-means si no realizamos eliminación de outliers pues hemos obtenido con ese modelo un f1 con valor 0.69, mientras que si realizamos outliers la mejor discretización es la de igual anchura pues ha obtenido un valor de f1 de 0.71.","metadata":{}}]}