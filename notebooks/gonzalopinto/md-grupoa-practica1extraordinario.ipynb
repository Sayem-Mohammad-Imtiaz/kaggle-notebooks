{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Práctica 1: Análisis exploratorio de datos, preprocesamiento y validación de modelos de clasificación\n\n### Minería de Datos: Curso académico 2020-2021\n\n### Profesorado:\n\n* Juan Carlos Alfaro Jiménez\n* José Antonio Gámez Martín\n\n\n\n### Integrantes:\n\n* Gonzalo Pinto Perez\n* Yeremi Martin Huaman Torres","metadata":{}},{"cell_type":"markdown","source":"# 1. Preeliminares","metadata":{}},{"cell_type":"markdown","source":"Para empezar vamos a cargar las librerias que utilizaremos durante el desarrollo de la práctica","metadata":{}},{"cell_type":"code","source":"from sklearn.dummy import DummyClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import *\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.impute import *\nfrom sklearn.ensemble import RandomForestClassifier\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn import FunctionSampler\nfrom imblearn.pipeline import make_pipeline\nfrom scipy.stats import shapiro\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.metrics import *\nimport numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport plotly.express as px\nimport ipywidgets as widgets\nfrom sklearn.compose import make_column_selector, make_column_transformer\n\n\n\n\n# Importamos nuestro propio fichero de utilidades\nimport md_grupoa_practica1extra_ficheroutilidad as utils\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:20.548976Z","iopub.execute_input":"2021-06-12T06:44:20.54957Z","iopub.status.idle":"2021-06-12T06:44:24.463923Z","shell.execute_reply.started":"2021-06-12T06:44:20.549485Z","shell.execute_reply":"2021-06-12T06:44:24.463102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## *1.1 Variables globales*","metadata":{}},{"cell_type":"markdown","source":"Fijamos la semilla que utilizaremos:","metadata":{}},{"cell_type":"code","source":"seed = 27912","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:24.466186Z","iopub.execute_input":"2021-06-12T06:44:24.466489Z","iopub.status.idle":"2021-06-12T06:44:24.470856Z","shell.execute_reply.started":"2021-06-12T06:44:24.466457Z","shell.execute_reply":"2021-06-12T06:44:24.469878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Fijamos el tamaño del conjunto de entrenamiento:","metadata":{}},{"cell_type":"code","source":"train_size = 0.7","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:24.473129Z","iopub.execute_input":"2021-06-12T06:44:24.473614Z","iopub.status.idle":"2021-06-12T06:44:24.485425Z","shell.execute_reply.started":"2021-06-12T06:44:24.473584Z","shell.execute_reply":"2021-06-12T06:44:24.484586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## *1.2 Funciones auxiliares*","metadata":{}},{"cell_type":"markdown","source":"Estas son las funciones auxiliares que hemos creado para esta práctica y que hemos añadido a nuestro utils:","metadata":{}},{"cell_type":"code","source":"# =============================================================================\n# Funciones creadas por nosotros\n# =============================================================================\n    \n#Funcion para realizar gráficos de caja\ndef plot_boxplot(data):\n    \n    var = data.columns\n    data = widgets.fixed(data)\n\n    widgets.interact(_plot_boxplot, data=data, var=var)\n\n#Función auxiliar para gráficos de caja    \ndef _plot_boxplot(data, var):\n    return data[var].iplot(kind=\"box\")\n\n#Función para calcular los outliers de las variables pasadas por parámetros para un conjunto de datos pasado por paámetros también \ndef calc_outliers(data, variables):\n    min=99999\n    max=0\n    total=0\n    total_variables=len(variables)\n    for var in variables:\n        outlier = []\n        aux= data[var]\n        q1= np.percentile(aux,25)\n        q3= np.percentile(data[var],75)\n        IQR= q3-q1\n        UF= q3+(1.5*IQR)\n        LF= q1-(1.5*IQR)\n        for s in data[var].values:\n            if(s>UF or s<LF):\n                outlier.append(s)\n        if(len(outlier)<min):\n            min= len(outlier)\n            minvar= var\n        if(len(outlier)>max):\n            max=len(outlier)\n            maxvar=var\n        print(f\"El número de outliers de la variable {var} es: {len(outlier)}\")\n        print(f\"Siendo los outliers los siguientes: {outlier}\")\n        print(\"\")\n        total=total+len(outlier)\n    print(\"----Conclusiones----\")\n    print(f\"El total de outliers que tenemos en el conjunto de datos es de: {total}\")\n    print(f\"Con una media de  {total/len(variables)} outliers por variable\")\n    print(f\"El mayor número de outliers lo encontramos en la variable {maxvar} con {max} outliers\")\n    print(f\"El menor número de outliers lo encontramos en la variable {minvar} con {min} outliers\")\n    print(\"--------------------\")\n\n\n\n#Función para calcular el porcentaje de ceros en variables que no deberían de tener ceros\ndef ZeroCount(Data, param):\n    for s in param:\n        aux=Data[s]\n        zeros=aux.astype(bool).sum(axis=0)\n        totalval=np.product(aux.shape)\n        result= (1-(zeros/totalval)) * 100    \n        #print(result)\n        print(f\"El porcentaje de ceros en la variable {s} es del {result:.2f}% \")\n        \n#Función generar un diagrama de barras para analizar la potencia discriminativa de los valores perdidos de una variable con respecto a la variable clase\ndef _ValPerdidos_VarClase(data,param,clase):\n    aux = data.copy()\n    ValPerdidos = []\n    \n    #Comprobamos todos los casos en los que la variable dada tiene valores perdidos\n    for i in aux.index:\n        if(aux.loc[i,param]==0):\n            ValPerdidos.append('ConValoresPerdidos')\n        else:\n            ValPerdidos.append('SinValoresPerdidos')\n            \n    #Añadimos un nuevo atributo indicando los casos en los que hay valores perdidos\n    aux.loc[:,'valperdidos']= ValPerdidos\n    \n    #Generación del diagrama de barras apilado\n    title = 'Valores perdidos de '+ param +' con respecto a la variable clase'\n    x = aux.valperdidos\n    color = clase\n    barnorm = \"fraction\"\n    a = px.histogram(x=x, color=color, barnorm=barnorm, title=title)\n    return a\n        \n\n#Función para calcular el porcentaje de valores nulos en variables\ndef MissingValuesCount(Data, param):\n    Nan= Data.isnull().sum()\n    for s in param:\n        Aux =Data[s]\n        TotalVal= np.product(Aux.shape)\n        NanSum = Aux.isnull().sum()\n        result= (NanSum/TotalVal)*100  \n        print(f\"El porcentaje de valores nulos en la variable {s} es del {result:.2f}% \")\n\n\n#Función para eliminar outliers\ndef outlier_rejection(X, y, seed):\n    model = IsolationForest(random_state=seed)\n    model.fit(X)\n    y_pred = model.predict(X)\n    return X[y_pred == 1], y[y_pred == 1]\n\n\n#Función para realizar la evaluacion de bases de datos medicas\ndef EvaluationWClassRepo(model,\n             X_train, X_test,\n             y_train, y_test):\n    \n    clf = model.fit(X_train, y_train)\n    \n    y_pred = clf.predict(X_test)\n\n    accuracy = accuracy_score(y_test, y_pred)\n    \n    d = dict(enumerate(y_test.cat.categories))\n    a=\"% s\" % d.get(0)\n    b=\"% s\" % d.get(1)\n    labels=[a,b]\n    print(classification_report(y_test, y_pred, target_names=labels))\n    \n    disp = plot_confusion_matrix(clf, X_test, y_test)\n    \n    accuracy= accuracy*100\n\n    disp.ax_.set_title(f\" Tasa de precisión = {accuracy:.2f}\"+\"%\")\n    ","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:24.487526Z","iopub.execute_input":"2021-06-12T06:44:24.48826Z","iopub.status.idle":"2021-06-12T06:44:24.512222Z","shell.execute_reply.started":"2021-06-12T06:44:24.488135Z","shell.execute_reply":"2021-06-12T06:44:24.511179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Acceso y almacenamiento de datos","metadata":{}},{"cell_type":"markdown","source":"## *2.1 Breast cancer Winsconsin*","metadata":{}},{"cell_type":"markdown","source":"La base de datos Breast Cancer Winscosin es el resultado del análisis de una imagen digitalizada de un aspirado con aguja fina (FNA) de una masa mamaria. El análisis se realiza teniendo en cuenta las distinas variables que maneja la base de datos las cuales son:\n\n1. ID number: Es un número creciente que servirá de identificador para cada uno de los casos de la base de datos.\n2. Diagnosis: Variable categórica que guardará el resultado del análisis de la masa mamaria. Si tiene el valor B en caso de que la masa sea benignea y M en caso de que la masa sea maligna. Esta variable categórica será la que tomemos como variable objetivo.\n3. radius: Variable continua real que guardará la media de las distancias desde el centro hasta los puntos del perímetro de la masa.\n4. texture: Variable continua real que guardará la desviación estándar de los valores de la escala de grises de la masa.\n5. perimeter: Variable continua real que guardará el perímetro de la masa.\n6. area: Variable real que guardará el perímetro de la masa.\n7. smoothness: Variable continua real que guardará la variación local en longitudes de radio de la masa.\n8. compactness: Variable continua real resultante de la operación perimeter^2 / area - 1.0 (los valores de la variable real corresponde a los de la masa)\n9. concavity: Variable continua real que representa la severidad de las porciones cóncavas del contorno de la masa.\n10. concave points: Variable real que represente el numero de porciones cóncavas  del contorno de la masa.\n11. symmetry: Variable continua real que representa la simetria de la masa.\n12. fractal dimension (\"coastline approximation\" - 1): Variable continua real que representa la aproximación de la linea costera de la masa\n\nLas dos primeras variables son variables de información y el resto son variables continuas que se computan para cada caso de la masa mamaria analizada. Para estas últimas variables habrá tres tipos para cada uno de los casos:\n\n    -Variable_mean: Guardará el valor medio de la variable.\n    -Variable_se: Guardará el error estándar de la variable.\n    -Variable_worst: Guardará el peor valor (media de los tres valores más grandes) de la variable.\n\nComo conclusion la base de datos se utilizará en nuestro estudio para generar un modelo que prediga según unos valores si la masa mamaria analiza es B (Benigna) o M (Maligna)\n","metadata":{}},{"cell_type":"markdown","source":"Cargamos la base de datos Breast cancer wisconsin  tratando la variable identificadora id como indice y la variable diagnosis como variable objetivo. Finalmente mostramos una muestra del conjunto de datos cargados","metadata":{}},{"cell_type":"code","source":"filepathWisconsin = \"../input/breast-cancer-wisconsin-data/data.csv\"\nindexWisconsin = \"id\"\ntargetWisconsin = \"diagnosis\"\ndataWisconsin = utils.load_data(filepathWisconsin, indexWisconsin, targetWisconsin)\ndataWisconsin.sample(5, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:24.513446Z","iopub.execute_input":"2021-06-12T06:44:24.513721Z","iopub.status.idle":"2021-06-12T06:44:24.601085Z","shell.execute_reply.started":"2021-06-12T06:44:24.513695Z","shell.execute_reply":"2021-06-12T06:44:24.600179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Si realizamos una observación de esta muestra, podemos darnos cuenta de que destaca una variable llamada Unnamed 32, ya que en la muestra todos los sus valores son nulos (NaN). Si nos descargamos el fichero .csv de la base de datos Breast Cancer Wisconsin, podemos observar que esta variable es ruido ya que se ha introducido por error a la hora de cargar el conjunto de datos pues en el fichero se ha introducido una coma de más y al cargarlo esa coma la toma como otra variable, para ser exactos como la variable Unnamed32.\nPor ello lo que vamos a hacer a continuación es eliminar dicha columna (mediante el método de pandas drop) del conjunto de datos dataWisconsin y enseñaremos otra muestra de dicho conjunto de datos para confirmar si se ha borrado correctamente.","metadata":{}},{"cell_type":"code","source":"dataWisconsin = dataWisconsin.drop(dataWisconsin.columns[31], axis = 'columns')\ndataWisconsin.sample(5, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:24.602284Z","iopub.execute_input":"2021-06-12T06:44:24.602552Z","iopub.status.idle":"2021-06-12T06:44:24.634179Z","shell.execute_reply.started":"2021-06-12T06:44:24.602526Z","shell.execute_reply":"2021-06-12T06:44:24.633381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Tras confirmar que se ha borrado correctamente Unamed32, el siguiente paso consitirá en dividir el conjunto de datos en dos subconjuntos; uno con las variables predictoras (X) y otro con las variables objetivo (Y). Después mostramos una muestra (sample) de los subconjuntos creados.","metadata":{}},{"cell_type":"code","source":"(XWisconsin, yWisconsin) = utils.divide_dataset(dataWisconsin, target=\"diagnosis\")","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:24.635242Z","iopub.execute_input":"2021-06-12T06:44:24.635649Z","iopub.status.idle":"2021-06-12T06:44:24.647004Z","shell.execute_reply.started":"2021-06-12T06:44:24.635591Z","shell.execute_reply":"2021-06-12T06:44:24.646311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"XWisconsin.sample(5, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:24.6482Z","iopub.execute_input":"2021-06-12T06:44:24.648688Z","iopub.status.idle":"2021-06-12T06:44:24.685452Z","shell.execute_reply.started":"2021-06-12T06:44:24.648649Z","shell.execute_reply":"2021-06-12T06:44:24.684583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yWisconsin.sample(5, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:24.687845Z","iopub.execute_input":"2021-06-12T06:44:24.688129Z","iopub.status.idle":"2021-06-12T06:44:24.695605Z","shell.execute_reply.started":"2021-06-12T06:44:24.688101Z","shell.execute_reply":"2021-06-12T06:44:24.694789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A continuación vamos a dividir nuestros subconjunto de datos en otros dos:\n*  uno que sirva como muestra de entrenemiento (XWisconsin_train y yWisconsin_train) (70% del subconjunto inicial)\n*  el otro que sirva como muestra de prueba (XWisconsin_test y yWisconsin_test) (30% del subconjunto incial)\n\nEsta división la realizaremos con el método train_test_split.\n\nFinalmente mostraremos una muestra de cada uno de los subconjuntos obtenidos de forma aleatoria (utilizando la semilla que hemos definido al principio de la práctica).","metadata":{}},{"cell_type":"code","source":"(XWisconsin_train, XWisconsin_test, yWisconsin_train, yWisconsin_test) = train_test_split(XWisconsin, yWisconsin,\n                                                      stratify=yWisconsin,\n                                                      random_state=seed,\n                                                      train_size=train_size)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:24.697353Z","iopub.execute_input":"2021-06-12T06:44:24.697862Z","iopub.status.idle":"2021-06-12T06:44:24.712511Z","shell.execute_reply.started":"2021-06-12T06:44:24.697827Z","shell.execute_reply":"2021-06-12T06:44:24.711772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"XWisconsin_train.sample(5, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:24.71389Z","iopub.execute_input":"2021-06-12T06:44:24.714365Z","iopub.status.idle":"2021-06-12T06:44:24.753122Z","shell.execute_reply.started":"2021-06-12T06:44:24.714325Z","shell.execute_reply":"2021-06-12T06:44:24.752488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"XWisconsin_test.sample(5, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:24.754111Z","iopub.execute_input":"2021-06-12T06:44:24.754512Z","iopub.status.idle":"2021-06-12T06:44:24.784162Z","shell.execute_reply.started":"2021-06-12T06:44:24.754476Z","shell.execute_reply":"2021-06-12T06:44:24.78321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yWisconsin_train.sample(5, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:24.785486Z","iopub.execute_input":"2021-06-12T06:44:24.785916Z","iopub.status.idle":"2021-06-12T06:44:24.800472Z","shell.execute_reply.started":"2021-06-12T06:44:24.785887Z","shell.execute_reply":"2021-06-12T06:44:24.799672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yWisconsin_test.sample(5, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:24.801602Z","iopub.execute_input":"2021-06-12T06:44:24.801906Z","iopub.status.idle":"2021-06-12T06:44:24.815263Z","shell.execute_reply.started":"2021-06-12T06:44:24.801879Z","shell.execute_reply":"2021-06-12T06:44:24.813927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## *2.2 Pima Indians diabetes*","metadata":{}},{"cell_type":"markdown","source":"La base de datos Pima Indians diabetes tiene el objetivo de predecir de forma diagnóstica si un paciente tiene o no diabetes, basándose en ciertas mediciones ya realizadas e incluidas en la base de datos. Algunas restricciones se han establecido en la seleccion de las instacias para la base de datos. En particular, todos los pacientes son mujeres con al menos 21 años con herencia del pueblo Pima (que és un grupo de indígenas de Estados Unidos que viven en Arizona). Las distitnas variables que maneja la base de datos son las siguientes:\n\n1. Pregnancies: Variable discreta que indica el número de veces que ha estado embarazada la paciente.\n2. Glucose: Variable continua entera que indica la concentración de glucosa en plasma de la paciente tras 2 horas de que se la haya realizado una prueba oral de tolerancia a la glucosa.\n3. BloodPresure: Variable continua entera que indica la presión arterial diastólica de la paciente en mm/hg.\n4. SkinThickness: Variable continua entera que indica el espesor del pliegue cutáneo del triceps de la paciente en mm\n5. Insulin: Variable continua entera que indica el suelo insulino tras 2 horas de la paciente en mu U/ml\n6. BMI: Variable continua real que indica el índice de masa corporal de la paciente dado por la divisón del peso en kg entre la altura en metros al cuadrado\n7. DiabetesPedigreeFunction: Variable continua real que indica el resultado de la función de pedigree.\n8. Age: Variable continua entera que indica la edad del paciente.\n9. Outcome: Variable categórica que puede tener los valores 1 o 0. Esta variable categórica tomará el valor 1 en el caso de que la paciente tenga diabetes y tomará el valor 0 en el caso de que la paciente no tenga diabetes.\n\nLa variable objetivo de este problema sería outcome, mientras que el resto serán variables predictoras.\nComo conclusión, recordar que los modelos generados por esta base de datos tendrán la finalidad de que, dependiendo de los valores de las variables predictoras, intentar diagnosticar si un paciente tiene diabetes o no \"rellenando\" el valor de la variable objetivo Outcome.\n\n","metadata":{}},{"cell_type":"markdown","source":"Lo primero que vamos a hacer es cargar la base de datos utilizando Outcome como variable objetivo y como la base de datos carece de una variable identificadora que se pueda utilizar como índice, no utilizaremos ninguna variable (None) como variable indice ya que en ese caso, el método load_data generá un indice de forma automática.","metadata":{}},{"cell_type":"code","source":"filepath = \"../input/pima-indians-diabetes-database/diabetes.csv\"\nindexDiabetes = None\ntargetDiabetes = \"Outcome\"\ndataDiabetes = utils.load_data(filepath, indexDiabetes, targetDiabetes)\ndataDiabetes.sample(5, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:24.816925Z","iopub.execute_input":"2021-06-12T06:44:24.817521Z","iopub.status.idle":"2021-06-12T06:44:24.857434Z","shell.execute_reply.started":"2021-06-12T06:44:24.817479Z","shell.execute_reply":"2021-06-12T06:44:24.856733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"En el siguiente paso dividimos el conjunto de datos en dos subconjuntos, uno con las variables predictoras (X) y otro con las variables objetivo (Y). Después mostramos una muestra (sample) de los subconjuntos creados.","metadata":{}},{"cell_type":"code","source":"(XDiabetes, yDiabetes) = utils.divide_dataset(dataDiabetes, target=\"Outcome\")","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:24.858356Z","iopub.execute_input":"2021-06-12T06:44:24.858784Z","iopub.status.idle":"2021-06-12T06:44:24.862832Z","shell.execute_reply.started":"2021-06-12T06:44:24.858745Z","shell.execute_reply":"2021-06-12T06:44:24.862206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"XDiabetes.sample(5, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:24.863895Z","iopub.execute_input":"2021-06-12T06:44:24.864391Z","iopub.status.idle":"2021-06-12T06:44:24.886791Z","shell.execute_reply.started":"2021-06-12T06:44:24.864358Z","shell.execute_reply":"2021-06-12T06:44:24.885956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yDiabetes.sample(5, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:24.887998Z","iopub.execute_input":"2021-06-12T06:44:24.888283Z","iopub.status.idle":"2021-06-12T06:44:24.895203Z","shell.execute_reply.started":"2021-06-12T06:44:24.888234Z","shell.execute_reply":"2021-06-12T06:44:24.894444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A continuación vamos a dividir nuestros subconjunto de datos en otros dos:\n*  uno que sirva como muestra de entrenemiento (XDiabetes_train y yDiabetes_train) (70% del subconjunto inicial)\n*  el otro que sirva como muestra de prueba (XDiabetes_test y yDiabetes_test) (30% del subconjunto incial)\n\nEsta división la realizaremos con el método train_test_split.\n\nFinalmente mostraremos una muestra de cada uno de los subconjuntos obtenidos de forma aleatoria (utilizando la semilla que hemos definido al principio de la práctica).","metadata":{}},{"cell_type":"code","source":"(XDiabetes_train, XDiabetes_test, yDiabetes_train, yDiabetes_test) = train_test_split(XDiabetes, yDiabetes,\n                                                      stratify=yDiabetes,\n                                                      random_state=seed,\n                                                      train_size=train_size)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:24.896289Z","iopub.execute_input":"2021-06-12T06:44:24.896753Z","iopub.status.idle":"2021-06-12T06:44:24.90906Z","shell.execute_reply.started":"2021-06-12T06:44:24.896721Z","shell.execute_reply":"2021-06-12T06:44:24.908024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"XDiabetes_train.sample(5, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:24.910408Z","iopub.execute_input":"2021-06-12T06:44:24.910801Z","iopub.status.idle":"2021-06-12T06:44:24.928801Z","shell.execute_reply.started":"2021-06-12T06:44:24.910773Z","shell.execute_reply":"2021-06-12T06:44:24.928107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"XDiabetes_test.sample(5, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:24.93014Z","iopub.execute_input":"2021-06-12T06:44:24.930427Z","iopub.status.idle":"2021-06-12T06:44:24.948644Z","shell.execute_reply.started":"2021-06-12T06:44:24.9304Z","shell.execute_reply":"2021-06-12T06:44:24.947463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yDiabetes_train.sample(5, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:24.949875Z","iopub.execute_input":"2021-06-12T06:44:24.950135Z","iopub.status.idle":"2021-06-12T06:44:24.962521Z","shell.execute_reply.started":"2021-06-12T06:44:24.95011Z","shell.execute_reply":"2021-06-12T06:44:24.961615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yDiabetes_test.sample(5, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:24.96377Z","iopub.execute_input":"2021-06-12T06:44:24.964337Z","iopub.status.idle":"2021-06-12T06:44:24.975795Z","shell.execute_reply.started":"2021-06-12T06:44:24.964292Z","shell.execute_reply":"2021-06-12T06:44:24.974835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Preeliminares del analisis exploratiro**\n\n","metadata":{}},{"cell_type":"markdown","source":"Antes de empezar el analisis exploratorio obtendremos los conjuntos de entrenamiento y de test para todas las bases de datos sobre las que realizaremos el análisis exploratorio. Para ello volvemos a unir (usando el método join_dataset del fichero utils) los conjuntos de variables predictoras con la variable clase de los subconjuntos de entrenamiento y de test de todas las bases de datos.","metadata":{}},{"cell_type":"code","source":"dataWisconsin_test= utils.join_dataset(XWisconsin_test,yWisconsin_test)\ndataWisconsin_train= utils.join_dataset(XWisconsin_train,yWisconsin_train)\n\ndataDiabetes_test= utils.join_dataset(XDiabetes_test,yDiabetes_test)\ndataDiabetes_train= utils.join_dataset(XDiabetes_train,yDiabetes_train)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:24.977042Z","iopub.execute_input":"2021-06-12T06:44:24.977603Z","iopub.status.idle":"2021-06-12T06:44:24.988304Z","shell.execute_reply.started":"2021-06-12T06:44:24.97755Z","shell.execute_reply":"2021-06-12T06:44:24.987717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Analisis exploratorio","metadata":{}},{"cell_type":"markdown","source":"## *3.1 Breast cancer Winsconsin*","metadata":{}},{"cell_type":"markdown","source":"### **Descripción del conjunto**\n\nTendremos que tener conocimento de:\n* Numeros de casos\n* Tipos de variables ","metadata":{}},{"cell_type":"markdown","source":"Primero mostramos el número de casos y variables del conjunto de datos de entrenamiento con el metodo .shape","metadata":{}},{"cell_type":"code","source":"dataWisconsin_train.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:24.989492Z","iopub.execute_input":"2021-06-12T06:44:24.989911Z","iopub.status.idle":"2021-06-12T06:44:24.998338Z","shell.execute_reply.started":"2021-06-12T06:44:24.989874Z","shell.execute_reply":"2021-06-12T06:44:24.997799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Podemos observar que el conjunto de datos tiene 398 casos y 31 variables,siendo estas quizas demasiadas para que se reprensenten con claridad en algunos de los gráficos que vamos a utilizar","metadata":{}},{"cell_type":"code","source":"dataWisconsin_train.info(memory_usage=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:24.999266Z","iopub.execute_input":"2021-06-12T06:44:24.999743Z","iopub.status.idle":"2021-06-12T06:44:25.02043Z","shell.execute_reply.started":"2021-06-12T06:44:24.999702Z","shell.execute_reply":"2021-06-12T06:44:25.019171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A continuación podemos observar gracias al metodo .info ,que devuelve información del conjunto de datos incluyendo el tipo de sus variables, que de cada una de las 31 variables que hay 30 son del tipo real y una que es del tipo categorico (Que es la variable que usaremos como variable objetivo, diagnosis)","metadata":{}},{"cell_type":"markdown","source":"Continuaremos mostrando los distitnos valores que pueden tomar nuestras variables categóricas con el método .categories:","metadata":{}},{"cell_type":"code","source":"yWisconsin_train.cat.categories","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:25.027218Z","iopub.execute_input":"2021-06-12T06:44:25.027509Z","iopub.status.idle":"2021-06-12T06:44:25.0337Z","shell.execute_reply.started":"2021-06-12T06:44:25.027483Z","shell.execute_reply":"2021-06-12T06:44:25.032901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Podemos observar que diagnosis es una variable categórica que puede tomar el valor B en caso de que el resultado del diagnosis de la masa del paciente sea benigna y M en el caso de que el resultado del diagnosis de la masa del paciente sea maligno.","metadata":{}},{"cell_type":"markdown","source":"### **Visualización de las variables**","metadata":{}},{"cell_type":"markdown","source":"Vamos a empezar realizando un histograma sobre el conjunto de datos de entrenamiento:","metadata":{}},{"cell_type":"code","source":"utils.plot_histogram(dataWisconsin_train)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:25.036454Z","iopub.execute_input":"2021-06-12T06:44:25.036817Z","iopub.status.idle":"2021-06-12T06:44:26.234618Z","shell.execute_reply.started":"2021-06-12T06:44:25.036784Z","shell.execute_reply":"2021-06-12T06:44:26.233587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Tras observar el histograma que hemos obtenido sobre el conjunto de datos de entrenamiento, podemos sacar las siguientes conclusiones:\n* La primera conclusión que podemos sacar esque cada una de las variables perteneciente a un grupo (mean, se o worst) poseen una distribución similar, con alguna excepción. Por ejemplo, las variables del grupo del valor medio (mean), tienen una distribución normal con tendencia central en forma de campana de gauss, a excepción, de las variables continuas area_mean, compactness_mean, concavity_mean y concave points_mean, que tienen una distribución con tendencia exponencial decreciente. Por otra parte, las variables del grupo del error medio (se) poseen una distribución exponencial decreciente apreciable en todas las variables del grupo. Finalmente, las variables del grupo del peor valor (worst) tienen una distribución normal con tenencia central en forma de campana de gauss, a excepción, de las variables continuas area_worst compactness_worst, concavity_worts y fractal dimension_worst.\n* La segunda conclusión que podemos sacar esque entre las 31 variables del conjunto de datos de entrenamiento, no hemos observado que haya presencia de datos no válidos ni indicios de outliers. No obstante; durante la realización de este análisis exploratorio realizaremos un diagrama de caja para cada una de las variables para analizar de forma más detallada la presencia de outliers.","metadata":{}},{"cell_type":"markdown","source":"A continuacion vamos a realizar un diagrama de barras:","metadata":{}},{"cell_type":"code","source":"utils.plot_barplot(dataWisconsin_train)\nB,M= yWisconsin_train.value_counts()\nprint('Numero de masas benigneas: ',B)\nprint('Numero de masas malignas : ',M)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:26.236102Z","iopub.execute_input":"2021-06-12T06:44:26.236673Z","iopub.status.idle":"2021-06-12T06:44:26.33388Z","shell.execute_reply.started":"2021-06-12T06:44:26.236615Z","shell.execute_reply":"2021-06-12T06:44:26.332886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Observamos que en nuestro conjunto de datos entrenamientos hay más casos en el que el diagnóstico final fue benigneo(250)que en el que el diagnóstico final fue maligno (148), esto quiere decir que el problema está desbalanceado.","metadata":{}},{"cell_type":"markdown","source":"Continuaremos con el análisis exploratorio realizando un diagrama de puntos:","metadata":{}},{"cell_type":"code","source":"utils.plot_pairplot(dataWisconsin_train, target=\"diagnosis\")","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:26.33533Z","iopub.execute_input":"2021-06-12T06:44:26.335731Z","iopub.status.idle":"2021-06-12T06:44:26.610035Z","shell.execute_reply.started":"2021-06-12T06:44:26.33569Z","shell.execute_reply":"2021-06-12T06:44:26.608933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lo único que podemos observar es lo que hemos mencionado al principio de este análisis, al ser 30 variables predictoras, algunas representaciones gráficas pueden no verse con claridad y este es un ejemplo. Por ello lo que vamos a hacer es dividir el diagrama de puntos entre tres, uno para cada uno de los tres tipos que pueden tener las variables predictoras: mean, se y worst.","metadata":{}},{"cell_type":"code","source":"mean_train = dataWisconsin_train.iloc[:,[0,1,2,3,4,5,6,7,8,9,30]]\nse_train = dataWisconsin_train.iloc[:,[10,11,12,13,14,15,16,17,18,19,30]]\nworst_train = dataWisconsin_train.iloc[:,[20,21,22,23,24,25,26,27,28,29,30]]\nutils.plot_pairplot(mean_train, target=\"diagnosis\")","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:26.611514Z","iopub.execute_input":"2021-06-12T06:44:26.611992Z","iopub.status.idle":"2021-06-12T06:44:26.737796Z","shell.execute_reply.started":"2021-06-12T06:44:26.611912Z","shell.execute_reply":"2021-06-12T06:44:26.7367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"utils.plot_pairplot(se_train, target=\"diagnosis\")","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:26.73917Z","iopub.execute_input":"2021-06-12T06:44:26.739566Z","iopub.status.idle":"2021-06-12T06:44:26.84461Z","shell.execute_reply.started":"2021-06-12T06:44:26.739527Z","shell.execute_reply":"2021-06-12T06:44:26.843724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"utils.plot_pairplot(worst_train, target=\"diagnosis\")","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:26.845969Z","iopub.execute_input":"2021-06-12T06:44:26.846278Z","iopub.status.idle":"2021-06-12T06:44:26.942133Z","shell.execute_reply.started":"2021-06-12T06:44:26.846245Z","shell.execute_reply":"2021-06-12T06:44:26.941004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Respecto a estas graficas podemas darnos cuenta que las variables continuas radius, perimeter y area estan muy relacionados (en los tres grupos de variables predictoras mean, se y worst), obviamente esto puede ser por que para obtener el perimetro y el area es necesario saber el radio. Entonces, sería factible descartar radius ya que sería una variable simple de la que se obtienen las variables derivadas perimeter y area, y estas dos tendrías más información a la hora de generar los modelos que la variable radius.\nTambién podemos observar que la mejor forma de realizar una discretización óptima sería utilizando dos intervalos y quizas la mejor estrategia sería utilizar KMeans, pero hay tantos casos que no se puede estar seguro a simple vista.","metadata":{}},{"cell_type":"markdown","source":"Para comprobar algunas de las conclusiones que hemos realizado en el apartado anterior vamos a generar una matriz de correlación:","metadata":{}},{"cell_type":"markdown","source":"Al igual que para el gráfico anterior vamos a realizar tres matrices distintas una para cada uno de los tipos que pueden tener las variables predictoras; mean,se y worst.","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots()\nsns.heatmap(mean_train.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:26.943319Z","iopub.execute_input":"2021-06-12T06:44:26.943676Z","iopub.status.idle":"2021-06-12T06:44:27.720046Z","shell.execute_reply.started":"2021-06-12T06:44:26.94355Z","shell.execute_reply":"2021-06-12T06:44:27.719055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots()\nsns.heatmap(se_train.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:27.721488Z","iopub.execute_input":"2021-06-12T06:44:27.721891Z","iopub.status.idle":"2021-06-12T06:44:28.40575Z","shell.execute_reply.started":"2021-06-12T06:44:27.721849Z","shell.execute_reply":"2021-06-12T06:44:28.404828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots()\nsns.heatmap(worst_train.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:28.407122Z","iopub.execute_input":"2021-06-12T06:44:28.407412Z","iopub.status.idle":"2021-06-12T06:44:29.06635Z","shell.execute_reply.started":"2021-06-12T06:44:28.407384Z","shell.execute_reply":"2021-06-12T06:44:29.065227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Las conclusiones que podemos sacar esque en los tres grupos de variables predictoras podemos presenciar que hay dos ternas de variables predictoras donde se presencia un alto grado de correlación entre sus miembros:\n* La primera terna consta de las variables continuas radius, perimeter y área, las cuales presentan un alto nivel de correlación debido a que perimeter y área son variables derivadas de radio. \n* La segunda terna consta de las variables continuas concavity, concave points y compactness las cuales también presentan un alto nivel de correlación debido a que compactness y concavity son variables derivadas de concave points.\nPor lo tanto, en el preprocesamiento no deberiamos de tener en cuenta las variables simples(radius y concave points) y utilizar solo las variables derivadas de estas ultimas ya que aportarán más información al modelo.\n","metadata":{}},{"cell_type":"markdown","source":"Diagrama de caja","metadata":{}},{"cell_type":"code","source":"plot_boxplot(dataWisconsin_train)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:29.068089Z","iopub.execute_input":"2021-06-12T06:44:29.068514Z","iopub.status.idle":"2021-06-12T06:44:29.174051Z","shell.execute_reply.started":"2021-06-12T06:44:29.06847Z","shell.execute_reply":"2021-06-12T06:44:29.173135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Debido a que estamos utilziando el método .iplot para generar los diagramas de cajas y que este método no genera diagramas de caja en los que se resalten los outliers presentes en una variable (como si hacen otros diagramas de cajas generados mediante seaborn o plotly express), y que no sabemos si estos gráficos serán visibles cuando hagamos el commit del notebook; hemos decidido apoyar las conclusiones que sacariamos de un diagrama de cajas mediante una función que hemos creado nosostros mismos. \nDicha función se llama calc_outliers y tras pasarle un conjunto de datos y el nombre de las variables de dicho conjunto de datos en las que queremos buscar la presencia de outliers como parámetros, te devuelve el número de outliers presentes en cada una de las variables solicitadas, un array con cada uno de los outliers presentes en cada variable y una conclusión final con el número total de outliers en el conjunto de datos, la media de outliers por variable en el conjunto de datos, la variable con el mayor número de outliers con el número de outliers que posee y la variable con el menor número de outliers con el corresponideinte número de outliers.\nDicho esto, el resultado de la ejecución de dicha función para el conjunto de datos de entrenamiento de Winsconsin pasándole tambíen como parámetro el nombre de todas las variables predictoras del conjunto sería el siguiente:","metadata":{}},{"cell_type":"code","source":"calc_outliers(dataWisconsin_train, ['radius_mean','texture_mean','perimeter_mean','area_mean','smoothness_mean','compactness_mean','concavity_mean','concave points_mean','symmetry_mean','fractal_dimension_mean',\n      'radius_se','texture_se','perimeter_se','area_se','smoothness_se','compactness_se','concavity_se','concave points_se','symmetry_se','fractal_dimension_se',\n      'radius_worst','texture_worst','perimeter_worst','area_worst','smoothness_worst','compactness_worst','concavity_worst','concave points_worst','symmetry_worst','fractal_dimension_worst',]\n)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:29.175545Z","iopub.execute_input":"2021-06-12T06:44:29.175955Z","iopub.status.idle":"2021-06-12T06:44:29.217197Z","shell.execute_reply.started":"2021-06-12T06:44:29.175914Z","shell.execute_reply":"2021-06-12T06:44:29.216258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Por lo tanto, las conclusiones que podemos sacar esque, aunque hay una variable predictora en el conjunto de datos sin ningún outlier (concave points_worst) el número total de outliers que tenemos en el conjunto de datos es demasiado grande (435) y dichos outliers están presentes en prácticamente todas las variables predictoras, por lo que se probará a utilizar un estimador que elimine los outliers para comprobar si mejoran los resultados de los distintos modelos al usarlo.","metadata":{}},{"cell_type":"markdown","source":"## *3.2 Pima Indians diabetes*","metadata":{}},{"cell_type":"markdown","source":"### **Descripción del conjunto**\n\nTendremos que tener conocimento de:\n* Numeros de casos\n* Tipos de variables ","metadata":{}},{"cell_type":"markdown","source":"Primero mostramos el número de casos y variables del conjunto de datos de entrenamiento con el metodo .shape","metadata":{}},{"cell_type":"code","source":"dataDiabetes_train.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:29.218784Z","iopub.execute_input":"2021-06-12T06:44:29.21918Z","iopub.status.idle":"2021-06-12T06:44:29.225383Z","shell.execute_reply.started":"2021-06-12T06:44:29.219135Z","shell.execute_reply":"2021-06-12T06:44:29.224327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"El número de casos del conjunto de datos es 537 mientras que el número de variables es 9","metadata":{}},{"cell_type":"markdown","source":"A continuación mostramos el tipo de cada una de las variables del conjunto de datos con el método .info:","metadata":{}},{"cell_type":"code","source":"dataDiabetes_train.info(memory_usage=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:29.226992Z","iopub.execute_input":"2021-06-12T06:44:29.227445Z","iopub.status.idle":"2021-06-12T06:44:29.240726Z","shell.execute_reply.started":"2021-06-12T06:44:29.227407Z","shell.execute_reply":"2021-06-12T06:44:29.239529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Donde podemos observar que de las 9 variables, todas son de tipo entero excepto tres; BMI y DiabetesPedigreeFunction que son de tipo real (dato que tendremos que tener en cuenta si las modificamos en el preprocesamiento), y Outcome que es de tipo categórico y es la que tomaremos como variable objetivo.","metadata":{}},{"cell_type":"markdown","source":"A continuación mostramos los distitnos valores que pueden tomar nuestras variables categóricas con el método .categories:","metadata":{}},{"cell_type":"code","source":"yDiabetes.cat.categories","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:29.242227Z","iopub.execute_input":"2021-06-12T06:44:29.242753Z","iopub.status.idle":"2021-06-12T06:44:29.251008Z","shell.execute_reply.started":"2021-06-12T06:44:29.242691Z","shell.execute_reply":"2021-06-12T06:44:29.249971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Podemos observar que la variable Outcome es una variable categórica numérica que puede tomar los valores 0 o 1 en caso negativo o afirmativo de que el paciente tenga diabetes respectivamente.","metadata":{}},{"cell_type":"markdown","source":"### **Visualización de las variables**","metadata":{}},{"cell_type":"markdown","source":"Vamos a empezar realizando un histograma sobre el conjunto de datos de entrenamiento:","metadata":{}},{"cell_type":"code","source":"utils.plot_histogram(dataDiabetes_train)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:29.252321Z","iopub.execute_input":"2021-06-12T06:44:29.252747Z","iopub.status.idle":"2021-06-12T06:44:29.386525Z","shell.execute_reply.started":"2021-06-12T06:44:29.252717Z","shell.execute_reply":"2021-06-12T06:44:29.385516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Si observamos la gráficas podemos observar dos detalles importantes:\n* Lo primero es que no todas las variables predictoras tienen una distribución normal con tendencia central en forma de campana de gauss, solamente las variables predictoras SkinThickness, BMI, BloodPresure y Glucose; mientras que el resto de variables predictoras ( Age, Pregnancies, Insulin y DiabetesPedigreeFunction) poseen una distribución con tendencia exponencial decreciente. De hecho en ciertas variables predictoras como DiabetesPedigreeFunction o Insulin, en sus gráficas podemos empezar a apreciar la aparición de outliers que comprobaremos más tarde con los gráficos de caja.\n* Lo segundo es que en las gráficas se puede observar como ciertas variables continuas toman valores perdidos, es decir toman el valor 0 cuando según la lógica de los valores que pueden tomar dichas variables continuas, sería imposible que dichas variables continuas tuvisen como valor un 0. Dichas variables continuas son Glucose (un paciente no puede tener 0 de glucosa), BloodPresure (un paciente no puede tener 0 de presión sanguínea), SkinThickness (la piel de un paciente debe de tener grosor), Insulin (un paciente ha de tener insulina) y BMI (el índice de masa corporal de una persona no puede ser 0).","metadata":{}},{"cell_type":"markdown","source":"A continuación debido a las conclusiones del histograma, vamos a obtener el porcentaje de ceros que tienen estas variables continuas con el método del fichero de utilidad ZeroCount y así comproboremos la cantidad de ruido que tienen estas variables continuas y si vale la pena tenerlas en cuenta para el preprocesamiento:","metadata":{}},{"cell_type":"code","source":"param=[\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\"]\n\nutils.ZeroCount(dataDiabetes_train,param)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:29.387995Z","iopub.execute_input":"2021-06-12T06:44:29.388369Z","iopub.status.idle":"2021-06-12T06:44:29.396971Z","shell.execute_reply.started":"2021-06-12T06:44:29.38832Z","shell.execute_reply":"2021-06-12T06:44:29.395795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lo que podemos observar esque el porcentaje de ruido que tienen variables continuas como BloodPresure, Glucose o BMI es aceptable, mientras que el de las variables continuas Insulin y SkinThickness (48.60% y 29.24% de ruido respectivamente) es demasiado alto, por lo tanto, a continuación vamos a analizar la potencia discriminativa de los valores perdidos de estas variables continuas con respecto a la variable clase, antes de concluir en si se deberían o no tenerse en cuenta a la hora de generar los modelos.","metadata":{}},{"cell_type":"markdown","source":"Para ello vamos a recurrir al método _ValPerdidos_VarClase de nuestro fichero de utilidad, al cuál tras pasarle como parámetros un conjunto de datos, el nombre de una variable predictora y la variable objetivo del conjunto de datos; creará un diagrama de barras \"apilado\" con dos barras, siendo la primera una representacion normalizada de los casos del conjunto de datos en los que la variable predictora (que hemos pasado como parámetro)  no tiene valores perdidos y la segunda la que si tiene valores perdidos. Además, cada una de las barras estará dividida en base a los valores de la variable objetivo que hemos pasado como parámetro anteriormente, representado el porcentaje de casos del conjunto de datos que toman los distintos valores de dicha variable objetivo(en el caso de la variable objetivo del conjunto de datos dataDiabetes_train dichos valores serán 0 o 1). Este tipo de gráfico nos pérmitirá comprobar la potencia discriminativa de los valores perdidos de una variable predictora con respecto a la variable clase.","metadata":{}},{"cell_type":"markdown","source":"Explicado el método, lo vamos a ejecutar para la variable predictora SkinThickness cuyos valores son en un 29,6% valores perdidos:","metadata":{}},{"cell_type":"code","source":"utils._ValPerdidos_VarClase(dataDiabetes_train,\"SkinThickness\",dataDiabetes_train.Outcome)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:29.398737Z","iopub.execute_input":"2021-06-12T06:44:29.399287Z","iopub.status.idle":"2021-06-12T06:44:29.510729Z","shell.execute_reply.started":"2021-06-12T06:44:29.39924Z","shell.execute_reply":"2021-06-12T06:44:29.510033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Y después lo vamos a ejecutar para la variable predictora Insulin cuyos valores son en un 48,60% valores perdidos:","metadata":{}},{"cell_type":"code","source":"utils._ValPerdidos_VarClase(dataDiabetes_train,\"Insulin\",dataDiabetes_train.Outcome)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:29.511771Z","iopub.execute_input":"2021-06-12T06:44:29.512201Z","iopub.status.idle":"2021-06-12T06:44:29.601327Z","shell.execute_reply.started":"2021-06-12T06:44:29.512161Z","shell.execute_reply":"2021-06-12T06:44:29.600506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Como podemos apreciar, los valores perdidos de estas dos variables predictoras no tienen una gran potencia discriminatoria, ya que la diferencia de porcentajes de casos en base al valor de la variable predictora Outcome no varía mucho entre los casos con valores perdidos y sin valores perdidos:\n* ± 0.05 (±5%) en el caso de la variable predictora SkinThickness.\n* ± 0.03 (±3%)en el caso de la variable predictora Insulin.\n\nPor lo tanto podemos concluir, que al carecer de poder discriminativo los valores perdidos de las variables SkinThickness e Insulin y al poseer ambas un alto porcentaje de valores perdidos (29,6% y 48,60%), es recomendable que no las tengamos en cuenta a la hora de generar nuestros modelos.","metadata":{}},{"cell_type":"markdown","source":"A continuacion vamos a realizar un diagrama de barras:","metadata":{}},{"cell_type":"code","source":"utils.plot_barplot(dataDiabetes_train)\nS,N= yDiabetes_train.value_counts()\nprint('Numero de Diabetes: ',S)\nprint('Numero de no Diabetes: ',N)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:29.602709Z","iopub.execute_input":"2021-06-12T06:44:29.603071Z","iopub.status.idle":"2021-06-12T06:44:29.689883Z","shell.execute_reply.started":"2021-06-12T06:44:29.603033Z","shell.execute_reply":"2021-06-12T06:44:29.689111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Podemos observar que en nuestro conjunto de datos hay más casos en los que la variable objetivo Outcome indicaba que el paciente tenia diabetes (350) que en los que la variable objetivo Outcome indicaba que el paciente no tenia diabetes (187). Al haber tanta diferencia entre el número de los casos en los que el paciente tiene o no diabetes podemos decir que el problema está desbalanceado.","metadata":{}},{"cell_type":"markdown","source":"Continuaremos con el análisis exploratorio realizando un diagrama de puntos:","metadata":{}},{"cell_type":"code","source":"utils.plot_pairplot(dataDiabetes_train, target=\"Outcome\")","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:29.69102Z","iopub.execute_input":"2021-06-12T06:44:29.691295Z","iopub.status.idle":"2021-06-12T06:44:29.781178Z","shell.execute_reply.started":"2021-06-12T06:44:29.69127Z","shell.execute_reply":"2021-06-12T06:44:29.780187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Podemos observar que hay ciertas variables predictoras muy relacionadas entre si, como Age y Pregnancies, Glucose y Age o Glucose e Insulin; por lo que quizas en procesos posteriores deberiamos eliminar alguno de los miembros de estos pares de variables predictoras. Tambíen podemos darnos cuenta de que si realizamos una discretización quizas deberíamos de realizarla con 3 intervalos, el problema, esque los datos están tan juntos que en principio no podemos definir ninguna estrategia de discretización correcta para este conjunto de datos.","metadata":{}},{"cell_type":"markdown","source":"Para comprobar algunas de las conclusiones que hemos realizado en el apartado anterior vamos a generar una matriz de correlación:","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots()\nsns.heatmap(dataDiabetes_train.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:29.782711Z","iopub.execute_input":"2021-06-12T06:44:29.783052Z","iopub.status.idle":"2021-06-12T06:44:30.266413Z","shell.execute_reply.started":"2021-06-12T06:44:29.783018Z","shell.execute_reply":"2021-06-12T06:44:30.265437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Al observar la matriz nos podemos dar cuenta de que el par de variables predictoras Glucose-Age y Glucose-Insulin están relacionados pero no lo suficiente para eliminar una de estas variables en el preprocesamiento; no obstante, el par de variables Age-Pregnancies es el más relacionado del conjunto de datos y quizas deberiamos de eliminar una de estas variables predictoras durante el preprocesamiento, siendo quizas, la más favorable a esta eliminación la variable predictora pregnancies, ya que en principio podemos suponer que aporta menos información que la variable predictora Age a los modelos que vamos a generar para nuestro conjunto de datos pues creemos que la edad(Age) es un factor más relevante para la aparición de la enfermedad diabetes que el número de embarazos(Pregnancies).","metadata":{}},{"cell_type":"markdown","source":"Para acabar el análisis exploratorio vamos a realizar un diagrama de cajas para comprobar si podrían haber outliers en las variables del conjunto de datos:","metadata":{}},{"cell_type":"code","source":"utils.plot_boxplot(dataDiabetes_train)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:30.267648Z","iopub.execute_input":"2021-06-12T06:44:30.267927Z","iopub.status.idle":"2021-06-12T06:44:30.351891Z","shell.execute_reply.started":"2021-06-12T06:44:30.267898Z","shell.execute_reply":"2021-06-12T06:44:30.350782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Aplicando la misma justificación que hemos desarrolado para los diagramas de cajas del conjunto de datos de Winsconsin, vamos a ejecutar la función calc_outliers para apoyar los resultados del diagrama de cajas:","metadata":{}},{"cell_type":"code","source":"calc_outliers(dataDiabetes_train, ['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age']\n)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:30.353468Z","iopub.execute_input":"2021-06-12T06:44:30.353948Z","iopub.status.idle":"2021-06-12T06:44:30.391367Z","shell.execute_reply.started":"2021-06-12T06:44:30.353903Z","shell.execute_reply":"2021-06-12T06:44:30.390346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Las conclusiones que podemos sacar esque el total de valores outliers en el conjunto de datos es bastante alta (114) y estan presentes en todas las variables predictoras del conjunto de datos, siendo la variable predictora que menos tiene 1, pero sigue teniendo como mínimo un outlier. Por lo tanto se justifica el uso de un estimador cuya función sea eliminar outliers para modelar este conjunto de datos y así comprobar si mejoran los resultados con respecto a un modelo que no elimine dichos outliers.","metadata":{}},{"cell_type":"markdown","source":"# 4. Preprocesamiento de datos","metadata":{}},{"cell_type":"markdown","source":"En esta parte aplicaremos el preprocesamiento en base a las modificaciones que hemos visto que necesitan los conjuntos de datos durante el análisis exploratorio.","metadata":{}},{"cell_type":"markdown","source":"Empezamos el preprocesamiento definiendo el estimador que hara uso de la función outlier_rejection del fichero de utilidad utils para eliminar outliers. Este estimador se utilizará posteriormente en la generación de modelos aplicandosé al conjunto de datos.","metadata":{}},{"cell_type":"code","source":"#Estimador para eliminar outliers\nOutlierRejection = FunctionSampler(func=utils.outlier_rejection, kw_args={\"seed\":seed})","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:30.392578Z","iopub.execute_input":"2021-06-12T06:44:30.39287Z","iopub.status.idle":"2021-06-12T06:44:30.396466Z","shell.execute_reply.started":"2021-06-12T06:44:30.392843Z","shell.execute_reply":"2021-06-12T06:44:30.395737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## *4.1 Breast cancer Winsconsin*","metadata":{}},{"cell_type":"markdown","source":"Como hemos concluido en el análisis exploratorio, en los tres grupos de variables predictoras (mean,se y worst) se pueden apreciar dos ternas de variables predictoras, donde estas están muy correlacionadas entre sí, ya que en cada una de estas ternas hay dos variables derivadas de la tercera variable de la terna que es una variable simple. Por ello en el preprocesamiento vamos a generar un estimador que elimine las dos variables simples (radius y concave points) de todos los grupos de variables (mean,se y worst) del conjunto  de datos para que no influyan en la generación del modelo ya que aportan menos información de la que aportan las variables que derivan de ellos.\nPara la generación del estimador vamos a utilizar el método make_column_transformer de la libreria sklearn.compose y vamos a indicar como parámetro del transformador 'drop' para que elimine la lista de variables predictoras de las que hemos hablado con anteriorioridad, además; hemos indicado que para el resto de variables del conjunto el estimador simplemente no las toque igualando el parámetro remainder como 'passthrough'.","metadata":{}},{"cell_type":"code","source":"preproceserWinsconsin = make_column_transformer(('drop',['radius_mean','radius_se','radius_worst','concave points_mean',\n          'concave points_se','concave points_worst']),\n                                                remainder='passthrough')\n","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:30.397475Z","iopub.execute_input":"2021-06-12T06:44:30.39787Z","iopub.status.idle":"2021-06-12T06:44:30.408544Z","shell.execute_reply.started":"2021-06-12T06:44:30.397842Z","shell.execute_reply":"2021-06-12T06:44:30.407488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Como dato aclaratorio, también podriamos haber generado el estimador utilizando el transformador 'passthrough' y seleccionado todas las variables predictoras con las que nos queremos quedar sin igualar el parámetro remainder a passthrough, pues esto hará que las variables que no le especifiquemos las borrará del conjunto de datos; básicamente es hacer el proceso que hemos hecho con el estimador al revés.","metadata":{}},{"cell_type":"markdown","source":"## *4.2 Pima Indians diabetes*","metadata":{}},{"cell_type":"markdown","source":"Como hemos indicado en el preprocesamiento de esta base de datos lo que tendremos que hacer será:\n* Sustituir los valores cero de las variables continuas Glucose, BloodPressure y BMI\n* Eliminar una variable predictora del par de variables predictoras Age y Pregnancies por su alto coeficiente de correlación\n* Eliminar las variables predictoras Insulin y SkinThickness por la alta cantidad de valores perdidos que tienen y la ausencia de poder discriminativo de estos.\n* Dejar el resto de variables del conjunto igual.\n\nPara la sustitución de valores cero de las variables predictoras Glucose, BloodPressure y BMI utilizaremos el estimador SimpleImputer pero teniendo en cuenta que BMI se trata de una variable real y que las otras dos se tratan de variables enteras, tendremos que generar un estimador para cada tipo de variable (entera y real) modificando la estrategia de búsqueda, pues aunque lo normal es utilizar la media para la sustitución de valores ruidosos, al ser Glucose y BloodPresure enteros, no se puede introducir de repente un valor con decimales (la media podría tener o no decimales) por ello el simpleImputer que afectará a las variables enteras utilizará la estrategia \"median\" sustituyendo los ceros por el valor más \"centrado\" entre todos  y que claramente será de tipo entero y sin decimales. Ambos SimpleImputer (de enteros y decimales) los \"combinaremos\" con un método make_column_transformer donde le pasaremos a cada estimador las variables correspondientes asignándolas al parámetro pattern del make_column_selector. Para dejar al resto de variables igual simplemente declararemos las variables predictoras que no se deben de tocar en un parámetro aparte y se introducirán en el make_column_transformer pero en vez de pasarle un estimador como parámetro introduciremos el valor 'passthrough' que simplemente dejará igual las variables predictoras. Finalmente si queremos eliminar las variables predictoras que hemos acordado en el análisis exploratorio bastará con no incluirlas en el make_colum_transformer.","metadata":{}},{"cell_type":"code","source":"#Variables para sustituir ceros\nfeatures1 = 'Glucose|BloodPressure'\nfeatures2 = 'BMI'\n#Variables que no hay que tocar\nfeatures3 = 'DiabetesPedigreeFunction|Age'\n\n#Estimador para integers\nreplace0Integer_Estimator = make_pipeline(SimpleImputer(strategy=\"median\",missing_values=0 ))\n#Estimador para reales\nreplace0Float_Estimator = make_pipeline(SimpleImputer(strategy=\"mean\",missing_values=0 ))\n\npreproceserDiabetes = make_column_transformer(\n    (replace0Integer_Estimator, make_column_selector(pattern= features1)),\n    (replace0Float_Estimator, make_column_selector(pattern= features2)),\n     ('passthrough', make_column_selector(pattern= features3)))\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:30.409813Z","iopub.execute_input":"2021-06-12T06:44:30.410164Z","iopub.status.idle":"2021-06-12T06:44:30.419534Z","shell.execute_reply.started":"2021-06-12T06:44:30.410135Z","shell.execute_reply":"2021-06-12T06:44:30.418741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Algoritmos de clasificación","metadata":{}},{"cell_type":"markdown","source":"En esta parte generaremos los modelos que vamos a evaluar y las pipelines que saldrán como resultado de aplicar a dichos modelos los estimadores que hemos creado en el apartado anterior (que también evaluaremos posteriormente).","metadata":{}},{"cell_type":"markdown","source":"Los modelos que evaluaremos serán el modelo zero_r y el modelo de arbol de decision que usará la semilla que estamos usando durante todo el problema.","metadata":{}},{"cell_type":"code","source":"#Generación del modelo zero_r\nzero_r_model = DummyClassifier(strategy=\"most_frequent\")\n#Generación del modelo de árbol de decision\ntree_model = DecisionTreeClassifier(random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:30.420775Z","iopub.execute_input":"2021-06-12T06:44:30.421176Z","iopub.status.idle":"2021-06-12T06:44:30.430827Z","shell.execute_reply.started":"2021-06-12T06:44:30.421145Z","shell.execute_reply":"2021-06-12T06:44:30.429808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## *5.1 Breast cancer Winsconsin*","metadata":{}},{"cell_type":"markdown","source":"Para empezar generamos los distintos discretizadores que aplicaremos al modelo de árbol de decisión. Como hemos mencionado en el análisis exploratorio utilizaremos 2 intervalos y probaremos todas las estrategias al no tener claro del todo cual hay que utilizar.","metadata":{}},{"cell_type":"code","source":"discretizerUWinsconsin = KBinsDiscretizer(n_bins=2, strategy=\"uniform\")\ndiscretizerQWinsconsin = KBinsDiscretizer(n_bins=2, strategy=\"quantile\")\ndiscretizerKWinsconsin = KBinsDiscretizer(n_bins=2, strategy=\"kmeans\")\n","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:30.432188Z","iopub.execute_input":"2021-06-12T06:44:30.432786Z","iopub.status.idle":"2021-06-12T06:44:30.441088Z","shell.execute_reply.started":"2021-06-12T06:44:30.432733Z","shell.execute_reply":"2021-06-12T06:44:30.440355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A continuación le aplicaremos al modelo de árbol de decisión el estimador con el preprocesamiento que hemos desarrolado en el apartado anterior. No se lo aplicamos al modelo zeroR porque no le afectaria. Tambien le aplicamos el estimador al árbol de decisión discretizado con 2 intervalos y todas las posibles estrategias de discretización.","metadata":{}},{"cell_type":"code","source":"\n#Modelo de árbol de decisón con eliminación de variables predictoras muy relacionadas\npreprocess_treemodel_Winsconsin=make_pipeline(preproceserWinsconsin, tree_model)\n\n#Modelo de árbol de decisión con tres tipos de discretizaciones y con eliminación\n# de variable predictoras muy relacionadas\npreprocess_treemodel_discretizeU_Winsconsin=make_pipeline(preproceserWinsconsin,discretizerUWinsconsin,tree_model)\npreprocess_treemodel_discretizeQ_Winsconsin=make_pipeline(preproceserWinsconsin,discretizerQWinsconsin,tree_model)\npreprocess_treemodel_discretizeK_Winsconsin=make_pipeline(preproceserWinsconsin,discretizerKWinsconsin,tree_model)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:30.442264Z","iopub.execute_input":"2021-06-12T06:44:30.442512Z","iopub.status.idle":"2021-06-12T06:44:30.451439Z","shell.execute_reply.started":"2021-06-12T06:44:30.442489Z","shell.execute_reply":"2021-06-12T06:44:30.450289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finalmente hemos generado cuatro pipelines extra, que son las mismas cuatro pipelines anteriores pero añadiéndoles un estimador que elimina outliers. Este estimador lo hemos añadido en cuatro pipelines extra aparte en vez de integrarlo todo junto porque sabemos que el proceso de eliminación de outliers puede generar sobreajuste y empeorar los resultados de la evaluación; por lo tanto vamos a evaluar tanto las pipelines sin eliminación de outliers como las que si que lo hacen y comparar los resultados obtenidos en el siguiente apartado.","metadata":{}},{"cell_type":"code","source":"\n#Modelo de árbol de decisón con eliminación de variables predictoras muy relacionadas \n#eliminación de outliers\nextra_preprocess_treemodel_Winsconsin=make_pipeline(OutlierRejection, preproceserWinsconsin, tree_model)\n\n#Modelo de árbol de decisión con tres tipos de discretizaciones y con eliminación\n# de variable predictoras muy relacionadas y eliminación de outliers\nextra_preprocess_treemodel_discretizeU_Winsconsin=make_pipeline(preproceserWinsconsin,OutlierRejection,discretizerUWinsconsin,tree_model)\nextra_preprocess_treemodel_discretizeQ_Winsconsin=make_pipeline(preproceserWinsconsin,OutlierRejection,discretizerQWinsconsin,tree_model)\nextra_preprocess_treemodel_discretizeK_Winsconsin=make_pipeline(preproceserWinsconsin,OutlierRejection,discretizerKWinsconsin,tree_model)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:30.452863Z","iopub.execute_input":"2021-06-12T06:44:30.453513Z","iopub.status.idle":"2021-06-12T06:44:30.464254Z","shell.execute_reply.started":"2021-06-12T06:44:30.453471Z","shell.execute_reply":"2021-06-12T06:44:30.463411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## *5.2 Pima Indians diabetes*","metadata":{}},{"cell_type":"markdown","source":"Para empezar generamos los distintos discretizadores que aplicaremos al modelo de árbol de decisión. Como hemos mencionado en el análisis exploratorio utilizaremos 3 intervalos y probaremos todas las estrategias al no tener claro del todo cual hay que utilizar","metadata":{}},{"cell_type":"code","source":"discretizerUDiabetes = KBinsDiscretizer(n_bins=3, strategy=\"uniform\")\ndiscretizerQDiabetes = KBinsDiscretizer(n_bins=3, strategy=\"quantile\")\ndiscretizerKDiabetes = KBinsDiscretizer(n_bins=3, strategy=\"kmeans\")","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:30.465947Z","iopub.execute_input":"2021-06-12T06:44:30.466583Z","iopub.status.idle":"2021-06-12T06:44:30.476069Z","shell.execute_reply.started":"2021-06-12T06:44:30.466541Z","shell.execute_reply":"2021-06-12T06:44:30.475173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A continuación le aplicaremos al modelo de árbol de decisión el estimador con el preprocesamiento que hemos desarrolado en el apartado anterior. No se lo aplicamos al modelo zeroR porque no le afectaria. Tambien le aplicamos el estimador al árbol de decisión discretizado con 3 intervalos y todas las posibles estrategias de discretización.","metadata":{}},{"cell_type":"code","source":"#Modelo de árbol de decisión con sustitución de ceros\npreprocess_treemodel_Diabetes=make_pipeline(preproceserDiabetes, tree_model)\n\n#Modelo de árbol de decisión con tres tipos de discretizaciones y sustitución de ceros\npreprocess_treemodel_discretizeU_Diabetes=make_pipeline(preproceserDiabetes,discretizerUDiabetes,tree_model)\npreprocess_treemodel_discretizeQ_Diabetes=make_pipeline(preproceserDiabetes,discretizerQDiabetes,tree_model)\npreprocess_treemodel_discretizeK_Diabetes=make_pipeline(preproceserDiabetes,discretizerKDiabetes,tree_model)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:30.477581Z","iopub.execute_input":"2021-06-12T06:44:30.477934Z","iopub.status.idle":"2021-06-12T06:44:30.485966Z","shell.execute_reply.started":"2021-06-12T06:44:30.477905Z","shell.execute_reply":"2021-06-12T06:44:30.485051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finalmente hemos generado cuatro pipelines extra, que son las mismas cuatro pipelines anteriores pero añadiéndoles un estimador que elimina outliers. Este estimador lo hemos añadido en cuatro pipelines extra aparte en vez de integrarlo todo junto porque sabemos que el proceso de eliminación de outliers puede generar sobreajuste y empeorar los resultados de la evaluación; por lo tanto vamos a evaluar tanto las pipelines sin eliminación de outliers como las que si que lo hacen y comparar los resultados obtenidos en el siguiente apartado.","metadata":{}},{"cell_type":"code","source":"\n#Modelo de árbol de decisión con sustitución de ceros y eliminación de outliers\nextra_preprocess_treemodel_Diabetes=make_pipeline(preproceserDiabetes,OutlierRejection, tree_model)\n\n#Modelo de árbol de decisión con tres tipos de discretizaciones, sustitución de ceros y eliminación de outliers\nextra_preprocess_treemodel_discretizeU_Diabetes=make_pipeline(preproceserDiabetes,OutlierRejection,discretizerUDiabetes,tree_model)\nextra_preprocess_treemodel_discretizeQ_Diabetes=make_pipeline(preproceserDiabetes,OutlierRejection,discretizerQDiabetes,tree_model)\nextra_preprocess_treemodel_discretizeK_Diabetes=make_pipeline(preproceserDiabetes,OutlierRejection,discretizerKDiabetes,tree_model)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:30.486891Z","iopub.execute_input":"2021-06-12T06:44:30.48714Z","iopub.status.idle":"2021-06-12T06:44:30.498651Z","shell.execute_reply.started":"2021-06-12T06:44:30.487116Z","shell.execute_reply":"2021-06-12T06:44:30.49785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. Evaluacion de modelos","metadata":{}},{"cell_type":"markdown","source":"El proceso de evaluación de modelos lo realizaremos siguiendo los siguientes pasos para cada uno de los subapartados de la evaluación (uno para cada uno de las bases de datos que hemos tratado):\n1. Mencion de la métrica que utilizaremos para elegir el mejor modelo de los evaluados, que dependerá de la naturaleza del problema del que trata la base de datos que utilicemos\n2. Mostrar el resultado de la evaluación sobre el conjunto de datos correspondiente de los modelos que usan los algoritmos ZeroR y el árbol de decisión sin inclusión de estimadores extra, el resultado de la evaluación sobre el conjunto de datos correspondiente de la pipeline resultado de aplicarle al árbol de decisión el preprocesamiento básico del conjunto de datos correspondiente y otras tres pipelines que le aplican al árbol de decisón las tres tipos de discretizaciones mencionadas anteriormente y el preprocesamiento básico; y finalmente el resultado de la evaluación sobre el conjunto de datos corresponidente de las últimas 4 pipelines añadiéndoles un estimador de eliminación de outliers. La evalución se realizará utilizando la función del fichero de utilidad utils EvaluationWClassRepo\n3. Redacción de una pequeña conclusión que resuma los resultados obtenidos y los detalles más importantes de estos.","metadata":{}},{"cell_type":"markdown","source":"## *6.1 Breast cancer Winsconsin*","metadata":{}},{"cell_type":"markdown","source":"Teniendo en cuenta que la base de datos Breast cancer winsconsin surge de un problema médico y por ello, la métrica normalmente utilizada para estos problemas es el recall o tasa de verdaderos positivos, es la que tendremos que que emplear para la evaluación. Dicha tasa la podemos ver en la estructura classsification report que generará el método EvalutationWClassRepo. \nFinalmente, al utilizarse la base de datos para predecir el resultado del análisis de una masa mamaria, consideraremos que dicho análisis da positivo si el diagnóstico es maligno,es decir; la tasa de veraderos positivos se observará teniendo en cuenta que un positivo quiere decir que la masa mamaria es maligna.","metadata":{}},{"cell_type":"markdown","source":"> ### *Modelos sin preprocesamiento*","metadata":{}},{"cell_type":"code","source":"utils.EvaluationWClassRepo(zero_r_model,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:30.499837Z","iopub.execute_input":"2021-06-12T06:44:30.500318Z","iopub.status.idle":"2021-06-12T06:44:30.673933Z","shell.execute_reply.started":"2021-06-12T06:44:30.500227Z","shell.execute_reply":"2021-06-12T06:44:30.672869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"utils.EvaluationWClassRepo(tree_model,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:30.674897Z","iopub.execute_input":"2021-06-12T06:44:30.675135Z","iopub.status.idle":"2021-06-12T06:44:30.845666Z","shell.execute_reply.started":"2021-06-12T06:44:30.675112Z","shell.execute_reply":"2021-06-12T06:44:30.844471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ### *Modelos con el preprocesamiento desarrollado anteriormente*","metadata":{}},{"cell_type":"code","source":"utils.EvaluationWClassRepo(preprocess_treemodel_Winsconsin,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:30.847143Z","iopub.execute_input":"2021-06-12T06:44:30.847545Z","iopub.status.idle":"2021-06-12T06:44:31.17845Z","shell.execute_reply.started":"2021-06-12T06:44:30.847506Z","shell.execute_reply":"2021-06-12T06:44:31.177738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"utils.EvaluationWClassRepo(preprocess_treemodel_discretizeU_Winsconsin,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:31.17959Z","iopub.execute_input":"2021-06-12T06:44:31.179904Z","iopub.status.idle":"2021-06-12T06:44:31.389571Z","shell.execute_reply.started":"2021-06-12T06:44:31.179876Z","shell.execute_reply":"2021-06-12T06:44:31.388574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"utils.EvaluationWClassRepo(preprocess_treemodel_discretizeQ_Winsconsin,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:31.390669Z","iopub.execute_input":"2021-06-12T06:44:31.390919Z","iopub.status.idle":"2021-06-12T06:44:31.595056Z","shell.execute_reply.started":"2021-06-12T06:44:31.390894Z","shell.execute_reply":"2021-06-12T06:44:31.594225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"utils.EvaluationWClassRepo(preprocess_treemodel_discretizeK_Winsconsin,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:31.596503Z","iopub.execute_input":"2021-06-12T06:44:31.596913Z","iopub.status.idle":"2021-06-12T06:44:31.843507Z","shell.execute_reply.started":"2021-06-12T06:44:31.596869Z","shell.execute_reply":"2021-06-12T06:44:31.842773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ### *Modelos con el preprocesamiento extra*","metadata":{}},{"cell_type":"code","source":"utils.EvaluationWClassRepo(extra_preprocess_treemodel_Winsconsin,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:31.84479Z","iopub.execute_input":"2021-06-12T06:44:31.845349Z","iopub.status.idle":"2021-06-12T06:44:32.283458Z","shell.execute_reply.started":"2021-06-12T06:44:31.845305Z","shell.execute_reply":"2021-06-12T06:44:32.282673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"utils.EvaluationWClassRepo(extra_preprocess_treemodel_discretizeU_Winsconsin,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:32.284576Z","iopub.execute_input":"2021-06-12T06:44:32.284842Z","iopub.status.idle":"2021-06-12T06:44:32.711674Z","shell.execute_reply.started":"2021-06-12T06:44:32.284816Z","shell.execute_reply":"2021-06-12T06:44:32.710779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"utils.EvaluationWClassRepo(extra_preprocess_treemodel_discretizeQ_Winsconsin,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:32.712784Z","iopub.execute_input":"2021-06-12T06:44:32.713033Z","iopub.status.idle":"2021-06-12T06:44:33.151478Z","shell.execute_reply.started":"2021-06-12T06:44:32.713008Z","shell.execute_reply":"2021-06-12T06:44:33.150528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"utils.EvaluationWClassRepo(extra_preprocess_treemodel_discretizeK_Winsconsin,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:33.153577Z","iopub.execute_input":"2021-06-12T06:44:33.153969Z","iopub.status.idle":"2021-06-12T06:44:33.660778Z","shell.execute_reply.started":"2021-06-12T06:44:33.153925Z","shell.execute_reply":"2021-06-12T06:44:33.659918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ### *Conclusiones*","metadata":{}},{"cell_type":"markdown","source":"Las conclusiones que hemos obtenido tras analizar los resultados de la evaluación de modelos son las siguientes:\n* Los dos mejores modelos son el modelo del árbol de decisión con el preprocesamiento básico y con discretización de igual frecuencia y el modelo del árbol de decisión con el preprocesamiento extra y con una discretización de igual frecuencia. Ambos tienen una tasa de verdaderos positivos del 0.92.\n* Si tenemos en cuenta la tasa de verdaderos positivos media (La media de la tasa de verdaderos positivos para positivo benigneo y positivo maligno), el mejor modelo sería el árbol de decisión con el preprocesamiento extra y con una discretización de igual frecuencia, con un tasa de verdaderos positivos media del 0.93.\n* En general hemos obtenido una tasa de verdaderos positivos alta para todos nuestros modelos (el más bajo sin contar el modelo ZeroR ha sido 0.64, que pertenece al modelo del árbol de decisión con el preprocesamiento básico y con una discretización de igual anchura).\n* El preprocesamiento extra,la eliminación de outliers, es posible que haya sobreajustado la mayoria de modelos generados para este conjunto de datos con este preprocesamiento, ya que los modelos que han eliminado outliers han tenido peores resultados que su contraparte sin eliminación de outliers(o iguales en el caso del modelo del árbol de decisión con preprocesamiento extra y con una discretización de igual frecuencia).\n* La mejor discretización para el modelo de árboles de decisión es la de igual frecuencia, eliminado o no outliers, teniendo ambos una tasa de verdaderos positivos del 0.92.","metadata":{}},{"cell_type":"markdown","source":"## *6.2 Pima Indians diabetes*","metadata":{}},{"cell_type":"markdown","source":"Teniendo en cuenta que la base de datos Pima Indians diabetes surge de un problema médico y por ello, la métrica normalmente utilizada para estos problemas es la que tendremos que emplear para la evaluación, el recall o tasa de verdaderos positivos. Dicha tasa la podemos ver en la estructura classsification report que generará el método EvalutationWClassRepo. \nFinalmente, al utilizarse la base de datos para predecir de forma diagnóstica si un paciente tiene diabete o no, consideraremos que dicho análisis da positivo si la variable objetivo Outcome tiene el valor 1, es decir; la tasa de verdaderos positivos se observará teniendo en cuenta que un positivo quiere decir que el paciente tiene diabetes.","metadata":{}},{"cell_type":"markdown","source":"> ### *Modelos sin preprocesamiento*","metadata":{}},{"cell_type":"code","source":"utils.EvaluationWClassRepo(zero_r_model,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:33.661914Z","iopub.execute_input":"2021-06-12T06:44:33.662178Z","iopub.status.idle":"2021-06-12T06:44:33.835608Z","shell.execute_reply.started":"2021-06-12T06:44:33.662153Z","shell.execute_reply":"2021-06-12T06:44:33.834682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"utils.EvaluationWClassRepo(tree_model,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:33.837006Z","iopub.execute_input":"2021-06-12T06:44:33.837273Z","iopub.status.idle":"2021-06-12T06:44:34.019818Z","shell.execute_reply.started":"2021-06-12T06:44:33.837245Z","shell.execute_reply":"2021-06-12T06:44:34.018811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ### *Modelos con el preprocesamiento desarrollado anteriormente*","metadata":{}},{"cell_type":"code","source":"utils.EvaluationWClassRepo(preprocess_treemodel_Diabetes,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:34.021157Z","iopub.execute_input":"2021-06-12T06:44:34.021521Z","iopub.status.idle":"2021-06-12T06:44:34.2219Z","shell.execute_reply.started":"2021-06-12T06:44:34.021479Z","shell.execute_reply":"2021-06-12T06:44:34.221165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"utils.EvaluationWClassRepo(preprocess_treemodel_discretizeU_Diabetes,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:34.223017Z","iopub.execute_input":"2021-06-12T06:44:34.223293Z","iopub.status.idle":"2021-06-12T06:44:34.42679Z","shell.execute_reply.started":"2021-06-12T06:44:34.223255Z","shell.execute_reply":"2021-06-12T06:44:34.425678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"utils.EvaluationWClassRepo(preprocess_treemodel_discretizeQ_Diabetes,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:34.428279Z","iopub.execute_input":"2021-06-12T06:44:34.42859Z","iopub.status.idle":"2021-06-12T06:44:34.652945Z","shell.execute_reply.started":"2021-06-12T06:44:34.428558Z","shell.execute_reply":"2021-06-12T06:44:34.651977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"utils.EvaluationWClassRepo(preprocess_treemodel_discretizeK_Diabetes,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:34.654063Z","iopub.execute_input":"2021-06-12T06:44:34.654311Z","iopub.status.idle":"2021-06-12T06:44:34.871102Z","shell.execute_reply.started":"2021-06-12T06:44:34.654288Z","shell.execute_reply":"2021-06-12T06:44:34.869958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ### *Modelos con el preprocesamiento extra*","metadata":{}},{"cell_type":"code","source":"utils.EvaluationWClassRepo(extra_preprocess_treemodel_Diabetes,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:34.87255Z","iopub.execute_input":"2021-06-12T06:44:34.87291Z","iopub.status.idle":"2021-06-12T06:44:35.311519Z","shell.execute_reply.started":"2021-06-12T06:44:34.872872Z","shell.execute_reply":"2021-06-12T06:44:35.310618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"utils.EvaluationWClassRepo(extra_preprocess_treemodel_discretizeU_Diabetes,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:35.313573Z","iopub.execute_input":"2021-06-12T06:44:35.31396Z","iopub.status.idle":"2021-06-12T06:44:35.753868Z","shell.execute_reply.started":"2021-06-12T06:44:35.31392Z","shell.execute_reply":"2021-06-12T06:44:35.753009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"utils.EvaluationWClassRepo(extra_preprocess_treemodel_discretizeQ_Diabetes,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:35.75496Z","iopub.execute_input":"2021-06-12T06:44:35.755223Z","iopub.status.idle":"2021-06-12T06:44:36.206823Z","shell.execute_reply.started":"2021-06-12T06:44:35.755189Z","shell.execute_reply":"2021-06-12T06:44:36.205943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"utils.EvaluationWClassRepo(extra_preprocess_treemodel_discretizeK_Diabetes,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T06:44:36.207872Z","iopub.execute_input":"2021-06-12T06:44:36.20815Z","iopub.status.idle":"2021-06-12T06:44:36.665893Z","shell.execute_reply.started":"2021-06-12T06:44:36.208126Z","shell.execute_reply":"2021-06-12T06:44:36.664981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ### *Conclusiones*","metadata":{}},{"cell_type":"markdown","source":"Las conclusiones que hemos obtenido tras analizar los resultados de la evaluación de modelos son las siguientes:\n* El mejor modelo que hemos obtenido ha sido el modelo del árbol de decisión sin discretización y con el preprocesamiento básico con una tasa de verdaderos positivos de 0.62.\n* Si tenemos en cuenta la tasa de verdaderos positivos media (La media de la tasa de verdaderos positivos para positivo de diabetes y positivo de que no tenga diabetes), el mejor modelo es el del árbol de decisión con el preprocesamiento básico y con una discretización basada en igual anchura, pues su tasa de verdaderos positivos media es de 0,71.\n* En general la tasa de veraderos positivos que hemos obtenidos de todos los modelos es bastante baja, siendo la más alta 0.62 y la más baja (sin tener en cuenta la del modelo ZeroR) ha sido 0,44; siendo esta a la vez la tasa de verdaderos positivos del modelo del árbol de decisión con el preprocesamiento básico y con una discretización basada en k-medias y la del modelo del árbol de decisión con el preprocesamiento extra y con una discretización basada en igual anchura.\n* La eliminación de outliers ha podido sobreajustar parte de los modelos que usaban el preprocesamiento extra, ya que en la mayoría de estos modelos se han obtenido peores resultados para la tasa de verdaderos positivos con respecto al mismo modelo con el preprocesamiento básico, siendo una excepción el modelo  de árbol de decisión con discretización basado en K medians cuya tasas de verdaderos positivos es 0.46 cuando se eliminan outliers y 0.44 sin la eliminación de outliers.\n* En el caso de la discretización, lo más recomendable es no realizar una discretización a este conjunto de datos si usamos como modelo un árbol de decisión, sin embargo la discretización que mejores resultados ha dado sin eliminación de outliers es la de igual frecuencia (con una tasa de verdaderos positivos de 0.59) y con eliminación de outliers es la basada en K medians (con una tasa de verdaderos positivos de 0.46). No obstante; están ambas por debajo del modelo del árbol de decisión sin discretizar con o sin eliminación de outliers (pero como mínimo con el preprocesamiento básico).\n","metadata":{}}]}