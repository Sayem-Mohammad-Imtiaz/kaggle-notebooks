{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nfrom sklearn.preprocessing import LabelEncoder\n\n\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/loan-prediction-problem-dataset/train_u6lujuX_CVtuZ9i.csv')\ndf.drop('Loan_ID',axis=1, inplace = True)\ndf['Credit_History'] = df['Credit_History'].astype('O')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Exploratory data analysis**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.duplicated().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\nsns.countplot(df['Loan_Status'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.select_dtypes('O').columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid = sns.FacetGrid(df, col = 'Loan_Status', size = 3.2, aspect = 1.6)\ngrid.map(sns.countplot, 'Gender')\n#most male got loan and male got higher chance to got loan than female\n#more male asked for loan too","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.patches as mpatches\n\nfig, axes = plt.subplots(2,1,sharex= True )\n\naxes[0].barh([0],[len(df[(df['Gender'] == 'Female') & (df['Loan_Status'] == 'Y')])], color = '#b5ffb9', edgecolor='white')\naxes[0].barh([0],[(df.Gender == 'Female').sum()- len(df[(df['Gender'] == 'Female') & (df['Loan_Status'] == 'Y')])],\n         left = [len(df[(df['Gender'] == 'Female') & (df['Loan_Status'] == 'Y')])],color = '#f9bc86', edgecolor='white')\n\n\nleg1 = mpatches.Patch (color = '#b5ffb9', label= 'Y')\nleg2 = mpatches.Patch (color = '#f9bc86', label = 'N')\naxes[0].legend(handles = [leg1,leg2], title = 'Loan Status')\naxes[0].text(5,0, str(np.round(len(df[(df['Gender'] == 'Female') & (df['Loan_Status'] == 'Y')])/(df.Gender == 'Female').sum()*100,2)) +str('%'), fontsize = 12)\naxes[0].text(80,0, str(np.round(len(df[(df['Gender'] == 'Female') & (df['Loan_Status'] == 'N')])/(df.Gender == 'Female').sum()*100,2)) +str('%'), fontsize = 12)\n#axes[0].axes.get_yaxis().set_visible(False)\naxes[0].set_ylabel('Female')\naxes[1].barh([0],[len(df[(df['Gender'] == 'Male') & (df['Loan_Status'] == 'Y')])], color = '#b5ffb9', edgecolor='white')\naxes[1].barh([0],[(df.Gender == 'Male').sum()- len(df[(df['Gender'] == 'Male') & (df['Loan_Status'] == 'Y')])],\n         left = [len(df[(df['Gender'] == 'Male') & (df['Loan_Status'] == 'Y')])],color = '#f9bc86', edgecolor='white')\naxes[1].set_ylabel('Female')\naxes[1].text(200,0, str(np.round(len(df[(df['Gender'] == 'Male') & (df['Loan_Status'] == 'Y')])/(df.Gender == 'Male').sum()*100,2)) +str('%'), fontsize = 12)\naxes[1].text(390,0, str(np.round(len(df[(df['Gender'] == 'Male') & (df['Loan_Status'] == 'N')])/(df.Gender == 'Male').sum()*100,2)) +str('%'), fontsize = 12)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid = sns.FacetGrid(df, col = 'Loan_Status', size = 3.2, aspect = 1.6)\ngrid.map(sns.countplot, 'Dependents')\n\n#if Loan_Status is 1, peole got higher chance to got rejected for a a loan\n# when Loan_Status = +3, people got higher chance to get a loan\n# when Loan_Status = 1, people got the highest chance to get a loan","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid = sns.FacetGrid(df, col = 'Loan_Status', size = 3.2, aspect = 1.6)\ngrid.map(sns.countplot, 'Married')\n\n#if you are married, you got a lower chance to get a loan","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid = sns.FacetGrid(df, col = 'Loan_Status',size=3.2, aspect = 1.6)\ngrid.map(sns.countplot, 'Education')\n\n# most graduate student got a loan (p)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid = sns.FacetGrid (df, col = 'Loan_Status', size=3.2, aspect = 1.6)\ngrid.map(sns.countplot,'Self_Employed')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid = sns.FacetGrid (df, col = 'Loan_Status', size = 3.2, aspect=1.6)\ngrid.map(sns.countplot, 'Credit_History')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid = sns.FacetGrid (df, col = 'Loan_Status', size = 3.2, aspect = 1.6)\ngrid.map(sns.countplot, 'Property_Area')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Built-in fucntion**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"In this data set, I gonna implement models such as *Logistic Regression, K NeighborsClassifier, Support Vector Machine, Decision Tree Classifier*.\nAll of these models will be evaluated on *Precision score, recall score, f1, log loss and accuracy*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import StratifiedKFold\n\nmodels = {\n    \"Logistic Regression\" : LogisticRegression(random_state = 42),\n    \"K Neighbors Classifier\": KNeighborsClassifier(),\n    \"SVC\" : SVC(random_state=42),\n    \"DecisionTreeClassifier\" : DecisionTreeClassifier(max_depth=1, random_state=42)\n}\nfrom sklearn.metrics import precision_score, recall_score, f1_score, log_loss, accuracy_score\n#(y_true, y_pred)\ndef check_result (y_true, y_pred):\n    pre = precision_score(y_true,y_pred)\n    rec = recall_score(y_true, y_pred)\n    f1  = f1_score(y_true, y_pred)\n    log = log_loss(y_true, y_pred)\n    acc = accuracy_score (y_true, y_pred)\n    return pre, rec, f1, log, acc\n\n\n\ndef implement_model (X,y, models ):\n    skt=StratifiedKFold(n_splits = 10, random_state =42, shuffle = True)\n    for name, model in models.items():\n        ls=[]\n        title_name=['pre', 'rec', 'f1', 'log', 'acc']\n        for train, test in skt.split(X,y):\n            model.fit(X.iloc[train],y.iloc[train])\n            y_pred = model.predict(X.iloc[test])\n            ls.append(check_result(y.iloc[test],y_pred))\n        print(name + ' : ')\n        print(pd.DataFrame(ls, columns= title_name).mean(axis=0))\n        print('-'*30)\n    \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Cleaning cate data by most popular value and numerical data by mean**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum().sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop Loan_ID\ntest=df.copy()\n\n#Put two different category of data types into list\ncate_col = [col for col in test.columns if test[col].dtypes == 'O']\nnum_col = [col for col in test.columns if test[col].dtype in ['int64','float64']]\n\n#replace numerical missing data by mean()\nfor col in num_col:\n    test[col] = test[col].fillna(test[col].mean())\n    \n#replace categorical missing data by most popular\nfor col in cate_col:\n    test[col] = test[col].fillna(value = test[col].value_counts().index[0])\n\n#label encode Categorical data\nle = LabelEncoder()\nfor col in cate_col:\n    test[col] = le.fit_transform(test[col])\n    \ny=test['Loan_Status']\nX=test.drop('Loan_Status',axis = 1)\n    \nimplement_model(X,y,models)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Cleaning cate data by most popular and use OneHot for cate with more than 2 unique value**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"In this step, I repeat the same as above but Categorical columns with higher than 2 unique values will be labeled by One Hot Encoder","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop Loan_ID\ntest=df.copy()\n\ncate_col = [col for col in test.columns if test[col].dtypes == 'O']\nnum_col = [col for col in test.columns if test[col].dtype in ['int64','float64']]\n\n#replace numerical missing data by mean()\nfor col in num_col:\n    test[col] = test[col].fillna(test[col].mean())\n#replace categorical missing data by most popular\nfor col in cate_col:\n    test[col] = test[col].fillna(value = test[col].value_counts().index[0])\n    \nle = LabelEncoder()\nfor col in [col for col in cate_col if col not in ['Property_Area', 'Dependents']]:\n    test[col] = le.fit_transform(test[col])\n\nfrom sklearn.preprocessing import OneHotEncoder\nOH_encoder = OneHotEncoder(handle_unknown = 'ignore',sparse = False)\nOH_cols_train = pd.DataFrame(OH_encoder.fit_transform(test[['Property_Area','Dependents']]))\n\ntest.drop(['Property_Area','Dependents'],axis=1,inplace=True)\n\ndf_final = pd.concat([test, OH_cols_train],axis=1)\n\ny=df_final['Loan_Status']\nX=df_final.drop('Loan_Status',axis = 1)\n    \nimplement_model(X,y,models)\n\n\n\n#One hot encoder give a slightly more positive to our result so I will keep this method","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create 2 columns : \n1. % of Co-Ap Income comparing with Ap Income (CoapplicantIncome / ApplicantIncome)\n2. Total Loan Amount over the term (LoanAmiybt * Loan_Amount_Term)\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop Loan_ID\ntest=df.copy()\n\ncate_col = [col for col in test.columns if test[col].dtypes == 'O']\nnum_col = [col for col in test.columns if test[col].dtype in ['int64','float64']]\n\n#replace numerical missing data by mean()\nfor col in num_col:\n    test[col] = test[col].fillna(test[col].mean())\n#replace categorical missing data by most popular\nfor col in cate_col:\n    test[col] = test[col].fillna(value = test[col].value_counts().index[0])\n    \nle = LabelEncoder()\nfor col in [col for col in cate_col if col not in ['Property_Area', 'Dependents']]:\n    test[col] = le.fit_transform(test[col])\n\ntest['%_of_App_Coapp'] = test['CoapplicantIncome'] / test['ApplicantIncome']\ntest['Total_loan'] = test['LoanAmount'] * test['Loan_Amount_Term']\n\n\nfig, ax = plt.subplots (1,2, figsize=(15,5))\nfig.tight_layout(pad=5.0)\na=test[['CoapplicantIncome','ApplicantIncome', 'LoanAmount', 'Loan_Amount_Term','Loan_Status']].corr()\nsns.heatmap(a, annot = True, ax = ax[0])\nax[0].set_title('Correlation of original columns')\n\nb=test[['%_of_App_Coapp','Total_loan', 'Loan_Status']].corr()\nsns.heatmap(b, annot = True, ax = ax[1])\nax[1].set_title('Correlation of new columns')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#New columns give better correlation with the Loan Status, therefore we gonna drop old columns\n\ntest.drop(['CoapplicantIncome', 'ApplicantIncome', 'LoanAmount','Loan_Amount_Term'],axis = 1,inplace=True)\n\nfrom sklearn.preprocessing import OneHotEncoder\nOH_encoder = OneHotEncoder(handle_unknown = 'ignore',sparse = False)\nOH_cols_train = pd.DataFrame(OH_encoder.fit_transform(test[['Property_Area','Dependents']]))\ntest.drop(['Property_Area','Dependents'],axis=1,inplace=True)\ntest = pd.concat([test, OH_cols_train],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import norm\n\nfig, ax = plt.subplots (2,2, figsize=(10,7))\nfig.tight_layout(pad=5.0)\n\nsns.distplot(test['Total_loan'], ax=ax[0,0], fit=norm)\nax[0,0].set_title('new_col_2_before log')\n\ntest['New_total_2'] = np.log(test['Total_loan'])\nsns.distplot(test['New_total_2'], ax=ax[0,1],fit=norm)\nax[0,1].set_title('New_col_after_log')\n\nsns.boxplot(test['New_total_2'],ax=ax[1,0])\nax[1,0].set_title('Dispersion of new col after log')\n\nthreshold = 0.1\nq25, q75 = np.percentile(test['New_total_2'],25), np.percentile(test['New_total_2'],75)\niqr = q75 - q25\ncut = iqr * threshold\nlower, upper = q25 - cut, q75 + cut\nsns.boxplot(test[test['New_total_2']>lower][test['New_total_2']<upper]['New_total_2'], ax = ax[1,1])\nax[1,1].set_title('Dispersion of new col after log and drop outliner')\ntest=test[test['New_total_2']>lower][test['New_total_2']<upper]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax =plt.subplots(1,2, figsize =(10,5))\nsns.distplot(test['%_of_App_Coapp'],ax= ax[0])\n\ntest['Bool_new_column']=(test['%_of_App_Coapp']==0).astype(int)\nsns.distplot(test['Bool_new_column'],ax= ax[1])\n\n\n#most of data equal to 0 so I put it into bool type","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1,2, figsize = (15,5))\na=test[['Total_loan','%_of_App_Coapp','Loan_Status']].corr()\nsns.heatmap(a , ax=axes[0], annot = True)\naxes[0].set_label('Not preprocessing 2 columns')\n\nb=test[['New_total_2','Bool_new_column','Loan_Status']].corr()\nsns.heatmap(b , ax = axes[1], annot = True)\naxes[1].set_label('After preprocessing 2 columns')\n\n\n\n#Our feature engineers on two new columns has a higher correlation with Loan Status","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.drop(['%_of_App_Coapp','Total_loan'],axis=1,inplace=True)\nX=test.drop('Loan_Status',axis=1)\ny=test['Loan_Status']\nimplement_model(X,y,models)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**By this step, I input the test data and make prediction on it**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = pd.read_csv('../input/loan-prediction-problem-dataset/test_Y3wMUE5_7gLdaTN.csv')\ndf1.drop('Loan_ID',axis=1, inplace = True)\ndf1['Credit_History'] = df1['Credit_History'].astype('O')\ncate_col = [col for col in df1.columns if df1[col].dtypes == 'O']\nnum_col = [col for col in df1.columns if df1[col].dtype in ['int64','float64']]\n\n#replace numerical missing data by mean()\nfor col in num_col:\n    df1[col] = df1[col].fillna(df1[col].mean())\n#replace categorical missing data by most popular\nfor col in cate_col:\n    df1[col] = df1[col].fillna(value = df1[col].value_counts().index[0])\n    \nle = LabelEncoder()\nfor col in [col for col in cate_col if col not in ['Property_Area', 'Dependents']]:\n    df1[col] = le.fit_transform(df1[col])\n\n\nfrom sklearn.preprocessing import OneHotEncoder\nOH_encoder = OneHotEncoder(handle_unknown = 'ignore',sparse = False)\nOH_cols_train = pd.DataFrame(OH_encoder.fit_transform(df1[['Property_Area','Dependents']]))\ndf1.drop(['Property_Area','Dependents'],axis=1,inplace=True)\n\ndf1 = pd.concat([df1, OH_cols_train],axis=1)\n\ndf1['%_of_App_Coapp'] = df1['CoapplicantIncome'] / df1['ApplicantIncome']\ndf1['Total_loan'] = df1['LoanAmount'] * df1['Loan_Amount_Term']\ndf1['New_total_2'] = np.log(df1['Total_loan'])\ndf1.drop(['CoapplicantIncome', 'ApplicantIncome', 'LoanAmount','Loan_Amount_Term'],axis = 1,inplace=True)\nthreshold = 0.1\nq25, q75 = np.percentile(df1['New_total_2'],25), np.percentile(df1['New_total_2'],75)\niqr = q75 - q25\ncut = iqr * threshold\nlower, upper = q25 - cut, q75 + cut\n\ndf1=df1[df1['New_total_2']>lower][df1['New_total_2']<upper]\n\ndf1['Bool_new_column']=(df1['%_of_App_Coapp']==0).astype(int)\ndf1.drop(['%_of_App_Coapp','Total_loan'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1[:5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Make prediction","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Choose Logistic Regression as result in highest precision, recall, f1, accuracy, log\nmodel =  LogisticRegression(random_state = 42)\nmodel.fit(X,y)\nmodel.predict(df1)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}