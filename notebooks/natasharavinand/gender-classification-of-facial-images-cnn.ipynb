{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Gender Classification of Facial Images\n"},{"metadata":{},"cell_type":"markdown","source":"Gender classification of facial images is a very important topic. It can provide information on an individual's identity and background. Currently, it's used in many applications such as services in human-computer interaction, visual surveillance, security, and intelligent advertising.\n\nIn this notebook, I will be building a convolutional neural network (CNN) in order to classify images from a dataset as either being of a man or woman.\n\nThis notebook is based off of a Kaggle notebook [here](https://www.kaggle.com/thanaphatj/gender-classification-of-facial-images-cnn/?select=age_gender.csv)."},{"metadata":{},"cell_type":"markdown","source":"## Overview of Data\n\nThis data can be found on Kaggle [here](https://www.kaggle.com/thanaphatj/gender-classification-of-facial-images-cnn/?select=age_gender.csv). It includes information on:\n\n- age (from 1 to 116)\n- ethnicity (0: white, 1: Black, 2: Asian, 3: Indian, 4: other)\n- gender (0: man, 1: woman)\n- image name\n- pixel data\n"},{"metadata":{},"cell_type":"markdown","source":"## Data Exploration\n\nWe can begin by loading in the CSV file and doing some initial data exploration. This will help guide our preprocessing as well. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os # accessing directory structure\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt # plotting\n%matplotlib inline\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom  IPython.display import display\nimport plotly.express as px\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, experimental, MaxPool2D, BatchNormalization\nfrom tensorflow.keras.losses import sparse_categorical_crossentropy, binary_crossentropy\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau \nfrom tensorflow.data import Dataset\nfrom tensorflow.keras import Input, Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.random import set_seed\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow import test\nimport random\n\n# Set Seed\nnp.random.seed(11)\nset_seed(11)\nrandom.seed(11)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \ndata = pd.read_csv(\"/kaggle/input/age-gender-and-ethnicity-face-data-csv/age_gender.csv\")\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='age', data=data) #age distribution","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='gender', data=data) #gender distribution","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Preprocessing\n\nIn data preprocessing, we prepare the data to be fed into a machine or deep learning model. In our preprocessing, we'll do a few things:\n\n- Select only data with people who are adults\n  - We see the data is heavily representing younger people, which might skew our model. Thus, we'll only select adults to create a more equal distribution.\n\n- Format width and height of pixel data\n\n- Splitting into `X` and `y`"},{"metadata":{"trusted":true},"cell_type":"code","source":"# select adults\ndata = data[data['age'] >= 18]\nsns.countplot(x='age', data=data) #age distribution","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We now find that the age distribution is more even."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.reset_index(drop=True, inplace=True)\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum() # Check null data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We don't appear to have any null values. If we did, we'd have to explore options such as removal or imputing."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Input image configuration\nnum_pixels = len(data['pixels'][0].split(' '))\ndimension = int(np.sqrt(num_pixels))\nimg_width = dimension\nimg_height = dimension\n\nprint(\"Pixels: {}\".format(num_pixels))\nprint(\"Width: {0}, Height: {1}\".format(img_width, img_height))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting dataset into X and y\nX_img = data.iloc[:,4].copy()\ny_age = data.iloc[:,0].copy()\ny_ethnicity = data.iloc[:,1].copy()\ny_gender = data.iloc[:,2].copy()\n\n# splitting the data into train and te sets.\nX_train, X_te, y_train, y_te = train_test_split(X_img,y_gender,test_size=0.3,random_state=11)\n# splitting 'te' set into validation and test set\nX_val, X_test, y_val, y_test = train_test_split(X_te,y_te,test_size=0.15,random_state=11)\n\ndef str_to_npArr(x):\n    '''\n    Function to convert pixel data (string) into numpy_array of pixels\n    '''\n    x = x.reset_index(drop=True)\n    x = x.apply(lambda x: np.array(x.split(), dtype=\"float32\")) #converting data to numpy array\n    return np.array([x[i].reshape(img_width, img_height, 1) for i in range(x.shape[0])])\n\n# Converting the string of pixels into image array for each of train, val and test set and normalization\nX_train = str_to_npArr(X_train)\nX_test = str_to_npArr(X_test)\nX_val = str_to_npArr(X_val)\n\nprint(\"Target: shape = (16593, 48, 48, 1), type = <class 'numpy.ndarray'>\")\nprint(\"Current: shape = {}, type = {}\".format(X_train.shape, type(X_train)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_columns = ['gender', 'ethnicity', 'age']\n\ndata_preprocess = data.drop('img_name', axis=1)\ny = data_preprocess[target_columns]\nX = data_preprocess.drop(target_columns, axis=1)\n\nprint(X)\nprint(\"--------------------------------------------------------\")\nprint(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = X['pixels'].apply(lambda x: np.array(x.split(), dtype=\"float32\")) #converting data to numpy array\nX = np.array(X)/255.0 # normalization\nX = np.array([ X[i].reshape(48,48,1) for i in range(X.shape[0]) ]) # channel is 1\n\nprint(\"Traget: X Shape: {}\".format(X.shape))\nprint(\"Current: X Shape: {}\".format(X.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before we move onto data visualization, we'll convert the other `y`'s to numpy arrays."},{"metadata":{"trusted":true},"cell_type":"code","source":"y_gender = np.array(y['gender'])\ny_ethnicity = np.array(y['ethnicity'])\ny_age = np.array(y['age'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Data Visualization**"},{"metadata":{"trusted":true},"cell_type":"code","source":"rows = 10 # rows in subplots\ncols = 3 # columns in subplots\nsamp = random.sample(range(X.shape[0]),rows*cols) #selecting 100 random samples\nx_samp = X[samp,:,:,:]\ny_samp_gender = y_gender[samp]\ny_samp_age = y_age[samp]\n    \nfig,ax = plt.subplots(rows,cols,figsize=(16,60))\nr = 0\nc = 0   \n\nfor i in range(rows*cols):\n    aa = x_samp[i,:,:,:].reshape(48,48)\n    ax[r,c].axis(\"off\")\n    ax[r,c].imshow(aa,cmap=\"gray\")\n    ax[r,c].set_title(f\"Gender: {'Female' if y_samp_gender[i]==1 else 'Male'}, Age: {y_samp_age[i]}\")\n    c+=1\n    if c == cols:\n        c=0\n        r+=1\n        \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Image Augmentation**"},{"metadata":{},"cell_type":"markdown","source":"**Data augmentation**: a technique to increase the diversity of your training set by applying random (but realistic) transformations such as image rotation.\nThis code below shows 100 samples of Data augmentation. I've changed the values below to allow for a bit more variation within the `ImageDataGenerator`."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_gen = ImageDataGenerator(rotation_range=40,\n                                   width_shift_range=1,\n                                    brightness_range=[0.7,1.3],\n                                    zoom_range=[0.7,1.3],\n                                    rescale=1/255\n                                   )\nval_data_gen = ImageDataGenerator(rescale=1/255)\n\ntest_data_gen = ImageDataGenerator(rescale=1/255)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"set_seed(11)\nrandom.seed(11)\nnp.random.seed(11)\n\nval_data = val_data_gen.flow(X_val,y_val,\n                                   seed=11,shuffle=False)\n\ntest_data = test_data_gen.flow(X_test,y_test,\n                                   seed=11,shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(10,5,figsize=(15,25))\nfor n in range(10):    \n    r = random.sample(range(X.shape[0]),1)[0]\n    ax[n,0].imshow(X[r].reshape(48,48),cmap=\"gray\")\n    ax[n,0].set_title(\"Original\")\n    ax[n,0].axis(\"off\")\n    for i in range(1,5):\n        ax[n,i].imshow(train_data_gen.random_transform(X[r]).reshape(48,48),cmap=\"gray\")\n        ax[n,i].set_title(\"Augmented\")\n        ax[n,i].axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Training the Model**"},{"metadata":{},"cell_type":"markdown","source":"In the model, we'll use a batch size of 32 and 40 epochs. We'll also use `Adam` as our optimizer and `ReLU` as our activation function. We'll be doing k-fold cross validation, but I've changed k to equal 8."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model configuration\nbatch_size = 32\nimg_width, img_height, img_num_channels = 48, 48, 1\nloss_function = sparse_categorical_crossentropy\nno_classes = 2\nno_epochs = 30\noptimizer = Adam()\nverbosity = 1\nnum_folds = 8\nactivation='relu' #relu activation\n\n# Determine shape of the data\ninput_shape = (img_width, img_height, img_num_channels)\ninput_shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set Seed\nrandom.seed(11)\nset_seed(11)\nnp.random.seed(11)\n\n# Define the K-fold Cross Validator\nkfold = KFold(n_splits=num_folds, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define per-fold score containers\nacc_per_fold = []\nloss_per_fold = []\n\n# K-fold Cross Validation model evaluation\nfold_no = 1\nfor train, test in kfold.split(X, y_gender):\n    \n  # Set Seed\n  random.seed(11)\n  set_seed(11)\n  np.random.seed(11)\n  \n  # Define the model architecture\n  model = Sequential()\n  \n  model.add(Conv2D(32, kernel_size=(3,3), input_shape=input_shape, activation='relu'))\n  model.add(MaxPooling2D(pool_size=(2,2)))\n  model.add(BatchNormalization())\n\n  model.add(Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'))\n  model.add(Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'))\n  model.add(MaxPooling2D(pool_size=(2,2)))\n  model.add(Dropout(0.5)) # dropout 50%\n  model.add(BatchNormalization())\n\n  model.add(Conv2D(128, kernel_size=(3,3), activation='relu', padding='same'))\n  model.add(Conv2D(128, kernel_size=(3,3), activation='relu', padding='same'))\n  model.add(MaxPooling2D(pool_size=(2,2)))\n  model.add(Dropout(0.5)) # dropout 50%\n  model.add(BatchNormalization())\n\n  model.add(Conv2D(256, kernel_size=(3,3), activation='relu', padding='same'))\n  model.add(Conv2D(256, kernel_size=(3,3), activation='relu', padding='same'))\n  model.add(MaxPooling2D(pool_size=(2,2)))\n  model.add(Dropout(0.5)) # dropout 50%\n  model.add(BatchNormalization())\n    \n  model.add(Conv2D(512, kernel_size=(3,3), activation='relu', padding='same'))\n  model.add(Conv2D(512, kernel_size=(3,3), activation='relu', padding='same'))\n  model.add(MaxPooling2D(pool_size=(2,2)))\n  model.add(Dropout(0.5)) # dropout 50%\n  model.add(BatchNormalization())\n\n  model.add(Conv2D(256, kernel_size=(3,3), activation='relu', padding='same'))\n  model.add(Conv2D(256, kernel_size=(3,3), activation='relu', padding='same'))\n  model.add(MaxPooling2D(pool_size=(2,2)))\n  model.add(Dropout(0.5)) # dropout 50%\n  model.add(BatchNormalization())\n\n  model.add(Flatten())\n  model.add(Dense(128, activation='relu'))\n  model.add(Dense(128, activation='softmax'))\n\n  # Compile the model\n  model.compile(loss=loss_function,\n              optimizer=optimizer,\n              metrics=['accuracy'])\n  \n  # Generate a print\n  print('------------------------------------------------------------------------')\n  print(f'Training for fold {fold_no} ...')\n    \n  early_stop = EarlyStopping(monitor=\"val_loss\",patience=5,mode=\"min\") # Ensure the model doesn't overfit\n  \n  # Set Seed\n  random.seed(11)\n  set_seed(11)\n  np.random.seed(11)\n    \n  # Fit data to model\n  history = model.fit(train_data_gen.flow(X[train], y_gender[train], seed=11),\n            callbacks=early_stop,\n            batch_size=batch_size,\n            epochs=no_epochs,\n            verbose=verbosity,\n            validation_data=train_data_gen.flow(X[test], y_gender[test],\n                                   seed=11))\n  \n  # Generate generalization metrics\n  fig = px.line(\n  history.history, y=['loss', 'val_loss'],\n  labels={'index': 'epoch', 'value': 'loss'}, \n  title='Training History')\n  fig.show()\n    \n  scores = model.evaluate(train_data_gen.flow(X[test], y_gender[test],\n                                   seed=11), verbose=0)\n  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n  acc_per_fold.append(scores[1] * 100)\n  loss_per_fold.append(scores[0])\n  \n  # Increase fold number\n  fold_no = fold_no + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# == Provide average scores ==\nprint('------------------------------------------------------------------------')\nprint('Score per fold')\nfor i in range(0, len(acc_per_fold)):\n  print('------------------------------------------------------------------------')\n  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\nprint('------------------------------------------------------------------------')\nprint('Average scores for all folds:')\nprint(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\nprint(f'> Loss: {np.mean(loss_per_fold)}')\nprint('------------------------------------------------------------------------')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set Seed\nrandom.seed(11)\nset_seed(11)\nnp.random.seed(11)\n  \n# Define the model architecture\nmodel = Sequential()\n  \nmodel.add(Conv2D(64, kernel_size=(3,3), input_shape=input_shape, activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(128, kernel_size=(3,3), activation='relu', padding='same'))\nmodel.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.3))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(256, kernel_size=(3,3), activation='relu', padding='same'))\nmodel.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.3))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(512, kernel_size=(3,3), activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(128, activation='softmax'))\n\n# Compile the model\nmodel.compile(loss=loss_function,\n              optimizer=optimizer,\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Final_train = np.append(X_train, X_val, axis=0)\nFinal_val = np.append(y_train, y_val, axis=0)\nfinal_training_data = train_data_gen.flow(Final_train, Final_val,\n                                   seed=11)\n\nrandom.seed(11)\nset_seed(11)\nnp.random.seed(11)\nfinal_model_history = model.fit(train_data_gen.flow(X, y_gender, seed=11),batch_size=32,epochs=20, validation_data=val_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generate generalization metrics\nfig = px.line(\nfinal_model_history.history, y=['loss', 'val_loss'],\nlabels={'index': 'epoch', 'value': 'val_loss'}, \ntitle='Training History')\nfig.show()\n\n\n# Generate generalization metrics\nfig = px.line(\nfinal_model_history.history, y=['accuracy', 'val_accuracy'],\nlabels={'index': 'epoch', 'value': 'accuracy'}, \ntitle='Training History')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pwd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save(\"backup\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Metrics\nmodel.evaluate(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict_classes(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confusion matrix\ncm = confusion_matrix(y_test, y_pred)\nsns.heatmap(cm, cmap='Greens', cbar=False, annot=True, fmt='d');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Error Analysis**"},{"metadata":{"trusted":true},"cell_type":"code","source":"error_index = (y_test != y_pred)#finding error indices\ny_test_error = y_test[error_index]\nX_test_error = X_test[error_index]\nprediction_error = y_pred[error_index]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rows=int(np.floor(sum(error_index)/3)) #rows in subplots\ncols=3 #columns in subplots\nx_samp = X_test_error\ny_samp = y_test_error\n\nfig,ax = plt.subplots(rows,cols,figsize=(15,50))\nr = 0\nc = 0\nfor i in range((rows*cols)-1):\n    aa = x_samp[i].reshape(48,48)\n    ax[r,c].axis(\"off\")\n    ax[r,c].imshow(aa,cmap=\"gray\")\n    actual_lab = \"Female\" if y_samp.iloc[i]==1 else \"Male\"\n    pred_lab = \"Female\" if int(prediction_error[i])==1 else \"Male\"\n    ax[r,c].set_title(f'Actual: {actual_lab}\\nPred: {pred_lab}')\n    c+=1\n    if c == cols:\n        c=0\n        r+=1\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = cv2.imread('../input/testset/mind-long.jpg',0)\nplt.imshow(img, cmap=\"gray\")\nimg = cv2.resize(img, (48,48))\nimg = np.reshape(img,[1,48,48,1])\nimg_pixels = img.astype(\"float32\") / 255.0\nclasses = model.predict_classes(img_pixels)\n\nmapper=['male','female']\nprint(mapper[classes[0]])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}