{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Frame the problem and look at the big picture.\n1. Define the objective in business terms.\n I will be analyzing the sales of alcohol in the state of Iowa.\n\n1. How will your solution be used?\n Solution will be used to advise liquor store accross the U.S. on which liquor sells the most/ brands/ mixers, what is bought frequently together. This data set should be represetive for the rest of the U.S.\n1. What are the current solutions/workarounds (if any)?\n Using excel formulas or other spread sheets.\n1. How should you frame this problem?\n Determine the best selling brands/types and try to find reasoning behind this and how it can relate to the rest of the U.S.\n1. How should performance be measured?\n How many connections I can make with the sales.\n1. Is the performance measure aligned with the business objective?\nYes, the perfomance will help me reach my objective\n1. What would be the minimum performance needed to reach the business objective?\n Simple data analytics.\n1. What are comparable problems? Can you reuse experience or tools?\n This problem could be looked at from various other product categorys. \n1. Is human expertise available?\n  Depends if i consider myself a liqior expert. Not readily availble. \n1. How would you solve the problem manually?\n Using spread sheets like excel or google docs. \n1. List the assumptions you (or others) have made so far?\nI belive the bigger names that are popular here in the south may sell high in northern states, although i could be wrong as it is a complete different culture alcohol wise. I would be impressed if Iowa sales are similiar to Louisiana liqour sales.\n1. Verify assumptions if possible.","metadata":{}},{"cell_type":"markdown","source":"# Get the data\nNote: Automate as much possible so you can easily get fresh data.\n\n1. List the data you need and how much you need.\n\nIowa state liquor sales data from 2017.\n\n1. Find and document where you can get the data.\n\nKaggle and the Iowa state website.\n\n1. Check how much space it will take.\n3GB\n\n1. Check legal obligations and get authorization if necessary.\n\nWill not need, this is an open source from Kaggle and the Iowa State website.\n\n\n1. Get access authorizations.\n\n1. Create a workspace (with enough storage space)\n\n1. Get the data.\n\n1. Convert the data to a format you can easily manipulate (without changing the data itself.)\nAlready done\n1. Ensure sensitive information is deleted or protected (e.g., anonymized)\nDone\n\n1. Check the size and type of data (time series, sample, geographical, etc).\nThe dataset contains information on the name, kind, price, quantity, and location of sale of sales of individual containers or packages of containers of alcoholic beverages.\n\n","metadata":{"id":"BqsvcoU5R3tA"}},{"cell_type":"markdown","source":"# Explore the data to gain insights.\n1. Create a copy of the data for exploration (sampling it down to a manageable size if necessary.)\n","metadata":{"id":"8umCdSNFR3tA"}},{"cell_type":"code","source":"import numpy as np\nimport seaborn as sns\nimport pandas as pd \nsales = pd.read_csv(\"../input/iowa-liquor-sales/Iowa_Liquor_Sales.csv\")\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. Create a R project to keep a record of your data exploration.\n1. Study each attribute and its characteristics. BELOW\n    - Name\n    - Type (categorical, int/float, bounded/unbounded, text, structured, etc.)\n    - % of missing values\n    - Noisiness and type of noise (stochastic, outliers, rounding errors, etc.)\n    - Usefulness for the task\n    - Type of distribution (Gaussian, uniform, logarithmic, etc.)\n1. Identify the target attribute(s).\n    -Sale\n    -Bottle Sold\n    -Date\n    -Sate Price\n    -Retail Price\n    -Pack\n    -Category Name\n    -Category\n    -City\n1. Visualize the data. below\n\n1. Study the correlations between attributes.\n   -I will be looking at correlations between State Price and Retail Price, different categorys/category names\n1. Study how you would solve the problem manually.\n    - Add up each individual sale and compare brand sales, types of alcohol sales. etc. \n1. Identify the promising transformations you may want to apply.\n1. Identify extra data that would be useful.\n     -if store location was already categorized with rural or city area\n1. Document what you have learned.","metadata":{}},{"cell_type":"code","source":"sales.head","metadata":{"id":"Ci6jBEPeKDDK","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sales.info","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sales.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sales.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sales['City'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sales['Category Name'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare the Data\n\nNotes:\n- Work on copies of the data (keep the original dataset intact)\n- Write functions for all data transformations you apply, for five reasons:\n    1. So you can easily prepare the data the next time you get a fresh dataset\n    1. So you can apply these transformations in future projects\n    1. To clean and prepare the test set\n    1. To clean and prepare new data instances once your solution is live.\n    1. To make it easy to treat your preparation choices\n\n\n1. Data Cleaning\n    - Fix or remove outliers\n    - Fill in missing values (e.g. with zero, mean, median...) or drop their rows (or columns)\n1. Feature selection\n    - Drop the attributes that provide no useful information for the task.\n1. Feature engineering, where appropriate:\n    - Discretize continuous features\n    - Decompose features (e.g., categorical, date/time, etc)\n    - Add promising transformations to features (e.g., log(x), sqrt(x),etc.).\n    - Aggregate features into promising new features.\n1. Feature scaling:\n    - Standardize or normalize features.","metadata":{"pycharm":{"name":"#%% md\n"},"id":"ke6oXyVnR3tA"}},{"cell_type":"code","source":"sales.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sales.dropna(inplace = True)\nsales.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This took out a couple thousand entries containing null data. \nNow I will delete columns I will no longer need.","metadata":{}},{"cell_type":"code","source":"#getting rid of an error of repeating names due to difference in capitilization\nsales[\"City\"]= sales[\"City\"].replace('Des Moines', \"DES MOINES\")\nsales[\"City\"]= sales[\"City\"].replace('Cedar Rapids', \"CEDAR RAPIDS\")\nsales[\"City\"]= sales[\"City\"].replace('Davenport', \"DAVENPORT\")\nsales[\"City\"]= sales[\"City\"].replace('Council Bluffs', \"COUNCIL BLUFFS\")\nsales[\"City\"]= sales[\"City\"].replace('Waterloo', \"WATERLOO\")\nsales[\"City\"]= sales[\"City\"].replace('West Des Moines', \"WEST DES MOINES\")\nsales[\"City\"]= sales[\"City\"].replace('Sioux City', \"SIOUX CITY\")\nsales[\"City\"]= sales[\"City\"].replace('Dubuque', \"DUBUQUE\")\nsales[\"City\"]= sales[\"City\"].replace('Iowa City', \"IOWA CITY\")\nsales[\"City\"]= sales[\"City\"].replace('Ames', \"AMES\")\nsales.loc[sales['Category Name'].str.contains('WHISK', case=False), 'Category Name'] = 'WHISKEY'\nsales.loc[sales['Category Name'].str.contains('VODKA', case=False), 'Category Name'] = 'VODKA'\nsales.loc[sales['Category Name'].str.contains('TEQ', case=False), 'Category Name'] = 'TEQUILA'\nsales.loc[sales['Category Name'].str.contains('GIN', case=False), 'Category Name'] = 'GIN'\nsales.loc[sales['Category Name'].str.contains('SCHNA', case=False), 'Category Name'] = 'SCHNAPPS'\nsales.loc[sales['Category Name'].str.contains('RUM', case=False), 'Category Name'] = 'RUM'\nsales.loc[sales['Category Name'].str.contains('Liqueur', case=False), 'Category Name'] = 'LIQUEUR'\nsales.loc[sales['Category Name'].str.contains('WINE', case=False), 'Category Name'] = 'WINE'\nsales.loc[sales['Category Name'].str.contains('BEER', case=False), 'Category Name'] = 'BEER'\nsales.loc[sales['Category Name'].str.contains('Bourbon', case=False), 'Category Name'] = 'BOURBON'\nsales.loc[sales['Category Name'].str.contains('Brandie', case=False), 'Category Name'] = 'Brandies'\nsales.loc[sales['Category Name'].str.contains('scotch', case=False), 'Category Name'] = 'SCOTCH'\nnew_sales = sales.copy()\ndel new_sales['County Number']\n#\"CEDAR RAPIDS\"\"DAVENPORT\"\"COUNCIL BLUFFS\"\"WATERLOO\"\"WEST DES MOINES\"\"SIOUX CITY\"\"DUBUQUE\" \"IOWA CITY\"\"AMES\"\ndel new_sales['Store Location']\n\ndel new_sales['Volume Sold (Gallons)']\nnew_sales.info","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Shortlist Promising Models\n\n1. Train many quick-and-dirty models from different categories (e.g. linear, naive Bayes, SVM, Random Forest, neural net, etc.) using standard parameters.\n1. Measure and compare thier performance.\n  - For each model, use N-fold cross-validation and compute the mean and standard deviation of the performance measure on the N folds. \n1. Analyse the most significate variables for each algorithm.\n1. Analyze the types of errors the models make.\n  - What data would a human have used to avoid these errors?\n1. Perform a quick round of feature selection and engineering.\n1. Perfon one or two more quick iterations of the five previous steps.\n1. Shortlist the top three to five most promising models, preferring models that make different types of errors. \n","metadata":{"id":"HqXXWqJOR7el"}},{"cell_type":"markdown","source":"Now I will look at the comparison of sales and cost for each day of the years 2016 and 2017 since 2015 is not fully there. ","metadata":{}},{"cell_type":"code","source":"new_sales['Date'] = pd.to_datetime(new_sales['Date'])\nnew_sales['State Bottle Retail'] = new_sales['State Bottle Retail'].str.replace('$', '').astype('float')\nnew_sales['State Bottle Cost'] = new_sales['State Bottle Cost'].str.replace('$', '').astype('float')\nnew_sales['Sale (Dollars)'] = new_sales['Sale (Dollars)'].str.replace('$', '').astype('float')\nnew_sales['Date'].head","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = new_sales[new_sales['Date'].dt.year > 2015]\ntest_data['Date'].head","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#shrink data to only top ten cities, then by date and sales each purchase a tick colored by city two seperate plots for each year 2016 and 2017\ndaily_sales2 = test_data.copy()\ndaily_sales2= daily_sales2.rename(columns={\"Sale (Dollars)\": \"Sale\"})\ndaily_sales2= daily_sales2[daily_sales2[\"City\"].str.contains\n                           (\"DES MOINES|CEDAR RAPIDS|DAVENPORT|COUNCIL BLUFFS|WATERLOO\") ==True]\n                            #WEST DES MOINES|SIOUX CITY|DUBUQUE|IOWA CITY|AMES\")==True]\ndaily_sales = daily_sales2.drop(daily_sales2[daily_sales2.Sale>4000].index, inplace=True)\ndaily_sales2= daily_sales2.sort_values(by=['Date'],ascending=True)\ndaily_sales2.head(10)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nsale_avg = daily_sales2['Sale'].mean()\ndaily_sales20162 = daily_sales2[daily_sales2['Date'].dt.year == 2016]\ndaily_sales20172 = daily_sales2[daily_sales2['Date'].dt.year == 2017]\nfig = plt.gcf()\nfig.set_size_inches(12, 8)\nsns.scatterplot(x=\"Date\", y=\"Sale\",hue=\"City\", size=\"Sale\", linewidth=0,data=daily_sales20162)\nprint(sale_avg)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.gcf()\nfig.set_size_inches(10, 8)\nsns.scatterplot(x=\"Date\", y=\"Sale\",hue=\"City\", size=\"Sale\", linewidth=0,data=daily_sales20172)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"daily_sales = test_data.groupby(by=['Date'])['Sale (Dollars)','State Bottle Cost'].sum().reset_index()\ndaily_sales.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nplt.figure(figsize=(20,5))\ndaily_sales2016 = daily_sales[daily_sales['Date'].dt.year == 2016]\ndaily_sales2017 = daily_sales[daily_sales['Date'].dt.year == 2017]\nsns.lineplot(x=\"Date\", y=\"Sale (Dollars)\",data=daily_sales2016)\nsns.lineplot(x=\"Date\", y=\"State Bottle Cost\",data=daily_sales2016)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,5))\nsns.lineplot(x=\"Date\", y=\"Sale (Dollars)\",data=daily_sales2017)\nsns.lineplot(x=\"Date\", y=\"State Bottle Cost\",data=daily_sales2017)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now I will look at the different types of alcohol sales. ","metadata":{}},{"cell_type":"code","source":"#Cities with most alc sales\n\nsales_percity = new_sales.groupby(by=['City'])['Sale (Dollars)','State Bottle Cost'].sum().reset_index()\nsales_percity['City Profit'] = sales_percity['Sale (Dollars)'].sub(sales_percity['State Bottle Cost'])\nprofit_percity = sales_percity.sort_values('City Profit', ascending=False).reset_index()\nprofit_percity.head()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.catplot(data=profit_percity.head(10), kind=\"bar\",x='City', y=\"City Profit\", palette=\"crest\", height = 5)\nplt.xticks(rotation=40)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#stores in each city\n\ncity_count = sales.groupby('City')['Store Number'].nunique().to_frame().sort_values('Store Number', ascending= False).reset_index()\ncity_count.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"citystore_sales = pd.merge(city_count, profit_percity, on='City', how='outer')\ncitystore_sales = citystore_sales.rename(columns={\"Store Number\": \"Store Count\"})\ncitystore_sales.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.barplot(data=citystore_sales.head(10), x=\"Store Count\", y=\"City Profit\", hue=\"City\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#cat_sales = sales.groupby('City')['Category Name', 'Date', 'Sale (Dollars)']\n#alctype_sale = sales.groupby('Category Name')['Sale (Dollars)'].sum()\ncat_sales = new_sales.groupby(by=['Category Name'])['Sale (Dollars)'].sum().reset_index()\ncatcost = new_sales.groupby(by=['Category Name'])['State Bottle Cost'].sum().reset_index()\ncatsales = pd.merge(cat_sales, catcost, on='Category Name', how='left')\ncatsales['Category Profit'] = catsales['Sale (Dollars)'].sub(catsales['State Bottle Cost'])\ncatsales = catsales.sort_values(by=['Category Profit'], ascending=False).reset_index()\ncatsales.head(40)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.catplot(data=catsales.head(5), kind=\"bar\",\n    x=\"Category Name\", y=\"Category Profit\",\n    ci=\"sd\", palette=\"dark\", alpha=.6, height=5)\n\n\n\nplt.xticks(rotation=40)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\ntest_pred = sales.drop(['Vendor Name', 'Item Description'], axis=1)\n#test_pred.head(10)\n#profit_percity\ncity_set = pd.factorize(test_pred['City'].unique())\ncity_set = (pd.DataFrame(city_set).T)\ncity_set.rename(columns={0 : \"City Code\", 1: \"City\"}, inplace=True)\ncity_set['City Code'] = city_set['City Code'].astype(str).astype(int)\ncity_set.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"city_sales_test = citystore_sales.drop(['index'], axis=1)\npred_percity = pd.merge(city_sales_test, city_set, on='City', how='left')\ncol = pred_percity.pop('City Code')\npred_percity.insert(0, col.name, col)\n\npred_percity.head(10)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.heatmap(pred_percity.corr(), cmap='Blues', annot=True,)\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn import linear_model\nfrom sklearn.linear_model import Ridge, RidgeCV","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = pred_percity[['City Profit', 'Store Count', 'State Bottle Cost']]\ny = pred_percity['Sale (Dollars)']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"alpha_range = 10.**np.arange(-2, 3)\nridgeregcv = RidgeCV(alphas=alpha_range, normalize=True, scoring='neg_mean_squared_error')\nridgeregcv.fit(X_train, y_train)\nridgeregcv.alpha_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ridgereg = Ridge(alpha=0.01, normalize=True)\nridgereg.fit(X_train, y_train)\ny_pred = ridgereg.predict(X_test)\nprint(y_pred)\nprint('--------')\nprint('RMSE =', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rc = ridgeregcv.coef_\nprint(X.columns, rc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy = metrics.r2_score(y_test, y_pred)\nmse= metrics.mean_squared_error(y_test, y_pred)\nmae=metrics.mean_absolute_error(y_test,y_pred)\nrmse=np.sqrt(metrics.mean_squared_error(y_test, y_pred))\nprint(accuracy)\nprint(mse)\nprint(mae)\nprint(rmse)\n\nplt.scatter(y_test, y_pred)\nplt.xlabel('Actual Sales')\nplt.ylabel('Predicted Sales')\nplt.title('Ridge Regression Predictor of Future Sales', fontsize='x-large')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fine-Tune the System\n1. Fine-tune the hyperparameters using cross-validation. \n1. Try Ensemble methods. Combining your best models will often produce better performance than running them individually.\n1. Once you are confident about your final model, measure its performance on the test set to estimate the generlization error. \n\n**DO NOT TWEAK YOUR MODEL AFTER MEASURING THE GENERALIZATION ERROR: YOU WOULD JUST START OVERFITTING THE TEST SET!**","metadata":{"id":"cC63S5d6Szg3"}},{"cell_type":"code","source":"delete_dates = new_sales.copy()\nmask = (delete_dates['Date'] > '2016-09-01') & (delete_dates['Date'] <= '2017-11-01')\ndelete_dates.loc[mask]\ntest_pred2 = delete_dates.drop(['Vendor Name', 'Item Description'], axis=1)\n#test_pred.head(10)\n#profit_percity\ncity_set2 = pd.factorize(test_pred2['City'].unique())\ncity_set2 = (pd.DataFrame(city_set2).T)\ncity_set2.rename(columns={0 : \"City Code\", 1: \"City\"}, inplace=True)\ncity_set2['City Code'] = city_set2['City Code'].astype(str).astype(int)\ncity_set2.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"delete_dates2 = delete_dates[delete_dates[\"City\"].str.contains\n                           (\"DES MOINES|CEDAR RAPIDS|DAVENPORT|COUNCIL BLUFFS|WATERLOO\") ==True]\n\n#sales_percity2['City Profit'] = sales_percity2['Sale (Dollars)'].sub(sales_percity2['State Bottle Cost'])\n#profit_percity2 = sales_percity2.sort_values('Sale (Dollars)', ascending=False).reset_index()\n#sales_percity2.head(10)\n\ncity_count2 = delete_dates2.groupby('City')['Store Number'].nunique().to_frame().sort_values('Store Number', ascending= False).reset_index()\ncity_count2.head(10)\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bottles_bycity = delete_dates2.groupby(by=['City'])['Bottles Sold'].sum().reset_index()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sales_bycity= delete_dates2.groupby(by=['City'])['Sale (Dollars)'].sum().to_frame().reset_index()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"retail_bycity= delete_dates2.groupby(by=['City'])['State Bottle Retail'].sum().reset_index()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cost_bycity= delete_dates2.groupby(by=['City'])['State Bottle Cost'].sum().reset_index()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"salespercity2 = pd.merge(city_count2, bottles_bycity, on='City', how='left')\nsalespercity2 = pd.merge(salespercity2, sales_bycity, on='City', how='left')\nsalespercity2 = pd.merge(salespercity2, retail_bycity, on='City', how='left')\nsalespercity2 = pd.merge(salespercity2, cost_bycity, on='City', how='left')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"salespercity2.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X2 = salespercity2[['Bottles Sold', 'Store Number', 'State Bottle Cost', 'State Bottle Retail']]\ny2 = salespercity2['Sale (Dollars)']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"alpha_range2 = 10.**np.arange(-2, 3)\nridgeregcv2 = RidgeCV(alphas=alpha_range2, normalize=True, scoring='neg_mean_squared_error')\nridgeregcv2.fit(X2_train, y2_train)\nridgeregcv2.alpha_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ridgereg2 = Ridge(alpha=0.01, normalize=True)\nridgereg2.fit(X2_train, y2_train)\ny2_pred = ridgereg2.predict(X2_test)\nprint(y2_pred)\nprint('--------')\nprint('RMSE =', np.sqrt(metrics.mean_squared_error(y2_test, y2_pred)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rc = ridgeregcv2.coef_\nprint(X2.columns, rc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy2 = metrics.r2_score(y2_test, y2_pred)\nmse2= metrics.mean_squared_error(y2_test, y2_pred)\nmae2=metrics.mean_absolute_error(y2_test,y2_pred)\nrmse2=np.sqrt(metrics.mean_squared_error(y2_test, y2_pred))\nprint(accuracy2)\nprint(mse2)\nprint(mae2)\nprint(rmse2)\n\nplt.scatter(y2_test, y2_pred)\nplt.xlabel('Actual Sales')\nplt.ylabel('Predicted Sales')\nplt.title('Ridge Regression Predictor of Future Sales', fontsize='x-large')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I overfit this model. The previous model is a better representation.","metadata":{}},{"cell_type":"markdown","source":"# Present You Solution\n\n1. Document what you have done. \n1. Create a nice presentation\n1. Explain why your solution achieves the business objective.\n1. Don't forget to present interesting points you noticed along the way. \n1. Ensure your key finding are communicated through beautiful visualization or easy-to-remember statements.","metadata":{"id":"u3zU6copTXI-"}},{"cell_type":"markdown","source":"Findings can be found in my presentation.","metadata":{}}]}