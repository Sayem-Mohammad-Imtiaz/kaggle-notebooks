{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Loading the dataset\ndiabetes_data = pd.read_csv(\"../input/pima-indians-diabetes-database/diabetes.csv\")\n\n#Print the first 5 rows of the dataframe.\ndiabetes_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Basic EDA and statistical analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# gives information about the data types,columns, null value counts, memory usage etc\ndiabetes_data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, let's understand the statistics that are generated by the describe() method:\n\n* count tells us the number of NoN-empty rows in a feature.\n* mean tells us the mean value of that feature.\n* std tells us the Standard Deviation Value of that feature.\n* min tells us the minimum value of that feature.\n* 25%, 50%, and 75% are the percentile/quartile of each features. This quartile information helps us to detect Outliers.\n* max tells us the maximum value of that feature."},{"metadata":{"trusted":true},"cell_type":"code","source":"diabetes_data.describe()\n## basic statistic details about the data (note only numerical columns would be displayed here unless parameter include=\"all\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diabetes_data.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Question creeping out of this summary\nCan minimum value of below listed columns be zero (0)?\nOn these columns, a value of zero does not make sense and thus indicates missing value.\n\nFollowing columns or variables have an invalid zero value:\n\n* Glucose\n* BloodPressure\n* SkinThickness\n* Insulin\n* BMI\nIt is better to replace zeros with nan since after that counting them would be easier and zeros need to be replaced with suitable values"},{"metadata":{"trusted":true},"cell_type":"code","source":"diabetes_data_copy = diabetes_data.copy(deep = True)\ndiabetes_data_copy[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] = diabetes_data_copy[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']].replace(0,np.NaN)\n\n## showing the count of Nans\nprint(diabetes_data_copy.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To fill these Nan values the data distribution needs to be understood"},{"metadata":{"trusted":true},"cell_type":"code","source":"p = diabetes_data.hist(figsize = (20,20))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diabetes_data_copy['Glucose'].fillna(diabetes_data_copy['Glucose'].mean(), inplace = True)\ndiabetes_data_copy['BloodPressure'].fillna(diabetes_data_copy['BloodPressure'].mean(), inplace = True)\ndiabetes_data_copy['SkinThickness'].fillna(diabetes_data_copy['SkinThickness'].median(), inplace = True)\ndiabetes_data_copy['Insulin'].fillna(diabetes_data_copy['Insulin'].median(), inplace = True)\ndiabetes_data_copy['BMI'].fillna(diabetes_data_copy['BMI'].median(), inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p = diabetes_data_copy.hist(figsize = (20,20))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diabetes_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.pairplot(diabetes_data)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p=sns.pairplot(diabetes_data_copy, hue = 'Outcome')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,10))  # on this line I just set the size of figure to 12 by 10.\np=sns.heatmap(diabetes_data.corr(), annot=True) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diabetes_data.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**clean data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,10))  # on this line I just set the size of figure to 12 by 10.\np=sns.heatmap(diabetes_data_copy.corr(), annot=True,cmap ='RdYlGn')  # seaborn has very simple solution for heatmap","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diabetes_data_copy.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Scaling the data\ndata Z is rescaled such that Œº = 0 and ùõî = 1, and is done through this formula:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X=diabetes_data_copy.drop('Outcome',axis=1)\ny=diabetes_data_copy['Outcome']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using KNN Algorithm"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20,random_state=1)\nknn=KNeighborsClassifier(n_neighbors=4)\nsc=StandardScaler()\nsc.fit(X_train)\nscaledX_train = sc.transform(X_train)\n# scaledX_train = sc.fit_transform(X_train)\nscaledX_test = sc.transform(X_test)\nknn.fit(scaledX_train,y_train)\nprint(\"What is the Testing Accuracy\")\nprint(knn.score(scaledX_test,y_test))\nprint(\"What is the Training Accuracy\")\nprint(knn.score(scaledX_train,y_train))\npredicted = knn.predict(scaledX_test)\nprint(confusion_matrix(y_test,predicted))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**ADABOOST**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\nimport numpy as np\n\nneighbors = np.arange(1, 60)\ntrain_accuracy_plot = np.empty(len(neighbors))\ntest_accuracy_plot = np.empty(len(neighbors))\n# Loop over different values of k\nfor i, k in enumerate(neighbors):\n    train = []\n    test = []\n    for j in range(10):\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20,random_state=j)\n        sc=StandardScaler()\n        scaledX_train = sc.fit_transform(X_train)\n        scaledX_test = sc.transform(X_test)\n        ad = AdaBoostClassifier(n_estimators=k)\n        ad.fit(scaledX_train,y_train)\n        train.append(ad.score(scaledX_train,y_train))\n        test.append(ad.score(scaledX_test,y_test))\n    #Compute accuracy on the training set\n    train_accuracy_plot[i] = np.mean(train)\n    #Compute accuracy on the testing set\n    test_accuracy_plot[i] = np.mean(test)\n# Generate plot\nplt.title('AdaBoostClassifier: Varying Number of Depth')\nplt.plot(neighbors, test_accuracy_plot, label = 'Testing Accuracy')\nplt.plot(neighbors, train_accuracy_plot, label = 'Training Accuracy')\nplt.legend()\nplt.xlabel('n_estimator')\nplt.ylabel('Accuracy')\nplt.show()\nprint(np.mean(train))\nprint(np.mean(test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**GRADIENT DESCENT**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\nimport numpy as np\nfrom sklearn.ensemble import GradientBoostingClassifier\nneighbors = np.arange(1, 60)\ntrain_accuracy_plot = np.empty(len(neighbors))\ntest_accuracy_plot = np.empty(len(neighbors))\n# Loop over different values of k\nfor i, k in enumerate(neighbors):\n    train = []\n    test = []\n    for j in range(10):\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20,random_state=j)\n        sc=StandardScaler()\n        scaledX_train = sc.fit_transform(X_train)\n        scaledX_test = sc.transform(X_test)\n        knn = GradientBoostingClassifier(n_estimators=k)\n        knn.fit(scaledX_train,y_train)\n        train.append(knn.score(scaledX_train,y_train))\n        test.append(knn.score(scaledX_test,y_test))\n    #Compute accuracy on the training set\n    train_accuracy_plot[i] = np.mean(train)\n    #Compute accuracy on the testing set\n    test_accuracy_plot[i] = np.mean(test)\n# Generate plot\nplt.title('GradientBoostClassifier: Varying Number of Depth')\nplt.plot(neighbors, test_accuracy_plot, label = 'Testing Accuracy')\nplt.plot(neighbors, train_accuracy_plot, label = 'Training Accuracy')\nplt.legend()\nplt.xlabel('n_estimator')\nplt.ylabel('Accuracy')\nplt.show()\nprint(\"Train Accuracy\")\nprint(np.mean(train))\nprint(\"Test Accuracy\")\nprint(np.mean(test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Random Forest**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\nimport numpy as np\n\nneighbors = np.arange(1, 60)\ntrain_accuracy_plot = np.empty(len(neighbors))\ntest_accuracy_plot = np.empty(len(neighbors))\n# Loop over different values of k\nfor i, k in enumerate(neighbors):\n    train = []\n    test = []\n    for j in range(10):\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20,random_state=j)\n        sc=StandardScaler()\n        scaledX_train = sc.fit_transform(X_train)\n        scaledX_test = sc.transform(X_test)\n        knn = RandomForestClassifier(n_estimators=k)\n        knn.fit(scaledX_train,y_train)\n        train.append(knn.score(scaledX_train,y_train))\n        test.append(knn.score(scaledX_test,y_test))\n    #Compute accuracy on the training set\n    train_accuracy_plot[i] = np.mean(train)\n    #Compute accuracy on the testing set\n    test_accuracy_plot[i] = np.mean(test)\n# Generate plot\nplt.title('Random Forest: Number of Estimators')\nplt.plot(neighbors, test_accuracy_plot, label = 'Testing Accuracy')\nplt.plot(neighbors, train_accuracy_plot, label = 'Training Accuracy')\nplt.legend()\nplt.xlabel('Number of estimators')\nplt.ylabel('Accuracy')\nplt.show()\nprint(\"Train Accuracy\")\nprint(np.mean(train))\nprint(\"Test accuracy\")\nprint(np.mean(test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import classification_report\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test,predicted))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}