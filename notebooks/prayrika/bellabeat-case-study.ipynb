{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n#-------------------------------------------------------------------------------------------------------\n%config Completer.use_jedi = False","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-14T14:00:52.763008Z","iopub.execute_input":"2021-06-14T14:00:52.76336Z","iopub.status.idle":"2021-06-14T14:00:52.789997Z","shell.execute_reply.started":"2021-06-14T14:00:52.763326Z","shell.execute_reply":"2021-06-14T14:00:52.788852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Business Task\nTo discover the trends in smart device usage and assist Bellabeat's marketing team to come up with an effective marketing strategy for the company based on the findings.\n### Stakeholders\n* Co-Founder and Chief Creative Officer, Ueska Srsen\n* Co-founder and executive member, Sando Mur\n* Bellabeat's marketing analytics team\n","metadata":{}},{"cell_type":"markdown","source":"# About Bellabeat\nBellabeat is a smart device manufacturer company found in 2013. It is a tech-driven wellness company for women with their offices around the world. The company offers a range of products including:\n* Bellabeat App - connects to the company's lines of wellness products and provides users with health data related to their activity, sleep, stress, menstrual cycle, and mindfulness habits.\n* Leaf - a bracelet which tracks user's sleep, activity and stress\n* Time - a smart watch to track user's sleep, activity and stress\n* Spring - smart water bottle to track daily water intake of the user\n* Membership - gives users 24/7 access to fully personalized health guidance based on their lifestyle and goals","metadata":{}},{"cell_type":"markdown","source":"# About the Dataset\nThe dataset analyzed in this study is the public dataset titled '[FitBit Fitness Tracker Data](http://https://www.kaggle.com/arashnic/fitbit)' provided by Mobius. These datasets were generated by respondents to a distributed survey via Amazon Mechanical Turk between 03.12.2016-05.12.2016. Thirty eligible Fitbit users consented to the submission of personal tracker data, including minute-level output for physical activity, heart rate, and sleep monitoring.\n### Limitations of the Dataset:\n* Small sample size of 30. \n* The data is collected over a span of 2 months which is a small period to uncover substantial long-term trends.\n* Further, the data is not recently collected.\n* The dataset does not come with metadata and/or a description and hence, we might need to invest some time to understand the variables and their relationships.\n\n### Characteristics of the Dataset\n* Long format\n* All data tables are related by ID attribute. \n* Calories burnt, steps, intensity, heart rate, sleep and weight logs are the metrics included in the dataset.\n\n","metadata":{}},{"cell_type":"markdown","source":"# Objective \nThis analysis focuses on the daily and hourly trends of usage data by the smart fitness device users.This analysis will help Bellabeat to provide the members with updated health guidance at the right timings. Specifically, I have attempted to address the following questions:\n1. How does the intensity level of users generally vary throughout the 24 hours of a day? Are there any common patterns which apply to the daily user activity in general?\n2. Is the daily activity level of users related with the day of the week? In other words, is the user activity typically higher on some days of the week as compared to the rest?\n3. Is user engagement higher on some days of the week as compared to others?","metadata":{}},{"cell_type":"markdown","source":"# Preparing the Data\nFor our analysis, we will specifically need data from dailyActivity_merged.csv, hourlyIntensities_merged.csv and sleepDay_merged.csv. Lets prepare the data from these three tables so that we can analyse them later.\n### Preparing the Daily Activity Data\nThe dataset stores the daily acitivity data of the users in dailyActivity_merged.csv. This file contains information about daily calories, steps and intensity level of the users. Here is a preview of the data: ","metadata":{}},{"cell_type":"code","source":"# reading the data from the csv file into pandas dataframe\ndaily_activity = pd.read_csv('/kaggle/input/fitbit/Fitabase Data 4.12.16-5.12.16/dailyActivity_merged.csv') # reading the csv file\ndaily_activity.head() # data preview","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:00:52.791483Z","iopub.execute_input":"2021-06-14T14:00:52.791748Z","iopub.status.idle":"2021-06-14T14:00:52.820307Z","shell.execute_reply.started":"2021-06-14T14:00:52.791721Z","shell.execute_reply":"2021-06-14T14:00:52.819191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" Next, we will get information about the general structure of our dataset:","metadata":{}},{"cell_type":"code","source":"daily_activity.info() # getting to know the dataset","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:00:52.822141Z","iopub.execute_input":"2021-06-14T14:00:52.822416Z","iopub.status.idle":"2021-06-14T14:00:52.840117Z","shell.execute_reply.started":"2021-06-14T14:00:52.822387Z","shell.execute_reply":"2021-06-14T14:00:52.838841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The daily_activity dataset has 940 entries and 15 columns. We see that all the variables have non-null entries in all the 940 rows. So, our data has no missing entries. Besides, all the values other than the ActivityDate are in proper integer or floating number format. We can convert the ActivityDate to a datetime format as follows to ensure consistent formats in our analysis:","metadata":{}},{"cell_type":"code","source":"daily_activity['ActivityDate']= pd.to_datetime(daily_activity['ActivityDate']) ","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:00:52.841661Z","iopub.execute_input":"2021-06-14T14:00:52.841991Z","iopub.status.idle":"2021-06-14T14:00:52.85158Z","shell.execute_reply.started":"2021-06-14T14:00:52.841959Z","shell.execute_reply":"2021-06-14T14:00:52.850391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lets check the exact number of user IDs included in the dataset:","metadata":{}},{"cell_type":"code","source":"daily_activity.Id.nunique()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:00:52.853277Z","iopub.execute_input":"2021-06-14T14:00:52.853738Z","iopub.status.idle":"2021-06-14T14:00:52.867308Z","shell.execute_reply.started":"2021-06-14T14:00:52.853703Z","shell.execute_reply":"2021-06-14T14:00:52.866359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This dataset has data for 33 fitbit users. Moving further, we must get rid of any duplicate values from our dataset so that our analysis is not biased towards any side.","metadata":{}},{"cell_type":"code","source":"daily_activity.drop_duplicates()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-14T14:00:52.868727Z","iopub.execute_input":"2021-06-14T14:00:52.869411Z","iopub.status.idle":"2021-06-14T14:00:52.906361Z","shell.execute_reply.started":"2021-06-14T14:00:52.869364Z","shell.execute_reply":"2021-06-14T14:00:52.905193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We see that no rows were dropped, this means that our dataset did not have any duplicate entries. The dataset is now all prepared to be used. ","metadata":{}},{"cell_type":"markdown","source":"### Preparing the Hourly Intensity Data\nThe hourly intensities with date and time information is stored for all users in hourlyIntensities_merged.csv. Let us take a look at this dataset:","metadata":{}},{"cell_type":"code","source":"hourly_intensities = pd.read_csv('/kaggle/input/fitbit/Fitabase Data 4.12.16-5.12.16/hourlyIntensities_merged.csv')\nhourly_intensities.head() ","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:00:52.907618Z","iopub.execute_input":"2021-06-14T14:00:52.907925Z","iopub.status.idle":"2021-06-14T14:00:52.935607Z","shell.execute_reply.started":"2021-06-14T14:00:52.907892Z","shell.execute_reply":"2021-06-14T14:00:52.934632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hourly_intensities.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:00:52.937407Z","iopub.execute_input":"2021-06-14T14:00:52.937698Z","iopub.status.idle":"2021-06-14T14:00:52.956022Z","shell.execute_reply.started":"2021-06-14T14:00:52.937669Z","shell.execute_reply":"2021-06-14T14:00:52.954573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This shows that the hourly_intensities dataset has no null values. Let us drop any duplicate rows, if any, in the dataset:","metadata":{}},{"cell_type":"code","source":"hourly_intensities.drop_duplicates()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-14T14:00:52.957684Z","iopub.execute_input":"2021-06-14T14:00:52.958114Z","iopub.status.idle":"2021-06-14T14:00:52.98127Z","shell.execute_reply.started":"2021-06-14T14:00:52.958071Z","shell.execute_reply":"2021-06-14T14:00:52.980097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We see that no rows were dropped. This implies that there were no duplicates in our data. Now, we will convert the data in the ActivityHour column to a datetime format:","metadata":{}},{"cell_type":"code","source":"hourly_intensities['ActivityHour']= pd.to_datetime(hourly_intensities['ActivityHour'])","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:00:53.017477Z","iopub.execute_input":"2021-06-14T14:00:53.017891Z","iopub.status.idle":"2021-06-14T14:00:55.260239Z","shell.execute_reply.started":"2021-06-14T14:00:53.017839Z","shell.execute_reply":"2021-06-14T14:00:55.259197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The number of users whose data is contained in this dataset are:","metadata":{}},{"cell_type":"code","source":"hourly_intensities.Id.nunique()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:00:55.261836Z","iopub.execute_input":"2021-06-14T14:00:55.262206Z","iopub.status.idle":"2021-06-14T14:00:55.269624Z","shell.execute_reply.started":"2021-06-14T14:00:55.262165Z","shell.execute_reply":"2021-06-14T14:00:55.26841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Processing the Data\nBeginning with our first question, we want to see if there are some hours of the day in which a  typical user will be generally more active than others. Presently, our dataset has time and date merged into one column. We want specifically the hourly information for our present use case. Therefore, we will extract the hour information from the ActivityHour column:","metadata":{}},{"cell_type":"code","source":"# extracting the hour information from datetime object\nhourly_intensities['Hour'] = hourly_intensities['ActivityHour'].dt.hour \nhourly_intensities['Hour'].head()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:00:55.272405Z","iopub.execute_input":"2021-06-14T14:00:55.27303Z","iopub.status.idle":"2021-06-14T14:00:55.287716Z","shell.execute_reply.started":"2021-06-14T14:00:55.27298Z","shell.execute_reply":"2021-06-14T14:00:55.286752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next, we would find the average of the total intensities of all users in a given hour. We can then, identify the hourly trends in intensity levels per hour. For finding average intensity level per hour, the code can be written as follows:","metadata":{}},{"cell_type":"code","source":"# aggregating information based on hour of the day for all entries in hourly_intensities dataframe\ngrouped_by_hour = hourly_intensities.groupby('Hour')['TotalIntensity'].sum().reset_index()\n\n# function for calculating the number of entries per hour in the dataframe\ndef find_divisor(grouped_series, reqd_colname, orig_df):\n    index_list=[] # to store the index information\n    number_per_index=[] # to store the number of entries per index\n    for entry in grouped_series[reqd_colname]:\n        index_list.append(entry)\n        number_per_index.append(len(orig_df[orig_df[reqd_colname]==entry]))\n    return pd.Series(number_per_index, index=index_list) \n\n#  Series with number of entries per hour\nentries_per_hour = find_divisor(grouped_by_hour, 'Hour', hourly_intensities) ","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:00:55.289632Z","iopub.execute_input":"2021-06-14T14:00:55.29003Z","iopub.status.idle":"2021-06-14T14:00:55.322984Z","shell.execute_reply.started":"2021-06-14T14:00:55.289994Z","shell.execute_reply":"2021-06-14T14:00:55.321995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function for dividing grouped series with number of entries per index\ndef find_average(dividend_series, dividend_colname, divisor_series):\n    avg_series = dividend_series[dividend_colname].divide(other = divisor_series, axis = 0)\n    return avg_series\n\n# Series with average activity level of users per hour\nactivity_per_hour = find_average(grouped_by_hour, 'TotalIntensity', entries_per_hour)\n\n# dataframe to store hour and corresponding activity level as an entry\ntemp_frame = {'Hour': activity_per_hour.index.tolist(), 'AvgIntensity' : activity_per_hour}\n\n# converting average_hourly_intensity dataframe to a csv file\naverage_hourly_intensity = pd.DataFrame(temp_frame)\naverage_hourly_intensity.to_csv('AverageHourlyIntensity.csv')\naverage_hourly_intensity.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:00:55.324286Z","iopub.execute_input":"2021-06-14T14:00:55.324555Z","iopub.status.idle":"2021-06-14T14:00:55.338267Z","shell.execute_reply.started":"2021-06-14T14:00:55.324528Z","shell.execute_reply":"2021-06-14T14:00:55.337201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analyzing the Data\nNow, we can observe the trend in user intensity level throughout the 24 hours of a day. Below is a Tableau graph created by plotting hours on the X-axis and average intensity on Y-axis from the AverageHourlyIntensity.csv file generated above:","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n# assigning data to be shown along each dimension\nx = average_hourly_intensity['Hour']\ny = average_hourly_intensity['AvgIntensity']\nplt.plot(x,y) # plotting the data\nplt.title('Average Activity Level Over 24 Hours') # giving a title to our plot\n#naming the axes\nplt.xlabel('Hour of the Day')\nplt.ylabel('Average Activity Level of a User')\nplt.show() # show the plot","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:00:55.339669Z","iopub.execute_input":"2021-06-14T14:00:55.33994Z","iopub.status.idle":"2021-06-14T14:00:55.469649Z","shell.execute_reply.started":"2021-06-14T14:00:55.339914Z","shell.execute_reply":"2021-06-14T14:00:55.468751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To obtain a more interactive visualization, we can download the output file 'AverageHourlyIntensity.csv' and plot a similar line chart in Tableau. Below is an embedded resulting graph for our data:","metadata":{}},{"cell_type":"code","source":"%%HTML \n<div class='tableauPlaceholder' id='viz1623582488949' style='position: relative'><noscript><a href='#'><img alt='Average Activity Level over 24 Hours ' src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Av&#47;AverageIntensityLeveloveraDay&#47;Sheet1&#47;1_rss.png' style='border: none' /></a></noscript><object class='tableauViz'  style='display:none;'><param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' /> <param name='embed_code_version' value='3' /> <param name='site_root' value='' /><param name='name' value='AverageIntensityLeveloveraDay&#47;Sheet1' /><param name='tabs' value='no' /><param name='toolbar' value='yes' /><param name='static_image' value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Av&#47;AverageIntensityLeveloveraDay&#47;Sheet1&#47;1.png' /> <param name='animate_transition' value='yes' /><param name='display_static_image' value='yes' /><param name='display_spinner' value='yes' /><param name='display_overlay' value='yes' /><param name='display_count' value='yes' /><param name='language' value='en-US' /></object></div>                <script type='text/javascript'>                    var divElement = document.getElementById('viz1623582488949');                    var vizElement = divElement.getElementsByTagName('object')[0];                    vizElement.style.width='100%';vizElement.style.height=(divElement.offsetWidth*0.75)+'px';                    var scriptElement = document.createElement('script');                    scriptElement.src = 'https://public.tableau.com/javascripts/api/viz_v1.js';                    vizElement.parentNode.insertBefore(scriptElement, vizElement);                </script>","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-14T14:00:55.470946Z","iopub.execute_input":"2021-06-14T14:00:55.471234Z","iopub.status.idle":"2021-06-14T14:00:55.476738Z","shell.execute_reply.started":"2021-06-14T14:00:55.471202Z","shell.execute_reply":"2021-06-14T14:00:55.47585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Sharing the Observations from Above Analysis\nThe acitvity level of the users starts rising from 4 AM and then drops again after 8 PM at night as expected given the general day and night activity patterns of people. This line graph gives us two other important insights:\n1. The activity levels undergo a little dip in afternoon at around 3 PM. This shows that people are sedentary in those hours of the room.\n2. The peak of activity is reached in the evening at 6 PM. Those timings may correspond with the commute timings of the office goers or the workout schedules of people. Presently we have limited information to conclude anything about the reason behind this insight since we do not know the exact composition of the users included in the dataset.\n### Next Steps\nMoving forward, we can perform our analysis on finding the weekday(s) which are the most busy versus the weekday(s) that see the least user activity. For doing so, lets put the required information into a dataframe to include columns for date and corresponding weekday for each entry in the hourly_intensities dataframe. First, we extract the date from the 'ActivityHour' column of hourly_intensities dataframe and store it into a new column, 'Date'.","metadata":{}},{"cell_type":"code","source":"hourly_intensities['Date'] = pd.to_datetime(hourly_intensities['ActivityHour'].dt.date)\nhourly_intensities['Date'].head()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:00:55.478009Z","iopub.execute_input":"2021-06-14T14:00:55.478301Z","iopub.status.idle":"2021-06-14T14:00:55.514559Z","shell.execute_reply.started":"2021-06-14T14:00:55.47827Z","shell.execute_reply":"2021-06-14T14:00:55.513561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next, we insert code to find the week day corresponding to each date in the 'Date' column as follows:","metadata":{}},{"cell_type":"code","source":"# code to convert each date to its corresponding weekday\nhourly_intensities['Day'] = hourly_intensities['Date'].dt.day_name()\n\n# grouping the entries according to weekdays with total intensity values per week day\ngrouped_by_day = hourly_intensities.groupby('Day')['TotalIntensity'].sum()\nweekday_intensity = pd.DataFrame({'Day':list(grouped_by_day.index.values), 'TotalIntensity': grouped_by_day})\n\n# series to store number of entries per week day\nentries_per_day = find_divisor(weekday_intensity, 'Day', hourly_intensities)\n\n# average activity level per week day\ntemp_avg_intensity = find_average (weekday_intensity, 'TotalIntensity', entries_per_day)\n\n# storing the results in a dataframe with desired scheme\ntemp_frame = pd.DataFrame({'Weekday': temp_avg_intensity.index.tolist(), 'AvgIntensity': temp_avg_intensity}).reset_index(drop=True)\n# converting the dataframe to a csv file\ntemp_frame.to_csv('IntensitiesWeekday.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:00:55.518047Z","iopub.execute_input":"2021-06-14T14:00:55.518435Z","iopub.status.idle":"2021-06-14T14:00:55.557306Z","shell.execute_reply.started":"2021-06-14T14:00:55.518401Z","shell.execute_reply":"2021-06-14T14:00:55.556416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Sharing the Observations from Above Analysis\nNow, we can visualize the trend for average activity level of a user over the seven days of a week. Below is a Tableau graph generated by plotting weekdays on x-axis and avergae intensity level on y-axis:","metadata":{}},{"cell_type":"code","source":"day = temp_frame['Weekday']\navg_int = temp_frame['AvgIntensity']\n \n# Figure Size\nfig = plt.figure(figsize =(10, 7))\n \n# Horizontal Bar Plot\nplt.bar(day, avg_int)\n \n# Show Plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:00:55.558846Z","iopub.execute_input":"2021-06-14T14:00:55.55924Z","iopub.status.idle":"2021-06-14T14:00:55.704598Z","shell.execute_reply.started":"2021-06-14T14:00:55.559198Z","shell.execute_reply":"2021-06-14T14:00:55.703471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For a more interactive graph in Tableau, we can download the output file 'IntensitiesWeekday.csv' obtained above and plot the data. Here's the visualization obtained in Tableau:","metadata":{}},{"cell_type":"code","source":"%%HTML\n<div class='tableauPlaceholder' id='viz1623573791361' style='position: relative'><noscript><a href='#'><img alt='Average Activity Level Over a Week ' src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Bo&#47;Book2_16235736520540&#47;Sheet1&#47;1_rss.png' style='border: none' /></a></noscript><object class='tableauViz'  style='display:none;'><param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' /> <param name='embed_code_version' value='3' /> <param name='site_root' value='' /><param name='name' value='Book2_16235736520540&#47;Sheet1' /><param name='tabs' value='no' /><param name='toolbar' value='yes' /><param name='static_image' value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Bo&#47;Book2_16235736520540&#47;Sheet1&#47;1.png' /> <param name='animate_transition' value='yes' /><param name='display_static_image' value='yes' /><param name='display_spinner' value='yes' /><param name='display_overlay' value='yes' /><param name='display_count' value='yes' /><param name='language' value='en-US' /></object></div>                <script type='text/javascript'>                    var divElement = document.getElementById('viz1623573791361');                    var vizElement = divElement.getElementsByTagName('object')[0];                    vizElement.style.width='100%';vizElement.style.height=(divElement.offsetWidth*0.75)+'px';                    var scriptElement = document.createElement('script');                    scriptElement.src = 'https://public.tableau.com/javascripts/api/viz_v1.js';                    vizElement.parentNode.insertBefore(scriptElement, vizElement);                </script>","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-14T14:00:55.706612Z","iopub.execute_input":"2021-06-14T14:00:55.706943Z","iopub.status.idle":"2021-06-14T14:00:55.712945Z","shell.execute_reply.started":"2021-06-14T14:00:55.70691Z","shell.execute_reply":"2021-06-14T14:00:55.711978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We see that the users are generally least active on Sunday and most active on Saturday. This can be due to a number of possiblities:\n1. People generally spend Saturdays on outings and relax on Sundays (applicable for people who follow a 5-day workweek). However, we do not have any demographic information about our sample population to confirm this hypothesis.\n2. In the 5 working days of the week, Tuesday is the most busy day followed by Friday. Wednesday is the least active day among the 5 workdays of the week.\n\n### Next Steps\nNext, we need to find if the users are consistently skipping logging their activites on some days or not. This will help us in determining if the lower activity level on somedays is actually due to low activity at user end or due to users skipping to log their activity. For this analysis, we go back to our daily_activity dataframe and add a column for weekdays:","metadata":{}},{"cell_type":"code","source":"# Finding week days corresponding to dates\ndaily_activity['Day'] = daily_activity['ActivityDate'].dt.day_name()\n\n# aggregating logging activity of users for each week day\nact_temp = daily_activity.groupby('Day')['LoggedActivitiesDistance'].sum()\nlogact_day = pd.DataFrame({'Day': list(act_temp.index.values), 'LoggedActivitiesDistance': act_temp}) \n\n# counting entries for each week day\ncount_day = find_divisor(logact_day, 'Day', daily_activity)\n\n# finding average logged activity level per week day\ntemp_avg = find_average(logact_day, 'LoggedActivitiesDistance', count_day)\ntemp_avg = logact_day['LoggedActivitiesDistance'].divide(other = count_day, axis=0)\n\n# storing required data in a dataframe with a desired scheme\ntemp_fr = pd.DataFrame({'Weekday': temp_avg.index.tolist(), 'AvgLoggedDistance': temp_avg}).reset_index(drop=True)\n# converting dataframe to a csv file\ntemp_fr.to_csv('LoggedActivitiesWeekday.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:00:55.714129Z","iopub.execute_input":"2021-06-14T14:00:55.714419Z","iopub.status.idle":"2021-06-14T14:00:55.743781Z","shell.execute_reply.started":"2021-06-14T14:00:55.714379Z","shell.execute_reply":"2021-06-14T14:00:55.742914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Sharing the Observations from Above Analysis\nThe following Tableau plot for logging user activity versus weekdays reveals an important insight:","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n# assigning data to be shown along each dimension\nx = temp_fr['Weekday']\ny = temp_fr['AvgLoggedDistance']\nplt.plot(x,y) # plotting the data\nplt.title('Average Logged Distance Per Week Day') # giving a title to our plot\n#naming the axes\nplt.xlabel('Week Day')\nplt.ylabel('Average Logged Distance')\nplt.show() # show the plot","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:00:55.744874Z","iopub.execute_input":"2021-06-14T14:00:55.745138Z","iopub.status.idle":"2021-06-14T14:00:55.878547Z","shell.execute_reply.started":"2021-06-14T14:00:55.745111Z","shell.execute_reply":"2021-06-14T14:00:55.877716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plotting the same data from the output file 'LoggedActivitesWeekday.csv' obtained above results in the following graph in Tableau:","metadata":{}},{"cell_type":"code","source":"%%HTML\n<div class='tableauPlaceholder' id='viz1623578323612' style='position: relative'><noscript><a href='#'><img alt='Logged Activity Per Week Day ' src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Bo&#47;Book1_16235779884360&#47;Sheet1&#47;1_rss.png' style='border: none' /></a></noscript><object class='tableauViz'  style='display:none;'><param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' /> <param name='embed_code_version' value='3' /> <param name='site_root' value='' /><param name='name' value='Book1_16235779884360&#47;Sheet1' /><param name='tabs' value='no' /><param name='toolbar' value='yes' /><param name='static_image' value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Bo&#47;Book1_16235779884360&#47;Sheet1&#47;1.png' /> <param name='animate_transition' value='yes' /><param name='display_static_image' value='yes' /><param name='display_spinner' value='yes' /><param name='display_overlay' value='yes' /><param name='display_count' value='yes' /><param name='language' value='en-US' /></object></div>                <script type='text/javascript'>                    var divElement = document.getElementById('viz1623578323612');                    var vizElement = divElement.getElementsByTagName('object')[0];                    vizElement.style.width='100%';vizElement.style.height=(divElement.offsetWidth*0.75)+'px';                    var scriptElement = document.createElement('script');                    scriptElement.src = 'https://public.tableau.com/javascripts/api/viz_v1.js';                    vizElement.parentNode.insertBefore(scriptElement, vizElement);                </script>","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-14T14:00:55.879534Z","iopub.execute_input":"2021-06-14T14:00:55.879952Z","iopub.status.idle":"2021-06-14T14:00:55.885861Z","shell.execute_reply.started":"2021-06-14T14:00:55.87992Z","shell.execute_reply":"2021-06-14T14:00:55.884712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since we get zero logged distances by users on the weekends, it is a good idea to download daily_activity dataframe as a csv file and inspect it in an Excel workbook to check if the graph is consistent with actual data. \nAfter checking, I found that my data was consistent with this finding. This drawback of Bellabeat's products provide us with a huge opportunity to channelize our marketing efforts in this direction.\n\n# Conclusions\n1. Saturdays followed by Tuesdays are the two days in a week when users are generally indulged in high intensity activites.\n2. Users consistently skip logging in their activity distance on weekends (i.e., Saturdays and Sundays). They are most likely to log in their distances on Mondays.\n3. User activity rises overall from 4 AM to 12 PM and dips in the noon, hitting the minimum at 3 PM. This is followed by a rise in activity again which reaches the maximum at 6 PM.\n\n# Recommendations and Future Scope\nMy recommendations to Bellabeat's marketing team are two-fold:\n1. The company can start 'Weekend Engagement Programmes' for its users so that users don't get disconnected from their health routines on weekends. \n2. In the sedentary hours of the noon, the users can be reminded to take a small break from their work and leave their seats to cut the long sitting hours. At the same time, the notifications and triggers can be kept to a minimum during 10 AM to 12 PM and 5-7 PM to avoid disturbance to user. This intelligent alerting system can be marketed to attract more potential customers and providing user delight for existing customers.\nThis dataset can also be used in future to gain further insights into the following relevant questions:\n1. How does user sleep on a particular day affect their activity and heartrate for the next day?\n2. Does the activity level trends over the 24 hours of the day vary when seen over the working days as compared to on the weekends?\n3. Do higher calories burnt necessarily correlate with a healthy heartrate?\n","metadata":{}},{"cell_type":"markdown","source":"\n","metadata":{}}]}