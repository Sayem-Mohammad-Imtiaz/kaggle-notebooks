{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n# Any results you write to the current directory are saved as output.\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression \nfrom sklearn import metrics\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"**Read Data From Files**"},{"metadata":{"trusted":true},"cell_type":"code","source":"_2015_report = pd.read_csv(\"../input/world-happiness/2015.csv\")\n_2016_report = pd.read_csv(\"../input/world-happiness/2016.csv\")\n_2017_report = pd.read_csv(\"../input/world-happiness/2017.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Basic high level info of datasets**"},{"metadata":{"trusted":true},"cell_type":"code","source":"_2015_report.describe()\n_2016_report.describe()\n_2017_report.describe()\n_2015_report.head(2)\n_2016_report.head(2)\n_2017_report.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Merge All DataSets into Single DataSet**\n\nMerged all datasets into single dataset 'total_report' and introduced new column called \"Year\" to represent the year to which the record belongs"},{"metadata":{"trusted":true},"cell_type":"code","source":"_2015_report[\"Year\"] = 2015\n_2016_report[\"Year\"] = 2016\n_2017_report[\"Year\"] = 2017\nclmns = ['Country', 'Happiness Rank', 'Happiness Score',\n       'Whisker High','Whisker Low', 'Economy (GDP per Capita)', 'Family',\n       'Health (Life Expectancy)', 'Freedom', 'Generosity', 'Trust (Government Corruption)',\n       'Dystopia Residual', 'Year']\n_2017_report.set_axis(clmns,axis=1)\n_2017_report = _2017_report[['Country', 'Happiness Rank', 'Happiness Score',\n       'Whisker High','Whisker Low', 'Economy (GDP per Capita)', 'Family',\n       'Health (Life Expectancy)', 'Freedom',  'Trust (Government Corruption)','Generosity',\n       'Dystopia Residual', 'Year']]\ntotal_report = pd.concat([_2015_report,_2016_report,_2017_report],axis=0,sort=False).reset_index().drop('index',axis=1)\ntotal_report.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Lets see stats for our new dataset..**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.concat([total_report.describe(),\ntotal_report.isnull().sum().to_frame().transpose().set_index(pd.Index(['missing']))],axis=0,sort=False)\ntotal_report.isnull().sum().sort_values(ascending=False).apply(lambda x:x/len(total_report))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can drop columns with more than 50 % missing data. I have created a new dataset removing those columns. As, region got 33 % of missing data we need to impute region column."},{"metadata":{"trusted":true},"cell_type":"code","source":"total_report_ = total_report[['Country', 'Region', 'Happiness Rank', 'Happiness Score', 'Economy (GDP per Capita)', 'Family',\n       'Health (Life Expectancy)', 'Freedom', 'Trust (Government Corruption)',\n       'Generosity', 'Dystopia Residual', 'Year', ]]\nregions = total_report_.Region.value_counts().index\nregion_countries={}\nfor reg in regions:\n    region_countries[reg] = total_report_.query('Region == \"'+reg+'\"')['Country'].drop_duplicates().values\ndef impute_regions(countries):\n    regions = []\n    for country in countries:\n        imputed = False\n        for reg,con in region_countries.items():\n            if country in con:\n                regions.append(reg)\n                imputed = True\n        if imputed == False:\n            regions.append(\"Asia\")\n    return regions\ntotal_report_.loc[total_report_.Region.isnull(),'Region'] = impute_regions(total_report_.loc[total_report_.Region.isnull(),'Country'])\ntotal_report_[\"Country\"] = total_report_.Country.astype(\"category\")\ntotal_report_[\"Region\"] = total_report_.Region.astype(\"category\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_report_.columns\nsns.pairplot(total_report_[['Happiness Score',\n       'Economy (GDP per Capita)', 'Family', 'Health (Life Expectancy)',\n       'Freedom', 'Trust (Government Corruption)', 'Generosity',\n       'Dystopia Residual']])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that Economy, Family and Health life variables have **strong linear correlation** with Happiness Score. Freedom shows weak linear correlation with Happiness Score, where as Trust exhibits some what non-linear correlation with Happiness Score."},{"metadata":{},"cell_type":"markdown","source":"Lets see correlation matrix for all numeric varibles. We will plot the heat map and see which variables are highly correlated with each other."},{"metadata":{"trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.heatmap(total_report_[['Happiness Score',\n       'Economy (GDP per Capita)', 'Family', 'Health (Life Expectancy)',\n       'Freedom', 'Trust (Government Corruption)', 'Generosity',\n       'Dystopia Residual']].corr(),vmin=-1, vmax=1, center=0,\n    cmap=sns.diverging_palette(20, 220, n=200),\n    square=True,annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"We can clearly see that (Economy,Health (Life Expectancy)) are strongly correlated with each other (0.79). And also we can see that (Economy,Family) are have a correlation of 0.59 and (Health, Family) have a correlation of 0.49. (Freedom, Trust) also have correlation of 0.49. (Generosity,Dystopia Residual) have a negetive correlation of 0.1. "},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"plt.figure(figsize=(8,5))\nfor c in total_report_.Region.cat.categories:\n    sns.distplot(total_report_.loc[total_report_.Region==str(c),\"Freedom\"],hist=False,label=str(c),kde=True);\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"plt.figure(figsize=(8,5))\nfor c in total_report_.Region.cat.categories:\n    sns.distplot(total_report_.loc[total_report_.Region==str(c),\"Economy (GDP per Capita)\"],hist=False,label=str(c),kde=True);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"trust = np.sqrt(total_report['Trust (Government Corruption)'])\n\nsns.jointplot(trust,total_report_[\"Happiness Score\"])\nsns.jointplot(total_report['Trust (Government Corruption)'],total_report_[\"Happiness Score\"])\n\ndf = pd.concat([pd.DataFrame(trust),pd.DataFrame(total_report_[\"Happiness Score\"])],axis=1)\ndf.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets apply simple linear regression model on this data. First, we have to encode our categorical data using Label Encoder and then we have to select features for our model. I have carefully selected features for our model based on assumptions made through our correlation matrix and other EDA techinques. "},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder = LabelEncoder()\ntotal_report_[\"Country\"] = encoder.fit_transform(total_report_[\"Country\"])\ntotal_report_[\"Region\"] = encoder.fit_transform(total_report_[\"Region\"])\ntotal_report_[\"Trust New\"] = trust\nX = total_report_[[\n       'Economy (GDP per Capita)', 'Family', \n       'Freedom', 'Trust (Government Corruption)', 'Generosity',\n       'Dystopia Residual']]\nY = total_report_[\"Happiness Score\"]\nX_train,X_test,Y_train,Y_test  = train_test_split(X,Y,test_size=0.2)\nlmr = LinearRegression();\nlmr.fit(X_train,Y_train)\ny_pred = lmr.predict(X_test)\ndf = pd.DataFrame({'Actual': Y_test.as_matrix().flatten(), 'Predicted': y_pred.flatten()})\n\"R-2 value:\"+str(np.sqrt(metrics.mean_squared_error(y_pred,Y_test)))\nresiduals = df[\"Actual\"]-df[\"Predicted\"]\ncoef = pd.Series(lmr.coef_).apply(lambda x: round(x,5))\npd.DataFrame(coef.as_matrix(),X.columns,columns=['Coeff'])\nsns.jointplot(y_pred,Y_test)\nsns.jointplot(y_pred,residuals)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see, our model had fit very nicely with our data with R-2 score of 0.17 and residual plot also looks fine.\n\nLets take one step ahead and try to predict Happiness Score for 2018 with our model. I got 2018 data from Kaggle website and uploaded to my kernel. Lets try our model on this data.."},{"metadata":{"trusted":true},"cell_type":"code","source":"_2018_report = pd.read_csv(\"../input/2018-report/WorldHappiness2018_Data.csv\")\n_2018_report.columns\ny_new = lmr.predict(_2018_report[['GDP_Per_Capita',\n       'Healthy_Life_Expectancy', 'Freedom_To_Make_Life_Choices', 'Generosity',\n       'Perceptions_Of_Corruption', 'Residual']].dropna())\ndf_2 = pd.DataFrame({'Actual':_2018_report.Score[:-1].dropna().as_matrix().flatten(),'Predicted':y_new.flatten()})\nresiduals = df_2['Actual']-df_2['Predicted']\n\"R-2 score:\"+str(np.sqrt(metrics.mean_squared_error(df[\"Actual\"],df[\"Predicted\"])))\nsns.jointplot(df_2['Actual'],df_2['Predicted'])\nsns.jointplot(df_2['Predicted'],residuals)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our model performed pretty well with 2018 data as well, with R2 score: 0.133.\n\n\n\n**Thats all from my side. This is my first kernel. Please let me know if I have done any mistakes.. :)**"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}