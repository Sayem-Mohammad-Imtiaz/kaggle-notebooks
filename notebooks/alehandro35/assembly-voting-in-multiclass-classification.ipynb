{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom scipy import stats\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import classification_report\nimport seaborn as sns\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import VotingClassifier\nimport matplotlib.pyplot as plt\nfrom pylab import rcParams\nfrom sklearn.naive_bayes import GaussianNB\n\nrcParams['figure.figsize'] = 18, 8","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-21T14:16:14.887707Z","iopub.execute_input":"2021-09-21T14:16:14.888094Z","iopub.status.idle":"2021-09-21T14:16:14.89617Z","shell.execute_reply.started":"2021-09-21T14:16:14.888059Z","shell.execute_reply":"2021-09-21T14:16:14.895169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Read .csv file and let's have a look at our data. Target column is 'price_range', plot it.","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/mobile-price-classification/train.csv')\ntest = pd.read_csv('../input/mobile-price-classification/test.csv')\nprint(train.head())\nsns.histplot(data=train, x=\"price_range\")","metadata":{"execution":{"iopub.status.busy":"2021-09-21T14:16:14.89813Z","iopub.execute_input":"2021-09-21T14:16:14.898716Z","iopub.status.idle":"2021-09-21T14:16:15.231072Z","shell.execute_reply.started":"2021-09-21T14:16:14.89867Z","shell.execute_reply":"2021-09-21T14:16:15.23035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we see our data is well balanced. Now we will check the number of Nan values and column types in the dataset.","metadata":{}},{"cell_type":"code","source":"print(train.info())","metadata":{"execution":{"iopub.status.busy":"2021-09-21T14:16:15.232957Z","iopub.execute_input":"2021-09-21T14:16:15.234264Z","iopub.status.idle":"2021-09-21T14:16:15.249202Z","shell.execute_reply.started":"2021-09-21T14:16:15.234213Z","shell.execute_reply":"2021-09-21T14:16:15.248325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Nan values were not found. Then we will plot some features distribution, for example top 6 most numerous features.","metadata":{}},{"cell_type":"code","source":"d = {}\nfor column in train.columns:\n    d[column] = train[column].nunique()\nprint(d)\nnumerous_columns = list(dict(sorted(d.items(), key=lambda x: x[1], reverse=True)).keys())[:6]\nprint(numerous_columns)\nf, axes = plt.subplots(2, 3)\nfor column, ax in zip(numerous_columns, axes.flatten()):\n        sns.boxplot(x=train[column], ax=ax)\n\n\n\n    \n","metadata":{"execution":{"iopub.status.busy":"2021-09-21T14:16:15.250688Z","iopub.execute_input":"2021-09-21T14:16:15.251388Z","iopub.status.idle":"2021-09-21T14:16:16.012391Z","shell.execute_reply.started":"2021-09-21T14:16:15.251338Z","shell.execute_reply":"2021-09-21T14:16:16.0114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now it's time to build corr matrix and watch dependency between features","metadata":{}},{"cell_type":"code","source":"corr = train.corr()\ncorr.style.background_gradient(cmap='coolwarm')","metadata":{"execution":{"iopub.status.busy":"2021-09-21T14:16:16.014922Z","iopub.execute_input":"2021-09-21T14:16:16.015288Z","iopub.status.idle":"2021-09-21T14:16:16.099684Z","shell.execute_reply.started":"2021-09-21T14:16:16.015246Z","shell.execute_reply":"2021-09-21T14:16:16.098728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Correlation between features mostly low, big correlation(0.8 < corr < 1) only between target column and 'ram'. Our dataset is pretty good, but i would try to make it a little better by removing outliers( I hope not worse :)). For this purpose we will use z-normalization.","metadata":{}},{"cell_type":"code","source":"z_scores = stats.zscore(train)\nabs_z_scores = np.abs(z_scores)\nfor column in abs_z_scores.columns:\n    print(column + ' ' + ' min:' + str(abs_z_scores[column].min()) + ' median:' + str(abs_z_scores[column].median()) + ' max:' + str(abs_z_scores[column].max()))\nfiltered_entries = (abs_z_scores < 2.5).all(axis=1)\nnew_train = train[filtered_entries]\ny = new_train['price_range']\nX = new_train.drop(['price_range'], axis=1)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-09-21T14:16:16.10113Z","iopub.execute_input":"2021-09-21T14:16:16.10143Z","iopub.status.idle":"2021-09-21T14:16:16.133942Z","shell.execute_reply.started":"2021-09-21T14:16:16.101391Z","shell.execute_reply":"2021-09-21T14:16:16.13292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we start to train our ML models. We will use roc auc score and classification report metrics as our main metrics for the quality assessment of our models.","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\nestimator = []\nclf = DecisionTreeClassifier(random_state=42)\nparams = {'max_depth': range(1,11), 'min_samples_split': range(2,11), 'min_samples_leaf': range(1,11)}\ngcv = GridSearchCV(clf, params, n_jobs=-1)\ngcv.fit(X_train, y_train)\nbest_gcv = gcv.best_estimator_\nestimator.append(('dtc', best_gcv))\nprint(best_gcv)\nprint()\ntree_predict_roc = best_gcv.predict_proba(X_test)\ntree_predict = best_gcv.predict(X_test)\nprint('roc_auc_score:', roc_auc_score(y_test, tree_predict_roc, average=\"weighted\", multi_class=\"ovr\"))\nprint()\nprint(classification_report(y_test, tree_predict))\n","metadata":{"execution":{"iopub.status.busy":"2021-09-21T14:16:16.135186Z","iopub.execute_input":"2021-09-21T14:16:16.135495Z","iopub.status.idle":"2021-09-21T14:16:36.797843Z","shell.execute_reply.started":"2021-09-21T14:16:16.135465Z","shell.execute_reply":"2021-09-21T14:16:36.796889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svc = SVC(random_state=42, probability=True)\nparam_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}\ngcv = GridSearchCV(svc, param_grid, n_jobs=-1)\ngcv.fit(X_train, y_train)\nbest_gcv = gcv.best_estimator_\nestimator.append(('svc', best_gcv))\nprint(best_gcv)\nprint()\nsvm_predict_roc = best_gcv.predict_proba(X_test)\nsvm_predict = best_gcv.predict(X_test)\nprint('roc_auc_score:', roc_auc_score(y_test, svm_predict_roc, average=\"weighted\", multi_class=\"ovr\"))\nprint()\nprint(classification_report(y_test, svm_predict))\n","metadata":{"execution":{"iopub.status.busy":"2021-09-21T14:16:36.799247Z","iopub.execute_input":"2021-09-21T14:16:36.799513Z","iopub.status.idle":"2021-09-21T14:17:11.989395Z","shell.execute_reply.started":"2021-09-21T14:16:36.799482Z","shell.execute_reply":"2021-09-21T14:17:11.988348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Also we can try XGBClassifier method, but execute time of this algorithm is too long for multiclass classification.\n[Read more!](https://towardsdatascience.com/xgboost-for-multi-class-classification-799d96bcd368)","metadata":{}},{"cell_type":"code","source":"'''xgb = XGBClassifier(objective='multi:softprob', nthread=4, eval_metric='mlogloss', random_state=42)\nparameters = {'max_depth': range (2, 10, 1), 'n_estimators': range(100, 220, 40), 'learning_rate': [0.1, 0.01, 0.05]}\ngcv = GridSearchCV(xgb, parameters, n_jobs=-1)\ngcv.fit(X_train, y_train)\nbest_gcv = gcv.best_estimator_\nestimator.append(('xgb', best_gcv))\nprint(best_gcv)\nprint()\nxgb_predict_roc = best_gcv.predict_proba(X_test)\nxgb_predict = best_gcv.predict(X_test)\nprint('roc_auc_score:', roc_auc_score(y_test, xgb_predict_roc, average=\"weighted\", multi_class=\"ovr\"))\nprint()\nprint(classification_report(y_test, xgb_predict))'''","metadata":{"execution":{"iopub.status.busy":"2021-09-21T14:17:11.991196Z","iopub.execute_input":"2021-09-21T14:17:11.991505Z","iopub.status.idle":"2021-09-21T14:17:11.99945Z","shell.execute_reply.started":"2021-09-21T14:17:11.991469Z","shell.execute_reply":"2021-09-21T14:17:11.998503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"param_grid_nb = { 'var_smoothing': np.logspace(0,-9, num=100)}\ngcv = GridSearchCV(estimator=GaussianNB(), param_grid=param_grid_nb, n_jobs=-1)\ngcv.fit(X_train, y_train)\nbest_gcv = gcv.best_estimator_\nestimator.append(('gauss', best_gcv))\nprint(best_gcv)\nprint()\ngauss_predict_roc = best_gcv.predict_proba(X_test)\ngauss_predict = best_gcv.predict(X_test)\nprint('roc_auc_score:', roc_auc_score(y_test, gauss_predict_roc, average=\"weighted\", multi_class=\"ovr\"))\nprint()\nprint(classification_report(y_test, gauss_predict))","metadata":{"execution":{"iopub.status.busy":"2021-09-21T14:17:12.001114Z","iopub.execute_input":"2021-09-21T14:17:12.001424Z","iopub.status.idle":"2021-09-21T14:17:13.659574Z","shell.execute_reply.started":"2021-09-21T14:17:12.001387Z","shell.execute_reply":"2021-09-21T14:17:13.658682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have trained three different ML models. For making our results even better let's try to do assembly of our models and get new results by voting.","metadata":{}},{"cell_type":"code","source":"vot_hard = VotingClassifier(estimators = estimator, voting ='hard')\nvot_hard.fit(X_train, y_train)\ny_pred = vot_hard.predict(X_test)\nvot_soft = VotingClassifier(estimators = estimator, voting ='soft')\nvot_soft.fit(X_train, y_train)\ny_pred_roc = vot_soft.predict_proba(X_test)\nprint('roc_auc_score:', roc_auc_score(y_test, y_pred_roc, average=\"weighted\", multi_class=\"ovr\"))\nprint()\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-09-21T14:17:13.662174Z","iopub.execute_input":"2021-09-21T14:17:13.662961Z","iopub.status.idle":"2021-09-21T14:17:15.008269Z","shell.execute_reply.started":"2021-09-21T14:17:13.66292Z","shell.execute_reply":"2021-09-21T14:17:15.007281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Conclusion: best accuracy and best roc auc score we have in SVC method. When we tried to make an assemble, our metrics became lower because of low performance of other algorithms.","metadata":{}}]}