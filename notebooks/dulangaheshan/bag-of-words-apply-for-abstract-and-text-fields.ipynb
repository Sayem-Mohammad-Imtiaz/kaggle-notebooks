{"cells":[{"metadata":{},"cell_type":"markdown","source":"## About this notebook\nIn this notebook, I applied bag of word for abstract and text columns and generated new files. I hope this will help some one who try to solve this tasks\nI used output files from [xhlulu's kernel output](https://www.kaggle.com/xhlulu/cord-19-eda-parse-json-and-generate-clean-csv),Go and check it and give credits.\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import nltk    \nimport random  \nimport string\n\nimport bs4 as bs  \nimport urllib.request  \nimport re \n\nimport os\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\n\nimport os\n\ndirectory = '/kaggle/input/cord-19-eda-parse-json-and-generate-clean-csv/'\n\nfor dirname, _, filenames in os.walk(directory):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"comm_use_df = pd.read_csv(\"/kaggle/input/cord-19-eda-parse-json-and-generate-clean-csv/clean_comm_use.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"comm_use_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"comm_use_df.columns\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**corpus into individual sentences**\"\nconvert the sentence to lower case, and then remove the punctuation and empty spaces from the text. and remove abstract key in every corpus"},{"metadata":{},"cell_type":"markdown","source":"**tokenize the sentences in the corpus and create a dictionary that contains words and their corresponding frequencies in the corpus**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def format_corpus(corpus):  \n    for i in range(len(corpus)):\n        corpus [i] = corpus [i].lower()\n        corpus [i] = re.sub(r'\\W',' ',corpus [i])\n        corpus [i] = re.sub(r'\\s+',' ',corpus [i])\n    return corpus","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**tokenize the sentences in the corpus and create a dictionary that contains words and their corresponding frequencies in the corpus**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def word_frequencies(corpus):\n    wordfreq = {}\n    for sentence in corpus:\n        tokens = nltk.word_tokenize(sentence)\n        for token in tokens:\n            if token not in wordfreq.keys():\n                wordfreq[token] = 1\n            else:\n                wordfreq[token] += 1\n    return wordfreq","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_bow_csv(csv_df,df_name): \n    all_rows = []\n    for i, row in csv_df.iterrows():\n        row = []\n        df = comm_use_df.loc[i]\n        row.append(df[\"paper_id\"])\n        abstract = str(df[\"abstract\"])[8:] ## 1st 8 chars contain abstract word\n        abs_corpus = format_corpus(nltk.sent_tokenize(abstract))\n        abs_wordfreq = word_frequencies(abs_corpus)\n#         row.append(abs_wordfreq)\n        \n        csv_df[\"BOW abstract\"] = str(abs_wordfreq)\n        text = str(df[\"text\"]) ## 1st 8 chars contain abstract word\n        text_corpus = format_corpus(nltk.sent_tokenize(text))\n        text_wordfreq = word_frequencies(text_corpus)\n#         row.append(text_wordfreq)\n        csv_df[\"BOW text\"] = str(text_wordfreq)\n    print(csv_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"comm_use_df[\"BOW abstract\"] = \"\"\ncomm_use_df[\"BOW text\"] = \"\"\nmake_bow_csv(comm_use_df,\"filename\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"comm_use_df.to_csv('BOW_comm_use.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"non_comm_use_df = pd.read_csv(\"/kaggle/input/cord-19-eda-parse-json-and-generate-clean-csv/clean_noncomm_use.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"non_comm_use_df[\"BOW abstract\"] = \"\"\nnon_comm_use_df[\"BOW text\"] = \"\"\nmake_bow_csv(non_comm_use_df,\"filename\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"non_comm_use_df.to_csv('BOW_non_comm_use.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}