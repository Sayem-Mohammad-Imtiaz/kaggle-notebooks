{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Langue des signes : réseaux de neurones","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Keras et Tensorflow","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Pour installer Keras et Tensorflow sans GPU :","execution_count":null},{"metadata":{},"cell_type":"raw","source":"conda install -c conda-forge keras\nconda install -c conda-forge tensorflow ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Pour installer la version GPU sous windows, cf https://medium.com/@raza.shahzad/setting-up-tensorflow-gpu-keras-in-conda-on-windows-10-75d4fd498198  \nSous Linux : http://deeplearning.lipingyang.org/2017/08/01/install-keras-with-tensorflow-backend/  \nSous MacOS (avec GPU Nvidia) : https://blog.wenhaolee.com/run-keras-on-mac-os-with-gpu/","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Initialisations","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Directive pour afficher les graphiques dans Jupyter\n%matplotlib inline\n\n# Pandas : librairie de manipulation de données\n# NumPy : librairie de calcul scientifique\n# MatPlotLib : librairie de visualisation et graphiques\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import model_selection\n\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score,auc, accuracy_score\n\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn import datasets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.datasets import mnist\n\nfrom keras.models import Sequential, load_model\n\nfrom keras.layers import Dense, Dropout, Flatten\n\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\n\nfrom keras.utils.np_utils import to_categorical","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Le dataset du langage des signes","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"On utilise le dataset du langage des signes :  \nhttps://www.kaggle.com/datamunge/sign-language-mnist#american_sign_language.PNG","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://storage.googleapis.com/kagglesdsdata/datasets/3258/5337/amer_sign2.png?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1582898150&Signature=FSNN2mBuff7zGjEYUvGBn%2FrLFoYAGfkl5ivl6PT127E7NEAAnfxyWKOLtSpRN3ZN4NbBoXhzo%2Bee%2F5rC%2F7rnI1SyTljAIzjqcE9%2BMINHU3IFBJqJErsH5ilIln2d73QG%2BMXz8F3jGezxjISP%2BGa3SD7WC13og1hpRHMjS0bo4teSkZCRNycHUaCQV16ZRGmhpgftAuhBxPUFZBqTt46nMpnG5pYpl6NYRAD4ss3%2B7BvmPS%2FUMzFwDCeZsNLq0VNcqpl05isQZ2qT1KhFdg1j0K0zp%2BO%2BIALp42iselnVsx%2B1cc97YsELZd1t6mIp6TrTUQ06HndlxSw9J1FilaQKdg%3D%3D\">","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv('../input/sign-language-mnist/sign_mnist_train/sign_mnist_train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Le dataset est bien équilibré (mais il manque les lettres Y et Z) :","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.label.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\nprint(labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On convertit les lignes de pixels en matrices (images) :","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"n_samples = len(df.index)\nimages = np.array(df.drop(['label'],axis=1))\nimages = images.reshape(n_samples,28,28)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On affiche les 50 premiers :","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,20))\nfor i in range(0,49) :\n    plt.subplot(10,5,i+1)\n    plt.axis('off')\n    plt.imshow(images[i], cmap=\"gray_r\")\n    plt.title(labels[df.label[i]])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Réseaux denses (sklearn)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"On sépare la cible et les caractéristiques :","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df['label']\nX = df.drop(['label'] , axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On normalise les valeurs entre 0 et 1 :","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = X/255","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Séparation train / test :","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On utilise la méthode *MLPClassifier* de *sklearn* pour utiliser un réseau de neurones à deux couches cachées de 200 et 60 neurones :","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\nmlp = MLPClassifier(hidden_layer_sizes=(200,60))\nmlp.fit(X_train,y_train)\ny_mlp = mlp.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"La pertinence est très bonne :","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"mlp_score = accuracy_score(y_test, y_mlp)\nprint(mlp_score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"et la matrice de confusion :","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(y_test, y_mlp, rownames=['Reel'], colnames=['Prediction'], margins=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Réseaux denses (Keras/Tensorflow)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"La définition du même réseau de neurones est un peu plus compliquée avec *Keras*, mais il est utile de comprendre cette première étape avant d'utiliser les réseaux convolutifs","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Comme l'activation d'un neurone donne une valeur (probabilité) entre 0 ou 1, on code la cible (classes entre 0 et 24) sous la forme d'un vecteur de 0 ou 1 (*one hot encoding*) avec *to_categorical* :","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils.np_utils import to_categorical","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y[0])\ny_cat = to_categorical(y)\nprint(y_cat[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On a seulement 25 classes (il manque les Y et Z dans le dataset) :","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"num_classes = y_cat.shape[1]\nprint(num_classes)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On sépare train et test :","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Pour Keras, il est nécessaire d'avoir des tableaux et non des dataframes :","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.array(X_train)\nX_test = np.array(X_test)\ny_train = np.array(y_train)\ny_test = np.array(y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On va utiliser une architecture en *couches* (modèle *Sequential*), avec des couches *denses* :","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On définit un modèle à deux couches cachées de 200 et 60 neurones  \nLa dernière couche comporte 25 neurones (le nombre de classes) pour la classification :","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(200, activation='relu'))\nmodel.add(Dense(60, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"L'activation de la dernière couche est un *softmax* : la somme des valeurs de l'activation des neurones de la dernière couche est 1  \n(on interprète la sortie des derniers neurones comme une probabilité d'appartenance à la classe correspondante)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"On \"compile\" le modèle, avec une *categorical_crossentropy* comme mesure de distance (distance probabiliste multi classes)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = model.fit(X_train , y_train , validation_data=(X_test,y_test), epochs=30, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Pertinence :","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"La variable *train* mémorise l'historique des scores sur l'ensemble d'apprentissage :","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.history['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"et sur l'ensemble de validation :","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.history['val_accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On définit une fonction pour afficher un graphique des scores :","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_scores(train) :\n    accuracy = train.history['accuracy']\n    val_accuracy = train.history['val_accuracy']\n    epochs = range(len(accuracy))\n    plt.plot(epochs, accuracy, 'b', label='Score apprentissage')\n    plt.plot(epochs, val_accuracy, 'r', label='Score validation')\n    plt.title('Scores')\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_scores(train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exercice : tester les réseaux de neurones sur le dataset *fashion_MNIST*","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Réseaux denses (sklearn)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Chargement des données","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/fashionmnist/fashion-mnist_train.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Préparation des données d'entrainement et de test.\nConversion des données DataFrame en tableaux.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = [\"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\n          \"Sneaker\",\"Bag\",\"Ankle boot\"]\ny = df['label']\nX = df.drop(['label'], axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On utilise la méthode *MLPClassifier* de *sklearn* pour utiliser un réseau de neurones à deux couches cachées de 200 et 60 neurones :","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"mlp = MLPClassifier(hidden_layer_sizes=(200,60))\nmlp.fit(X_train,y_train)\ny_mlp = mlp.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mlp_score = accuracy_score(y_test, y_mlp)\nprint(mlp_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(y_test, y_mlp, rownames=['Reel'], colnames=['Prediction'], margins=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"La pertinence est assez bonne(0.88) et la matrice de confusion est aussi assez bonne.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Réseaux denses (Keras/Tensorflow)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Comme l'activation d'un neurone donne une valeur (probabilité) entre 0 ou 1, on code la cible (classes entre 0 et 24) sous la forme d'un vecteur de 0 ou 1 (*one hot encoding*) avec *to_categorical* :","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils.np_utils import to_categorical\nprint(y[0])\ny_cat = to_categorical(y)\nprint(y_cat[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Pour Keras on utilise des tableaux","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.array(X_train)\nX_test = np.array(X_test)\ny_train = np.array(y_train)\ny_test = np.array(y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On va utiliser une architecture en *couches* (modèle *Sequential*), avec des couches *denses* :","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On définit un modèle à deux couches cachées de 200 et 60 neurones  \nLa dernière couche comporte 25 neurones (le nombre de classes) pour la classification :","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"num_classes = y_cat.shape[1]\n\nmodel = Sequential()\nmodel.add(Dense(200, activation='relu'))\nmodel.add(Dense(60, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On \"compile\" le modèle, avec une *categorical_crossentropy* comme mesure de distance (distance probabiliste multi classes)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = model.fit(X_train , y_train , validation_data=(X_test,y_test), epochs=30, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_scores(train) :\n    accuracy = train.history['accuracy']\n    val_accuracy = train.history['val_accuracy']\n    epochs = range(len(accuracy))\n    plt.plot(epochs, accuracy, 'b', label='Score apprentissage')\n    plt.plot(epochs, val_accuracy, 'r', label='Score validation')\n    plt.title('Scores')\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_scores(train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"La pertinence est de 0.87% ce qui est très correct.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}