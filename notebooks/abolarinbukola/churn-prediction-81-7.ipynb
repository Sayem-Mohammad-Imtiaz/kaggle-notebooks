{"cells":[{"metadata":{},"cell_type":"markdown","source":"### INTRODUCTION\n\n#### Predicting the customer churn mainly through logistic regression\n#### churn class was classified into two categories  No(0) and Yes(1)\n#### Steps taken in preprocessing includes Data cleaning, Standardization etc\n#### Other models where used to compare accuracy\n\n### SIDE NOTE\n#### You can leave your question about any unclear part in the comment section\n#### Any correction will be highly welcomed"},{"metadata":{},"cell_type":"markdown","source":"### LOADING THE DATAFRAME"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import the neccesary libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nsns.set()\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import svm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '/kaggle/input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv'\n\ndf = pd.read_csv(path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df.describe(include = 'all')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### DATA CLEANING"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### This data is clean but on further analysis TotalCharges includes some empty value which we will replace with 0"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Value count of the column\ndf['TotalCharges'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Replacing the empty value with zero \ndf['TotalCharges'].replace(' ', 0, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['TotalCharges'].apply (lambda x: x== ' ')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Changing the column datatype to float\ndf['TotalCharges'] = df['TotalCharges'].astype('float')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### DATASET ANALYSIS AND OUTLIERS REMOVAL\n\n#### we will plot the distribution of all the numeric variables in other to be able to identify outliers and any other abnormalities\n#### Outliers will be dealt with by removing either top 1% or the bottom 1%\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['tenure']) #This distribution plot appears to be normal with no outlier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['MonthlyCharges']) #This distribution plot appears to be normal with no outlier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['TotalCharges'])#This distribution plot appears to be having a few outliers. Let's explore it further","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Selecting Totalcharges above 8500 to see if they are outliers\ndf[df['TotalCharges'].apply (lambda x: x > 8500)]\n#Upon further exploration they are not outliers","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### CHECKING OLS ASSUMPTIONS\n\n#### Let's check that our dataset are not violating any of this assumptions which includes:\n#### 1. No Endogeneity\n#### 2. Normality and Homoscedasticity\n#### 3.No Autocorrelation\n#### 4.NO multicollinearity: making sure our independents variables are not strongly related(correlated) with each other\n\n####  We are not violating  assumptions 1 through 3 but for NO multicollinearity we need to check"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Getting Variables in our dataframe\ndf.columns.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom statsmodels.tools.tools import add_constant\n\n# the target column (in this case 'churn') should not be included in variables\n#Categorical variables already turned into dummy indicator may or maynot be added if any\nvariable = df[['tenure', 'MonthlyCharges','TotalCharges',]]\nX = add_constant(variable)\nvif = pd.DataFrame()\nvif['VIF']  = [variance_inflation_factor(X.values, i) for i in range (X.shape[1])]\nvif['features'] = X.columns\n\nvif\n#Using 10 as the minimum vif values i.e any independent variable 10 and above will have to be dropped\n#From the results all independent variable are below 10","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Standardization\n\n#### Standardizing helps to give our independent varibles a more standard and relatable numeric scale, it also helps in improving model accuracy\n#### We are going to standardize only our numerical variables then use new columns to hold the resulting values"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Selecting the variable\nscale_int = df[['MonthlyCharges']]\n\nscaler = StandardScaler()#Selecting the standardscaler\nscaler.fit(scale_int)#fitting our independent variables","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['scaled_monthly']= scaler.transform(scale_int)#scaling","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scale_int = df[['tenure']] #Selecting the variable\n\nscaler = StandardScaler()#Selecting the standardscaler\nscaler.fit(scale_int)#fitting our independent variables","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['scaled_tenure']= scaler.transform(scale_int)#scaling","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scale_int = df[['tenure']] #Selecting the variable\n\nscaler = StandardScaler()#Selecting the standardscaler\nscaler.fit(scale_int)#fitting our independent variables","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['scaled_charges']= scaler.transform(scale_int)#scaling","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()# Checking our scaled results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe(include = 'all')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dropping columns not needed\ndf.drop(['tenure','MonthlyCharges','customerID', 'TotalCharges'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dummy Variables\n#### churn is a categorical variable so we need  to turn it into a dummy indicator before we can perform our regression\n#### For other categorical variable we will use get_dummies"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Turning Churn to a dummy indicator with 1 standing yes and 0 standing for no\ndf['Churn'] = df['Churn'].map({'Yes':1, 'No':0})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Variables in our dataframe\ndf.columns.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#new dataframe with dummies\ndf_dummies = pd.get_dummies(df, drop_first = True)\n\ndf_dummies","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### LOGISTIC REGRESSION"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Declaring independent variable i.e x\n#Declaring Target variable i.e y\nx = df_dummies.drop('Churn', axis = 1)\ny = df_dummies['Churn']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Splitting our data into train and test dataframe\nx_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2, random_state = 24)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg = LogisticRegression() #Selecting the model\nreg.fit(x_train, y_train) #training the model with x_train and y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predicting with our already trained model using x_test\ny_hat = reg.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Getting the accuracy of our model\nacc = metrics.accuracy_score(y_hat, y_test)\nacc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#The intercept for our regression\nreg.intercept_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Coefficient for all our variables\nreg.coef_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### CONFUSION MATRIX"},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_hat,y_test)\ncm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Format for easier understanding\ncm_df = pd.DataFrame(cm)\ncm_df.columns = ['Predicted 0','Predicted 1']\ncm_df = cm_df.rename(index={0: 'Actual 0',1:'Actual 1'})\ncm_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Our model predicted '0' correctly 954 times while  predicting '0' incorrectly 154 times\n#### Also it predicted  '1'  correctly 198 times while predicting '1' incorrectly  103"},{"metadata":{},"cell_type":"markdown","source":"### OTHER MODELS"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier # for K nearest neighbours\nfrom sklearn import svm #for Support Vector Machine (SVM) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt = DecisionTreeClassifier()\ndt.fit(x_train,y_train)\ny1 = dt.predict(x_test)\nacc1 = metrics.accuracy_score(y1, y_test)\nacc1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kk = KNeighborsClassifier()\nkk.fit(x_train,y_train)\ny2 = kk.predict(x_test)\nacc2 = metrics.accuracy_score(y2, y_test)\nacc2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sv = svm.SVC()\nsv.fit(x_train,y_train)\ny3 = sv.predict(x_test)\nacc3 = metrics.accuracy_score(y3, y_test)\nacc3","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### After comparison with some other model  logistic regression gave us the best accuracy with ~81.8% followed closely by svm model with ~81.7%"},{"metadata":{},"cell_type":"markdown","source":"###  CONCLUSION\n#### Let's try to make a table and with weight(BIAS) and odds "},{"metadata":{"trusted":true},"cell_type":"code","source":"result = pd.DataFrame(data = x.columns.values, columns = ['features'] )\nresult['weight'] = np.transpose(reg.coef_)\nresult['odds'] = np.exp(np.transpose(reg.coef_))\n\nresult","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":4}