{"cells":[{"metadata":{"_uuid":"74870ef203b02ebb7968fa0b25840f8b73e844a1"},"cell_type":"markdown","source":"# Flavors of Cacao - Análisis de visualización"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":false,"_kg_hide-input":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sb\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_blobs # load make_blobs to simulate data\nfrom sklearn import decomposition # load decomposition to do PCA analysis with sklearn","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"334414472f944cb6001dc98b6da47d5137dc2295"},"cell_type":"markdown","source":"Vamos a trabajar con un set de datos sobre un ranking de barras de chocolate.\n\nLo primero de todo es cargar con el dataset y para eso necesitamos parsear CSV ya que la información viene con este formato."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"chocolate_data = pd.read_csv(\"../input/flavors_of_cacao.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e6f2958860eea0580683152418c2f872da650d3b"},"cell_type":"markdown","source":"Para trabajar con este dataset primero vamos a transformar un par de datos para que sea más fácil trabajar en el futuro con ellos.\n\nPrimero vamos a modificamos el nombre de las columnas para que sea más fácil trabajar con ellas, quitando espacios y nombres muy largos."},{"metadata":{"trusted":true,"_uuid":"1bfe35b6d5e86a3f1b3c80d7cd080b8dec0bdefc"},"cell_type":"code","source":"original_col = chocolate_data.columns\nnew_col = ['Company', 'Species', 'REF', 'ReviewDate', 'CocoaPercent','CompanyLocation', 'Rating', 'BeanType', 'Country']\nchocolate_data =chocolate_data.rename(columns=dict(zip(original_col, \nnew_col)))\nchocolate_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8e27e28d78f6bb5e5d03d34e5f5add172ea236a0"},"cell_type":"markdown","source":"Luego vamos a transformar los porcentajes de la columna **CocoaPercent**  a valores entre **0** y **1** para que sea más fácil poder graficar/comparar estos valores."},{"metadata":{"trusted":true,"_uuid":"3079a3b12a562576e7e902c6513d4a77089c934f"},"cell_type":"code","source":"#Remove % sign from CocoaPercent column \nchocolate_data['CocoaPercent'] = chocolate_data['CocoaPercent'].str.replace('%','').astype(float)/100\nchocolate_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"82b50720598c01cbd2b0e8dfdaa57b3a234a1897"},"cell_type":"markdown","source":"En los siguientes graficos podemos ver la distribución de valores que tienen las Columnas **Rating**, **REF** y **CocoaPercent**\n\nComo podemos ver en el primer gráfico el **Rating** varía desde **1** hasta **5** pero la mayoría de los chocolates están entre los valores de **2,5** y **4** de **Rating**\n\nEn el caso de **REF** el cual son los números de referencia de los datos agregados. Mientras más alto el **REF** más nuevo el dato.\n\nPor último como podemos ver el en el tercer gráfico, el **CocoaPercent** varía entre **0.4** y **1** (**40%** y **100%** ya que nosotros modificamos esta columna). Acá podemos visualizar que claramente que las companias tienen una tendencia a fabricar chocolates con un ** 70%** de Cacao."},{"metadata":{"trusted":true,"_uuid":"fd8f6ce4547b27b8fe98a55b5cb943b4fc060fe7"},"cell_type":"code","source":"sb.distplot(chocolate_data['Rating'],kde = False)\nplt.show()\nsb.distplot(chocolate_data['REF'],kde = False)\nplt.show()\nsb.distplot(chocolate_data['CocoaPercent'],kde = False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a19ba1db0f37918d1bd3171b63813067c3e22585"},"cell_type":"markdown","source":"En los siguientes gráficos se intenta visualizar si hay relación entre ciertas columnas.\n\nEn el primer gráfico vemos que no hay mucha relación entre  el porcentaje de cacao y el rating ya que la mayor parte de los datos están agrupados en el centro con algunos casos dispersos.\n\nUn caso parecido pasa con el segundo gráfico. Lo que podríamos decir es que se fueron \"normalizando\" los ratings a lo largo del tiempo  entre los valores  **2** y **4**"},{"metadata":{"trusted":true,"_uuid":"d83a33ec22c01f7f6eb1aeab90fc1ba848b71018"},"cell_type":"code","source":"ax = plt.axes()\nax.scatter(chocolate_data['CocoaPercent'], chocolate_data['Rating'])\nax.set(xlabel='Cocoa Strength',\n       ylabel='Rating',\n       title='Cocoa Strength vs Rating')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e353bc89257c7003e044e2097ed63a5f79cacfd2"},"cell_type":"code","source":"ax = plt.axes()\nax.scatter(chocolate_data['ReviewDate'], chocolate_data['Rating'])\nax.set(xlabel='ReviewDate',\n       ylabel='Rating',\n       title='Country vs Rating')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"27962448030d7a4bbb858617aec79c281b311230"},"cell_type":"markdown","source":"En este gráfico de barras podemos visualizar las 5 compañias que más aparecen en el dataset siendo *Soma* la que ha liderado el ranking."},{"metadata":{"trusted":true,"_uuid":"f413540a72799a685dfdbb458ca7be5fc43c5add"},"cell_type":"code","source":"bc = plt.axes()\n\nCompanyfreq=chocolate_data['Company'].value_counts()\nx=[] #init empty lists\ny=[]\nfor i in range (0,5):\n    x.append(Companyfreq.axes[0][i])\n    y.append(Companyfreq[i])\n    \nbc.bar(x,y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a89f9837444a9d6876ce91d6f8d7437d49d5325f"},"cell_type":"markdown","source":"Por otro lado podemos agrupar datos de manera que podemos sacar la media del rating de cada pais y así poder graficar un ranking de los paises que son los mejores productores de barras de chocolate segun este dataset."},{"metadata":{"trusted":true,"_uuid":"e48d053a91f024660e31a98793ed80c96b0a7c05"},"cell_type":"code","source":"mean_by_country = chocolate_data.groupby([\"CompanyLocation\"])['Rating'].mean()\nmean_sorted = mean_by_country.sort_values(ascending=False)\ntop_bottom_5 = pd.concat([mean_sorted[:5], mean_sorted[-5:]])\ntop_bottom_5.plot('barh')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2987456dbefa02e479ea31512811f19b5371f8e3"},"cell_type":"markdown","source":"Podemos definir un sistema de rating que sea\n\n*  Raiting < 3.0  => Insatisfactorio\n*  Raiting >= 3.0 Y Raiting < 4.0  =>  Satisfactorio\n*  Raiting >= 4.0  => Premium\n\nComo podemos ver en el gráfico un **5.6%** de las barras de chocolate se las conciera como Premium"},{"metadata":{"trusted":true,"_uuid":"d96ebf732284c745128db6b5adfc3ec1fa2fdcba"},"cell_type":"code","source":"unsatisfactory = chocolate_data[chocolate_data['Rating'] < 3.0] \nsatisfactory = chocolate_data[(chocolate_data['Rating'] >= 3.0) & (chocolate_data['Rating'] < 4.0)] \npre_elite = chocolate_data[chocolate_data['Rating'] >= 4.0] \nlabel_names=['Insatisfactorio','Satisfactorio','Premium']\n\nsizes = [unsatisfactory.shape[0],satisfactory.shape[0],pre_elite.shape[0]]\nexplode = (0.05,0.05,0.05)\nplt.pie(sizes,labels=label_names,explode=explode,autopct='%1.1f%%',pctdistance=0.85\n        ,startangle=90,shadow=True)\nfig=plt.gcf()\nmy_circle=plt.Circle((0,0),0.7,color='white') #white center\nfig.gca().add_artist(my_circle)\nplt.axis('equal')\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f1559d316eed38b77b4b3ddde61713dfe4c123f8"},"cell_type":"markdown","source":"**===================================================================================================================================================**"},{"metadata":{"_uuid":"f9f6fdcf0a36921b316b8f54005d19ac639f64a6"},"cell_type":"markdown","source":"# Principal Component Analysis (PCA)\n\nTrabajar con dataset muy grandes trae muchos inconvenientes no solo en cuestión de tiempo de procesamiento sino tambien a la hora de graficar.\n\nEl análisis de componentes principales, o **PCA**, es una técnica estadística para convertir datos de alta a baja dimensionalidad. Esto se realiza al seleccionar las características más importantes que capturan la máxima información sobre el conjunto de datos. Las características se seleccionan en base a la varianza que causan en la salida. La característica que causa la mayor variación se la llama componente principal. La característica que es responsable de la segunda varianza más alta se la llama segundo componente principal, y así sucesivamente. Es importante mencionar que los componentes principales no tienen ninguna correlación entre sí.\n\nPara este caso vamos a simular el dataset usando el modulo **make_blobs** de la librerpia **scikit-learn** como tambien el modulo de **PCA**  que ya importarmos al principio.\n\nEl modulo **make_blobs** sirve para contruir datasets simulados, sirve facilmente para contruir multiples clusters gaussianos y es muy utlizado para testear algoritmos de clustering.\nEn este caso vamos a construir una matriz de 100x10 (100 muestras con 10 observaciones). Estas 100 muestras fueron generadas por 4 clusters diferentes. Ya que estamos simulando la información nosotros sabemos  a que cluster pertenece cada muestra."},{"metadata":{"trusted":true,"_uuid":"ee323e75f8237e6a50dc18ac5ef58e5d78d6bfd8"},"cell_type":"code","source":"X1, Y1 = make_blobs(n_features=10, \n         n_samples=100,\n         centers=4, random_state=4,\n         cluster_std=2)\nprint(X1.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1ff05154803d6caa8cdc85e8ee1f75192fa3f86e"},"cell_type":"markdown","source":"**X1** es la matriz de 100x10 e **Y1** es la asginación de cada cluster. \n\nEl siguiente paso es crear el modelo de **PCA** con **4** componentes."},{"metadata":{"trusted":true,"_uuid":"79de6e84ffbf6e22d6884650c2bb7a9c00195ed6"},"cell_type":"code","source":"pca = decomposition.PCA(n_components=4)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"223b5c12500046ac756503ef7c82e348a657c1f3"},"cell_type":"markdown","source":"Ya que no tenemos que hacer transformaciónes sobre los datos, pasamos al siguiente paso donde ejecutamos la etapa de entrenamiento con la matriz **X1** y obtenemos nuestras componentes principales."},{"metadata":{"trusted":true,"_uuid":"edb151f432e44cb9f304a39e926a4d4b827efee5"},"cell_type":"code","source":"pc = pca.fit_transform(X1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bf784b5bb5ce6b97b58e05692533a00ef05c71f4"},"cell_type":"markdown","source":"Ahora volvemos a genera la matriz incluyendo el vector de clusters previamente creador por la librería."},{"metadata":{"trusted":true,"_uuid":"bc596f30b030f5e3a2ba3751675ea5ae91bee3e1"},"cell_type":"code","source":"pc_df = pd.DataFrame(data = pc , \n        columns = ['PC1', 'PC2','PC3','PC4'])\npc_df['Cluster'] = Y1\npc_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"66e1cec4904b2b52f1c378c03407a009b29c9caa"},"cell_type":"markdown","source":"Si examinamos la varianza de cada componente obtenida podemos notar que el las primeras **2** componentes abarcan el **70%** de la variación del dataset"},{"metadata":{"trusted":true,"_uuid":"ffe199543a6281d375976bb87ce9b37bddb7f255"},"cell_type":"code","source":"print(pca.explained_variance_ratio_)\nprint(str(round((pca.explained_variance_ratio_[0] + pca.explained_variance_ratio_[1])*100,2))+\"%\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4a9fb782c558dc10cfacf36161e8ccafae320ba3"},"cell_type":"markdown","source":"Acá podemos ver la varianza individual de cada componente"},{"metadata":{"trusted":true,"_uuid":"09e7153395a5e4049d55920d96a119c0c980b37c"},"cell_type":"code","source":"df = pd.DataFrame({'var':pca.explained_variance_ratio_,\n             'PC':['PC1','PC2','PC3','PC4']})\nsb.barplot(x='PC',y=\"var\", \n           data=df, color=\"c\");","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"135407acf274ea2be3fde788faa7122a62be0acd"},"cell_type":"markdown","source":"Ahora podemos usar las primeras **2** componentes principales (las que tienen una varianza mayor) para realizar un scatter plot."},{"metadata":{"trusted":true,"_uuid":"f7d3bff6366ff498b197ee2c3fb2c779fd38b8a6"},"cell_type":"code","source":"sb.lmplot( x=\"PC1\", y=\"PC2\",\n  data=pc_df, \n  fit_reg=False, \n  hue='Cluster', # color by cluster\n  legend=True,\n  scatter_kws={\"s\": 80}) # specify the point size","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a959f5acba9d991752f0fc579571be1f35f94ac3"},"cell_type":"markdown","source":"Podemos ver claramente los **4** clusters en nuestros datos, solo necesitamos de las **2** primeras componentes para separar completamente nuestros clusters."},{"metadata":{"_uuid":"afc6d5cf35762c0970363debbed5604d8538c7d2"},"cell_type":"markdown","source":"**===================================================================================================================================================**"},{"metadata":{"_uuid":"3b79e605bcb70f6de713578539c5276560f7bd86"},"cell_type":"markdown","source":"# Algoritmos genéticos\n\n## Teoría básica\nUn algoritmo genético se inspira en la teoría de Darwin de la selección Natural para resolver problemas de optimización. Es una buena solución sobre todo cuando se tiene información incompleta o imperfecta, o incluso limitada capacidad computacional.\nLos tres principios fundamentales necesarios para la evolución (según la Teoría de Darwin)  a suceder son: \n\n   1.  **Herencia:**  Debe ser un proceso por el cual los niños reciben la propiedad de sus padres.\n   2. **Variación:** Debe haber una variedad de rasgos presentes en la población o un medio de introducir una variación. \n   3. **Selección:** Debe existir un mecanismo por el que algunos miembros de la población puedan ser padres y transmitir su información genética y otros no (supervivencia del más apto).\n  \n## Como llevar los principios a un algoritmo genético\n\nHay 5 etapas en un algoritmo genético:\n1. Crear una población inicial\n2. Definir una función de fitness\n3. Seleccionar los padres\n4. Realizar un crossover (cruce)\n5. Realizar una mutación\n\n\n### Código\n\nA continuación vamos a mostrar un código en Python que realiza un algoritmo genético muy básico a modo de ejemplo en el cual se trata de reproducir/copiar una cadena de caracteres (el target en este caso) sin realmente usar la cadena más que para comparar.\n\nLa idea general de este algoritmo genético es un bucle que utiliza las funciones anteriores para generar una secuencia de gen candidato, compararla con la mejor opción anterior y mutarla al azar hasta que todos los genes coincidan con los del objetivo.\n\nHay muchas formas de calcular un valor de fitness (qué tan cerca está la cadena del objetivo) para la cadena generada. Para este problema en particular, simplemente contaremos el número de caracteres que son iguales entre la cadena candidata y la cadena de destino (target)."},{"metadata":{"trusted":true,"_uuid":"a901a32afaba6296e2f233b713d778974d98ff1d"},"cell_type":"code","source":"import datetime\nimport random\n\n#Definición de constantes\ngeneSet = \"abcdefghijklmnñopqrstuvwxyzABCDEFGHIJKLMNÑOPQRSTUVWXYZ \"\ntarget = \"Hola Mundo\"\n\n#Inicialización de variables\nrandom.seed(2)\nstartTime = datetime.datetime.now()\n\ndef generate_parent(lenght):\n    \"\"\"\n        Define muestra aleatoria para que sea nuestro padre\n        Ejemplo: random.sample(geneSet, 5) == > ['o', 'S', 'D', 'B', 'L']\n\n    \"\"\"\n    genes = []\n    while len(genes) < lenght:\n        sampleSize = min(lenght - len(genes), len(geneSet))\n        genes.extend(random.sample(geneSet, sampleSize))\n    return ''.join(genes)\n\ndef get_fitness(guess):\n    \"\"\"\n        Función de aptitud donde sumamos 1 si nuestra muestra aleatoria\n        coincide en lugar y caracter de nuestro target\n        Ejemplo: \n        zip(target, \"Ho iLEPHIZ\") sería\n        [('H', 'H'),\n         ('o', 'o'),\n         ('l', ' '),\n         ('a', 'i'),\n         (' ', 'L'),\n         ('M', 'E'),\n         ('u', 'P'),\n         ('n', 'H'),\n         ('d', 'I'),\n         ('o', 'Z')]\n         \n         al recorrerlo  la primera iteración expected = H y actual = H por lo tanto suma 1\n         .\n         .\n         .\n         en la ultima iteración expected = o y actual = Z por lo tanto suma 0\n         resultado es 2 por las 2 primeras iteraciones\n    \"\"\"\n    return sum(1 for expected, actual in zip(target, guess) if expected == actual)\n\ndef mutate(parent):\n    \"\"\"\n        Creamos una muestra aletoria y la vamos a agregar\n    \"\"\"\n    index = random.randrange(0, len(parent))\n    childGenes = list(parent)\n    newGene, alternate = random.sample(geneSet, 2)\n    childGenes[index] = alternate if newGene == childGenes[index] else newGene\n    return ''.join(childGenes)\n\ndef display(guess):\n    timeDiff =  datetime.datetime.now() - startTime\n    fitness = get_fitness(guess)\n    print('{}\\t{}\\t{}'.format(guess, fitness, timeDiff))\n    \nbestParent = generate_parent(len(target)) # Genera String aleatorio de la misma longitud que el target\nbestFitness = get_fitness(bestParent)\ndisplay(bestParent)\n\nwhile True:\n    child = mutate(bestParent)\n    childFitness = get_fitness(child)\n    if bestFitness >= childFitness:\n        continue\n    display(child)\n    if childFitness >= len(bestParent):\n        break\n    bestFitness = childFitness\n    bestParent = child","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e32dd501120891efe1a330caa2cf7aa9555ba672"},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}