{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import torch\nimport torchvision\nimport numpy\nimport matplotlib.pyplot as plt\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mnist_train=pd.read_csv('/kaggle/input/mnist-in-csv/mnist_train.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we generally load data using pandas just for Exploratory data analysis because pytorch has inbuilt dataloaders to create mini batches and many other features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"mnist_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Here we can see we have a column dedicated for label and other 784 data for 28*28 pixel of a image","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"random_sample=mnist_train.sample(8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_features=random_sample.drop('label',axis=1)\nimage_batch=(torch.tensor(image_features.values/255)).reshape(-1,28,28)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_batch.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid=torchvision.utils.make_grid(image_batch.unsqueeze(1),nrow=8)\nprint(grid.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The unsqueeze is used to add new axis or dimension to the image matrix","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,12))\nplt.imshow(grid.numpy().transpose(1,2,0))\nplt.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features=mnist_train.drop('label',axis=1)\ntrain_label=mnist_train['label']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data import Dataset,DataLoader","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# torch.from_numpy(image_features.values[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#custom datasets class must implement __getitem__ and __len__ methods\nclass MnistDataset(Dataset):\n    def __init__(self,path,transform=None):\n        #loading dataframe as xy\n        xy=pd.read_csv(path)\n        #x is for the image matrix\n        self.x=xy.iloc[:,1:].values\n        #y is for the label\n        self.y=xy['label']\n        #n_samples gives number of images\n        self.n_samples=len(xy)\n        self.transform=transform\n        \n    def __getitem__(self,index):\n        sample=self.x[index],np.array(self.y[index])\n        if self.transform is not None:\n            sample=self.transform(sample)\n        return sample\n    def __len__(self):\n        return self.n_samples\n\n#custom transformation class  must implement __call__\nclass ToTensor:\n    def __call__(self,sample):\n        inputs,target=sample\n        #from_numpy converts numpy arrays to tensors\n        return torch.from_numpy(inputs),torch.from_numpy(target)\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_path='/kaggle/input/mnist-in-csv/mnist_train.csv'\ntest_path='/kaggle/input/mnist-in-csv/mnist_test.csv'\ntrain_set=MnistDataset(train_path,transform=ToTensor())\n# test_set=MnistDataset(test_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"first_data=train_set[0]\nplt.imshow(first_data[0].numpy().reshape(28,28))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torchvision import transforms\n\ntrain_loader=DataLoader(train_set,batch_size=100,shuffle=True)\n# test_loader=DataLoader(test_set,batch_size=100,shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(iter(train_loader).next()[0][0].reshape(28,28))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"iter(train_loader).next()[0][0].dtype","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is very important to check the data type so we should convert the data to float during the training phase \nThese simple mistakes will cause hours of headache","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#it is 1 because of single channel of colour i.e Black&White or Grayscale image\ninput_size=1\n#first convolution converts 1 channel to 16 channels in feature maps\nhid1_size=16\n#similary to 32 channels\nhid2_size=32\n\nk_conv_size=5# kernel or filter size\nimport torch.nn.functional as F\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Net(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        self.layer1=torch.nn.Sequential(\n        torch.nn.Conv2d(input_size,hid1_size,k_conv_size),\n        torch.nn.BatchNorm2d(hid1_size),\n        torch.nn.ReLU(),\n        torch.nn.MaxPool2d(kernel_size=2)\n            \n        )\n        \n        self.layer2=torch.nn.Sequential(\n            torch.nn.Conv2d(hid1_size,hid2_size,k_conv_size),\n            torch.nn.BatchNorm2d(hid2_size),\n            torch.nn.ReLU(),\n            torch.nn.MaxPool2d(kernel_size=2)\n        )\n        self.fc=torch.nn.Linear(512,10)\n        \n        \n    def forward(self,x):\n        x=self.layer1(x)\n        \n        x=self.layer2(x)\n        #Changing the image into one dimensional tensor for feeding the fully connected layers\n        x=x.reshape(x.shape[0],-1)\n       \n        x=self.fc(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=Net()\ndevice=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#It is to check model accepts the input or not\n# x=torch.randn(100,1,28,28)\n# model(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr=1e-3\nloss_fn=torch.nn.CrossEntropyLoss()\noptimizer=torch.optim.SGD(model.parameters(),lr=lr,momentum=0.9)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs=3\nloss_values=[]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"targets=np.array([])\npreds=np.array([])\nfor epoch in range(epochs):\n    for i,(img,target) in enumerate(train_loader):\n        img=img.reshape(100,1,28,28).float().to(device)\n        optimizer.zero_grad()\n        output=model(img)\n        pred=torch.argmax(output,axis=1)\n#         print(target,pred)\n        targets=np.hstack([targets,target.cpu().numpy()])\n        preds=np.hstack([preds,pred.cpu().numpy()])\n        loss=loss_fn(output,target.to(device))\n        \n        loss.backward()\n        optimizer.step()\n        if i % 100==0:\n            print(loss)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score,recall_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(targets,preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"recall_score(targets,preds,average='macro')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}