{"cells":[{"metadata":{},"cell_type":"markdown","source":"#  **Simple and Multiple Linear Regression**\nLab Exercises - Week 2\n\n----------"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nprint(os.listdir(\"../input/data-for-lab-2\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn import linear_model as lm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Declaring an array\narr = np.array([[1,2,3],[4,5,6]])\n\nprint(\"Array dimensions:\\n\", arr.shape)\nprint(\"Array preview:\\n\", arr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Function to generate a Matrix with all values as 1.\nidentityMatrix = np.ones((2,2))\nprint(\"Identity Matrix:\\n\",identityMatrix)\n\n#Function to stack so as to make a single Matrix horizontally.\nx = np.hstack((identityMatrix,arr))\nprint(\"Stacking arrays:\\n\",x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dot Product \n#Calculation: [[7*11+8*13, 7*12+8*14],[9*11+10*13, 9*12+10*14]]\na = np.array([[7,8],[9,10]]) \nb = np.array([[11,12],[13,14]]) \nprint(np.dot(a,b))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Transpose\nmat = np.array([[7,8],[9,10],[11,12],[13,14]]) \n\nprint(\"Original Matrix:\\n\", mat)\nprint(\"Tranposed Matrix:\\n\", np.transpose(mat))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to calculate the inverse of a matrix\nmat = np.array([[7,8],[9,10]])\nprint(\"Matrix Inverse:\\n\", np.linalg.inv(mat))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 'x1' functions as an independent variable and 'y' as a dependent variable \ny = np.array([[1.55],[0.42],[1.29],[0.73],[0.76],[-1.09],[1.41],[-0.32]])\nx1 = np.array([[1.13],[-0.73],[0.12],[0.52],[-0.54],[-1.15],[0.20],[-1.09]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Generating regression coefficients\nid = np.ones((8,1))\nx = np.hstack((id,x1))\nbeta=(np.dot(np.dot(np.linalg.inv(np.dot(x.transpose(),x)),x.transpose()),y))\nprint(beta)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Result - Calculation\nyp1 = beta[0]+beta[1]*x1\nprint(np.hstack((x1,y,yp1)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Input Dataframe\nd = pd.DataFrame(np.hstack((x1,y)))\nd.columns = [\"x1\",\"y\"]\nprint(d)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Linear Regression - model fitting\nmodel = lm.LinearRegression()\nresults = model.fit(x1,y)\nprint (results)\nprint(model.intercept_, model.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Result: Scikit-Learn\nyp2 = model.predict(x1)\nprint(yp2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Linear Regression representation using scatter plot\nplt.scatter(x1,y)\nplt.plot(x1,yp2, color=\"blue\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Prediction for new values\nx1new = pd.DataFrame(np.hstack(np.array([[1],[0],[-0.12],[0.52]])))\nx1new.columns=[\"x1\"]\nyp2new = model.predict(x1new)\nprint(x1new)\nprint(yp2new)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Input Dataframe\ny = np.array([[1.55],[0.42],[1.29],[0.73],[0.76],[-1.09],[1.41],[-0.32]])\nx1 = np.array([[1.13],[-0.73],[0.12],[0.52],[-0.54],[-1.15],[0.20],[-1.09]])\nx2 = np.array([[1],[0],[1],[1],[0],[1],[0],[1]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"id = np.ones((8,1))\nx = np.hstack((id,x1,x2))\nprint(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculating regression coefficients \nbeta=(np.dot(np.dot(np.linalg.inv(np.dot(x.transpose(),x)),x.transpose()),y))\nprint(beta)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Result - Calculation\nyp1 = beta[0]+beta[1]*x1+beta[2]*x2\nprint(np.hstack((x,y,yp1)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Input Dataframe\nd = pd.DataFrame(np.hstack((x1,x2,y)))\nd.columns = [\"x1\",\"x2\",\"y\"]\nprint(d)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Multiple Linear Regression - Model Fitting\ninputDF = d[[\"x1\",\"x2\"]]\nmodel = lm.LinearRegression()\nresults = model.fit(inputDF,y)\nprint(model.intercept_, model.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Result: Scikit-Learn\nyp2 = model.predict(inputDF)\nprint(yp2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Prediction for new values\nx1new = pd.DataFrame(np.hstack((np.array([[1],[0],[-0.12],[0.52]]),np.array([[1],[-1],[2],[0.77]]))))\nx1new.columns=[\"x1\",\"x2\"]\nprint(x1new)\nyp2new = model.predict(x1new)\nprint(np.hstack((x1new,yp2new)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d=pd.read_csv(\"../input/data-for-lab-2/survey.csv\")\nd=d.rename(index=str,columns={\"Wr.Hnd\":\"WrHnd\"})\nprint(d.head())\nd = d[[\"WrHnd\",\"Height\"]]\nprint(d.head())\nprint(d.isnull().values.any())\nprint(d.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking for Null/NaN values\nd = d.dropna()\nprint(\"Check for NaN/null values:\\n\",d.isnull().values.any())\nprint(\"Number of NaN/null values:\\n\",d.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Simple Linear Regression \ninputDF = d[[\"WrHnd\"]]\noutcomeDF = d[[\"Height\"]]\nmodel = lm.LinearRegression()\nresults = model.fit(inputDF,outcomeDF)\n\nprint(model.intercept_, model.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d = pd.read_csv(\"../input/data-for-lab-2/clock.csv\")\nprint(d.head())\nprint(\"Check for NaN/null values:\\n\",d.isnull().values.any())\nprint(\"Number of NaN/null values:\\n\",d.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Multiple Linear Regression\ninputDF = d[[\"Bidders\",\"Age\"]]\noutputDF = d[[\"Price\"]]\n\nmodel = lm.LinearRegression()\nresults = model.fit(inputDF,outputDF)\n\nprint(model.intercept_, model.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"OutputDF_Predict = model.predict(inputDF)\nprint(np.hstack((inputDF,outputDF, OutputDF_Predict)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Voil√†! This is the end of the lab session for week 2.** <br>\nDo not forget to commit your notebook and set the access to private. Share the notebook with Prof. Karim (Kaggle id: karimshaikh) and Manish Varma (Kaggle id: manishvarma)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# HOME WORK_W3\n# Part A\nimport os\nprint(os.listdir(\"../input/udemy-courses\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom IPython.display import display\nfrom sklearn import linear_model as lm\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Udemy Courses dataset\n\nd = pd.read_csv(\"../input/udemy-courses/udemy_courses.csv\")\nprint(d.head())\nprint(\"Check for NaN/null values:\\n\",d.isnull().values.any())\nprint(\"Number of NaN/null values:\\n\",d.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Multiple Linear Regression\ninputDF = d[[\"price\",\"num_reviews\"]]\noutputDF = d[[\"num_subscribers\"]]\n\nmodel = lm.LinearRegression()\nresults = model.fit(inputDF,outputDF)\n\nprint(model.intercept_, model.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outputDF_predict = model.predict(inputDF)\nprint(np.hstack((inputDF,outputDF, outputDF_predict)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Linear Regression representation using scatter plot\nplt.scatter(inputDF.num_reviews,outputDF)\nplt.plot(inputDF.num_reviews, outputDF_predict, color=\"blue\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Kevin> as as predictor variables are clustered in between 0 and 5000,overall outcome of the linear regression seemed toe be influenced."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Part B.\n\ny = np.array([[2147],[2792],[2174],[513],[300],[901]])\nx1 = np.array([[23],[923],[74],[169],[31],[36]])\nid = np.ones((6,1))\nx = np.hstack((id,x1))\n\nbeta=(np.dot(np.dot(np.linalg.inv(np.dot(x.transpose(),x)),x.transpose()),y))\nprint(\"beta:\\n\",beta)\nyp1 = beta[0]+beta[1]*x1\nprint(\"prediction:\\n\",np.hstack((x1,y,yp1)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.boxplot(x1)\nplt.show()\nplt.boxplot(y)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Boxplot(x1)shows there is one outlier that was excluded in the boxplot.\nBoxplot(y) shows mean value is about 1500 and interquatile value is about 1500 as well."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(x1,y)\nplt.plot(x1,yp1,color=\"blue\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"most numbers are located in between 0 and 200 and one seems outlier. This is similar to the observation from the boxplot.\nBut, the prediction shows the linear regression but I doubt as most numbers are clustered."},{"metadata":{"trusted":true},"cell_type":"code","source":"#sum of squares of residuals\nr = y - yp1\nnp.sum(r*r)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}