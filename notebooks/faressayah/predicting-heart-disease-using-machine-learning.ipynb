{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 🩺 Predicting heart disease using machine learning\n\n# 📑 Problem Definition\n\nIn a statement,\n> Given clinical parameters about a patient, can we predict whether or not they have heart disease?\n\n# 📝 Features\n\nThis is where you'll get different information about each of the features in your data. You can do this via doing your own research (such as looking at the links above) or by talking to a subject matter expert (someone who knows about the dataset).\n\n# 💾 **Create data dictionary**\n\n1. `age` - age in years\n2. `sex` - (1 = male; 0 = female)\n3. `cp` - chest pain type\n    * 0: Typical angina: chest pain related decrease blood supply to the heart\n    * 1: Atypical angina: chest pain not related to heart\n    * 2: Non-anginal pain: typically esophageal spasms (non heart related)\n    * 3: Asymptomatic: chest pain not showing signs of disease\n4. `trestbps` - resting blood pressure (in mm Hg on admission to the hospital) anything above 130-140 is typically cause for concern\n5. `chol` - serum cholestoral in mg/dl\n    * serum = LDL + HDL + .2 * triglycerides\n    * above 200 is cause for concern\n6. `fbs` - (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)\n    * '>126' mg/dL signals diabetes\n7. `restecg` - resting electrocardiographic results\n    * 0: Nothing to note\n    * 1: ST-T Wave abnormality\n        * can range from mild symptoms to severe problems\n        * signals non-normal heart beat\n    * 2: Possible or definite left ventricular hypertrophy\n        * Enlarged heart's main pumping chamber\n8. `thalach` - maximum heart rate achieved\n9. `exang` - exercise induced angina (1 = yes; 0 = no)\n10. `oldpeak` - ST depression induced by exercise relative to rest looks at stress of heart during excercise unhealthy heart will stress more\n11. `slope` - the slope of the peak exercise ST segment\n    * 0: Upsloping: better heart rate with excercise (uncommon)\n    * 1: Flatsloping: minimal change (typical healthy heart)\n    * 2: Downslopins: signs of unhealthy heart\n12. `ca` - number of major vessels (0-3) colored by flourosopy\n    * colored vessel means the doctor can see the blood passing through\n    * the more blood movement the better (no clots)\n13. `thal` - thalium stress result\n    * 1,3: normal\n    * 6: fixed defect: used to be defect but ok now\n    * 7: reversable defect: no proper blood movement when excercising\n14. `target` - have disease or not (1=yes, 0=no) (= the predicted attribute)","metadata":{}},{"cell_type":"code","source":"!pip install -q hvplot","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-08-24T13:46:11.084306Z","iopub.execute_input":"2021-08-24T13:46:11.084695Z","iopub.status.idle":"2021-08-24T13:46:18.211946Z","shell.execute_reply.started":"2021-08-24T13:46:11.084663Z","shell.execute_reply":"2021-08-24T13:46:18.211011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport hvplot.pandas\nfrom scipy import stats\n\n%matplotlib inline\nsns.set_style(\"whitegrid\")\nplt.style.use(\"fivethirtyeight\")","metadata":{"execution":{"iopub.status.busy":"2021-08-24T13:46:18.213746Z","iopub.execute_input":"2021-08-24T13:46:18.214134Z","iopub.status.idle":"2021-08-24T13:46:18.229716Z","shell.execute_reply.started":"2021-08-24T13:46:18.214095Z","shell.execute_reply":"2021-08-24T13:46:18.228719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/heart-disease-uci/heart.csv\")\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T13:46:18.23181Z","iopub.execute_input":"2021-08-24T13:46:18.232207Z","iopub.status.idle":"2021-08-24T13:46:18.260603Z","shell.execute_reply.started":"2021-08-24T13:46:18.232165Z","shell.execute_reply":"2021-08-24T13:46:18.259727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 🔍 Exploratory Data Analysis (EDA)\n\n📌 **The goal here is to find out more about the data and become a subject matter export on the dataset you're working with.** \n\n1. What question(s) are you trying to solve?\n2. What kind of data do we have and how do we treat different types?\n3. What's missing from the data and how do you deal with it?\n4. Where are the outliers and why should you care about them?\n5. How can you add, change or remove features to get more out of your data?","metadata":{}},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T13:46:18.262423Z","iopub.execute_input":"2021-08-24T13:46:18.262703Z","iopub.status.idle":"2021-08-24T13:46:18.279399Z","shell.execute_reply.started":"2021-08-24T13:46:18.262677Z","shell.execute_reply":"2021-08-24T13:46:18.278082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-24T13:46:18.280727Z","iopub.execute_input":"2021-08-24T13:46:18.28119Z","iopub.status.idle":"2021-08-24T13:46:18.288144Z","shell.execute_reply.started":"2021-08-24T13:46:18.281149Z","shell.execute_reply":"2021-08-24T13:46:18.287165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option(\"display.float\", \"{:.2f}\".format)\ndata.describe()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T13:46:18.289669Z","iopub.execute_input":"2021-08-24T13:46:18.290325Z","iopub.status.idle":"2021-08-24T13:46:18.34105Z","shell.execute_reply.started":"2021-08-24T13:46:18.290284Z","shell.execute_reply":"2021-08-24T13:46:18.340038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.target.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T13:46:18.342581Z","iopub.execute_input":"2021-08-24T13:46:18.34319Z","iopub.status.idle":"2021-08-24T13:46:18.351961Z","shell.execute_reply.started":"2021-08-24T13:46:18.343149Z","shell.execute_reply":"2021-08-24T13:46:18.350713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.target.value_counts().hvplot.bar(\n    title=\"Heart Disease Count\", xlabel='Heart Disease', ylabel='Count', \n    width=500, height=350\n)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-24T13:46:18.355199Z","iopub.execute_input":"2021-08-24T13:46:18.355602Z","iopub.status.idle":"2021-08-24T13:46:18.461422Z","shell.execute_reply.started":"2021-08-24T13:46:18.355546Z","shell.execute_reply":"2021-08-24T13:46:18.460464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking for messing values\ndata.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T13:46:18.463232Z","iopub.execute_input":"2021-08-24T13:46:18.463593Z","iopub.status.idle":"2021-08-24T13:46:18.475013Z","shell.execute_reply.started":"2021-08-24T13:46:18.463564Z","shell.execute_reply":"2021-08-24T13:46:18.473863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 📌 Notes:\n> - We have `165` person with heart disease and `138` person without heart disease, so our problem is balanced.\n> - Looks like the perfect dataset!!! No null values :-)","metadata":{}},{"cell_type":"code","source":"categorical_val = []\ncontinous_val = []\nfor column in data.columns:\n    if len(data[column].unique()) <= 10:\n        categorical_val.append(column)\n    else:\n        continous_val.append(column)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T13:46:18.476859Z","iopub.execute_input":"2021-08-24T13:46:18.477372Z","iopub.status.idle":"2021-08-24T13:46:18.488Z","shell.execute_reply.started":"2021-08-24T13:46:18.477305Z","shell.execute_reply":"2021-08-24T13:46:18.486725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categorical_val","metadata":{"execution":{"iopub.status.busy":"2021-08-24T13:46:18.490018Z","iopub.execute_input":"2021-08-24T13:46:18.490593Z","iopub.status.idle":"2021-08-24T13:46:18.498706Z","shell.execute_reply.started":"2021-08-24T13:46:18.490383Z","shell.execute_reply":"2021-08-24T13:46:18.49756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"have_disease = data.loc[data['target']==1, 'sex'].value_counts().hvplot.bar(alpha=0.4) \nno_disease = data.loc[data['target']==0, 'sex'].value_counts().hvplot.bar(alpha=0.4) \n\n(no_disease * have_disease).opts(\n    title=\"Heart Disease by Sex\", xlabel='Sex', ylabel='Count',\n    width=500, height=450, legend_cols=2, legend_position='top_right'\n)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-24T13:46:18.500239Z","iopub.execute_input":"2021-08-24T13:46:18.500671Z","iopub.status.idle":"2021-08-24T13:46:18.736741Z","shell.execute_reply.started":"2021-08-24T13:46:18.500631Z","shell.execute_reply":"2021-08-24T13:46:18.735608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"have_disease = data.loc[data['target']==1, 'cp'].value_counts().hvplot.bar(alpha=0.4) \nno_disease = data.loc[data['target']==0, 'cp'].value_counts().hvplot.bar(alpha=0.4) \n\n(no_disease * have_disease).opts(\n    title=\"Heart Disease by Chest Pain Type\", xlabel='Chest Pain Type', ylabel='Count',\n    width=500, height=450, legend_cols=2, legend_position='top_right'\n)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-24T13:46:18.737955Z","iopub.execute_input":"2021-08-24T13:46:18.738218Z","iopub.status.idle":"2021-08-24T13:46:18.971041Z","shell.execute_reply.started":"2021-08-24T13:46:18.738192Z","shell.execute_reply":"2021-08-24T13:46:18.970133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"have_disease = data.loc[data['target']==1, 'fbs'].value_counts().hvplot.bar(alpha=0.4) \nno_disease = data.loc[data['target']==0, 'fbs'].value_counts().hvplot.bar(alpha=0.4) \n\n(no_disease * have_disease).opts(\n    title=\"Heart Disease by fasting blood sugar\", xlabel='fasting blood sugar > 120 mg/dl (1 = true; 0 = false)', \n    ylabel='Count', width=500, height=450, legend_cols=2, legend_position='top_right'\n)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T13:46:18.972394Z","iopub.execute_input":"2021-08-24T13:46:18.97266Z","iopub.status.idle":"2021-08-24T13:46:19.199048Z","shell.execute_reply.started":"2021-08-24T13:46:18.972634Z","shell.execute_reply":"2021-08-24T13:46:19.198165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"have_disease = data.loc[data['target']==1, 'restecg'].value_counts().hvplot.bar(alpha=0.4) \nno_disease = data.loc[data['target']==0, 'restecg'].value_counts().hvplot.bar(alpha=0.4) \n\n(no_disease * have_disease).opts(\n    title=\"Heart Disease by resting electrocardiographic results\", xlabel='resting electrocardiographic results', \n    ylabel='Count', width=500, height=450, legend_cols=2, legend_position='top_right'\n)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-24T13:46:19.200122Z","iopub.execute_input":"2021-08-24T13:46:19.20038Z","iopub.status.idle":"2021-08-24T13:46:19.419716Z","shell.execute_reply.started":"2021-08-24T13:46:19.200355Z","shell.execute_reply":"2021-08-24T13:46:19.418684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 15))\n\nfor i, column in enumerate(categorical_val, 1):\n    plt.subplot(3, 3, i)\n    data[data[\"target\"] == 0][column].hist(bins=35, color='blue', label='Have Heart Disease = NO', alpha=0.6)\n    data[data[\"target\"] == 1][column].hist(bins=35, color='red', label='Have Heart Disease = YES', alpha=0.6)\n    plt.legend()\n    plt.xlabel(column)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T13:46:19.420851Z","iopub.execute_input":"2021-08-24T13:46:19.42111Z","iopub.status.idle":"2021-08-24T13:46:23.370677Z","shell.execute_reply.started":"2021-08-24T13:46:19.421085Z","shell.execute_reply":"2021-08-24T13:46:23.369763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 📌 Notes:\n\n> - `cp` {Chest Pain} : People with cp equl to 1, 2, 3 are more likely to have heart disease than people with cp equal to 0.\n> - `restecg` {resting electrocardiographic results} : People with value 1 (signals non-normal heart beat, can range from mild symptoms to severe problems) are more likely to have heart disease.\n> - `exang` {exercise induced angina} : People with value 0 (No ==> exercice induced angina) have heart disease more than people with value 1 (Yes ==> exercice induced angina)\n> - `slope` {the slope of the peak exercise ST segment} : People with slope value equal to 2 (Downslopins: signs of unhealthy heart) are more likely to have heart disease than people with slope value equal to 0 (Upsloping: better heart rate with excercise) or 1 (Flatsloping: minimal change (typical healthy heart)).\n> - `ca` {number of major vessels (0-3) colored by flourosopy} : the more blood movement the better so people with ca equal to 0 are more likely to have heart disease.\n> - `thal` {thalium stress result} : People with thal value equal to 2 (fixed defect: used to be defect but ok now) are more likely to have heart disease.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15, 15))\n\nfor i, column in enumerate(continous_val, 1):\n    plt.subplot(3, 2, i)\n    data[data[\"target\"] == 0][column].hist(bins=35, color='blue', label='Have Heart Disease = NO', alpha=0.6)\n    data[data[\"target\"] == 1][column].hist(bins=35, color='red', label='Have Heart Disease = YES', alpha=0.6)\n    plt.legend()\n    plt.xlabel(column)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T13:46:23.372117Z","iopub.execute_input":"2021-08-24T13:46:23.372637Z","iopub.status.idle":"2021-08-24T13:46:25.648293Z","shell.execute_reply.started":"2021-08-24T13:46:23.372595Z","shell.execute_reply":"2021-08-24T13:46:25.647287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 📌 Notes:\n> - `trestbps` : resting blood pressure (in mm Hg on admission to the hospital) anything above 130-140 is typically cause for concern\n> - `chol` {serum cholestoral in mg/dl} : above 200 is cause for concern.\n> - `thalach` {maximum heart rate achieved} : People how acheived a maximum more than 140 are more likely to have heart disease.\n> - `oldpeak` ST depression induced by exercise relative to rest looks at stress of heart during excercise unhealthy heart will stress more","metadata":{}},{"cell_type":"markdown","source":"### Age vs. Max Heart Rate for Heart Disease","metadata":{}},{"cell_type":"code","source":"# Create another figure\nplt.figure(figsize=(9, 7))\n\n# Scatter with postivie examples\nplt.scatter(data.age[data.target==1],\n            data.thalach[data.target==1],\n            c=\"salmon\")\n\n# Scatter with negative examples\nplt.scatter(data.age[data.target==0],\n            data.thalach[data.target==0],\n            c=\"lightblue\")\n\n# Add some helpful info\nplt.title(\"Heart Disease in function of Age and Max Heart Rate\")\nplt.xlabel(\"Age\")\nplt.ylabel(\"Max Heart Rate\")\nplt.legend([\"Disease\", \"No Disease\"]);","metadata":{"execution":{"iopub.status.busy":"2021-08-24T13:46:25.649688Z","iopub.execute_input":"2021-08-24T13:46:25.650216Z","iopub.status.idle":"2021-08-24T13:46:25.959256Z","shell.execute_reply.started":"2021-08-24T13:46:25.650172Z","shell.execute_reply":"2021-08-24T13:46:25.95845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 🧮 Correlation Matrix","metadata":{}},{"cell_type":"code","source":"# Let's make our correlation matrix a little prettier\ncorr_matrix = data.corr()\nfig, ax = plt.subplots(figsize=(15, 15))\nax = sns.heatmap(corr_matrix,\n                 annot=True,\n                 linewidths=0.5,\n                 fmt=\".2f\",\n                 cmap=\"YlGnBu\");\nbottom, top = ax.get_ylim()\nax.set_ylim(bottom + 0.5, top - 0.5)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T13:46:25.960591Z","iopub.execute_input":"2021-08-24T13:46:25.960954Z","iopub.status.idle":"2021-08-24T13:46:27.384568Z","shell.execute_reply.started":"2021-08-24T13:46:25.960925Z","shell.execute_reply":"2021-08-24T13:46:27.38366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.drop('target', axis=1).corrwith(data.target).hvplot.barh(\n    width=600, height=400, \n    title=\"Correlation between Heart Disease and Numeric Features\", \n    ylabel='Correlation', xlabel='Numerical Features',\n)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T13:46:27.385769Z","iopub.execute_input":"2021-08-24T13:46:27.386029Z","iopub.status.idle":"2021-08-24T13:46:27.486422Z","shell.execute_reply.started":"2021-08-24T13:46:27.386003Z","shell.execute_reply":"2021-08-24T13:46:27.485544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- `fbs` and `chol` are the lowest correlated with the target variable.\n- All other variables have a significant correlation with the target variable.","metadata":{}},{"cell_type":"markdown","source":"# 🔄 Data Processing\n\nAfter exploring the dataset, I observed that I need to convert some categorical variables into dummy variables and scale all the values before training the Machine Learning models.\nFirst, I'll use the `get_dummies` method to create dummy columns for categorical variables.","metadata":{}},{"cell_type":"code","source":"categorical_val.remove('target')\ndataset = pd.get_dummies(data, columns = categorical_val)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T13:46:27.489493Z","iopub.execute_input":"2021-08-24T13:46:27.489813Z","iopub.status.idle":"2021-08-24T13:46:27.505025Z","shell.execute_reply.started":"2021-08-24T13:46:27.489783Z","shell.execute_reply":"2021-08-24T13:46:27.503839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T13:46:27.506634Z","iopub.execute_input":"2021-08-24T13:46:27.507455Z","iopub.status.idle":"2021-08-24T13:46:27.530288Z","shell.execute_reply.started":"2021-08-24T13:46:27.507403Z","shell.execute_reply":"2021-08-24T13:46:27.529273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(data.columns)\nprint(dataset.columns)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T13:46:27.534745Z","iopub.execute_input":"2021-08-24T13:46:27.53508Z","iopub.status.idle":"2021-08-24T13:46:27.541061Z","shell.execute_reply.started":"2021-08-24T13:46:27.535043Z","shell.execute_reply":"2021-08-24T13:46:27.539937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\ns_sc = StandardScaler()\ncol_to_scale = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\ndataset[col_to_scale] = s_sc.fit_transform(dataset[col_to_scale])","metadata":{"execution":{"iopub.status.busy":"2021-08-24T13:46:27.542882Z","iopub.execute_input":"2021-08-24T13:46:27.543178Z","iopub.status.idle":"2021-08-24T13:46:27.68086Z","shell.execute_reply.started":"2021-08-24T13:46:27.543152Z","shell.execute_reply":"2021-08-24T13:46:27.679887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T13:46:27.682054Z","iopub.execute_input":"2021-08-24T13:46:27.682337Z","iopub.status.idle":"2021-08-24T13:46:27.706175Z","shell.execute_reply.started":"2021-08-24T13:46:27.682309Z","shell.execute_reply":"2021-08-24T13:46:27.705118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 🤖 Models Building","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\ndef print_score(clf, X_train, y_train, X_test, y_test, train=True):\n    if train:\n        pred = clf.predict(X_train)\n        clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))\n        print(\"Train Result:\\n================================================\")\n        print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n        print(\"_______________________________________________\")\n        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")\n        \n    elif train==False:\n        pred = clf.predict(X_test)\n        clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n        print(\"Test Result:\\n================================================\")        \n        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n        print(\"_______________________________________________\")\n        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-08-24T13:46:27.707437Z","iopub.execute_input":"2021-08-24T13:46:27.707729Z","iopub.status.idle":"2021-08-24T13:46:27.748585Z","shell.execute_reply.started":"2021-08-24T13:46:27.707702Z","shell.execute_reply":"2021-08-24T13:46:27.747699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = dataset.drop('target', axis=1)\ny = dataset.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T13:46:27.749729Z","iopub.execute_input":"2021-08-24T13:46:27.750026Z","iopub.status.idle":"2021-08-24T13:46:27.773833Z","shell.execute_reply.started":"2021-08-24T13:46:27.749998Z","shell.execute_reply":"2021-08-24T13:46:27.772925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we've got our data split into training and test sets, it's time to build a machine learning model.\n\nWe'll train it (find the patterns) on the training set.\n\nAnd we'll test it (use the patterns) on the test set.\n\nWe're going to try 3 different machine learning models:\n> 1. Logistic Regression \n> 2. K-Nearest Neighbours Classifier\n> 3. Support Vector machine\n> 4. Decision Tree Classifier\n> 5. Random Forest Classifier\n> 6. XGBoost Classifier","metadata":{}},{"cell_type":"markdown","source":"## 1. Logistic Regression","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlr_clf = LogisticRegression(solver='liblinear')\nlr_clf.fit(X_train, y_train)\n\nprint_score(lr_clf, X_train, y_train, X_test, y_test, train=True)\nprint_score(lr_clf, X_train, y_train, X_test, y_test, train=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T13:46:27.774892Z","iopub.execute_input":"2021-08-24T13:46:27.775139Z","iopub.status.idle":"2021-08-24T13:46:28.258128Z","shell.execute_reply.started":"2021-08-24T13:46:27.775115Z","shell.execute_reply":"2021-08-24T13:46:28.257434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_score = accuracy_score(y_test, lr_clf.predict(X_test)) * 100\ntrain_score = accuracy_score(y_train, lr_clf.predict(X_train)) * 100\n\nresults_df = pd.DataFrame(data=[[\"Logistic Regression\", train_score, test_score]], \n                          columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\nresults_df","metadata":{"execution":{"iopub.status.busy":"2021-08-24T13:46:28.258999Z","iopub.execute_input":"2021-08-24T13:46:28.259254Z","iopub.status.idle":"2021-08-24T13:46:28.274497Z","shell.execute_reply.started":"2021-08-24T13:46:28.25923Z","shell.execute_reply":"2021-08-24T13:46:28.273817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. K-nearest neighbors","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nknn_clf = KNeighborsClassifier()\nknn_clf.fit(X_train, y_train)\n\nprint_score(knn_clf, X_train, y_train, X_test, y_test, train=True)\nprint_score(knn_clf, X_train, y_train, X_test, y_test, train=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T13:46:28.27542Z","iopub.execute_input":"2021-08-24T13:46:28.275791Z","iopub.status.idle":"2021-08-24T13:46:28.382112Z","shell.execute_reply.started":"2021-08-24T13:46:28.275764Z","shell.execute_reply":"2021-08-24T13:46:28.381118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_score = accuracy_score(y_test, knn_clf.predict(X_test)) * 100\ntrain_score = accuracy_score(y_train, knn_clf.predict(X_train)) * 100\n\nresults_df_2 = pd.DataFrame(data=[[\"K-nearest neighbors\", train_score, test_score]], \n                          columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\nresults_df = results_df.append(results_df_2, ignore_index=True)\nresults_df","metadata":{"execution":{"iopub.status.busy":"2021-08-24T13:46:28.383735Z","iopub.execute_input":"2021-08-24T13:46:28.384152Z","iopub.status.idle":"2021-08-24T13:46:28.41817Z","shell.execute_reply.started":"2021-08-24T13:46:28.384111Z","shell.execute_reply":"2021-08-24T13:46:28.417288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Support Vector machine","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\n\n\nsvm_clf = SVC(kernel='rbf', gamma=0.1, C=1.0)\nsvm_clf.fit(X_train, y_train)\n\nprint_score(svm_clf, X_train, y_train, X_test, y_test, train=True)\nprint_score(svm_clf, X_train, y_train, X_test, y_test, train=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T13:46:28.419292Z","iopub.execute_input":"2021-08-24T13:46:28.419544Z","iopub.status.idle":"2021-08-24T13:46:28.457418Z","shell.execute_reply.started":"2021-08-24T13:46:28.41952Z","shell.execute_reply":"2021-08-24T13:46:28.456492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_score = accuracy_score(y_test, svm_clf.predict(X_test)) * 100\ntrain_score = accuracy_score(y_train, svm_clf.predict(X_train)) * 100\n\nresults_df_2 = pd.DataFrame(data=[[\"Support Vector Machine\", train_score, test_score]], \n                          columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\nresults_df = results_df.append(results_df_2, ignore_index=True)\nresults_df","metadata":{"execution":{"iopub.status.busy":"2021-08-24T13:46:28.458609Z","iopub.execute_input":"2021-08-24T13:46:28.458929Z","iopub.status.idle":"2021-08-24T13:46:28.480676Z","shell.execute_reply.started":"2021-08-24T13:46:28.4589Z","shell.execute_reply":"2021-08-24T13:46:28.479918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Decision Tree Classifier ","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\n\ntree_clf = DecisionTreeClassifier(random_state=42)\ntree_clf.fit(X_train, y_train)\n\nprint_score(tree_clf, X_train, y_train, X_test, y_test, train=True)\nprint_score(tree_clf, X_train, y_train, X_test, y_test, train=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T13:46:28.481826Z","iopub.execute_input":"2021-08-24T13:46:28.482091Z","iopub.status.idle":"2021-08-24T13:46:28.536961Z","shell.execute_reply.started":"2021-08-24T13:46:28.482065Z","shell.execute_reply":"2021-08-24T13:46:28.536274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_score = accuracy_score(y_test, tree_clf.predict(X_test)) * 100\ntrain_score = accuracy_score(y_train, tree_clf.predict(X_train)) * 100\n\nresults_df_2 = pd.DataFrame(data=[[\"Decision Tree Classifier\", train_score, test_score]], \n                          columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\nresults_df = results_df.append(results_df_2, ignore_index=True)\nresults_df","metadata":{"execution":{"iopub.status.busy":"2021-08-24T13:46:28.537876Z","iopub.execute_input":"2021-08-24T13:46:28.538239Z","iopub.status.idle":"2021-08-24T13:46:28.556328Z","shell.execute_reply.started":"2021-08-24T13:46:28.538212Z","shell.execute_reply":"2021-08-24T13:46:28.555499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Random Forest","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\n\nrf_clf = RandomForestClassifier(n_estimators=1000, random_state=42)\nrf_clf.fit(X_train, y_train)\n\nprint_score(rf_clf, X_train, y_train, X_test, y_test, train=True)\nprint_score(rf_clf, X_train, y_train, X_test, y_test, train=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T13:46:28.557469Z","iopub.execute_input":"2021-08-24T13:46:28.557925Z","iopub.status.idle":"2021-08-24T13:46:30.710013Z","shell.execute_reply.started":"2021-08-24T13:46:28.557897Z","shell.execute_reply":"2021-08-24T13:46:30.70892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_score = accuracy_score(y_test, rf_clf.predict(X_test)) * 100\ntrain_score = accuracy_score(y_train, rf_clf.predict(X_train)) * 100\n\nresults_df_2 = pd.DataFrame(data=[[\"Random Forest Classifier\", train_score, test_score]], \n                          columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\nresults_df = results_df.append(results_df_2, ignore_index=True)\nresults_df","metadata":{"execution":{"iopub.status.busy":"2021-08-24T13:46:30.711337Z","iopub.execute_input":"2021-08-24T13:46:30.711646Z","iopub.status.idle":"2021-08-24T13:46:30.933102Z","shell.execute_reply.started":"2021-08-24T13:46:30.71161Z","shell.execute_reply":"2021-08-24T13:46:30.931879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6. XGBoost Classifer","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier\n\nxgb_clf = XGBClassifier(use_label_encoder=False)\nxgb_clf.fit(X_train, y_train)\n\nprint_score(xgb_clf, X_train, y_train, X_test, y_test, train=True)\nprint_score(xgb_clf, X_train, y_train, X_test, y_test, train=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T13:46:30.93464Z","iopub.execute_input":"2021-08-24T13:46:30.935022Z","iopub.status.idle":"2021-08-24T13:46:31.108904Z","shell.execute_reply.started":"2021-08-24T13:46:30.934983Z","shell.execute_reply":"2021-08-24T13:46:31.10815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_score = accuracy_score(y_test, xgb_clf.predict(X_test)) * 100\ntrain_score = accuracy_score(y_train, xgb_clf.predict(X_train)) * 100\n\nresults_df_2 = pd.DataFrame(data=[[\"XGBoost Classifier\", train_score, test_score]], \n                          columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\nresults_df = results_df.append(results_df_2, ignore_index=True)\nresults_df","metadata":{"execution":{"iopub.status.busy":"2021-08-24T13:46:31.110271Z","iopub.execute_input":"2021-08-24T13:46:31.110829Z","iopub.status.idle":"2021-08-24T13:46:31.134459Z","shell.execute_reply.started":"2021-08-24T13:46:31.110792Z","shell.execute_reply":"2021-08-24T13:46:31.133637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 🤖 Models Hyperparameter Tuning","metadata":{}},{"cell_type":"markdown","source":"## 1. Logistic Regression Hyperparameter Tuning","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nparams = {\"C\": np.logspace(-4, 4, 20),\n          \"solver\": [\"liblinear\"]}\n\nlr_clf = LogisticRegression()\n\nlr_cv = GridSearchCV(lr_clf, params, scoring=\"accuracy\", n_jobs=-1, verbose=1, cv=5, iid=True)\nlr_cv.fit(X_train, y_train)\nbest_params = lr_cv.best_params_\nprint(f\"Best parameters: {best_params}\")\nlr_clf = LogisticRegression(**best_params)\n\nlr_clf.fit(X_train, y_train)\n\nprint_score(lr_clf, X_train, y_train, X_test, y_test, train=True)\nprint_score(lr_clf, X_train, y_train, X_test, y_test, train=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T13:46:31.135672Z","iopub.execute_input":"2021-08-24T13:46:31.136241Z","iopub.status.idle":"2021-08-24T13:46:33.796912Z","shell.execute_reply.started":"2021-08-24T13:46:31.136205Z","shell.execute_reply":"2021-08-24T13:46:33.795995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_score = accuracy_score(y_test, lr_clf.predict(X_test)) * 100\ntrain_score = accuracy_score(y_train, lr_clf.predict(X_train)) * 100\n\ntuning_results_df = pd.DataFrame(data=[[\"Tuned Logistic Regression\", train_score, test_score]], \n                          columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\ntuning_results_df","metadata":{"execution":{"iopub.status.busy":"2021-08-24T13:46:33.7983Z","iopub.execute_input":"2021-08-24T13:46:33.798568Z","iopub.status.idle":"2021-08-24T13:46:33.817079Z","shell.execute_reply.started":"2021-08-24T13:46:33.79854Z","shell.execute_reply":"2021-08-24T13:46:33.816227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. K-nearest neighbors Hyperparameter Tuning","metadata":{}},{"cell_type":"code","source":"train_score = []\ntest_score = []\nneighbors = range(1, 30)\n\nfor k in neighbors:\n    model = KNeighborsClassifier(n_neighbors=k)\n    model.fit(X_train, y_train)\n    train_score.append(accuracy_score(y_train, model.predict(X_train)))\n#     test_score.append(accuracy_score(y_test, model.predict(X_test)))","metadata":{"execution":{"iopub.status.busy":"2021-08-24T13:46:33.81818Z","iopub.execute_input":"2021-08-24T13:46:33.818434Z","iopub.status.idle":"2021-08-24T13:46:34.286596Z","shell.execute_reply.started":"2021-08-24T13:46:33.81841Z","shell.execute_reply":"2021-08-24T13:46:34.285585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 7))\n\nplt.plot(neighbors, train_score, label=\"Train score\")\n# plt.plot(neighbors, test_score, label=\"Test score\")\nplt.xticks(np.arange(1, 21, 1))\nplt.xlabel(\"Number of neighbors\")\nplt.ylabel(\"Model score\")\nplt.legend()\n\nprint(f\"Maximum KNN score on the test data: {max(train_score)*100:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2021-08-24T13:46:34.287861Z","iopub.execute_input":"2021-08-24T13:46:34.288237Z","iopub.status.idle":"2021-08-24T13:46:34.722815Z","shell.execute_reply.started":"2021-08-24T13:46:34.28819Z","shell.execute_reply":"2021-08-24T13:46:34.721885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knn_clf = KNeighborsClassifier(n_neighbors=27)\nknn_clf.fit(X_train, y_train)\n\nprint_score(knn_clf, X_train, y_train, X_test, y_test, train=True)\nprint_score(knn_clf, X_train, y_train, X_test, y_test, train=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T13:46:34.72421Z","iopub.execute_input":"2021-08-24T13:46:34.724506Z","iopub.status.idle":"2021-08-24T13:46:34.775705Z","shell.execute_reply.started":"2021-08-24T13:46:34.724477Z","shell.execute_reply":"2021-08-24T13:46:34.77371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_score = accuracy_score(y_test, knn_clf.predict(X_test)) * 100\ntrain_score = accuracy_score(y_train, knn_clf.predict(X_train)) * 100\n\nresults_df_2 = pd.DataFrame(data=[[\"Tuned K-nearest neighbors\", train_score, test_score]], \n                          columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\ntuning_results_df = tuning_results_df.append(results_df_2, ignore_index=True)\ntuning_results_df","metadata":{"execution":{"iopub.status.busy":"2021-08-24T13:46:34.777151Z","iopub.execute_input":"2021-08-24T13:46:34.777671Z","iopub.status.idle":"2021-08-24T13:46:34.826124Z","shell.execute_reply.started":"2021-08-24T13:46:34.777602Z","shell.execute_reply":"2021-08-24T13:46:34.822866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Support Vector Machine Hyperparameter Tuning","metadata":{}},{"cell_type":"code","source":"svm_clf = SVC(kernel='rbf', gamma=0.1, C=1.0)\n\nparams = {\"C\":(0.1, 0.5, 1, 2, 5, 10, 20), \n          \"gamma\":(0.001, 0.01, 0.1, 0.25, 0.5, 0.75, 1), \n          \"kernel\":('linear', 'poly', 'rbf')}\n\nsvm_cv = GridSearchCV(svm_clf, params, n_jobs=-1, cv=5, verbose=1, scoring=\"accuracy\")\nsvm_cv.fit(X_train, y_train)\nbest_params = svm_cv.best_params_\nprint(f\"Best params: {best_params}\")\n\nsvm_clf = SVC(**best_params)\nsvm_clf.fit(X_train, y_train)\n\nprint_score(svm_clf, X_train, y_train, X_test, y_test, train=True)\nprint_score(svm_clf, X_train, y_train, X_test, y_test, train=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T13:46:34.827388Z","iopub.execute_input":"2021-08-24T13:46:34.827674Z","iopub.status.idle":"2021-08-24T13:46:37.67755Z","shell.execute_reply.started":"2021-08-24T13:46:34.827647Z","shell.execute_reply":"2021-08-24T13:46:37.676654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_score = accuracy_score(y_test, svm_clf.predict(X_test)) * 100\ntrain_score = accuracy_score(y_train, svm_clf.predict(X_train)) * 100\n\nresults_df_2 = pd.DataFrame(data=[[\"Tuned Support Vector Machine\", train_score, test_score]], \n                          columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\ntuning_results_df = tuning_results_df.append(results_df_2, ignore_index=True)\ntuning_results_df","metadata":{"execution":{"iopub.status.busy":"2021-08-24T13:46:37.68088Z","iopub.execute_input":"2021-08-24T13:46:37.681178Z","iopub.status.idle":"2021-08-24T13:46:37.702871Z","shell.execute_reply.started":"2021-08-24T13:46:37.681148Z","shell.execute_reply":"2021-08-24T13:46:37.701905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Decision Tree Classifier Hyperparameter Tuning","metadata":{}},{"cell_type":"code","source":"params = {\"criterion\":(\"gini\", \"entropy\"), \n          \"splitter\":(\"best\", \"random\"), \n          \"max_depth\":(list(range(1, 20))), \n          \"min_samples_split\":[2, 3, 4], \n          \"min_samples_leaf\":list(range(1, 20))\n          }\n\ntree_clf = DecisionTreeClassifier(random_state=42)\ntree_cv = GridSearchCV(tree_clf, params, scoring=\"accuracy\", n_jobs=-1, verbose=1, cv=3)\ntree_cv.fit(X_train, y_train)\nbest_params = tree_cv.best_params_\nprint(f'Best_params: {best_params}')\n\ntree_clf = DecisionTreeClassifier(**best_params)\ntree_clf.fit(X_train, y_train)\n\nprint_score(tree_clf, X_train, y_train, X_test, y_test, train=True)\nprint_score(tree_clf, X_train, y_train, X_test, y_test, train=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T13:46:37.704161Z","iopub.execute_input":"2021-08-24T13:46:37.704437Z","iopub.status.idle":"2021-08-24T13:47:11.756278Z","shell.execute_reply.started":"2021-08-24T13:46:37.70441Z","shell.execute_reply":"2021-08-24T13:47:11.755255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_score = accuracy_score(y_test, tree_clf.predict(X_test)) * 100\ntrain_score = accuracy_score(y_train, tree_clf.predict(X_train)) * 100\n\nresults_df_2 = pd.DataFrame(data=[[\"Tuned Decision Tree Classifier\", train_score, test_score]], \n                          columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\ntuning_results_df = tuning_results_df.append(results_df_2, ignore_index=True)\ntuning_results_df","metadata":{"execution":{"iopub.status.busy":"2021-08-24T13:47:11.757794Z","iopub.execute_input":"2021-08-24T13:47:11.758177Z","iopub.status.idle":"2021-08-24T13:47:11.77737Z","shell.execute_reply.started":"2021-08-24T13:47:11.758137Z","shell.execute_reply":"2021-08-24T13:47:11.776356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Random Forest Classifier Hyperparameter Tuning","metadata":{}},{"cell_type":"code","source":"n_estimators = [500, 900, 1100, 1500]\nmax_features = ['auto', 'sqrt']\nmax_depth = [2, 3, 5, 10, 15, None]\nmin_samples_split = [2, 5, 10]\nmin_samples_leaf = [1, 2, 4]\n\nparams_grid = {\n    'n_estimators': n_estimators, \n    'max_features': max_features,\n    'max_depth': max_depth, \n    'min_samples_split': min_samples_split,\n    'min_samples_leaf': min_samples_leaf\n              }\n\nrf_clf = RandomForestClassifier(random_state=42)\nrf_cv = GridSearchCV(rf_clf, params_grid, scoring=\"accuracy\", cv=3, verbose=1, n_jobs=-1)\nrf_cv.fit(X_train, y_train)\nbest_params = rf_cv.best_params_\nprint(f\"Best parameters: {best_params}\")\n\nrf_clf = RandomForestClassifier(**best_params)\nrf_clf.fit(X_train, y_train)\n\nprint_score(rf_clf, X_train, y_train, X_test, y_test, train=True)\nprint_score(rf_clf, X_train, y_train, X_test, y_test, train=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T13:47:11.779148Z","iopub.execute_input":"2021-08-24T13:47:11.779529Z","iopub.status.idle":"2021-08-24T14:03:31.487283Z","shell.execute_reply.started":"2021-08-24T13:47:11.779491Z","shell.execute_reply":"2021-08-24T14:03:31.486359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_score = accuracy_score(y_test, rf_clf.predict(X_test)) * 100\ntrain_score = accuracy_score(y_train, rf_clf.predict(X_train)) * 100\n\nresults_df_2 = pd.DataFrame(data=[[\"Tuned Random Forest Classifier\", train_score, test_score]], \n                          columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\ntuning_results_df = tuning_results_df.append(results_df_2, ignore_index=True)\ntuning_results_df","metadata":{"execution":{"iopub.status.busy":"2021-08-24T14:03:31.488939Z","iopub.execute_input":"2021-08-24T14:03:31.489338Z","iopub.status.idle":"2021-08-24T14:03:31.711555Z","shell.execute_reply.started":"2021-08-24T14:03:31.489297Z","shell.execute_reply":"2021-08-24T14:03:31.710667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6. XGBoost Classifier Hyperparameter Tuning","metadata":{}},{"cell_type":"code","source":"param_grid = dict(\n    n_estimators=stats.randint(10, 1000),\n    max_depth=stats.randint(1, 10),\n    learning_rate=stats.uniform(0, 1)\n)\n\nxgb_clf = XGBClassifier(use_label_encoder=False)\nxgb_cv = RandomizedSearchCV(\n    xgb_clf, param_grid, cv=3, n_iter=50, \n    scoring='accuracy', n_jobs=-1, verbose=1\n)\nxgb_cv.fit(X_train, y_train)\nbest_params = xgb_cv.best_params_\nprint(f\"Best paramters: {best_params}\")\n\nxgb_clf = XGBClassifier(**best_params)\nxgb_clf.fit(X_train, y_train)\n\nprint_score(xgb_clf, X_train, y_train, X_test, y_test, train=True)\nprint_score(xgb_clf, X_train, y_train, X_test, y_test, train=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T14:03:31.712798Z","iopub.execute_input":"2021-08-24T14:03:31.713087Z","iopub.status.idle":"2021-08-24T15:02:13.540419Z","shell.execute_reply.started":"2021-08-24T14:03:31.713058Z","shell.execute_reply":"2021-08-24T15:02:13.539585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_score = accuracy_score(y_test, xgb_clf.predict(X_test)) * 100\ntrain_score = accuracy_score(y_train, xgb_clf.predict(X_train)) * 100\n\nresults_df_2 = pd.DataFrame(data=[[\"Tuned XGBoost Classifier\", train_score, test_score]], \n                          columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\ntuning_results_df = tuning_results_df.append(results_df_2, ignore_index=True)\ntuning_results_df","metadata":{"execution":{"iopub.status.busy":"2021-08-24T15:02:13.541895Z","iopub.execute_input":"2021-08-24T15:02:13.542462Z","iopub.status.idle":"2021-08-24T15:02:13.569266Z","shell.execute_reply.started":"2021-08-24T15:02:13.542421Z","shell.execute_reply":"2021-08-24T15:02:13.568281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results_df","metadata":{"execution":{"iopub.status.busy":"2021-08-24T15:02:13.57195Z","iopub.execute_input":"2021-08-24T15:02:13.572388Z","iopub.status.idle":"2021-08-24T15:02:13.582727Z","shell.execute_reply.started":"2021-08-24T15:02:13.572346Z","shell.execute_reply":"2021-08-24T15:02:13.581643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It seems that the results doesn't improved a lot after hyperparamter tuning. Maybe because the dataset is small. ","metadata":{}},{"cell_type":"markdown","source":"# 6. Features Importance According to Random Forest and XGBoost","metadata":{}},{"cell_type":"code","source":"def feature_imp(df, model):\n    fi = pd.DataFrame()\n    fi[\"feature\"] = df.columns\n    fi[\"importance\"] = model.feature_importances_\n    return fi.sort_values(by=\"importance\", ascending=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T15:02:13.584285Z","iopub.execute_input":"2021-08-24T15:02:13.584717Z","iopub.status.idle":"2021-08-24T15:02:13.596088Z","shell.execute_reply.started":"2021-08-24T15:02:13.584674Z","shell.execute_reply":"2021-08-24T15:02:13.595262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_imp(X, rf_clf).plot(kind='barh', figsize=(12,7), legend=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T15:02:13.597366Z","iopub.execute_input":"2021-08-24T15:02:13.597973Z","iopub.status.idle":"2021-08-24T15:02:14.116074Z","shell.execute_reply.started":"2021-08-24T15:02:13.597928Z","shell.execute_reply":"2021-08-24T15:02:14.115129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_imp(X, xgb_clf).plot(kind='barh', figsize=(12,7), legend=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T15:02:14.117269Z","iopub.execute_input":"2021-08-24T15:02:14.117547Z","iopub.status.idle":"2021-08-24T15:02:14.533786Z","shell.execute_reply.started":"2021-08-24T15:02:14.11752Z","shell.execute_reply":"2021-08-24T15:02:14.532852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}