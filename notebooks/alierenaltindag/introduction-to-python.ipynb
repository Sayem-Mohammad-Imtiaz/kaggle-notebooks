{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\ndata = pd.read_csv(\"../input/Pokemon.csv\") # Import dataset\ndata.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Matplotlib**"},{"metadata":{},"cell_type":"markdown","source":"**There are 3 plot type in Matplotlib**\n* Line Plot\n* Histogram\n* Scatter Plot"},{"metadata":{},"cell_type":"markdown","source":"Let's plot the graph showing the relationship between Hp and Attack with Line Plot, Histogram and Scatter Plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.HP.plot(kind='line',grid=True,label='HP',color=\"red\",linestyle='-',alpha=0.5,linewidth=1) # Hp\ndata.Attack.plot(kind='line',color='green',grid=True,label='Attack',linestyle='-',alpha=0.5,linewidth=1) # Attack\nplt.legend(loc='upper left') # We use this function for distinguish lines.\nplt.xlabel('HP')\nplt.ylabel('Attack')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Scatter Plot**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.plot(kind='scatter',x = 'HP',y = 'Attack',alpha = 0.7,color = 'red')\nplt.xlabel(\"HP\")\nplt.ylabel('Attack')\nplt.title(\"Hp Attack Scatter Plot\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Histogram Plot**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Defense.plot(kind='hist',bins=100,figsize=(8,5))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Dictionary**"},{"metadata":{"trusted":true},"cell_type":"code","source":"dictionary = {\"Key1\":\"Value1\", \"Key2\":\"Value2\", \"Key3\":\"Value3\"}\nprint(dictionary.keys())\nprint(dictionary.values())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(dictionary[\"Key1\"])\n\ndictionary[\"Key2\"] = \"none\"\nprint(dictionary[\"Key2\"])\n\ndictionary[\"Key4\"] = \"Value4\"\nprint(dictionary[\"Key4\"])\n\ndictionary.clear()\nprint(dictionary)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Pandas**"},{"metadata":{},"cell_type":"markdown","source":"**Series and Data Frames**"},{"metadata":{"trusted":true},"cell_type":"code","source":"series = data[\"Attack\"] # data[\"Attack\"] = Series\ndata_frame = data[[\"Attack\"]] # data[[\"Attack\"]] = Data_Frame\nprint(type(series),\"\\n\",type(data_frame))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Filtering Dataset with Pandas**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filtering = data[\"Attack\"]>170\ndata[filtering]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[(data[\"Attack\"]>150) & (data[\"HP\"]>100)]\ndata[np.logical_and(data[\"Attack\"]>150, data[\"HP\"]>100)] # Both are same thing","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Loops**"},{"metadata":{"trusted":true},"cell_type":"code","source":"list = [1,2,3,4,5]\nfor i in list:\n    print(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for index,value in enumerate(list): # We use enumerate method for print both index and value\n    print(index,\":\",value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dictionary = {\"Key1\":\"Value1\",\"Key2\":\"Value2\",\"Key3\":\"Value3\"}\nfor key,value in dictionary.items():\n    print(key,\":\",value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for index,value in data[[\"Attack\"]][0:3].iterrows():\n    print(index, \" : \",value)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Python Data Science Toolbox**"},{"metadata":{},"cell_type":"markdown","source":"**User Defined Function**"},{"metadata":{},"cell_type":"markdown","source":"* Sometimes functions can return more than one value. For example:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def udf():\n    t = (1,2,3) # We defined a tuple named t\n    return t # We return 3 values through tuple\na,b,c = udf()\nprint(a,b,c)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Scope**"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = 3 # Global variable\ndef scope():\n    x = 1 # Local variable\n    return x\nprint(x)\nprint(scope())\nprint(\"\")\n# Global variables can access by everywhere but Local variables can only accessible from local\n\n# If there is no local variable you will access to global variable. for example:\ny = 3\ndef scope2():\n    z = 3*y # y variable is global variable\n    return z\nprint(scope2())\n\n# Extra Information: You can't use built in scope names and Python's preset method names as variable names.\n# To see built in scopes:\nimport builtins\ndir(builtins) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Nested Function**"},{"metadata":{},"cell_type":"markdown","source":"* It mean function inside function"},{"metadata":{"trusted":true},"cell_type":"code","source":"def sqrt():\n    def total():\n        a = 10\n        b = 6\n        c = a+b\n        return c\n    return total()**0.5 # We take the sqrt of the value returned from the total function\n\nprint(sqrt())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Default And Flexible Arguments**"},{"metadata":{},"cell_type":"markdown","source":"* We can define a default value for the parameter that the function takes. For example:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Default Arguments:\ndef f(x,y = 2):\n    return x+y\nprint(f(1)) # I didn't assign a value to variable y\nprint(f(1,4)) # We can change the default value of variable y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Flexible Arguments\n# We use flexible arguments for send as many values as we want to a function. For example:\ndef f(*args):\n    for i in args:\n        print(i)\nf(1)\nf(1,2,3)\nprint(\"\")\n\n# Also We use flexible arguments for send as many dictionary items as we want to a function. For example:\ndef g(**kwargs):\n    for key, value in kwargs.items():\n        print(key,\":\",value)\ng(key1 = \"value1\",key2 = \"value2\",key3 = \"value3\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Lambda Function**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# We use Lambda Function for define a function easily. For example:\nf = lambda x : x**2 # First, We defined x variable and this function will return square of x\nprint(f(3))\n\ng = lambda x,y : x+y # First, We defined x, y variable and this function will return sum of x and y\nprint(g(1,3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Anonymous Function**"},{"metadata":{},"cell_type":"markdown","source":"* We use this function for send multiple values ​​to a function that takes one value."},{"metadata":{"trusted":true},"cell_type":"code","source":"# map(function, values) # If you want to send multiple values. You must send them in the list\ny = list(map(lambda x:x**2,[1,2,3])) # We must convert map function to list format. Because it will return multiple values\nprint(y)\n# If you get an error in this code, don't mind because the error may be caused by kaggle","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Iterators**"},{"metadata":{},"cell_type":"markdown","source":"* Iterable are an objects. For example lists and dictionaries are iterable objects\n* Iterator: produce next value with next() method."},{"metadata":{"trusted":true},"cell_type":"code","source":"x = [1,2,3,4,5,6]\nit = iter(x)\nprint(next(it)) # Print next iteration\nprint(next(it))\nprint(*it) # Print remaining iteration\nprint(\"\")\n\nstring = \"asdfg\"\nit2 = iter(string)\nprint(next(it2)) # Print next iteration\nprint(*it2) # Print remaining iteration\n\n# All objects that we can use with loops are iterable objects","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Zip**"},{"metadata":{},"cell_type":"markdown","source":"* We use this method to map two lists. For example:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Zip\nlist1 = [1,2,3,4]\nlist2 = [5,6,7,8] # the length of the first list must be equal to the length of the second list\nf = list(zip(list1,list2)) # We must convert zip function to list format.\n\n# Unzip\nunzip = zip(*f)\nunlist1,unlist2 = list(unzip) # Unzip returns tuple\nprint(unlist1)\nprint(unlist2)\n# If you get an error in this code, don't mind because the error may be caused by kaggle","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**List Comprehension**"},{"metadata":{},"cell_type":"markdown","source":"* List comprehensions are used for creating new lists from other iterables. For example:"},{"metadata":{"trusted":true},"cell_type":"code","source":"list1 = [1,2,3,4] # Lists are iterable object\nf = [i**2 for i in list1]\nprint(f)\nprint(\"\")\n\n# Conditional List Comprehension\nlist2 = [10,15,20,25]\ng = [i if i%10==0 else i**2 if i==15 else i+3 for i in list2]\nprint(g)\n# Both is same\n# def g(*args):\n#     for i in args:\n#         if(i % 10 == 0):\n#             print(i)\n#         elif(i == 15):\n#             print(i**2)\n#         else:\n#             print(i+3)\n# g(10,20,36,64)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's try to use List Comprehension with Pandas"},{"metadata":{"trusted":true},"cell_type":"code","source":"avg = sum(data.Attack)/len(data.Attack) # We found the average attack\ndata[\"Avg_Attack\"] = [\"High\" if i > avg else \"Low\" for i in data.Attack] # If pokemon's attack is higher than average, Avg_Attack will be High. If not Avg_Attack will be Low\nprint(avg)\ndata.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Cleaning Data**"},{"metadata":{},"cell_type":"markdown","source":"* The data we obtain may not always be clean. In these cases, we need to pre-process the data"},{"metadata":{},"cell_type":"markdown","source":"### Explotary Data Analysis\nvalue_counts(): Frequency counts\n<br>outliers: the value that is considerably higher or lower from rest of the data\n* Lets say value at 75% is Q3 and value at 25% is Q1. \n* Outlier are smaller than Q1 - 1.5(Q3-Q1) and bigger than Q3 + 1.5(Q3-Q1). (Q3-Q1) = IQR\n<br>We will use describe() method. Describe method includes:\n* count: number of entries\n* mean: average of entries\n* std: standart deviation\n* min: minimum entry\n* 25%: first quantile\n* 50%: median or second quantile\n* 75%: third quantile\n* max: maximum entry\n\n<br> What is quantile?\n\n* 1,4,5,6,8,9,11,12,13,14,15,16,17\n* The median is the number that is in **middle** of the sequence. In this case it would be 11.\n\n* The lower quartile is the median in between the smallest number and the median i.e. in between 1 and 11, which is 6.\n* The upper quartile, you find the median between the median and the largest number i.e. between 11 and 17, which will be 14 according to the question above."},{"metadata":{"trusted":true},"cell_type":"code","source":"# For example lets look frequency of pokemom types\nprint(data['Type 1'].value_counts(dropna =False))  # if there are nan values that also be counted\n# As it can be seen below there are 112 water pokemon or 70 grass pokemon","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe() # ignore null entries","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visual Exploratory Data Analysis\n* Box plots: visualize basic statistics like outliers, min/max or quantiles"},{"metadata":{"trusted":true},"cell_type":"code","source":"# For example: compare attack of pokemons that are legendary  or not\n# Black line at top is max\n# Blue line at top is 75%\n# Red line is median (50%)\n# Blue line at bottom is 25%\n# Black line at bottom is min\n# There are no outliers\ndata.boxplot(column='Attack',by = 'Legendary')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tidy Data\nWe tidy data with melt().\nDescribing melt is confusing. Therefore lets make example to understand it."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Firstly I create new data from pokemons data to explain melt nore easily.\ndata_new = data.head(5) # I only take 5 rows into new data\nmelted = pd.melt(frame = data_new,id_vars = 'Name',value_vars= ['Attack','Defense'])\nmelted","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Privoting Data\nReverse of melting."},{"metadata":{"trusted":true},"cell_type":"code","source":"melted.pivot(index = 'Name', columns = 'variable',values='value')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Concatenating Data\nWe can concatenate two dataframe **"},{"metadata":{"trusted":true},"cell_type":"code","source":"data1 = data.head()\ndata2 = data.tail()\nconc_data_row = pd.concat([data1,data2],axis = 0,ignore_index = True)\nconc_data_row","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1 = data['Attack'].head()\ndata2= data['Defense'].head()\nconc_data_col = pd.concat([data1,data2],axis =1) # axis = 0 : adds dataframes in row\nconc_data_col","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Types\nThere are 5 basic data types: object(string),booleab,  integer, float and categorical.\n<br> We can make conversion data types like from str to categorical or from int to float\n<br> Why is category important: \n* make dataframe smaller in memory \n* can be utilized for analysis especially for sklearn(we will learn later)"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets convert object(str) to categorical and int to float.\ndata[\"Type 1\"] = data[\"Type 1\"].astype('category')\ndata['Speed'] = data['Speed'].astype('float')\ndata.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Missing Data And Testing With Assert\nIf we encounter with missing data, what we can do:\n* leave as is\n* drop them with dropna()\n* fill missing value with fillna()\n* fill missing values with test statistics like mean\n<br>Assert statement: check that you can turn on or turn off when you are done with your testing of the program"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets check Type 2\ndata[\"Type 2\"].value_counts(dropna =False)\n# As you can see, there are 386 NAN value","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets drop nan values\ndata1=data   # also we will use data to fill missing value so I assign it to data1 variable\ndata1[\"Type 2\"].dropna(inplace = True)  # inplace = True means we do not assign it to new variable. Changes automatically assigned to data\n# So does it work ?","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Lets check with assert statement\n# Assert statement:\nassert 1==1 # return nothing because it is true","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert  data['Type 2'].notnull().all() # returns nothing because we drop nan values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"Type 2\"].fillna('empty',inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert  data['Type 2'].notnull().all() # returns nothing because we do not have nan values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # With assert statement we can check a lot of thing. For example\n# assert data.columns[1] == 'Name'\n# assert data.Speed.dtypes == np.int","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Pandas Foundation**"},{"metadata":{},"cell_type":"markdown","source":"### Review of Pandas\nAs you notice, I do not give all idea in a same time. Although, we learn some basics of pandas, we will go deeper in pandas.\n* single column = series\n* NaN = not a number\n* dataframe.values = numpy"},{"metadata":{},"cell_type":"markdown","source":"### Building Data Frames From Scratch\n* We can build data frames from csv as we did earlier.\n* Also we can build dataframe from dictionaries\n    * zip() method: This function returns a list of tuples, where the i-th tuple contains the i-th element from each of the argument sequences or iterables.\n* Adding new column\n* Broadcasting: Create new column and assign a value to entire column"},{"metadata":{"trusted":true},"cell_type":"code","source":"# data frames from dictionary\ncountry = [\"Spain\",\"France\"]\npopulation = [\"11\",\"12\"]\nlist_label = [\"country\",\"population\"]\nlist_col = [country,population]\nzipped = list(zip(list_label,list_col))\ndata_dict = dict(zipped)\ndf = pd.DataFrame(data_dict)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"income\"] = 0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visual Exploratory Data Analysis\n* Plot\n* Subplot\n* Histogram:\n    * bins: number of bins\n    * range(tuble): min and max values of bins\n    * normed(boolean): normalize or not\n    * cumulative(boolean): compute cumulative distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"data1 = data.loc[:,[\"Attack\",\"Defense\",\"Speed\"]]\ndata1.plot()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1.plot(subplots = True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1.plot(kind = \"scatter\",x=\"Attack\",y=\"Defense\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1.plot(kind=\"hist\",y=\"Defense\",bins = 50,range=(0,250),normed = True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# histogram subplot with non cumulative and cumulative\nfig, axes = plt.subplots(nrows=2,ncols=1)\ndata1.plot(kind = \"hist\",y = \"Defense\",bins = 50,range= (0,250),normed = True,ax = axes[0])\ndata1.plot(kind = \"hist\",y = \"Defense\",bins = 50,range= (0,250),normed = True,ax = axes[1],cumulative = True)\nplt.savefig('graph.png')\nplt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Index'ng Pandas Time Series\n* datetime = object\n* parse_dates(boolean): Transform date to ISO 8601 (yyyy-mm-dd hh:mm:ss ) format"},{"metadata":{"trusted":true},"cell_type":"code","source":"time_list = [\"1992-03-08\",\"1992-04-12\"]\ndatetime_object = pd.to_datetime(time_list)\nprint(type(datetime_object))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# close warning\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# In order to practice lets take head of pokemon data and add it a time list\ndata2 = data.head()\ndate_list = [\"1992-01-10\",\"1992-02-10\",\"1992-03-10\",\"1993-03-15\",\"1993-03-16\"]\ndatetime_object = pd.to_datetime(date_list)\ndata2[\"date\"] = datetime_object\n# lets make date as index\ndata2= data2.set_index(\"date\")\ndata2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data2.loc[\"1993-03-16\"])\nprint(data2.loc[\"1992-03-10\":\"1993-03-16\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Resampling Pandas Time Series\n* Resampling: statistical method over different time intervals\n    * Needs string to specify frequency like \"M\" = month or \"A\" = year\n* Downsampling: reduce date time rows to slower frequency like from daily to weekly\n* Upsampling: increase date time rows to faster frequency like from daily to hourly\n* Interpolate: Interpolate values according to different methods like ‘linear’, ‘time’ or index’ \n    * https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.interpolate.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"data2.resample(\"A\").mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data2.resample(\"M\").mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# In real life (data is real. Not created from us like data2) we can solve this problem with interpolate\n# We can interpolate from first value\ndata2.resample(\"M\").first().interpolate(\"linear\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data2.resample(\"M\").mean().interpolate(\"linear\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Manipulating Data Frames With Pandas"},{"metadata":{},"cell_type":"markdown","source":"### Indexing Data Frames\n* Indexing using square brackets\n* Using column attribute and row label\n* Using loc accessor\n* Selecting only some columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/Pokemon.csv')\ndata = data.set_index(\"#\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"HP\"][1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.loc[1,[\"HP\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[[\"HP\",\"Attack\"]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Slicing Data Frame\n* Difference between selecting columns\n    * Series and data frames\n* Slicing and indexing series\n* Reverse slicing \n* From something to end"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(type(data[\"HP\"]))\nprint(type(data[[\"HP\"]]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.loc[1:5,[\"HP\",\"Defense\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# From something to end\ndata.loc[1:10,\"Speed\":]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Filtering Data Frames\nCreating boolean series\nCombining filters\nFiltering column based others"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"HP\"][data[\"Speed\"]<15]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Transforming Data\n* Plain python functions\n* Lambda function: to apply arbitrary python function to every element\n* Defining column using other columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plain python functions\ndef div(n):\n    return n/2\ndata[\"HP\"].apply(div)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"HP\"].apply(lambda n : n/2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"total_power\"] = data.Attack + data.Defense\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Index Object And Labeled Data\nindex: sequence of label"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data.index.name)\n# Let's change it\ndata.index.name = \"index_name\"\nprint(data.index.name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()\ndata3 = data.copy()\ndata3.index = range(100,900)\ndata3.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We can make one of the column as index. I actually did it at the beginning of manipulating data frames with pandas section\n# It was like this\n# data= data.set_index(\"#\")\n# also you can use \n# data.index = data[\"#\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Hierarchical Indexing\n* Setting indexing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets read data frame one more time to start from beginning\ndata = pd.read_csv('../input/Pokemon.csv')\ndata.head()\n# As you can see there is index. However we want to set one or more column to be index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1 = data.set_index([\"Type 1\",\"Type 2\"])\ndata1.head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Pivoting Data Frames\n* pivoting: reshape tool"},{"metadata":{"trusted":true},"cell_type":"code","source":"dic = {\"treatment\":[\"A\",\"A\",\"B\",\"B\"],\"gender\":[\"F\",\"M\",\"F\",\"M\"],\"response\":[10,45,5,9],\"age\":[15,4,72,65]}\ndf = pd.DataFrame(dic)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.pivot(index=\"treatment\",columns = \"gender\",values=\"response\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Stacking and Unstacking DataFrame\n* deal with multi label indexes\n* level: position of unstacked index\n* swaplevel: change inner and outer level index position"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = df.set_index([\"treatment\",\"gender\"])\ndf1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# levels determines indexes\ndf1.unstack(level=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2 = df1.swaplevel(0,1)\ndf2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Melting Data Frames\n* Reverse of pivoting"},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.melt(df,id_vars = \"treatment\",value_vars = [\"age\",\"response\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Categoricals and Groupby"},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(\"treatment\").mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(\"treatment\")[\"age\",\"response\"].mean()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}