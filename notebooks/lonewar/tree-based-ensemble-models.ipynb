{"cells":[{"metadata":{"collapsed":true,"_uuid":"c0ea3272ad765f8a0e5b68504cba23a9bb810e1f"},"cell_type":"markdown","source":"# Predicting churning customers"},{"metadata":{"_uuid":"149748e95d668318fee88261a8006961f0e0a1f0"},"cell_type":"markdown","source":"## Exploratory Data Analysis\n\n (1) Preliminary analysis\n \n (2) Explore each individual variable\n\n (3) Explore pairwise relationship between variables\n\n (4) Explore each variable against the target variable"},{"metadata":{"_uuid":"4119b2c0366f05ad7b98f0720a3678b6ae89036e"},"cell_type":"markdown","source":"### (1) Preliminary analysis"},{"metadata":{"trusted":false,"_uuid":"9e79fa076687ac6b54f80f8ecab30bfb15ff32ec"},"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv('../input/bigml_59c28831336c6604c800002a.csv', sep=',')\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"b8d938095a936c8a1e567a5de97e86b0d88a9d93"},"cell_type":"code","source":"df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"19348272485a1dab92b1e03b125c507f1656f672"},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"4549de94076a87ac56f0ef44347efa3cd0fc41a9"},"cell_type":"code","source":"list(df.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"533052103bcdb68cd21a24f71c1141056351e89f"},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"eaba3f1eb31759a4e21604259b66980bad76edfc"},"cell_type":"code","source":"print(df['phone number'].nunique())\nprint(df['state'].nunique()) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"4eb54d7afa087fc0ecbb35f27032f306a7616ae1"},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"499994356f37a60c3c4e25b31cc045e8e0ced066"},"cell_type":"markdown","source":"### (2) Explore each individual variable: visualizing the distributions of some columns\nThe column 'state' is discrete and of high cardinality. Therefore using one-hot encoding may result in very sparse features. This feature may be useful.</br>\nThe column 'area code': why only three values? 'area code' is of int64 type but it may be supposed to be considered as categorical values.</br>\nThe column 'phone number' is the IDs of the records. It is unique to each record. We will not use it.</br>\nThe target variable 'churn' is imbalanced (almost 6:1). We may need to tackle this problem.</br></br>\n\nThis is a binary classification problem. Each row of the data corresponds to a unique user that belongs to a single class (True/False)."},{"metadata":{"trusted":false,"_uuid":"6816cc376e76235393ddf42a8aa01f905664989a"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"d176e1d33abfdaf80eb130242db7e52ac0ddadd4"},"cell_type":"code","source":"fig, axs = plt.subplots(3, 4, figsize=(20, 10))\n\ndf.state.value_counts().plot(kind='bar', ax=axs[0,0]); axs[0,0].set_title('state')\ndf.hist(column='account length', ax=axs[0,1]); axs[0,1].set_title('account length')\ndf['area code'].value_counts().plot(kind='bar', ax=axs[0,2]); axs[0,2].set_title('area code')\ndf['international plan'].value_counts().plot(kind='bar', ax=axs[0,3]); axs[0,3].set_title('international plan')\n\ndf['voice mail plan'].value_counts().plot(kind='bar', ax=axs[1,0]); axs[1,0].set_title('voice mail plan')\ndf.hist(column='number vmail messages', ax=axs[1,1]); axs[1,1].set_title('number vmail messages')\n\ndf.hist(column='customer service calls', ax=axs[2,0]); axs[2,0].set_title('customer service calls')\ndf.churn.value_counts().plot(kind='bar', ax=axs[2,1]); axs[2,1].set_title('churn');","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"17fe6ffbab8e149691d634d1da47a36dc5451393"},"cell_type":"code","source":"churn_true = len(df[df['churn'] == True].index)\nchurn_false = len(df[df['churn'] == False].index)\nprint('Churn rate is: {}. \\nchurn_false/churn_true = {}. churn_false - churn_true = {}. \\nThe data is imbalanced.'\n      .format(churn_true / (churn_true + churn_false), churn_false / churn_true, churn_false - churn_true))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"4f9fefa832772a7ae0274c9dd36df3752878e520"},"cell_type":"code","source":"cols = list(df.columns)\ncols.remove('state')\ncols.remove('area code')\ncols.remove('phone number')\ncols.remove('international plan')\ncols.remove('voice mail plan')\ncols.remove('churn')\n\n# Define a set of columns to be removed. They are not to be used as features.\ncols_to_remove = {'phone number', } # 'churn' not included\n\nprint(cols)\nprint()\nprint(cols_to_remove)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ffdfa0798111dbe3819d9b05c6df85082159d9e3"},"cell_type":"markdown","source":"### (3) Explore pairwise relationship between variables (scatterplot matrix & correlation matrix)\nWe can see that there are linear correlations between each of the following column pairs: 'total day minutes' and 'total day charge', 'total eve minutes' and 'total eve charge', 'total night minutes' and 'total night charge', and 'total intl minutes' and 'total intl charge'. </br>\n\nWe can therefore remove the four '*** charge' columns."},{"metadata":{"trusted":false,"_uuid":"d719c135ff242c95e9f94f4a4c7a5ee718fea98a"},"cell_type":"code","source":"sns.pairplot(df[cols], size=2.7)\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d1e9b94a7cc31eda668ca14a07288eec65007604"},"cell_type":"markdown","source":"Correlation matrix between each pair of features\nThis confirms the above observations."},{"metadata":{"trusted":false,"_uuid":"2ea1819ca1177e76ff2001be1954694af7bfeff0"},"cell_type":"code","source":"cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"4b80bf20b3c4353f4c2ce998106c3fea4d434fb4"},"cell_type":"code","source":"import numpy as np\n\ncm = np.corrcoef(df[cols].values.T)\nsns.set(font_scale=1.0)\nplt.figure(figsize=(10,10))\nhm = sns.heatmap(cm,\n                 cbar=True,\n                 annot=True,\n                 square=True,\n                 fmt='.2f',\n                 annot_kws={'size': 10},\n                 xticklabels=cols,\n                 yticklabels=cols)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"cf8ddcd1d9887e4e3dfaf4ac1cbce54465bb60aa"},"cell_type":"code","source":"cols_to_remove.update(['total day charge', 'total eve charge', 'total night charge', 'total intl charge'])\ncols_to_remove","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e15f5397652bad397355527d7275d02aacc45d27"},"cell_type":"markdown","source":"### (4) Explore each variable against the target variable\nThe observation:</br>\npositive and negative classes ('churn') of data have different distributions in the the features, especially in 'total day minutes', 'international plan' and 'customer service call', etc."},{"metadata":{"trusted":false,"_uuid":"cbb566134b9fc508ba2b7af9fbb5713804b36cfd"},"cell_type":"code","source":"df.groupby(['churn']).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"0d0690d5721fd2f2319b25745ce522c391ca6de6"},"cell_type":"code","source":"fig, axs = plt.subplots(3, 4, figsize=(20, 12))\ndf.groupby(['churn'])['account length'].plot(kind='kde', legend=True, ax=axs[0,0]); axs[0,0].set_title('account length')\ndf.groupby(['churn'])['number vmail messages'].plot(kind='kde', legend=True, ax=axs[0,1]); axs[0,1].set_title('number vmail messages')\ndf.groupby(['churn'])['total day minutes'].plot(kind='kde', legend=True, ax=axs[0,2]); axs[0,2].set_title('total day minutes')\ndf.groupby(['churn'])['total day calls'].plot(kind='kde', legend=True, ax=axs[0,3]); axs[0,3].set_title('total day calls')\ndf.groupby(['churn'])['total eve minutes'].plot(kind='kde', legend=True, ax=axs[1,0]); axs[1,0].set_title('total eve minutes')\ndf.groupby(['churn'])['total eve calls'].plot(kind='kde', legend=True, ax=axs[1,1]); axs[1,1].set_title('total eve calls')\ndf.groupby(['churn'])['total night minutes'].plot(kind='kde', legend=True, ax=axs[1,2]); axs[1,2].set_title('total night minutes')\ndf.groupby(['churn'])['total night calls'].plot(kind='kde', legend=True, ax=axs[1,3]); axs[1,3].set_title('total night calls')\ndf.groupby(['churn'])['total intl minutes'].plot(kind='kde', legend=True, ax=axs[2,0]); axs[2,0].set_title('total intl minutes')\ndf.groupby(['churn'])['total intl calls'].plot(kind='kde', legend=True, ax=axs[2,1]); axs[2,1].set_title('total intl calls')\ndf.groupby(['churn'])['customer service calls'].plot(kind='kde', legend=True, ax=axs[2,2]); axs[2,2].set_title('customer service calls');\n# Because the classes are imbalanced, I think 'kde' is more preferred than 'hist' here.","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"2736d50ffaa955167416e9c1d3303326f526ffba"},"cell_type":"code","source":"fig, axs = plt.subplots(1, 3, figsize=(15, 5))\nsns.countplot(x='international plan', hue='churn', data=df, ax=axs[0])\n# axs[0].set_title('international plan')\nsns.countplot(x='voice mail plan', hue='churn', data=df, ax=axs[1])\n# axs[1].set_title('voice mail plan')\nsns.countplot(x='customer service calls', hue='churn', data=df, ax=axs[2])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"77d6575b45e9f60d077bf3caf4c099ac3957342a"},"cell_type":"markdown","source":"# Data preprocessing\n\nThis includes encoding categorical variables, etc.\nI did not do feature scaling since I'm going to use tree-based algorithms. \nThere is no null values."},{"metadata":{"trusted":false,"_uuid":"785879163c317561ce35848967d2722e9994ab1c"},"cell_type":"code","source":"cols_to_remove","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"d7bfa18bab36687e85410338c1dfd60fde7899b5"},"cell_type":"code","source":"df2 = df.drop(list(cols_to_remove), axis=1)\ndf2.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d5bf5b4d10fcb9a717021ef05910ea07c0461bcf"},"cell_type":"markdown","source":"Applying encoding to categorical variables"},{"metadata":{"trusted":false,"_uuid":"640c84f55f7f5c725add2ec98b8e072badee259e"},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n# The following two are of multiple categories\n# ohencoder = OneHotEncoder()\n\n# TODO\n# [Observations] 'state' and 'area code' columns are categorical and should be applied with one-hot encoding. \n# However due to 'state' is of high cardinality (51), this would negatively affect the prediction performance (low split gain)\n# RF may be affected more than GBDT.\n# 'area code' is of 3 categories. I applied one-hot encoding on it.\n\n\n# The following three are of binary categories\nlabel_encoder = LabelEncoder()\ndf2['international plan'] = label_encoder.fit_transform(df2['international plan'])\ndf2['voice mail plan'] = label_encoder.fit_transform(df2['voice mail plan'])\ndf2['churn'] = label_encoder.fit_transform(df2['churn'])\n\n\ndf2.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false,"_uuid":"b89bf18d07bfee1300447a22d067c23fecbbecf5"},"cell_type":"code","source":"# one-hot encoding 'area code'\ndf2 = pd.get_dummies(df2, columns=['area code'], prefix='areacode', drop_first=True)\ndf2.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"63010957160ff94395a5cc878029b7080ab03e81"},"cell_type":"markdown","source":"# Churn Prediction"},{"metadata":{"_uuid":"cf4dac058951df62aa006cee59b7645fc05984be"},"cell_type":"markdown","source":"## Splitting the data for training and testing"},{"metadata":{"_uuid":"3cc407b83700d67fba74f6cf0f3e090ead289515"},"cell_type":"markdown","source":"Select the features to be used, and then split the data into training dataset and test dataset. Make sure the proportion of different target values is consistent by using 'stratify=y'."},{"metadata":{"trusted":false,"_uuid":"9ac49f2239e3321a9ed6878f9600d9255f68fb83"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = df2.loc[:, [c for c in list(df2.columns) if c not in cols_to_remove | {'churn', 'state', 'area code'}]].values\ny = df2.loc[:, 'churn'].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"114b6aa20a7d657b9ff68c9b004b911c993f33a1"},"cell_type":"code","source":"X_train.shape, X_test.shape, y_train.shape, y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"31191f758e312c09eea1f5792151c7695fa84838"},"cell_type":"markdown","source":"Because the data is imbalanced, I'll oversample the minor class (Churn=True) to make the data more balanced using SMOTE."},{"metadata":{"trusted":false,"_uuid":"89207c888d1d1bea1aa6e6eff196d81d82416df3"},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nsm = SMOTE(random_state=0, ratio=1.0)\nX_train_balanced, y_train_balanced = sm.fit_resample(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"9632fb466eedac8fa542615cd7a268468555b182"},"cell_type":"code","source":"X_train_balanced.shape, y_train_balanced.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"6d4a986df14025ae731b2c955f33a173b1a5bde7"},"cell_type":"code","source":"import collections\ncollections.Counter(y_train_balanced)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6ce8dad17c8249a5c7b29e738e1ac45b07662032"},"cell_type":"markdown","source":"## Training and evaluating the models \n\nI used tree-based algorithms."},{"metadata":{"trusted":false,"_uuid":"d2e04d431d6208bce9ab7b569467217044bb4c8a"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=10, criterion='entropy')\nrf.fit(X_train_balanced, y_train_balanced)\ny_pred = rf.predict(X_test)\n\nfrom sklearn.metrics import classification_report, f1_score, roc_auc_score\nprint(classification_report(y_test, y_pred))\n\nmetric_result = pd.DataFrame(data=[['RandomForestClassifier', f1_score(y_test, y_pred), roc_auc_score(y_test, y_pred)]], \n                             columns=['algorithm', 'f1_score', 'roc_auc_score'])\n\ndel y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"f92712c7d7ffcd049689af356131d9acb6effb9c"},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\n\ntree = DecisionTreeClassifier(criterion='entropy', random_state=1, max_depth=3)\nada = AdaBoostClassifier(base_estimator=tree, n_estimators=500, learning_rate=0.1, random_state=1)\nada.fit(X_train_balanced, y_train_balanced)\ny_pred = ada.predict(X_test)\n\nprint(classification_report(y_test, y_pred))\nmetric_result.loc[1] = ['AdaBoostClassifier', f1_score(y_test, y_pred), roc_auc_score(y_test, y_pred)]\n\ndel y_pred","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false,"_uuid":"ef7b25252cec831cb31a8afaff1cbb2e3d1fb415"},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\ngbc = GradientBoostingClassifier(loss='deviance', n_estimators=100, max_depth=4)\ngbc.fit(X_train_balanced, y_train_balanced)\ny_pred = gbc.predict(X_test)\n\nprint(classification_report(y_test, y_pred))\nmetric_result.loc[2] = ['GradientBoostingClassifier', f1_score(y_test, y_pred), roc_auc_score(y_test, y_pred)]\n\ndel y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"55a1eec54cc31a9efd4929e5bb5b136a8f9c30db"},"cell_type":"code","source":"metric_result","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"225ada057b6e6d185fb54a977237b4b9f81959e4"},"cell_type":"code","source":"metric_result.plot(x='algorithm', kind='barh')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8256078f5d37a57a8eedfd5548c31ea2654fc4a1"},"cell_type":"markdown","source":"After I tried one-hot encoding on the 'state' feature, I found that it seems Random Forest tends to be more affected by the encoding, in comparison to Gradient Boosting."},{"metadata":{"_uuid":"1ba003cac662d1c3917d10696c86d3fd6ae125b4"},"cell_type":"markdown","source":"# Next"},{"metadata":{"_uuid":"2a2da2552feaf698e6f74f8e40391c4ef8ba8b0d"},"cell_type":"markdown","source":"LightGBM, with Optimal Split for Categorical Features (https://lightgbm.readthedocs.io/en/latest/Features.html#optimal-split-for-categorical-features)\n\nAdaCost: Misclassification Cost-sensitive Boosting"},{"metadata":{"trusted":false,"_uuid":"a3227da9798fd83720bb3ca0a21e1c4013576f3b"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":1}