{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Overview of Assignment**\nThis project was designed to classify bird species using Kaggle.  \n\n**Description of the Data**\nThe \"100-bird-species\" data contains images of 190 bird species.  The data is split into test, validation, and train data with 950 images, 950 images, and 25,812 images, respectively.  The images are all in jpg format.  The dimesions of the images are 224, 224, 3.\n\n**Summary of Methods**\nThe first method used in this project is fastai Data Block API.  This was used to normalize and view the images of the first 25 birds with their respective labels.  ImageDataGenerator data augmentation was then used to scale the images.  InceptionV3 was applied to the ImageNet dataset for training.  \n\n**Summary of Model**\nThe model was built using the InceptionV3 base data.  BatchNormalization was applied and the layer was flattened.  Relu activation was used along with a Dense layer.  The Dense layer output was 190 to match the number of bird species at the time of this writing.  A SoftMax activation was then applied.  The model was compiled using the RMSprop optimizer with a learning rate of 0.001.  Categorical Crossentropy was also used.\nThe second model used a functional API.  Numerous layers of Conv2D, AveragePooling2D, BatchNormalization, Concatenation, and Dense were used.  The SGD optimizer was applied.\n\n**Analysis of Results**\nThe model performed decently with a test accuracy of 67.79% using the InceptionV3 model.  The loss rate was 5.85%.\nThe second model performed poorly as functional APIs are not the best solution for this kind of data/classification."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Imports statements\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import backend\nfrom tensorflow.keras.layers import Dense, Input, Activation, Dropout, Flatten, BatchNormalization, Concatenate\nfrom tensorflow.keras.optimizers import Adam, SGD, RMSprop\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.applications import InceptionV3\nfrom tensorflow.keras.utils import plot_model\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom fastai.vision import *\nfrom IPython.core.display import display, HTML\ndisplay(HTML(\"<style>.container { width:100% !important; }</style>\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Directories were created using the os.path.join function to access the training, validation, and testing datasets within the 100-bird-species data set."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Directory calls\nsource_dir = Path('../input/100-bird-species/')\nsource_dir.ls()\ntrain_dir = os.path.join(source_dir, 'train')\nvalid_dir = os.path.join(source_dir, 'valid')\ntest_dir = os.path.join(source_dir, 'test')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"fastai Data Block API was used to view a sample of images and labels."},{"metadata":{"trusted":true},"cell_type":"code","source":"img_src = (ImageList.from_folder(source_dir)\n                .split_by_folder(train='train', valid='valid')\n                .label_from_folder()\n                .add_test_folder('test')\n                .transform(get_transforms(), size=224))\n\nbird_data = img_src.databunch(bs=32).normalize(imagenet_stats)\nbird_data.show_batch()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data augmentation was applied using ImageDataGenerator to create each of the three data sets."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create data sets\ndata_gen = ImageDataGenerator(rescale=1./255, )\ntrain_data = data_gen.flow_from_directory(train_dir, target_size=(224,224))\nvalid_data = data_gen.flow_from_directory(valid_dir, target_size=(224,224))\ntest_data = data_gen.flow_from_directory(test_dir, target_size=(224,224))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"InceptionV3 was used on the \"imagenet\" dataset as the base of this model.  Additional Layers were applied to increase accuracy."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build model\nbackend.clear_session()\nconv_base = InceptionV3 (weights = 'imagenet', \n                  include_top = False,\n                  input_shape = (224, 224, 3))\nconv_base.trainable = False # Freeze the Inception V3 weights.\n\nmodel = Sequential()\nmodel.add(conv_base)\nmodel.add(BatchNormalization())\nmodel.add(keras.layers.Flatten())\nmodel.add(Activation('relu'))\nmodel.add(Dense(190))\nmodel.add(Activation('softmax'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The model was compiled using the RMSprop optimizer."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compile model\nmodel.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.001, decay=1e-6, momentum=0.9),\n             loss = 'categorical_crossentropy',\n             metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The accuracy vs epoch and loss values vs epoch were plotted and displayed.  The model was then applied to the test data to view accuracy."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot graphs\nhistory = model.fit_generator(\n    train_data,\n    steps_per_epoch=766,\n    epochs=50,\n    validation_data=valid_data,\n    validation_steps=29,\n    verbose = 1,\n    callbacks=[EarlyStopping(monitor='val_accuracy', patience = 4, restore_best_weights = True)])\n\n#plot accuracy vs epoch\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot loss values vs epoch\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Evaluate test data.\nscores = model.evaluate(test_data, verbose=1)\nprint('Test loss:', scores[0])\nprint('Test accuracy:', scores[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A functional API model was used on the 100-bird-species data as well."},{"metadata":{"trusted":true},"cell_type":"code","source":"backend.clear_session()\n\n# Input model\ninput_a = Input(shape=(224,224,3))\n\n# Create Tower 1\nconv2d_a = Conv2D(64, (3,3), padding = 'same', activation='relu')(input_a)\n\n# Create Tower 2\nconv2d_b = Conv2D(64, (3,3), padding = 'same', activation='relu')(input_a)\n\n# Batch Norm.\nbatch_normalization_a = BatchNormalization()(input_a)\n\n# Create Tower 3\nconv2d_c = Conv2D(64, (3,3), padding = 'same', activation='relu')(batch_normalization_a)\npool_a = AveragePooling2D((3, 3), padding = 'same', strides=(1,1))(conv2d_c)\n\n# Create Tower 4\nconv2d_d = Conv2D(64, (3,3), padding = 'same', activation='relu')(batch_normalization_a)\npool_b = AveragePooling2D((3, 3), padding = 'same', strides=(1,1))(conv2d_d)\n\n# Create Tower 5\nconv2d_e = Conv2D(64, (3,3), padding = 'same', activation='relu')(batch_normalization_a)\nconv2d_f = Conv2D(64, (3,3), padding = 'same', activation='relu')(conv2d_e)\npool_c = AveragePooling2D((3, 3), padding = 'same', strides=(1,1))(conv2d_f)\n\n# Create Tower 6\nconv2d_g = Conv2D(64, (3,3), padding = 'same', activation='relu')(batch_normalization_a)\nconv2d_h = Conv2D(64, (3,3), padding = 'same', activation='relu')(conv2d_g)\nconv2d_i = Conv2D(64, (3,3), padding = 'same', activation='relu')(conv2d_h)\npool_d = AveragePooling2D((3, 3), padding = 'same', strides=(1,1))(conv2d_i)\n\n# Concatentate\nconcatenate_a = Concatenate(axis=-1)([pool_a, pool_b, pool_c, pool_d])\n\n# Batch Norm.\nbatch_normalization_b = BatchNormalization()(concatenate_a)\n\n# Create Tower 7\nconv2d_j = Conv2D(64, (3,3), strides=(1,1),padding = 'same', activation='relu')(batch_normalization_b)\n\n# Create Tower 8\nconv2d_k = Conv2D(64, (3,3), strides=(1,1), padding = 'same', activation='relu')(conv2d_j)\n\n# Batch Norm.\nbatch_normalization_c = BatchNormalization()(conv2d_k)\n\n# Flatten\nflat_a = keras.layers.Flatten()(batch_normalization_c)\n\n# Batch Norm.\nbatch_normalization_d = BatchNormalization()(flat_a)\n\n# Hidden connected layer and output\ndense_a = Dense(32, activation='relu')(batch_normalization_d)\ndropout_a = Dropout(0.5)(dense_a)\ndense_b = Dense(190, activation='softmax')(dropout_a)\n\nmodel_2 = Model(inputs=input_a, outputs=dense_b)\n# plot graph\nplot_model(model_2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The functional API was then compiled using the SGD optimizer with a learning rate of 0.001.  Plots were generated."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compile, fit, plot, and assess\nmodel_2.compile(optimizer = tf.keras.optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9),\n             loss = 'categorical_crossentropy',\n             metrics = ['accuracy'])\n\nhistory = model_2.fit_generator(\n    train_data,\n    steps_per_epoch=766,\n    epochs=50,\n    validation_data=valid_data,\n    validation_steps=29,\n    verbose = 1,\n    callbacks=[EarlyStopping(monitor='val_accuracy', patience = 4, restore_best_weights = True)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot accuracy vs epoch\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot loss values vs epoch\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Evaluate test data.\nscores = model_2.evaluate(test_data, verbose=1)\nprint('Test loss:', scores[0])\nprint('Test accuracy:', scores[1])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}