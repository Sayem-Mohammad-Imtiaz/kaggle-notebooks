{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport folium\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The dataset has the information about the air pollution of Seoul, Korea. \n1. Measurement Summary -- It is the combined form of the 3 detailed dataset. It included different gases concentration values measured at different lattitude/longitude at different timestamp. \n2. Measurement Item Info -- It provide us the information about the severity of the concentration of any particulate."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"measure_df = pd.read_csv('/kaggle/input/air-pollution-in-seoul/AirPollutionSeoul/Measurement_summary.csv')\nserverity_df = pd.read_csv('/kaggle/input/air-pollution-in-seoul/AirPollutionSeoul/Original Data/Measurement_item_info.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating function for each particulate type to assign severity category as Good, Normal, Bad or Very Bad."},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef severitySO2(x):\n    severity = \"\"\n    if(x <= 0.02):\n        severity = \"Good\"\n    elif((x > 0.02) & (x <= 0.05)):\n        severity = \"Normal\"\n    elif((x > 0.05) & (x <= 0.15)):\n        severity = \"Bad\"\n    elif((x > 0.15) & (x <= 1.0)):\n        severity = \"Very Bad\"\n    return severity\n\ndef severityNO2(x):\n    severity = \"\"\n    if(x <= 0.03):\n        severity = \"Good\"\n    elif((x > 0.03) & (x <= 0.06)):\n        severity = \"Normal\"\n    elif((x > 0.06) & (x <= 0.2)):\n        severity = \"Bad\"\n    elif((x > 0.2) & (x <= 2.0)):\n        severity = \"Very Bad\"\n    return severity\n    \ndef severityCO(x):\n    severity = \"\"\n    if(x <= 2):\n        severity = \"Good\"\n    elif((x > 2) & (x <= 9)):\n        severity = \"Normal\"\n    elif((x > 9) & (x <= 15)):\n        severity = \"Bad\"\n    elif((x > 15) & (x <= 50)):\n        severity = \"Very Bad\"\n    return severity\n    \ndef severityO3(x):\n    severity = \"\"\n    if(x <= 0.03):\n        severity = \"Good\"\n    elif((x > 0.03) & (x <= 0.09)):\n        severity = \"Normal\"\n    elif((x > 0.09) & (x <= 0.15)):\n        severity = \"Bad\"\n    elif((x > 0.15) & (x <= 0.5)):\n        severity = \"Very Bad\"\n    return severity\n\ndef severityPM10(x):\n    severity = \"\"\n    if(x <= 30):\n        severity = \"Good\"\n    elif((x > 30) & (x <= 80)):\n        severity = \"Normal\"\n    elif((x > 80) & (x <= 150)):\n        severity = \"Bad\"\n    elif((x > 150) & (x <= 600)):\n        severity = \"Very Bad\"\n    return severity\n    \ndef severityPM25(x):\n    severity = \"\"\n    if(x <= 15):\n        severity = \"Good\"\n    elif((x > 15) & (x <= 35)):\n        severity = \"Normal\"\n    elif((x > 35) & (x <= 75)):\n        severity = \"Bad\"\n    elif((x > 75) & (x <= 500)):\n        severity = \"Very Bad\"\n    return severity","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Breaking measurement date into date and time individual columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"date_time = measure_df['Measurement date'].str.split(\" \", n=1, expand=True)\nmeasure_df['date'] = date_time[0]\nmeasure_df['time'] = date_time[1]\nmeasure_df = measure_df.drop(['Measurement date'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It has been observed that, there are some null values as -1 which could have occured because of the mistake in reading and mistake in the apparatus."},{"metadata":{"trusted":true},"cell_type":"code","source":"measure_df[[\"SO2\",\"NO2\",\"O3\",\"CO\",\"PM10\",\"PM2.5\"]].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"-1 Values in all columns\")\nprint(\"Total Rows : \", measure_df.shape)\nprint(\"SO2   : \",measure_df[measure_df.SO2 == -1].shape[0])\nprint(\"NO2   : \",measure_df[measure_df.NO2 == -1].shape[0])\nprint(\"CO    : \",measure_df[measure_df.CO == -1].shape[0])\nprint(\"O3    : \",measure_df[measure_df.O3 == -1].shape[0])\nprint(\"PM10  : \",measure_df[measure_df.PM10 == -1].shape[0])\nprint(\"PM2.5 : \",measure_df[measure_df['PM2.5'] == -1].shape[0])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.impute import SimpleImputer\nimp = SimpleImputer(missing_values=-1, strategy='mean')\ndf_imputed = pd.DataFrame(imp.fit_transform(measure_df[[\"SO2\",\"NO2\",\"O3\",\"CO\",\"PM10\",\"PM2.5\"]]))\ndf_imputed.columns = measure_df[[\"SO2\",\"NO2\",\"O3\",\"CO\",\"PM10\",\"PM2.5\"]].columns\ndf_imputed.index = measure_df.index\nremain_df = measure_df[measure_df.columns.difference([\"SO2\",\"NO2\",\"O3\",\"CO\",\"PM10\",\"PM2.5\"])]\ndf = pd.concat([remain_df, df_imputed], axis=1)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['SO2 Severity'] = df.apply(lambda row: severitySO2(row['SO2']), axis=1)\ndf['NO2 Severity'] = df.apply(lambda row: severityNO2(row['NO2']), axis=1)\ndf['CO Severity'] = df.apply(lambda row: severityCO(row['CO']), axis=1)\ndf['O3 Severity'] = df.apply(lambda row: severityO3(row['O3']), axis=1)\ndf['PM10 Severity'] = df.apply(lambda row: severityPM10(row['PM10']), axis=1)\ndf['PM2.5 Severity'] = df.apply(lambda row: severityPM25(row['PM2.5']), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_mean_date = df.groupby(['date'], as_index=False).agg({'SO2':'mean', 'NO2':'mean', 'O3':'mean', 'CO':'mean', 'PM10':'mean', 'PM2.5':'mean'})\ndf_mean_date['date'] = pd.to_datetime(df_mean_date.date)\ndf_mean_date.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(50,10)) \nsns.lineplot(data=df_mean_date, x='date',y='SO2')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(50,10)) \nsns.lineplot(data=df_mean_date, x='date',y='NO2')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(50,10)) \nsns.lineplot(data=df_mean_date, x='date',y='CO')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(50,10)) \nsns.lineplot(data=df_mean_date, x='date',y='O3')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(50,10)) \nsns.lineplot(data=df_mean_date, x='date',y='PM10')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(50,10)) \nsns.lineplot(data=df_mean_date, x='date',y='PM2.5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (20,8))        \nsns.heatmap(df[[\"SO2\",\"NO2\",\"O3\",\"CO\",\"PM10\",\"PM2.5\"]].corr(),annot=True, cmap = 'coolwarm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"main_df = pd.read_csv('/kaggle/input/air-pollution-in-seoul/AirPollutionSeoul/Measurement_summary.csv')\nexecept_date_df = df[df.columns.difference([\"date\",\"time\"])]\nmain_df['Measurement date'] = pd.to_datetime(main_df['Measurement date'])\nmain_df = pd.concat([main_df['Measurement date'], execept_date_df], axis=1)\nmain_df['hour'] = main_df['Measurement date'].apply(lambda x: x.hour)\nmain_df['month'] = main_df['Measurement date'].apply(lambda x: x.month)\nmain_df['day'] = main_df['Measurement date'].apply(lambda x: x.day)\nmain_df['week'] = main_df['Measurement date'].apply(lambda x: x.week)\nmain_df['year'] = main_df['Measurement date'].apply(lambda x: x.year)\nmain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"main_df['month'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"main_df_2017 = main_df.loc[main_df['year'] == 2017]\nmain_df_2018 = main_df.loc[main_df['year'] == 2018]\nmain_df_2019 = main_df.loc[main_df['year'] == 2019]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from folium.plugins import HeatMap\ndef generateBaseMap(default_location=[37.572016, 127.005007], default_zoom_start=12):\n    base_map = folium.Map(location=default_location, control_scale=True, zoom_start=default_zoom_start)\n    return base_map\n# base_map = generateBaseMap()\n# HeatMap(data=main_df[['Latitude', 'Longitude', 'PM2.5']].groupby(['Latitude', 'Longitude']).sum().reset_index().values.tolist(), radius=8, max_zoom=13).add_to(base_map)\n# base_map","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_year_list = []\nfor year in main_df.year.sort_values().unique():\n    df_year_list.append(main_df.loc[main_df.year == year, ['Latitude', 'Longitude', 'PM2.5']].groupby(['Latitude', 'Longitude']).mean().reset_index().values.tolist())\nfrom folium.plugins import HeatMapWithTime\nbase_map = generateBaseMap(default_zoom_start=11)\nHeatMapWithTime(df_year_list, radius=70, gradient={0.05: 'blue', 0.5: 'green', 0.75: 'yellow', 1.0: 'red'}, min_opacity=0.5, max_opacity=0.8, use_local_extrema=True).add_to(base_map)\nbase_map","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_month_list_2017 = []\nfor month in main_df_2017.month.sort_values().unique():\n    df_month_list_2017.append(main_df_2017.loc[main_df_2017.month == month, ['Latitude', 'Longitude', 'PM2.5']].groupby(['Latitude', 'Longitude']).mean().reset_index().values.tolist())\nfrom folium.plugins import HeatMapWithTime\nbase_map = generateBaseMap(default_zoom_start=11)\nHeatMapWithTime(df_month_list_2017, radius=70, gradient={0.05: 'blue', 0.5: 'green', 0.75: 'yellow', 1.0: 'red'}, min_opacity=0.5, max_opacity=0.8, use_local_extrema=True).add_to(base_map)\nbase_map","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_week_list_2017 = []\nfor week in main_df_2017.week.sort_values().unique():\n    df_week_list_2017.append(main_df_2017.loc[main_df_2017.week == week, ['Latitude', 'Longitude', 'PM2.5']].groupby(['Latitude', 'Longitude']).mean().reset_index().values.tolist())\nfrom folium.plugins import HeatMapWithTime\nbase_map = generateBaseMap(default_zoom_start=11)\nHeatMapWithTime(df_week_list_2017, radius=50, gradient={0.05: 'blue', 0.5: 'green', 0.75: 'yellow', 1.0: 'red'}, min_opacity=0.5, max_opacity=0.8, use_local_extrema=True).add_to(base_map)\nbase_map","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}