{"cells":[{"metadata":{"id":"CnX_FOMcvU6w","outputId":"dcd6ee47-1bee-4039-b5f4-be03cae6cdea","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nimport os\nimport random","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First let's look at the columns_description, seems interesting..."},{"metadata":{"trusted":true},"cell_type":"code","source":"# desc_df = pd.read_csv('../input/credit-card/columns_description.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"BUT! If we run the commented out line it gives us an error. Turns out columns_description.csv is actually a weirdly formatted .xls file. You can download it from the main dataset page: https://www.kaggle.com/mishra5001/credit-card?select=columns_description.csv, and analyse it, but otherwise let's just leave it be.\n\nOn to the next file"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_app = pd.read_csv('../input/credit-card/application_data.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Great, it's actually a CSV file. And now we've used `pandas` to import it as a `DataFrame` instance (hence the \"df\" in the name). How big is it I wonder?"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print(df_app.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ok, about 300,000 rows, 122 columns. That's a lot of data. What does it look like?"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df_app.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The most important column here is `TARGET`. The description for this variable is:\n\n> Target variable (1 - client with payment difficulties: he/she had late payment more than X days on at least one of the first Y installments of the loan in our sample, 0 - all other cases)\n\nBasically, this is the variable that the dataset is centered around. If this were a modeling competition, it would be the one we had to try to predict. Looking at the description it seems ot boil down to \"did the perosn who made this application later miss a bunch of payments (a.k.a. credit card fraud, which also includes accidental fraud)?\"\n\nLet's see how many people committed fraud."},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print(\"number of people who committed fraud:\", df_app[\"TARGET\"].sum())\nprint(\"proportion of people who committed fraud:\", df_app[\"TARGET\"].sum() / len(df_app))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's look at the other columns. Are there any columns that look like they might be predictive of fraud?"},{"metadata":{"trusted":true},"cell_type":"code","source":"list(df_app.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`FLAG_OWNS_CAR` seems a likely candidate. I bet peole who own cars are less likely to miss payments. Let's see if this bears out in the data. First we'll create a new dataframe containing only those rows belonging to applicants who own cars."},{"metadata":{"trusted":true},"cell_type":"code","source":"car_owners = df_app[df_app[\"FLAG_OWN_CAR\"] == \"Y\"]\nprint(car_owners.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looks like there are about 100,000 car owners in the data, around 1/3rd of the dataset. Now let's see if fraud is more or less common among car owners."},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_fraud_prop(df):\n    print(\"number of rows in dataframe:\", len(df))\n    print(\"number of positive targets:\", df[\"TARGET\"].sum())\n    print(\"proportion of positive targets:\", df[\"TARGET\"].sum() / len(df))\n    \nshow_fraud_prop(car_owners)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hmm.. apparently car owners are slightly less likely to commit fraud, but only slightly. How about men vs women? First lets see what values are in this column:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_app[\"CODE_GENDER\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Apparently there are basically only two genders in this dataset, now which one commits more fraud? Probably the men right?"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"male fraud\")\nshow_fraud_prop(df_app[df_app[\"CODE_GENDER\"] == \"M\"])\nprint(\"female fraud\")\nshow_fraud_prop(df_app[df_app[\"CODE_GENDER\"] == \"F\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Knew it lol. Ok, how about income, let's use `pandas`'s `describe()` function to get a better idea about the distribution of the `AMT_INCOME_TOTAL` column:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_app[\"AMT_INCOME_TOTAL\"].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nice not having to calculate all those stats manually. Ok now let's compare fraud among high earners to fraud among low earners."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"high earner fraud\")\nshow_fraud_prop(df_app[df_app[\"AMT_INCOME_TOTAL\"] > 2.025000e+05])\n\nprint(\"low earner fraud\")\nshow_fraud_prop(df_app[df_app[\"AMT_INCOME_TOTAL\"] < 1.125000e+05])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There isn't too much difference here... Ok, enough messing around, let's start plotting! We'll start simple. Let's create a bar chart over the gender data we were looking at earlier, using the python plotting library `seaborn` (imported as `sns`)"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=\"CODE_GENDER\", data=df_app)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"That was easy eh? As we can see, it's plotted the number of rows in the dataset with male vs female applicants. Let's try another categorical column:"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=\"NAME_CONTRACT_TYPE\", data=df_app)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Apparently cash loans are much more popular. In general, looking a graphs is much easier on the eyes than squinting at printout, but the magic of plotting really gets started when you compare different variables on the same plot. \n\nBelow is one of my favorite hand-spun custom plotting functions. I'm going to use it to plot the average fraud rate accross gender."},{"metadata":{"trusted":true},"cell_type":"code","source":"def mean_count_plot(df, col, target, rc={'figure.figsize':(15,10)}):\n    sns.set(rc=rc)\n    ax = sns.countplot(x=col, data=df)\n    ax2 = ax.twinx()\n    ax.set_xticklabels(ax.get_xticklabels(),rotation=80)    \n    ax2 = sns.pointplot(x=col, y=target, data=df, color='black', legend=False, errwidth=0.5)\n    ax.grid(False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_count_plot(df_app, \"CODE_GENDER\", \"TARGET\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Not bad eh? Much easier to parse than the `prints` we were doing earlier.\n\nBut we're just getting started baby. Now let's try some scatter plots over some of the numerical columns using `matplotlib` imported as `plt`. "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(df_app[\"AMT_CREDIT\"], df_app[\"AMT_INCOME_TOTAL\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hmm... that wasn't super informative because the graph had to include that one person with a crazy high income. Let's remove that outlier and plot again. \n\nTo help us do this we're going to use the `matplotlib` `Axis` class. Basically an `Axis` is a single graph. Usually I use the `Axis` object rather than `plt` when I need to make a more complicated graph."},{"metadata":{"trusted":true},"cell_type":"code","source":"_, ax = plt.subplots()\nax.set_ylim((0, 2e7))\nax.scatter(df_app[\"AMT_CREDIT\"], df_app[\"AMT_INCOME_TOTAL\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hmm... still not super informative because all the blue dots are overlapping. To get a bit more insight we'll lower the ceiling again and make the dots a little transparent."},{"metadata":{"trusted":true},"cell_type":"code","source":"_, ax = plt.subplots()\nax.set_ylim((0, 1e6))\nax.scatter(df_app[\"AMT_CREDIT\"], df_app[\"AMT_INCOME_TOTAL\"],  alpha=0.01)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There we go. By being a bit more careful with our plotting we've revealed that there's a very strong correlation between the amount of credit applied for and the total income of the applicant, which wasn't at all obvious beforehand. \n\nTo end I'd like to show you a custom scatter plotting function and use it to compare "},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_plot(data, x, y, compcol, aalpha=0.1, balpha=0.1, xlim=None, ylim=None):\n    alphamap = {False: aalpha, True: balpha}\n    colormap = {False: \"tab:blue\", True: \"red\"}\n    \n    for val in [False, True]:          \n        plt.scatter(x, y, data=data[data[compcol] == val], alpha=alphamap[val], s=20, c=colormap[val])\n    \n    plt.xlabel(x)\n    plt.ylabel(y)\n    \n    if xlim is not None:\n        plt.xlim(xlim)\n        \n    if ylim is not None:\n        plt.ylim(ylim)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"split_plot(df_app,  \"AMT_CREDIT\", \"LIVINGAPARTMENTS_MODE\", \"TARGET\", aalpha=0.01, balpha=0.07, ylim=(0, 0.4))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we plot the amount of credit applied for against the mode of the number of living apartments in the building where the applicant lives (see the data explanation (https://www.kaggle.com/mishra5001/credit-card?select=columns_description.csv). Blue dots represent non-fraudlent instances, and red dots represent fraud. \n\nThis allows us to see that fraud seems to occur slightly more often when the number of living apartments is a little higher, though in general fraud seems to be evenly distributed through the data along these axes. \n\nThat's all, now get plotting!"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_prev = pd.read_csv(\"../input/credit-card/previous_application.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list(df_prev.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_prev.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df_app.join(df_prev, on=\"SK_ID_CURR\", rsuffix=\"_PREV\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"split_plot(df.sample(100000),  \"AMT_CREDIT\", \"AMT_CREDIT_PREV\", \"TARGET\", aalpha=0.01, balpha=0.07, ylim=(0, 4e5), xlim=(0, 4e6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}