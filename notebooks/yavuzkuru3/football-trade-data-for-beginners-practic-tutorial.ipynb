{"cells":[{"metadata":{},"cell_type":"markdown","source":"**DATA SCIENTIST**\n\nIn this tutorial, I only explain you what you need to be a data scientist neither more nor less.\n\nData scientist need to have these skills:\n\n1. Basic Tools: Like python, R or SQL. You do not need to know everything. What you only need is to learn how to use python\n2. Basic Statistics: Like mean, median or standart deviation. If you know basic statistics, you can use python easily.\n3. Data Munging: Working with messy and difficult data. Like a inconsistent date and string formatting. As you guess, python helps us.\n4. Data Visualization: Title is actually explanatory. We will visualize the data with python like matplot and seaborn libraries.\n5. Machine Learning: You do not need to understand math behind the machine learning technique. You only need is understanding basics of machine learning and learning how to implement it while using python.\n"},{"metadata":{},"cell_type":"markdown","source":"As a summary we will learn python to be data scientist !!!"},{"metadata":{},"cell_type":"markdown","source":"In this kernel, I only use thing what base command for data science. I reference in https://www.kaggle.com/kanncaa1/data-sciencetutorial-for-beginners#DATA-SCIENTIST. Therefor,I tried to try the codes except for the codes used in this tutorial."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns  # visualization tool\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dataRead():\n    #Read data\n    df = pd.read_csv(\"/kaggle/input/top-250-football-transfers-from-2000-to-2018/top250-00-19.csv\")\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df= dataRead()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**1- Introduction Python**"},{"metadata":{},"cell_type":"markdown","source":"MATPLOTLIB"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('ggplot')\nplt.rcParams['figure.figsize'] = (9, 9)\n# Histogram\ndf.hist()\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='Position',data=df)\nplt.xticks(rotation=90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pointplot(x='index',y='Season',data=pd.DataFrame(df.Season.value_counts()).reset_index().sort_values('index'))\nplt.xticks(rotation=90)\nplt.xlabel('Season')\nplt.ylabel('Number of Trade')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**DICTIONARY**"},{"metadata":{"trusted":true},"cell_type":"code","source":"dictionary = {'spain' : 'madrid','usa' : 'vegas'}\nprint(dictionary.keys())\nprint(dictionary.values())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dictionary['spain'] = \"barcelona\"    # update existing entry\nprint(dictionary)\ndictionary['france'] = \"paris\"       # Add new entry\nprint(dictionary)\ndel dictionary['spain']              # remove entry with key 'spain'\nprint(dictionary)\nprint('france' in dictionary)        # check include or not\ndictionary.clear()                   # remove all entries in dict\nprint(dictionary)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(dictionary)       # it gives error because dictionary is deleted","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**PANDAS**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"series = df['Age']        # data['Defense'] = series\nprint(type(series))\ndata_frame = df[['Age']]  # data[['Defense']] = data frame\nprint(type(data_frame))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1 - Filtering Pandas data frame\nx = df['Age']>30     # There are only 3 pokemons who have higher defense value than 200\ndf[x]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This is also same with previous code line. Therefore we can also use '&' for filtering.\ndf[(df['Age']>25) & (df['Transfer_fee']>60000000)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**2. PYTHON DATA SCIENCE TOOLBOX**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets classify pleyers whether they have high or low . Our threshold is average speed.\n#df.info()\ndf.Transfer_fee.head()\n# Basic statistics about the data and its variables\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets return pokemon csv and make one more list comprehension example\n# lets classify pokemons whether they have high or low speed. Our threshold is average speed.\nthreshold = sum(df.Transfer_fee)/len(df.Transfer_fee)\ndf[\"Transfer_fee\"] = [\"high\" if i > threshold else \"low\" for i in df.Transfer_fee]\ndf.loc[:10,[\"Transfer_fee Level\",\"Transfer_fee\"]] # we will learn loc more detailed later","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(df)\ndf = dataRead()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**3.CLEANING DATA**"},{"metadata":{},"cell_type":"markdown","source":"DIAGNOSE DATA for CLEANING"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()  # head shows first 5 rows","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tail shows last 5 rows\ndf.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**EXPLORATORY DATA ANALYSIS**\n\n\nvalue_counts(): Frequency counts\noutliers: the value that is considerably higher or lower from rest of the data\n\nLets say value at 75% is Q3 and value at 25% is Q1.\nOutlier are smaller than Q1 - 1.5(Q3-Q1) and bigger than Q3 + 1.5(Q3-Q1). (Q3-Q1) = IQR\nWe will use describe() method. Describe method includes:\ncount: number of entries\nmean: average of entries\nstd: standart deviation\nmin: minimum entry\n25%: first quantile\n50%: median or second quantile\n75%: third quantile\nmax: maximum entry"},{"metadata":{"trusted":true},"cell_type":"code","source":"# For example lets look frequency of pokemom types\nprint(df['Position'].value_counts(dropna =False))  # if there are nan values that also be counted\n# As it can be seen below there are 112 water pokemon or 70 grass pokemon","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For example max HP is 255 or min defense is 5\ndf.describe() #ignore null entries","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### VISUAL EXPLORATORY DATA ANALYSIS\nBox plots: visualize basic statistics like outliers, min/max or quantiles\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For example: compare fee value of players that are legendary  or not\n# amaç hangi sezonda transfer edilen oyuncuların \ndf.boxplot(column='Age',by = 'Season')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**TIDY DATA**"},{"metadata":{},"cell_type":"markdown","source":"We tidy data with melt(). Describing melt is confusing. Therefore lets make example to understand it."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Firstly I create new data from transfer data to explain melt nore easily.\n\ndata_new = df.head()    # I only take 5 rows into new data\ndata_new","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets melt\n# id_vars = what we do not wish to melt\n# value_vars = what we want to melt\nmelted = pd.melt(frame=data_new,id_vars = 'Name', value_vars= ['Transfer_fee','Market_value'])\nmelted","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**PIVOTING DATA**"},{"metadata":{},"cell_type":"markdown","source":"Reverse of melting."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Index is name\n# I want to make that columns are variable\n# Finally values in columns are value\nmelted.pivot(index = 'Name', columns = 'variable',values='value')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**CONCATENATING DATA**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Firstly lets create 2 data frame\ndata1 = df.head()\ndata2= df.tail()\nconc_data_row = pd.concat([data1,data2],axis =0,ignore_index =True) # axis = 0 : adds dataframes in row\nconc_data_row","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1 = df['Transfer_fee'].head()\ndata2= df['Market_value'].head()\nconc_data_col = pd.concat([data1,data2],axis =1) # axis = 0 : adds dataframes in row\nconc_data_col","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**DATA TYPES**\n\nThere are 5 basic data types: object(string),booleab, integer, float and categorical.\nWe can make conversion data types like from str to categorical or from int to float\nWhy is category important:\n\nmake dataframe smaller in memory\ncan be utilized for anlaysis especially for sklear(we will learn later)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**MISSING DATA and TESTING WITH ASSERT**\nIf we encounter with missing data, what we can do:\n\nleave as is\ndrop them with dropna()\nfill missing value with fillna()\nfill missing values with test statistics like mean\nAssert statement: check that you can turn on or turn off when you are done with your testing of the program"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Market value değerlerini kontrol ediyoruz\ndf[\"Market_value\"].value_counts(dropna =False)\n# .Göründüğü gibi 1260 tane NaN var ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Market_value\"].dropna(inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert 1==1 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert  df['Market_value'].notnull().all()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}