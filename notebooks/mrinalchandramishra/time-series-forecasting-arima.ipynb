{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1 align=\"center\"><font color='#1f4d40'>Time Series Modelling‚è∞</font></h1>"},{"metadata":{},"cell_type":"markdown","source":"### <font color='#001a33'>Helloüôå everyone, Before moving ahead let me clear Some Steps we Gonna Follow. If You Follow step by step It will be very easy To understand.</font>\n* <font color='#001a33'>Introduction To Problem üßß</font>\n* <font color='#001a33'>DATA Collection And Infoüõ† </font>\n* <font color='#001a33'>Data  Preprocessing‚Ñπ</font>\n* <font color='#001a33'>Data Analysisüìä</font>\n* <font color='#001a33'>Model building üèó</font>"},{"metadata":{},"cell_type":"markdown","source":"## <font color='#1f4d40'>Introduction To Problemüßß</font>\n<font color='#001a33'>Wind powerüçÉ or wind energy is the use of wind to provide mechanicalüõ† power through wind turbines to turn electric generators for electrical power. Wind power is a popular sustainable, renewable source of power that has a much smaller impact on the environment compared to burning fossil fuels.</font>\n<br>\n<font color='#001a33'>In this Notebook we will look into the wind energy generation Data of 4 company From Date-23/09/2019 to 18/09/2020.</font>\n<br>\n#### <font color='#1f4d40'>WHAT WE HAVE TO DO?‚ùì</font>\n* <font color='#001a33'> Finding insights from data.üìà</font>\n* <font color='#001a33'> Total Wind energy generation.</font>\n* <font color='#001a33'> Building Model to Predict future Generation</font>\n\n<br>\n\n#### <font color='#1f4d40'>WHAT ARE WE WAITING FOR. LETS GET STARTED.ü¶æ</font>\n\n\n\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # for data visualization\nimport seaborn as sns # advance data visualization\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color='#1f4d40'>Data Collectionüî¨</font>\n<font color='#001a33'>AS we can see from the above table that our data has 4 CSV files One for each companyüè≠</font>\n* <font color='#001a33'>/kaggle/input/wind-power-generation/TenneTTSO.csv</font>\n* <font color='#001a33'>/kaggle/input/wind-power-generation/50Hertz.csv</font>\n* <font color='#001a33'>/kaggle/input/wind-power-generation/TransnetBW.csv</font>\n* <font color='#001a33'>/kaggle/input/wind-power-generation/Amprion.csv</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# we will create 4 seperate data-frame for each company and load our csv file in that.\ndf1=pd.read_csv('/kaggle/input/wind-power-generation/TenneTTSO.csv')\ndf2=pd.read_csv('/kaggle/input/wind-power-generation/50Hertz.csv')\ndf3=pd.read_csv('/kaggle/input/wind-power-generation/TransnetBW.csv')\ndf4=pd.read_csv('/kaggle/input/wind-power-generation/Amprion.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now we will see the shape of our data\nprint(\"columns in dataframe1=\",df1.shape[1],\" And rows are=\",df1.shape[0])\nprint(\"columns in dataframe2=\",df2.shape[1],\" And rows are=\",df2.shape[0])\nprint(\"columns in dataframe3=\",df3.shape[1],\" And rows are=\",df3.shape[0])\nprint(\"columns in dataframe4=\",df4.shape[1],\" And rows are=\",df4.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets print some of the rows to check data\ndf1.head(2)\n# we will not print the head part of all the 3 left data frame as it will same as first only values are different.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets check for the Total No of Numerical and categorical variable\nprint(\"Total No of Cat Features=\",sum(df1.dtypes=='object'))\nprint(\"Total No of Numr Features=\",sum(df1.dtypes=='float'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets check if our data contains any null values or not if any than we will do further analysis\ncount=0\nfor i in df1.isnull().sum():\n    if i==1 :\n        count=1\nif(count==0):\n    print(\"No NUll Value in Df1\")\n    \ncount=0\nfor i in df2.isnull().sum():\n    if i==1 :\n        count=1\nif(count==0):\n    print(\"No NUll Value in Df2\")\ncount=0   \nfor i in df3.isnull().sum():\n    if i==1 :\n        count=1\nif(count==0):\n    print(\"No NUll Value in Df3\")\ncount=0   \nfor i in df4.isnull().sum():\n    if i==1 :\n        count=1\nif(count==0):\n    print(\"No NUll Value in Df4\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### <font color='#1f4d40'>SO WE ARE DONE WITH INFO ABOUT DATA AND DATA COLLECTION PROCESS‚Ñπ. BEFORE MOVING AHEAD LETS CONCLUDE SOME POINTS.üëÜ</font>\n* <font color='#001a33'>We have created 4 Data frame.</font>\n* <font color='#001a33'>There are 397 rows and 97 columns in each data.</font>\n* <font color='#001a33'>There is one Category Feature i.e-Date AND Rest all 96 features Are Date.</font>\n* <font color='#001a33'>If we look At features we found that Except date columns there are reading realeted to every 15 minutes starting from 00:00:00 to 23:45:00</font>\n* <font color='#001a33'>DataSet Has No Null Values.</font>\n"},{"metadata":{},"cell_type":"markdown","source":"## <font color='#1f4d40'>DATA PREPROCESSING AND CLEANINGüìΩ</font>\n### <font color='#001a33'>How we will Preprocess our DAta?‚ùì</font>\n\n* <font color='#001a33'>We will extract only some useful info from the data. i.e. we will find total energy in a day.</font>\n* <font color='#001a33'>Mean Energy in a day.</font>\n* <font color='#001a33'>Total  energy in Each 6 hours.</font>\n* <font color='#001a33'>Mean  energy in Each 6 hours.</font>\n* <font color='#001a33'>Max  energy generation in 15 min.</font>\n* <font color='#001a33'>Min  energy generation in 15 min.</font>\n\n#### <font color='#ff4d4d'>Data Preprocessing is one of the time consuming task. SO Look each step carefully.‚ö†</font>\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# here these are the features we will extract from single dataframe\n#FOR DATA-FRAME 1\ndf1['total energy generated/day']=df1.sum(axis=1,numeric_only=True)\ndf1['mean energy generated/15 min']=df1.mean(axis=1,numeric_only=True)\ndf1['min energy during 15 min']=df1.min(axis=1,numeric_only=True)\ndf1['max energy during 15 minute']=df1.max(axis=1,numeric_only=True)\ndf1['0 to 6 energy generated Total']=df1.loc[:,'00:00:00':'05:45:00'].sum(axis=1,numeric_only=True)\ndf1['0 to 6 mean energy generated']=df1.loc[:,'00:00:00':'05:45:00'].mean(axis=1,numeric_only=True)\ndf1['6 to 12 energy generated Total']=df1.loc[:,'06:00:00':'11:45:00'].sum(axis=1,numeric_only=True)\ndf1['6 to 12 mean energy generated']=df1.loc[:,'06:00:00':'11:45:00'].mean(axis=1,numeric_only=True)\ndf1['12 to 18 energy generated Total']=df1.loc[:,'12:00:00':'17:45:00'].sum(axis=1,numeric_only=True)\ndf1['12 to 18 mean energy generated']=df1.loc[:,'12:00:00':'17:45:00'].mean(axis=1,numeric_only=True)\ndf1['18 to 24 energy generated Total']=df1.loc[:,'18:00:00':'23:45:00'].sum(axis=1,numeric_only=True)\ndf1['18 to 24 mean energy generated']=df1.loc[:,'18:00:00':'23:45:00'].mean(axis=1,numeric_only=True)\n\n#FOR DATA-FRAME 2\ndf2['total energy generated/day']=df2.sum(axis=1,numeric_only=True)\ndf2['mean energy generated/15 min']=df2.mean(axis=1,numeric_only=True)\ndf2['min energy during 15 min']=df2.min(axis=1,numeric_only=True)\ndf2['max energy during 15 minute']=df2.max(axis=1,numeric_only=True)\ndf2['0 to 6 energy generated Total']=df2.loc[:,'00:00:00':'05:45:00'].sum(axis=1,numeric_only=True)\ndf2['0 to 6 mean energy generated']=df2.loc[:,'00:00:00':'05:45:00'].mean(axis=1,numeric_only=True)\ndf2['6 to 12 energy generated Total']=df2.loc[:,'06:00:00':'11:45:00'].sum(axis=1,numeric_only=True)\ndf2['6 to 12 mean energy generated']=df2.loc[:,'06:00:00':'11:45:00'].mean(axis=1,numeric_only=True)\ndf2['12 to 18 energy generated Total']=df2.loc[:,'12:00:00':'17:45:00'].sum(axis=1,numeric_only=True)\ndf2['12 to 18 mean energy generated']=df2.loc[:,'12:00:00':'17:45:00'].mean(axis=1,numeric_only=True)\ndf2['18 to 24 energy generated Total']=df2.loc[:,'18:00:00':'23:45:00'].sum(axis=1,numeric_only=True)\ndf2['18 to 24 mean energy generated']=df2.loc[:,'18:00:00':'23:45:00'].mean(axis=1,numeric_only=True)\n\n#FOR DATA-FRAME 3\ndf3['total energy generated/day']=df3.sum(axis=1,numeric_only=True)\ndf3['mean energy generated/15 min']=df3.mean(axis=1,numeric_only=True)\ndf3['min energy during 15 min']=df3.min(axis=1,numeric_only=True)\ndf3['max energy during 15 minute']=df3.max(axis=1,numeric_only=True)\ndf3['0 to 6 energy generated Total']=df3.loc[:,'00:00:00':'05:45:00'].sum(axis=1,numeric_only=True)\ndf3['0 to 6 mean energy generated']=df3.loc[:,'00:00:00':'05:45:00'].mean(axis=1,numeric_only=True)\ndf3['6 to 12 energy generated Total']=df3.loc[:,'06:00:00':'11:45:00'].sum(axis=1,numeric_only=True)\ndf3['6 to 12 mean energy generated']=df3.loc[:,'06:00:00':'11:45:00'].mean(axis=1,numeric_only=True)\ndf3['12 to 18 energy generated Total']=df3.loc[:,'12:00:00':'17:45:00'].sum(axis=1,numeric_only=True)\ndf3['12 to 18 mean energy generated']=df3.loc[:,'12:00:00':'17:45:00'].mean(axis=1,numeric_only=True)\ndf3['18 to 24 energy generated Total']=df3.loc[:,'18:00:00':'23:45:00'].sum(axis=1,numeric_only=True)\ndf3['18 to 24 mean energy generated']=df3.loc[:,'18:00:00':'23:45:00'].mean(axis=1,numeric_only=True)\n\n#FOR DATA-FRAME 4\ndf4['total energy generated/day']=df4.sum(axis=1,numeric_only=True)\ndf4['mean energy generated/15 min']=df4.mean(axis=1,numeric_only=True)\ndf4['min energy during 15 min']=df4.min(axis=1,numeric_only=True)\ndf4['max energy during 15 minute']=df4.max(axis=1,numeric_only=True)\ndf4['0 to 6 energy generated Total']=df4.loc[:,'00:00:00':'05:45:00'].sum(axis=1,numeric_only=True)\ndf4['0 to 6 mean energy generated']=df4.loc[:,'00:00:00':'05:45:00'].mean(axis=1,numeric_only=True)\ndf4['6 to 12 energy generated Total']=df4.loc[:,'06:00:00':'11:45:00'].sum(axis=1,numeric_only=True)\ndf4['6 to 12 mean energy generated']=df4.loc[:,'06:00:00':'11:45:00'].mean(axis=1,numeric_only=True)\ndf4['12 to 18 energy generated Total']=df4.loc[:,'12:00:00':'17:45:00'].sum(axis=1,numeric_only=True)\ndf4['12 to 18 mean energy generated']=df4.loc[:,'12:00:00':'17:45:00'].mean(axis=1,numeric_only=True)\ndf4['18 to 24 energy generated Total']=df4.loc[:,'18:00:00':'23:45:00'].sum(axis=1,numeric_only=True)\ndf4['18 to 24 mean energy generated']=df4.loc[:,'18:00:00':'23:45:00'].mean(axis=1,numeric_only=True)\n\n# so we have extracted all these feature as i have mentioned earlier. now we will drop the 96 columns which are now not useful.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets look now howour dataframe looks\nprint(df1.shape)\ndf1.head(3)\n\n# take a look on how we have added different columns so now we will drop the earlier columns except date.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# as from the above code we have extracted useful info from the data now what we will do is drop all the columns from 00:00:00 to 23:45:00\ndf1.drop(df1.loc[:,'00:00:00':'23:45:00'],axis=1,inplace=True)\ndf2.drop(df2.loc[:,'00:00:00':'23:45:00'],axis=1,inplace=True)\ndf3.drop(df3.loc[:,'00:00:00':'23:45:00'],axis=1,inplace=True)\ndf4.drop(df4.loc[:,'00:00:00':'23:45:00'],axis=1,inplace=True)\n\ndf1.head() #lets look at our table NOW.\n# we are going in a good direction as now we are done with data preprocessing and created a table \n#which will have useful info and reduced original table","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#one more thing left to do i.e converting our date to datetime object\ndf1['Date']=pd.to_datetime(df1['Date'])\ndf2['Date']=pd.to_datetime(df2['Date'])\ndf3['Date']=pd.to_datetime(df3['Date'])\ndf4['Date']=pd.to_datetime(df4['Date'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color='#1f4d40'>Exploratory Data Analysisüìä</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\n\n# first lets describe about data\ny=[df1['total energy generated/day'].sum(),df2['total energy generated/day'].sum(),df3['total energy generated/day'].sum(),df4['total energy generated/day'].sum()]\nfig,ax=plt.subplots(1,2,figsize=(15,4))\n#fig-1\nsns.barplot(y=y,x=[\"TenneTTSO\",\"50Hertz\",\"TransnetBW\",\"Amprion\"],palette=\"Blues\",ax=ax[0])\nax[0].set_ylabel(\"energy in 10^6\")\nax[0].set_title(\"Total Energy generation in 397 Days\")\n#fig-2\ny=[df1['mean energy generated/15 min'].mean(),df2['mean energy generated/15 min'].mean(),df3['mean energy generated/15 min'].mean(),df4['mean energy generated/15 min'].mean()]\nsns.barplot(y=y,x=[\"TenneTTSO\",\"50Hertz\",\"TransnetBW\",\"Amprion\"],palette=\"Reds\",ax=ax[1])\nax[1].set_ylabel(\"energy unit\")\nax[1].set_title(\"Mean Energy generation in each 15 min\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(rc={'axes.facecolor':'#000000', 'figure.facecolor':'white'})\nfig,ax=plt.subplots(4,1,figsize=(20,12))\n#fig-1\nsns.lineplot(x=df1['Date'],y=df1['total energy generated/day'],color='#33ffad',ax=ax[0])\nplt.grid(False)\nax[0].set_xticks([])\nax[0].set_xlabel(\"TenneTTSO\")\nax[0].set_ylabel(\"\")\n#fig-2\nsns.lineplot(x=df2['Date'],y=df2['total energy generated/day'],color='#80ccff',ax=ax[1])\nplt.grid(False)\nax[1].set_xticks([])\nax[1].set_ylabel(\"TOTAL ENERGY Generated\")\nax[1].set_xlabel(\"50Hertz\")\n#fig-1\nsns.lineplot(x=df3['Date'],y=df3['total energy generated/day'],color='#ff944d',ax=ax[2])\nplt.grid(False)\nax[2].set_xticks([])\nax[2].set_xlabel(\"TransnetBW\")\nax[2].set_ylabel(\"\")\n#fig-1\nsns.lineplot(x=df4['Date'],y=df4['total energy generated/day'],color='#ccff66',ax=ax[3])\nplt.grid(False)\nax[3].set_ylabel(\"\")\nax[3].set_xlabel(\"Amprion\")\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <font color='#001a33'>Lets Conclude Some Points Now.üè¥‚Äç‚ò†Ô∏è</font>\n\n* <font color='#001a33'>We have plotted our date and the total energy genaration in that particular day</font>\n* <font color='#001a33'>AS we can see that is is time series data so Fitting linear regression is noyt good for its Future prediction</font>\n"},{"metadata":{},"cell_type":"markdown","source":"# <font color='#1f4d40'>MODEL BUILDING - ARIMAüèó</font>\n<font color='#001a33'>ARIMA is an acronym that stands for AutoRegressive Integrated Moving Average. It is a class of model that captures a suite of different standard temporal structures in time series data.</font>\n* <font color='#001a33'>About the ARIMA model the parameters used and assumptions made by the model.</font>\n* <font color='#001a33'>How to fit an ARIMA model to data and use it to make forecasts</font>\n* <font color='#001a33'>How to configure the ARIMA model on your time series problem.</font>\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#before moving ahead lets cut our dataset only to Total Energy generation\ndf1=df1[['Date','total energy generated/day']]\ndf2=df2[['Date','total energy generated/day']]\ndf3=df3[['Date','total energy generated/day']]\ndf4=df4[['Date','total energy generated/day']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets see if our data is stationery or not.\nfrom statsmodels.tsa.stattools import adfuller\ntest_result=adfuller(df1['total energy generated/day'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <font color='#001a33'>Why we need to check It if data is stationary or not?</font>\n* <font color='#001a33'>Stationary data means its mean,variance and auto correlation does not change over time</font>\n* <font color='#001a33'>If data is not stationary we have to bring it by doing differencing.</font>\n\n\n### <font color='#001a33'>How can we test if data is stationary or not?</font>\n* <font color='#001a33'>we can test it by adfuller test.</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Ho: It is non stationary\n#H1: It is stationary\n\ndef adfuller_test(sales):\n    result=adfuller(sales)\n    labels = ['ADF Test Statistic','p-value','#Lags Used','Number of Observations Used']\n    for value,label in zip(result,labels):\n        print(label+' : '+str(value) )\n    if result[1] <= 0.05:\n        print(\"strong evidence against the null hypothesis(Ho), reject the null hypothesis. Data has no unit root and is stationary\")\n    else:\n        print(\"weak evidence against null hypothesis, time series has a unit root, indicating it is non-stationary \")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"for df1\")\nadfuller_test(df1['total energy generated/day'])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color='#001a33'>Lets Conclude Some points</font>\n* <font color='#001a33'>As we found out that our data is stationery..lets move to further step</font>\n* <font color='#001a33'>If the data is non Stationery then we have to find differencing.</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets plot the autocorrelation graph\nfrom pandas.plotting import autocorrelation_plot\nautocorrelation_plot(df1['total energy generated/day'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Final Thoughts on Autocorrelation and Partial Autocorrelation\n* Identification of an AR model is often best done with the PACF.\n* For an AR model, the theoretical PACF ‚Äúshuts off‚Äù past the order of the model. The phrase ‚Äúshuts off‚Äù means that in theory the partial autocorrelations are equal to 0 beyond that point. Put another way, the number of non-zero partial autocorrelations gives the order of the AR model. By the ‚Äúorder of the model‚Äù we mean the most extreme lag of x that is used as a predictor.\n* Identification of an MA model is often best done with the ACF rather than the PACF.\n\n* For an MA model, the theoretical PACF does not shut off, but instead tapers toward 0 in some manner. A clearer pattern for an MA model is in the ACF. The ACF will have non-zero autocorrelations only at lags involved in the model.\n\n* p,d,q p AR model lags d differencing q MA lags"},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets plot the graph to find the suitable value of P and Q\nimport statsmodels.api as sm\nfrom statsmodels.graphics.tsaplots import plot_acf,plot_pacf\nfig = plt.figure(figsize=(12,8))\nax1 = fig.add_subplot(211)\nfig = sm.graphics.tsa.plot_acf(df1['total energy generated/day'],lags=40,ax=ax1)\nax2 = fig.add_subplot(212)\nfig = sm.graphics.tsa.plot_pacf(df1['total energy generated/day'],lags=40,ax=ax2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* What is tell Us\n* it gives us a p value which is exponential decrease till at what point=4,so p=4\n* we will select q value as 1 as there is suddent decrese in 1"},{"metadata":{},"cell_type":"markdown","source":"### <font color='#001a33'>Fitting simple Arima Model</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# p=4,d=0(as difference =0),q=1\nfrom statsmodels.tsa.arima_model import ARIMA\n#lets fit our model\nmodel=ARIMA(df1['total energy generated/day'],order=(4,0,1))\nmodel_fit=model.fit()\nmodel_fit.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets see how our model is fitted on training data\ndf1['forecast']=model_fit.predict(start=100,end=397,dynamic=True)\ndf1[['total energy generated/day','forecast']].plot(figsize=(12,8))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <font color='#001a33'>AS You can see that our Simple Arima Does not work well It just draw the straight lineüñá. i.e orange line....we will fit it with Seasonal Arimaüå•</font>\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets give seasonal difference of one month\nmodel=sm.tsa.statespace.SARIMAX(df1['total energy generated/day'],order=(2, 0, 1),seasonal_order=(2,0,1,30))\nresults=model.fit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1['forecast']=results.predict(start=178,end=250,dynamic=True)\ndf1[['total energy generated/day','forecast']].plot(figsize=(12,8))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font color='#001a33'>SO We are done with it. I know this is not the best Model and i have not tuned this model. THis notebook is just to give you idea on how to deal with time series data.</font>\n\n### <font color='#001a33'> IF You Like This NOtebook Please give it a upvote‚¨Üüëç...and for comment any feedback or suggestion on how i can improve.</font>"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}