{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\nfrom sklearn.utils import class_weight\nfrom sklearn.preprocessing import StandardScaler\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Input, Dropout, BatchNormalization\nfrom tensorflow.keras.models import model_from_json, load_model\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nprint(tf.__version__)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    if filenames:\n        csv_path = os.path.join(dirname, filenames[0])\nprint(csv_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras import backend as K\n\ndef recall(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives / (possible_positives + K.epsilon())\n    return recall\n\ndef precision(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    return precision\n\ndef f1_score(y_true, y_pred):\n    prec = precision(y_true, y_pred)\n    rec = recall(y_true, y_pred)\n    return 2*((prec*rec)/(prec+rec+K.epsilon()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(csv_path)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cols = df.columns.values\nY = df[df_cols[-1]].values\nX = df[df_cols[:-1]].values\n\nY = Y - 1\nY = Y.astype(int)\n\nX, Y = shuffle(X, Y)\nNtrain = int(len(Y) * 0.7)\n\nXtrain, Xtest = X[:Ntrain], X[Ntrain:]\nYtrain, Ytest = Y[:Ntrain], Y[Ntrain:]\nprint(Ytrain.shape)\nprint(Xtrain.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Handling Classes"},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\nclasses = list(set(Ytrain))\nclass_data = dict(Counter(Ytrain))\nclass_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Set class weights :\n\nw(j) = n / (k * n(j))"},{"metadata":{"trusted":true},"cell_type":"code","source":"class_weights = class_weight.compute_class_weight('balanced',\n                                                 np.unique(Ytrain),\n                                                 Ytrain)\nclass_weights = {i : class_weights[i] for i in range(len(set(Ytrain)))}\nclass_weights","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Xscalar = StandardScaler()\nXscalar.fit(Xtrain)\n\nXtrain = Xscalar.transform(Xtrain)\nXtest = Xscalar.transform(Xtest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epoches = 80\nbatch_size = 32\nval_split = 0.1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model 1: Training The DNN Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def classifier1():\n    n_features = Xtrain.shape[1]\n    inputs = Input(shape=(n_features,))\n    x = Dense(512, activation='relu')(inputs)\n    x = Dense(256, activation='relu')(x)\n    x = Dense(256, activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dense(64, activation='relu')(x)\n    x = Dense(64, activation='relu')(x)\n    x = Dense(64, activation='relu')(x)\n    x = Dropout(0.3)(x)\n    outputs = Dense(3, activation='softmax')(x)\n    model = Model(inputs, outputs)\n    \n    model.compile(\n        loss='sparse_categorical_crossentropy',\n        optimizer='adam',\n        metrics=['acc',f1_score,precision, recall] \n    )\n    history = model.fit(\n                    Xtrain,\n                    Ytrain,\n                    batch_size=batch_size,\n                    epochs=num_epoches,\n                    validation_split=val_split,\n                    class_weight=class_weights\n                    )\n    return history, model\n    \ndef plot_metrics(history):\n    loss_train = history.history['loss']\n    loss_val = history.history['val_loss']\n    \n    loss_train = np.cumsum(loss_train) / np.arange(1,num_epoches+1)\n    loss_val = np.cumsum(loss_val) / np.arange(1,num_epoches+1)\n    plt.plot(loss_train, 'r', label='Training loss')\n    plt.plot(loss_val, 'b', label='validation loss')\n    plt.title('Training and Validation loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.show()\n    \n    acc_train = history.history['acc']\n    acc_val = history.history['val_acc']\n    \n    plt.plot(acc_train, 'r', label='Training loss')\n    plt.plot(acc_val, 'b', label='validation loss')\n    plt.title('Training and Validation Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.show()\n    \n    precision_train = history.history['precision']\n    precision_val = history.history['val_precision']\n    \n    plt.plot(precision_train, 'r', label='Training loss')\n    plt.plot(precision_val, 'b', label='validation loss')\n    plt.title('Training and Validation Precision')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.show()\n    \n    recall_train = history.history['recall']\n    recall_val = history.history['val_recall']\n    \n    plt.plot(recall_train, 'r', label='Training loss')\n    plt.plot(recall_val, 'b', label='validation loss')\n    plt.title('Training and Validation Recall')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.show()\n    \n    f1_score_train = history.history['f1_score']\n    f1_score_val = history.history['val_f1_score']\n    \n    plt.plot(f1_score_train, 'r', label='Training loss')\n    plt.plot(f1_score_val, 'b', label='validation loss')\n    plt.title('Training and Validation F1 Score')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history1, model1 = classifier1()\nplot_metrics(history1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"P = model1.predict(Xtest)\nYpred = P.argmax(axis=1)\nmodel1.evaluate(Xtest, Ytest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}