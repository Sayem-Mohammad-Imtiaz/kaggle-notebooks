{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Students campus placement Prediction Model","metadata":{"id":"Bp31FSRtXKDO"}},{"cell_type":"markdown","source":"### DATASET INFORMATION: \n\nThis data set consists of Placement data of students in our campus. It includes secondary and higher secondary school percentage and specialization. It also includes degree specialization, type and Work experience and salary offers to the placed students\n\n","metadata":{}},{"cell_type":"markdown","source":"* sl_no\t  == Serial Number\n* gender\t  == Gender- Male='M',Female='F'\n* ssc_p\t  == Secondary Education percentage- 10th Grade\n* ssc_b\t  == Board of Education- Central/ Others\n* hsc_p\t  == Higher Secondary Education percentage- 12th Grade\n* hsc_b\t  == Board of Education- Central/ Others\n* hsc_s\t  == Specialization in Higher Secondary Education\n* degree_p\t  == Degree Percentage\n* degree_t\t  == Under Graduation(Degree type)- Field of degree education\n* workex\t  == Work Experience\n* etest_p\t  == Employability test percentage ( conducted by college)\n* specialisation\t  == Post Graduation(MBA)- Specialization\n* mba_p\t  == MBA percentage\n* status\t  == Status of placement- Placed/Not placed\n* salary  == Salary offered by corporate to candidates","metadata":{}},{"cell_type":"markdown","source":"____________","metadata":{"id":"SGpkpY_gXKDQ"}},{"cell_type":"code","source":"import numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load the dataset","metadata":{}},{"cell_type":"code","source":"df=pd.read_csv('../input/factors-affecting-campus-placement/Placement_Data_Full_Class.csv')\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.\tData Understanding (8 marks)\n\na.\tRead the dataset (tab, csv, xls, txt, inbuilt dataset). What are the number of rows and no. of cols & types of variables (continuous, categorical etc.)? (1 MARK)\n\nb.\tCalculate five-point summary for numerical variables (1 MARK)\n\nc.\tSummarize observations for categorical variables â€“ no. of categories, % observations in each category. (2 mark)\n\nd.\tCheck for defects in the data such as missing values, null, outliers, etc and also check for class imbalance. (4 marks)\n","metadata":{"id":"lZvUeySbXKDi"}},{"cell_type":"code","source":"#dataset shape\nprint('Number of rows:',df.shape[0])\nprint('Number of columns:',df.shape[1])","metadata":{"id":"RcSCehg3XKDj","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# datatype of variables\ndf.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 5 point summary\ndf.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#describe categorical variables\ndf.describe(include=[np.object])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Values count in each categories","metadata":{}},{"cell_type":"code","source":"a=df['gender'].value_counts()\npercent=(a.values/df.shape[0])*100 #% observations\nb=pd.DataFrame()\nb['Type']=df['gender'].unique()\nb['Percentage']=percent\nb","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a=df['ssc_b'].value_counts()\npercent=(a.values/df.shape[0])*100 #% observations\nb=pd.DataFrame()\nb['Type']=df['ssc_b'].unique()\nb['Percentage']=percent\nb","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a=df['hsc_b'].value_counts()\npercent=(a.values/df.shape[0])*100 #% observations\nb=pd.DataFrame()\nb['Type']=df['hsc_b'].unique()\nb['Percentage']=percent\nb","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a=df['status'].value_counts()\npercent=(a.values/df.shape[0])*100 #% observations\nb=pd.DataFrame()\nb['Type']=df['status'].unique()\nb['Percentage']=percent\nb","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checked for missing values\nprint(df.isnull().sum())\n\nplt.figure(figsize=(10,6))\nsns.heatmap(df.isnull())\nplt.show()\n\n#There are 67 missing values in salary column","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# We will impute null values\n\nprint('Skewness in salary :',df['salary'].skew())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#since salary is right skewed, we will impute null values by median\n\ndf['salary'].fillna(df['salary'].median(),inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df.isnull().sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checked for outliers\n\nplt.figure(figsize=(10,6))\ndf.boxplot()\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Individual boxplots are plotted\ndf1=df.select_dtypes(exclude='object')\nfor i in range(len(df1.columns)):\n    sns.boxplot(df1.iloc[:,i])\n    plt.show()\n    \n    \n    \n#We can observe that the salary and HSC percentage are having outliers\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#We will remove outliers\n#We can observe that the salary and HSC percentage are having outliers\n\nq1=df.quantile(0.25)\nq3=df.quantile(0.75)\niqr=q3-q1\n\nll=q1-iqr\nul=q3+iqr\n\ndf=df[~((df<ll)|(df>ul)).any(axis=1)]\ndf=df.reset_index(drop=True)\n\n\nplt.figure(figsize=(10,6))\ndf.boxplot()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checked for data inbalance\n\nsns.countplot(df['status'])\nplt.show()\n\n\n#We can clearly observe the imbalance in the data givien for placement status since the count of students \n#placed is more than the count of student who did not placed\n# But the target variable is fairly represents two classes\n ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#Correlation matrix\nplt.figure(figsize=(10,6))\nsns.heatmap(df.corr(),annot=True)\nplt.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### EDA","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.scatterplot(x=df['ssc_p'],y=df['hsc_p'],hue=df['status'])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.scatterplot(x=df['degree_p'],y=df['hsc_p'],hue=df['status'])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.barplot(x=df['status'],y=df['ssc_p'],hue=df['ssc_b'])\nplt.show()\n\nsns.barplot(x=df['status'],y=df['hsc_p'])\nplt.show()\n\nsns.barplot(x=df['status'],y=df['degree_p'])\nplt.show()\n\nsns.barplot(x=df['status'],y=df['mba_p'])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.barplot(x=df['status'],y=df['etest_p'])\nplt.show()\n\nsns.countplot(x=df['status'],hue=df['workex'])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### INFERENCES:\n1. From the above scatterplots , we can say that the people who are having high ssc,hsc , degree percentage are more likely to get placed rather than those are having less percentsge.\n\n2. From the above boxplot we can say that the average percentage of the students who are placed are more than those who are not placed.\n\n3. Basically the placement of student depends on the previous marks.(ssc,hsc,degree) \n    \n4. People having more work experience will likely to get placed    ","metadata":{}},{"cell_type":"code","source":"# standard deviation\ndf.std()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We remove serial number\ndf.drop(columns=['sl_no'],inplace=True)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Label encoding & dummy variable encoding\nfrom sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()\ndf['status']=le.fit_transform(df['status'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Categorical vars converted into dummy vars\n\ndf_cat1=df.drop(columns='status').select_dtypes('object')\ndf_cat=pd.get_dummies(df_cat1,drop_first=True)\ndf_cat.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Numerical variables are scaled\nfrom scipy.stats import zscore\ndf_num1=df.select_dtypes(exclude='object')\ndf_num=df_num1.apply(zscore)\ndf_num.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Concatenating x_cat & x_num\n\ndf_x=pd.concat([df_num,df_cat] , axis=1)\ndf_x.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train test split\n\nfrom sklearn.model_selection import train_test_split\nx=df_x.drop(columns='status')\ny=df['status']\nxtrain,xtest,ytrain,ytest=train_test_split( x , y , test_size=0.3 , random_state=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# To check whether xtrain & xtest are representing fair data or not ,\n#We will plot distplot for any one of the numerical feature\n\nprint('Skewness train:',xtrain['ssc_p'].skew())\nsns.distplot(xtrain['ssc_p'])\nplt.show()\n\n\nprint('Skewness test:',xtest['ssc_p'].skew())\nsns.distplot(xtest['ssc_p'])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xtrain.std()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xtest.std()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"1.We can see that the data is normally distributed throughout 3 standard deviation in both the train & test dataset.\n\n2.So train & test data are representing overall data","metadata":{}},{"cell_type":"markdown","source":"## Model Building","metadata":{"id":"zTcAtW63XKD2"}},{"cell_type":"code","source":"#THREE models are build below -KNN.DECISION TREE, RANDOM FOREST\n#Model is fitted using decision tree classifier\n# Because it can capture the non-linearity in the data \n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import KFold,cross_val_score\ndt=DecisionTreeClassifier(criterion='entropy')\n\ndt.fit(xtrain,ytrain)\n\nypred=dt.predict(xtest)\nypredt=dt.predict(xtrain)\nypred_prob=dt.predict_proba(xtest)[:,1]\n\nscore=cross_val_score(dt, xtrain,ytrain,scoring='accuracy', cv=5)\n\nbias_error=np.mean(1-score)\nvar_error=np.std(score)\nprint('Bias_error',bias_error)\nprint('Variance_error:',var_error)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ROC CURVE FOR Decision tree model\n\nfrom sklearn.metrics import roc_curve,roc_auc_score\n\nprint('Area under the roc :',roc_auc_score(ytest,ypred_prob))\nfpr,tpr,threshold=roc_curve(ytest,ypred_prob)\nplt.plot(fpr,tpr)\nplt.plot([0,1],[0,1],'r--')\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Random forest model is build\nrf=RandomForestClassifier(n_estimators=20 , criterion='entropy',random_state=10)\nrf.fit(xtrain,ytrain)\nypredr=rf.predict(xtest)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#KNN Model is build\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV\n\nknn=KNeighborsClassifier()\nparam={'n_neighbors':np.arange(1,80)}\n\ngs=GridSearchCV(knn, param_grid=param , scoring='roc_auc')\ngs.fit(xtrain,ytrain)\ngs.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knn=KNeighborsClassifier(n_neighbors=15,weights='distance')\nknn.fit(xtrain,ytrain)\nypredk=knn.predict(xtest)\nypredk_train=knn.predict(xtrain)\nprint('Overall accuracy of the knn test data:',accuracy_score(ytest,ypredk))\nprint('Overall accuracy of the knn train data:',accuracy_score(ytrain,ypredk_train))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\n\nprint('Overall accuracy of the Decision tree model test data:',accuracy_score(ytest,ypred))\nprint('Overall accuracy of the Decision tree model train data:',accuracy_score(ytrain,ypredt))\n#print('Overall accuracy of the Random forest model:',accuracy_score(ytest,ypredr))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### INFERENCES:\n1.We can clearly see that , all the models build above are having the more accuracy for train data & for test data they are having less accuracy.\n\n2. It means that the model is overfitted over train data\n    \n3. We need to minimize the variance error , it can be minimized using bagging techniques.    ","metadata":{}},{"cell_type":"code","source":"\nfrom sklearn.metrics import classification_report\n\n#Classification report for model build using Decision tree\nprint(classification_report(ytest,ypred))\n\n\n#We can observe from below classification report that the people who will get placed \n#can be predicted with 96% of the accuracy.\n#The people who will not get placed is predicted with accuracy of 82%\n# Model is overfitted model & also has imbalace in the data\n# We will apply bagging ensemble technique to overcome this.\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n1. From all the three models build above , we can clearly see that the training accuracy is more than the testing accuracy ,\n so model is overffited the training data.\n \n2. Therefore the variance error of the model is also more. to reduce variance error we will go for bagging technique\n","metadata":{}},{"cell_type":"code","source":"#BAGGING with Decision tree\n\nfrom sklearn.ensemble import BaggingClassifier\ndt=DecisionTreeClassifier()\nbg=BaggingClassifier(base_estimator=dt,n_estimators=30,random_state=10)\n\nbg.fit(xtrain,ytrain)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ypredb=bg.predict(xtest)\nypredb_prob=bg.predict_proba(xtest)[:,1]\nypredb_train=bg.predict(xtrain)\n\nprint('Overall accuracy of the Decision tree model with bagging test data:',accuracy_score(ytest,ypredb))\nprint('Overall accuracy of the Decision tree model with bagging  train data:',accuracy_score(ytrain,ypredb_train))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ROC CURVE FOR Decision tree model whith bagging\n\nfrom sklearn.metrics import roc_curve,roc_auc_score\n\nprint('Area under the roc :',roc_auc_score(ytest,ypredb_prob))\nfpr,tpr,threshold=roc_curve(ytest,ypredb_prob)\nplt.plot(fpr,tpr)\nplt.plot([0,1],[0,1],'r--')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# PLOTTING PREVIOUS & BAGGING ROC \n\nprint('Area under the roc :',roc_auc_score(ytest,ypred_prob))\nfpr,tpr,threshold=roc_curve(ytest,ypred_prob)\nplt.plot(fpr,tpr , label='WITHOUT BAGGING')\nplt.plot([0,1],[0,1],'r--')\n\n\nprint('Area under the roc :',roc_auc_score(ytest,ypredb_prob))\nfpr,tpr,threshold=roc_curve(ytest,ypredb_prob)\nplt.plot(fpr,tpr, label='WITH BAGGING')\nplt.plot([0,1],[0,1],'r--')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### INFERENCES:\n1.testing accuracy has been improved from the previous decision tree model.\n\n2.Decision tree model without bagging has less testing accuracy than the decision tree model with bagging model\n\n3.From above ROC Curve , we ca clearly see that the area under the curve for the model  build using BAGGING technique is more than the are under the curve for the model build without bagging technique.\n\n\n\n4.ROC_AUC Score of the model is improved So the accuracy of the model has been increased by bagging the Decision tree model.\n","metadata":{}},{"cell_type":"markdown","source":"### INFERENCES:\n1. From EDA part done  , We can clearly see that the previous class marks matters in placements.\nThe students having more marks in ssc,hsc ,degree are likely to get placed than the ones having less marks.\n\n2. So the marks is one of the important criteria to predict whether the person will get placed or not .\n\n3. Experience  of the person also matters in placement.There are more chances that Experienced person will get placed.\n\n4. Then we built Decision tree model .\nThe model is overfitted on the training dataset therefore we are getting less accuracy for testing dataset.\nAlso the imbalance in data will reflect in the precision & recall matrix also.\n\n5. Since the data is having more number of placed people's data so more characteristics or variety of data for this group is  available to build model & predict the people who will get placed.\nBut the data of people who are not got placed is less so may be all the variety of characteristics of these class are not available or not enough to predict the person will not get placed.\n\n6. Ensemble techniques are used to overcome the overfitting & underfitting of the model.\nSince above model is overfitted , we have to use bagging ensemble technique to minimize the variance error\n\n7. So we build bagging model with base model as Decision tres thereby we overcame the overfitting problem.\nNow the accuracy for testing dataset has been improved than the previous model.\n\n8. We compared the results using ROC Curve & roc_auc score","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}