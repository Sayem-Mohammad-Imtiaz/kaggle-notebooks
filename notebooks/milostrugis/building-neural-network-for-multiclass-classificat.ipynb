{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is my attempt to build the Neural Network from scratch and classify Iris species"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport random\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"Path = \"/kaggle/input/iris/Iris.csv\"\nPath1 = \"C:/Users/wilkm/Desktop/aaaa/iris1.xlsx\"\n\niris =  pd.read_csv(Path)\niris = iris.iloc[:, 1:6]\niris.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# normalising features\niris_trans = iris\niris_trans.head()\ndata = iris_trans.iloc[:, 0:4]\nvalues = data.values\nscaler = MinMaxScaler()\nprint(scaler.fit(data))\nMinMaxScaler(copy=True, feature_range=(0, 1))\niris_trans.iloc[:, 0:4] = scaler.transform(data)\niris_trans.Species = pd.Categorical(iris_trans.Species)\niris_trans['categ'] = iris_trans.Species.cat.codes\niris_trans.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"iris_trans[\"categ\"].value_counts()\n# balanced dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#splitting data to training and test tests \ntrain_df, test_df = train_test_split(iris_trans, test_size = 0.25,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualising data\ncateg = iris_trans.iloc[:, 5]\nfeat = iris_trans.iloc[:, 0:2]\ncateg = iris_trans.iloc[:, 5]\nfeat = iris_trans.iloc[:, 0:2]\nplt.scatter(feat.iloc[:,0], feat.iloc[:,1], c = categ)\nplt.title(\"Iris data set\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x = np.array(train_df.iloc[:, 0:4])\ntrain_x  = train_x[:, [0,1]]\ntest_x = np.array(test_df.iloc[:, 0:4])\ntest_x  = test_x[:, [0,1]]\ntrain_y = np.array(pd.get_dummies(train_df.iloc[:, 5]))\ntest_y = np.array(pd.get_dummies(test_df.iloc[:, 5]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# First attempt to bulid neural network and to use the object-oriented programming \ndef sigmoid(x):\n        return 1 / (1 + np.exp(-x))\n\ndef deriv_sigmoid(x):\n    return sigmoid(x) * (1 - sigmoid(x))\n\ndef softmax(x):\n    expx= np.exp(x)\n    return expx / expx.sum(axis=1, keepdims=True)\n\n\n\n\n\nclass NeuralNetwork:\n    import matplotlib.pyplot as plt\n    def __init__(self, input_x, output_act, alpha, epochs):\n   \n        self.input_x      = input_x\n        self.output_act = output_act\n        \n        no_of_examp = self.input_x .shape[0]\n        \n        self.W1   = np.random.rand(self.input_x.shape[1],4) \n        self.B1   = np.random.randn(4)            \n        self.W2   = np.random.rand(4,self.output_act.shape[1]) \n        self.B2   = np.random.randn(self.output_act.shape[1])\n        self.output     = np.zeros(self.output_act.shape)\n        self.alpha = alpha\n        self.epochs = epochs\n        self.error = [] \n   \n     \n    \n    def feedforward(self, input_x):\n        self.v1 = np.dot(input_x, self.W1) + self.B1\n        self.layer1 = sigmoid(self.v1)\n        self.v2 = np.dot(self.layer1, self.W2) + self.B2      \n        self.output = softmax(self.v2)\n        return self.output\n    \n    def backprop(self, input_x, output_act, alpha):\n        out_error = self.output - self.output_act\n        der_W2 = np.dot(self.layer1.T, out_error)\n        der_B2 = out_error\n        \n        der_W1 = np.dot(self.input_x.T, ((self.layer1 *(1-self.layer1)) * np.dot(out_error , self.W2.T)))\n        der_B1 = (self.layer1 *(1-self.layer1)) * np.dot(out_error , self.W2.T)\n        \n        self.W1 -= alpha * der_W1\n        self.B1 -= alpha * der_B1.sum(axis=0)\n\n        self.W2 -= alpha * der_W2\n        self.B2 -= alpha * der_B2.sum(axis=0) \n        #return self.W1, self.B1, self.W2, self.B2 \n    def train(self, input_x, output_act, alpha, epochs):\n        self.error = []\n        for epoch in range(self.epochs):\n            self.feedforward(input_x)\n            self.backprop(input_x, output_act, alpha)\n            if epoch % 200 == 0:\n                loss = np.sum(-1*np.multiply(output_act, np.log(self.output)))\n                #loss = loss/no_of_examp\n                print('Loss function value: ', loss)\n                self.error.append(loss)\n        plt.plot(self.error)\n        plt.title(\"Loss\")\n    def test(self, data, act_y, results = False):\n        res = np.around(self.feedforward(data))\n        x = 0\n        for i in range(len(res)):\n            if(all(act_y[i]==res[i])):\n                x+= 1\n        acc = round((x / len(res)), 2)\n        print('Accuracy: {0:2.2f}'.format(acc))\n        if results == True:\n            print(\"Predicted values: \", \"\\n\" ,res)\n       ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# training the network\nnew_network = NeuralNetwork(train_x, train_y, 0.01, 5000)\nnew_network.train(train_x, train_y, 0.01, 5000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print training accuracy\nnew_network.test(train_x, train_y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The accuracy is very good, that can be expected for a well categorised data set"},{"metadata":{"trusted":true},"cell_type":"code","source":"# print test data accuracy and results\nnew_network.test(test_x,test_y, True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"import pandas as pd\nmushrooms = pd.read_csv(\"../input/mushroom-classification/mushrooms.csv\", header = 0)\nmushrooms.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print( mushrooms[\"class\"].value_counts()/mushrooms.shape[0]*100)\n# looking an % values, this is a balanced data set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(mushrooms.shape)\n# there are 22 features in the set, and all features are categorical","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Performing multiple correspondence analysis wii reduce dimensionality\nIt is \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install prince","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import prince","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mca = prince.MCA()\nmushrooms_mca_categ = mushrooms.iloc[:, 0] # extract labels\nmushrooms_mca = mushrooms.iloc[:, 1:] # features\nmushrooms_mca.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mca = mca.fit(mushrooms_mca) # same as calling ca.fs_r(1)\nmca = mca.transform(mushrooms_mca) # same as calling ca.fs_r_sup(df_new) for *another* test set.\nprint(mca.head(20))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(mca.head(20))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mushrooms_new = pd.concat([mca, mushrooms_mca_categ], axis=1)\nmushrooms_new[\"class\"] = pd.Categorical(mushrooms_new[\"class\"])\nmushrooms_new[\"class_cat\"] = mushrooms_new[\"class\"].cat.codes\nmushrooms_new.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = mushrooms_new[\"class_cat\"]# poisonus1, edible0\nfeat1 = mushrooms_new[0]\nfeat2 = mushrooms_new[1]\nplt.scatter(feat1, feat2, c = labels)\nplt.title(\"Musrooms MCA features\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After MCA classes look rather well separable"},{"metadata":{"trusted":true},"cell_type":"code","source":"mush_train, mush_test = train_test_split(mushrooms_new, test_size = 0.25, random_state = 42)\nmush_train_x = np.array(mush_train.iloc[:, 0:2])\nmush_train_y = np.array(pd.get_dummies(mush_train.iloc[:, 3]))\nmush_test_x = np.array(mush_test.iloc[:, 0:2])\nmush_test_y = np.array(pd.get_dummies(mush_test.iloc[:, 3]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_network2 = NeuralNetwork(mush_train_x, mush_train_y, 0.0001, 5000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_network2.train(mush_train_x, mush_train_y, 0.0001, 5000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_network2.test(mush_train_x, mush_train_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_network2.test(mush_test_x, mush_test_y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Both training and test results have very good accuracy"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}