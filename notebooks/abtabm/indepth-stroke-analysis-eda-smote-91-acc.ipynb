{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 id=\"contents\" style=\"text-align:center; background-color:#acdf87;color:white;padding-top:15px;padding-bottom:15px\"><strong>CONTENTS</strong><a class=\"anchor-link\" href=\"https://www.kaggle.com/abtabm/indepth-stroke-analysis-eda-smote-91-acc/#contents\">¶</a></h1>\n","metadata":{}},{"cell_type":"markdown","source":"1. [Importing Packages & Dataset](#imp)\n1. [EDA](#eda)\n   1. [Numerical Features](#num)\n   1. [Categorical Features](#cat)\n1. [Data Preprocessing](#DataPre)\n   1. [Encoding](#enc)\n   1. [Splitting](#spl)\n   1. [SMOTE](#smt)\n1. [Modelling](#model)\n   1. [Logistic Regression](#LR)\n   1. [SVM](#SVM)\n   1. [Decision Tree](#DT)\n   1. [Random Forest](#RF)\n   1. [XGBoost](#XG)\n1. [Conclusion](#concl)","metadata":{}},{"cell_type":"markdown","source":"<div id=\"imp\"></div>","metadata":{}},{"cell_type":"markdown","source":"<h1 id=\"importing-packages\" style=\"font-size:20px; color:white; background-color:#5dd466 ;text-align:center;padding-top:10px;padding-bottom:10px\"><strong>IMPORTING PACKAGES & DATASET</strong><a class=\"anchor-link\" href=\"https://www.kaggle.com/abtabm/indepth-stroke-analysis-eda-smote-91-acc/#importing-packages\">¶</a></h1>","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport plotly.express as px\nfrom IPython.core.display import display, HTML, Javascript\nfrom plotly.offline import download_plotlyjs,init_notebook_mode\ninit_notebook_mode(connected=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_o = pd.read_csv(\"../input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv\")\ndata_o.head(8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = data_o.drop(\"id\",axis=1)\ndata.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**A total of 201 missing values in BMI**","metadata":{}},{"cell_type":"code","source":"data[\"bmi\"].fillna(data[\"bmi\"].mean(),inplace=True)\ndata.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The age column looks weird as the min value is 0.08 which probably means that age is counted in days or there is some noise in this column , we need to analyze it in data cleaning**","metadata":{}},{"cell_type":"markdown","source":"<div id=\"eda\"></div>","metadata":{}},{"cell_type":"markdown","source":"<h1 id= \"eda\" style=\"font-size:20px; color:White; background-color:#5dd466 ;text-align:center;padding-top:10px;padding-bottom:10px\"><strong>EXPLORATORY DATA ANALYSIS</strong><a class=\"anchor-link\" href=\"https://www.kaggle.com/abtabm/indepth-stroke-analysis-eda-smote-91-acc/#eda\">¶</a></h1>","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,10))\ncorr = data.corr()\nsns.heatmap(corr,cmap = 'viridis',annot=True,fmt=\".2f\",vmin=-1,vmax=1,linewidths=0.2)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div id=\"num\"></div>","metadata":{}},{"cell_type":"markdown","source":"### **NUMERICAL FEATURES**\n<div id=\"num\"></div>","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(20,5))\nuncat_data = [\"age\",\"bmi\",\"avg_glucose_level\"]\n\nplt.subplot(1,3,1)\natt = data[\"age\"].values\np = sns.distplot(att,color=\"violet\")\np.set_title(\"Age Distribution\",fontsize=16)\np.set_xlim([min(att),max(att)])\n\nplt.subplot(1,3,2)\natt = data[\"bmi\"].values\np = sns.distplot(att,color=\"black\")\np.set_title(\"BMI Distribution\",fontsize=16)\np.set_xlim([min(att),max(att)])\n\nplt.subplot(1,3,3)\natt = data[\"avg_glucose_level\"].values\np = sns.distplot(att,color=\"orange\")\np.set_title(\"Age Distribution\",fontsize=16)\np.set_xlim([min(att),max(att)])","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.figure_factory as ff\ngroup_labels = ['0', '1']\nl = [data['age'][(data[\"stroke\"] == 0)],data['age'][(data[\"stroke\"] == 1)]]\nfig = ff.create_distplot(l, group_labels,curve_type='kde',colors = ['slategray', 'magenta'])\nfig.update_layout(title_text='Age & Stroke Distribution',xaxis_title=\"Age Distribution\",yaxis_title=\"Frequency\")\nfig.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **We can infer that after the age of 40 the risk of Stroke increases.**\n- **At the age above 76 there is high chance of stroke.**","metadata":{}},{"cell_type":"code","source":"import plotly.figure_factory as ff\ngroup_labels = ['0', '1']\nl = [data['bmi'][(data[\"stroke\"] == 0)],data['bmi'][(data[\"stroke\"] == 1)]]\nfig = ff.create_distplot(l, group_labels,curve_type='kde',colors = ['#F66095', '#2BCDC1']\n)\nfig.update_layout(title_text='BMI & Stroke Distribution',xaxis_title=\"BMI Distribution\",yaxis_title=\"Frequency\")\nfig.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Below 18.5 - Underweight\n- 18.5-24.9 - Normal\n- 25.0-29.9 - Overweight\n- 30.0 And Above - Obese\n- **The BMI 30 above is considered as Obese, hence the chance of stroke is more in obese people.**","metadata":{}},{"cell_type":"code","source":"import plotly.figure_factory as ff\ngroup_labels = ['0', '1']\nl = [data['avg_glucose_level'][(data[\"stroke\"] == 0)],data['avg_glucose_level'][(data[\"stroke\"] == 1)]]\nfig = ff.create_distplot(l, group_labels,curve_type='kde',colors = ['#393E46', 'rgb(0, 200, 200)'])\nfig.update_layout(title_text='Avg Glucose Level & Stroke Distribution',xaxis_title=\"Avg_Glucose_Level Distribution\",yaxis_title=\"Frequency\")\nfig.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **Elevated glucose level results in higher chances of a stroke, a trait observed in diabetic patients.**\n- **From the graph we can infer that above the level of 150/160, the risk of stroke increases.**","metadata":{}},{"cell_type":"markdown","source":"### **CATEGORICAL & BOOLEAN FEATURES**\n<div id=\"cat\"></div>","metadata":{}},{"cell_type":"code","source":"print('No Stroke :', round(data['stroke'].value_counts()[0]/len(data) * 100,2), '% of the dataset')\nprint('Stroke :', round(data['stroke'].value_counts()[1]/len(data) * 100,2), '% of the dataset')\nfig = px.histogram(data, x=\"stroke\", color=\"stroke\",barmode=\"group\") \nfig.update_layout(title_text=\"Stroke Count\")\nfig.show()","metadata":{"_kg_hide-input":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.histogram(data, x=\"smoking_status\", color=\"stroke\",barmode=\"group\") \nfig.update_layout(title_text=\"Smoking Status Count\")\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**There is a high disproportion in the dataset, which could eventually lead to bad model, hence Sampling is required**","metadata":{}},{"cell_type":"code","source":"plt.subplots(figsize=(20,5))\nsns.set_style(style=\"darkgrid\")\n\nplt.subplot(1,3,1)\nsns.countplot(\"ever_married\",data=data,palette=\"Paired\",hue=\"stroke\")\n\nplt.subplot(1,3,2)\nsns.countplot(\"hypertension\",data=data,palette=\"crest\",hue='stroke')\n\nplt.subplot(1,3,3)\nsns.countplot(\"heart_disease\",data=data,palette=\"tab10\",hue='stroke')","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.subplots(figsize=(20,10))\n\nplt.subplot(2,3,1)\nsns.countplot(\"gender\",data=data,palette=\"mako\",hue='stroke')\n\nplt.subplot(2,3,2)\nsns.countplot(\"work_type\",data=data,palette=\"rocket_r\",hue='stroke')\n\nplt.subplot(2,3,3)\nsns.countplot(\"Residence_type\",data=data,palette=\"autumn\",hue='stroke')","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\nfig = px.scatter(data, x=\"bmi\", y=\"avg_glucose_level\", color=\"stroke\",color_continuous_scale=\"tropic\")\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Due to imbalance in dataset it is hard to analyze but we can see that:**\n- **Higher the glucose level (150-250) Result in high Stroke chances.**\n- **BMI Above 30-40 intersecting with the glucose level has a higher risk of stroke.**","metadata":{}},{"cell_type":"markdown","source":"<div id=\"DataPre\"></div>","metadata":{}},{"cell_type":"markdown","source":"<h1 id=\"preprocessing\" style=\"font-size:20px; color:White; background-color:#5dd466 ;text-align:center;padding-top:10px;padding-bottom:10px\"><strong>DATA PREPROCESSING</strong><a class=\"anchor-link\" href=\"https://www.kaggle.com/abtabm/indepth-stroke-analysis-eda-smote-91-acc/#preprocessing\"></a></h1>","metadata":{}},{"cell_type":"code","source":"data_X = data.drop(\"stroke\",axis=1)\ndata_y = data.iloc[:,-1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Checking for unique values in the dataset**","metadata":{}},{"cell_type":"code","source":"cat_col = data_X.select_dtypes(include = 'object').columns.to_list()\nnum_col = data_X.select_dtypes(include= ['int64','float64']).columns.to_list()\n\nfor i in num_col:\n    print(i + \": \",data_X[i].nunique())\n    print(\"------------------------------------------------------------------\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[data_X[\"age\"]==0.32]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Well if we convert it into int, we can loose children's data, as 0.32 might be 32 days.","metadata":{}},{"cell_type":"markdown","source":"### **Encoding Data**\n<div id=\"enc\"></div>","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\ncat_encode = ColumnTransformer([('encoder', OneHotEncoder(), [0,5,9])], remainder= 'passthrough')\ndata_X = cat_encode.fit_transform(data_X)\ndata_X = pd.DataFrame(data_X)\ndata_X","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()\ndata_X[15] = encoder.fit_transform(data_X[15])\ndata_X[16] = encoder.fit_transform(data_X[16])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_X.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Scaling & Splitting The Data**\n<div id=\"spl\"></div>","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(data_X, data_y, test_size= 0.2, random_state=42)\n\nfrom sklearn.preprocessing import StandardScaler \nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **SMOTE Handling Imbalance Data**\n<div id=\"smt\"></div>","metadata":{}},{"cell_type":"code","source":"ax = plt.subplots(figsize=(20,7))\nplt.subplot(1,2,1)\nax=sns.countplot('stroke', data=pd.DataFrame(y_train), palette='viridis',hue=\"stroke\",dodge=False)\nplt.title(\"Stroke Count Before Oversampling\")\nfor p in ax.patches:\n    ax.annotate((p.get_height()), (p.get_x() + p.get_width() / 2., p.get_height()), ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')\n\nfrom imblearn.over_sampling import SMOTE\nsamp = SMOTE(random_state=3)\nX_train, y_train = samp.fit_resample(X_train, y_train.ravel())\n    \nplt.subplot(1,2,2)\nax=sns.countplot('stroke', data=pd.DataFrame(y_train,columns=[\"stroke\"]), palette='viridis',hue=\"stroke\",dodge=False)\nplt.title(\"Stroke Count After Oversampling\")\nfor p in ax.patches:\n    ax.annotate((p.get_height()), (p.get_x() + p.get_width() / 2., p.get_height()), ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div id=\"model\"></div>","metadata":{}},{"cell_type":"markdown","source":"<h1 id=\"modelling\" style=\"font-size:20px; color:White; background-color:#5dd466 ;text-align:center;padding-top:10px;padding-bottom:10px\"><strong>MODELLING</strong><a class=\"anchor-link\" href=\"https://www.kaggle.com/abtabm/indepth-stroke-analysis-eda-smote-91-acc/#modelling\">¶</a></h1>","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, roc_auc_score, accuracy_score, ConfusionMatrixDisplay, precision_score, recall_score, f1_score, classification_report, roc_curve, plot_roc_curve, auc, average_precision_score, precision_recall_curve, plot_precision_recall_curve\nfrom sklearn.model_selection import cross_val_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def metrics(model,x,y_test,y_pred):\n    cv = cross_val_score(model_1,X_train,y_train, cv = 5) \n    roc = roc_auc_score(y_test, y_pred)  \n    precision = precision_score(y_test, y_pred)  \n    recall = recall_score(y_test, y_pred)  \n    f1 = f1_score(y_test, y_pred)\n    print(classification_report(y_test, y_pred))\n    print(\"\\nAccuracy Score: \",accuracy_score(y_test, y_pred))\n    print(\"\\nROC AUC Score: {:.2f}\".format(roc))\n    print(\"\\nPrecision: {:.2f}\".format(precision))\n    print(\"\\nRecall: {:.2f}\".format(recall))\n    print(\"\\nF1: {:.2f}\".format(f1))\n    f, axes = plt.subplots(1,2, figsize=(20,7))\n    sns.set_theme(style = 'white')\n    #-------------------------------------CONFUSION MATRIX----------------------------------\n    \n    cm = confusion_matrix(y_test, y_pred)\n    sns.heatmap(cm, cmap = 'Blues_r', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15},ax=axes[0] ,yticklabels = ['0', '1'], xticklabels = ['Predicted 0', 'Predicted 1'])\n    \n    #-------------------------------------ROC_AUC Curve----------------------------------\n    \n    plot_roc_curve(model, x, y_test,ax=axes[1]) \n    plt.plot([0, 1], [0, 1], linestyle = '--', color = '#b01717')\n    plt.show()        ","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Logistic Regression**\n<div id=\"LR\"></div>","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nmodel_1 = LogisticRegression(random_state=42)\nmodel_1.fit(X_train,y_train)\ny_pred = model_1.predict(X_test)\nmetrics(model_1,X_test,y_test,y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Support Vector Machine**\n<div id=\"SVM\"></div>","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\nmodel_2 = SVC(random_state=42)\nmodel_2.fit(X_train,y_train)\ny_pred = model_2.predict(X_test)\nmetrics(model_2,X_test,y_test,y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Decision Tree**\n<div id=\"DT\"></div>","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nmodel_3 = DecisionTreeClassifier(random_state=42)\nmodel_3.fit(X_train,y_train)\ny_pred = model_3.predict(X_test)\nmetrics(model_3,X_test,y_test,y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Random Forest**\n<div id=\"RF\"></div>","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nmodel_4 = RandomForestClassifier(random_state=42)\nmodel_4.fit(X_train,y_train)\ny_pred = model_4.predict(X_test)\nmetrics(model_4,X_test,y_test,y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **XGBoost**\n<div id=\"XG\"></div>","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier\nmodel_5 = XGBClassifier(random_state=42,eval_metric=\"error\")\nmodel_5.fit(X_train,y_train)\ny_pred = model_5.predict(X_test)\nmetrics(model_5,X_test,y_test,y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 id=\"conclusion\" style=\"font-size:20px; color:White; background-color:#5dd466 ;text-align:center;padding-top:10px;padding-bottom:10px\"><strong>CONCLUSION</strong><a class=\"anchor-link\" href=\"https://www.kaggle.com/abtabm/indepth-stroke-analysis-eda-smote-91-acc/#conclusion\">¶</a></h1>\n\n<div id=\"concl\"></div>","metadata":{}},{"cell_type":"markdown","source":"- Higher **recall** and **f1-score** is required, but there aren't many True postives in the dataset. \n- The AUC Score of **Random Forest** and **Logistic Regression** is high, \n- Moreover True positive are more in the **XGBoost** and **Random Forest** Model\n\n#### I am open to advice/suggestions to improve this notebook and i am curious to know which metric should be focussed more for this problem.","metadata":{}}]}