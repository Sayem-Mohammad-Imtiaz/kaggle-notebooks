{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Predicting Heart Attacks\n\nIn this notebook, we predict which people are at risk for heart attacks.","metadata":{}},{"cell_type":"markdown","source":"## The Data\n\nWe use the \"Heart Attack Analysis & Prediction Dataset\" provided by Rashik Rahman.\n\nAge : Age of the patient\n\nSex : Sex of the patient\n\nexang: exercise induced angina (1 = yes; 0 = no)\n\nca: number of major vessels (0-3)\n\ncp : Chest Pain type chest pain type\n- Value 1: typical angina\n- Value 2: atypical angina\n- Value 3: non-anginal pain\n- Value 4: asymptomatic\n\ntrtbps : resting blood pressure (in mm Hg)\n\nchol : cholestoral in mg/dl fetched via BMI sensor\n\nfbs : (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)\n\nrest_ecg : resting electrocardiographic results\n\n- Value 0: normal\n- Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)\n- Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\n- thalach : maximum heart rate achieved\n\ntarget : 0= less chance of heart attack 1= more chance of heart attack","metadata":{}},{"cell_type":"markdown","source":"# Import Libraries and Read Data","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom scipy.stats import chi2_contingency\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve, auc, make_scorer\nfrom scikitplot.metrics import plot_roc\nfrom sklearn.preprocessing import RobustScaler, StandardScaler, minmax_scale, Normalizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nplt.style.use('default')\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-23T13:36:17.51892Z","iopub.execute_input":"2021-06-23T13:36:17.519371Z","iopub.status.idle":"2021-06-23T13:36:18.991416Z","shell.execute_reply.started":"2021-06-23T13:36:17.51925Z","shell.execute_reply":"2021-06-23T13:36:18.990201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/heart-attack-analysis-prediction-dataset/heart.csv')\ndf","metadata":{"execution":{"iopub.status.busy":"2021-06-23T13:36:18.992882Z","iopub.execute_input":"2021-06-23T13:36:18.993173Z","iopub.status.idle":"2021-06-23T13:36:19.043941Z","shell.execute_reply.started":"2021-06-23T13:36:18.993144Z","shell.execute_reply":"2021-06-23T13:36:19.042949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-23T13:36:19.04544Z","iopub.execute_input":"2021-06-23T13:36:19.045714Z","iopub.status.idle":"2021-06-23T13:36:19.064454Z","shell.execute_reply.started":"2021-06-23T13:36:19.045686Z","shell.execute_reply":"2021-06-23T13:36:19.063782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().any()","metadata":{"execution":{"iopub.status.busy":"2021-06-23T13:36:19.065789Z","iopub.execute_input":"2021-06-23T13:36:19.066366Z","iopub.status.idle":"2021-06-23T13:36:19.082829Z","shell.execute_reply.started":"2021-06-23T13:36:19.066332Z","shell.execute_reply":"2021-06-23T13:36:19.081863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"delete_item = df[df.duplicated()]\n\ndf.drop(index = delete_item.index, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T13:36:19.084111Z","iopub.execute_input":"2021-06-23T13:36:19.084714Z","iopub.status.idle":"2021-06-23T13:36:19.103901Z","shell.execute_reply.started":"2021-06-23T13:36:19.084677Z","shell.execute_reply":"2021-06-23T13:36:19.102901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA\n## Univariate Analysis\n\n","metadata":{}},{"cell_type":"markdown","source":"### Target Variable","metadata":{}},{"cell_type":"code","source":"sns.countplot(x = 'output',data=df);","metadata":{"execution":{"iopub.status.busy":"2021-06-23T13:36:19.105222Z","iopub.execute_input":"2021-06-23T13:36:19.105705Z","iopub.status.idle":"2021-06-23T13:36:19.273377Z","shell.execute_reply.started":"2021-06-23T13:36:19.105672Z","shell.execute_reply":"2021-06-23T13:36:19.272079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Categorical Variables","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(25,10))\n\nplt.subplot(241)\n\nsns.countplot(x = 'sex', data=df)\n\nplt.subplot(242)\nsns.countplot(x = 'cp', data=df)\n\nplt.subplot(243)\nsns.countplot(x = 'fbs', data=df)\n\nplt.subplot(244)\nsns.countplot(x = 'restecg', data=df)\n\nplt.subplot(245)\nsns.countplot(x = 'exng', data=df)\n\nplt.subplot(246)\nsns.countplot(x = 'slp', data=df)\n\nplt.subplot(247)\nsns.countplot(x = 'caa', data=df)\n\nplt.subplot(248)\nsns.countplot(x = 'thall', data=df);\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-23T13:36:19.275003Z","iopub.execute_input":"2021-06-23T13:36:19.275431Z","iopub.status.idle":"2021-06-23T13:36:20.169906Z","shell.execute_reply.started":"2021-06-23T13:36:19.275385Z","shell.execute_reply":"2021-06-23T13:36:20.168994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Numerical Variables","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,15))\n\nplt.subplot(321)\nsns.histplot(x = 'age', data=df)\n\nplt.subplot(322)\nsns.histplot(x = 'trtbps', data=df)\n\nplt.subplot(323)\nsns.histplot(x = 'chol', data=df)\n\nplt.subplot(324)\nsns.histplot(x = 'thalachh', data=df)\n\nplt.subplot(325)\nsns.histplot(x = 'oldpeak', data=df);\n","metadata":{"execution":{"iopub.status.busy":"2021-06-23T13:36:20.172583Z","iopub.execute_input":"2021-06-23T13:36:20.173119Z","iopub.status.idle":"2021-06-23T13:36:20.935109Z","shell.execute_reply.started":"2021-06-23T13:36:20.173075Z","shell.execute_reply":"2021-06-23T13:36:20.934059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Bivariate Analysis","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:08:49.548467Z","iopub.execute_input":"2021-06-17T14:08:49.548981Z","iopub.status.idle":"2021-06-17T14:08:49.559924Z","shell.execute_reply.started":"2021-06-17T14:08:49.548941Z","shell.execute_reply":"2021-06-17T14:08:49.558256Z"}}},{"cell_type":"code","source":"risky = df[df['output'] == 1]\n\nnot_risky = df[df['output'] == 0]\n","metadata":{"execution":{"iopub.status.busy":"2021-06-23T13:36:20.937125Z","iopub.execute_input":"2021-06-23T13:36:20.937681Z","iopub.status.idle":"2021-06-23T13:36:20.944791Z","shell.execute_reply.started":"2021-06-23T13:36:20.937637Z","shell.execute_reply":"2021-06-23T13:36:20.943861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,7))\n\nplt.subplot(131)\nsns.countplot(data=df,x='sex', hue='output')\n\nplt.subplot(132)\nsns.countplot(data=df,x='fbs', hue='output')\n\nplt.subplot(133)\nsns.countplot(data=df,x='exng', hue='output');","metadata":{"execution":{"iopub.status.busy":"2021-06-23T13:36:20.945945Z","iopub.execute_input":"2021-06-23T13:36:20.946227Z","iopub.status.idle":"2021-06-23T13:36:21.320196Z","shell.execute_reply.started":"2021-06-23T13:36:20.9462Z","shell.execute_reply":"2021-06-23T13:36:21.31927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2021-06-23T13:36:21.321324Z","iopub.execute_input":"2021-06-23T13:36:21.321569Z","iopub.status.idle":"2021-06-23T13:36:21.339674Z","shell.execute_reply.started":"2021-06-23T13:36:21.321545Z","shell.execute_reply":"2021-06-23T13:36:21.338549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(25,10))\n\nplt.subplot(331)\nsns.kdeplot(data=df, x='age',hue='output',fill=True,palette=[\"blue\",\"orange\"], alpha=.5, linewidth=0)\n\nplt.subplot(332)\nsns.kdeplot(data=df, x='cp',hue='output',fill=True,palette=[\"blue\",\"orange\"], alpha=.5, linewidth=0)\n\nplt.subplot(333)\nsns.kdeplot(data=df, x='trtbps',hue='output',fill=True,palette=[\"blue\",\"orange\"], alpha=.5, linewidth=0)\n\nplt.subplot(334)\nsns.kdeplot(data=df, x='chol',hue='output',fill=True,palette=[\"blue\",\"orange\"], alpha=.5, linewidth=0)\n\nplt.subplot(335)\nsns.kdeplot(data=df, x='restecg',hue='output',fill=True,palette=[\"blue\",\"orange\"], alpha=.5, linewidth=0)\n\nplt.subplot(336)\nsns.kdeplot(data=df, x='thalachh',hue='output',fill=True,palette=[\"blue\",\"orange\"], alpha=.5, linewidth=0)\n\nplt.subplot(337)\nsns.kdeplot(data=df, x='oldpeak',hue='output',fill=True,palette=[\"blue\",\"orange\"], alpha=.5, linewidth=0)\n\nplt.subplot(338)\nsns.kdeplot(data=df, x='slp',hue='output',fill=True,palette=[\"blue\",\"orange\"], alpha=.5, linewidth=0)\n\nplt.subplot(339)\nsns.kdeplot(data=df, x='caa',hue='output',fill=True,palette=[\"blue\",\"orange\"], alpha=.5, linewidth=0);","metadata":{"execution":{"iopub.status.busy":"2021-06-23T13:36:21.340663Z","iopub.execute_input":"2021-06-23T13:36:21.340906Z","iopub.status.idle":"2021-06-23T13:36:22.985229Z","shell.execute_reply.started":"2021-06-23T13:36:21.340883Z","shell.execute_reply":"2021-06-23T13:36:22.984461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# Model Building\n","metadata":{}},{"cell_type":"markdown","source":"## Model Preparation\n\nTo prepare the model we must get dummy variables for all the categorical variables. We also select a lower test size because there is not a lot of training data so we want to use as much as possible for training.","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"modeling_df = df.copy()\n\ncat_cols = ['sex','cp','fbs','restecg','exng','slp','caa','thall']\nnum_cols = ['age','trtbps','chol','thalachh','oldpeak']\n\n\n\npd.get_dummies(modeling_df, columns = cat_cols, drop_first = True)\n\n\n\nX = modeling_df.drop(['output'],axis=1)\ny = modeling_df[['output']]\n\n\n\n\n\nX_train, X_val, y_train, y_val = train_test_split(X,y, test_size=.10, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T13:36:22.986195Z","iopub.execute_input":"2021-06-23T13:36:22.986562Z","iopub.status.idle":"2021-06-23T13:36:23.003967Z","shell.execute_reply.started":"2021-06-23T13:36:22.986536Z","shell.execute_reply":"2021-06-23T13:36:23.002603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Establishing Baseline Performance\n​\nTo understand if our model holds any weight, we need to establish a baseline model to test our models against.","metadata":{}},{"cell_type":"code","source":"X_train.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-06-23T13:36:23.006114Z","iopub.execute_input":"2021-06-23T13:36:23.006573Z","iopub.status.idle":"2021-06-23T13:36:23.028191Z","shell.execute_reply.started":"2021-06-23T13:36:23.006526Z","shell.execute_reply":"2021-06-23T13:36:23.027286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('All Positive model equals:',130/y_train.size)\n\nprint('All Negative model equals:',111/y_train.size)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T13:36:23.029554Z","iopub.execute_input":"2021-06-23T13:36:23.029919Z","iopub.status.idle":"2021-06-23T13:36:23.035521Z","shell.execute_reply.started":"2021-06-23T13:36:23.029879Z","shell.execute_reply":"2021-06-23T13:36:23.034435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since the all positive model has a higher accuracy we will be using it for our baseline. This means that out model must beat an accuracy score of 53.94%.","metadata":{}},{"cell_type":"markdown","source":"## Model Selection\n\n### Defining model functions","metadata":{}},{"cell_type":"markdown","source":"This is a function to plot the ROC curve for each model.","metadata":{}},{"cell_type":"code","source":"def plot_roc_curve(fpr, tpr):\n    plt.plot(fpr, tpr, color='orange', label='ROC')\n    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-23T13:36:23.036888Z","iopub.execute_input":"2021-06-23T13:36:23.037257Z","iopub.status.idle":"2021-06-23T13:36:23.048298Z","shell.execute_reply.started":"2021-06-23T13:36:23.037199Z","shell.execute_reply":"2021-06-23T13:36:23.047454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This function efficiently trains each model on the training data and makes predictions for our validation set.","metadata":{}},{"cell_type":"code","source":"def fit_model(model):\n    \n    model.fit(X_train, y_train)\n    val_preds = model.predict(X_val)\n    print(pd.DataFrame(confusion_matrix(y_val,val_preds),\\\n            columns=[\"Predicted No\", \"Predicted Yes\"],\\\n            index=[\"No\",\"Yes\"]))\n    print('\\n')\n    print(classification_report(y_val, val_preds))\n    \n    probs = model.predict_proba(X_val)\n    probs = probs[:, 1]\n    fpr, tpr, thresholds = roc_curve(y_val, probs)\n    plot_roc_curve(fpr,tpr)\n    print('auc score: '+ str(roc_auc_score(y_val,val_preds)))","metadata":{"execution":{"iopub.status.busy":"2021-06-23T13:36:23.049495Z","iopub.execute_input":"2021-06-23T13:36:23.050039Z","iopub.status.idle":"2021-06-23T13:36:23.060945Z","shell.execute_reply.started":"2021-06-23T13:36:23.05Z","shell.execute_reply":"2021-06-23T13:36:23.060126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Fitting","metadata":{}},{"cell_type":"markdown","source":"### Logistic Regression","metadata":{}},{"cell_type":"code","source":"log_model = LogisticRegression(max_iter=700)\n\nfit_model(log_model)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T13:36:23.062146Z","iopub.execute_input":"2021-06-23T13:36:23.062816Z","iopub.status.idle":"2021-06-23T13:36:23.391129Z","shell.execute_reply.started":"2021-06-23T13:36:23.062774Z","shell.execute_reply":"2021-06-23T13:36:23.390223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### K-nearest Neighbors","metadata":{}},{"cell_type":"code","source":"knn_model = KNeighborsClassifier(n_neighbors=50)\n\nfit_model(knn_model)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T13:36:23.392461Z","iopub.execute_input":"2021-06-23T13:36:23.392729Z","iopub.status.idle":"2021-06-23T13:36:23.574181Z","shell.execute_reply.started":"2021-06-23T13:36:23.392701Z","shell.execute_reply":"2021-06-23T13:36:23.573406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Decision Tree Classifier","metadata":{}},{"cell_type":"code","source":"tree_model = DecisionTreeClassifier(criterion='entropy', max_depth=5, max_leaf_nodes=10)\n\nfit_model(tree_model)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T13:36:23.575085Z","iopub.execute_input":"2021-06-23T13:36:23.575361Z","iopub.status.idle":"2021-06-23T13:36:23.749598Z","shell.execute_reply.started":"2021-06-23T13:36:23.575329Z","shell.execute_reply":"2021-06-23T13:36:23.748594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Random Forest Classifier","metadata":{}},{"cell_type":"code","source":"rf_model = RandomForestClassifier(n_estimators=1000, criterion = \"entropy\")\n\nfit_model(rf_model)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T13:36:23.750761Z","iopub.execute_input":"2021-06-23T13:36:23.75101Z","iopub.status.idle":"2021-06-23T13:36:25.537164Z","shell.execute_reply.started":"2021-06-23T13:36:23.750985Z","shell.execute_reply":"2021-06-23T13:36:25.536057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb = XGBClassifier(max_depth = 100,learning_rate = .07, booster = \"gblinear\" )\n\nfit_model(xgb)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T13:36:25.538449Z","iopub.execute_input":"2021-06-23T13:36:25.5387Z","iopub.status.idle":"2021-06-23T13:36:25.763275Z","shell.execute_reply.started":"2021-06-23T13:36:25.538676Z","shell.execute_reply":"2021-06-23T13:36:25.762412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion\n\nOut of all the models that we tried, the xgb classifier outperformed the rest. It out-performed the baseline model accuracy by about 40%. It performed the best at predicting people who are more risk of having a heart attack. We had a very small data set to work with and a very small test set to work with so we should question how well this model may do on new unforseen data. ","metadata":{}},{"cell_type":"markdown","source":"## Next Steps\n\nThe next step would be to collect more data. We have a very small data set to work with and there is a lot of potential to make a great model if we had more data to train it on. With an increase in records, Deep learning methods would also be interesting to apply here. ","metadata":{}}]}