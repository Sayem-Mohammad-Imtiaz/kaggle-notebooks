{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom pandas import Series, DataFrame\nimport numpy as np\n\n# Visualization\nimport matplotlib.pylab as plt\nfrom matplotlib import font_manager, rc\nimport seaborn as sns\nplt.style.use(['fivethirtyeight'])\n\n%matplotlib inline\n\n#EDA\n#pip install -U pandas-profiling[notebook]\nfrom pandas_profiling import ProfileReport\n# how to use it\n#profile = ProfileReport(df, title='Pandas Profiling Report')\n\n\n#default theme\nsns.set(context='notebook', style='darkgrid', palette='deep', font='sans-serif', font_scale=1, color_codes=False, rc=None)\n\n# Preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Hyperparameter Optimization\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom bayes_opt import BayesianOptimization\n\n# Modeling\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC \nfrom catboost import CatBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\n\n#Cross-validation\nfrom sklearn.model_selection import StratifiedKFold, KFold\n\n#Ensembling\nfrom sklearn.ensemble import VotingClassifier\nfrom vecstack import StackingTransformer\nfrom vecstack import stacking\n\n# Evaluation\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\n\n# Utility\nimport os\nimport time\nimport random\nimport warnings; warnings.filterwarnings(\"ignore\")\nfrom IPython.display import Image\nimport pickle\nfrom tqdm import tqdm\nimport platform\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <span style=\"color:green\"> Objective: </span>\n### <span style=\"color:green\"> Predict which of the customers will have their loan approved. </span>"},{"metadata":{},"cell_type":"markdown","source":"### Let's get the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(r\"../input/loan-prediction-problem-dataset/train_u6lujuX_CVtuZ9i.csv\")\ntest = pd.read_csv(r\"../input/loan-prediction-problem-dataset/test_Y3wMUE5_7gLdaTN.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Briefly check the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"train:\", train.size, \"\\ntest:\", test.size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### We have up to 7! object type features. We will have to deal with them later."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe(include=\"all\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.describe(include= \"all\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## (quick) Data Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"#check the EDA part where all the packages are\nprofile = ProfileReport(train, title = \"Train data\")\nprofile","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The great thing about this tool is that is quickly lets you see all the analysis we did before.\n\nIt presents it to you in an simple and easy to read way. Of course, it gives you an overall report, not a specific relationship you can find by making your own graphs. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Nan values\ntrain.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Okay! there are some Nan values and we have the object type.  That just means one thing:\n\n## Data cleaning!"},{"metadata":{},"cell_type":"markdown","source":"### Strings"},{"metadata":{},"cell_type":"markdown","source":"From the .head function, We have four string columns: Gender, Married,Education and Property area. Let's check how they are."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'TRAIN DATA \\nGender: \\n{train[\"Gender\"].value_counts()},\\nMarried: {train[\"Married\"].value_counts()},\\nEducation: {train[\"Education\"].value_counts()}, \\nProperty: {train[\"Property_Area\"].value_counts()}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'TEST DATA \\nGender: \\n{test[\"Gender\"].value_counts()},\\nMarried: {test[\"Married\"].value_counts()},\\nEducation: {test[\"Education\"].value_counts()}, \\nProperty: {test[\"Property_Area\"].value_counts()}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will deal with them with the excellent code from Yonatan Rabinovich, on his \"Loan Prediction Dataset ML Project\" notebook.\n\n\ncheck it here: https://www.kaggle.com/yonatanrabinovich/loan-prediction-dataset-ml-project"},{"metadata":{},"cell_type":"markdown","source":"We could use panda's pd.get_dummies to create dummies out of the categorical values. We may make a comparison between that method and assigning a number to the categories."},{"metadata":{"trusted":true},"cell_type":"code","source":"#converting categorical values to numbers\n\nto_numeric = {'Male': 1, 'Female': 2,\n'Yes': 1, 'No': 2,\n'Graduate': 1, 'Not Graduate': 2,\n'Urban': 3, 'Semiurban': 2,'Rural': 1,\n'Y': 1, 'N': 0,\n'3+': 3}\n\n# adding the new numeric values from the to_numeric variable to both datasets\ntrain = train.applymap(lambda lable: to_numeric.get(lable) if lable in to_numeric else lable)\ntest = test.applymap(lambda lable: to_numeric.get(lable) if lable in to_numeric else lable)\n\n# convertind the Dependents column\nDependents_ = pd.to_numeric(train.Dependents)\nDependents__ = pd.to_numeric(test.Dependents)\n\n# dropping the previous Dependents column\ntrain.drop(['Dependents'], axis = 1, inplace = True)\ntest.drop(['Dependents'], axis = 1, inplace = True)\n\n# concatination of the new Dependents column with both datasets\ntrain = pd.concat([train, Dependents_], axis = 1)\ntest = pd.concat([test, Dependents__], axis = 1)\n\n# checking the our manipulated dataset for validation\nprint(f\"training set (row, col): {train.shape}\\n\\ntesting set (row, col): {test.shape}\\n\")\nprint(train.info(), \"\\n\\n\", test.info())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Nan"},{"metadata":{},"cell_type":"markdown","source":"For this, we can: \n\n1. Get rid of the corresponding nan values.\n2. Get rid of the whole feature.\n3. Set the values to some value (zero, the mean, the median, etc.)."},{"metadata":{},"cell_type":"markdown","source":"Remember:\n    \n    Theoretically, 25 to 30% is the maximum missing values are allowed, beyond which we might want to drop the variable from analysis. \n    \n in this case is no problem, but is a nice reminder"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.impute import SimpleImputer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#let's imput with the median for numeric features using the median\nfor_numeric = SimpleImputer(strategy= 'median')\na = for_numeric.fit_transform(train[[\"LoanAmount\", \"Loan_Amount_Term\", \"Credit_History\"]])\na = pd.DataFrame(a,columns= [\"LoanAmount\", \"Loan_Amount_Term\", \"Credit_History\"])\ntrain[[\"LoanAmount\", \"Loan_Amount_Term\", \"Credit_History\"]] = a","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now let's imput the object type features with most_frequent categorical varaibles\nfor_object = SimpleImputer(strategy= \"most_frequent\")\nb = for_object.fit_transform(train[[\"Gender\", 'Married', \"Dependents\", \"Self_Employed\"]])\nb = pd.DataFrame(b, columns= [\"Gender\", 'Married', \"Dependents\", \"Self_Employed\"])\ntrain[[\"Gender\", 'Married', \"Dependents\", \"Self_Employed\"]] = b","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, the same but with the TEST dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"for_numeric = SimpleImputer(strategy= 'median')\na = for_numeric.fit_transform(test[[\"LoanAmount\", \"Loan_Amount_Term\", \"Credit_History\"]])\na = pd.DataFrame(a,columns= [\"LoanAmount\", \"Loan_Amount_Term\", \"Credit_History\"])\ntest[[\"LoanAmount\", \"Loan_Amount_Term\", \"Credit_History\"]] = a","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for_object = SimpleImputer(strategy= \"most_frequent\")\nb = for_object.fit_transform(test[[\"Gender\", 'Married', \"Dependents\", \"Self_Employed\"]])\nb = pd.DataFrame(b, columns= [\"Gender\", 'Married', \"Dependents\", \"Self_Employed\"])\ntest[[\"Gender\", 'Married', \"Dependents\", \"Self_Employed\"]] = b","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"test.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's quickly drop \"Loan_ID\" since we don't need it\ntrain = train.drop(\"Loan_ID\", axis= 1)\ntrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = test.drop(\"Loan_ID\", axis = 1)\ntest","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### okay, we are set, we can go to the \n## Models!"},{"metadata":{"trusted":true},"cell_type":"code","source":"#let's divide in X and y. Since we are going to predict the \"Loan_status\", let's take it out\nX = train.drop([\"Loan_Status\"], axis = 1)\nX","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train[[\"Loan_Status\"]]\ny","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Divide the train data set into train and test to teach and test the models\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size =0.03, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's try many different models first"},{"metadata":{"trusted":true},"cell_type":"code","source":"#We will use 6 different models with random sets of hyperparameters \n#and will pass all of them in a dictionary that will be inside a lsit\nclfs = [\n    (\n        KNeighborsClassifier(n_jobs= -1),\n        {'n_neighbors' : [5, 6, 7],\n         'weights': ['uniform', 'distance']\n        }\n    ),\n    (\n      XGBClassifier(n_jobs= -1, random_state= 42),\n        {'learning_rate' : [0.002, 0.001, 0.01],\n         'max_depth' : [5, 10, 15, 20],\n         'n_estimators' : [7000, 6500, 7500],\n         'reg_alpha' : [0.9, 0.8, 1],\n         'reg_lambda' : [0.9, 0.8, 1],\n         'subsample' : [0.9, 0.8, 1],\n         'metric_period' : [50, 100, 50]       \n        }\n    ),\n    (\n        LGBMClassifier(n_jobs = -1, random_state = 42),\n        {'learning_rate': [0.002, 0.0045, 0.02],\n         'num_iteration': [10000, 9000, 11000],\n         'n_estimators' : [50, 100, 150, 200],\n         'boosting_type' : ['gbdt', 'dart', 'goss'],\n         'lambda_l1': [4.6, 5, 6],\n         'lambda_l2': [1.9, 2, 3],\n         'num_leaves' : [50, 102, 150],\n         'min_child_samples' : [10, 20, 30]\n         }\n    ),\n# (\n#         LogisticRegression(random_state=0),  #I avoided calculating these models for time reasons. \n#         {'C': np.arange(0.1, 1.1, 0.1),      \n#          'penalty': ['l1','l2']}\n#     ),\n#     (\n#         RandomForestClassifier(random_state=0),\n#         {'n_estimators': [100,200,300],\n#          'max_depth': [3,4,5],\n#          'max_features': (np.arange(0.5, 1.0, 0.1))}\n#     ),\n    (\n        MLPClassifier(random_state= 42),\n        {'hidden_layer_sizes' : [50, 100, 200],\n         'activation' : ['identity', 'logistic', 'tanh', 'relu'],\n         'solver': ['lbfgs', 'sgd', 'adam'],\n         'alpha' : [0.002, 0.0001, 0.01],\n         'learning_rate' : ['constant', 'invscaling', 'adaptive'],\n         'learning_rate_init' : [0.002, 0.005, 0.01, 0.1],\n         'max_iter' : [100, 500, 1000],\n         'momentum' : [0.7, 0.64, 0.8, 0.9]  \n        }  \n    )\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's use stratified cross validation for improving our score.\nstra = StratifiedKFold(n_splits= 5, random_state= 42)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"clfs_tuned = []  \nfor clf, param_grid in tqdm(clfs):\n    start = time.time()\n    iterations =  1 if clfs in ['MLPClassifier'] else 1 #MLP takes more time to compute, so let's reduce the amount of iterations for that model\n    rand_search = RandomizedSearchCV(clf, param_grid,  n_iter= iterations, random_state=42,\n                                     scoring='roc_auc', return_train_score= True,\n                                     cv= stra, n_jobs=-1)\n    rand_search.fit(x_train, y_train)\n    clf_name = type(clf).__name__\n    clf_score = rand_search.score(x_test, y_test)\n    print('{:30s} {:30f} {:.1f}'.format(clf_name, clf_score, time.time() - start))\n    clfs_tuned.append((clf_name, rand_search.best_params_, clf_score)) #storing the name of the model, \n                                                                        #best hyperparameters and score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#because we are going to get a table to check the best results, let's make in a way so we see all the content of the table, \n#by setting the max display\npd.set_option('display.max_columns', None)\npd.set_option('display.max_colwidth', -1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(clfs_tuned)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    Now that we now the best models we can construct and fit the best model\n    "},{"metadata":{"trusted":true},"cell_type":"code","source":"best_model = XGBClassifier(subsample =  1, reg_lambda = 0.8, reg_alpha = 1, n_estimators= 6500, \n                           metric_period= 100, max_depth= 20, learning_rate= 0.002)\nbest_model.fit(x_train, y_train)\nprediction = best_model.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Again, I found the kernel from Rabinovich quite useful with this little piece of code that I didn't know of:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, prediction))\nXGB_report = accuracy_score(prediction, y_test)\nprint(f\"{round(XGB_report*100,2)}% Accurate\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Thanks for this small piece of code to get a confusion matrix and accuracy so easily!"},{"metadata":{},"cell_type":"markdown","source":"## Check Feature importance"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = DecisionTreeClassifier(max_depth= 5, random_state= 42)\nclf.fit(x_train, y_train).score(x_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = range(1,10)\ny1 = [DecisionTreeClassifier(max_depth=i, random_state=42).fit(x_train, y_train).score(x_train, y_train) for i in x]\ny2 = [DecisionTreeClassifier(max_depth=i, random_state=42).fit(x_train, y_train).score(x_test, y_test) for i in x]\nplt.plot(x,y1,label='train')\nplt.plot(x,y2,label='test')\nplt.xlabel('depth of tree')\nplt.ylabel('accuracy')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Now,let's use the .feature_importances_ method"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.barplot(x=clf.feature_importances_, y= train.columns[1:])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## It appears we are doing some over-fitting with our model. There are many ways to correct this:\n\n### 1.Cross-validation (did it) ✔\n### 2.Train with more data (That is true. Our dataset doesn't have that much data) ✔\n### 3.Remove features by checking relevance. (Done it. We observed that Property area seems to be the most relevant feature)  \n### 4.Early Stopping (This could be done with XGboost with the parameter early_stopping_rounds= #)\n### 5.Regularization (tunning hyperparameters. Done it with Randomized Search CV)\n### 6.Ensembling (Will update this later)\n\n### For now, we have an almost 90% accuracy model. "},{"metadata":{},"cell_type":"markdown","source":"## Export"},{"metadata":{"trusted":true},"cell_type":"code","source":"output = pd.DataFrame.from_dict([{'y_test':y_test, 'prediction': prediction}]) #due to the nature of y_test we pass it as a list inside dict\noutput.to_csv('prediction.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <span style=\"color: green\"> NOTE: </span>\n    \nI will updtate the notebook to give a more complete analysis of the data base. \n\nFor now, I hope you learned to do some easy Exploratory Data Analysis and Randomized Search with multiple models at once. \n\nIf you found the notebook useful, please upvote.\n\nAnd if you have any question or found some errors, let me know! Thanks for reading!!"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}