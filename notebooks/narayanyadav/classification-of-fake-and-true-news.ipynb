{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-04T14:08:43.833242Z","iopub.execute_input":"2021-07-04T14:08:43.833561Z","iopub.status.idle":"2021-07-04T14:08:43.843128Z","shell.execute_reply.started":"2021-07-04T14:08:43.83353Z","shell.execute_reply":"2021-07-04T14:08:43.842091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>Steps for classification fake and True news</h2>\n<ol>\n    <li>load the dataset</li>\n      <li>Data Preprocessing</li>\n    <ul>\n        <li>Checking missing values</li>\n         <li>Remove link from news text</li>\n         <li>Remove Punctuation</li>\n         <li>Remove Stopwords</li>\n         <li>Perform TFIDFVectorizer</li>\n    </ul>\n      <li>Create a Model</li>\n      <li>Test the Model</li>\n    </ol>","metadata":{}},{"cell_type":"markdown","source":"<h1>1. Load Dataset</h1>","metadata":{}},{"cell_type":"code","source":"\"\"\"\"import the dataset\"\"\"\ndata_fake = pd.read_csv(\"../input/fake-and-real-news-dataset/Fake.csv\")\ndata_true = pd.read_csv(\"../input/fake-and-real-news-dataset/True.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-07-04T13:47:14.359914Z","iopub.execute_input":"2021-07-04T13:47:14.360276Z","iopub.status.idle":"2021-07-04T13:47:16.391752Z","shell.execute_reply.started":"2021-07-04T13:47:14.360243Z","shell.execute_reply":"2021-07-04T13:47:16.390944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"insert the output(target) column in dataset\"\"\"\ndata_fake['target'] = 'Fake'\ndata_true['target'] = 'True'","metadata":{"execution":{"iopub.status.busy":"2021-07-04T13:47:25.63899Z","iopub.execute_input":"2021-07-04T13:47:25.639371Z","iopub.status.idle":"2021-07-04T13:47:25.650435Z","shell.execute_reply.started":"2021-07-04T13:47:25.639336Z","shell.execute_reply":"2021-07-04T13:47:25.649522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_fake.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T13:47:27.789501Z","iopub.execute_input":"2021-07-04T13:47:27.789838Z","iopub.status.idle":"2021-07-04T13:47:27.811788Z","shell.execute_reply.started":"2021-07-04T13:47:27.789808Z","shell.execute_reply":"2021-07-04T13:47:27.810685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_true.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T13:47:30.00474Z","iopub.execute_input":"2021-07-04T13:47:30.005204Z","iopub.status.idle":"2021-07-04T13:47:30.033Z","shell.execute_reply.started":"2021-07-04T13:47:30.00516Z","shell.execute_reply":"2021-07-04T13:47:30.032151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"concat both the dataset in one dataset\"\"\"\ndata = pd.concat([data_fake,data_true],axis=0,ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T13:50:47.09437Z","iopub.execute_input":"2021-07-04T13:50:47.094694Z","iopub.status.idle":"2021-07-04T13:50:47.112859Z","shell.execute_reply.started":"2021-07-04T13:50:47.094666Z","shell.execute_reply":"2021-07-04T13:50:47.112109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T13:50:49.768762Z","iopub.execute_input":"2021-07-04T13:50:49.769106Z","iopub.status.idle":"2021-07-04T13:50:49.781272Z","shell.execute_reply.started":"2021-07-04T13:50:49.769069Z","shell.execute_reply":"2021-07-04T13:50:49.780166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# count the number of fake and True news. \ndata['target'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T13:50:51.458943Z","iopub.execute_input":"2021-07-04T13:50:51.459308Z","iopub.status.idle":"2021-07-04T13:50:51.47483Z","shell.execute_reply.started":"2021-07-04T13:50:51.459277Z","shell.execute_reply":"2021-07-04T13:50:51.473893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(data['target'])","metadata":{"execution":{"iopub.status.busy":"2021-07-04T13:50:56.679451Z","iopub.execute_input":"2021-07-04T13:50:56.679773Z","iopub.status.idle":"2021-07-04T13:50:56.835322Z","shell.execute_reply.started":"2021-07-04T13:50:56.679744Z","shell.execute_reply":"2021-07-04T13:50:56.834344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1>2. Data Preprocessing</h1>\n&nbsp<h2>Checking missing or None value</h2>","metadata":{}},{"cell_type":"code","source":"\"\"\"checking whether any missing or empty text row is not present in dataset\"\"\"\ndata['text'].isna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T13:51:03.234219Z","iopub.execute_input":"2021-07-04T13:51:03.235981Z","iopub.status.idle":"2021-07-04T13:51:03.252376Z","shell.execute_reply.started":"2021-07-04T13:51:03.235723Z","shell.execute_reply":"2021-07-04T13:51:03.25154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"there is no NaN cell in text","metadata":{}},{"cell_type":"markdown","source":"<h2>Remove links</h2>","metadata":{}},{"cell_type":"code","source":"\"\"\"check whether text column is full link and remove it\"\"\"\ndef remove_link_from(text):\n    txt = ''\n    text = text.split(' ')\n    for tx in text:\n        if ('http' in text) or (\".com\" in text) or ('https' in text) or ('.in' in text) or ('bit.ly' in text) or ('tiny' in text):\n            continue\n        else:\n            txt = txt+tx\n    return txt","metadata":{"execution":{"iopub.status.busy":"2021-07-04T14:08:59.78711Z","iopub.execute_input":"2021-07-04T14:08:59.78743Z","iopub.status.idle":"2021-07-04T14:08:59.792227Z","shell.execute_reply.started":"2021-07-04T14:08:59.787402Z","shell.execute_reply":"2021-07-04T14:08:59.791238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"appply it to text column\"\"\"\ndata['text'] = data['text'].apply(remove_link_from)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T14:09:01.772319Z","iopub.execute_input":"2021-07-04T14:09:01.772652Z","iopub.status.idle":"2021-07-04T14:09:01.86061Z","shell.execute_reply.started":"2021-07-04T14:09:01.772621Z","shell.execute_reply":"2021-07-04T14:09:01.859717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\n# remove digit\ndef remove_digit(data):\n    regen_data = re.sub('[^a-zA-Z]',' ',data)\n    return regen_data.lower()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T14:09:21.387997Z","iopub.execute_input":"2021-07-04T14:09:21.388362Z","iopub.status.idle":"2021-07-04T14:09:21.392392Z","shell.execute_reply.started":"2021-07-04T14:09:21.388331Z","shell.execute_reply":"2021-07-04T14:09:21.391549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['text'] = data['text'].apply(remove_digit)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T14:09:24.137306Z","iopub.execute_input":"2021-07-04T14:09:24.137624Z","iopub.status.idle":"2021-07-04T14:09:26.970484Z","shell.execute_reply.started":"2021-07-04T14:09:24.137596Z","shell.execute_reply":"2021-07-04T14:09:26.96938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>Remove Punctution</h2>","metadata":{}},{"cell_type":"code","source":"\"\"\"now remove the punctuation marks\"\"\"\nimport string\npnc = string.punctuation\npnc+= '\\n \\n\\n \\t \\t\\t \\r \\b'\n\n\ndef remove_punctuation(txt):\n    txt = txt.split()\n    txt = [word.lower() for word in txt if word not in pnc]\n    return ' '.join(txt)\n\ndata['text'] = data['text'].apply(remove_punctuation)\n        \n        ","metadata":{"execution":{"iopub.status.busy":"2021-07-04T14:09:35.079475Z","iopub.execute_input":"2021-07-04T14:09:35.079883Z","iopub.status.idle":"2021-07-04T14:09:36.107189Z","shell.execute_reply.started":"2021-07-04T14:09:35.079847Z","shell.execute_reply":"2021-07-04T14:09:36.10634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"check number of text with empty entry\"\"\"\ndata[data['text'] == ' ']","metadata":{"execution":{"iopub.status.busy":"2021-07-04T14:09:38.267746Z","iopub.execute_input":"2021-07-04T14:09:38.268109Z","iopub.status.idle":"2021-07-04T14:09:38.283837Z","shell.execute_reply.started":"2021-07-04T14:09:38.26807Z","shell.execute_reply":"2021-07-04T14:09:38.283094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"remove all stopwords from the <b>text</b> feature of the dataset, there are no need to stopwords in model.provide parameter in tfidfvectorizer <b>stop","metadata":{"execution":{"iopub.status.busy":"2021-07-04T03:43:29.475782Z","iopub.execute_input":"2021-07-04T03:43:29.476354Z","iopub.status.idle":"2021-07-04T03:43:29.480863Z","shell.execute_reply.started":"2021-07-04T03:43:29.476252Z","shell.execute_reply":"2021-07-04T03:43:29.480219Z"}}},{"cell_type":"code","source":"\"\"\"split independent and dependent data\"\"\"\nX = data['text']\ny = data['target']","metadata":{"execution":{"iopub.status.busy":"2021-07-04T14:09:43.962936Z","iopub.execute_input":"2021-07-04T14:09:43.963302Z","iopub.status.idle":"2021-07-04T14:09:43.967537Z","shell.execute_reply.started":"2021-07-04T14:09:43.96327Z","shell.execute_reply":"2021-07-04T14:09:43.966579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"perform label encoding\"\"\"\ny = pd.get_dummies(y,drop_first=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T14:09:46.992723Z","iopub.execute_input":"2021-07-04T14:09:46.993092Z","iopub.status.idle":"2021-07-04T14:09:47.004573Z","shell.execute_reply.started":"2021-07-04T14:09:46.993036Z","shell.execute_reply":"2021-07-04T14:09:47.003363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"convert multidimention array to one-dim array with reshape function\"\"\"\ny = y.values.reshape(-1,)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T14:09:50.082719Z","iopub.execute_input":"2021-07-04T14:09:50.08308Z","iopub.status.idle":"2021-07-04T14:09:50.087903Z","shell.execute_reply.started":"2021-07-04T14:09:50.083018Z","shell.execute_reply":"2021-07-04T14:09:50.086368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score,classification_report,confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2021-07-04T14:09:51.722603Z","iopub.execute_input":"2021-07-04T14:09:51.722927Z","iopub.status.idle":"2021-07-04T14:09:51.964087Z","shell.execute_reply.started":"2021-07-04T14:09:51.722895Z","shell.execute_reply":"2021-07-04T14:09:51.963203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>Remove Stopword and Perform TFIDFVectorize opration</h2>","metadata":{}},{"cell_type":"code","source":"\"\"\"intialize a TfidVector\"\"\"\ntfvctor = TfidfVectorizer(stop_words='english',max_df=0.5)\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.20,random_state=10)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T14:09:57.207708Z","iopub.execute_input":"2021-07-04T14:09:57.208024Z","iopub.status.idle":"2021-07-04T14:09:57.220715Z","shell.execute_reply.started":"2021-07-04T14:09:57.207993Z","shell.execute_reply":"2021-07-04T14:09:57.219544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"perform fit Transform\"\"\"\nX_train = tfvctor.fit_transform(X_train)\nX_test = tfvctor.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T14:10:00.17274Z","iopub.execute_input":"2021-07-04T14:10:00.173085Z","iopub.status.idle":"2021-07-04T14:10:09.145309Z","shell.execute_reply.started":"2021-07-04T14:10:00.173032Z","shell.execute_reply":"2021-07-04T14:10:09.144372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1>3. Create Model and Test it</h1>","metadata":{}},{"cell_type":"markdown","source":"popuar algorithms that is used for binary classification.\n<ul>\n    <li>Logistic Regression</li>\n     <li>K-Nearest Neighbour</li>\n     <li>Decision tree classifier</li>\n     <li>Support Vector Machine</li>\n     <li>Naive bayes</li>\n    </ul>\n <h1>Logistic Regression</h1>","metadata":{}},{"cell_type":"code","source":"\"\"\"create Logistic Regression classification model \"\"\"\nlclassify = LogisticRegression()\n\"\"\"fit the model with train and test data\"\"\"\nlclassify.fit(X_train,y_train)\n\"\"\"predict x_test data\"\"\"\npred_data = lclassify.predict(X_test)\n\"\"\"calculate accuracy and classification_report\"\"\"\nacc = accuracy_score(y_test,pred_data)\ncnfm = confusion_matrix(y_test,pred_data)\ncr = classification_report(y_test,pred_data)\nprint(\"classification by Logistic Regression\")\nprint(\"Accuracy:\",acc)\nprint(\"confusion matrix: \\n\",cnfm)\nprint(\"classification report: \\n\",cr)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T14:10:19.533099Z","iopub.execute_input":"2021-07-04T14:10:19.533426Z","iopub.status.idle":"2021-07-04T14:10:38.69181Z","shell.execute_reply.started":"2021-07-04T14:10:19.533398Z","shell.execute_reply":"2021-07-04T14:10:38.690559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1>Naive Bayes</h1>","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\n\nNBclassify = MultinomialNB().fit(X_train, y_train)\npred_data = NBclassify.predict(X_test)\n\"\"\"calculate accuracy and classification_report\"\"\"\nNBacc = accuracy_score(y_test,pred_data)\nNBcnfm = confusion_matrix(y_test,pred_data)\nNBcr = classification_report(y_test,pred_data)\nprint(\"classification by Naive Bayes:\")\nprint(\"Accuracy:\",NBacc)\nprint(\"confusion matrix:\\n\",NBcnfm)\nprint(\"classification report:\\n\",NBcr)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T14:10:43.65746Z","iopub.execute_input":"2021-07-04T14:10:43.657785Z","iopub.status.idle":"2021-07-04T14:10:43.776202Z","shell.execute_reply.started":"2021-07-04T14:10:43.657754Z","shell.execute_reply":"2021-07-04T14:10:43.775185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h4>if you all find out this notebook helpful, upvotes it</h4>","metadata":{"execution":{"iopub.status.busy":"2021-07-04T04:18:01.910466Z","iopub.execute_input":"2021-07-04T04:18:01.910815Z","iopub.status.idle":"2021-07-04T04:18:01.915331Z","shell.execute_reply.started":"2021-07-04T04:18:01.910785Z","shell.execute_reply":"2021-07-04T04:18:01.914461Z"}}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}