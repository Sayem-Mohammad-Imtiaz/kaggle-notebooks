{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Netflix Dataset Solutions**\n\nThe objective of this notebook is to follow a step-by-step workflow, explaining each step and rationale for every decision we take during solution development. The main focus of our notebook is to provide Data acquisition, Data Exploration, Data Preprocessing, Model training and evaluation and Presentation and report writing, to provide the most optimal prediction of our chosen dataset.\n","metadata":{}},{"cell_type":"markdown","source":"**Workflow stages**\n\nThe competition solution workflow goes through seven stages described in the Data Science Solutions book.\n×\tQuestion or problem definition.\n×\tAcquire training and testing data.\n×\tWrangle, prepare, and cleanse the data.\n×\tAnalyze, identify patterns, and explore the data.\n×\tModel, predict and solve the problem.\n×\tVisualize, report, and present the problem solving steps and final solution.\n×\tSupply or submit the results.\n\nThe workflow indicates general sequence of how each stage may follow the other. However there are use cases with exceptions.\n×\tWe may combine multiple workflow stages. We may analyze by visualizing data.\n×\tPerform a stage earlier than indicated. We may analyze data before and after wrangling.\n×\tPerform a stage multiple times in our workflow. Visualize stage may be used multiple times.\n×\tDrop a stage altogether. We may not need supply stage to productize or service enable our dataset for a competition.\n","metadata":{}},{"cell_type":"markdown","source":"**Question and problem definition**\n*TV Shows and Movies listed on Netflix*\n\nThis dataset consists of TV shows and movies available on Netflix as of 2019. The dataset is collected from Flexible which is a third-party Netflix search engine.\nIn 2018, they released an interesting report which shows that the number of TV shows on Netflix has nearly tripled since 2010. The streaming service’s number of movies has decreased by more than 2,000 titles since 2010, while its number of TV shows has nearly tripled. It will be interesting to explore what all other insights can be obtained from the same dataset.\nIntegrating this dataset with other external datasets such as IMDB ratings, rotten tomatoes can also provide many interesting findings.\nInspiration\nSome of the interesting questions (tasks) which can be performed on this dataset -\n×\tUnderstanding what content is available in different countries\n×\tIdentifying similar content by matching text-based features\n×\tNetwork analysis of Actors / Directors and find interesting insights\n×\tIs Netflix has increasingly focusing on TV rather than movies in recent years.\n","metadata":{}},{"cell_type":"code","source":"#libraries Imported\n# data analysis and wrangling\nimport pandas as pd\nimport numpy as np\nimport random as rnd\nfrom datetime import datetime\nimport re\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n# machine learning\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#accquiring data\nnetflix_ds = pd.read_csv('../input/netflix-shows/netflix_titles.csv')\nnetflix_ds1=netflix_ds\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#analyze data columns\nprint(netflix_ds.columns.values)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Which features are categorical?**\nThese values classify the samples into sets of similar samples. Within categorical features are the values nominal, ordinal, ratio, or interval based? Among other things this helps us select the appropriate plots for visualization.\n•\tCategorical: Title, Type, and Show Id, Country, Description, Director, Cast, , Listed in.\n\n**Which features are numerical?**\nWhich features are numerical? These values change from sample to sample. Within numerical features are the values discrete, continuous or time series based? Among other things this helps us select the appropriate plots for visualization.\n•\tContinuous: Release Years.\n","metadata":{}},{"cell_type":"code","source":"netflix_ds.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preview the data from the start\nnetflix_ds.head()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preview the data from the end\nnetflix_ds.tail()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Which features are mixed data types?**\nThe data can be Numerical alphanumeric data within same feature. These are candidates for correcting goal.\n•\tRating, Duration, is a mix of numeric and alphanumeric data types. Show Id is alphanumeric.\n\n**Which features may contain errors or typos?\nWhich features contain blank, null or empty values?\nWhat are the data types for various features?**\nThis is harder to review for a large dataset, however reviewing a few samples from a smaller dataset may just tell us outright, which features may require correcting.\n•\tDirector, Cast, Release Year, date added, Country features may contain errors or typos as there are several ways used to describe a name including titles, round brackets, and quotes used for alternative or short names.\n\n**Which features may contain errors or typos?\nWhich features contain blank, null or empty values?\nWhat are the data types for various features?**\nThese will require correcting.\nDirector, Cast, Release Year, Date added features contain a number of null values in that order for the training dataset.\n\n**Which features may contain errors or typos?\nWhich features contain blank, null or empty values?\nWhat are the data types for various features?**\n•\tOne feature is integer.\n•\tEleven features are strings (object).\n","metadata":{}},{"cell_type":"code","source":"#datatype of columns\nnetflix_ds1=netflix_ds\nnetflix_ds.info()\nprint('_'*40)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**What is the distribution of numerical feature values across the samples?**\nThis helps us determine, among other early insights, how representative is the training dataset of the actual problem domain.\n•\tTotal samples are 7787.\n•\tRelease years with year 2013 with 1012 values is the most used\n","metadata":{}},{"cell_type":"code","source":"netflix_ds.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**What is the distribution of categorical features?**\n•\tShow id are unique across the dataset (count=unique=7787)\n•\tType variable as two possible values with 65% male (top=movie, freq=5377/count=7787).\n•\tCountry values have several duplicates across samples. Alternatively several passengers shared a cabin.\n•\tRating takes 14 possible values. TV-MA most popular\n•\tDate added feature has high ratio of duplicate values (unique=1565).\n","metadata":{}},{"cell_type":"code","source":"netflix_ds.describe(include=['O'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Assumptions based on data analysis**\n\nWe arrive at following assumptions based on data analysis done so far. We may validate these assumptions further before taking appropriate actions.\n\n**Correlating:**\n\nWe want to know how well does each feature correlate with type either movie or TV show. We want to do this early in our project and match these quick correlations with modeled correlations later in the project.\n\n**Completing:**\n\n1.\tWe may want to complete date added feature as it is definitely correlated to type.\n2.\tWe may want to complete the country feature as it may also correlate with type or another important feature.\n\n\n**Correcting:**\n\n1.\tCountry feature may be dropped from our analysis as it contains high ratio of duplicates (22%) and there may not be a correlation with type.\n2.\tCountry feature may be dropped as it is highly incomplete or contains many null values both in training and test dataset.\n3.\tShow id, title, description and listed after extracting important information from them, may be dropped from training dataset as it does not contribute to survival.\n4.\tTitle and description feature is relatively non-standard, may not contribute directly to type, so maybe dropped.\n\n**Creating:**\n\n1.\tWe may want to create a new feature called genre extracted from Listed in \n2.\tWe may want to engineer the rating feature to extract numbers as a new feature.\n3.\tWe may want to create new feature for continent. This turns a continuous numerical feature into an ordinal categorical feature.\n\n**Classifying:**\n\nWe may also add to our assumptions based on the problem description noted earlier.\n1.\tMovie (type=movie) were more likely to have made in United States.\n2.\tRating TV_MA was more likely to be movies.\n3.\tThe movie duration was more likely to be 90 min.\n","metadata":{}},{"cell_type":"code","source":"d2=netflix_ds[(netflix_ds['type']=='Movie')]\nd2.describe(include=['O'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Converting a categorical feature**\n\nNow we can convert features which contain strings to numerical values. This is required by most model algorithms. Doing so will also help us in achieving the feature completing goal. Let us start by converting type feature to a new feature called Gender where TV Show=1 and movie=2.\n\n","metadata":{}},{"cell_type":"code","source":"\n#conversion of a type column into numerical data\ntitle_mapping = {\"TV Show\": 1, \"Movie\": 0}\nnetflix_ds['type'] = netflix_ds['type'].map(title_mapping)\nnetflix_ds.head()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#conversion of a Duration into numerical data\nnetflix_ds['duration'] = netflix_ds.duration.str.extract('([0-9]+)', expand=False)\nnetflix_ds['duration'] = pd.to_numeric(netflix_ds['duration'])\nnetflix_ds.head()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#conversion of a Show Id into numerical data\nnetflix_ds['show_id'] = netflix_ds.show_id.str.extract('([0-9]+)', expand=False)\nnetflix_ds['show_id'] = pd.to_numeric(netflix_ds['show_id'])\nnetflix_ds.head()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#conversion of a rating column into numerical data\nnetflix_ds['rating'] = netflix_ds['rating'].astype(str)\nr = {'TV-MA':1, 'R': 2,  'PG-13':3, 'TV-14':4, 'TV-PG':5 ,'NR':6 ,'TV-G':7 ,'TV-Y':8 , 'TV-Y7':9, 'PG':10, 'G':11, 'NC-17': 12,  'TV-Y7-FV' :13, 'UR':14}\nnetflix_ds['rating'] = netflix_ds['rating'].map(r)\nnetflix_ds['rating'] = netflix_ds['rating'].fillna(1)\nnetflix_ds['rating'] = netflix_ds['rating'].astype(int)\nnetflix_ds.head()\nnetflix_ds.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#conversion of a date added into numerical data\nnetflix_ds['date_added'] = pd.to_datetime(netflix_ds['date_added'], errors= \"coerce\")\ndateTimeObj = datetime.now()\nnetflix_ds['date_added'] = pd.DatetimeIndex(netflix_ds['date_added']).year\ndf=netflix_ds['date_added'].value_counts().idxmax()\nprint(netflix_ds.date_added.describe())\nnetflix_ds['date_added'] = netflix_ds['date_added'].fillna(2019)\nnetflix_ds['date_added'] = netflix_ds['date_added'].astype(int)\nnetflix_ds.head()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Creating new feature extracting from existing**\n\nWe want to analyze if listed in feature can be engineered to extract genre and test correlation between genre and type, and continent from country  before dropping Name and listed in features.\n\n**Observations:**\n\nWhen we plot Genre, type, we note the following observations.\n\n* Most titles band Age groups accurately. For example: Master title has Age mean of 5 years.\n* Type among genre bands varies slightly.\n* Certain genre mostly movies like sports, children and family and rest are TV shows like drama.\n\n**Decision:**\nWe decide to retain the new Genre and continent from country feature for model training.\n","metadata":{}},{"cell_type":"code","source":"#Extraction of genre added from Listed in column\nnetflix_ds['genre']=netflix_ds.listed_in.str.extract(r'(Horror|Action & Adventure|Sci-Fi & Fantasy|Romantic|Comedies|Dramas|Sports|Trillers|Classic|cult|Children & Family|Science & Nature|Music)', expand=False)\ng={\"Horror\": 1,\"Action & Adventure\": 2,\"Sci-Fi & Fantasy\": 3, \"Romantic\": 4, \"Comedies\": 5, \"Dramas\": 6, \"Sports\": 7, \"Trillers\": 8, \"Classic\": 9, \"cult\": 10, \"Children & Family\": 11, \"Science & Nature\": 12}\n#Extraction of genre added into numerical data\nnetflix_ds['genre'] = netflix_ds['genre'].map(g)\nnetflix_ds['genre'] = netflix_ds['genre'].fillna(0)\nnetflix_ds['genre'] = netflix_ds['genre'].astype(int)\npd.crosstab(netflix_ds['genre'], netflix_ds['type'])\nnetflix_ds[[\"genre\", \"type\"]].groupby(['genre'], as_index=False).mean().sort_values(by='type', ascending=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Group Country in Continent\n#conversion of a country into numerical data\ncon=netflix_ds.country.unique()\nasia=['Russian', 'China', 'India', 'Kazakhstan','Saudi Arabia', 'Iran', 'Mongolia', 'Indonesia',  'Pakistan',  'Turkey',  'Myanmar',  'Afghanistan',  'Yemen',  'Thailand', 'Turkmenistan', 'Uzbekistan', 'Iraq', 'Japan', 'Vietnam','Malaysia' ,'Oman', 'Philippines','Laos', 'Kyrgyzstan', 'Nepal','Tajikistan','North Korea',' South Korea', 'Jordan', 'Azerbaijan','syria', 'combodia' ,'Bangladash', 'United Arab Emirates','Georgia', 'Sri Lanka', 'Bhutan', 'Taiwan', 'Armenia', 'Israel kuwait', 'Timor-Leste', 'Qatar', 'Lebanon','Cyprus', 'Palestine','Brunei','Bahrain','Singapore', 'Maldives']\neurope=['Germany','United Kingdom','France','Italy','Spain','Ukraine','Poland','Romania','Netherlands','Belgium','Czech Republic','Greece','Portugal','Sweden','Hungary','Belarus','Austria','Serbia','Switzerland','Bulgaria','Denmark','Finland','Slovakia','Norway','Ireland','Croatia','Moldova','Bosnia','Albania','Lithuania','North Macedonia','Slovenia','Latvia','Estonia','Montenegro','Luxembourg','Malta','Iceland','ndorra','Monaco','Liechtenstein','San Marino','Holy See']\nAfrica=['Ethiopia', 'Nigeria','Egypt','DR Congo','Tanzania','South Africa','Kenya','Uganda','Algeria','Sudan','Morocco','Angola','Mozambique','Ghana','Madagascar','Cameroon','Côte dIvoire','Niger','Burkina Faso','Mali','Malawi','Zambia','Senegal','Chad','Somalia','Zimbabwe','Guinea','Rwanda','Benin','Burundi','Tunisia','South Sudan','Togo','Sierra Leone','Libya','Congo','Liberia','Central African Republic','Mauritania','Eritrea','Namibia','Gambia','Botswana','Gabon','Lesotho','Guinea-Bissau','Equatorial Guinea','Mauritius','Eswatini','Djibouti','Co','Cabo Verde','Sao Tome','Seychelles']\nAustralia=['Micronesia', 'Fiji', 'Kiribati', 'Marshall Islands', 'Nauru', 'New Zealand', 'Palau', 'Papua New Guinea', 'Samoa','Solomon Islands', 'Tonga', 'Tuvalu','Vanuatu']\nAmerica=['Anguilla','United Kingdom','Barbuda','Argentina','Aruba','Netherlands','Bahamas','Barbados','Belize','Bermuda','Bolivia','Bonaire','Norway','Brazil','British Virgin Islands','Canada','Cayman Islands','Chile','Clipperton Island','Colombia','Costa Rica','Cuba','Curaçao','Dominica','Dominican Republic','Ecuador','El Salvador','Falkland Islands','French Guiana' ,'Greenland','Denmark','Grenada','Guadeloupe','Guatemala','Guyana','Haiti','Honduras','Jamaica','Martinique','Mexico','Montserrat','Navassa Island','United States','Nicaragua','Panama','Paraguay','Peru','Puerto Rico','Saba','Saint Barthélemy','Saint Kitts','Saint Lucia','Saint Martin','Saint Pierre','Saint Vincent','Sint Eustatius','Sint Maarten', 'South Georgia','South Sandwich Islands','Suriname','Trinidad','Tobago','Turks','Caicos Islands','Virgin Islands','United States of America','Uruguay','Venezuela']\nnetflix_ds['continenta']=netflix_ds.country.str.contains(r'(Russian|China|India|Kazakhstan|Saudi Arabia|Iran|Mongolia|Indonesia|Pakistan|Turkey|Myanmar|Afghanistan|Yemen|Thailand|Turkmenistan|Uzbekistan|Iraq|Japan|Vietnam|Malaysia|Oman|Philippines|Laos|Kyrgyzstan|Nepal|Tajikistan|North Korea|South Korea|Jordan|Azerbaijan|syria|combodia|Bangladash|United Arab Emirates|Georgia|Sri Lanka|Bhutan|Taiwan|Armenia|Israel|kuwait|Timor-Leste|Qatar|Lebanon|Cyprus|Palestine|Brunei|Bahrain|Singapore|Maldives)')\nnetflix_ds.loc[netflix_ds.continenta == True, \"continenta\"] = \"Asia\"\nnetflix_ds['continente']=netflix_ds.country.str.contains(r'(Germany|United Kingdom|France|Italy|Spain|Ukraine|Poland|Romania|Netherlands|Belgium|Czech Republic|Greece|Portugal|Sweden|Hungary|Belarus|Austria|Serbia|Switzerland|Bulgaria|Denmark|Finland|Slovakia|Norway|Ireland|Croatia|Moldova|Bosnia|Albania|Lithuania|North Macedonia|Slovenia|Latvia|Estonia|Montenegro|Luxembourg|Malta|Iceland|ndorra|Monaco|Liechtenstein|San Marino|Holy See)')\nnetflix_ds.loc[netflix_ds.continente == True, \"continente\"] = \"Europe\"\nnetflix_ds['continentaf']=netflix_ds.country.str.contains(r'(Ethiopia| Nigeria|Egypt|DR Congo|Tanzania|South Africa|Kenya|Uganda|Algeria|Sudan|Morocco|Angola|Mozambique|Ghana|Madagascar|Cameroon|Côte dIvoire|Niger|Burkina Faso|Mali|Malawi|Zambia|Senegal|Chad|Somalia|Zimbabwe|Guinea|Rwanda|Benin|Burundi|Tunisia|South Sudan|Togo|Sierra Leone|Libya|Congo|Liberia|Central African Republic|Mauritania|Eritrea|Namibia|Gambia|Botswana|Gabon|Lesotho|Guinea-Bissau|Equatorial Guinea|Mauritius|Eswatini|Djibouti|Co|Cabo Verde|Sao Tome|Seychelles)')\nnetflix_ds.loc[netflix_ds.continentaf == True, \"continentaf\"] = \"Africa\"\nnetflix_ds['continentau']=netflix_ds.country.str.contains(r'(Micronesia| Fiji|Kiribati|Marshall Islands|Nauru|New Zealand|Palau|Papua New Guinea|Samoa|Solomon Islands|Tonga|Tuvalu|Vanuatu)')\nnetflix_ds.loc[netflix_ds.continentau == True, \"continentau\"] = \"Australia\"\nnetflix_ds['continentam']=netflix_ds.country.str.contains(r'(Anguilla|United Kingdom|Barbuda|Argentina|Aruba|Netherlands|Bahamas|Barbados|Belize|Bermuda|Bolivia|Bonaire|Norway|Brazil|British Virgin Islands|Canada|Cayman Islands|Chile|Clipperton Island|Colombia|Costa Rica|Cuba|Curaçao|Dominica|Dominican Republic|Ecuador|El Salvador|Falkland Islands|French Guiana |Greenland|Denmark|Grenada|Guadeloupe|Guatemala|Guyana|Haiti|Honduras|Jamaica|Martinique|Mexico|Montserrat|Navassa Island|United States|Nicaragua|Panama|Paraguay|Peru|Puerto Rico|Saba|Saint Barthélemy|Saint Kitts|Saint Lucia|Saint Martin|Saint Pierre|Saint Vincent|Sint Eustatius|Sint Maarten| South Georgia|South Sandwich Islands|Suriname|Trinidad|Tobago|Turks|Caicos Islands|Virgin Islands|United States of America|Uruguay|Venezuela)')\nnetflix_ds.loc[netflix_ds.continentam == True, \"continentam\"] = \"America\"\n#conversion of a rating column into numerical data\n#conversion of a rating column into numerical data\ncontin = {'Asia':1, 'Europe': 2,  'Africa':3, 'Australia':4, 'America':5}\nnetflix_ds['continenta'] = netflix_ds['continenta'].map(contin)\nnetflix_ds['continente'] = netflix_ds['continente'].map(contin)\nnetflix_ds['continentaf'] = netflix_ds['continentaf'].map(contin)\nnetflix_ds['continentau'] = netflix_ds['continentau'].map(contin)\nnetflix_ds['continentam'] = netflix_ds['continentam'].map(contin)\nnetflix_ds['continenta'] = netflix_ds['continenta'].fillna(0)\nnetflix_ds['continente'] = netflix_ds['continente'].fillna(0)\nnetflix_ds['continentaf'] = netflix_ds['continentaf'].fillna(0)\nnetflix_ds['continentau'] = netflix_ds['continentau'].fillna(0)\nnetflix_ds['continentam'] = netflix_ds['continentam'].fillna(0)\nnetflix_ds['continent'] = netflix_ds['continenta']+netflix_ds['continente']+netflix_ds['continentaf']+netflix_ds['continentau']+netflix_ds['continentam']\nnetflix_ds['continent'] = netflix_ds['continent'].astype(int)\nnetflix_ds.loc[(netflix_ds.continent>5),'continent']=5\nnetflix_ds['continent'] = netflix_ds['continenta']+netflix_ds['continente']+netflix_ds['continentaf']+netflix_ds['continentau']+netflix_ds['continentam']\nnetflix_ds['continent'] = netflix_ds['continent'].astype(int)\nnetflix_ds.loc[(netflix_ds.continent>5),'continent']=5\nnetflix_ds = netflix_ds.drop(['continenta','continente','continentaf', 'continentau', 'continentam'], axis=1)\nnetflix_ds.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Analyze by pivoting features**\n\nTo confirm some of our observations and assumptions, we can quickly analyze our feature correlations by pivoting features against each other. We can only do so at this stage for features which do not have any empty values. It also makes sense doing so only for features which are categorical (type), ordinal (Duration) or discrete (Rating, date added and year released) type.\n•\tDate Added : We observe significant correlation (>1) among. We decide to include this feature in our model.\n","metadata":{}},{"cell_type":"code","source":"#Pivot date _added\nnetflix_ds[['date_added', 'type']].groupby(['date_added'], as_index=False).mean().sort_values(by='type', ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Pivot Release year\nnetflix_ds[['release_year', 'type']].groupby(['release_year'], as_index=False).mean().sort_values(by='type', ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Pivot Continent\nnetflix_ds[['continent', 'type']].groupby(['continent'], as_index=False).mean().sort_values(by='type', ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#pivot Rating\nnetflix_ds[['rating', 'type']].groupby(['rating'], as_index=False).mean().sort_values(by='type', ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Pivot Genre\nnetflix_ds[['genre', 'type']].groupby(['genre'], as_index=False).mean().sort_values(by='type', ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#pivot Duration\nnetflix_ds[['genre', 'type']].groupby(['genre'], as_index=False).mean().sort_values(by='type', ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Analyze by visualizing data**\n\nLet us start by understanding correlations between numerical features and our solution goal (type). A histogram chart is useful for analyzing continuous numerical variables like date added where extracting there year will help solve problem. The histogram can indicate distribution of samples using automatically. Note that x-axis in histogram visualizations represents the count of samples.\n\n**Observations:**\n\n•\t2019 most movies where added.\n•\tOldest passengers (Age = 80) survived.\n•\t2009 to 2012 only movies were added.\n•\tMost samples are in 1925 to 2021 range.\n•\tRange can be quite complex as int numbers presents date\n\n**Decisions:**\n\nThis simple analysis confirms our assumptions as decisions for subsequent workflow stages.\n•\tWe should consider date added in our model training.\n•\tComplete the date added feature for null values by replacing them with the most frequent.\n•\tWe should extract year from date added to simplify.\n","metadata":{}},{"cell_type":"code","source":"#Correlating numerical features: type (Tv show or movie) and date added on Netflix\nh2 = sns.FacetGrid(netflix_ds, col='type')\nh2.map(plt.hist, 'date_added', bins=5)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Correlating numerical and ordinal features**\n\nWe can combine multiple features for identifying correlations using a single plot. This can be done with numerical and categorical features which have numeric values.\n\n**Observations:**\n\n•\tThe description is useless to our data so we drop it.\n•\tThe country can be  quit long so w have grouped it into a new column continent\n•\tThe genre is extracted from listed in as it can tell more about the type  \n•\tFrom release year 1942 1984 most of the type released were movies \n\n**Decisions:**\n\n•\tConsider release year for model training.\n•\tDuration\n","metadata":{}},{"cell_type":"code","source":"#Correlating numerical features: type (Tv show or movie) and release year on Netflix\nh2 = sns.FacetGrid(netflix_ds, col='type')\nh2.map(plt.hist, 'release_year', bins=5)\nh2 = sns.FacetGrid(netflix_ds, col='type')\nh2.map(plt.hist, 'duration', bins=5)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Correlating categorical features:**\n\nNow we can correlate categorical features with our solution goal.\n\n**Observations:**\n\n•\tMost rating categories are movies and are more.\n•\tThe genre can help us identify type either movie or TV show.\n\n**Decisions:**\n\n•\tAdd Rating feature to model training.\n•\tAdd Genre feature to model training.\n","metadata":{}},{"cell_type":"code","source":"#Correlating numerical features: type (Tv show or movie) and Rating and genre on Netflix\nh2 = sns.FacetGrid(netflix_ds, col='type')\nh2.map(plt.hist, 'rating', bins=5)\nh2 = sns.FacetGrid(netflix_ds, col='type')\nh2.map(plt.hist, 'genre', bins=5)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Wrangle data**\n\nWe have collected several assumptions and decisions regarding our datasets and solution requirements. So far we did not have to change a single feature or value to arrive at these. Let us now execute our decisions and assumptions for correcting, creating, and completing goals.\n\n**Correcting by dropping features**\n\nThis is a good starting goal to execute. By dropping features we are dealing with fewer data points. Speeds up our notebook and eases the analysis.\nBased on our assumptions and decisions we want to drop the description, title, show id, listd in country director and cast after extracting useful information.\n","metadata":{}},{"cell_type":"code","source":"#Dropping Of Unwanted Columns\nprint(\"Before\", netflix_ds.shape)\nnetflix_ds = netflix_ds.drop(['title','country','cast','director', 'listed_in', 'description'], axis=1)\n\"After\", netflix_ds.shape\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#After complete conversion into numerical data\nnetflix_ds.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Model, predict and solve**\n\nNow we are ready to train a model and predict the required solution. There are 60+ predictive modeling algorithms to choose from. We must understand the type of problem and solution requirement to narrow down to a select few models which we can evaluate. Our problem is a classification and regression problem. We want to identify relationship between output (type TV show or movie) with other variables or features (Genre, continent, year...). We are also performing a category of machine learning which is called supervised learning as we are training our model with a given dataset. With these two criteria - Supervised Learning plus Classification and Regression, we can narrow down our choice of models to a few. These include:\n\n×\tLogistic Regression\n×\tKNN or k-Nearest Neighbors\n×\tSupport Vector Machines\n×\tNaive Bayes classifier\n×\tDecision Tree\n×\tRandom Forrest\n×\tPerceptron\n×\tArtificial neural network\n×\tRVM or Relevance Vector Machine\n","metadata":{}},{"cell_type":"code","source":"#divide data into train and test\n#model Data:\nfeature_cols = ['continent', 'date_added','release_year', 'rating','duration','genre']\nX = netflix_ds[feature_cols] # Features\ny = netflix_ds.type # Target variable\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=0)# Logistic Regression\nX_train.shape, y_train.shape, X_test.shape\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Logistic Regression Algorithm\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\nY_pred = logreg.predict(X_test)\nacc_log = round(logreg.score(X_train, y_train) * 100, 2)\nprint(acc_log)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#corelation b?w columns\ncoeff_df = pd.DataFrame(netflix_ds.columns.delete(0))\ncoeff_df.columns = ['Feature']\ncoeff_df[\"Correlation\"] = pd.Series(logreg.coef_[0])\ncoeff_df.sort_values(by='Correlation', ascending=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#svc algorithm:\nsvc = SVC()\nsvc.fit(X_train, y_train)\nY_pred = svc.predict(X_test)\nacc_svc = round(svc.score(X_train, y_train) * 100, 2)\nprint(acc_svc)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#KNN algorithm:\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, y_train)\nY_pred = knn.predict(X_test)\nacc_knn = round(knn.score(X_train, y_train) * 100, 2)\nprint(acc_knn)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Naive Bayes algorithm:\ngaussian = GaussianNB()\ngaussian.fit(X_train, y_train)\nY_pred = gaussian.predict(X_test)\nacc_gaussian = round(gaussian.score(X_train, y_train) * 100, 2)\nprint(acc_gaussian)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Preceptron algorithm:\nperceptron = Perceptron()\nperceptron.fit(X_train, y_train)\nY_pred = perceptron.predict(X_test)\nacc_perceptron = round(perceptron.score(X_train, y_train) * 100, 2)\nprint(acc_perceptron)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#linear svc algorithm:\nlinear_svc = LinearSVC()\nlinear_svc.fit(X_train, y_train)\nY_pred = linear_svc.predict(X_test)\nacc_linear_svc = round(linear_svc.score(X_train, y_train) * 100, 2)\nacc_linear_svc\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sgd algorithm:\nsgd = SGDClassifier()\nsgd.fit(X_train, y_train)\nY_pred = sgd.predict(X_test)\nacc_sgd = round(sgd.score(X_train, y_train) * 100, 2)\nacc_sgd\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#decision Tree algorithm:\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, y_train)\nY_pred = decision_tree.predict(X_test)\nacc_decision_tree = round(decision_tree.score(X_train, y_train) * 100, 2)\nprint(acc_decision_tree)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Random Forest algorithm:\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, y_train)\nY_pred = random_forest.predict(X_test)\nrandom_forest.score(X_train, y_train)\nacc_random_forest = round(random_forest.score(X_train, y_train) * 100, 2)\nprint(acc_random_forest)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model Evaluation\nmodels = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n              'Random Forest', 'Naive Bayes', 'Perceptron', \n              'Stochastic Gradient Decent', 'Linear SVC', \n              'Decision Tree'],\n    'Score': [acc_svc, acc_knn, acc_log, \n              acc_random_forest, acc_gaussian, acc_perceptron, \n              acc_sgd, acc_linear_svc, acc_decision_tree]})\nmodels.sort_values(by='Score', ascending=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Model submission\nsubmission = pd.DataFrame({\n        \"type\": Y_pred\n    })\nsubmission.sort_values(by='type', ascending=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}