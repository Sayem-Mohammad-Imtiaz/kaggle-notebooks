{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport math\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-28T02:25:35.302986Z","iopub.execute_input":"2021-07-28T02:25:35.30356Z","iopub.status.idle":"2021-07-28T02:25:35.326289Z","shell.execute_reply.started":"2021-07-28T02:25:35.303468Z","shell.execute_reply":"2021-07-28T02:25:35.32483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing important libraries","metadata":{}},{"cell_type":"code","source":"from sklearn.datasets import make_blobs\nfrom sklearn.datasets import make_circles\nfrom sklearn.preprocessing import StandardScaler\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2021-07-28T02:25:35.398646Z","iopub.execute_input":"2021-07-28T02:25:35.399736Z","iopub.status.idle":"2021-07-28T02:25:36.612008Z","shell.execute_reply.started":"2021-07-28T02:25:35.399629Z","shell.execute_reply":"2021-07-28T02:25:36.611108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Simulating data using sklearn ","metadata":{}},{"cell_type":"code","source":"# Generate sample data\nX, y = make_circles(n_samples=1000, factor=0.009, noise=0.15)\n\n#-------------------------------------------------------------\nads_arr = StandardScaler().fit_transform(X)\nsns.scatterplot(x=ads_arr[:,0],y=ads_arr[:,1],hue=y)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T02:25:36.613349Z","iopub.execute_input":"2021-07-28T02:25:36.613633Z","iopub.status.idle":"2021-07-28T02:25:36.935011Z","shell.execute_reply.started":"2021-07-28T02:25:36.613592Z","shell.execute_reply":"2021-07-28T02:25:36.933954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DBSCAN from scratch","metadata":{}},{"cell_type":"markdown","source":"## UDFs for calculation of distances","metadata":{}},{"cell_type":"code","source":"#distance calculation UDF\ndef minkowski_(point_a,point_b,p=2):\n    \n    if p==1:\n        print('----> Manhattan')\n        dist = np.sum(abs(point_a-point_b))\n        print('Manual Distance :',dist)\n    elif p==2:\n        #print('----> Euclidean')\n        dist = np.sqrt(np.sum(np.square(point_a-point_b)))\n        #print('Manual Distance :',dist)\n        \n    return dist\n\n#------------------------------------------------------------------\n#UDF for Calculation of distance from a point to every ther point\ndef distance_to_all(curr_vec,data,p_=2):\n\n    #curr_vec = X_arr[0] #example\n    distance_list = []\n    #data = X_arr[0:5]\n\n    for vec_idx in range(len(data)):\n        dist = minkowski_(point_a=curr_vec,point_b=data[vec_idx],p=p_)\n        distance_list.append(dist)\n\n    return distance_list","metadata":{"execution":{"iopub.status.busy":"2021-07-28T02:25:36.936928Z","iopub.execute_input":"2021-07-28T02:25:36.937486Z","iopub.status.idle":"2021-07-28T02:25:36.946225Z","shell.execute_reply.started":"2021-07-28T02:25:36.937441Z","shell.execute_reply":"2021-07-28T02:25:36.945546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## UDF for calculating the core, border and noisy point along with directly density reachable mapping of each point","metadata":{}},{"cell_type":"code","source":"\n\ndef core_border_noise_mapping(data=ads_arr,min_points=10,epsilon=0.38):\n    \n    #Initializing trays for collecting labels & dictionaries for key-value combinations\n    core = []\n    interim = []\n    density_reachable = []\n    idx_dict = {} #Mapping of each point to its directly density reachable points (within epsilon)\n    nmin_dict= {} #Count of total density reachable points within epsilon for each point\n    \n    \n    #-----------------------------------------------------------------------------------------\n    for idx in range(len(data)): #For each point of data\n\n        current_arr = data[idx]\n        current_to_all = np.array(distance_to_all(curr_vec=current_arr,data=data,p_=2)) #Calculating distance\n\n        inside_ = np.argwhere(current_to_all<epsilon).ravel() #Filtering for within epsilon (not inclusive)\n        #print('Index :',idx,'- Len :',len(inside_))\n        length = len(inside_)\n        idx_dict.update({idx : inside_}) #Updating the points which are within eps wrt 'idx' point\n        nmin_dict.update({idx : length}) #Updating the no of points which are within eps wrt 'idx' point\n\n    #-----------------------------------------------------------------------------------------\n    idx_dict_updated = {} #Copy of the mapping dict with removal of self distance (a point has 0 distance with itself)\n    for key,val in idx_dict.items():\n        val_ = val[val!=key]\n        idx_dict_updated.update({key : val_})\n\n    #-----------------------------------------------------------------------------------------\n    #Classifying between Core and non-core (interim) points through nmin parameter\n    for (key,value) in nmin_dict.items():\n\n        if value>=min_points:\n            core.append(key)\n        elif value<=min_points:\n            interim.append(key)\n\n    #----------------------------------------------------\n    print('Total core points :',len(core))\n    print('Total interim points :',len(interim))\n\n    #---------------------------------------------------- \n    #Calculating the directly density reachable points (All points which are within eps of any point)\n    for key_ in idx_dict_updated.keys():\n\n        val = list(idx_dict_updated[key_])\n        density_reachable += val\n\n    density_reachable = list(set(density_reachable)) #Unique through conversion to set\n    print('Total density reachable points :',len(density_reachable))\n    #density_reachable[0:4]\n\n    #----------------------------------------------------\n    noise = []\n    border = []\n    \n    #Classifying between border and noisy points\n    for idx in interim:\n        if idx in density_reachable:\n            border.append(idx)\n        elif idx not in density_reachable:\n            noise.append(idx)\n\n    print('Total noisy points :', len(noise))\n    print('Total border points :',len(border))\n    #----------------------------------------------------\n    \n    return core,border,noise,idx_dict_updated\n","metadata":{"execution":{"iopub.status.busy":"2021-07-28T02:48:27.361239Z","iopub.execute_input":"2021-07-28T02:48:27.361637Z","iopub.status.idle":"2021-07-28T02:48:27.376419Z","shell.execute_reply.started":"2021-07-28T02:48:27.361585Z","shell.execute_reply":"2021-07-28T02:48:27.374251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Nearest Neighbour Graph (tuning epsilon value)\n- Used to find out the the approximate epsilon value from a min_points available (distribution of each point's epsilon to accomodate n_min points) \n- The elbow point is our requirement","metadata":{}},{"cell_type":"code","source":"#!pip install kneed  #If not already installed\nfrom sklearn.neighbors import NearestNeighbors #Nearest Neighbor Calculator\n#from kneed import KneeLocator\n\nnbrs = NearestNeighbors(n_neighbors=6,algorithm='auto',metric='minkowski',p=2,n_jobs=-1).fit(ads_arr)\ndistances, indices = nbrs.kneighbors(ads_arr)\n\n#-----------------------------------------------------------------------------------------------------\ndistances = np.sort(distances[:,-1], axis=0)\ni = np.arange(len(distances))\n#knee = KneeLocator(i, distances, S=1, curve='convex', direction='increasing', interp_method='polynomial')\n\n#-----------------------------------------------------------------------------------------------------\nsns.set_style('darkgrid')\nax = sns.lineplot(x=range(0,len(ads_arr)),y=distances,color='g')\nax.set(xlabel='No of Points',ylabel='Distance of kth neighbor',title='Elbow Curve of kth distance-vs-point')\n#knee.plot_knee()","metadata":{"execution":{"iopub.status.busy":"2021-07-28T03:23:01.550737Z","iopub.execute_input":"2021-07-28T03:23:01.551126Z","iopub.status.idle":"2021-07-28T03:23:01.933529Z","shell.execute_reply.started":"2021-07-28T03:23:01.551096Z","shell.execute_reply":"2021-07-28T03:23:01.932318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Insights :\nFor 6 nearest neighbours (including itself),the elbow occurs at around 0.3 epsilon value","metadata":{}},{"cell_type":"markdown","source":"## Invoking the above UDF to classify points into core, border and noise category + get the directly density reachable mapping","metadata":{}},{"cell_type":"code","source":"epsilon = 0.31 #Calculate through Nearest Neighbours Distance graph\nmin_points = 5\n\ncore,border,noise,idx_dict_updated = core_border_noise_mapping(data=ads_arr,min_points=min_points,epsilon=epsilon)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T02:57:25.100282Z","iopub.execute_input":"2021-07-28T02:57:25.100679Z","iopub.status.idle":"2021-07-28T02:57:38.718686Z","shell.execute_reply.started":"2021-07-28T02:57:25.100642Z","shell.execute_reply":"2021-07-28T02:57:38.717395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## UDF for expanding greedy search","metadata":{}},{"cell_type":"code","source":"def expand_clusters(point, neighbors_, border_, core_, idx_dict_updated_):\n    \n    #Starting of allotment of cluster\n    clusters[point] = counter\n    \n    #print('Length of neighbor at START :',len(neighbors_)) ##\n\n    i = 0 #Initializing\n    \n    #Total directly density reachable elements to cluster tray (gets updated automatically for density reachable & density connected)\n    while i < len(neighbors_): \n        \n        nextPoint = neighbors_[i]\n        \n        if (nextPoint in border_) and (nextPoint not in counter_assign): #In border AND not alloted already\n            #print('For border :',nextPoint)\n            clusters[nextPoint] = counter\n            counter_assign.append(nextPoint) \n        \n        elif (nextPoint in core_) and (nextPoint not in counter_assign): #In core AND not alloted already\n            #print('For Core :',nextPoint)\n            clusters[nextPoint] = counter\n            \n            counter_assign.append(nextPoint)\n            #print('Next point else :',nextPoint)\n            \n            nextNeighbors = list(idx_dict_updated_[nextPoint]) \n            \n            #print('---- New neigbors :',len(nextNeighbors)) ##\n            \n            neighbors_ = neighbors_ + nextNeighbors #Updating with new list of directly density reachable since the new addition to cluster was a core point\n            \n            #print('Length of neighbor at end :',len(neighbors_)) ##\n        \n        i += 1 #Next element in the tray\n        \n        #return clusters_ ","metadata":{"execution":{"iopub.status.busy":"2021-07-28T02:57:38.720748Z","iopub.execute_input":"2021-07-28T02:57:38.721057Z","iopub.status.idle":"2021-07-28T02:57:38.730393Z","shell.execute_reply.started":"2021-07-28T02:57:38.721028Z","shell.execute_reply":"2021-07-28T02:57:38.728717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Implementation of DBSCAN loop","metadata":{}},{"cell_type":"code","source":"clusters = np.array([np.nan]*len(ads_arr)) #Initializing clusters with required size and nan value \nprint('Cluster length :',clusters.shape)\n\ncounter = 0 #Start of allotment counter\ncounter_assign = [] #Counter for assignment (To prevent over-write of clusters)\n\nfor idx in range(len(ads_arr)): #For each data point\n    \n    if idx not in counter_assign: #Checking if that point is not assigned already\n\n        print('---------------------------------------- idx :',idx)\n        #print('------------------ counter :',counter)\n        if idx in noise: #If index of the point in noise list, no allotment required\n            #print('noise :',idx)\n            clusters[idx] = -1 #Allotment for noisy points\n            counter_assign.append(idx)\n\n        else : #If core or border point\n            #print('Core :',idx)\n            \n            print('------------------ counter :',counter)\n            \n            neighbors = list(idx_dict_updated[idx]) #Directly density reachable for that point\n            \n            expand_clusters(point=idx,\n                            neighbors_=neighbors,\n                            border_=border,\n                            core_=core,\n                            idx_dict_updated_=idx_dict_updated) #Greedy search algo to allot cluster till the edge\n            \n            counter += 1 #Changing cluster label value\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-28T02:57:38.733001Z","iopub.execute_input":"2021-07-28T02:57:38.733482Z","iopub.status.idle":"2021-07-28T02:57:54.127869Z","shell.execute_reply.started":"2021-07-28T02:57:38.733431Z","shell.execute_reply":"2021-07-28T02:57:54.12678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Info regarding clusters formed through manual implementation ","metadata":{}},{"cell_type":"code","source":"print('Total clusters :',len(np.unique(clusters)))\nprint('Unique cluster values :',np.unique(clusters))","metadata":{"execution":{"iopub.status.busy":"2021-07-28T03:13:32.284488Z","iopub.execute_input":"2021-07-28T03:13:32.284987Z","iopub.status.idle":"2021-07-28T03:13:32.290626Z","shell.execute_reply.started":"2021-07-28T03:13:32.284955Z","shell.execute_reply":"2021-07-28T03:13:32.289944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plotting the sccater plot for manual DBSCAN labels","metadata":{}},{"cell_type":"code","source":"sns.scatterplot(x=ads_arr[:,0],y=ads_arr[:,1],hue=clusters)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T02:57:54.167896Z","iopub.execute_input":"2021-07-28T02:57:54.168173Z","iopub.status.idle":"2021-07-28T02:57:54.459101Z","shell.execute_reply.started":"2021-07-28T02:57:54.168144Z","shell.execute_reply":"2021-07-28T02:57:54.458114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sklearn benchmarking","metadata":{}},{"cell_type":"code","source":"from sklearn.cluster import DBSCAN\n\n#-------------------------------------------------------------------------------------\ndbscan = DBSCAN(eps=epsilon,min_samples=min_points,metric='euclidean',n_jobs=-1)\ndbscan.fit(ads_arr)\ndbscan_labels = dbscan.labels_","metadata":{"execution":{"iopub.status.busy":"2021-07-28T03:14:20.989911Z","iopub.execute_input":"2021-07-28T03:14:20.990275Z","iopub.status.idle":"2021-07-28T03:14:21.10391Z","shell.execute_reply.started":"2021-07-28T03:14:20.990246Z","shell.execute_reply":"2021-07-28T03:14:21.103095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Scatterplot for sklearn DBSCAN labels","metadata":{}},{"cell_type":"code","source":"sns.scatterplot(x=ads_arr[:,0],y=ads_arr[:,1],hue=dbscan_labels)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T02:57:54.577431Z","iopub.execute_input":"2021-07-28T02:57:54.578101Z","iopub.status.idle":"2021-07-28T02:57:54.854786Z","shell.execute_reply.started":"2021-07-28T02:57:54.578054Z","shell.execute_reply":"2021-07-28T02:57:54.853758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Insights : \n- The sklearn implementation and the manual implementation seem to be in sync as the results are similar, hence the logic implemented here is correct","metadata":{}},{"cell_type":"markdown","source":"# END","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}