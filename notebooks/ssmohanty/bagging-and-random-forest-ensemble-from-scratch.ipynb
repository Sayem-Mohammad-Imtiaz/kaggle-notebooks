{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-27T03:48:49.918711Z","iopub.execute_input":"2021-07-27T03:48:49.919169Z","iopub.status.idle":"2021-07-27T03:48:49.930182Z","shell.execute_reply.started":"2021-07-27T03:48:49.919129Z","shell.execute_reply":"2021-07-27T03:48:49.929092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Input of ADS","metadata":{}},{"cell_type":"code","source":"input_ads_pre = pd.read_csv('../input/titanic/train_data.csv')\ninput_ads_pre.drop(columns=['Unnamed: 0','Title_1','Title_2','Title_3','Title_4'],inplace=True) #Dropping un-necessary columns\n#-----------------------------------------------------------------\nprint(input_ads_pre.shape)\ninput_ads_pre.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-27T03:40:50.186217Z","iopub.execute_input":"2021-07-27T03:40:50.186781Z","iopub.status.idle":"2021-07-27T03:40:50.219412Z","shell.execute_reply.started":"2021-07-27T03:40:50.186732Z","shell.execute_reply":"2021-07-27T03:40:50.218373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Null Check","metadata":{}},{"cell_type":"code","source":"pd.DataFrame(input_ads_pre.isnull().sum()).T","metadata":{"execution":{"iopub.status.busy":"2021-07-27T03:41:02.854237Z","iopub.execute_input":"2021-07-27T03:41:02.85468Z","iopub.status.idle":"2021-07-27T03:41:02.870012Z","shell.execute_reply.started":"2021-07-27T03:41:02.854644Z","shell.execute_reply":"2021-07-27T03:41:02.869214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Description of target variable","metadata":{}},{"cell_type":"code","source":"#Total survived vs not-survived split in the training data\ninput_ads_pre['Survived'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-07-27T03:41:38.973394Z","iopub.execute_input":"2021-07-27T03:41:38.973771Z","iopub.status.idle":"2021-07-27T03:41:38.983932Z","shell.execute_reply.started":"2021-07-27T03:41:38.973738Z","shell.execute_reply":"2021-07-27T03:41:38.982959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Shuffling the ADS","metadata":{}},{"cell_type":"code","source":"from sklearn.utils import shuffle\n#np.random.seed(100)\n\ninput_ads = shuffle(input_ads_pre,random_state=100)\nprint(input_ads.shape)\ninput_ads = input_ads.reset_index(drop=True)\ninput_ads.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-07-27T03:41:37.02486Z","iopub.execute_input":"2021-07-27T03:41:37.02542Z","iopub.status.idle":"2021-07-27T03:41:37.939398Z","shell.execute_reply.started":"2021-07-27T03:41:37.025387Z","shell.execute_reply":"2021-07-27T03:41:37.938408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Manipulation of data into train and test","metadata":{}},{"cell_type":"code","source":"target = 'Survived' #To predict\n\n#--------------------------------------------------------------------------------\n#Splitting into X & Y datasets (supervised training)\nX = input_ads[[cols for cols in list(input_ads.columns) if target not in cols]]\ny = input_ads[target]\n\n#--------------------------------------------------------------------------------\n#Since test data is already placed in the input folder separately, we will just import it\ntest_ads_pre = pd.read_csv('../input/titanic/test_data.csv')\ntest_ads_pre.drop(columns=['Unnamed: 0','Title_1','Title_2','Title_3','Title_4'],inplace=True) #Dropping un-necessary columns\ntest_ads = shuffle(test_ads_pre,random_state=100)\ntest_ads = test_ads.reset_index(drop=True)\n\n#Splitting into X & Y datasets (supervised training)\nX_test = test_ads[[cols for cols in list(test_ads.columns) if target not in cols]]\ny_test = test_ads[target]\n\nprint('Train % of total data:',100 * X.shape[0]/(X.shape[0] + X_test.shape[0]))\n#--------------------------------------------------------------------------------\n#Manipulation of datasets for convenience and consistency\nX_arr = np.array(X)\nX_test_arr = np.array(X_test)\n\ny_arr = np.array(y).reshape(X_arr.shape[0],1)\ny_test_arr = np.array(y_test).reshape(X_test_arr.shape[0],1)\n\n#--------------------------------------------------------------------------------\n#Basic Summary\nprint(X_arr.shape)\nprint(X_test_arr.shape)\nprint(y_arr.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-27T03:42:01.924609Z","iopub.execute_input":"2021-07-27T03:42:01.92502Z","iopub.status.idle":"2021-07-27T03:42:01.954499Z","shell.execute_reply.started":"2021-07-27T03:42:01.924989Z","shell.execute_reply":"2021-07-27T03:42:01.953399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Independent Logistic Regression & Decision Tree model","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import tree\n#max_depth=2,min_samples_split=7,min_samples_leaf=8,\n\n#Decision Tree Classifier\ndt_clf = DecisionTreeClassifier(random_state=100)\ndt_clf.fit(X_arr,y_arr)\nsklearn_preds_dt = dt_clf.predict(X_test_arr)\n\n#---------------------------------------------------------------------------\n#Logistic Regression\nlr_clf = LogisticRegression(solver='sag',random_state=100)\nlr_clf.fit(X_arr,y_arr)\nsklearn_preds_lr = lr_clf.predict(X_test_arr)\n\n#Evaluation of the predictions\nprint('#- Decision Tree ---------------------------------------------------#')\nprint('ROC AUC of test set :',roc_auc_score(y_test_arr,sklearn_preds_dt))\nprint('Accuracy of test set :',accuracy_score(y_test_arr,sklearn_preds_dt),'\\n')\n\nprint('#- Logistic Regression ---------------------------------------------#')\nprint('ROC AUC of test set :',roc_auc_score(y_test_arr,sklearn_preds_lr))\nprint('Accuracy of test set :',accuracy_score(y_test_arr,sklearn_preds_lr),'\\n')","metadata":{"execution":{"iopub.status.busy":"2021-07-27T03:42:53.903624Z","iopub.execute_input":"2021-07-27T03:42:53.904073Z","iopub.status.idle":"2021-07-27T03:42:54.233374Z","shell.execute_reply.started":"2021-07-27T03:42:53.90403Z","shell.execute_reply":"2021-07-27T03:42:54.232241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Bagging wrapper logic from scratch","metadata":{}},{"cell_type":"markdown","source":"## UDF for bootstrap sampling","metadata":{}},{"cell_type":"code","source":"#UDF for bootstrapping sampling logic\ndef bootstrapped_sample(arr,random_state):\n    \n    np.random.seed(random_state)\n    \n    boot_sample_idx = np.random.choice(a=range(len(arr)),size=len(arr),replace=True)\n    boot_sample = arr[boot_sample_idx]\n    \n    return boot_sample","metadata":{"execution":{"iopub.status.busy":"2021-07-27T03:43:47.194189Z","iopub.execute_input":"2021-07-27T03:43:47.194564Z","iopub.status.idle":"2021-07-27T03:43:47.200165Z","shell.execute_reply.started":"2021-07-27T03:43:47.194535Z","shell.execute_reply":"2021-07-27T03:43:47.198975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## UDF for Bagging (works very similar for regression as well)","metadata":{}},{"cell_type":"code","source":"def bagging_ensemble_clf(estimator,X_arr_,y_arr_,test,n_iters,threshold=0.5):\n\n    pred_array = np.array([np.nan]*len(test)).reshape((len(test)),1)\n\n    joint_arr = np.append(X_arr_,y_arr_,axis=-1)\n    \n    #Bootstrapping and model building interatively\n    for n in range(n_iters):\n\n        sample = bootstrapped_sample(arr=joint_arr,random_state=n)\n\n        #print('Shape before :',sample.shape)\n        X_sample = sample[:,0:-1]\n        y_sample = sample[:,-1]\n\n        estimator.fit(X_sample,y_sample)\n        pred_array_temp = np.array(estimator.predict(test)).reshape((len(test)),1)\n\n        pred_array = np.append(pred_array,pred_array_temp,axis=-1)\n        #print('Pred array shape :',pred_array.shape)\n\n\n    #--------------------------------------------------------------------------------------------------------\n    #Aggregation\n    pred_array = pred_array[:,1:]\n    #print(pred_array)\n    \n    pred = np.sum(pred_array,axis=1) \n    #print(pred)\n    \n    n_preds = pred_array.shape[1]\n    #print(n_preds)\n    \n    pred = pred/n_preds\n    #print(pred)\n    \n    pred = (pred>threshold).astype(int)\n    print('Unique preds :',np.unique(pred))\n    \n\n    return pred","metadata":{"execution":{"iopub.status.busy":"2021-07-27T03:46:42.980336Z","iopub.execute_input":"2021-07-27T03:46:42.980764Z","iopub.status.idle":"2021-07-27T03:46:42.990833Z","shell.execute_reply.started":"2021-07-27T03:46:42.980733Z","shell.execute_reply":"2021-07-27T03:46:42.989758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Invoking Bagginf UDF with Decision Tree model ","metadata":{}},{"cell_type":"code","source":"decision_tree = DecisionTreeClassifier(random_state=100)\n\npreds_dt = bagging_ensemble_clf(estimator=decision_tree,X_arr_=X_arr,y_arr_=y_arr,test=X_test_arr,n_iters=500)\nprint(preds_dt.shape)\n\nprint('#- Manual Bagging w/ Decision Tree ---------------------------------------------------#')\nprint('ROC AUC of test set :',roc_auc_score(y_test_arr,preds_dt))\nprint('Accuracy of test set :',accuracy_score(y_test_arr,preds_dt),'\\n')","metadata":{"execution":{"iopub.status.busy":"2021-07-27T03:48:39.354858Z","iopub.execute_input":"2021-07-27T03:48:39.35533Z","iopub.status.idle":"2021-07-27T03:48:40.945656Z","shell.execute_reply.started":"2021-07-27T03:48:39.355297Z","shell.execute_reply":"2021-07-27T03:48:40.944466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Invoking Bagginf UDF with Logistic Regression model ","metadata":{}},{"cell_type":"code","source":"log_reg = LogisticRegression(solver='saga',random_state=100)\n\npreds_lr = bagging_ensemble_clf(estimator=log_reg,X_arr_=X_arr,y_arr_=y_arr,test=X_test_arr,n_iters=500)\nprint(preds_lr.shape)\n\nprint('#- Manual Bagging w/ Logistic Regression Tree ---------------------------------------------------#')\nprint('ROC AUC of test set :',roc_auc_score(y_test_arr,preds_lr))\nprint('Accuracy of test set :',accuracy_score(y_test_arr,preds_lr),'\\n')","metadata":{"execution":{"iopub.status.busy":"2021-07-27T03:54:25.999073Z","iopub.execute_input":"2021-07-27T03:54:25.999482Z","iopub.status.idle":"2021-07-27T03:54:34.67352Z","shell.execute_reply.started":"2021-07-27T03:54:25.999447Z","shell.execute_reply":"2021-07-27T03:54:34.672427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Random Forest Classifier (Very simple after this point)","metadata":{}},{"cell_type":"code","source":"decision_tree = DecisionTreeClassifier(max_features='sqrt',random_state=100) #For RF only DT can be the estimator & max_features='sqrt'\n\npreds_rf = bagging_ensemble_clf(estimator=decision_tree,X_arr_=X_arr,y_arr_=y_arr,test=X_test_arr,n_iters=500)\nprint(preds_rf.shape)\n\nprint('#- Manual Random Forest ---------------------------------------------------#')\nprint('ROC AUC of test set :',roc_auc_score(y_test_arr,preds_rf))\nprint('Accuracy of test set :',accuracy_score(y_test_arr,preds_rf),'\\n')","metadata":{"execution":{"iopub.status.busy":"2021-07-27T03:54:45.618815Z","iopub.execute_input":"2021-07-27T03:54:45.619205Z","iopub.status.idle":"2021-07-27T03:54:46.66736Z","shell.execute_reply.started":"2021-07-27T03:54:45.619175Z","shell.execute_reply":"2021-07-27T03:54:46.666164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sklearn Benchmarking","metadata":{}},{"cell_type":"markdown","source":"# Bagging with DT","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import BaggingClassifier\n\ndecision_tree = DecisionTreeClassifier(random_state=100)\n\nbagging_skl = BaggingClassifier(base_estimator=decision_tree,\n                                n_estimators=500,\n                                max_features=1.0,\n                                bootstrap=True,\n                                random_state=100,\n                                n_jobs=-1)\nbagging_skl.fit(X_arr,y_arr)\nbagging_skl_pred = bagging_skl.predict(X_test_arr)\n\n#--------------------------------------------------------------------------------------------------------\nprint('#- Sklearn Bagging Classifier ---------------------------------------------------#')\nprint('ROC AUC of test set :',roc_auc_score(y_test_arr,bagging_skl_pred))\nprint('Accuracy of test set :',accuracy_score(y_test_arr,bagging_skl_pred),'\\n')","metadata":{"execution":{"iopub.status.busy":"2021-07-27T03:54:12.084501Z","iopub.execute_input":"2021-07-27T03:54:12.084934Z","iopub.status.idle":"2021-07-27T03:54:13.427048Z","shell.execute_reply.started":"2021-07-27T03:54:12.084897Z","shell.execute_reply":"2021-07-27T03:54:13.425893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sklearn Random Forest","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrf_skl = RandomForestClassifier(n_estimators=500,\n                                max_features='sqrt',\n                                bootstrap=True,\n                                random_state=100,\n                                n_jobs=-1)\nrf_skl.fit(X_arr,y_arr)\nrf_skl_pred = rf_skl.predict(X_test_arr)\n\n#--------------------------------------------------------------------------------------------------------\nprint('#- Sklearn Bagging Classifier ---------------------------------------------------#')\nprint('ROC AUC of test set :',roc_auc_score(y_test_arr,rf_skl_pred))\nprint('Accuracy of test set :',accuracy_score(y_test_arr,rf_skl_pred),'\\n')","metadata":{"execution":{"iopub.status.busy":"2021-07-27T03:54:54.113677Z","iopub.execute_input":"2021-07-27T03:54:54.114048Z","iopub.status.idle":"2021-07-27T03:54:55.712752Z","shell.execute_reply.started":"2021-07-27T03:54:54.114019Z","shell.execute_reply":"2021-07-27T03:54:55.711766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Insights : The manual implementations are giving almost identical quality of predictions for normal bagging and random forest with the sklearn versions","metadata":{}},{"cell_type":"markdown","source":"# END","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}