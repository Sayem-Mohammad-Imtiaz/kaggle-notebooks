{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-27T04:06:18.342348Z","iopub.execute_input":"2021-07-27T04:06:18.342827Z","iopub.status.idle":"2021-07-27T04:06:18.383901Z","shell.execute_reply.started":"2021-07-27T04:06:18.342727Z","shell.execute_reply":"2021-07-27T04:06:18.383087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import ADS","metadata":{}},{"cell_type":"code","source":"input_ads_pre = pd.read_csv('../input/titanic/train_data.csv')\ninput_ads_pre.drop(columns=['Unnamed: 0','Title_1','Title_2','Title_3','Title_4'],inplace=True) #Dropping un-necessary columns\n#-----------------------------------------------------------------\nprint(input_ads_pre.shape)\ninput_ads_pre.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-27T04:06:21.291131Z","iopub.execute_input":"2021-07-27T04:06:21.291488Z","iopub.status.idle":"2021-07-27T04:06:21.470429Z","shell.execute_reply.started":"2021-07-27T04:06:21.291459Z","shell.execute_reply":"2021-07-27T04:06:21.469652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Null Check","metadata":{}},{"cell_type":"code","source":"pd.DataFrame(input_ads_pre.isnull().sum()).T","metadata":{"execution":{"iopub.status.busy":"2021-07-27T04:06:33.501808Z","iopub.execute_input":"2021-07-27T04:06:33.502641Z","iopub.status.idle":"2021-07-27T04:06:33.518858Z","shell.execute_reply.started":"2021-07-27T04:06:33.502596Z","shell.execute_reply":"2021-07-27T04:06:33.517704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Description of Target Variable","metadata":{}},{"cell_type":"code","source":"#Total survived vs not-survived split in the training data\ninput_ads_pre['Survived'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-07-27T04:06:51.087318Z","iopub.execute_input":"2021-07-27T04:06:51.087766Z","iopub.status.idle":"2021-07-27T04:06:51.099219Z","shell.execute_reply.started":"2021-07-27T04:06:51.087731Z","shell.execute_reply":"2021-07-27T04:06:51.098192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Shuffling the data","metadata":{}},{"cell_type":"code","source":"from sklearn.utils import shuffle\n#np.random.seed(100)\n\n#----------------------------------------------------\ninput_ads = shuffle(input_ads_pre,random_state=100)\nprint(input_ads.shape)\ninput_ads = input_ads.reset_index(drop=True)\ninput_ads.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-07-27T04:06:59.076652Z","iopub.execute_input":"2021-07-27T04:06:59.077358Z","iopub.status.idle":"2021-07-27T04:07:00.03794Z","shell.execute_reply.started":"2021-07-27T04:06:59.077315Z","shell.execute_reply":"2021-07-27T04:07:00.03713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train-Test manipulation of data","metadata":{}},{"cell_type":"code","source":"target = 'Survived' #To predict\n\n#--------------------------------------------------------------------------------\n#Splitting into X & Y datasets (supervised training)\nX = input_ads[[cols for cols in list(input_ads.columns) if target not in cols]]\ny = input_ads[target]\n\n#--------------------------------------------------------------------------------\n#Since test data is already placed in the input folder separately, we will just import it\ntest_ads_pre = pd.read_csv('../input/titanic/test_data.csv')\ntest_ads_pre.drop(columns=['Unnamed: 0','Title_1','Title_2','Title_3','Title_4'],inplace=True) #Dropping un-necessary columns\ntest_ads = shuffle(test_ads_pre,random_state=100)\ntest_ads = test_ads.reset_index(drop=True)\n\n#Splitting into X & Y datasets (supervised training)\nX_test = test_ads[[cols for cols in list(test_ads.columns) if target not in cols]]\ny_test = test_ads[target]\n\nprint('Train % of total data:',100 * X.shape[0]/(X.shape[0] + X_test.shape[0]))\n#--------------------------------------------------------------------------------\n#Manipulation of datasets for convenience and consistency\nX_arr = np.array(X)\nX_test_arr = np.array(X_test)\n\ny_arr = np.array(y).reshape(X_arr.shape[0],1)\ny_test_arr = np.array(y_test).reshape(X_test_arr.shape[0],1)\n\n#--------------------------------------------------------------------------------\n#Basic Summary\nprint(X_arr.shape)\nprint(X_test_arr.shape)\nprint(y_arr.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-27T04:07:21.936092Z","iopub.execute_input":"2021-07-27T04:07:21.936692Z","iopub.status.idle":"2021-07-27T04:07:21.968349Z","shell.execute_reply.started":"2021-07-27T04:07:21.936654Z","shell.execute_reply":"2021-07-27T04:07:21.967423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Stacking Wrapper Logic from scratch","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-07-27T04:10:17.98336Z","iopub.execute_input":"2021-07-27T04:10:17.983783Z","iopub.status.idle":"2021-07-27T04:10:17.988251Z","shell.execute_reply.started":"2021-07-27T04:10:17.983747Z","shell.execute_reply":"2021-07-27T04:10:17.987266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing all the necessary models for base model purpose","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nimport xgboost as xgb","metadata":{"execution":{"iopub.status.busy":"2021-07-27T04:10:43.102295Z","iopub.execute_input":"2021-07-27T04:10:43.102671Z","iopub.status.idle":"2021-07-27T04:10:43.10897Z","shell.execute_reply.started":"2021-07-27T04:10:43.102639Z","shell.execute_reply":"2021-07-27T04:10:43.107557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## UDF for Stacking Ensemble Training (Clf)","metadata":{}},{"cell_type":"code","source":"def stacking_ensemble_clf_training(data_x,data_y,estimator_tray,meta_estimator,passthrough=True):\n\n    fit_level_1 = [] #Model trays for level 1\n    fit_level_2 = [] #model Trays for level 2\n    train_pred_arr = np.array([np.nan] * len(data_x)).reshape(len(data_x),1)\n\n    for estimator in estimator_tray: #Creating level 1 models\n\n        estimator.fit(data_x,data_y)\n        pred_temp = np.array(estimator.predict(data_x)).reshape(len(data_x),1)\n        train_pred_arr = np.append(train_pred_arr,pred_temp,axis=-1)\n        fit_level_1.append(estimator)\n\n    train_pred_arr = train_pred_arr[:,1:] #Removing the first null column\n\n    if passthrough==False: #If training data doesnt needs to be passed to the level 2\n\n        meta_estimator.fit(train_pred_arr,data_y)\n        fit_level_2.append(meta_estimator)\n        #pred_meta = meta_estimator.predict(X_test_arr)\n\n    elif passthrough==True: #If training data needs to be passed to the level 2\n\n        train_pass = np.append(data_x,train_pred_arr,axis=-1)\n        meta_estimator.fit(train_pass,data_y)\n        fit_level_2.append(meta_estimator)\n        \n        #pred_meta = meta_estimator.predict(X_test_arr)\n\n    return fit_level_1,fit_level_2[0]\n","metadata":{"execution":{"iopub.status.busy":"2021-07-27T04:12:34.406947Z","iopub.execute_input":"2021-07-27T04:12:34.407373Z","iopub.status.idle":"2021-07-27T04:12:34.417165Z","shell.execute_reply.started":"2021-07-27T04:12:34.407339Z","shell.execute_reply":"2021-07-27T04:12:34.416022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## UDF for Stacking Ensemble Prediction","metadata":{}},{"cell_type":"code","source":"def stacking_ensemble_clf_predict(data_x_test,data_y_test,fit_level_1_tray,meta_estimator,passthrough=True):\n\n    train_pred_arr = np.array([np.nan] * len(data_x_test)).reshape(len(data_x_test),1) #Initializing level 1 prediction array\n\n    for estimator in fit_level_1_tray: #Predcitng for each base model\n\n        pred_temp = np.array(estimator.predict(data_x_test)).reshape(len(data_x_test),1)\n        train_pred_arr = np.append(train_pred_arr,pred_temp,axis=-1)\n\n    train_pred_arr = train_pred_arr[:,1:] #Removing the first null column\n\n    if passthrough==False: #Should match with training\n\n        pred_meta = meta_estimator.predict(train_pred_arr)\n\n    elif passthrough==True: #Should match with training\n\n        train_pass = np.append(data_x_test,train_pred_arr,axis=-1)\n        pred_meta = meta_estimator.predict(train_pass)\n\n    return pred_meta\n","metadata":{"execution":{"iopub.status.busy":"2021-07-27T04:15:30.196555Z","iopub.execute_input":"2021-07-27T04:15:30.196921Z","iopub.status.idle":"2021-07-27T04:15:30.205298Z","shell.execute_reply.started":"2021-07-27T04:15:30.196891Z","shell.execute_reply":"2021-07-27T04:15:30.204034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Invoking UDF for Stacking Ensemble Training (Clf)","metadata":{}},{"cell_type":"code","source":"#Level 1 models\nlog_reg = LogisticRegression(solver='sag',random_state=100)\nsgd_clf = SGDClassifier(random_state=100)\nknn = KNeighborsClassifier(n_neighbors=3)\ndt_clf = DecisionTreeClassifier(random_state=100)\nrf_clf = RandomForestClassifier(random_state=100)\nsvc = SVC(random_state=100)\n\nxgb_ = xgb.XGBClassifier(random_state=100) #Meta Classifier\n#-----------------------------------------------------------------------------------------------------------------\nlevel_1 = [log_reg,sgd_clf,knn,dt_clf,rf_clf,svc]\n#meta = xgb_\n\n#-----------------------------------------------------------------------------------------------------------------\nfit_level_1,meta_estimator = stacking_ensemble_clf_training(data_x=X_arr,\n                                                            data_y=y_arr,\n                                                            estimator_tray=level_1,\n                                                            meta_estimator=xgb_,\n                                                            passthrough=True)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-27T04:15:27.416514Z","iopub.execute_input":"2021-07-27T04:15:27.417253Z","iopub.status.idle":"2021-07-27T04:15:27.854837Z","shell.execute_reply.started":"2021-07-27T04:15:27.417202Z","shell.execute_reply":"2021-07-27T04:15:27.853985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Invoking prediction UDF for Stacking Ensemble","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import accuracy_score\n\nfinal_preds = stacking_ensemble_clf_predict(data_x_test=X_test_arr,\n                                            data_y_test=y_test_arr,\n                                            fit_level_1_tray=fit_level_1,\n                                            meta_estimator=meta_estimator,\n                                            passthrough=True)\n\n#-------------------------------------------------------------------------------\n#Evaluation of the manual ensemble\nprint('ROC AUC of test set :',roc_auc_score(y_test_arr,final_preds))\nprint('Accuracy of test set :',accuracy_score(y_test_arr,final_preds))","metadata":{"execution":{"iopub.status.busy":"2021-07-27T04:16:14.802261Z","iopub.execute_input":"2021-07-27T04:16:14.802656Z","iopub.status.idle":"2021-07-27T04:16:14.846317Z","shell.execute_reply.started":"2021-07-27T04:16:14.802622Z","shell.execute_reply":"2021-07-27T04:16:14.845456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sklearn Benchmark","metadata":{}},{"cell_type":"code","source":"#Base Estimators\nestimators_list = [\n('log_reg', LogisticRegression(solver='sag',random_state=100)),\n('sgd_clf', SGDClassifier(random_state=100)),\n('knn', KNeighborsClassifier(n_neighbors=3)),\n('dt_clf', DecisionTreeClassifier(random_state=100)),\n('rf_clf', RandomForestClassifier(random_state=100)),\n('svc', SVC(random_state=100))]\n\nxgb_ = xgb.XGBClassifier(random_state=100) #Meta Classifier","metadata":{"execution":{"iopub.status.busy":"2021-07-27T04:16:37.673059Z","iopub.execute_input":"2021-07-27T04:16:37.673806Z","iopub.status.idle":"2021-07-27T04:16:37.68106Z","shell.execute_reply.started":"2021-07-27T04:16:37.673766Z","shell.execute_reply":"2021-07-27T04:16:37.679909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Sklearn implementation of Stacking","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import StackingClassifier\n\nstacking = StackingClassifier(estimators=estimators_list,\n                              final_estimator=xgb_,\n                              stack_method='predict',\n                              passthrough=True,\n                              n_jobs=-1)\n\nstacking.fit(X_arr,y_arr)\nstacking_pred = stacking.predict(X_test_arr)\n\n#--------------------------------------------------------------------------\n#Evaluating\nprint('ROC AUC of test set :',roc_auc_score(y_test_arr,stacking_pred))\nprint('Accuracy of test set :',accuracy_score(y_test_arr,stacking_pred))","metadata":{"execution":{"iopub.status.busy":"2021-07-27T04:17:03.248807Z","iopub.execute_input":"2021-07-27T04:17:03.249263Z","iopub.status.idle":"2021-07-27T04:17:07.673342Z","shell.execute_reply.started":"2021-07-27T04:17:03.249204Z","shell.execute_reply":"2021-07-27T04:17:07.666235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Insights: The accuracy and ROC-AUC scores for both sklearn and manual implementations are same indicating correct implementation of the logic","metadata":{}},{"cell_type":"markdown","source":"# END","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}