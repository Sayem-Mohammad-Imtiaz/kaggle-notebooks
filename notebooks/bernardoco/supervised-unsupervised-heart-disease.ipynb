{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Abstract\n\nKaggle Dasatet Link: https://www.kaggle.com/ronitf/heart-disease-uci\n\n* In this notebook I've been through some classification algorithms to predict the presence of heart disease in a patient using previous patient's data.\n\n* Even though we have a labeled dataset, I've tried to use K-Means Clustering (Unsupervised), since I didn't use it before, to predict using Principal Component Analysis decomposition and achieved a similar result.\n\n* Target variable represented by the column 'target' maps: {0: 'Healthy', 1: 'Abnormality'}"},{"metadata":{},"cell_type":"markdown","source":"# Imports"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/heart-disease-uci/heart.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['thal'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[df['thal'] == 0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Note:** There is no register of the 0 value for 'thal' in https://archive.ics.uci.edu/ml/datasets/Heart+Disease. I've tried to remove the only 2 entries for some simplicity, but I've got much worse results. So I'm leaving as it is."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Renaming DataFrame columns to a more comprehensible feature description"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns = ['age', 'sex', 'chest_pain_type', 'resting_blood_pressure', 'cholesterol', 'fasting_blood_sugar', 'rest_ecg', 'max_heart_rate_achieved',\n       'exercise_induced_angina', 'st_depression', 'st_slope', 'num_major_vessels', 'thalassemia', 'target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['sex'] = df['sex'].map({0: 'F',\n                           1: 'M'})\n\ndf['chest_pain_type'] = df['chest_pain_type'].map({0: 'typical angina',\n                                                   1: 'atypical angina',\n                                                   2: 'non-anginal pain',\n                                                   3: 'asymptomatic'})\n\ndf['fasting_blood_sugar'] = df['fasting_blood_sugar'].map({0: 'lower than 120mg/ml',\n                                                           1: 'greater than 120mg/ml'})\n\ndf['rest_ecg'] = df['rest_ecg'].map({0: 'normal',\n                                     1: 'ST-T wave abnormality',\n                                     2: 'left ventricular hypertrophy'})\n\ndf['exercise_induced_angina'] = df['exercise_induced_angina'].map({0: 'no',\n                                                                   1: 'yes'})\n\ndf['st_slope'] = df['st_slope'].map({0: 'upsloping',\n                                     1: 'flat',\n                                     2: 'downsloping'})\n\ndf['thalassemia'] = df['thalassemia'].map({1: 'normal',\n                                           2: 'fixed defect',\n                                           3: 'reversable defect'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.displot(data=df, x='age', col='sex', hue='target', kind='kde')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.displot(data=df, x='age', col='chest_pain_type', hue='target')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.displot(df['resting_blood_pressure'], kde=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.displot(df['cholesterol'], kde=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Outlier!"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[df['cholesterol'] > 500]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.displot(df['max_heart_rate_achieved'], kde=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.displot(df['st_depression'], kde=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='num_major_vessels', data=df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='chest_pain_type', y='age', data=df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df, hue='target')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colormap = plt.cm.RdBu\nplt.figure(figsize=(12,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(df.corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"One Hot Enconding our dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"onehot_df = pd.get_dummies(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"onehot_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = onehot_df.target.values\nx = onehot_df.drop('target', axis=1).values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import KFold, cross_val_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Testing Classifiers\n\n10 Fold Cross Validation to evaluate the performance of some algorithms"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate Models\n\nn_folds = 10\nmodels = []\n\n\n# Scaling features\nscaler = StandardScaler()\nscaler.fit(x_train)\n\nscaled_x_train = scaler.transform(x_train)\nscaled_x_test = scaler.transform(x_test)\n\n\nmodels.append(('LR', LogisticRegression()))\nmodels.append(('Tree', DecisionTreeClassifier()))\nmodels.append(('Forest', RandomForestClassifier()))\nmodels.append(('XGB', XGBClassifier(use_label_encoder=False, eval_metric='logloss')))\nmodels.append(('NB', GaussianNB()))\n\nfor name, model in models:\n    kfold = KFold(n_splits=n_folds)\n    cv_results = cross_val_score(model, scaled_x_train, y_train, cv=kfold, scoring='accuracy')\n    print(\"%6s %.3f %.3f \" % (name, cv_results.mean(), cv_results.std()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Testing Random Forest. We could do a randomized search with [sklearn's randomized search](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) and try to find the optimal hyperparameters for our case, but I won't cover this in this notebook."},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(max_depth=5, n_estimators=100)\n\n# Train the model on training data\nrf.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = rf.predict(x_test).round()\nprint('Random Forest')\nprint(\"Test Accuracy: %.2f\" % ((pred == y_test).mean()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_test, pred)\nsns.heatmap(cm, square=True, annot=True)\nplt.title('Confusion Matrix')\nplt.ylabel('True label')\nplt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_importance = rf.feature_importances_\nonehot_df_x = onehot_df.drop('target', axis=1)\nnames = [col for col in onehot_df_x.columns[feature_importance.argsort()[::-1]]]\n\nplt.figure(figsize=(10,10))\nsns.barplot(y=names, x=np.sort(feature_importance)[::-1], orient='h').set_title('Feature Importance')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dimensionality Reduction (PCA)\n\nLet's try to find some clusters in our data so we can try others approaches. We will decompose our data in components so we retain 90% of variance."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\n\npca = PCA(n_components=0.9)\npc = pca.fit_transform(scaled_x_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,4))\nsns.barplot(x=np.array(range(pca.n_components_)), y=pca.explained_variance_ratio_)\nplt.xlabel(\"Components\")\nplt.ylabel(\"Variance\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(pc[:, 0], pc[:, 1], c=y_train, label=y_train)\nplt.title(\"PCA\")\nplt.xlabel(\"1st Component\")\nplt.ylabel(\"2nd Component\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With only 2 components we have some noise in the center but it's already looking pretty distinguishable! Let's see with 3 components..."},{"metadata":{"trusted":true},"cell_type":"code","source":"from mpl_toolkits.mplot3d import Axes3D\n\nfig = plt.figure(figsize=(8,8))\nax = Axes3D(fig)\nax.scatter(pc[:, 0], pc[:, 1], pc[:, 2], c=y_train)\nax.set_xlabel('1st Component')\nax.set_ylabel('2nd Component')\nax.set_zlabel('3rd Component')\nax.set_title('PCA')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# K-Nearest Neighbours\n\nNow we're going to test the performance of the KNN algorithm using our PCA decomposition, since we could see clusters and some clear distinguish between our target label."},{"metadata":{},"cell_type":"markdown","source":"For comparison, let's train our KNN with the original dataset, and then use the PCA decompositions to see if we can get any better."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import mean_squared_error\n# K-Nearest-Neighbors\n\nprint('  k     Accuracy      MSE_In        MSE_Out')\nprint('--------------------------------------------')\nfor k in range(1, 30, 2):\n    knn = KNeighborsClassifier(n_neighbors=k, weights='uniform')\n    knn = knn.fit(scaled_x_train, y_train)\n\n    y_train_predict = knn.predict(scaled_x_train)\n    y_test_predict  = knn.predict(scaled_x_test)\n\n    acc = (y_test_predict == y_test).mean()\n    mse_in  = mean_squared_error(y_train, y_train_predict)\n    mse_out = mean_squared_error(y_test, y_test_predict)\n    \n    \n    print(\"%3d %10.2f %13.4f  %12.4f\" % (k , acc, mse_in , mse_out))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And now with PCA"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import mean_squared_error\n# K-Nearest-Neighbors\n\nprint('  k     Accuracy      MSE_In        MSE_Out')\nprint('--------------------------------------------')\nfor k in range(1, 30, 2):\n    knn = KNeighborsClassifier(n_neighbors=k, weights='uniform')\n    knn = knn.fit(pc, y_train)\n\n    y_train_predict = knn.predict(pc)\n    y_test_predict  = knn.predict(pca.transform(scaled_x_test))\n\n    acc = (y_test_predict == y_test).mean()\n    mse_in  = mean_squared_error(y_train, y_train_predict)\n    mse_out = mean_squared_error(y_test, y_test_predict)\n    \n    \n    print(\"%3d %10.2f %13.4f  %12.4f\" % (k , acc, mse_in , mse_out))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"An increase of 2% in Test Accuracy when using the PCA components!"},{"metadata":{},"cell_type":"markdown","source":"# K-Means Clustering\n\nNow, let's see the performance of a basic KMeans with our PCA components."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\n\nkm = KMeans(n_clusters=2)\nkm.fit(pc)\n\nscaled_x_test = scaler.transform(x_test)\ntest_pcs = pca.transform(scaled_x_test)\n\npredicts = km.predict(test_pcs)\n\nacc1 = (predicts == y_test).mean()\nacc2 = (predicts == np.logical_not(y_test)).mean()\n\nprint('K-Means')\nprint('Test Accuracy: %.2f' % max(acc1, acc2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion\n\nAll models we've tested presented good results, and we could get a nice view of our data with the PCA decomposition."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}