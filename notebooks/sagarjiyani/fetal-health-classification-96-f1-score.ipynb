{"cells":[{"metadata":{},"cell_type":"markdown","source":"# <center><u>Fetal Health Classification</u></center>\n   #### <p>This dataset contains 2126 records of features extracted from Cardiotocogram exams, which were then classified by three expert obstetritians into 3 classes:\n* Normal\n* Suspect\n* Pathological</p>\n \n<p><h3 style=\"display: inline;\">Target :</h3> So in this task, We will classify the data into three categories using various classification algorithms to achieve lowest prediction error.</p>\n\n### Table of Content :\n1. Importing Data and Libraries\n2. Exploratory Data Analysis (EDA)\n3. Data Pre-processing\n6. Modeling & Hypertuning<br />\n    * Logistic Regression<br />\n    * Random Forest Classifier<br />\n    * Gradient Boosting Classifier <br />\n    * XGBoost Classifier <br />\n6. Model Stacking\n7. Plotting a Learning Curve"},{"metadata":{},"cell_type":"markdown","source":"<h2 style='color:blue'>1. Import Necessary Libraries and Dataset</h2>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Data Vizulization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Splitting the data\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\n\n# Algorithms\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom xgboost import XGBClassifier\n\n# Model Stacking\nfrom sklearn.ensemble import StackingClassifier\n\n# For Hyper-parameter Tuning the model\nfrom sklearn.model_selection import GridSearchCV\n\n# For checking Model Performance\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import learning_curve\n\nimport warnings\nwarnings.simplefilter(action=\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/fetal-health-classification/fetal_health.csv')\ndata.head().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" <h2 style='color:blue'>2. Exploratory Data Analysis (EDA)</h2>\n <p>EDA and Data Vizulization gives the basic overview of the quality and nature of the information available before you begin studying it in more detail. A statistical model can be used or not, but primarily EDA is for seeing what the data can tell us beyond the formal modeling or hypothesis testing task.</p>\n<p>In this step, We will get the basic information about the data like Mean, Standard Daviation, Quatiles, Min-Max values of all the numeric features.\n<p>Also, We will try to understand the data using various plots.</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Analyze & Vizulize the Target Variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['fetal_health'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data['fetal_health'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['fetal_health'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Histogram"},{"metadata":{"trusted":true},"cell_type":"code","source":"hist_plot = data.hist(figsize=(20,20))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Correlation Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = data.corr()\n\nplt.figure(figsize=(12,10))\nsns.heatmap(corr, annot=True, cmap='rainbow')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style='color:blue'>3. Data Pre-processing</h2>"},{"metadata":{},"cell_type":"markdown","source":"From the Correlation matrix, we can say that 'histogram_mode', 'histogram_mean' and 'histogram_median' are highly correlated to each other. Also, 'histogram_min' and 'histogram_width' are highly negatively correlated. So we will remove 'histogram_mode', 'histogram_median' and 'histogram_min' columns from the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(['histogram_min','histogram_median','histogram_mode'], axis=1)\ndata","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Find Missing Values :\n<i>The real-world data often has a lot of missing values. The cause of missing values can be data corruption or failure to record data. The handling of missing data is very important during the preprocessing of the dataset as many machine learning algorithms do not support missing values.</i>"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Count the missing and null values\nnv = data.columns[data.isnull().any()]\nprint('Null values = ', nv)\n\nmv = data.columns[data.isna().any()]\nprint('Missing values = ', mv)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Splitting the Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting data into 75% train set and 25% test set\n\nX = data.drop(['fetal_health'], axis=1)\ny = data['fetal_health']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style='color:blue'>4. Modeling and Hypertuning</h2>"},{"metadata":{},"cell_type":"markdown","source":"<h3 style='color: green'>Logistic Regression</h3>"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LogisticRegression()\nmodel.fit(X_train, y_train)\nmodel.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Find out the best parameters using GridSearchCV"},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\"tol\": [0.0001,0.0002,0.0003],\n          \"intercept_scaling\": [1, 2, 3, 4]\n         }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_method = StratifiedKFold(n_splits=3, \n                            random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GridSearchCV_LR = GridSearchCV(estimator=LogisticRegression(), \n                       param_grid=params,\n                       cv=cv_method,\n                       n_jobs=2,\n                       scoring=\"accuracy\"\n                      )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GridSearchCV_LR.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_params_LR = GridSearchCV_LR.best_params_\nbest_params_LR","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression(C=10, intercept_scaling=1, tol=0.0001, penalty=\"l2\", solver=\"liblinear\", random_state=42)\nlr.fit(X_train, y_train)\nlr.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = lr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Classification Report"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Classification Report\")\nprint(classification_report(y_test, pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Confusion Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"ax= plt.subplot()\nsns.heatmap(confusion_matrix(y_test, pred), annot=True, ax = ax, cmap = \"BuPu\");\n\n# labels, title and ticks\nax.set_xlabel(\"Predicted labels\")\nax.set_ylabel(\"True labels\")\nax.set_title(\"Confusion Matrix\")\nax.xaxis.set_ticklabels([\"Normal\", \"Suspect\", \"Pathological\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3 style='color: green'>Random Forest Classifier</h3>"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = RandomForestClassifier()\nmodel.fit(X_train, y_train)\nmodel.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Find out the best parameters using GridSearchCV"},{"metadata":{"trusted":true},"cell_type":"code","source":"params_RF = {\"min_samples_split\": [2, 6, 20],\n             \"min_samples_leaf\": [1, 4, 16],\n             \"n_estimators\" :[100,150, 200, 250],\n             \"criterion\": [\"gini\"]             \n            }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GridSearchCV_RF = GridSearchCV(estimator=RandomForestClassifier(), \n                                param_grid=params_RF, \n                                cv=cv_method,\n                                n_jobs=2,\n                                scoring=\"accuracy\"\n                                )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GridSearchCV_RF.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_params_RF = GridSearchCV_RF.best_params_\nbest_params_RF","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(criterion=\"gini\", n_estimators = 100, min_samples_leaf=1, min_samples_split=2, random_state=42)\nrf.fit(X_train, y_train)\nrf.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_rf = rf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Classification Report"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Classification Report\")\nprint(classification_report(y_test, pred_rf))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Confusion Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"ax= plt.subplot()\nsns.heatmap(confusion_matrix(y_test, pred_rf), annot=True, ax = ax, cmap = \"BuPu\")\n\n# labels, title and ticks\nax.set_xlabel(\"Predicted labels\")\nax.set_ylabel(\"True labels\")\nax.set_title(\"Confusion Matrix\")\nax.xaxis.set_ticklabels([\"Normal\", \"Suspect\", \"Pathological\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3 style='color: green'>Gradient Boosting Classifier</h3>"},{"metadata":{"trusted":true},"cell_type":"code","source":"gbc = GradientBoostingClassifier()\ngbc.fit(X_train, y_train)\nmodel.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_gbc = gbc.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Classification Report"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Classification Report\")\nprint(classification_report(y_test, pred_gbc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Confusion Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = plt.subplot()\nsns.heatmap(confusion_matrix(y_test, pred_gbc), annot=True, ax = ax, cmap = \"BuPu\")\n\n# labels, title and ticks\nax.set_xlabel(\"Predicted labels\")\nax.set_ylabel(\"True labels\")\nax.set_title(\"Confusion Matrix\")\nax.xaxis.set_ticklabels([\"Normal\", \"Suspect\", \"Pathological\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3 style='color: green'>XGBoost Classifier</h3>"},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb = XGBClassifier()\nxgb.fit(X_train, y_train)\nxgb.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_xgb = xgb.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Classification Report\")\nprint(classification_report(y_test, pred_xgb))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = plt.subplot()\nsns.heatmap(confusion_matrix(y_test, pred_xgb), annot=True, ax = ax, cmap = \"BuPu\")\n\n# labels, title and ticks\nax.set_xlabel(\"Predicted labels\")\nax.set_ylabel(\"True labels\")\nax.set_title(\"Confusion Matrix\")\nax.xaxis.set_ticklabels([\"Normal\", \"Suspect\", \"Pathological\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style='color:blue'> Model Stcking</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"estimators = [\n    ('rf', RandomForestClassifier(criterion=\"gini\", n_estimators = 100, min_samples_leaf=1, min_samples_split=2, random_state=42)),\n    ('gb', GradientBoostingClassifier()),\n    ('xgb', XGBClassifier()\n    )\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = StackingClassifier(estimators=estimators, final_estimator=RandomForestClassifier(criterion=\"gini\", n_estimators = 100, min_samples_leaf=1, min_samples_split=2, random_state=42), cv=5)\nclf.fit(X_train, y_train).score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_clf = clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Classification Report\")\nprint(classification_report(y_test, pred_clf))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = plt.subplot()\nsns.heatmap(confusion_matrix(y_test, pred_clf), annot=True, ax = ax, cmap = \"BuPu\")\n\n# labels, title and ticks\nax.set_xlabel(\"Predicted labels\")\nax.set_ylabel(\"True labels\")\nax.set_title(\"Confusion Matrix\")\nax.xaxis.set_ticklabels([\"Normal\", \"Suspect\", \"Pathological\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style='color:blue'>Plotting a Learning Curve</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_learning_curve(estimator, title, x, y, ylim=None, cv=None,\n                        n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5)):\n    \n    plt.figure()\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n        \n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Score\")\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, x, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.grid()\n\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"#80CBC4\",\n             label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"#00897B\",\n             label=\"Cross-validation score\")\n\n    plt.legend(loc=\"best\")\n    return plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression Curve"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_learning_curve(GridSearchCV_LR.best_estimator_,title = \"Logistict Regression learning curve\", x = X_train, y = y_train, cv = cv_method)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random forest Curve"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_learning_curve(GridSearchCV_RF.best_estimator_,title = \"Random Forest learning curve\", x = X_train, y = y_train, cv = cv_method)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Gradient Boosting Classifier Curve"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_learning_curve(gbc,title = \"Gradient Boosting Classifier learning curve\", x = X_train, y = y_train, cv = cv_method)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### XGBoost Classifier Curve"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_learning_curve(xgb, title = \"XGBoost Classifier learning curve\", x = X_train, y = y_train, cv = cv_method)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Stacked Model Curve"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_learning_curve(clf, title = \"Stacked Model learning curve\", x = X_train, y = y_train, cv = cv_method)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}