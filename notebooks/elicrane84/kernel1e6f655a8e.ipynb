{"cells":[{"metadata":{"trusted":false},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def evaluate_model(predictions, probs, train_predictions, train_probs):\n    \"\"\"Compare machine learning model to baseline performance.\n    Computes statistics and shows ROC curve.\"\"\"\n    \n    baseline = {}\n    \n    baseline['recall'] = recall_score(y_test, [1 for _ in range(len(y_test))])\n    baseline['precision'] = precision_score(y_test, [1 for _ in range(len(y_test))])\n    baseline['roc'] = 0.5\n    \n    results = {}\n    \n    results['recall'] = recall_score(y_test, predictions)\n    results['precision'] = precision_score(y_test, predictions)\n    results['roc'] = roc_auc_score(y_test, probs)\n    \n    train_results = {}\n    train_results['recall'] = recall_score(y_train, train_predictions)\n    train_results['precision'] = precision_score(y_train, train_predictions)\n    train_results['roc'] = roc_auc_score(y_train, train_probs)\n    \n#     for metric in ['recall', 'precision', 'roc']:\n#         print(f'{metric.capitalize()} Baseline: {round(baseline[metric], 2)} Test: {round(results[metric], 2)} Train: {round(train_results[metric], 2)}')\n    \n    # Calculate false positive rates and true positive rates\n    base_fpr, base_tpr, _ = roc_curve(y_test, [1 for _ in range(len(y_test))])\n    model_fpr, model_tpr, _ = roc_curve(y_test, probs)\n\n    plt.figure(figsize = (8, 6))\n    plt.rcParams['font.size'] = 16\n    \n    # Plot both curves\n    plt.plot(base_fpr, base_tpr, 'b', label = 'baseline')\n    plt.plot(model_fpr, model_tpr, 'r', label = 'model')\n    plt.legend();\n    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate'); plt.title('ROC Curves');","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def predictAndCreateConfusionMatrix(model,X_predict,y_true):\n    yhat = model.predict(X_predict)\n    \n    cnf_matrix = confusion_matrix(y_true, yhat, labels=[1,0])\n    np.set_printoptions(precision=2)\n\n\n    # Plot non-normalized confusion matrix\n    plt.figure()\n    plot_confusion_matrix(cnf_matrix, classes=['1','0'],normalize= False,  title='Confusion matrix')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import pandas as pd\ncs_test = pd.read_csv(\"../input/give-me-some-credit-dataset/cs-test.csv\")\ncs_training = pd.read_csv(\"../input/give-me-some-credit-dataset/cs-training.csv\")\nsampleEntry = pd.read_csv(\"../input/give-me-some-credit-dataset/sampleEntry.csv\")\nprint(len(cs_training.index))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"dfCredit_NoBaby = cs_training.loc[cs_training['age'] > 0]\ndfCredit_NoBaby_NoNulls = dfCredit_NoBaby.loc[dfCredit_NoBaby['NumberOfDependents'].notnull() & dfCredit_NoBaby['MonthlyIncome'].notnull()]\ndfCredit_Removed  = dfCredit_NoBaby_NoNulls.loc[:, dfCredit_NoBaby_NoNulls.columns != 'Id']\nprint(len(dfCredit_Removed.index))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#filt_df.describe()\nlow = .02\nhigh = .98\nquant_df = dfCredit_Removed.quantile([low, high])\n#print(quant_df)\ndfCredit_RemoveOutliers = dfCredit_Removed.apply(lambda x: x[(x >= quant_df.loc[low,x.name]) & \n                                    (x <= quant_df.loc[high,x.name])], axis=0)\ndfCredit_98Quantile = dfCredit_RemoveOutliers.dropna()\nprint(len(dfCredit_98Quantile.index))\ndfCredit_98Quantile.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"dfOutlierMissing = cs_training.dropna()\ndfOutlierMissing.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"dfCredit_Use = dfOutlierMissing#dfCredit_NoBaby_NoNulls_NoID.dropna()#dfCredit_98Quantile\n#lsIxDelete = dfCredit_Use[dfCredit_Use['DebtRatio'] >= 1].index\n#lsIxDelete += dfCredit_Use[dfCredit_Use['MonthlyIncome'] > 13000].index\n#dfCredit_Use = dfCredit_Use.drop(lsIxDelete)\ndesc = dfCredit_Use.describe()\ndesc","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"dfCredit_Use['NumberOfNonRealEstateCreditLines'] = dfCredit_Use['NumberOfOpenCreditLinesAndLoans']  - dfCredit_Use['NumberRealEstateLoansOrLines']\ndfCredit_Use['TotalDebtIncome'] = dfCredit_Use['DebtRatio'] * dfCredit_Use['MonthlyIncome']\ndfCredit_Use['NumberOfTimesPastDue'] = dfCredit_Use['NumberOfTime30-59DaysPastDueNotWorse'] + dfCredit_Use['NumberOfTime60-89DaysPastDueNotWorse'] + dfCredit_Use['NumberOfTimes90DaysLate']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"dfCredit_Use.loc[:,'disc_age'] = '<29'\n\ndfCredit_Use.loc[:,'age_21_29'] = 0\nlsIx = dfCredit_Use.loc[(dfCredit_Use['age'] <= 29)].index\ndfCredit_Use.ix[lsIx,'age_21_29'] = 1\n\ndfCredit_Use.loc[:,'age_30_69'] = 0\nlsIx = dfCredit_Use.loc[(dfCredit_Use['age'] >= 30) & (dfCredit_Use['age']<= 69)].index\ndfCredit_Use.ix[lsIx,'age_30_69'] = 1\ndfCredit_Use.ix[lsIx,'disc_age'] = '30_69'\n\ndfCredit_Use.loc[:,'age_70_'] = 0\nlsIx = dfCredit_Use.loc[(dfCredit_Use['age'] >= 70)].index\ndfCredit_Use.ix[lsIx,'age_70_'] = 1\ndfCredit_Use.ix[lsIx,'disc_age'] = '>70'","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"dfCredit_Use.loc[:,'disc_numcreditlines'] = '<4'\n\nlsIx = dfCredit_Use.loc[(dfCredit_Use['NumberOfOpenCreditLinesAndLoans'] >=4)].index\ndfCredit_Use.ix[lsIx,'disc_numcreditlines'] = '4+'","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"dfCredit_Use.loc[:,'disc_debtratio'] = '<1'\n\nlsIx = dfCredit_Use.loc[(dfCredit_Use['DebtRatio'] >=1)].index\ndfCredit_Use.ix[lsIx,'disc_debtratio'] = '1+'","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"dfCredit_Use.loc[:,'disc_income'] = '<1000'\n\ndfCredit_Use.loc[:,'income_0_1999'] = 0\nlsIx = dfCredit_Use.loc[(dfCredit_Use['MonthlyIncome'] <= 1999)].index\ndfCredit_Use.ix[lsIx,'income_0_1999'] = 1\n\ndfCredit_Use.loc[:,'income_1999_13000'] = 0\nlsIx = dfCredit_Use.loc[(dfCredit_Use['MonthlyIncome'] > 1999) & (dfCredit_Use['MonthlyIncome']<= 13000)].index\ndfCredit_Use.ix[lsIx,'income_1999_13000'] = 1\ndfCredit_Use.ix[lsIx,'disc_income'] = '1999_13000'\n\ndfCredit_Use.loc[:,'income_13000_'] = 0\nlsIx = dfCredit_Use.loc[(dfCredit_Use['MonthlyIncome'] > 13000)].index\ndfCredit_Use.ix[lsIx,'income_13000_'] = 1\ndfCredit_Use.ix[lsIx,'disc_income'] = '>13000'","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"dfCredit_Use['irc_age_21_29'] = dfCredit_Use['age_21_29'] * dfCredit_Use['age']\ndfCredit_Use['irc_age_30_69'] = dfCredit_Use['age_30_69'] * dfCredit_Use['age']\ndfCredit_Use['irc_age_70_'] = dfCredit_Use['age_70_'] * dfCredit_Use['age']\n\ndfCredit_Use['irc_income_0_1999'] = dfCredit_Use['income_0_1999'] * dfCredit_Use['MonthlyIncome']\ndfCredit_Use['irc_income_1999_13000'] = dfCredit_Use['income_1999_13000'] * dfCredit_Use['MonthlyIncome']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"dfCredit_Use.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"lsContinuousRegressors = ['RevolvingUtilizationOfUnsecuredLines', 'age', 'NumberOfTime30-59DaysPastDueNotWorse',\n                         'DebtRatio','MonthlyIncome','NumberOfOpenCreditLinesAndLoans', 'NumberOfTimes90DaysLate',\n                         'NumberRealEstateLoansOrLines', 'NumberOfTime60-89DaysPastDueNotWorse',\n                         'NumberOfDependents']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"lsContinuousRegressors = ['RevolvingUtilizationOfUnsecuredLines', 'age', 'NumberOfTimesPastDue',\n                            'NumberOfNonRealEstateCreditLines'] #,'NumberOfDependents','TotalDebtIncome',","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import numpy as np\nfrom matplotlib.ticker import NullFormatter\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\nfrom sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\nimport itertools","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"lsContinuousRegressors = ['age','TotalDebtIncome','MonthlyIncome','DebtRatio',\n                         'NumberRealEstateLoansOrLines', \n                         'NumberOfDependents',\n                         'RevolvingUtilizationOfUnsecuredLines',\n                         'NumberOfTime30-59DaysPastDueNotWorse','NumberOfTime60-89DaysPastDueNotWorse','NumberOfTimes90DaysLate',\n                         #'NumberOfOpenCreditLinesAndLoans',\n                         'NumberOfNonRealEstateCreditLines',\n                         'NumberOfDependents']\nlsInteractionRegressors = ['irc_age_21_29','irc_age_30_69','irc_age_70_','irc_income_0_1999','irc_income_1999_13000']\nlsDiscreteRegressors = ['age_21_29','age_70_','income_0_1999','income_13000_']\n\nlsRegressors = lsContinuousRegressors + lsInteractionRegressors + lsDiscreteRegressors\nlsRegressors","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y = np.asarray(dfCredit_Use['SeriousDlqin2yrs'])\nX_cont = np.asarray(dfCredit_Use[lsContinuousRegressors])#\nX_cont_norm = preprocessing.StandardScaler().fit(X_cont).transform(X_cont)\nx_irc = np.asarray(dfCredit_Use[lsInteractionRegressors])\nX_disc = np.asarray(dfCredit_Use[lsDiscreteRegressors])\nX_full = np.concatenate((X_cont_norm,X_disc),axis=1)#x_irc,\nprint(len(y))\nprint(len(X_full))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split( X_cont, y, test_size=0.2, random_state=4)\nprint ('Train set:', X_train.shape,  y_train.shape)\nprint ('Test set:', X_test.shape,  y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"LR = LogisticRegression(C=.01,solver='liblinear').fit(X_train,y_train)\nprint(LR)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from collections import OrderedDict\ndictCoeff = OrderedDict()\ninc = 0\nfor coef in lsRegressors:\n    dictCoeff[coef] = LR.coef_[0][inc]/(1-LR.coef_[0][inc])\n    print(coef + ': ' + str(dictCoeff[coef]))\n    inc+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"predictAndCreateConfusionMatrix(LR,X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"predictAndCreateConfusionMatrix(LR,X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"clf = DecisionTreeClassifier()\nclf = clf.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"predictAndCreateConfusionMatrix(clf,X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"predictAndCreateConfusionMatrix(clf,X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from collections import Counter\ndictCounter = Counter(y_test)\n\nprint(\"Increase in true positive: \" + str((537-465)/dictCounter[1]))\nprint(\"Increase in false positive: \" + str((430-277)/dictCounter[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# RANDOM FOREST\n\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Create the model with 100 trees\nmodel = RandomForestClassifier(n_estimators=100, \n                               bootstrap = True,\n                               max_features = 'sqrt')\n# Fit on training data\nmodel.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Actual class predictions\nrf_predictions = model.predict(X_test)\n# Probabilities for each class\nrf_probs = model.predict_proba(X_test)[:, 1]\n\n# train set\nrf_train_predictions = model.predict(X_train)\n# Probabilities for each class\nrf_train_probs = model.predict_proba(X_train)[:, 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import precision_score, recall_score, roc_auc_score, roc_curve\n\n# Calculate roc auc\nAUC_rf = roc_auc_score(y_test, rf_probs)\nAUC_rf","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from collections import Counter\nprint(Counter(rf_predictions))\nprint(Counter(y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print (classification_report(y_test, rf_predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Compute confusion matrix\ncnf_matrix = confusion_matrix(y_test, rf_predictions, labels=[1,0])\nnp.set_printoptions(precision=2)\n\n# Plot non-normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=['1','0'],normalize= False,  title='Confusion matrix')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"evaluate_model(rf_predictions, rf_probs, rf_train_predictions, rf_train_probs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\n\n# Hyperparameter grid\nparam_grid = {\n    'n_estimators': np.linspace(10, 200).astype(int),\n    'max_depth': [None] + list(np.linspace(3, 20).astype(int)),\n    'max_features': ['auto', 'sqrt', None] + list(np.arange(0.5, 1, 0.1)),\n    'max_leaf_nodes': [None] + list(np.linspace(10, 50, 500).astype(int)),\n    'min_samples_split': [2, 5, 10],\n    'bootstrap': [True, False]\n}\n\n# Estimator for use in random search\nestimator = RandomForestClassifier(random_state = 5)\n\n# Create the random search model\nrs = RandomizedSearchCV(estimator, param_grid, n_jobs = -1, \n                        scoring = 'roc_auc', cv = 3, \n                        n_iter = 10, verbose = 1, random_state=5)\n\n# Fit \nrs.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"rs.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"best_model = rs.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_rfb_predictions = best_model.predict(X_train)\ntrain_rfb_probs = best_model.predict_proba(X_train)[:, 1]\n\nrfb_predictions = best_model.predict(X_test)\nrfb_probs = best_model.predict_proba(X_test)[:, 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"n_nodes = []\nmax_depths = []\n\nfor ind_tree in best_model.estimators_:\n    n_nodes.append(ind_tree.tree_.node_count)\n    max_depths.append(ind_tree.tree_.max_depth)\n    \nprint(f'Average number of nodes {int(np.mean(n_nodes))}')\nprint(f'Average maximum depth {int(np.mean(max_depths))}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"evaluate_model(rfb_predictions, rfb_probs, train_rfb_predictions, train_rfb_probs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Compute confusion matrix\ncnf_matrix = confusion_matrix(y_test, rfb_predictions, labels=[1,0])\nnp.set_printoptions(precision=2)\n\n# Plot non-normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=['1','0'],normalize= False,  title='Confusion matrix')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Calculate roc auc\nAUC_rfb = roc_auc_score(y_testset, rfb_probs)\nAUC_rfb","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python [conda root]","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}