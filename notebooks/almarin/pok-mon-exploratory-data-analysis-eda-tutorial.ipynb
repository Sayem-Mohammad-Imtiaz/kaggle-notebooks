{"cells":[{"metadata":{"_uuid":"8eaf3d493f3a2852811c044bcfd57038b0e4fa88"},"cell_type":"markdown","source":"# Comprehensive Exploratory Data Analysis (EDA) Tutorial with pandas and Pokémon Database (UPDATE 30/11)\n\n## Welcome to this Kernel and thanks for visiting it!\n\nHey Kagglers, this kernel is intended to show steps of EDAs using `pandas` module for `python`. The dataset selected is the _Pokémon_ available [here](https://www.kaggle.com/abcsds/pokemon)! It is an easy and fun database to start using our most basic tools and play around without feeling pressure from competitions.\n\nThe structure of this notebook is the following:\n1. Data exploration: first peak at the data.\n2. More data reviewing!\n3. Data cleaning.\n4. Classification models: predicting character's legendary status and main type.\n5. Regression models: predicting character's HP.\n\nThe idea is that just after performing some action, it is justified so everyone can learn the reasond behind that decision. In data science, is easy to find someone that can simply type code mindlessly. The real challenge is to make all decisions and processes based on a strong foundation. Therefore, if something is not clear enough, I encourage you to ask it in the comments section so we can discuss about it! :)\n\n---\nThe parts already covered are:\n1. `[x] Data exploration: first peak at the data.`\n2. `[ ] More data reviewing!` <- coming soon\n3. `[ ] Data cleaning.` <- coming soon\n4. `[ ] Classification models: predicting character's legendary status and main type.` <- coming soon\n5. `[ ] Regression models: predicting character's HP.` <- coming soon\n---\n"},{"metadata":{"trusted":false,"_uuid":"6a1c4df47af6c4e6f739b93a6e8da8707224d8ff"},"cell_type":"code","source":"# Import relevant packages\nimport matplotlib.pyplot as plt # For plot configuration\nimport numpy as np              # For numerical operations\nimport pandas as pd             # For database management\nimport seaborn as sns           # For plotting data easily\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nsns.set()                       # Set seaborn style so plots are nice!","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"1a326aa5c60d5729ff395f92e94ba1205618a728"},"cell_type":"code","source":"# Read the file with the `.read_csv()` method\ndf = pd.read_csv('../input/Pokemon.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fdf283ca0019f2d000cfe8592a49747a80911c36"},"cell_type":"markdown","source":"## 1. Data exploration: first peak at the data\n\nReminder: the variable types are the following.\n* __Nominal__: names, gender... Variables that have not really an intrinsic numerical value. Categories are nominal variables.\n* __Ordinal__: scales, education degrees... Numerical variables that have order but they do not display proportions (e.g. _very good_ does not necessarily mean that it is the double of _good_ but simply that it is in a higher position).\n* __Discrete__: number of chairs in a room, days in the calendar... Natural numbers (i.e. with no decimals, e.g. 0, 4, 129, -12).\n* __Real__: height, weight... Numbers from the Real numbers set (i.e. any non-complex number, e.g. 0.9182, $\\sqrt{34}$)."},{"metadata":{"_uuid":"4f13e2354cd37476074d5339a0ab2fbfccfab62b"},"cell_type":"markdown","source":"### 1.1 Simple facts about the dataset\n\nCheck the variables of the dataset and obtain a few descriptive statistics."},{"metadata":{"trusted":false,"_uuid":"4428f29ae53840d0eb2c62e6344d959482120c29"},"cell_type":"code","source":"n_rows, n_cols = df.shape\nprint('The dataset has {} rows and {} columns.'.format(n_rows, n_cols))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"583a2de2eebacaa634636bd20f1421cc39473827"},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"c5caa499785d936fe183c90ca30cfe109d8cfddd"},"cell_type":"code","source":"columns = df.columns\nprint('Columns names: {}.'.format(columns.tolist()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"85a212b02cc0ce4e6b897324e94cb3a26b16543f"},"cell_type":"markdown","source":"### 1.2 Insights from `.columns`\n* We have columns with spaces in their names and punctuation symbols (e.g. \".\").\n* The number of the pokemon is called with a __reserved__ `python` symbol."},{"metadata":{"_uuid":"db902026ed4958873ebb1c39bf7f03d5af7c8507"},"cell_type":"markdown","source":"After the insights we have gained it is obvious we have to solve two problems:\n*  In general, naming things with spaces is not recommended. One of the reasons is that if we want to quickly access the feature (e.g. pressing `Tab`), we won't find it and we will have to be typed completely. It is better to replace all spaces with underscores.\n* We need to fix the column with the reserved symbol as well.\n\nLet's fix the columns renaming them :)!"},{"metadata":{"trusted":false,"_uuid":"b6c909394b75257dbf50675188b6dfec778377ce"},"cell_type":"code","source":"# Method 1: step by step\n#    1. Create a copy of the df\n#    2. Assign the new column name to the old one.\n#    3. Delete the old column.\n# Notice jhow this method reorders the columns!\ndf_slow = df.copy()\ndf_slow['Num'] = df['#']\nto_rename = columns[[2,3,8,9]]\nfor col in to_rename:\n    if '.' in col:\n        cola = col.replace('. ', '_')\n    else:\n        cola = col.replace(' ', '_')\n    df_slow[cola] = df[col]\ndf_slow = df_slow.drop(columns=columns[[0,2,3,8,9]])\nprint(df_slow.columns)\n\n\n# Method 2: built-in function\n#    1. Create a copy of the df\n#    2. Create the mapping\n#    3. Apply the function\ndf_good = df.copy()\nmapper = {'#': 'Num'}\nmapper.update({col: col.replace(' ','_') if '.' not in col else col.replace('. ', '_') for col in to_rename.tolist()})\ndf_good.rename(columns=mapper, inplace=True)\nprint(df_good.columns)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e7505b7c707f1edeefc92985e2caf7c67ff25752"},"cell_type":"markdown","source":"With that we can see that we have 13 columns the following data:\n1. Number of Pokémon (discrete variable).\n2. Name of the Pokémon (nominal variable).\n3. Its main type (nominal variable).\n4. Secondary type (nominal variable).\n5. Total: sum of Attack, Defense, Special Attak and Special Defense points (discrete variable).\n6. Stats for fighting that add up to the total (discrete variable).\n7. Generation that it was first seen (nominal variable).\n8. Whether or not the Pokémon is legendary (nominal variable).\n\nIn reality, the stats could be real variables (e.g. Pikachu could have a HP of 34.8 instead of 35) that have been discretized in this dataset."},{"metadata":{"_uuid":"298e528d5ca972a6f2520b61f106ddc13c165503"},"cell_type":"markdown","source":"### 1.3 `unique()` and `describe()`\n\nLet's say that we want to know what are the unique Pokémons that we have:"},{"metadata":{"trusted":false,"_uuid":"b4e74b23ee5d2566254f9079da114baf1714a332"},"cell_type":"code","source":"# 1. We can use the built-in method of pandas \"unique()\"\nnames = df.Name.unique()\n\n# 2. Print a few names:\nprint('Some Pokémon names are: '+('\"{}\", '*3).format(*np.random.choice(names, 3))+\n      'and \"{}\".'.format(*np.random.choice(names,1)))\nprint('The amount of unique Pokémons is {}.'.format(len(names)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"48404eabc63a07d4ad3b88c3cf375ff9f6371813"},"cell_type":"code","source":"df_good.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ad9d352ce79bc3d35a064ef31d20834f872956b8"},"cell_type":"markdown","source":"### 1.4 Insights from `.describe()`\n* It is clear that the stats for the number (i.e. column '#') does not provide any information.\n* 'Total' allows us to see what is the distribution of available points for any character.\n* The following stats show the distribution of each stat. Seems that, given that the mean and the median (i.e. 50%) are close to each other, they seem to follow a normal distribution.\n* The generation is a categorical variable. Therefore, the description doesn't provide anything useful.\n* Since all variables have the same count as the dataset size, we can conclude that these variables have no missing values."},{"metadata":{"trusted":false,"_uuid":"b115dbcc3f5f3015d97aaf50541e63138c5407b2"},"cell_type":"code","source":"# Let's store these variables since we will use it later on\nstats = df_good.columns[4:-3]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fd0476aa7d38636929d72873645ebec0b65ac8f3"},"cell_type":"markdown","source":"### 1.5 Distribution plots\n\n\nNormally, instead of reading the numbers, it is better to see the distribution of the variables so let's do it! :)"},{"metadata":{"trusted":false,"_uuid":"b9772bd2f4d071c6168d92f83f08f5bef6ad9e93"},"cell_type":"code","source":"sns.pairplot(data=df_good.iloc[:,5:-2], \n             kind='reg')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"70fd452e244424e41dd8085514fd728d68d4bfdf"},"cell_type":"markdown","source":"### 1.6 Insights\n* We can see that most of the data is right skewed since all histograms have most of the values in the left.\n* Also we can see that some variables seem to be correlated: for instance the HP and the Attack.\n* It can be seen also that there are outliers in the data. For instance, in the HP vs. Attack it looks that they are highly correlated but it doesn't if we plot Attack vs. HP. When the data has not many outliers, changing the order of the variables should not alter the correlation."},{"metadata":{"_uuid":"c750fc26a1374f4d0537f08b632b19b63a90242b"},"cell_type":"markdown","source":"Let's vamp it up by plotting it depending on the generation they come from so it looks cooler!"},{"metadata":{"trusted":false,"_uuid":"ff7f3ce6bf5dae15aa1eabb6f0939d6b92b2c96c"},"cell_type":"code","source":"sns.pairplot(data=df_good.iloc[:,5:-1],       # Take all stats and the Generation column\n             diag_kind='kde',                 # Instead of a histogram, plot a KDE\n             kind='reg',                      # Plot regression lines as well\n             plot_kws=dict(truncate=True),    # Autoadjust the axis to the data\n             vars=df_good.iloc[:,5:-2],       # Use only the stats columns for the plots...\n             hue='Generation')                # ...and Generation as the separation variable.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"39d020eb393e82704be9e865673f970f9f3398a1"},"cell_type":"markdown","source":"### 1.6 Insights (II)\n* Interessantly enough, it can be seen that eventhough most of the variables seem to follow the same KDE, `Speed` is different for generation 4 with respect of the rest. Likewise with the `Defense`. One could think that the designers of the Pokémon did a bit more innovative characters in that generation.\n* The outliers are from different generations. It would also be interesting to see if they are of the same `Type_1`, `Type_2`, `Legendary` or not. It will be done further down in the more advanced analysis."},{"metadata":{"_uuid":"c5fdcbe7881678ce9437ee7cd97f1ce7d823231d"},"cell_type":"markdown","source":"### 1.7 Categorical variables overview\n\nLet's continue with the analysis for the non-numerical variables. Usually, we would like to know how much of each category we have. For that we have two approaches defined below."},{"metadata":{"trusted":false,"_uuid":"f4bc991710af24de128f7492abdca43bf290db03"},"cell_type":"code","source":"for category in ['Type_1', 'Type_2', 'Generation', 'Legendary']:\n    print('\"{}\" has {} missing values. The rest are:'.format(category, df_good[category].isnull().sum()))\n    \n    # 1.a Simple, built-in method \"value_counts()\"\n    types_simple = df_good[category].value_counts()\n    # 1.b MapReduce strategy: group by type and count the instances, keeping only the number (column 'Num')\n    types_group = df_good.groupby(category).count()['Num']\n    \n    # Both yield the same counting *BUT* the ordering is different:\n    #    - groupby: alphabetical order.\n    #    - value_counts: frequency order.\n    # Either way, we can print any of the results (personally I like the frequency order):\n    print(types_simple, end='\\n\\n')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6a53264ff158c024c4dad012e8db42c7728f4a7e"},"cell_type":"markdown","source":"### 1.8 Insights from categorical variables:\n* Both `Type_` variables have a big amount of categories. This will can be counter productive when trying to learn a model.\n* `Type_2` has a big amount of missing values that represent 386/800=0.48 of the data."},{"metadata":{"_uuid":"c1b149756a7b4b82cad3e0f4522c40bf9b0796f1"},"cell_type":"markdown","source":"## Summary part 1\n* Data is pretty clean and straightforward.\n* We had to rename some columns to avoid further problems.\n* Seems like there are some outliers seen in the numerical variables that we will have to take into account in next steps.\n* Similarly, the categorical variables have probably too many categories and some have a high amount of missing values.\n\n---"},{"metadata":{"_uuid":"b4fef56f7471796aec35365f04c5c529e96d4709"},"cell_type":"markdown","source":"## 2. More on the data"},{"metadata":{"_uuid":"7d1d1ed6d2e75e78dccd83592ab96f9fe76524b4"},"cell_type":"markdown","source":"### 2.1 Cleaning outliers\n\nFirst, let's define a function that it going to help us doing the analysis process simpler."},{"metadata":{"trusted":false,"_uuid":"0f52088da422fb2fbeb8e27ff4ad0bf09c94b357"},"cell_type":"code","source":"# CLEANING OUTLIERS ---- ongoing\n# CATEGORY FIXING ------ todo\n# ONE-HOT LABELING ----- todo\n# PLOTS! --------------- put them everywhere","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"ea208d75162b6c8e9538ac66b77a7686dcbdb687"},"cell_type":"code","source":"def outlier_check(data):\n    \"\"\"\n    This function obtains a pandas Series and plots the distribution\n    of the variable, along with bars that indicate the upper (or \n    lower) 5% of the data.\n    \"\"\"\n    # 1. First computations of maximum, mean and standard deviation\n    M = max(data)\n    m, s = np.mean(data), np.std(data)\n    \n    # 2. L(ow) and H(igh) filters.\n    L, H = m-2*s, m+2*s\n    \n    # 3. Plot congiguration\n    f, ax = plt.subplots()\n    f.set_figheight(5)\n    f.set_figwidth(5)\n    ax.set_ylim([0,0.025])\n    ax.set_xlim([0,M])\n    ax.set_title('\"{}\" outlier detection'.format(data.name))\n    \n    # 3.1 Draw a vertical line in the upper limit and shade it\n    ax.vlines(H, 0, 0.025, color='red', linestyle='dashed')\n    ax.fill_between(x=[H,M], y1=0.025, color='red', alpha=.05)\n    \n    # 3.2 Similarly for the lower limit\n    ax.vlines(L, 0, 0.025, color='red', linestyle='dashed')\n    ax.fill_between(x=[0,L], y1=0.025, color='red', alpha=.05)\n    \n    # 4. Plot the distribution\n    sns.distplot(data, ax=ax)\n    \n    # 5. Return the indices of the outliers\n    return data[(data<L) | (data>H)].index","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"047ffefd14ff0fecc71fee68b2312bfcb3dcc76b"},"cell_type":"markdown","source":"With the helper function `oulier_check()` now we can see fancy plots of our real-valued features."},{"metadata":{"scrolled":false,"trusted":false,"_uuid":"069d2c00f1eefe2077a81a9f0a8747784d2d017d"},"cell_type":"code","source":"df_good['Outlier'] = np.zeros((len(df_good),1))\nfor var in stats:\n    df_good.loc[outlier_check(df_good[var]),'Outlier'] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"f8e8c8a7a89a122ab90df6c07a3ab20fca2f8d11"},"cell_type":"code","source":"len(df_good.loc[df_good.Outlier==1, :])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"647ee93843c6c759b745ad6c4583fe23949b39b9"},"cell_type":"markdown","source":"As one can see, 125 out of 800 Pokémon (16%) are outliers. It is a lot. We need to further investigate what is going on!\n\n#### Research 1:\nWe might suspect that most of them should be Legendary, given that they have special abilities. Let's check it out."},{"metadata":{"trusted":false,"_uuid":"4b299817b7c211130e8e95fa73cb4054c8cd5a82"},"cell_type":"code","source":"legendary = len(df_good[df_good.Legendary==True])\nlegendary_outliers = len(df_good.loc[(df_good.Outlier==1) & (df_good.Legendary==True), :])\nprint('There are {} legendary Pokémon, out of those {} have outlier stats.'.format(legendary, legendary_outliers))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c132f36701c91e7d795a08991896ba3a7088ad64"},"cell_type":"markdown","source":"Eventhough it's a lot of them, not all Legendary characters are actually special!"},{"metadata":{"_uuid":"f5d06194d35fd07c7bfeb66c92bd284eda3fa0f1"},"cell_type":"markdown","source":"#### Research 2:\nWhy are there so many non legendary outliers? Maybe they are the _Mega_ versions of some characters, let's check it out."},{"metadata":{"trusted":false,"_uuid":"eb599d82fe172f17ef57690209d6d3e5f7b0eef9"},"cell_type":"code","source":"normal_outliers = len(df_good.loc[(df_good.Outlier==1) & (df_good.Legendary==False), :])\nmega_outliers = len([pokemon for pokemon in df_good.loc[(df_good.Outlier==1) & (df_good.Legendary==False), 'Name'] \n                 if 'Mega' in pokemon])\n\nprint('There are {} normal outlier Pokémon, out of those {} are \"Mega\" versions.'.format(normal_outliers, mega_outliers))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5c9426530c7491dfe01fb196b7e96624dc149b26"},"cell_type":"markdown","source":"### 2.2 Insigths from outlier analysis\n1. We can breakdown the 125 outliers into: 41 Legendary, 26 Mega and 84 Normal outliers.\n2. As we can see, there are 65 Legendary Pokémons, of which only 41 have stats that are not represented in the 95% of the rest of the Pokémon.\n3. There are, therefore, 24 Legendary Pokémons with not so special stats.\n4. We need to treat the Legendary characters different.\n5. From the rest, the Mega versions are really different from the normal versions.\n6. We need to treat Mega characters different as well!\n7. We can drop the normal Pokémons.\n\n----\n\nOne option to work with the outliers is simply to drop them, which is what I'm going to be doing here. However, other methods of outlier treatment could be easily implemented. They include methods like:\n* Treating the feature in which they are outliers as a random variable coming form a certain probability distribution and assign a random number from that distribution.\n* Same as before but assigning them an extreme value in the distribution.\n* Change the value by the mean, median or mode."},{"metadata":{"trusted":false,"_uuid":"1fb37a9848aea02099cb1a9847839915c4dbfd94"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"097f6e5fcdacd898202a813a56f712153ea833b2"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"e877141425b4b784a2897a94edb6ee4fec8dcc8e"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"5f05ecf238e1c934067611b63a0f0265d8b5b011"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"3c626b84c5ac44d701ae48adbf5b0a2c6137f92d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"c03551d48e9fe1c388f2ece872636bae507732ab"},"cell_type":"code","source":"sns.jointplot(df_good.iloc[:,0], df_good.iloc[:,5], kind='reg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"b39cb01e77d2b3b7c0fb0879ea411a2674cd2712"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"347393eefc1274181d68b2c06e016f1ed508f9a8"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"dcea7a6b7767f7c3fc9e37a040a232f2b90f75d6"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"d789fa7f8819b9825fd3587f68716b066c0ddecf"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"2e8d2531705361d807109ee77b246fa719b0ec59"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}