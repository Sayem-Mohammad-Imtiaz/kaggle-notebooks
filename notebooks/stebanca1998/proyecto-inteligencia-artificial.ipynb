{"cells":[{"metadata":{},"cell_type":"markdown","source":"* Proyecto 2 de Inteligencia Artificial\n\nIntegrantes: \n* Steban Cadena Girldo - 1670129\n* Daniel Diaz - 1629338\n* Liliana Narvaez - 1530302\n* Bryan Biojó - 1629366\n"},{"metadata":{},"cell_type":"markdown","source":"Inicialmente se importan las librerias necesarias para realizar poder implementar los diferentes modelos de machine learning"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.tree import export_graphviz\nimport graphviz\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.naive_bayes import GaussianNB\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lo que hacemos a continuación es asignar la variable \"data\" como un DataFrame de pandas en el cual estan los datos de prueba a ser usados a lo largo del proyecto. \nAdicionalmente, se imprime una descripción de este conjunto de datos, \n"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data=pd.read_csv(\"../input/heart-disease-uci/heart.csv\")\ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"--------------------------------------------------------------------CARACTERISTICAS--------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"A continuación se describe que significa cada sigla del conjunto de caracteristicas que pueden influir en la predicción de una enfermedad del corazón.\n\n* age: Edad del paciente\n* sex: Sexo del paciente (1 si es hombre, 0 si es mujer)\n* cp: Es el tipo de dolor de pecho que presenta el paciente, este puede ser de 4 tipos por lo que los valores que pueden tomar son [0,1,2,3]\n* trestbps: Esta caracteristica representa la presión arterial en reposo\n* chol: Esta caracteristica representa el colesterol serico medido en mg/dl\n* fbs: Es un valor que es 1 si la cantidad de glucosa en la sangre supera los 120  y 0 si no lo hace\n* restecg: Este valor representa los resultados de un electrocardiograma hecho en reposo aplicado al paciente, el cual se clasifica en 3 grupos.  \n* thalach: Este valor es la medida de la frecuencia cardiaca maxima alcanzada por el paciente\n* exang: Es te valor es 1 si el paciente presenta angina inducida por el ejercicio, y 0 si no es así\n* oldpeak: Este valor representa la depresión ST inducida por ejercicio relativo al descanso\n* slope: Este valor representa la pendiente del segmento de pico de ejercicio ST\n* ca: Este valor representa cuantos vasos principales fueron coloreados por fluorosopía\n* thal: thal\n\nClasificando estas caracteristicas en numericas y categoricas obtenemos los dos grupos asi:\n1. Numéricas: age, trestbps, chol, thalach, oldpeak\n2. Categoricas: sex, cp, fbs, restecg, exang, slope, ca, thal\n\nA las variables categoricas se le añade la caracteristica \"target\" el cual es la caracteristica objetivo la cual es 1 si el resultado de la clasificación es positivo para una enfermedad cardiaca y 0 si el resultado es negativo\n\nA continuación se grafican los datos correpsondientes a cada una de estas caracteriticas obtenidos del Dataset. Las variables numéricas se represnetan por medio de histogramas y las variables categoricas por medio de diagramas circulares"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(2, 3, figsize = (15,10))\naxs[0, 0].hist(data[\"age\"], bins=60, alpha=1, edgecolor = 'black',  linewidth=1)\naxs[0, 0].set_title('Edades')\naxs[0, 1].hist(data[\"trestbps\"], bins=60, alpha=1, edgecolor = 'black',  linewidth=1)\naxs[0, 1].set_title('Presión en reposo')\naxs[0, 2].hist(data[\"chol\"], bins=60, alpha=1, edgecolor = 'black',  linewidth=1)\naxs[0, 2].set_title('Colesterol serico')\naxs[1, 0].hist(data[\"thalach\"], bins=60, alpha=1, edgecolor = 'black',  linewidth=1)\naxs[1, 0].set_title('Frecuencia cardiaca max')\naxs[1, 1].hist(data[\"oldpeak\"], bins=60, alpha=1, edgecolor = 'black',  linewidth=1)\naxs[1, 1].set_title('Depresión inducida por ejercicio')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Imprimir las variables categoricas"},{"metadata":{"trusted":true},"cell_type":"code","source":"labels1 ='Hombre','Mujer'\nlabels2 = '0','2','1','3'\nlabels3 = 'Si','No'\nlabels4 = '1','0','2'\nlabels5 = 'No','Si'\nlabels6 = '2','1','0'\nlabels7 = '0','1','2','3','4'\nlabels8 = '2','3','1','0'\nlabels9 = 'Si','No'\n\nfig, axs = plt.subplots(3, 3, figsize = (10,10))\naxs[0, 0].pie(data[\"sex\"].value_counts(),labels=labels1, autopct='%1.1f%%', shadow=True)\naxs[0, 0].set_title('Sexo')\naxs[0, 1].pie(data[\"cp\"].value_counts(),labels=labels2, autopct='%1.1f%%', shadow=True)\naxs[0, 1].set_title('Tipo de dolor de pecho')\naxs[0, 2].pie(data[\"fbs\"].value_counts(),labels=labels3, autopct='%1.1f%%', shadow=True)\naxs[0, 2].set_title('Glucosa > 120')\naxs[1, 0].pie(data[\"restecg\"].value_counts(),labels=labels4, autopct='%1.1f%%', shadow=True)\naxs[1, 0].set_title('Electro en reposo')\naxs[1, 1].pie(data[\"exang\"].value_counts(),labels=labels5, autopct='%1.1f%%', shadow=True)\naxs[1, 1].set_title('Angina por ejercicio')\naxs[1, 2].pie(data[\"slope\"].value_counts(),labels=labels6, autopct='%1.1f%%', shadow=True)\naxs[1, 2].set_title('Pendiente del segmento de pico')\naxs[2, 0].pie(data[\"ca\"].value_counts(),labels=labels7, autopct='%1.1f%%', shadow=True)\naxs[2, 0].set_title('Vasos ppals pintados por flourosopía')\naxs[2, 1].pie(data[\"thal\"].value_counts(),labels=labels8, autopct='%1.1f%%', shadow=True)\naxs[2, 1].set_title('Thal')\naxs[2, 2].pie(data[\"target\"].value_counts(),labels=labels9, autopct='%1.1f%%', shadow=True)\naxs[2, 2].set_title('Ataque al corazon')\n\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"![](http://)El paso a seguir es dividir nuestro conjunto de datos en 2, el conjunto de datos de entrenamiento y el conjunto de pruebas, para ellos se hace uso de la función \"train_test_split\" con la cual le daremos "},{"metadata":{"trusted":true},"cell_type":"code","source":"atributos = data[[\"age\",\"sex\",\"cp\",\"trestbps\",\"chol\",\"fbs\",\"restecg\",\"thalach\",\"exang\",\"oldpeak\",\"slope\",\"ca\",\"thal\"]].values\ntarget = data[\"target\"].values\n\nX_entrenamiento,X_test,y_entrenamiento,y_test = train_test_split(atributos,target,test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"------------------------------------------------------------MODELO DE ÁRBOL DE DECISIÓN------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"Inicialmente vamos a definir un modelo de árbol de decisión sin parametros de entrada para observar el resultado obtenido. Adicional a eso vamos a imprimir el árbol obtenido para ver cuales fueron sus criterios de selección."},{"metadata":{"trusted":true},"cell_type":"code","source":"arbol1 = DecisionTreeClassifier()\narbol1.fit(X_entrenamiento,y_entrenamiento)\n\nprint(\"Score del entrenamiento\")\nprint(arbol1.score(X_entrenamiento,y_entrenamiento))\nprint(\"Score del test\")\nprint(arbol1.score(X_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Analizando los resultados de implementar un modelo de árbol de decisión vemos que si realizamos una prueba sobre el conjunto de datos de entrenamiento la precisión de la predicción es del 100%, lo cual no es bueno pues sabemos que se esta presentando un sobreajuste de los datos, esto lo que quiere decir es que la función que halló el algoritmo se ajusta perfectamente a esos datos o a esas caracteristicas especificas, por lo que cuando recibe datos que no corresponden al conjunto de entrenamiento no genera una buena predicción; Esto se puede ver evidenciado al notar que la precisión con el conjunto de prueba es del 74%.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"features=[\"age\",\"sex\",\"cp\",\"trestbps\",\"chol\",\"fbs\",\"restecg\",\"thalach\",\"exang\",\"oldpeak\",\"slope\",\"ca\",\"thal\"]\nexport_graphviz(arbol1,out_file='arbol1.dot',class_names='target', feature_names=features, impurity=False, filled=True)\nwith open('arbol1.dot') as f:\n    dot_graph=f.read()\ngraphviz.Source(dot_graph)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"En la imagen mostrada anteriormente podemos observar cual es la estructura del árbol para realizar la clasificación dadas la caracteristicas, cuya profundidad es 10 y tiene un total de 41 nodos hoja; Posterior al diagrama del árbol se muestran las importancias dadas a cada caracteristica\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"carac = data.shape[1]\n\nfor i in range(13):\n    print(features[i],\": \",arbol1.feature_importances_[i]*100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Por medio de varias ejecuciones del árbol de decisión, se pudo ver que las características del conjunto de datos a las cuales más se le dieron importancia para evaluar si un paciente padece o no una enfermedad del corazón, fueron el tipo de dolor de pecho(cp) y la cantidad de vasos coloreados en la flouroscopia(ca) mientras que la cantidad de glucosa en la sangre es la característica menos influyente en la toma de decisiones.\n\n\nPara tratar de solucionar el problema de sobre ajuste lo que hicimos fue cambiar los parámetros del árbol de decisión de tal manera que pueda generar un buen modelo. Los parámetros cambiados fueron la profundidad máxima del árbol, a la cual le asignamos un valor de 6, y el numero mínimo de ejemplos que debe cumplir una determinada condición para que el árbol efectué una división, se le asigno un valor de 15.\n\n\nLos resultados de implementar el modelo mencionado pueden ser vistos a continuación:"},{"metadata":{"trusted":true},"cell_type":"code","source":"arbol2 = DecisionTreeClassifier(criterion= \"entropy\",max_depth=6, min_samples_split = 15)\narbol2.fit(X_entrenamiento,y_entrenamiento)\n\nprint(\"Score del entrenamiento\")\nprint(arbol2.score(X_entrenamiento,y_entrenamiento))\nprint(\"Score del test\")\nprint(arbol2.score(X_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Luego de haber ajustado los parametros anteriormente mencionados, notamos que en algunos casos mejoran las precisiones tanto en con el conjunto de entrenamiento como con el conjunto de prueba. La precesión del conjunto de entrenamiento baja hasta valores entre 70% y 90% gracias a lo cual podriamos inferir que el problema de sobreajuste ha sido mejorado; sin embargo esto no necesariamente influye a una buena predicción dados los datos del conjunto de prueba, llegando a oscilar la precisión de estos entre el 65% y el 86%,teniendo asi que no en todos los casos se garantiza una buena predicción."},{"metadata":{"trusted":true},"cell_type":"code","source":"export_graphviz(arbol2,out_file='arbol2.dot',class_names='target', feature_names=features, impurity=False, filled=True)\n\nwith open('arbol2.dot') as f:\n    dot_graph=f.read()\ngraphviz.Source(dot_graph)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Al observar el arbol generado con este segundo modelo vemos que los parametros asignados al modelo han sido tenidos en cuenta,viendo como la profundidad máxima del arbol es de 6 y viendo como los ejemplos con menos de 15 ejemplos no fueron divididos con el fin de generar más ramas dentro del arbol.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"carac = data.shape[1]\nfor i in range(13):\n    print(features[i],\": \",arbol2.feature_importances_[i]*100)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ahora obteniendo las importancias dadas a las caracteristicas presentan algunos cambios, como por ejemplo,vemos como la cantidad de glucosa en la sangre no influye en la decisión tomada por el algoritmo tal como sucedia con el primer modelo. Se le suma a las caracteristicas poco influyentes el electrocardiograma en reposo (trestbps) y los resultados clasificados de haber hecho el electrocardiograma en reposo(restecg). Por otra parte las caracteristicas más influyentes son el (thal) con un 30% de importancia, le sigue el dolor de pecho y finalmete el numero de vasos coloreados con fluorosopía. "},{"metadata":{},"cell_type":"markdown","source":"A continuación, se imprime la matriz de confusión del modelo árbol de decisión. Esta matriz nos permite conocer el numero de aciertos que obtuvo el algoritmo y asi poder analizar si lo consideramos un buen modelo o no"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Matriz de confusión\")\nprint(confusion_matrix(arbol2.predict(X_test), y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---------------------------------------------------------------------MODELO BAYESIANO-------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"Para este modelo se intenta clasificar si dadas unas características corresponden o no a una enfermedad del corazón, utilizando como suposición que los datos son mutuamente excluyentes entre si, es decir que cada característica no influye probabilísticamente en que ocurra ninguna de las otras, y ademas de esto se usa una distribución gaussiana como suposición para el modelo de datos."},{"metadata":{"trusted":true},"cell_type":"code","source":"bayes = GaussianNB()\nbayes.fit(X_entrenamiento,y_entrenamiento)\n\nprint(\"Score del test\")\nprint(bayes.score(X_test,y_test))\nprint(\"Score del entrenamiento\")\nprint(bayes.score(X_entrenamiento,y_entrenamiento))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Se imprime la matriz de confusión del modelo bayesiano"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Matriz de confusión\")\nprint(confusion_matrix(bayes.predict(X_test), y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---------------------------------------------------------------------REDES NEURONALES-------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"Para el modelo con redes neuronales se utilizo la libreria keras la cual ayuda a la creación de este ipo de algoritmos. \nInicialmente podemos decir que nuestra red neuronal posee 4 capas que poseen la siguiente distribución: La capa de entrada, dos capas ocultas y la capa de salida. La  primera capa al ser la capa de caracteristicas o el conjunto de entrada tiene 13 nodos. luego de esto las dos capas siguientes tienen 16 nodos cada una, sin embargo se diferencian en que la primera de estas dos capas cuenta con una función de activación Rectificador o (relu) la segunda de estas capas posee una función de activación \"Sigmoide\", luego de que los datos han pasado por estas tres capas deben llegar a la capa de salida. \n\nUna caracteristica importante es la cantidad de epochs o de iteraciónes que realizará la red neuronal para obtener la función de predicción adecuada o mejor dicho, los pesos bajo los cuales son enviados los parametros de entrada. Nosotros configuramos 1000 iteraciones gracias a que con esta cantidad el modelo ofrece una buena precisión, contrario a lo que sucedía si colocabamos 100 o 200 iteraciones pues las precisiones no eran las adecuadas."},{"metadata":{"trusted":true},"cell_type":"code","source":"red = Sequential()\nred.add(Dense(16, input_dim=13, activation='sigmoid'))\nred.add(Dense(14, activation='relu'))\nred.add(Dense(1, activation='sigmoid'))\n\nred.compile(loss='mean_squared_error',\n              optimizer='adam',\n              metrics=['binary_accuracy'])\n\nred.fit(X_entrenamiento, y_entrenamiento, epochs=1000)\n\nscoreT = red.evaluate(X_test, y_test)\nscoreE = red.evaluate(X_entrenamiento, y_entrenamiento)\n\nprint(\"Score del test\")\nprint(\"%s: %.2f%%\" % (red.metrics_names[1], scoreT[1]*100))\nprint(\"Score del entrenamiento\")\nprint(\"%s: %.2f%%\" % (red.metrics_names[1], scoreE[1]*100))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in red.layers:\n    g=layer.get_config()\n    h=layer.get_weights()\n    print ('Weights of layer: ',h)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como podemos ver en los resultados anteriores, en cada iteración el modelo de la red neuronal va ajustando los pesos de tal manera que se maximice el nivel de precisión que tiene la misma para clasificar los datos."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Matriz de confusión\")\nprint(confusion_matrix(red.predict_classes(X_test), y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** Conclusiones **\n\n\nComo conclusión de los tres modelos podemos decir que el árbol de decisiones es bastante susceptible a sufrir un sobreajuste dependiendo de el tipo de configuración que se le haya pasado como parametro, además de que esté al ajustars tiende a ceñirse bastante al conjunto de datos de entrenamiento y consecuentemete no tener el mismo nivel de precisión al clasificar cuando se le cambia el conjunto de datos. El modelo bayesiano es más preciso a la hora de entrenarse con un conjunto de datos, esto lo podemos evidenciar relacionando el puntaje obtenido del conjunto de datos de entrenamiento y el conjunto de datos de prueba, sin embargo este modelo supone que todas las caracteristicas son mutuamente excluyentes, obviando asi las posibles correlaciones entre estas, como por ejemplo la edad que probabilísticamente está relacionada con la angina inducida por ejercicio, lo cual causa que haya un factor de probabilidad que no sé está teniendo en cuenta. Finalmente el modelo de redes neuronales, es el que más nos resulta útil a la hora de dar una clasificación a los resultados, dado que el puntaje que se obtiene para el conjunto de datos de entrenamiento, no es susceptible a una sobre estimación fácilmente y no tiene el problema probabilístico que se le da a el modelo de bayes.\n\nAdemás de esto podemos ver que un modelo es aceptable dada su matriz de confusión observando si su matriz es diagonalmente dominante, dado que esta indica el número de clasificaciones correctas que realizó el modelo de clasificación.\n\n\n\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}