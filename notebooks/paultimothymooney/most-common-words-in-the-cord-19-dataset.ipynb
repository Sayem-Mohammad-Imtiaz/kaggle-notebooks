{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Most Common Words in the CORD-19 Dataset","metadata":{"papermill":{"duration":0.011715,"end_time":"2020-11-25T17:13:09.01723","exception":false,"start_time":"2020-11-25T17:13:09.005515","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"[CORD-19](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge) is a resource of over 400,000 scholarly articles, including over 150,000 with full text, about COVID-19 and the coronavirus group. \n\nThese are the most common words in the titles of the papers from the CORD-19 dataset. ","metadata":{"papermill":{"duration":0.010488,"end_time":"2020-11-25T17:13:09.038599","exception":false,"start_time":"2020-11-25T17:13:09.028111","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nfrom wordcloud import WordCloud, STOPWORDS\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport warnings \nwarnings.filterwarnings('ignore')\n\ndef count_ngrams(dataframe,column,begin_ngram,end_ngram): \n    # adapted from https://stackoverflow.com/questions/36572221/how-to-find-ngram-frequency-of-a-column-in-a-pandas-dataframe\n    word_vectorizer = CountVectorizer(ngram_range=(begin_ngram,end_ngram), analyzer='word')\n    sparse_matrix = word_vectorizer.fit_transform(df['title'].dropna())\n    frequencies = sum(sparse_matrix).toarray()[0]\n    most_common = pd.DataFrame(frequencies, \n                               index=word_vectorizer.get_feature_names(), \n                               columns=['frequency']).sort_values('frequency',ascending=False)\n    most_common['ngram'] = most_common.index\n    most_common.reset_index()\n    return most_common\n\ndef word_cloud_function(df,column,number_of_words):\n    # adapted from https://www.kaggle.com/benhamner/most-common-forum-topic-words\n    topic_words = [ z.lower() for y in\n                       [ x.split() for x in df[column] if isinstance(x, str)]\n                       for z in y]\n    word_count_dict = dict(Counter(topic_words))\n    popular_words = sorted(word_count_dict, key = word_count_dict.get, reverse = True)\n    popular_words_nonstop = [w for w in popular_words if w not in stopwords.words(\"english\")]\n    word_string=str(popular_words_nonstop)\n    wordcloud = WordCloud(stopwords=STOPWORDS,\n                          background_color='white',\n                          max_words=number_of_words,\n                          width=1000,height=1000,\n                         ).generate(word_string)\n    plt.clf()\n    plt.imshow(wordcloud)\n    plt.axis('off')\n    plt.show()\n\ndef word_bar_graph_function(df,column,title):\n    # adapted from https://www.kaggle.com/benhamner/most-common-forum-topic-words\n    topic_words = [ z.lower() for y in\n                       [ x.split() for x in df[column] if isinstance(x, str)]\n                       for z in y]\n    word_count_dict = dict(Counter(topic_words))\n    popular_words = sorted(word_count_dict, key = word_count_dict.get, reverse = True)\n    popular_words_nonstop = [w for w in popular_words if w not in stopwords.words(\"english\")]\n    plt.barh(range(50), [word_count_dict[w] for w in reversed(popular_words_nonstop[0:50])])\n    plt.yticks([x + 0.5 for x in range(50)], reversed(popular_words_nonstop[0:50]))\n    plt.title(title)\n    plt.show()\n    \ndf = pd.read_csv('/kaggle/input/CORD-19-research-challenge/metadata.csv')  \nthree_gram = count_ngrams(df,'title',3,3)\nwords_to_exclude = [\"my\",\"to\",\"at\",\"for\",\"it\",\"the\",\"with\",\"from\",\"would\",\"there\",\"or\",\"if\",\"it\",\"but\",\"of\",\"in\",\"as\",\"and\",'NaN','dtype']","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":18048.927112,"end_time":"2020-11-25T22:13:57.97624","exception":false,"start_time":"2020-11-25T17:13:09.049128","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Most Common Words","metadata":{"papermill":{"duration":0.010796,"end_time":"2020-11-25T22:13:57.999359","exception":false,"start_time":"2020-11-25T22:13:57.988563","status":"completed"},"tags":[]}},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nword_bar_graph_function(df,'title','Most common words in titles of papers in CORD-19 dataset')","metadata":{"_kg_hide-input":true,"papermill":{"duration":33.971755,"end_time":"2020-11-25T22:14:31.982233","exception":false,"start_time":"2020-11-25T22:13:58.010478","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.bar(three_gram.sort_values('frequency',ascending=False)[0:10].iloc[::-1], \n             x=\"frequency\", \n             y=\"ngram\",\n             title='Most Common 3-Words in Titles of Papers in CORD-19 Dataset',\n             orientation='h')\nfig.show()","metadata":{"_kg_hide-input":true,"papermill":{"duration":1.832966,"end_time":"2020-11-25T22:14:33.827453","exception":false,"start_time":"2020-11-25T22:14:31.994487","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Most Common Journals","metadata":{"papermill":{"duration":0.021376,"end_time":"2020-11-25T22:14:33.873073","exception":false,"start_time":"2020-11-25T22:14:33.851697","status":"completed"},"tags":[]}},{"cell_type":"code","source":"value_counts = df['journal'].value_counts()\nvalue_counts_df = pd.DataFrame(value_counts)\nvalue_counts_df['journal_name'] = value_counts_df.index\nvalue_counts_df['count'] = value_counts_df['journal']\nfig = px.bar(value_counts_df[0:20].iloc[::-1], \n             x=\"count\", \n             y=\"journal_name\",\n             title='Most Common Journals in CORD-19 Dataset',\n             orientation='h')\nfig.show()","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.208518,"end_time":"2020-11-25T22:14:34.100495","exception":false,"start_time":"2020-11-25T22:14:33.891977","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The contents of this code cell were adapted from\n# https://www.kaggle.com/latimerb/cord-19-beginner-eda\ndf2 = pd.read_csv('/kaggle/input/CORD-19-research-challenge/metadata.csv')  \ndf2['publish_time'] = df2['publish_time'].str[:4]\nall_years = df2['publish_time'].values.astype(str)\nall_4_digit = []\nfor y in all_years:\n    if len(y)==4:\n        all_4_digit.append(y)\nall_4_digit = np.array(all_4_digit)\n[years,counts]=np.unique(all_4_digit.astype(int),return_counts=True)\nraw_data = {'years': years, \n        'counts': counts}\ndf2 = pd.DataFrame(raw_data, columns = ['years', 'counts'])\nfig = px.bar(df2.sort_values('years',ascending=False)[0:50].iloc[::-1], \n             x=\"counts\", \n             y=\"years\",\n             title='Most Common Date of Publication in CORD-19 Dataset',\n             orientation='h')\nfig.show()","metadata":{"_kg_hide-input":true,"papermill":{"duration":8.227533,"end_time":"2020-11-25T22:14:42.343187","exception":false,"start_time":"2020-11-25T22:14:34.115654","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sample File and Sample Abstract","metadata":{"papermill":{"duration":0.015059,"end_time":"2020-11-25T22:14:42.374098","exception":false,"start_time":"2020-11-25T22:14:42.359039","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import json\nfile_path = '/kaggle/input/CORD-19-research-challenge/document_parses/pdf_json/252878458973ebf8c4a149447b2887f0e553e7b5.json'\nwith open(file_path) as json_file:\n     json_file = json.load(json_file)\n# Uncomment the line below to preview the entire full-text document\n# json_file ","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.037987,"end_time":"2020-11-25T22:14:42.427561","exception":false,"start_time":"2020-11-25T22:14:42.389574","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(json_file['metadata']['title'])\nprint('\\nAbstract: \\n\\n', json_file['abstract'])","metadata":{"papermill":{"duration":0.026581,"end_time":"2020-11-25T22:14:42.469766","exception":false,"start_time":"2020-11-25T22:14:42.443185","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nword_cloud_function(df,'title',50000)","metadata":{"_kg_hide-input":true,"papermill":{"duration":57.881267,"end_time":"2020-11-25T22:15:40.367817","exception":false,"start_time":"2020-11-25T22:14:42.48655","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.03083,"end_time":"2020-11-25T22:15:40.42931","exception":false,"start_time":"2020-11-25T22:15:40.39848","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]}]}