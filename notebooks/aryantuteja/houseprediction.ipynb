{"cells":[{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#importing sklearn\nimport sklearn\n\n# Common imports\nimport numpy as np\nimport pandas as pd\nimport os\n\n# To plot pretty figures in jupyter notebooks\n%matplotlib inline\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nmpl.rc('axes', labelsize=14)\nmpl.rc('xtick', labelsize=12)\nmpl.rc('ytick', labelsize=12)\n\n# Ignore useless warnings (see SciPy issue #5998)\nimport warnings\nwarnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#getting data from csv\nhouse = pd.read_csv('../input/california-housing-prices/housing.csv')\nhouse.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"house.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"house[\"ocean_proximity\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"house.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plotting histogram\nhouse.hist(bins=50, figsize=(20,15))\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(dpi = 80, figsize = (6,4))\nax = fig.add_axes([1,1,1,1])\nax.set(xlabel = 'Median Income Class',ylabel = 'Frequency',title = 'Distribution of Median Income')\nhouse[\"median_income\"].hist(color='black',ax = ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"house[\"income_cat\"] = pd.cut(house[\"median_income\"],\n                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n                               labels=[1, 2, 3, 4, 5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"house[\"income_cat\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(dpi = 80, figsize = (6,4))\nax = fig.add_axes([1,1,1,1])\nax.set(xlabel = 'Median Income Category',ylabel = 'Frequency',title = 'Distribution of Median Income Category')\nhouse[\"income_cat\"].hist(color = 'orange',ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Most median income values are clustered around 2–5 (tens of thousands of dollars),but some median incomes go far beyond 6. It is important to have a sufficient number of instances in your dataset for each stratum, or else the estimate of the stratum’s importance may be biased. This means that you should not have too many strata, and each stratum should be large enough."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing and Using Stratified shuffle split\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\nsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\nfor train_index, test_index in split.split(house, house[\"income_cat\"]):\n    strat_train_set = house.loc[train_index]\n    strat_test_set = house.loc[test_index]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"house = strat_train_set.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"house.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4,\ns=house[\"population\"]/100, label=\"population\", figsize=(10,7),\nc=\"median_house_value\", cmap=plt.get_cmap(\"jet\"), colorbar=True,\n)\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> This image tells that the housing price is very much related to the location and to the population density."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"corr = house.corr()\nmask = np.triu(np.ones_like(corr,dtype = bool))\n\nplt.figure(dpi=100)\nplt.title('Correlation Analysis')\nsns.heatmap(corr,mask=mask,annot=False,lw=0,linecolor='white',cmap='viridis',fmt = \"0.2f\")\nplt.xticks(rotation=90)\nplt.yticks(rotation = 0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from pandas.tools.plotting import scatter_matrix\nfrom pandas.plotting import scatter_matrix\n\nattributes = [\"median_house_value\", \"median_income\", \"total_rooms\",\n              \"housing_median_age\"]\nscatter_matrix(house[attributes], figsize=(12, 10))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#The most promising attribute to predict the median house value is the median income, so let’s zoom in on their correlation scatterplot\nfig = plt.figure(dpi = 80, figsize = (6,4))\nax = fig.add_axes([1,1,1,1])\n\nhouse.plot(kind=\"scatter\", x=\"median_income\", y=\"median_house_value\",\n             alpha=0.1,color = 'black',ax=ax)\nplt.axis([0, 16, 0, 550000])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> This plot reveals a few things. First, the correlation is indeed very strong; you can clearly see the upward trend and the points are not too dispersed."},{"metadata":{},"cell_type":"markdown","source":"#### Let us create few more attributes !!"},{"metadata":{"trusted":true},"cell_type":"code","source":"house[\"rooms_per_household\"] = house[\"total_rooms\"]/house[\"households\"]\nhouse[\"bedrooms_per_room\"] = house[\"total_bedrooms\"]/house[\"total_rooms\"]\nhouse[\"population_per_household\"]=house[\"population\"]/house[\"households\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = house.corr()\nmask = np.triu(np.ones_like(corr,dtype = bool))\n\nplt.figure(dpi=100)\nplt.title('Correlation Analysis')\nsns.heatmap(corr,mask=mask,annot=False,lw=0,linecolor='white',cmap='cividis',fmt = \"0.2f\")\nplt.xticks(rotation=90)\nplt.yticks(rotation = 0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Not bad! The new bedrooms_per_room attribute is much more correlated with the median house value than the total number of rooms or bedrooms. "},{"metadata":{},"cell_type":"markdown","source":"# Data Pipeline"},{"metadata":{"trusted":true},"cell_type":"code","source":"# droping labels for training set\nhouse = strat_train_set.drop(\"median_house_value\", axis=1) \nhouse_labels = strat_train_set[\"median_house_value\"].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.preprocessing import OneHotEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\n\n# column index\nrooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6\n\nclass CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n    def __init__(self, add_bedrooms_per_room = True): # no *args or **kargs\n        self.add_bedrooms_per_room = add_bedrooms_per_room\n    def fit(self, X, y=None):\n        return self  # nothing else to do\n    def transform(self, X):\n        rooms_per_household = X[:, rooms_ix] / X[:, households_ix]\n        population_per_household = X[:, population_ix] / X[:, households_ix]\n        if self.add_bedrooms_per_room:\n            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n            return np.c_[X, rooms_per_household, population_per_household,\n                         bedrooms_per_room]\n        else:\n            return np.c_[X, rooms_per_household, population_per_household]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"#importing pipeline and standardScaler \nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nnum_pipeline = Pipeline([\n        ('imputer', SimpleImputer(strategy=\"median\")),\n        ('attribs_adder', CombinedAttributesAdder()),\n        ('std_scaler', StandardScaler()),\n    ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\n\nhouse_num = house.drop(\"ocean_proximity\", axis=1)\n\nnum_attribs = list(house_num)\ncat_attribs = [\"ocean_proximity\"]\n\n\nfull_pipeline = ColumnTransformer([\n        (\"num\", num_pipeline, num_attribs),\n        (\"cat\", OneHotEncoder(), cat_attribs),\n    ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"house_prepared = full_pipeline.fit_transform(house)\nhouse_prepared","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Training\nUSING LINEAR REGRESSION, DECISION TREES REGRSSOR AND RANDOM FOREST REGRESSOR FOR MODEL TRAINING AND CHECKING OUT EACH ONE PERFORMANCE AND USING THE BEST ESTIMATOR"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"#importing random forest regressor to predict the value of house\nfrom sklearn.ensemble import RandomForestRegressor\n\nforest_reg = RandomForestRegressor()\nforest_reg.fit(house_prepared, house_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#to know the MSE and MAE of the model used \nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\n\nhouse_predicted = forest_reg.predict(house_prepared)\nforest_mse = mean_squared_error(house_labels, house_predicted)\nforest_rmse = np.sqrt(forest_mse)\nprint(\"RMSE ==> \", forest_rmse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_scores(scores):\n    print(\"Scores:\", scores)\n    print(\"Mean:\", scores.mean())\n    print(\"Standard deviation:\", scores.std())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#impoting cross val score to crossvalidaton about the performance of the model tained\nfrom sklearn.model_selection import cross_val_score\n\nforest_scores = cross_val_score(forest_reg, house_prepared, house_labels,\n                                scoring=\"neg_mean_squared_error\", cv=5)\nforest_rmse_scores = np.sqrt(-forest_scores)\ndisplay_scores(forest_rmse_scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = [\n    # try 12 (3×4) combinations of hyperparameters\n    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n    # then try 6 (2×3) combinations with bootstrap set as False\n    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n  ]\n\nforest_reg = RandomForestRegressor(random_state=42)\n# train across 5 folds, that's a total of (12+6)*5=90 rounds of training \ngrid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n                           scoring='neg_mean_squared_error',\n                           return_train_score=True)\ngrid_search.fit(house_prepared, house_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cvres = grid_search.cv_results_\nfor mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n    print(np.sqrt(-mean_score), params)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluate Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"final_model = grid_search.best_estimator_\n\nX_test = strat_test_set.drop(\"median_house_value\", axis=1)\ny_test = strat_test_set[\"median_house_value\"].copy()\n\nX_test_prepared = full_pipeline.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_predictions = final_model.predict(X_test_prepared)\n\nfinal_mse = mean_squared_error(y_test, final_predictions)\nfinal_rmse = np.sqrt(final_mse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"RMSE on Test ==> \",final_rmse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import stats\n\nconfidence = 0.95\nsquared_errors = (final_predictions - y_test) ** 2\nnp.sqrt(stats.t.interval(confidence, len(squared_errors) - 1,\n                         loc=squared_errors.mean(),\n                         scale=stats.sem(squared_errors)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}