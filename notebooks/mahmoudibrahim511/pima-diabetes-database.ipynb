{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#used libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import MinMaxScaler as Scaler\nfrom sklearn.metrics import classification_report\nfrom sklearn.svm import SVC","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#load data\ndata_set=pd.read_csv(\"../input/pima-indians-diabetes-database/diabetes.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploring Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_set.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_set.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#rows x columns\ndata_set.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#statistics of the data\ndata_set.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check duplicates\ndata_set.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check null values\ndata_set.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#data distribution? \ndata_set.hist(figsize = (20,20))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate the median value for BMI\nmedian_BMI = data_set['BMI'].median()\nprint(median_BMI)\n# Substitute it in the BMI column of the\n# dataset where values are 0\ndata_set['BMI'] = data_set['BMI'].replace(\n    to_replace=0, value=median_BMI)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate the median value for BloodPressure\nmedian_BD = data_set['BloodPressure'].median()\nprint(median_BD)\ndata_set['BloodPressure'] = data_set['BloodPressure'].replace(\n    to_replace=0, value=median_BD)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate the median value for Glucose\nmedian_Glucose = data_set['Glucose'].median()\nprint(median_Glucose)\ndata_set['Glucose'] = data_set['Glucose'].replace(\n    to_replace=0, value=median_Glucose)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate the median value for SkinThickness\nmedian_STH = data_set['SkinThickness'].median()\nprint(median_STH)\ndata_set['SkinThickness'] = data_set['SkinThickness'].replace(\n    to_replace=0, value=median_STH)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate the median value for Insulin\nmedian_Insulin = data_set['Insulin'].median()\nprint(median_Insulin)\ndata_set['Insulin'] = data_set['Insulin'].replace(\n    to_replace=0, value=median_Insulin)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#how many women with 0 Pregnancies?\n(data_set[\"Pregnancies\"]==0).sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_set.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# data visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_set.hist(figsize = (20,20))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"OUTCOMES=pd.Series(data_set['Outcome'].value_counts(ascending = False))\nOUTCOMES","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"OUTCOMES.plot.pie()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = data_set.corr()\ncorr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,10))\np=sns.heatmap(corr, annot=True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Splitting Data & Feature Scaling"},{"metadata":{"trusted":true},"cell_type":"code","source":"#x-->input(features) \nx=data_set.iloc[:,:-1].values\n#y-->output(has diab or not)\ny=data_set.iloc[:,-1].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the training dataset in 2/3 / 1/3\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=1/3,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apply a scaler\nscaler = Scaler()\nscaler.fit(x_train)\nx_train = scaler.transform(x_train)\nx_test = scaler.transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# train a KNN model"},{"metadata":{"trusted":true},"cell_type":"code","source":"KNN1=KNeighborsClassifier(n_neighbors=14)\nKNN1.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predict x_test\ny_pred_KNN_1=KNN1.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#show result\ncn1=confusion_matrix(y_test,y_pred_KNN_1)\ncn1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#training better KNN model\nKNN2=KNeighborsClassifier(leaf_size=10, n_neighbors=25, p=1,weights='uniform',algorithm='auto')\nKNN2.fit(x_train,y_train)\n#predict & show result\ny_pred_KNN_2=KNN2.predict(x_test)\ncn=confusion_matrix(y_test,y_pred_KNN_2)\ncn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#visualize result\nfrom sklearn import metrics\ncnf_matrix = metrics.confusion_matrix(y_test, y_pred_KNN_2)\np = sns.heatmap(pd.DataFrame(cnf_matrix), annot=True,fmt='g')\nplt.title('Confusion matrix')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#classification_report\nprint(classification_report(y_test,y_pred_KNN_2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# train a SVC model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_svc=SVC(C=10.0,kernel='rbf',gamma='auto')\nmodel_svc.fit(x_train,y_train)\ny_pred_SVC=model_svc.predict(x_test)\ncn=confusion_matrix(y_test,y_pred_SVC)\ncn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cnf_matrix_2 = metrics.confusion_matrix(y_test, y_pred_SVC)\np = sns.heatmap(pd.DataFrame(cnf_matrix_2), annot=True,fmt='g')\nplt.title('Confusion matrix')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test,y_pred_SVC))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Test models"},{"metadata":{"trusted":true},"cell_type":"code","source":"#extrnal data\n#SVC_model\nnew_df = pd.DataFrame([[6, 168, 72, 35, 0, 43.6, 0.627, 65]])\nnew_df_scaled = scaler.transform(new_df)\nprediction_SVC_1 = model_svc.predict(new_df_scaled)\nprediction_SVC_1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#KNN_model\nprediction_KNN_1 = KNN2.predict(new_df_scaled)\nprediction_KNN_1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#random row from data\n#SVC_model\nrow_3 = pd.DataFrame([[1,89,66,23,94,28.1,0.167,21]])\nrow_3_scaled=scaler.transform(row_3)\nprediction_SVC_2 = model_svc.predict(row_3_scaled)\nprediction_SVC_2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#KNN_model\nprediction_KNN_2 = KNN2.predict(row_3_scaled)\nprediction_KNN_2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# save models"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\nPkl_Filename = \"KNN.pkl\"  \n\nwith open(Pkl_Filename, 'wb') as file:  \n    pickle.dump(KNN2, file)\n# Load the Model back from file\nwith open(Pkl_Filename, 'rb') as file:  \n    Pickled_LR_Model = pickle.load(file)\n\nPickled_LR_Model.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Pkl_Filename_2 = \"SVC.pkl\"  \n\nwith open(Pkl_Filename_2, 'wb') as file:  \n    pickle.dump(model_svc, file)\n# Load the Model back from file\nwith open(Pkl_Filename_2, 'rb') as file:  \n    Pickled_LR_Model_2 = pickle.load(file)\n\nPickled_LR_Model_2.predict(x_test)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}