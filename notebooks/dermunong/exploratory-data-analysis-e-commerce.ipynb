{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Source\nhttps://www.kaggle.com/carrie1/ecommerce-data\n\n# Context\nTypically e-commerce datasets are proprietary and consequently hard to find among publicly available data. However, The UCI Machine Learning Repository has made this dataset containing actual transactions from 2010 and 2011. The dataset is maintained on their site, where it can be found by the title \"Online Retail\".\n\n# Content\n\"This is a transnational data set which contains all the transactions occurring between 01/12/2010 and 09/12/2011 for a UK-based and registered non-store online retail.The company mainly sells unique all-occasion gifts. Many customers of the company are wholesalers.\"\n\n# Acknowledgements\nPer the UCI Machine Learning Repository, this data was made available by Dr Daqing Chen, Director: Public Analytics group. chend '@' lsbu.ac.uk, School of Engineering, London South Bank University, London SE1 0AA, UK.\n\n# Inspiration\nAnalyses for this dataset could include time series, clustering, classification and more.\n\n1. Data Preparation\n2. Exploring the content of variables\n    * Negative quantity and unitprice\n    * Country\n    * Customer\n    * Product\n3. Trending\n    * New Customers by month\n    * Sales by month"},{"metadata":{},"cell_type":"markdown","source":"# 1. Data Preparation"},{"metadata":{},"cell_type":"markdown","source":"## Import the library and data"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objs as go\nimport datetime as dt\nfrom plotly.offline import init_notebook_mode,iplot\nimport warnings\n\n\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\n# Any results you write to the current directory are saved as output.# 1. Data Preparation","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/ecommerce-data/data.csv',encoding = \"ISO-8859-1\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check if there is any missing data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems that there're many rows which **CustomerID** is missing and a few row with (product) ** Description** is missing. I'll keep in mind about this but not filter it out yet.\n\nNext, I'm going to check the type of data in each columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Convert **InvoiceDate** to datetime"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['InvoiceDate'] = df['InvoiceDate'].astype('datetime64[ns]')\n\n#Convert date to year-month\ndf['InvoiceMonth'] = df['InvoiceDate'].dt.strftime('%Y-%m')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Exploring the content of variables"},{"metadata":{},"cell_type":"markdown","source":"## 2.1 Negative Quantity and UnitPrice"},{"metadata":{},"cell_type":"markdown","source":"Take a quick look in numerical columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The **min** in each column is negative value which probably means a refund order or the data is incorrect but I assume that it's a refund order. I'll check more about it, start with negative **Quantity**."},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['Quantity']<0].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The **InvoiceNo** has prefix **C** which probably means canceled order. I'll look into **CustomerID** 17584 data if we find something else."},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['CustomerID']==17548]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The **InvoiceNo** 550755 and C552049 are exactly the same in quantity and products, but the **InvoiceDate** of **C** is over a month later. So I think **InvoiceNo** with C in prefix is refund order.\n\nAnother case is **InvoiceNo** C536391 which has no matched order but if we look at the **InvoiceDate** and **index**, this refund order is very early in dataset, so I think it refund for the order that occured before the company collected the data.\n\nLet's see if there're a lot of refunds."},{"metadata":{"trusted":true},"cell_type":"code","source":"cnt_order = df[df['Quantity']>0]['InvoiceNo'].nunique()\ncnt_refund = df[df['Quantity']<0]['InvoiceNo'].nunique()\n\n\nprint(\"Total Orders : \",cnt_order)\nprint(\"Total Refund Order : \",cnt_refund)\nprint(\"%Refund : \",cnt_refund/(cnt_order)*100,\"%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Number of refund order is aroud 25%! We should dig deeper to find why the %refund is so high (may be I was wrong about refund).\n\nI create **RefundFlg** to make in easier when we want to filter it."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['RefundFlg'] = df['Quantity']<0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finding out which products has the most %refund"},{"metadata":{"trusted":true},"cell_type":"code","source":"prod_order = df[df['Quantity']>0].groupby(['StockCode','Description']).InvoiceNo.nunique().sort_values(ascending = False).reset_index()\nprod_order = prod_order.rename(columns = {'InvoiceNo' : 'TotalOrder'})\nprod_order_refund = df[df['Quantity']<0].groupby(['StockCode','Description']).InvoiceNo.nunique().sort_values(ascending = False).reset_index()\nprod_order_refund = prod_order_refund.rename(columns = {'InvoiceNo' : 'TotalRefundOrder'})\n\njoin_prod_order = prod_order.merge(prod_order_refund,left_on = [\"StockCode\",\"Description\"],right_on = [\"StockCode\",\"Description\"],how = 'left')\njoin_prod_order['%Refund'] = join_prod_order['TotalRefundOrder']/join_prod_order['TotalOrder']*100\njoin_prod_order = join_prod_order.sort_values(by = 'TotalRefundOrder',ascending = False)\njoin_prod_order.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**M** doesn't seem like the name of product, may be there is something is hidden inside the data.\n\nThis time I'll sort by %refund but select only product that has at least 10 refund order."},{"metadata":{"trusted":true},"cell_type":"code","source":"join_prod_order = join_prod_order.sort_values(by = '%Refund',ascending = False)\njoin_prod_order[join_prod_order['TotalRefundOrder']>=10].head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The top 4 doesn't seem like the name of products and **TotalRefundOrder** is higher that **TotalOrder**! From the descriptions, I think in this case, it is about additional fee or discounted fee.\n\nEven the top 4 is not the problems, other products in top 10 seem to be problems and should find out why these product has high %refund.\n\nNext, I'll try to recalculate %refund again by excluding the non-product (top 4 in above table)"},{"metadata":{"trusted":true},"cell_type":"code","source":"prod_only_order = join_prod_order[~join_prod_order['StockCode'].isin(['AMAZONFEE','S','BANK CHARGES','M'])]\nTotalRefundProdOrder = prod_only_order['TotalRefundOrder'].sum()\nTotalReProdOrder = prod_only_order['TotalOrder'].sum()\nprint(\"%Refund : \",TotalRefundProdOrder/TotalReProdOrder*100,\"%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"%Refund is 1.68%. It makes a lot more sense!"},{"metadata":{},"cell_type":"markdown","source":"> **Comment on this part:**\n    It's okay to use C as prefix to define that this order is refund but it would be a lot better if it can specify which order is refunded. For example, **InvoiceNo** : C1234 is the refund order of **InvoiceNo** : 1234 or you can create a new column that tell which ordered is refunded (the value of this column in normal order is null). "},{"metadata":{},"cell_type":"markdown","source":"Next let's see the data with negative **UnitPrice**."},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['UnitPrice']<0].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The prefix of **InvoiceNo** is A in thist case and **Description** tell us that it means bad debt. So the company might give customers credit and some of them didn't pay back and becomes bad debt."},{"metadata":{},"cell_type":"markdown","source":"Creating **Net** column for easier calculation sales in the future. The **Net** is calculated from **Quantity** x **UnitPrice**. \n\nNote : Keep in mind that the refund order has negative **Net** value"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Net'] = df['Quantity']*df['UnitPrice']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.2 Country"},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_by_country = df.groupby(['Country']).Net.sum().sort_values(ascending = False).reset_index()\nTotalSales = sales_by_country['Net'].sum()\n\n\nsales_by_country['% of total sales'] = sales_by_country['Net']/TotalSales\n#Top 5 countries by sales\nsales_by_country.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most of the sales are from UK which is around 84% of total sales (Company is based in UK)\n"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## 2.3 Customers\n\nIn this part I'd like to learn more about the customers. I'll start with calculating:\n* Average per Order (AOV)\n* Repeat Customers : Customers who has more than 1 orders\n\nNote : \n* There're many rows that **CustomerID** is missing so I'll filter out in this part.\n* Assume that there is no refund and bad debt to simplify calculation"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_wt_cust = df[(df['CustomerID'].notnull()) & (df['Quantity']>0)]\n\norder_net = df_wt_cust.groupby(['InvoiceNo']).Net.sum()\naov = order_net.mean()\nplt.hist(order_net,bins=1000)\nplt.xlim(0,2000)\nplt.xlabel(\"Order value\")\nplt.ylabel(\"Number of orders\")\nprint(\"AOV : \",aov)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The aov is 480. Next I'm going to find the %repeat customers.\n\nFrom the last part, we learned that there're refunded orders, so I'll calculated number of orders per customer by count total orders and subtract by total refund order by each customer"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Repeat Customers\n\n#Exlude non-product rows\n\ndf_for_rpt_cust = df_wt_cust.copy()\ndf_for_rpt_cust = df_for_rpt_cust[~df_for_rpt_cust['StockCode'].isin(['AMAZONFEE','S','BANK CHARGES','M'])]\n\ncust_wt_total_order = df_for_rpt_cust[df_for_rpt_cust['Net']>0].groupby(['CustomerID']).InvoiceNo.nunique().reset_index()\ncust_wt_total_order = cust_wt_total_order.rename(columns = {'InvoiceNo' : 'TotalOrder'})\n\ncust_wt_total_refund_order = df_for_rpt_cust[df_for_rpt_cust['Net']<0].groupby(['CustomerID']).InvoiceNo.nunique().reset_index()\ncust_wt_total_refund_order = cust_wt_total_refund_order.rename(columns = {'InvoiceNo' : 'TotalRefundOrder'})\n\njoin_cust_wt_total_order = cust_wt_total_order.merge(cust_wt_total_refund_order,left_on = 'CustomerID',right_on='CustomerID',how = 'left')\n# convert null to 0\njoin_cust_wt_total_order['TotalRefundOrder'] = np.where(join_cust_wt_total_order['TotalRefundOrder'].isnull(),0,join_cust_wt_total_order['TotalRefundOrder'])\njoin_cust_wt_total_order['TotalSuccessOrder'] = join_cust_wt_total_order['TotalOrder']-join_cust_wt_total_order['TotalRefundOrder']\n\njoin_cust_wt_total_order['RepeatFlg'] = join_cust_wt_total_order['TotalSuccessOrder']>=2\n\nCntCustomer = join_cust_wt_total_order.CustomerID.nunique()\nCntRepeatCustomer = join_cust_wt_total_order[join_cust_wt_total_order['RepeatFlg']==True].CustomerID.nunique()\nPctRepeatCustomer = CntRepeatCustomer/CntCustomer\n\nprint(\"%Repeat Customer : \",PctRepeatCustomer*100,\"%\")\n\nplt.hist(join_cust_wt_total_order['TotalSuccessOrder'],bins = 100)\nplt.xlim(0,30)\nplt.xlabel(\"Number of Orders\")\nplt.ylabel(\"Number of Customers\")\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"%Repeat Customer is 65.5% which is pretty high and many customers keep coming back multiple times.\n\nLet's see which products that make customers keep coming back"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_wt_cust.groupby(['CustomerID','Description']).InvoiceNo.nunique().sort_values(ascending = False).reset_index().head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the top 10 products, we learn that there're customers who buy a lot of products and a lot of orders. These customers might buy this orders to sell in their area (just guessing)\n\nThe previous data table makes me curious about sales concentration in customers. If most of the sales are from just a few of  customers, I think it's risky for the company because when these customer gone, all of the sales gone.\n\nThe next thing I'm going to find is the number of customers that make 80% sales of the company. I want to make sure that this number is not too low. I'll select only sales in last 3 months (from 9Sep2011)"},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_by_cust = df_wt_cust[df_wt_cust['InvoiceDate']>dt.date(2011,9,9)].groupby('CustomerID').Net.sum().sort_values(ascending=False).reset_index()\nTotalSales = sales_by_cust.Net.sum()\nsales_by_cust['%TotalSales'] = sales_by_cust['Net']/TotalSales\n\n\ndef cust_concentration(threshold):\n\n    cnt_cust = 0\n    accm_pct = 0\n\n    for index, row in sales_by_cust.iterrows():\n        if accm_pct ==0:\n            accm_pct = row['%TotalSales']\n        else:\n            accm_pct = accm_pct+row['%TotalSales']\n        cnt_cust = cnt_cust+1\n        \n        if accm_pct>=threshold:\n            return cnt_cust\n\n\nprint(\"70% of sales are from \",cust_concentration(0.7),\" customers\")        \nprint(\"80% of sales are from \",cust_concentration(0.8),\" customers\")\nprint(\"90% of sales are from \",cust_concentration(0.9),\" customers\")\nprint(\"100% of sales are from \",sales_by_cust.CustomerID.nunique(),\" customers\")\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"80% of sales are from 956 customers which is pretty high number. So even some customers stop buying, it won't affect the company mmuch."},{"metadata":{},"cell_type":"markdown","source":"## 2.4 Products\n\nIt's the same as customer, I want to make sure that company sales don't rely to much on some products. So I'm going to find product sales concentration, the approach is the same as customers.\n\nNote : Calculation in this case is not related to the **CustomerID**, so I'm going to use all data to calculate (even **CustomerID** is missing)."},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_by_prod = df[df['InvoiceDate']>dt.date(2011,9,9)].groupby('StockCode').Net.sum().sort_values(ascending=False).reset_index()\nTotalSalesAll = sales_by_prod.Net.sum()\nsales_by_prod['%TotalSales'] = sales_by_prod['Net']/TotalSalesAll\n\ndef prod_concentration(threshold):\n\n    cnt_prod = 0\n    accm_pct = 0\n\n    for index, row in sales_by_prod.iterrows():\n        if accm_pct ==0:\n            accm_pct = row['%TotalSales']\n        else:\n            accm_pct = accm_pct+row['%TotalSales']\n        cnt_prod = cnt_prod+1\n        \n        if accm_pct>=threshold:\n            return cnt_prod\n\n\nprint(\"70% of sales are from \",prod_concentration(0.7),\" products\")        \nprint(\"80% of sales are from \",prod_concentration(0.8),\" products\")\nprint(\"90% of sales are from \",prod_concentration(0.9),\" products\")\nprint(\"100% of sales are from \",sales_by_prod.StockCode.nunique(),\" products\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The number of products is high enough, so the company don't rely to much on few products."},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# 3. Trending\n\nIn this part, I want to see if company is still okay by looking at trend in sales and customers."},{"metadata":{},"cell_type":"markdown","source":"## 3.1 Number of new customers by month"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf_for_trend = df.copy()\n\n#Define new customer\n\ncust_wt_fst_order = df_for_trend.groupby(['CustomerID']).InvoiceDate.min().reset_index()\ncust_wt_fst_order = cust_wt_fst_order.rename(columns = {\"InvoiceDate\" : \"FirstInvoiceDate\"})\n\ndf_for_trend = df_for_trend.merge(cust_wt_fst_order,left_on = 'CustomerID',right_on = 'CustomerID',how = 'left')\n\ndf_for_trend['FirstOrderFlg'] = (df_for_trend['InvoiceDate'] == df_for_trend['FirstInvoiceDate'])\n\ndf_new_cust = df_for_trend[df_for_trend['FirstOrderFlg']==True][['CustomerID','InvoiceMonth']].drop_duplicates()\n\nagg_df_new_cust = df_new_cust.groupby(\"InvoiceMonth\").CustomerID.nunique().reset_index()\nplt.bar(agg_df_new_cust['InvoiceMonth'],agg_df_new_cust['CustomerID'])\nplt.xticks(rotation=90)\nplt.xlabel(\"InvoiceMonth\")\nplt.ylabel(\"Number of New Customers\")\nplt.title('Number of New Customers by month')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"agg_df_cust = df_for_trend.groupby(\"InvoiceMonth\").CustomerID.nunique().reset_index()\n\nplt.bar(agg_df_cust['InvoiceMonth'],agg_df_cust['CustomerID'])\nplt.xticks(rotation=90)\nplt.xlabel(\"InvoiceMonth\")\nplt.ylabel(\"Number of Customers\")\nplt.title('Number of Customers by month')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.2 Sales by month"},{"metadata":{"trusted":true},"cell_type":"code","source":"agg_sales = df_for_trend.groupby('InvoiceMonth').Net.sum().reset_index()\n\nplt.bar(agg_df_cust['InvoiceMonth'],agg_df_cust['CustomerID'])\nplt.xticks(rotation=90)\nplt.xlabel(\"InvoiceMonth\")\nplt.ylabel(\"Sales\")\nplt.title('Sales by month')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the chart above, it seems that the data on Dec2011 is not complete, so we'll look only data from Dec10-Nov11 (12 months).\n\nNumber of new customers is clearly in downtrend during Mar11-Aug11 and higher in Sep11-Nov11 because of high season period (data from sales by month that sales spike during the end of the year). One thing that company should be concern is customer acquisition because customer has their own lifecycle, so one day they'll churn anyway. There're many things that company can do such as increasing budget for acquiring new customers, analyzing the source of new customers to improve stretegies.\n\nAnother thing we learn from chart is seasonality is sales. Because the products of the company is gift, it depends on holidies or ceremonies (as we can see from sales at the end of the year). So the company should always prepare in inventory and manpower before peak season."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}