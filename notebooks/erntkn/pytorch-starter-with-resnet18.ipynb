{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Versions:**\n* v2: Changed optimizer to SGD, it converged better and faster. Accuracy **%94**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install torchsummary","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport time\nimport torch\nimport torch.nn as nn\nfrom torchsummary import summary\nimport torchvision\nfrom torchvision import transforms, models\nfrom torch.utils.data import Dataset, DataLoader, random_split\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport time\nimport cv2\nfrom skimage import io, color\nfrom PIL import Image\nfrom sklearn.preprocessing import LabelEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/bee-vs-wasp/kaggle_bee_vs_wasp/labels.csv\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in data.index:\n    data[\"path\"].iloc[i] = data[\"path\"].iloc[i].replace(\"\\\\\", \"/\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le = LabelEncoder()\nle.fit(data[\"label\"])\ndata[\"label\"] = le.transform(data[\"label\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.is_validation.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.is_final_validation.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_data(dt):\n    idx = list()\n    a = pd.DataFrame()\n    b = pd.DataFrame()\n    for i in data.index:\n        if dt[\"is_validation\"].iloc[i] == 1:\n            a = a.append(dt.iloc[i])\n            idx.append(i)\n        if dt[\"is_final_validation\"].iloc[i] == 1:    \n            b = b.append(dt.iloc[i])\n            idx.append(i)\n\n    dt = dt.drop(dt.index[idx])\n    dt = dt.reset_index()\n    a = a.reset_index()\n    b = b.reset_index()\n    return dt, a, b \n\ntrain_df, val_df, test_df = split_data(data)\n# sanity check\nprint(\"Length of train dataset: \", len(train_df))\nprint(\"Length of validation dataset: \" ,len(val_df))\nprint(\"Length of test dataset: \", len(test_df))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_df.label = val_df.label.astype(np.int64)\ntest_df.label = test_df.label.astype(np.int64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.RandomResizedCrop(224),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\ntest_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class BeeDataset(Dataset):\n    def __init__(self, df:pd.DataFrame, imgdir:str, train:bool,\n                 transforms=None):\n        self.df = df\n        self.imgdir = imgdir\n        self.train = train\n        self.transforms = transforms\n    \n    def __getitem__(self, index):\n        im_path = os.path.join(self.imgdir, self.df.iloc[index][\"path\"])\n        x = cv2.imread(im_path)\n        x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n        x = cv2.resize(x, (224, 224))\n\n        if self.transforms:\n            x = self.transforms(x)\n        \n        if self.train:\n            y = self.df.iloc[index][\"label\"]\n            return x, y\n        else:\n            return x\n    \n    def __len__(self):\n        return len(self.df)\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.model = models.resnet18(pretrained=True)\n        self.model.fc = nn.Linear(512, 4)\n    \n    def forward(self, x):\n        output = self.model(x)\n        return output\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = BeeDataset(df=train_df,\n                        imgdir=\"../input/bee-vs-wasp/kaggle_bee_vs_wasp\",\n                        train=True,\n                        transforms=train_transform)\n\nval_data = BeeDataset(df=val_df,\n                      imgdir=\"../input/bee-vs-wasp/kaggle_bee_vs_wasp\",\n                      train=True,\n                      transforms=test_transform)\n\ntest_data = BeeDataset(df=test_df,\n                       imgdir=\"../input/bee-vs-wasp/kaggle_bee_vs_wasp\",\n                       train=True,\n                       transforms=test_transform)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\narch = Net()\narch.to(device)\noptim = torch.optim.SGD(arch.parameters(), lr=1e-3, momentum=0.9)\n\n\ntrain_loader = DataLoader(dataset=train_data, shuffle=True, batch_size=32, num_workers=4)\nval_loader = DataLoader(dataset=val_data, shuffle=True, batch_size=32, num_workers=4)\ntest_loader = DataLoader(dataset=test_data, shuffle=True, batch_size=32, num_workers=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"summary(batch_size=32, input_size=(3, 224, 224), model=arch)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(model, optimizer, n_epochs, criterion):\n    start_time = time.time()\n    for epoch in range(1, n_epochs+1):\n        epoch_time = time.time()\n        epoch_loss = 0\n        correct = 0\n        total=0\n        print(\"Epoch {} / {}\".format(epoch, n_epochs))\n        model.train()\n        \n        for inputs, labels in train_loader:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            optimizer.zero_grad() # zeroed grads\n            outputs = model(inputs) # forward pass\n            loss = criterion(outputs, labels) # softmax + cross entropy\n            loss.backward() # back pass\n            optimizer.step() # updated params\n            epoch_loss += loss.item() # train loss\n            _, pred = torch.max(outputs, dim=1)\n            correct += (pred.cpu() == labels.cpu()).sum().item()\n            total += labels.shape[0]\n        acc = correct / total\n        \n        model.eval()\n        a=0\n        pred_val=0\n        correct_val=0\n        total_val=0\n        with torch.no_grad():\n            for inp_val, lab_val in val_loader:\n                inp_val = inp_val.to(device)\n                lab_val = lab_val.to(device)\n                out_val = model(inp_val)\n                loss_val = criterion(out_val, lab_val)\n                a += loss_val.item()\n                _, pred_val = torch.max(out_val, dim=1)\n                correct_val += (pred_val.cpu()==lab_val.cpu()).sum().item()\n                total_val += lab_val.shape[0]\n            acc_val = correct_val / total_val\n        epoch_time2 = time.time()\n        print(\"Duration: {:.0f}s, Train Loss: {:.4f}, Train Acc: {:.4f}, Val Loss: {:.4f}, Val Acc: {:.4f}\"\n              .format(epoch_time2-epoch_time, epoch_loss/len(labels), acc, a/len(lab_val), acc_val))\n    end_time = time.time()\n    print(\"Total Time:{:.0f}s\".format(end_time-start_time))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def eval_model(model):\n    correct = 0\n    total = 0\n    model.eval()\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images = images.to(device)\n            labels = labels.to(device)\n            outputs = model(images)\n            _, pred = torch.max(outputs, dim=1)\n            correct += (pred == labels).sum().item()\n            total += labels.shape[0]\n    print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_model(model=arch, optimizer=optim, n_epochs=15, criterion=criterion)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eval_model(arch)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### I will update this notebook overtime, every upvote appreciated. If you have any questions or improvements feel free to comment.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}