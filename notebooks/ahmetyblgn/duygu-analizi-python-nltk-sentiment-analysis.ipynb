{"cells":[{"metadata":{"_uuid":"06618ca7bf3370f24475d2cd39f8a3ac076c53fb"},"cell_type":"markdown","source":"** Duygu analizi:**  Yapacağımız işlem duyguların kategorik olarak düzenlenmesi ve duyguları pozitif, negatif yada nötr olarak sınıflandırılma işlemidir."},{"metadata":{"trusted":true,"_uuid":"e165adebea563d52d8f7bdc6e344b56f910c548b"},"cell_type":"code","source":"#Öncelikle kullanacağımız python kütüphanaelerini ekliyerek çalışmamıza başlıyoruz\nimport numpy as np #Bu kütüphane lineer cebir için kullandığımız kütüphane fonksiyonlarını içeriyor\nimport pandas as pd # verilerimizi işlemek için pandas kütüphanasini kullanıyoruz(örn pd.read_scv)\nfrom sklearn.model_selection import train_test_split #Bu işlem ile verilerimizi eğitim ve test(%70-%30) olacak çekilde bölüyoruz\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.classify import SklearnClassifier\n\nfrom wordcloud import WordCloud, STOPWORDS\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom subprocess import check_output ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3e4d02c3b39a490828936c17b0c2a67a2fbe2d14"},"cell_type":"markdown","source":"Ben bu çalışmada sadece duygu(sentiment) analizi yapacağım için veri seti içeridinde bulunan ancak ihtiyacım olmayacak sütunları veri setinden çıkarıyorum."},{"metadata":{"trusted":true,"_uuid":"8b4a9feba7c9cc82af15e300093b6497a8cfed06"},"cell_type":"code","source":"veri = pd.read_csv('../input/Sentiment.csv')\n#Veri setinde sadece ihtiyacım olacak sütunlar kalıyor.\nveri = veri[['text', 'sentiment']]\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"057dbfcb9c3e2c37d3fa31493960194107d38fa7"},"cell_type":"markdown","source":"İlk olarak şimdi elimde bulunan veri setini eğitim ve test verileri olacak şekilde ikiye bölüyorum test için %10 ve eğitim için %90 olacak şekilde verileri ayırıyorum, bu çalışmada sadece duyguların pozitif mi yoksa negatifmi olduğu ile ilgileniyorum dolayısı ile nötr duyguları de veri setimden çıkarıyorum."},{"metadata":{"trusted":true,"_uuid":"6e85a4720992694fd3e65cc816ec8cac3294a9fb"},"cell_type":"code","source":"#Veri Setimi Eğitim ve test verilerine ayırıyorum\ntrain, test = train_test_split(veri, test_size = 0.1)\n#Sonra Veri seti içerisindeki Nötr duyguları çıkarıyorum\ntrain = train[train.sentiment !=\"Neutral\"]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a7612fd6eac8454f2e0a5146cef296050a78de0a"},"cell_type":"markdown","source":"Bir sonraki edım için eğitim setimdeki verilerden Nötr verileri çıkardım dolayısı ile görselleştirme işlemi daha da kolaylaştı. Daha sonra veri seti içerisinde #hashtag olan değerleri ve link içeren değerleri temizliyorum. Şimdi artık en empatik değerleri WordCloud dan  Negatif ve Pozitif olacak şekilde görselleştiriyorum."},{"metadata":{"_cell_guid":"516a52cc-dd69-3b5f-7487-1467a701f1e2","_uuid":"80166ec8053bc64d52ccb664027886f37cc72d5d","trusted":true,"scrolled":true},"cell_type":"code","source":"train_pos = train[ train['sentiment'] == 'Positive']\ntrain_pos = train_pos['text']\ntrain_neg = train[ train['sentiment'] == 'Negative']\ntrain_neg = train_neg['text']\n\ndef wordcloud_draw(data, color = 'black'):\n    words = ' '.join(data)\n    cleaned_word = \" \".join([word for word in words.split()\n                            if 'http' not in word\n                                and not word.startswith('@')\n                                and not word.startswith('#')\n                                and word != 'RT'\n                            ])\n    wordcloud = WordCloud(stopwords=STOPWORDS,\n                      background_color=color,\n                      width=2500,\n                      height=2000\n                     ).generate(cleaned_word)\n    plt.figure(1,figsize=(13, 13))\n    plt.imshow(wordcloud)\n    plt.axis('off')\n    plt.show()\n    \nprint(\"Pozirif Kelimeler\")\nwordcloud_draw(train_pos,'white')\nprint(\"Negatif Kelimeler\")\nwordcloud_draw(train_neg)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c15ad8853ed6459ee78c0eb2825ff1d7f9e71229"},"cell_type":"markdown","source":"Pozitif kelime setinde aşağıdaki kelimeleri ve ifadeleri fark etmek ilginç:\n  ** hakikat **, ** güçlü **, ** meşru **, ** birlikte **, ** aşk **, ** iş **\n  (**truth**, **strong**, **legitimate**,  **together**, **love**, **job**)\n\nBenim yorumumda, insanlar ideal adaylarının doğru, meşru, iyi ve kötünün üzerinde olduğuna inanmaya eğilimlidirler.\n---------------\nAynı şekilde Negatif kelimeler içerisindeki :\n**etki**, **haberler**,**asansor müziği**,**hayal kırıklığı**, **yumuşaktop**, **makyaj yapmak**, **Kiraz toplama**, **denemek** gibi kelimelerin olması da ilginç.\n\nAnladığım kadarıyla insanlar kararlı bir şekilde harekete geçmeyi başardılar ve azarlanan adayların çok yumuşak ve vişne almayı düşündüklerini söylediler."},{"metadata":{"_uuid":"ca80d4966ec94f16fcf422223d88fb89f2a4e5ad"},"cell_type":"markdown","source":"Görselleştirmeden sonra eğitim setinden hashtag, link ve sonlandırıcı kelimeleri çıkardım. \n**Stop Word :** Arama sorgularında kullanılmak üzere önemli bir önem taşımayan kelimelerdir. Genellikle bu kelimeler gereksiz bilgi döndürdüğü için arama sorgularından filtrelenir. (the, for, this vb.)"},{"metadata":{"trusted":true,"_uuid":"e8c32c9a9307637d48420a8c5a1169c4d6e1903f"},"cell_type":"code","source":"tweets =[]\nstopwords_set = set(stopwords.words(\"english\"))\n\nfor index, row in train.iterrows():\n    words_filtered = [e.lower() for e in row.text.split() if len(e) >= 3]\n    words_cleaned = [word for word in words_filtered\n                    if 'http' not in word\n                    and not word.startswith('@')\n                    and not word.startswith('#')\n                    and word != 'RT']\n    words_without_stopwords = [word for word in words_cleaned if not word in stopwords_set]\n    tweets.append((words_cleaned, row.sentiment))\n    \ntest_pos = test[test['sentiment'] == 'Positive']\ntest_pos = test_pos['text']\ntest_neg = test[test['sentiment'] == 'Negative']\ntest_neg = test_neg['text']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9ef1dc01f96a2c5cd3fb0793448d5849ecf4ff2f"},"cell_type":"markdown","source":"Bir sonraki adım olarak, nltk lib ile adlandırılan özellikleri ilk önce sık dağılımı ölçüp ve sonuçta oluşan anahtar kelimeleri  çıkardım."},{"metadata":{"trusted":true,"_uuid":"08c033c3973d66bf6b9fcb73490f23330210b17f"},"cell_type":"code","source":"#Kelimelerin özelliklerini çıkarıyorum.\ndef get_words_in_tweets(tweets):\n    all =[]\n    for (words, sentiment) in tweets:\n        all.extend(words)\n    return all\ndef get_word_features(wordlist):\n    wordlist = nltk.FreqDist(wordlist)\n    features = wordlist.keys()\n    return features\nw_features = get_word_features(get_words_in_tweets(tweets))\n\ndef extract_features(document):\n    document_words = set(document)\n    features = {}\n    for word in w_features:\n        features['containts(%s)' % word] = (word in document_words)\n    return features","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0fc651ef03dd98808cc96239fe11fbba8bd33d1c"},"cell_type":"markdown","source":"En sık tekrar eden kelimeleri görselleştiriyorum. Genellikle kelimeler tartışma merkezi etrafında toplanıyor."},{"metadata":{"_cell_guid":"d4202bb1-ef8a-312c-e5a9-27bb282411eb","_uuid":"e38df0e71a54993df58ce98c119eb711c2e7ee63","trusted":true},"cell_type":"code","source":"wordcloud_draw(w_features)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1c8ac3c2-22ed-d267-d04c-931d9e2f9080","_uuid":"81e7054b9ea9dbf6825361b10f56d81feb6b6280","trusted":true},"cell_type":"code","source":"wordcloud_draw(w_features)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f7133cac94f1ae67b28cc5a3a37cef1e1fd203ae"},"cell_type":"markdown","source":"nltk Naive Bayes sınıfandırmacıyı kullanarak kelimeleri özelliklerine göre sınıflandırdım."},{"metadata":{"trusted":true,"_uuid":"16101f130eef85be891d78cb5c2ea8b4fe83b1c3"},"cell_type":"code","source":"#Naive Bayes sınıflandırıcıyı eğitiyorum\ntraining_set = nltk.classify.apply_features(extract_features, tweets)\nclassifier = nltk.NaiveBayesClassifier.train(training_set)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5a6088dd972722dfc42b847a4950475121b3b025"},"cell_type":"markdown","source":" Son olarak, çok akıllı olmayan metriklerle, sınıflandırıcı algoritmasının nasıl puanlandırma yaptığını ölçmeye çalıştım."},{"metadata":{"trusted":true,"_uuid":"67570b297a28c98319d2366e4175a7f313b1f07c"},"cell_type":"code","source":"neg_cnt = 0\npos_cnt = 0\nfor obj in test_neg:\n    res = classifier.classify(extract_features(obj.split()))\n    if(res == 'Negative'):\n        neg_cnt = neg_cnt + 1\nfor obj in test_pos:\n    res = classifier.classify(extract_features(obj.split()))\n    if(res == 'Positive'):\n        pos_cnt = pos_cnt + 1\n\nprint('[Negative]: %s/%s' % (len(test_neg), neg_cnt))\nprint('[Positive]: %s/%s' % (len(test_pos), pos_cnt))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4af6ddb1d6fcb51c94397976a246ac7e48108b6c"},"cell_type":"markdown","source":"![](http://)## Son değerlendirme.##\n\nBu projede nltk ve NaiveBayes Machine Learning algoritmasının Sentiment Analizi için ne kadar iyi performans gösterdiğini merak ettim. Benim deneyimime göre, olumsuz yorumlar için oldukça iyi çalışıyor. Sorunlar tweet'ler ironik olduğunda, alaycı referansa sahip veya kendi zor bir içeriğe sahip olduğunda ortaya çıkar.\n\nAşağıdaki tweet'i düşünün:\n* \"Merhaba, Liberallerin Trump'u yok edememesi ne kadar üzücü.\nDaha önce de düşündüğünüz gibi, ** sad ** ve ** destroy ** ifadeleri, anlam ve bağlamı göz önüne alındığında bu tweet pozitif olsa da, değerlendirmeyi büyük ölçüde etkilemektedir.\n\nDeğerlendirme doğruluğunu geliştirmek için, içeriği ve referansları dikkate almak için bir şeye ihtiyacımız var. Proje 2.0 olarak, bir LSTM ağı kurmaya çalışacağım ve sonuçlarını bu nltk Makine Öğrenimi uygulamasına kıyasla kıyaslayacağım. "},{"metadata":{"_cell_guid":"feda97ab-f4fe-24a5-34a9-a46926f77fe7","_uuid":"8ff584da5e75a4223ec4dab387a25b20416af32e","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}