{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Supervised Learning\n### Logistic Regression"},{"metadata":{},"cell_type":"markdown","source":"## Heart Attack Possibility\n### Problem Statement:\nWith the given data you are required to identify the key hidden patterns accociated with heart attack and use the information to build a predictive model which can identify and predict the possibility of getting a heart attack.\n\n### Solution:\nBuilding a predictive model comprising of Logistic Regression which can identify the patients who are likely to have a heart attack and also predict the possibility of getting a heart attack.\n\n### Approach:\n- EDA: Exploratory Data Analysis.\n- Preparing the data for modeling.\n- Training the model.\n- Model Evaluation.\n- prediction on test data."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ignoring warnings\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing relevant libraries.\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport statsmodels.api as sm\nimport sklearn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_selection import RFE\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setting the visual preferance\nplt.style.use('dark_background')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Task 1: EDA - Exploratory Data Analysis\n- ### Subtask 1.1: Read and understand the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/health-care-data-set-on-heart-attack-possibility/heart.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"round(df.isnull().sum()/len(df.index)*100,4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Explanation: \nThe data set has total of 303 rows and 14 columns out of which there are 13 independent and 1 dependent variable which are all numerical. There is no missing values in the data set and there is only 1 duplicate value which can be removed."},{"metadata":{},"cell_type":"markdown","source":"- ### Subtask 1.2: Assigning proper column names"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.rename(columns = {'cp': 'chest pain', 'trestbps': 'resting BP', 'chol': 'cholestoral', 'fbs': 'fasting Blood sugar',\n                    'restecg': 'resting ECG', 'thalach': 'maximum heart rate', 'exang': 'exercise induced angina',\n                    'oldpeak': 'ST depression', 'ca': 'no.of major vessels blocked', 'thal': 'defect'}, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- ### Subtask 1.3: Outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"var = df.drop('target', axis = 1).columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (15,15))\nfor x in enumerate(var):\n    plt.subplot(5,3,x[0]+1)\n    sns.boxplot(x[1], data = df, palette = 'Purples')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outliers = ['resting BP', 'cholestoral', 'maximum heart rate', 'ST depression', \n            'no.of major vessels blocked', 'defect']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (15, 10))\nfor x in enumerate(outliers):\n    plt.subplot(2,3,x[0]+1)\n    sns.boxplot(x[1], data = df, palette = 'Purples')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['resting BP'].quantile([0.25,0.50,0.75,0.90,0.95,0.99])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[df['resting BP']> 160, ['resting BP']] = 160","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Explanation:\nThere are not much outliers in the dataset. There are very few data points which are outliers and this can be ignored. Only the variable 'resting BP' had around 4% of the data as outliers hence this was treated by capping the outliers to the 95th percentile. "},{"metadata":{},"cell_type":"markdown","source":"- ### Subtask 1.4: Data visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = 'sex', data = df, palette = 'Purples')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Explanation:\nThe data set has an imbalance ratio in gender. Only 96 observations have been taken for females and there is over 207 observations for male patients."},{"metadata":{"trusted":true},"cell_type":"code","source":"bins = [0,10,20,30,40,50,60,70,80]\nlabels = ['<10', '10-20', '21-30', '31-40', '41-50', '51-60', '61-70', '71-80']\ndf['age_group'] = pd.cut(x = df['age'], bins = bins, labels = labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,5))\nsns.countplot(x = df['age_group'], hue= df['target'], palette= 'Purples')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Explanation:\nThe age group 41-50 has the highest chance of getting a heart attack when compared to all other age groups. The no. of heart attack patients are twice the no.of non heart attack patients in that age group."},{"metadata":{"trusted":true},"cell_type":"code","source":"one = df.loc[df['target'] == 1]\nzero = df.loc[df['target'] == 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"var = ['resting BP', 'cholestoral', 'maximum heart rate', 'ST depression']\nplt.figure(figsize = (14,7))\nfor x in enumerate(var):\n    plt.subplot(2,2,x[0]+1)\n    sns.kdeplot(data = one[x[1]], shade = True, color = 'r')\n    \nfor x in enumerate(var):\n    plt.subplot(2,2,x[0]+1)\n    sns.kdeplot(data = zero[x[1]], shade = True, color = 'c')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Explanation:\n- The red line represents heart attack patients and the cyan line present non heart attack patients.\n- The maximum heart rate appears to be very high for the heart attack patients. \n- The normal cholestrol should be <170 mg/dl. However as per the above distribution both the groups are having higher cholestrol level. \n- The normal resting BP should be 120 Hgmm. However majority of both the groups are having BP in the range of 120 - 130."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,5))\nsns.countplot(x = 'chest pain', hue = 'target', data = df, palette = 'Purples')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Explanation:\nType 2 chest pain is more susceptible for getting a heart attack."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculating the imbalance percentage.\nlabel = ['Heart Attack', 'Non-Heart Attack']\nexplode = [0.1,0]\ndf['target'].value_counts().plot.pie(explode = explode, labels = label, shadow = True, startangle=60, \n                                      autopct='%1.1f%%', textprops = {'color' : 'k'})\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Task 2: Preparing the data for modeling\n- ### Subtask 2.1: Dropping unnecessary columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop('age_group', axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop_duplicates(inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- ### Subtask 2.2: Splitting the data into train-test and rescaling of variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting the data into train and test.\ndf_train, df_test = train_test_split(df, train_size = 0.70, random_state = 100)\nprint(df_train.shape)\nprint(df_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Rescalling of variable.\nvar = ['age', 'chest pain', 'resting BP', 'cholestoral', 'resting ECG', 'maximum heart rate', \n       'ST depression', 'slope', 'no.of major vessels blocked', 'defect']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler()\ndf_train[var] = scaler.fit_transform(df_train[var])\ndf_train.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Explanation:Â¶\nVariable trasnformation is a very vital step before building any ML algorithm.\n- It helps in faster computation. (convergence happen quickly)\n- If all the variables are in the same unit, then it is easier to interpret the results from the model."},{"metadata":{},"cell_type":"markdown","source":"- ### Subtask 2.3: Correlation and Heatmap"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculating the correlation between variables.\ndf_train.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Heatmap\nplt.figure(figsize = (15,10))\nheat = sns.heatmap(df_train.corr(), annot = True, cmap = 'Purples')\nbottom, top = heat.get_ylim()\nheat.set_ylim(bottom+0.5, top+0.5)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Task 3: Training the model\n- ### Subtask 3.1: Assigning X and Y"},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_train = df_train.pop('target')\nX_train = df_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- ### Subtask 3.2: RFE- Recursive Feature Elimination"},{"metadata":{"trusted":true},"cell_type":"code","source":"log_reg = LogisticRegression()\nrfe = RFE(log_reg, 10)\nrfe_model = rfe.fit(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(zip(X_train.columns, rfe_model.ranking_)).sort_values(by = 1, ascending = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col = X_train.columns[rfe_model.support_]\ncol","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- ### Subtask 3.2: Stats Models\n  - Note: Assuming alpha to be 0.05 with 95% of confidence interval.\n        - H0: The variable is <= 0.05 and is significant in determining Heart Attack.\n        - H1: The variable is > 0.05 and is insignificant in determining Heart Attack\n  - Note: Assuming permitable VIF level to be <5."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model_1\nX_train_sm = sm.add_constant(X_train[col])\nlog_model = sm.GLM(Y_train, X_train_sm, families = sm.families.Binomial).fit()\nprint(log_model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vif = pd.DataFrame()\nvif['Features'] = col\nvif['VIF'] = [variance_inflation_factor(X_train[col].values, x) for x in range(X_train[col].shape[1])]\nvif['VIF'] = round(vif['VIF'],2)\nvif = vif.sort_values(by = 'VIF', ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_2 = X_train[col].drop('cholestoral', axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_2_sm = sm.add_constant(X_2)\nlog_model_2 = sm.GLM(Y_train, X_2_sm, families = sm.families.Binomial()).fit()\nprint(log_model_2.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vif = pd.DataFrame()\nvif['Features'] = X_2.columns\nvif['VIF'] = [variance_inflation_factor(X_2.values, x) for x in range(X_2.shape[1])]\nvif['VIF'] = round(vif['VIF'],2)\nvif = vif.sort_values(by = 'VIF', ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_3 = X_2.drop('slope', axis = 1)\nX_3_sm = sm.add_constant(X_3)\nlog_model_3 = sm.GLM(Y_train, X_3_sm, families = sm.families.Binomial()).fit()\nprint(log_model_3.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vif = pd.DataFrame()\nvif['Features'] = X_3.columns\nvif['VIF'] = [variance_inflation_factor(X_3.values, x) for x in range(X_3.shape[1])]\nvif['VIF'] = round(vif['VIF'],2)\nvif = vif.sort_values(by = 'VIF', ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_4 = X_3.drop('exercise induced angina', axis = 1)\nX_4_sm = sm.add_constant(X_4)\nlog_model_4 = sm.GLM(Y_train, X_4_sm, families = sm.families.Binomial()).fit()\nprint(log_model_4.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vif = pd.DataFrame()\nvif['Features'] = X_4.columns\nvif['VIF'] = [variance_inflation_factor(X_4.values, x) for x in range(X_4.shape[1])]\nvif['VIF'] = round(vif['VIF'],2)\nvif = vif.sort_values(by = 'VIF', ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_5 = X_4.drop('age', axis = 1)\nX_5_sm = sm.add_constant(X_5)\nlog_model_5 = sm.GLM(Y_train, X_5_sm, families = sm.families.Binomial()).fit()\nprint(log_model_5.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vif = pd.DataFrame()\nvif['Features'] = X_5.columns\nvif['VIF'] = [variance_inflation_factor(X_5.values, x) for x in range(X_5.shape[1])]\nvif['VIF'] = round(vif['VIF'],2)\nvif = vif.sort_values(by = 'VIF', ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_6 = X_5.drop('defect', axis = 1)\nX_6_sm = sm.add_constant(X_6)\nlog_model_6 = sm.GLM(Y_train, X_6_sm, families = sm.families.Binomial()).fit()\nprint(log_model_6.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vif = pd.DataFrame()\nvif['Features'] = X_6.columns\nvif['VIF'] = [variance_inflation_factor(X_6.values, x) for x in range(X_6.shape[1])]\nvif['VIF'] = round(vif['VIF'],2)\nvif = vif.sort_values(by = 'VIF', ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Explanation:\nlog_model_6 is the final model. The P value for all the features is less than 0.05 (< 0.05) which makes all the features significant in the model. Also the VIF scores for these variables is less than 5. Which means that the features are independant and there is no multicollinearity between them."},{"metadata":{},"cell_type":"markdown","source":"## Task 4: Model Evaluation\n- ### Subtask 4.1: Finding the Optimal Threshold"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting using the log_model_6\nY_train_pred = log_model_6.predict(X_6_sm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Conversion at different probability\ncutoff = pd.DataFrame()\ncutoff['Actual'] = Y_train.values\ncutoff['Pred'] = Y_train_pred.values\nnum = [float(x/10) for x in range(10)]\nfor x in num:\n    cutoff[x] = cutoff['Pred'].map(lambda i: 1 if i > x else 0)\ncutoff.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculating various measures.\nmeasures = pd.DataFrame(columns = ['Probability', 'Accuracy', 'Sensitivity', 'FPR', 'Specificity', 'FNR'])\nfor x in num:\n    metrix = metrics.confusion_matrix(cutoff['Actual'], cutoff[x])\n    total = sum(sum(metrix))\n    Accuracy = (metrix[0,0]+metrix[1,1])/total\n    Sensitivity = metrix[1,1]/(metrix[1,1]+metrix[1,0])\n    FPR = metrix[0,1]/(metrix[0,1]+metrix[0,0])\n    Specificity = metrix[0,0]/(metrix[0,0]+metrix[0,1])\n    FNR = metrix[1,0]/(metrix[1,0]+metrix[1,1])\n    measures.loc[x] = [x, Accuracy, Sensitivity, FPR, Specificity, FNR]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"measures","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Plotting the lines to find the optimal Threshold limit.\nmeasures.plot.line(x = 'Probability', y = ['Accuracy', 'Sensitivity', 'Specificity'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Explanation\nThe Optimal Thrushold limit is a point where 'Accuracy', 'Sensitivity' and 'Specificity are fairly decent and are almost equal. It is usually the intersection point on the graph. Hence the optimal thrushold limit is 0.6."},{"metadata":{},"cell_type":"markdown","source":"- ### Subtask 4.2: ROC- Receiver Operating Characteristic Curve"},{"metadata":{"trusted":true},"cell_type":"code","source":"def roc (actual, prob):\n    FPR, TPR, threshold = metrics.roc_curve(actual, prob, drop_intermediate = False)\n    auc_score = metrics.roc_auc_score(actual, prob)\n    plt.plot(FPR, TPR, label = 'ROC curve (area = %0.2f)' %auc_score)\n    plt.legend(loc = 'lower right')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic Curve')\n    plt.show()\n    return None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FPR, TPR, threshold = metrics.roc_curve(cutoff['Actual'], cutoff['Pred'], drop_intermediate = False)\nroc(cutoff['Actual'], cutoff['Pred'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Explanation\nThe model has achieved the ROC score of 0.90 which is pretty high and also from the above graph we can observe that the curve is hugging the TPR. This means that the model is able to identify patients who are likely to get a heart attack correctly by reducing the FPR."},{"metadata":{},"cell_type":"markdown","source":"##### Solution: Selecting the Cut of point.\nEven though the optimal threshold limit was identified at 0.6 we cannot go ahead with this cut off point as it was only able to reach the accuracy and sensitivity of 82%. When it comes to cardiac arrest there is minimal chance of error. Hence factors like accuracy, sensitivity and FNR plays atmost importance. Keeping all this factors in mind, the cut off limit is set at 0.5 at which the model is able to produce the following scores. (Best results)"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"measures.loc[measures['Probability']== 0.5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Task 5: Prediction and Evaluation on Test data\n- ### Subtask 5.1: Prediction "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test[var] = scaler.transform(df_test[var])\ndf_test.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Assigning X and Y\nY_test = df_test.pop('target')\nX_test = df_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Matching the test data with Log_model_6 columns\ncols = X_6.columns\nX_test = X_test[cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prediction on test data\nX_test_sm = sm.add_constant(X_test)\nY_test_pred = log_model_6.predict(X_test_sm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.DataFrame()\ntest['Actual'] = Y_test.values\ntest['Pred'] = Y_test_pred.values\ntest['Final'] = test['Pred'].map(lambda x: 1 if x >= 0.5 else 0)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- ### Subtask 5.2: Evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"con = metrics.confusion_matrix(test['Actual'], test['Final'])\ncon","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sensitivity = con[1,1]/(con[1,1]+con[1,0])\nspecificity = con[0,0]/(con[0,0]+con[0,1])\nFNR = con[1,0]/(con[1,0]+con[1,1])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print({'Accuracy': round(metrics.accuracy_score(test['Actual'], test['Final']),2)})\nprint({'Sensitivity': round(sensitivity, 2)})\nprint({'Specificity': round(specificity, 2)})\nprint({'FNR': round(FNR, 2)})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Explanation\nThe model is also performing well on the Test data. This ensures stability of the model."},{"metadata":{},"cell_type":"markdown","source":"- ### Subtask 5.3: Probability of getting a heart attack"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test['target'] = Y_test.values\ndf_test['probability'] = test['Pred'].values\ndf_test['final'] = test['Final'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}