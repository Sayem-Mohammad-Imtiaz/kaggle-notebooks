{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\nimport numpy as np\nimport pandas as pd \n\ndata=pd.read_csv('/kaggle/input/spam-text-message-classification/SPAM text message 20170820 - Data.csv')\nprint(data.describe())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"x=data['Message']\ny=np.array(data['Category'])\n\n#label conversion\ny=np.where(y=='ham',0,1)\nprint(y[:6])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Message word tokenization"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\ntokenizer=Tokenizer(num_words=10000)\ntokenizer.fit_on_texts(x)\nsequences=tokenizer.texts_to_sequences(x)\nword_index=tokenizer.word_index\nx=pad_sequences(sequences,maxlen=14)#first 14 words of the message\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nVector Representation Processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nglove6b='/kaggle/input/glove6b/glove.6B.100d.txt'\nembeddings={}\nf=open(os.path.join(glove6b))\n\nfor line in f:\n    values=line.split()# list of vector representation of words\n    \n    word=values[0]\n \n    coefs=np.asarray(values[1:],dtype='float32')#only vector representations of words\n   \n    embeddings[word]=coefs#dictionary containing keys and indexes\nf.close\nprint('word count',len(embeddings))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nCreating a matrix of vector representations"},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_dim=100\n\nembedding_matrix=np.zeros((10000,embedding_dim))\nfor word, i in word_index.items():\n    if i< 10000:#\n        embedding_vector=embeddings.get(word)#word vectors\n        if embedding_vector is not None:#IF WORDS FROM glove NO TO aclImdb\n\n            embedding_matrix[i]=embedding_vector#ZERO MATRIX ASSIGNS a word from glove (vector)\n           ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nTraining and test selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,train_size=0.7,random_state=1000)\nprint('TRAIN:',x_train.shape)\nprint('TEST:',x_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nNetwork architecture"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Embedding,Flatten,Dense\nfrom keras import layers\nfrom keras import regularizers\nfrom keras import optimizers\nmodel=Sequential()\nmodel.add(Embedding(10000,100,input_length=14))\nmodel.add(Flatten())\nmodel.add(Dense(64,kernel_regularizer=regularizers.l1(0.001),activation='elu'))\nmodel.add(layers.Dropout(0.7))\nmodel.add(Dense(1,activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nPre-training"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.layers[0].set_weights([embedding_matrix]) #loading pre-trained layer\nmodel.layers[0].trainable=False #freezing the 'embedding' layer so that it does not change its values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['acc'])\nhistory=model.fit(x_train,y_train,epochs=10,batch_size=20)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_loss,test_acc=model.evaluate(x_test,y_test)\nprint('mistake:', test_loss)\nprint('accuracy', test_acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}