{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cd554dd6-8aa5-658a-fbdb-9b3e594d882d"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport scipy.stats as st\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score, learning_curve\nfrom sklearn.preprocessing import StandardScaler, PolynomialFeatures\nfrom sklearn.metrics import confusion_matrix, auc, roc_curve, f1_score, roc_auc_score, cohen_kappa_score\n \nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import ExtraTreeClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom xgboost import XGBClassifier\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom os import path\n\npd.set_option('display.max_columns', None) # for displaying all columns\nnp.random.seed(0) # for reproducibility"},{"cell_type":"markdown","metadata":{"_cell_guid":"2439fed6-cadd-b5b4-a371-240fea1b834a"},"source":"## Exploratory data analysis\n#### First view"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1b535890-3e05-6b2f-9c20-f56740773e58"},"outputs":[],"source":"data = pd.read_csv(\"../input/WA_Fn-UseC_-HR-Employee-Attrition.csv\")\ndata.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"01e8966b-5e34-dc3d-3781-eac0753f3180"},"outputs":[],"source":"data.describe()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e9532b6f-a5aa-2fde-65ec-95c9bb662404"},"outputs":[],"source":"data.info()"},{"cell_type":"markdown","metadata":{"_cell_guid":"ee41f38b-5fd0-5c54-12e9-3aec4ecb6444"},"source":"Plot histogram for our target value **Attrtion**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"11465483-3a42-41f2-0fb0-08902e53405b"},"outputs":[],"source":"fig = plt.figure(figsize=(5, 5))\ny = [\"No\", \"Yes\"]\nax = sns.categorical.barplot(y, np.array(data.Attrition.value_counts(normalize=True)), saturation=1)\nax.set_xticklabels(y)\nax.set_title(\"Attrition\")\nax.set_xlabel(\"\")\nax.set_ylabel(\"Frequency\")\nax.set_ylim([0,1])\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"10bca949-be2b-253a-2ec4-881aa2214c16"},"source":"This histogram says that we have an unbalanced data. Therefore, in this case, our model we can not use ** accuracy **, becouse this metric will give very good results, even if our model will generate all the time ** \"No\" **."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b9146bbf-f7a0-78aa-17b5-b5d24718db46"},"outputs":[],"source":"#sns.boxplot(data=data.YearsAtCompany)\n#sns.distplot(data.MonthlyIncome)\nfig = plt.figure(figsize=(10, 10))\nax = fig.add_subplot(1,1,1)\ncorr_data = data.select_dtypes([\"number\"]).corr()\nsns.heatmap(corr_data, ax=ax)\nax.tick_params(axis='both', which='major', labelsize=20)\nax.set_title(\"Pearson correlation map\")\nplt.tight_layout()\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"12ab1f2e-5fc5-65ce-f655-a9149f48371c"},"outputs":[],"source":"fig = plt.figure(figsize=(10, 52))\ncols = 3\ntarget_column = \"Attrition\"\nrows = np.ceil(float(data.shape[1] / cols))\nfor i, column in enumerate(data.columns):\n    if target_column == column:\n        continue\n    ax = fig.add_subplot(rows, cols, i+1)\n    ax.set_title(column)\n    if data.dtypes[column] == np.object:\n        cts = data[[target_column, column]]\n        cts = cts.groupby([target_column, column]).size()\n        cts.unstack().T.plot(kind=\"bar\", ax=ax, stacked=True, alpha=1)\n    else:\n        cts = data[[target_column, column]]\n        #(xmin, xmax) = (min(cts[column].tolist()), max(cts[column].tolist()))\n        cts.groupby(target_column)[column].plot(\n            bins=16,\n            kind=\"hist\",\n            stacked=True,\n            alpha=1,\n            legend=True,\n            ax=ax,\n            #range=[xmin, max]\n        )\nplt.tight_layout()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5a386b56-58ba-fda0-95ba-cce9aed97ee2"},"outputs":[],"source":"target_label = \"Attrition\"\n\ndef plot_num(label, data, ax, bins=16):\n    d = data[[label, target_label]].sort_values(label).reset_index(drop=True)\n    t = np.linspace(data[[label]].min()[label], data[[label]].max()[label], bins)\n    \n    m = pd.DataFrame({\"BINS\":np.round((d[[label]].values >= t) * t, 2).max(axis=1)})\n    p = pd.concat([d, m], axis=1).groupby([\"BINS\", target_label]).count().unstack().fillna(0)\n\n    b = p[label][\"Yes\"] / p[label][\"No\"]\n    ax.bar(b.index, b, width=(t[1] - t[0]) *0.8)\n    ax.set_title(label)\n    ax.set_ylabel(\"YES / NO\")\n    return ax\n\ndef plot_cat(label, data, ax, bins=16):\n    t = data[[label, target_label]]\n    c = pd.DataFrame({\"Count\":np.ones(len(t), dtype=np.bool)})\n    t = pd.concat([t, c], axis=1)\n    b = t.groupby([label, target_label]).count().unstack()\n    r = b[\"Count\"][\"Yes\"] / b[\"Count\"][\"No\"]\n    ax.bar(np.arange(len(r)), r, tick_label=r.index)\n    ax.set_ylabel(\"YES / NO\")\n    ax.set_xticklabels(ax.xaxis.get_majorticklabels(), rotation=\"vertical\")\n    ax.set_title(label)\n    return ax"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d35e75bb-826f-5e97-cee9-ff11194a627a"},"outputs":[],"source":"fig = plt.figure(figsize=(10, 40))\n\ncols = 3\ntarget_column = \"Attrition\"\nrows = np.ceil(float(data.shape[1] / cols))\nfor i, column in enumerate(data.columns):\n    if target_column == column or column==\"Over18\":\n        continue\n    ax = fig.add_subplot(rows, cols, i+1)\n    ax.set_title(column)\n    plot_func = None\n    if data.dtypes[column] == np.object or  len(np.unique(data[column])) <= 16:\n        plot_func = plot_cat\n    else:\n        plot_func = plot_num\n    ax = plot_func(column, data, ax)\n        \nplt.tight_layout()\nplt.show()\nfig.autofmt_xdate()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2d7b1765-474e-4747-b955-c42d345ba839"},"outputs":[],"source":"fig = plt.figure(2, figsize=(10, 5))\nax1 = fig.add_subplot(1,2,1)\nax2 = fig.add_subplot(1,2,2)\nax1 = plot_num(\"TotalWorkingYears\", data, ax1, 16)\nax2 = plot_num(\"YearsAtCompany\", data, ax2)\nplt.tight_layout()\n#plt.savefig(\"YearsAtCompanyVSYearsInCurrentRole.png\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ac1e0392-6318-6a82-1c4e-4d895ad31e71"},"outputs":[],"source":"fig = plt.figure(2, figsize=(10, 5))\nax1 = fig.add_subplot(1,2,1)\nax2 = fig.add_subplot(1,2,2)\nax1 = plot_num(\"MonthlyIncome\", data, ax1, 16)\nax2 = plot_cat(\"JobLevel\", data, ax2)\nplt.tight_layout()\n#plt.savefig(\"MonthlyIncomeVSJobLevel.png\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d2246b6b-464e-8b2f-415b-11267301fb08"},"outputs":[],"source":"fig = plt.figure(2, figsize=(10, 5))\nax1 = fig.add_subplot(1,2,1)\nax2 = fig.add_subplot(1,2,2)\nax1 = plot_cat(\"PerformanceRating\", data, ax1, 16)\nax2 = plot_num(\"PercentSalaryHike\", data, ax2, 16)\n#ax1.set_title(\"MonthlyIncome vs TotalWorkingYears\")\n#ax1.set_xlabel(\"PercentSalaryHike\")\n#ax1.set_ylabel(\"PerformanceRating\")\n#ax1.scatter(data[\"PercentSalaryHike\"], data[\"PerformanceRating\"])\nplt.tight_layout()\n#plt.savefig(\"PerformanceRatingVSPercentSalaryHike.png\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4e72f61d-b138-5c08-b973-7649682fa8f0"},"outputs":[],"source":"fig = plt.figure(2, figsize=(10, 5))\nax = fig.add_subplot(1,1,1)\nax.set_title(\"TotalWorkingYears vs MonthlyIncome\")\nax.set_xlabel(\"TotalWorkingYears\")\nax.set_ylabel(\"MonthlyIncome\")\nax.scatter(data[\"TotalWorkingYears\"], data[\"MonthlyIncome\"], c=data[[\"Attrition\"]].eq([\"Yes\"]).mul(1), cmap=plt.cm.autumn)\n#ax1 = fig.add_subplot(1,2,1)\n#ax2 = fig.add_subplot(1,2,2)\n#ax1 = plot_num(\"TotalWorkingYears\", data, ax1, 16)\n#ax2 = plot_num(\"MonthlyIncome\", data, ax2)\nplt.tight_layout()\n#plt.savefig(\"TotalWorkingYearsVSMonthlyIncome.png\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"faf8b7cf-91df-8d3b-efe6-612c08b94cf3"},"outputs":[],"source":"\nfig = plt.figure(2, figsize=(10, 5))\nax1 = fig.add_subplot(1,2,1)\nax2 = fig.add_subplot(1,2,2)\nax1 = plot_cat(\"YearsWithCurrManager\", data, ax1, 16)\nax2 = plot_num(\"YearsAtCompany\", data, ax2)\nplt.tight_layout()\n#plt.savefig(\"YearsWithCurrManagerVYearsAtCompany.png\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3c3e4911-2ab0-a96a-4cb4-cb85c2ea2cbc"},"outputs":[],"source":"fig = plt.figure(2, figsize=(7, 5))\nax1 = fig.add_subplot(1,1,1)\nax1 = plot_num(\"MonthlyRate\", data, ax1, 10)\nplt.tight_layout()\n#plt.savefig(\"MonthlyRate.png\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"280b9ba5-1699-b0d1-74f5-129a66175e0a"},"outputs":[],"source":"fig = plt.figure(figsize=(10, 4))\nax1 = fig.add_subplot(1, 4, 1)\nax1 = plot_cat(\"OverTime\", data, ax1)\nax2 = fig.add_subplot(1, 4, 2)\nax2 = plot_cat(\"MaritalStatus\", data, ax2)\nax3 = fig.add_subplot(1, 4, 3)\nax3 = plot_cat(\"Gender\", data, ax3)\nax4 = fig.add_subplot(1, 4, 4)\nax4 = plot_cat(\"BusinessTravel\", data, ax4)\nax4.set_xticklabels([\"No\", \"Frequently\", \"Rarely\"])\n\nax1.tick_params(axis='both', which='major', labelsize=15)\nax2.tick_params(axis='both', which='major', labelsize=15)\nax3.tick_params(axis='both', which='major', labelsize=15)\nax4.tick_params(axis='both', which='major', labelsize=15)\nplt.tight_layout()\n#plt.savefig(\"Categorial.png\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"fca9d473-cf9a-7e3b-28a2-53d15f2cb6b0"},"source":"## Data cleaning\n\nAs we can see our data has a numeric and categorical data. So we find a column that does not carry useful information, such as those that have the same value for each row. For this, we define the number of unique values for each column."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"47ba6e8a-48d0-a72c-ee76-624e91eae470"},"outputs":[],"source":"uniq = data.apply(lambda x: len(np.unique(np.array(x))))\nuniq"},{"cell_type":"markdown","metadata":{"_cell_guid":"a547ff95-ed88-72ab-0d3e-e1c0eda305ef"},"source":"Then we find the column that has only one values for all rows and we delete them."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"de62b216-407f-2085-bcfe-bae023eff4bf"},"outputs":[],"source":"no_inf = uniq.index[uniq==1]\nprint(no_inf)\ndata.drop(labels=no_inf, axis=1, inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"93a9c837-bee7-e102-97b8-94a79e17b515"},"outputs":[],"source":"unuseful_label = [\"DailyRate\", \"EmployeeNumber\", \"HourlyRate\", \"MonthlyRate\", \"PercentSalaryHike\", \n                  \"PerformanceRating\", \"TrainingTimesLastYear\" , \"YearsSinceLastPromotion\", \"Gender\"]\ndata.drop(unuseful_label, axis=1, inplace=True)"},{"cell_type":"markdown","metadata":{"_cell_guid":"4c852196-cf58-1413-47e2-273838913098"},"source":"Then we find all the categorical attributes that have only two unique values and encode them as **0** or **1**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6c974337-485a-bbf2-fd03-4d4648cbe409"},"outputs":[],"source":"two_val = uniq.index[(uniq==2) & (data.dtypes == \"object\")]\nprint(two_val)\n\ndata[two_val] = data[two_val].eq([\"Yes\", \"Yes\"]).mul(1)\ndata[two_val].head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"e8a1c843-47b3-2584-bcfa-fc9745915f98"},"source":"Changing numerical features to one-hot encoded"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"260dec89-16f5-1e83-66e7-337c5b3171c3"},"outputs":[],"source":"numerical_val = data.columns[data.dtypes != \"object\"]\ndata = pd.get_dummies(data, columns=data.columns.drop(numerical_val))\ndata.info()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"54b122b7-12da-bf07-c070-4f169f281b36"},"outputs":[],"source":"fig = plt.figure(figsize=(10, 10))\nax = fig.add_subplot(1,1,1)\nax = data.corr().ix[\"Attrition\"].drop(\"Attrition\").sort_values().plot(kind=\"barh\", figsize=(10, 12), ax=ax)\nax.tick_params(axis='y', which='major', labelsize=18)\nax.set_title(\"Attrititon Corelation\")\nplt.tight_layout()\n#plt.savefig(\"AttritionCorelation.png\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"b603f994-d28a-6657-8fbf-99d65df0812d"},"source":"## Building and Learning Model\nTo simplify the construction of the model, we will continue to operate on the Numpy arrays, and also convert the integer value to a floating-point value, to prevent unnecessary warnings"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8191214b-8ecc-3d6b-9f8a-1bb4e7583dfb"},"outputs":[],"source":"Y = data[[\"Attrition\"]].values.ravel()\nX = data.drop(\"Attrition\", axis=1).values.astype(\"float64\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"12521d0f-2b33-4f6a-07e6-f6557307d062"},"source":"To prevent problems with convergence, we normalize all our data."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4976e544-0577-2906-d410-e39240ae4511"},"outputs":[],"source":"scaler = StandardScaler()\nX = scaler.fit_transform(X)"},{"cell_type":"markdown","metadata":{"_cell_guid":"ddd2164b-0521-bc81-8aa9-893b03bc19df"},"source":"We divide our sample into test and training in relation **1/4**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"594e808d-9487-ffcc-fa18-a5bb2f34dc1a","collapsed":true},"outputs":[],"source":"X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=0)"},{"cell_type":"markdown","metadata":{"_cell_guid":"338ca6c4-9398-e91d-4226-ff6a504a44c3"},"source":"We denote the function for finding parameters for the concise classifier. To select the classifier, a ** `roc auc` ** metric was chosen, such as that which is well suited for unbalanced binary samples. Also for a visual understanding of the result, I build a counfusion matrix , showing the number of correctly and incorrectly classified objects."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4d31487e-83d7-8faa-4458-c53a99f0425b"},"outputs":[],"source":"def plot_confusion_matrix(y_test, y_pred, iters=500):\n        fig = plt.figure(figsize=(7, 7))\n        ax = sns.heatmap(confusion_matrix(y_test, y_pred), \n                         annot=True, \n                         cbar=False, \n                         linewidths=2, \n                         linecolor=\"k\",\n                         annot_kws={\"size\": 30},\n                         fmt=\"\")\n        ax.tick_params(axis='y', which='major', labelsize=18)\n        ax.set_title(\"Confusion matrix\", fontdict={\"size\": 18})\n        ax.set_ylabel(\"True label\", fontdict={\"size\": 18})\n        ax.set_xlabel(\"Predicted label\")\n        fig.tight_layout()\n        return ax\n    \ndef plot_learning_curve(train_sizes, train_scores, test_scores):\n    fig = plt.figure(dpi=100)\n    train_scores_mean = train_scores.mean(axis=1)\n    train_scores_std = train_scores.std(axis=1)\n    test_scores_mean = test_scores.mean(axis=1)\n    test_scores_std = test_scores.std(axis=1)\n    #fig.grid()\n    ax1 = fig.add_subplot(1,1,1)\n    ax1.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    ax1.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    ax1.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n             label=\"Training score\")\n    ax1.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n             label=\"Cross-validation score\")\n\n    ax1.legend(loc=\"best\")\n    fig.tight_layout()\n    return ax1\n\ndef search_parameter(clf, params, X, y, cv=5, iters=500):\n    \n    model = RandomizedSearchCV(clf(), param_distributions=params, \n                               n_iter=iters, cv=cv, n_jobs=-1, scoring=\"f1\", \n                               error_score=0, verbose=1)\n    model.fit(X, y)\n    return model"},{"cell_type":"markdown","metadata":{"_cell_guid":"d366bd9d-f483-d58c-a6d5-ac6d0f9b6ca2"},"source":"### SGDClassifier\nDemonstration of parameters for which a search was conducted for a stochastic gradient classifier"},{"cell_type":"markdown","metadata":{"_cell_guid":"7058cfc7-d43e-607b-3d3a-b200b57bff85"},"source":"    params = {\"loss\": [\"hinge\", \"log\", \"squared_hinge\", \"perceptron\"],\n              \"penalty\": [\"elasticnet\"],\n              \"l1_ratio\": np.linspace(0, 1, 20),\n              \"n_iter\": [900],\n              \"alpha\": 10.0**np.arange(-5, 2),\n              \"class_weight\": [\"balanced\", None],\n              \"random_state\": [0]}\n    sgd_result = search_parameter(SGDClassifier, params, X_train, y_train, iters=500)"},{"cell_type":"markdown","metadata":{"_cell_guid":"592c9ee2-24e1-62d3-76b2-4db1c7ea7479"},"source":"Final model"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d6c9e061-e738-9e25-98da-9f1e9dc62058"},"outputs":[],"source":"sgd_params = {'alpha': 0.0001,\n              'class_weight': None,\n              'l1_ratio': 1,\n              'loss': 'log',\n              'n_iter': 908,\n              'penalty': 'elasticnet',\n              'random_state': 1, \n              'shuffle': True}\nclf = SGDClassifier(**sgd_params)\nclf.fit(X_train, y_train)\n\nprint(\"Accuracy for train dataset: {}\".format(clf.score(X_train, y_train)))\nprint(\"Accuracy for test dataset: {}\".format(clf.score(X_test, y_test)))\nprint(\"F1: {}\".format(f1_score(y_test, clf.predict(X_test))))\nprint(\"AUC ROC: {}\".format(roc_auc_score(y_test, clf.predict(X_test))))\nplot_confusion_matrix(y_test, clf.predict(X_test))\n##plt.savefig(\"ConfusionSGD.png\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3398ff39-1f6c-4910-bf33-700cb47dd1c9"},"outputs":[],"source":"train_sizes, train_scores, valid_score = learning_curve(SGDClassifier(**sgd_params), X_train, y_train, train_sizes=[0.1, 0.3, 0.6, 0.9, 1], cv=5, scoring=\"f1\")\nplot_learning_curve(train_sizes, train_scores, valid_score)\n#plt.savefig(\"LearningCurveSGD.png\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"39bf7e9e-16d8-0d7f-eab4-cabff39efd34"},"source":"### SVM"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4a8de55e-df48-d390-4829-59eb386b8941"},"outputs":[],"source":"param = {\n    \"C\":1,\n    \"kernel\":\"linear\",\n    \"gamma\":1,\n    \"random_state\":0,\n}\n#param = svc_result.best_params_\n\nclf = SVC(**param)\nclf.fit(X_train, y_train)\n\nprint(\"Accuracy for train dataset: {}\".format(clf.score(X_train, y_train)))\nprint(\"Accuracy for test dataset: {}\".format(clf.score(X_test, y_test)))\nprint(\"F1: {}\".format(f1_score(y_test, clf.predict(X_test))))\nprint(\"AUC ROC: {}\".format(roc_auc_score(y_test, clf.predict(X_test))))\nplot_confusion_matrix(y_test, clf.predict(X_test))\n#plt.savefig(\"ConfusionSVM.png\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"420c8b5b-f9d2-894a-2f4c-0757bc4d8230"},"outputs":[],"source":"train_sizes, train_scores, valid_score = learning_curve(clf, X_train, y_train, train_sizes=np.linspace(0.01,1,10), cv=5, scoring=\"f1\")\nplot_learning_curve(train_sizes, train_scores, valid_score)\n#plt.savefig(\"LerningCUrveSVM.png\")"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}