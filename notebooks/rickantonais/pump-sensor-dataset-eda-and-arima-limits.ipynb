{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this kernel I wanted to practice with time series with classic statistical tools in order to check if it could help for anomaly detection.\nAt first I've just studied if an ARIMA model variant could predict some irregular univariate time series and I noticed a few limits. Please feel free if you notice some irregularities in the methods I've employed"},{"metadata":{},"cell_type":"markdown","source":"At first, let's load all our needed libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import rcParams\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX, SARIMAXResults\nfrom statsmodels.tsa.stattools import adfuller\nfrom sklearn.metrics import mean_squared_error\nos.getcwd()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.chdir('..')\nos.listdir()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.chdir(\"input\")\nos.listdir()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#path = r\"C:\\Users\\[..]\\Desktop\\pump-sensor-data\"\n#df = pd.read_csv(os.path.abspath(path + r\"/sensor.csv\"),index_col = \"timestamp\",parse_dates=[\"timestamp\"])\ndf = pd.read_csv('sensor.csv',index_col = \"timestamp\",parse_dates=[\"timestamp\"])\ndf.drop(\"Unnamed: 0\",axis=1,inplace=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['machine_status'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's drop \"sensor_15\" as it won't bring anything to our study"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop('sensor_15',axis=1,inplace=True)\ndf[\"machine_status\"]=df.machine_status.astype(\"category\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We'll check our categorical variable is now considered as a \"category\" type variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.machine_status.dtype","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"sensor_00\"].plot(figsize=(10,6))\nplt.xticks(color=\"white\")\nplt.yticks(color=\"white\")\nplt.title(\"Capteur 0 série temporelle\", color=\"white\")\nplt.xlabel(\"Timestamp\", color=\"white\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[(df.index.month>=4) & (df.index.month<=6)][\"sensor_00\"].plot(figsize=(10,7))\nplt.xticks(color=\"white\")\nplt.yticks(color=\"white\")\nplt.xlabel(\"Timestamp\", color=\"white\")\nplt.title(\"Extract of the time series between April and June for sensor 00\",color = \"white\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"machine_status\"].cat.categories","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"machine_status_code\"]=df[\"machine_status\"].cat.codes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"machine_status\"].cat.codes.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"machine_status\"].cat.codes.plot(figsize=(10,7))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[df[\"machine_status\"]==\"BROKEN\",[\"machine_status\",\"machine_status_code\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[df[\"machine_status\"]==\"RECOVERING\",[\"machine_status\",\"machine_status_code\"]].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[df[\"machine_status\"]==\"NORMAL\",[\"machine_status\",\"machine_status_code\"]].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We'll now have an overview of all sensors to check if there is some interesting pattern to look at"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"df[(df.index.month>=4) & (df.index.month<=5)].plot(figsize=(15,120), subplots=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I've also added the \"machine_status_code\" in the plot in order to look if there was some obvious patterns that could be landmarked in a certain period\nwe can see some sensors can be grouped for a further study in a multivariate time series study, for this notebook we'll just focus on a univariate time series study with classical statistical tool ARIMA"},{"metadata":{},"cell_type":"markdown","source":"Let's grab an subset of our sensor data so my computer doesn't cry when I want to train my model on it, I took 2 month of data between April and end of May"},{"metadata":{"trusted":true},"cell_type":"code","source":"#On sélectionne une partie de notre dataset pour entrainer notre modèle supervisé\ndf_train = df[(df.index.month>=4) & (df.index.month<=5)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's do some imputation for missing values on \"sensor 00\" time series"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[\"sensor_00\"].fillna(method='bfill',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[\"sensor_00\"].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's check if there is some pattern we can see with the machine status"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[[\"sensor_00\",\"machine_status_code\"]].plot(figsize=(10,6),subplots=True)\nplt.title(\"Capteur 00 et status de fonctionnement de la machine\", color=\"white\")\nplt.xticks(color=\"white\",rotation=0)\nplt.yticks(color=\"white\")\nplt.xlabel(\"Timestamp\", color=\"white\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems like this time series is pretty much correlated with the broken state of the machine and may be a good indicator for the broken state of the system, we'll check it for another notebook. For now the only interest is to manipulate and forecast to check robustness of classical methods"},{"metadata":{},"cell_type":"markdown","source":"We'll check for stationarity with AD-Fuller test and check if the p-value is <= 0.5"},{"metadata":{"trusted":true},"cell_type":"code","source":"#On check la stationarité de la série temporelle avec le test ADF\nadfuller(df_train[\"sensor_00\"],maxlag=50)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Seems good at first! But let's check it visually, I'll differenciate our time series and then look further"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[\"sensor_00\"].shift(1).head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"sensor00_acf_plot = plot_acf((df_train[\"sensor_00\"].shift(1)-df_train[\"sensor_00\"]).dropna(), lags=50, title=\"ACF Sensor 00\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Not really convincing, we'll also do the partial autocorrelation plot for our sensor 00 for the exercice"},{"metadata":{"trusted":true},"cell_type":"code","source":"sensor00_pacf_plot = plot_pacf(df_train[\"sensor_00\"], lags=50, title=\"PACF Sensor 00\")","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"type(df_train.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rcParams['figure.figsize'] = 11, 9\ndecomposed_sensor00 = sm.tsa.seasonal_decompose(df_train[\"sensor_00\"], freq=360)\nfigure = decomposed_sensor00.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We'll need to remove seasonality, for this we'll test which are the best values for our model"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"#resDiff = sm.tsa.arma_order_select_ic(df_train[\"sensor_00\"], max_ar=10, max_ma=10, ic='aic', trend='c')\n#print('ARMA(p,q) = ',resDiff[\"aic_min_order\"],' is the best!')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Took forever to run on my computer... But I'll save it for this kernel and the best result was (9,9) for AR and MA values and we had some intuition of this result through the autocorrelation plot"},{"metadata":{},"cell_type":"markdown","source":"We'll use a value of 1 for differentiation d parameter. I've followed the following guidelines [here](http://people.duke.edu/~rnau/arimrule.htm) which mentions about overdifferencing if out lag value in ACF plot goes >= -0.5.\nAfter 1 differentiation, ACF for lag 1 was already equal to -0.2 and then dived into negatives beyond the threshold of the guidelines so we'll keep our d=1\nWhich gives us an ARIMA(9,1,9)"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = SARIMAX(df_train[\"sensor_00\"], order=(9,1,9))\nresults = model.fit()\nresults.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results_plot = results.plot_diagnostics(figsize=(15,12))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, we'll plot our results to check if we have :\n- our KDE distribution that follows a N(0,1) distribution (not really the case here...)\n- qq-plot of our residuals follows the linear trend of the sample taken from a standart normal distribution \n- our correlogram reflects stationarity (seems good!)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.index[0], df_train.index[-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr_start, tr_end = '2018-04-01 00:00:00','2018-05-31 23:59:00'\ntr_pred = '2018-06-10 00:00:00'\nsteps_to_predict = 5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forecast = results.forecast(steps_to_predict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[\"prediction\"] = results.predict(start=70640,end=87840, dynamic=True)\ndf_train[[\"sensor_00\",\"prediction\"]].plot(figsize=(12,8))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see how much ARIMAX is limited for time series for important rebounds which aren't very regular"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[\"prediction\"] = results.predict(start=73640,end=87840, dynamic=True)\ndf_train[[\"sensor_00\",\"prediction\"]].plot(figsize=(12,8))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we notice, linear prediction is dependent on the chosen forecasting starting time => very little reliability if we want to do anomaly detection on a single time series."},{"metadata":{},"cell_type":"markdown","source":"In conclusion : \n- ARIMA seems good for regular patterns which are noticeable on the time series itself but not on random time series just like we did here\n- Our prediction depends on the forecasting time and even though we did prediction on a portion of data that we trained on, it's supposed to overfit and our prediction should match out data but it's not even the case, mistake in the process or misfit of the model for our data ?\n- ARIMA is such a pain to make it work and a lot of hypotheses must be met in order to validate the model (normality condition on the data distribution => transformations)\n- It would be interesting to compare approaches with recent machine learning techniques in order to compare a linear approach to a non linear one\n\nIn a next notebook I'd like to do the same study on another time series of the same dataset with a NN and a RNN to compare forecasting performances\n\nAs I'm a beginner, many flaws may happen in the process I've offered in this notebook, I'd be glad to have feedbacks for any who'd be taking time to point out unclear points I'm grateful in advance to you!"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"nbformat":4,"nbformat_minor":1}