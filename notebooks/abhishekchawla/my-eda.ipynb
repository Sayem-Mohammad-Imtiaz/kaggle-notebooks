{"cells":[{"metadata":{},"cell_type":"markdown","source":"# About this Notebook\n\nIn this kernel, I will briefly explain the structure of dataset.I will generate and analyze metafeatures. Then, I will visualize the dataset using Matplotlib, seaborn and Plotly to gain as much insight as I can . Also I will approach this problem as an NLP Classification problem to build a model\n\nIn case you are just starting with NLP here is a guide to Approach almost any NLP Problem by Grandmaster [**@Abhishek Thakur**](https://www.slideshare.net/abhishekkrthakur/approaching-almost-any-nlp-problem)\n\n**<span style=\"color:Red\">If you find this kernel useful, Please Upvote it , it motivates me to write more Quality content**","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import string\nimport numpy as np \nimport random\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom plotly import graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\nfrom collections import Counter\nfrom fastai.text import *\nfrom fastai.callbacks import *\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nimport os\n\nimport nltk\nfrom nltk.corpus import stopwords\n\nfrom tqdm import tqdm\nimport os\nimport nltk\nimport random\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Below a Helper Function that generates random colors","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def random_colours(number_of_colors):\n    '''\n    Simple function for random colours generation.\n    Input:\n        number_of_colors - integer value indicating the number of colours which are going to be generated.\n    Output:\n        Color in the following format: ['#E86DA4'] .\n    '''\n    colors = []\n    for i in range(number_of_colors):\n        colors.append(\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]))\n    return colors","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/60k-stack-overflow-questions-with-quality-rate/data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* We have 60k rows 6 columns","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# EDA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Distribution in 50% of data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = train.sample(frac=0.5).groupby('Y').count()['Body'].reset_index().sort_values(by='Body',ascending=False)\ntemp.style.background_gradient(cmap='Purples')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure(go.Funnelarea(\n    text =temp.Y,\n    values = temp.Body,\n    title = {\"position\": \"top center\", \"text\": \"Funnel-Chart of Question Quality Distribution\"}\n    ))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Generating Meta Features\n\n* Difference In Number Of words of title and body\n* Jaccard Similarity Scores between title and body\n\nFor what who don't know what Jaccard Similarity is : https://www.geeksforgeeks.org/find-the-jaccard-index-and-jaccard-distance-between-the-two-given-sets/\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c)) / (len(a) + len(b) - len(c))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results_jaccard=[]\n\nfor ind,row in train.iterrows():\n    sentence1 = row.Title\n    sentence2 = row.Body\n\n    jaccard_score = jaccard(sentence1,sentence2)\n    results_jaccard.append([sentence1,sentence2,jaccard_score])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"jaccard = pd.DataFrame(results_jaccard,columns=[\"Title\",\"Body\",\"jaccard_score\"])\ntrain = train.merge(jaccard,how='outer')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Num_words_body'] = train['Body'].apply(lambda x:len(str(x).split())) #Number Of words in Selected Text\ntrain['Num_words_title'] = train['Title'].apply(lambda x:len(str(x).split())) #Number Of words in main text\ntrain['difference_in_words'] = abs(train['Num_words_body'] - train['Num_words_title']) #Difference in Number of words text and Selected Text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Let's look at the distribution of Meta-Features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\np1=sns.kdeplot(train['Num_words_body'], shade=True, color=\"r\").set_title('Kernel Distribution of Number Of words')\np1=sns.kdeplot(train['Num_words_title'], shade=True, color=\"b\")\nplt.xlim(0,300)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Of course question body will have more words than the title**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Now It will be more interesting to see the differnce in number of words and jaccard_scores across different Segment**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Y.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\np1=sns.kdeplot(train[train['Y']=='HQ']['difference_in_words'], shade=True, color=\"b\").set_title('Kernel Distribution of Difference in Number Of words')\np2=sns.kdeplot(train[train['Y']=='LQ_CLOSE']['difference_in_words'], shade=True, color=\"r\")\np2=sns.kdeplot(train[train['Y']=='LQ_EDIT']['difference_in_words'], shade=True, color=\"g\")\nplt.legend(labels=['HQ','LQ_CLOSE','LQ_EDIT'])\nplt.xlim(-20,500)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\np1=sns.kdeplot(train[train['Y']=='HQ']['jaccard_score'], shade=True,).set_title('KDE of Jaccard Scores across different Quality Question')\np2=sns.kdeplot(train[train['Y']=='LQ_CLOSE']['jaccard_score'], shade=True, )\np3=sns.kdeplot(train[train['Y']=='LQ_EDIT']['jaccard_score'], shade=True, )\nplt.legend(labels=['HQ','LQ_CLOSE','LQ_EDIT'])\nplt.xlim(-0.05,0.4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA of Conclusion\n* Target distribution is almost identical for all 3 categories\n* `LQ_EDIT` questions have less difference in num of words between **Body** and **Title**.\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Cleaning the Corpus\n\nNow Before We Dive into extracting information out of words in title and body,let's first clean the data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_text(text):\n    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n    and remove words containing numbers.'''\n    text = str(text).lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Title'] = train['Title'].apply(lambda x:clean_text(x))\ntrain['Body'] = train['Body'].apply(lambda x:clean_text(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Most Common words in our Body","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['temp_list'] = train['Body'].apply(lambda x:str(x).split())\ntop = Counter([item for sublist in train['temp_list'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(20))\ntemp.columns = ['Common_words','count']\ntemp.style.background_gradient(cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.bar(temp, x=\"count\", y=\"Common_words\", title='Commmon Words in Body', orientation='h', \n             width=700, height=700,color='Common_words')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**OOPS!** While we cleaned our dataset we didnt remove the stop words and hence we can see one of the most common words is 'to'. \nLet's try again after removing the stopwords.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.treemap(temp, path=['Common_words'], values='count',title='Tree of Most Common Words in the body')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Most Common words in Title\n\nLet's also look at the most common words in Title","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_stopword(x):\n    return [y for y in x if y not in stopwords.words('english')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['temp_list1'] = train['Title'].apply(lambda x:str(x).split()) #List of words in every row for text\ntrain['temp_list1'] = train['temp_list1'].apply(lambda x:remove_stopword(x)) #Removing Stopwords","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top = Counter([item for sublist in train['temp_list1'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(25))\ntemp = temp.iloc[1:,:]\ntemp.columns = ['Common_words','count']\ntemp.style.background_gradient(cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.bar(temp, x=\"count\", y=\"Common_words\", title='Commmon Words in Title', orientation='h', \n             width=700, height=700,color='Common_words')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Top 3 Question words are Regarding **C, python, and error**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Most common words Question Quality Wise\n\nLet's look at the most common words in different question qualities","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"hq = train[train['Y']=='HQ']\nlq_edit = train[train['Y']=='LQ_EDIT']\nlq_close = train[train['Y']=='LQ_CLOSE']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#MosT common HQ words\ntop = Counter([item for sublist in hq['temp_list'] for item in sublist])\ntemp_p = pd.DataFrame(top.most_common(20))\ntemp_p.columns = ['Common_words','count']\ntemp_p.style.background_gradient(cmap='Greens')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.bar(temp_p, x=\"count\", y=\"Common_words\", title='Most Commmon HQ words', orientation='h', \n             width=700, height=700,color='Common_words')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#MosT common lq_edit words\ntop = Counter([item for sublist in lq_edit['temp_list'] for item in sublist])\ntemp_n = pd.DataFrame(top.most_common(20))\ntemp_n = temp_n.iloc[1:,:]\ntemp_n.columns = ['Common_words','count']\ntemp_n.style.background_gradient(cmap='Reds')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.treemap(temp_n, path=['Common_words'], values='count',title='Tree Of Most Common LQ_EDIT Words')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#MosT common lq_close words\ntop = Counter([item for sublist in lq_close['temp_list'] for item in sublist])\ntemp_n = pd.DataFrame(top.most_common(20))\ntemp_n = temp_n.loc[1:,:]\ntemp_n.columns = ['Common_words','count']\ntemp_n.style.background_gradient(cmap='Reds')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.bar(temp_n, x=\"count\", y=\"Common_words\", title='Most Commmon LQ_CLOSE words', orientation='h', \n             width=700, height=700,color='Common_words')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.treemap(temp_n, path=['Common_words'], values='count',title='Tree Of Most LQ_CLOSE Words')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* We can see words like **i,to , a, and, the,is** are common in all three segments .","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Let's Look at Unique Words in each Segment\n\nWe will look at unique words in each segment in the Following Order:\n* HQ\n* LQ_EDIT\n* LQ_CLOSE","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_text = [word for word_list in train['temp_list1'] for word in word_list]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def words_unique(segment,numwords,raw_words):\n    '''\n    Input:\n        segment - Segment category (ex. 'HQ,LQ_EDIT');\n        numwords - how many specific words do you want to see in the final result; \n        raw_words - list  for item in train_data[train_data.segments == segments]['temp_list1']:\n    Output: \n        dataframe giving information about the name of the specific ingredient and how many times it occurs in the chosen cuisine (in descending order based on their counts)..\n\n    '''\n    allother = []\n    for item in train[train.Y != segment]['temp_list1']:\n        for word in item:\n            allother .append(word)\n    allother  = list(set(allother ))\n    \n    specificnonly = [x for x in raw_text if x not in allother]\n    \n    mycounter = Counter()\n    \n    for item in train[train.Y == segment]['temp_list1']:\n        for word in item:\n            mycounter[word] += 1\n    keep = list(specificnonly)\n    \n    for word in list(mycounter):\n        if word not in keep:\n            del mycounter[word]\n    \n    Unique_words = pd.DataFrame(mycounter.most_common(numwords), columns = ['words','count'])\n    \n    return Unique_words","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## HQ Questions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Unique_P= words_unique('HQ', 10, raw_text)\nprint(\"The top 10 unique words in HQ are:\")\nUnique_P.style.background_gradient(cmap='Greens')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from palettable.colorbrewer.qualitative import Pastel1_7\nplt.figure(figsize=(16,10))\nmy_circle=plt.Circle((0,0), 0.7, color='white')\nplt.pie(Unique_P['count'], labels=Unique_P.words, colors=Pastel1_7.hex_colors)\np=plt.gcf()\np.gca().add_artist(my_circle)\nplt.title('DoNut Plot Of Unique HQ Words')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Unique_lqedit = words_unique('LQ_EDIT', 10, raw_text)\nprint(\"The top 10 unique words in LQ_EDIT are:\")\nUnique_lqedit.style.background_gradient(cmap='Reds')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from palettable.colorbrewer.qualitative import Pastel1_7\nplt.figure(figsize=(16,10))\nmy_circle=plt.Circle((0,0), 0.7, color='white')\nplt.rcParams['text.color'] = 'black'\nplt.pie(Unique_lqedit['count'], labels=Unique_lqedit.words, colors=Pastel1_7.hex_colors)\np=plt.gcf()\np.gca().add_artist(my_circle)\nplt.title('DoNut Plot Of Unique LQ_EDIT Words')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Unique_N= words_unique('LQ_CLOSE', 10, raw_text)\nprint(\"The top 10 unique words in LQ_CLOSE are:\")\nUnique_N.style.background_gradient(cmap='Oranges')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from palettable.colorbrewer.qualitative import Pastel1_7\nplt.figure(figsize=(16,10))\nmy_circle=plt.Circle((0,0), 0.7, color='white')\nplt.pie(Unique_N['count'], labels=Unique_N.words, colors=Pastel1_7.hex_colors)\np=plt.gcf()\np.gca().add_artist(my_circle)\nplt.title('DoNut Plot Of Unique LQ_CLOSE Words')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**By Looking at the Unique Words of each segment ,we now have much more clarity about the data,these unique words are very strong determiners of segment of questions**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## It's Time For WordClouds\n\nWe will be building wordclouds in the following order:\n\n* WordCloud of HQ Questions\n* WordCloud of LQ_EDIT Questions\n* WordCloud of LQ_CLOSE Questions","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def plot_wordcloud(text, mask=None, max_words=200, max_font_size=100, figure_size=(20.0,8.0), color = 'white',\n                   title = None, title_size=40, image_color=False):\n    stopwords = set(STOPWORDS)\n    more_stopwords = {'u', \"im\"}\n    stopwords = stopwords.union(more_stopwords)\n\n    wordcloud = WordCloud(background_color=color,\n                    stopwords = stopwords,\n                    max_words = max_words,\n                    max_font_size = max_font_size, \n                    random_state = 42,\n                    width=800, \n                    height=400,\n                    mask = mask)\n    wordcloud.generate(str(text))\n    \n    plt.figure(figsize=figure_size)\n    if image_color:\n        image_colors = ImageColorGenerator(mask);\n        plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\");\n        plt.title(title, fontdict={'size': title_size,  \n                                  'verticalalignment': 'bottom'})\n    else:\n        plt.imshow(wordcloud);\n        plt.title(title, fontdict={'size': title_size, 'color': 'black', \n                                  'verticalalignment': 'bottom'})\n    plt.axis('off');\n    plt.tight_layout()  \nd = '/kaggle/input/masks-for-wordclouds/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_wordcloud(hq.Body,color='white',max_font_size=100,title_size=30,title=\"WordCloud of HQ Questions\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_wordcloud(lq_edit.Body,color='white',max_font_size=100,title_size=30,title=\"WordCloud of LQ_EDIT Questions\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_wordcloud(lq_close.Body,color='white',max_font_size=100,title_size=30,title=\"WordCloud of LQ_CLOSE Questions\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeling the Problem as NLP Text Classification Task\n\n\n\n**Text classification is the process of assigning tags or categories to text according to its content. \nIt's one of the fundamental tasks in Natural Language Processing (NLP) with broad applications such as sentiment analysis, topic labeling, spam detection, and intent detection.**\n\n* We will use a AWD_LSTM arch.\n* First we will build a language model that better understands questions language.\n* Then using the language model we will build a classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = train[['Title','Body','Y']].copy()\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = Path('/kaggle/input/')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Language Model for questions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_lm = (TextList.from_df(df, path, cols=['Title','Body'] ) # Create A text list for model\n                   .split_by_rand_pct(0.2)  # how to split data, 80% train, 20% validation\n                   .label_for_lm() # label according to a language model\n                   .databunch(bs=64)) # create a databunch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_lm.save('/kaggle/working/data_lm.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_lm.show_batch(rows=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = language_model_learner(data_lm,AWD_LSTM,drop_mult=0.4,\n                               metrics=[accuracy,Perplexity()],model_dir='/kaggle/working/').to_fp16()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"callbacks = SaveModelCallback(learn, monitor=\"perplexity\", mode=\"min\", name=\"best_lang_model\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = 5e-02\nmoms = (0.8, 0.7)\nwd = 0.1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training the language model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(8, slice(lr), moms=moms, wd=wd, callbacks=[callbacks])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.load('best_lang_model');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"txt = 'the question is very simple'\n[learn.predict(txt,n_words=30,temperature=0.5) for i in range(5)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save_encoder('ftenc')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = None\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Now Time to Build a Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_cls = (TextList.from_df(df, path, cols=['Title','Body'], vocab=data_lm.vocab)\n            # Creating a textlist for lang model df--> dataframe , cols = Columns of df you want to include in classifier model , vocab=we will use same vacab we use to create a language model\n                    .split_by_rand_pct(0.2,seed=64)\n            #   will take 20% of text as validation set\n                    .label_from_df(cols='Y')\n            # label the classifier from dataframe cols= target columns name\n                    .databunch(bs=128))\n            # creates a databunch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_cls.show_batch(rows=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = text_classifier_learner(data_cls, AWD_LSTM, metrics=[accuracy], drop_mult=0.3,model_dir='/kaggle/working/').to_fp16()\nclf.load_encoder('/kaggle/working/ftenc');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Classifier Model Summary","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cb = SaveModelCallback(clf, monitor=\"accuracy\", mode=\"max\", name=\"best_clf\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.unfreeze()\nclf.fit_one_cycle(8, 1e-2 ,moms=(0.8,0.7), callbacks=[cb])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Classfier Interpretation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.load('best_clf');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"interp = TextClassificationInterpretation.from_learner(clf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"interp.show_intrinsic_attention(\"why are java optionals immutable\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"interp.show_intrinsic_attention(\"why ternary operator in swift is so picky\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"interp.plot_confusion_matrix(figsize=(5,5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Lets see our top losses","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"interp.show_top_losses(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2> <span style=\"color:Red\">I hope you Liked my kernel. An upvote is a gesture of appreciation and encouragement, to keep improving my efforts ,be kind to show one.</h2>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}