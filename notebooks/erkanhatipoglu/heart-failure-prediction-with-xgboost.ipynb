{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction  <a id='introduction'></a>\n\nThis is a starter code for Heart Failure Prediction using XGBoost. The reader may easily try different approaches and concepts (EDA, Feature Engineering, different models, etc.) by forking the notebook. I have tried to keep this notebook as basic as possible for this purpose.\n\nSklearn has several functions to calculate and display accuracy, recall, precision, and F1 scores. However. I will not use those functions. I will rather calculate those results by manually for demonstration purposes. \n\nWe need to increase the recall score for this very dataset task since we do not want to misclassify heart failure cases. In other words, we want the number of true positives to be as high as possible while the number of false negatives is as small as possible. It is better to falsely treat a patient than leaving another patient to die because of misclassification.\n\nIt seems that the time column needs to be dropped since it is not a predictor.  It turns out that we cannot get a time value for new patients after deployment. Please refer to [this thread](https://www.kaggle.com/andrewmvd/heart-failure-clinical-data/discussion/178372) and [Attribute Information](https://archive.ics.uci.edu/ml/datasets/Heart+failure+clinical+records) for further discussions on the subject.\n\nI also want to thank [@Larxel](https://www.kaggle.com/andrewmvd) for this dataset.\n\nThank you for reading.\n\n\n# Table of Contents\n* [Introduction](#introduction)\n* [Helper Functions](#functions)\n* [Getting the Data](#getdata)\n* [Preprocessing](#preprocessing) \n* [Pipeline and Validation with early_stopping_rounds](#pipeline) \n* [Grid Search](#gridsearch)    \n* [Prediction](#prediction)\n* [Conclusion](#conclusion) \n* [References](#references)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nfrom pandas_profiling import ProfileReport\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, precision_score, classification_report, recall_score\nimport pandas_profiling","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Helper Functions <a id='functions'></a>  "},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<b>Tip:</b> We will use some helper functions throughout the notebook. Collecting them in one place is a good idea. It makes the code more organized.\n</div>"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"scrolled":true},"cell_type":"code","source":"def calculate_cf (y_valid, preds):\n    ''' A function that calculates the confusion matrix, accuracy, precision, recall, and f1_score.\n        Accuracy, precision, recall, and f1_score can be easily obtained by using sklearn features. \n        this function is only for demontration purposes.'''\n    \n    # Calculating confusion_matrix\n    CM = confusion_matrix(y_valid, preds)\n\n    # Calculate True Positives(TP), False Positives(FP)\n    # False Negative(FN) and True Negatives(TN) from confusion_matrix\n    true_negatives = CM[0][0]\n    false_negatives = CM[1][0]\n    true_positives = CM[1][1]\n    false_positives = CM[0][1]\n\n    # You can easily get these values in sklearn using \n    # accuracy_score, precision_score, classification_report, etc.\n    # I calculate these values for demonstration purposes.\n    accuracy = (true_positives + true_negatives)/(true_positives + false_positives + false_negatives + true_negatives)\n    precision = (true_positives) / (true_positives + false_positives)\n    recall = (true_positives) / (true_positives + false_negatives)\n    f1_score = 2 * (precision * recall) / (precision + recall)\n    \n    return true_negatives, false_negatives, true_positives, false_positives,accuracy, precision, recall, f1_score\n\ndef display_results (y_valid, preds):\n    ''' A function that displays the results'''\n    # get the results\n    true_negatives, false_negatives, true_positives, false_positives,accuracy, precision, recall, f1_score = calculate_cf (y_valid, preds)\n    \n    blank= \" \"\n    star = \"*\"\n    print(blank*50 + \"Death Event\") \n    print(blank*30 + star*55)\n    print(blank*35 + \"Positive\" + blank * 30 + \"Negative\")\n    print(blank * 30 + star*18 + blank * 19 + star*18)\n    print(\"Predicted\" + blank*7 + \"Positive\" + blank  * 11 + str(true_positives)+ \" (TP)\" + blank * 32 + str(false_positives) + \" (FP)\")\n    print(\"Class\" + blank*11 + \"Negative\" + blank  * 11 + str(false_negatives)+ \" (FN)\" + blank * 31 + str(true_negatives) + \" (TN)\")\n    print()\n    print(\"Accuracy = (TP+TN)/(TP+FP+FN+TN) = {:.2f}\".format(accuracy))\n    print(\"Precision = (TP)/(TP+FP) = {:.2f}\".format(precision))\n    print(\"Recall = (TP)/(TP+FN) = {:.2f}\".format(recall))\n    print(\"F1 score = 2 * (Precision*Recall)/(Precision+Recall) = {:.2f}\".format(f1_score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Getting the Data  <a id='getdata'></a>"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# Read the data\ntrain_data = pd.read_csv('/kaggle/input/heart-failure-clinical-data/heart_failure_clinical_records_dataset.csv')\n\n# Make a copy to avoid changing original data\nX = train_data.copy()\n\nprint('Data is OK')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"X.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"X.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing  <a id='preprocessing'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the target, separate target and time from predictors\ny = X.DEATH_EVENT              \nX.drop(['DEATH_EVENT', 'time'], axis=1, inplace=True)\n\n# Break off validation set from training data\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n                                                                random_state=0)\n# Display results\nprint (\"Shapes:\")\nprint (\"X: {}\".format(X.shape))\nprint (\"y: {}\".format(y.shape))\nprint()\nprint (\"X_train: {}\".format(X_train.shape))\nprint (\"X_valid: {}\".format(X_valid.shape))\nprint (\"y_train: {}\".format(y_train.shape))\nprint (\"y_valid: {}\\n\".format(y_valid.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select numeric columns\nnumerical_cols = [cname for cname in X_train.columns if X_train[cname].dtype in ['int64', 'float64']]\nnumerical_cols","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Pipeline and Validation with early_stopping_rounds <a id='pipeline'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define transformers\n# Preprocessing for numerical data\n\nnumerical_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n\n# Bundle preprocessing for numerical and categorical data\npreprocessor = ColumnTransformer(\n    transformers=[('numerical', numerical_transformer, numerical_cols)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define Model\nmodel = XGBClassifier(learning_rate = 0.1,\n                            n_estimators=500,\n                            max_depth=5,\n                            min_child_weight=1,\n                            gamma=0,\n                            subsample=0.8,\n                            colsample_bytree=0.8,\n                            reg_alpha = 0,\n                            reg_lambda = 1,\n                            random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-danger\">  \n<p>If we want to use early_stopping_rounds with our pipeline we cannot use the validation set (X_valid) directly. This is because sklearn pipelines do not process the eval_set used with early_stopping_rounds. As a result, we need to process our validation set before using early_stopping_rounds.</p> \n\n<p>There is a great danger here. If we forget to process our validation set and if processed data has the same number of columns as the unprocessed data we may not see an error. Validation with unprocessed data may mislead us. </p>\n\n<p>In order to process the eval_set, we need to fit_transform X_valid by using our preprocessor which is basically a pipeline consists of transformers (does not have an estimator).</p>\n</div>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocessing of validation data\nX_valid_eval = preprocessor.fit(X_train, y_train).transform (X_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display the number of remaining columns after transformation \nprint(\"We have\", X_valid_eval.shape[1], \"features after transformation\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define XGBClassifier fitting parameters for the pipeline\nfit_params = {\"model__early_stopping_rounds\": 50,\n              \"model__eval_set\": [(X_valid_eval, y_valid)],\n              \"model__verbose\": False,\n              \"model__eval_metric\" : \"error\"}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create and Evaluate the Pipeline\n# Bundle preprocessing and modeling code in a pipeline\nmy_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', model)\n                             ])\n\n# Preprocessing of training data, fit model \nmy_pipeline.fit(X_train, y_train, **fit_params)\n\n# Get predictions\npreds = my_pipeline.predict(X_valid)\n\n# Evaluate the model\nscore = accuracy_score(y_valid,preds)\n\n# Display the result\nprint(\"Score: {}\".format(score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display results\ndisplay_results (y_valid, preds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Grid Search  <a id='gridsearch'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define model parameters for grid search\nparam_grid = {'model__learning_rate': [0.1],\n              'model__n_estimators': [13],\n              'model__max_depth': [3, 4, 5, 6],\n              'model__min_child_weight': [1, 2, 3, 4],\n              'model__gamma': [0],\n              'model__subsample': [0.60, 0.70, 0.80, 0.90],\n              'model__colsample_bytree': [0.60, 0.70, 0.80, 0.90],\n              'model__random_state' : [42]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Perform grid search\n# Use model parameters defined above. We use scoring as recall to minimize \n# False Negatives\nsearch = GridSearchCV(my_pipeline, param_grid, cv=5, n_jobs=-1,scoring='recall')\nsearch.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction  <a id='prediction'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get predictions\npreds = search.predict(X_valid)\n\n# Evaluate the model\nscore = accuracy_score(y_valid,preds)\n\nprint(\"Score: {}\".format(score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_results (y_valid, preds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion  <a id='conclusion'></a>"},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-warning\">  \n<b>Warning:</b> Below, for the XGBClassifier(random_state=0) example we need to change both L10 and L16 for the model and L7 for the train_test_split.  \n</div>"},{"metadata":{},"cell_type":"markdown","source":"We had used `scoring='recall'` for our grGridSearchCV, and improved our scores as below:\n\n### Using train_test_split(random_state=0)\n\n* Accuracy:  from 0.77 to 0.85\n* Precision: from 0.76 to 0.94\n* Recall:    from 0.57 to 0.65\n* F1 score:  from 0.65 to 0.77\n\nIf we had shuffled our validation set with different random_state values we would have got different results such as:\n\n\n### Using train_test_split(random_state=1)\n*(change L7)*\n\n* Accuracy:  from 0.85 to 0.92\n* Precision: from 0.73 to 0.85\n* Recall:    from 0.57 to 0.79\n* F1 score:  from 0.64 to 0.81\n\n### Using train_test_split(random_state=42)\n*(change L7)*\n\n* Accuracy:  from 0.72 to 0.80\n* Precision: from 0.72 to 0.84\n* Recall:    from 0.52 to 0.64\n* F1 score:  from 0.60 to 0.73\n\n\nIf we had changed our model with different random_state values we would have got different results such as:\n\n### Using XGBClassifier(random_state=0)\n*(change L7, L10, L16)*\n\n* Accuracy:  from 0.75 to 0.92\n* Precision: from 0.79 to 0.95\n* Recall:    from 0.48 to 0.83\n* F1 score:  from 0.59 to 0.88"},{"metadata":{},"cell_type":"markdown","source":"# References   <a id='references'></a>\n* [@Larxel](https://www.kaggle.com/andrewmvd)\n* [Do not use time as a feature (Discussion Thread)](https://www.kaggle.com/andrewmvd/heart-failure-clinical-data/discussion/178372)\n* [Machine learning can predict survival of patients with heart failure from serum creatinine and ejection fraction alone (Research Article)](https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-020-1023-5)\n* [10-simple-hacks-to-speed-up-your-data-analysis - Parul Pandey](https://www.kaggle.com/parulpandey/10-simple-hacks-to-speed-up-your-data-analysis)\n* [Dataset Transformations - Scikit-learn](https://scikit-learn.org/stable/data_transforms.html)\n* [Intermediate Machine Learning Course - Pipelines](https://www.kaggle.com/alexisbcook/pipelines)\n* [Kaggle Learn](https://www.kaggle.com/learn/overview)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}