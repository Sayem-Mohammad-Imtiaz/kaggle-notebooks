{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Tensorflow Gradient Tape - Example\n\nThis is a simple example to demonstrate the gradient tape functionality from Tensorflow API. The gradient tape is a powerfull concept in tensorflow which allow us to wtite the custom training loops while calculating automatic differentiation (computational differentation).\nThe **Automatic (computational) differentiation** is fast and efficient way to compute partial derivatives using chain rules with simple aritmatic operations.\n\n## Gradient Tape\nThe tensorflow Gradient Tape require 4 basic components:\n1. The model\n2. The **loss** function - to compute model loss\n3. The **optimizer** to update the model weights\n4. The **Step** functions to encapsulate the forwar & backward pass of the network\n"},{"metadata":{},"cell_type":"markdown","source":"### Parameterized CNN\nThis is a utilty to create a custom dynamic CNN with the network architecture defined using the paramaters.\nThe utility defined [here](https://www.kaggle.com/pankaj1234/parameterizedcnn) with all the required information. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom parameterizedcnn import ParameterizedCNN \n\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import categorical_crossentropy\nfrom tensorflow.keras.utils import to_categorical\n\nimport tensorflow as tf\nimport sys","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Use the MNIST dataset for the analysis "},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"mtrain = pd.read_csv(\"../input/mnist-in-csv/mnist_train.csv\")\nmtest = pd.read_csv(\"../input/mnist-in-csv/mnist_test.csv\")\nmnist_train = np.array(mtrain)\nmnist_test = np.array(mtest)\nmnist_train_label = mnist_train[:,0]\nmnist_test_label = mnist_test[:,0]\nmnist_train = mnist_train[:,1:]\nmnist_test = mnist_test[:,1:]\nmnist_train=mnist_train.reshape(60000,28,28,1)\nmnist_train = mnist_train.astype(\"float32\")/255.0\nmnist_test=mnist_test.reshape(10000,28,28,1)\nmnist_test = mnist_test.astype(\"float32\")/255.0\n\n\nplt.imshow(mnist_train[0].reshape(28,28), cmap='gray')\nmnist_train_label = to_categorical(mnist_train_label)\nmnist_test_label = to_categorical(mnist_test_label)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### STEP FUNCTION\n1. Defined the loss from the prediction\n2. Capture the gradients in the Tape from the predicted-loss\n3. apply (update) the gradients - for the weights\n\nThis is components 2,3 & 4 required for Gradient Tape as mentioned above."},{"metadata":{"trusted":true},"cell_type":"code","source":"def step_function(X,y):\n    with tf.GradientTape() as tape:\n        pred = model(X)\n        loss = categorical_crossentropy(y, pred)\n        \n        grads=tape.gradient(loss, model.trainable_variables)\n        opt.apply_gradients(zip(grads, model.trainable_variables))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Instantiate the Parameterized CNN model\nThis is component# 1 required for Gradient Tape "},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"EPOCHS = 25\nBS = 64\nINIT_LR = 1e-3\n\n# model parameters\ndefault_parameters = {\"filters\":[16,32,64], \"filter_size\":[3,3,3], \"pool_size\":[2,2,2],\"padding\": [\"same\",\"same\",\"same\"], \"drop_out\":[0.3,0.4,0.5],\"dense\":256}\nimg_shape = (28,28,1)\nmnist_classes = 10\n\nmodel = ParameterizedCNN.generate_model(input_shape=img_shape, hyperparameters = default_parameters, classes=mnist_classes)\n\nopt = Adam(lr=INIT_LR, decay=INIT_LR/EPOCHS)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Apply the step function\n"},{"metadata":{"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"updates = int(len(mnist_train)/BS)\nfor i in range(0, updates):\n    start = i * BS\n    end = start + BS\n    \n    step_function(mnist_train[start:end], mnist_train_label[start:end])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hence this apply the custom training loop required to train the model using Tensorflow Gradient Tape API."},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer=opt, loss=categorical_crossentropy,\tmetrics=[\"acc\"])\n\n(loss, acc) = model.evaluate(mnist_test, mnist_test_label)\nprint(\"Model accuracy : {:.4f}\".format(acc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> *adapted from PyImagesearch :)*"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}