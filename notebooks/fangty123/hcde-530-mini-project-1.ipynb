{"cells":[{"metadata":{},"cell_type":"markdown","source":"# HCDE 530 - Mini Project 1 Housing Price Prediction\nby Tianyu (Tyler) Fang\n\n## Overview\n\nThis project is my first attempt to try out the entry-level machine learning leveraging simple and multiple linear regression to produce models that can predict housing prices based on existing data points.\n\nThe high-level process of the porject is to:\n\n1. Clean and profile the publicly available data on housing prices for King County with analysis\n2. Visualize data based on several variables (features) to identify and confirm relevancy\n3. Build simple linear regression model from these features: sqft_living, zipcode, yr_built; and compare performances\n4. Build multiple linear regression model using features mentioned above, and assess its performance\n\nThe data set used by this project is \"House Sales in King County, USA\" available on Kaggle - https://www.kaggle.com/harlfoxem/housesalesprediction, which contains house sale prices for King County sold between May 2014 and May 2015.\n\nBut as required by assignment, here's another one available from King County Public Data: https://aqua.kingcounty.gov/extranet/assessor/Real%20Property%20Sales.zip"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Profile\n\nLike most data sets, the \"House Sales in King County, USA\" data set contains more variables/features than what's needed for the purpose of this analysis. So the first step is to load the data from CSV file into pandas dataFrame for examine and flitering."},{"metadata":{"trusted":true},"cell_type":"code","source":"sales = pd.read_csv('/kaggle/input/housesalesprediction/kc_house_data.csv')\n\n# print the number of data points and types of metadata\nprint('Number of data points: ' + str(sales.shape[0]))\nprint('Types of metadata: ' + str(sales.shape[1]))\n\n# sample top 5 lines of sales data to see what's available\n# also force pandas to display all columns\npd.set_option('display.max_columns', 110)\nsales.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 20 features available in the dataset. Based on conventional wisdom, I think the following variables will be particular interesting:\n\n1. price - the target\n2. sqft_living - logically the most important factor of price\n3. zipcode - location, location, location\n4. yr_built/yr_renovated - newer houses should probably have higher prices, but in tight market like Seattle this may not be true\n5. bedrooms/bathrooms - If time permits, I will try to incoprate them into my model too.\n\nThe next step is to filter the data set based on variables selected above and clean up by dropping all NaN cells."},{"metadata":{"trusted":true},"cell_type":"code","source":"filtered_data = sales.loc[:, ['price', 'sqft_living', 'yr_built', 'yr_renovated', 'zipcode', 'bedrooms', 'bathrooms']]\ncleaned_data = filtered_data.dropna()\n\n# confirm the shape of cleaned data\nprint(cleaned_data.shape)\n\n# Next, sample the first 5 rows of data to make sure it contains correct information\ncleaned_data.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In addition, we need to process the colum on yr_built/yr_renovated and bedrooms/bathrooms so they show up as one feature which is easier to build visualization and regression model.\n\nFor yr_built/yr_renovated, which really matters is the age till last renovation. We will take the yr_renovated if it's available, otherwise fallback to yr_built. Then use current year (2015 for this dataset) to minus the yr_built/yr_renovated to get age.\n\nHowever, a house renovated in 2010 should not be treated as \"new\" as a house actually built in 2010. Thus, we need to penalize the renovated house for better prediction outcome. Picking a random constant 1.5 here and will see how it impacts the result.\n\n> **Age = yr_renovated != 0 ? (2015 - yr_renovated) * 1.5 : (2015 - yr_built) **\n\nFor bedrooms/bathrooms, will simply combine them. Again, bathrooms should not be treated as same signifcance with bedroom, so penalize that with a 0.8 factor to try it out.\n\n> **Rooms = bedrooms + 0.8 * bathrooms**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# using apply function to create a new column age\ncleaned_data['age'] = cleaned_data.apply(lambda row: 1.5 * (2015 - row.yr_renovated) if row.yr_renovated != 0 else (2015 - row.yr_built), axis = 1)\n\n# using apply function to create a new column age\ncleaned_data['rooms'] = cleaned_data.apply(lambda row: row.bedrooms + (row.bathrooms * 0.8), axis = 1)\n\n# Next, sample the first 5 rows of data to make sure age and rooms looks correct\ncleaned_data.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Visualization\n\nWith data cleaned and filtered, we are ready for next step of the project which is to visualize the data and examine visually to confirm the relevancy guess I made above - using scatter plot should be a good choice here."},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.figure(figsize=(30, 10))\n\n# first, drop the yr_built, yr_renovated, bedrooms, and bathrooms column as they are no longer needed\nfinal_data = cleaned_data.loc[:, ['price', 'sqft_living', 'age', 'rooms', 'zipcode']]\n\nfinal_data.plot.scatter(x='sqft_living', y='price', c='DarkBlue')\nfinal_data.plot.scatter(x='age', y='price', c='Blue')\nfinal_data.plot.scatter(x='rooms', y='price', c='Yellow')\nfinal_data.plot.scatter(x='zipcode', y='price', c='Red')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the scatter plot above, it's easy to tell that there are some linear relationship between the price and sqft_living and rooms - which makes sense. And combining them will probably yield a even more linear relationship. Let's try that with 3D scatter plot which can plot 2 factors together."},{"metadata":{"trusted":true},"cell_type":"code","source":"from mpl_toolkits import mplot3d\n\n# create 3D scatter plot with sqft_living and rooms\nfig = plt.figure()\nsqft_living_age = plt.axes(projection='3d')\nzdata = final_data['price']\nxdata = final_data['sqft_living']\nydata = final_data['rooms']\nsqft_living_age.scatter3D(xdata, ydata, zdata, c=zdata, cmap='Blues');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For age and zipcode however, they do not have a direct relationship with price like the other two features, and will probably only be meaningful for analysis when fixing some other variables. Let's try that by sampling the houses of 2900 < sqft_living < 3100 and 6.5 < rooms < 7.5, and try the popular zipcodes. Hopefully we will see some inverse linear relationship as I expected. UPDATE: Unfortunately this is not true."},{"metadata":{"trusted":true},"cell_type":"code","source":"# sample the data points matching the criteria\nsampled_data = final_data.loc[(final_data.sqft_living >= 2800) & (final_data.sqft_living <= 3200) & (final_data.rooms >= 6.0) & (final_data.rooms <= 8.0)] \n\n# confirm the shape of sampled data\nprint(sampled_data.shape)\n\n# use bar chart of figure out popular zipcodes\nzip_code_data = sampled_data.groupby('zipcode')[\"price\"].count().reset_index(name=\"count\")\n# select the top 5 zipcodes after sorting for bar chart\nzip_code_data = zip_code_data.sort_values(by='count', ascending=False).head(5)\nzip_code_data.plot.bar(x='zipcode', y='count', figsize=(30, 10))\n\n# now lets try each popular zipcode one by one\ndata_98075 = sampled_data.loc[sampled_data.zipcode == 98075]\ndata_98075.plot.scatter(x='age', y='price', c='Blue')\ndata_98059 = sampled_data.loc[sampled_data.zipcode == 98059]\ndata_98059.plot.scatter(x='age', y='price', c='Blue')\ndata_98052 = sampled_data.loc[sampled_data.zipcode == 98052]\ndata_98052.plot.scatter(x='age', y='price', c='Blue')\ndata_98006 = sampled_data.loc[sampled_data.zipcode == 98006]\ndata_98006.plot.scatter(x='age', y='price', c='Blue')\ndata_98038 = sampled_data.loc[sampled_data.zipcode == 98038]\ndata_98038.plot.scatter(x='age', y='price', c='Blue')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Simple Linear Regression Model\n\nHere comes the exciting part! Let's start building the machine learning model using linear regression. Here I'm using the popular library called sklearn which was recommended by a few tutorials. Based on the data visualization above, I shall use sqft_living and rooms for this analysis.\n\n### Model with sqft_living\n\nBut before that, I need to split data into training set and test set in order to assess the performance of my model - I'm choosing a 75-25 split here. "},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nfrom sklearn.model_selection import train_test_split \nfrom sklearn.linear_model import LinearRegression \n\nx_sqft = np.array(final_data['sqft_living']).reshape(-1, 1)\ny_price = np.array(final_data['price'])\n\n# splitting the data for simple regssion based on sqft_living\nx_sqft_train, x_sqft_test, y_price_train, y_price_test = train_test_split(x_sqft,y_price,test_size=1/4, random_state=0)\n\n# fitting simple linear regression to the training Set\nlinear_regressor = LinearRegression()\nlinear_regressor.fit(x_sqft_train, y_price_train)\n\n# using the linear regression to predict prices in training set\nsqft_train_prediction = linear_regressor.predict(x_sqft_train)\n\n# visualizing the prediction line in training set \nplt.scatter(x_sqft_train, y_price_train, color= 'yellow')\nplt.plot(x_sqft_train, sqft_train_prediction, color = 'darkblue')\nplt.xlabel(\"sqft_living\")\nplt.ylabel(\"price\")\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To assess the performance of this model, I will calculate the average difference between the prediction (running on training data) with the actual price in training set. Then compare the same difference between the prediction from test data with the actual price in test set, and use this to derive the percentage of consistency which will be my benchmark for assessing model performance.\n\n> Average Prediction Difference (APD) = avg(prediction - actual)\n\n> Percentage of Consistency (PoC) = 1 - (APD(training set) - APD(test set)) / APD(training set)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# function to calculate the average difference between prediction and actual price\ndef calculateDiffAvg(y_data, y_prediction):\n    print('Length of data set: ' + str(len(y_prediction)))\n    sum_diff = 0\n    for index in range(len(y_prediction)):\n        sum_diff += abs(y_prediction[index] - y_data[index])\n    average_diff = sum_diff / len(y_prediction)\n    return average_diff\n\n# function to calculate the percentage of consistency\ndef calculatePercentConsistent(diff_train, diff_test):\n    return (1 - (abs(diff_train - diff_test) / diff_train)) * 100\n\ndiff_avg_train = calculateDiffAvg(y_price_train, sqft_train_prediction)\nprint('Average difference in training set: ' + diff_avg_train.astype(str))\n\n# using the linear regression to predict prices in test set\nsqft_test_prediction = linear_regressor.predict(x_sqft_test)\ndiff_avg_test = calculateDiffAvg(y_price_test, sqft_test_prediction)\nprint('Average difference in test set: ' + diff_avg_test.astype(str))\n\n# calculate the percentage of consistency\nper_consist = calculatePercentConsistent(diff_avg_train,diff_avg_test)\nprint('Percentage of consistency: %s' % per_consist)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model with rooms\n\nThe model that predict using linear regression from sqft_living has an average difference of 173K, which is obviously not a great number in terms of accuracy. But at least it achieves high percentage of consistency when running on test data as well.\n\nNow repeat the same process for rooms."},{"metadata":{"trusted":true},"cell_type":"code","source":"x_room = np.array(final_data['rooms']).reshape(-1, 1)\n\n# splitting the data for simple regssion based on rooms\nx_room_train, x_room_test, y_price_train, y_price_test = train_test_split(x_room,y_price,test_size=1/4, random_state=0)\n\n# fitting simple linear regression to the training Set\nlinear_regressor_room = LinearRegression()\nlinear_regressor_room.fit(x_room_train, y_price_train)\n\n# using the linear regression to predict prices in training set\nroom_train_prediction = linear_regressor_room.predict(x_room_train)\n\n# visualizing the prediction line in training set \nplt.scatter(x_room_train, y_price_train, color= 'red')\nplt.plot(x_room_train, room_train_prediction, color = 'darkblue')\nplt.xlabel(\"rooms\")\nplt.ylabel(\"price\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diff_avg_train = calculateDiffAvg(y_price_train, room_train_prediction)\nprint('Average difference in training set: ' + diff_avg_train.astype(str))\n\n# using the linear regression to predict prices in test set\nroom_test_prediction = linear_regressor_room.predict(x_room_test)\ndiff_avg_test = calculateDiffAvg(y_price_test, room_test_prediction)\nprint('Average difference in test set: ' + diff_avg_test.astype(str))\n\n# calculate the percentage of consistency\nper_consist = calculatePercentConsistent(diff_avg_train,diff_avg_test)\nprint('Percentage of consistency: %s' % per_consist)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From result above, we can see that using rooms for simple linear regression model yield a result of average difference of rougle 210K, which is worse than the model on sqft_living which was 173K.\n\n## Multiple Linear Regression Model\n\nNow, let's try combine multiple variables into the linear regression model, with a hope that it can do better on Average Prediction Difference as well as Percentage of Consistency. The variables I'm picking are sqft_living, rooms and age. This is due to the fact that zipcodes are discrete data and might impact the result in non-contributing way."},{"metadata":{"trusted":true},"cell_type":"code","source":"# select multiple variables for linear regression this time\nx_multi = final_data.loc[:, ['sqft_living', 'rooms', 'age']].values\n\n# splitting the data for simple regssion based on rooms\nx_multi_train, x_multi_test, y_price_train, y_price_test = train_test_split(x_multi,y_price,test_size=1/4, random_state=0)\n\n# fitting linear regression to the training Set\nlinear_regressor_multi = LinearRegression()\nlinear_regressor_multi.fit(x_multi_train, y_price_train)\n\n# using the linear regression to predict prices in training set\nmulti_train_prediction = linear_regressor_multi.predict(x_multi_train)\n\ndiff_avg_train = calculateDiffAvg(y_price_train, multi_train_prediction)\nprint('Average difference in training set: ' + diff_avg_train.astype(str))\n\n# using the linear regression to predict prices in test set\nmulti_test_prediction = linear_regressor_multi.predict(x_multi_test)\ndiff_avg_test = calculateDiffAvg(y_price_test, multi_test_prediction)\nprint('Average difference in test set: ' + diff_avg_test.astype(str))\n\n# calculate the percentage of consistency\nper_consist = calculatePercentConsistent(diff_avg_train,diff_avg_test)\nprint('Percentage of consistency: %s' % per_consist)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As shown above, by using the multiple linear regression, I was able to reduce the average difference in prediction from 173K of using just sqft_living to 168K, which is a marginal improvement, but not as much as I hoped. I suspect if I fitler data set based a single zipcode and redo the analysis, the result will be much better.\n\n## Final Thoughts\n\nIn this project I tried out using pandas, numpy and sklearn to clean, analyze, visualize and predict data based on the classic \"House Sales in King County, USA\" dataset found on Kaggle. A few thoughts after completing the journey here on what's learnt and can be improved:\n\n1. Visualization is a powerful tool to yield insight and should always be tried out being heading down into the Machine Learning stage. For example, I always assumed that age would have a strong negative-linear relationship with price, but as visualization showed, this assumption was not true.\n2. Linear regression as the most basic model is obviously very limited when analyzing housing prices which in reality is impacted by much more factors than analyzed here. A more powerful and comprehensive model/algorithm is needed to further this analysis.\n3. As I mentioned, if I fitler data set based a single zipcode and redo the analysis, I suspect the result will be much better. Unfortunately I don't have time to finish this before the deadline."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}