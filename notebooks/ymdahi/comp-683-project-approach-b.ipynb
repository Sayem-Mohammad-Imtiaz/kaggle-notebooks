{"cells":[{"metadata":{"_uuid":"479cb602496b5012774acd789e6abad20ccb4860"},"cell_type":"markdown","source":"The following notebook/kernel is for [COMP 683 Group B](https://www.kaggle.com/ymdahi/comp-683-group-b-project-proposal/notebook).\n\n# Overview\nThis notebook will apply machine learning concepts to the Stack Overflow Developer Survey data in an effort to analyze and predict factors of **Job Satisfaction**. Specifically, we'll use the data from the  'AssesJob' set of questions to search for patterns for Job Satisfaction."},{"metadata":{"_uuid":"8b9c3e20487c92ad73a61afe6e24362b6995f1cf"},"cell_type":"markdown","source":"### Random Forest Classification\nRandom forest  is a trademark term for an ensemble classifier that consists of many decision trees and outputs the class that is the mode of the classes output by individual trees. \n![](https://i1.wp.com/dataaspirant.com/wp-content/uploads/2017/04/Random-Forest-Introduction.jpg?resize=768%2C384)\n\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os # operating system interface\nimport matplotlib.pyplot as plt\n\n# bring in data source\nso_results_file_path = '../input/survey_results_public.csv'\n#so_schema_file_path = '../input/survey_results_schema.csv'\n\n# create dataframe to hold results data\ndf = pd.read_csv(so_results_file_path)\n\ndf = df.dropna(subset=['JobSatisfaction'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7eada5c00e7aafd4c52f0ca1c37156beef6a312a"},"cell_type":"markdown","source":"## 1.0 Columns of Interest\nIn this section we'll explain how we are going to approach the data that interests us. The first thing to note about this dataset is that the data is largely qualitative. Given this, we will have to look for opportunities that allow us to more effectively and easily model our data."},{"metadata":{"_uuid":"6431e7f1c14bb5d91f62fe90f2ea1612470dc458"},"cell_type":"markdown","source":"### 1.1 Job Satisfaction\n\n> **\"Overall, how satisfied are you with your job thus far?\"**\n\nSurvey respondants were given the following options to select from when answering this question:\n\n* Extremely dissatisfied\n* Moderately dissatisfied\n* Slightly dissatisfied\n* Neither satisfied nor dissatisfied\n* Slightly satisfied\n* Moderately satisfied\n* Extremely satisfied\n\nFor the purpose of this assignment, we'll convert these 7 qualitative values to integers 1 through 7, where 1 represents 'Extremely dissatisfied' and 7 represents 'Extremely satisfied'. We'll perform this conversion in the next block:\n"},{"metadata":{"trusted":true,"_uuid":"2db060518be3c168336dd58ce18e7c9704ae9d61"},"cell_type":"code","source":"df['JobSatisfaction'].value_counts().plot.pie()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"239e754fc44f40f987a80e6b12791bfd60f1f7fb"},"cell_type":"code","source":"# Create a pandas column from 'CareerSatisfaction' that converts the qualitative values to quantitative values\nJobSatRating = []\nfor row in df['JobSatisfaction']:\n    if row == 'Extremely dissatisfied':\n        JobSatRating.append(1)\n    elif row == 'Moderately dissatisfied':\n        JobSatRating.append(2)\n    elif row == 'Slightly dissatisfied':\n        JobSatRating.append(3)\n    elif row == 'Neither satisfied nor dissatisfied':\n        JobSatRating.append(4)\n    elif row == 'Slightly satisfied':\n        JobSatRating.append(5)\n    elif row == 'Moderately satisfied':\n        JobSatRating.append(6)\n    elif row == 'Extremely satisfied':\n        JobSatRating.append(7)\n    else:\n        JobSatRating.append('Failed') # failed\n\ndf['JobSatRating'] = JobSatRating\n\ndf['JobSatRating'].describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3b6bce108546062b1e6e8a208659181957d83c02"},"cell_type":"markdown","source":"### 1.2 The AssessJob Question Set\nWhile there is alot of data that might be of interest to our model, we are going to be using the set of questions related to \"Assessing a potential job opportunity\" in our model. The reason for this decision is brevity: if we were to use qualitative data, such as country, degree, favourite frameworks, etc., we would need to perform coding of that data into some workable, quantifiable format. While not impossible, it is out of the scope of this assignment.\n\nThat said, the question set selected might suprise us with useful insight into how respondants with low or high Career Satisfaction might evaluate certain job characteristics.\n\nThe question set reads: \n\n>** \"Imagine that you are assessing a potential job opportunity. Please rank the following aspects of the job opportunity in order of importance (by dragging the choices up and down), where 1 is the most important and 10 is the least important\"**\n\nThe 10 options provided to the user to order include:\n\n1. AssessJob1: The **industry** that I'd be working in\n* AssessJob2: The **financial performance** or funding status of the company or organization\n* AssessJob3: The languages, **frameworks**, and other technologies I'd be working with\n* AssessJob4: The compensation and **benefits** offered\n* AssessJob5: The office environment or company **culture**\n* AssessJob6: The opportunity to work from home/**remotely**\n* AssessJob7: Opportunities for **professional development**\n* AssessJob8: The **diversity** of the company or organization\n* AssessJob9:  How widely used or **impactful** the product or service I'd be working on is\n* AssessJob10: **Salary** and/or bonuses\n\nThese columns contain a value between 1 and 10 that represents how the respondant ranked the importance of the factor."},{"metadata":{"trusted":true,"_uuid":"e48eb666a51258a1a0ef89a43225836f882ff21b"},"cell_type":"code","source":"# Columns that we are interested in observing.\ncolumns_of_interest = ['AssessJob1','AssessJob2','AssessJob3','AssessJob4','AssessJob5','AssessJob6','AssessJob7','AssessJob8','AssessJob9','AssessJob10','JobSatisfaction','JobSatRating']\n\n# Drop any rows that does not have complete data for the COI above.\nclean_df = df[columns_of_interest].dropna()\n\n# Rename the columns in our COI so they are easier to read.\nclean_df.columns = ['Industry', 'FinancialStatus','Frameworks','Benefits','Culture','Remote','PD','Diversity','Impact','Salary','JobSatisfaction','JobSatRating']\n\n# The column we want to predict\ntarget_column = ['JobSatRating']\n\n# The columns we will use to model and make prediction\nprediction_columns = ['Industry', 'FinancialStatus','Frameworks','Benefits','Culture','Remote','PD','Diversity','Impact','Salary']\n\n# Let's tale a look at our dataframe\nclean_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"40f32a11a7c70bd1e740111694a348c8a37d793f"},"cell_type":"code","source":"# Let's take a look at our prediction columns\nclean_df[prediction_columns].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3391be66101e7f0c2ab26ab9731bc83578fe450d"},"cell_type":"code","source":"# Box Plot for Prediction Columns\nclean_df[prediction_columns].boxplot(figsize=(18,10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b98f30d5c830df456bf87155926711d78b04d50"},"cell_type":"code","source":"clean_df[prediction_columns].hist(figsize=(18,10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f080b4d52557047c429834f13897b8626814a6e2"},"cell_type":"code","source":"# Count and plot predictors that ranked 3 or lower. i.e. higher importance.\nprint (clean_df[clean_df[prediction_columns]<=3].count())\nprint (clean_df[clean_df[prediction_columns]<=3].count().plot.bar())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fde19429b0ebe52c8f227c6ddadcf0048b38c9e3"},"cell_type":"code","source":"# Count and plot predictors that ranked 7 or higher. i.e lower importance\nprint (clean_df[clean_df[prediction_columns]>=7].count())\nprint (clean_df[clean_df[prediction_columns]>=7].count().plot.bar())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4ec3c17ece086b3055e236dc332b85c0e03896cd"},"cell_type":"markdown","source":"### Pre-Model Analysis of DataFrame\nThere are a couple of interesting pieces of information to note:\n\n* Most respondents ranked 'Culture' as having the most important in a potential job.\n* Also ranked higher in priority: 'Benefits' and 'Diversity'.\n* Most respondents ranked 'Impact' as having least importance in a potential job.\n* Also, other lower ranked factors included 'Financial Status' and 'Industry'"},{"metadata":{"_uuid":"05c02aec611601da9813dcb12f4d12387ee1aa4c"},"cell_type":"markdown","source":"## 2.0 Modelling, Training, and Predictions\nWe will use a Random Forest Classifier to train our data and build our mode."},{"metadata":{"trusted":true,"_uuid":"21e4572a5973fbc0bf4f169b9dbb01d9ca47e5cf"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nnp.random.seed(0)\n\n# Randomly pick some data to be training data.\nclean_df['is_train'] = np.random.uniform(0, 1, len(clean_df)) <= .75\n\n# Create two new dataframes, one with the training rows, one with the test rows\ntrain = clean_df[clean_df['is_train']==True]\ntest = clean_df[clean_df['is_train']==False]\n\n# Show the number of observations for the test and training dataframes\nprint('Number of observations in the training data:', len(train))\nprint('Number of observations in the test data:',len(test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cba061b906cd9c27f2a221d8021d78bef8d93f36"},"cell_type":"code","source":"# Remembering our prediction and target columns\nprint ('What we want to predict: ')\nprint (target_column)\nprint ('Factors we will consider when predicting: ')\nprint (prediction_columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a79f58f4d5800b56f6248af25ecf94026752ebfc"},"cell_type":"code","source":"clean_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"345775bb6980272301bda48b5b523857d243ceca"},"cell_type":"code","source":"# Create new df to hold training data\ny = train[target_column]\ny.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"38320605949a46cbddf1027b308ae039a78ef8be"},"cell_type":"code","source":"# Create a random forest Classifier. By convention, clf means 'Classifier'\nclf = RandomForestClassifier(n_jobs=2, random_state=0)\n\n# Train the Classifier to take the training features and learn how they relate\n# to the training y (the career satisfaction rating)\nclf.fit(train[prediction_columns], y)\nprint (clf.score(train[prediction_columns], y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ed91f8608693e754364a58c61a94f8280002a1a0"},"cell_type":"code","source":"# Apply the Classifier we trained to the test data (which, remember, it has never seen before)\nprint(clf.predict(test[prediction_columns]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8f7dacf8974d4dcc3a204581ddb33fd35a8f681"},"cell_type":"code","source":"# View the predicted probabilities of the first 10 observations\nprint(clf.predict_proba(test[prediction_columns])[0:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c967c5d8187d81cfd6437fdb5f6b112117b0f26d"},"cell_type":"code","source":"preds = clf.predict(test[prediction_columns])\nprint('Predictions for first 5 elements in test df:')\nprint(preds[0:5])\nprint('Actual values for first 5 elements in test df:')\nprint(test['JobSatRating'].head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d4ee98ad098b6804bb55819ad908b3792b00bea"},"cell_type":"code","source":"# Create confusion matrix\ncm = pd.crosstab(test['JobSatRating'], preds, rownames=['Actual JobSatisfaction'], colnames=['Predicted JobSatisfaction'])\ncm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d09b0b437bd5a4559d5e3057c161b49641fc8243","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"cm.plot.bar(figsize=(18,10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"883d3dd3c1139febde853bb0218c9daccf614f2e"},"cell_type":"code","source":"cm.plot(kind=\"bar\", figsize=(8,8),stacked=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e4d9c61d0dfd29eebe22bb06a589369d6567a5bc"},"cell_type":"code","source":"# View a list of the features and their importance scores\nimp = list(zip(train[prediction_columns], clf.feature_importances_))\nimp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"344ba9bca511b3b612bd52ca1fb288112615a112"},"cell_type":"code","source":"std = np.std([tree.feature_importances_ for tree in clf.estimators_],\n             axis=0)\nindices = np.argsort(importances)[::-1]\n\n# Print the feature ranking\nprint(\"Feature ranking:\")\n\nfor f in range(train[prediction_columns].shape[1]):\n    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n\n# Plot the feature importances of the forest\nplt.figure()\nplt.title(\"Feature importances\")\nplt.bar(range(train[prediction_columns].shape[1]), importances[indices],\n       color=\"grey\", yerr=std[indices], align=\"center\")\nplt.xticks(range(train[prediction_columns].shape[1]), indices)\nplt.xlim([-1, train[prediction_columns].shape[1]])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c5519e0701cd80722c5a16fd9052d3ff1cd696d3"},"cell_type":"markdown","source":"### Links\n* https://www.analyticsvidhya.com/blog/2017/09/common-machine-learning-algorithms/\n* https://www.analyticsvidhya.com/blog/2016/04/complete-tutorial-tree-based-modeling-scratch-in-python/"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}