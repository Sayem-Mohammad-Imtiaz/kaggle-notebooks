{"cells":[{"metadata":{},"cell_type":"markdown","source":"# EDA and Profiling the data with pandas_profiler is out of scope....for details see:https://www.kaggle.com/blakperlz/botnet-data-profiling-and-proposed-ml-techniques","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# This is a variation focusing on AutoML using TPOT.  For details on TPOT see... https://pypi.org/project/TPOT/","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Code below is inspired by and not the same as: https://www.datacamp.com/community/tutorials/tpot-machine-learning-python","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# import the basics\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\n# import TPOT and sklearn \nfrom tpot import TPOTClassifier\nfrom sklearn.datasets import load_digits\nfrom sklearn.model_selection import train_test_split\nimport sklearn.metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Raw data from the first file\ndata = pd.read_csv('../input/unsw-nb15/UNSW-NB15_1.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Data Prep**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Raw data from the first file\ndata = pd.read_csv('../input/unsw-nb15/UNSW-NB15_1.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sample top 5\ndata.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Well the data has no headers....we can find what they 'should be' via the features file.\n#then lets reload the data\n# and we'll make two copies of it in case we want to experiment later\ndata2 = data = pd.read_csv('../input/unsw-nb15/UNSW-NB15_1.csv', header = None, names = ['srcip','sport','dstip','dsport','proto','state','dur','sbytes','dbytes','sttl','dttl','sloss','dloss','service','Sload','Dload','Spkts','Dpkts','swin','dwin','stcpb','dtcpb','smeansz','dmeansz','trans_depth','res_bdy_len','Sjit','Djit','Stime','Ltime','Sintpkt','Dintpkt','tcprtt','synack','ackdat','is_sm_ips_ports','ct_state_ttl','ct_flw_http_mthd','is_ftp_login','ct_ftp_cmd','ct_srv_src','ct_srv_dst','ct_dst_ltm','ct_src_ ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','attack_cat','Label'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#make a data frame\ndf = pd.DataFrame(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Double check results\ndata.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#What were the column names again?\ndf.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This is a noisy data set.  Traditional netflow is a lot simpler.  \n# Let's make a smaller data set....if you don't know what these are...check out the data dictionary '....features.csv'\n# Make a new df so there is no overwrite\nfeatures = df[[\"sport\",\"dsport\",\"proto\",\"Dpkts\", \"Spkts\",\"Label\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check features\nfeatures.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#data types\nfeatures.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#well shoot....now the coorect way is to do a .loc, but lets try a quicker route...\n#copy/paste.  Note this is the the 'correct' way, but it works for now\nfeatures2=features.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Machines read numbers, so let's convert to numbers\n#BTW when ran the first time sport and dsport were 'rejected', so this is a 'must'.\nfeatures2['sport'] = pd.to_numeric(features['sport'], errors='coerce')\nfeatures2['dsport'] = pd.to_numeric(features['sport'], errors='coerce')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We can also do label encoding...\n#Label encoding per: https://www.datacamp.com/community/tutorials/categorical-data\nfrom sklearn.preprocessing import LabelEncoder\n\nlb_make = LabelEncoder()\nfeatures2['proto'] = lb_make.fit_transform(features2['proto'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# are there any null values?\nfeatures2.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop all rows with null values\n#make a new variable so you can trace back your work when troubleshooting\nfeatures3 = features2.dropna(how='any',axis=0) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Validate this has been corrected\nfeatures3.isnull().sum()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data has now been profiled, cleaned, and preprocessed.  Time for actual analysis and machine learning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# import the libraries\nfrom tpot import TPOTClassifier\nfrom sklearn.model_selection import train_test_split\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count the labels\nfeatures3['Label'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Alright...about 700K records","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# double check there are no null values\npd.isnull(features3).any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make a new Label variable\nLabel = features3['Label'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create indices by spliting the data\nfrom sklearn.model_selection import train_test_split\ntraining_indices, validation_indices = training_indices, testing_indices = train_test_split(features3.index,\n                                                                                            stratify = Label,\n                                                                                            train_size=0.75, test_size=0.25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Test the size, aka is it what you were expecting\ntraining_indices.size, validation_indices.size","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 524,994+174999 = 699,993....and that matches earlier numbers so data is still in good shape","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfrom tpot import TPOTClassifier\nfrom tpot import TPOTRegressor\n\ntpot = TPOTClassifier(generations=5,verbosity=2)\n\ntpot.fit(features3.drop('Label',axis=1).loc[training_indices].values,\n         features3.loc[training_indices,'Label'].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tpot.score(features3.drop('class',axis=1).loc[validation_indices].values,\n           features3.loc[validation_indices, 'Label'].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tpot.score(features3.drop('class',axis=1).loc[validation_indices].values,\n           features3.loc[validation_indices, 'Label'].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}