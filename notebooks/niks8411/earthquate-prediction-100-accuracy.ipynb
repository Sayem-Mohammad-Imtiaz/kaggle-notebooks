{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\npd.set_option(\"max_columns\", None)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"../input/earthquake-database/database.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a list with numeric columns for visualization\n\nnumeric_columns = []\n\nfor column in data.columns:\n    if data.dtypes[column] !=\"object\":\n        numeric_columns.append(column) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numeric_columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Correlation matrix with heatmap\n\ncorr_mat = data[numeric_columns].corr() \nplt.figure(figsize=(12,8))\nsns.heatmap(corr_mat, annot=True, cmap=\"Blues\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = data.drop(\"ID\", axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_inputs(df):\n    \n    df = df.copy()\n    \n    # Dropping columns with more than 30% missing values\n    \n    for column in data.columns:\n        if df[column].isna().mean() > 0.3:\n            df = df.drop(column, axis=1) \n        \n    # Filling the missing values of the Root Mean Square column\n    \n    df[\"Root Mean Square\"] = df[\"Root Mean Square\"].fillna(df[\"Root Mean Square\"].mean())\n    \n    # Dropping the rows with missing targat values\n    \n    df = df.dropna(axis=0).reset_index(drop=True)\n    \n    # Extracting the date features\n    \n    df[\"Month\"] = df[\"Date\"].apply(lambda x: (x[0:2])) \n    df[\"Year\"] = df[\"Date\"].apply(lambda x: (x[-4:]))    \n    df = df.drop(\"Date\", axis=1)\n    \n    # Convert Month column to integer or float\n    \n    df[\"Month\"] = df[\"Month\"].astype(np.int)\n    \n    # Dropping the rows in the Year column which have Z and converting the column to int or float\n    \n    invalid_indexes = df[df[\"Year\"].str.contains(\"Z\")].index\n    df = df.drop(invalid_indexes, axis=0).reset_index(drop=True)\n    \n    df[\"Year\"] = df[\"Year\"].astype(np.int)\n    \n    # Extracting the hour feature\n    \n    df[\"Hour\"] = df[\"Time\"].apply(lambda x: np.int(x[0:2])) \n    \n    df = df.drop(\"Time\", axis=1)\n    \n    # Binary encode the Status column\n    \n    df[\"Status\"] = df[\"Status\"].replace({\"Automatic\": 1, \"Reviewed\": 0})\n    \n    # One-hot encoding\n    \n    for column in [\"Type\", \"Magnitude Type\", \"Source\", \"Location Source\", \"Magnitude Source\"]:\n        dummies = pd.get_dummies(df[column])\n        df = pd.concat([df, dummies], axis=1)\n        df = df.drop(column, axis=1)\n    \n    \n    # Splitting and scaling the data\n    \n    y = df[\"Status\"]\n    X = df.drop(\"Status\", axis=1)\n    \n    # Scaling X \n    \n    scaler = StandardScaler()\n    X = pd.DataFrame(scaler.fit_transform(X), columns = X.columns)\n    \n    # Train test split\n    \n    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, random_state=42)\n    \n    return X_train, X_test, y_train, y_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test= preprocess_inputs(data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training\n\nmodel = RandomForestClassifier()\nmodel.fit(X_train, y_train)\nprint(\"RF trained.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Results\n\nmodel.score(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}