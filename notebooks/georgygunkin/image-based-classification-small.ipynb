{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#loading in the csv data\ndf = pd.read_csv('/kaggle/input/fashion-product-images-small/myntradataset/styles.csv',error_bad_lines=False)\n\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[1748:1754].head(6)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df[540:541].id.values[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\nimport cv2\nfor i in range(1748, 1754):\n    \n    thisId = str(df[i:i+1].id.values[0])\n    \n    imageName = '/kaggle/input/fashion-product-images-small/myntradataset/images/'+ thisId +'.jpg'\n    image = cv2.imread(imageName)\n    image = RGB_im = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    \n    plt.imshow(image)\n    plt.title(f'Image {thisId}')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.dropna()\ndf.nunique()\ndf.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Looking at all the unique labels in all categorical columns \ncat_columns = ['gender', 'masterCategory', 'subCategory', 'articleType','baseColour', 'season', 'year', 'usage']\n\nfor col in cat_columns:\n    print(col)\n    print(df[col].unique())\n    print('-------------------------')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The images in this Dataset are very low resolution (80x60). We will be using the categories that are visually distinct even at such a low resolution.\n\nThe categories year, usage, season, and gender mighht not be clearly visually distinct in some cases, so we wont be using them.\n\nThe categories, masterCategory and subCategory are distinct enough groups, but they are not specific enough for practical use. \n","metadata":{}},{"cell_type":"code","source":"value_counts = df['subCategory'].value_counts()\n\nindexes = value_counts.index\n\nvalues = value_counts.values\n\ntypes_used = indexes[:i]\nprint('Types used: ',types_used)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Taking a subset of 20000 images\nold_df = df\ndf = old_df[:25000]\nlen(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_trimmed = old_df[:15923]\n\ndf_extended = pd.concat([old_df, df_trimmed], ignore_index=True)\n\nlen(df_extended)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we will load in all the images from the remaining rows, and convert them to numpy arrays with img_to_array function in keras.","metadata":{}},{"cell_type":"code","source":"# AUGMENT\n\ndata = []\n\n# Reading all the images and processing the data in them \n\nfrom tensorflow.keras.preprocessing.image import img_to_array\nimport cv2\n\nIX = 80\nIY = 60\n\ninvalid_ids = []\n\ncount = 0\n\nfor name in df.id:\n\n    try:\n        count += 1\n        image = cv2.imread('/kaggle/input/fashion-product-images-small/myntradataset/images/'+str(name)+'.jpg')\n        imageResized = cv2.resize(image, (IX,IY) )\n        \n        # Flipping the image horizontally -> augmentation of the first 15923 image starts here\n        if (count >= 44077):\n            imageResized = cv2.flip(imageResized, 1)\n        \n        image = img_to_array(imageResized)\n        data.append(image)        \n    except: \n        # Images for certain ids are missing, so they are not added to the dataset  \n        invalid_ids.append(name)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NO AUGMENT\n\n#data = []\n\n# Reading all the images and processing the data in them \n\n#from tensorflow.keras.preprocessing.image import img_to_array\n#import cv2\n\n#IX = 80\n#IY = 60\n\n#invalid_ids = []\n\n#for name in df.id:\n\n#    try:\n#        image = cv2.imread('/kaggle/input/fashion-product-images-small/myntradataset/images/'+str(name)+'.jpg')\n#        imageResized = cv2.resize(image, (IX,IY) )\n#        image = img_to_array(imageResized)\n#        data.append(image)        \n#    except: \n        # Images for certain ids are missing, so they are not added to the dataset  \n#        invalid_ids.append(name)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import img_to_array\nimport cv2\n\nIX = 80\nIY = 60","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labelsInit = []\n\ncount = 0\n\nfor index, row in df.iterrows():\n    \n    count += 1\n    \n    if row['id'] in invalid_ids:\n        continue\n\n    labelsInit.append(row['subCategory'])\n    \nprint(count)\nlen(labelsInit)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Unique categories\ndf[\"subCategory\"].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\n# converting data into numpy arrays\n\ndata = np.array(data, dtype=\"float\") / 255.0\nlabels = np.array(labelsInit)\n\nprint(labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we will create binary vectors as the outputs of the model","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelBinarizer\n\n# creating a binary vector for the input labels \n\nmlb = LabelBinarizer()\nlabels = mlb.fit_transform(labels)\n\nprint(mlb.classes_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\nfrom tensorflow.keras.optimizers import Adam\n\ninputShape = (IY, IX, 3)\n\nmodel = Sequential()\n\nmodel.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=inputShape))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.4)) # Dropout increased from 0.3 to 0.4\n\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.4)) # Dropout increased from 0.3 to 0.4\n\nmodel.add(Flatten()) \n\nmodel.add(Dense(128))\nmodel.add(Activation('relu'))\n\n\nout = len(mlb.classes_)\n\nmodel.add(Dense(out))\nmodel.add(Activation('sigmoid'))\n\noptimizer = Adam(learning_rate=0.000875, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=True)\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer=optimizer,\n              metrics=['mse'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# splitting data into testing and training set \n\n(trainX, testX, trainY, testY) = train_test_split(data,labels, test_size=0.2, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch = 32\nE = 100\n\n#training the model \nmodel.fit(x=trainX,y=trainY,\n          epochs=E ,verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TEST SET\nprint(\"Predicting on the test set\")\npreds = model.predict(testX)\n\n\n# since the predictions of the model are sigmoid, we will first binarize them to 0 or 1\npred_binarized = []\n\nfor pred in preds:\n    index = np.argmax(pred)\n    ar = np.zeros((pred.shape[0],), dtype=int)\n    ar[index] = 1\n    pred_binarized.append(ar)\n\npred_binarized = np.array(pred_binarized)   \n\n# we convert the output vectors to the predicted labels\ntrue_test_labels = mlb.inverse_transform(testY)\npred_test_labels = mlb.inverse_transform(pred_binarized)\n\ncorrect = 0\nwrong = 0\n\n# Evaluating the predictions of the model\n\nfor i in range(len(testY)):\n\n    true_labels = list(true_test_labels[i])\n\n    pred_labels = list(pred_test_labels[i])\n\n    label1 = true_labels[0]\n    label2 = true_labels[1]\n\n    if label1 in pred_labels:\n        correct+=1\n    else:\n        wrong+=1\n\n    if label2 in pred_labels:\n        correct+=1\n    else:\n        wrong+=1    \n\n\n\nprint('correct: ', correct)\nprint('missing/wrong: ', wrong)\nprint('Accuracy: ',correct/(correct+wrong))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TRAIN SET\nprint(\"Predicting on the train set\")\npredsTrain = model.predict(trainX)\n\n\n# since the predictions of the model are sigmoid, we will first binarize them to 0 or 1\npred_binarized_train = []\n\nfor pred in predsTrain:\n    index = np.argmax(pred)\n    ar = np.zeros((pred.shape[0],), dtype=int)\n    ar[index] = 1\n    pred_binarized_train.append(ar)\n\npred_binarized_train = np.array(pred_binarized_train)   \n\n# we convert the output vectors to the predicted labels\ntrue_train_labels = mlb.inverse_transform(trainY)\npred_train_labels = mlb.inverse_transform(pred_binarized_train)\n\ncorrect = 0\nwrong = 0\n\n# Evaluating the predictions of the model\n\nfor i in range(len(trainY)):\n\n    true_labels = list(true_train_labels[i])\n\n    pred_labels = list(pred_train_labels[i])\n\n    label1 = true_labels[0]\n    label2 = true_labels[1]\n    \n    if label1 in pred_labels:\n        correct+=1\n    else:\n        wrong+=1\n\n    if label2 in pred_labels:\n        correct+=1\n    else:\n        wrong+=1    \n\nprint('correct: ', correct)\nprint('missing/wrong: ', wrong)\nprint('Accuracy: ',correct/(correct+wrong))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(testY)):\n    if (true_test_labels[i] != pred_test_labels[i]):\n        print('True labels: ',true_test_labels[i],' Predicted labels: ',pred_test_labels[i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}