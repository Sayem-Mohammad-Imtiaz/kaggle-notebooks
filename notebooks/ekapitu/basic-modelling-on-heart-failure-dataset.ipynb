{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"heart_data = pd.read_csv(\"../input/heart-failure-clinical-data/heart_failure_clinical_records_dataset.csv\")\nheart_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"heart_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check for null values\nheart_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separate features and target variable\nfeatures = ['age', 'anaemia', 'creatinine_phosphokinase', 'diabetes',\n       'ejection_fraction', 'high_blood_pressure', 'platelets',\n       'serum_creatinine', 'serum_sodium', 'sex', 'smoking', 'time']\n\nx = heart_data[features]\ny = heart_data[\"DEATH_EVENT\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.rcParams[\"figure.figsize\"] = 12,1\nplt.rcParams[\"font.size\"] = 14\n\n# Non boolean values\nsns.boxplot(x=heart_data[\"creatinine_phosphokinase\"], color=\"grey\")\nplt.show()\nsns.boxplot(x=heart_data[\"ejection_fraction\"], color=\"grey\")\nplt.show()\nsns.boxplot(x=heart_data[\"platelets\"], color=\"grey\")\nplt.show()\nsns.boxplot(x=heart_data['serum_creatinine'], color = 'grey')\nplt.show()\nsns.boxplot(x=heart_data[\"serum_sodium\"], color=\"grey\")\nplt.show()\nsns.boxplot(x=heart_data[\"time\"], color=\"grey\")\nplt.show()\nsns.boxplot(x=heart_data[\"age\"], color=\"grey\")\nplt.show()\n\n# Boolean values: diabetes, sex, smoking, anaemia, high_blood_pressure","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove outliers\nheart_data[\"ejection_fraction\"] = heart_data[heart_data[\"ejection_fraction\"] < 70]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalize features\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\n\nscaler = StandardScaler().fit(x_train)\nx_train = scaler.fit_transform(x_train)\nx_test = scaler.fit_transform(x_test)\n\nencoder = LabelEncoder().fit(y)\n\ny_train = encoder.fit_transform(y_train)\ny_test = encoder.fit_transform(y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logistic regresssion","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Storing the accuracy of all models\nall_model_accuracy = {}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit model\nfrom sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression(random_state=0)\nmodel.fit(x_train, y_train)\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\n# Predict, calculate score\ny_pred = model.predict(x_test)\n\nconf_matrix = confusion_matrix(y_pred, y_test)\naccuracy = model.score(x_test, y_test)\n\nall_model_accuracy[\"LogisticRegression\"] = accuracy\n\nprint(conf_matrix)\nprint(accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## K nearest neighbors\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# KNN model\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# For grid search\naccuracy_results = []\n\nneighbor_range = range(3, 10)\nfor num_neighbors in neighbor_range:\n    clf = KNeighborsClassifier(n_neighbors=num_neighbors, metric = 'minkowski')\n    clf.fit(x_train, y_train)\n#     y_pred = clf.predict(x_test_scaled)\n    accuracy_results.append(clf.score(x_test, y_test))\n    \nimport matplotlib.pyplot as plt\n\nplt.plot(list(neighbor_range), accuracy_results)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using num neighbors = 9\n\nknn_model = KNeighborsClassifier(n_neighbors=9, metric=\"minkowski\")\nknn_model.fit(x_train, y_train)\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\ny_pred = knn_model.predict(x_test)\n\nconf_matrix = confusion_matrix(y_test, y_pred)\nprint(conf_matrix)\n\naccuracy = accuracy_score(y_test, y_pred)\nall_model_accuracy[\"KNN\"] = accuracy\nprint(accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Decision Tree","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\ndtree_model = DecisionTreeClassifier(random_state=0, criterion=\"entropy\")\n\ndtree_model.fit(x_train, y_train)\n\ny_predict = dtree_model.predict(x_test)\n\nconf_matrix = confusion_matrix(y_pred, y_test)\naccuracy = dtree_model.score(x_test, y_test)\n\nall_model_accuracy[\"DecisionTree\"] = accuracy\n\nprint(conf_matrix)\nprint(accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random forest","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\naccuracy_results = []\nnum_trees = range(100, 200)\n\nfor num_tree in num_trees:\n    rf_model = RandomForestClassifier(random_state=0, n_estimators=num_tree, criterion='entropy')\n    rf_model.fit(x_train, y_train)\n    \n    accuracy_results.append(rf_model.score(x_test, y_test))\n    \nimport matplotlib.pyplot as plt\n\nplt.plot(list(num_trees), accuracy_results)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using 110 trees\nrf_model = RandomForestClassifier(n_estimators=110, random_state=0, criterion='entropy')\nrf_model.fit(x_train, y_train)\n\ny_pred = rf_model.predict(x_test)\naccuracy = accuracy_score(y_test, y_pred)\n\nall_model_accuracy[\"RandomForest\"] = accuracy\nprint(confusion_matrix(y_test, y_pred))\nprint(accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Neural network","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom keras import layers\n\nann_model = keras.Sequential()\n\n# Add 4 layers\nann_model.add(layers.Dense(units=10, activation='relu'))\nann_model.add(layers.Dense(units=10, activation='relu'))\nann_model.add(layers.Dense(units=10, activation='relu'))\nann_model.add(layers.Dense(units=10, activation='relu'))\n\n# Add output layer\nann_model.add(layers.Dense(units=1, activation='sigmoid'))\n\n# Build\nann_model.compile(optimizer = 'adam', loss = 'binary_crossentropy' , metrics = ['accuracy'] )\n\n# Train\nann_model.fit(x_train, y_train, batch_size = 32, epochs = 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Summary of model\nann_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting\ny_predict = ann_model.predict(x_test)\ny_predict = (y_predict > 0.5) # Convert to boolean\n# y_predict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = accuracy_score(y_test, y_predict)\n\nall_model_accuracy[\"NeuralNetwork\"] = accuracy\n\nprint(confusion_matrix(y_predict, y_test))\nprint(accuracy_score(y_predict, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## XGBoost Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\n\naccuracy_results = []\nnum_estimators = range(10, 100, 10)\n\nfor num_estimator in num_estimators:\n    model = XGBClassifier(n_estimators=num_estimator)\n    model.fit(x_train, y_train)\n    \n    accuracy_results.append(model.score(x_test, y_test))\n    \nimport matplotlib.pyplot as plt\n\nplt.plot(list(num_estimators), accuracy_results)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = XGBClassifier(n_estimators=80)\nmodel.fit(x_train, y_train)\n\ny_pred = model.predict(x_test)\naccuracy = accuracy_score(y_pred, y_test)\n\nall_model_accuracy[\"XGBoost\"] = accuracy\n\nprint(confusion_matrix(y_pred, y_test))\nprint(accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_model_accuracy","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plotting all accuracy results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pylab as plt\n\nfont = {'family' : 'normal',\n        'size'   : 13}\n\nplt.rc('font', **font)\n\nplt.figure(figsize=(15, 5))\n\nticks = range(1,7)\ntick_label = list(all_model_accuracy.keys())\nheight = list(all_model_accuracy.values())\n\nplt.bar(ticks, height, tick_label=tick_label)\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Classifier models\")\nplt.show()\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}