{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nprint(f\"Last updated on {pd.to_datetime('today').strftime('%m/%d/%Y')}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Covid-19 subset of articles"},{"metadata":{},"cell_type":"markdown","source":"[CORD-19](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge) data set of scholarly articles about COVID-19 and the coronavirus group. This notebook uses the title and publication dates of articles to create a subset that are specifically about Covid-19 or SARS-CoV-2.\n\nDataset | # Articles | Output Files\n---|---|---\nCORD-19 | 52398 | cord19_meta.csv\nFull text | 36977 |\nUniques | 36610 | cord19.csv\nAfter 12/01/2019 | 4714\nCovid-19 | 3106 | covid19.csv\nCovid-19-meta | 4561 | covid19_meta.csv"},{"metadata":{"trusted":true},"cell_type":"code","source":"import glob\nimport json\nimport os\nimport numpy as np\nimport pandas as pd\nfrom pprint import pprint\n\ninput_path = '/kaggle/input/CORD-19-research-challenge/'\n\n# See JSON schema here: https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge#json_schema.txt\ndef read_text(file, key):\n    entries = file[key]\n    if isinstance(entries, dict):\n        entries = entries.values()\n    return '\\n'.join([x['text'] for x in entries])\n\n# Each paragraph is a separate entry in the body_text data.\ndef read_body_text(file):\n    prev_section = None\n    text = []\n    for x in file['body_text']:\n        section = x['section']\n        if section != prev_section:\n            text.append('<SECTION>')\n            text.append(section)\n            prev_section = section\n        text.append(x['text'])\n    return '\\n'.join(text)\n    \ndef read_file(filename):\n    file = json.load(open(filename, 'rb'))\n    data = {\n        'paper_id': file['paper_id'],\n        'title': file['metadata']['title'],\n        'abstract': read_text(file, 'abstract'),\n        'body_text': read_body_text(file),\n        'ref_entries': read_text(file, 'ref_entries'),\n    }\n    return data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load all pdf json article contents"},{"metadata":{"trusted":true},"cell_type":"code","source":"json_files = sorted(glob.glob(f'{input_path}/**/pdf_json/*.json', recursive=True))\nprint('Total pdf files: ', len(json_files))\n\nfile_contents = []\nfor i, file in enumerate(json_files):\n    if i % 2000 == 0:\n        print(f'Processing {i} of {len(json_files)}')\n    file_contents.append(read_file(file))\ncontent_df = pd.DataFrame(file_contents)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load metadata and join with contents"},{"metadata":{"trusted":true},"cell_type":"code","source":"metadata_path = f'{input_path}/metadata.csv'\nmeta_df = pd.read_csv(metadata_path, dtype={\n    'sha': str,\n    'doi': str,\n    'pmcid': str,\n    'pubmed_id': str,\n    'Microsoft Academic Paper ID': str,\n    'WHO #Covidence': str,\n})\npd.options.display.max_colwidth = 100\nmeta_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('PDF-only: ', meta_df[meta_df.has_pdf_parse & ~meta_df.has_pmc_xml_parse].cord_uid.count())\nprint('PMC-only: ', meta_df[~meta_df.has_pdf_parse & meta_df.has_pmc_xml_parse].cord_uid.count())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df = content_df.merge(meta_df, how='inner', left_on='paper_id', right_on='sha')\nfull_df = full_df.replace(r'^\\s*$', np.nan, regex=True)\nfull_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df['title'] = full_df.title_y.fillna(full_df.title_x)\nfull_df['abstract'] = full_df.abstract_y.fillna(full_df.abstract_x)\nfull_df.drop(columns=['sha', 'title_x', 'title_y', 'abstract_x', 'abstract_y'], inplace=True)\nfull_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dedup, filter, and write to csv"},{"metadata":{"trusted":true},"cell_type":"code","source":"stats = {}\nstats['total'] = meta_df.shape[0]\nstats['full text'] = full_df.shape[0]\ndf = full_df\n\n# Drop duplicates by title (an article may come from multiple sources resulting in dups).\ndf = df.drop_duplicates(['title'])\nstats['uniques'] = df.shape[0]\ndf.to_csv('cord19.csv', index=False)\n\n# Filter by publish time.\ndf = df[pd.to_datetime(df.publish_time, errors='coerce') >= pd.to_datetime('2019-12-01')]\nstats['after 12/01/2019'] = df.shape[0]\n\n# Filter by covid-19 keywords.\nkeywords = ['novel coronavirus', 'COVID-19', 'COVID19', 'SARS-CoV-2', '2019-nCov']\nkeywords_regex = '|'.join(keywords)\ndf_covid19 = df[df.title.str.contains(keywords_regex, na=False, case=False, regex=True) | df.abstract.str.contains(keywords_regex, na=False, case=False, regex=True)]\nstats['covid-19'] = df_covid19.shape[0] \ndf_covid19.to_csv('covid19.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Write full metadata as well:\nmeta_df.to_csv('cord19_meta.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Also write covid19_metadata for all articles, including those without full text.\ndf = meta_df\ndf = df.drop_duplicates(['title'])\ndf = df[pd.to_datetime(df.publish_time, errors='coerce') >= pd.to_datetime('2019-12-01')]\ndf_covid19_meta = df[df.title.str.contains(keywords_regex, na=False, case=False, regex=True) | df.abstract.str.contains(keywords_regex, na=False, case=False, regex=True)]\nstats['covid-19-meta'] = df_covid19_meta.shape[0] \ndf_covid19_meta.to_csv('covid19_meta.csv', index=False)\npd.DataFrame([stats]).transpose()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Sample data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_covid19_meta.head(1).transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_covid19.head(1).transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_covid19.iloc[0].abstract)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_covid19.iloc[0].body_text.split('<SECTION>')[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meta_df[meta_df.title.str.contains('Coronaviruses: a paradigm of new emerging zoonotic diseases', case=False, na=False)]","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":4}