{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Introduction\nHello thereee!\n\nIn this project, the goal is to build two models - `Logistic Regression and LSTM` - that can detect and classify the sentiments (`postive, negative or neutral`)  of COVID19-related tweets. We'll also do some exploratory data analysis along the way\n\nThe dataset used can be found [here](https://www.kaggle.com/datatattle/covid-19-nlp-text-classification)"},{"metadata":{},"cell_type":"markdown","source":"## Import Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# data preprocessing\nimport nltk\nfrom nltk import word_tokenize\nfrom nltk.corpus import stopwords\n\n\n# model building\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n\n# metrics\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\nimport re\n\n%matplotlib inline\npd.options.display.max_rows = 300\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Understanding the Data"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# load the datasets\ntrain = pd.read_csv(\"../input/covid-19-nlp-text-classification/Corona_NLP_train.csv\", encoding=\"latin-1\")\ntest = pd.read_csv(\"../input/covid-19-nlp-text-classification/Corona_NLP_test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.info(), '\\n')\nprint(test.info())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    - UserName and ScreenName are randomly generated fields for unique identification purpose only. Their values wouldn't   impact our model, hence, we will be dropping both columns\n    - Location is the only column with missing values\n    - TweetAt, which contains times the tweets were made, has an object datatype - we'll be converting this to a datetime   datatype\n    - Sentiment is the target variable"},{"metadata":{},"cell_type":"markdown","source":"#### Duplicates and Null values"},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop duplicate entries\ntrain.drop_duplicates(inplace= True)\ntest.drop_duplicates(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop UserName and ScreenName columns\ntrain.drop(['UserName', 'ScreenName'], axis=1, inplace=True)\ntest.drop(['UserName', 'ScreenName'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# show columns with missing values\nplt.figure(figsize=(14,4))\nfor index, df in enumerate([train, test]):\n    plt.subplot(1,2, index+1)\n    sns.heatmap(df.isnull(), cmap='viridis', yticklabels= False).set_title('train' if index==0 else 'test')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# check number of missing values\nprint(train.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# check Location\nprint(train.Location.value_counts(normalize= True, dropna= False)[:30] *100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- About 21% of the Location data is missing\n- The Location values include both cities & countries and do not follow a consistent pattern - which makes it quite chaellnging to clean. However, I'll tidy up the column a bit by replacinig cases where we have for instance, `\"London, England\"` with just `\"London\"`; `\"Los Angeles, CA\"` with `\"Los Angeles\"`"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Location = train.Location.str.split(',').str[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis"},{"metadata":{},"cell_type":"markdown","source":"### Sentiment"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"print(train.Sentiment.value_counts(normalize=True) * 100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To make analysis easier, let's rename the \"Extremely Positive\", \"Extremely Negative\" labels to \"Positive\" and \"Negative\" respectively"},{"metadata":{"trusted":true},"cell_type":"code","source":"# replace \"extremely positive/negative\" with \"postive/negative\"\ntrain[\"Sentiment\"] = train[\"Sentiment\"].str.replace(\"Extremely Negative\", \"Negative\")\ntrain[\"Sentiment\"] = train[\"Sentiment\"].str.replace(\"Extremely Positive\", \"Positive\")\n\ntest['Sentiment'] = test.Sentiment.str.replace('Extremely Positive', 'Positive')\ntest['Sentiment'] = test.Sentiment.str.replace('Extremely Negative', 'Negative')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot of tweet sentiment distribution\nplt.figure(figsize=(6,6))\n\nsentiments = train.Sentiment.value_counts()\n\nsns.set_palette(\"coolwarm\")\nplt.pie(sentiments,\n        labels= sentiments.index,\n        autopct='%1.1f%%', startangle=80, \n        pctdistance=0.82, textprops={\"fontsize\": 14})\n\ncentreCircle = plt.Circle((0,0),0.65,fc='white')\nfig = plt.gcf()\nfig.gca().add_artist(centreCircle)\n\nplt.tight_layout()\nplt.title(\"How much of our tweet data is +ve -ve or neutral?\", x=0.53, fontsize= 16)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    - The tweets are mostly either postive or negative, with just about 20% of the tweet data classified as neutral"},{"metadata":{},"cell_type":"markdown","source":"### Location\nLet's check out the places around the world that tweeted the most about COVID. We'll also check out the mood of these tweets."},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot of top cities/countries\nplt.style.use(\"fivethirtyeight\")\n\nplt.figure(figsize=(16, 6))\nlocation = sns.countplot(x= 'Location', data= train, hue=\"Sentiment\", order=train.Location.value_counts()[:10].index)\nlocation.set_title(\"Which places tweeted the most about COVID-19?\", y=1.05)\n\ndef axis_labels(ax):\n    ax.set_ylabel(\"Number of tweets\")\n    ax.set_xlabel(\"\")\n\naxis_labels(location)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    - Most covid-related tweets seem to come from four major countries - the United Kingdom, the USA, Cananda and India.\n    - London and New York lead the way in terms of cities that tweeted the most about covid19\n    - We also observe a pattern: there are more positive tweets than negative in all cities/countries, except England - well this actually follows the general trend in our data, as we have more postive tweets than negative and more negative ones than neutral"},{"metadata":{},"cell_type":"markdown","source":"### Tweet At\nAs `TweetAt` contains dates the tweets in our data were made, let's proceed to find out:\n- the period range our tweet data was gathered\n- the most frequent day(s) of the week and month(s) users made covid-related tweets\n\nFor the latter, we would need to create a new day and month column"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting the TweetAt column to date time \ntrain['TweetAt'] = pd.to_datetime(train['TweetAt'])\n\n# create day of the week and month columns\ntrain['day'] = train['TweetAt'].dt.dayofweek\ntrain['month'] = train['TweetAt'].dt.month\n\ndays = {0: 'Monday', 1: 'Tuesday', 2:'Wednesday', 3: 'Thursday', 4: 'Friday', 5: 'Saturday', 6: 'Sunday'}\nmonths = {0: 'January ', 1: 'February', 2:'March', 3: 'April', 4: 'May', 5: 'June', 6: 'July',\n      7:'August', 8:'September', 9: 'October', 10: 'November', 11: 'December'  }\n\ntrain[\"day\"] = train[\"day\"].map(days)\ntrain[\"month\"] = train[\"month\"].map(months)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"First tweet: {train['TweetAt'].dt.date.min()}, Last tweet: {train['TweetAt'].dt.date.max()}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    Our tweet data, which contains covid-related tweets made only in 2020, was collected over an 11-month period (January 4, 2020 through to December 4, 2020)"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14, 6))\ndays = sns.countplot(x=\"day\", data=train)\ndays.set_title(\"What days were the most covid-related tweets made in 2020?\", \n                                             y=1.05)\n\ndef add_labels(ax, space):\n    for rect in ax.patches:\n        width = rect.get_width()\n        height = rect.get_height()\n        total = train.shape[0]\n        \n        ax.text(rect.get_x() + width/2,\n               height + space,\n               '{}%'.format(int(np.round(height/total*100))),\n                ha=\"center\")\n\nadd_labels(days, 100)\naxis_labels(days)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    - About 35% of the tweets were made on a Tuesday/Wednesday, with Sunday having the least engagement"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14, 6))\nmonths = sns.countplot(train['month'])\nmonths.set_title(\"Which months in 2020 were the most covid-related tweets made?\", \n                                             y=1.05)\n\nadd_labels(months, 300)\naxis_labels(months)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- A whooping 64% of the tweets were made in April! \n- This could perhaps be because it was around this period the number of cases and death toll first skyrocketed.  \n- According to the timeline of COVID-19 events stated in this [article](https://www.thinkglobalhealth.org/article/updated-timeline-coronavirus), the Week of March 30–April 4 saw the Worldwide coronavirus cases exceed one million; with millions of Americans filing for unemployment and major sporting events such Wimbledon Tennis Tournament getting canceled for the first time in a very long time. These were very serious and sudden events that shook the world and hence got people talking and tweeting a lot."},{"metadata":{},"cell_type":"markdown","source":"### Tweets"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# check out the first two tweets\ndef tweets(df, n, col_name=\"OriginalTweet\"):\n    for tweet_no, tweet in enumerate(df[col_name][:n]):\n        print(tweet_no+1, tweet, '\\n')\n        print(\"*\" * 60, '\\n')\n        \ntweets(train, 10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    The tweet data looks really unclean (well .. as expected) - but before proceeding to prepare our tweet text for modelling, let's explore the most frequent hashtags and top mentions in our data"},{"metadata":{},"cell_type":"markdown","source":"#### Most common #hashtags"},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud,STOPWORDS,ImageColorGenerator\nfrom PIL import Image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_wordCloud(pattern):\n    \"\"\"create word cloud visualization\n    \n    arguments:\n        pattern (str): regex pattern to extract certain text from the data\n    \"\"\"\n    data = train[\"OriginalTweet\"].str.extractall(pattern)[0].value_counts()\n\n    data.index = data.index.map(str)                                                       # convert data index to string\n    data_wc = WordCloud(max_words = 500, colormap='Dark2_r', \n                        background_color='white').generate_from_frequencies(data)          # generate word cloud\n\n    # display the cloud\n    fig = plt.figure()\n    fig.set_figwidth(12) # set width\n    fig.set_figheight(12) # set height\n\n    plt.imshow(data_wc, interpolation=\"bilinear\")\n    plt.axis(\"off\")\n    plt.show()\n    \n# create word cloud of the most frequently used hashtags\nhashtag = r\"(#\\w+)\"\ncreate_wordCloud(hashtag)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Most Mentions"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# create word cloud of most frequent mentions\nmentions = r\"(@\\w+)\"\ncreate_wordCloud(mentions)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    - Former US president, Donald Trump is unsurprisingly among the most tagged persons. We also see the UK prime minister,   Boris Johnson and Indian Prime Minister, Narendra Modi also gathered a number of mentions\n    - CNN, BBCNews and SkyNews are the most tagged news channels, with Piers Morgan being the most tagged TV personality \n    - Retail companies such as Tesco, Walmart and Morrisons got a lot of mentions too"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Text Preprocessing\nNext step is to clean and prepare our tweet data for modeling. So,we proceed to:\n- Remove all hastages, links and numbers\n- Remove Stopwords (common words like \"the\", \"a\" etc)\n- Tokenize and Vectorize words, i.e, convert tweet words to numbers\n\nBut first, we combine the training and test dataframes, then keep just the features relevant to our model building - `OriginalTweet` and `Sentiment`"},{"metadata":{"trusted":true},"cell_type":"code","source":"# combine train and test dataframes\ncombined = pd.concat([train, test], ignore_index= True)\n\n# select relevant features: tweet and Sentiments\ncombined = combined.loc[:, [\"OriginalTweet\", \"Sentiment\"]]\n\n# load stop words\nstop_word = stopwords.words('english')\n\ndef clean_tweet(text):\n    text = re.sub(r\"#\\w+\", \" \", text)            # remove hashtags\n    text = re.sub(r\"@\\w+\", \" \",text)             # remove mentions\n    text = re.sub(r\"http\\S+\", \" \", text)         # remove urls\n    text = re.sub(r\"[^a-zA-Z]\", \" \", text)        # remove non-words (digits, punctuations etc)\n    text = text.lower().strip()                  # convert tweet to lowercase and strip\n    \n    text = \" \".join([word for word in text.split() if not word in stop_word])           # remove stop words    \n    \n    text = \" \".join(nltk.word_tokenize(text))           # tokenize text\n      \n    return text\n\n# clean OriginalTweet and assign the data to an new \"tweet\" column\ncombined['tweet'] = combined['OriginalTweet'].apply(lambda x: clean_tweet(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print first few tweets to confirm the data is rid of non-word characters\ntweets(combined, 7, \"tweet\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# most common words in our tweet data\ncorpus = \",\".join(word for word in combined.tweet)\nstopwords = set(STOPWORDS)\ntweet_wc = WordCloud(max_words = 500, colormap='Dark2_r', \n                        background_color='white', stopwords=stopwords).generate(corpus)   \n\n# display the cloud\nfig = plt.figure()\nfig.set_figwidth(10) # set width\nfig.set_figheight(10) # set height\n\nplt.imshow(tweet_wc, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# encode Sentiment label values\nle = LabelEncoder()\ncombined.Sentiment = le.fit_transform(combined.Sentiment)\n\n# split data back into training and validation sets and sets\ntrain = combined[: len(train)]\ntest = combined[len(train):].reset_index(drop=True)\n\n# split test test set\nX_test = test.tweet\ny_test = test.Sentiment\n\n\n# split training set into training and validation set\nX_train, X_val, y_train, y_val = train_test_split(train.tweet,\n                                                    train.Sentiment, test_size=0.2,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# initialize vectorizer\nvectorizer = CountVectorizer(stop_words='english', ngram_range=(1,2), min_df=5).fit(X_train)\n\nX_train = vectorizer.transform(X_train)\nX_val = vectorizer.transform(X_val)\nX_test = vectorizer.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Modeling"},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# intialize model and fit it on the training data\nlogmodel = LogisticRegression(max_iter=10000)\nlogmodel.fit(X_train, y_train)\n\n# check training accuracy\ncross_val_score(logmodel, X_train, y_train, cv=5, verbose=1, n_jobs=-1).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# extract labels from encoder\nlabels = list(le.classes_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make predictions\nval_pred = logmodel.predict(X_val)\ntest_pred = logmodel.predict(X_test)\n\n# print classification report\nprint(classification_report(val_pred, y_val, target_names= labels), '\\n')\nprint(classification_report(test_pred, y_test, target_names= labels))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check test accuracy\nprint('accuracy score on validation set: ', accuracy_score(y_val, val_pred))\nprint('accuracy score on test set:', accuracy_score(y_test, test_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    The model performs about the same on both the validation set and the given test dataset\n    \nNext, we check out how the LSTM model will perform on our data"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### LSTM"},{"metadata":{"trusted":true},"cell_type":"code","source":"max_features = 20000                                            # maximum number of words to take from corpus\ntokenizer = Tokenizer(num_words=max_features, split=' ')            # initialize tokenizer\ntokenizer.fit_on_texts(train['tweet'].values)                   # fit tokenizer on training data\n\n\nmax_len = np.max(train.tweet.apply(lambda x :len(x)))\nvocab_length = len(tokenizer.word_index)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"print(\"Number of unique token:\", vocab_length)\nprint(\"Maximum sequence length:\", max_len)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get text sequences from training and test dataframes\ntrain_x = tokenizer.texts_to_sequences(train['tweet'].values)\nX_test = tokenizer.texts_to_sequences(test['tweet'].values)\n\n\n# adding padding of zeros to obtain uniform length for all sequences\ntrain_x = pad_sequences(train_x, maxlen= max_len)\nX_test = pad_sequences(X_test, maxlen= max_len)\n\n# encode sentiment label values\ntrain_y_encoded = pd.get_dummies(train['Sentiment']).values\ny_test_encoded = pd.get_dummies(test['Sentiment']).values\n\n\n# split training data \nX_train, X_val, Y_train, y_val = train_test_split(train_x, train_y_encoded, test_size = 0.33, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print(train_x.shape, X_test.shape)\nprint(train_y_encoded.shape, y_test_encoded.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape,Y_train.shape)\nprint(X_val.shape, y_val.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Model Building"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"embed_dim = 16\nlstm_out = 196\n\nmodel = Sequential()\nmodel.add(Embedding(vocab_length, embed_dim, input_length = max_len))\nmodel.add(SpatialDropout1D(0.4))\nmodel.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\nmodel.add(Dense(3,activation='softmax'))\n\nmodel.compile(loss = 'categorical_crossentropy', \n              optimizer='adam',\n              metrics = ['accuracy'])\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Model Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train, Y_train, \n          validation_data=(X_val, y_val), \n          epochs=5, batch_size= 32, \n          shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Model Evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluating model on test dataset\nmodel.evaluate(X_test, y_test_encoded, verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(X_test)\npredictions = np.argmax(predictions, axis=1)\n\n# predictions = model.predict_classes(X_test)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# classification report\nprint(classification_report(y_test, predictions, target_names= labels))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    - As seen, the LTSM algorithm yields a better performance on our data (84% accuracy) than the Logistic Regression (79% accuracy)\n    - While 79-84% is a fairly good score for accuracy, the performance of each model can still be further improved by tuning necessary parameters"},{"metadata":{},"cell_type":"markdown","source":"##### Author: Ayomide Aderonmu"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}