{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dd5a4b6b-d938-2307-2ffa-25a1b1bd6232"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"977c5ad4-0a29-f24e-b655-35918c211329"},"outputs":[],"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# we'll want this for plotting\nimport matplotlib.pyplot as plt\n\n# we'll want this for text manipulation\nimport re\n\n# for quick and dirty counting\nfrom collections import defaultdict\n\n# the Naive Bayes model\nfrom sklearn.naive_bayes import MultinomialNB\n# function to split the data for cross-validation\nfrom sklearn.model_selection import train_test_split\n# function for transforming documents into counts\nfrom sklearn.feature_extraction.text import CountVectorizer\n# function for encoding categories\nfrom sklearn.preprocessing import LabelEncoder\n\n# have to use latin1 even though it results in a lot of dead characters\ntwigen = pd.read_csv(\"../input/gender-classifier-DFE-791531.csv\", encoding='latin1')\ntwigen.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e467584e-154a-73f3-f8b0-6d4b56d1f50b"},"outputs":[],"source":"def normalize_text(s):\n    # just in case\n    s = str(s)\n    s = s.lower()\n    \n    # remove punctuation that is not word-internal (e.g., hyphens, apostrophes)\n    s = re.sub('\\s\\W',' ',s)\n    s = re.sub('\\W\\s',' ',s)\n    \n    # make sure we didn't introduce any double spaces\n    s = re.sub('\\s+',' ',s)\n    \n    return s\n\ntwigen['text_norm'] = [normalize_text(s) for s in twigen['text']]\ntwigen['description_norm'] = [normalize_text(s) for s in twigen['description']]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"32424d04-5f39-0d81-2065-f06f666fc28b"},"outputs":[],"source":"# how many observations are gold standard?\ngold_values = defaultdict(int)\nfor val in twigen._golden:\n    gold_values[val] += 1\nprint(gold_values)\n\n# what does the confidence look like?\nprint(np.any(np.isnan(twigen['gender:confidence'])))\n# we've got at least one NaN, so let's remove\ngender_confidence = twigen['gender:confidence'][np.where(np.invert(np.isnan(twigen['gender:confidence'])))[0]]\nprint(len(gender_confidence))\ngender_nonones = gender_confidence[np.where(gender_confidence < 1)[0]]\nprint(len(gender_nonones))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bfc86615-1d9a-0cee-5a1d-55e3d77ab86c"},"outputs":[],"source":"twigen_confident = twigen[twigen['gender:confidence']==1]\ntwigen_confident.shape"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"45872bac-cfa2-2865-74bb-2e85391deea4"},"outputs":[],"source":"# pull the data into vectors\nvectorizer = CountVectorizer()\nx = vectorizer.fit_transform(twigen_confident['text_norm'])\n\nencoder = LabelEncoder()\ny = encoder.fit_transform(twigen_confident['gender'])\n\n# split into train and test sets\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n\n# take a look at the shape of each of these\nprint(x_train.shape)\nprint(y_train.shape)\nprint(x_test.shape)\nprint(y_test.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4f645851-826b-c87a-b11e-30c2eb285dd9"},"outputs":[],"source":"nb = MultinomialNB()\nnb.fit(x_train, y_train)\n\nprint(nb.score(x_test, y_test))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"49a334f1-1f53-3411-ecbe-9742a84f63dc"},"outputs":[],"source":"twigen['all_features'] = twigen['text_norm'].str.cat(twigen['description_norm'], sep=' ')\n\ntwigen_confident = twigen[twigen['gender:confidence']==1]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b5290dbf-da1f-82b5-2f58-acf854d9ac69"},"outputs":[],"source":"# pull the data into vectors\nvectorizer = CountVectorizer()\nx = vectorizer.fit_transform(twigen_confident['text_norm'])\n\nencoder = LabelEncoder()\ny = encoder.fit_transform(twigen_confident['gender'])\n\n# split into train and test sets\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n\nnb = MultinomialNB()\nnb.fit(x_train, y_train)\n\nprint(nb.score(x_test, y_test))"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}