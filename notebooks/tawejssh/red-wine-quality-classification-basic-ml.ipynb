{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier \nfrom sklearn.model_selection import train_test_split, StratifiedShuffleSplit, cross_val_score, GridSearchCV\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import classification_report, roc_curve, roc_auc_score, auc, precision_score, recall_score, f1_score, confusion_matrix\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.preprocessing import label_binarize, LabelEncoder\nfrom scipy import stats\nfrom itertools import cycle","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reading data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/red-wine-quality-cortez-et-al-2009/winequality-red.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA: Exploratory Data Analysis"},{"metadata":{},"cell_type":"markdown","source":"Note: We'll consider all possible qualities. In a further step we can transform it into a binary classification problem"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Data length: {len(data)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check missing data\ndata.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#correlation matrix\nplt.figure(figsize=(10,5))\nheatmap = sns.heatmap(data.corr(), annot=True, fmt=\".1f\")\nheatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\nheatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plot pairwise relationships in data for few features  (plot size constraint)\ncols_sns = ['residual sugar', 'chlorides', 'density', 'pH', 'alcohol', 'quality']\nsns.set(style=\"ticks\")\nsns.pairplot(data[cols_sns], hue='quality')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='quality', data=data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Features distribution over quality's possible values\nfig, ax = plt.subplots(4, 3, figsize=(15, 15))\nfor var, subplot in zip(data.columns, ax.flatten()):\n    if var == \"quality\":\n        continue\n    else:\n        sns.boxplot(x=data['quality'], y=data[var], data=data, ax=subplot)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preparing Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"features, labels = data.loc[:,data.columns !='quality'], data['quality']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(labels, kde=True, hist=False)\nplt.title('KDE: Kernel Density Estimation')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that data is skewed and some qualities are more probable (5 and 6) to occur than the others."},{"metadata":{"trusted":true},"cell_type":"code","source":"#scaling data\nscaler = MinMaxScaler()\nX = scaler.fit_transform(features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#classic split the data into train and test sets for unbalanced data isn't a good idea\nxtr, xts, ytr, yts = train_test_split(X, labels, test_size=0.3, random_state=42, shuffle = True)\n#We'll opt for stratified shuffled split for better class proportions\nsss = StratifiedShuffleSplit(test_size=0.3)\nfor train_index, test_index in sss.split(X, labels):\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = labels[train_index], labels[test_index]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking if train and test lables have the same set of possible values\ny_train.unique(), y_test.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg = LogisticRegression(multi_class='ovr', class_weight='balanced', random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = logreg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes_q = sorted(data.quality.unique())\nclasses_q","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#For ROC curves we have to binarize lables\ny_test_bin = label_binarize(y_test, classes=classes_q)\ny_pred_bin = label_binarize(y_pred, classes=classes_q)\n#Compute ROC curve and ROC area for each class\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(len(classes_q)):\n    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_bin[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Compute micro-average ROC curve and ROC area\nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_bin.ravel(), y_pred_bin.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ROC for a specific class\nlw = 2\nplt.plot(fpr[2], tpr[2], color='darkorange',\n         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])\nplt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic example')\nplt.legend(loc=\"lower right\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ROC for multiclass #sklearn doc\n# First aggregate all false positive rates\nall_fpr = np.unique(np.concatenate([fpr[i] for i in range(len(classes_q))]))\n\n# Then interpolate all ROC curves at this points\nmean_tpr = np.zeros_like(all_fpr)\nfor i in range(len(classes_q)):\n    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n\n# Finally average it and compute AUC\nmean_tpr /= len(classes_q)\n\nfpr[\"macro\"] = all_fpr\ntpr[\"macro\"] = mean_tpr\nroc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\n# Plot all ROC curves\nplt.figure(figsize=(10,5))\n# plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n#          label='micro-average ROC curve (area = {0:0.2f})'\n#                ''.format(roc_auc[\"micro\"]),\n#          color='deeppink', linestyle=':', linewidth=4)\n\n# plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n#          label='macro-average ROC curve (area = {0:0.2f})'\n#                ''.format(roc_auc[\"macro\"]),\n#          color='navy', linestyle=':', linewidth=4)\n\ncolors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red', 'magenta'])\nfor i, color in zip(range(len(classes_q)), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n             label='ROC curve of quality {0} (area = {1:0.2f})'\n             ''.format(classes_q[i], roc_auc[i]))\n\nplt.plot([0, 1], [0, 1], 'k--', lw=lw)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Some extension of Receiver operating characteristic to multi-class')\nplt.legend(loc=\"lower right\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Bigger area in the top left corner means Better results. Considering the task as a binary classification one may give better results"},{"metadata":{},"cell_type":"markdown","source":"# Binary Classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Initial dataset\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Transform labels into binary ones: 'bad' and 'good'\nbins = (2, 6.5, 8)\nquality_names = ['bad', 'good']\ndata['quality'] = pd.cut(data.quality, bins=bins, labels=quality_names)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### EDA: Binary Classification Task"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data=data, x='quality')\nplt.title('Quality Count Plot')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plot pairwise relationships in data for few features  (plot size constraint)\ncols_sns = ['residual sugar', 'chlorides', 'density', 'pH', 'alcohol', 'quality']\nsns.set(style=\"ticks\")\nsns.pairplot(data[cols_sns], hue='quality')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Features distribution over quality's possible values\nfig, ax = plt.subplots(4, 3, figsize=(15, 15))\nfor var, subplot in zip(data.columns, ax.flatten()):\n    if var == \"quality\":\n        continue\n    else:\n        sns.boxplot(x=data['quality'], y=data[var], data=data, ax=subplot)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Encoding labels\nlabel_encoder = LabelEncoder()\ndata['quality'] = label_encoder.fit_transform(data['quality'])\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Prepare data\nX, y = data.loc[:, data.columns != 'quality'], data['quality']\nnew_scaler = MinMaxScaler()\nX = scaler.fit_transform(X)\n#We'll opt for stratified shuffled split again for better class proportions\nnew_sss = StratifiedShuffleSplit(test_size=0.3)\nfor train_index, test_index in new_sss.split(X, labels):\n    new_X_train, new_X_test = X[train_index], X[test_index]\n    new_y_train, new_y_test = y[train_index], y[test_index]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this part we'll try multiple algorithms."},{"metadata":{},"cell_type":"markdown","source":"## Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"log_reg = LogisticRegression(random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_reg.fit(new_X_train, new_y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg_y_pred = log_reg.predict(new_X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Precision Score: {precision_score(new_y_test, logreg_y_pred)}')\nprint(f'Recall Score: {recall_score(new_y_test, logreg_y_pred)}')\nprint(f'F1-Score: {f1_score(new_y_test, logreg_y_pred)}') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cross Validation for Logistic Regression\nlg = LogisticRegression()\ncv_lg_result = cross_val_score(lg, X, y, cv=5, scoring='f1_macro')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Mean F1-Score of Cross Validation {np.mean(cv_lg_result)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Grid Search \ngrid ={\"C\": [0.001,0.01,0.1,1,10,100]}\nlg_ = LogisticRegression()\nlg_cv = GridSearchCV(lg_, grid, cv=3)\nlg_cv.fit(new_X_train, new_y_train)\n\n#hyperparameters\nprint(f\"Tuned hyperparameters: {lg_cv.best_params_}\")\nprint(f\"Best score: {lg_cv.best_score_}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_logreg = lg_cv.best_estimator_\nbest_logreg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_gs_pred = best_logreg.predict(new_X_test)\nprint(\"With Grid Search...\")\nprint(f'Precision Score: {precision_score(new_y_test, y_gs_pred)}')\nprint(f'Recall Score: {recall_score(new_y_test, y_gs_pred)}')\nprint(f'F1-Score: {f1_score(new_y_test, y_gs_pred)}') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ROC\nfpr, tpr, thresholds = roc_curve(new_y_test, y_gs_pred)\nplt.plot([0,1], [0,1], '--k')\nplt.plot(fpr, tpr)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Confusion Matrix\ncm = confusion_matrix(new_y_test, y_gs_pred)\nsns.heatmap(cm, annot=True, fmt='d')\nplt.title('Confusion Matrix')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf.fit(new_X_train, new_y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_rf_pred = rf.predict(new_X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Random Forest Performance...')\nprint(f'Precision Score: {precision_score(new_y_test, y_rf_pred)}')\nprint(f'Recall Score: {recall_score(new_y_test, y_rf_pred)}')\nprint(f'F1-Score: {f1_score(new_y_test, y_rf_pred)}') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ROC\nfpr_rf, tpr_rf, thresholds_rf = roc_curve(new_y_test, y_rf_pred)\nplt.plot([0,1], [0,1], '--k')\nplt.plot(fpr_rf, tpr_rf)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can easily notice that the results improved comparing to Logistic Regression"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"rf_param_grid = {\"n_estimators\": np.arange(2,50),\n                \"max_depth\": np.arange(2,50),\n                \"min_samples_split\": np.arange(2,50),\n                \"min_samples_leaf\":np.arange(2,50),\n                \"max_leaf_nodes\": np.arange(2,50)}\n\ni=1\nfor param, range_param in rf_param_grid.items():\n        rf_grid = GridSearchCV(estimator=RandomForestClassifier(random_state=42),\n                              param_grid={param:range_param},\n                              scoring='f1_macro')\n        rf_grid.fit(new_X_train, new_y_train)\n        df = pd.DataFrame(rf_grid.cv_results_)\n        plt.figure(figsize=(20,5))\n        plt.subplot(2,3,i)\n        plt.plot(range_param, df.mean_test_score.values)\n        plt.title(param)\n        i += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Based on the plots above we can test the following model\nrf_test = RandomForestClassifier(n_estimators=28,\n                                max_depth=14,\n                                random_state=42)\nrf_test.fit(new_X_train, new_y_train)\nyy = rf_test.predict(new_X_test)\nf1_score(new_y_test, yy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":4}