{"cells":[{"metadata":{},"cell_type":"markdown","source":"## What users are talking about at Hacker News? "},{"metadata":{},"cell_type":"markdown","source":"The objective of this projects is to look into Hacker News posts titles to identify the most common topics that users are posting, liking and talking about. \n\nThere are four questions answered in this notebook:  \n- What are the most common topics on Hacker News about?\n- What are the most popular posts on Hacker News about?\n- What are the most commented posts on Hacker News about?\n- Is there difference in average amount of comments and points for posts created at different time of a day and day of a week? And is this difference the same for all types of posts? \n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import libraries used in the project:\nimport csv\nimport datetime as dt\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport string\n\nfrom sklearn.feature_extraction.text import CountVectorizer\n","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Open and explore dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# open the hacker_news.csv file\nf = open('../input/HN_posts_year_to_Sep_26_2016.csv')\n\n#parse the data from the file\nreader = csv.reader(f)\n\n# convert data into a list of lists format\nhn = list(reader)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check length of dataset:\nlen(hn)","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"293120"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# extract header from data and assign it to variable headers:\nheaders = hn[0]\nprint(\"Headers:\", headers)","execution_count":7,"outputs":[{"output_type":"stream","text":"Headers: ['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove headers from hn:\nhn = hn[1:]\n\n#print first and last 5 rows of dataset:\nprint(\"HN first row\", hn[1:5])","execution_count":8,"outputs":[{"output_type":"stream","text":"HN first row [['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24'], ['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19'], ['12578989', 'algorithmic music', 'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext', '1', '0', 'poindontcare', '9/26/2016 3:16'], ['12578979', 'How the Data Vault Enables the Next-Gen Data Warehouse and Data Lake', 'https://www.talend.com/blog/2016/05/12/talend-and-Â\\x93the-data-vaultÂ\\x94', '1', '0', 'markgainor1', '9/26/2016 3:14']]\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"According to documentation: this data set is Hacker News posts from the last 12 months (up to September 26 2016).  \nLets check the exact amount of days, weeks and hours in dataset:"},{"metadata":{"trusted":true},"cell_type":"code","source":"#create empty list of dates\ndates =[]\n\n# itterate over dataset and convert each create_at into 'datetime.datetime' class.\nfor row in hn:\n    d = dt.datetime.strptime(row[6],\"%m/%d/%Y %H:%M\" )\n    #append each create_at to dates list:\n    dates.append(d)\n\n# sort dates using sorted():\nsorted_dates = sorted(dates)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# find how many days are in dataset:\ndays = (sorted_dates[-1].date()- sorted_dates[0].date()).days\nprint(\"Days:\", days)\n# find how many weeks are in dataset:\nweeks = days/7\nprint(\"Weeks:\", weeks)\n","execution_count":10,"outputs":[{"output_type":"stream","text":"Days: 386\nWeeks: 55.142857142857146\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"the dataset contains 386 days of data, that is more than 55 fuul weeks. To have unbiased data while looking into data by week and hour, lets cut out one day from dataset, so that only 385 and full 55 weeks of data remains in dataset:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# calculate dateand time that is exactly 385 days away from last date in dataset, and name it as last_datetime:\nlast_datetime = sorted_dates[-1] -  dt.timedelta(days=385)\nprint(last_datetime)","execution_count":11,"outputs":[{"output_type":"stream","text":"2015-09-07 03:26:00\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create new dataset hn_new that only contains posts older than last_datetime:\nhn_new = []\n\nfor row in hn:\n    d = dt.datetime.strptime(row[6],\"%m/%d/%Y %H:%M\" )\n    if d >= last_datetime:\n        hn_new.append(row)      ","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check current oldest date of initial dataset:\nprint(\"Initial dataset\")\nprint(\"first row of dataset:\", hn[0] )\nprint(\"last row of dataset:\", hn[-1] )\nprint(\"-------------------------------\")\nprint(\"Current dataset\")\n# check if last date of new dataset: \nprint(\"first row of dataset:\", hn_new[0] )\nprint(\"last row of dataset:\", hn_new[-1])","execution_count":13,"outputs":[{"output_type":"stream","text":"Initial dataset\nfirst row of dataset: ['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26']\nlast row of dataset: ['10176903', 'Toyota Establishes Research Centers with MIT and Stanford for AI Research', 'http://newsroom.toyota.co.jp/en/detail/9233109/', '4', '0', 'tim_sw', '9/6/2015 5:50']\n-------------------------------\nCurrent dataset\nfirst row of dataset: ['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26']\nlast row of dataset: ['10179951', 'Fast Memory Copy (1996)', 'http://now.cs.berkeley.edu/Td/bcopy.html', '6', '1', 'userbinator', '9/7/2015 3:32']\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"As can be seen above current dataset contains exactly 385 full days."},{"metadata":{},"cell_type":"markdown","source":"## What are the most common topics on Hacker News about?"},{"metadata":{},"cell_type":"markdown","source":"To identify the most common topics in Hacker News posts lets look at words that are used in titles and create a dictionary that will have 'words' as keys and counts as items:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# clean titles and split them in separate words:\n#-------------------------------------------------------\n# create empty list of words:\nwords= []\n\n# for each row in dataset:\nfor row in hn_new:\n    #assign the title in each post to variable called title:\n    title = row[1]\n    #remove punctuations and split title into separate words:\n    for c in string.punctuation:\n        title = title.replace(c,\" \")\n        splited_title = title.split(\" \")\n        \n    #convert all words into lower case and append to list words:    \n    for word in splited_title:\n        word = word.lower()\n        words.append(word)       \n            ","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create dictionary that will show how many times each word is mentioned in posts:\n#-----------------------------------------------------------------------------------\n#create empty dictionary:\ncount_dictionary = {}\n\n# for each word in words list:\nfor word in words:\n    # check if word already in dictionary, and if yes, append 1 to count:\n    if word in count_dictionary.keys():\n        #add points to the word in count_dictionary:\n        count_dictionary[word] +=1\n    # if not, add this word in discionary with count =1:    \n    else:\n        count_dictionary[word] = 1\n   ","execution_count":15,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### top 50 words in count_dictionary:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# sort dictionary by counts and display top 50 words in count_dictionary:\nsorted(count_dictionary.items(), reverse = True, key = lambda x: x[1] )[:50]\n","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"[('', 224779),\n ('the', 74174),\n ('to', 55112),\n ('a', 48429),\n ('of', 42492),\n ('and', 37499),\n ('in', 37011),\n ('for', 36199),\n ('is', 21140),\n ('hn', 20251),\n ('on', 19906),\n ('with', 19192),\n ('s', 18793),\n ('how', 18052),\n ('your', 12989),\n ('you', 11565),\n ('show', 10750),\n ('new', 10118),\n ('from', 9886),\n ('ask', 9575),\n ('what', 9055),\n ('why', 8868),\n ('an', 8311),\n ('are', 7554),\n ('it', 7091),\n ('data', 6874),\n ('by', 6709),\n ('i', 6550),\n ('at', 6496),\n ('that', 6196),\n ('google', 6174),\n ('be', 5336),\n ('app', 5306),\n ('can', 5214),\n ('as', 5178),\n ('about', 4927),\n ('open', 4665),\n ('do', 4616),\n ('using', 4612),\n ('1', 4444),\n ('we', 4424),\n ('not', 4381),\n ('web', 4350),\n ('2', 4183),\n ('apple', 4176),\n ('its', 4142),\n ('will', 4128),\n ('first', 3962),\n ('startup', 3895),\n ('code', 3814)]"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"It can be concluded that most common significant words in count_dictionary are: hn - abbreviation for Haker News, show, new, ask, data, google, app, us (probably most mean - US rather than us (can be investigated further, but not a topic for this project), web, startup. \n\n#### Posts' topics chosen for further research:\n1. Ask HN and Show HN posts:\nIt is not surprising that HN, Ask and Show words appear as most common.   \nAsk HN and Show HN posts are standard posts for Haker News in which users ask the Hacker News community a specific question or share some projects, product or in general some information. \n2. Post about Data.    \nIt is also interesting to investigate how many posts are about data science.\n3. Posts about Google \n"},{"metadata":{},"cell_type":"markdown","source":"### Total amount of posts in Hacker News dataset for most frequent topics"},{"metadata":{"trusted":true},"cell_type":"code","source":"# separate posts with Ask HN and Show HN types from other posts:\n#-----------------------------------------------------------------\n# create empty lists to store ask, show and other posts:\nask_posts = []\nshow_posts = []\nother_posts = []\n\n# for each row in dataset:\nfor row in hn_new:\n    #assign the title in each post to variable called title:\n    title = row[1]\n    \n    #if title has 'Ask HN' phrase in it, add it to ask_posts list:\n    if 'Ask HN' in title:\n        ask_posts.append(row)\n    #if title has 'Show HN' phrase in it, add it to show_posts list:    \n    elif 'Show HN' in title:\n        show_posts.append(row)   \n    #else add post to other_posts list:    \n    else:\n        other_posts.append(row)\n    ","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of Ask HN posts:\", len(ask_posts))\nprint(\"Number of Show HN posts:\",len(show_posts))\nprint(\"Number of other posts:\",len(other_posts))  ","execution_count":18,"outputs":[{"output_type":"stream","text":"Number of Ask HN posts: 9111\nNumber of Show HN posts: 10148\nNumber of other posts: 273465\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"#### Conclusions about amount of Ask HN and Show HN posts on Hacker News:\n1. Number of Ask HN and Show HN posts is 9111 and 10148. In dictionary above \"ask\" word had 9575 recordings and \"show\" word - 10750. It is not surprising as \"ask\" and \"show\" words are common in English language and can be used also for other purposes rather than Ask HN and Show HN posts.\n2. About 3,1% of dataset is Ask HN posts (9111 out of 292724)\n3. About 3,5% of dataset is Show HN posts (10148 out of 292724)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#check how often users are talking about topics related to data, science and data science:\n#-------------------------------------------------------------------------------------------\n\n#create empty lists to store posts about data, science and data_science :\ndata_posts=[]\ndata_science_posts=[]\ndata_science_list = ['data', 'scien']\nscience_posts = []\ngoogle_posts = []\nstartup_posts = []\n\n#for each row in dataset:\nfor row in hn_new:\n    #assign the title in each post to variable called title:\n    title = row[1]\n    #clean title to easier distinguish identify words:\n    for c in string.punctuation:\n        words= []\n        title = title.replace(c,\" \")\n        splited_title = title.split(\" \")  \n        for word in splited_title:\n            word = word.lower()\n            words.append(word)\n            \n    # join clean words from title back together:         \n    words = ' '.join(words)        \n    \n    #if there are both 'data' and 'scien' in the title, append it to data_scince posts list:\n    if all(word in words for word in data_science_list):\n        data_science_posts.append(row)      \n    #if there is word 'data' in title, append it to data_posts list:    \n    if 'data' in words:\n        data_posts.append(row)\n    #if there is root 'scien' in title, append it to science_posts list:       \n    if 'scien' in words:\n        science_posts.append(row)\n    #if there is word 'google' in title, append it to google_posts lists:\n    if 'google' in words:\n        google_posts.append(row)\n","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Total amount of posts:\", len(hn_new))\nprint(\"Number of posts about data:\",len(data_posts))\nprint(\"Number of posts about data science:\",len(data_science_posts))\nprint(\"Number of posts about science:\",len(science_posts))\n","execution_count":20,"outputs":[{"output_type":"stream","text":"Total amount of posts: 292724\nNumber of posts about data: 8374\nNumber of posts about data science: 795\nNumber of posts about science: 3749\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"#### Conclusions about amount of Data posts on Hacker News:\n\n1. From 3749 posts about science, 795 posts are about data science (around 21 % of all posts about science)   \n2. From 292724 total posts on Hacker News 8374 are talking about data (around 2.9%). Also data is mentined in created dictionary among top 50 words (26th place) suggesting that it is very hot topic.\n3. According to dictionary calculation 'data' word was mentioned 6874 times in post titles, and 8374 posts have 'data' as root-word in them. "},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of posts about Google:\",len(google_posts))\n","execution_count":21,"outputs":[{"output_type":"stream","text":"Number of posts about Google: 6435\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"#### Conclusions about amount of Google posts on Hacker News:\nAbout 2,2% of dataset is Ask HN posts (6435 out of 292724)\n"},{"metadata":{},"cell_type":"markdown","source":"## What are the most popular posts on Hacker News about?"},{"metadata":{},"cell_type":"markdown","source":"To identify the most popular topics in Hacker News posts lets look at words that are used in titles and create a dictionary that will have 'words' as keys and points for each word as items:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# create dictionary that contains points received for this specific title:\n# --------------------------------------------------------------------------------------------------------\n# create empty dictionary:\npoints_dictionary ={}\n\n\n#for each row in dataset:\nfor row in hn_new:\n    #assign the title in each post to variable called title:\n    words = []\n    title = row[1]\n    for c in string.punctuation:\n        title = title.replace(c,\" \")\n        splited_title = title.split(\" \")\n        \n        #convert all words into lower case and append to list words:    \n    for word in splited_title:\n        word = word.lower()\n        words.append(word)  \n        \n    for word in words:\n            # check if word already in dictionary, and if yes, append 1 to count:\n        if word in points_dictionary.keys():\n            #add points to the word in count_dictionary:\n            points_dictionary[word] += int(row[3])\n        # if not, add this word in discionary with count =1:    \n        else:\n            points_dictionary[word] = int(row[3])","execution_count":22,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### top 50 words in points_dictionary:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# sort dictionary by counts and display top 50 words in point_dictionary:\nsorted(points_dictionary.items(), reverse = True, key = lambda x: x[1] )[:50]\n","execution_count":23,"outputs":[{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"[('', 3170352),\n ('the', 1042202),\n ('to', 769838),\n ('a', 768582),\n ('of', 618925),\n ('in', 537354),\n ('and', 482839),\n ('for', 479503),\n ('is', 352225),\n ('on', 284879),\n ('s', 274443),\n ('hn', 273839),\n ('how', 242274),\n ('with', 226955),\n ('show', 158249),\n ('from', 144286),\n ('why', 142820),\n ('i', 139136),\n ('new', 131743),\n ('an', 128824),\n ('your', 128478),\n ('you', 127452),\n ('what', 116110),\n ('google', 115060),\n ('are', 108446),\n ('ask', 107555),\n ('by', 104989),\n ('open', 102570),\n ('at', 95787),\n ('that', 94330),\n ('it', 93871),\n ('1', 83546),\n ('as', 80416),\n ('be', 78577),\n ('0', 77043),\n ('data', 75342),\n ('we', 75048),\n ('my', 74998),\n ('not', 74078),\n ('source', 74024),\n ('has', 70692),\n ('code', 68954),\n ('web', 66635),\n ('apple', 66053),\n ('2', 65821),\n ('about', 65363),\n ('its', 64146),\n ('do', 64005),\n ('now', 63345),\n ('can', 62478)]"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"\nSignificant words are in top 50 points_list are :  \n- hn, show, new, google, ask, open, data, code, web, apple.  \n\nThis list looks very similar to count_dictionary top 50 list that is not surprising, as the more posts related to ptopic is posted, the more total points this topic will get. \n\n\nBut the question is: Did this topics recieve so many points because of quantity of posts or due to popularity among users? In order to understand the answer, average amount of points per post is calculated:"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Find the total number of points in ask and show posts:\n#--------------------------------------------------------\n#initialize variables:\ntotal_ask_points = 0\ntotal_show_points = 0\ntotal_data_points = 0\nall_points=0\ntotal_google_points = 0\ntotal_startup_points = 0\n\n## add comments for each ask_post together\nfor row in ask_posts:\n    total_ask_points += int(row[3])\n    \n## add comments for each show_post together:\nfor row in show_posts:\n    total_show_points += int(row[3])\n    \n## add comments for each data_science_post together:\nfor row in data_posts:\n    total_data_points += int(row[3])  \n    \n## add all comments for all posts together:\nfor row in hn_new:\n    all_points += int(row[3])\n    \n## add all comments for google posts together:    \nfor row in google_posts:\n    total_google_points += int(row[3])    \n    \n    \n#calculate and print average amount of posts for posts:\n#----------------------------------------------------------\navg_ask_points = total_ask_points/len(ask_posts)\navg_show_points = total_show_points/len(show_posts)\navg_data_points = total_data_points/len(data_posts)\navg_all_points = all_points/len(hn_new)\navg_google_points = total_google_points/len(google_posts)\n\nprint('%s: %.2f'% (\"Average amount of points for all posts\",avg_all_points))\nprint('%s: %.2f'% (\"Average amount of points for Ask HN posts\",avg_ask_points))\nprint('%s: %.2f'% (\"Average amount of points for Show HN posts\",avg_show_points))\nprint('%s: %.2f'% (\"Average amount of points for posts about data\",avg_data_points))\nprint('%s: %.2f'% (\"Average amount of points for google posts\",avg_google_points))","execution_count":24,"outputs":[{"output_type":"stream","text":"Average amount of points for all posts: 15.02\nAverage amount of points for Ask HN posts: 11.34\nAverage amount of points for Show HN posts: 14.86\nAverage amount of points for posts about data: 12.70\nAverage amount of points for google posts: 18.09\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"#### Conclusion about popularity of most common topics on Hacker News: \n\nEven though most common topics on Hacker News are Ask HN, Show HN, Data and Google, only posts about Google recieved on average more points that all posts in general on Hacker News.  \n"},{"metadata":{},"cell_type":"markdown","source":"To understand what about are the most popular topics, lets create separate dictionary by average points.\nThere is no need to look into words that are only mentioned rarely in the dictionary, as sample will not be representative. Let's check only words that are mentioned in post titles more than 100 times:"},{"metadata":{"trusted":true},"cell_type":"code","source":"top_point_dictionary = {}\n\nfor key in points_dictionary.keys():\n    if count_dictionary[key] > 100:\n        top_point_dictionary[key] = points_dictionary[key]/count_dictionary[key]\n        ","execution_count":25,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### top 50 words in top_point_dictionary:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# sort dictionary by counts and display top 50 words in point_dictionary:\nsorted(top_point_dictionary.items(), reverse = True, key = lambda x: x[1] )[:50]","execution_count":26,"outputs":[{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"[('died', 89.6078431372549),\n ('lee', 59.504347826086956),\n ('gitlab', 51.62420382165605),\n ('alphago', 50.326530612244895),\n ('sourced', 48.578947368421055),\n ('rust', 47.85984251968504),\n ('arrested', 45.41379310344828),\n ('dear', 43.5668449197861),\n ('backdoor', 43.06741573033708),\n ('tcp', 42.64748201438849),\n ('lisp', 42.55230125523013),\n ('tpp', 41.87591240875913),\n ('beats', 41.31901840490798),\n ('doom', 41.27619047619048),\n ('atlas', 41.075471698113205),\n ('acquire', 40.8130081300813),\n ('judge', 40.75590551181102),\n ('browsing', 40.6),\n ('snowden', 39.85950413223141),\n ('pixel', 38.77952755905512),\n ('openbsd', 38.33548387096774),\n ('tensorflow', 38.098684210526315),\n ('plain', 37.63194444444444),\n ('gnu', 37.57377049180328),\n ('mozilla', 37.025270758122744),\n ('operating', 36.00420168067227),\n ('message', 35.895306859205775),\n ('firefox', 35.69284064665127),\n ('announcing', 35.05694760820045),\n ('shut', 35.03862660944206),\n ('bans', 34.604838709677416),\n ('x86', 34.5722891566265),\n ('overflow', 34.333333333333336),\n ('leaving', 34.32748538011696),\n ('department', 34.177304964539005),\n ('passes', 34.049586776859506),\n ('freebsd', 34.02173913043478),\n ('shuts', 33.96551724137931),\n ('im', 33.82089552238806),\n ('stripe', 33.66463414634146),\n ('llvm', 33.354838709677416),\n ('encrypt', 33.0625),\n ('satoshi', 32.85585585585586),\n ('detect', 32.616279069767444),\n ('eff', 32.17088607594937),\n ('spent', 32.09708737864078),\n ('asking', 32.04032258064516),\n ('dropbox', 32.03496503496503),\n ('ocaml', 31.75187969924812),\n ('spacex', 31.711484593837536)]"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"#### Conclusion about popularity of topics on Hacker News:\n\nFrom top_point_dictionary can be concluded that most popular topics (topics that have significant amount of posts to judge and have highest amount of points on average) are:\n\n- Died, Lee, GitLab, AlphaGo, Sorced, Rust, Arrested, etc. \n\nIt is interesting to mention that none of top counts is in this list. "},{"metadata":{},"cell_type":"markdown","source":"## What are the most commented posts on Hacker News about?"},{"metadata":{},"cell_type":"markdown","source":"Average amount of comments for Count top posts: 'Ask HN', 'Show HN', 'Data' and \"Google':"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Find the total number of comments in ask and show posts:\n#--------------------------------------------------------\n#initialize variables:\ntotal_ask_comments = 0\ntotal_show_comments = 0\ntotal_data_comments = 0\ntotal_google_comments = 0\nall_comments=0\n\n## add comments for each ask_post together\nfor row in ask_posts:\n    total_ask_comments += int(row[4])\n    \n## add comments for each show_post together:\nfor row in show_posts:\n    total_show_comments += int(row[4])\n    \n## add comments for each data_science_post together:\nfor row in data_posts:\n    total_data_comments += int(row[4])  \n    \n## add all comments for google posts together:    \nfor row in google_posts:\n    total_google_comments += int(row[4])          \n    \n## add all comments for all posts together:\nfor row in hn_new:\n    all_comments += int(row[4])      \n    \n#calculate and print average amount of posts for posts:\n#----------------------------------------------------------\navg_ask_comments = total_ask_comments/len(ask_posts)\navg_show_comments = total_show_comments/len(show_posts)\navg_data_comments = total_data_comments/len(data_posts)\navg_google_comments = total_google_comments/len(google_posts)\navg_all_comments = all_comments/len(hn)\n\nprint(\"Average amount of comments for all posts:\",avg_all_comments)\nprint(\"Average amount of comments for Ask posts:\",avg_ask_comments)\nprint(\"Average amount of comments for Show posts:\",avg_show_comments)\nprint(\"Average amount of comments for posts about data science:\",avg_data_comments)\nprint(\"Average amount of comments for google posts:\",avg_google_comments)\n","execution_count":27,"outputs":[{"output_type":"stream","text":"Average amount of comments for all posts: 6.517011862076495\nAverage amount of comments for Ask posts: 10.40687081549775\nAverage amount of comments for Show posts: 4.893082380764683\nAverage amount of comments for posts about data science: 3.587174588010509\nAverage amount of comments for google posts: 8.468686868686868\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"#### Conclusions on average amount of comments for most frequent posts:\n\n1. Aks HN posts and posts about Google are commented more often than all posts in general: 10,4 and 8,5 vs 6,5 comments per post.\n2. Show HN posts and posts about Data are commented less often that all posts in general: 4,9 and 3,6 vs 6,5 comments per post\n"},{"metadata":{},"cell_type":"markdown","source":"To understand what about are the most commented posts' topics, lets create separate dictionary by average comments. There is no need to look into words that are only mentioned rarely in the dictionary, as sample will not be representative. Let's check only words that are mentioned in post titles more than 100 times:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# create dictionary that contains total comments received for each word in titles:\n# --------------------------------------------------------------------------\n# create empty dictionary:\ncomments_dictionary ={}\n\n\n#for each row in dataset:\nfor row in hn_new:\n    #assign the title in each post to variable called title:\n    words = []\n    title = row[1]\n    for c in string.punctuation:\n        title = title.replace(c,\" \")\n        splited_title = title.split(\" \")\n        \n        #convert all words into lower case and append to list words:    \n    for word in splited_title:\n        word = word.lower()\n        words.append(word)  \n        \n    for word in words:\n            # check if word already in dictionary, and if yes, append 1 to count:\n        if word in comments_dictionary.keys():\n            #add points to the word in count_dictionary:\n            comments_dictionary[word] += int(row[4])\n        # if not, add this word in discionary with count =1:    \n        else:\n            comments_dictionary[word] = int(row[4])","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create dictionary that contains average amount of comments received for each word in titles:\ntop_comments_dictionary = {}\n\nfor key in comments_dictionary.keys():\n    if count_dictionary[key] > 100:\n        top_comments_dictionary[key] = comments_dictionary[key]/count_dictionary[key]\n        ","execution_count":29,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### top 50 words in top_comments_dictionary:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# sort dictionary by counts and display top 50 words in point_dictionary:\nsorted(top_comments_dictionary.items(), reverse = True, key = lambda x: x[1] )[:50]","execution_count":30,"outputs":[{"output_type":"execute_result","execution_count":30,"data":{"text/plain":"[('income', 29.892307692307693),\n ('lee', 28.26086956521739),\n ('hired', 26.271317829457363),\n ('poverty', 25.141592920353983),\n ('hiring', 24.93688362919132),\n ('decline', 23.401515151515152),\n ('alphago', 23.231292517006803),\n ('shuts', 22.23448275862069),\n ('leave', 21.632142857142856),\n ('gitlab', 21.585987261146496),\n ('died', 21.019607843137255),\n ('arrested', 20.810344827586206),\n ('systemd', 20.693548387096776),\n ('beats', 20.63803680981595),\n ('bans', 20.370967741935484),\n ('asking', 20.338709677419356),\n ('anymore', 20.06474820143885),\n ('leaving', 20.0),\n ('basic', 19.83238095238095),\n ('fired', 19.433333333333334),\n ('judge', 19.38976377952756),\n ('macbook', 18.80916030534351),\n ('ama', 18.536082474226806),\n ('unlock', 18.40909090909091),\n ('shut', 18.390557939914164),\n ('lisp', 18.292887029288703),\n ('moment', 18.27480916030534),\n ('rust', 18.27244094488189),\n ('acquire', 18.195121951219512),\n ('exercise', 18.157894736842106),\n ('laptop', 18.045454545454547),\n ('poor', 18.028753993610223),\n ('seeking', 17.959731543624162),\n ('marissa', 17.942857142857143),\n ('homeless', 17.862385321100916),\n ('sourced', 17.82236842105263),\n ('june', 17.747826086956522),\n ('toxic', 17.741071428571427),\n ('iphones', 17.74),\n ('americans', 17.641025641025642),\n ('gnu', 17.631147540983605),\n ('april', 17.453333333333333),\n ('dao', 17.388489208633093),\n ('blame', 17.299212598425196),\n ('firefox', 17.016166281755197),\n ('dying', 16.89677419354839),\n ('dear', 16.887700534759357),\n ('doom', 16.847619047619048),\n ('am', 16.7986798679868),\n ('january', 16.703703703703702)]"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"#### Conclusion about most commented of topics on Hacker News:\n\nFrom top_comments_dictionary can be concluded that most popular topics (topics that have significant amount of posts to judge and have highest amount of points on average) are:\n\n- Income, Lee, Hired, Poverty, Hiring, Decline, AlphaGo, etc. \n\nIt is interesting to mention that none of top counts is in this list. "},{"metadata":{},"cell_type":"markdown","source":"## Is there difference in average amount of comments and points for posts created at different time of a day and day of a week? And is this difference the same for all types of posts? "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create function that takes list of posts as input and calculates average amount of comments for this posts by hour:\n#--------------------------------------------------------------------------------------------------------------------\n\ndef average_by(posts):\n    \n    #create an empty list :\n    result_list=[]\n\n    # for each row in ask_posts creare a list containing create_date and number of comments:\n    for row in posts:\n        result_list.append([row[6], int(row[4]), int(row[3])])\n    \n    \n    #create empty dictionaries to store how may posts and comments vs hour posted:    \n    counts_by_hour = {}\n    comments_by_hour = {}\n    points_by_hour = {}\n    counts_by_day = {}\n    comments_by_day = {}\n    points_by_day = {}\n\n    # for each row in result_list count how many comments and posts are posted and add them into created dictionaries:\n    for row in result_list:\n        d = dt.datetime.strptime(row[0],\"%m/%d/%Y %H:%M\" )\n        h = d.hour\n        w = d.isoweekday()\n\n        if str(h) in counts_by_hour.keys():\n            counts_by_hour[str(h)] +=1\n            comments_by_hour[str(h)] += row[1]\n            points_by_hour[str(h)] += row[2]\n        else:\n            counts_by_hour[str(h)] = 1\n            comments_by_hour[str(h)] = row[1]\n            points_by_hour[str(h)] = row[2]\n            \n        if str(w) in counts_by_day.keys():\n            counts_by_day[str(w)] +=1\n            comments_by_day[str(w)] += row[1]\n            points_by_day[str(w)] += row[2]\n        else:\n            counts_by_day[str(w)] = 1\n            comments_by_day[str(w)] = row[1]    \n            points_by_day[str(w)] = row[2]\n            \n    return counts_by_hour , comments_by_hour, counts_by_day, comments_by_day, points_by_hour, points_by_day","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# calculate average number of comments per post:\ndef avg_by(counts_by, comments_by):  \n    \n    avg_by = []\n\n    for key in comments_by:\n    \n        avg_by.append([key, comments_by[key]/counts_by[key]]) \n        \n    return avg_by   ","execution_count":32,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# apply average_by_hour() and sorted_swap() functions on ask, data and all posts:\n\nask_counts_by_hour , ask_comments_by_hour, ask_counts_by_day, ask_comments_by_day,\\\n    ask_points_by_hour, ask_points_by_day = average_by(ask_posts)\navg_comments_by_hour_ask = avg_by(ask_counts_by_hour , ask_comments_by_hour)\navg_comments_by_day_ask = avg_by(ask_counts_by_day , ask_comments_by_day)\navg_points_by_hour_ask = avg_by(ask_counts_by_hour , ask_points_by_hour)\navg_points_by_day_ask = avg_by(ask_counts_by_day , ask_points_by_day)\n\ndata_counts_by_hour , data_comments_by_hour, data_counts_by_day, data_comments_by_day,\\\n    data_points_by_hour, data_points_by_day = average_by(data_posts)\navg_comments_by_hour_data = avg_by(data_counts_by_hour , data_comments_by_hour)\navg_comments_by_day_data = avg_by(data_counts_by_day , data_comments_by_day)\navg_points_by_hour_data = avg_by(data_counts_by_hour , data_points_by_hour)\navg_points_by_day_data = avg_by(data_counts_by_day , data_points_by_day)\n\ngoogle_counts_by_hour , google_comments_by_hour, google_counts_by_day, google_comments_by_day,\\\n    google_points_by_hour, google_points_by_day = average_by(google_posts)\navg_comments_by_hour_google = avg_by(google_counts_by_hour , google_comments_by_hour)\navg_comments_by_day_google = avg_by(google_counts_by_day , google_comments_by_day)\navg_points_by_hour_google = avg_by(google_counts_by_hour , google_points_by_hour)\navg_points_by_day_google = avg_by(google_counts_by_day , google_points_by_day)\n\nall_counts_by_hour , all_comments_by_hour, all_counts_by_day, all_comments_by_day,\\\n    all_points_by_hour, all_points_by_day = average_by(hn_new)\navg_comments_by_hour_all = avg_by(all_counts_by_hour , all_comments_by_hour)\navg_comments_by_day_all = avg_by(all_counts_by_day , all_comments_by_day)\navg_points_by_hour_all = avg_by(all_counts_by_hour , all_points_by_hour)\navg_points_by_day_all = avg_by(all_counts_by_day , all_points_by_day)","execution_count":33,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create function that takes list unsorted posts and sorts it by hour:\n#----------------------------------------------------------------------\ndef sorted_avg(avg_list):\n    \n    sorted_hour = pd.DataFrame(avg_list)\n    sorted_hour.iloc[:,0]=sorted_hour.iloc[:,0].astype(int)\n    sorted_hour= sorted_hour.sort_values(by= 0)   \n    \n    return sorted_hour","execution_count":34,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create function that takes dictionary of posts and returns it in form of the list, but sorted by hour:\n#--------------------------------------------------------------------------------------------------------\n\ndef sorted_count(dictionary):\n\n    list_key_value = [ [k,v] for k, v in dictionary.items()]\n\n    sorted_count = pd.DataFrame(list_key_value)\n    sorted_count.iloc[:,0]=sorted_count.iloc[:,0].astype(int)\n    sorted_count= sorted_count.sort_values(by= 0)  \n\n    return sorted_count","execution_count":35,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot average amount of comments by hour:\n\n# convert sorted_hour to dataframe and sort by hour:\nsorted_comments_hour_ask = sorted_avg(avg_comments_by_hour_ask)\nsorted_comments_hour_data = sorted_avg(avg_comments_by_hour_data)\nsorted_comments_hour_google = sorted_avg(avg_comments_by_hour_google)\nsorted_comments_hour_all = sorted_avg(avg_comments_by_hour_all)\n\n\n#convert counts_by_hour to dataframe and sort by hour :\nsorted_count_hour_ask = sorted_count(ask_counts_by_hour)\nsorted_count_hour_all = sorted_count(all_counts_by_hour)\nsorted_count_hour_data = sorted_count(data_counts_by_hour)\nsorted_count_hour_google = sorted_count(google_counts_by_hour)\n\n#convert points by hour to dataframe and sort by hour:\nsorted_points_hour_ask = sorted_avg(avg_points_by_hour_ask)\nsorted_points_hour_all = sorted_avg(avg_points_by_hour_all)\nsorted_points_hour_data = sorted_avg(avg_points_by_hour_data)\nsorted_points_hour_google = sorted_avg(avg_points_by_hour_google)\n\n\n#plot sorted by hour average amount comments for Ask HN posts\nfig, ax = plt.subplots(3,4)\nfig.set_size_inches(18, 9)\n\nax[0,0].bar(sorted_comments_hour_ask.iloc[:,0], sorted_comments_hour_ask.iloc[:,1], color = 'skyblue')\nax[0,0].set_title(\"Ask Posts\")\nax[0,0].set_ylabel(\"Average amount of\\n comments per Post\\n per hour\")\nax[0,1].bar(sorted_comments_hour_google.iloc[:,0], sorted_comments_hour_google.iloc[:,1], color = 'orange')\nax[0,1].set_title(\"Google Posts\")\nax[0,2].bar(sorted_comments_hour_data.iloc[:,0], sorted_comments_hour_data.iloc[:,1],  color ='green')\nax[0,2].set_title(\"Posts about Data\")\nax[0,3].bar(sorted_comments_hour_all.iloc[:,0], sorted_comments_hour_all.iloc[:,1], color = 'brown')\nax[0,3].set_title(\"All Posts\")\n\nax[1,0].bar(sorted_points_hour_ask.iloc[:,0], sorted_points_hour_ask.iloc[:,1]/weeks, color = 'skyblue')\nax[1,0].set_ylabel(\"Average amount of\\n points per hour\")\nax[1,1].bar(sorted_points_hour_google.iloc[:,0], sorted_points_hour_google.iloc[:,1]/weeks, color = 'orange')\nax[1,2].bar(sorted_points_hour_data.iloc[:,0], sorted_points_hour_data.iloc[:,1]/weeks, color ='green')\nax[1,3].bar(sorted_points_hour_all.iloc[:,0], sorted_points_hour_all.iloc[:,1]/weeks, color = 'brown')\n\nax[2,0].bar(sorted_count_hour_ask.iloc[:,0], sorted_count_hour_ask.iloc[:,1]/weeks, color = 'skyblue')\nax[2,0].set_ylabel(\"Average amount of\\n posts per hour\")\nax[2,1].bar(sorted_count_hour_google.iloc[:,0], sorted_count_hour_google.iloc[:,1]/weeks, color = 'orange')\nax[2,2].bar(sorted_count_hour_data.iloc[:,0], sorted_count_hour_data.iloc[:,1]/weeks, color ='green')\nax[2,3].bar(sorted_count_hour_all.iloc[:,0], sorted_count_hour_all.iloc[:,1]/weeks, color = 'brown')\n","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":36,"data":{"text/plain":"<BarContainer object of 24 artists>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"#### Conclusions about comments vs hour of the day:   \nIn general it is clear that for all posts fluctuations for average comments vs hours of a day are low. However, if to look separatelly by topics- fluctuations are bigger. It is difficult to say why exactly it happens, but most probably it is due to less datapoints for specific topics. \n\n#### Conclusions about points vs hour of the day:   \nGraphs are very similar to graphs for average amount of comments, with slight difference. It is natural as users commenting and liking behaviour is similar. If one person have seen a post that he/she likes it is more probable that he/she will comment this post rather than the post that he/she didn't like, and vice versa.\n\n\n#### Conclusions about average amount of posts vs hour of the day:  \nPosting activity of users for all types of posts is increasing starting from 10:00 in the morning until approximatelly 17:00. Then it tends to go down. Pick posting activity is between 15:00 and 17:00.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot average amount of comments by hour:\n\n# convert sorted_day to dataframe and sort by day:\nsorted_comments_day_ask = sorted_avg(avg_comments_by_day_ask)\nsorted_comments_day_data = sorted_avg(avg_comments_by_day_all)\nsorted_comments_day_all = sorted_avg(avg_comments_by_day_data)\nsorted_comments_day_google = sorted_avg(avg_comments_by_day_google)\n\n#convert counts_by_day to dataframe and sort by day :\nsorted_count_day_ask = sorted_count(ask_counts_by_day)\nsorted_count_day_all = sorted_count(all_counts_by_day)\nsorted_count_day_data = sorted_count(data_counts_by_day)\nsorted_count_day_google = sorted_count(google_counts_by_day)\n\n#convert points by day to dataframe and sort by day:\nsorted_points_day_ask = sorted_avg(avg_points_by_day_ask)\nsorted_points_day_all = sorted_avg(avg_points_by_day_all)\nsorted_points_day_data = sorted_avg(avg_points_by_day_data)\nsorted_points_day_google = sorted_avg(avg_points_by_day_google)\n\n#plot sorted by day average amount comments for Ask HN posts\nfig, ax = plt.subplots(3, 4)\nfig.set_size_inches(18, 9)\n\nax[0,0].bar(sorted_comments_day_ask.iloc[:,0], sorted_comments_day_ask.iloc[:,1], color = 'skyblue')\nax[0,0].set_title(\"Ask Posts\")\nax[0,0].set_ylabel(\"Average amount of\\n comments per Post\\n per week\")\nax[0,1].bar(sorted_comments_day_google.iloc[:,0], sorted_comments_day_google.iloc[:,1], color = 'orange')\nax[0,1].set_title(\"Google Posts\")\nax[0,2].bar(sorted_comments_day_data.iloc[:,0], sorted_comments_day_data.iloc[:,1],  color ='green')\nax[0,2].set_title(\"Posts about Data\")\nax[0,3].bar(sorted_comments_day_all.iloc[:,0], sorted_comments_day_all.iloc[:,1], color = 'brown')\nax[0,3].set_title(\"All Posts\")\n\nax[1,0].bar(sorted_points_day_ask.iloc[:,0], sorted_points_day_ask.iloc[:,1]/weeks, color = 'skyblue')\nax[1,0].set_ylabel(\"Average amount of\\n points per week\")\nax[1,1].bar(sorted_points_day_google.iloc[:,0], sorted_points_day_google.iloc[:,1]/weeks, color = 'orange')\nax[1,2].bar(sorted_points_day_data.iloc[:,0], sorted_points_day_data.iloc[:,1]/weeks, color ='green')\nax[1,3].bar(sorted_points_day_all.iloc[:,0], sorted_points_day_all.iloc[:,1]/weeks, color = 'brown')\n\n\nax[2,0].bar(sorted_count_day_ask.iloc[:,0], sorted_count_day_ask.iloc[:,1]/weeks, color = 'skyblue')\nax[2,0].set_ylabel(\"Average amount of\\n posts per week\")\nax[2,1].bar(sorted_count_day_google.iloc[:,0], sorted_count_day_google.iloc[:,1]/weeks, color = 'orange')\nax[2,2].bar(sorted_count_day_data.iloc[:,0], sorted_count_day_data.iloc[:,1]/weeks, color ='green')\nax[2,3].bar(sorted_count_day_all.iloc[:,0], sorted_count_day_all.iloc[:,1]/weeks, color = 'brown')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Conclusions about comments and points vs hour of the day:   \n\nIn general users are more active in commenting and liking posts created on weekends and beginning of a week.\n \n#### Conclusions about average amount of posts vs hour of the day:  \nIn general posting activity increases by middle of the week and drops by the end of the week. On the weekends for all types of posts activity is very low.\n\n#### General conclusion: \n\nEven though users tend to post more in the middle of a week, according to statistics, posts created during weekends tend to recieve more comments. It is not surprising: as users are very active during middle of a week, posts created during weekends have more chances to be checked and commented than posts created in the middle of the week.\n"},{"metadata":{},"cell_type":"markdown","source":"## Summary and Conclusions :\n\nDuring the project it was discovered that:\n1. Most common topics on Hacker News are:\n    - 'Ask HN' and 'Show HN' posts\n    - Posts about topics related to words: 'Data', 'Google', 'new', 'app', 'US', etc.\n2. Most popular posts on Hacker News about topics related to words:\n    - 'Died', 'Lee', 'GitLab', 'AlphaGo', 'Sorced', 'Rust', 'Arrested', etc.\n3. Most commented posts on Hacker News about topics related to words:\n     - 'Income' , 'Lee' , 'Hired' , 'Poverty', 'Hiring', 'Decline', 'AlphaGo', etc.\n4. There is no difference in terms of average amount of comments and points for posts vs time of the day\n5. Posting activity of users for all types of posts is increasing starting from 10:00 in the morning until \napproximatelly 17:00. Then it tends to go down. Pick posting activity is between 15:00 and 17:00.\n6. In general users are more active in commenting and liking posts created on weekends and beginning of a week.\n7. In general posting activity increases by middle of the week and drops by the end of the week. On the weekends \nfor all types of posts activity is relatively low."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}