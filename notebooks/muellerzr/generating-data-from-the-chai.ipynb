{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Generating Data from the Chai\n\nWhile helping out Sanyam with this dataset, I wrote a little script that converts our raw text into something that can work for ML frameworks, so let's get into it!","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport re","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's take a look at some of the files we're working with. We'll use the raw `.txt`'s:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"f = open('../input/chai-time-data-science/Raw Subtitles/E75.txt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f.readline()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f.readline()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f.readline()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So we can see that we've got the speaker, a timestamp, and the text, before a `\\n` at the end. So let's write a function to do this:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_transcript(fn, save=False, save_path=''):\n    \"Takes transcript and converts it to `DataFrame`\"\n    pat = r'([A-Za-z]|\\s+)\\s([0-9]{0,2}:{0,1}[0-9]{1,2}:[0-9][0-9])'\n    f = open(fn, \"r\")\n    t = True\n    df = pd.DataFrame(columns = ['Time', 'Speaker', 'Text'])\n    i = 0\n    first = True\n    while t:\n        line = f.readline()\n        if line == '': t = False\n        i += 1\n        line = re.split(pat, line[:-1])\n        if len(line) == 4:\n            is_new = 1\n            speak = line[0]\n            time = line[2]\n        while is_new == 1:\n            if first:\n                line = f.readline()\n                for i in range(6):\n                    l_c = f.readline()\n                    if speak not in l_c and time not in l_c:\n                        line += l_c\n                i += 1\n                first = False\n            else:\n                line = f.readline()\n                i += 1\n            if len(line) > 2 and line != '\\n':\n                line = line[:-1]\n                df.loc[i] = [time, speak, line]\n                df.reset_index()\n            else:\n                is_new = 0\n    df.reset_index(drop=True, inplace=True)\n    df['Text'] = df['Text'].replace('\\n', '')\n    if save:\n        df.to_csv(save_path+fn.name[:-3] + 'csv', index=False, sep='|')\n    return df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In our function we're using regex to extract the speaker name and the time, and if it's the first row, we grab the next 6 `readlines` due to how Sanyam has his wonderful interviews formatted. Let's try that one:\n\n> Also, do note the seperator for our `csv`'s are a pipe (|), this is due to how we have many commas in our transcripts, so NumPy won't play nice","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = extract_transcript('../input/chai-time-data-science/Raw Subtitles/E73.txt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So now we have an annotated format! Let's convert all of them:\n\nWe'll use `fastai`'s helpful additions to pathlib as well:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai.vision import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = Path('../input/chai-time-data-science/Raw Subtitles/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path.ls()[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for fn in path.ls():\n    extract_transcript(fn, '../output/kaggle/working/')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And now we have working CSV's for the entire dataset, have fun!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('./E70.csv', delimiter='|')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}