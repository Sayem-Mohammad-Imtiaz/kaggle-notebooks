{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f2dd972b-2b19-ba82-9626-beb3a48214ff"},"outputs":[],"source":"import pandas as pd\nimport numpy as np\n\nfrom keras.models import Sequential\nfrom keras.layers import Embedding, Dense, Activation, Dropout\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers import GRU\nfrom keras.optimizers import RMSprop\n\nimport random"},{"cell_type":"markdown","metadata":{"_cell_guid":"889c9840-fc65-7ed1-a512-4e911d852727"},"source":"## Because the dataset is too big, we load only `num_questions` questions to the memory."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8d00d087-f51f-db81-59a6-c1f65565b8ae"},"outputs":[],"source":"num_questions = 500"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4cfe70f9-db4e-08ac-3d94-d48f72f5b02a"},"outputs":[],"source":"questions = pd.read_csv(\"../input/Questions.csv\", encoding='latin1')\ntext = list(questions[\"Body\"])[:num_questions]"},{"cell_type":"markdown","metadata":{"_cell_guid":"b8d2d950-d4c8-2a05-f9dd-b41e614f606b"},"source":"## Get indices for characters for the future one-hot character encoding."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fc49e08c-5d88-44c4-558b-da1716838f59"},"outputs":[],"source":"chars = set()\nfor i in range(len(text)):\n    chars = chars.union(set(text[i]))\nchars = sorted(chars)\nchar_index = dict((c, i) for i, c in enumerate(chars))\nindex_char = dict((i, c) for i, c in enumerate(chars))"},{"cell_type":"markdown","metadata":{"_cell_guid":"f7f2d6a0-036d-cf73-21f9-5945816d5113"},"source":"## Load sequences (i.e., sentences of the questions) and vectorise them."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dc17f076-12e7-facb-269a-f47ac790327f"},"outputs":[],"source":"sequence_len = 30\nstep = 1\n\nnum_sequences = 0\n\nfor quest in text:\n    for i in range(0, len(quest) - sequence_len, step):\n        num_sequences += 1\n        #sequences.append(quest[i: i + sequence_len])\n        #next_chars.append(quest[i + sequence_len])\n        \nprint(\"# sequences:\", num_sequences)\n\n\nX = np.zeros((num_sequences, sequence_len, len(chars)), dtype = np.bool)\ny = np.zeros((num_sequences, len(chars)), dtype = np.bool)\n\nfor quest in text:\n    for i in range(0, len(quest) - sequence_len, step):\n        seq = quest[i: i + sequence_len]\n        next_char = quest[i + sequence_len]\n        for j, ch in enumerate(seq):\n            X[i, j, char_index[ch]] = 1\n        y[i, char_index[next_char]] = 1"},{"cell_type":"markdown","metadata":{"_cell_guid":"6b552d9b-8b64-e9a3-8e59-21014c2ea87e"},"source":"## Build the model."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cf3450a3-3d05-b9c2-cc2f-8cb7966dea85"},"outputs":[],"source":"model = Sequential()\n\nmodel.add(GRU(512, return_sequences = True, input_shape = (sequence_len, len(chars))))\n#model.add(BatchNormalization())\nmodel.add(Dropout(.2))\n\nmodel.add(GRU(256))\n#model.add(BatchNormalization())\nmodel.add(Dropout(.2))\n\nmodel.add(Dense(len(chars)))\nmodel.add(Activation('softmax'))\n\noptimizer = RMSprop(lr=0.01)\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizer)"},{"cell_type":"markdown","metadata":{"_cell_guid":"62167c04-bc9c-60e8-b52b-68b2cea6c637"},"source":"## Here we define two important functions:\n- `sample` is a function used for generating random characters from the input vector of character probabilities. We will use it in the output question generation process.\n\n- `data_generator` is a function that generates output subsamples (also called \"batches\") as an input to our model."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0d912e71-5ed2-cb09-cdf5-7d3c44e13f25"},"outputs":[],"source":"def sample(preds, temperature=1.0):\n    preds = np.asarray(preds).astype('float64')\n    preds = np.log(preds) / temperature\n    exp_preds = np.exp(preds)\n    preds = exp_preds / np.sum(exp_preds)\n    probas = np.random.multinomial(1, preds, 1)\n    return np.argmax(probas)\n\n\ndef data_generator(batch_size):\n    while 1:\n        index = np.random.randint(0, num_sequences, batch_size)\n        yield X[index, :, :], y[index, :]"},{"cell_type":"markdown","metadata":{"_cell_guid":"38ec8917-c15e-3925-da92-4f7945c1b5d0"},"source":"## Run the model and generate questions at each iteration."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"64c4cfbc-af0a-3fed-e4b1-8a6d5a6bcddf"},"outputs":[],"source":"n_iter = 5\nbatch_size = 64\nmax_gen_len = 300\nn_samples = 10\n\n\nfor iteration in range(1, n_iter):\n    print(\"Iteration:\", iteration)\n    \n    model.fit_generator(data_generator(batch_size), \n                        samples_per_epoch = batch_size * n_samples, \n                        nb_epoch = 1, verbose=1)\n    \n    seq_index = random.randint(0, len(text))\n    start_index = random.randint(0, len(text[seq_index]) - sequence_len - 1)\n    print(\"Sequence seed:\\n\\t\", text[seq_index][start_index : start_index + sequence_len])\n    \n    for temper in [.2, .6, 1.3]:\n        print(\"-\" * 30)\n        generated = ''\n        sequence = text[seq_index][start_index : start_index + sequence_len]\n        generated += sequence\n        \n        for i in range(max_gen_len):\n            x = np.zeros((1, sequence_len, len(chars)))\n            for i, ch in enumerate(sequence):\n                    x[0, i, char_index[ch]] = 1.\n                    \n            pred_ch = model.predict(x, verbose = 0)[0]\n            next_index = sample(pred_ch, temper)\n            next_char = index_char[next_index]\n\n            generated += next_char\n            sequence = sequence[1:] + next_char\n        print(generated)\n    print(\"-\" * 30)"},{"cell_type":"markdown","metadata":{"_cell_guid":"87217de3-ed4e-1ffa-ebd0-2ace33260b3f"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a44efd19-7dc2-12cc-85e5-9da687146073"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}