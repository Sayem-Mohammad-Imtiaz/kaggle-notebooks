{"cells":[{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:05.53124Z","iopub.status.busy":"2020-09-24T01:22:05.528411Z","iopub.status.idle":"2020-09-24T01:22:06.812063Z","shell.execute_reply":"2020-09-24T01:22:06.812525Z"},"id":"moB4tpEHxKB3","trusted":true},"cell_type":"code","source":"# Use seaborn for pairplot\n!pip install -q seaborn","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:06.818887Z","iopub.status.busy":"2020-09-24T01:22:06.817715Z","iopub.status.idle":"2020-09-24T01:22:08.646796Z","shell.execute_reply":"2020-09-24T01:22:08.646235Z"},"id":"1rRo8oNqZ-Rj","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\n\n# Make numpy printouts easier to read.\nnp.set_printoptions(precision=3, suppress=True)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:08.651909Z","iopub.status.busy":"2020-09-24T01:22:08.651252Z","iopub.status.idle":"2020-09-24T01:22:13.845864Z","shell.execute_reply":"2020-09-24T01:22:13.845242Z"},"id":"9xQKvCJ85kCQ","trusted":true},"cell_type":"code","source":"import tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers.experimental import preprocessing\n\nprint(tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{"id":"gFh9ne3FZ-On"},"cell_type":"markdown","source":"### Get the data\nFirst download and import the dataset using pandas:"},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:13.852655Z","iopub.status.busy":"2020-09-24T01:22:13.852002Z","iopub.status.idle":"2020-09-24T01:22:14.654748Z","shell.execute_reply":"2020-09-24T01:22:14.655199Z"},"id":"CiX2FI4gZtTt","trusted":true},"cell_type":"code","source":"url = '../input/yeh-concret-data/Concrete_Data_Yeh.csv'\ncolumn_names = [\"cement\",\"slag\",\"flyash\",\"water\",\"superplasticizer\",\"coarseaggregate\",\"fineaggregate\",\"age\",\"csMPa\"\n]\n\nraw_dataset = pd.read_csv(url)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:14.667756Z","iopub.status.busy":"2020-09-24T01:22:14.667071Z","iopub.status.idle":"2020-09-24T01:22:14.674215Z","shell.execute_reply":"2020-09-24T01:22:14.674744Z"},"id":"2oY3pMPagJrO","trusted":true},"cell_type":"code","source":"dataset = raw_dataset.copy()\ndataset.tail()","execution_count":null,"outputs":[]},{"metadata":{"id":"3MWuJTKEDM-f"},"cell_type":"markdown","source":"### Clean the data\n\nThe dataset contains a few unknown values."},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:14.680977Z","iopub.status.busy":"2020-09-24T01:22:14.680263Z","iopub.status.idle":"2020-09-24T01:22:14.682955Z","shell.execute_reply":"2020-09-24T01:22:14.683335Z"},"id":"JEJHhN65a2VV","trusted":true},"cell_type":"code","source":"dataset.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"id":"9UPN0KBHa_WI"},"cell_type":"markdown","source":"Drop those rows to keep this initial tutorial simple."},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:14.688546Z","iopub.status.busy":"2020-09-24T01:22:14.687924Z","iopub.status.idle":"2020-09-24T01:22:14.691112Z","shell.execute_reply":"2020-09-24T01:22:14.691514Z"},"id":"4ZUDosChC1UN","trusted":true},"cell_type":"code","source":"dataset = dataset.dropna()","execution_count":null,"outputs":[]},{"metadata":{"id":"8XKitwaH4v8h"},"cell_type":"markdown","source":"The `\"Origin\"` column is really categorical, not numeric. So convert that to a one-hot:\n\nNote: You can set up the `keras.Model` to do this kind of transformation for you. That's beyond the scope of this tutorial. See the [preprocessing layers](../structured_data/preprocessing_layers.ipynb) or [Loading CSV data](../load_data/csv.ipynb) tutorials for examples."},{"metadata":{"id":"Cuym4yvk76vU"},"cell_type":"markdown","source":"### Split the data into train and test\n\nNow split the dataset into a training set and a test set.\n\nWe will use the test set in the final evaluation of our models."},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:14.726365Z","iopub.status.busy":"2020-09-24T01:22:14.725813Z","iopub.status.idle":"2020-09-24T01:22:14.727513Z","shell.execute_reply":"2020-09-24T01:22:14.72792Z"},"id":"qn-IGhUE7_1H","trusted":true},"cell_type":"code","source":"train_dataset = dataset.sample(frac=0.8, random_state=0)\ntest_dataset = dataset.drop(train_dataset.index)","execution_count":null,"outputs":[]},{"metadata":{"id":"J4ubs136WLNp"},"cell_type":"markdown","source":"### Inspect the data\n\nHave a quick look at the joint distribution of a few pairs of columns from the training set.\n\nLooking at the top row it should be clear that the fuel efficiency (MPG) is a function of all the other parameters. Looking at the other rows it should be clear that they are each functions of eachother."},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:14.740983Z","iopub.status.busy":"2020-09-24T01:22:14.733861Z","iopub.status.idle":"2020-09-24T01:22:19.709876Z","shell.execute_reply":"2020-09-24T01:22:19.710355Z"},"id":"oRKO_x8gWKv-","trusted":true},"cell_type":"code","source":"sns.pairplot(train_dataset[[\"cement\",\"slag\",\"flyash\",\"water\",\"superplasticizer\",\"coarseaggregate\",\"fineaggregate\",\"age\",\"csMPa\"]], diag_kind='kde')","execution_count":null,"outputs":[]},{"metadata":{"id":"gavKO_6DWRMP"},"cell_type":"markdown","source":"Also look at the overall statistics, note how each feature covers a very different range:"},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:19.719318Z","iopub.status.busy":"2020-09-24T01:22:19.717278Z","iopub.status.idle":"2020-09-24T01:22:19.749506Z","shell.execute_reply":"2020-09-24T01:22:19.748895Z"},"id":"yi2FzC3T21jR","trusted":true},"cell_type":"code","source":"train_dataset.describe().transpose()","execution_count":null,"outputs":[]},{"metadata":{"id":"Db7Auq1yXUvh"},"cell_type":"markdown","source":"### Split features from labels\n\nSeparate the target value, the \"label\", from the features. This label is the value that you will train the model to predict."},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:19.755887Z","iopub.status.busy":"2020-09-24T01:22:19.755092Z","iopub.status.idle":"2020-09-24T01:22:19.757179Z","shell.execute_reply":"2020-09-24T01:22:19.756619Z"},"id":"t2sluJdCW7jN","trusted":true},"cell_type":"code","source":"train_features = train_dataset.copy()\ntest_features = test_dataset.copy()\n\ntrain_labels = train_features.pop('csMPa')\ntest_labels = test_features.pop('csMPa')","execution_count":null,"outputs":[]},{"metadata":{"id":"mRklxK5s388r"},"cell_type":"markdown","source":"## Normalization\n\nIn the table of statistics it's easy to see how different the ranges of each feature are."},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:19.768552Z","iopub.status.busy":"2020-09-24T01:22:19.766697Z","iopub.status.idle":"2020-09-24T01:22:19.79193Z","shell.execute_reply":"2020-09-24T01:22:19.792389Z"},"id":"IcmY6lKKbkw8","trusted":true},"cell_type":"code","source":"train_dataset.describe().transpose()[['mean', 'std']]","execution_count":null,"outputs":[]},{"metadata":{"id":"-ywmerQ6dSox"},"cell_type":"markdown","source":"It is good practice to normalize features that use different scales and ranges. \n\nOne reason this is important is because the features are multiplied by the model weights. So the scale of the outputs and the scale of the gradients are affected by the scale of the inputs. \n\nAlthough a model *might* converge without feature normalization, normalization makes training much more stable. "},{"metadata":{"id":"aFJ6ISropeoo"},"cell_type":"markdown","source":"### The Normalization layer\nThe `preprocessing.Normalization` layer is a clean and simple way to build that preprocessing into your model.\n\nThe first step is to create the layer:"},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:19.796972Z","iopub.status.busy":"2020-09-24T01:22:19.796314Z","iopub.status.idle":"2020-09-24T01:22:19.80551Z","shell.execute_reply":"2020-09-24T01:22:19.804843Z"},"id":"JlC5ooJrgjQF","trusted":true},"cell_type":"code","source":"normalizer = preprocessing.Normalization()","execution_count":null,"outputs":[]},{"metadata":{"id":"XYA2Ap6nVOha"},"cell_type":"markdown","source":"Then `.adapt()` it to the data:"},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:27.716978Z","iopub.status.busy":"2020-09-24T01:22:27.71626Z","iopub.status.idle":"2020-09-24T01:22:28.025993Z","shell.execute_reply":"2020-09-24T01:22:28.025303Z"},"id":"CrBbbjbwV91f","trusted":true},"cell_type":"code","source":"normalizer.adapt(np.array(train_features))","execution_count":null,"outputs":[]},{"metadata":{"id":"oZccMR5yV9YV"},"cell_type":"markdown","source":"This calculates the mean and variance, and stores them in the layer. "},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:28.032119Z","iopub.status.busy":"2020-09-24T01:22:28.03143Z","iopub.status.idle":"2020-09-24T01:22:28.03504Z","shell.execute_reply":"2020-09-24T01:22:28.034549Z"},"id":"GGn-ukwxSPtx","trusted":true},"cell_type":"code","source":"print(normalizer.mean.numpy())","execution_count":null,"outputs":[]},{"metadata":{"id":"oGWKaF9GSRuN"},"cell_type":"markdown","source":"When the layer is called it returns the input data, with each feature independently normalized:"},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:28.042754Z","iopub.status.busy":"2020-09-24T01:22:28.042074Z","iopub.status.idle":"2020-09-24T01:22:28.047614Z","shell.execute_reply":"2020-09-24T01:22:28.047069Z"},"id":"2l7zFL_XWIRu","trusted":true},"cell_type":"code","source":"first = np.array(train_features[:1])\n\nwith np.printoptions(precision=2, suppress=True):\n  print('First example:', first)\n  print()\n  print('Normalized:', normalizer(first).numpy())","execution_count":null,"outputs":[]},{"metadata":{"id":"6o3CrycBXA2s"},"cell_type":"markdown","source":"## Linear regression\n\nBefore building a DNN model, start with a linear regression."},{"metadata":{"id":"lFby9n0tnHkw"},"cell_type":"markdown","source":"### One Variable\n\nStart with a single-variable linear regression, to predict `MPG` from `Horsepower`.\n\nTraining a model with `tf.keras` typically starts by defining the model architecture.\n\nIn this case use a `keras.Sequential` model. This model represents a sequence of steps. In this case there are two steps:\n\n* Normalize the input `horsepower`.\n* Apply a linear transformation ($y = mx+b$) to produce 1 output using `layers.Dense`.\n\nThe number of _inputs_ can either be set by the `input_shape` argument, or automatically when the model is run for the first time."},{"metadata":{"id":"Xp3gAFn3TPv8"},"cell_type":"markdown","source":"First create the horsepower `Normalization` layer:"},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:28.056201Z","iopub.status.busy":"2020-09-24T01:22:28.055572Z","iopub.status.idle":"2020-09-24T01:22:28.062035Z","shell.execute_reply":"2020-09-24T01:22:28.062668Z"},"id":"1gJAy0fKs1TS","trusted":true},"cell_type":"code","source":"superplasticizer = np.array(train_features['superplasticizer'])\n\nsuperplasticizer_normalizer = preprocessing.Normalization(input_shape=[1,])\nsuperplasticizer_normalizer.adapt(superplasticizer)","execution_count":null,"outputs":[]},{"metadata":{"id":"4NVlHJY2TWlC"},"cell_type":"markdown","source":"Build the sequential model:"},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:28.075226Z","iopub.status.busy":"2020-09-24T01:22:28.074585Z","iopub.status.idle":"2020-09-24T01:22:28.099052Z","shell.execute_reply":"2020-09-24T01:22:28.098478Z"},"id":"c0sXM7qLlKfZ","trusted":true},"cell_type":"code","source":"superplasticizer_model = tf.keras.Sequential([\n    superplasticizer_normalizer,\n    layers.Dense(units=1)\n])\n\nsuperplasticizer_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"id":"eObQu9fDnXGL"},"cell_type":"markdown","source":"This model will predict `MPG` from `Horsepower`.\n\nRun the untrained model on the first 10 horse-power values. The output won't be good, but you'll see that it has the expected shape, `(10,1)`:"},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:28.104528Z","iopub.status.busy":"2020-09-24T01:22:28.103842Z","iopub.status.idle":"2020-09-24T01:22:28.494359Z","shell.execute_reply":"2020-09-24T01:22:28.49378Z"},"id":"UfV1HS6bns-s","trusted":true},"cell_type":"code","source":"superplasticizer_model.predict(superplasticizer[:10])","execution_count":null,"outputs":[]},{"metadata":{"id":"CSkanJlmmFBX"},"cell_type":"markdown","source":"Once the model is built, configure the training procedure using the `Model.compile()` method. The most important arguments to compile are the `loss` and the `optimizer` since these define what will be optimized (`mean_absolute_error`) and how (using the `optimizers.Adam`)."},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:28.506986Z","iopub.status.busy":"2020-09-24T01:22:28.506337Z","iopub.status.idle":"2020-09-24T01:22:28.51516Z","shell.execute_reply":"2020-09-24T01:22:28.514658Z"},"id":"JxA_3lpOm-SK","trusted":true},"cell_type":"code","source":"superplasticizer_model.compile(\n    optimizer=tf.optimizers.Adam(learning_rate=0.1),\n    loss='mean_absolute_error')","execution_count":null,"outputs":[]},{"metadata":{"id":"Z3q1I9TwnRSC"},"cell_type":"markdown","source":"Once the training is configured, use `Model.fit()` to execute the training:"},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:28.52144Z","iopub.status.busy":"2020-09-24T01:22:28.520771Z","iopub.status.idle":"2020-09-24T01:22:31.497659Z","shell.execute_reply":"2020-09-24T01:22:31.496971Z"},"id":"-iSrNy59nRAp","trusted":true},"cell_type":"code","source":"%%time\nhistory = superplasticizer_model.fit(\n    train_features['superplasticizer'], train_labels,\n    epochs=100,\n    # suppress logging\n    verbose=0,\n    # Calculate validation results on 20% of the training data\n    validation_split = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"id":"tQm3pc0FYPQB"},"cell_type":"markdown","source":"Visualize the model's training progress using the stats stored in the `history` object."},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:31.508263Z","iopub.status.busy":"2020-09-24T01:22:31.507543Z","iopub.status.idle":"2020-09-24T01:22:31.510817Z","shell.execute_reply":"2020-09-24T01:22:31.510388Z"},"id":"YCAwD_y4AdC3","trusted":true},"cell_type":"code","source":"hist = pd.DataFrame(history.history)\nhist['epoch'] = history.epoch\nhist.tail()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:31.515825Z","iopub.status.busy":"2020-09-24T01:22:31.515034Z","iopub.status.idle":"2020-09-24T01:22:31.51702Z","shell.execute_reply":"2020-09-24T01:22:31.517399Z"},"id":"9E54UoZunqhc","trusted":true},"cell_type":"code","source":"def plot_loss(history):\n  plt.plot(history.history['loss'], label='loss')\n  plt.plot(history.history['val_loss'], label='val_loss')\n  plt.ylim([0, 100])\n  plt.xlabel('Epoch')\n  plt.ylabel('Error [csMPa]')\n  plt.legend()\n  plt.grid(True)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:31.527487Z","iopub.status.busy":"2020-09-24T01:22:31.526599Z","iopub.status.idle":"2020-09-24T01:22:31.790176Z","shell.execute_reply":"2020-09-24T01:22:31.790709Z"},"id":"yYsQYrIZyqjz","trusted":true},"cell_type":"code","source":"plot_loss(history)","execution_count":null,"outputs":[]},{"metadata":{"id":"CMNrt8X2ebXd"},"cell_type":"markdown","source":"Collect the results on the test set, for later:"},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:31.796644Z","iopub.status.busy":"2020-09-24T01:22:31.795688Z","iopub.status.idle":"2020-09-24T01:22:31.840884Z","shell.execute_reply":"2020-09-24T01:22:31.841419Z"},"id":"kDZ8EvNYrDtx","trusted":true},"cell_type":"code","source":"test_results = {}\n\ntest_results['superplasticizer'] = superplasticizer_model.evaluate(\n    test_features['superplasticizer'],\n    test_labels, verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"id":"F0qutYAKwoda"},"cell_type":"markdown","source":"SInce this is a single variable regression it's easy to look at the model's predictions as a function of the input:"},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:31.846035Z","iopub.status.busy":"2020-09-24T01:22:31.845152Z","iopub.status.idle":"2020-09-24T01:22:31.907419Z","shell.execute_reply":"2020-09-24T01:22:31.907969Z"},"id":"xDS2JEtOn9Jn","trusted":true},"cell_type":"code","source":"x = tf.linspace(10, 70, 101)\ny = superplasticizer_model.predict(x)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:31.912754Z","iopub.status.busy":"2020-09-24T01:22:31.91211Z","iopub.status.idle":"2020-09-24T01:22:31.9139Z","shell.execute_reply":"2020-09-24T01:22:31.91438Z"},"id":"rttFCTU8czsI","trusted":true},"cell_type":"code","source":"def plot_superplasticizer(x, y):\n  plt.scatter(train_features['superplasticizer'], train_labels, label='Data')\n  plt.plot(x, y, color='k', label='Predictions')\n  plt.xlabel('superplasticizer')\n  plt.ylabel('csMPa')\n  plt.legend()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:31.924809Z","iopub.status.busy":"2020-09-24T01:22:31.922118Z","iopub.status.idle":"2020-09-24T01:22:32.062094Z","shell.execute_reply":"2020-09-24T01:22:32.062513Z"},"id":"7l9ZiAOEUNBL","trusted":true},"cell_type":"code","source":"plot_superplasticizer(x,y)","execution_count":null,"outputs":[]},{"metadata":{"id":"Yk2RmlqPoM9u"},"cell_type":"markdown","source":"### Multiple inputs"},{"metadata":{"id":"PribnwDHUksC"},"cell_type":"markdown","source":"You can use an almost identical setup to make predictions based on multiple inputs. This model still does the same $y = mx+b$ except that $m$ is a matrix and $b$ is a vector.\n\nThis time use the `Normalization` layer that was adapted to the whole dataset."},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:32.070149Z","iopub.status.busy":"2020-09-24T01:22:32.069333Z","iopub.status.idle":"2020-09-24T01:22:32.08649Z","shell.execute_reply":"2020-09-24T01:22:32.086912Z"},"id":"ssnVcKg7oMe6","trusted":true},"cell_type":"code","source":"linear_model = tf.keras.Sequential([\n    normalizer,\n    layers.Dense(units=1)\n])","execution_count":null,"outputs":[]},{"metadata":{"id":"IHlx6WeIWyAr"},"cell_type":"markdown","source":"When you call this model on a batch of inputs, it produces `units=1` outputs for each example."},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:32.095284Z","iopub.status.busy":"2020-09-24T01:22:32.094144Z","iopub.status.idle":"2020-09-24T01:22:32.159913Z","shell.execute_reply":"2020-09-24T01:22:32.160306Z"},"id":"DynfJV18WiuT","trusted":true},"cell_type":"code","source":"linear_model.predict(train_features[:10])","execution_count":null,"outputs":[]},{"metadata":{"id":"hvHKH3rPXHmq"},"cell_type":"markdown","source":"When you call the model it's weight matrices will be built. Now you can see that the `kernel` (the $m$ in $y=mx+b$) has a shape of `(9,1)`."},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:32.164845Z","iopub.status.busy":"2020-09-24T01:22:32.164208Z","iopub.status.idle":"2020-09-24T01:22:32.167469Z","shell.execute_reply":"2020-09-24T01:22:32.167852Z"},"id":"DwJ4Fq0RXBQf","trusted":true},"cell_type":"code","source":"linear_model.layers[1].kernel","execution_count":null,"outputs":[]},{"metadata":{"id":"eINAc6rZXzOt"},"cell_type":"markdown","source":"Use the same `compile` and `fit` calls as for the single input `horsepower` model:"},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:32.176328Z","iopub.status.busy":"2020-09-24T01:22:32.175658Z","iopub.status.idle":"2020-09-24T01:22:32.181642Z","shell.execute_reply":"2020-09-24T01:22:32.181007Z"},"id":"A0Sv_Ybr0szp","trusted":true},"cell_type":"code","source":"linear_model.compile(\n    optimizer=tf.optimizers.Adam(learning_rate=0.1),\n    loss='mean_absolute_error')","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:32.186699Z","iopub.status.busy":"2020-09-24T01:22:32.186119Z","iopub.status.idle":"2020-09-24T01:22:34.990391Z","shell.execute_reply":"2020-09-24T01:22:34.989747Z"},"id":"EZoOYORvoTSe","trusted":true},"cell_type":"code","source":"%%time\nhistory = linear_model.fit(\n    train_features, train_labels, \n    epochs=100,\n    # suppress logging\n    verbose=0,\n    # Calculate validation results on 20% of the training data\n    validation_split = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"id":"EdxiCbiNYK2F"},"cell_type":"markdown","source":"Using all the inputs achieves a much lower training and validation error than the `horsepower` model: "},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:35.003869Z","iopub.status.busy":"2020-09-24T01:22:35.002976Z","iopub.status.idle":"2020-09-24T01:22:35.131785Z","shell.execute_reply":"2020-09-24T01:22:35.131141Z"},"id":"4sWO3W0koYgu","trusted":true},"cell_type":"code","source":"plot_loss(history)","execution_count":null,"outputs":[]},{"metadata":{"id":"NyN49hIWe_NH"},"cell_type":"markdown","source":"Collect the results on the test set, for later:"},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:35.136278Z","iopub.status.busy":"2020-09-24T01:22:35.135677Z","iopub.status.idle":"2020-09-24T01:22:35.182412Z","shell.execute_reply":"2020-09-24T01:22:35.181739Z"},"id":"jNC3D1DGsGgK","trusted":true},"cell_type":"code","source":"test_results['linear_model'] = linear_model.evaluate(\n    test_features, test_labels, verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"id":"SmjdzxKzEu1-"},"cell_type":"markdown","source":"## A DNN regression"},{"metadata":{"id":"DT_aHPsrzO1t"},"cell_type":"markdown","source":"The previous section implemented linear models for single and multiple inputs.\n\nThis section implements single-input and multiple-input DNN models. The code is basically the same except the model is expanded to include some \"hidden\"  non-linear layers. The name \"hidden\" here just means not directly connected to the inputs or outputs."},{"metadata":{"id":"6SWtkIjhrZwa"},"cell_type":"markdown","source":"These models will contain a few more layers than the linear model:\n\n* The normalization layer.\n* Two hidden, nonlinear, `Dense` layers using the `relu` nonlinearity.\n* A linear single-output layer.\n\nBoth will use the same training procedure so the `compile` method is included in the `build_and_compile_model` function below."},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:35.188858Z","iopub.status.busy":"2020-09-24T01:22:35.187815Z","iopub.status.idle":"2020-09-24T01:22:35.190295Z","shell.execute_reply":"2020-09-24T01:22:35.189765Z"},"id":"c26juK7ZG8j-","trusted":true},"cell_type":"code","source":"def build_and_compile_model(norm):\n  model = keras.Sequential([\n      norm,\n      layers.Dense(64, activation='relu'),\n      layers.Dense(64, activation='relu'),\n      layers.Dense(1)\n  ])\n\n  model.compile(loss='mean_absolute_error',\n                optimizer=tf.keras.optimizers.Adam(0.001))\n  return model","execution_count":null,"outputs":[]},{"metadata":{"id":"7T4RP1V36gVn"},"cell_type":"markdown","source":"### One variable"},{"metadata":{"id":"xvu9gtxTZR5V"},"cell_type":"markdown","source":"Start with a DNN model for a single input: \"Horsepower\""},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:35.198946Z","iopub.status.busy":"2020-09-24T01:22:35.19794Z","iopub.status.idle":"2020-09-24T01:22:35.23255Z","shell.execute_reply":"2020-09-24T01:22:35.233005Z"},"id":"cGbPb-PHGbhs","trusted":true},"cell_type":"code","source":"dnn_superplasticizer_model = build_and_compile_model(superplasticizer_normalizer)","execution_count":null,"outputs":[]},{"metadata":{"id":"Sj49Og4YGULr"},"cell_type":"markdown","source":"This model has quite a few more trainable parameters than the linear models."},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:35.240094Z","iopub.status.busy":"2020-09-24T01:22:35.239015Z","iopub.status.idle":"2020-09-24T01:22:35.241924Z","shell.execute_reply":"2020-09-24T01:22:35.242423Z"},"id":"ReAD0n6MsFK-","trusted":true},"cell_type":"code","source":"dnn_superplasticizer_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"id":"0-qWCsh6DlyH"},"cell_type":"markdown","source":"Train the model:"},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:35.248393Z","iopub.status.busy":"2020-09-24T01:22:35.247444Z","iopub.status.idle":"2020-09-24T01:22:38.332111Z","shell.execute_reply":"2020-09-24T01:22:38.331487Z"},"id":"sD7qHCmNIOY0","trusted":true},"cell_type":"code","source":"%%time\nhistory = dnn_superplasticizer_model.fit(\n    train_features['superplasticizer'], train_labels,\n    validation_split=0.2,\n    verbose=0, epochs=100)","execution_count":null,"outputs":[]},{"metadata":{"id":"dArGGxHxcKjN"},"cell_type":"markdown","source":"This model does slightly better than the linear-horsepower model."},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:38.345721Z","iopub.status.busy":"2020-09-24T01:22:38.34514Z","iopub.status.idle":"2020-09-24T01:22:38.478351Z","shell.execute_reply":"2020-09-24T01:22:38.478896Z"},"id":"NcF6UWjdCU8T","trusted":true},"cell_type":"code","source":"plot_loss(history)","execution_count":null,"outputs":[]},{"metadata":{"id":"TG1snlpR2QCK"},"cell_type":"markdown","source":"If you plot the predictions as a function of `Horsepower`, you'll see how this model takes advantage of the nonlinearity provided by the hidden layers:"},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:38.483141Z","iopub.status.busy":"2020-09-24T01:22:38.482537Z","iopub.status.idle":"2020-09-24T01:22:38.558542Z","shell.execute_reply":"2020-09-24T01:22:38.557806Z"},"id":"hPF53Rem14NS","trusted":true},"cell_type":"code","source":"x = tf.linspace(2, 50, 10)\ny = dnn_superplasticizer_model.predict(x)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:38.568501Z","iopub.status.busy":"2020-09-24T01:22:38.566181Z","iopub.status.idle":"2020-09-24T01:22:38.711703Z","shell.execute_reply":"2020-09-24T01:22:38.712188Z"},"id":"rsf9rD8I17Wq","trusted":true},"cell_type":"code","source":"plot_superplasticizer(x, y)","execution_count":null,"outputs":[]},{"metadata":{"id":"WxCJKIUpe4io"},"cell_type":"markdown","source":"Collect the results on the test set, for later:"},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:38.716754Z","iopub.status.busy":"2020-09-24T01:22:38.716153Z","iopub.status.idle":"2020-09-24T01:22:38.760061Z","shell.execute_reply":"2020-09-24T01:22:38.759346Z"},"id":"bJjM0dU52XtN","trusted":true},"cell_type":"code","source":"test_results['dnn_superplasticizer_model'] = dnn_superplasticizer_model.evaluate(\n    test_features['superplasticizer'], test_labels,\n    verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"id":"S_2Btebp2e64"},"cell_type":"markdown","source":"### Full model"},{"metadata":{"id":"aKFtezDldLSf"},"cell_type":"markdown","source":"If you repeat this process using all the inputs it slightly improves the performance on the validation dataset."},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:38.768817Z","iopub.status.busy":"2020-09-24T01:22:38.768076Z","iopub.status.idle":"2020-09-24T01:22:38.804752Z","shell.execute_reply":"2020-09-24T01:22:38.805194Z"},"id":"c0mhscXh2k36","trusted":true},"cell_type":"code","source":"dnn_model = build_and_compile_model(normalizer)\ndnn_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:38.810864Z","iopub.status.busy":"2020-09-24T01:22:38.810234Z","iopub.status.idle":"2020-09-24T01:22:41.86598Z","shell.execute_reply":"2020-09-24T01:22:41.865426Z"},"id":"CXDENACl2tuW","trusted":true},"cell_type":"code","source":"%%time\n\n\nhistory = dnn_model.fit(\n    train_features, train_labels,\n    validation_split=0.2,\n    verbose=0, epochs=100)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:41.879402Z","iopub.status.busy":"2020-09-24T01:22:41.87808Z","iopub.status.idle":"2020-09-24T01:22:42.012803Z","shell.execute_reply":"2020-09-24T01:22:42.013367Z"},"id":"-9Dbj0fX23RQ","trusted":true},"cell_type":"code","source":"plot_loss(history)","execution_count":null,"outputs":[]},{"metadata":{"id":"hWoVYS34fJPZ"},"cell_type":"markdown","source":"Collect the results on the test set:"},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:42.018406Z","iopub.status.busy":"2020-09-24T01:22:42.01768Z","iopub.status.idle":"2020-09-24T01:22:42.066235Z","shell.execute_reply":"2020-09-24T01:22:42.065635Z"},"id":"-bZIa96W3c7K","trusted":true},"cell_type":"code","source":"test_results['dnn_model'] = dnn_model.evaluate(test_features, test_labels, verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"id":"uiCucdPLfMkZ"},"cell_type":"markdown","source":"## Performance"},{"metadata":{"id":"rDf1xebEfWBw"},"cell_type":"markdown","source":"Now that all the models are trained check the test-set performance and see how they did:"},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:42.075989Z","iopub.status.busy":"2020-09-24T01:22:42.075266Z","iopub.status.idle":"2020-09-24T01:22:42.078596Z","shell.execute_reply":"2020-09-24T01:22:42.077963Z"},"id":"e5_ooufM5iH2","trusted":true},"cell_type":"code","source":"pd.DataFrame(test_results, index=['Mean absolute error [csMPa]']).T","execution_count":null,"outputs":[]},{"metadata":{"id":"DABIVzsCf-QI"},"cell_type":"markdown","source":"These results match the validation error seen during training."},{"metadata":{"id":"ft603OzXuEZC"},"cell_type":"markdown","source":"### Make predictions\n\nFinally, predict have a look at the errors made by the model when making predictions on the test set:"},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:42.084155Z","iopub.status.busy":"2020-09-24T01:22:42.083532Z","iopub.status.idle":"2020-09-24T01:22:42.271958Z","shell.execute_reply":"2020-09-24T01:22:42.271363Z"},"id":"Xe7RXH3N3CWU","trusted":true},"cell_type":"code","source":"test_predictions = dnn_model.predict(test_features).flatten()\n\na = plt.axes(aspect='equal')\nplt.scatter(test_labels, test_predictions)\nplt.xlabel('True Values [csMPa]')\nplt.ylabel('Predictions [csMPa]')\nlims = [0, 50]\nplt.xlim(lims)\nplt.ylim(lims)\n_ = plt.plot(lims, lims)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"19wyogbOSU5t"},"cell_type":"markdown","source":"It looks like the model predicts reasonably well. \n\nNow take a look at the error distribution:"},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:42.28694Z","iopub.status.busy":"2020-09-24T01:22:42.284769Z","iopub.status.idle":"2020-09-24T01:22:42.434968Z","shell.execute_reply":"2020-09-24T01:22:42.435375Z"},"id":"f-OHX4DiXd8x","trusted":true},"cell_type":"code","source":"error = test_predictions - test_labels\nplt.hist(error, bins=25)\nplt.xlabel('Prediction Error [csMPa]')\n_ = plt.ylabel('Count')","execution_count":null,"outputs":[]},{"metadata":{"id":"KSyaHUfDT-mZ"},"cell_type":"markdown","source":"If you're happy with the model save it for later use:"},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:42.441835Z","iopub.status.busy":"2020-09-24T01:22:42.441026Z","iopub.status.idle":"2020-09-24T01:22:42.950867Z","shell.execute_reply":"2020-09-24T01:22:42.950174Z"},"id":"4-WwLlmfT-mb","trusted":true},"cell_type":"code","source":"dnn_model.save('model')","execution_count":null,"outputs":[]},{"metadata":{"id":"Benlnl8UT-me"},"cell_type":"markdown","source":"If you reload the model, it gives identical output:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test_features)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:42.958269Z","iopub.status.busy":"2020-09-24T01:22:42.957475Z","iopub.status.idle":"2020-09-24T01:22:43.460604Z","shell.execute_reply":"2020-09-24T01:22:43.461103Z"},"id":"dyyyj2zVT-mf","trusted":true},"cell_type":"code","source":"reloaded = tf.keras.models.load_model('model')\n\ntest_results['reloaded'] = reloaded.evaluate(\n    test_features, test_labels, verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_data=train_features[:1].copy()\nnew_data=new_data.replace([500.0, 0.0, 0.0, 200.0,0.0,1125.0,613.0,3],[498.0, 0.0, 0.0, 200.0,0.0,1125.0,613.0,4])\npredict=reloaded.predict(new_data)\nprint(predict)\nprint(new_data)\ntf.keras.utils.plot_model(\n    reloaded, to_file='model.png', show_shapes=False, show_layer_names=True,\n    rankdir='TB', expand_nested=False, dpi=96)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-09-24T01:22:43.469882Z","iopub.status.busy":"2020-09-24T01:22:43.469205Z","iopub.status.idle":"2020-09-24T01:22:43.471446Z","shell.execute_reply":"2020-09-24T01:22:43.471949Z"},"id":"f_GchJ2tg-2o","trusted":true},"cell_type":"code","source":"pd.DataFrame(test_results, index=['Mean absolute error [c]']).T","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}