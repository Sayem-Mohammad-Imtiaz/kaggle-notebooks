{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diabetes_data = pd.read_csv(\"/kaggle/input/pima-indians-diabetes-database/diabetes.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diabetes_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diabetes_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diabetes_data.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot the data in graph\n\ndiabetes_data_plot = diabetes_data.hist(figsize=(20,20))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diabetes_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(10,5))\n\ndiabetes_data_heatmap = sns.heatmap(diabetes_data.corr(),annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# normalize the data\nfrom sklearn.preprocessing import StandardScaler\n\ndiabetes_data_scaler = StandardScaler()\n\nX_data = pd.DataFrame(diabetes_data_scaler.fit_transform(diabetes_data.drop([\"Outcome\"],axis = 1),),\n                     columns=['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n       'BMI', 'DiabetesPedigreeFunction', 'Age'])\nY_data = diabetes_data[\"Outcome\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# splitting our data into training and testing data\n\nfrom sklearn.model_selection import train_test_split\n\nX_train,X_test,Y_train,Y_test = train_test_split(X_data,Y_data,test_size=1/3,random_state=42,stratify=Y_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score,recall_score,roc_auc_score,f1_score,precision_score,confusion_matrix\n\ndef evaluation_model(Y_test,Y_prediction):\n    \n    accuracy = accuracy_score(Y_test,Y_prediction)\n    recall_scr = recall_score(Y_test,Y_prediction)\n    f1_scr = f1_score(Y_test,Y_prediction)\n    auc_score = roc_auc_score(Y_test,Y_prediction)\n    precision_scr = precision_score(Y_test,Y_prediction)\n    \n    accuracy_metrics = {\"accuracy score \":round(accuracy,3),\n                       \"recall score \": round(recall_scr,3),\n                       \"f1_score \":round(f1_scr,3),\n                       \"roc_auc_score \": round(auc_score,3),\n                       \"precision score \":round(precision_scr,3)}\n    \n    return print(accuracy_metrics)\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we are gonna use knn to see the model accuracy\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier()\nknn_fit = knn.fit(X_train,Y_train)\nknn_prediction = knn.predict(X_test)\nknn_score = knn.score(X_test,Y_test)\nevaluation_model(Y_test,knn_prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neighbors  = range(1,16)\n\nknn = KNeighborsClassifier()\n\nfor i in neighbors:\n    knn.set_params(n_neighbors = i) # setting number of nearest neighbors\n     \n    # Fit the algorithm\n    print(f\"Accuracy with {i} neighbors is -->  {round(knn.fit(X_train,Y_train).score(X_test,Y_test),3)} %\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we see that we get the highest accuracy with 11 neighbors\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors = 11)\nknn_fit = knn.fit(X_train,Y_train)\nknn_prediction = knn.predict(X_test)\nknn_score = knn.score(X_test,Y_test)\nevaluation_model(Y_test,knn_prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}