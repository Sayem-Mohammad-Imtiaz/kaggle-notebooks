{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction"},{"metadata":{},"cell_type":"markdown","source":"[Fairseq](https://github.com/pytorch/fairseq/tree/master/examples/bart) is a sequence modeling toolkit that allows researchers and developers to train custom models for translation, summarization, language modeling and other text generation tasks."},{"metadata":{},"cell_type":"markdown","source":"# BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"},{"metadata":{},"cell_type":"markdown","source":"[BART](https://github.com/pytorch/fairseq/tree/master/examples/bart) is sequence-to-sequence model trained with denoising as pretraining objective. We show that this pretraining objective is more generic and show that we can match RoBERTa Results on SQuAD and GLUE and gain state-of-the-art results on summarization (XSum, CNN dataset), long form generative question answering (ELI5) and dialog response genration (ConvAI2). See the associated paper for more details."},{"metadata":{},"cell_type":"markdown","source":"# Setup"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# !pip install fairseq","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Make evaluation dataset from .csv files"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"# import pandas as pd\n# df_summary = pd.read_csv(\"../input/news-summary/news_summary_more.csv\")\n# news_txt = df_summary['text']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# with open('/kaggle/working/news_text.txt','w') as save_txt:\n#     for i in range(100):\n#         save_txt.write(news_txt[i].strip()+'\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load model for evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import torch\n\n# bart = torch.hub.load('pytorch/fairseq', 'bart.large.cnn')\n# bart.cuda()\n# bart.eval()\n# bart.half()\n# count = 1\n# bsz = 32","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# with open('/kaggle/working/news_text.txt') as source, open('/kaggle/working/test.hypo', 'w') as fout:\n#     sline = source.readline().strip()\n#     slines = [sline]\n#     for sline in source:\n#         if count % bsz == 0:\n#             with torch.no_grad():\n#                 hypotheses_batch = bart.sample(slines, beam=4, lenpen=2.0, max_len_b=140, min_len=55, no_repeat_ngram_size=3)\n\n#             for hypothesis in hypotheses_batch:\n#                 fout.write(hypothesis + '\\n')\n#                 fout.flush()\n#             slines = []\n\n#         slines.append(sline.strip())\n#         count += 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Save generated summary and store as *\"test.hypo\"* file"},{"metadata":{"trusted":true},"cell_type":"code","source":"# with open('/kaggle/working/news_text.txt', 'r') as fout:\n#     src=fout.readlines()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# with open('/kaggle/working/test.hypo', 'r') as fout:\n#     s=fout.readlines()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# i=12\n# print('Source text:'+'\\n'+src[i])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print('Summary text:'+'\\n'+s[i])\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}