{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Introduction**\n\nReally simple introduction into Voting Classifiers. The final model achieves a 98% accuracy. "},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd \nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\nfrom sklearn.decomposition import PCA as sklearnPCA\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.utils.multiclass import unique_labels\nimport os\nprint(os.listdir(\"../input\"))\n\n# Model selection and optimization was done outside of this kernel!","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/data.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.diagnosis = [1 if each == \"M\" else 0 for each in data.diagnosis]\ndata.drop(['Unnamed: 32',\"id\"], axis=1, inplace=True)\nY = data.diagnosis.values\nx_data = data.drop(['diagnosis'], axis=1)\nscaler = StandardScaler()\nX = scaler.fit_transform(x_data)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X, test_X, train_y, test_y = train_test_split(X, Y, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Instansiate models\ntree = DecisionTreeClassifier(random_state=1)\nsvm = SVC(probability=True, kernel='linear', C=1, gamma = 0.001)\nlog = LogisticRegression(random_state=0, solver='liblinear', \n                         multi_class='ovr')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eclf = VotingClassifier(estimators=[\n     ('tree', tree), ('svm', svm), ('log', log)\n], voting='soft')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"eclf.fit(train_X, train_y)\npred_y = eclf.predict(test_X)\naccuracy_score(test_y, pred_y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Results of the voting classifier model are **97.9%**. \n\nFor a more complete view of model performance, I have included both the regular and normalized matrices below. "},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def plot_confusion_matrix(y_true, y_pred, classes,\n                          normalize=False,\n                          title=None,\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if not title:\n        if normalize:\n            title = 'Normalized confusion matrix'\n        else:\n            title = 'Confusion matrix, without normalization'\n\n    # Compute confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    # Only use the labels that appear in the data\n    classes = ['Malignant', 'Benign']\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    fig, ax = plt.subplots()\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    # We want to show all ticks...\n    ax.set(xticks=np.arange(cm.shape[1]),\n           yticks=np.arange(cm.shape[0]),\n           # ... and label them with the respective list entries\n           xticklabels=classes, yticklabels=classes,\n           title=title,\n           ylabel='True label',\n           xlabel='Predicted label')\n\n    # Rotate the tick labels and set their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n\n    # Loop over data dimensions and create text annotations.\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    return ax\n\nnp.set_printoptions(precision=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot non-normalized confusion matrix\nplot_confusion_matrix(test_y, pred_y, classes=['Malignant', 'Benign'],\n                      title='Confusion matrix, without normalization')\n\n# Plot normalized confusion matrix\nplot_confusion_matrix(test_y, pred_y, classes=['Malignant', 'Benign'], normalize=True,\n                      title='Normalized confusion matrix')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"nbformat":4,"nbformat_minor":1}