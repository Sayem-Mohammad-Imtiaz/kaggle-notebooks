{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"# Diabetes Prediction\n\n## Logistic regression fit with classification performance analysis, e.g. ROC curve\n\n*with some explanations*"},{"metadata":{},"cell_type":"markdown","source":"### Importing Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\n\nimport seaborn as sns\n\nimport statsmodels.api as sm\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score, roc_curve, plot_roc_curve","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loading Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/diabetes-dataset/diabetes2.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* If Outcome is 1,then person has diabetes.\n* If Outcome is 0,then person has not diabetes."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Preparation and pre-processing\n\n  - define endogene and exogene data \n  - split data to clealy separate train and test sub-population\n  - scale data for prediction\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.iloc[:,:-1]\ny = df.iloc[:,-1]\n\nx_names = X.columns\ny_name = y.name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_X_train, df_X_test, y_train, y_test = train_test_split(X, y,test_size=0.25, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sc = StandardScaler()\nX_train = sc.fit_transform(df_X_train)\nX_test = sc.transform(df_X_test)\n\n# # what means scaling?\ndisplay(\n    df_X_train.describe(),\n    # mean -> 0, std.dev. -> 1\n    pd.DataFrame(data=X_train, index=df_X_train.index, columns=df_X_train.columns).describe()\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_index = y_train.index\ntest_index = y_test.index","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plotting Data - Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"if False: # takes some time\n# if True: \n    _ = sns.pairplot(hue=y_name, data=df.loc[train_index]) #, kind='reg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_, axs = plt.subplots(1, 2, figsize=(14, 6))\n\nfor i, X in enumerate([df_X_train, df_X_test]):\n    with sns.axes_style(\"white\"):\n        corr = X.corr()\n        mask = np.zeros_like(corr)\n        mask[np.triu_indices_from(mask)] = True\n        sns.heatmap(corr, robust=True, cmap='viridis', mask=mask, ax=axs[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model: fit and predict"},{"metadata":{},"cell_type":"markdown","source":"#### using `statsmodels`"},{"metadata":{"trusted":true},"cell_type":"code","source":"logit_model = sm.Logit(y_train, X_train)\n\nresult = logit_model.fit()\n\nresult.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_proba_sm = result.predict()\ny_pred_sm = (y_pred_proba_sm > 0.5).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = df_X_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_, axs = plt.subplots(2, len(cols)//2, figsize=(14, 6), tight_layout=True)\nfor i, col in enumerate(cols):\n    ax = axs[i % 2][i // 2]\n    df_X_train.join(y_train).plot.scatter(x=col, y='Outcome', ax=ax)\n    ax.plot(df_X_train[col], y_pred_proba_sm, '.c')\n    ax.plot(df_X_train[col], y_pred_sm, '.r')\n    ax.set_title(f'x{i+1}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### using `sklearn`\n\nand make use of train and test split"},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\nlogreg.coef_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = logreg.predict(X_test)\ny_pred_proba = logreg.predict_proba(X_test)[:, 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_, axs = plt.subplots(2, len(cols)//2, figsize=(14, 6), tight_layout=True)\nfor i, col in enumerate(cols):\n    ax = axs[i % 2][i // 2]\n    df_X_test.join(y_test).plot.scatter(x=col, y='Outcome', ax=ax)\n    ax.plot(df_X_test[col], y_pred_proba, '.c')\n    ax.plot(df_X_test[col], y_pred, '.r')\n    ax.set_title(f'coef #{i+1}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Confusion Matrix, accuracy score and classification report"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n\nconfusion_matrix_result = confusion_matrix(y_test, y_pred)\naccuracy_score_result = accuracy_score(y_test,y_pred)\nclassification_report_result = classification_report(y_test, y_pred)\n\ndisplay(\n    confusion_matrix_result,\n    accuracy_score_result,\n)\n\nprint(classification_report_result)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### understanding the classification performance"},{"metadata":{"trusted":true},"cell_type":"code","source":"support_0 = confusion_matrix_result[0, :].sum()\nsupport_1 = confusion_matrix_result[1, :].sum()\ncnt_pred_0 = confusion_matrix_result[:, 0].sum()\ncnt_pred_1 = confusion_matrix_result[:, 1].sum()\n\ndisplay(\n    f'support of \"0\" -> {support_0}',\n    f'support of \"1\" -> {support_1}',\n    # Negative Predicitve Value\n    f'precision of \"0\" = NPV -> {confusion_matrix_result[0, 0] / cnt_pred_0 :.2f}',\n    # Positive Predicitive Value\n    f'precision of \"1\" = PPV -> {confusion_matrix_result[1, 1] / cnt_pred_1 :.2f}',\n    # True Negative Rate, specificity\n    f'recall of \"0\" = TNR -> {confusion_matrix_result[0, 0] / support_0 :.2f}',\n    # True Positive Rate, sensitivity\n    f'recall of \"1\" = TPR -> {confusion_matrix_result[1, 1] / support_1 :.2f}',\n    # False Negative Rate, misses\n    f'FNR = 1 - TPR -> {confusion_matrix_result[1, 0] / support_1 :.2f}',\n    # False Positive Rate, fall-out\n    f'FPR = 1 - TNR -> {confusion_matrix_result[0, 1] / support_0 :.2f}',\n)\n\nfit_FPR = confusion_matrix_result[0, 1] / support_0\nfit_TPR = confusion_matrix_result[1, 1] / support_1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ROC curve (variant 1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"logit_roc_auc = roc_auc_score(y_test, y_pred_proba)\nfpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n\nfig, axs = plt.subplots(2, 1, sharex=True, figsize=(6, 8), tight_layout=True)\nax = axs[0]\nax.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\nax.plot([0, 1], [0, 1],'k:')\nax.plot(fit_FPR, fit_TPR, 'ro')\nax.set_xlim([0.0, 1.0])\nax.set_ylim([0.0, 1.05])\nax.set_ylabel('True Positive Rate')\nax.set_title('Receiver Operating Characteristic')\nax.legend(loc=\"lower right\")\n\n# index of 0.5 threshold\nidx_thres_05 = np.where(thresholds <= 0.5)[0][0]\n\nax = axs[1]\nax.plot(fpr, thresholds)\nax.axvline(fpr[idx_thres_05], color='r', ls=':')\nax.set_ylim(0, 1)\nax.set_title('Thresholds')\nax.set_xlabel('False Positive Rate')\n\nfig.savefig('Log_ROC')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ROC curve (variant 2)\n\nusing `plot_roc_curve`"},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = plt.figure().gca()\n_ = plot_roc_curve(logreg, X_test, y_test, ax=ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### ToDo\neventually extend with cross validation like [scikit-learn.org/stable/auto_examples/model_selection/plot_roc_crossval.html](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc_crossval.html)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}