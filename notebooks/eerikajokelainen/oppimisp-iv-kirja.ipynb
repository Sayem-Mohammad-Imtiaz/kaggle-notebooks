{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Oppimispäiväkirja 1:\n\nJohdanto datatieteeseen 2021 oppimispäiväkirja. Ensimmäinen luento tällä kurssilla alkoi johdatuksella kurssin aiheeseen sekä ohjeisiin (oppimispäiväkirja ja harjoitustyö). Osallistuin reaaliaikaisesti ensimmäiselle luennolle, koska se töiden puolesta sopi aikatauluihin. Aineistona tässä oppimispäiväkirjassa käytän pitkälti luentoaineistoa, koska se oli kattava ja selkeä. Eli lähtökohtaisesti käsittelemäni asiat oppimispäiväkirjassa pohjautuvat luennoitsijan materiaaliin ellen toisin mainitse. \n\nLuennon pääteemat olivat datatieteen käsittelyssä eli siinä, miten datatiede määritellään, missä sitä tarvitaan ja millaiset tulevaisuuden näkymät \"alalla\" on. Datatiede koostuu neljästä eri kokonaisuudesta, jotka luennolla määriteltiin seuraaviksi: liiketoimintaosaaminen, ohjelmointi- ja tietokantaosaaminen, tilastollinen analyysi sekä datalähtöinen visualisointi. CRISP-DM -malli oli myös yksi ensimmäisellä luennolla käsitellyistä aiheista. Malli esittää prosessikuvauksen datatieteen prosesseista, mikä koostuu seuraavista kohdista: data - business understanding <-> dataunderstanding - data preparation - modeling- evaluation -deployment. \"Dataunderstanding\" tuntuu itselle ehkä näistä kaikista vieraammalta ja toivon, että kurssin aikana opin tästä lisää eli kuinka ymmärstää paremmin dataa. Monesti datan käsittely jää hyvin pintapuoliseksi,jolloin syvällinen ymmärrys sen käyttömahdollisuuksista heikkenee. Lisäksi käsiteltävinä aiheina olivat datan määrän suuri kasvu ja sen käsittely - nykyisen datan käsittely ja tekoäly painottuu koneoppimiseen. Teemana koneoppiminen ei ollut itselle aikaisemmin yhtään tuttua, vaikka termiä paljon kuuleekin. Luulen, että tästä luentokerrasta eniten minulle käteen jäi se, kuinka paljon oikeasti dataa on ja miten sen \"oikeanlainen\" käsittely voi tuoda haluttuja lopputuloksia etenkin liike-elämässä, joka itselleni on tärkeä teema opiskelujen ja työn kannalta.\n\nKäytin aikaa aika paljon alussa näiden eri ohjelmien asentamiseen, sekä ensimmäiset koodien toimintaan saamiseksi. Katsoin myös Youtubesta videoita, jotta pääsin alkuun. Anacondasin sivuilta löysin myös ohjevideon Anacondan lataamiseen, joka helpotti huomattavan paljon. Myös Kaggle tuli ensimmäistä kertaa tutuksi ja siellä oli datan lisäksi hyviä opetusvinkkejä Pythonin käyttöön. Kuitenkin datan tuominen sellaisessa muodossa, että pystyn alkaa tekemään siitä data-analyysiä ei ainakaan vielä onnistunut tässä vaiheessa, joten sitä pitää harjoitella. \n\nTärkeimmät \"oivallukset\" luentokerralta:\n- Jupyter Notebook, jonka päätin ottaa käyttöön ensimmäistä kertaa\n- Datan suuri määrä ja se, kuinka sitä voidaan käsitellä\n- Erilaiset työtehtävät datan parissa (Data Scientist tms.)\n- CRISP-DM -malli oli täysin uusi termi itselleni\n- Hans Roslingin video oli hyvin mielenkiintoinen ja avasi omat silmät\n\n\"Parannusaiheita\" on hankala keksiä, mielestäni luentoa oli mukava kuunnella ja pysyi suhteellisen hyvin kärryillä. Ehkä sellainen parannusehdotus, että kaikki uudet järjestelmät eivät olleet itselleni tuttuja ennestään, joten ne vähän sekottivat alkuun. Toisaalta oma pohjatietoni ei kurssille vastaa vaadittua, joten sikäli ymmärrän, että aivan \"nollasta\" ei voi lähteä liikkeelle. Toinen parannusehdotus on, että mielestäni luentomateriaalit ovat hyvin hajanaisesti eri paikoissa, joka hankaloittaa vähän tiedonhakua. \n\nKatsoin täältä alkuun ensin apua koodeihin:\nhttps://dev.socrata.com/blog/2016/02/01/pandas-and-jupyter-notebook.html \n-> olen katsonut täältä, koska oma lähtötasoni on aivan aloittelija, joten siksi päädyin katsomaan \"valmiita\" materiaaleja aluksi. Kyseisellä sivustolla on perus tilastolliseen analyysiin liittyviä koodeja ja ohjeita, jotka mielestäni olivat selkeitä.\n-> lisäksi osan koodeista olen katsonut demo-klinkan materiaaleista, ja koin sen ihan hyödylliseksi. En ennen tätä tiennyt, kuin print ('hello world'), ja nyt ainakin jollain tasolla ymmärsin import, print (head) ja muut perus käskyt, joiden avulla pääsin alkuun. \n-> data on peräisin Kagglesta, jossa käsitellään ETF Fundeja. \n","metadata":{}},{"cell_type":"code","source":"print ('hello world')","metadata":{"execution":{"iopub.status.busy":"2021-05-28T14:01:42.304729Z","iopub.execute_input":"2021-05-28T14:01:42.305434Z","iopub.status.idle":"2021-05-28T14:01:42.317507Z","shell.execute_reply.started":"2021-05-28T14:01:42.305304Z","shell.execute_reply":"2021-05-28T14:01:42.316648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print ('mita kuuluu')","metadata":{"execution":{"iopub.status.busy":"2021-08-24T08:49:00.634999Z","iopub.execute_input":"2021-08-24T08:49:00.635382Z","iopub.status.idle":"2021-08-24T08:49:00.641523Z","shell.execute_reply.started":"2021-08-24T08:49:00.635339Z","shell.execute_reply":"2021-08-24T08:49:00.640141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nprint(pd.__version__)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T08:48:58.432264Z","iopub.execute_input":"2021-08-24T08:48:58.432664Z","iopub.status.idle":"2021-08-24T08:48:58.438198Z","shell.execute_reply.started":"2021-08-24T08:48:58.43263Z","shell.execute_reply":"2021-08-24T08:48:58.436878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Declare the libraries that will be used\nimport pandas as pd\n# Used to plot the results\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\nstyle.use('ggplot')","metadata":{"execution":{"iopub.status.busy":"2021-08-25T10:54:52.484001Z","iopub.execute_input":"2021-08-25T10:54:52.484502Z","iopub.status.idle":"2021-08-25T10:54:52.505106Z","shell.execute_reply.started":"2021-08-25T10:54:52.484337Z","shell.execute_reply":"2021-08-25T10:54:52.503967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2021-08-25T10:54:58.525304Z","iopub.execute_input":"2021-08-25T10:54:58.525806Z","iopub.status.idle":"2021-08-25T10:54:58.576748Z","shell.execute_reply.started":"2021-08-25T10:54:58.525762Z","shell.execute_reply":"2021-08-25T10:54:58.575743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/mutual-funds-and-etfs/ETFs.csv')\ndf.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T08:49:06.137553Z","iopub.execute_input":"2021-08-24T08:49:06.137969Z","iopub.status.idle":"2021-08-24T08:49:06.31032Z","shell.execute_reply.started":"2021-08-24T08:49:06.137931Z","shell.execute_reply":"2021-08-24T08:49:06.309537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df.dtypes)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T08:49:21.672169Z","iopub.execute_input":"2021-08-24T08:49:21.672792Z","iopub.status.idle":"2021-08-24T08:49:21.680609Z","shell.execute_reply.started":"2021-08-24T08:49:21.672726Z","shell.execute_reply":"2021-08-24T08:49:21.679454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2021-08-24T08:49:26.331947Z","iopub.execute_input":"2021-08-24T08:49:26.332456Z","iopub.status.idle":"2021-08-24T08:49:26.378432Z","shell.execute_reply.started":"2021-08-24T08:49:26.332419Z","shell.execute_reply":"2021-08-24T08:49:26.377451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"caps = lambda x: x.upper()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T14:01:42.651139Z","iopub.execute_input":"2021-05-28T14:01:42.651636Z","iopub.status.idle":"2021-05-28T14:01:42.656511Z","shell.execute_reply.started":"2021-05-28T14:01:42.651593Z","shell.execute_reply":"2021-05-28T14:01:42.655388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"caps ('moi')","metadata":{"execution":{"iopub.status.busy":"2021-05-28T14:01:42.657973Z","iopub.execute_input":"2021-05-28T14:01:42.658535Z","iopub.status.idle":"2021-05-28T14:01:42.670462Z","shell.execute_reply.started":"2021-05-28T14:01:42.658495Z","shell.execute_reply":"2021-05-28T14:01:42.669478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Oppimispäiväkirja 2. \n\nTällä kerralla luennon aiheena oli datan kerääminen ja jalostaminen. En päässyt osallistumaan reaaliaikaisesti opetukseen, koska olin töissä mutta katsoin luennon jälkeenpäin itse. Pääasiassa käytän hyväksi Jupyter Notebookissa ollutta materiaalia eli materiaalia, mitä luennoitsija on koonnut luennolle. Mikäli käytän muuta materiaalia, ilmoitan siitä erikseen. Lisäksi katsoin jälkikäteen demo-klinikan videon, koska töiden vuoksi en sitäkään pystynyt katsomaan oikeassa aikataulussa. Katsoin heti alussa myös Datacampin linkin, jossa oli hyvin selkeästi selitetty käskyt, joita Pythonilla voidaan käyttään. Luulen, että tämä auttaa ainakin tulevaisuudessa, sillä käskyt ovat itselläni tässä vaiheessa edelleen aika hukassa. \n\nData Science Workflow artikkeli oli ihan mielenkiintoinen ja se käytiin myös luennolla läpi hyvin. Datan siivoamiseen käytettävä aika yllätti ehkä itseni, ja se olikin hyvä nosto. Luennolla käytiin läpi myös datatieteenprosessi, joka jakautuu seuraaviin päävaiheisiin: tiedon esikäsittely, vuoropuhelu analyysin ja reflektion välillä ja lopputulosten viestiminen vastaanottajalle soveltuvassa muodossa. Tutuin vaihe itselleni näistä on viimeinen, eli vastaanottajalle viestiminen. Tiedon esikäsittely on vaikeampaa, koska en omaa tällä hetkellä ainakaan vielä sellaisia taitoja, joiden avulla osaisin käsitellä erityisen paljon tietoa alussa. Mielenkiintoista oli se, kuinka dataa ja tietoa voidaan hyödyntää liike-elämässä, koska se on itselleni läheinen aihe. Aika pienessä osassa yrityksistä on oma data-analytiikan tiimi, joka varmasti näkyy siinä, että dataa ei osata yrityksissä hyödyntää täysissä määrin ja oikein. \n\nHarward Business Reviewin artikkeli siitä, että datatieteen tiimit tarvitsevat \"generalisteja\", ei vain \"specialisteja\" oli mielenkiintoinen. Poiketen yleisestä ajatuksesta, että pitäisi olla erikoistunut yhteen tiettyyn aihealueeseen haastetaan kyseisessä artikkelissa. Myös artikkelin perustelut siitä, miksi näin olivat mielenkiintoisia. Etenkin datatieteen parissa oppiminen on jatkuvaa ja ehkä siksi myös kokonaisuuksien hahmottaminen suuressa määrin on tärkeää - tai näin ainakin itse ajattelen asiasta. Itsestä kuitenkin tuntuu siltä, että yritykset silti etsivät \"specialisteja\" tai olettavat tämän osaavan kaikki järjestelmät tai monet järjestelmät asiantuntijan tavoin. Ehkä tärkeämpää on se, että henkilö tietää, missä kohti mitäkin on järkevää käyttää ja mitä eri järjestelmillä voidaan tehdä. Toki uskon siltikin, että datatieteen tiimit tarvitsevat kovan luokan asiantuntijoita juuri yhden osa-alueen osalta, mutta siksi juuri tiimissä onkin hyvä olla erilaisia henkilöitä. \n\nRyömijät ja raapijat olivat termeinä tässä yhteydessä itselleni uusia. Siihen liittyvät koodit vaikuttivat hieman monimutkaisilta. Verkkokauppa.com esimerkki luennolla havainnollisti kuitenkin niiden käyttöä hyvin, mutta en usko, että tällä hetkellä itse osaisin hyödyntää niitä millään tavalla. Tämä kuitenkin avasi silmiäni, mitä kaikkea yritykset voi tehdä tai saatta tehdä, ja mikä on eettisesti ja laillisesti oikein (Power-esimerkki). Lopussa \"alkuohjeet\" Pandasin käyttöön olivat hyvät, koska tuskailin sen kanssa ennen kuin kerkesin katsoa luennon ja diat. Tämä ainakin auttoi siinä, että sain Pandasin käyttöön ja \"yhdistettyä\" Jupyterin kanssa. \n\nTietotekniikkaa opiskeleva kaverini on auttanut jonkin verran alussa ja kertounut esimerkiksi aikaisemmin BeautifulSoup -järjestelmästä. En silloin ymmärtänyt, mitä se meinaa, joten hauska oli huomata, että nämä asiat käytiin nyt luennolla läpi ja ymmärsin ainakin hieman paremmmin, mitä sillä voidaan tehdä. \n\nTärkeimmät oivallukset:\n- Datatieteenprosessi: mitä itse osaan ja mitä en todellakaan osaa\n- Se, kuinka paljon datan siivoamiseen täytyy käyttää aikaa (voisiko tätä prosessia tehostaa jollain tapaa tulevaisuudessa, vaikka datan määrä kasvaa kokoajan)\n- Datan hyödyntäminen liike-elämässä: yritykset hyödyntävät sitä vielä \"liian\" vähän ainakin omasta mielestä -> toivottavasti tulevaisuudessa voin olla vaikuttamassa tähän!\n- Pandas, luentomateriaalit auttoivat ymmärtämään alkuun pääsemisessä Pandasin kanssa\n- Minua kiinnostaa datan hyödyntäminen liiketoiminnassa, mutta ei ehkä suoranaisesti menetelmät tai itse datan esikäsittely\n- Positiivisempi kuva siitä, että voin itsekin opetella käyttämään Pythonia, Jupyterya, Pandasia tms. Aikaisemmin ajattelin, että ne ovat liian vaikeita\n\nParannettavaa ehkä luennolle: olisin voinut tarvita lisäapua raapijoiden ja ryömijöiden kanssa, mutta muuten ei mitään! Verkkokauppa.com esimerkki oli hyvä ja tässä vaiheessa varmaan riittää minulle. ","metadata":{}},{"cell_type":"code","source":"\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-24T08:50:28.101977Z","iopub.execute_input":"2021-08-24T08:50:28.102373Z","iopub.status.idle":"2021-08-24T08:50:28.147035Z","shell.execute_reply.started":"2021-08-24T08:50:28.102333Z","shell.execute_reply":"2021-08-24T08:50:28.145844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print ('moi')","metadata":{"execution":{"iopub.status.busy":"2021-05-28T14:01:42.689326Z","iopub.execute_input":"2021-05-28T14:01:42.689834Z","iopub.status.idle":"2021-05-28T14:01:42.696028Z","shell.execute_reply.started":"2021-05-28T14:01:42.689782Z","shell.execute_reply":"2021-05-28T14:01:42.694955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('1+3=4')","metadata":{"execution":{"iopub.status.busy":"2021-05-28T14:01:42.697942Z","iopub.execute_input":"2021-05-28T14:01:42.698471Z","iopub.status.idle":"2021-05-28T14:01:42.707485Z","shell.execute_reply.started":"2021-05-28T14:01:42.698423Z","shell.execute_reply":"2021-05-28T14:01:42.706479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/climate-change-earth-surface-temperature-data/GlobalLandTemperaturesByCountry.csv')\ndf.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T08:50:33.416733Z","iopub.execute_input":"2021-08-24T08:50:33.417068Z","iopub.status.idle":"2021-08-24T08:50:34.381551Z","shell.execute_reply.started":"2021-08-24T08:50:33.41704Z","shell.execute_reply":"2021-08-24T08:50:34.380316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndf['AverageTemperature'].is_unique","metadata":{"execution":{"iopub.status.busy":"2021-08-24T08:50:38.262125Z","iopub.execute_input":"2021-08-24T08:50:38.262549Z","iopub.status.idle":"2021-08-24T08:50:38.300008Z","shell.execute_reply.started":"2021-08-24T08:50:38.262514Z","shell.execute_reply":"2021-08-24T08:50:38.299093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-08-24T08:50:41.21421Z","iopub.execute_input":"2021-08-24T08:50:41.214649Z","iopub.status.idle":"2021-08-24T08:50:41.223079Z","shell.execute_reply.started":"2021-08-24T08:50:41.214613Z","shell.execute_reply":"2021-08-24T08:50:41.221753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfZone=df[['Country', 'AverageTemperature']]\ndfZone.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T08:50:43.692089Z","iopub.execute_input":"2021-08-24T08:50:43.692915Z","iopub.status.idle":"2021-08-24T08:50:43.716182Z","shell.execute_reply.started":"2021-08-24T08:50:43.692873Z","shell.execute_reply":"2021-08-24T08:50:43.715423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Oppimispäiväkirja 3.\n\nTällä kerralla aiheena oli koneoppiminen. Tämä kerran luennon katsoin myös jälkikäteen, koska töiden puolesta en voinut osallistua reaaliaikaisesti luennolle. Tällä kerralla aiheena oli käydä läpi koneoppimisen perusteita. Luin artikkelin myös siitä, kuinka laadullinen tieto jalostuu laskennalliseksi: piirteet sosiaalisen median analytiikassa. Artikkeli oli silmiä avaava, koska en etukäteen tiennyt, kuinka kehittynyttä koneoppiminen voi olla ja kuinka se tunnistaa esimerkiksi ihmiset kuvasta prosentuaalisella todennäköisyydellä. Myös luennolla lyhyesti läpi käyty esimerkki siitä, että miten koneoppimisen myötä saatetaan olettaa tiettyjä asioita mm. iPhonen ja Androitin käyttäjistä. \n\nKoneoppiminen terminä on kuultu monessa yhteydessä, mutta itselleni sen syvempi ymmärtäminen on jäänyt hieman auki. Luennon aikana ja materiaaleista koneoppiminen terminä avautui hyvin, sekä se, mihin koneoppimistä tarvitaan. Luennolla käytiin läpi myös sitä, kuinka tekoälyn kehitys on jaettu kolmeen eri osaan DARPAn John Launchburyn ehdotuksen mukaan: käsin rakennettuun toteutukseen, tilastolliseen oppimiseen sekä tilanteeseen mukautuvaan oppivaan tekoälyyn. Oli siis ihan mielenkiintoista perehtyä lyhyesti myös tekoälyn kehityksen historiaan sekä vaiheisiin. Viimeinen kohta eli ohjattu oppiminen oli luennolla pääosassa käsittelyä - ja mielestäni se olikin tärkeää, koska uskon näille taidoille olevan kysyntää myös työelämässä. Esimerkiksi luennolla mainittu lineraainen regressio ja sen käyttäminen hintojen tai muiden asioiden ennustamisessa on tärkeä osa mm. analyytikon tehtäviä, joka ainakin itselleni voisi olla mielenkiintoinen urakokeilu. Lineaarista regressiota olen käyttänyt muilla tilasto-ohjelmilla, kuten Statalle, mutta Pythonilla sen tekeminen ja opettelu on pitkässä juoksussa varmasti fiksumpaa. Lisäksi Stata ja muut ns. \"vanhanaikaiset\" tilastoohjelmistot eivät tietääkseni ainakaan pysty samallaisiin toimintoihin kuin Python. \n\nLuennolla käydyt esimerkit puhelinliittymistä ja kuinka uutta \"halvempaa\" liittymää tarjomalla saadaan uusi datapiste, ja tärkeimpänä tietenkina asiakkaan asiakkuuden jatkaminen. Mielestäni tämä avasi hyvin konkreettisesti sitä, missä kaikkialla ja miten koneoppimista käytetään. Minun on itse hankala tarkemmin ottaa kantaa syvällisemmin koneoppimiseen, koska asia on täysin uutta. Esimerkkien avulla aiheesta saa kuitenkin mielenkiintoisemman, sillä ajattelin aikaisemmin sen olevan niin kauaskantoista asiaa, josta minä en voi ymmärtää yhtään mitään. \n\nLuonnollisen kielenanalyysi oli uutta aikalailla kokonaan ja kuulosti monimutkaiselta ainakin siltä osin, että itse osaisin \"koodata\", niin että esimerkiksi osaisin poistaa hukkasanoja. Mutta varmasti tärkeä aihe ja toki hyvä tiedostaa, että tällaiselle on kasvava tarve tulevaisuudessa, kuten luennolla käytiin läpi. \n\nLuennolla käyty malli esimerkki mallista, kannattaako lainaa antaa asiakkaalle oli hyvä ja sai ainakin itseni innostumaan enemmän aiheesta, koska päästiin hieman lähemmäksi kaupallisuutta ja pankkien toimintaa. Tämän kerran luentoesimerkki oli tähän astisista esimerkeistä paras sekä hyödyllisin, toki myös laajin. Käytän tätä varmasti hyödykseni paljon harjoitustyötä tehdessäni ja palaan aiheeseen vielä uudestaan. Pitää myös itse kokeilla mallin tekemistä, jolloin jokainen kohta aukeaa varmasti paremmin. Etsin myös Kagglesta saman tyyppisen aineiston liittyen lainoihin, sekä tutkin muutenkin Kagglen kautta  Sanaselityksiä ei tällä luennolla kauheammin tullut, mutta se ei mielestäni mitään haitannut. Yleisesti koneoppimista käytiin esimerkein läpi, joka on hyvä asia, koska pelkkä termien läpikäyminen ei sinällään opeta kauheasti.\n\nTärkeimmät oivallukset:\n- Koneoppiminen yleisesti ja sen käyttö\n- Teköälyn kehityksen vaiheet\n- Lineaarinen regressio Pythonilla (aikaisemmin tuttu vain Statalla) -> mielenkiinto opetella myös Pythonilla1\n- Luotonanto esimerkki ja oivallukset, miten pankit voivat käyttää vielä enemmän hyödyksi tätä\n- Onko mallin muuttujat merkittäviä vai ei, miten niiden merkittävyyttä tulisi tulkita\n\n+ Mielestäni luennolla oli hyvä nosto siitä, että tällä kurssilla suhtaudutaan dataan optimisesti (ns. niinkuin diplomi-insinöörit, vaikka itse en sellainen olekkaan), suhtaudun kuitenkin positiivisesti ja uskon datan ja teknologian tuovan paljon hyöytyä eri osa-alueille, vaikka en nyt asiantuntija olekkaan\n\nParannettavaa voisi olla \"luentodiojen\" selkeydessä - välillä en aina ihan hahmota kaavioiden ja tekstien ideaa. Siksi joitakin termejä voisi avata enemmän dioissa. Vaikka tietenkin itse luentovideolla asiat avataan hyvin. Myöskään kaikki linkit esimerkiksi asiakaspoistumaan ei itselläni toiminut, mutta en tiedä johtuuko sitten selaimesta. \n\nKoodeissa käytin hyväksi demo-klinikan koodeja, mutta eri aineistolla, jonka olen ottanut Kagglesta. Aineisto käsittelee myös credit-risk-dataa, joten ajattelin sen jossakin määrin sopivan aiheeseen. ","metadata":{}},{"cell_type":"code","source":"!pip install sklearn\n!pip install numpy","metadata":{"execution":{"iopub.status.busy":"2021-08-24T08:50:48.197386Z","iopub.execute_input":"2021-08-24T08:50:48.198076Z","iopub.status.idle":"2021-08-24T08:51:43.017172Z","shell.execute_reply.started":"2021-08-24T08:50:48.198036Z","shell.execute_reply":"2021-08-24T08:51:43.016193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn import preprocessing\nfrom sklearn.impute import SimpleImputer as Imputer\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import mean_squared_error, accuracy_score\nfrom sklearn.linear_model import SGDClassifier, LogisticRegression\nfrom sklearn.svm import SVC\n\nfrom warnings import filterwarnings\nfilterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-05-28T14:02:38.069833Z","iopub.execute_input":"2021-05-28T14:02:38.070282Z","iopub.status.idle":"2021-05-28T14:02:39.24467Z","shell.execute_reply.started":"2021-05-28T14:02:38.070233Z","shell.execute_reply":"2021-05-28T14:02:39.243314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2021-08-24T08:51:43.01919Z","iopub.execute_input":"2021-08-24T08:51:43.019832Z","iopub.status.idle":"2021-08-24T08:51:43.039242Z","shell.execute_reply.started":"2021-08-24T08:51:43.019778Z","shell.execute_reply":"2021-08-24T08:51:43.038002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/credit-risk-data/train_u6lujuX_CVtuZ9i.csv')","metadata":{"execution":{"iopub.status.busy":"2021-08-24T08:52:09.998092Z","iopub.execute_input":"2021-08-24T08:52:09.998486Z","iopub.status.idle":"2021-08-24T08:52:10.010517Z","shell.execute_reply.started":"2021-08-24T08:52:09.998453Z","shell.execute_reply":"2021-08-24T08:52:10.009458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df[:10000]","metadata":{"execution":{"iopub.status.busy":"2021-08-24T08:52:14.499063Z","iopub.execute_input":"2021-08-24T08:52:14.499559Z","iopub.status.idle":"2021-08-24T08:52:14.5042Z","shell.execute_reply.started":"2021-08-24T08:52:14.499526Z","shell.execute_reply":"2021-08-24T08:52:14.503145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T08:52:16.55902Z","iopub.execute_input":"2021-08-24T08:52:16.559373Z","iopub.status.idle":"2021-08-24T08:52:16.583307Z","shell.execute_reply.started":"2021-08-24T08:52:16.559344Z","shell.execute_reply":"2021-08-24T08:52:16.582453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T08:52:20.768168Z","iopub.execute_input":"2021-08-24T08:52:20.768745Z","iopub.status.idle":"2021-08-24T08:52:20.791117Z","shell.execute_reply.started":"2021-08-24T08:52:20.768708Z","shell.execute_reply":"2021-08-24T08:52:20.789489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols_to_remove = ['Gender','Loan_ID']\ndata = df.drop(cols_to_remove, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T08:52:25.24211Z","iopub.execute_input":"2021-08-24T08:52:25.242536Z","iopub.status.idle":"2021-08-24T08:52:25.250001Z","shell.execute_reply.started":"2021-08-24T08:52:25.242498Z","shell.execute_reply":"2021-08-24T08:52:25.249086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = []\nfor i in data['ApplicantIncome']:\n    if i == 'Loan_Status':\n        y.append(1)\n    else:\n        y.append(0)\n\ndata = data.drop('Loan_Status', axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-24T08:52:29.350855Z","iopub.execute_input":"2021-08-24T08:52:29.351439Z","iopub.status.idle":"2021-08-24T08:52:29.358048Z","shell.execute_reply.started":"2021-08-24T08:52:29.351386Z","shell.execute_reply":"2021-08-24T08:52:29.357297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(data.info())\ndata = pd.get_dummies(data)\nprint(data.info())","metadata":{"execution":{"iopub.status.busy":"2021-08-24T08:52:33.319103Z","iopub.execute_input":"2021-08-24T08:52:33.319537Z","iopub.status.idle":"2021-08-24T08:52:33.362523Z","shell.execute_reply.started":"2021-08-24T08:52:33.319501Z","shell.execute_reply":"2021-08-24T08:52:33.36151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xMean = np.mean(data, axis=0)\nxDev = np.std(data, axis=0)\nxNorm = (data - xMean) / xDev\n\nx = data.values #returns numpy array\nmin_max_scaler = preprocessing.MinMaxScaler()\nx_scaled = min_max_scaler.fit_transform(x)\nxMinMax = pd.DataFrame(x_scaled)\nxNoNorm = data","metadata":{"execution":{"iopub.status.busy":"2021-08-24T08:52:37.662182Z","iopub.execute_input":"2021-08-24T08:52:37.662628Z","iopub.status.idle":"2021-08-24T08:52:37.771915Z","shell.execute_reply.started":"2021-08-24T08:52:37.66259Z","shell.execute_reply":"2021-08-24T08:52:37.769924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xNorm","metadata":{"execution":{"iopub.status.busy":"2021-08-24T08:52:40.777349Z","iopub.execute_input":"2021-08-24T08:52:40.777758Z","iopub.status.idle":"2021-08-24T08:52:40.812616Z","shell.execute_reply.started":"2021-08-24T08:52:40.777719Z","shell.execute_reply":"2021-08-24T08:52:40.811417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Oppimispäiväkirja 4. \n\nTämä luento käsitteli pitkälti harjoitustyön tekemistä ja sen vaiheita. Mielestäni tämä luento oli hyvä ja auttoi ainakin itseäni harjoitustyön kanssa, koska ennen luentoa en oikein tiennyt, mitä minun tulisi käytännössä tehdä ja miten. Tässä vaiheessa en myöskään ole aloittanut vielä harjoitustyön tekemistä, joten sikäli asia on myös uutta. Kävin ensin luentodiat läpi, mutta luentovideo oli mielestäni tässä kohden parempi, koska siinä käytiin läpi harjoitustyön tekemistä ja data-analyysiä esimerkkien kautta läpi.\n\nNiklas Stephensonin mahdollisuuskehikko oli täysin uusi, mutta tulen sitä käyttämään harjoitustyössä hyväksi. Tämä oli hyvin konkreettinen esimerkki ja uskon, että tätä käytetään myös oikeassa yrityselämässä ja se tekikin tästä hyvin mielenkiintoisen! Se miten yritykset tätä käyttävät loppupeleissään hyväksi omassa data-analyysissään on toki hieman epäselvä. Luultavasti tässä olisi parantamisen varaa ja näin yritykset saisivat yhä enemmän irti omasta liiketoiminnastaan ja pystyisivät ymmärtämään syvällisemmin esimerkiksi asiakkaidensa tarpeita ja toimintamalleja. En päässyt valitettavasti mukaan ryhmäkeskusteluihin, koska olin töissä luennon aikana. \n\nPäätin tämän perusteella, että teen harjoitustyön todennäköisesti AirBnB -aineistosta, koska luulen ymmärtäväni yhtiön liiketoimintaa ainakin jollain tasolla, ja se oli yksi tärkeä osa Stephensonin mallia. Vastaan tässä myös luennolla käytyihin kysymyksiin omasta näkökulmasta:\n- Miten näkisitte että Airbnb tapauskuvauksessa voisi yllä mainittu mittakehikko toimia?\n- Miten laatu, nopeus ja robustisuus voisi muuttua datan avulla?\n\nEnsimmäiseen kysymykseen vastauksena koen, että Airbnb:N tapauksessa mittakehikko, joka luentomateriaalissa on voi toimia, koska saatavilla oleva data tukee laatua, nopeutta ja robustisuutta. Toinen kysymys on itselleni haastavampi, koska en oikein ole varma ymmärränkö kysymystä ihan oikein. Luulen, että mitä laadukkaampi data on tai mitä paremmin se on voitu kerätä, sitä laadukkaampaa ja nopeampaa sen käsittely on. \n\nMielestäni luennolla oli mielenkiintoinen pointti se, että Airbnb:n yksi tärkeimmistä liiketoiminnan lähteistä on luottamus, jotta vuokranantajat pysyvät sovelluksessa. Voisin ehkä pyöritellä harjoitustyössä myös tätä teemaa, mutta en oikein vielä tarkalleen tiedä, että miten. Kaupungiksi valitsen luultavasti Helsingin, koska tunnen kaupungin ja asun täällä. Tunnen myös yleisesti jollain tavalla Helsingin asuntomarkkinaa, joten sen takia valitsen sen. Vaikkakin se ei silloin ole \"matkustamista\" minulle. \n\nTämän viikon koodailuissa käytin aineistona Tukholman Airbnb -dataa, joka on peräisin Kagglesta. Mielestäni täältä löytää ihan hyvin dataa ja tämä sopi aiheeseenkin hyvin. Koodit ovat peräisin koodiklinikan harjoitusmateriaaleista, mutta data on itse etsimäni. Koodaus ei itsenäisesti onnistu, joten noiden koodiklinikan esimerkkien avulla pääsen aiheeseen kiinni paremmin. Tämä muistuttaa hieman nyt esimerkiksi Stataa, jota olen käyttänyt tilastotieteen kurssilla.\n\nTärkeimmät oivallukset:\n- Mahdollisuuskehikko: täysin uusi juttu mutta kuulostaa hyödylliseltä!\n- Liiketoiminnan syvällinen ymmärtäminen, jotta datan analysoimisessa olisi ylipäätään mitään järkeä tai että saadaan oikeat lopputulokset\n- Datan visualisoinnin tärkeys: katsoja saa paremman käsityksen tutkimuksesta ja hahmottaa eri muuttujat (mikä oleellista ja mikä ei)\n- Mallintaminen eli kuinka ratkaista kysymys ohjelmallisesti\n- Iterointi, eli aina voi keksiä uusia kysymyksiä datan käsittelyn jälkeen\n\nParannusehdotus: ehkä lisää vielä esimerkkejä, jos jotain pakko keksiä. Minusta tämä luento oli kuitenkin todella hyvä ja selkeä! Kiitos.\n\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn import preprocessing\nfrom sklearn import linear_model\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.impute import SimpleImputer\n\nimport matplotlib.pyplot as plt\nimport os","metadata":{"execution":{"iopub.status.busy":"2021-08-24T08:52:48.027794Z","iopub.execute_input":"2021-08-24T08:52:48.02814Z","iopub.status.idle":"2021-08-24T08:52:49.167818Z","shell.execute_reply.started":"2021-08-24T08:52:48.02811Z","shell.execute_reply":"2021-08-24T08:52:49.166805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndf = pd.read_csv('/kaggle/input/stockholm-sweden-airbnb-listings/reviews_detailed.csv')\ndf.to_csv('data.csv')\nprint(df.info())\n","metadata":{"execution":{"iopub.status.busy":"2021-08-24T08:59:40.837536Z","iopub.execute_input":"2021-08-24T08:59:40.838151Z","iopub.status.idle":"2021-08-24T08:59:43.766445Z","shell.execute_reply.started":"2021-08-24T08:59:40.838105Z","shell.execute_reply":"2021-08-24T08:59:43.765315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/stockholm-sweden-airbnb-listings/listings.csv')\ndf.to_csv('data.csv')\nprint(df.info())","metadata":{"execution":{"iopub.status.busy":"2021-08-24T09:02:16.85927Z","iopub.execute_input":"2021-08-24T09:02:16.859722Z","iopub.status.idle":"2021-08-24T09:02:17.07556Z","shell.execute_reply.started":"2021-08-24T09:02:16.859684Z","shell.execute_reply":"2021-08-24T09:02:17.074334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df[['number_of_reviews','last_review','reviews_per_month']]\n\nprint(df.head())\nprint(df.number_of_reviews.unique())","metadata":{"execution":{"iopub.status.busy":"2021-08-24T09:04:45.578677Z","iopub.execute_input":"2021-08-24T09:04:45.579073Z","iopub.status.idle":"2021-08-24T09:04:45.59488Z","shell.execute_reply.started":"2021-08-24T09:04:45.579042Z","shell.execute_reply":"2021-08-24T09:04:45.59373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.dropna()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T09:07:41.543172Z","iopub.execute_input":"2021-08-24T09:07:41.543899Z","iopub.status.idle":"2021-08-24T09:07:41.55495Z","shell.execute_reply.started":"2021-08-24T09:07:41.543856Z","shell.execute_reply":"2021-08-24T09:07:41.553777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"le = preprocessing.LabelEncoder()\n\narr = le.fit_transform(df.number_of_reviews)\n\ndf.number_of_reviews = arr\n\n# 2 - ...OR alternative way \ndf_label = df.apply(preprocessing.LabelEncoder().fit_transform)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T09:08:28.983649Z","iopub.execute_input":"2021-08-24T09:08:28.984345Z","iopub.status.idle":"2021-08-24T09:08:29.005789Z","shell.execute_reply.started":"2021-08-24T09:08:28.984288Z","shell.execute_reply":"2021-08-24T09:08:29.004714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(arr)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T09:08:43.719455Z","iopub.execute_input":"2021-08-24T09:08:43.719868Z","iopub.status.idle":"2021-08-24T09:08:43.734142Z","shell.execute_reply.started":"2021-08-24T09:08:43.719832Z","shell.execute_reply":"2021-08-24T09:08:43.732967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Perform Linear Regression\nlr = linear_model.LinearRegression()\n\n# define labels and data (i.e y and X)\ny = df.number_of_reviews\nX = df.drop(columns='last_review')\n\npredict = cross_val_predict(lr, X, y, cv=10)\n\nfig, ax = plt.subplots(figsize=(20, 10))\nax.scatter(y, predict, edgecolors=(0, 0, 0))\nax.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=4)\nax.set_xlabel('Measured')\nax.set_ylabel('Predicted')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T09:09:58.884503Z","iopub.execute_input":"2021-08-24T09:09:58.884931Z","iopub.status.idle":"2021-08-24T09:09:59.250886Z","shell.execute_reply.started":"2021-08-24T09:09:58.884894Z","shell.execute_reply":"2021-08-24T09:09:59.250016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Oppimispäiväkirja 5.\n\nTämä luento oli vierailijaluento, jonka kävin läpi jälkikäteen töiden takia. Kiva, että saatiin kurssille myös työelämän edustusta. Mielestäni parasta tässä oli kuulla henkilön koulu- ja uratarinaa vähän tarkemmin ja miksi hän oli kiinnostunut aiheesta. Luennosta teki myös hyvän se, että siellä käytiin henkilöiden kesken vuoropuhelua, mikä tuo kertausta siihen, mitä aikaisemmin luennolla on käyty läpi. Eli tämä siis mielestäni hyvää kertausta!\n\nOikeastaan kaikki luennolla käydyt asiat olivat uusia itselleni termit mukaan lukien. Aiheena oli luonnollisen kielen analyysi. Koen siis oppineeni aika paljon tämän luennon aikana ja tässä oppimispäiväkirjassa käyn läpi myös termejä, jotka käyn itse läpi. Aluksi luennolla käytiin läpi termiä NLP, joka tarkoittaa datatieteen alaa, jossa datalähteenä on luonnollinen kieli. NLP:tä käytetään esimerkiksi chatboteissa ja automaattisissa konekäännöksissä. Kieli linkittyykin koneoppimiseen useimmiten. Google Colaboraty on Googlen ylläpitämä Notebook-palvelu. Luennolla käytiin pikakomentoja läpi, jotka toki tässä vaiheessa ei mieleen jäänyt kauhean tarkasti.\n\nLuentoesimerkki ministerien vastauksista ja niiden luokutteluista oli ihan mielenkiintoinen, eikä vaikuttanut kuunnellessa niin monimutkaiselta. Käytäntö itselleni olisi varmasti ihan toista. Luennoitsija selitti hyvin selkeästi mitä tekee ja milloinkin. Tässä myös helpotti se, että hän puhui Suomea niin keskittyminen oli helpompaa. Esikäsittelyn tärkeys tuli ainakin ilmi, koska jos siinä epäonnistutaan, malli on käytännössä epäonnistunut ja sieltä saatava tieto on epätotta. Esimerkiksi se, miksi puolustusministerin puheenvuoroja ei ollut niin paljon oli syynä se, että järjestelmä ei tunnistanut kyseisen ministerin sanoja samalla tavalla kuin toisen ministerin. \n\nTämän viikon koodien kohdalla olen käyttänyt myös apuan koodiklinikkaa, mutta aineiston olen hakenut Kaggelsta aikaisempien viikkojen tapaan. \n\nTärkeimmät oivallukset:\n- Uudet termit\n- Stepwordit eli hukkasanat, kuinka niitä voidaan lukea ja tulkita\n- Datasettien tasapainotus, kun ryhmissä tapahtuu muutoksia (ministeriöesimerkki)\n- Oli mielenkiintoista nähdä, kuinka sanoja voi muokata\n- FastText -kirjasto, missä käsitellään sanoja vektorimuodossa\n- Twiittien yhdistäminen dataan!\n\nEn keksi oikein tarkkaa parannettavaa luennolta, koska mielestäni se oli kaiken kaikkiaan hyvin rakennettu ja suunniteltu! Toki olisi ollut mielenkiintoista kuulla vielä konkreettisesti enemmän hänen urasta ja siitä millainen esimerkiksi tyypillinen työpäivä on. Ei välttämättä liity kurssin teemaan suoraan, joten ymmärrän miksi tähän nyt ei niin paljoa ole käytetty aikaa. Oli kiva kuulla kuitenkin Solitan Akatemiasta ja tällaisesta mahdollisuudesta. ","metadata":{}},{"cell_type":"code","source":"!pip install sklearn\n!pip install numpy","metadata":{"execution":{"iopub.status.busy":"2021-08-24T12:49:31.537763Z","iopub.execute_input":"2021-08-24T12:49:31.538227Z","iopub.status.idle":"2021-08-24T12:50:26.289827Z","shell.execute_reply.started":"2021-08-24T12:49:31.538126Z","shell.execute_reply":"2021-08-24T12:50:26.288583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn import preprocessing\nfrom sklearn.impute import SimpleImputer as Imputer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.decomposition import PCA\n\nfrom warnings import filterwarnings\nfilterwarnings('ignore')\n","metadata":{"execution":{"iopub.status.busy":"2021-08-24T12:50:26.294222Z","iopub.execute_input":"2021-08-24T12:50:26.294575Z","iopub.status.idle":"2021-08-24T12:50:27.493032Z","shell.execute_reply.started":"2021-08-24T12:50:26.294538Z","shell.execute_reply":"2021-08-24T12:50:27.492035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/credit-risk-data/train_u6lujuX_CVtuZ9i.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-08-24T12:51:19.489233Z","iopub.execute_input":"2021-08-24T12:51:19.489758Z","iopub.status.idle":"2021-08-24T12:51:19.502345Z","shell.execute_reply.started":"2021-08-24T12:51:19.489723Z","shell.execute_reply":"2021-08-24T12:51:19.501235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df = df[:10000]","metadata":{"execution":{"iopub.status.busy":"2021-08-24T12:51:34.041432Z","iopub.execute_input":"2021-08-24T12:51:34.041893Z","iopub.status.idle":"2021-08-24T12:51:34.046651Z","shell.execute_reply.started":"2021-08-24T12:51:34.041856Z","shell.execute_reply":"2021-08-24T12:51:34.045269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T12:51:45.869582Z","iopub.execute_input":"2021-08-24T12:51:45.869984Z","iopub.status.idle":"2021-08-24T12:51:45.909176Z","shell.execute_reply.started":"2021-08-24T12:51:45.869946Z","shell.execute_reply":"2021-08-24T12:51:45.907897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T12:52:04.249585Z","iopub.execute_input":"2021-08-24T12:52:04.250028Z","iopub.status.idle":"2021-08-24T12:52:04.274544Z","shell.execute_reply.started":"2021-08-24T12:52:04.249993Z","shell.execute_reply":"2021-08-24T12:52:04.273169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols_to_remove = ['Loan_ID','Married']\ndata = df.drop(cols_to_remove, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T12:54:43.070867Z","iopub.execute_input":"2021-08-24T12:54:43.071345Z","iopub.status.idle":"2021-08-24T12:54:43.079811Z","shell.execute_reply.started":"2021-08-24T12:54:43.071309Z","shell.execute_reply":"2021-08-24T12:54:43.078983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Oppimispäiväkirja 6.\n\nTämä luento käsitteli ohjaamatonta oppimista poiketen ohjatusta oppimisesta, jota aikaisemmin ollaan käsitelty. Kävin luennon teemat läpi itsenäisesti, koska olin töissä päivän. Ohjaamattomasta oppimisesta on kyse silloin, kun ennalta ennustettua piirrettä ei ole - välillä data-analyysissä tarvitaan myös ohjaamatonta oppimista! Ohjaamattoman oppimisen piirteitä ovat ostoskorianalyysi, verkostoanalyysi, ryvästäminen sekä aihemallinnus. Ennestään tuttu termi oli ryvästäminen sekä ostoskorianalyysi, muutta verkostoanalyysi sekä aihemallinnus olivat uusia termejä. \n\nKävin lukemassa hieman lisää myös ohjaamattomasta koneoppimisesta ja sen erioista muihin koneoppimisen muotoihin ElementsofAI -kurssin sivustolta. Mielestä siellä oli selitetty esimerkein myös hyvin, mitä ohjaamattomalla koneoppimisella tarkoitetaan. Sivustolla selitettiin myös generatiivisesta oppimisesta, jonka avulla esimerkiksi ihmisen kasvokuvista voidaan luoda koneella samanlaista dataa, jotka näyttävät oikeilta kasvokuvilta. Ilmeisesti tämä on noussut viime vuosien aikana. \n\nMuuttujien normalisointia ja siihen liittyvää datan pyörittämistä (vinkkejä siihen ja koodia) auttoi ymmärtämään luentomateriaaleissa ollut linkki Alex Greenin blogitekstiin, jonka kävin lukemassa luentomateriaalien läpi käynnin jälkeen. Luennolla käytiin enemmän läpi ryvästämistä, joka aiheena oli hieman jo tuttua, joten pääsin perehtymään asiaan tarkemmin luentomateriaaleista. K-means algortimi oli kuitenkin uusi termi, ja tutkin aihetta hieman lisää itse Googlen avulla, koska en alkuun tajunnut mistä oli kyse.\nKaiken kaikkiaan tämä luento ei ollut ehkä edellisiin nähden niin laaja, enkä ole varma kuinka paljon tulevaisuudessa käytän näitä asioita. Toisaalta tämä tuntui aiheeltaan kaikista haastavammalta. Luultavasti ohjaamaton oppiminenkin ja siihen liittyvä data-analyysi tulee vastaan jossain tilanteessa, mitä en tällä hetkellä itse välttämättä edes ymmärrä. \n\nTopic Modeling Scikit Learn - artikkeli oli hyvä, vaikkakin minulle aika tuntematonta asiaa. Luulen, että artikkelista ja koodeista voi olla apua, kun myöhemmin alan tekemään koodeja tältä viikolta. Gensim oli myös uusi juttu, mutta mielestäni näitä eri \"kirjastoja\" on jotenkin helpompi käyttää Kagglen kautta Jupyter-työkirjana, kuin miten alkuperäisesti yritin Jupyteryllä. \n\nTärkeimmät oivallukset:\n- ohjaamaton oppiminen ja missä kaikessa sitä voidaan käyttää (osa vielä vähän auki edelleen!)\n- ohjaamattoman oppimisen eri piirteet (ryvästämminen ja ostoskorianalyysi hieman tuttuja)\n- muuttujien normalisointi\n- K-means algoritmin tarkoitus\n- Elokuvien (Netflix) luokittelut ja siihen liittyvät esimerkit luennolla, aikaisemmin en ollut ajatellut, että tässäkin voidaan käyttää ohjaamatonta koneoppimista. Varmaan ensi kerralla, kun katsoo Netflixiä niin osaa kiinnittää eri tavalla huomiota myös tähän aiheeseen. \n- Se, että paljon voi etsiä lisätietoa eri aiheista myös itse\n\nParannusehdotuksena ehkä tulevaisuutta ajatellen se, että aukaistaisiin enemmän vielä materieeleihin termejä. Toki varmasti ihan hyvä aktivoida opiskelijoita etsimään itse myös tietoa. Ja vaikka videoilla käydäänkin läpi laajasti aiheita, ei kaikki jää aina mieleen tai ehkä silloin jäisi, jos luennolla olisi enemmän vuoropuhelua, kuten edellisellä luennolla. Ymmärrän toki, että tämä ei mitenkään ole aina mahdollista. Mutta muuta en oikein keksi, koska pidät mielestäni luennot hyvin!","metadata":{}},{"cell_type":"code","source":"#!pip install holoviews","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport pylab as pl\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn import preprocessing\nimport matplotlib.pyplot as plt\nimport holoviews as hv\nfrom holoviews import opts\n# from src import mglearn\nhv.extension('bokeh')\n%matplotlib inline","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/netflix-shows/netflix_titles.csv\", low_memory=False)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-25T10:56:18.775663Z","iopub.execute_input":"2021-08-25T10:56:18.776062Z","iopub.status.idle":"2021-08-25T10:56:18.882476Z","shell.execute_reply.started":"2021-08-25T10:56:18.776024Z","shell.execute_reply":"2021-08-25T10:56:18.881501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-08-25T10:56:51.208872Z","iopub.execute_input":"2021-08-25T10:56:51.20924Z","iopub.status.idle":"2021-08-25T10:56:51.247543Z","shell.execute_reply.started":"2021-08-25T10:56:51.20921Z","shell.execute_reply":"2021-08-25T10:56:51.246395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"dfNum = df[['rating','duration','date_added']]\ndfNum.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-25T10:59:24.605204Z","iopub.execute_input":"2021-08-25T10:59:24.605602Z","iopub.status.idle":"2021-08-25T10:59:24.619201Z","shell.execute_reply.started":"2021-08-25T10:59:24.605567Z","shell.execute_reply":"2021-08-25T10:59:24.618286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfNum.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-08-25T11:13:09.673336Z","iopub.execute_input":"2021-08-25T11:13:09.67377Z","iopub.status.idle":"2021-08-25T11:13:09.685379Z","shell.execute_reply.started":"2021-08-25T11:13:09.673732Z","shell.execute_reply":"2021-08-25T11:13:09.684211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tietueita = dfNum.shape\ntietueita","metadata":{"execution":{"iopub.status.busy":"2021-08-25T11:13:38.003075Z","iopub.execute_input":"2021-08-25T11:13:38.003452Z","iopub.status.idle":"2021-08-25T11:13:38.009014Z","shell.execute_reply.started":"2021-08-25T11:13:38.003418Z","shell.execute_reply":"2021-08-25T11:13:38.008076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfNum[dfNum.isnull().any(axis=1)]","metadata":{"execution":{"iopub.status.busy":"2021-08-25T11:13:50.929832Z","iopub.execute_input":"2021-08-25T11:13:50.930333Z","iopub.status.idle":"2021-08-25T11:13:50.946458Z","shell.execute_reply.started":"2021-08-25T11:13:50.930299Z","shell.execute_reply":"2021-08-25T11:13:50.945351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Koodit otettu luentomateriaaleista ja aineisto haettu Kagglesta, joka on eri kuin luentomateriaaleissa, mutta aiheeseen liittyvä. Valitsin vaan muutaman muuttujan tarkastelavaksi, sen mukaan, että ne ovat myös sellaisia, jotka voi laittaa järjestykseen. Käytin siis myös KMeans-ryvästämistä. Oma osaamiseni ei nyt riitä sen arvioimiseen, onko aineisto siisti etukäteen vai ei. ","metadata":{}},{"cell_type":"markdown","source":"Oppimispäiväkirja 7.\n\nViimeisen luennon aiheena oli visuaalinen analytiikka - ja tämä ainakin kiinnosti aiheen perusteella itseäni paljon! Ihan alkuun visuaalisella analyytikalla tarkoitetaan datatieteessä kahta asiaa: raakadatan tutkiva kartoittaminen sekä lopputuloksen esittäminen sellaisessa muodossa, että kohdeyleisö ymmärtää asian. Etenkin jälkimmäinen sopii perusajatukseen hyvin, sillä se miten lopputuloksen esittää on paljon merkitystä. Haluaisin myös itse oppia lisää siitä, kuinka data-analyysin ratkaisut voidaan esittää paremmin ja tehokkaammin yleisölle visuaalisesta näkökulmasta katsottuna.\n\nKartoittava analytiikka ja sen jälkeinen kommunikointi ovat keskeinen osa datatieteessä, kun puhutaan visualisoinnista, kuten luennolla käytiin läpi. Tämä oli hyvä pointti nostaa esille, sillä selkeä kommunikointi ei kyllä auta siinä vaiheessa, kun tehty data / analytiikka on virheellistä. Ja tämä toki toimii myös toisin päin, eli vaikka data olisi täyttä asiaa, mutta jos kommunikointi on puutteellista, ei kohderyhmälle saada haluttua tulosta aikaiseksi. \n\nBen Fryn (2008) kehittelemä seitsämän askeleen kohta datan visualisoinnille oli mielestäni selkeä, kun se luentomateriaalissa ja luennolla käytiin läpi. Etenkin viimeinen kohta vuorovaikuttaminen oli mielestäni tärkeää, sillä sen, millä tavalla lopputuloksen esittää on merkitystä. Lopputuloksen esittämisen pitäisi toimia vuorovaikutuksessa yleisön kanssa ja siksi datan visualisointi onkin hyvin tärkeää.\n\nHuonosta datan visualisoinnista ollut esimerkki oli hyvä, koska siitä kävi ilmi, että visualisoinnin merkitys oli suuri. Mielestäni esitetty data oli tehty huonosti, epäselvästi, eikä siihen jaksanut kiinnittää tarkempaa huomiota edes. Esimerkiksi palkkien suuri ero, vaikka prosentuaalinen ero oli todella pieni, väärensi illuusiota datan oikeasta erosta. Myös liiallinen värien käyttö ja materiaali, sekä vääränlainen kuvaaja vaikuttavat siihen, kuinka laadukasta visualisointi on. Nämä olivat ennestään jo tuttuja asioita, mutta toisaalta hyvä muistuttaa itseään myös aina näistä.\n\nStreamlitin käyttö oli kyllä aika haastavan oloista, enkä saanut ajettua itse ohjelmaa tähän notebookiin nyt. Kävin kuitenkin tutustumassa Streamlitin sivuihin, että olen ainakin tietoinen sen olemassa olosta. Luennon perusteella kuulostaa kuitenkin aika kätevältä sovellukselta, kun mietitään visualisoinnin näkökulmasta. \n\nItse datan visualisointi Pythonilla on kyllä itselleni haastavaa, niin kuin muutkin asiat tällä kurssilla. Uskon kuitenkin oppineeni tällä kurssilla paljon, vaikka oma taso on heikko edelleen. Olen oppinut näistä eri kirjastoista, sekä esimerkiksi Kagglen käyttö on tullut tutuksi. Nämä kaikki olivat täysin uusia asioita ennen kurssille tuloa, enkä ollut koskaan edes kuullut Jupyter Notebookista. Joten siihden nähden koen oppineeni, vaikkakin kurssin tavoitteisiin nähden osaamiseni on silti heikkoa. Minulla on mennyt aikaa myös perusohjelmien lataamiseen (Anaconda tms.), mutta toivottavasti tulevaisuudessa työelämässä pääsen jossain kohti hyötymään näistä taidoista. Luulen myös, että tulevilla maisterikursseilla LUT:issa tulen saamaan hyötyä tästä, koska vastaava kurssi olisi ollut huomattavasti tätä helpompi. \n\nTärkeimmät oivallukset:\n- visualisoinnin merkitys\n- aihe kiinnostaa itseäni tämän jälkeen vielä enemmän\n- seitsämän askeleen kohta datan visualisoinnille\n- kuinka pythonilla voi visualisoida dataa (tämä vaikeaa!), miten pystytään luottamaan aineistoon, että se on tosi tms. \n- huonot visualisoinnin tavat (liikaa aineistoa, värejä tms.)\n- tutustuin paremmin Tableuhun\n\nLisäksi oli mukavaa, kun luennolla käytiin läpi myös harjoitustyön tekemistä sekä summattiin koko kurssi yhteen nippuun. Tämä oli mielestäni kokonaisuudessaan hyvä luento ja materiaalit, joten hankala keksiä parannettavaa. Ehkä jonkin reaalimaailman yritys-casen lisäisin tähän.\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport holoviews as hv\nfrom holoviews import opts\nhv.extension('bokeh')","metadata":{"execution":{"iopub.status.busy":"2021-08-25T12:21:37.71863Z","iopub.execute_input":"2021-08-25T12:21:37.719166Z","iopub.status.idle":"2021-08-25T12:21:39.273396Z","shell.execute_reply.started":"2021-08-25T12:21:37.71912Z","shell.execute_reply":"2021-08-25T12:21:39.272645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nurl = '/kaggle/input/stockholm-sweden-airbnb-listings/listings.csv'\ndf = pd.read_csv(url,index_col=0,parse_dates=[0])\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-25T12:22:43.917122Z","iopub.execute_input":"2021-08-25T12:22:43.917504Z","iopub.status.idle":"2021-08-25T12:22:44.014165Z","shell.execute_reply.started":"2021-08-25T12:22:43.917474Z","shell.execute_reply":"2021-08-25T12:22:44.013376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scatter = hv.Scatter(df, 'price', 'room_type')\nscatter","metadata":{"execution":{"iopub.status.busy":"2021-08-25T12:24:57.651125Z","iopub.execute_input":"2021-08-25T12:24:57.651467Z","iopub.status.idle":"2021-08-25T12:24:57.768312Z","shell.execute_reply.started":"2021-08-25T12:24:57.651435Z","shell.execute_reply":"2021-08-25T12:24:57.767152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Tämä kuvaaja on kyllä hyvin epäselvä, eikä tällaista nyt tietenkään voi käyttää missään esityksessä esimerkiksi. Kuitenkin tästä näkee hieman hinnan ja huoneen tyypin korrelaatiota Tukholmassa olevien Airbnb asuntojen osalta. Omat taitoni ei riitä Streamlitin käyttämiseen tässä vaiheessa. \n","metadata":{"execution":{"iopub.status.busy":"2021-08-25T12:27:12.472086Z","iopub.execute_input":"2021-08-25T12:27:12.472426Z","iopub.status.idle":"2021-08-25T12:27:12.52033Z","shell.execute_reply.started":"2021-08-25T12:27:12.472397Z","shell.execute_reply":"2021-08-25T12:27:12.519222Z"}}}]}