{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Fasttext vs LSTM\n\n![fasttext](https://opendatascience.com/wp-content/uploads/2021/01/ogimage-e1610396279996-300x89.png)"},{"metadata":{},"cell_type":"markdown","source":"### What is Fasttext?\n\nFastText is an open-source, free, lightweight library that allows users to learn text representations and text classifiers. It works on standard, generic hardware. Models can later be reduced in size to even fit on mobile devices."},{"metadata":{},"cell_type":"markdown","source":"### What is LSTM?\n\nLong-Short-Term Memory (LSTM) is a special kind of recurrent neural network capable of learning long-term dependencies, remembering information for long periods as its default behaviour. There are three steps in an LSTM network:\n- Step 1: The network decides what to forget and what to remember.\n- Step 2: It selectively updates cell state values.\n- Step 3: The network decides what part of the current state makes it to the output."},{"metadata":{"trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"!pip install num2words\n!pip install fasttext","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport string\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import PorterStemmer, WordNetLemmatizer\nfrom num2words import num2words\nimport os\nimport fasttext\nimport fasttext.util\nfrom sklearn.svm import SVC\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load pre-trained model from fasttext"},{"metadata":{"trusted":true},"cell_type":"code","source":"!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!gzip -d ./cc.en.300.bin.gz","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ft = fasttext.load_model('cc.en.300.bin')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Preprocess functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"stemmer = PorterStemmer()\nlemmatizer= WordNetLemmatizer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_url(x):\n    \n    x = re.sub(r'@\\w+','',x)\n    x = re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', x)\n    \n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_stopwords(x):\n    stop_words = set(stopwords.words('english')) \n    return [word for word in x if word not in stop_words]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def number_remove(tokens): # Alternatif olarak numeric deÄŸerler kelimelerede cevrilebilir.\n        \n    return [word for word in tokens if word.isalpha()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def steming(tokens):\n        \n    return [stemmer.stem(word) for word in tokens]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def lemmetizing(tokens):\n        \n    return [lemmatizer.lemmatize(word) for word in tokens]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def number_to_word(tokens):\n           \n    return [num2words(word) if word.isdigit() else word for word in tokens]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def list_to_str(tokens):\n    return ' '.join([str(item) for item in tokens ])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vectorize tweets with fasttext pre-trained model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_ft_vector(df):\n    df['OriginalTweet'] = df['OriginalTweet'].apply(remove_url)\n    df['OriginalTweet'] = df['OriginalTweet'].apply(lambda x : x.lower())\n    df['OriginalTweet'] = df['OriginalTweet'].apply(lambda x : x.translate(str.maketrans('', '', string.punctuation)))\n    df['OriginalTweet'] = df['OriginalTweet'].apply(word_tokenize)\n    df['OriginalTweet'] = df['OriginalTweet'].apply(remove_stopwords)\n    df['OriginalTweet'] = df['OriginalTweet'].apply(number_to_word)\n    df = df[~df['OriginalTweet'].str.len().eq(0)]\n    df['OriginalTweet'] = df['OriginalTweet'].apply(list_to_str)\n    df['fasttext'] = df['OriginalTweet'].apply(ft.get_sentence_vector)\n    return df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Add label for fasttext train without pre-trained"},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_fasttext(df):\n    df['OriginalTweet'] = df['OriginalTweet'].apply(remove_url)\n    df['OriginalTweet'] = df['OriginalTweet'].apply(lambda x : x.lower())\n    df['OriginalTweet'] = df['OriginalTweet'].apply(lambda x : x.translate(str.maketrans('', '', string.punctuation)))\n    df['OriginalTweet'] = df['OriginalTweet'].apply(word_tokenize)\n    df['OriginalTweet'] = df['OriginalTweet'].apply(remove_stopwords)\n    df['OriginalTweet'] = df['OriginalTweet'].apply(number_to_word)\n    df = df[~df['OriginalTweet'].str.len().eq(0)]\n    df['OriginalTweet'] = df['OriginalTweet'].apply(list_to_str)\n    df['Sentiment'] = df['Sentiment'].apply(lambda x : '__label__' + str(x))\n    return df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Stemming and lemmetizing are good preprocessing for the lstm model, although not good for fasttext"},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_lstm(df):\n    df['OriginalTweet'] = df['OriginalTweet'].apply(remove_url)\n    df['OriginalTweet'] = df['OriginalTweet'].apply(lambda x : x.lower())\n    df['OriginalTweet'] = df['OriginalTweet'].apply(lambda x : x.translate(str.maketrans('', '', string.punctuation)))\n    df['OriginalTweet'] = df['OriginalTweet'].apply(word_tokenize)\n    df['OriginalTweet'] = df['OriginalTweet'].apply(remove_stopwords)\n    df['OriginalTweet'] = df['OriginalTweet'].apply(number_remove)\n    df['OriginalTweet'] = df['OriginalTweet'].apply(steming)\n    df['OriginalTweet'] = df['OriginalTweet'].apply(lemmetizing)\n    df = df[~df['OriginalTweet'].str.len().eq(0)]\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/covid-19-nlp-text-classification/Corona_NLP_train.csv', \n                        encoding = 'latin-1')\n\ndf_test = pd.read_csv('/kaggle/input/covid-19-nlp-text-classification/Corona_NLP_test.csv', \n                        encoding = 'latin-1')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fasttext classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"filtered_df_train = df_train[['Sentiment', 'OriginalTweet']]\nfiltered_df_test = df_test[['Sentiment', 'OriginalTweet']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"encoding = {'Extremely Negative': 'Negative',\n            'Negative': 'Negative',\n            'Neutral': 'Neutral',\n            'Positive':'Positive',\n            'Extremely Positive': 'Positive'\n           }\n\nfiltered_df_train['Sentiment'].replace(encoding, inplace=True)\nfiltered_df_test['Sentiment'].replace(encoding, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"filtered_df_train = preprocess_fasttext(filtered_df_train)\nfiltered_df_test = preprocess_fasttext(filtered_df_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Returns dataframes into txt files to train with fasttext"},{"metadata":{"trusted":true},"cell_type":"code","source":"filtered_df_train.to_csv('train.txt', header=False, index=False, sep=' ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filtered_df_test.to_csv('test.txt', header=False, index=False, sep=' ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ft_model = fasttext.train_supervised(input='train.txt', epoch=5, dim=200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ft_scores = ft_model.test('test.txt')\nft_scores[1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fasttext classification with pre-trained vectors"},{"metadata":{"trusted":true},"cell_type":"code","source":"filtered_df_train = df_train[['OriginalTweet', 'Sentiment']]\nfiltered_df_test = df_test[['OriginalTweet', 'Sentiment']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"encoding = {'Extremely Negative': 0,\n            'Negative': 0,\n            'Neutral': 1,\n            'Positive':2,\n            'Extremely Positive': 2\n           }\n\nfiltered_df_train['Sentiment'].replace(encoding, inplace=True)\nfiltered_df_test['Sentiment'].replace(encoding, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"filtered_df_train = preprocess_ft_vector(filtered_df_train)\nfiltered_df_test = preprocess_ft_vector(filtered_df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.stack(filtered_df_train['fasttext'])\ny_train = np.array(filtered_df_train['Sentiment'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = np.stack(filtered_df_test['fasttext'])\ny_test = np.array(filtered_df_test['Sentiment'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Use Support Vector Classification for vectorized tweets"},{"metadata":{"trusted":true},"cell_type":"code","source":"svm = SVC()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svm.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svm_pred= svm.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svm_score = metrics.accuracy_score(y_test, svm_pred)\nsvm_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### LSTM Classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = Tokenizer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filtered_df_train = df_train[['OriginalTweet', 'Sentiment']]\nfiltered_df_test = df_test[['OriginalTweet', 'Sentiment']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"encoding = {'Extremely Negative': 0,\n            'Negative': 0,\n            'Neutral': 1,\n            'Positive':2,\n            'Extremely Positive': 2\n           }\n\nfiltered_df_train['Sentiment'].replace(encoding, inplace=True)\nfiltered_df_test['Sentiment'].replace(encoding, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"filtered_df_train = preprocess_lstm(filtered_df_train)\nfiltered_df_test = preprocess_lstm(filtered_df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer.fit_on_texts(filtered_df_train['OriginalTweet'])\nvocab_len = len(tokenizer.word_index) + 1\n\nmax_len = np.max(filtered_df_train['OriginalTweet'].apply(lambda x :len(x)))\nprint(vocab_len, max_len)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = tokenizer.texts_to_sequences(filtered_df_train['OriginalTweet'])\nX_test = tokenizer.texts_to_sequences(filtered_df_test['OriginalTweet'])\n\ny_train = filtered_df_train['Sentiment']\ny_test = filtered_df_test['Sentiment']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = pad_sequences(X_train, maxlen= max_len, padding='post')\nX_test = pad_sequences(X_test, maxlen= max_len, padding='post')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\ny_train = to_categorical(y_train, 3)\ny_test = to_categorical(y_test, 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow.keras.layers as layers\nfrom tensorflow.keras.losses import CategoricalCrossentropy\nfrom tensorflow.keras.optimizers import Adam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_dim = 200\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Embedding(vocab_len, embedding_dim, input_length=X_train.shape[1]),\n    tf.keras.layers.LSTM(128, return_sequences=True),\n    tf.keras.layers.LSTM(128, return_sequences=True),\n    tf.keras.layers.LSTM(128, return_sequences=True),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.GlobalAveragePooling1D(),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.Dense(3, activation='softmax')\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='categorical_crossentropy',\n              optimizer='Adam',metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train, y_train, epochs=10, batch_size=32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lstm_score = model.evaluate(X_test, y_test)\nlstm_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Comparision of Scores"},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = pd.DataFrame({'Model' : ['LSTM', 'SVM', 'Fasttext'],\n          'Score' : [lstm_score[1], svm_score, ft_scores[1]]})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(5,5))\nax = sns.barplot(x=\"Model\", y=\"Score\", data=scores)\n\nfor index, row in scores.iterrows():\n    ax.text(index, row.Score, round(row.Score,3), color='black', ha=\"center\")\n    \nplt.title(\"Accuracy Score Table\")\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}