{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 0.Stablishing the goal\n<html>\n    <h1 style='background: #D3D3D3;  color:black; font-size:45px; padding:10px; border:8px solid black;'><center><b>üèÅ Goal</b></center></h1>\n</html>\n\nIn this notebook, we will explore a dataset(https://www.kaggle.com/spscientist/students-performance-in-exams), which contains 1000 entries of students.  \nThe main goal will be to stablish a **gender prediction** with ML based on the available features and conclude about the most important features in this prediction.","metadata":{}},{"cell_type":"markdown","source":"# 1.Importing\n<html>\n    <h1 style='background: #D3D3D3;  color:black; font-size:45px; padding:10px; border:8px solid black;'><center><b>üìö Importing Libraries and Data</b></center></h1>\n</html>","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# turn off warnings for final notebook\nimport warnings\nwarnings.filterwarnings('ignore')\n\npd.set_option('display.max_columns', None)\n%matplotlib inline\nsns.set_context('notebook')\nsns.set_palette('Set2')\nsns.set_style('darkgrid')","metadata":{"execution":{"iopub.status.busy":"2021-09-13T00:36:04.577162Z","iopub.execute_input":"2021-09-13T00:36:04.577627Z","iopub.status.idle":"2021-09-13T00:36:05.460916Z","shell.execute_reply.started":"2021-09-13T00:36:04.577585Z","shell.execute_reply":"2021-09-13T00:36:05.460126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Importing the dataset\ndf=pd.read_csv('../input/students-performance-in-exams/StudentsPerformance.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-13T00:36:05.462314Z","iopub.execute_input":"2021-09-13T00:36:05.462746Z","iopub.status.idle":"2021-09-13T00:36:05.502821Z","shell.execute_reply.started":"2021-09-13T00:36:05.462702Z","shell.execute_reply":"2021-09-13T00:36:05.501859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2.Exploring and Preparing\n<html>\n    <h1 style='background: #D3D3D3;  color:black; font-size:45px; padding:10px; border:8px solid black;'><center><b>üîé Exploring and Preparing</b></center></h1>\n</html>","metadata":{}},{"cell_type":"code","source":"# general information about the dataset\ndf.info()\ndf.isnull().sum().sort_values(ascending=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T00:36:05.504329Z","iopub.execute_input":"2021-09-13T00:36:05.504727Z","iopub.status.idle":"2021-09-13T00:36:05.533261Z","shell.execute_reply.started":"2021-09-13T00:36:05.504686Z","shell.execute_reply":"2021-09-13T00:36:05.532245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*No apparent absent data.  \n*The datatypes seem to be correct.","metadata":{}},{"cell_type":"markdown","source":"<html>\n    <h1 style='background: #D3D3D3;  color:black; font-size:30px; padding:10px; border:8px solid black;'><center><b>Numerical Variables</b></center></h1>\n</html>","metadata":{}},{"cell_type":"code","source":"num = df.select_dtypes(include=np.number)\nnum.columns","metadata":{"execution":{"iopub.status.busy":"2021-09-13T00:36:05.534759Z","iopub.execute_input":"2021-09-13T00:36:05.535074Z","iopub.status.idle":"2021-09-13T00:36:05.543348Z","shell.execute_reply.started":"2021-09-13T00:36:05.535044Z","shell.execute_reply":"2021-09-13T00:36:05.542312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig,ax = plt.subplots(figsize=(10,5))\n\nbplot=ax.boxplot(num,\n                 patch_artist=True,\n                labels=num.columns)\n\ncolors=['blue','red','green']\nfor patch, color in zip(bplot['boxes'], colors):\n    patch.set_facecolor(color)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T00:36:05.544441Z","iopub.execute_input":"2021-09-13T00:36:05.544891Z","iopub.status.idle":"2021-09-13T00:36:05.760084Z","shell.execute_reply.started":"2021-09-13T00:36:05.544826Z","shell.execute_reply":"2021-09-13T00:36:05.759098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"At the boxplot, we see some outliers, but nothing unexpected considering a school exam.","metadata":{}},{"cell_type":"code","source":"# Frequency distribution\nfig, axs = plt.subplots(nrows=1,ncols=3, figsize=(20,5), sharey=True, tight_layout=True)\n\nbin_num=30\ncolors=['blue','red','green']\nprops = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n\nfor i in range(0,3):\n    n, bins, patches = axs[i].hist(num[num.columns[i]],bins=bin_num,color=colors[i])\n    axs[i].set_title(num.columns[i], size=20,fontweight='bold')\n    axs[i].axvline(x=num[num.columns[i]].mean())\n    mu = num[num.columns[i]].mean()\n    sigma = num[num.columns[i]].std()\n    textstr = '\\n'.join((\n        r'$\\mu=%.2f$' % (mu, ),\n        r'$\\sigma=%.2f$' % (sigma, )))\n    axs[i].text(0.82*i, 0.95, textstr, transform=ax.transAxes, fontsize=14,\n        verticalalignment='top', bbox=props)\n    \naxs[0].set_ylabel('Frequency', size=20,fontweight='bold') ","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-09-13T00:36:05.761249Z","iopub.execute_input":"2021-09-13T00:36:05.761526Z","iopub.status.idle":"2021-09-13T00:36:06.913976Z","shell.execute_reply.started":"2021-09-13T00:36:05.761499Z","shell.execute_reply":"2021-09-13T00:36:06.913087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The frequency distribution, also doesn't show anything unexpected, but there seems to be some bias towards the score of 70 in all exams.","metadata":{}},{"cell_type":"code","source":"num.describe()","metadata":{"execution":{"iopub.status.busy":"2021-09-13T00:36:06.915299Z","iopub.execute_input":"2021-09-13T00:36:06.915784Z","iopub.status.idle":"2021-09-13T00:36:06.941272Z","shell.execute_reply.started":"2021-09-13T00:36:06.915736Z","shell.execute_reply":"2021-09-13T00:36:06.940205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10, 8))\nax.set_title(\"Correlation Matrix\\n\", size=20,fontweight='bold')\nsns.heatmap(num.corr(), annot=True,ax=ax,);","metadata":{"execution":{"iopub.status.busy":"2021-09-13T00:36:06.944119Z","iopub.execute_input":"2021-09-13T00:36:06.944449Z","iopub.status.idle":"2021-09-13T00:36:07.244551Z","shell.execute_reply.started":"2021-09-13T00:36:06.944415Z","shell.execute_reply":"2021-09-13T00:36:07.243294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here, we see the correlation matrix of the numerical variables, namely the exams scores.  \nWe observe a very strong correlation between \"writing score\" and the \"reading score\".  \nWe also see a strong correlation between \"writing score\" and \"math score\".\nIt can be concluded that the performance of the stundents tend to be rather linear, if they have higher( or lower) score in one domain, it is expected the other domains to also be higher(or lower) and vice versa.","metadata":{}},{"cell_type":"code","source":"plt.subplots(figsize=(7, 7))\nsns.kdeplot(data=num, x=\"reading score\", y=\"writing score\", levels=50, color=\"b\",thresh=0,cmap=\"rocket\",fill=True)\nsns.kdeplot(data=num, x=\"math score\", y=\"writing score\", levels=50, color=\"b\",thresh=0,cmap=\"rocket\",fill=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T00:36:07.247165Z","iopub.execute_input":"2021-09-13T00:36:07.247898Z","iopub.status.idle":"2021-09-13T00:36:09.610756Z","shell.execute_reply.started":"2021-09-13T00:36:07.247824Z","shell.execute_reply":"2021-09-13T00:36:09.609859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with sns.axes_style(\"white\"):\n    g = sns.pairplot(df, diag_kind=\"kde\",height= 4,corner=True,diag_kws={\"linewidth\": 0, \"shade\": False})\n    g.map_lower(sns.kdeplot,  levels=50, color=\"b\",thresh=0,cmap=\"rocket\",fill=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T00:36:09.612037Z","iopub.execute_input":"2021-09-13T00:36:09.612344Z","iopub.status.idle":"2021-09-13T00:36:14.328958Z","shell.execute_reply.started":"2021-09-13T00:36:09.612306Z","shell.execute_reply":"2021-09-13T00:36:14.3279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"g = sns.pairplot(df, diag_kind=\"kde\", height=4,hue='gender',corner=False)\ng.map_lower(sns.kdeplot,  levels=50,hue=None,thresh=0,cmap=\"rocket\",fill=True)\n\ng.fig.text(0.33, 1.02,'Distribution of Test Scores by Gender', fontsize=20)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T00:36:14.330523Z","iopub.execute_input":"2021-09-13T00:36:14.330837Z","iopub.status.idle":"2021-09-13T00:36:20.942483Z","shell.execute_reply.started":"2021-09-13T00:36:14.3308Z","shell.execute_reply":"2021-09-13T00:36:20.941611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we see the distribution of the scores, now also in respect to the gender of the students.\n* There is overlap among the distributions, but we can see that the female students have a better mean performance in writing and reading, the male students in the other hand, have a slight edge in math\n* When combined, the writing and math scores, make distinct areas when it comes to gender. Those probably will be relevant predictors in the model.\n* Due to the overlap, it is important to check for the statistical relevance of the differences, especially in regard to math scores, where the distributions seems to be somewhat similar.","metadata":{}},{"cell_type":"code","source":"from scipy.stats import ttest_ind\n'''\nFail to Reject H0: Sample distributions are equal.\nReject H0: Sample distributions are not equal.\n'''\nstat, p = ttest_ind(df['math score'][df['gender']=='female'], df['math score'][df['gender']=='male'])\nprint('Statistics=%.3f, p=%.3f \\n' % (stat, p))\n# interpret\nalpha = 0.05\nprint(\"Comparison between the math score of male and female students: \")\nif p > alpha:\n    print('Same distributions (fail to reject H0)')\nelse:\n    print('Different distributions (reject H0)')","metadata":{"execution":{"iopub.status.busy":"2021-09-13T00:36:20.943765Z","iopub.execute_input":"2021-09-13T00:36:20.944236Z","iopub.status.idle":"2021-09-13T00:36:20.955658Z","shell.execute_reply.started":"2021-09-13T00:36:20.944204Z","shell.execute_reply":"2021-09-13T00:36:20.954651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<html>\n    <h1 style='background: #D3D3D3;  color:black; font-size:30px; padding:10px; border:8px solid black;'><center><b>Categorical Variables</b></center></h1>\n</html>","metadata":{}},{"cell_type":"code","source":"cat = df.select_dtypes(exclude=np.number)\nprint(\"List of categorical variables:\")\ncat.columns","metadata":{"execution":{"iopub.status.busy":"2021-09-13T00:36:20.957159Z","iopub.execute_input":"2021-09-13T00:36:20.957542Z","iopub.status.idle":"2021-09-13T00:36:20.975154Z","shell.execute_reply.started":"2021-09-13T00:36:20.95751Z","shell.execute_reply":"2021-09-13T00:36:20.974158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def label_function(val):\n    return f'{val / 100 * len(df):.0f}\\n{val:.0f}%'\n\nfig, axs = plt.subplots(3,2, figsize=(15, 15))\nfor i in range(0,5):\n    cat.groupby(cat.columns[i]).size().plot(kind='pie', autopct=label_function, textprops={'fontsize': 13}, cmap='tab20c', ax=axs[int((i-i%2)/2),i%2])\n    axs[int((i-i%2)/2),i%2].set_title(cat.columns[i], size=20,fontweight='bold')\n    axs[int((i-i%2)/2),i%2].set_ylabel(None)\n\nplt.axis('off')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-13T00:36:20.976753Z","iopub.execute_input":"2021-09-13T00:36:20.97742Z","iopub.status.idle":"2021-09-13T00:36:21.762935Z","shell.execute_reply.started":"2021-09-13T00:36:20.977376Z","shell.execute_reply":"2021-09-13T00:36:21.761945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we see the distribution of the students among the categorical variables. No anomalities perceived.","metadata":{}},{"cell_type":"markdown","source":"<html>\n    <h1 style='background: #D3D3D3;  color:black; font-size:30px; padding:10px; border:8px solid black;'><center><b>Categorical X Numerical Variables</b></center></h1>\n</html>","metadata":{}},{"cell_type":"markdown","source":"The following plot allow us to have a bird-eye view of the distribution of the numerical variables along the categorical variables. The main point is to detect anomalies or behaviours of interest.","metadata":{}},{"cell_type":"code","source":"fig,ax = plt.subplots(5,3,figsize=(30, 20))\nfor i in range(0,5):\n    for j in range(0,3):\n        sns.violinplot(ax=ax[i,j], x=cat[cat.columns[i]], y=num[num.columns[j]], data=df)","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-09-13T00:36:21.76437Z","iopub.execute_input":"2021-09-13T00:36:21.764959Z","iopub.status.idle":"2021-09-13T00:36:24.87963Z","shell.execute_reply.started":"2021-09-13T00:36:21.764916Z","shell.execute_reply":"2021-09-13T00:36:24.878673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After the general view, we can inspect particulary interesting plots with the following graph.\nLet's take for instance the writing scores and the parental level of education:","metadata":{}},{"cell_type":"code","source":"fig,ax = plt.subplots(figsize=(15, 10))\nedu_order=order= [ \n        'some high school',\n        'high school',\n        'some college',\n        \"associate's degree\",\n        \"bachelor's degree\",  \n        \"master's degree\"]\nax = sns.violinplot(x=\"parental level of education\", y=\"writing score\", data=df, inner=None, order= edu_order)\nax = sns.swarmplot(x=\"parental level of education\", y=\"writing score\", data=df,\n                   color=\"white\", edgecolor=\"gray\",order= edu_order)\nt = ax.text(\n    0.2, 2, \"Small improvement in the writing scores along parental education\", ha=\"left\", va=\"center\", rotation=0, size=13,\n    bbox=dict(boxstyle=\"rarrow,pad=0.3\", fc=\"#CBC3E3\", ec=\"#301934\", lw=1))","metadata":{"execution":{"iopub.status.busy":"2021-09-13T01:03:52.357709Z","iopub.execute_input":"2021-09-13T01:03:52.358241Z","iopub.status.idle":"2021-09-13T01:03:53.01275Z","shell.execute_reply.started":"2021-09-13T01:03:52.358196Z","shell.execute_reply":"2021-09-13T01:03:53.01149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we can see a small but clear improvement in the writing scores as the parental level of education increases.","metadata":{}},{"cell_type":"code","source":"g = sns.FacetGrid(df, col=\"race/ethnicity\", hue=\"gender\")\ng.map(sns.histplot, \"math score\", alpha=0.5)\ng.add_legend()","metadata":{"execution":{"iopub.status.busy":"2021-09-13T00:36:25.54645Z","iopub.execute_input":"2021-09-13T00:36:25.546838Z","iopub.status.idle":"2021-09-13T00:36:27.49703Z","shell.execute_reply.started":"2021-09-13T00:36:25.546809Z","shell.execute_reply":"2021-09-13T00:36:27.496162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3.Processing\n<html>\n    <h1 style='background: #D3D3D3;  color:black; font-size:45px; padding:10px; border:8px solid black;'><center><b>üõ† Processing</b></center></h1>\n</html>","metadata":{}},{"cell_type":"code","source":"# We are going to process data\n#First we have to give different treatment to three classes: ordinal Categorical features, non-ordinal Categorical features and Numerical features.\n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import OrdinalEncoder\n\ncat = df.select_dtypes(exclude=np.number)\nnum = df.drop(columns=cat.columns) # Numerical features\nprint(\"Number of unique values per categorical feature:\\n\", cat.nunique())\n\ncat_ord = cat[['parental level of education','gender']] # ordinal categorical features\ncat.drop(columns=['parental level of education','gender'],inplace=True) #non-ordinal categorical features\n\n\n#Encoding ordinal categorical features\n\n# define order\norder_1 = [ \n        'some high school',\n        'high school',\n        'some college',\n        \"associate's degree\",\n        \"bachelor's degree\",  \n        \"master's degree\"]\norder_2 =['male','female']\n\n# define ordinal encoding\nencoder = OrdinalEncoder(categories=[order_1,order_2])\n# transform data\nencoder.fit(cat_ord[['parental level of education','gender']])\ncat_ord_encoded = pd.DataFrame(encoder.transform(cat_ord[['parental level of education','gender']]))\n\ncat_ord_encoded.columns = ['parental level of education','gender']\n\n\n#Encoding  non-ordinal categorical features\n\nenc = OneHotEncoder(sparse=False).fit(cat)\ncat_encoded = pd.DataFrame(enc.transform(cat))\ncat_encoded.columns = enc.get_feature_names(cat.columns)\n\n# Numerical features will be standardized\nfrom sklearn.preprocessing import StandardScaler\nnum.iloc[:, 0:3] = StandardScaler().fit_transform(num.iloc[:, 0:3])","metadata":{"execution":{"iopub.status.busy":"2021-09-13T00:36:27.498426Z","iopub.execute_input":"2021-09-13T00:36:27.498732Z","iopub.status.idle":"2021-09-13T00:36:27.666067Z","shell.execute_reply.started":"2021-09-13T00:36:27.498702Z","shell.execute_reply":"2021-09-13T00:36:27.665299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# merge numeric and categorical data\ndf2 = pd.concat([cat_encoded,cat_ord_encoded, num], axis=1)\ndf2.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-13T00:36:27.667028Z","iopub.execute_input":"2021-09-13T00:36:27.667333Z","iopub.status.idle":"2021-09-13T00:36:27.696366Z","shell.execute_reply.started":"2021-09-13T00:36:27.667305Z","shell.execute_reply":"2021-09-13T00:36:27.695316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now the dataset is ready to be inserted in a model","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = df2.drop(columns='gender')\ny = df2['gender']\n\n\nx_train , x_test , y_train, y_test = train_test_split(X,y,test_size = 0.2 , random_state = 23)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T00:36:27.69782Z","iopub.execute_input":"2021-09-13T00:36:27.698272Z","iopub.status.idle":"2021-09-13T00:36:27.76679Z","shell.execute_reply.started":"2021-09-13T00:36:27.698229Z","shell.execute_reply":"2021-09-13T00:36:27.765951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here, we split the dataset so we can test it for accuracy after modelling.","metadata":{}},{"cell_type":"markdown","source":"# 4.Prediction\n<html>\n    <h1 style='background: #D3D3D3;  color:black; font-size:45px; padding:10px; border:8px solid black;'><center><b>üîÆ Prediction</b></center></h1>\n</html>","metadata":{}},{"cell_type":"markdown","source":"## 4.1 Random Forest","metadata":{}},{"cell_type":"code","source":"score_list = []\nfrom sklearn.ensemble import RandomForestClassifier\nfor each in range (1,100):\n    rf = RandomForestClassifier(n_estimators = each,random_state = 7,bootstrap = \"False\",criterion=\"gini\",\n                                min_samples_split = 10 , min_samples_leaf = 1)\n    rf.fit(x_train,y_train)\n    score_list.append(rf.score(x_test,y_test))\n    \nrf_max = np.max(score_list)\nprint(\"RF Max Score : \",rf_max)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T00:36:27.767872Z","iopub.execute_input":"2021-09-13T00:36:27.768283Z","iopub.status.idle":"2021-09-13T00:36:40.009101Z","shell.execute_reply.started":"2021-09-13T00:36:27.768253Z","shell.execute_reply":"2021-09-13T00:36:40.00834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.subplots(figsize=(7, 7))\nplt.plot(score_list)\nplt.title(\"Accuracy x estimators\\n\", size=20,fontweight='bold')","metadata":{"execution":{"iopub.status.busy":"2021-09-13T00:36:40.010159Z","iopub.execute_input":"2021-09-13T00:36:40.010571Z","iopub.status.idle":"2021-09-13T00:36:40.21022Z","shell.execute_reply.started":"2021-09-13T00:36:40.010541Z","shell.execute_reply":"2021-09-13T00:36:40.209103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We can expect the random forest Classifier to have an accuracy around 85%.**","metadata":{}},{"cell_type":"code","source":"#Training with the best number of estimators\n\nbest = score_list.index(max(score_list)) + 1\n\nrf = RandomForestClassifier(n_estimators = best,random_state = 7,bootstrap = \"False\",criterion=\"gini\",\n                            min_samples_split = 10 , min_samples_leaf = 1)\nrf.fit(x_train,y_train)\n\n\nfrom sklearn.metrics import plot_confusion_matrix\n\nwith sns.axes_style(\"white\"):\n    titles_options = [(\"Confusion matrix, without normalization\", None),\n                      (\"Normalized confusion matrix\", 'true')]\n    class_names = ['Male','Female']\n    for title, normalize in titles_options:\n        fig, ax = plt.subplots(figsize=(7, 7))\n        disp = plot_confusion_matrix(rf, x_test, y_test,\n                                     display_labels=class_names,\n                                     cmap='rocket',\n                                     normalize=normalize,\n                                    ax=ax)\n        disp.ax_.set_title(title)\n\n        print(title)\n        print(disp.confusion_matrix)\n    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-13T00:36:40.214006Z","iopub.execute_input":"2021-09-13T00:36:40.21433Z","iopub.status.idle":"2021-09-13T00:36:40.872231Z","shell.execute_reply.started":"2021-09-13T00:36:40.2143Z","shell.execute_reply":"2021-09-13T00:36:40.871087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The confusion matrix show us that given the data available, it is easier to predict female students(90% accuracy). Male students incur in more false labelling as females(17%).","metadata":{}},{"cell_type":"markdown","source":"## 4.2 Support Vector Machine","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\nsvm1 = SVC(gamma = 0.01 , C = 500 , kernel = \"rbf\")\nsvm1.fit(x_train,y_train)\nsvm1_score = svm1.score(x_test,y_test)\nprint(\"SVM Max Score = : \", svm1_score)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T00:36:40.874662Z","iopub.execute_input":"2021-09-13T00:36:40.875167Z","iopub.status.idle":"2021-09-13T00:36:40.919597Z","shell.execute_reply.started":"2021-09-13T00:36:40.87511Z","shell.execute_reply":"2021-09-13T00:36:40.918324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with sns.axes_style(\"white\"):\n    titles_options = [(\"Confusion matrix, without normalization\", None),\n                      (\"Normalized confusion matrix\", 'true')]\n    class_names = ['Male','Female']\n    for title, normalize in titles_options:\n        fig, ax = plt.subplots(figsize=(7, 7))\n        disp = plot_confusion_matrix(svm1, x_test, y_test,\n                                     display_labels=class_names,\n                                     cmap='rocket',\n                                     normalize=normalize,\n                                    ax=ax)\n        disp.ax_.set_title(title)\n\n        print(title)\n        print(disp.confusion_matrix)\n    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-13T00:36:40.920923Z","iopub.execute_input":"2021-09-13T00:36:40.921227Z","iopub.status.idle":"2021-09-13T00:36:41.407729Z","shell.execute_reply.started":"2021-09-13T00:36:40.921194Z","shell.execute_reply":"2021-09-13T00:36:41.406669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**With the support vector machine model, we can expect a accuracy of 89,5%.**","metadata":{}},{"cell_type":"markdown","source":"# 5.Relative Relevance of features\n<html>\n    <h1 style='background: #D3D3D3;  color:black; font-size:45px; padding:10px; border:8px solid black;'><center><b>ü•á Most relevant features</b></center></h1>\n</html>","metadata":{}},{"cell_type":"code","source":"import eli5\nfrom eli5.sklearn import PermutationImportance\n\nperm = PermutationImportance(rf, random_state=1).fit(x_test, y_test)\neli5.show_weights(perm, feature_names = x_test.columns.tolist(), top=7)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T00:36:41.410083Z","iopub.execute_input":"2021-09-13T00:36:41.410532Z","iopub.status.idle":"2021-09-13T00:36:50.313312Z","shell.execute_reply.started":"2021-09-13T00:36:41.410482Z","shell.execute_reply":"2021-09-13T00:36:50.312296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To establish the relative relevance of the features in predicting the gender of the student, we are going to model a Random Forest Regressor, so that the target variable become continuous. Afterward we are going to apply the **SHAP (SHapley Additive exPlanations)** to rank order the features. ","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nbest = score_list.index(max(score_list)) + 1\n\nrf_reg = RandomForestRegressor(n_estimators = best,random_state = 7,bootstrap = \"False\",criterion=\"mse\",\n                            min_samples_split = 10 , min_samples_leaf = 1)\nrf_reg.fit(x_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T00:36:50.316656Z","iopub.execute_input":"2021-09-13T00:36:50.316996Z","iopub.status.idle":"2021-09-13T00:36:50.54788Z","shell.execute_reply.started":"2021-09-13T00:36:50.316966Z","shell.execute_reply":"2021-09-13T00:36:50.546807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shap\n\n# calculate shap values \nex = shap.Explainer(rf_reg)\nshap_val = ex(x_test)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-09-13T00:36:50.549368Z","iopub.execute_input":"2021-09-13T00:36:50.549772Z","iopub.status.idle":"2021-09-13T00:36:53.420663Z","shell.execute_reply.started":"2021-09-13T00:36:50.549731Z","shell.execute_reply":"2021-09-13T00:36:53.419434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap.plots.bar(shap_val, show=False)\nplt.title('Mean SHAP value per feature\\n Gender Analysis',size=20,fontweight='bold')","metadata":{"execution":{"iopub.status.busy":"2021-09-13T00:36:53.422984Z","iopub.execute_input":"2021-09-13T00:36:53.423429Z","iopub.status.idle":"2021-09-13T00:36:53.768715Z","shell.execute_reply.started":"2021-09-13T00:36:53.423381Z","shell.execute_reply":"2021-09-13T00:36:53.767539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we see that the most important variables when predicting the target feature, namely \"gender\",are the writing, math and reading scores.  \nAll other variables are dispensable.","metadata":{}},{"cell_type":"code","source":"# plot\n\nplt.title('SHAP summary for Gender prediction', size=20)\nshap.plots.beeswarm(shap_val, max_display=5,show=False)\nfig = plt.gcf()\nfig.set_figheight(7)\nfig.set_figwidth(12)\nax = plt.gca()\nax.set_xlabel(r'Average SHAP values', fontsize=16)\nax.set_ylabel('Parameters', fontsize=16)\nleg = ax.legend()\nt = ax.text(\n    0.05, -0.6, \"Predict female\", ha=\"left\", va=\"center\", rotation=0, size=13,\n    bbox=dict(boxstyle=\"rarrow,pad=0.3\", fc=\"#CBC3E3\", ec=\"#301934\", lw=1))\nt = ax.text(\n    -0.05, -0.6, \"Predict male\", ha=\"right\", va=\"center\", rotation=0, size=13,\n    bbox=dict(boxstyle=\"larrow,pad=0.3\", fc=\"#CBC3E3\", ec=\"#301934\", lw=1))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-13T00:36:53.770368Z","iopub.execute_input":"2021-09-13T00:36:53.77078Z","iopub.status.idle":"2021-09-13T00:36:54.152777Z","shell.execute_reply.started":"2021-09-13T00:36:53.770728Z","shell.execute_reply":"2021-09-13T00:36:54.151759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This beeswarp graph shows the dispersion of the SHAP values along the variables. As expected the three test scores contribute with higher absolute values, giving more certainty to the model prediction.","metadata":{}},{"cell_type":"code","source":"shap.initjs()\nshap.plots.force(shap_val[10])","metadata":{"execution":{"iopub.status.busy":"2021-09-13T00:36:54.153993Z","iopub.execute_input":"2021-09-13T00:36:54.15429Z","iopub.status.idle":"2021-09-13T00:36:54.187694Z","shell.execute_reply.started":"2021-09-13T00:36:54.154261Z","shell.execute_reply":"2021-09-13T00:36:54.186511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class color:\n   PURPLE = '\\033[95m'\n   CYAN = '\\033[96m'\n   DARKCYAN = '\\033[36m'\n   BLUE = '\\033[94m'\n   GREEN = '\\033[92m'\n   YELLOW = '\\033[93m'\n   RED = '\\033[91m'\n   BOLD = '\\033[1m'\n   UNDERLINE = '\\033[4m'\n   END = '\\033[0m'\n\nprint(color.BOLD + \"Individual number 280\\n\" + color.END)\nprint(x_test.iloc[10])\nprint(color.BOLD + y_test.map({1:'female',0:\"male\"}).iloc[10] + color.END)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T00:36:54.189196Z","iopub.execute_input":"2021-09-13T00:36:54.189587Z","iopub.status.idle":"2021-09-13T00:36:54.202884Z","shell.execute_reply.started":"2021-09-13T00:36:54.189546Z","shell.execute_reply":"2021-09-13T00:36:54.201734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we apply the SHAP waterfall to a single individual. This allow us to follow the path the model takes and helps to understand why the top three variables are determinant in the assertion","metadata":{}},{"cell_type":"code","source":"explainer = shap.TreeExplainer(rf_reg)\nshap_values = explainer.shap_values(x_test)\nshap.dependence_plot(\"writing score\", shap_values, x_test,show=False)\nfig = plt.gcf()\nfig.set_figheight(7)\nfig.set_figwidth(10)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T00:36:54.204481Z","iopub.execute_input":"2021-09-13T00:36:54.204958Z","iopub.status.idle":"2021-09-13T00:36:54.611876Z","shell.execute_reply.started":"2021-09-13T00:36:54.204914Z","shell.execute_reply":"2021-09-13T00:36:54.610779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<html>\n    <h1 style='background: #D3D3D3;  color:black; font-size:45px; padding:10px; border:8px solid black;'><center><b>üòâ Upvote if you liked the content.</b></center></h1>\n</html>","metadata":{}},{"cell_type":"markdown","source":"## BONUS: This method can also be applied to predict numerical values\n<html>\n    <h1 style='background: #D3D3D3;  color:black; font-size:45px; padding:10px; border:8px solid black;'><center><b>Math Score Prediction</b></center></h1>\n</html>","metadata":{}},{"cell_type":"code","source":"X = df2.drop(columns='math score')\ny = df2['math score']\n\n\nx_train , x_test , y_train, y_test = train_test_split(X,y,test_size = 0.2 , random_state = 23)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T00:36:54.613381Z","iopub.execute_input":"2021-09-13T00:36:54.613689Z","iopub.status.idle":"2021-09-13T00:36:54.621254Z","shell.execute_reply.started":"2021-09-13T00:36:54.61366Z","shell.execute_reply":"2021-09-13T00:36:54.620281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nbest = score_list.index(max(score_list)) + 1\n\nrf_reg = RandomForestRegressor(n_estimators = best,random_state = 7,bootstrap = \"False\",criterion=\"mse\",\n                            min_samples_split = 10 , min_samples_leaf = 1)\nrf_reg.fit(x_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T00:36:54.622553Z","iopub.execute_input":"2021-09-13T00:36:54.622868Z","iopub.status.idle":"2021-09-13T00:36:54.867534Z","shell.execute_reply.started":"2021-09-13T00:36:54.62282Z","shell.execute_reply":"2021-09-13T00:36:54.8666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score_list = []\nfor each in range (1,100):\n    rf = RandomForestRegressor(n_estimators = each,random_state = 7,bootstrap = \"False\",criterion=\"mse\",\n                                min_samples_split = 10 , min_samples_leaf = 1)\n    rf.fit(x_train,y_train)\n    score_list.append(rf.score(x_test,y_test))\n    \nrf_max = np.max(score_list)\nprint(\"RF Max Score : \",rf_max)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T00:36:54.870987Z","iopub.execute_input":"2021-09-13T00:36:54.871306Z","iopub.status.idle":"2021-09-13T00:37:08.975188Z","shell.execute_reply.started":"2021-09-13T00:36:54.871274Z","shell.execute_reply":"2021-09-13T00:37:08.973975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.subplots(figsize=(7, 7))\nplt.plot(score_list)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T00:37:08.976613Z","iopub.execute_input":"2021-09-13T00:37:08.977033Z","iopub.status.idle":"2021-09-13T00:37:09.190464Z","shell.execute_reply.started":"2021-09-13T00:37:08.97699Z","shell.execute_reply":"2021-09-13T00:37:09.188493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best = score_list.index(max(score_list)) + 1\n\nrf = RandomForestRegressor(n_estimators = best, random_state = 7 ,criterion=\"mse\",\n                            min_samples_split = 10 , min_samples_leaf = 1)\nrf.fit(x_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T00:37:09.192344Z","iopub.execute_input":"2021-09-13T00:37:09.19289Z","iopub.status.idle":"2021-09-13T00:37:09.44547Z","shell.execute_reply.started":"2021-09-13T00:37:09.192813Z","shell.execute_reply":"2021-09-13T00:37:09.444364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shap\n\n# calculate shap values \nex = shap.Explainer(rf)\nshap_val = ex(x_test)\n\n# plot\n\nplt.title('SHAP summary for math score prediction', size=16)\nshap.plots.beeswarm(shap_val, max_display=5,show=False)\nfig = plt.gcf()\nfig.set_figheight(7)\nfig.set_figwidth(12)\nax = plt.gca()\nax.set_xlabel(r'Average SHAP values', fontsize=16)\nax.set_ylabel('Parameters', fontsize=16)\nleg = ax.legend()\nt = ax.text(\n    0.05, -0.6, \"Predict higher math score\", ha=\"left\", va=\"center\", rotation=0, size=13,\n    bbox=dict(boxstyle=\"rarrow,pad=0.3\", fc=\"#CBC3E3\", ec=\"#301934\", lw=1))\nt = ax.text(\n    -0.05, -0.6, \"Predict lower math score\", ha=\"right\", va=\"center\", rotation=0, size=13,\n    bbox=dict(boxstyle=\"larrow,pad=0.3\", fc=\"#CBC3E3\", ec=\"#301934\", lw=1))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-13T01:06:54.481564Z","iopub.execute_input":"2021-09-13T01:06:54.482063Z","iopub.status.idle":"2021-09-13T01:06:55.346124Z","shell.execute_reply.started":"2021-09-13T01:06:54.482025Z","shell.execute_reply":"2021-09-13T01:06:55.344961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"select = range(5)\nfeatures = x_test.iloc[select]\nfeatures_display = x_test.loc[features.index]\nshap.decision_plot(ex.expected_value,ex.shap_values(features)[0:5] , features_display) ","metadata":{"execution":{"iopub.status.busy":"2021-09-13T01:02:16.777461Z","iopub.execute_input":"2021-09-13T01:02:16.777828Z","iopub.status.idle":"2021-09-13T01:02:17.372876Z","shell.execute_reply.started":"2021-09-13T01:02:16.777795Z","shell.execute_reply":"2021-09-13T01:02:17.371819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap.plots.force(shap_val[2],figsize=(10,5))","metadata":{"execution":{"iopub.status.busy":"2021-09-13T00:37:10.799933Z","iopub.execute_input":"2021-09-13T00:37:10.80027Z","iopub.status.idle":"2021-09-13T00:37:10.808343Z","shell.execute_reply.started":"2021-09-13T00:37:10.800238Z","shell.execute_reply":"2021-09-13T00:37:10.807411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class color:\n   PURPLE = '\\033[95m'\n   CYAN = '\\033[96m'\n   DARKCYAN = '\\033[36m'\n   BLUE = '\\033[94m'\n   GREEN = '\\033[92m'\n   YELLOW = '\\033[93m'\n   RED = '\\033[91m'\n   BOLD = '\\033[1m'\n   UNDERLINE = '\\033[4m'\n   END = '\\033[0m'\n\nprint(color.BOLD + \"Individual number 167\\n\" + color.END)\nprint(rf.predict(x_test[16:17]))\nprint(  df['math score'].describe().loc['mean']   + (rf.predict(x_test[10:11]))[0]*df['math score'].describe().loc['std'])\n\n\nprint(x_test.iloc[16])\nprint(color.BOLD + str(df['math score'].loc[705]) + color.END)\nprint(color.BOLD + str(df['math score'].describe().loc['mean'] +y_test.loc[705]*df['math score'].describe().loc['std']) + color.END)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T00:37:10.809764Z","iopub.execute_input":"2021-09-13T00:37:10.810061Z","iopub.status.idle":"2021-09-13T00:37:10.857956Z","shell.execute_reply.started":"2021-09-13T00:37:10.810034Z","shell.execute_reply":"2021-09-13T00:37:10.857049Z"},"trusted":true},"execution_count":null,"outputs":[]}]}