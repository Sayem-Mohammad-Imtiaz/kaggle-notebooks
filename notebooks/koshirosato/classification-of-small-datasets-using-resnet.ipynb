{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1><font size=\"6\">Classification of small datasets using ResNet</font></h1>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Here is an example implementation using a small image dataset. There are 210 images and 10 classes in this dataset.\n\nThanks to [Olga Belitskaya] for publishing this dataset.\n\n[Olga Belitskaya]: https://www.kaggle.com/olgabelitskaya","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Import libraries","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.applications import ResNet50, ResNet101, ResNet152\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Set configurations and read metadata","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"SEED = 42\nEPOCHS = 50\nBATCH_SIZE = 32 \nIMG_SIZE = 256\nROOT = '../input/flower-color-images/flower_images/flower_images/'\n\ndf = pd.read_csv(ROOT + 'flower_labels.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def seed_everything(seed):\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    tf.random.set_seed(seed)\n\nseed_everything(SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.replace({0:'phlox',1:'rose',2:'calendula',3:'iris',4:'leucanthemum maximum',\n                 5:'bellflower',6:'viola',7:'rudbeckia laciniata',\n                 8:'peony',9:'aquilegia'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.label.value_counts().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plot images","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def img_plot(df):\n    imgs = []\n    labels = []\n    df = df.sample(frac=1)\n    for file, label in zip(df['file'][:25], df['label'][:25]):\n        img = cv2.imread(ROOT+file)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        imgs.append(img)\n        labels.append(label)\n    f, ax = plt.subplots(5, 5, figsize=(15,15))\n    for i, img in enumerate(imgs):\n        ax[i//5, i%5].imshow(img)\n        ax[i//5, i%5].axis('off')\n        ax[i//5, i%5].set_title(labels[i])\n    plt.show()\n\nimg_plot(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create datasets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df, test_df = train_test_split(df, \n                                     test_size=0.5, \n                                     random_state=SEED, \n                                     stratify=df['label'].values)\n\n\n\ndef create_datasets(df, img_size):\n    imgs = []\n    for file in tqdm(df['file']):\n        img = cv2.imread(ROOT+file)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = cv2.resize(img, (img_size,img_size))\n        imgs.append(img)\n    # not normalize    \n    imgs = np.array(imgs)\n    df = pd.get_dummies(df['label'])\n    return imgs, df\n\n\ntrain_imgs, train_df = create_datasets(train_df, IMG_SIZE)\ntest_imgs, test_df = create_datasets(test_df, IMG_SIZE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Build the model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Using ResNet50","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"num_classes = len(df.label.value_counts())\n\ndef build_model(ResNet, img_size, n):\n    inp = Input(shape=(img_size,img_size, n))\n    resnet = ResNet(input_shape=(img_size,img_size,n),\n                    weights='imagenet',\n                    include_top=False)\n    # freeze ResNet\n    resnet.trainable = False\n    x = resnet(inp)\n    x = GlobalAveragePooling2D()(x)\n    x = Dropout(0.5)(x)\n    x = Dense(num_classes, activation='softmax')(x)\n    model = tf.keras.Model(inputs=inp, outputs=x)\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    return model\n\n\nresnet50 = build_model(ResNet50, IMG_SIZE, 3)\nresnet50.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = tf.keras.callbacks.ModelCheckpoint('resnet50.h5', \n                                                monitor='loss', \n                                                save_best_only=True,\n                                                save_weights_only=True)\n\nresnet50.fit(train_imgs, train_df, batch_size=BATCH_SIZE,\n          epochs=EPOCHS, verbose=0, callbacks=[checkpoint])\nresnet50.load_weights('resnet50.h5')\n\n\nresnet50.evaluate(test_imgs, test_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Using ResNet101","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet101 = build_model(ResNet101, IMG_SIZE, 3)\nresnet101.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = tf.keras.callbacks.ModelCheckpoint('resnet101.h5', \n                                                monitor='loss', \n                                                save_best_only=True,\n                                                save_weights_only=True)\n\nresnet101.fit(train_imgs, train_df, batch_size=BATCH_SIZE,\n              epochs=EPOCHS, verbose=0, callbacks=[checkpoint])\nresnet101.load_weights('resnet101.h5')\n\nresnet101.evaluate(test_imgs, test_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Using ResNet152","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet152 = build_model(ResNet152, IMG_SIZE, 3)\nresnet152.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = tf.keras.callbacks.ModelCheckpoint('resnet152.h5', \n                                                monitor='loss', \n                                                save_best_only=True,\n                                                save_weights_only=True)\n\nresnet152.fit(train_imgs, train_df, batch_size=BATCH_SIZE,\n              epochs=EPOCHS, verbose=0, callbacks=[checkpoint])\nresnet152.load_weights('resnet152.h5')\n\nresnet152.evaluate(test_imgs, test_df)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}