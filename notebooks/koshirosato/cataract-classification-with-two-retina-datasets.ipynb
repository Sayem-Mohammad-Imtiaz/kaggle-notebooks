{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1><font size=\"6\">Cataract Classification</font></h1>\n\nIn this notebook, uses two retina datasets to challenge the cataract classification.\n\n## Contents\n* [Import libraries](#import)\n* [Set configurations and read metadata](#set)\n* [Process Cataract dataset](#process1)\n* [Process Ocular disease recognition dataset](#process2)\n* [Create datasets](#create)\n* [Build the model(1)](#build1)\n* [Build the model(2)](#build2)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Import libraries <a name=\"import\"> </a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -q efficientnet >> /dev/null","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os, glob, cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import get_custom_objects\nimport efficientnet.tfkeras as efn\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Set configurations and read metadata <a name=\"set\"> </a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"SEED = 42\nEPOCHS = 100\nBATCH_SIZE = 32\nIMG_HEIGHT = 192\nIMG_WIDTH = 256\n\n# cataract dataset\nIMG_ROOT = '../input/cataractdataset/dataset/'\nIMG_DIR = [IMG_ROOT+'1_normal', \n           IMG_ROOT+'2_cataract', \n           IMG_ROOT+'2_glaucoma', \n           IMG_ROOT+'3_retina_disease']\n\n# ocular-disease-recognition dataset\nOCU_IMG_ROOT = '../input/ocular-disease-recognition-odir5k/ODIR-5K/Training Images/'\nocu_df = pd.read_excel('../input/ocular-disease-recognition-odir5k/ODIR-5K/data.xlsx')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def seed_everything(seed):\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    tf.random.set_seed(seed)\n\nseed_everything(SEED)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Process Cataract dataset <a name=\"process1\"> </a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_df = pd.DataFrame(0, \n                  columns=['paths', \n                           'cataract'],\n                  index=range(601))\n\nfilepaths = glob.glob(IMG_ROOT + '*/*')\n\n\nfor i, filepath in enumerate(filepaths):\n    filepath = os.path.split(filepath)\n    cat_df.iloc[i, 0] = filepath[0] + '/' + filepath[1]\n    \n    if filepath[0] == IMG_DIR[0]:    # normal\n        cat_df.iloc[i, 1] = 0\n    elif filepath[0] == IMG_DIR[1]:  # cataract\n        cat_df.iloc[i, 1] = 1\n    elif filepath[0] == IMG_DIR[2]:  # glaucoma\n        cat_df.iloc[i, 1] = 2\n    elif filepath[0] == IMG_DIR[3]:  # retine_disease\n        cat_df.iloc[i, 1] = 3\n        \n# only sample normal and cataract        \ncat_df = cat_df.query('0 <= cataract < 2')\ncat_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of normal and cataract images')\nprint(cat_df['cataract'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Process Ocular disease recognition dataset <a name=\"process2\"> </a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ocu_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def has_cataract_mentioned(text):\n    if 'cataract' in text:\n        return 1\n    else:\n        return 0\n    \nocu_df['left_eye_cataract'] = ocu_df['Left-Diagnostic Keywords']\\\n                                 .apply(lambda x: has_cataract_mentioned(x))\nocu_df['right_eye_cataract'] = ocu_df['Right-Diagnostic Keywords']\\\n                                 .apply(lambda x: has_cataract_mentioned(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le_df = ocu_df.loc[:, ['Left-Fundus', 'left_eye_cataract']]\\\n        .rename(columns={'left_eye_cataract':'cataract'})\nle_df['paths'] = OCU_IMG_ROOT + le_df['Left-Fundus']\nle_df = le_df.drop('Left-Fundus', axis=1)\n\n\nre_df = ocu_df.loc[:, ['Right-Fundus', 'right_eye_cataract']]\\\n        .rename(columns={'right_eye_cataract':'cataract'})\nre_df['paths'] = OCU_IMG_ROOT + re_df['Right-Fundus']\nre_df = re_df.drop('Right-Fundus', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"re_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of left eye images')\nprint(le_df['cataract'].value_counts())\nprint('\\nNumber of right eye images')\nprint(re_df['cataract'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is a large bias in the dataset. So make it even.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def downsample(df):\n    df = pd.concat([\n        df.query('cataract==1'),\n        df.query('cataract==0').sample(sum(df['cataract']), \n                                       random_state=SEED)\n    ])\n    return df\n\n\nle_df = downsample(le_df)\nre_df = downsample(re_df)\n\nprint('Number of left eye images')\nprint(le_df['cataract'].value_counts())\nprint('\\nNumber of right eye images')\nprint(re_df['cataract'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ocu_df = pd.concat([le_df, re_df])\nocu_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create datasets <a name=\"create\"> </a>\nCombine the two metadata and use them to load the image data and create datasets.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([cat_df, ocu_df], ignore_index=True)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df, test_df = train_test_split(df, \n                                     test_size=0.2, \n                                     random_state=SEED, \n                                     stratify=df['cataract'])\n\ntrain_df, val_df = train_test_split(train_df,\n                                    test_size=0.15,\n                                    random_state=SEED,\n                                    stratify=train_df['cataract'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_datasets(df, img_width, img_height):\n    imgs = []\n    for path in tqdm(df['paths']):\n        img = cv2.imread(path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = cv2.resize(img, (img_width, img_height))\n        imgs.append(img)\n        \n    imgs = np.array(imgs, dtype='float32')\n    df = pd.get_dummies(df['cataract'])\n    return imgs, df\n\n\ntrain_imgs, train_df = create_datasets(train_df, IMG_WIDTH, IMG_HEIGHT)\nval_imgs, val_df = create_datasets(val_df, IMG_WIDTH, IMG_HEIGHT)\ntest_imgs, test_df = create_datasets(test_df, IMG_WIDTH, IMG_HEIGHT)\n\ntrain_imgs = train_imgs / 255.0\nval_imgs = val_imgs / 255.0\ntest_imgs = test_imgs / 255.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot the first 25 sheets of image data for training\n\nf, ax = plt.subplots(5, 5, figsize=(15,15))\nnorm_list = list(train_df[0][:25])\nfor i, img in enumerate(train_imgs[:25]):\n    ax[i//5, i%5].imshow(img)\n    ax[i//5, i%5].axis('off')\n    if norm_list[i] == 1:\n        ax[i//5, i%5].set_title('TrainData: Normal')\n    else:\n        ax[i//5, i%5].set_title('TrainData: Cataract')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot the first 25 sheets of image data for Test\nf, ax = plt.subplots(5, 5, figsize=(15,15))\nnorm_list = list(test_df[0][:25])\nfor i, img in enumerate(test_imgs[:25]):\n    ax[i//5, i%5].imshow(img)\n    ax[i//5, i%5].axis('off')\n    if norm_list[i] == 1:\n        ax[i//5, i%5].set_title('TestData: Normal')\n    else:\n        ax[i//5, i%5].set_title('TestData: Cataract')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Build the model(1) <a name=\"build1\"> </a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class Mish(tf.keras.layers.Layer):\n\n    def __init__(self, **kwargs):\n        super(Mish, self).__init__(**kwargs)\n        self.supports_masking = True\n\n    def call(self, inputs):\n        return inputs * K.tanh(K.softplus(inputs))\n\n    def get_config(self):\n        base_config = super(Mish, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def compute_output_shape(self, input_shape):\n        return input_shape\ndef mish(x):\n    return tf.keras.layers.Lambda(lambda x: x*K.tanh(K.softplus(x)))(x)\n \nget_custom_objects().update({'mish': Activation(mish)})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_shape = (IMG_HEIGHT, IMG_WIDTH, 3)\n\nmodel = Sequential()\nmodel.add(Conv2D(16, kernel_size=3, padding='same', \n                 input_shape=input_shape, activation='mish'))\nmodel.add(Conv2D(16, kernel_size=3, padding='same', activation='mish'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(3))\nmodel.add(Dropout(0.3))\nmodel.add(Conv2D(16, kernel_size=3, padding='same', activation='mish'))\nmodel.add(Conv2D(16, kernel_size=3, padding='same', activation='mish'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(3))\nmodel.add(Dropout(0.3))\nmodel.add(Flatten())\nmodel.add(Dense(2, activation='softmax'))\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Use some image data augmentation to generate randomly augmented image data from the ImageDataGenerator Object.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"generator = ImageDataGenerator(horizontal_flip=True, \n                               height_shift_range=0.1,\n                               fill_mode='reflect') \n\n\n\nes_callback = tf.keras.callbacks.EarlyStopping(patience=20, \n                                               verbose=1, \n                                               restore_best_weights=True)\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=10, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(generator.flow(train_imgs, \n                                   train_df,\n                                   batch_size=BATCH_SIZE), \n                    epochs=EPOCHS,\n                    steps_per_epoch=len(train_imgs)/BATCH_SIZE,\n                    callbacks=[es_callback, reduce_lr],\n                    validation_data=(val_imgs, val_df))\n\n\npd.DataFrame(history.history)[['accuracy', 'val_accuracy']].plot()\npd.DataFrame(history.history)[['loss', 'val_loss']].plot()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(test_imgs, test_df) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Build the model(2) <a name=\"build2\"> </a>\nWe will train using a model that has been pre-trained.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model(img_height, img_width, n):\n    inp = Input(shape=(img_height,img_width,n))\n    efnet = efn.EfficientNetB0(\n        input_shape=(img_height,img_width,n), \n        weights='imagenet', \n        include_top=False\n    )\n    x = efnet(inp)\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(2, activation='softmax')(x)\n    model = tf.keras.Model(inputs=inp, outputs=x)\n    opt = tf.keras.optimizers.Adam(learning_rate=0.000003)\n    loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.01)\n    model.compile(optimizer=opt, loss=loss, metrics=['accuracy'])\n    return model\n\nmodel = build_model(IMG_HEIGHT, IMG_WIDTH, 3)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generator = ImageDataGenerator(horizontal_flip=True, \n                               height_shift_range=0.1,\n                               fill_mode='reflect') \n\n\n\nes_callback = tf.keras.callbacks.EarlyStopping(patience=20, \n                                               verbose=1, \n                                               restore_best_weights=True)\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=10, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(generator.flow(train_imgs, \n                                   train_df,\n                                   batch_size=BATCH_SIZE), \n                    epochs=EPOCHS,\n                    steps_per_epoch=len(train_imgs)/BATCH_SIZE,\n                    callbacks=[es_callback, reduce_lr],\n                    validation_data=(val_imgs, val_df))\n\n\npd.DataFrame(history.history)[['accuracy', 'val_accuracy']].plot()\npd.DataFrame(history.history)[['loss', 'val_loss']].plot()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(test_imgs, test_df) ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}