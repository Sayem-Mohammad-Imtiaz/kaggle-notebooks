{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n# importing ploting libraries\nimport matplotlib.pyplot as plt   \n\n#importing seaborn for statistical plots\nimport seaborn as sns\n\n#Let us break the X and y dataframes into training set and test set. For this we will use\n#Sklearn package's data splitting function which is based on random function\n\nfrom sklearn.model_selection import train_test_split\n\nimport numpy as np\n\n\n# calculate accuracy measures and confusion matrix\nfrom sklearn import metrics\n\n\nfrom sklearn.metrics import recall_score\n\nfrom imblearn.over_sampling import SMOTE\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Reading the dataset\npima_df = pd.read_csv(\"/kaggle/input/pima-indians-diabetes-database/diabetes.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pima_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let us check whether any of the columns has any value other than numeric i.e. data is not corrupted such as a \"?\" instead of \n# a number.\n\n# we use np.isreal a numpy function which checks each column for each row and returns a bool array, \n# where True if input element is real.\n# applymap is pandas dataframe function that applies the np.isreal function columnwise\n# Following line selects those rows which have some non-numeric value in any of the columns hence the  ~ symbol\n\npima_df[~pima_df.applymap(np.isreal).all(1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# replace the missing values in pima_df with median value :Note, we do not need to specify the column names\n# every column's missing value is replaced with that column's median respectively\npima_df = pima_df.fillna(pima_df.median())\npima_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets analysze the distribution of the various attributes\npima_df.describe().transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let us look at the target column which is 'Outcome' to understand how the data is distributed amongst the various values\npima_df.groupby([\"Outcome\"]).count()\n\n# Most are not diabetic. The ratio is almost 1:2 in favor or class 0.  The model's ability to predict class 0 will \n# be better than predicting class 1. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pairplot using sns\n\nsns.pairplot(pima_df , hue='Outcome' , diag_kind = 'kde')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#data for all the attributes are skewed, especially for the variable \"Insulin\"\n\n#The mean for test is 80(rounded) while the median is 30.5 which clearly indicates an extreme long tail on the right","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Attributes which look normally distributed (glucose, blood pressure, skin thickness, and BMI).\n# Some of the attributes look like they may have an exponential distribution (pregnancy, insulin, DiabetesPedigreeFunction, age).\n# Age should probably have a normal distribution, the constraints on the data collection may have skewed the distribution.\n\n# There is no obvious relationship between age and onset of diabetes.\n# There is no obvious relationship between DiabetesPedigreeFunction function and onset of diabetes.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"array = pima_df.values\nX = array[:,0:7] # select all rows and first 8 columns which are the attributes\nY = array[:,8]   # select all rows and the 8th column which is the classification \"Yes\", \"No\" for diabeties\ntest_size = 0.30 # taking 70:30 training and test set\nseed = 7  # Random numbmer seeding for reapeatability of the code\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\ntype(X_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SMOTE to upsample smaller class"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Before UpSampling, counts of label '1': {}\".format(sum(y_train==1)))\nprint(\"Before UpSampling, counts of label '0': {} \\n\".format(sum(y_train==0)))\n\nsm = SMOTE(sampling_strategy = 1 ,k_neighbors = 5, random_state=1)   #Synthetic Minority Over Sampling Technique\nX_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel())\n\n\nprint(\"After UpSampling, counts of label '1': {}\".format(sum(y_train_res==1)))\nprint(\"After UpSampling, counts of label '0': {} \\n\".format(sum(y_train_res==0)))\n\n\n\nprint('After UpSampling, the shape of train_X: {}'.format(X_train_res.shape))\nprint('After UpSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit the model on original data i.e. before upsampling\n\nfrom sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\ny_predict = model.predict(X_test)\nmodel_score = model.score(X_test, y_test)\nprint(model_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred = model.predict(X_test)\n\nprint(metrics.classification_report(y_test, test_pred))\nprint(metrics.confusion_matrix(y_test, test_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# UpSample smaller class"},{"metadata":{"trusted":true},"cell_type":"code","source":"# fit model on upsampled data \n\nmodel.fit(X_train_res, y_train_res)\ny_predict = model.predict(X_test)\nmodel_score = model.score(X_test, y_test)\nprint(model_score)\nprint(metrics.confusion_matrix(y_test, y_predict))\nprint(metrics.classification_report(y_test, y_predict))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Down Sampling the larger class"},{"metadata":{"trusted":true},"cell_type":"code","source":"non_diab_indices = pima_df[pima_df['Outcome'] == 0].index   # Get the record numbers of non-diab cases\nno_diab = len(pima_df[pima_df['Outcome'] == 0])             # how many non-diab cases\nprint(no_diab)\n\ndiab_indices = pima_df[pima_df['Outcome'] == 1].index       # record number of the diabeteics cases\ndiab = len(pima_df[pima_df['Outcome'] == 1])                # how many diabetic cases\nprint(diab)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_indices = np.random.choice( non_diab_indices, no_diab - 200 , replace=False)    #Randomly pick up 200 non-diab indices","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"down_sample_indices = np.concatenate([diab_indices,random_indices])  # combine the 200 non-diab indices with diab indices","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pima_df_down_sample = pima_df.loc[down_sample_indices]  # Extract all those records for diab and non-diab to create new set\npima_df_down_sample.shape\npima_df_down_sample.groupby([\"Outcome\"]).count()  # look at the class distribution after downsample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"array = pima_df_down_sample.values\nX = array[:,0:7] # select all rows and first 8 columns which are the attributes\nY = array[:,8]   # select all rows and the 8th column which is the classification \"Yes\", \"No\" for diabeties\ntest_size = 0.30 # taking 70:30 training and test set\nseed = 7  # Random numbmer seeding for reapeatability of the code\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\ntype(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('After DownSampling, the shape of X_train: {}'.format(X_train.shape))\nprint('After DownSampling, the shape of X_test: {} \\n'.format(X_test.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit the model on 30%\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\ny_predict = model.predict(X_test)\nmodel_score = model.score(X_test, y_test)\nprint(model_score)\nprint(metrics.confusion_matrix(y_test, y_predict))\nprint(metrics.classification_report(y_test, y_predict))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## IMBLearn Random Under Sampling"},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.under_sampling import RandomUnderSampler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rus = RandomUnderSampler(return_indices=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_rus, y_rus, id_rus = rus.fit_sample(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_rus","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_rus.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## IMBLearn Random Over Sampling\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import RandomOverSampler\n\nros = RandomOverSampler()\n\nX_ros, y_ros = ros.fit_sample(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_ros","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_ros.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_ros.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##  Deleting nearest majority neighbors  TomekLinks\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.under_sampling import TomekLinkstl = TomekLinks(return_indices=True, ratio='majority')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tl = TomekLinks(return_indices=True, ratio='majority')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_tl, y_tl, id_tl = tl.fit_sample(X_train, y_train)   # id_tl is removed instances of majority class","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_tl.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_tl.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Upsampling followed by downsampling\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.combine import SMOTETomek","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"smt = SMOTETomek(ratio='auto')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_smt, y_smt = smt.fit_sample(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_smt.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cluster based undersampling\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.under_sampling import ClusterCentroids","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cc = ClusterCentroids()  \nX_cc, y_cc = cc.fit_sample(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_cc.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_cc","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}