{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#Import libraries \n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom plotnine import *\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **1. Introduction**"},{"metadata":{},"cell_type":"markdown","source":"**1.1 Background**\n\nThis dataset contains the information about the movies . For a movie to be commercial success , it depends on various factors like director, actors ,critic reviews and viewers reaction. Imdb score is one of the important factor to measure the movie's success. "},{"metadata":{},"cell_type":"markdown","source":"**1.2 Description of dataset attributes**"},{"metadata":{},"cell_type":"markdown","source":"Please find the details for the datset attributes:-\n\n1. Color :- Movie is black or coloured\n2. Director_name:- Name of the movie director\n3. num_critic_for_reviews :- No of critics for the movie\n4. duration:- movie duration in minutes\n5. director_facebook_likes:-Number of likes for the Director on his Facebook Page\n6. actor_3_facebook_likes:- No of likes for the actor 3 on his/her facebook Page\n7. actor2_name:- name of the actor 2\n8. actor_1_facebook_likes:- No of likes for the actor 1 on his/her facebook Page\n9. gross:- Gross earnings of the movie in Dollars\n10. genres:- Film categorization like ‘Animation’, ‘Comedy’, ‘Romance’, ‘Horror’, ‘Sci-Fi’, ‘Action’, ‘Family’\n11. actor_1_name:- Name of the actor 1\n12. movie_title:-Title of the movie\n13. num_voted_users:-No of people who voted for the movie\n14. cast_total_facebook_likes:- Total facebook like for the movie\n15. actor_3_name:- Name of the actor 3\n16. facenumber_in_poster:- No of actors who featured in the movie poster\n17. plot_keywords:-Keywords describing the movie plots\n18. movie_imdb_link:-Link of the movie link\n19. num_user_for_reviews:- Number of users who gave a review\n20. language:- Language of the movie \n21. country:- Country where movie is produced\n22. content_rating:- Content rating of the movie\n23. budget:- Budget of the movie in Dollars\n24. title_year:- The year in which the movie is released\n25. actor_2_facebook_likes:- facebook likes for the actor 2\n26. imdb_score:- IMDB score of the movie\n27. aspect_ratio :- Aspect ratio the movie was made in\n28. movie_facebook_likes:- Total no of facebook likes for the movie\n    "},{"metadata":{},"cell_type":"markdown","source":"**1.3 Case Study**\n\n\nThe dataset here gives the massive information about the movies and their IMDB scores respectively. We are going to analyze each and every factors which can influence the imdb ratings so that we can predict better results.The movie with the higher imdb score is more successful as compared to the movies with low imdb score. "},{"metadata":{},"cell_type":"markdown","source":"**2. Data Preprocessing**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Reading the Data \n\nmovie_df=pd.read_csv(\"/kaggle/input/imdb-5000-movie-dataset/movie_metadata.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Displaying the first 10 records\n\nmovie_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Shape of the dataset (no of rows and no of columns)\n\nmovie_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Displaying the data type of the dataset attributes \n\nmovie_df.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We can say we have the datset divided into categorical and numeric columns \"\n\n**Categorical Columns**\n\nColor,Director name, actor name,genres,movie_title,language,country,content_rating.\n\n**Numerical Columns**\n\nnum_critic_for_reviews,duration,director_facebook_likes ,actor_3_facebook_likes,actor_1_facebook_likes ,gross,num_voted_users,cast_total_facebook_likes,facenumber_in_poster,num_user_for_reviews ,budget,title_year, actor_2_facebook_likes ,imdb_score,aspect_ratio,movie_facebook_likes\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Five point summary for the numerical columns in the dataset\n\nmovie_df.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dropping the Imdb link from the dataset\n\nmovie_df.drop('movie_imdb_link', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Removing the color section as most of the movies is colored\n\nmovie_df[\"color\"].value_counts()\n\nmovie_df.drop('color',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking for the columns present in the datset\nmovie_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking for the missing values in the dataset\n\nmovie_df.isna().any()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#No of the missing values in the dataset\n\nmovie_df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We can remove the null values from the dataset where the count is less . so that we don't loose much data \n\nmovie_df.dropna(axis=0,subset=['director_name', 'num_critic_for_reviews','duration','director_facebook_likes','actor_3_facebook_likes','actor_2_name','actor_1_facebook_likes','actor_1_name','actor_3_name','facenumber_in_poster','num_user_for_reviews','language','country','actor_2_facebook_likes','plot_keywords'],inplace=True)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movie_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** We lost only 6% of the data which is acceptable**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Replacing the content rating with Value R as it has highest frequency\n\nmovie_df[\"content_rating\"].fillna(\"R\", inplace = True) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Replacing the aspect_ratio with the median of the value as the graph is right skewed \n\nmovie_df[\"aspect_ratio\"].fillna(movie_df[\"aspect_ratio\"].median(),inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We need to replace the value in budget with the median of the value\n\nmovie_df[\"budget\"].fillna(movie_df[\"budget\"].median(),inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We need to replace the value in gross with the median of the value \n\nmovie_df['gross'].fillna(movie_df['gross'].median(),inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Recheck that all the null values are removed\n\nmovie_df.isna().sum()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We don't have any null values in the datset anymore**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Removing the duplicate values in the datset\n\nmovie_df.drop_duplicates(inplace=True)\nmovie_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Count of the language values \n\nmovie_df[\"language\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**94 % of the movie is english**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Graphical presentaion \nplt.figure(figsize=(40,10))\nsns.countplot(movie_df[\"language\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Most of the values for the languages is english we can drop the english column\n\nmovie_df.drop('language',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating a new column to check the net profit made by the company (Gross-Budget) \n\nmovie_df[\"Profit\"]=movie_df['budget'].sub(movie_df['gross'], axis = 0) \n\nmovie_df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating a new column to check the profit percentage made by the company \n\nmovie_df['Profit_Percentage']=(movie_df[\"Profit\"]/movie_df[\"gross\"])*100\nmovie_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**So we have added two new columns  profit and profit percentage made by the movies**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Value counts for the countries \n\nvalue_counts=movie_df[\"country\"].value_counts()\nprint(value_counts)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We can see most of the movies are from USA ,UK and the rest of the countries**"},{"metadata":{"trusted":true},"cell_type":"code","source":"##get top 2 values of index\nvals = value_counts[:2].index\nprint (vals)\nmovie_df['country'] = movie_df.country.where(movie_df.country.isin(vals), 'other')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Successfully divided the country into three catogories \nmovie_df[\"country\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movie_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**3. Data Visualization**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking for the movies released year wise \n\n(ggplot(movie_df)         # defining what data to use\n + aes(x='title_year')    # defining what variable to use\n + geom_bar(size=20) # defining the type of plot to use\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** We can see the most of the movies which are released after 1980 **"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Relationship between the imdb score and the profit made by the movie \n\nggplot(aes(x='imdb_score', y='Profit'), data=movie_df) +\\\n    geom_line() +\\\n    stat_smooth(colour='blue', span=1)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** We can see that there is strong corelation between the imdb_score and the profit . The movies with high imdb rating have made more profit**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Relationship between imdb score and profit percentage\n\nggplot(aes(x='imdb_score', y='Profit'), data=movie_df) +\\\n    geom_line() +\\\n    stat_smooth(colour='blue', span=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Movies with high IMDB has made more percentage**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking for the imdb rating of the movies and compared with the countries  \n\nggplot(aes(x='country', y='imdb_score'), data=movie_df) +\\\n    geom_line() +\\\n    stat_smooth(colour='blue', span=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Most of the movies above rating 8.75 are from USA**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Finding the corelation between imdb_rating with respect to no of facebook likes \n\n(ggplot(movie_df)\n + aes(x='imdb_score', y='movie_facebook_likes')\n + geom_line()\n + labs(title='IMDB_Score vs. Facebook like for Movies', x='IMDB scores', y='Facebook Likes for movies')\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Movie with high IMDB rating have most no of facebook likes**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Top 20 movies based on the profit they made\n\nplt.figure(figsize=(10,8))\nmovie_df= movie_df.sort_values(by ='Profit' , ascending=False)\nmovie_df_new=movie_df.head(20)\nax=sns.pointplot(movie_df_new['Profit'], movie_df_new['budget'], hue=movie_df_new['movie_title'])\nax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\nplt.tight_layout()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Top 20 movies based on the profit percentage\nplt.figure(figsize=(10,8))\nmovie_df= movie_df.sort_values(by ='Profit_Percentage' , ascending=False)\nmovie_df_new=movie_df.head(20)\nax=sns.pointplot(movie_df_new['Profit_Percentage'], movie_df_new['budget'], hue=movie_df_new['movie_title'])\nax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Top 20 directors based on the IMDB ratings\nplt.figure(figsize=(10,8))\n\nmovie_df= movie_df.sort_values(by ='imdb_score' , ascending=False)\nmovie_df_new=movie_df.head(20)\nax=sns.pointplot(movie_df_new['director_name'], movie_df_new['imdb_score'], hue=movie_df_new['movie_title'])\nax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\nplt.tight_layout()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Commercial success vs critial acclaim\nmovie_df= movie_df.sort_values(by ='Profit_Percentage' , ascending=False)\nmovie_df_new=movie_df.head(20)\n(ggplot(movie_df_new)\n + aes(x='imdb_score', y='gross',color = \"content_rating\")\n + geom_point()\n +  geom_hline(aes(yintercept = 600)) + \n  geom_vline(aes(xintercept = 10)) + \n  xlab(\"Imdb score\") + \n  ylab(\"Gross money earned in million dollars\") + \n  ggtitle(\"Commercial success Vs Critical acclaim\") +\n  annotate(\"text\", x = 8.5, y = 700, label = \"High ratings \\n & High gross\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Movies with High content rating were not commercial success**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Top 20 actors of movies based on the commerical success\n\nplt.figure(figsize=(10,8))\n\nmovie_df= movie_df.sort_values(by ='Profit_Percentage' , ascending=False)\nmovie_df_new=movie_df.head(20)\nax=sns.pointplot(movie_df_new['actor_1_name'], movie_df_new['Profit_Percentage'], hue=movie_df_new['movie_title'])\nax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Top 20 actors of movies based on the imdb rating of the movies \n\nplt.figure(figsize=(10,8))\n\nmovie_df= movie_df.sort_values(by ='imdb_score' , ascending=False)\nmovie_df_new=movie_df.head(20)\nax=sns.pointplot(movie_df_new['actor_1_name'], movie_df_new['imdb_score'], hue=movie_df_new['movie_title'])\nax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\nplt.tight_layout()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Country of Top 20 movies based on imdb rating\n\nplt.figure(figsize=(10,8))\n\nmovie_df= movie_df.sort_values(by ='imdb_score' , ascending=False)\nmovie_df_new=movie_df.head(20)\nax=sns.pointplot(movie_df_new['country'], movie_df_new['imdb_score'], hue=movie_df_new['movie_title'])\nax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**4.Data Preparation for the models**"},{"metadata":{},"cell_type":"markdown","source":"**4.1 Removing the Columns with names** "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Removing the director name column\n\nmovie_df.drop('director_name', axis=1, inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Removing the actor1 ,actor 2 and actor 3 names \n\nmovie_df.drop('actor_1_name',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movie_df.drop('actor_2_name',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movie_df.drop('actor_3_name',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dropping the movie title \n\nmovie_df.drop('movie_title',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping the plot keywords\nmovie_df.drop('plot_keywords',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Value count of genres\n\nmovie_df['genres'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Most of the values are equally distributed in genres column ,so we can remove the genres column\n\nmovie_df.drop('genres',axis=1,inplace =True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**4.2 Remove the linear dependant variables****"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropiing the profit column from the dataset\nmovie_df.drop('Profit',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dropping the profit percentage column from the dataset\n\nmovie_df.drop('Profit_Percentage',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"**4.3 Remove the coreelated variables**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation with heat map\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncorr = movie_df.corr()\nsns.set_context(\"notebook\", font_scale=1.0, rc={\"lines.linewidth\": 2.5})\nplt.figure(figsize=(13,7))\n# create a mask so we only see the correlation values once\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask, 1)] = True\na = sns.heatmap(corr,mask=mask, annot=True, fmt='.2f')\nrotx = a.set_xticklabels(a.get_xticklabels(), rotation=90)\nroty = a.set_yticklabels(a.get_yticklabels(), rotation=30)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** We can see that the cast_total_facebook_likes and actor_1_facebook_like are highly correlated to each other. Both actor2 and actor3 are also somehow correlated to the total. So we want to modify them into two variables: actor_1_facebook_likes and other_actors_facebook_likes.\n\nThere are high correlations among num_voted_users, num_user_for_reviews and num_critic_for_reviews. We want to keep num_voted_users and take the ratio of num_user_for_reviews and num_critic_for_reviews."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Adding the facebook likes of actor 2 and actor 3 together \nmovie_df['Other_actor_facebbok_likes']=movie_df[\"actor_2_facebook_likes\"] + movie_df['actor_3_facebook_likes']\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dropping the actor 2 and actor 3 facebook likes columns as they have been added together \n\nmovie_df.drop('actor_2_facebook_likes',axis=1,inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmovie_df.drop('actor_3_facebook_likes',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movie_df.drop('cast_total_facebook_likes',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Ratio of the ratio of num_user_for_reviews and num_critic_for_reviews.\n\nmovie_df['critic_review_ratio']=movie_df['num_critic_for_reviews']/movie_df['num_user_for_reviews']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dropping the num_critic_for_review\n\nmovie_df.drop('num_critic_for_reviews',axis=1,inplace=True)\nmovie_df.drop('num_user_for_reviews',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# New Correlation matrix shown in the figure \n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncorr = movie_df.corr()\nsns.set_context(\"notebook\", font_scale=1.0, rc={\"lines.linewidth\": 2.5})\nplt.figure(figsize=(13,7))\n# create a mask so we only see the correlation values once\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask, 1)] = True\na = sns.heatmap(corr,mask=mask, annot=True, fmt='.2f')\nrotx = a.set_xticklabels(a.get_xticklabels(), rotation=90)\nroty = a.set_yticklabels(a.get_yticklabels(), rotation=30)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we can see none of the attributes are not much correlated to each other.All are below 0.7 "},{"metadata":{"trusted":true},"cell_type":"code","source":"# We need to categorize the imdb values in the range of 0-4,4-6,6-8 and 8-10 to mark them as the bad,average,good and excellent movies respectively\n\nmovie_df[\"imdb_binned_score\"]=pd.cut(movie_df['imdb_score'], bins=[0,4,6,8,10], right=True, labels=False)+1\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dropping the imdb_score column as it is being replaced with the imdb_binned_score values \nmovie_df.drop('imdb_score',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movie_df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"**5. Handling the categorical data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"movie_df = pd.get_dummies(data = movie_df, columns = ['country'] , prefix = ['country'] , drop_first = True)\nmovie_df = pd.get_dummies(data = movie_df, columns = ['content_rating'] , prefix = ['content_rating'] , drop_first = True)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movie_df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** 6. Splitting the data into training and test data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nX=pd.DataFrame(columns=['duration','director_facebook_likes','actor_1_facebook_likes','gross','num_voted_users','facenumber_in_poster','budget','title_year','aspect_ratio','movie_facebook_likes','Other_actor_facebbok_likes','critic_review_ratio','country_USA','country_other','content_rating_G','content_rating_GP','content_rating_M','content_rating_NC-17','content_rating_Not Rated','content_rating_PG','content_rating_PG-13','content_rating_Passed','content_rating_R','content_rating_TV-14','content_rating_TV-G','content_rating_TV-PG','content_rating_Unrated','content_rating_X'],data=movie_df)\ny=pd.DataFrame(columns=['imdb_binned_score'],data=movie_df)\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.3,random_state=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"**7.Feature scaling**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\nX_train = sc_X.fit_transform(X_train)\nX_test = sc_X.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**8. Classification Model Selection**"},{"metadata":{},"cell_type":"markdown","source":"**8.1 Logistic Regression**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Logistic Regression\n\nfrom sklearn.linear_model import LogisticRegression\nlogit =LogisticRegression()\nlogit.fit(X_train,np.ravel(y_train,order='C'))\ny_pred=logit.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Confusion matrix for logistic regression**\n\nfrom sklearn import metrics\ncnf_matrix = metrics.confusion_matrix(y_test, y_pred)\nprint(cnf_matrix)\n\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**8.2 KNN**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#KNN \nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=22)\nknn.fit(X_train, np.ravel(y_train,order='C'))\nknnpred = knn.predict(X_test)\ncnf_matrix = metrics.confusion_matrix(y_test, knnpred)\nprint(cnf_matrix)\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, knnpred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**8.3 SVC**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#SVC\nfrom sklearn.svm import SVC\nsvc= SVC(kernel = 'sigmoid')\nsvc.fit(X_train, np.ravel(y_train,order='C'))\nsvcpred = svc.predict(X_test)\ncnf_matrix = metrics.confusion_matrix(y_test, svcpred)\nprint(cnf_matrix)\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, svcpred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**8.4 Naive Bayes**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Naive bayes\n\nfrom sklearn.naive_bayes import GaussianNB\ngaussiannb= GaussianNB()\ngaussiannb.fit(X_train, np.ravel(y_train,order='C'))\ngaussiannbpred = gaussiannb.predict(X_test)\ncnf_matrix = metrics.confusion_matrix(y_test, gaussiannbpred)\nprint(cnf_matrix)\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, gaussiannbpred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**8.5 Decision Tree**\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Decision Tree\n\nfrom sklearn.tree import DecisionTreeClassifier\ndtree = DecisionTreeClassifier(criterion='gini') #criterion = entopy, gini\ndtree.fit(X_train, np.ravel(y_train,order='C'))\ndtreepred = dtree.predict(X_test)\ncnf_matrix = metrics.confusion_matrix(y_test, dtreepred)\nprint(cnf_matrix)\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, dtreepred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**8.6 Ada Boosting**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Ada Boosting\nfrom sklearn.ensemble import AdaBoostClassifier\nabcl = AdaBoostClassifier(base_estimator=dtree, n_estimators=60)\nabcl=abcl.fit(X_train,np.ravel(y_train,order='C'))\nabcl_pred=abcl.predict(X_test)\ncnf_matrix = metrics.confusion_matrix(y_test, abcl_pred)\nprint(cnf_matrix)\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, abcl_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**8.7 Random Forest**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Random Forest\n\nfrom sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(n_estimators = 200)#criterion = entopy,gini\nrfc.fit(X_train, np.ravel(y_train,order='C'))\nrfcpred = rfc.predict(X_test)\ncnf_matrix = metrics.confusion_matrix(y_test, rfcpred)\nprint(cnf_matrix)\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, rfcpred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**8.8 Bagging Classifier**[](http://)"},{"metadata":{"trusted":true},"cell_type":"code","source":"new_movie_df=movie_df.pop(\"imdb_binned_score\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Bagging classfier\n\nfrom sklearn.ensemble import BaggingClassifier\nbgcl = BaggingClassifier(n_estimators=60, max_samples=.7 , oob_score=True)\n\nbgcl = bgcl.fit(movie_df, new_movie_df)\nprint(bgcl.oob_score_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**8.9 Gradient Boosting**\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Gradient boosting\n\nfrom sklearn.ensemble import GradientBoostingClassifier\ngbcl = GradientBoostingClassifier(n_estimators = 50, learning_rate = 0.09, max_depth=5)\ngbcl = gbcl.fit(X_train,np.ravel(y_train,order='C'))\ntest_pred = gbcl.predict(X_test)\ncnf_matrix = metrics.confusion_matrix(y_test, test_pred)\nprint(cnf_matrix)\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, test_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**8.10 XGBooosting**\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\nxgb = XGBClassifier()\nxgb.fit(X_train, np.ravel(y_train,order='C'))\nxgbprd = xgb.predict(X_test)\ncnf_matrix = metrics.confusion_matrix(y_test, xgbprd)\nprint(cnf_matrix)\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, xgbprd))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**9.Model Comparison**\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nprint('Logistic  Reports\\n',classification_report(y_test, y_pred))\nprint('KNN Reports\\n',classification_report(y_test, knnpred))\nprint('SVC Reports\\n',classification_report(y_test, svcpred))\nprint('Naive BayesReports\\n',classification_report(y_test, gaussiannbpred))\nprint('Decision Tree Reports\\n',classification_report(y_test, dtreepred))\nprint('Ada Boosting\\n',classification_report(y_test, abcl_pred))\nprint('Random Forests Reports\\n',classification_report(y_test, rfcpred))\nprint('Bagging Clasifier',bgcl.oob_score_) \nprint('Gradient Boosting',classification_report(y_test, test_pred))\nprint('XGBoosting\\n',classification_report(y_test, xgbprd))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**10.Conclusion**\n\nThe conclusion is that Random Forest Algorithm along with the gradient boosting have the accuracy of 74.5 and 75.5 respectively"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}