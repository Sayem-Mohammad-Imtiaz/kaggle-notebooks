{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Human Resorce Data to Predict Employee Attrition\n\nIn this project we are going to develop a model that could predict which employees are more likely to quit. \nThis fictional data created by IBM data scientist. We are going to explore the data and then create a model to predict how likely the employee quit the job.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Load the libraries and the data","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nemployee_df = pd.read_csv('/kaggle/input/ibm-hr-analytics-attrition-dataset/WA_Fn-UseC_-HR-Employee-Attrition.csv')\nemployee_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"employee_df['PercentSalaryHike'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"employee_df['PercentSalaryHike'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import for interactive plotting\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"employee_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set()\n# Let's see if we have any missing data, luckily we don't!\nsns.heatmap(employee_df.isnull(), yticklabels=False, cbar=False, cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"for column in employee_df.select_dtypes(include=['object']):\n    print(column)\n    print(employee_df[column].unique())\n    print('-----------------------------------')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* 1470 employee worked at the company over time\n* We have categorical and numerical data: we need to investigate the this separately\n* Attrition columns indicate \"Yes\" if the employee quit the job and \"No\" employee stayed at the company. We should convert this 1 and 0 for using in Machine learning model. \n* Overtime also has Yes and NO. So we need to convert this column to 1 and 0.\n\n* Over18 column has only Y[Yes] meaning every employee over18 so we don't need this information.\n* Standard Hour has only unique value 80. So we don't need this column.\n* Same including the 'EmployeeCount','EmployeeNumber' column.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"employee_df['Attrition'] = employee_df['Attrition'].apply(lambda x:1 if x == \"Yes\" else 0 )\nemployee_df['OverTime'] = employee_df['OverTime'].apply(lambda x:1 if x ==\"Yes\" else 0 )\n#drop the column, use inplce True for delete the information from the memeory\nemployee_df.drop(['EmployeeCount','EmployeeNumber','Over18','StandardHours'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"employee_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visulazing the distibution of the data for every feature\nemployee_df.hist(bins=30, figsize=(20,20), color='b', alpha=0.6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"attrition = employee_df[employee_df['Attrition'] == 1]\nno_attrition = employee_df[employee_df['Attrition']==0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = make_subplots(rows=1, cols=2,\n                    specs=[[{\"type\":\"xy\"},{\"type\":\"domain\"}]],\n                    subplot_titles= (\"Count of Attrition\", \"Distribution of Attrition\"))\n\nfig.add_trace(go.Bar(x = employee_df['Attrition'].value_counts(),\n                     y = ['Employee who stayed', 'Employee who left'],\n                     orientation = 'h',\n                     opacity=0.8),\n                     row=1,col=1)\n\nfig.add_trace(go.Pie(values=employee_df['Attrition'].value_counts(),\n                    opacity=0.8),\n                    row=1, col=2)\nfig.update_layout(height=400, showlegend=False)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def categorical_colum_investigaton(col_name):\n    \"\"\"First Plot: Pie chart for categorical column to see percentage of each value\n       Secons Plot: Count plot for categorical column to see the number of count for each of the type\n       Third Plot is Number of Count for separeted for Attribition\"\"\"\n\n    f,ax = plt.subplots(1,3, figsize=(18,6))\n    employee_df[col_name].value_counts().plot.pie(autopct='%1.1f%%',ax=ax[0],shadow=True, cmap='Set3')\n    employee_df[col_name].value_counts().plot.bar(cmap='Set3',ax=ax[1])\n    ax[1].set_title(f'Number of Employee by {col_name}')\n    ax[1].set_ylabel('Count')\n    ax[1].set_xlabel(f'{col_name}')\n    sns.countplot(col_name, hue='Attrition',data=employee_df, ax=ax[2], palette='Set3')\n    ax[2].set_title(f'Attrition by {col_name}')\n    ax[2].set_xlabel(f'{col_name}')\n    ax[2].set_ylabel('Count')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_colum_investigaton('Gender')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_colum_investigaton('BusinessTravel')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_colum_investigaton('EducationField')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_colum_investigaton('MaritalStatus')\ncategorical_colum_investigaton('Department')\ncategorical_colum_investigaton('JobRole')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correlations = employee_df.corr()\nfig, ax = plt.subplots(figsize=(20,20))\nsns.heatmap(correlations, annot=True)\n# Job level is strongly correlated with total working hours\n# Monthly income is strongly correlated with Job level\n# Monthly income is strongly correlated with total working hours\n# Age is stongly correlated with monthly income\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def categorical_numerical_comperation(numerical_col, caterical_col1, caterical_col2):\n    \n\n    f,ax = plt.subplots(1,2, figsize=(18,6))\n    \n    g1= sns.swarmplot( caterical_col1, numerical_col,hue='Attrition', data=employee_df, dodge=True, ax=ax[0], palette='Set2')\n    ax[0].set_title(f'{numerical_col} vs {caterical_col1} separeted by Attrition')\n    g1.set_xticklabels(g1.get_xticklabels(), rotation=45) \n\n    \n    g2 = sns.swarmplot( caterical_col2, numerical_col,hue='Attrition', data=employee_df, dodge=True, ax=ax[1], palette='Set2')\n    ax[1].set_title(f'{numerical_col} vs {caterical_col1} separeted by Attrition')\n    g2.set_xticklabels(g2.get_xticklabels(), rotation=45) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_numerical_comperation('Age','Gender','MaritalStatus')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_numerical_comperation('Age','JobRole','EducationField')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_numerical_comperation('MonthlyIncome','Gender','MaritalStatus')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_colum_investigaton('Total_Satisfaction')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_colum_investigaton('EnvironmentSatisfaction')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_colum_investigaton('JobInvolvement')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_colum_investigaton('NumCompaniesWorked')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_colum_investigaton('YearsWithCurrManager')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_colum_investigaton('OverTime')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_colum_investigaton('StockOptionLevel')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_colum_investigaton('Education')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_colum_investigaton('TrainingTimesLastYear')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def numerical_colum_investigaton(col_name):\n    f,ax = plt.subplots(1,2, figsize=(18,6))\n    sns.kdeplot(attrition[col_name], label='Employee who left',ax=ax[0], shade=True, color='palegreen')\n    sns.kdeplot(no_attrition[col_name], label='Employee who stayes', ax=ax[0], shade=True, color='salmon')\n    \n    sns.boxplot(y=col_name, x='Attrition',data=employee_df, palette='Set2', ax=ax[1])\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_colum_investigaton(\"Age\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_colum_investigaton('DistanceFromHome')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_colum_investigaton('MonthlyIncome')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_colum_investigaton('HourlyRate')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_colum_investigaton('JobInvolvement')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_colum_investigaton('PercentSalaryHike')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_colum_investigaton('Age')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_colum_investigaton('DailyRate')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_colum_investigaton('TotalWorkingYears')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_colum_investigaton('YearsAtCompany')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Age: Create a new column using qcut for categorixing the Age\n* Daily Rate: Morelikely the employee left compant if the dailt rate less than 700. So Create new column if daily  arte less than 700 is 1 else 0\n* DistanceFromHome:If the DistanceFromHome more than 10 then employee more likely quit the job.\n* Create new column called Total_Satisfaction using  EnvironmentSatisfaction, JobInvolvement,JobSatisfaction, RelationshipSatisfaction,WorkLifeBalance\n* \n                                     \n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Enginiring\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"employee_df['Total_Satisfaction'] = (employee_df['EnvironmentSatisfaction'] + \n                                     employee_df['JobInvolvement'] + \n                                     employee_df['JobSatisfaction'] + \n                                     employee_df['RelationshipSatisfaction'] +\n                                     employee_df['WorkLifeBalance']) /5 \n\n# drop used column and \nemployee_df.drop(['EnvironmentSatisfaction','JobInvolvement','JobSatisfaction','RelationshipSatisfaction','WorkLifeBalance'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"employee_df['Total_Satisfaction_bool'] = employee_df['Total_Satisfaction'].apply(lambda x:1 if x>=2.2 else 0 ) \nemployee_df.drop('Total_Satisfaction', axis=1, inplace=True)\n\n#Age Column:Employee more likey the drop the job younger than 35\nemployee_df['Age_bool'] = employee_df['Age'].apply(lambda x:1 if x<35 else 0)\nemployee_df.drop('Age', axis=1, inplace=True)\n\n#Daily Rate:Employee more likey the drop the job if dailtRate less than 750\nemployee_df['DailyRate_bool'] = employee_df['DailyRate'].apply(lambda x:1 if x<750 else 0)\nemployee_df.drop('DailyRate', axis=1, inplace=True)\n\n#Departman: Employee more likey the drop the job if the employee working at Sales Departmaen\nemployee_df['Department_bool'] = employee_df['Department'].apply(lambda x:1 if x=='Sales' else 0)\nemployee_df.drop('Department', axis=1, inplace=True)\n\n# DistanceFromHome: Employee more likey the drop the job if the employeeworking far more than 10\nemployee_df['DistanceFromHome_bool'] = employee_df['DistanceFromHome'].apply(lambda x:1 if x>10 else 0)\nemployee_df.drop('DistanceFromHome', axis=1, inplace=True)\n\n# HourlyRate: Employee  more likey the drop the job if the employee working hourly rate less than 65\nemployee_df['HourlyRate_bool'] = employee_df['HourlyRate'].apply(lambda x:1 if x<65 else 0)\nemployee_df.drop('HourlyRate', axis=1, inplace=True)\n\n#JobRole: Employee more likey the drop the job if the employee working as Sales Executive \nemployee_df['JobRole_bool'] = employee_df['JobRole'].apply(lambda x:1 if x=='Sales Executive' else 0)\nemployee_df.drop('JobRole', axis=1, inplace=True)\n\n#MontlyIncome:Employee more likey the drop the job if the employee working as Sales Executive \nemployee_df['MonthlyIncome_bool'] = employee_df['MonthlyIncome'].apply(lambda x:1 if x<3500 else 0)\nemployee_df.drop('MonthlyIncome', axis=1, inplace=True)\n\n#NumCompaniesWorked: Employee more likey the drop the job if the employee working as Sales Executive \nemployee_df['NumCompaniesWorked_bool'] = employee_df['NumCompaniesWorked'].apply(lambda x:1 if x>4 else 0)\nemployee_df.drop('NumCompaniesWorked', axis=1, inplace=True)\n\n#TotalWorkingYears: Employee  more likey the drop the job if the employee working as Sales Executive \nemployee_df['TotalWorkingYears_bool'] = employee_df['TotalWorkingYears'].apply(lambda x:1 if x<8 else 0)\nemployee_df.drop('TotalWorkingYears', axis=1, inplace=True)\n\n#YearsAtCompany: Employee more likey the drop the job if the employee working as Sales Executive \nemployee_df['YearsAtCompany_bool'] = employee_df['YearsAtCompany'].apply(lambda x:1 if x<3 else 0)\nemployee_df.drop('YearsAtCompany', axis=1, inplace=True)\n\n#JobRole Column  more likey the drop the job if the employee working as Sales Executive \nemployee_df['YearsInCurrentRole_bool'] = employee_df['YearsInCurrentRole'].apply(lambda x:1 if x<3 else 0)\nemployee_df.drop('YearsInCurrentRole', axis=1, inplace=True)\n\n#JobRole Column  more likey the drop the job if the employee working as Sales Executive \nemployee_df['YearsSinceLastPromotion_bool'] = employee_df['YearsSinceLastPromotion'].apply(lambda x:1 if x<1 else 0)\nemployee_df.drop('YearsSinceLastPromotion', axis=1, inplace=True)\n\n#JobRole Column  more likey the drop the job if the employee working as Sales Executive \nemployee_df['YearsWithCurrManager_bool'] = employee_df['YearsWithCurrManager'].apply(lambda x:1 if x<1 else 0)\nemployee_df.drop('YearsWithCurrManager', axis=1, inplace=True)\n\nemployee_df.drop(['MonthlyRate','PercentSalaryHike'], axis=1, inplace=True)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"convert_category = ['BusinessTravel','Education','EducationField','MaritalStatus','StockOptionLevel','OverTime','Gender','TrainingTimesLastYear']\nfor col in convert_category:\n        employee_df[col] = employee_df[col].astype('category')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"employee_df.info()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## CREATE TESTING AND TRAINING DATASET & PERFORM DATA CLEANING","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#separate the categorical and numerical column\nX_categorical = employee_df.select_dtypes(include=['category'])\nX_numerical = employee_df.select_dtypes(include=['int64'])\n\n#create teh target column\ny = employee_df['Attrition']\nX_numerical.drop('Attrition', axis=1, inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#handle the categorical variable\nfrom sklearn.preprocessing import OneHotEncoder\nonehotencoder = OneHotEncoder()\n\nX_categorical = onehotencoder.fit_transform(X_categorical).toarray()\nX_categorical = pd.DataFrame(X_categorical)\nX_categorical","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#concat the categorical and numerical values\n\nX_all = pd.concat([X_categorical, X_numerical], axis=1)\nX_all.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Scaler the data\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX = scaler.fit_transform(X_all)\n\nfrom sklearn.model_selection import train_test_split\nX_train,X_test, y_train, y_test = train_test_split(X,y, test_size=0.25)\n\nprint(f\"Train data shape: {X_train.shape}, Test Data Shape {X_test.shape}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## A LOGISTIC REGRESSION CLASSIFIER","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#import libraires\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix, classification_report\n\nmodel = LogisticRegression()\n\nmodel.fit(X_train, y_train)\nmodel\ny_pred = model.predict(X_test)\nprint(f\"Accuracy of Logistic Regression: %{100* accuracy_score(y_pred, y_test)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_test, y_pred)\nsns.heatmap(cm, annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Calculation Roc Curve and driving","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\n#predict probabilities\ny_probability = model.predict_proba(X_test)\n#keep probabilities positive outcomes only\ny_probability = y_probability[:,1]\n## calculate scores\nlogistic_roc_score = roc_auc_score(y_test, y_probability)\nprint(\"Logistic ROC AUC:%.3f\" %(logistic_roc_score) )\n\n# generate a no skill prediction (majority class)\nnoskill_prob = [0 for _ in range(len(y_test))]\nnoskill_roc_auc = roc_auc_score(y_test,noskill_prob )\nprint(\"No Skill ROC AUC:%.3f\" %(noskill_roc_auc))\n\n#calculate the roc curve\nlo_fpr, lo_tpr, _ =roc_curve(y_test, y_probability)\nno_fpr, no_tpr, _ =roc_curve(y_test, noskill_prob)\n\nplt.plot(lo_fpr, lo_tpr, linestyle='dashed', label ='Logistic')\nplt.plot(no_fpr, no_tpr, linestyle='dotted', label= 'No Skill')\n\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## TRAIN AND EVALUATE A RANDOM FOREST CLASSIFIER","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nmodel_Ran = RandomForestClassifier()\n\nmodel_Ran.fit(X_train, y_train)\n\ny_pred_Ran = model_Ran.predict(X_test)\n\nprint(f\"Accuracy of Randon Forest Model: {accuracy_score(y_test, y_pred_Ran)}\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm_Ran = confusion_matrix(y_test, y_pred_Ran)\nsns.heatmap(cm_Ran, annot=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_pred_Ran))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\n\n# generate a no skill prediction (majority class)\nnoskill_prob = [0 for _ in range(len(y_test))]\nnoskill_roc_auc = roc_auc_score(y_test,noskill_prob )\nprint(\"No Skill ROC AUC:%.3f\" %(noskill_roc_auc))\n\n#predict probabilities\ny_probability = model.predict_proba(X_test)\n#keep probabilities positive outcomes only\ny_probability = y_probability[:,1]\n## calculate scores\nlogistic_roc_score = roc_auc_score(y_test, y_probability)\nprint(\"Logistic ROC AUC:%.3f\" %(logistic_roc_score) )\n\n\n\n#Probabilities for random forest\ny_probability_Ran = model_Ran.predict_proba(X_test)\n#keep probabilities positive outcomes only\ny_probability_Ran = y_probability_Ran[:,1]\n## calculate scores\nRandomF_roc_score = roc_auc_score(y_test, y_probability_Ran)\nprint(\"Random Forest ROC AUC:%.3f\" %(RandomF_roc_score) )\n\n\n#calculate the roc curve\nlo_fpr, lo_tpr, _ =roc_curve(y_test, y_probability)\nno_fpr, no_tpr, _ =roc_curve(y_test, noskill_prob)\nra_fpr, ra_tpr, _ =roc_curve(y_test, y_probability_Ran)\n\n\nplt.plot(lo_fpr, lo_tpr, linestyle='dashed', color= 'r', label ='Logistic Regression Model')\nplt.plot(ra_fpr, ra_tpr, linestyle='dashed', color= 'b', label= 'Random Forest Model')\nplt.plot(no_fpr, no_tpr, linestyle='dotted', label= 'No Skill')\n\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## TRYING MULTIPLE MODEL WITH CROSS VALIDATION","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score, cross_val_predict\nfrom sklearn import svm\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import GridSearchCV\n\n\n\n\nkfold = KFold(n_splits=10, random_state=22,shuffle=True)\nxyz= []\naccuracy = []\nstd = []\ny_pred_list = []\n\n\nclassifiers = ['Linear Svm',\n              'Radical Svm',\n              'Logistic Regression',\n              'KNN',\n              'Decision Tree',\n              'Naive Bayes',\n              'Random Forest',\n              'XGBoost']\n\nmodels = [svm.SVC(kernel='linear'),\n         svm.SVC(kernel='rbf'),\n         LogisticRegression(solver='liblinear'),\n         KNeighborsClassifier(),\n          DecisionTreeClassifier(),\n          GaussianNB(),\n          RandomForestClassifier(n_estimators=100),\n          XGBClassifier()\n        ]\n\nfor i in models:\n    model = i \n    cv_result =cross_val_score(model, \n                               X_train, \n                               y_train, \n                               cv=kfold,\n                              scoring='accuracy')\n    y_pred = cross_val_predict(model, X, y, cv=10)\n    y_pred_list.append(y_pred)\n    cv_result =cv_result\n    xyz.append(cv_result.mean())\n    std.append(cv_result.std())\n    accuracy.append(cv_result)\n    \n    \n    \n    \nnew_model_data_frame =pd.DataFrame({'Cv Mean': xyz,\n                                   'Std': std},\n                                   index=classifiers)\n\nnew_model_data_frame","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(12,16))\nplt.xticks(rotation=45)\nsns.boxplot(new_model_data_frame.index, accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nC=[0.05, 0.1, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\ngamma=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\nkernel=['rbf','linear']\nhyper = {'kernel':kernel, 'C':C, 'gamma':gamma}\ngd =GridSearchCV(estimator=svm.SVC(), param_grid=hyper, verbose=True)\n\n\ngd.fit(X_train,y_train)\n\n\nprint(gd.best_score_)\nprint(gd.best_estimator_)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}