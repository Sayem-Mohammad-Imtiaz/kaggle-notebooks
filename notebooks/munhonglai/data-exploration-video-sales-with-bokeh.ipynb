{"cells":[{"metadata":{},"cell_type":"markdown","source":"# First Kaggle: Video Sales Data Visualisation and Predicting Global Sales"},{"metadata":{},"cell_type":"markdown","source":"1. Plot stacked bar chart, line plot and bar plot to examine the relationship of different factors with Global_Sales\n2. Use Bokeh to create a interactive plot for cumulative sales for top 30 publishers\n3. Create a Random Forest Regression Tree to predict global sales."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\nimport pandas as pd\nimport seaborn as sns\nfrom math import ceil\n\nfrom bokeh.io import curdoc, show\nfrom bokeh.layouts import column, layout\nfrom bokeh.models import ColumnDataSource, CustomJSFilter, Slider, CustomJS, DateRangeSlider\nfrom bokeh.plotting import figure, output_file, output_notebook, show\nfrom datetime import date\n\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import MinMaxScaler\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/videogamesales/vgsales.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**1.1 Check the data structure**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**1.2. Check Null Value**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**1.3. Exclude the data containing the NULL values**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data[data['Year'].isnull() == False]\ndata = data[data['Publisher'].isnull() == False]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**1.4 Check the sales of each Platform in each regions by percentage**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"names = list(data.columns)[6:11]\n\n# Calculate the sum of urban by party\ngrouped = data.groupby('Platform')[names].sum()\ngrouped = grouped.T\n\ngreenBars = []\norangeBars = []\nblueBars = []\ngreyBars = []\n\nfor j in range(0, len(grouped.columns)):\n    greenBars = greenBars + [grouped.iloc[0,j]/grouped.iloc[4,j]]\n    orangeBars = orangeBars + [grouped.iloc[1,j]/grouped.iloc[4,j]]\n    blueBars = blueBars + [grouped.iloc[2,j]/grouped.iloc[4,j]]\n    greyBars = greyBars + [grouped.iloc[3,j]/grouped.iloc[4,j]]\n\nr = list(range(len(grouped.columns)))\n\n# plot\nbarWidth = 0.85\nplatform_names = list(grouped.columns)\n# Create green Bars - 1\nplt.bar(r, greenBars, color='#b5ffb9', edgecolor='white', width=barWidth, label = 'NA')\n# Create orange Bars - 2\nplt.bar(r, orangeBars, bottom=greenBars, color='#f9bc86', edgecolor='white', width=barWidth, label = 'EU')\n# Create blue Bars - 3\nplt.bar(r, blueBars, bottom=[i+j for i,j in zip(greenBars, orangeBars)], color='#a3acff', edgecolor='white', width=barWidth, label = 'Japan')\n# Create grey Bars - 3\nplt.bar(r, greyBars, bottom=[i+j for i,j,k in zip(greenBars, orangeBars, blueBars)], color='#888a99', edgecolor='white', width=barWidth, label = 'Other')\n\n# Custom x axis\nplt.xticks(r, platform_names)\nplt.xticks(rotation=90)\nplt.xlabel(\"Platform\")\n\n#Add legend\nplt.legend(loc='upper left', bbox_to_anchor=(1,1), ncol=1)\n\n# Show graphic\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Total does not add up to 1 because of rounding"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Year'].unique()\nlen(data['Year'].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**1.5. Find out the Sales in each Year for each Region by %**"},{"metadata":{"trusted":true},"cell_type":"code","source":"names = list(data.columns)[6:11]\n\n# Calculate the sum of urban by party\ngrouped = data.groupby('Year')[names].sum()\ngrouped = grouped.T\n\ngreenBars = []\norangeBars = []\nblueBars = []\ngreyBars = []\n\nfor j in range(0, len(grouped.columns)):\n    greenBars = greenBars + [grouped.iloc[0,j]/grouped.iloc[4,j]]\n    orangeBars = orangeBars + [grouped.iloc[1,j]/grouped.iloc[4,j]]\n    blueBars = blueBars + [grouped.iloc[2,j]/grouped.iloc[4,j]]\n    greyBars = greyBars + [grouped.iloc[3,j]/grouped.iloc[4,j]]\n\nr = list(range(len(grouped.columns)))\n\n# plot\nbarWidth = 0.85\nplatform_names = list(grouped.columns)\n# Create green Bars - 1\nplt.bar(r, greenBars, color='#b5ffb9', edgecolor='white', width=barWidth, label = 'NA')\n# Create orange Bars - 2\nplt.bar(r, orangeBars, bottom=greenBars, color='#f9bc86', edgecolor='white', width=barWidth, label = 'EU')\n# Create blue Bars - 3\nplt.bar(r, blueBars, bottom=[i+j for i,j in zip(greenBars, orangeBars)], color='#a3acff', edgecolor='white', width=barWidth, label = 'Japan')\n# Create grey Bars - 3\nplt.bar(r, greyBars, bottom=[i+j for i,j,k in zip(greenBars, orangeBars, blueBars)], color='#888a99', edgecolor='white', width=barWidth, label = 'Other')\n\n# Custom x axis\nplt.xticks(r, platform_names)\nplt.xticks(rotation=90)\nplt.xlabel(\"Year\")\n\n#Add legend\nplt.legend(loc='upper left', bbox_to_anchor=(1,1), ncol=1)\n\n# Show graphic\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The data for 2017 and 2020 seems to be incomplete. Let's remove the data in 2017 and 2020"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data[data['Year'] != 2017]\ndata = data[data['Year'] != 2020]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**1.6. Look at the Global Sales by Year**"},{"metadata":{"trusted":true},"cell_type":"code","source":"grouped = pd.DataFrame(data.groupby(['Year'])['Global_Sales'].sum()).reset_index()\n\nsns.lineplot(x='Year', y='Global_Sales', data=grouped)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**1.7. Global Sales by Platform**"},{"metadata":{"trusted":true},"cell_type":"code","source":"grouped = pd.DataFrame(data.groupby(['Platform'])['Global_Sales'].sum()).reset_index()\n\ngrouped = grouped.sort_values(by='Global_Sales', ascending=False)\n\nplt.bar(grouped['Platform'], grouped['Global_Sales'])\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**1.8 Global Sales by Genre**"},{"metadata":{"trusted":true},"cell_type":"code","source":"grouped = pd.DataFrame(data.groupby(['Genre'])['Global_Sales'].sum()).reset_index()\n\ngrouped = grouped.sort_values(by='Global_Sales', ascending=False)\n\nplt.bar(grouped['Genre'], grouped['Global_Sales'])\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**1.9 Global Sales by Genre by Year**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate the sum of urban by party\ngrouped = pd.DataFrame(data.groupby(['Year','Genre'])['Global_Sales'].sum()).reset_index()\n\n# platform = list(set(data['Platform']))[1:5]\n# grouped_1 = grouped[grouped['Platform'].isin(platform)]\n\nfig, axes = plt.subplots(nrows=2, ncols=2, sharex=True, sharey=True, figsize=(16,20))\nnum_graph = 4\nid_per_graph = ceil(len(grouped.Genre.unique())/ num_graph)\ncount = 0\nfor i in range(2):\n    for j in range(2):\n        genre = list(set(data['Genre']))[count*id_per_graph:(count+1)*id_per_graph]\n        sns.lineplot(x='Year', y='Global_Sales', hue='Genre', data=grouped[grouped['Genre'].isin(genre)], ax=axes[i][j])\n        count += 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**1.10 Global Sales by Genre by Year**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Publisher.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# names = list(data.columns)[6:11]\n\n# Calculate the sum of urban by party\ngrouped = pd.DataFrame(data.groupby('Publisher')['Global_Sales'].sum()).reset_index()\ngrouped = grouped.sort_values(by='Global_Sales', ascending=False)\ngrouped_1 = grouped.head(30)\nplt.boxplot(grouped_1['Global_Sales']) \n  \n# show plot \nplt.show() \n\ngrouped_1 = grouped_1.T\n\nr = list(range(len(grouped_1.iloc[0])))\n\n# plot\n\n# plt.ylim(0,100)\ntop_30_publisher_names = list(grouped_1.iloc[0])\n# Create green Bars - 1\nplt.bar(r, grouped_1.iloc[1])\n\n# Custom x axis\nplt.xticks(r, top_30_publisher_names)\nplt.xticks(rotation=90)\nplt.xlabel(\"Publisher\")\n\n#Add legend\nplt.legend(loc='upper left', bbox_to_anchor=(1,1), ncol=1)\n\n# Show graphic\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**2.1 Global Sales by Publishers in 2008**"},{"metadata":{"trusted":true},"cell_type":"code","source":"output_file('vbar.html')\n\ndataset = data[data['Publisher'].isin(top_30_publisher_names)]\n\n# Calculate the sum of urban by party\n\ndataset = dataset[dataset['Year']==2008]\ngrouped = pd.DataFrame(dataset.groupby(['Publisher'])['Global_Sales'].sum()).reset_index()\ngrouped = grouped.sort_values(by='Global_Sales')\ndataset1 = {'publishers' : list(grouped.Publisher.unique()),\n        'global_sales' : list(grouped['Global_Sales'])}\n\nsource = ColumnDataSource(data=dataset1)\npublishers = list(grouped.Publisher.unique())\n\np = figure(y_range = publishers, plot_width=500, plot_height=400, title=\"Global Sales by Publishers in 2008\")\np.hbar(y = 'publishers', height=0.5,\n       right = 'global_sales', source = source, color=\"firebrick\")\n\noutput_notebook()\nshow(p)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get the cumulative sales for top 30 publishers"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = data[data['Publisher'].isin(top_30_publisher_names)].reset_index()\n\ngrouped = pd.DataFrame(dataset.groupby(['Year','Publisher'])['Global_Sales'].sum()).reset_index()\ngrouped = grouped.sort_values(by=['Year','Global_Sales']).reset_index()\n\ncumulative_sales = []\n\nYear = list(range(1980,2017))\n\nfor i in range(len(top_30_publisher_names)):\n    for j in range(len(Year)):\n        if sum(grouped.loc[(grouped['Year']==Year[j]) & (grouped['Publisher']==top_30_publisher_names[i]),'Global_Sales']) == 0:\n            a_row = {'index': len(grouped)+1, \n                     'Year': Year[j], \n                     'Publisher': top_30_publisher_names[i], \n                     'Global_Sales': 0}\n            row_df = pd.DataFrame([a_row])\n            grouped = pd.concat([row_df, grouped], ignore_index=True)\n\ngrouped = grouped.sort_values(by=['Year','Global_Sales']).reset_index()          \n            \nfor i in range(len(grouped)):\n    cumulative_sales = cumulative_sales + [sum(grouped.loc[(grouped['Year']<=grouped['Year'][i]) & (grouped['Publisher']==grouped['Publisher'][i]),'Global_Sales'])]\n    \ngrouped['Cumulative_sales'] = cumulative_sales","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**2.2 Top 30 Publishers cumulative sales in 2016**"},{"metadata":{"trusted":true},"cell_type":"code","source":"output_file('vbar.html')\n\ngrouped1 = grouped[grouped['Year']==2016]\ngrouped1 = pd.DataFrame(grouped1.groupby(['Publisher'])['Cumulative_sales'].sum()).reset_index()\ngrouped1 = grouped1.sort_values(by='Cumulative_sales')\ndataset1 = {'publishers' : list(grouped1.Publisher.unique()),\n        'global_sales' : list(grouped1['Cumulative_sales'])}\n\nsource = ColumnDataSource(data=dataset1)\npublishers = list(grouped1.Publisher.unique())\n\np = figure(y_range = publishers, plot_width=1000, plot_height=400, title=\"Cumulative Sales by Publishers in 2016\")\np.hbar(y = 'publishers', height=0.5,\n       right = 'global_sales', source = source, color=\"firebrick\")\n\noutput_notebook()\n\nshow(p)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**2.3. Top 30 Publishers cumulative sales from 1980 to 2016**"},{"metadata":{"trusted":true},"cell_type":"code","source":"output_file('vbar.html')\n\ntrue_source = ColumnDataSource(data={'year': grouped.loc[:,'Year'],\n                                    'publishers': grouped.loc[:,'Publisher'],\n                                    'global_sales': grouped.loc[:,'Cumulative_sales']})\nsource = ColumnDataSource(data={'year': grouped.loc[grouped['Year']==2016,'Year'],\n                                'publishers': grouped.loc[grouped['Year']==2016,'Publisher'],\n                                'global_sales': grouped.loc[grouped['Year']==2016,'Cumulative_sales']})\ncallback = CustomJS(args=dict(source=source, ts=true_source), code='''\n                    var f=cb_obj.value;\n\n                    var data = ts.data;\n\n                    var data1 = source.data;\n                    var year = [];\n                    var publishers = [];\n                    var global_sales = [];\n\n                    // iterate through rows of data source and see if each satisfies some constraint\n                    for (var i = 0; i < ts.get_length(); i++){\n                        if (data['year'][i] == f){\n                            year.push(data['year'][i]);\n                            publishers.push(data['publishers'][i]);\n                            global_sales.push(data['global_sales'][i]);\n                        }\n                    }\n\n                    data1['year'] = year\n                    data1['publishers'] = publishers\n                    data1['global_sales'] = global_sales\n\n                    \n                    source.change.emit();\n            ''')\n\n#                     data1['global_sales'].sort(function(a, b){return a - b})\n\np = figure(y_range = publishers, plot_width=1000, plot_height=400, title=\"Cumulative Sales by Publishers in from 1980 to 2016\")\np.hbar(y = 'publishers', height=0.5,\n       right = 'global_sales', source = source, color=\"firebrick\")\n\ndate_slider = Slider(title = 'Year', value=(2016),\n                    start=Year[0], end=Year[-1], max_width = 400)\ndate_slider.js_on_change('value', callback)\n\noutput_notebook()\n\nlayout = column(date_slider, p)\n\nshow(layout)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**3.0 Random Forest Tree Regression to predict sales of top 30 publishers**"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = data[data['Publisher'].isin(top_30_publisher_names)]\ndataset = dataset[dataset['Global_Sales']>=1]\ndataset = pd.DataFrame({'Genre': dataset['Genre'], 'Publisher': dataset['Publisher'], 'Year':dataset['Year'], 'Global_Sales':dataset['Global_Sales']})\n\nX = dataset.iloc[:, 0:-1].values\ny = dataset.iloc[:, -1].values\n\nlabelencoder = LabelEncoder()\nX[:, 0] = labelencoder.fit_transform(X[:, 0])\nX[:, 1] = labelencoder.fit_transform(X[:, 1])\n\nct = ColumnTransformer([(\"Genre\", OneHotEncoder(), [0])], remainder = 'passthrough')\nX = ct.fit_transform(X)\n\nX = X.toarray()\n\nct = ColumnTransformer([(\"Publisher\", OneHotEncoder(), [12])], remainder = 'passthrough')\nX = ct.fit_transform(X)\n\n# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n\nscaler = MinMaxScaler()\ny_train = scaler.fit_transform(y_train.reshape(-1,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting Random Forest Regression to the dataset\n\nfrom sklearn.ensemble import RandomForestRegressor\nregressor = RandomForestRegressor(n_estimators = 100, random_state = 0)\nregressor.fit(X_train, y_train)\n# Predicting a new result\npredict_train = regressor.predict(X_train)\npredict_test = regressor.predict(X_test)\n\ny_test = scaler.fit_transform(y_test.reshape(-1,1))\n\nimport math\nfrom sklearn.metrics import mean_squared_error\ntrainScore = math.sqrt(mean_squared_error(predict_train, y_train))\nprint('Train Score: %.2f RMSE' % (trainScore))\nvalScore = math.sqrt(mean_squared_error(predict_test, y_test))\nprint('Test Score: %.2f RMSE' % (valScore))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}