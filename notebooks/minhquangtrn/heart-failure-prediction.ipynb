{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# HEART FAILURE PREDICTION\n","metadata":{}},{"cell_type":"code","source":"# Data clearnning and EDA\nimport pandas as pd\nimport numpy as np\nimport math\nimport json\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:14:58.964791Z","iopub.execute_input":"2021-05-29T13:14:58.965579Z","iopub.status.idle":"2021-05-29T13:14:59.867198Z","shell.execute_reply.started":"2021-05-29T13:14:58.965449Z","shell.execute_reply":"2021-05-29T13:14:59.865855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Introduction","metadata":{}},{"cell_type":"markdown","source":"Heart is among the most important organs, early-predicting heart failure is a vital matter to any patients with cardiovascular diseases (CVDs). In this background, electronic health records  (EHRs, also called medical records) is a useful source of information on which several screening studies have been working. However, healthcare data has vast data sources, with multiple attributes, which causes difficulty in manually handling the data. Many models varying from standard statistical techniques for sufficient datasets to machine learning models for large-scale datasets have been developed and applied in identifying risks at early stages of heart failure. \n\nThis project is only concerned with the standard statistical techniques as it is sufficient for such a dataset of 299 patients to deal with 3 main problems: (1) Analyze the change of health indicator with regards to gender and age of the patients, (2) Analyze which factors contribute to the mortality rate of a patient and (3) From the given data, Can we build a model which can effectively predict the patient possibility of death. In the following part, we will have a quick review about the related work regarding this data set and discussion about the result. \n","metadata":{}},{"cell_type":"markdown","source":"## I. Exploratory Data Analysis","metadata":{}},{"cell_type":"markdown","source":"In this section, some basic investigation about the data is performed to gain deeper insight about the data set. Then, more analysis is conducted to answer our research question.","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('../input/heart-failure-clinical-data/heart_failure_clinical_records_dataset.csv')","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:14:59.871582Z","iopub.execute_input":"2021-05-29T13:14:59.871933Z","iopub.status.idle":"2021-05-29T13:14:59.893741Z","shell.execute_reply.started":"2021-05-29T13:14:59.871899Z","shell.execute_reply":"2021-05-29T13:14:59.89242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:14:59.896098Z","iopub.execute_input":"2021-05-29T13:14:59.896788Z","iopub.status.idle":"2021-05-29T13:14:59.934255Z","shell.execute_reply.started":"2021-05-29T13:14:59.896741Z","shell.execute_reply":"2021-05-29T13:14:59.933038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1. Overview on data set","metadata":{}},{"cell_type":"markdown","source":"The dataset contains the medical records of 299 patients of heart failure, which consisted of 194 men and 105 women. The patient's ages vary from 40 to 95 years old. The dataset keeps track of clinical, body, and lifestyle information of the patients, which are called features in this research. There are 13 features in the dataset, 12 of which are considered to be potential reasons contributing to mortality of patients with Cardiovascular Heart Disease (CHD): age, anaemia, Creatinine-Phosphokinase (CPK), diabetes, Ejection Fraction (EF), High Blood Pressure (HBP), platelets, serum creatinine, serum sodium, sex, smoking. Some of the features are of binary data type: anaemia, diabetes, HBP, sex, smoking and death event, which then are taken as category features. The other are continuous (analogous) values, which are taken as numeric features. \n","metadata":{}},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:14:59.935858Z","iopub.execute_input":"2021-05-29T13:14:59.936134Z","iopub.status.idle":"2021-05-29T13:14:59.958761Z","shell.execute_reply.started":"2021-05-29T13:14:59.936107Z","shell.execute_reply":"2021-05-29T13:14:59.957233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 13 rows in the above table representing 13 clinical features in the patients’ profile: 12 complementary features and one target feature (death event). There is no null value for all features and the type of data is either of type float or integer, which means the data is cleaned and ready to be analysed.","metadata":{}},{"cell_type":"code","source":"categorical_features = ['anaemia', 'diabetes', 'high_blood_pressure', 'sex', 'smoking', 'DEATH_EVENT']\nnumerical_features = ['age', 'creatinine_phosphokinase', 'ejection_fraction', 'platelets', 'serum_creatinine', 'serum_sodium', 'time']\nhealth_features = ['anaemia', 'diabetes', 'high_blood_pressure', 'creatinine_phosphokinase', 'ejection_fraction', 'platelets', 'serum_creatinine', 'serum_sodium']","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:14:59.960237Z","iopub.execute_input":"2021-05-29T13:14:59.960546Z","iopub.status.idle":"2021-05-29T13:14:59.973Z","shell.execute_reply.started":"2021-05-29T13:14:59.960515Z","shell.execute_reply":"2021-05-29T13:14:59.971774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[numerical_features].describe()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:14:59.974649Z","iopub.execute_input":"2021-05-29T13:14:59.974974Z","iopub.status.idle":"2021-05-29T13:15:00.022909Z","shell.execute_reply.started":"2021-05-29T13:14:59.974945Z","shell.execute_reply":"2021-05-29T13:15:00.021686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The statistical quantitative characteristics of the numerical feature of the dataset is reported in the table above. The total number, mean value, standard deviation, minimum value and maximum value, and the quartiles of the numeric features are taken in full sample (all patients). The calculated quantitative description of each  feature then can be used to build their respective box plot.\n","metadata":{}},{"cell_type":"markdown","source":"##### Age","metadata":{}},{"cell_type":"code","source":"sns.histplot(x=data.age)\nplt.title('Age Distribution')\nplt.xlabel('Age')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:00.024525Z","iopub.execute_input":"2021-05-29T13:15:00.024847Z","iopub.status.idle":"2021-05-29T13:15:00.267324Z","shell.execute_reply.started":"2021-05-29T13:15:00.024816Z","shell.execute_reply":"2021-05-29T13:15:00.266211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The age distribution is shown in the above bar chart. All of the patients are between 40 and 95 years old with most of them being from 40 to 72 years old. The patients’ number of 56 to 62 years old got the highest count, with more than 50 people. From the age of 75 onwards, the patients’ number decreased in proportional to their age range. Three last columns of age ranges got the least number of patients (under 10 patients). \n","metadata":{}},{"cell_type":"code","source":"sns.displot(data=data, x=\"age\", hue=\"DEATH_EVENT\", multiple=\"stack\", kind='kde')\nplt.title('Distribution of Age and Death event')\nplt.xlabel('Age')\nplt.show() ","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:00.269829Z","iopub.execute_input":"2021-05-29T13:15:00.270156Z","iopub.status.idle":"2021-05-29T13:15:00.744661Z","shell.execute_reply.started":"2021-05-29T13:15:00.270122Z","shell.execute_reply":"2021-05-29T13:15:00.743446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The age and death event distribution is shown in the following line chart. The area between two curves indicates the number of survived patients with respect to their age, while the area between lower curve and the horizontal axis shows the number of dead patients. In detail, the area of survived patients increases from the age of 45 to 75 before decreasing after the age of 75. The peak of survival density of above 0.03 is between 60 and 70 years old. The patients of 80 years old or above had the slimmest density of survival with below 0.01 survival density compared to 0.005 death density. \n","metadata":{}},{"cell_type":"markdown","source":"##### Ejection fraction","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,5))\nsns.boxplot(x=data.ejection_fraction, ax=ax)\nplt.title('Box plot of ejection fraction')\nplt.xlabel('Ejection fraction')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:00.747036Z","iopub.execute_input":"2021-05-29T13:15:00.747425Z","iopub.status.idle":"2021-05-29T13:15:00.889838Z","shell.execute_reply.started":"2021-05-29T13:15:00.747377Z","shell.execute_reply":"2021-05-29T13:15:00.888396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The box plot of ejection fraction is as shown in above table. The mean value is 38%, the Q1 and Q3 are 30% and 45% respectively. The minimum value is 10% and the maximum value is 65%.  \n","metadata":{}},{"cell_type":"code","source":"sns.displot(data=data, x=\"ejection_fraction\", hue=\"DEATH_EVENT\", multiple=\"stack\", kind='kde')\nplt.title('Distribution of ejection fraction and Death event')\nplt.xlabel('ejection_fraction')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:00.891879Z","iopub.execute_input":"2021-05-29T13:15:00.892382Z","iopub.status.idle":"2021-05-29T13:15:01.335742Z","shell.execute_reply.started":"2021-05-29T13:15:00.892328Z","shell.execute_reply":"2021-05-29T13:15:01.334841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The distribution of ejection fraction and death event is shown as above. The area between two curves represents the survival density while the area between the lower curve and the horizontal axis is the death density. The survival density reaches its peak of above 0.04 at around 40% of the ejection fraction, however, drops significantly if the ejection fraction is either below 20% or above 70%. ","metadata":{}},{"cell_type":"markdown","source":"##### Creatinine phosphokinase","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20,5))\nsns.boxplot(x=data.creatinine_phosphokinase, ax=ax)\nplt.title('Box plot of creatinine phosphokinase')\nplt.xlabel('Creatinine phosphokinase')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:01.336968Z","iopub.execute_input":"2021-05-29T13:15:01.33745Z","iopub.status.idle":"2021-05-29T13:15:01.496975Z","shell.execute_reply.started":"2021-05-29T13:15:01.337412Z","shell.execute_reply":"2021-05-29T13:15:01.495607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are many outlier in Creatinine phosphokinase feature. We can consider eliminate those during feature engineering process.","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20,10))\nsns.histplot(x=data.creatinine_phosphokinase, ax=ax)\nplt.title('Distribution of creatinine phosphokinase')\nplt.xlabel('creatinine phosphokinase')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:01.49864Z","iopub.execute_input":"2021-05-29T13:15:01.499005Z","iopub.status.idle":"2021-05-29T13:15:01.827156Z","shell.execute_reply.started":"2021-05-29T13:15:01.498971Z","shell.execute_reply":"2021-05-29T13:15:01.825847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The distribution of creatinine phosphokinase is shown in the above bar chart. The level of CPK enzyme in the blood is mostly distributed from 0 to below 3000 mcg/L. \n","metadata":{}},{"cell_type":"code","source":"sns.displot(data=data, x=\"creatinine_phosphokinase\", hue=\"DEATH_EVENT\", multiple=\"stack\", kind='kde')\nplt.title('Distribution of creatinine phosphokinase and Death event')\nplt.xlabel('creatinine_phosphokinase')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:01.828386Z","iopub.execute_input":"2021-05-29T13:15:01.828692Z","iopub.status.idle":"2021-05-29T13:15:02.4388Z","shell.execute_reply.started":"2021-05-29T13:15:01.828661Z","shell.execute_reply":"2021-05-29T13:15:02.43751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The distribution of creatinine phosphokinase and death events. The survival density is enlarged when the level of CPK enzyme in the blood is from 0 to 1000 mcg/L and decreases if the creatinine phosphokinase level is higher than 2000 mcg/L. \n","metadata":{}},{"cell_type":"markdown","source":"##### Plateletes","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20,5))\nsns.boxplot(x=data.platelets, ax=ax)\nplt.title('Boxplot of platelets')\nplt.xlabel('Plateletes')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:02.44063Z","iopub.execute_input":"2021-05-29T13:15:02.440956Z","iopub.status.idle":"2021-05-29T13:15:02.575819Z","shell.execute_reply.started":"2021-05-29T13:15:02.440924Z","shell.execute_reply":"2021-05-29T13:15:02.574473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The box plot of platelets shows the mean value of platelets in blood of all patients is 260 kiloplatelets/mL. The Q1 and Q3 value are 220 kiloplatelets/mL and 300 kiloplatelets/mL, respectively. There are many outliers in the box plot. \n","metadata":{}},{"cell_type":"code","source":"sns.displot(data=data, x=\"platelets\", hue=\"DEATH_EVENT\", multiple=\"stack\", kind='kde')\nplt.title('Distribution of platelets and Death event')\nplt.xlabel('platelets')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:02.577449Z","iopub.execute_input":"2021-05-29T13:15:02.5778Z","iopub.status.idle":"2021-05-29T13:15:02.972755Z","shell.execute_reply.started":"2021-05-29T13:15:02.577768Z","shell.execute_reply":"2021-05-29T13:15:02.971454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The distribution of platelets and death events is in the above line chart. The area of survival, which lies between two curves, increases when the platelets in blood is from 200 kiloplatelets/mL to 350 kiloplatelets/mL, however, decreases when the platelets drops out of the range. \n","metadata":{}},{"cell_type":"markdown","source":"##### Serum creatinine","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20,5))\nsns.boxplot(x=data.serum_creatinine, ax=ax)\nplt.title('Box plot of serum cretinine')\nplt.xlabel('Serum creatinine')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:02.974357Z","iopub.execute_input":"2021-05-29T13:15:02.974692Z","iopub.status.idle":"2021-05-29T13:15:03.115882Z","shell.execute_reply.started":"2021-05-29T13:15:02.974659Z","shell.execute_reply":"2021-05-29T13:15:03.114334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.displot(data=data, x=\"serum_creatinine\", hue=\"DEATH_EVENT\", multiple=\"stack\", kind='kde')\nplt.title('Distribution of serum_creatinine and Death event')\nplt.xlabel('serum_creatinine')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:03.117647Z","iopub.execute_input":"2021-05-29T13:15:03.117988Z","iopub.status.idle":"2021-05-29T13:15:03.45293Z","shell.execute_reply.started":"2021-05-29T13:15:03.117956Z","shell.execute_reply":"2021-05-29T13:15:03.451504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The distribution of serum creatinine and death events is shown in the above line chart. The survival density area lying between two curves increases when the level of creatinine in the blood is between 1 mg/dL and 1.8 mg/dL. However, the survival density decreases dramatically when the level of creatinine is either below 1 mg/dL or above 2 mg/dL. \n","metadata":{}},{"cell_type":"markdown","source":"##### Seruim sodium","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20,5))\nsns.boxplot(x=data.serum_sodium, ax=ax)\nplt.title('Box plot of serum sodium')\nplt.xlabel('Seruim sodium')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:03.454573Z","iopub.execute_input":"2021-05-29T13:15:03.454941Z","iopub.status.idle":"2021-05-29T13:15:03.60832Z","shell.execute_reply.started":"2021-05-29T13:15:03.454907Z","shell.execute_reply":"2021-05-29T13:15:03.607332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.displot(data=data, x=\"serum_sodium\", hue=\"DEATH_EVENT\", multiple=\"stack\", kind='kde')\nplt.title('Distribution of serum_sodium and Death event')\nplt.xlabel('serum_sodium')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:03.610096Z","iopub.execute_input":"2021-05-29T13:15:03.610578Z","iopub.status.idle":"2021-05-29T13:15:03.945484Z","shell.execute_reply.started":"2021-05-29T13:15:03.610526Z","shell.execute_reply":"2021-05-29T13:15:03.944272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The minimum value of serum sodium is 125 mEq/L. The Q1 and Q3 values are 134 mEq/L and mEq/L respectively. The mean is 137 mEq/L. The maximum value is 150 mEq/L. There are many outliers to the left. \n","metadata":{}},{"cell_type":"markdown","source":"##### Time","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20,5))\nsns.boxplot(x=data.time, ax=ax)\nplt.title('Box plot of time')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:03.946803Z","iopub.execute_input":"2021-05-29T13:15:03.947121Z","iopub.status.idle":"2021-05-29T13:15:04.091684Z","shell.execute_reply.started":"2021-05-29T13:15:03.94709Z","shell.execute_reply":"2021-05-29T13:15:04.09042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Average value of follow-up time is 130 days. The patients had the follow-up time of 4-285 days. \n","metadata":{}},{"cell_type":"markdown","source":"#### Categorical features","metadata":{}},{"cell_type":"markdown","source":"##### Anaemia","metadata":{}},{"cell_type":"code","source":"data['anaemia'].value_counts().plot(kind='bar')\nplt.xlabel(\"anaemia\", labelpad=14)\nplt.ylabel(\"Count of people\", labelpad=14)\nplt.title('The number of people has and do not have anaemia')","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:04.093508Z","iopub.execute_input":"2021-05-29T13:15:04.093883Z","iopub.status.idle":"2021-05-29T13:15:04.277335Z","shell.execute_reply.started":"2021-05-29T13:15:04.093847Z","shell.execute_reply":"2021-05-29T13:15:04.276242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The number of the patients did not have anaemia was over 160 patients. The number of patients had anaemia was 40 patients less than the one had not, which was over 120 patients. \n","metadata":{}},{"cell_type":"code","source":"pd.crosstab(data.anaemia  ,data.DEATH_EVENT).plot(kind='bar')\nplt.title('Mortality rate correlating to anaemia')\nplt.xlabel('Anaemia')\nplt.ylabel('Death')\nplt.show()","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-05-29T13:15:04.278986Z","iopub.execute_input":"2021-05-29T13:15:04.279316Z","iopub.status.idle":"2021-05-29T13:15:04.473331Z","shell.execute_reply.started":"2021-05-29T13:15:04.279283Z","shell.execute_reply":"2021-05-29T13:15:04.471954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The mortality rate correlating to anaemia is shown in the following bar chart. The first two columns show the mortality rate of the patients who did not have anaemia and the other two columns show the mortality rate for those who had anaemia. For those who did not have anaemia, there were 120 survived patients and 50 dead patients. For those who had, there were 80 survived patients and 40 dead patients. \n","metadata":{}},{"cell_type":"markdown","source":"##### Diabetes","metadata":{}},{"cell_type":"code","source":"data['diabetes'].value_counts().plot(kind='bar')\nplt.xlabel(\"diabetes\", labelpad=14)\nplt.ylabel(\"Count of people\", labelpad=14)\nplt.title('The number of people has and do not have diabetes')","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:04.479526Z","iopub.execute_input":"2021-05-29T13:15:04.479924Z","iopub.status.idle":"2021-05-29T13:15:04.638947Z","shell.execute_reply.started":"2021-05-29T13:15:04.479889Z","shell.execute_reply":"2021-05-29T13:15:04.637486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.crosstab(data.diabetes  ,data.DEATH_EVENT).plot(kind='bar')\nplt.title('Mortality rate correlating to diabetes')\nplt.xlabel('Diabetes')\nplt.ylabel('Death')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:04.64208Z","iopub.execute_input":"2021-05-29T13:15:04.642451Z","iopub.status.idle":"2021-05-29T13:15:04.826675Z","shell.execute_reply.started":"2021-05-29T13:15:04.642417Z","shell.execute_reply":"2021-05-29T13:15:04.825345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For the patient who did not have diabetes, the survived patients were nearly 120 patients and the dead patients were around 55 patients. For one who had, the dead patients’ number was over 80 and the dead patients were below 50 patients. \n","metadata":{}},{"cell_type":"markdown","source":"##### High blood pressure","metadata":{}},{"cell_type":"code","source":"data['high_blood_pressure'].value_counts().plot(kind='bar')\nplt.xlabel(\"high_blood_pressure\", labelpad=14)\nplt.ylabel(\"Count of people\", labelpad=14)\nplt.title('The number of people with or without high_blood_pressure')","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:04.82793Z","iopub.execute_input":"2021-05-29T13:15:04.828266Z","iopub.status.idle":"2021-05-29T13:15:04.990094Z","shell.execute_reply.started":"2021-05-29T13:15:04.828226Z","shell.execute_reply":"2021-05-29T13:15:04.988753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.crosstab(data.high_blood_pressure  ,data.DEATH_EVENT).plot(kind='bar')\nplt.title('Mortality rate correlating to high_blood_pressure')\nplt.ylabel('high_blood_pressure')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:04.991707Z","iopub.execute_input":"2021-05-29T13:15:04.992071Z","iopub.status.idle":"2021-05-29T13:15:05.1848Z","shell.execute_reply.started":"2021-05-29T13:15:04.992037Z","shell.execute_reply":"2021-05-29T13:15:05.183133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For those who had hypertension, the dead patients were 40 patients, compared to 65 survived patients. While the number of dead patients were 55 patients compared to nearly 140 survived patients in the group of non-hypertension patients. \n","metadata":{}},{"cell_type":"markdown","source":"##### Gender","metadata":{}},{"cell_type":"code","source":"data['sex'].value_counts().plot(kind='bar')\nplt.xlabel(\"gender\", labelpad=14)\nplt.ylabel(\"Count of people\", labelpad=14)\nplt.title('Number of male and female')","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:05.186657Z","iopub.execute_input":"2021-05-29T13:15:05.187076Z","iopub.status.idle":"2021-05-29T13:15:05.3455Z","shell.execute_reply.started":"2021-05-29T13:15:05.187032Z","shell.execute_reply":"2021-05-29T13:15:05.344357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Smoking","metadata":{}},{"cell_type":"code","source":"data['smoking'].value_counts().plot(kind='bar')\nplt.xlabel(\"Smoke\", labelpad=14)\nplt.ylabel(\"Count of people\", labelpad=14)\nplt.title('Number of patient smoke')","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:05.346989Z","iopub.execute_input":"2021-05-29T13:15:05.347545Z","iopub.status.idle":"2021-05-29T13:15:05.513788Z","shell.execute_reply.started":"2021-05-29T13:15:05.347473Z","shell.execute_reply":"2021-05-29T13:15:05.512297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.crosstab(data.smoking  ,data.DEATH_EVENT).plot(kind='bar')\nplt.title('Mortality rate correlating to smoking')\nplt.ylabel('Count of people')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:05.515325Z","iopub.execute_input":"2021-05-29T13:15:05.515682Z","iopub.status.idle":"2021-05-29T13:15:05.706625Z","shell.execute_reply.started":"2021-05-29T13:15:05.515649Z","shell.execute_reply":"2021-05-29T13:15:05.705329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The number of dead patients who did smoke was 30, compared to over 60 dead patients who did not. The survived patients who did smoke were 60, while the survived patients who did not smoke were nearly 140 patients. \n","metadata":{}},{"cell_type":"markdown","source":"##### Death event","metadata":{}},{"cell_type":"code","source":"data['DEATH_EVENT'].value_counts().plot(kind='bar')\nplt.xlabel(\"DEATH_EVENT\", labelpad=14)\nplt.ylabel(\"Count of people\", labelpad=14)\nplt.title('Number of death patients')","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:05.7083Z","iopub.execute_input":"2021-05-29T13:15:05.708736Z","iopub.status.idle":"2021-05-29T13:15:06.019118Z","shell.execute_reply.started":"2021-05-29T13:15:05.70869Z","shell.execute_reply":"2021-05-29T13:15:06.01757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['DEATH_EVENT'].value_counts()\n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:06.021243Z","iopub.execute_input":"2021-05-29T13:15:06.021716Z","iopub.status.idle":"2021-05-29T13:15:06.031006Z","shell.execute_reply.started":"2021-05-29T13:15:06.021672Z","shell.execute_reply":"2021-05-29T13:15:06.029763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There were around 200 dead patients and nearly 100 survived patients. We can see that there exist an imbalance between two value in the target of the data set (death event).\n","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(16,10))\nsns.heatmap(data.corr(method='pearson'), annot=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:06.032602Z","iopub.execute_input":"2021-05-29T13:15:06.033048Z","iopub.status.idle":"2021-05-29T13:15:07.133241Z","shell.execute_reply.started":"2021-05-29T13:15:06.033006Z","shell.execute_reply":"2021-05-29T13:15:07.131656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 2. The patients’ age and sex affect the their health’s indicators \n\n","metadata":{}},{"cell_type":"markdown","source":"To analyze the effects of age and sex on other health indicators, we performed one-way ANOVA analysis of each indicator with age and sex as factors. The ANOVA tests yield crucial information which helps determine whether the null hypothesis is accepted or decline for each indicator\n\nThe ANOVA tests focus on performing Ordinary Least Square regression (OLS regression) between the factors and each dependent variable. The regression method estimates the parameters (slope and intercept) by minimizing the sum of square of differences between the available data and the predicted values. The method is chosen due to the simple model of the data (2 factors and 1 dependent variable for each model)\n\nCrtical values:\nGiven data size = 299, degree of freedom = 2, significant level = 0.05, we have\n<ul>\n<li>F critical = 3.026</li>\n<li>t critical = 1.968</li>\n</ul>","metadata":{}},{"cell_type":"code","source":"from sklearn import linear_model\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:07.135189Z","iopub.execute_input":"2021-05-29T13:15:07.135681Z","iopub.status.idle":"2021-05-29T13:15:08.283944Z","shell.execute_reply.started":"2021-05-29T13:15:07.135619Z","shell.execute_reply":"2021-05-29T13:15:08.282718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rsquared: get r squared\n# fvalue: get f value\n# f_pvalue: get p value\n# params: get coefficient\n# tvalues: get t-statistic\n\ntest_results = []\ncoef_results = []\nt_results = []\nf_pass_results = []\nt_pass_results = []\nf_crit = 3.026\nt_crit = 1.968\n\nfor feature in health_features:\n    results = smf.ols(feature + ' ~ age + sex', data=data).fit()\n    \n    test = [round(results.rsquared, 3), round(results.fvalue, 3), round(results.f_pvalue, 3)]\n    coef = [round(results.params[1], 4), round(results.params[2], 4)]\n    t = [round(results.tvalues[1], 3), round(results.tvalues[2], 3)]\n    f_pass = [\"Pass\" if round(results.fvalue, 3) <= f_crit else \"Fail\"]\n    t_pass = [\"Pass\" if (t[0] <= t_crit) and (t[0] >= t_crit * -1) else \"Fail\",\n              \"Pass\" if (t[1] <= t_crit) and (t[1] >= t_crit * -1) else \"Fail\"]\n    \n    test_results.append(test)\n    coef_results.append(coef)\n    t_results.append(t)\n    f_pass_results.append(f_pass)\n    t_pass_results.append(t_pass)\n    \n    print('\\033[1m ANOVA of age and sex with', feature,'\\033[0m')\n    print(results.summary())\n    print('\\n')","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-05-29T13:15:08.28558Z","iopub.execute_input":"2021-05-29T13:15:08.285911Z","iopub.status.idle":"2021-05-29T13:15:08.464044Z","shell.execute_reply.started":"2021-05-29T13:15:08.285874Z","shell.execute_reply":"2021-05-29T13:15:08.462738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the ANOVA results, the most crucial variables are selected. These include:\n<ul>\n<li>Coeficients: shows the slope of each factor</li>\n<li>F and p-value: determines whether the null hypothesis is rejected or not in general</li>\n<li>t-statistics: determines whether the null hypothesis is rejected or not for each factor</li>    \n<li>r-squared: determines how much data fits the regression model</li>\n</ul>","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (20,5)) \nax.set_axis_off() \ntable = ax.table( \n    cellText = test_results,  \n    rowLabels = health_features,  \n    colLabels = ['r squared', 'F', 'p'],\n    colWidths = [0.1] * 3,\n    loc = 'center') \ntable.set_fontsize(14)\ntable.scale(2, 2)\n   \nax.set_title('r squared, F, and p value of both age and sex in regards to each health indicator (indicators are dependent)', fontweight =\"bold\") \n   \nplt.show() ","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:08.465583Z","iopub.execute_input":"2021-05-29T13:15:08.465938Z","iopub.status.idle":"2021-05-29T13:15:08.829096Z","shell.execute_reply.started":"2021-05-29T13:15:08.465905Z","shell.execute_reply":"2021-05-29T13:15:08.827814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (20,5)) \nax.set_axis_off() \ntable = ax.table( \n    cellText = coef_results,  \n    rowLabels = health_features,  \n    colLabels = ['age', 'sex'],\n    colWidths = [0.1] * 2,\n    loc = 'center') \ntable.set_fontsize(14)\ntable.scale(2, 2)\n   \nax.set_title('Cooeficients of age and sex in regards to each health indicator (indicators are dependent)', fontweight =\"bold\") \n   \nplt.show() ","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:08.830703Z","iopub.execute_input":"2021-05-29T13:15:08.831033Z","iopub.status.idle":"2021-05-29T13:15:09.125492Z","shell.execute_reply.started":"2021-05-29T13:15:08.831Z","shell.execute_reply":"2021-05-29T13:15:09.124021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (20,5)) \nax.set_axis_off() \ntable = ax.table( \n    cellText = t_results,  \n    rowLabels = health_features,  \n    colLabels = ['age', 'sex'],\n    colWidths = [0.1] * 2,\n    loc = 'center') \ntable.set_fontsize(14)\ntable.scale(2, 2)\n   \nax.set_title('t-statistics of age and sex in regards to each health indicator (indicators are dependent)', fontweight =\"bold\") \n   \nplt.show() ","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:09.127589Z","iopub.execute_input":"2021-05-29T13:15:09.128041Z","iopub.status.idle":"2021-05-29T13:15:09.414046Z","shell.execute_reply.started":"2021-05-29T13:15:09.12799Z","shell.execute_reply":"2021-05-29T13:15:09.41252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Results analysis","metadata":{}},{"cell_type":"markdown","source":"The null hypothesis result for each indicator is shown as below:","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (20,5)) \nax.set_axis_off() \ntable = ax.table( \n    cellText = f_pass_results,  \n    rowLabels = health_features,  \n    colLabels = ['F test result'],\n    colWidths = [0.1],\n    loc = 'center') \ntable.set_fontsize(14)\ntable.scale(2, 2)\n   \nax.set_title('Null hypothesis result of age and sex in regards to each health indicator (F critical = 3.026)', fontweight =\"bold\") \n   \nplt.show() ","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:09.416061Z","iopub.execute_input":"2021-05-29T13:15:09.416544Z","iopub.status.idle":"2021-05-29T13:15:09.633649Z","shell.execute_reply.started":"2021-05-29T13:15:09.416496Z","shell.execute_reply":"2021-05-29T13:15:09.632345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From this, we accept the null hypothesis of age and sex when the dependent variables are\n<ul>\n<li>Anaemia</li>\n<li>Creatinine phosphokinase</li>\n<li>Platelets</li>    \n<li>Serum sodium</li>\n</ul>\nThis means both factors together do not affect these indicators while the remaining indicators are affected","metadata":{}},{"cell_type":"markdown","source":"The t test result of age and sex in regards to each health indicator is shown as below:","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (20,5)) \nax.set_axis_off() \ntable = ax.table( \n    cellText = t_pass_results,  \n    rowLabels = health_features,  \n    colLabels = ['age', 'sex'],\n    colWidths = [0.1] * 2,\n    loc = 'center') \ntable.set_fontsize(14)\ntable.scale(2, 2)\n   \nax.set_title('t test result of age and sex in regards to each health indicator (t critical = 1.968)', fontweight =\"bold\") \n   \nplt.show() ","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:09.635563Z","iopub.execute_input":"2021-05-29T13:15:09.635995Z","iopub.status.idle":"2021-05-29T13:15:09.906354Z","shell.execute_reply.started":"2021-05-29T13:15:09.635946Z","shell.execute_reply":"2021-05-29T13:15:09.905096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The results show how age and sex individually affects other indicators. If a factor passes the t test against an indicator, it means that the factor has no effect on it and vice versa.\n\nFrom the results, we can confirm that:\n<ol>\n<li>Age individually affects:</li>\n    <ul>\n        <li>Serum creatinine</li>\n    </ul>\n<li>Sex individually affects:</li>\n    <ul>\n        <li>Diabetes</li>\n        <li>Ejection fraction</li>\n        <li>Platelets</li>\n    </ul>\n</ol>","metadata":{}},{"cell_type":"markdown","source":"#### 3. Do health indices affect the mortality rate of patients?\n\n","metadata":{}},{"cell_type":"markdown","source":"##### ANOVA results","metadata":{}},{"cell_type":"markdown","source":"For this task, we peform ANOVA analysis on DEATH_EVENT, with all other variables being factors\n\nCrtical values: Given data size = 299, degree of freedom = 12, significance level = 0.05, we have:\n<ul>\n<li>F critical = 1.786</li>\n<li>t critical = 1.968</li>\n</ul>","metadata":{}},{"cell_type":"code","source":"# rsquared: get r squared\n# fvalue: get f value\n# f_pvalue: get p value\n# params: get coefficient\n# tvalues: get t-statistic\n\ntest_results = []\ncoef_and_t_results = []\nt_pass_results = []\nt_crit = 1.968\nindex = 1\n\nresults = smf.ols('DEATH_EVENT ~ age + anaemia + creatinine_phosphokinase + diabetes + ejection_fraction + high_blood_pressure' +\n                  ' + platelets + serum_creatinine + serum_sodium + sex + smoking + time', data=data).fit()\n\ntest_values = [round(results.rsquared, 3), round(results.fvalue, 3), round(results.f_pvalue, 3)]\ntest_results.append(test_values)\nwhile index < len(results.params):\n    coef_and_t = [round(results.params[index], 4), round(results.tvalues[index], 3)]\n    t_pass = [\"Pass\" if (round(results.tvalues[index], 3) <= t_crit) and (round(results.tvalues[index], 3) >= t_crit * - 1) else \"Fail\"]\n    \n    coef_and_t_results.append(coef_and_t)\n    t_pass_results.append(t_pass)\n    index += 1\n\nprint(results.summary())\nprint('\\n')","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-05-29T13:15:09.907904Z","iopub.execute_input":"2021-05-29T13:15:09.908521Z","iopub.status.idle":"2021-05-29T13:15:10.117317Z","shell.execute_reply.started":"2021-05-29T13:15:09.90847Z","shell.execute_reply":"2021-05-29T13:15:10.116448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (20,3)) \nax.set_axis_off() \ntable = ax.table( \n    cellText = test_results,    \n    colLabels = ['r squared', 'F', 'p'],\n    colWidths = [0.1] * 3,\n    loc = 'center') \ntable.set_fontsize(14)\ntable.scale(2, 2)\n   \nax.set_title('r squared, F, and p value of all health indicators in regards to DEATH_EVENT (indicators are independent)', fontweight =\"bold\") \n   \nplt.show() ","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:10.118706Z","iopub.execute_input":"2021-05-29T13:15:10.119311Z","iopub.status.idle":"2021-05-29T13:15:10.244708Z","shell.execute_reply.started":"2021-05-29T13:15:10.119263Z","shell.execute_reply":"2021-05-29T13:15:10.243872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (20,7)) \nax.set_axis_off() \ntable = ax.table( \n    cellText = coef_and_t_results,  \n    rowLabels = data.columns[:12],  \n    colLabels = ['coefficient', 't'],\n    colWidths = [0.1] * 2,\n    loc = 'center') \ntable.set_fontsize(14)\ntable.scale(2, 2)\n   \nax.set_title('Cooeficient and t_statistic of each health indicator in regards to DEATH_EVENT (indicators are independent)', fontweight =\"bold\") \n   \nplt.show() ","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:10.246062Z","iopub.execute_input":"2021-05-29T13:15:10.246672Z","iopub.status.idle":"2021-05-29T13:15:10.621313Z","shell.execute_reply.started":"2021-05-29T13:15:10.246625Z","shell.execute_reply":"2021-05-29T13:15:10.620139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Results analysis  \nWith the F value being 17.036 while the F critical value is 1.786, we reject the null hypothesis. This means that all health indicators together affect the mortality rate\n\nThe t test result of each indicator against DEATH_EVENT is shown as below:","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (20,7)) \nax.set_axis_off() \ntable = ax.table( \n    cellText = t_pass_results,  \n    rowLabels = data.columns[:12],  \n    colLabels = ['t test result'],\n    colWidths = [0.1],\n    loc = 'center') \ntable.set_fontsize(14)\ntable.scale(2, 2)\n   \nax.set_title('t test result of each health indicator in regards to DEATH_EVENT (t critical = 1.968)', fontweight =\"bold\") \n   \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:10.622773Z","iopub.execute_input":"2021-05-29T13:15:10.6231Z","iopub.status.idle":"2021-05-29T13:15:10.974022Z","shell.execute_reply.started":"2021-05-29T13:15:10.623064Z","shell.execute_reply":"2021-05-29T13:15:10.973234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From this, we notice that only 4 indicators fail the t test against DEATH_EVENT, which are:\n<ul>\n<li>Age</li>\n<li>Ejection fraction</li>\n<li>Serum creatinine</li>    \n<li>Time</li>\n</ul>\nThis means that only these factors affect the mortality rate","metadata":{}},{"cell_type":"markdown","source":"## Predictive analysis","metadata":{}},{"cell_type":"markdown","source":"The Exploratory data analysis step above gave us a profound understanding about the data set, thus, the next step is to perform predictive analysis. The aim of this stage is to built a classification model which can made accurate prediction about the death event of given patient. In the next sections, several steps need to performed which are feature engineering, hyperparatunning, data modelling and model evaluation. ","metadata":{}},{"cell_type":"code","source":"# Import ML library\nfrom sklearn.metrics import classification_report, f1_score, accuracy_score, recall_score, precision_score\nfrom sklearn.metrics import plot_confusion_matrix, plot_roc_curve\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import KFold, StratifiedKFold, cross_val_score, train_test_split, RandomizedSearchCV\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nimport lightgbm as lgb \n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:10.975562Z","iopub.execute_input":"2021-05-29T13:15:10.97619Z","iopub.status.idle":"2021-05-29T13:15:12.325733Z","shell.execute_reply.started":"2021-05-29T13:15:10.976121Z","shell.execute_reply":"2021-05-29T13:15:12.324496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature engineering","metadata":{}},{"cell_type":"markdown","source":"As stated above, in this section, we have to modify the data set before use it to train model. The steps are:\n* split the data\n* oversampling data set using SMOTE technique  \n\nIt is noticeable to mention that we have try remove outlier in the data set but not increase the accuracy of the model.","metadata":{}},{"cell_type":"code","source":"# Split the data into train and test set \ny = data['DEATH_EVENT']\nX = data.drop(['DEATH_EVENT'], axis=1)\nX_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:12.32715Z","iopub.execute_input":"2021-05-29T13:15:12.327511Z","iopub.status.idle":"2021-05-29T13:15:12.337472Z","shell.execute_reply.started":"2021-05-29T13:15:12.327478Z","shell.execute_reply":"2021-05-29T13:15:12.335908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The target of this data set show imbalance which can cause bias to the model which is affect our final prediction, therefore, we have to balancing the target of the data set by over sampling method using imblearn package. We applied SMOTE technique which first selects a minority class instance a at random and finds its k nearest minority class neighbors. Then it will created sample based on the K nearest neighbour class.\n","metadata":{}},{"cell_type":"code","source":"# Over sampling train data to avoid imbalance data set\nfrom imblearn.over_sampling import SMOTE\n\ndf = pd.concat([X_train, y_train], axis=1)\n\nsm = SMOTE(sampling_strategy='minority', random_state=7)\n\n# Fit the model to generate the data.\noversampled_trainX, oversampled_trainY = sm.fit_resample(df.drop('DEATH_EVENT', axis=1), df['DEATH_EVENT'])\noversampled_train = pd.concat([pd.DataFrame(oversampled_trainY), pd.DataFrame(oversampled_trainX)], axis=1)\noversampled_train['DEATH_EVENT'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:12.339512Z","iopub.execute_input":"2021-05-29T13:15:12.340121Z","iopub.status.idle":"2021-05-29T13:15:12.537923Z","shell.execute_reply.started":"2021-05-29T13:15:12.340024Z","shell.execute_reply":"2021-05-29T13:15:12.536812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = oversampled_trainX.copy()\ny_train = oversampled_trainY.copy()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:12.539323Z","iopub.execute_input":"2021-05-29T13:15:12.539622Z","iopub.status.idle":"2021-05-29T13:15:12.544724Z","shell.execute_reply.started":"2021-05-29T13:15:12.539593Z","shell.execute_reply":"2021-05-29T13:15:12.543643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluation Framework","metadata":{}},{"cell_type":"markdown","source":"In this project, the use the accuracy score, F1 score and ROC curve to evaluate the performance of model. While accuracy show the overall accuracy of the model, F1 score give us insight from the precision and recall score to understand if there exist any problem regarding the imbalance data set. In addition, the ROC curve is used for measuring the trade off between true positive rate and fasle positive rate","metadata":{}},{"cell_type":"code","source":"def evaluate_model_performance(clf, X_train, y_train):\n    '''evaluate a classification model's performance\n    INPUT:\n    clf - Model object\n    X_train - Training data matrix\n    y_train - Expected model output vector\n    OUTPUT:\n    clf_accuracy: Model accuracy\n    clf_f1_score: Model F1-score\n    clf_recall_score: model recall score\n    clf_precision_score: model precision score\n    '''\n    y_pred_rf = clf.predict(X_train)\n    clf_accuracy = accuracy_score(y_train, y_pred_rf)\n    clf_f1_score = f1_score(y_train, y_pred_rf)\n    clf_recall_score = recall_score(y_train, y_pred_rf, average='binary')\n    clf_precision_score = precision_score(y_train, y_pred_rf, average='binary')\n\n    confusion_matrix = plot_confusion_matrix(clf, X_train, y_train, \n                                             cmap=plt.cm.plasma,\n                                             normalize='true')\n    plt.grid(False)\n    plt.title(\"Confusion matrix\")\n    \n    roc_display = plot_roc_curve(clf, X_train, y_train)\n    plt.title(\"ROC Curve and AUC score\")\n\n    return clf_accuracy, clf_f1_score, clf_recall_score, clf_precision_score","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:12.546168Z","iopub.execute_input":"2021-05-29T13:15:12.546506Z","iopub.status.idle":"2021-05-29T13:15:12.558712Z","shell.execute_reply.started":"2021-05-29T13:15:12.546476Z","shell.execute_reply":"2021-05-29T13:15:12.557157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_score = []","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:12.56016Z","iopub.execute_input":"2021-05-29T13:15:12.560489Z","iopub.status.idle":"2021-05-29T13:15:12.576533Z","shell.execute_reply.started":"2021-05-29T13:15:12.560457Z","shell.execute_reply":"2021-05-29T13:15:12.575238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature selection","metadata":{}},{"cell_type":"markdown","source":"Before train the model and perform hyperparameter tunning, we train an baseline model `RandomForest` to observe the feature important of each feature.","metadata":{}},{"cell_type":"code","source":"%%time\n\nrf =  RandomForestClassifier(n_jobs=4)\n\nrf.fit(X_train, y_train)\n\nacc, f1, recall, precision = evaluate_model_performance(rf, X_val, y_val)\nprint(acc)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:12.577749Z","iopub.execute_input":"2021-05-29T13:15:12.578064Z","iopub.status.idle":"2021-05-29T13:15:13.61547Z","shell.execute_reply.started":"2021-05-29T13:15:12.578035Z","shell.execute_reply":"2021-05-29T13:15:13.614103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Feature Selection\n\nfeat_importances = pd.Series(rf.feature_importances_, index=X_train.columns)\nprint(feat_importances.sort_values(ascending=True))\nfeat_importances.nlargest(12).plot(kind='barh')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:13.616927Z","iopub.execute_input":"2021-05-29T13:15:13.617237Z","iopub.status.idle":"2021-05-29T13:15:13.955837Z","shell.execute_reply.started":"2021-05-29T13:15:13.617208Z","shell.execute_reply":"2021-05-29T13:15:13.954535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the graph above we can see that `anaemia`, `high_blood_pressure`, `diabetes` have the least impact on the target. Whle `serum_creatine`, `time`, `ejection_fraction` and `age` are the most important feature which similar to the ANOVA analysis above.\n","metadata":{}},{"cell_type":"code","source":"selected_features = ['time', 'age', 'ejection_fraction', 'serum_creatinine', \"serum_sodium\"]","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:13.957298Z","iopub.execute_input":"2021-05-29T13:15:13.957645Z","iopub.status.idle":"2021-05-29T13:15:13.963495Z","shell.execute_reply.started":"2021-05-29T13:15:13.957574Z","shell.execute_reply":"2021-05-29T13:15:13.962154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data modelling","metadata":{}},{"cell_type":"markdown","source":"In this section we use `GridSearchCV` to perform hyperparameter trainning and cross validation in order to achieve model with the optimize initialization. In this section we will train 5 different models from the simple model to high performance stacked model and compare the result to select the best model for predict the survival rate of a patient.","metadata":{}},{"cell_type":"markdown","source":"1. Gaussian Naive Bayes","metadata":{}},{"cell_type":"markdown","source":"Gaussian Naive Bayes model is a basic classification model based on Naivebayes theorem. Basically, the model will compute the probability of the hypothesis based on the prior knowlegde about the hypothesis. The model we applied in this project is the variant of the naive bayes model which it assumpt that the data is gausian distribution. ","metadata":{}},{"cell_type":"code","source":"%%time\n\nnb_clf =  GaussianNB()\n\nnb_clf.fit(X_train, y_train)  \n\nprint('Best Score: ', nb_clf.score(X_val, y_val))\n\nacc, f1, recall, precision = evaluate_model_performance(nb_clf, X_val, y_val)\nmodel_score.append(['Gaussian Naive Bayes', acc, f1, recall, precision])","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:13.965134Z","iopub.execute_input":"2021-05-29T13:15:13.965585Z","iopub.status.idle":"2021-05-29T13:15:14.356394Z","shell.execute_reply.started":"2021-05-29T13:15:13.965538Z","shell.execute_reply":"2021-05-29T13:15:14.355016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Although the simplicity of the model, the model show great result with 80% accuraccy and AUC is 0.85. It is noted that, in the confusion matrix, the false positive is higher than true positive which is because the unbalance data set at the beginning.","metadata":{}},{"cell_type":"markdown","source":"2. Logistic regression","metadata":{}},{"cell_type":"markdown","source":"The logistic regression is a linear approach for classification problems with a major difference is it uses sigmoid function. ","metadata":{}},{"cell_type":"code","source":"%%time\n\nmodel =  LogisticRegression()\n\nparameters = {\n    'penalty': ['l2'],\n    'solver': ['lbfgs', 'liblinear'],\n    'C': [ 0.01, 0.1, 10, 100],\n    'max_iter': [5000, 10000, 20000]\n}\n\nlog_reg = GridSearchCV(model, parameters, refit=True, verbose=1, cv = 5, n_jobs = 4)\nlog_reg.fit(X_train, y_train)\n\nprint('Best Score: ', log_reg.best_score_*100, '\\nBest Parameters: ', log_reg.best_params_)\n\nacc, f1, recall, precision = evaluate_model_performance(log_reg, X_val, y_val)\nmodel_score.append(['Logistic regression', acc, f1, recall, precision])","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:14.358059Z","iopub.execute_input":"2021-05-29T13:15:14.358464Z","iopub.status.idle":"2021-05-29T13:15:18.010415Z","shell.execute_reply.started":"2021-05-29T13:15:14.358428Z","shell.execute_reply":"2021-05-29T13:15:18.008959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The model also show great result with high accuraccy and AUC score. Also, the false positive is better than naive bayes model.","metadata":{}},{"cell_type":"markdown","source":"3. AdaboostClassifier","metadata":{}},{"cell_type":"markdown","source":"Adaboost classifier is a high performance stacked model, it use a combination of weak learner, combine it by weighted majority and made prediction.","metadata":{}},{"cell_type":"code","source":"\n%%time\n\nmodel = AdaBoostClassifier()\n\nparameters = {\n    'n_estimators': [200, 300, 500, 600, 800],\n    'learning_rate':[0.001, 0.1, 0.2, 0.5]\n}\n\nada_clf = GridSearchCV(model, parameters, refit=True, verbose=1, cv = 5, n_jobs = 4)\nada_clf.fit(X_train, y_train)\n\nprint('Best Score: ', ada_clf.best_score_*100, '\\nBest Parameters: ', ada_clf.best_params_)\n\nacc, f1, recall, precision = evaluate_model_performance(ada_clf, X_val, y_val)\nmodel_score.append(['Adaboost classifier', acc, f1, recall, precision])","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:18.014106Z","iopub.execute_input":"2021-05-29T13:15:18.014494Z","iopub.status.idle":"2021-05-29T13:15:57.218981Z","shell.execute_reply.started":"2021-05-29T13:15:18.014457Z","shell.execute_reply":"2021-05-29T13:15:57.218148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The model show great result. the AUC score is higher which prove that the model have a good measure of separability.","metadata":{}},{"cell_type":"markdown","source":"4. Random forest","metadata":{}},{"cell_type":"markdown","source":"Random forest model is an algorithm by randomize the each batch of data set to the decision tree and perform voting to make final prediction.","metadata":{}},{"cell_type":"code","source":"%%time\nmodel =  RandomForestClassifier()\n\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\n\nparameters = {'n_estimators': [100, 200, 300],\n               'max_features': ['auto', 'sqrt'],\n               'max_depth': max_depth,\n               'min_samples_split': [2, 5],\n               'min_samples_leaf': [1, 2] }\n\nrf_clf= GridSearchCV(model, parameters, refit=True, verbose=1, cv = 5, n_jobs = 4)\nrf_clf.fit(X_train, y_train)\n\nprint('Best Score: ', rf_clf.best_score_*100, '\\nBest Parameters: ', rf_clf.best_params_)\n\nacc, f1, recall, precision = evaluate_model_performance(rf_clf, X_val, y_val)\nmodel_score.append(['Random Forest', acc, f1, recall, precision])","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:15:57.220331Z","iopub.execute_input":"2021-05-29T13:15:57.220624Z","iopub.status.idle":"2021-05-29T13:19:50.44113Z","shell.execute_reply.started":"2021-05-29T13:15:57.220594Z","shell.execute_reply":"2021-05-29T13:19:50.439781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The model have 90% accuraccy on the trainning set and good AUC score on validation set.","metadata":{}},{"cell_type":"markdown","source":"5. LightGBM","metadata":{}},{"cell_type":"markdown","source":"The lightGBM is an gradient boosting model uses tree based learning algorithms. It is widely known as the more efficient version of XGBoosting model and can have great performance when dealing with large data set.","metadata":{}},{"cell_type":"code","source":"%%time\n\nmodel = lgb.LGBMClassifier()\n# Create parameters to search\ngridParams = {\n    'learning_rate': [0.01, 0.1, 0.001],\n    'max_depth': [5, 10, 15, None],\n    'min_data_in_leaf': [30, 50, 100],\n    'boosting_type': ['gbdt', 'dart']\n    }\n\n# To view the default model params:\nmodel.get_params().keys()\n\n# Create the grid\nlgb_clf = GridSearchCV(model, gridParams,\n                    verbose=1,\n                    cv = 5,\n                    n_jobs = 4)\n# Run the grid\nlgb_clf.fit(X_train, y_train)\n\n# Print the best parameters found\nprint(lgb_clf.best_params_)\nprint(lgb_clf.best_score_)\n\nacc, f1, recall, precision = evaluate_model_performance(lgb_clf, X_val, y_val)\nmodel_score.append(['LightGBM', acc, f1, recall, precision])","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:19:50.443201Z","iopub.execute_input":"2021-05-29T13:19:50.443641Z","iopub.status.idle":"2021-05-29T13:19:55.970601Z","shell.execute_reply.started":"2021-05-29T13:19:50.443593Z","shell.execute_reply":"2021-05-29T13:19:55.969431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The performance is quite similar to the random forest model, except it AUC score is slightly higher","metadata":{}},{"cell_type":"markdown","source":"### Model Evaluation","metadata":{}},{"cell_type":"markdown","source":"After trainning model and hyperparameter tunning phase, model with their best initialization is use to predict the test data set.","metadata":{}},{"cell_type":"code","source":"# Display the score of model with test data set\nscores = pd.DataFrame(model_score, columns =['Model', 'Accuracy Score', 'F1 Score', 'Recall score', 'Precision score'])\nscores","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:19:55.972259Z","iopub.execute_input":"2021-05-29T13:19:55.972843Z","iopub.status.idle":"2021-05-29T13:19:55.992471Z","shell.execute_reply.started":"2021-05-29T13:19:55.972796Z","shell.execute_reply":"2021-05-29T13:19:55.99141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(2, 2, figsize=(20,10))\nfig.suptitle('Model performance comparision')\n\nsns.barplot(data=scores, x='Model', y='Accuracy Score',  ax=axes[0][0])\naxes[0][0].set_title('Accuraccy Score')\n\nsns.barplot(data=scores, x='Model', y='F1 Score',  ax=axes[0][1])\naxes[0][1].set_title('F1 Score')\n\nsns.barplot(data=scores, x='Model', y='Recall score',  ax=axes[1][0])\naxes[1][0].set_title('Recall Score')\n\nsns.barplot(data=scores, x='Model', y='Precision score',  ax=axes[1][1])\naxes[1][1].set_title('Precision Score')","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:19:55.994262Z","iopub.execute_input":"2021-05-29T13:19:55.994607Z","iopub.status.idle":"2021-05-29T13:19:56.627736Z","shell.execute_reply.started":"2021-05-29T13:19:55.99456Z","shell.execute_reply":"2021-05-29T13:19:56.62645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the table and the bar chart, we can saw that the `Gaussian Naive Bayes`, `Logistic Regression` and `LightGBM` is model with high accuraccy and F1 scores. It is strange since the simplest model produce the best result. However, looking on the data set with originally have only 300 records which is considered small, hence, the complex models couldn't have enough data to optimize result bad performance. The `lightGBM` is an exception, the accuracy of the model is slightly lower than `naive bayes` but have higher AUC score","metadata":{}},{"cell_type":"markdown","source":"#### Data Modelling with feature selection","metadata":{}},{"cell_type":"markdown","source":"We choose the `Naive Bayes` and `LightGBM` to train with data with selected feature which are  `serum_creatine`, `serum_sodium`, `time`, `ejection_fraction` and `age`","metadata":{}},{"cell_type":"code","source":"X_train_selected = X_train[selected_features]\nX_val_selected = X_val[selected_features]\nX_train_selected","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:19:56.629301Z","iopub.execute_input":"2021-05-29T13:19:56.629734Z","iopub.status.idle":"2021-05-29T13:19:56.653151Z","shell.execute_reply.started":"2021-05-29T13:19:56.629688Z","shell.execute_reply":"2021-05-29T13:19:56.651953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nmodel = lgb.LGBMClassifier()\n# Create parameters to search\ngridParams = {\n    'learning_rate': [0.01, 0.1, 0.001],\n    'max_depth': [5, 10, 15, None],\n    'min_data_in_leaf': [30, 50, 100],\n    'boosting_type': ['gbdt', 'dart']\n    }\n\n# To view the default model params:\nmodel.get_params().keys()\n\n# Create the grid\nlgb = GridSearchCV(model, gridParams,\n                    verbose=1,\n                    cv = 5,\n                    n_jobs = 4)\n# Run the grid\nlgb.fit(X_train_selected, y_train)\n\n# Print the best parameters found\nprint(lgb.best_params_)\nprint(lgb.best_score_)\n\nacc, f1, recall, precision = evaluate_model_performance(lgb, X_val_selected, y_val)\n\nprint(\"Accuraccy:\", acc*100)\nprint(\"F1 score:\", f1)\nprint(\"Recall:\", recall)\nprint(\"precision:\", precision)\nmodel_score.append(['LBGM_classifier with feature selection', acc, f1, recall, precision])\n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:19:56.654623Z","iopub.execute_input":"2021-05-29T13:19:56.654917Z","iopub.status.idle":"2021-05-29T13:20:00.621537Z","shell.execute_reply.started":"2021-05-29T13:19:56.654881Z","shell.execute_reply":"2021-05-29T13:20:00.62041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nmodel =  KNeighborsClassifier()\n\nparameters = { \n    'n_neighbors':[1, 3, 5, 10, 15],\n    'weights':['uniform', 'distance'],\n    'metric':['euclidean', 'manhattan', 'minkowski'] \n}\n\nknn_clf= GridSearchCV(model, parameters, refit=True, verbose=1, cv = 10, n_jobs = 4)\nknn_clf.fit(X_train_selected, y_train)\n\nprint('Best Score: ', knn_clf.best_score_*100, '\\nBest Parameters: ', knn_clf.best_params_)\nacc, f1, recall, precision = evaluate_model_performance(knn_clf, X_val_selected, y_val)\n\nprint(\"Accuraccy:\", acc*100)\nprint(\"F1 score:\", f1)\nprint(\"Recall:\", recall)\nprint(\"precision:\", precision)\nmodel_score.append(['KNN with feature selection', acc, f1, recall, precision])","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:20:00.623278Z","iopub.execute_input":"2021-05-29T13:20:00.623883Z","iopub.status.idle":"2021-05-29T13:20:02.255946Z","shell.execute_reply.started":"2021-05-29T13:20:00.623837Z","shell.execute_reply":"2021-05-29T13:20:02.254536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\n\nmodel =  MLPClassifier()\n\nparameters = { \n    'activation': ['relu', 'logistic', 'tanh'],\n    'hidden_layer_sizes':[20, 50, 100],\n    'solver': ['adam', 'lbfgs'],\n    'batch_size' :[10, 20, 30],\n    'learning_rate_init': [0.0001, 0.001, 0.1],\n    'max_iter': [1000, 2000]\n}\n\nmlp_clf= GridSearchCV(model, parameters, refit=True, verbose=3, cv = 5, n_jobs = 4)\nmlp_clf.fit(X_train_selected, y_train)\n\nprint('Best Score: ', knn_clf.best_score_*100, '\\nBest Parameters: ', knn_clf.best_params_)\nacc, f1, recall, precision = evaluate_model_performance(mlp_clf, X_val_selected, y_val)\n\nprint(\"Accuraccy:\", acc*100)\nprint(\"F1 score:\", f1)\nprint(\"Recall:\", recall)\nprint(\"precision:\", precision)\nmodel_score.append(['MLP with feature selection', acc, f1, recall, precision])","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:20:02.257702Z","iopub.execute_input":"2021-05-29T13:20:02.258151Z","iopub.status.idle":"2021-05-29T13:36:26.528991Z","shell.execute_reply.started":"2021-05-29T13:20:02.258105Z","shell.execute_reply":"2021-05-29T13:36:26.525734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = pd.DataFrame(model_score, columns =['Model', 'Accuracy Score', 'F1 Score', 'Recall score', 'Precision score'])\nscores","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:36:26.531457Z","iopub.execute_input":"2021-05-29T13:36:26.53191Z","iopub.status.idle":"2021-05-29T13:36:26.555292Z","shell.execute_reply.started":"2021-05-29T13:36:26.531865Z","shell.execute_reply":"2021-05-29T13:36:26.553945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the result, we can see that data set with feature selection have improve the accuraccy of the LightGBM model to 80% and the F1 score to 0.739 which is the highest compare to other model. Also, the AUC score is also seen a little improvement. Hence, we can see the faeature selection can improve the model performance and also generalize model. As a result, it is resonable to conclude that the LightGBM model is the most suitable for this problems, however, Gaussian Naive bayes and Logistic Regression should be considered because of its performance and simplicity. ","metadata":{}},{"cell_type":"markdown","source":"## Conclusion","metadata":{}},{"cell_type":"markdown","source":"In conclusion, through this project our team have applied several data analysis and machine learning techiniques to gain useful insight from the data set to answer the research questions. In the exploratory data analysis part, each feature is inspected to have a basic understand about each featue, then we perform analysis of variance (ANOVA) in order to evaluate the impact of patient's age and sex of health indicators and the affect of each health inidcator to the morality rate. We have founf that time, age, ejection fraction and serum creatinine are major factor contribute to the patient's chance of survival. Finally, we have build and analyze different models to predict the survival chance of the patient. The result show that LightGBM and Gausian Naive Bayes shows the best performance whith 80% accuraccy and 0.74 F1 score. In the future, more investigation need to perform to gather more patients's data and increase the features to improve the accuraccy of the model.","metadata":{}}]}