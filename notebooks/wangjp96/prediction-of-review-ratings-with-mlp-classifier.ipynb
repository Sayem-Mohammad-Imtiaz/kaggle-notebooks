{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport nltk\nfrom nltk.corpus import stopwords\nimport sklearn\nimport re\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"def get_data():\n    df = pd.read_csv('../input/GrammarandProductReviews.csv')\n    return df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"81ba22d6ccab20b58f9aaf7e6e574ccec2e3e8a7"},"cell_type":"markdown","source":"First of all,  take a brief look at the structure of the data set."},{"metadata":{"trusted":true,"_uuid":"f38efaffc47202fa3939fcee33b54e93383e8c29","collapsed":true},"cell_type":"code","source":"rawdata = get_data()\nrawdata.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1f1beacd0b8335a5387f682914d343e4ca7408eb"},"cell_type":"markdown","source":"Since our target is to predict the rating of users by their review text, we claim that other columns in the data set are irrevelent to our target and thus excluded.<br>\nIt is also required to remove all rows containing null review text data."},{"metadata":{"trusted":true,"_uuid":"8bdded8d94493a6b952cda2c6b7723d51a27cae6","collapsed":true},"cell_type":"code","source":"useful_list = ['reviews.rating', 'reviews.text']\ndata = rawdata.dropna(subset=['reviews.text'])[useful_list]\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eade8182cf1773db2a38bb5942efa58a0d06bc7d"},"cell_type":"markdown","source":"As we can see, after dropping null data, we get a data set consisting of 71008 sample reviews. "},{"metadata":{"trusted":true,"_uuid":"f7f949cdb058e880f524017a7ef3ac690aacb161","collapsed":true},"cell_type":"code","source":"plt.hist(data['reviews.rating'], range=(1, 6), align='left', color='y', edgecolor='black')\nfor x, y in zip(range(1, 6), data['reviews.rating'].value_counts(sort=False)):\n    plt.text(x, y, str(y), ha='center', va='bottom', fontsize=8)\nplt.title('Rating distribution')\nplt.xlabel('ratings')  \nplt.ylabel('frequency')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3c5529f713825553966c3cfb3412baec9c0f649b"},"cell_type":"markdown","source":"Here are some statistical results on text length."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"21812b2859786a5f98881c054888dced016ad929"},"cell_type":"code","source":"def split_text(text):\n    text = re.sub(\"[+\\.\\!\\/_,$%^*(+\\\"\\']+|[+——！，。？、~@#￥%……&*（）]+\", \"\", text)\n    text = text.lower()\n    return text.split()\n\ndef get_text_len(data):\n    len_dict = {'text_length' : {}}\n    for i in range(len(data)):\n        text = str(data.iloc[i]['reviews.text'])\n        len_dict['text_length'][i] = len(split_text(text))\n    len_df = pd.DataFrame.from_dict(len_dict)\n    return pd.concat([data.reset_index(drop=True), len_df], axis=1)\n\ntext_len_df = get_text_len(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"109d0a6433b6fd710cdf5786fe5efda74926cd7d","collapsed":true},"cell_type":"code","source":"print(\"The average text length is \" + str(text_len_df['text_length'].mean()))\nprint(\"The correlation coefficient between text length and rating is \" + str(text_len_df.corr().iloc[0][1]))\nprint(\"The longest review text consists of \" + str(max(text_len_df['text_length'])) + \" words.\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3628f7756edd1cae18d50f783f8cfdce88dc617e","collapsed":true},"cell_type":"code","source":"len(text_len_df[text_len_df['text_length'] > 200])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3cb709abe72bdc9c59e646d82a780f419d9001d1"},"cell_type":"markdown","source":"Since there are only less than 1000 reviews whose length goes above 200, here we only display the frequency distribution of text length shorter than 200."},{"metadata":{"trusted":true,"_uuid":"353bcae406f89d7bcf56baeb86d0f4e389e1f307","collapsed":true},"cell_type":"code","source":"plt.figure(figsize=(12, 8))\nplt.hist(text_len_df['text_length'], bins=40, range=(0, 200), align='left', color='y', edgecolor='black')\nplt.title('Distribution of text length (<= 200)')\nplt.xlabel('text length')  \nplt.ylabel('frequency')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5d1708e903a83ff375c1af61d94d90d314a9132a"},"cell_type":"markdown","source":" To train our model, we should first divide the samples into training and testing sets. Here we randomly select 70% of the samples as the training set and the rest as the testing set."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8662fd3beace27d8e4fd836cb3768b2eadfc0d7c"},"cell_type":"code","source":"def split_data(data, frac=0.7):\n    train = data.sample(frac=frac)\n    test = data[~data.index.isin(train.index)]\n    return train, test\n\ntrain_data, test_data = split_data(data)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"676d2ca82b380e3c8ee9f61fc061abfe8c0c03d5"},"cell_type":"markdown","source":"Then use word2vec to vectorize text data."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f1ba8b7bceb0250fa027c4de7624d0f58fa91d9b"},"cell_type":"code","source":"def get_sentence_list(data, column):\n    sentence_list = []\n    stop = [re.sub(\"[+\\.\\!\\/_,$%^*(+\\\"\\']+|[+——！，。？、~@#￥%……&*（）]+\", \"\", word) for word in stopwords.words('english')]\n    for i in range(len(data)):\n        text = data.iloc[i][column]\n        word_list = [word for word in split_text(text) if word not in stop]\n        sentence_list.append(word_list)\n    return sentence_list\n\nfrom gensim.models import Word2Vec\n\ndef get_word_vec(data, column, dims=100):\n    s_list = get_sentence_list(data, column)\n    model = Word2Vec(s_list, size=dims, min_count=5)\n    wv = model.wv\n    del model\n    return wv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"991b283af415b8a79c835054233a00351a62a96f","collapsed":true},"cell_type":"code","source":"len(text_len_df[text_len_df['text_length'] > 50]) / len(data)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c5a9cc794b8ed43f74a8f311239b3ac9252e2020"},"cell_type":"markdown","source":"As only less than 25% of the reviews come with more than 50 words, we claim that the model can determine the features of the whole review by reading only the first 50 words. Therefore a variable \"max_sent_len\" is set with the value 50."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f67cd8ffb5b386f59c72e7ba9eb966979ae02bb3"},"cell_type":"code","source":"def vectorize_data(data, column='reviews.text', with_wv=False, return_wv=True, init_wv=None, dims=100, max_sent_len=50):\n    if with_wv:\n        wv = init_wv\n    else:\n        wv = get_word_vec(data, column, dims)\n    df  = {'word_vec' : {}}\n    for i in range(len(data)):\n        text = data.iloc[i][column]\n        word_list = split_text(text)\n        sentence_mat = []\n        j = 0\n        while j < max_sent_len:\n            if j < len(word_list):\n                if word_list[j] in wv:\n                    sentence_mat.append(list(wv[word_list[j]]))\n                else:\n                    sentence_mat.append([0] * dims)\n            else:\n                sentence_mat.append([0] * dims)\n            j += 1\n        df['word_vec'][i] = np.array(sentence_mat).flatten()\n    result = pd.DataFrame.from_dict(df)\n    if return_wv:\n        return pd.concat([data.reset_index(drop=True), result], axis=1), wv\n    else:\n        return pd.concat([data.reset_index(drop=True), result], axis=1)\n\ndef get_matrix(data):\n    result = []\n    for i in range(len(data)):\n        result.append(list(data.iloc[i]['word_vec']))\n    return np.array(result)\n\ndef get_score(data, col_1='reviews.rating', col_2='predicted_rating'):\n    count = 0\n    for i in range(len(data)):\n        if data.iloc[i][col_1] == data.iloc[i][col_2]:\n            count += 1\n    return count / len(data)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"10ed6f00ba1e0be72d18d585d400c4e027a42307"},"cell_type":"markdown","source":"Finally, introduce the MLP neural network classifier in sklearn as the model for training."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"d025afbc3f21658905c29192664527e5a1930e8c"},"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\nmodel = MLPClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a2bc21c84b8837468202f2ccc0529418c085e0a4"},"cell_type":"code","source":"def use_model(train_data, test_data, model, x_col='reviews.text', y_col='reviews.rating'):\n    train, wv = vectorize_data(train_data, x_col)\n    x = get_matrix(train)\n    y = np.array(train[y_col])\n    model.fit(x, y)\n    test= vectorize_data(test_data, with_wv=True, return_wv=False, init_wv=wv)\n    test_x = get_matrix(test)\n    y_predict = model.predict(test_x)\n    y_pre_df = pd.DataFrame(y_predict)\n    y_pre_df.columns = ['predicted_rating']\n    prediction = pd.concat([test_data.reset_index(drop=True), y_pre_df], axis=1)\n    return prediction, get_score(prediction, col_1=y_col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6f607c5f03ecbad3183c7df8bc14f643fea49d5d"},"cell_type":"code","source":"prediction, score = use_model(train_data, test_data, model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f37a5e2edee8f9fb279362773cc37ece8cae57e6","collapsed":true},"cell_type":"code","source":"score","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"da57a81d3badabb4a47ee0e509b5c13a21dbb331"},"cell_type":"markdown","source":"The accuracy of the model comes around 64%. Not a quite satisfying result it seems. Therefore we consider to divide ratings into two classes, so as to convert the problem to a binary classification problem.<br>\nFor this issue, we define rating 4 and 5 as \"positive\" rating (labelled as 1), and rating 1, 2 and 3 as \"negative\" rating (labelled as 0)."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"37f115152f784bcea6fb29014ecb70fcc51f6a23"},"cell_type":"code","source":"def get_binary(data, column='reviews.rating'):\n    df = {'binary_rating' : {}}\n    for i in range(len(data)):\n        if data.iloc[i][column] >= 4:\n            df['binary_rating'][i] = 1\n        elif data.iloc[i][column] <= 3:\n            df['binary_rating'][i] = 0\n    result = pd.DataFrame.from_dict(df)\n    return pd.concat([data.reset_index(drop=True), result], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"117833c46a09dc79d5b86bb887660f2fab673a83","collapsed":true},"cell_type":"code","source":"data_bin = get_binary(data)\ntrain_data_bin, test_data_bin = split_data(data_bin)\npred_bin, score_bin = use_model(train_data_bin, test_data_bin, model, y_col='binary_rating')\nscore_bin","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"387af1e3a12aa4beeda2e022507e89951eb51878"},"cell_type":"markdown","source":"We get an accuracy of approximately 88%.\n\nConsider an alternative approach to characterize text data, by finding words which may represent the user's positive or negative opinions. We can divide these words into \"commendatory\" and \"derogatory\" terms, while filtering out the \"neutral\" ones."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3339c03675e1cf70bd60899bb5ef0f2127c03c3e"},"cell_type":"code","source":"def get_key_words(data, column='reviews.text'):\n    s_list = get_sentence_list(data, column)\n    word_dict = {}\n    for sentence in s_list:\n        for word in sentence:\n            if word not in word_dict.keys():\n                word_dict[word] = 1\n            else:\n                word_dict[word] += 1\n    result = {'words' : {}, 'frequency' : {}}\n    count = 0\n    for word in word_dict.keys():\n        result['words'][count] = word\n        result['frequency'][count] = word_dict[word]\n        count += 1\n    return pd.DataFrame.from_dict(result)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7dbec0de241fe348bc8849c45416c98638bcbfc6"},"cell_type":"markdown","source":"Here we decide to select the top 100 words that appeared most in either \"positive\" or \"negative\" reviews. Then we exclude words that appeared in both of them."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"0059862dcd9fc948929e9427f459b02bc15c2954"},"cell_type":"code","source":"def get_pos_and_neg_words(data):\n    data_pos = data[data['reviews.rating'] >= 4]\n    data_neg = data[data['reviews.rating'] <= 3]\n    pos_words = list(get_key_words(data_pos).nlargest(100, 'frequency')['words'])\n    neg_words = list(get_key_words(data_neg).nlargest(100, 'frequency')['words'])\n    commendatory = [word for word in pos_words if word not in neg_words]\n    derogatory = [word for word in neg_words if word not in pos_words]\n    return commendatory, derogatory","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a19a2e408f5aca5a4d9d28ec15668e4e4d9f7e35"},"cell_type":"code","source":"def encode_text_by_word_frequency(data, column='reviews.text'):\n    commendatory, derogatory = get_pos_and_neg_words(data)\n    result = {'pos_word_frequency' : {}, 'neg_word_frequency' : {}}\n    for i in range(len(data)):\n        text = data.iloc[i][column]\n        word_list = split_text(text)\n        pos_count = 0\n        neg_count = 0\n        for word in word_list:\n            if word in commendatory:\n                pos_count += 1\n            if word in derogatory:\n                neg_count += 1\n        rating = data.iloc[i]['reviews.rating']\n        if rating >= 4:\n            result['pos_word_frequency'][i] = pos_count\n            result['neg_word_frequency'][i] = -neg_count\n        elif rating <= 3:\n            result['pos_word_frequency'][i] = -pos_count\n            result['neg_word_frequency'][i] = neg_count\n    result_df = pd.DataFrame.from_dict(result)\n    return pd.concat([data.reset_index(drop=True), result_df], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d93808524c4264982bbc0ed75ea3feb5831b7c91","collapsed":true},"cell_type":"code","source":"data_alt = encode_text_by_word_frequency(data_bin, column='reviews.text')\ntrain_alt, test_alt = split_data(data_alt)\ntrain_x = np.array(train_alt[['pos_word_frequency', 'neg_word_frequency']])\ntrain_y = np.array(train_alt['binary_rating'])\n\nmodel.fit(train_x, train_y)\n\ntest_x = np.array(test_alt[['pos_word_frequency', 'neg_word_frequency']])\ny_predict = model.predict(test_x)\ny_pred_df = pd.DataFrame(y_predict)\ny_pred_df.columns = ['predicted_rating']\npred_alt = pd.concat([test_alt.reset_index(drop=True), y_pred_df], axis=1)\nscore_alt = get_score(pred_alt, col_1='binary_rating')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8641f7b02bd781d4b49eeccb80b7007a64128cfa","collapsed":true},"cell_type":"code","source":"score_alt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"73717f52a663d1a5b80ffade807a93208d0e6263"},"cell_type":"markdown","source":"Now the accuracy of the prediction rises to 97%."},{"metadata":{"_uuid":"27f093605243bc7abc2325a8848cf88ffb2aa34f"},"cell_type":"markdown","source":"It is also interesting to check out what words are considered by the model as commendatory and what derogatory."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"0459be8ef2482781bf64f152f86759294326aeef"},"cell_type":"code","source":"commendatory, derogatory = get_pos_and_neg_words(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"199a8f0eacdceaddc1e02a949c948890ba68665f","collapsed":true},"cell_type":"code","source":"from wordcloud import WordCloud\nwordcloud = WordCloud(max_font_size=30, background_color='gray').generate(re.sub(\"'\", \"\", str(commendatory)))\nplt.figure(figsize=(8, 8))\nplt.imshow(wordcloud)\nplt.title(\"Commendatory Terms\")\nplt.axis(\"off\")\nplt.show()\n\nwordcloud = WordCloud(max_font_size=30, background_color='gray').generate(re.sub(\"'\", \"\", str(derogatory)))\nplt.figure(figsize=(8, 8))\nplt.imshow(wordcloud)\nplt.title(\"Derogatory Terms\")\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}