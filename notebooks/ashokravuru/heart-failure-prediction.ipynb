{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Supress Warnings\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"heart_df = pd.read_csv('/kaggle/input/heart-failure-clinical-data/heart_failure_clinical_records_dataset.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"heart_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"heart_df.describe().transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col = list(heart_df.columns)\nheart_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(vars=col, diag_kind = 'kde', data = heart_df, hue= 'DEATH_EVENT')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"binary_vars = ['anaemia','diabetes','high_blood_pressure','sex','smoking','DEATH_EVENT']\nplt.figure(figsize=(8,24))\nfor i in enumerate(binary_vars):\n    plt.subplot(3,2,i[0]+1)\n    sns.countplot(heart_df[i[1]],hue='DEATH_EVENT', data = heart_df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cont_vars = ['age','creatinine_phosphokinase','ejection_fraction','platelets','serum_creatinine','serum_sodium','time']\nplt.figure(figsize=(10,24))\nfor i in enumerate(cont_vars):\n    plt.subplot(4,2,i[0]+1)\n    sns.boxplot(y=heart_df[i[1]], data = heart_df)\nplt.show()\n\n# plt.figure(figsize=(8,24))\n# for i in enumerate(cont_vars):\n#     plt.subplot(4,2,i[0]+1)\n#     sns.boxplot(y=i[1],x='DEATH_EVENT', data = heart_df)\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data Preparation for Modeling\n# outlier treatment\ncapping =['creatinine_phosphokinase','ejection_fraction','platelets','serum_creatinine','serum_sodium']\n\nfor i in capping:\n    Q3  = heart_df[i].quantile(0.75)\n    Q1  = heart_df[i].quantile(0.25)\n    IQR = Q3-Q1\n    UW = Q3 + 1.5*IQR\n    LW = Q1 - 1.5*IQR\n    heart_df[i]= heart_df[i].apply(lambda x: x if x<=UW else UW)\n    heart_df[i] = heart_df[i].apply(lambda x: x if x>=LW else LW)\n    \ncont_vars = ['age','creatinine_phosphokinase','ejection_fraction','platelets','serum_creatinine','serum_sodium','time']\nplt.figure(figsize=(10,24))\nfor i in enumerate(cont_vars):\n    plt.subplot(4,2,i[0]+1)\n    sns.boxplot(y=heart_df[i[1]], data = heart_df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,12))\nsns.heatmap(data=heart_df.corr(),cmap=\"YlGnBu\",annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Logistic Regression Model Preparation\n# Train and Test split\nimport sklearn \nfrom sklearn.model_selection import train_test_split\ntrain,test =train_test_split(heart_df, random_state=100, test_size=0.3)\n\ntrain.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating (X_train, y_train) and (X_test, y_test)\n\ny_train = train.pop('DEATH_EVENT')\nX_train = train\n\ny_test = test.pop('DEATH_EVENT')\nX_test = test\n\nX_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Performing Feature Scaling \nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_train[cont_vars] = scaler.fit_transform(X_train[cont_vars])\nX_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Buliding the model\nimport statsmodels.api as sm\n# Constant to X_train\nX_train_sm = sm.add_constant(X_train)\n\n# Building a model\nlgr0 =sm.GLM(y_train,X_train_sm, families = sm.families.Binomial())\nlgr0.fit().summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking VIF for the X_train data set\n\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = pd.DataFrame()\nX = X_train_sm\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# high_blood_pressure feature has P value = 0.97 can be dropped\nX_train_sm.drop('high_blood_pressure', axis=1,inplace =True)\nX_train_sm.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Building a model 1\nlgr1 = sm.GLM(y_train,X_train_sm, families = sm.families.Binomial())\nres1 = lgr1.fit().summary()\nres1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vif = pd.DataFrame()\nX = X_train_sm\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# platelets feature has P value = 0.793 can be dropped\nX_train_sm.drop('platelets', axis=1,inplace =True)\nX_train_sm.head()\n\n# Building a model 2\nlgr2 = sm.GLM(y_train,X_train_sm, families = sm.families.Binomial())\nres2 = lgr2.fit().summary()\nres2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# diabetes feature has P value = 0.794 can be dropped\nX_train_sm.drop('diabetes', axis=1,inplace =True)\nX_train_sm.head()\n\n# Building a model 3\nlgr3 = sm.GLM(y_train,X_train_sm, families = sm.families.Binomial())\nres3 = lgr3.fit().summary()\nres3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# anaemia feature has P value = 0.784 can be dropped\nX_train_sm.drop('anaemia', axis=1,inplace =True)\nX_train_sm.head()\n\n# Building a model 4\nlgr4 = sm.GLM(y_train,X_train_sm, families = sm.families.Binomial())\nres4 = lgr4.fit().summary()\nres4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# smoking feature has P value = 0.614 can be dropped\nX_train_sm.drop('smoking', axis=1,inplace =True)\nX_train_sm.head()\n\n# Building a model 5\nlgr5 = sm.GLM(y_train,X_train_sm, families = sm.families.Binomial())\nres5 = lgr5.fit().summary()\nres5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# serum_sodium feature has P value = 0.49 can be dropped\nX_train_sm.drop('serum_sodium', axis=1,inplace =True)\nX_train_sm.head()\n\n# Building a model 6\nlgr6 = sm.GLM(y_train,X_train_sm, families = sm.families.Binomial())\nres6 = lgr6.fit().summary()\nres6","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creatinine_phosphokinase feature has P value = 0.18 can be dropped\nX_train_sm.drop('creatinine_phosphokinase', axis=1,inplace =True)\nX_train_sm.head()\n\n# Building a model 7\nlgr7 = sm.GLM(y_train,X_train_sm, families = sm.families.Binomial())\nres7 = lgr7.fit().summary()\nres7","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sex feature has P value = 0.172 can be dropped\nX_train_sm.drop('sex', axis=1,inplace =True)\nX_train_sm.head()\n\n# Building a model 8\nlgr8 = sm.GLM(y_train,X_train_sm, families = sm.families.Binomial())\nres8 = lgr8.fit()\nres8.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vif = pd.DataFrame()\nX = X_train_sm\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred = res8.predict(X_train_sm)\ntrain_pred = pd.DataFrame(y_train_pred)\ntrain_pred.columns = [\"train_prob\"]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"y_test.reshape(-1,1)\ny_test","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pred['DEATH_EVENT']= y_train.values.reshape(-1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pred.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# columns with different probability cutoffs \nnumbers = [x for x in range(100)]\nfor i in numbers:\n    k=train_pred.train_prob*100\n    train_pred[i]= k.map(lambda x: 1 if x > i else 0)\ntrain_pred.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# calculate accuracy sensitivity and specificity for various Score (probability*100) cutoffs.\n# creating a cutoff dataframe \ncutoff_df = pd.DataFrame( columns = ['Score','accuracy','sensi','speci','Precision','F1_score'])\n\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix\n\n# Actual/Predicted     N       P\n        # N          TN        FP\n        # P          FN        TP\n\n# TP = confusion[1,1] # true positive \n# TN = confusion[0,0] # true negatives\n# FP = confusion[0,1] # false positives\n# FN = confusion[1,0] # false negatives\n\nnum = [x for x in range(100)]\nfor i in num:\n    cm = metrics.confusion_matrix(train_pred.DEATH_EVENT, train_pred[i] )\n    total=sum(sum(cm))\n    accuracy = (cm[0,0]+cm[1,1])/total\n    \n    speci = cm[0,0]/(cm[0,0]+cm[0,1])\n    sensi = cm[1,1]/(cm[1,0]+cm[1,1])\n    Precision = cm[1,1]/(cm[1,1]+cm[0,1])\n    F1_score = 2*Precision*  sensi/(Precision+sensi)\n    Score = i\n    cutoff_df.loc[i] =[Score,accuracy,sensi,speci,Precision,F1_score]\ncutoff_df.iloc[20:45]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Plot accuracy, sensitivity and specificity for various probabilities\nplt.figure(figsize=(12,8))\ncutoff_df.plot.line(x='Score', y=['accuracy','sensi','speci'])\nplt.show()\n\nplt.figure(figsize=(12,8))\ncutoff_df.plot.line(x='Score', y=['Precision','F1_score'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# with cutoff at 39 , sensivity: 83 Accuracy : 0.81 , specificity : 0.81 and Precision 0.66, F1 = 73\n# Model evaluation using test dataset\n\ncol = list(X_train_sm.columns)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Performing Feature Scaling for Test \nX_test[cont_vars] = scaler.transform(X_test[cont_vars])\nX_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# adding constant to X_test\nX_test_sm = sm.add_constant(X_test)\n\n# Model Prediction res8\ntest_prob = res8.predict(X_test_sm[col])\n\ntest_prob","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_df = pd.DataFrame(test_prob)\nfinal_df.columns =['test_prob']\nfinal_df['predicted_test'] = final_df['test_prob'].apply(lambda x: 1 if x> 0.39 else 0)\nfinal_df['DEATH_EVENT']= y_test.values.reshape(-1)\nfinal_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confusion matrix for test\nct = metrics.confusion_matrix(final_df['DEATH_EVENT'],final_df['predicted_test'])\nTP = ct[1,1] # true positive \nTN = ct[0,0] # true negatives\nFP = ct[0,1] # false positives\nFN = ct[1,0] # false negative\n\nsen = round(TP/(TP+FN),2)\nspec = round(TN/(TN+FP),2)\naccu = round((TP+TN)/sum(sum(ct)),2)\npre = round(TP/(TP+FP),2)\nF1 = round(2*pre*sen/(pre+sen),2)\nprint('Model Evaluation Parameters: \\n')\nprint('Sensitivity_Test: ',sen)\nprint('Specificity_Test: ',spec)\nprint('Accuracy_Test: ',accu)\nprint('Precision_Test: ',pre)\nprint('F1_Score: ',F1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}