{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read data","metadata":{}},{"cell_type":"code","source":"row_data = pd.read_csv('/kaggle/input/star-type-classification/Stars.csv')\nrow_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploring data","metadata":{}},{"cell_type":"code","source":"# Checking for duplicate lines\n\nrow_data.duplicated().unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking for empty cells in data\n\nrow_data.isnull().sum() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Ð¡lass balance check\n\nplt.figure(figsize=(20,5))\nsns.countplot(x = row_data['Type'])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Numerical features exploration\n\nnumerical_features = ['Temperature', 'L', 'R', 'A_M']\n\nfor column_name in numerical_features:\n    plt.figure(figsize=(8,6))\n    sns.distplot(x = row_data[column_name])\n    plt.xlabel(column_name)\n    plt.show()\n    \n    plt.figure(figsize=(9,3))\n    sns.boxplot(x = row_data[column_name])\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The boxplots shows some outliers from Temperature, relative Luminosity (L) and relative Radius (R).\n# Let's Explore them in more detail","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outliers_Temperature = row_data.loc[row_data['Temperature'] > 33000]\nprint('Star Type with Temperature > 33000:', ', '.join([str(i) for i in outliers_Temperature['Type'].unique()]))\nprint()\nprint(outliers_Temperature)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outliers_L = row_data.loc[row_data['L'] > 500000]\nprint('Star Type with L > 500000:', ', '.join([str(i) for i in outliers_L['Type'].unique()]))\nprint()\nprint(outliers_L)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outliers_R = row_data.loc[row_data['R'] > 500]\nprint('Star Type with R > 500:', ', '.join([str(i) for i in outliers_R['Type'].unique()]))\nprint()\nprint(outliers_R)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# After researching the data and reading sites about stars and space,\n# I came to the conclusion that these data are not outliers. You cannot get rid of them.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Categorical features exploration\n\ncategorical_features = ['Color', 'Spectral_Class']\n\nfor column_name in categorical_features:\n    plt.figure(figsize=(20,5))\n    sns.countplot(x = row_data[column_name])\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Encoding categorical features\n\nle = LabelEncoder()\n\nfor column_name in categorical_features:\n    row_data[column_name] = le.fit_transform(row_data[column_name])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Features correlation exploration\n\n# Pearson correlation\nplt.figure(figsize=(10,8))\ncorr = row_data.corr(method='pearson')\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)] = True\nsns.heatmap(corr, annot=True, fmt= '.2f', cmap='RdBu', mask=mask)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Spearman correlation\nplt.figure(figsize=(10,8))\ncorr = row_data.corr(method='spearman')\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)] = True\nsns.heatmap(corr, annot=True, fmt= '.2f', cmap='RdBu', mask=mask)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The data show a strong correlation between L and R; L, R, Temperature and A_M; Temperature and Color.\n\n# The correlation between Temperature and Color is explained by physics - one depends on the other.\n\n# The correlation between L and R (and partly Temperature) is explained by the fact that L is calculated from R and Temperature.\n\n# The correlation between L, R, Temperature and A_M is explained by the fact that A_M is calculated from L,\n# which, as I wrote above, is calculated from R and Temperature.\n\n# From all of the above, it follows that in the work you can ignore such parameters as L, R and Temperature.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preparing data","metadata":{}},{"cell_type":"code","source":"# Split data in to train and test sets\n\ndata_X = row_data.iloc[:, 3:6]  # data without Temperature, L, R and target variable\ndata_y = row_data['Type']  # target variable\n\nX_train, X_test, y_train, y_test = train_test_split(data_X, data_y, test_size=0.33, random_state=42, stratify=data_y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scaling data\n\nscaler = StandardScaler()\n\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Trying out different models using kFold cross-validation","metadata":{}},{"cell_type":"code","source":"models = []\n\nmodels.append(('KNN',KNeighborsClassifier(n_jobs=-1)))\nmodels.append(('LR',LogisticRegression(random_state=42,n_jobs=-1)))\nmodels.append(('DT',DecisionTreeClassifier(random_state=42)))\nmodels.append(('Bag_DT',BaggingClassifier(DecisionTreeClassifier(random_state=42), random_state=42, n_jobs=-1)))\nmodels.append(('RF',RandomForestClassifier(random_state=42, n_jobs=-1)))\nmodels.append(('GBC',GradientBoostingClassifier(random_state=42)))\n\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\n\nfor name, model in models:\n    scores = cross_val_score(model, X_train, y_train, scoring='f1_weighted', cv=kf, n_jobs=-1)\n    accuracy = scores.mean()\n    std = scores.std()\n    print(f\"{name} : Mean F1 {round(accuracy, 3)} STD:({round(std, 3)})\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The best results were shown by DecisionTreeClassifier and BaggingClassifier\n# Let's check the DecisionTreeClassifier on the test set","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training DecisionTreeClassifier\n\ndt = DecisionTreeClassifier(random_state=42)\ndt.fit(X_train, y_train)\n\n# Getting predicted values\ny_predicted = dt.predict(X_test)\n\nprint('Accuracy of DecisionTreeClassifier is', dt.score(X_test, y_test)*100, '%')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a confusion matrix\n\nconf_matix = pd.crosstab(y_test, y_predicted)\n\nsns.heatmap(conf_matix, cmap='Greys', annot=True, \n            linecolor='black', square='True',\n            linewidths=0.2)\nplt.ylabel(\"Real type of stars\")\nplt.xlabel(\"Predicted type of stars\") \nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Too good to be true","metadata":{}}]}