{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Bu çalışmada iş ilanlarının gerçek mi sahte mi olduğunu 3 farklı algoritma üzerinden test etmeye çalışıcaz. Kullanıcağımız ML algoritmaları sırasıyla şu şekildedir. \n\n1) Logistic Regression \n2) Naive Bayes\n3) KNN "},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Kullanılacak kütüphaneler.\nimport pandas as pd\nimport re\nimport nltk \nfrom nltk.corpus import stopwords\nimport nltk as nlp\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom nltk.corpus import wordnet\nfrom nltk.stem import WordNetLemmatizer\nimport matplotlib.pyplot as plt\nimport nltk as nlp\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# csv formatındaki datamızı df değişkenine atıyoruz\ndf = pd.read_csv(\"/kaggle/input/real-or-fake-fake-jobposting-prediction/fake_job_postings.csv\",encoding = \"latin1\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()\nprint(df.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del df[\"salary_range\"]\ndel df[\"job_id\"]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# datadaki metinleri tek bir text verisi haline getiriyoruz.\ndf.fillna(\" \",inplace = True)\ndf['text']=df['title']+\" \"+df['location']+\" \"+df['department']+\" \"+df['company_profile']+\" \"+df['description']+\" \"+df['requirements']+\" \"+df['benefits']+\" \"+df['employment_type']+\" \" +df['required_education']+\" \"+df['industry']+\" \"+df['function'] \ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# datada gereksiz bilgileri siliyoruz.\ndel df['title']\ndel df['location']\ndel df['department']\ndel df['company_profile']\ndel df['description']\ndel df['requirements']\ndel df['benefits']\ndel df['employment_type']\ndel df['required_experience']\ndel df['required_education']\ndel df['industry']\ndel df['function']\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Datamızı düzenli hale getirdik, şimdi onu bir ML algoritmasına uygun hale getirmemiz gerekiyor. Sırasıyla uygulayacağımız adımlar:\n\n1) Cleaning Data : Bu adımda textde bulunan ifadeleri algoritmamızın anlayağı bir hale getireceğiz. Mesela, \"!!merHAba\" gibi bir ifadeyi \"merhaba\" şekline çevireceğiz.\n\n2) Bag of Words : Texti ML uygulayacak hale getireceğiz.\n\n3) Text Classification: Bu adımda ise ML algoritmaları ile varmak istediğimiz sonuçları ediniyoruz. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cleaning Data:\ntext_list = []\nfor text in df.text:\n    text= re.sub(\"[^a-zA-Z]\",\" \",text) #a-z A-Z aralığı dışındaki tüm ifadeleri boşluk ile değiştiriyoruz\n    text = text.lower()   # buyuk harftan kucuk harfe çeviriyoruz\n    text = nltk.word_tokenize(text) # textdeki her bir kelimeyi ayırıyoruz\n    lemma = nlp.WordNetLemmatizer() \n    text = [lemma.lemmatize(word) for word in text] # for döngüsü ile textin içindeki her kelimeyi köklerine ayırıyoruz\n    text = \" \".join(text)  # tek tek ayırdığımız kelimeleri aralarına boşluk koyarak tekrar birleştiriyoruz\n    text_list.append(text) # oluşturduğumuz tüm textleri bir listenin içine topluyoruz  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bag of Words:\n \nmax_features = 150    # textde en çok kullandılan 150 kelime.\n# stop_words ile ingilizce harici kelimeleri siliyoruz.\ncount_vectorizer = CountVectorizer(max_features=max_features, stop_words = \"english\") \n\n# metodumuzu textler üzerinde fit ediyoruz ve sonucu bir liste haline getiriyoruz.   \nsparce_matrix = count_vectorizer.fit_transform(text_list).toarray() \n\nprint(\"en sık kullanılan {} kelimeler :{}\".format(max_features,count_vectorizer.get_feature_names()))\nx = sparce_matrix\ny = df.iloc[:,3].values ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# datamızı train ve test olarak 0.1 oranıyla ayırdık.\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.1,random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Logistic Regression:\nlr = LogisticRegression()\nlr.fit(x_train,y_train)\nprint(\"logreg accuracy {}\".format(lr.score(x_test,y_test)))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Naive Bayes\nnb = GaussianNB()\nnb.fit(x_train,y_train)\n\n# prediction \ny_pred = nb.predict(x_test)\n\nprint(\"nb accuracy:\",nb.score(y_pred.reshape(-1,1),y_test))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# KNN \nknn = KNeighborsClassifier(n_neighbors = 3) # n_neighbors = k\nknn.fit(x_train,y_train)\nprediction = knn.predict(x_test)\nprint(\" {} knn score: {} \".format(3,knn.score(x_test,y_test)))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_list = []\nfor each in range(1,15):\n    knn2 = KNeighborsClassifier(n_neighbors = each)\n    knn2.fit(x_train,y_train)\n    score_list.append(knn2.score(x_test,y_test))\n    \nplt.plot(range(1,15),score_list)\nplt.xlabel(\"k values\")\nplt.ylabel(\"accuracy\")\nplt.show()\n\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}