{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport plotly.express as px\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n \nfrom sklearn.model_selection import train_test_split \nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/top50spotify2019/top50.csv', encoding='latin-1')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.drop(['Unnamed: 0', 'Track.Name'], axis = 1, inplace = True) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Popularity'] = pd.qcut(data['Popularity'], q=2, labels=[0, 1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The hist() function in pyplot module of matplotlib library is used to plot a histogram. Parameters: This method accept the following parameters that are described below: x : This parameter are the sequence of data**","metadata":{}},{"cell_type":"code","source":"def onehot_encode(df, column, prefix):\n    df = df.copy()\n    dummies = pd.get_dummies(df[column], prefix=prefix)\n    df = pd.concat([df, dummies], axis=1)\n    df = df.drop(column, axis=1)\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndata.hist(bins=100,figsize=(20, 10))\nplt.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=onehot_encode(data,'Artist.Name','art_n')\ndata=onehot_encode(data,'Genre','gen')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**A heatmap contains values representing various shades of the same colour for each value to be plotted. Usually the darker shades of the chart represent higher values than the lighter shade. For a very different value a completely different colour can also be used.**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(27, 16))\nsns.heatmap(data, annot=True, fmt='.0f', cmap=\"YlGnBu\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = data.loc[:, 'Popularity']\nX = data.drop('Popularity', axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = StandardScaler()\n\nX = scaler.fit_transform(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"log_model = LogisticRegression()\nlin_model = LinearRegression()\nknn_model = KNeighborsClassifier()\ndec_model = DecisionTreeClassifier()\nmlp_model = MLPClassifier()\nsvm_model = SVC()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"log_model.fit(X_train, y_train)\nlin_model.fit(X_train, y_train)\nknn_model.fit(X_train, y_train)\ndec_model.fit(X_train, y_train)\nmlp_model.fit(X_train, y_train)\nsvm_model.fit(X_train, y_train)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"log_acc = log_model.score(X_test, y_test)\nlin_acc = lin_model.score(X_test, y_test)\nknn_acc = knn_model.score(X_test, y_test)\ndec_acc = dec_model.score(X_test, y_test)\nmlp_acc = mlp_model.score(X_test, y_test)\nsvm_acc = svm_model.score(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Logistic Regression Accuracy:\", log_acc)\nprint(\"Leniar Regression Accuracy:\", lin_acc)\nprint(\"K-Nearest-Neighbors Accuracy:\", knn_acc)\nprint(\"Decision Tree Accuracy:\", dec_acc)\nprint(\"Neural Network Accuracy:\", mlp_acc)\nprint(\"Support Vector Machine Accuracy:\", svm_acc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.bar(\n    x=[\"Logistic Regression\",\"K-Nearest-Neighbors\", \"Decision Tree\", \"Neural Network\", \"Support Vector Machine\"],\n    y=[log_acc, knn_acc, dec_acc, mlp_acc, svm_acc],\n    color=[\"Logistic Regression\",\"K-Nearest-Neighbors\", \"Decision Tree\", \"Neural Network\", \"Support Vector Machine\"],\n    labels={'x': \"Model\", 'y': \"Accuracy\"},\n    title=\"Model Accuracy Comparison\"\n)\n\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fig, ax = plt.subplots(figsize=(14, 14))\n# plot_partial_dependence(svm_model,features=[0,1,2,3,4,5,6,7,8] ,X=X, ax=ax,feature_names=data.columns,grid_resolution=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fig, ax = plt.subplots(figsize=(14, 14))\n# plot_partial_dependence(log_model,features=[0,1,2,3,4,5,6,7,8] ,X=X, ax=ax,feature_names=data.columns,grid_resolution=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}