{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Introduction\n\nhai kagglers, today i'm going to make a predictions on Mobile phone pricing dataset using random forest, XGboost and SVM algorithm, let's see which one perform the best.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Import Modules","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Quick look\n\nIn this dataset, we got two csv files, train data and test data. both had 21 column each.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/mobile-price-classification/train.csv')\ntest = pd.read_csv('../input/mobile-price-classification/test.csv')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our target column is price range from train data. this column has 4 unique value, 0 for low cost mobile phone, 1 for medium cost mobile phone. 2 for high cost and 3 for very high cost. Since the data disributed evenly, we are going to use it as it is,","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# 0 for low cost\n# 1 for medium cost\n# 2 for high cost\n# 3 for very high cost\n\ntrain.price_range.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## EDA\n# Distribution\n\ntrain.hist(bins=30, figsize=(15, 15))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we have a distribution plot for every columns, a few column is evenly distributed like dual sim, bluetooth, price range, wifi, and touch screen. The others distributed randomly.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Most important feature\n\nCorr = train.corr()\n\nIF = Corr['price_range'].sort_values(ascending=False).head(10).to_frame()\nIF.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f = plt.figure(figsize=(15,12))\n\n# corr with ram\nax = f.add_subplot(221)\nax = sns.scatterplot(x=\"price_range\", y=\"ram\", color='b', data=train)\nax.set_title('Corr with RAM')\n\n# corr with Battery\nax = f.add_subplot(222)\nax = sns.scatterplot(x=\"price_range\", y=\"battery_power\", color='c', data=train)\nax.set_title('Corr with battery')\n\n# corr with px_width\nax = f.add_subplot(223)\nax = sns.scatterplot(x=\"price_range\", y=\"px_width\", color='r', data=train)\nax.set_title('Corr with px width')\n\n# corr with height\nax = f.add_subplot(224)\nax = sns.scatterplot(x=\"price_range\", y=\"px_height\", color='g', data=train)\nax.set_title('Corr with px height')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The most important feature is ram, battery power, width and height. Ram is strongly correlated with price range. Herewe can conclude that the main factor of the price is the ram itself. The other are not to strong and seem almost distributed evenly.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Modeling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split Data\n\nX = train.drop('price_range', axis=1)\ny = train['price_range']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('X_train : ' + str(X_train.shape))\nprint('X_test : ' + str(X_test.shape))\nprint('y_train : ' + str(y_train.shape))\nprint('y_test : ' + str(y_test.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nclassifier = RandomForestClassifier(n_estimators = 200, criterion = 'entropy', random_state = 12)\nclassifier.fit(X_train, y_train)\n\n# predict\ny_pred = classifier.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\nprint(accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### XGBoost","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\n\n# Instantiate the XGBClassifier: xg_cl\nxg_cl = xgb.XGBClassifier(objective='multi:softmax', num_class=3, n_estimators=150, seed=123)\nxg_cl.fit(X_train, y_train)\npreds = xg_cl.predict(X_test)\n\n# Compute the accuracy: accuracy\naccuracy = float(np.sum(preds==y_test))/y_test.shape[0]\nprint(\"accuracy: %f\" % (accuracy))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### SVM","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV\n\nsvm = SVC()\n\nparameters = {'C':[0.1, 1, 10], 'gamma':[0.00001, 0.0001, 0.001, 0.01, 0.1]}\nmodel = GridSearchCV(svm, param_grid=parameters)\nmodel.fit(X_train, y_train)\n\n# Best parameters\nprint(\"Best CV params\", model.best_params_)\n\n# accuracy\nprint(\"Test accuracy :\", model.score(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we found that SVM perfrom the better than the other algorithm. We are going to use this model to predict the data on train and test data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## Assign the value\n\npredicted_value = model.predict(X_test)\nactual_value = y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## COmparison distribution in Train data\n\nsns.distplot(actual_value, hist=False, label=\"Actual Values\")\nsns.distplot(predicted_value, hist=False, label=\"Predicted Values\")\nplt.title('Distribution Comaprison with SVM')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predict\n\nLet's predict the price range in test data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X2 = test.drop('id', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Perform predictions\n\npredicted_test_value = model.predict(X2)\npd.value_counts(predicted_test_value)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we have value count on every unique value on predicted test price range. This is almost evenly distributed, but the phone with a very high cost is dominating over the others with 26.5 %. and the lowest is medium cost with 23.2 %.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Here is how distribution look like in test data price range\n\nsns.distplot(predicted_value, hist=False, label=\"Predicted Values\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## End\n\nThat is all for this kernel today, hope you like it.\nThank you.\nHave a good day.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}