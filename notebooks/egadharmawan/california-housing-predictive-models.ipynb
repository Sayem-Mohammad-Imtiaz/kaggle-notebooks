{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Introduction\n\nHai kaggler, in this kernel i'm going to perform prediction on california housing Dataset. I'm using Linear Regression, Random Forest Regressor and Decision Tree Regressor. Let's get started.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Import Modules","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.special import inv_boxcox\nfrom scipy.stats import boxcox","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Quick Look\n\nTake a quick look at the dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/california-housing-prices/housing.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fill Missing Value\n\nWe got a few missing value on total_rooms columns, let's fill the missing value.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.fillna(method='ffill')\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.ocean_proximity.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Engineering\n\nPerforming feature engineering to change categorical value to numerical value","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.get_dummies(df)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Correlation map to see how features are correlated with SalePrice\nCor_heat = df.corr()\nplt.figure(figsize=(16,16))\nsns.heatmap(Cor_heat, cmap = \"RdBu_r\", vmax=0.9, square=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The visualization above is correlation between every columns, it's interesting how total_rooms, total_bedrooms, household, and population are strongly correlated. The target column is median house value, let's see what most important feature we have.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## Lets see what most important features we have\n\nIF = Cor_heat['median_house_value'].sort_values(ascending=False).head(10).to_frame()\nIF.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"median house value is strongly correlated with median income, let's see what most important feature for median income.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"IF = Cor_heat['median_income'].sort_values(ascending=False).head(10).to_frame()\nIF.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Transformation\n\nBefore performing prediction, we need to make sure the target dataset is not skewed.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Basic Distribution\n\nprint('Skew Value : ' + str(df.median_house_value.skew()))\nsns.distplot(df.median_house_value)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"0.97 is pretty bad, let's see if we can find a better skew value.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"f = plt.figure(figsize=(16,16))\n\n# log 1 Transform\nax = f.add_subplot(221)\nL1p = np.log1p(df.median_house_value)\nsns.distplot(L1p,color='b',ax=ax)\nax.set_title('skew value Log 1 transform: ' + str(np.log1p(df.median_house_value).skew()))\n\n# Square Log Transform\nax = f.add_subplot(222)\nSRT = np.sqrt(df.median_house_value)\nsns.distplot(SRT,color='c',ax=ax)\nax.set_title('Skew Value Square Transform: ' + str(np.sqrt(df.median_house_value).skew()))\n\n# Log Transform\nax = f.add_subplot(223)\nLT = np.log(df.median_house_value)\nsns.distplot(LT, color='r',ax=ax)\nax.set_title('Skew value Log Transform: ' + str(np.log(df.median_house_value).skew()))\n\n# Box Cox Transform\nax = f.add_subplot(224)\nBCT,fitted_lambda = boxcox(df.median_house_value,lmbda=None)\nsns.distplot(BCT,color='g',ax=ax)\nax.set_title('Skew Value Box Cox Transform: ' + str(pd.Series(BCT).skew()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have box cox transformation as the best transformation with skew value near to 0, but to make sure let's perform prediction on all of them","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Spliting Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Train = df.drop('median_house_value', axis=1)\nTest = df.median_house_value","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Assign the distribution of Sale Price\n\nfeature_SP = {'Log Transform': LT,\n              'Square Root Transform': SRT,\n              'Box-Cox Transform':BCT,\n              'Log 1 Transform': L1p}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Modeling\n\nI'm using Linear Regression, Decision Tree Regressor, and Random Forest Regressor.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Linear Regression\n\nfrom sklearn.linear_model import LinearRegression\nLR = LinearRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Random Forest Regressor\n\nfrom sklearn.ensemble import RandomForestRegressor\nRFR = RandomForestRegressor(n_estimators=25,max_depth=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Decision Tree Regressor\n\nfrom sklearn.tree import DecisionTreeRegressor\nDTR =DecisionTreeRegressor(random_state=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"alg = [LR, RFR, DTR]\npredicted_value = {}\n\nfor y in alg:\n    print(str(y.__class__.__name__) + ' results')\n    for key, value in feature_SP.items():\n        Test = value\n        X_train, X_test, y_train, y_test = train_test_split(Train, Test, test_size=0.33, random_state=42)\n        y.fit(X_train, y_train)\n        predicted_value[str(y.__class__.__name__) + ' with ' + str(key)] = y.predict(X_test)\n        score = y.score(X_test, y_test)\n        print('Accuracy with ' + str(key) + ' transformation : ' + str(np.mean(score)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_value","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## End\n\nThe best result is when we using Decision Tree Regressor and applying Log Transformation on the target data.\nthat is all for this kernel, thank you.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}