{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Project by Elodie NGANTCHOU KEMADJOU\n\n###  For the course project, i will pick any dataset of my choice and apply the concepts learned in this course to train deep learning models end-to-end with PyTorch, experimenting with different hyperparameters & metrics.\n\n### For this project, i use Convolutional Neural Network to Classify Birds","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"project_name = \"200-bird-species\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install jovian --upgrade --quiet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import jovian","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### *Librairies*","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### First thing we will want to do is import a bunch of handy libraries:","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nfrom random import randrange\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nimport torchvision\nimport torchvision.models as models\nfrom torchvision.datasets.utils import download_url\nfrom torchvision.datasets import ImageFolder\nimport torchvision.transforms as tt\nfrom torchvision.utils import make_grid\nimport matplotlib.pyplot as plt\n%matplotlib inline\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data set of 200 bird species. 27503 training images, 1000 test images(5 per species) and 1000 validation images(5 per species.\nAll images are 224 X 224 X 3 color images in jpg format. Also includes a \"consolidated\" image set that combines the training, test and validation images into a single data set. This is useful for users that want to create their own training, test and validation sets.\nImages for each species are contained in a separate sub directory. Convenient if you use Keras flow from directory as a means to input the data.\n\n[https://www.kaggle.com/gpiosenka/100-bird-species](http://)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import dataset\n\ndata_dir = '../input/100-bird-species'\nprint('Folders :', os.listdir(data_dir))\nclasses = os.listdir(data_dir + \"/train\")\nprint(\"num species:\", num_classes)\nprint({cls: len(os.listdir(data_dir + f\"/train/{cls}/\")) for cls in sorted(classes)})\nprint('classes :', classes)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Before we go further, we should talk a bit about the three “kinds” of data we will be interacting with; training, test, and validation.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = tt.Compose(\n    [\n        tt.ToTensor(), \n    ]\n)\n\n# Create datasets\ntrain_ds = ImageFolder(data_dir+'/train', transform)\nvalid_ds = ImageFolder(data_dir+'/test', transform)\n\n# set the batch size\nbatch_size = 64\n\ntrain_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=3, pin_memory=True)\nvalid_dl = DataLoader(valid_ds, batch_size*2, num_workers=2, pin_memory=True)\n\nclasses = valid_ds.classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_example(data):\n    [img, label] = data\n    print(classes[label])\n    plt.imshow(img.permute(1, 2, 0))\n    \nimage_number = randrange(20000)\nshow_example(train_ds[image_number])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_batch(dl):\n    for images, labels in dl:\n        fig, ax = plt.subplots(figsize=(12, 12))\n        ax.set_xticks([]); ax.set_yticks([])\n        ax.imshow(make_grid(images[:64], nrow=8).permute(1, 2, 0))\n        break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_batch(train_dl)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_batch(valid_dl)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, we will add a few convenience methods to move our data to a specific device. A CPU is sufficient for certain ML problems, but we will use a GPU to train our model, as it is a bit better equipped for the type of matrix operations our model will be doing during training and will result in faster epochs. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# pick a device\ndef get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)\n    \n\ndevice = get_default_device()\ndevice","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n\nclass ImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['train_loss'], result['val_loss'], result['val_acc']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Hidden Layers (Making the Network)\n\nWe use the ImageClassificationBase that we covered earlier, but we tell our network to use a pre-trained ResNet — torchvision.models.resnet34. We add a new last layer, which takes the inputs from the previous layer of the network and outputs the number of species we are classifying, as previously stated. After we move our model to the GPU","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class BirdResnet(ImageClassificationBase):\n    def __init__(self):\n        super().__init__()\n        # Use a pretrained model\n        self.network = models.resnet34(pretrained=True)\n        # Replace last layer\n        num_ftrs = self.network.fc.in_features\n        self.network.fc = nn.Linear(num_ftrs, num_classes)\n    \n    def forward(self, xb):\n        return torch.sigmoid(self.network(xb))\n    \n    def freeze(self):\n        # To freeze the residual layers\n        for param in self.network.parameters():\n            param.require_grad = False\n        for param in self.network.fc.parameters():\n            param.require_grad = True\n    \n    def unfreeze(self):\n        # Unfreeze all layers\n        for param in self.network.parameters():\n            param.require_grad = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = to_device(BirdResnet(), device)\nmodel","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.cuda.empty_cache()\ntrain_dl = DeviceDataLoader(train_dl, device)\nvalid_dl = DeviceDataLoader(valid_dl, device)\nto_device(model, device);\n\n# print outputs for a single batch\nfor images, labels in train_dl:\n    print('images.shape:', images.shape)\n    out = model(images)\n    print('out.shape:', out.shape)\n    print('all outputs:', out)\n    break\n    \n# show the highest probability values and their index/classes\nvalues, indices = out.max(0)\nprint(\"max values\", values)\nprint(\"max indices\", index)\nprint(\"guesses\", [classes[index] for index in indices])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create the test dataset\ntest_dataset = ImageFolder(data_dir+'/test', tt.ToTensor())\n\n#methods to pick a random image and make a prediciton\ndef predict_image(img, model):\n    # Convert to a batch of 1\n    xb = to_device(img.unsqueeze(0), device)\n    # Get predictions from model\n    yb = model(xb)\n    # Pick index with highest probability\n    _, preds  = torch.max(yb, dim=1)\n    # Retrieve the class label\n    return test_dataset.classes[preds[0].item()]\n\ndef get_random_test_image(dataset):\n    rand_num = randrange(len(dataset))\n    return dataset[rand_num]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let’s see how well the untrained model does identifying a few birds… We call .permute() in here because the plotting library we are using (matplotlib) expects the dimensions of the image tensor to be in a different order.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"img, label = get_random_test_image(dataset=test_dataset)\nplt.imshow(img.permute(1, 2, 0))\nprint('Label:', test_dataset.classes[label], ', Predicted:', predict_image(img, model))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img, label = get_random_test_image(dataset=test_dataset)\nplt.imshow(img.permute(1, 2, 0))\nprint('Label:', test_dataset.classes[label], ', Predicted:', predict_image(img, model))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img, label = get_random_test_image(dataset=test_dataset)\nplt.imshow(img.permute(1, 2, 0))\nprint('Label:', test_dataset.classes[label], ', Predicted:', predict_image(img, model))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        model.train()\n        train_losses = []\n        for batch in train_loader:\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = [evaluate(model, valid_dl)]\nhistory","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs = 10\nopt_func = torch.optim.Adam\nlr = 0.001","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# freeze the model to only train the last layer\nmodel.freeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = fit(num_epochs, lr, model, train_dl, valid_dl, opt_func)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_loss = [hist['val_loss'] for hist in history]\ntrain_loss = [hist['train_loss'] for hist in history]\nval_acc = [hist['val_acc'] for hist in history]\nplt.plot(val_loss, label=\"Validation Loss\")\nplt.plot(train_loss, label=\"Training Loss\")\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\nplt.show()\n\nplt.plot()\nplt.plot(val_acc)\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.axis([0, 10, 0, 1])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img, label = get_random_test_image(dataset=test_dataset)\nplt.imshow(img.permute(1, 2, 0))\nprint('Label:', test_dataset.classes[label], ', Predicted:', predict_image(img, model))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img, label = get_random_test_image(dataset=test_dataset)\nplt.imshow(img.permute(1, 2, 0))\nprint('Label:', test_dataset.classes[label], ', Predicted:', predict_image(img, model))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img, label = get_random_test_image(dataset=test_dataset)\nplt.imshow(img.permute(1, 2, 0))\nprint('Label:', test_dataset.classes[label], ', Predicted:', predict_image(img, model))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img, label = get_random_test_image(dataset=test_dataset)\nplt.imshow(img.permute(1, 2, 0))\nprint('Label:', test_dataset.classes[label], ', Predicted:', predict_image(img, model))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img, label = get_random_test_image(dataset=test_dataset)\nplt.imshow(img.permute(1, 2, 0))\nprint('Label:', test_dataset.classes[label], ', Predicted:', predict_image(img, model))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_loader = DataLoader(test_dataset, batch_size*2, num_workers=4, pin_memory=True)\ntest_loader = DeviceDataLoader(test_loader, device)\nevaluate(model, test_loader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import jovian","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"jovian.commit(project=project_name, environment=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"jovian.commit(project=project_name, environment=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}