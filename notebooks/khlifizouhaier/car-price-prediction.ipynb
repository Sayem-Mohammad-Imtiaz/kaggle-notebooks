{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/car-price-prediction/CarPrice_Assignment.csv\")\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# symboling: -2 (least risky) to +3 most risky\n# Most cars are 0,1,2\ndata['symboling'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# aspiration: An (internal combustion) engine property showing \n# whether the oxygen intake is through standard (atmospheric pressure)\n# or through turbocharging (pressurised oxygen intake)\ndata['aspiration'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drivewheel: frontwheel, rear wheel or four-wheel drive \ndata['drivewheel'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# target variable: price of car\n\nfig, ax= plt.subplots(1,2,figsize=(15,5))\n\nsns.distplot(data['price'], norm_hist=False, kde=True, ax=ax[0], color='blue')\nax[0].set_xlabel('Car Price')\nax[0].set_ylabel('Count of cars',size=12)\nax[0].set_title('Count Of Cars By Price',size=15,weight=\"bold\")\n\nsns.distplot(data['price'], kde=True, ax=ax[1], color='green')\nax[1].set_xlabel('Car Price')\nax[1].set_ylabel('Relative Frequency of cars',size=12)\nax[1].set_title('Density or Relative Frequency Of Cars By Price',size=15,weight=\"bold\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n# Observations on Target Variable- Price:\n \n1. The target variable price has a positive skew, however majority of the cars are low priced.\n2. More than 50% of the cars (around 105-107 out of total of 205) are priced 10,000 and close to 35% cars are priced between 10,000 and 20,000. So around 85% of cars in US market are priced between 5,000 to 20,000.\n3. Based on above observations and graph on right side (KDE/green one) it appears there are 2 distributions one for cars priced between 5,000 and 25000 and another distribution for high priced cars 25,000 and above. (Notice the approximate bell curve\nfrom little less than 30000 upto 45,000/50,000)"},{"metadata":{},"cell_type":"markdown","source":"# Data Exploration\nTo perform linear regression, the target variable should be linearly related to independent variables. Let's see whether that's true in this case."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_numeric=data.select_dtypes(include=['float64','int64'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dropping symboling and car_ID as symboling is more of categorical variable as described before and car_ID is only \n#an index type variable and not a predictor\ndata_numeric = data_numeric.drop(['symboling', 'car_ID'], axis=1)\ndata_numeric.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pair_wise scatter plot\nplt.figure(figsize=(20, 10))\nsns.pairplot(data_numeric)\n#as we can see its difficult to interpret these graphs due to somany of them\n#a BETTER way of checking linearity is in below cell","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i,col in enumerate(data_numeric.columns):\n    plt.figure(i)\n    sns.scatterplot(x=data_numeric[col],y=data_numeric['price'])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* These var's appears to have a linear relation with price: carwidth, curbweight, enginesize, horsepower, boreration and citympg.\n\n* Other variables either don't have a relation with price or relationship isn't strong. None of the varibales appear to have polynomial relation with price.\n\n* In linear regression assumptions validation section we will check for linearity assumption in detail"},{"metadata":{},"cell_type":"markdown","source":"# Correlation matrix\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix=data_numeric.corr()\ncorr_matrix\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''For best visualization of correlation between variables we'll use heatmap'''\n\n\nplt.figure(figsize=(10,15))\nsns.heatmap(corr_matrix,annot=True,cmap=\"YlGnBu\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Useful insights from Corr Heatmap\nDependent var and indep. var's :\n* Positive corr : Price highly correlated with enginesize, curbweight, horsepower, carwidth (all of these variables represent the size/weight/engine power of the car)\n\n* Negative corr: Price negatively corr with mpg var's citympg and highwaympg. This suggest that cars having high mileage may fall in the 'economy' cars category or in other words indicates that Low priced cars have mostly high mpg\n\nCorrelation among independent variables:\n\n* Many independent variables are highly correlated; wheelbase, carlength, curbweight, enginesize etc. are all measures of 'size/weight', and are positively correlated\n\nSince indep. var's are highly correlated (more than 80% corr among many of them ) we'll have to pay attention to multicollinearity, which we will check in assumptions validation section using VIF score."},{"metadata":{},"cell_type":"markdown","source":"# Section 2: Data Cleaning: Missing values and feature data type check\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.symboling=data.symboling.astype('object')\n\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Extracting car names. car name is the first word (before space)\ncar_names = data['CarName'].apply(lambda x: x.split(\" \")[0])\ncar_names[:10]\ndata['CarName']=car_names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['CarName'].value_counts()\n\n#many car names are duplicates like toyota and toyouta, porsche and porcshce etc.\n# we need to fix incorrect spelling and get car_names column in order\n\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#volkswagen\ndata.loc[(data['CarName']==\"vw\")|(data['CarName']==\"vokswagen\"),'CarName']=\"volkswagen\"\n#porsche\ndata.loc[(data['CarName']==\"porcshce\"),'CarName']=\"porsche\"\n\n#toyota\ndata.loc[(data['CarName']==\"toyouta\"),'CarName']=\"toyota\"\n\n# nissan\ndata.loc[data['CarName'] == \"Nissan\",'CarName'] = 'nissan'\n\n# mazda\ndata.loc[data['CarName'] == \"maxda\",'CarName'] = 'mazda'\n\ndata['CarName'].value_counts()\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Section 3. Data Preparation: feature engineering\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"X=data.drop(columns=['price',\"car_ID\"])\ny=data['price']\nX.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating dummy variables for categorical variables\ndata.info()\ncars_categorical = X.select_dtypes(include=['object'])\ncars_categorical.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating dummy variables\ncars_dummies = pd.get_dummies(cars_categorical, drop_first=True)\ncars_dummies.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cars_dummies.columns\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=X.drop(columns=cars_categorical)\nX.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfX=pd.merge(X,cars_dummies,on=X.index)\n#or\ndfX=pd.concat([X,cars_dummies],axis=1)\ndfX.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Scaling the features\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import scale\n\n# storing column names in cols, since column names are (annoyingly) lost after \n# scaling (the df is converted to a numpy array)\ndfX_scaled=pd.DataFrame(scale(dfX))\ndfX_scaled.columns=dfX.columns\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''Generate descriptive statistics:\nDescriptive statistics include those that summarize the central tendency,\ndispersion and shape of a dataset’s distribution, excluding NaN values.'''\ndfX.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split into train and test\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(dfX_scaled, y, \n                                                    train_size=0.7,\n                                                    test_size = 0.3, random_state=100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n# Section 4. Model Building and Feature Selection using RFE\n Since our dependent variable price looks to be linearly related to most of the independent variables we are using Linear Regression only and not other types of regression like Polynomial, Random Forest/Boosting regression etc."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model with all features\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LinearRegression\n\nlm=LinearRegression()\nlm.fit(X_train,y_train)\n\ny_pred_test=lm.predict(X_test)\ny_pred_train=lm.predict(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#Rsqaure\nfrom sklearn.metrics import r2_score\n\nprint('R-sqaure on train data: {}'.format(r2_score(y_true=y_train, y_pred=y_pred_train)))\nprint('R-sqaure on test data: {}'.format(r2_score(y_true=y_test, y_pred=y_pred_test)))\n\n#Standard error/RMSE\nerror_train=y_pred_train-y_train\nerror_test=y_pred_test-y_test\n\nprint('RMSE on train data: {}'.format(((error_train**2).mean())**0.5))\nprint('RMSE on test data: {}'.format(((error_test**2).mean())**0.5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}