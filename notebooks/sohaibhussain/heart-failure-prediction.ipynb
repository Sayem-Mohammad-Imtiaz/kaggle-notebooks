{"cells":[{"metadata":{},"cell_type":"markdown","source":"<center><img src='https://i.ytimg.com/vi/pB7SWDcgPic/maxresdefault.jpg'></center>"},{"metadata":{},"cell_type":"markdown","source":"## Problem Statement"},{"metadata":{},"cell_type":"markdown","source":"There are some factors that affects death of an patenet. This dataset contains person's information like age ,sex , blood pressure, smoke, diabetes,ejection fraction, creatinine phosphokinase, serum_creatinine, serum_sodium, time and we have to predict their DEATH EVENT.\n\n1. age\n2. anaemia - Decrease of red blood cells or hemoglobin (boolean)\n3. creatinine_phosphokinase - Level of the CPK enzyme in the blood (mcg/L)\n4. diabetes - If the patient has diabetes (boolean)\n5. ejection_fraction - Percentage of blood leaving the heart at each contraction (percentage)\n6. high_blood_pressure - If the patient has hypertension (boolean)\n7. platelets - Platelets in the blood (kiloplatelets/mL)\n8. serum_creatinine - Level of serum creatinine in the blood (mg/dL)\n9. serum_sodium - Level of serum sodium in the blood (mEq/L)\n10. sex - Woman or man (binary)\n11. smoking - If the patient smokes or not (boolean)\n12. time - Follow-up period (days)\n13. DEATH_EVENT - If the patient deceased during the follow-up period (boolean)"},{"metadata":{},"cell_type":"markdown","source":"## Import Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Some mandatory Libraries\nimport string \nimport warnings\nimport numpy as np\nimport pandas as pd\n\n# plotting\nimport seaborn as sns;\nimport matplotlib.pyplot as plt\n\n# features selection\nfrom sklearn.feature_selection import chi2\nfrom sklearn.feature_selection import SelectKBest\n\n# scaling\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\n\n# model building\nfrom sklearn.svm import SVC\nfrom sklearn.svm import NuSVC\nfrom sklearn.svm import LinearSVC\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\n\n# sccuracy\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import classification_report, confusion_matrix, plot_roc_curve, plot_precision_recall_curve\n\n# others\n%matplotlib inline\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## [1.1] Load Data\n\nLoading the data into the pandas data frame is certainly one of the most important steps, as we can see that the value from the data set is comma-separated. So all we have to do is to just read the CSV into a data frame and pandas data frame does the job for us."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/heart-failure-clinical-data/heart_failure_clinical_records_dataset.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here __\"DEATH_EVENT\"__ is the target column."},{"metadata":{},"cell_type":"markdown","source":"## [2.1] Lets Explore the Data\n\nExploratory Data Analysis or (EDA) is understanding the data sets by summarizing their main characteristics often plotting them visually. This step is very important especially when we arrive at modeling the data in order to apply Machine learning.\n\n1. Checking the types of data.\n2. Dropping irrelevant columns.\n3. Renaming the columns.\n4. Dropping the duplicate rows.\n5. Dropping the missing or null values.\n6. Detecting Outliers\n7. Plotting"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Shape of our Data:',df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check datatypes\n\nprint(df.dtypes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check min, max and other details\n\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check the missing or null values.\n\nprint(df.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('DEATH_EVENT:')\nprint(df['DEATH_EVENT'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Distribution of DEATH_EVENT:')\nprint(df['DEATH_EVENT'].value_counts()/len(df))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Let's try to visualise the same using plots.__"},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.countplot(x='DEATH_EVENT', data=df, facecolor=(0, 0, 0, 0), linewidth=5, edgecolor=sns.color_palette(\"dark\", 3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we can see our data is immbalanced. So we need to perform some preprocessing on this dataset."},{"metadata":{},"cell_type":"markdown","source":"#### [2.1.1] Plot Correlation Metrice:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# define correlation matrice\ncorr = df.corr()\n\n# Generate a mask for the upper triangle\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)] = True\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\nwith sns.axes_style(\"white\"):\n    # Set up the matplotlib figure\n    f, ax = plt.subplots(figsize=(10, 8))\n    ax = sns.heatmap(corr, cmap=cmap, mask=mask, vmax=.3, square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we can see __'diabetes', 'sex' and 'smoking'__ has very less impact in our target value."},{"metadata":{},"cell_type":"markdown","source":"#### [2.1.2] Best Featues:"},{"metadata":{"trusted":true},"cell_type":"code","source":"#apply SelectKBest class to extract best features\nX_train = df.drop(['DEATH_EVENT'], axis=1)\nY_test = df['DEATH_EVENT']\nbestfeatures = SelectKBest(score_func=chi2, k=10)\nfit = bestfeatures.fit(X_train, Y_test)\ndfscores = pd.DataFrame(fit.scores_)\ndfcolumns = pd.DataFrame(X_train.columns)\n\n#concat two dataframes for better visualization \nfeatureScores = pd.concat([dfcolumns,dfscores],axis=1)\nfeatureScores.columns = ['Featue','Score']\nfeature_imp = featureScores.nlargest(X_train.shape[1],'Score')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot top 5 features\n\nprint(feature_imp.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot each feature with it's importance\n\nax = sns.barplot(x='Score', y='Featue', data=feature_imp)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### [2.1.3] Pairplot:"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df, hue=\"DEATH_EVENT\", palette=\"husl\",diag_kind=\"kde\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### [2.1.3] Univariate Analysis:"},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in df.columns[:12]:\n    sns.barplot(x='DEATH_EVENT',y=column, data=df, palette='Blues_d')\n    plt.title('Death Event Vs. {}'.format(string.capwords(column.replace(\"_\", \" \"))))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we can see some featutes has quite good impact in our terget such as **'serum_creatinine'** and **'time'**. Let's analyse these two featues a little bit more."},{"metadata":{"trusted":true},"cell_type":"code","source":"# define two new dataframe for Survived & Non Servived\n\nsurvived = df[df['DEATH_EVENT'] == 0]\nnot_survived = df[df['DEATH_EVENT'] == 1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Analyse Time based on PDF & CDF:__"},{"metadata":{"trusted":true},"cell_type":"code","source":"counts, bin_edges = np.histogram(survived['time'], bins=10, density = True)\npdf = counts/(sum(counts))\ncdf = np.cumsum(pdf)\nplt.plot(bin_edges[1:],pdf);\nplt.plot(bin_edges[1:], cdf)\n\ncounts, bin_edges = np.histogram(not_survived['time'], bins=10, density = True)\npdf = counts/(sum(counts))\ncdf = np.cumsum(pdf)\nplt.plot(bin_edges[1:],pdf);\nplt.plot(bin_edges[1:], cdf)\n\nplt.xlabel('Time')\nplt.title('PDF & CDF (Time)')\nplt.legend(['PDF of Survived','CDF of Survived','PDF of Non-Survived','CDF of Non-Survived'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Onservations on Time:**\n\nTime can be key feature to analyse our target. If follow up days is morethan **100** then maximum (Near about 20%) chances that patent is well. On the other hand if the patenet has lessthan **50** days follow up days then 30% chances that patenet has heart failure.\n\n__Analyse Serum Creatinine based on PDF & CDF:__"},{"metadata":{"trusted":true},"cell_type":"code","source":"counts, bin_edges = np.histogram(survived['serum_creatinine'], bins=10, density = True)\npdf = counts/(sum(counts))\ncdf = np.cumsum(pdf)\nplt.plot(bin_edges[1:],pdf);\nplt.plot(bin_edges[1:], cdf)\n\ncounts, bin_edges = np.histogram(not_survived['serum_creatinine'], bins=10, density = True)\npdf = counts/(sum(counts))\ncdf = np.cumsum(pdf)\nplt.plot(bin_edges[1:],pdf);\nplt.plot(bin_edges[1:], cdf)\n\nplt.xlabel('Serum Creatinine')\nplt.title('PDF & CDF (Serum Creatinine)')\nplt.legend(['PDF of Survived','CDF of Survived','PDF of Non-Survived','CDF of Non-Survived'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Onservations on Serum Creatinine:**\n\nIt is also an key feature to anayse. If patent's Serum Creatinine is more that 6 it is higer chances that patent has heart failuire.\n\n__Analyse the outlieres:__"},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in df.columns[:12]:\n    sns.boxplot(x='DEATH_EVENT',y=column, data=df, palette='Set3')\n    plt.title('Death Event Vs. {}'.format(string.capwords(column.replace(\"_\", \" \"))))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we can have some extream outliers such as **'creatinine_phosphokinase'** and **'serum_sodium'**\n\n### Observation on EDA\n\nFrom the above analysis we can't conclude anything as we have major overlap between data. But we can point out some of the details as,\n\n* Most of my patentece are between 40-80 age group. \n* Most of the Nonsurvived patentece are between 45 to 65 age group.\n* Ejection Fraction bellow 40 is a good singh. More than 50% patentece survived who fad Ejection Fraction less than 40.\n* Geder is also overlapped alot. But we can say 60% males and 40% females are srvived. \n* From **Time in Days** we can say more non survived patentece are found as my observation period increase.\n\nOn a nutshell we can say Univariate analysis is not that good as we have lot of overlapper between datas. Let's try other techniques to be more accurate analysis."},{"metadata":{},"cell_type":"markdown","source":"## [3.1] Data Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"__Remove Outliers__"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Apply MinMaxScaler__"},{"metadata":{"trusted":true},"cell_type":"code","source":"# define features need to be scale\n# select all numeric features except categorial\ncols = ['age', 'creatinine_phosphokinase', 'ejection_fraction', 'platelets', 'serum_sodium', 'time']\n\n# define object\nscaler = MinMaxScaler()\n\n# perform Min Max Scaling\nfor col in cols:\n    scaler.fit(df[col].values.reshape(-1, 1))\n    df['nrm_' + col] = scaler.transform(df[col].values.reshape(-1, 1))\n\n# drop old columns\ndf.drop(['age', 'creatinine_phosphokinase', 'ejection_fraction', 'platelets', 'serum_sodium', 'time'], axis = 1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## [4.1] Train Test Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(df.drop(['DEATH_EVENT'], axis=1), df['DEATH_EVENT'], test_size=0.3, random_state=11)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## [5.1] Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define classifiers with default parameters.\n\nclassifiers = {\n    'SVC': SVC(),\n    'LinearSVC': LinearSVC(),\n    'NuSVC': NuSVC(),\n    'DecisionTree':DecisionTreeClassifier()\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for name, classifier in classifiers.items():\n    classifier.fit(X_train, y_train)\n    training_score = cross_val_score(classifier, X_train, y_train, cv=5)\n    print('Classifiers: ',name, 'has training score of', round(training_score.mean(),2) * 100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## [6.1] Hyper Parameter Tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"# SVC\n\nparams = {\n    'C':[10**-3, 10**-2, 10**-1, 1, 10, 10**2, 10**3], \n    'kernel':['linear', 'poly', 'rbf', 'sigmoid'],\n    'gamma': ['scale', 'auto']\n}\n\ngs = GridSearchCV(SVC(), params, cv = 5, n_jobs=-1, scoring='accuracy')\ngs_results = gs.fit(X_train, y_train)\n\nSVC_best_estimator = gs.best_estimator_ # store best estimators for future analysis\n\nprint('Best Accuracy: ', gs_results.best_score_)\nprint('Best Parametrs: ', gs_results.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LinearSVC\n\nparams = {\n    'C':[10**-3, 10**-2, 10**-1, 1, 10, 10**2, 10**3], \n    'penalty':['l1', 'l2'],\n    'loss': ['hinge', 'squared_hinge']\n}\n\ngs = GridSearchCV(LinearSVC(), params, cv = 5, n_jobs=-1, scoring='accuracy')\ngs_results = gs.fit(X_train, y_train)\n\nLinearSVC_best_estimator = gs.best_estimator_ # store best estimators for future analysis\n\nprint('Best Accuracy: ', gs_results.best_score_)\nprint('Best Parametrs: ', gs_results.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# DecisionTree\n\nparams = {\n    'criterion': ['gini', 'entropy'],\n    'max_depth': [2,4,6,8,10,12]\n}\n\ngs = GridSearchCV(DecisionTreeClassifier(), params, cv = 5, n_jobs=-1, scoring='accuracy')\ngs_results = gs.fit(X_train, y_train)\n\nDecisionTree_best_estimator = gs.best_estimator_ # store best estimators for future analysis\n\nprint('Best Accuracy: ', gs_results.best_score_)\nprint('Best Parametrs: ', gs_results.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot top 5 best features\n\npd.Series(DecisionTree_best_estimator.feature_importances_, index=X_train.columns).nlargest(5).plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Plot classification report:__"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pred = SVC_best_estimator.predict(X_train)\nprint(classification_report(y_train,train_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pred = LinearSVC_best_estimator.predict(X_train)\nprint(classification_report(y_train,train_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pred = DecisionTree_best_estimator.predict(X_train)\nprint(classification_report(y_train,train_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## [7.1] Accuracy on Test:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Final Test Accuracy for')\nprint('     SVC:',SVC_best_estimator.score(X_test,y_test))\nprint('     Linear SVC:',LinearSVC_best_estimator.score(X_test,y_test))\nprint('     Decision Tree:',DecisionTree_best_estimator.score(X_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Polt AUC Curve with DecisionTree:__"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc_curve(DecisionTree_best_estimator, X_test, y_test)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_precision_recall_curve(DecisionTree_best_estimator, X_test, y_test)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Confusion Matrix with Decision Tree__"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = DecisionTree_best_estimator.predict(X_test)\nsns.heatmap(confusion_matrix(y_test,pred),annot=True)\nplt.ylabel(\"Actual\")\nplt.xlabel(\"Prediction\")\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}