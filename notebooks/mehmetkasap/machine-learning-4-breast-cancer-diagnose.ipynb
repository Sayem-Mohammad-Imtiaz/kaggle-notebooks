{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# import warnings\nimport warnings\n# ignore warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"af346d839b8099c75d10beef3477f914f0db7e33"},"cell_type":"code","source":"# information of our data (lenght, how many NaN objects we have etc.)\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"07db99f976090f6422008492bf91357896b56f93"},"cell_type":"code","source":"# to see features and target variable of the first 5 rows\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"39bb18bbf890d9c731e8acfeb2c49769210ab27c"},"cell_type":"code","source":"# to see features and target variable of the last 5 rows\ndata.tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aa772bd1b664bf9578577f5078759bab7adaadf3"},"cell_type":"markdown","source":"* **drop unnecessary columns**"},{"metadata":{"trusted":true,"_uuid":"75145677882541c8b42f25b4e2bda533f268ce7e"},"cell_type":"code","source":"data = data.drop(['Unnamed: 32', 'id'], axis=1)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0ba49083394397d417605a4f908ba5387f367a27"},"cell_type":"markdown","source":"* **how many types of diagnosis do we have?**"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"63761a0f727baaa1b9b28f7da9a2c6453fa8c348"},"cell_type":"code","source":"data['diagnosis'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a2354ec5e084362deae1fc4b6521918bf16178b0"},"cell_type":"code","source":"import seaborn as sns\nsns.countplot(data['diagnosis'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a7ea838378e21c89732fd694af6cfc9c7924b7a3"},"cell_type":"markdown","source":"*** change diagnosis column to integers**"},{"metadata":{"trusted":true,"_uuid":"bec899d53e4a7a2caaa5fbf6ef96d3520bb4a38e"},"cell_type":"code","source":"data['diagnosis'] = [1 if x=='M' else 0 for x in  data['diagnosis']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e65826695db778b33d355f4819c120d7bbe5ac7c"},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3d3eec96a45d058c5d5b3db76941ace48b4405e6"},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0c8484c9cbd8e2aeb9962e724824f67371f4bb83"},"cell_type":"code","source":"color_list = ['red' if i==1.0 else 'green' for i in data.loc[:,'diagnosis']]\npd.plotting.scatter_matrix(data.iloc[:, 7:13],\n                                       c=color_list,\n                                       figsize= [10,15],\n                                       diagonal='hist',\n                                       alpha=0.5,\n                                       s = 200,\n                                       marker = '*',\n                                       edgecolor= \"black\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a85653772c98d3a034352802ef4f881510f7d00a"},"cell_type":"markdown","source":"**Choosing x and y values**\n1. x is our features except diagnosis (classification columns)\n2. y is diagnosis"},{"metadata":{"trusted":true,"_uuid":"dac5e8d2e4cddb3e97c28dd0a632024800e58448"},"cell_type":"code","source":"x = data.iloc[:,1:]\ny = data['diagnosis']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eb21cb21397b56a5b1478f9c9fe7287e2c1b41c9"},"cell_type":"markdown","source":"**Split our data into train data and test data**"},{"metadata":{"trusted":true,"_uuid":"4af47510c271cca713a7d2e39446c089632488d4"},"cell_type":"code","source":"# train test split\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.3,random_state = 1) # 0.3 means 30% of data is splitted for testing. Remaining 70% is used to train our data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"54af30afc6f3b1acc303bfaa3486013b1d5f0c9f"},"cell_type":"markdown","source":"**K-NEAREST NEIGHBORS (KNN)**\n1. k is a selected number (for example k=3)\n2. we select k nearest neighbors of a particle that we want to predict\n3. in this selected set, if we have more M diagnosis than B diagnosis, we predict this particle as M. Or vise versa  "},{"metadata":{"trusted":true,"_uuid":"5e9f16b7ccd7ddbc95807d66e17c7418bc7540c0"},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(x_train,y_train) # to train our data\npredicted_values = knn.predict(x_test)\ncorrect_values = np.array(y_test) # just to make them array","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a845bba69fe43f3519694ba31843b774dfc2c70"},"cell_type":"code","source":"predicted_values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"26435feae488bddbd18ca1c5b85278477710bc9a"},"cell_type":"code","source":"correct_values","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"614624ed3af1450d47cfd06789262760c3c7391d"},"cell_type":"markdown","source":"**KNN Prediction Score**"},{"metadata":{"trusted":true,"_uuid":"23b68e24cec632023e33e57157962736cce49c54"},"cell_type":"code","source":"print('KNN (with k=3) accuracy is: ',knn.score(x_test,y_test)) # accuracy","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"662609f45a32f9b79ac42e43c3c01aa7e4056196"},"cell_type":"markdown","source":"**k value**\n1. k value is as hyperparameter\n2. but is this selected k value (k=3) optimum one?"},{"metadata":{"trusted":true,"_uuid":"57f0e003a1f1f514d4514832f878f25cbac7b8ef"},"cell_type":"code","source":"neig = np.arange(1,25)\ntest_accuracy = []\n# Loop over different values of k\nfor k in neig:\n    # k from 1 to 25(exclude)\n    knn = KNeighborsClassifier(n_neighbors=k)\n    # Fit with knn\n    knn.fit(x_train,y_train)\n    # test accuracy\n    test_accuracy.append(knn.score(x_test, y_test))\n\n# Plot\nplt.figure(figsize=[13,8])\nplt.plot(neig, test_accuracy, label = 'Testing Accuracy')\nplt.legend()\nplt.title('k-value VS Accuracy')\nplt.xlabel('Number of Neighbors')\nplt.ylabel('Accuracy')\nplt.xticks(neig)\nplt.savefig('graph.png')\nplt.show()\nprint(\"Best accuracy is {} with K = {}\".format(np.max(test_accuracy),1+test_accuracy.index(np.max(test_accuracy))))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5a0c06239c1c3903172f5819f9a3df900c1435d0"},"cell_type":"markdown","source":"**REGRESSION**"},{"metadata":{"_uuid":"6193fef024471922600164d536806465d657dfea"},"cell_type":"markdown","source":"**Linear Regression**\n1. y = ax + b where y = target, x = feature and a = parameter of model\n2. We choose parameter of model(a) according to minimum error function that is lost function"},{"metadata":{"trusted":true,"_uuid":"ae06aed6efc0fe22bd62c05d4a91ef104050a2f5"},"cell_type":"code","source":"data1 = data[data['diagnosis'] == 1.0]\nx = np.array(data1.loc[:,'fractal_dimension_mean']).reshape(-1,1)\ny = np.array(data1.loc[:,'symmetry_mean']).reshape(-1,1)\n# Scatter\nplt.figure(figsize=[10,10])\nplt.scatter(x=x,y=y)\nplt.xlabel('fractal_dimension_mean')\nplt.ylabel('symmetry_mean')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"29381a7f430a4c6869891a6b79bd8fe3abd1f1dd"},"cell_type":"code","source":"# LinearRegression\nfrom sklearn.linear_model import LinearRegression\nLR = LinearRegression()\n# data to be predicted\ntest_data = np.linspace(min(x), max(x)).reshape(-1,1)\n# Fit\nLR.fit(x,y)\n# Predict\npredicted = LR.predict(test_data)\n# score\nprint('score: ',LR.score(x, y))\n# Plot regression line and scatter\nplt.figure(figsize=(10,10))\nplt.plot(test_data, predicted, color='black', linewidth=3)\nplt.scatter(x=x,y=y)\nplt.xlabel('fractal_dimension_mean')\nplt.ylabel('symmetry_mean')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cd9eca76c298b3280af939a2a281998148e2c3b9"},"cell_type":"markdown","source":"**CROSS VALIDATION**\n* In KNN method if we change train-test data,  the score can change. But if the score changes according to our data to which score values should I rely on?\n* the answer is I dont know. But if I use cross validation, I can find a reasonable accuracy."},{"metadata":{"trusted":true,"_uuid":"519fb4bce68ccb46955faa1d90861e9fd5cc3601"},"cell_type":"code","source":"# CV\nfrom sklearn.model_selection import cross_val_score\nreg = LinearRegression()\nk = 5 # 5 times split train and predict \ncv_result = cross_val_score(reg,x,y,cv=k) # uses R^2 as score \nprint('CV Scores: ',cv_result)\nprint('CV scores average: ',np.sum(cv_result)/k)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c3363e46ae3624a6b494616f334941d7267f255"},"cell_type":"markdown","source":"**Random Forest Regression**"},{"metadata":{"trusted":true,"_uuid":"e1a36c9dc2a0ca6104a4d0c37a1d33b72babe086"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nx = data.iloc[:,1:]\ny = data['diagnosis']\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.3,random_state = 1) \nRF = RandomForestClassifier(random_state = 4)\nRF.fit(x_train,y_train)\ny_predicted = RF.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2ca9b85c2fd7bef461b0b1dd0f838af68d547a8b"},"cell_type":"markdown","source":"**Confusion matrix with random forest**"},{"metadata":{"trusted":true,"_uuid":"29253f4545525a52d86be71e25531070c600bdf2"},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test,y_predicted)\nprint('Confusion matrix: \\n',cm)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9c2fbbb0ad4d62b031ba249c074e9954bc7a80e5"},"cell_type":"markdown","source":"**Classification Report**"},{"metadata":{"trusted":true,"_uuid":"4568243bd69e504ffe5d5ef554d28f8b3a27946c"},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint('Classification report: \\n',classification_report(y_test,y_predicted))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e31023f2f11f3eab13a99c87f315563f60ff1a73"},"cell_type":"code","source":"# visualize with seaborn library\nsns.heatmap(cm,annot=True,fmt=\"d\") \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2ff939c93dd1ca182c35770205e32461eb5b9b2c"},"cell_type":"markdown","source":"we see that for the diagnosis 0 we have predicted 106 of them correctly (2 false prediction) (98% accuracy for diagnosis 0)\n\non the other hand, \n\nwe see that for the diagnosis 1 we have predicted 56 of them correctly (7 false prediction) (89% accuracy for diagnosis 1)"},{"metadata":{"_uuid":"da2d35ab13747f89c0ef8966389bae13ab75cc89"},"cell_type":"markdown","source":"**Logistic Regression**"},{"metadata":{"trusted":true,"_uuid":"c0c24e8621d4c58ef83e59380e307c8644a33353"},"cell_type":"code","source":"x = data.iloc[:,1:]\ny = data['diagnosis']\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.3,random_state = 1)\nfrom sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression()\nlogreg.fit(x_train,y_train)\ny_pred = logreg.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"319a5e21eeaad89f137b6a1e9c70034d5c35fad4"},"cell_type":"code","source":"print('logistic regression score: ', logreg.score(x_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c6741cb1f2b67311d2b3d8b17e321252d6a9bad2"},"cell_type":"markdown","source":"**Cross Validation for logistic regression**"},{"metadata":{"trusted":true,"_uuid":"daf1ccf070a52cbb8a5c140819caa5f569d90046"},"cell_type":"code","source":"# CV\nfrom sklearn.model_selection import cross_val_score\nlogreg = LogisticRegression()\nk = 5 # 5 times split train and predict \ncv_result = cross_val_score(logreg,x,y,cv=k) # uses R^2 as score \nprint('CV Scores: ',cv_result)\nprint('CV scores average: ',np.sum(cv_result)/k)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eea5c30d78137b80790611b48348f0b624dffdf9"},"cell_type":"markdown","source":"**HYPERPARAMETER TUNING**\n\nGridSearchCV is utilized for finding the hyperparameters (KNN)"},{"metadata":{"trusted":true,"_uuid":"264fd708ca4d99f9c87255d7781f489f676a2eb8"},"cell_type":"code","source":"# grid search cross validation with 1 hyperparameter (KNN)\nfrom sklearn.model_selection import GridSearchCV\ngrid = {'n_neighbors': np.arange(1,50)}\nknn = KNeighborsClassifier()\nknn_cv = GridSearchCV(knn, grid, cv=3) # GridSearchCV\nknn_cv.fit(x_train,y_train)# Fit\n\n# Print hyperparameter\nprint(\"Tuned hyperparameter k: {}\".format(knn_cv.best_params_)) \nprint(\"Best score: {}\".format(knn_cv.best_score_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d6837416c3f1a5f16ffefd7d63389166c586a2a1"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}