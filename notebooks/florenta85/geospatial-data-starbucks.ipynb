{"cells":[{"metadata":{},"cell_type":"markdown","source":"**[Geospatial Analysis Home Page](https://www.kaggle.com/learn/geospatial-analysis)**\n\n---\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\nYou are a Starbucks big data analyst ([thatâ€™s a real job!](https://www.forbes.com/sites/bernardmarr/2018/05/28/starbucks-using-big-data-analytics-and-artificial-intelligence-to-boost-performance/#130c7d765cdc)) looking to find the next store into a [Starbucks Reserve Roastery](https://www.businessinsider.com/starbucks-reserve-roastery-compared-regular-starbucks-2018-12#also-on-the-first-floor-was-the-main-coffee-bar-five-hourglass-like-units-hold-the-freshly-roasted-coffee-beans-that-are-used-in-each-order-the-selection-rotates-seasonally-5).  These roasteries are much larger than a typical Starbucks store and have several additional features, including various food and wine options, along with upscale lounge areas.  You'll investigate the demographics of various counties in the state of California, to determine potentially suitable locations.\n\n<center>\n<img src=\"https://i.imgur.com/BIyE6kR.png\" width=\"450\"><br/><br/>\n</center>\n\nBefore you get started, run the code cell below to set everything up.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\nimport pandas as pd\nimport geopandas as gpd\nfrom learntools.geospatial.tools import geocode\n\nimport folium \nfrom folium import Choropleth, Marker\nfrom folium.plugins import HeatMap, MarkerCluster\n\nfrom shapely.geometry import MultiPolygon","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"You'll use the `embed_map()` function from the previous exercise to visualize your maps.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def embed_map(m, file_name):\n    from IPython.display import IFrame\n    m.save(file_name)\n    return IFrame(file_name, width='100%', height='500px')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exercises\n\n### 1) Geocode the missing locations.\n\nRun the next code cell to create a DataFrame `starbucks` containing Starbucks locations in the state of California.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load and preview Starbucks locations in California\nstarbucks = pd.read_csv(\"../input/geospatial-learn-course-data/starbucks_locations.csv\")\nstarbucks.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most of the stores have known (latitude, longitude) locations.  But, all of the locations in the city of Berkeley are missing.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# How many rows in each column have missing values?\nprint(starbucks.isnull().sum())\n\n# View rows with missing locations\nrows_with_missing = starbucks[starbucks[\"City\"]==\"Berkeley\"]\nrows_with_missing","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Use the code cell below to fill in these values with the OpenStreetMap Nominatim geocoder.\n\nNote that in the tutorial, we used `geocode()` (from `geopandas.tools`) to geocode values, and this is what you can use in your own projects outside of this micro-course.  \n\nIn this exercise, you will use a slightly different function `geocode()` (from `learntools.geospatial.tools`).  This function was imported at the top of the notebook and works identically to the function from GeoPandas.\n\nSo, in other words, as long as: \n- you don't change the import statements at the top of the notebook, and \n- you call the geocoding function as `geocode()` in the code cell below, \n\nyour code will work as intended!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Your code here\ndef my_geocoder(row):\n    point = geocode(row, provider='nominatim').geometry[0]\n    return pd.Series({'Longitude': point.x, 'Latitude': point.y})\n\nberkeley_locations = rows_with_missing.apply(lambda x: my_geocoder(x['Address']), axis=1)\nstarbucks.update(berkeley_locations)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2) View Berkeley locations.\n\nLet's take a look at the locations you just found.  Visualize the (latitude, longitude) locations in Berkeley in the OpenStreetMap style. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a base map\nm_2 = folium.Map(location=[37.88,-122.26], zoom_start=13)\n\n# Add a marker for each Berkeley location\nfor idx, row in starbucks[starbucks[\"City\"]=='Berkeley'].iterrows():\n    Marker([row['Latitude'], row['Longitude']]).add_to(m_2)\n\n# Show the map\nembed_map(m_2, 'q_2.html')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3) Consolidate your data.\n\nRun the code below to load a GeoDataFrame `CA_counties` containing the name, area (in square kilometers), and a unique id (in the \"GEOID\" column) for each county in the state of California.  The \"geometry\" column contains a polygon with county boundaries.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"CA_counties = gpd.read_file(\"../input/geospatial-learn-course-data/CA_county_boundaries/CA_county_boundaries/CA_county_boundaries.shp\")\nCA_counties.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, we create three DataFrames:\n- `CA_pop` contains an estimate of the population of each county.\n- `CA_high_earners` contains the number of households with an income of at least $150,000 per year.\n- `CA_median_age` contains the median age for each county.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"CA_pop = pd.read_csv(\"../input/geospatial-learn-course-data/CA_county_population.csv\", index_col=\"GEOID\")\nCA_high_earners = pd.read_csv(\"../input/geospatial-learn-course-data/CA_county_high_earners.csv\", index_col=\"GEOID\")\nCA_median_age = pd.read_csv(\"../input/geospatial-learn-course-data/CA_county_median_age.csv\", index_col=\"GEOID\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Use the next code cell to join the `CA_counties` GeoDataFrame with `CA_pop`, `CA_high_earners`, and `CA_median_age`.\n\nName the resultant GeoDataFrame `CA_stats`, and make sure it has 8 columns: \"GEOID\", \"name\", \"area_sqkm\", \"geometry\", \"population\", \"high_earners\", and \"median_age\".  Also, make sure the CRS is set to `{'init': 'epsg:4326'}`.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Joining all the following dataset's solumn into \"cols_to_add\"\ncols_to_add = CA_pop.join([CA_high_earners, CA_median_age]).reset_index()\n# Merging \"cols_to_add\" and \"CA_stats\" on GEOID\nCA_stats = CA_counties.merge(cols_to_add, on=\"GEOID\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that we have all of the data in one place, it's much easier to calculate statistics that use a combination of columns.  Run the next code cell to create a \"density\" column with the population density.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"CA_stats[\"density\"] = CA_stats[\"population\"] / CA_stats[\"area_sqkm\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4) Which counties look promising?\n\nCollapsing all of the information into a single GeoDataFrame also makes it much easier to select counties that meet specific criteria.\n\nUse the next code cell to create a GeoDataFrame `sel_counties` that contains a subset of the rows (and all of the columns) from the `CA_stats` GeoDataFrame.  In particular, you should select counties where:\n- there are at least 100,000 households making \\$150,000 per year,\n- the median age is less than 38.5, and\n- the density of inhabitants is at least 285 (per square kilometer).\n\nAdditionally, selected counties should satisfy at least one of the following criteria:\n- there are at least 500,000 households making \\$150,000 per year,\n- the median age is less than 35.5, or\n- the density of inhabitants is at least 1400 (per square kilometer).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Your code here\nsel_counties = CA_stats[((CA_stats.high_earners > 100000) &\n                         (CA_stats.median_age < 38.5) &\n                         (CA_stats.density > 285) &\n                         ((CA_stats.median_age < 35.5) |\n                         (CA_stats.density > 1400) |\n                         (CA_stats.high_earners > 500000)))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5) How many stores did you identify?\n\nWhen looking for the next Starbucks Reserve Roastery location, you'd like to consider all of the stores within the counties that you selected.  So, how many stores are within the selected counties?\n\nTo prepare to answer this question, run the next code cell to create a GeoDataFrame `starbucks_gdf` with all of the starbucks locations.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"starbucks_gdf = gpd.GeoDataFrame(starbucks, geometry=gpd.points_from_xy(starbucks.Longitude, starbucks.Latitude))\nstarbucks_gdf.crs = {'init': 'epsg:4326'}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, how many stores are in the counties you selected?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fill in your answer\nlocations_of_interest = gpd.sjoin(starbucks_gdf, sel_counties)\nnum_stores = len(locations_of_interest)\nprint(num_stores)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 6) Visualize the store locations.\n\nCreate a map that shows the locations of the stores that you identified in the previous question.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a base map\nm_6 = folium.Map(location=[37,-120], zoom_start=6)\n\n# Show selected store locations in a decluster way using MarkerCluster\nmc = MarkerCluster()\n\nlocations_of_interest = gpd.sjoin(starbucks_gdf, sel_counties)\nfor idx, row in locations_of_interest.iterrows():\n    if not math.isnan(row['Longitude']) and not math.isnan(row['Latitude']):\n        mc.add_child(folium.Marker([row['Latitude'], row['Longitude']]))\n\nm_6.add_child(mc)\n\n# Show the map\nembed_map(m_6, 'q_6.html')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Looking where to build new Stores in San Francisco","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create \"San_Francisco) df from \"starbucks\" \nSan_Francisco = starbucks[starbucks[\"City\"]==\"San Francisco\"]\n# Creating a GeoDataFrame of \"San_Francisco\"\nSan_Francisco_gdf = gpd.GeoDataFrame(San_Francisco, geometry=gpd.points_from_xy(San_Francisco.Longitude, San_Francisco.Latitude))\n# Adding the CRS data\nSan_Francisco_gdf.crs = {'init': 'epsg:4326'}\n# Converting the ESPG to 2263 for unit purposes to convert in metres\nSan_Francisco_gdf = San_Francisco_gdf.to_crs(epsg=2263)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a buffer of 1km radius to capture the coverage of each store in \"San_Francisco\"\nbuffer_in_meters = (1 * 1000) # Change the kms wished to cover\ncoverage = gpd.GeoDataFrame(geometry=San_Francisco_gdf.geometry).buffer(buffer_in_meters)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create map with release incidents and monitoring stations\nm_7 = folium.Map(location=[37.77,-122.4], zoom_start=12)\n# View SF stores\nfor idx, row in San_Francisco_gdf.iterrows():\n    Marker([row['Latitude'], row['Longitude']]).add_to(m_7)\n# Plot each polygon on the map\nfolium.GeoJson(coverage.geometry.to_crs(epsg=4326)).add_to(m_7)\n# Adding the Ltn and Lat data markers\nfolium.LatLngPopup().add_to(m_7)\n\nembed_map(m_7, 'm_7.html')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Provide 2 new locations for potential new stores\n# Proposed location of hospital 1\nlat_1 = 37.7771\nlong_1 = -122.4650\n\n# Proposed location of hospital 2\nlat_2 = 37.7442\nlong_2 = -122.4136\n\n# Do not modify the code below this line - Creating a new_df based on choosen location\nnew_df = pd.DataFrame(\n        {'Latitude': [lat_1, lat_2],\n         'Longitude': [long_1, long_2]})\nnew_gdf = gpd.GeoDataFrame(new_df, geometry=gpd.points_from_xy(new_df.Longitude, new_df.Latitude))\nnew_gdf.crs = {'init' :'epsg:4326'}\nnew_gdf = new_gdf.to_crs(epsg=2263) # Converting to ESPG 2263 to be on the same scale as previous map\n# get new coverage\nnew_coverage = gpd.GeoDataFrame(geometry=new_gdf.geometry).buffer(buffer_in_meters)\n# make the map\nm_8 = folium.Map(location=[37.77,-122.4], zoom_start=12) \nfolium.GeoJson(coverage.geometry.to_crs(epsg=4326)).add_to(m_8) # Adding existing coverage\nfolium.GeoJson(new_coverage.geometry.to_crs(epsg=4326)).add_to(m_8) # Adding new coverage\n# Add new stores\nfor idx, row in new_gdf.iterrows():\n    Marker([row['Latitude'], row['Longitude']], icon=folium.Icon(color=\"red\")).add_to(m_8)\n# View existing stores\nfor idx, row in San_Francisco_gdf.iterrows():\n    Marker([row['Latitude'], row['Longitude']]).add_to(m_8)\nfolium.LatLngPopup().add_to(m_8)\n# Display Map\ndisplay(embed_map(m_8, 'q_8.html'))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}