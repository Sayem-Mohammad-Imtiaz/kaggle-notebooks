{"cells":[{"metadata":{},"cell_type":"markdown","source":"# ML Project - Bank Marketing Prediction\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"> Reading dataset","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"import pandas as pd\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df = pd.read_csv('bank-marketing.csv')\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cleaning the data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"- droping the data which is not giving proper information.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"df2 = df.drop(df[df['education'] == 'unknown'].index, axis = 0, inplace = False)\ndf2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- droping the outliers in the data.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"from scipy.stats import zscore\nprint(df2['balance'].mean())\ndf2['baloutliers']= zscore(df2['balance'])\ncle = (df2['baloutliers']>3) | (df2['baloutliers']<-3 )\ndf3 = df2.drop(df2[cle].index, axis = 0, inplace = False)\ndf4 = df3.drop('baloutliers', axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- droping the column 'contact' because it is of no use.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"df5 = df4.drop('contact', axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- converting categorical month column to numerical.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"df5['Month'] = df5['month']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"Month = {\"jan\":1,\"feb\":2,\"mar\":3,\"apr\":4,\"may\":5,\"jun\":6,\"jul\":7,\"aug\":8,\"sep\":9,\"oct\":10,\"nov\":11,\"dec\":12}\ndf5['Month'] = [Month[item] for item in df5['Month']]\ndf5","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- droping the record of those customer who cut the call after knowning it is from bank(in the starting 5 sec).","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"df5['duration'] = df5['duration'].apply(lambda n:n/60).round(2)\ndf6 = df5.drop(df5[df5['duration']<5/60].index, axis = 0, inplace = False)\ndf6","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df7 = df6.drop(df6[df6['poutcome'] == 'other'].index, axis = 0, inplace = False)\ndf7","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- converting target column response to numerical for the better understanding of ML algorithm.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"df7['Response'] = df7['response']\ndf7['Response'] = pd.get_dummies(df7['Response'], drop_first = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Describeing the pdays column:\n > mean\n \n > median\n \n > mode","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"df['pdays'].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- mean = 40.197\n- median = -1\n- minimum = -1\nyes,the minimum and the median value both are same -1.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"-  Describe the pdays column : this time limiting to the relevant values of pdays. ","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"ddf = df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ddf.drop(ddf[ddf['pdays'] == -1].index, inplace = True)\nddf['pdays'].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- mean = 224.577\n- median = 194\n- minimum = 1\nyes,there is a difference in a median and the mean value you can see previous mean is '40' but now it is '224'same withw median it changes from '-1' to '194'.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"- A horizontal bar graph with the median values of balance for each education level value.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"> importing matplot and seaborn liberaries for the better visualisation of data","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ddf2 = df7.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ddf2['Edu'] = df7['education']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"Education = {\"primary\":1,\"secondary\":2,\"tertiary\":3}\nddf2['Edu'] = [Education[item] for item in ddf2['Edu']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"barG = ddf2[['Edu','balance']].groupby(\"Edu\").median().plot(kind='barh',legend = False,color = 'yellowgreen')\nbarG.set_ylabel(\"Education  \\n1:primary , 2:secondary ,3: tertiary\")\nbarG.set_xlabel(\"balance\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#ddf2.groupby('Edu').median()\n#if someone wants to se numbers.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> tertiary group has highest median value according to the graph.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"- boxplot on pdays column to see outliers in the data.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.boxplot(df7['pdays'])\nprint('outliers')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" > here we can see there is too many outliers point.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# EDA:  Exploratory Data Analysis ","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.catplot(\"response\",\"duration\",data = df7)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- by this chart we can say that when the duration of call is less ,the more is the chances of \"No\" as a response.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.catplot(\"response\",\"balance\",data = df7)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- by this chart we can say that the response of person was not depend on balance.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.catplot(\"response\",\"pdays\",data = df7)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- by this chart we can say that count of pday increases the chances of \"yes\" response is more.","execution_count":null},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"sns.catplot(\"response\",\"previous\",data = df7) \nsns.catplot(\"response\",\"campaign\",data = df7)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- by this chart we can say that there is no such relation between response and previous contact with a person.\nsame thing with campaign.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"g= sns.pairplot(df7)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- by this pairplot we can say that the target variable \"response\" is related with all these column but best with duration.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(30,30))\nax = sns.heatmap(df7.corr(), annot = True, linewidth = 3)\nax.tick_params(size = 10, labelsize = 10)\nplt.title(\"bank marketing\", fontsize = 25)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- by this heatmap we can say that response is highly correlated with duration column.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#  Machine Learning Algorithm","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"> droping column and data which are of no use.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"df7.drop(['marital'],axis=1, inplace=True)\ndf8 = df7.iloc[:, 0:7]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df7.drop(['month'],axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df7.drop(['response'],axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> creating dummies to convert categorical variable to numerical.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"df7 = pd.get_dummies(df7,drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df10=df7['Response'].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df7.drop(['Response'],axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df7 = pd.merge(df7, df10, left_index = True, right_index = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" **LOGISTIC REGRESSION**.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"> importing liberaries to apply algorithm on the data.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nLR = LogisticRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nsc = MinMaxScaler()\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"models = []\nmodels.append(('LR', LogisticRegression()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- splitting the data.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"df_train, df_test = train_test_split(df7, test_size=0.2, random_state=51)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train = df_train.drop('Response', axis=1)\ny_train = df_train['Response']\n \nprint('Shape of X = ', X_train.shape)\nprint('Shape of y = ', y_train.shape) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### RFE","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.feature_selection import RFE","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"LR.fit(X_train, y_train)\n\nrfe = RFE(LR, 10)  \nrfe = rfe.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"list(zip(X_train.columns,rfe.support_,rfe.ranking_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"col = X_train.columns[rfe.support_]\ncol","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train_rfe = X_train[col]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import statsmodels.api as sm  \nX_train_rfe = sm.add_constant(X_train_rfe)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"LR = sm.OLS(y_train,X_train_rfe).fit()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### VIF","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"from statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = pd.DataFrame()\nX = X_train_rfe\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import statsmodels.api as sm  \nX_train_lm = sm.add_constant(X_train_rfe)\nLR = sm.OLS(y_train,X_train_lm).fit()  \nprint(LR.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"array = df7.values\nX = array[:,0:-1]\nY = array[:,-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train, X_test, Y_train, Y_test= train_test_split(X, Y, test_size=0.2, random_state=51)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\nresult = []\nfor name, model in models:\n    kfold = KFold(n_splits=10, random_state=51)    \n    croresult = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')    \n    result.append(croresult)\n    output = \"%s: %f (%f)\" % (name, croresult.mean(), croresult.std())\n    print(output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"LR = LogisticRegression()\nLR.fit(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"predictions = LR.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Accuracy score-","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"print(accuracy_score(Y_test, predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport pylab as pl\ncm = confusion_matrix(Y_test, predictions)\npl.matshow(cm)\npl.title('Confusion matrix \\n')\npl.colorbar()\npl.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**RANDOM FOREST**","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"array = df7.values\nX = array[:,0:-1]\nY = array[:,-1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Train test split.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train, X_test, Y_train, Y_test= train_test_split(X, Y, test_size=0.2, random_state=51)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"models = []\nmodels.append(('RFC', RandomForestClassifier()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"result = []\nfor name, model in models:\n    kfold = KFold(n_splits=10, random_state=51)\n    croresults = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='neg_mean_squared_error')\n    result.append(croresults)\n    output = \"%s: %f (%f)\" % (name, croresults.mean(), croresults.std())\n    print(output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"RFC = RandomForestClassifier(n_estimators=50)\nRFC.fit(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"predictions = RFC.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Accuracy score-","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"print(accuracy_score(Y_test, predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport pylab as pl\ncm = confusion_matrix(Y_test, predictions)\npl.matshow(cm)\npl.title('Confusion matrix \\n')\npl.colorbar()\npl.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- The best metric is of randomforest but actually by these confusion matrix we can say that the dataset is highly unbalanced, with nearly all client actually decline to subscribe.This says that the accuracy score is biased, and further evaluation should be carried out to determine the accuracy of logistic regression model.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"- By all these evaluation we can say that the random forest model perform well on the dataset as the score is high.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"- By the evaluation we can say that the top feature is \"Duration\".","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}