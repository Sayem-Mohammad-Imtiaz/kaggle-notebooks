{"cells":[{"metadata":{},"cell_type":"markdown","source":"Origin: [Taido notebook](https://www.kaggle.com/taidopurason/vgg-based-architecture-0-70-test-acc)","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\n%matplotlib inline\nimport os\nimport gc\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reading in the data","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data_fer = pd.read_csv('../input/fer2013/fer2013.csv')\ndata_fer.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral\nidx_to_emotion_fer = {0:\"Angry\", 1:\"Disgust\", 2:\"Fear\", 3:\"Happy\", 4:\"Sad\", 5:\"Surprise\", 6:\"Neutral\"}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_fer_train, y_fer_train = np.rollaxis(data_fer[data_fer.Usage == \"Training\"][[\"pixels\", \"emotion\"]].values, -1)\nX_fer_train = np.array([np.fromstring(x, dtype=\"uint8\", sep=\" \") for x in X_fer_train]).reshape((-1, 48, 48))\ny_fer_train = y_fer_train.astype('int8')\n\nX_fer_test_public, y_fer_test_public = np.rollaxis(data_fer[data_fer.Usage == \"PublicTest\"][[\"pixels\", \"emotion\"]].values, -1)\nX_fer_test_public = np.array([np.fromstring(x, dtype=\"uint8\", sep=\" \") for x in X_fer_test_public]).reshape((-1, 48, 48))\ny_fer_test_public = y_fer_test_public.astype('int8')\n\nX_fer_test_private, y_fer_test_private = np.rollaxis(data_fer[data_fer.Usage == \"PrivateTest\"][[\"pixels\", \"emotion\"]].values, -1)\nX_fer_test_private = np.array([np.fromstring(x, dtype=\"uint8\", sep=\" \") for x in X_fer_test_private]).reshape((-1, 48, 48))\ny_fer_test_private = y_fer_test_private.astype('int8')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Flatten, Dense, Input, Dropout, Conv2D, MaxPool2D, BatchNormalization\nfrom tensorflow.keras.utils import to_categorical, plot_model\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data preprocessing and augmentation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE=128","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_fer_train.reshape((-1, 48, 48, 1))\nX_val = X_fer_test_public.reshape((-1, 48, 48, 1))\nX_test = X_fer_test_private.reshape((-1, 48, 48, 1))\ny_train = to_categorical(y_fer_train,7)\ny_val = to_categorical(y_fer_test_public,7)\ny_test = to_categorical(y_fer_test_private,7)\n\ntrain_datagen = ImageDataGenerator(\n    featurewise_center=False,\n    featurewise_std_normalization=False,\n    rotation_range=10,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    zoom_range=.1,\n    horizontal_flip=True,\n)\n\nval_datagen = ImageDataGenerator(\n    featurewise_center=False,\n    featurewise_std_normalization=False,\n)\n\ntrain_datagen.fit(X_train)\nval_datagen.fit(X_train)\n\ntrain_flow = train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE)\nval_flow = val_datagen.flow(X_val, y_val, batch_size=BATCH_SIZE, shuffle=False)\ntest_flow = val_datagen.flow(X_test, y_test, batch_size=1, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model training","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"DROPOUT_RATE = 0.3\nCONV_ACTIVATION = \"relu\"\n\nimg_in = Input(shape=(48,48,1))\n\nX = Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal', activation=CONV_ACTIVATION)(img_in)\nX = BatchNormalization()(X)\nX = Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal', activation=CONV_ACTIVATION)(X)\nX = BatchNormalization()(X)\n\nX = MaxPool2D((2, 2), strides=(2, 2), padding='same')(X)\nX = Dropout(DROPOUT_RATE)(X)\n\n\nX = Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal', activation=CONV_ACTIVATION)(X)\nX = BatchNormalization()(X)\nX = Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal', activation=CONV_ACTIVATION)(X)\nX = BatchNormalization()(X)\nX = Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal', activation=CONV_ACTIVATION)(X)\nX = BatchNormalization()(X)\n\nX = MaxPool2D((2, 2), strides=(2, 2), padding='same')(X)\nX = Dropout(DROPOUT_RATE)(X)\n\nX = Conv2D(256, (3, 3), padding='same', kernel_initializer='he_normal', activation=CONV_ACTIVATION)(X)\nX = BatchNormalization()(X)\nX = Conv2D(256, (3, 3), padding='same', kernel_initializer='he_normal', activation=CONV_ACTIVATION)(X)\nX = BatchNormalization()(X)\nX = Conv2D(256, (3, 3), padding='same', kernel_initializer='he_normal', activation=CONV_ACTIVATION)(X)\nX = BatchNormalization()(X)\nX = Conv2D(256, (3, 3), padding='same', kernel_initializer='he_normal', activation=CONV_ACTIVATION)(X)\nX = BatchNormalization()(X)\n\nX = MaxPool2D((2, 2), strides=(2, 2), padding='same')(X)\nX = Dropout(DROPOUT_RATE)(X)\n\nX = Conv2D(256, (3, 3), padding='same', kernel_initializer='he_normal', activation=CONV_ACTIVATION)(X)\nX = BatchNormalization()(X)\nX = Conv2D(256, (3, 3), padding='same', kernel_initializer='he_normal', activation=CONV_ACTIVATION)(X)\nX = BatchNormalization()(X)\nX = Conv2D(256, (3, 3), padding='same', kernel_initializer='he_normal', activation=CONV_ACTIVATION)(X)\nX = BatchNormalization()(X)\nX = Conv2D(256, (3, 3), padding='same', kernel_initializer='he_normal', activation=CONV_ACTIVATION)(X)\nX = BatchNormalization()(X)\nX = MaxPool2D((2, 2), strides=(2, 2), padding='same')(X)\nX = Dropout(DROPOUT_RATE)(X)\n\nX = Conv2D(512, (3, 3), padding='same', kernel_initializer='he_normal', activation=CONV_ACTIVATION)(X)\nX = BatchNormalization()(X)\nX = Conv2D(512, (3, 3), padding='same', kernel_initializer='he_normal', activation=CONV_ACTIVATION)(X)\nX = BatchNormalization()(X)\nX = Conv2D(512, (3, 3), padding='same', kernel_initializer='he_normal', activation=CONV_ACTIVATION)(X)\nX = BatchNormalization()(X)\nX = Conv2D(512, (3, 3), padding='same', kernel_initializer='he_normal', activation=CONV_ACTIVATION)(X)\nX = BatchNormalization()(X)\nX = MaxPool2D((2, 2), strides=(2, 2), padding='same')(X)\nX = Dropout(DROPOUT_RATE)(X)\n\nX = Flatten()(X)\nX = Dense(2048, activation=\"relu\")(X)\nX = Dropout(DROPOUT_RATE)(X)\nX = Dense(1024, activation=\"relu\")(X)\nX = Dropout(DROPOUT_RATE)(X)\nX = Dense(512, activation=\"relu\")(X)\nX = Dropout(DROPOUT_RATE)(X)\n\nout = Dense(7, activation='softmax')(X)\n\nmodel = Model(inputs=img_in, outputs=out)\nmodel.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['categorical_accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(model, show_shapes=True, show_layer_names=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_categorical_accuracy', mode='max', verbose=1, patience=20)\ncheckpoint_loss = ModelCheckpoint('best_loss_weights.h5', verbose=1, monitor='val_loss',save_best_only=True, mode='min')\ncheckpoint_acc = ModelCheckpoint('best_accuracy_weights.h5', verbose=1, monitor='val_categorical_accuracy',save_best_only=True, mode='max')\nlr_reduce = ReduceLROnPlateau(monitor='val_categorical_accuracy', mode='max', factor=0.5, patience=5, min_lr=1e-7, cooldown=1, verbose=1)\n\nhistory = model.fit_generator(\n        train_flow, \n        steps_per_epoch= X_train.shape[0] // BATCH_SIZE,\n        epochs=150, \n        validation_data=val_flow,\n        validation_steps = X_val.shape[0] // BATCH_SIZE,\n        callbacks=[early_stopping, checkpoint_acc, checkpoint_loss, lr_reduce]\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n\n# summarize history for accuracy\nplt.plot(history.history['categorical_accuracy'])\nplt.plot(history.history['val_categorical_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate_model(weights_path):\n    model.load_weights(weights_path)\n    y_pred = model.predict_generator(test_flow, steps=X_test.shape[0])\n    y_pred_cat = np.argmax(y_pred, axis=1)\n    y_true_cat = np.argmax(test_flow.y, axis=1)\n    report = classification_report(y_true_cat, y_pred_cat)\n    print(report)\n\n    conf = confusion_matrix(y_true_cat, y_pred_cat, normalize=\"true\")\n\n    labels = idx_to_emotion_fer.values()\n    _, ax = plt.subplots(figsize=(8, 6))\n    ax = sns.heatmap(conf, annot=True, cmap='YlGnBu', \n                     xticklabels=labels, \n                     yticklabels=labels)\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model with the best loss","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluate_model('best_loss_weights.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model with the best accuracy","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluate_model('best_accuracy_weights.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prune, quantize and fine-tune best model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -q tensorflow-model-optimization","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow_model_optimization as tfmot\n\nmodel.load_weights('best_accuracy_weights.h5')\n\nprune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n\n# Fine-tune prunned model on a couple of epochs,\n# because the model may loose some of the learned features\npruning_epochs = 2\nvalidation_split = X_val.shape[0] / X_train.shape[0]\n\nnum_images = X_train.shape[0] * (1 - validation_split)\nend_step = np.ceil(num_images / BATCH_SIZE).astype(np.int32) * epochs\n\npruning_params = {\n    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.5,\n                                                             final_sparsity=0.8,\n                                                             begin_step=0,\n                                                             end_step=end_step)\n}\n\nmodel_for_pruning = prune_low_magnitude(model, **pruning_params)\n\nmodel_for_pruning.compile(loss='categorical_crossentropy', \n                          optimizer=Adam(0.001), \n                          metrics=['categorical_accuracy'])\n\nprint(model_for_pruning.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fine tune pruning model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import tempfile\n\nlogdir = tempfile.mkdtemp()\n\ncallbacks = [\n    tfmot.sparsity.keras.UpdatePruningStep(),\n    tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n]\n\nmodel_for_pruning.fit_generator(\n    train_flow, \n    steps_per_epoch= X_train.shape[0] // BATCH_SIZE,\n    epochs=pruning_epochs,\n    validation_data=val_flow,\n    validation_steps = X_val.shape[0] // BATCH_SIZE,\n    callbacks=callbacks\n)\n\nmodel.save('pruned_model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluate_model('pruned_model.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Compress model 3x stripping pruning wrappers","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport tensorflow as tf\n\ncompressed_model = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n\ntf.keras.models.save_model(compressed_model, 'compressed_model.h5', include_optimizer=False)\n\npruned_model_size = os.path.getsize('compressed_model.h5')\npruned_model_size_mb = pruned_model_size // 1024 // 1024\n\nbest_acc_model_size = os.path.getsize('best_accuracy_weights.h5')\nbest_acc_model_size_mb = best_acc_model_size // 1024 // 1024\n\nimprovement = int((1 - pruned_model_size / best_acc_model_size) * 100)\n\nprint(f'Pruned model size is {pruned_model_size_mb} Mbytes')\nprint(f'Pre-pruning model size is {best_acc_model_size_mb} Mbytes')\nprint(f'Improvement compared to pre-pruning model is {improvement}%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Save compressed model graph and weights","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\n\ncompressed_model_json = compressed_model.to_json()\nwith open('compressed_model.json', 'w') as f:\n    f.write(compressed_model_json)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install tensorflowjs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflowjs as tfjs\n\ntfjs.converters.save_keras_model(compressed_model, 'compressed_model_js.json')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}