{"cells":[{"metadata":{"_uuid":"8072b87d9d9e99f6347a2c8500523fad5cc94c83","scrolled":true,"_cell_guid":"c5b10497-0187-4578-9660-97f7f923f308","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow.contrib.eager as tfe\ntf.enable_eager_execution()\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport os","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"1bcdd82c73351bb3c4ce7e95946aaacf7bc16b90","_cell_guid":"a86682df-f823-41db-9801-b34b3437f55d","trusted":true},"cell_type":"code","source":"print(os.listdir('/kaggle/input'))","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"b46ce63d329f15dd74c5eb62f7a7a6b62d53302e","_cell_guid":"4523d2a2-8b77-4747-9a14-1191280a76bd"},"cell_type":"markdown","source":"**Explore and Understand Data**"},{"metadata":{"_uuid":"fef50d00940eb6ca4cc13625daa68bdad1afd2d4","_cell_guid":"5cc1d85d-6a36-432c-8367-bf63d0856f81","trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/diabetes.csv')\ndata.head()","execution_count":3,"outputs":[]},{"metadata":{"_uuid":"580135af6c9f8daff5be2d70716a8c0fa3bb4bb6","scrolled":true,"_cell_guid":"13e1681f-7b70-42cf-8e1a-dad3541493ec","trusted":true},"cell_type":"code","source":"data.describe()","execution_count":4,"outputs":[]},{"metadata":{"_uuid":"fa63991475bd49b22afeb0060e3542240c1261aa","_cell_guid":"29b058f3-f79d-4fd6-a715-bc82c15fc406","trusted":true},"cell_type":"code","source":"data.head()","execution_count":5,"outputs":[]},{"metadata":{"_uuid":"7a568a6eeeefc04b6b2211bd17e9818faa73d73d","_cell_guid":"c76f01a4-ff32-4f56-917a-7b2ba5b15106","trusted":true},"cell_type":"code","source":"#import plotly.offline as py\n#py.init_notebook_mode(connected=True)\n#import plotly.graph_objs as go\n#import plotly.tools as tls\n#import cufflinks as cf\n#cf.set_config_file(offline=True, world_readable=True, theme='ggplot')\n\ndata['Outcome'].value_counts().plot(kind='bar')","execution_count":6,"outputs":[]},{"metadata":{"_uuid":"7f418e1b17101ab570523a2d0bf8190b92519a7a","_cell_guid":"86ce3063-960a-4c9c-8a7b-c4af8db2fbf3","trusted":true},"cell_type":"code","source":"data.hist(figsize=(12,12));","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"ac338188340f27a6af17b60c122b7f4a8f216495","_cell_guid":"39f5b12a-80cd-44ff-8639-18b65e3c8f6f","trusted":true},"cell_type":"code","source":"X = data[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin','BMI', 'DiabetesPedigreeFunction', 'Age']] \nY = data['Outcome']\n\nprint(X.columns)","execution_count":8,"outputs":[]},{"metadata":{"_uuid":"b25057c8ea944fff998ef0fa0a6ef9dcebe65f73","_cell_guid":"242132d7-7027-4841-a512-55f40ae02231"},"cell_type":"markdown","source":"***Now Tensor flow***"},{"metadata":{"_uuid":"9aa2a9a2200927bcefd9185cbc5e0d65289f3019","_cell_guid":"831fd346-631c-410e-b69d-0541194336e9","trusted":true},"cell_type":"code","source":"data.values.astype(float)[4]","execution_count":9,"outputs":[]},{"metadata":{"_uuid":"c86b94c593983583c4ede1a97b1c922f50143e07","_cell_guid":"9997da01-7551-47fa-89f4-d995debbd1a5","trusted":true},"cell_type":"code","source":"def parse_csv(line):\n    example_defaults = [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0]]  # sets field types\n    parsed_line = tf.decode_csv(line, example_defaults)\n    #print(parsed_line)\n    \n    # First 8 fields are features, combine into single tensor\n    features = tf.reshape(parsed_line[:-1], shape=(8,))\n    # Last field is the label\n    label = tf.reshape(parsed_line[-1], shape=())\n    return features, label\nprint('parsing...')","execution_count":10,"outputs":[]},{"metadata":{"_uuid":"d9e931920fbcd88f09851029ebe933452f27b965","scrolled":false,"_cell_guid":"95ef4c0d-e563-4a16-89b6-c5f04230dee8","trusted":true},"cell_type":"code","source":"train_dataset = tf.data.TextLineDataset('/kaggle/input/diabetes.csv')\ntrain_dataset = train_dataset.skip(1)             # skip the first header row\ntrain_dataset = train_dataset.map(parse_csv)      # parse each row\ntrain_dataset = train_dataset.shuffle(buffer_size=200)  # randomize\ntrain_dataset = train_dataset.batch(140)\n\n# View a single example entry from a batch\n#iterator = train_dataset.make_one_shot_iterator()\n#features, label = iterator.get_next()\n\nfeatures, label = tfe.Iterator(train_dataset).next()\nprint(\"example features:\", features[31])","execution_count":11,"outputs":[]},{"metadata":{"_uuid":"3238d6d5d57635c673f63def5a88fe51379d8e2e","_cell_guid":"56c70f77-5353-42ab-8657-12b85954e0f4","trusted":true},"cell_type":"code","source":"print(\"example label:\", label[31])","execution_count":12,"outputs":[]},{"metadata":{"_uuid":"879be51db3eb9f1137451b68a85e60340cfb3c78","_cell_guid":"abcdda75-bd81-46b3-bab0-126db345ccf2","trusted":true},"cell_type":"code","source":"model = tf.keras.Sequential([\n  tf.keras.layers.Dense(10, activation=\"relu\", input_shape=(8,)),  # input shape required\n  tf.keras.layers.Dense(15, activation=\"relu\"),\n  tf.keras.layers.Dense(2)\n])\n\nprint('Model creation')","execution_count":13,"outputs":[]},{"metadata":{"_uuid":"025f41cd57888b78659e8b8a84f268fdc4e4b046","_cell_guid":"a1b438be-eca4-402e-8c2c-58859b355707","trusted":true,"collapsed":true},"cell_type":"code","source":"def loss(model, x, y):\n    y_ = model(x)\n    return tf.losses.sparse_softmax_cross_entropy(labels=y, logits=y_)\n\ndef grad(model, inputs, targets):\n    with tfe.GradientTape() as tape:\n        loss_value = loss(model, inputs, targets)\n    return tape.gradient(loss_value, model.variables)","execution_count":14,"outputs":[]},{"metadata":{"_uuid":"6ffe30adbe50bb26af3f1955b9b1f541dbf83473","collapsed":true,"_cell_guid":"943e6adb-0785-46e8-8d6f-b11f181d9848","trusted":true},"cell_type":"code","source":"optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)","execution_count":15,"outputs":[]},{"metadata":{"_uuid":"5297bedb6822d9ef3b6e4be8a960d45bd269f944","_cell_guid":"9efdd8f3-88de-4b8e-9d57-ff1e1a80facb","trusted":true},"cell_type":"code","source":"# keep results for plotting\ntrain_loss_results = []\ntrain_accuracy_results = []\n\nnum_epochs = 201\n\nfor epoch in range(num_epochs):\n    epoch_loss_avg = tfe.metrics.Mean()\n    epoch_accuracy = tfe.metrics.Accuracy()\n\n      # Training loop - using batches\n    for x, y in tfe.Iterator(train_dataset):\n        # Optimize the model\n        grads = grad(model, x, y)\n        optimizer.apply_gradients(zip(grads, model.variables),\n                                  global_step=tf.train.get_or_create_global_step())\n\n        # Track progress\n        epoch_loss_avg(loss(model, x, y))  # add current batch loss\n        # compare predicted label to actual label\n        epoch_accuracy(tf.argmax(model(x), axis=1, output_type=tf.int32), y)\n\n        # end epoch\n    train_loss_results.append(epoch_loss_avg.result())\n    train_accuracy_results.append(epoch_accuracy.result())\n    \n    if epoch % 50 == 0:\n        print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch,\n                                                                    epoch_loss_avg.result(),\n                                                                    epoch_accuracy.result()))","execution_count":19,"outputs":[]},{"metadata":{"_uuid":"921a37e48fcada2f0f1ad07254694a86561a5c01","_cell_guid":"ef2e04b0-f555-4306-a261-b38bd5a53133","trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\nfig.suptitle('Training Metrics')\n\naxes[0].set_ylabel(\"Loss\", fontsize=14)\naxes[0].plot(train_loss_results)\n\naxes[1].set_ylabel(\"Accuracy\", fontsize=14)\naxes[1].set_xlabel(\"Epoch\", fontsize=14)\naxes[1].plot(train_accuracy_results)\n\nplt.show()","execution_count":17,"outputs":[]},{"metadata":{"_uuid":"b2d1756726ccd615ec9c2dfc8780e7b69e32a171","_cell_guid":"db8d66c4-ba3f-433f-9e51-6630fd7f0fb2","trusted":true},"cell_type":"code","source":"class_ids = [\"No\", \"Yes\"]\n\npredict_dataset = tf.convert_to_tensor([\n    [6.0   , 148.0   ,  72.0   ,  35.0   ,   0.0   ,  33.6  ,   0.627,    50.0   ,],\n    [61.0   , 18.0   ,  10.0   ,  65.0   ,   0.0   ,  12.6  ,   0.927,    55.0   ,],\n    [40.   , 110.0  ,  92.0   ,   0.0  ,   0.0  ,  37.6  ,   0.191, 30.0    ]\n    \n])\n\npredictions = model(predict_dataset)\n\nfor i, logits in enumerate(predictions):\n    class_idx = tf.argmax(logits).numpy()\n    name = class_ids[class_idx]\n    print(\"Example {} prediction: {}\".format(i, name))","execution_count":22,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}