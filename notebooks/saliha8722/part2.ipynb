{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv(os.path.join(dirname, filename))\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns = ['country', 'year', 'sex', 'age', 'suicides_no', 'population',\n       'suicides/100kpop', 'country_year', 'HDI_for_year',\n       'gdp_for_year_dollars', 'gdp_per_capita_dollars', 'generation']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#gdp_for_year_dollars sütunu virgül kullanılarak string olarak kaydedilmiş, bunu numerically olacak şekilde çeviriyorum\ndata['gdp_for_year_dollars'] = data['gdp_for_year_dollars'].str.replace(',','').astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#numerical sütunlar-> year, suicides_no, population, suicides/100k pop, HDI for year, gdp_for_year_dollars, gdp_per_capita_dollars \n#categorical-object sütunlar-> country, sex, age, generation (kümeleme/sınıflandırma)\n\n#country-year zaten varolan iki sütunun birleşimi olduğu için gereksiz, bu yüzden siliyorum.\ndel data['country_year']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['HDI_for_year'] = data['HDI_for_year'].fillna(data['HDI_for_year'].median())\ndata['HDI_for_year'].isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask = data.dtypes == np.object\ncategorical_cols = data.columns[mask]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask #categorical sütunları görebiliriz - (true)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Kaç tane ekstra sütun oluşturulacağının belirlenmesi:\nnum_ohc_cols = (data[categorical_cols]\n                .apply(lambda x: x.nunique())\n                .sort_values(ascending=False))\n\n\n# Yalnizca bir deger varsa kodlamaya gerek yoktur\nsmall_num_ohc_cols = num_ohc_cols.loc[num_ohc_cols>1]\n\n# one-hot sütun sayısı - kategori sayısı = 1\nsmall_num_ohc_cols -= 1\nsmall_num_ohc_cols.sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n\ndata_ohc = data.copy()\nle = LabelEncoder()\nohc = OneHotEncoder()\n\nfor col in num_ohc_cols.index:\n    \n    # object sütunları numerically çevirme\n    dat = le.fit_transform(data_ohc[col]).astype(np.int)\n    \n    # orjinal sütunu dataframe'den kaldıralım\n    data_ohc = data_ohc.drop(col, axis=1)\n\n    new_dat = ohc.fit_transform(dat.reshape(-1,1))\n    n_cols = new_dat.shape[1]\n    col_names = ['_'.join([col, str(x)]) for x in range(n_cols)]\n    new_df = pd.DataFrame(new_dat.toarray(), \n                          index=data_ohc.index, \n                          columns=col_names)\n    data_ohc = pd.concat([data_ohc, new_df], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_ohc.shape[1] - data.shape[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data.shape[1])\ndata = data.drop(num_ohc_cols.index, axis=1)\nprint(data.shape[1]) #ilgili sütun 11den 7ye düştü","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#for suicides_no\n\nfrom sklearn.model_selection import train_test_split\n\ny_col = 'suicides_no'\n\n# splitting one-hot kodlanmamış\nfeature_cols = [x for x in data.columns if x != y_col]\nX_data = data[feature_cols]\ny_data = data[y_col]\n\nX_train, X_test, y_train, y_test = train_test_split(X_data, y_data, \n                                                    test_size=0.3, random_state=42)\n# splitting one-hot kodlanmış\nfeature_cols = [x for x in data_ohc.columns if x != y_col]\nX_data_ohc = data_ohc[feature_cols]\ny_data_ohc = data_ohc[y_col]\n\nX_train_ohc, X_test_ohc, y_train_ohc, y_test_ohc = train_test_split(X_data_ohc, y_data_ohc, \n                                                    test_size=0.3, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(X_train_ohc.index == X_train.index).all()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\nLR = LinearRegression()\nerror_df = list()\n\n# one-hot kodlanmamış veriler\nLR = LR.fit(X_train, y_train)\ny_train_pred = LR.predict(X_train)\ny_test_pred = LR.predict(X_test)\n\nerror_df.append(pd.Series({'train': mean_squared_error(y_train, y_train_pred),\n                           'test' : mean_squared_error(y_test,  y_test_pred)},\n                           name='no enc'))\n# one-hot kodlanmış veriler\nLR = LR.fit(X_train_ohc, y_train_ohc)\ny_train_ohc_pred = LR.predict(X_train_ohc)\ny_test_ohc_pred = LR.predict(X_test_ohc)\n\nerror_df.append(pd.Series({'train': mean_squared_error(y_train_ohc, y_train_ohc_pred),\n                           'test' : mean_squared_error(y_test_ohc,  y_test_ohc_pred)},\n                          name='one-hot enc'))\nerror_df = pd.concat(error_df, axis=1)\nerror_df\n#One-hot kodlanmış model verilere daha fazla uyacağı için, one-hot kodlanmamış modelde daha fazla error rate aldık. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Kopyalama uyarilariyla ayari sessize alma\npd.options.mode.chained_assignment = None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\n\nscalers = {'standard': StandardScaler(),\n           'minmax': MinMaxScaler(),\n           'maxabs': MaxAbsScaler()}\n\ntraining_test_sets = {\n    'not_encoded': (X_train, y_train, X_test, y_test),\n    'one_hot_encoded': (X_train_ohc, y_train_ohc, X_test_ohc, y_test_ohc)}\nmask = X_train.dtypes == np.float\nfloat_columns = X_train.columns[mask]\n\nLR = LinearRegression()\n\nerrors = {}\nfor encoding_label, (_X_train, _y_train, _X_test, _y_test) in training_test_sets.items():\n    for scaler_label, scaler in scalers.items():\n        trainingset = _X_train.copy()  # kopyalayin cunku bunu bir kereden fazla olceklemek istemiyoruz.\n        testset = _X_test.copy()\n        trainingset[float_columns] = scaler.fit_transform(trainingset[float_columns])\n        testset[float_columns] = scaler.transform(testset[float_columns])\n        LR.fit(trainingset, _y_train)\n        predictions = LR.predict(testset)\n        key = encoding_label + ' - ' + scaler_label + 'scaling'\n        errors[key] = mean_squared_error(_y_test, predictions)\n\nerrors = pd.Series(errors)\nprint(errors.to_string())\nprint('-' * 80)\nfor key, error_val in errors.items():\n    print(key, error_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nsns.set_context('talk')\nsns.set_style('whitegrid')\nsns.set_palette('dark')\n\nax = plt.axes()\nax.scatter(y_test, y_test_pred, alpha=.5)\n\nax.set(xlabel='Actual', \n       ylabel='Predicted',\n       title='Number of Suicides Predictions using Linear Regression');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#for HDI_for_year\n\nfrom sklearn.model_selection import train_test_split\n\ny_col = 'HDI_for_year'\n\n# splitting one-hot kodlanmamış\nfeature_cols = [x for x in data.columns if x != y_col]\nX_data = data[feature_cols]\ny_data = data[y_col]\n\nX_train, X_test, y_train, y_test = train_test_split(X_data, y_data, \n                                                    test_size=0.3, random_state=42)\n# splitting one-hot kodlanmış\nfeature_cols = [x for x in data_ohc.columns if x != y_col]\nX_data_ohc = data_ohc[feature_cols]\ny_data_ohc = data_ohc[y_col]\n\nX_train_ohc, X_test_ohc, y_train_ohc, y_test_ohc = train_test_split(X_data_ohc, y_data_ohc, \n                                                    test_size=0.3, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(X_train_ohc.index == X_train.index).all() #indexlerde bir değişim olmadı","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\nLR = LinearRegression()\n\n# Hata degerleri icin depolama\nerror_df = list()\n\n# one-hot kodlanmamis veriler\nLR = LR.fit(X_train, y_train)\ny_train_pred = LR.predict(X_train)\ny_test_pred = LR.predict(X_test)\n\nerror_df.append(pd.Series({'train': mean_squared_error(y_train, y_train_pred),\n                           'test' : mean_squared_error(y_test,  y_test_pred)},\n                           name='no enc'))\n\n# one-hot kodlanmis veriler\nLR = LR.fit(X_train_ohc, y_train_ohc)\ny_train_ohc_pred = LR.predict(X_train_ohc)\ny_test_ohc_pred = LR.predict(X_test_ohc)\n\nerror_df.append(pd.Series({'train': mean_squared_error(y_train_ohc, y_train_ohc_pred),\n                           'test' : mean_squared_error(y_test_ohc,  y_test_ohc_pred)},\n                          name='one-hot enc'))\n\n# Sonuclari bir araya getirelim\nerror_df = pd.concat(error_df, axis=1)\nerror_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.options.mode.chained_assignment = None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\n\nscalers = {'standard': StandardScaler(),\n           'minmax': MinMaxScaler(),\n           'maxabs': MaxAbsScaler()}\n\ntraining_test_sets = {\n    'not_encoded': (X_train, y_train, X_test, y_test),\n    'one_hot_encoded': (X_train_ohc, y_train_ohc, X_test_ohc, y_test_ohc)}\n\n# Onceden olceklendirdigimiz bir seyi olceklendirmemek icin \n# float sutunlarin listesini ve float verilerini alin \n# Orijinal verileri her seferinde ölceklememiz gerekiyor\nmask = X_train.dtypes == np.float\nfloat_columns = X_train.columns[mask]\n\n# initialize model\nLR = LinearRegression()\n\n# tum olası kombinasyonlari tekrarlayin ve hatalari alin\nerrors = {}\nfor encoding_label, (_X_train, _y_train, _X_test, _y_test) in training_test_sets.items():\n    for scaler_label, scaler in scalers.items():\n        trainingset = _X_train.copy()  # kopyalayin cunku bunu bir kereden fazla olceklemek istemiyoruz.\n        testset = _X_test.copy()\n        trainingset[float_columns] = scaler.fit_transform(trainingset[float_columns])\n        testset[float_columns] = scaler.transform(testset[float_columns])\n        LR.fit(trainingset, _y_train)\n        predictions = LR.predict(testset)\n        key = encoding_label + ' - ' + scaler_label + 'scaling'\n        errors[key] = mean_squared_error(_y_test, predictions)\n\nerrors = pd.Series(errors)\nprint(errors.to_string())\nprint('-' * 80)\nfor key, error_val in errors.items():\n    print(key, error_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n\nsns.set_context('talk')\nsns.set_style('whitegrid')\nsns.set_palette('dark')\n\nax = plt.axes()\n#  y_test, y_test_pred kullanilacak\nax.scatter(y_test, y_test_pred, alpha=.5)\n\nax.set(xlabel='Actual', \n       ylabel='Predicted',\n       title='HDI_for_year Predictions using Linear Regression');","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}