{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Get Data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/amazon-music-reviews/Musical_instruments_reviews.csv')\ndf_copy = df.copy()\ndf.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.reviewText   = df.reviewText + df.summary\ndf.reviewTime   = df.reviewTime.apply(lambda string: [int(i) for i in string.replace(',','').split()])\ndf['month']     = df.reviewTime.apply(lambda x: x[0])\ndf['date']      = df.reviewTime.apply(lambda x: x[1])\ndf['year']      = df.reviewTime.apply(lambda x: x[2])\ndf.drop(columns = ['asin','helpful','summary','unixReviewTime','reviewTime'],axis=0,inplace=True)\n\ndf.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Cleaning Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"import string\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import wordnet,WordNetLemmatizer\n\ndef remove_punctuation(the_string):\n    for c in string.punctuation:\n        the_string = str(the_string).replace(c,'')\n    return the_string\n\ndef remove_digits(the_string):\n    for c in range(10):        \n        the_string = str(the_string).replace(str(c),'')\n    return the_string\n\ndf.reviewText = df.reviewText.apply(remove_punctuation).apply(remove_digits)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_stopwords(sentence):\n    stopword_list = stopwords.words('english')\n    stopword_list.append(['www','http'])\n    new_sentence = ''\n    for word in sentence.split():\n        if word not in stopword_list:\n            new_sentence += ' '+word.lower()\n    return new_sentence[1:]\n\ndf.reviewText = df.reviewText.apply(remove_stopwords)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import wordnet\n\nwnl = WordNetLemmatizer()\n\ndef do_lemmatize(sentence):\n      \n    _list = nltk.pos_tag(str(sentence).split())   \n    \n    the_sentence = ''\n    for _tuple in _list:        \n        wrd    = _tuple[0]                      \n        if _tuple[1][0] in ['N','V','J','R']:\n            if _tuple[1][0]=='N':\n                pos_tg = 'n'\n            elif _tuple[1][0]=='V':\n                pos_tg = 'v'\n            elif _tuple[1][0]=='J':\n                pos_tg = 'a'\n            else:\n                pos_tg = 'r'\n        else:\n            pos_tg = 'n'\n            \n        the_sentence+=' ' + wnl.lemmatize(wrd,pos_tg)\n        \n    return the_sentence[1:]\n\ndf.reviewText = df.reviewText.apply(do_lemmatize)\n\ndel wnl\n\ndf.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.stem import SnowballStemmer\n\nsbs = SnowballStemmer('english')\n\ndef stem_tokens(sentence):\n    the_sentence = ''\n    for word in str(sentence).split():\n        the_sentence+=' '+sbs.stem(word)\n    return the_sentence\n\ndf.reviewText = df.reviewText.apply(stem_tokens)\n\ndel sbs\n\ndf.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['n_words']      = df.reviewText.apply(lambda x:len(x))\ndf['unique_words'] = df.reviewText.apply(lambda string:len(set(str(string).split())))\n\ndf.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from textblob import TextBlob\n\ndef get_sentiment(string):\n    return list(TextBlob(string).sentiment)\n\ndf['tb_sentiment'] = df.reviewText.apply(get_sentiment)\ndf['polarity']     = df.tb_sentiment.apply(lambda x:x[0])\ndf['subjectivity'] = df.tb_sentiment.apply(lambda x:x[1])\ndf.drop(columns=['tb_sentiment'],axis=0,inplace=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Adding Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\nsentence_list = []\nfor index,row in df.iterrows():    \n    sentence_list.append(row.reviewText)    \n        \nV = TfidfVectorizer()\n_tuple   = V.fit_transform(sentence_list)\ncol_name = V.get_feature_names()  \n\ndel sentence_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = pd.DataFrame(_tuple)\ntemp.columns=['dat']\n\ndef get_tfidf_disp(temp):\n    array = list([])\n    for i in range(temp.shape[0]):\n        sentence_list = str(temp.dat[i]).split('\\n')\n        for sentence in sentence_list:\n            word_list = sentence.split('\\t')        \n            \n            word_list[0] = word_list[0].replace(',','').replace('(','').replace(')','').replace(':','')            \n            \n            _temp = word_list[0].split()\n            \n            if len(_temp)>0:\n                word_id = word_list[0].split()[1]                                \n                value = word_list[1]\n                array.append([i,word_id,float(value)])\n                                        \n    array = pd.DataFrame(array)\n    array.columns = ['doc','word_id','value']\n    array.sort_values(by='value',ascending=False,inplace=True)\n    return array\n\ntemp_array = get_tfidf_disp(temp)\ndel temp\n\ntemp_array.head(3)              ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Top N Words"},{"metadata":{"trusted":true},"cell_type":"code","source":"#temp_array = temp_array[:200]\nselect_col = list(set([col_name[int(word_id)] for word_id in temp_array.word_id]))\n\ndel temp_array\n\nprint(*select_col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"array   = _tuple.toarray()\ntemp_df = pd.DataFrame(array)\ntemp_df.columns = col_name\n\ndel array\n\ntemp_df = temp_df[select_col]\ntemp_df.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in temp_df.columns:\n    df[col] = temp_df[col]\ndf.drop(columns=['reviewText'],axis=0,inplace=True)    \n\ndel temp_df\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Training Functions "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n\ndef give_prediction(temp_df):\n   \n    y = [1 if i==5 else 0 for i in temp_df.overall]        \n    X = temp_df.drop(columns='overall',axis=0)\n    \n    # Train-Test Split\n    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=7)\n    print('sum of y-test = ',sum(y_test),len(y_test))\n\n    # Drop Unnecessary Columns before Training\n    X_train_id = X_train[['reviewerID','reviewerName']]\n    X_train.drop(columns=['reviewerID','reviewerName'],axis=0,inplace=True)\n\n    X_test_id = X_test[['reviewerID','reviewerName']]\n    X_test.drop(columns=['reviewerID','reviewerName'],axis=0,inplace=True)\n    \n    # Model Development\n    lr = LogisticRegression(max_iter=100, solver='liblinear',random_state=7)\n    lr.fit(X_train,y_train)\n    \n    # Get Predictions  \n    y_pred = lr.predict(X_test) \n    y_pred_proba = lr.predict_proba(X_test)\n    X_test_id['y_test']       = y_test\n    X_test_id['y_pred']       = y_pred\n    X_test_id['y_pred_proba'] = [r[0] for r in y_pred_proba]\n  \n    return X_test_id,lr.coef_\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Check Appropiate Dataset "},{"metadata":{},"cell_type":"markdown","source":"#### Orginal Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_345 = df.copy()\nresult_df,coef = give_prediction(df_345)\n\nprint('Accuracy Score = '        ,accuracy_score(result_df.y_test,result_df.y_pred))\nprint('\\nConfusion Matrix\\n'     ,confusion_matrix(result_df.y_test,result_df.y_pred))\nprint('\\nClassification Report\\n',classification_report(result_df.y_test,result_df.y_pred))\n\nresult_df.y_pred.hist(bins=2)\n\ndel df_345,result_df,coef","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Eliminating Target with Low Levels"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_345 = df[df.overall>2]\nresult_df,coef_ = give_prediction(df_345)\n\nprint('Accuracy Score = '        ,accuracy_score(result_df.y_test,result_df.y_pred))\nprint('\\nConfusion Matrix\\n'     ,confusion_matrix(result_df.y_test,result_df.y_pred))\nprint('\\nClassification Report\\n',classification_report(result_df.y_test,result_df.y_pred))\n\nresult_df.y_pred.hist(bins=2)\n\ndel df_345,result_df,coef_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_45 = df[df.overall>3]\nresult_df,coef_ = give_prediction(df_45)\n\nprint('Accuracy Score = '        ,accuracy_score(result_df.y_test,result_df.y_pred))\nprint('\\nConfusion Matrix\\n'     ,confusion_matrix(result_df.y_test,result_df.y_pred))\nprint('\\nClassification Report\\n',classification_report(result_df.y_test,result_df.y_pred))\n\nresult_df.y_pred.hist(bins=2)\n\ndel df_45,result_df,coef_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Drop Some Columns based on Knowledge"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_word = df.copy()\ndf_word['nu_words'] = df_word.n_words - df_word.unique_words\ndf_word.drop(columns=['unique_words','month','date','year'],axis=0,inplace=True)\n\nresult_df,coef_ = give_prediction(df_word)\n\nprint('Accuracy Score = '        ,accuracy_score(result_df.y_test,result_df.y_pred))\nprint('\\nConfusion Matrix\\n'     ,confusion_matrix(result_df.y_test,result_df.y_pred))\nprint('\\nClassification Report\\n',classification_report(result_df.y_test,result_df.y_pred))\n\nresult_df.y_pred.hist(bins=2)\n\ndel df_word,result_df,coef_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"UnderSampling"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_us = df[df.overall==5][:5000]\ndf_us = df_us.append(df[df.overall<5])\n\nresult_df,coef_ = give_prediction(df_us)\n\nprint('Accuracy Score = '        ,accuracy_score(result_df.y_test,result_df.y_pred))\nprint('\\nConfusion Matrix\\n'     ,confusion_matrix(result_df.y_test,result_df.y_pred))\nprint('\\nClassification Report\\n',classification_report(result_df.y_test,result_df.y_pred))\n\nresult_df.y_pred.hist(bins=2)\n\ndel df_us,result_df,coef_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"OverSampling"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_os = df.copy()\nfor i in range(1):\n    df_os = df.append(df[df.overall<2])\n\nresult_df,coef_ = give_prediction(df_os)\n\nprint('Accuracy Score = '        ,accuracy_score(result_df.y_test,result_df.y_pred))\nprint('\\nConfusion Matrix\\n'     ,confusion_matrix(result_df.y_test,result_df.y_pred))\nprint('\\nClassification Report\\n',classification_report(result_df.y_test,result_df.y_pred))\n\nresult_df.y_pred.hist(bins=2)\n\ndel df_os,result_df,coef_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Combination of Above Methods (OverSampling + Column Elimination)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_cb = df.copy()\n\n# Under Sampling\ndf_cb = df[df.overall==5][:]\ndf_cb = df_cb.append(df[df.overall<5])\n\n# Feature Engineering\ndf_cb['nu_words'] = df_cb.n_words - df_cb.unique_words\ndf_cb.drop(columns=['unique_words','month','date','year'],axis=0,inplace=True)\n\n# Over Sampling\nfor i in range(0):\n    df_cb = df_cb.append(df_cb[df_cb.overall<2])\n    \n# Predictive Analysis    \nresult_df,coef_ = give_prediction(df_cb)\n\nprint('Accuracy Score = '        ,accuracy_score(result_df.y_test,result_df.y_pred))\nprint('\\nConfusion Matrix\\n'     ,confusion_matrix(result_df.y_test,result_df.y_pred))\nprint('\\nClassification Report\\n',classification_report(result_df.y_test,result_df.y_pred))\n\nresult_df.y_pred.hist(bins=2)\n\ndel df_cb,result_df,coef_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}