{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#-------------------------IMPORT LIBRARIES-------------------\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport plotly as py\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler \nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import SGDClassifier\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\nfrom sklearn.model_selection import cross_val_score\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#--------------------------------reading and analyzing data-----------------------------\n\ndataset = pd.read_csv('../input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv')\n\nprint(dataset.info())\n\nprint('-----------------------------------\\n')\n\nprint(dataset.isnull().sum())\n#201 null values in 'bmi'\n\nprint('-----------------------------------\\n')\n\n#replacing null values of 'bmi' with mean\ndataset.bmi.replace(to_replace=np.nan, value=dataset.bmi.mean(), inplace=True)\n\nprint(dataset.isnull().sum())\n#no null values \n\nprint('-----------------------------------\\n')\n\n#describing the dataset\nprint(dataset.describe())\n\nprint('-----------------------------------\\n')\n\nprint(dataset.stroke.value_counts())\n#imbalanced\n\nprint('-----------------------------------\\n')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-------------------------------removing outliers and redundant columns----------------------------\n\n#redundant\ndataset.drop(labels='id', axis=1, inplace=True)\n\n#----------outliers for bmi----------\nsns.boxplot(data=dataset, y='bmi')\nplt.title('Boxplot of bmi')\nplt.show()\n\nfor i in np.arange(0, 1.1, 0.1):\n    print(f'The {99+i}th percentile of BMI is: {np.percentile(dataset.bmi, 99+i)}')\n    \n#99.9% of people have BMI less than 65\ndataset.drop(dataset[dataset.bmi>65].index, inplace=True)\n\n#-----------outliers for avg glucose level----------\nsns.boxplot(data=dataset, y='avg_glucose_level')\nplt.title('Boxplot of avg_glucose_level')\nplt.show()\n\nfor i in np.arange(0, 1.1, 0.1):\n    print(f'The {99+i}th percentile of Average Glucose Level is: {np.percentile(dataset.avg_glucose_level, 99+i)}')\n    \n#close values\n    \n#----------outliers for age-------------\nsns.boxplot(data=dataset, y='age')\nplt.title('Boxplot of age')\nplt.show()\n\n#no outliers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#----------------determining the types of columns----------------------\ncategorical = (dataset.dtypes == \"object\")\ncategorical_list = list(categorical[categorical].index)\n\nprint(\"Categorical variables:\")\nprint(categorical_list)\n\nprint('-----------------------------------\\n')\n\nnumerical = (dataset.dtypes == \"float64\")\nnumerical_list = list(numerical[numerical].index)\n\nprint(\"Numerical variables:\")\nprint(numerical_list)\n\nprint('-----------------------------------\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#----------------DATA COPY FOR VISUALIZATION--------------------\n\nStrokeAnalysis = dataset.copy()\nStrokeAnalysis['hypertension'] = StrokeAnalysis['hypertension'].apply(lambda x : 'Hypertension' if x == 1 else 'No Hypertension') \nStrokeAnalysis['heart_disease'] = StrokeAnalysis['heart_disease'].apply(lambda x : 'Heart Disease' if x == 1 else 'No Heart Disease') \nStrokeAnalysis['stroke'] = StrokeAnalysis['stroke'].apply(lambda x : 'Suffered Stroke' if x == 1 else 'Never Suffered Stroke') \nStrokeAnalysis['ever_married'] = StrokeAnalysis['ever_married'].apply(lambda x : 'Married' if x == 'Yes' else 'Unmarried') \n\n\n#NO HYPERTENSION VS HYPERTENSION & NO HEART DISEASE VS HEART DISEASE\n\nplt.figure(figsize=(10,6))\nplacement = 1\n\nfor i in ['hypertension','heart_disease']:\n    label = []\n    value = []\n    for j in range(len(StrokeAnalysis[i].value_counts().index)):\n        label.append(StrokeAnalysis[i].value_counts().index[j])\n        value.append(StrokeAnalysis[i].value_counts()[j])\n        \n    plt.subplot(1,2,placement)    \n    explode = (0.1, 0.2)\n    plt.pie(value, labels = label,autopct='%1.2f%%',colors=['darkslategrey','paleturquoise'],shadow=True,explode=explode)\n    plt.title(\"{} VS {}\".format(label[0],label[1]))\n    placement += 1\n    \nplt.tight_layout(pad=0.4)  \n\n#The propotion of patients with hypertension and heart diseases are very low.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#MARRIED VS UNMARIED & URBAN VS RURAL\n\nplt.figure(figsize=(10,6))\nplacement = 1\n\nfor i in ['ever_married','Residence_type']:\n    label = []\n    value = []\n    for j in range(len(StrokeAnalysis[i].value_counts().index)):\n        label.append(StrokeAnalysis[i].value_counts().index[j])\n        value.append(StrokeAnalysis[i].value_counts()[j])\n        \n    plt.subplot(1,2,placement)    \n    explode = (0.1, 0.2)\n    plt.pie(value, labels = label,autopct='%1.2f%%',colors=['darkslategrey','paleturquoise'],shadow=True,explode=explode)\n    plt.title(\"{} VS {}\".format(label[0],label[1]))\n    placement += 1\n    \nplt.tight_layout(pad=0.4) \n\n#We see that the number of patients married are much more. The proportion of rural and urban patients are almost equal.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#WORK TYPE\n\nplt.subplot(1,1,1)  \nlabel = StrokeAnalysis['work_type'].value_counts().index\nvalue = StrokeAnalysis['work_type'].value_counts().values\nplt.pie(value, labels = label,autopct='%1.2f%%',colors=['deepskyblue','steelblue','lightslategrey','skyblue','crimson'],shadow=True,explode=None)\nplt.title(\"Work Types\")\n\nplt.tight_layout(pad=0.4) \n\n#--------------------visualization of the distribution of numerical columns------------------\n\nfor n in numerical_list:\n     plt.figure(figsize = (9,3))\n     plt.hist(dataset[n], bins = 50)\n     plt.xlabel(n)\n     plt.ylabel(\"Frequency\")\n     plt.title(\"{} Distribution with Histogram\".format(n))\n     plt.show()\n\n#-----------------------------visualization of stroke vs other columns----------------------------\n\nfor i in categorical_list:\n    ax = sns.countplot(data=dataset, x=i,hue=\"stroke\")\n    plt.title(\"Effect of {} on Stroke\".format(i))\n    \n    for p in ax.patches:\n        ax.annotate(f'{round(p.get_height()/len(dataset)*100,2)} %', xy=(p.get_x() + p.get_width() / 2,  \n            p.get_height()), ha='center', va='center', size=13, xytext=(0, 8), textcoords='offset points')\n    plt.show()\n\n#----------------------------------heatmap correlation----------------------------------\n\nplt.figure(figsize = (8,6))  \nsns.heatmap(dataset.corr(),annot = True,cmap=\"Purples\")\nplt.show()\n\n\nx = dataset.iloc[:,:-1].values\ny = dataset.iloc[:, -1].values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-------------------ENCODING------------------------\n\n#one-hot encoding of categorical data (gender, work_type, smoking status)\n\nct = ColumnTransformer(transformers= [('encoder', OneHotEncoder(), [0,5,9])], remainder= 'passthrough')\nx = np.array(ct.fit_transform(x))\n\n\n#label encoding of binary columns (ever_married, residence_type)\n\nle = LabelEncoder()\nx[:, 15] = le.fit_transform(x[:, 15])\nx[:, 16] = le.fit_transform(x[:, 16])\n\nprint('Shape of X: ', x.shape)\nprint('Shape of Y: ', y.shape)\n\nprint('-----------------------------------\\n')\n\n#--------------------------------splitting the dataset into the training set and test set-------------------------\n\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, stratify=y)\n\nprint(\"x_train shape: \",x_train.shape)\nprint(\"x_test shape: \",x_test.shape)\nprint(\"y_train shape: \",y_train.shape)\nprint(\"y_test shape: \",y_test.shape)\n\nprint('-----------------------------------\\n')\n\n#----------------SCALING----------------\n\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#--------------------MODEL SELECTION-------------------------\n\nmodels = [['Logistic Regreesion', LogisticRegression(random_state=0)],\n          ['SGD Classifier', SGDClassifier(loss='log', n_jobs=-1, random_state=0)],\n          ['SVM', SVC(random_state=0)],\n          ['KNeighbors Classifier', KNeighborsClassifier()],\n          ['GaussianNB', GaussianNB()],\n          ['BernoulliNB', BernoulliNB()],\n          ['Decision Tree Classifier', DecisionTreeClassifier(random_state=0)],\n          ['Random Forest Classifier', RandomForestClassifier(random_state=0)]]\n\nlist1= []\n\nfor m in range(len(models)):\n    \n    list2= []\n    model = models[m][1]\n    model.fit(x_train, y_train)\n    y_pred = model.predict(x_test)\n    \n    #Confusion Matrix\n    cm = confusion_matrix(y_test, y_pred)  \n    #K-Fold Validation\n    accuracies = cross_val_score(estimator = model, X = x_train, y = y_train, cv = 10) \n    #Precision Score\n    precision = precision_score(y_test, y_pred)  \n    #Recall Score\n    recall = recall_score(y_test, y_pred) \n    #F1 Score\n    f1 = f1_score(y_test, y_pred)  \n    \n    print(models[m][0],':',\"\\n\")\n    print(\"Confusion matrix:\\n \")\n    print(cm,\"\\n\")\n    print('Accuracy Score: ',accuracy_score(y_test, y_pred))\n    print(\"\\nK-Fold Validation Mean Accuracy: {:.2f} %\".format(accuracies.mean()*100),\"\\n\")\n    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100),\"\\n\")\n    print('Precision: {:.2f}'.format(precision),\"\\n\")\n    print('Recall: {:.2f}'.format(recall),\"\\n\")\n    print('F1: {:.2f}'.format(f1),\"\\n\")\n    print('-----------------------------------\\n')\n    list2.append(models[m][0])\n    list2.append((accuracy_score(y_test, y_pred))*100) \n    list2.append(accuracies.mean()*100)\n    list2.append(accuracies.std()*100)\n    list2.append(precision)\n    list2.append(recall)\n    list2.append(f1)\n    list1.append(list2)\n\n\ndf = pd.DataFrame(list1, columns= ['Model', 'Accuracy Score', 'K-Fold Mean Accuracy', 'Std. Deviation', 'Precision', 'Recall', 'F1'])\ndf.sort_values(by= ['Accuracy Score', 'K-Fold Mean Accuracy'], inplace= True, ascending= False)\nprint(df)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dst_st_gen = dataset.query('gender != \"Other\"').groupby(['gender', 'stroke']).agg({'stroke': 'count'}).rename(columns = {'stroke': 'count'}).reset_index()\ndst_st_gen.iloc[[0, 2], 1] = \"didn't have a stroke\"\ndst_st_gen.iloc[[1, 3], 1] = \"had a stroke\"\n\nfig = px.sunburst(dst_st_gen, path = ['gender', 'stroke'], values = 'count', color = 'gender',\n                 color_discrete_map = {'Female': '#e381bc', 'Male': '#81a8e3'}, width = 700, height = 700)\n\nfig.update_layout(annotations = [dict(text = 'Distribution of stroke by gender', \n                                      x = 0.5, y = 1.1, font_size = 22, showarrow = False, \n                                      font_family = 'Arial Black',\n                                      font_color = 'black')])\n\nfig.update_traces(textinfo = 'label + percent parent')\n                  \nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}