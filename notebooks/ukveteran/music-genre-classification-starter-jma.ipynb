{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import librosa\nimport librosa.display\nimport json\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom matplotlib.pyplot import specgram\nimport pandas as pd\nimport seaborn as sns\nimport glob \nimport os\nfrom tqdm import tqdm\nimport pickle\nimport IPython.display as ipd ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fname = '/kaggle/input/gtzan-dataset-music-genre-classification/Data/genres_original/disco/disco.00007.wav'  \ndata, sampling_rate = librosa.load(fname)\nplt.figure(figsize=(15, 5))\nlibrosa.display.waveplot(data, sr=sampling_rate)\n\n# Paly it again to refresh our memory\nipd.Audio(data, rate=sampling_rate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_size = 60000\nBATCH_SIZE = 8\ntest_size = 10000\nepochs = 20\n# set the dimensionality of the latent space to a plane for visualization later\nlatent_dim = 2\nnum_examples_to_generate = 2\n\nBASE_PATH = '../input/gtzan-dataset-music-genre-classification/Data/genres_original'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def DatasetLoader(class_):\n    music_list = np.array(sorted(os.listdir(BASE_PATH+'/'+class_)))\n    train_music_1 = list(music_list[[0,52,19,39,71,12,75,85,3,45,24,46,88]]) #99,10,66,76,41\n    train_music_2 = list(music_list[[4,43,56,55,45,31,11,13,70,37,21,78]]) #65,32,53,22,19,80,89,\n    TrackSet_1 = [(BASE_PATH)+'/'+class_+'/%s'%(x) for x in train_music_1]\n    TrackSet_2 = [(BASE_PATH)+'/'+class_+'/%s'%(x) for x in train_music_2]\n\n    return TrackSet_1, TrackSet_2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load(file_):\n    data_, sampling_rate = librosa.load(file_,sr=3000, offset=0.0, duration=30)\n    data_ = data_.reshape(1,90001)\n    return data_\nmap_data = lambda filename: tf.compat.v1.py_func(load, [filename], [tf.float32])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TrackSet_1, TrackSet_2 = DatasetLoader('disco')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample = TrackSet_1[1]\nsample_, sampling_rate = librosa.load(sample,sr=3000, offset=0.0, duration=30)\nipd.Audio(sample_,rate=3000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import librosa.display\nplt.figure(figsize=(18,15))\nfor i in range(4):\n    plt.subplot(4, 4, i + 1)\n    j = load(TrackSet_1[i])\n    librosa.display.waveplot(j[0], sr=3000)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}