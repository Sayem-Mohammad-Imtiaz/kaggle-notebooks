{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import the libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2 as cv\nfrom tqdm import tqdm\nimport random\nimport os\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout, Activation\nfrom keras import optimizers\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom keras.models import load_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Show a example of the data","metadata":{}},{"cell_type":"code","source":"img = cv.imread(\"../input/english-handwritten-characters-dataset/Img/img011-053.png\")\nplt.imshow(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Read the csv file, Print the first 5 rows","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(r'../input/english-handwritten-characters-dataset/english.csv')\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Explore the classes","metadata":{}},{"cell_type":"code","source":"classes = df['label'].unique()\nprint(f'\\nThe Classes:\\n {classes} ')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Read the images","metadata":{}},{"cell_type":"code","source":"# Define the data path\nDATADIR = \"../input/english-handwritten-characters-dataset\"         \n\n# Read the csv file\ndataset = pd.read_csv(DATADIR + '/english.csv')\n# Get a 500 random values/rows\nrand = random.sample(range(len(dataset)), 500)\n# Make the random 500 as a validation data\nvalidation_set = pd.DataFrame(dataset.iloc[rand, :].values, columns=['image', 'label'])\n# Drop the 500 from the orignal data set\ndataset.drop(rand, inplace=True)\n# Get a 5 random rows/values from the validation set\nrand = random.sample(range(len(validation_set)), 5)\n# from the 5 random Create the test set \ntest_set = pd.DataFrame(validation_set.iloc[rand, :].values, columns=['image', 'label'])\n# Drop the 5 from the validation set\nvalidation_set.drop(rand, inplace=True)\n# Show the validation set as a example\nvalidation_set","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_generator = ImageDataGenerator(rescale=1/255, shear_range=0.2, zoom_range=0.2)\ndata_generator = ImageDataGenerator(rescale=1/255)\ntraining_data_frame = train_data_generator.flow_from_dataframe(dataframe=dataset, directory=DATADIR, x_col='image', y_col='label', \n                                                               target_size=(64, 64), class_mode='categorical')\nvalidation_data_frame = data_generator.flow_from_dataframe(dataframe=validation_set, directory=DATADIR, x_col='image', y_col='label', \n                                                           target_size=(64, 64), class_mode='categorical')\ntest_data_frame = data_generator.flow_from_dataframe(dataframe=test_set, directory=DATADIR, x_col='image', y_col='label', \n                                                     target_size=(64, 64), class_mode='categorical', shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Build the model","metadata":{}},{"cell_type":"code","source":"# Define the model\nmodel = Sequential()\n\n# Add first Convolutional Layer\nmodel.add(Conv2D(32, (3, 3), padding='same',\n                 input_shape=(64,64,3)))\n# Add a relu Activation \nmodel.add(Activation('relu'))\n# Add a second Convolutional Layer\nmodel.add(Conv2D(32, (3, 3)))\n# Add a relu Activation \nmodel.add(Activation('relu'))\n# Add a Max pooling layer\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n# Add a Dropout layer\nmodel.add(Dropout(0.25))\n\n# Add third Convolutional Layer\nmodel.add(Conv2D(64, (3, 3), padding='same'))\n# Add a relu Activation \nmodel.add(Activation('relu'))\n# Add Fourth Convolutional Layer\nmodel.add(Conv2D(64, (3, 3)))\n# Add a relu Activation \nmodel.add(Activation('relu'))\n# Add a Max pooling layer\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n# Add a Dropout Layer\nmodel.add(Dropout(0.25))\n\n# Add Fifth Convolutional Layer\nmodel.add(Conv2D(64, (3, 3), padding='same'))\n# Add a Activation Layer\nmodel.add(Activation('relu'))\n# Add a sixth Convolutional Layer\nmodel.add(Conv2D(64, (3, 3)))\n# Add a Activation Layer\nmodel.add(Activation('relu'))\n# Add a Max Pooling Layer\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n# Add a Dropout Layer\nmodel.add(Dropout(0.25))\n\n# Add a Flatten Layer\nmodel.add(Flatten())\n# Add a Dense layer Layer\nmodel.add(Dense(512))\n# Add a Activation Layer\nmodel.add(Activation('relu'))\n# Add a Dropout Layer\nmodel.add(Dropout(0.5))\n# Add the Output Dense Layer\nmodel.add(Dense(62, activation='softmax'))\n\n# Compile the model\nmodel.compile(optimizers.RMSprop(lr=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train/Fit the model","metadata":{}},{"cell_type":"code","source":"# Train the model for 50 epochs\nhistory = model.fit(training_data_frame, validation_data=validation_data_frame, epochs=50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot the result","metadata":{}},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(50)\n\nplt.figure(figsize=(15, 15))\nplt.subplot(2, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Save the model","metadata":{}},{"cell_type":"code","source":"# Save the model as model.h5\nmodel.save('model.h5')\n# Load the model\nmodel = load_model('model.h5')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print the class indices \nprint(\"Prediction Dict: \", training_data_frame.class_indices)\n# Predict on the test data \npred = model.predict(test_data_frame)\n# Create a class/labels dictionary\nclassDict = {\n            0: \"0\", 1: \"1\", 2: \"2\", 3: \"3\", 4: \"4\", 5: \"5\", 6: \"6\", 7: \"7\", 8: \"8\", 9: \"9\", 10: \"A\",\n            11: \"B\", 12: \"C\", 13: \"D\", 14: \"E\", 15: \"F\", 16: \"G\", 17: \"H\", 18: \"I\", 19: \"J\", 20: \"K\",\n            21: \"L\", 22: \"M\", 23: \"N\", 24: \"O\", 25: \"P\", 26: \"Q\", 27: \"R\", 28: \"S\", 29: \"T\", 30: \"U\",\n            31: \"V\", 32: \"W\", 33: \"X\", 34: \"Y\", 35: \"Z\", 36: \"a\", 37: \"b\", 38: \"c\", 39: \"d\", 40: \"e\",\n            41: \"f\", 42: \"g\", 43: \"h\", 44: \"i\", 45: \"j\", 46: \"k\", 47: \"l\", 48: \"m\", 49: \"n\", 50: \"o\",\n            51: \"p\", 52: \"q\", 53: \"r\", 54: \"s\", 55: \"t\", 56: \"u\", 57: \"v\", 58: \"w\", 59: \"x\", 60: \"y\",\n            61: \"z\"}\n\n# Make a data frame that contains the probability for each class\noutputDf = pd.DataFrame(pred)\n# Get the index of the max probability from the output Data frame\nmaxIndex = list(outputDf.idxmax(axis=1))\n# Print the max index\nprint(\"Max index: \", maxIndex)\n# Make a loop in range the length of the test data (5)\nfor i in range(len(test_set)):\n    # Read the image \n    image = cv.imread(DATADIR + '/' + test_set.at[i, 'image'])\n    # The title of the plot which is the predicted label\n    plt.title(classDict.get(maxIndex[i], \"error\"))\n    # Show the actual image\n    plt.imshow(image)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}