{"cells":[{"metadata":{},"cell_type":"markdown","source":"In [this dataset](https://www.kaggle.com/altruistdelhite04/loan-prediction-problem-dataset), we need to predict whether or not to approve a loan based on the past information of the person. This is a classification problem and we will use machine learning, Decision Tree Classifier model, to make the prediction.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Import Libraries\nFirst, we import necessary libraries, such as:","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set()\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Import The Data","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/loan-prediction-problem-dataset/train_u6lujuX_CVtuZ9i.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Read The Data\nFirst, let's see the first 5 rows to familiarize ourself with the data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To get more details, we are going to print ```info()``` and ```describe()``` to make a quick observation and gain some insight from it.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Quick observation on the combined data\n- Total loaner: 614\n- Feature that can be dropped from training immediately:\n    - **Loan_ID**\n- The **Loan_Status** feature, as target array, can be used as a reference to fill missing values, so we will not drop it immediately.\n- The **Dependents** feature is given in categorical but contain numerical variables. Therefore, we have to converted it to numerical variables.\n- The **Credit_History** feature is given in numerical, with 1 means 'Yes' and 0 means 'No'. We will converted it to categorical feature.\n- Features that have missing values:\n    - **Credit_History:**        50\n    - **Self_Employed:**         32\n    - **LoanAmount:**            22\n    - **Dependents:**            15\n    - **Gender:**                14\n    - **Loan_Amount_Term:**      13\n    - **Married:**                3","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Plot The Distribution of Numerical Features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot the distribution of numerical features\ntrain.hist(bins=50,figsize=(10,10),grid=False)\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see we got right-skewed and left-skewed. We will fix this in the next step by taking the log of the values to make it normally distributed. By making it normally distributed, we can improve our model.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Drop Features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop feature\ntrain.drop(['Loan_ID'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Change to Numerical","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#check unique values\ntrain['Dependents'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#replace '3+' with '3'\ntrain['Dependents'].replace('3+', '3', inplace=True)\n\n#change to numerical\ntrain['Dependents'] = train['Dependents'].astype('float')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Changet to Categorical","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#check unique values\ntrain['Credit_History'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#replace 1.0 with 'Y' and 0.0 with 'N'\ntrain['Credit_History'].replace({1.: 'Y', 0.: 'N'}, inplace=True)\n\n#change to categorical\ntrain['Credit_History'] = train['Credit_History'].astype('object')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fill Missing Value: ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"- Fill with mode()","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#fill missing values with mode \nfeatures_fill_with_mode = ['Self_Employed',\n                           'Dependents',\n                           'Gender',\n                           'Loan_Amount_Term']\n\nfor feature in features_fill_with_mode:\n    train[feature].fillna(train[feature].mode()[0], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Fill with mean()","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#fill missing values with mean\ntrain['LoanAmount'].fillna(train['LoanAmount'].mean(), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Credit_History Feature\n\nBefore we fill missing values in Credit_History feature, we will take a deeper look by plotting it.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='Credit_History', hue='Loan_Status', data=train);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the plot above, we can see that Credit_History is important feature. Most people with 0 credit history didn't get a loan. But, most people who got credit history have so much better chance to get a loan.\n\nSince Credit_History = 'Y' is the value that appears most often in both Loan_Status, so we will fill missing values with 'Y' ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Credit_History'].fillna('Y', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Married Feature\n\nFor start, we will check if the missing values in the Married feature have Dependets or CoapplicantIncome more than 0, and fill it with 'Yes' if true and 'No' if otherwise.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#check Dependents and CoapplicantIncome\nmask = ((train['Dependents'] > 0) | (train['CoapplicantIncome'] > 0)) \\\n        & \\\n        train['Married'].isnull()\n\ntrain[mask][['Married','Dependents','CoapplicantIncome']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fill missing values\ntrain.loc[mask,'Married'] = 'Yes'\ntrain['Married'].fillna('No', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Target Array\nlet's look at the target distribution","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train['Loan_Status']);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the distribution above, we can consider that the data is not imbalanced. So, we can straight to the next step: change it to numerical feature.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#transform to numerical\ntrain['Loan_Status'] = train['Loan_Status'].apply(lambda x: 1 if x=='Y' else 0)\n\n#correlation\nsns.heatmap(train.corr(),annot=True);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#copy \ntarget_array = train['Loan_Status'].copy()\n\n#drop\ntrain.drop(['Loan_Status'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Creating new features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#create total income feature\ntrain['Total_Income'] = train['ApplicantIncome'] + train['CoapplicantIncome']\n\n#create average loan amount feature (per day)\ntrain['Loan_Amount_Avg'] = train['LoanAmount'] / train['Loan_Amount_Term']\n\n#drop\ntrain.drop(['ApplicantIncome','CoapplicantIncome'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Epilogue","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"- Chech for any missing values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#missing values\nprint(train.isnull().any().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Normality Test","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#define a normality test function\ndef normalityTest(data, alpha=0.05):\n    \"\"\"data (array)   : The array containing the sample to be tested.\n\t   alpha (float)  : Significance level.\n\t   return True if data is normal distributed\"\"\"\n    \n    from scipy import stats\n    \n    statistic, p_value = stats.normaltest(data)\n    \n    #null hypothesis: array comes from a normal distribution\n    if p_value < alpha:  \n        #The null hypothesis can be rejected\n        is_normal_dist = False\n    else:\n        #The null hypothesis cannot be rejected\n        is_normal_dist = True\n    \n    return is_normal_dist","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check normality of all numericaal features and transform it if not normal distributed\nfor feature in train.columns:\n    if (train[feature].dtype != 'object'):\n        if normalityTest(train[feature]) == False:\n            train[feature] = np.log1p(train[feature])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Creating Dummies","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#create dummies\ntrain = pd.get_dummies(train, drop_first=True)\n\nprint(train.shape)\ndisplay(train.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Creating features matrix (X) and target array (y)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train\ny = target_array","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating a Model\nWe begin by splitting data into two subsets: for training data and for testing data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model training : Decision Tree Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\n#create a model\nmodel = DecisionTreeClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#search grid for optimal parameters\nfrom sklearn.model_selection import GridSearchCV\n\nparam_grid = {'random_state' : [0,42],\n              'max_depth': [1,10,100]}\n\ngrid = GridSearchCV(model, param_grid, cv=5)\n\ngrid.fit(X_train, y_train)\n\nprint(grid.best_params_)\nprint(grid.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\n\n#use the best model\nmodel = grid.best_estimator_\n\n#make a prediction\ny_predict = model.predict(X_test)\n\n#calculate classification report\nprint(classification_report(y_test,y_predict))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}