{"cells":[{"metadata":{"_cell_guid":"9290e5f3-2c90-453c-8e5d-745a51721d2c","_uuid":"ad759b9e-ed4f-416d-89f4-7ea3c37526be"},"cell_type":"markdown","source":"  **To have a fully self-driving car, it is necessary for vehicules to understand and follow traffic signs.**"},{"metadata":{"_cell_guid":"fb004b18-0206-45a0-88c2-f89017c8a1bd","_uuid":"14bb5c23-4eaf-44d8-a568-09f8e81ad2b6"},"cell_type":"markdown","source":"# This project classify traffic signs present in an image."},{"metadata":{"_cell_guid":"b157142c-f50c-415a-a4b3-17cac9c809ad","_uuid":"1e798597-557e-4eb5-988a-f6755985cf0c"},"cell_type":"markdown","source":"We **iterate** over all the classes, **open** image content into an **array** with The PIL library . and append **resized** images and their respective labels in the data and labels list"},{"metadata":{"_cell_guid":"610e2474-1990-45a8-927f-78816a2721ca","_uuid":"3e4198c1-a044-4d56-982d-35da912e6a24","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom PIL import Image\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n\ndata = []\nlabels = []\nsize = (30,30)\nclasses = 43\nfor i in range(classes):\n    path = \"../input/gtsrb-german-traffic-sign/Train/\" +str(i)\n    images = os.listdir(path)\n    for a in images:\n        try:\n            image = Image.open(path + '/'+ a)\n            image = image.resize(size)\n            image = np.array(image) /255.0\n            data.append(image)\n            labels.append(i)\n        except:\n            print(\"Error loading image\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"fd2f63d1-0fdd-4395-978b-971130ebbe77","_uuid":"0721fe85-85e7-4dec-8c74-fbcc2c3f660b"},"cell_type":"markdown","source":"convert the list into numpy to feed to the model.\nthe shape of our data now is (39209, 30, 30, 3)"},{"metadata":{"_cell_guid":"8ed36a4f-c3e7-4d56-aa61-fbb78983984e","_uuid":"26fe240d-cd82-4de4-919e-535c53492c7d","trusted":false},"cell_type":"code","source":"data = np.array(data)\nlabels = np.array(labels)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f3aec8a7-73b4-42b7-9700-ca2969ca8b84","_uuid":"a2e1a116-1489-45f7-9bc8-2ce9092ab638"},"cell_type":"markdown","source":"we split data to training and validation"},{"metadata":{"_cell_guid":"1bd12094-f087-4fb0-8cc7-52e5af8c4766","_uuid":"548d5ea4-dabb-4985-88c1-273d5dbaf921","trusted":false},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.1, random_state=42)\ny_train = to_categorical(y_train, 43)\ny_test = to_categorical(y_test, 43)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"60b3a1ba-4778-40a6-9b34-85440f30dfd9","_uuid":"b1cd1e22-67de-4ecd-81f4-b4539946d079"},"cell_type":"markdown","source":"**building and compiling the model + training**"},{"metadata":{"_cell_guid":"0b791d70-05da-4962-b75a-c00f919724cf","_uuid":"e35e0eab-fc6f-4ac7-86d6-e2909c104d68","trusted":false},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=X_train.shape[1:]))\nmodel.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(rate=0.25))\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(rate=0.25))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(rate=0.5))\nmodel.add(Dense(43, activation='softmax'))\n\n#Compilation of the model\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9bf568bc-75e2-44e8-a8f0-947e8f81b238","_uuid":"5d950eaf-dc03-4298-b567-100d12b37e10","trusted":false},"cell_type":"code","source":"epochs = 15\nhistory = model.fit(X_train, y_train, batch_size=32, epochs=epochs, validation_data=(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bc17d24a-4133-4971-9b6a-71a1280a31f6","_uuid":"c7a86030-984a-4cf1-bba1-1260bcf17935"},"cell_type":"markdown","source":"Plotting the graph for accuracy and the loss"},{"metadata":{"_cell_guid":"0b94c72a-663d-4042-acba-b1f823489a4b","_uuid":"a19e2518-8d2a-4fd2-b011-05b9aa52e74f","trusted":false},"cell_type":"code","source":"plt.figure(0)\nplt.plot(history.history['accuracy'], label='training accuracy')\nplt.plot(history.history['val_accuracy'], label='val accuracy')\nplt.title('Accuracy')\nplt.xlabel('epochs')\nplt.ylabel('accuracy')\nplt.legend()\nplt.show()\n\nplt.figure(1)\nplt.plot(history.history['loss'], label='training loss')\nplt.plot(history.history['val_loss'], label='val loss')\nplt.title('Loss')\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"aa6c3217-719b-4a60-87ab-6ff0bb685a81","_uuid":"2950c670-a43b-46f3-9ec7-1ad155264aaa"},"cell_type":"markdown","source":"In a test.csv file, we have the details related to the image path and their respective class labels. we extract images ane their labels and do the same prepocessing as before"},{"metadata":{"_cell_guid":"e5db4473-d949-40a1-ac4b-005db18928b3","_uuid":"f6f8808b-49e4-424e-ba74-2435e0147725","trusted":false},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\ny_test = pd.read_csv('/kaggle/input/gtsrb-german-traffic-sign/Test.csv')\nlabels = y_test[\"ClassId\"].values\nimgs = y_test[\"Path\"].values\n\ndata=[]\nfor img in imgs:\n    image = Image.open('/kaggle/input/gtsrb-german-traffic-sign/'+img)\n    image = image.resize((30,30))\n    data.append(np.array(image))\nX_test=np.array(data)\npred = model.predict_classes(X_test)\n#Accuracy with the test data\nfrom sklearn.metrics import accuracy_score\nprint(accuracy_score(labels, pred))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a5ebcbee-e5e1-45c4-98d6-9804385eb89a","_uuid":"0c3e20a8-d8aa-4dcb-9fa0-05b17f73695c","trusted":false},"cell_type":"code","source":"model.save(\"traffic_classifier.h5\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}