{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Task for Today  \n\n***\n\n## Michelin Restaurant Star Prediction  \n\nGiven *data about Michelin starred restaurants*, let's try to predict the **number of stars** of a given restaurant.  \n  \nWe will use a logistic regression model to make our predictions."},{"metadata":{},"cell_type":"markdown","source":"# Getting Started"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport re\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.linear_model import LogisticRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"one_star_df = pd.read_csv('../input/michelin-restaurants/one-star-michelin-restaurants.csv')\ntwo_star_df = pd.read_csv('../input/michelin-restaurants/two-stars-michelin-restaurants.csv')\nthree_star_df = pd.read_csv('../input/michelin-restaurants/three-stars-michelin-restaurants.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"one_star_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"two_star_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"three_star_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"one_star_df['stars'] = pd.Series(0, index=one_star_df.index)\ntwo_star_df['stars'] = pd.Series(1, index=two_star_df.index)\nthree_star_df['stars'] = pd.Series(2, index=three_star_df.index)\n\ncombined_df = pd.concat([one_star_df, two_star_df, three_star_df], axis=0).sample(frac=1.0).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combined_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = combined_df['stars'].copy()\nX = combined_df.drop('stars', axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Unneeded Columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = X.drop(['name', 'zipCode', 'url'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Missing Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"X.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X['price'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X['price'] = X['price'].fillna(X['price'].mode().values[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"{column: list(X[column].unique()) for column in X.columns if X.dtypes[column] == 'object'}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"price_ordering = ['$', '$$', '$$$', '$$$$', '$$$$$']\n\nX['price'] = X['price'].apply(lambda price: price_ordering.index(price))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing zip codes from city column\nX['city'] = X['city'].apply(lambda city: re.sub(r' - \\d+$', '', city) if str(city) != 'nan' else city)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def onehot_encode(df, columns, prefixes):\n    df = df.copy()\n    for column, prefix in zip(columns, prefixes):\n        dummies = pd.get_dummies(df[column], prefix=prefix)\n        df = pd.concat([df, dummies], axis=1)\n        df = df.drop(column, axis=1)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = onehot_encode(\n    X,\n    ['city', 'region', 'cuisine'],\n    ['CI', 'RE', 'CU']\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Scaling/Splitting"},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\n\nX = scaler.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=40)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"models = []\nCs = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n\nfor i in range(len(Cs)):\n    model = LogisticRegression(C=Cs[i])\n    model.fit(X_train, y_train)\n    models.append(model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Results"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_acc = [model.score(X_test, y_test) for model in models]\n\nprint(f\"Model Accuracy (C={Cs[0]}):\", model_acc[0])\nprint(f\" Model Accuracy (C={Cs[1]}):\", model_acc[1])\nprint(f\"  Model Accuracy (C={Cs[2]}):\", model_acc[2])\nprint(f\"   Model Accuracy (C={Cs[3]}):\", model_acc[3])\nprint(f\"   Model Accuracy (C={Cs[4]}):\", model_acc[4])\nprint(f\"  Model Accuracy (C={Cs[5]}):\", model_acc[3])\nprint(f\" Model Accuracy (C={Cs[6]}):\", model_acc[4])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps://youtu.be/Nm8FO8_yHUI"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}