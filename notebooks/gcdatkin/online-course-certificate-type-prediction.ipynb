{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Task for Today  \n\n***\n\n## Online Course Certificate Type Prediction  \n  \nGiven *data about online courses from MIT and Harvard*, let's try to predict whether a given course offers **honor code certificates**.  \n  \nWe will use a random forest classification model within a scikit-learn pipeline to make our predictions."},{"metadata":{},"cell_type":"markdown","source":"# Getting Started"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\npd.set_option('max_columns', None)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.metrics import confusion_matrix, classification_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/course-study/appendix.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_inputs(df):\n    df = df.copy()\n    \n    # Drop unused columns\n    df = df.drop(['Course Number', 'Course Title', 'Instructors'], axis=1)\n    \n    # Fill missing values\n    df['% Played Video'] = df['% Played Video'].replace('---', np.NaN).astype(np.float)\n    df['% Played Video'] = df['% Played Video'].fillna(df['% Played Video'].mean())\n    \n    # Extract date features\n    df['Launch Date'] = pd.to_datetime(df['Launch Date'])\n    df['Launch Year'] = df['Launch Date'].apply(lambda x: x.year)\n    df['Launch Month'] = df['Launch Date'].apply(lambda x: x.month)\n    df['Launch Day'] = df['Launch Date'].apply(lambda x: x.day)\n    df = df.drop('Launch Date', axis=1)\n    \n    # Split df into X and y\n    y = df['Honor Code Certificates']\n    X = df.drop('Honor Code Certificates', axis=1)\n    \n    # Train-test split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True, random_state=1)\n    \n    return X_train, X_test, y_train, y_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = preprocess_inputs(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building Pipeline"},{"metadata":{"trusted":true},"cell_type":"code","source":"onehot_transformer = Pipeline(steps=[\n    ('onehot', OneHotEncoder(sparse=False, drop='if_binary'))\n])\n\npreprocessor = ColumnTransformer(transformers=[\n    ('onehot', onehot_transformer, ['Institution', 'Course Subject'])\n], remainder='passthrough')\n\nmodel = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('scaler', StandardScaler()),\n    ('classifier', RandomForestClassifier(\n        random_state=1,\n        class_weight={\n            0: 1.0,\n            1: 1.0\n        }\n    ))\n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Results"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(X_test)\n\nacc = model.score(X_test, y_test)\ncm = confusion_matrix(y_test, y_pred, labels=[0, 1])\nclr = classification_report(y_test, y_pred, labels=[0, 1], target_names=[\"Negative\", \"Positive\"])\n\nprint(\"Accuracy: {:.2f}%\".format(acc * 100))\n\nplt.figure(figsize=(6, 6))\nsns.heatmap(cm, annot=True, fmt='g', vmin=0, cmap='Blues', cbar=False)\nplt.xticks(ticks=[0.5, 1.5], labels=[\"Negative\", \"Positive\"])\nplt.yticks(ticks=[0.5, 1.5], labels=[\"Negative\", \"Positive\"])\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix\")\nplt.show()\n\nprint(\"Classification Report:\\n---------------------\\n\", clr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps://youtu.be/PLRZW6Az4hw"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}