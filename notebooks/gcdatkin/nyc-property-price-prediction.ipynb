{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Task for Today  \n\n***\n\n## NYC Property Price Prediction  \n\nGiven *data about property in New York City*, let's try to predict the **price** of a given piece of property.  \n  \nWe will use XGBoost to make our predictions."},{"metadata":{},"cell_type":"markdown","source":"# Getting Started"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nimport xgboost as xgb\n\nfrom sklearn.metrics import r2_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/nyc-property-sales/nyc-rolling-sales.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['SALE PRICE'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def onehot_encode(df, columns, prefixes):\n    df = df.copy()\n    \n    for column, prefix in zip(columns, prefixes):\n        dummies = pd.get_dummies(df[column], prefix=prefix)\n        df = pd.concat([df, dummies], axis=1)\n        df = df.drop(column, axis=1)\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_inputs(df):\n    df = df.copy()\n    \n    # Remove any records where we don't have a sale price\n    df['SALE PRICE'] = df['SALE PRICE'].replace(' -  ', np.NaN).astype(np.float)\n    df = df.dropna(axis=0).reset_index(drop=True)\n    \n    # Remove unnecessary/difficult feature columns\n    df = df.drop(['Unnamed: 0', 'BLOCK', 'LOT', 'EASE-MENT','ADDRESS', 'APARTMENT NUMBER'], axis=1)\n    \n    # Fill missing values with np.NaN\n    df = df.replace(' -  ' , np.NaN)\n    \n    # Fill missing values with column means\n    for column in ['LAND SQUARE FEET', 'GROSS SQUARE FEET']:\n        df[column] = df[column].astype(np.float)\n        df[column] = df[column].fillna(df[column].mean())\n    \n    # Get year, month, and day features from SALE DATE column\n    df['SALE DATE'] = pd.to_datetime(df['SALE DATE'])\n    \n    df['YEAR'] = df['SALE DATE'].apply(lambda x: x.year)\n    df['MONTH'] = df['SALE DATE'].apply(lambda x: x.month)\n    df['DAY'] = df['SALE DATE'].apply(lambda x: x.day)\n    \n    df = df.drop('SALE DATE', axis=1)\n    \n    # Make numeric categorical features into string columns\n    for column in ['BOROUGH', 'ZIP CODE']:\n        df[column] = df[column].astype(str)\n    \n    # One-hot encode remaining categorical features\n    df = onehot_encode(\n        df,\n        columns=[\n            'BOROUGH', 'ZIP CODE', 'NEIGHBORHOOD', 'BUILDING CLASS CATEGORY',\n            'TAX CLASS AT PRESENT', 'BUILDING CLASS AT PRESENT', 'BUILDING CLASS AT TIME OF SALE'\n        ],\n        prefixes=['BO', 'ZC', 'NE', 'BC', 'TX', 'BP', 'BS']\n    )\n    \n    # Split df into X and y\n    y = df['SALE PRICE'].copy()\n    X = df.drop('SALE PRICE', axis=1).copy()\n    \n    # Scale X with a standard scaler\n    scaler = StandardScaler()\n    \n    X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n    \n    return X, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X, y = preprocess_inputs(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=123)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=123)\n\ndtrain = xgb.DMatrix(X_train, label=y_train)\ndval = xgb.DMatrix(X_val, label=y_val)\ndtest = xgb.DMatrix(X_test, label=y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {'learning_rate': 0.001, 'max_depth': 6, 'lambda': 0.01}\n\nmodel = xgb.train(params, dtrain, num_boost_round=10000, evals=[(dval, 'eval')], early_stopping_rounds=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_true = np.array(y_test)\ny_pred = model.predict(dtest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Model R^2 Score: {:.4f}\".format(r2_score(y_true, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps://youtu.be/_T-tk_2b9pY"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}