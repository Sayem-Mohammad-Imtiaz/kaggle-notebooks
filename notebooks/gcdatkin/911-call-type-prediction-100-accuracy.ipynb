{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Task for Today  \n\n***\n\n## 911 Call Type Prediction  \n\nGiven *data about 911 calls*, let's try to predict the **type** of a given call.  \n  \nWe will use a multi-input TensorFlow neural network to make our predictions."},{"metadata":{},"cell_type":"markdown","source":"# Getting Started"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport re\n\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/montcoalert/911.csv', nrows=50000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"{column: len(data[column].unique()) for column in data.columns}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_sequences(texts, vocab_length=10000):\n    tokenizer = Tokenizer(num_words=vocab_length)\n    tokenizer.fit_on_texts(texts)\n    \n    sequences = tokenizer.texts_to_sequences(texts)\n    \n    max_seq_length = np.max([len(sequence) for sequence in sequences])\n    \n    sequences = pad_sequences(sequences, maxlen=max_seq_length, padding='post')\n    \n    return sequences","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def onehot_encode(df, columns, prefixes):\n    df = df.copy()\n    \n    for column, prefix in zip(columns, prefixes):\n        dummies = pd.get_dummies(df[column], prefix=prefix)\n        df = pd.concat([df, dummies], axis=1)\n        df = df.drop(column, axis=1)\n        \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_inputs(df):\n    \n    # Drop e column (only 1 value)\n    df = df.drop('e', axis=1)\n    \n    # Create label column and drop the title column\n    df['type'] = df['title'].apply(lambda x: re.search(r'^\\w+', x).group(0))\n    df = df.drop('title', axis=1)\n    \n    # Create date/time features\n    df['timeStamp'] = pd.to_datetime(df['timeStamp'])\n    df['year'] = df['timeStamp'].apply(lambda x: x.year)\n    df['month'] = df['timeStamp'].apply(lambda x: x.month)\n    df['day'] = df['timeStamp'].apply(lambda x: x.day)\n    df['hour'] = df['timeStamp'].apply(lambda x: x.hour)\n    df['minute'] = df['timeStamp'].apply(lambda x: x.minute)\n    df['second'] = df['timeStamp'].apply(lambda x: x.second)\n    df = df.drop('timeStamp', axis=1)\n    \n    # Get sequences for desc and addr columns (and drop original columns)\n    vocab_length = 10000\n    desc_sequences = get_sequences(df['desc'], vocab_length=vocab_length)\n    addr_sequences = get_sequences(df['addr'], vocab_length=vocab_length)\n    df = df.drop(['desc', 'addr'], axis=1)\n    \n    # One-hot encode remaining categorical columns (zip and twp)\n    df = onehot_encode(df, columns=['zip', 'twp'], prefixes=['z', 't'])\n    \n    # Split df into X and y \n    y = df['type'].copy()\n    X = df.drop('type', axis=1).copy()\n    \n    # Map labels to integers\n    label_mapping = {'EMS': 0, 'Traffic': 1, 'Fire': 2}\n    y = y.replace(label_mapping)\n    \n    # Scale X with a standard scaler\n    scaler = StandardScaler()\n    X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n    \n    return X, desc_sequences, addr_sequences, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X, desc_sequences, addr_sequences, y = preprocess_inputs(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"desc_sequences.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"addr_sequences.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, desc_train, desc_test, addr_train, addr_test, y_train, y_test = \\\n    train_test_split(X, desc_sequences, addr_sequences, y, train_size=0.7, random_state=123)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"desc_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_inputs = tf.keras.Input(shape=(X_train.shape[1],))\ndesc_inputs = tf.keras.Input(shape=(desc_train.shape[1],))\naddr_inputs = tf.keras.Input(shape=(addr_train.shape[1],))\n\n# X_inputs\nX_dense1 = tf.keras.layers.Dense(128, activation='relu')(X_inputs)\nX_dense2 = tf.keras.layers.Dense(128, activation='relu')(X_dense1)\n\n# desc_inputs\ndesc_embedding = tf.keras.layers.Embedding(\n    input_dim=10000,\n    output_dim=64,\n    input_length=desc_train.shape[1]\n)(desc_inputs)\ndesc_flatten = tf.keras.layers.Flatten()(desc_embedding)\n\n# addr_inputs\naddr_embedding = tf.keras.layers.Embedding(\n    input_dim=10000,\n    output_dim=64,\n    input_length=addr_train.shape[1]\n)(addr_inputs)\naddr_flatten = tf.keras.layers.Flatten()(addr_embedding)\n\n# Concatenate results\nconcat = tf.keras.layers.concatenate([X_dense2, desc_flatten, addr_flatten])\n\n# Make predictions\noutputs = tf.keras.layers.Dense(3, activation='softmax')(concat)\n\n\nmodel = tf.keras.Model(inputs=[X_inputs, desc_inputs, addr_inputs], outputs=outputs)\n\nprint(model.summary())\ntf.keras.utils.plot_model(model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(\n    optimizer='adam',\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n\nhistory = model.fit(\n    [X_train, desc_train, addr_train],\n    y_train,\n    validation_split=0.2,\n    batch_size=32,\n    epochs=20,\n    callbacks=[\n        tf.keras.callbacks.ReduceLROnPlateau()\n    ]\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Results"},{"metadata":{"trusted":true},"cell_type":"code","source":"results = model.evaluate([X_test, desc_test, addr_test], y_test, verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Model loss: {:.5f}\".format(results[0]))\nprint(\"Model accuracy: {:.2f}%\".format(results[1] * 100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps://youtu.be/I78TAjpPFD8"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}