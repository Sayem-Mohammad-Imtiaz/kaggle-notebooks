{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Task for Today  \n\n***\n\n## Spotify Hit Prediction  \n\nGiven *data about Spotify songs from the 1960s-2010s*, let's try to predict whether a given song will be a **hit** or not.\n\nWe will use a variety of classification models to make our predictions."},{"metadata":{},"cell_type":"markdown","source":"# Getting Started"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import LinearSVC, SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n\nimport warnings\nwarnings.filterwarnings(action='ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfs = [pd.read_csv(f'../input/the-spotify-hit-predictor-dataset/dataset-of-{decade}0s.csv') for decade in ['6', '7', '8', '9', '0', '1']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, decade in enumerate([1960, 1970, 1980, 1990, 2000, 2010]):\n    dfs[i]['decade'] = pd.Series(decade, index=dfs[i].index)\n\ndata = pd.concat(dfs, axis=0).sample(frac=1.0, random_state=1).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_inputs(df):\n    df = df.copy()\n    \n    # Drop high-cardinality categorical columns\n    df = df.drop(['track', 'artist', 'uri'], axis=1)\n    \n    # Split df into X and y\n    y = df['target']\n    X = df.drop('target', axis=1)\n    \n    # Train-test split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True, random_state=1)\n    \n    # Scale X\n    scaler = StandardScaler()\n    scaler.fit(X_train)\n    X_train = pd.DataFrame(scaler.transform(X_train), index=X_train.index, columns=X_train.columns)\n    X_test = pd.DataFrame(scaler.transform(X_test), index=X_test.index, columns=X_test.columns)\n    \n    return X_train, X_test, y_train, y_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = preprocess_inputs(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"models = {\n    \"                   Logistic Regression\": LogisticRegression(),\n    \"                   K-Nearest Neighbors\": KNeighborsClassifier(),\n    \"                         Decision Tree\": DecisionTreeClassifier(),\n    \"Support Vector Machine (Linear Kernel)\": LinearSVC(),\n    \"   Support Vector Machine (RBF Kernel)\": SVC(),\n    \"                        Neural Network\": MLPClassifier(),\n    \"                         Random Forest\": RandomForestClassifier(),\n    \"                     Gradient Boosting\": GradientBoostingClassifier()\n}\n\nfor name, model in models.items():\n    model.fit(X_train, y_train)\n    print(name + \" trained.\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Results"},{"metadata":{"trusted":true},"cell_type":"code","source":"for name, model in models.items():\n    print(name + \": {:.2f}%\".format(model.score(X_test, y_test) * 100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps://youtu.be/Yg3RGlucdQU"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}