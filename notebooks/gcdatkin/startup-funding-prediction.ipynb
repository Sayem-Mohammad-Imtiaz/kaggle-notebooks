{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Task for Today  \n\n***\n\n## Startup Funding Prediction  \n\nGiven *data about startups in India*, let's try to predict the **funding** provided to a given startup.\n\nWe will use a TensorFlow/Keras neural network within a scikit-learn pipeline to make our predictions."},{"metadata":{},"cell_type":"markdown","source":"# Getting Started"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\n\nimport tensorflow as tf\n\nfrom sklearn.metrics import r2_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/indian-startup-funding/startup_funding.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_inputs(df):\n    df = df.copy()\n    \n    # Drop ID and high-cardinality columns\n    df = df.drop(['Sr No', 'Startup Name', 'SubVertical', 'Investors Name'], axis=1)\n    \n    # Clean \\\\xc2\\\\xa0 examples\n    df = df.applymap(lambda x: x.replace(r'\\\\xc2\\\\xa0', '') if type(x) == str else x)\n    \n    # Clean target column\n    df['Amount in USD'] = df['Amount in USD'].apply(lambda x: x.replace(',', '') if str(x) != 'nan' else x)\n    df['Amount in USD'] = df['Amount in USD'].replace({\n        'undisclosed': np.NaN,\n        'unknown': np.NaN,\n        'Undisclosed': np.NaN,\n        'N/A': np.NaN,\n        '14342000+': '14342000'\n    })\n    \n    # Drop missing target rows\n    missing_target_rows = df[df['Amount in USD'].isna()].index\n    df = df.drop(missing_target_rows, axis=0).reset_index(drop=True)\n    \n    # Drop columns with more than 25% missing values\n    df = df.drop('Remarks', axis=1)\n    \n    # Fill categorical missing values with most frequent occurence\n    for column in ['Industry Vertical', 'City  Location', 'InvestmentnType']:\n        df[column] = df[column].fillna(df[column].mode()[0])\n    \n    # Clean date column\n    df['Date dd/mm/yyyy'] = df['Date dd/mm/yyyy'].replace({\n        '05/072018': '05/07/2018',\n        '01/07/015': '01/07/2015',\n        '22/01//2015': '22/01/2015'\n    })\n    \n    # Extract date features\n    df['Date dd/mm/yyyy'] = pd.to_datetime(df['Date dd/mm/yyyy'])\n    df['Year'] = df['Date dd/mm/yyyy'].apply(lambda x: x.year)\n    df['Month'] = df['Date dd/mm/yyyy'].apply(lambda x: x.month)\n    df['Day'] = df['Date dd/mm/yyyy'].apply(lambda x: x.day)\n    df = df.drop('Date dd/mm/yyyy', axis=1)\n    \n    # Convert target column to float\n    df['Amount in USD'] = df['Amount in USD'].astype(np.float)\n    \n    # Split df into X and y\n    y = df['Amount in USD']\n    X = df.drop('Amount in USD', axis=1)\n    \n    # Train-test split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True, random_state=1)\n    \n    return X_train, X_test, y_train, y_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = preprocess_inputs(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building Pipeline"},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model():\n    inputs = tf.keras.Input(shape=(532,))\n    x = tf.keras.layers.Dense(128, activation='relu')(inputs)\n    x = tf.keras.layers.Dense(128, activation='relu')(x)\n    outputs = tf.keras.layers.Dense(1, activation='linear')(x)\n    \n    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n    \n    model.compile(\n        optimizer='adam',\n        loss='mse'\n    )\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nominal_transformer = Pipeline(steps=[\n    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))\n])\n\npreprocessor = ColumnTransformer(transformers=[\n    ('nominal', nominal_transformer, ['Industry Vertical', 'City  Location', 'InvestmentnType'])\n], remainder='passthrough')\n\nregressor = tf.keras.wrappers.scikit_learn.KerasRegressor(build_model)\n\nmodel = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('scaler', StandardScaler()),\n    ('regressor', regressor)\n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(\n    X_train,\n    y_train,\n    regressor__validation_split=0.2,\n    regressor__batch_size=32,\n    regressor__epochs=100,\n    regressor__callbacks=[\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=3,\n            restore_best_weights=True\n        )\n    ]\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Results"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(X_test)\n\nrmse = np.sqrt(np.mean((y_test - y_pred)**2))\nprint(\"     Test RMSE: {:.2f}\".format(rmse))\n\nr2 = r2_score(y_test, y_pred)\nprint(\"Test R^2 Score: {:.5f}\".format(r2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps://youtu.be/K5NqUMZomYE"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}