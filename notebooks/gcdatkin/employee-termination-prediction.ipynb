{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Task for Today  \n\n***\n\n## Employee Termination Prediction  \n\nGiven *employee data from HR*, let's try to predict which employees are most likely to be **terminated**.\n\nWe will use various classification models to make our predictions. "},{"metadata":{},"cell_type":"markdown","source":"# Getting Started"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/human-resources-data-set/HRDataset_v14.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"def encode_dates(df, columns_with_prefixes):\n    df = df.copy()\n    \n    for column, prefix in columns_with_prefixes:\n        df[column] = pd.to_datetime(df[column])\n        \n        df[prefix + '_year'] = df[column].apply(lambda x: x.year)\n        df[prefix + '_month'] = df[column].apply(lambda x: x.month)\n        df[prefix + '_day'] = df[column].apply(lambda x: x.day)\n        \n        df = df.drop(column, axis=1)\n        \n    return df\n\ndef ordinal_encode(df, columns_with_orderings):\n    df = df.copy()\n    \n    for column, ordering in columns_with_orderings:\n        df[column] = df[column].apply(lambda x: ordering.index(x))\n        \n    return df\n\ndef onehot_encode(df, columns_with_prefixes):\n    df = df.copy()\n    \n    for column, prefix in columns_with_prefixes:\n        dummies = pd.get_dummies(df[column], prefix=prefix)\n        df = pd.concat([df, dummies], axis=1)\n        df = df.drop(column, axis=1)\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_inputs(df, scaler):\n    df = df.copy()\n    \n    # Drop unneeded columns\n    df = df.drop(['Employee_Name', 'EmpID', 'MaritalStatusID', 'Sex', 'PositionID', 'DeptID', 'PerfScoreID', 'EmpStatusID', 'EmploymentStatus', 'DateofTermination', 'TermReason', 'ManagerID'], axis=1)\n    ''\n    # Date encoding\n    date_columns = [\n        ('DOB', \"DOB\"),\n        ('DateofHire', \"DOH\"),\n        ('LastPerformanceReview_Date', \"PRD\")\n    ]\n    df = encode_dates(df, columns_with_prefixes=date_columns)\n    \n    # Ordinal encoding\n    ordinal_columns = [\n        ('PerformanceScore', ['PIP', 'Needs Improvement', 'Fully Meets', 'Exceeds'])\n    ]\n    df = ordinal_encode(df, columns_with_orderings=ordinal_columns)\n    \n    # One-hot encoding\n    nominal_columns = [\n        ('Position', \"PS\"),\n        ('State', \"ST\"),\n        ('Zip', \"ZP\"),\n        ('MaritalDesc', \"MD\"),\n        ('CitizenDesc', \"CD\"),\n        ('HispanicLatino', \"HL\"),\n        ('RaceDesc', \"RD\"),\n        ('Department', \"DE\"),\n        ('ManagerName', \"MN\"),\n        ('RecruitmentSource', \"RS\")\n    ]\n    df = onehot_encode(df, columns_with_prefixes=nominal_columns)\n    \n    # Split df into X and y\n    y = df['Termd'].copy()\n    X = df.drop('Termd', axis=1)\n    \n    # Train-test split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=1)\n    \n    # Scale X\n    scaler.fit(X_train)\n    \n    X_train = pd.DataFrame(scaler.transform(X_train), columns=X.columns)\n    X_test = pd.DataFrame(scaler.transform(X_test), columns=X.columns)\n    \n    return X_train, X_test, y_train, y_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler()\n\nX_train, X_test, y_train, y_test = preprocess_inputs(data, scaler)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"models = {\n    \"   K-Nearest Neighbors\": KNeighborsClassifier(),\n    \"   Logistic Regression\": LogisticRegression(),\n    \"Support Vector Machine\": SVC(),\n    \"         Decision Tree\": DecisionTreeClassifier(),\n    \"        Neural Network\": MLPClassifier()\n}\n\nfor name, model in models.items():\n    model.fit(X_train, y_train)\n    print(name + \" trained.\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Results"},{"metadata":{"trusted":true},"cell_type":"code","source":"for name, model in models.items():\n    print(name + \" Accuracy: {:.2f}%\".format(model.score(X_test, y_test) * 100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps://youtu.be/v0XdNicMXuY"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}