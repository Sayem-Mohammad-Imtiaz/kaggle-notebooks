{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Task for Today  \n\n***\n\n## Fake News Detection  \n\nGiven *titles of various news articles*, let's try to predict whether a given piece of news is **fake** or not.  \n  \nWe will use a TensorFlow GRU RNN to make our predictions."},{"metadata":{},"cell_type":"markdown","source":"# Getting Started"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport plotly.express as px\n\nfrom nltk.stem import PorterStemmer\nimport re\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"true_news = pd.read_csv('../input/fake-and-real-news-dataset/True.csv')\nfake_news = pd.read_csv('../input/fake-and-real-news-dataset/Fake.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"true_news","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fake_news","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"true_df = pd.concat([true_news['title'], pd.Series(0, index=true_news.index, name='label')], axis=1)\nfake_df = pd.concat([fake_news['title'], pd.Series(1, index=fake_news.index, name='label')], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"true_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fake_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"news_df = pd.concat([true_df, fake_df], axis=0).sample(frac=1.0, random_state=34).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"news_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"ps = PorterStemmer()\n\ndef process_title(title):\n    new_title = title.lower()\n    new_title = re.sub(r'\\$[^\\s]+', 'dollar', new_title)\n    new_title = re.sub(r'[^a-z0-9\\s]', '', new_title)\n    new_title = re.sub(r'[0-9]+', 'number', new_title)\n    new_title = new_title.split(\" \")\n    new_title = list(map(lambda x: ps.stem(x), new_title))\n    new_title = list(map(lambda x: x.strip(), new_title))\n    if '' in new_title:\n        new_title.remove('')\n    return new_title","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"titles = news_df['title'].apply(process_title)\n\nlabels = np.array(news_df['label'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"titles","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get size of vocabulary\nvocabulary = set()\n\nfor title in titles:\n    for word in title:\n        if word not in vocabulary:\n            vocabulary.add(word)\n\nvocab_length = len(vocabulary)\n\n# Get max length of a sequence\nmax_seq_length = 0\n\nfor title in titles:\n    if len(title) > max_seq_length:\n        max_seq_length = len(title)\n\n# Print results\nprint(\"Vocab length:\", vocab_length)\nprint(\"Max sequence length:\", max_seq_length)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = Tokenizer(num_words=vocab_length)\ntokenizer.fit_on_texts(titles)\n\nsequences = tokenizer.texts_to_sequences(titles)\n\nword_index = tokenizer.word_index\n\nmodel_inputs = pad_sequences(sequences, maxlen=max_seq_length)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_inputs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_inputs.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(model_inputs, labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_dim = 64\n\n\ninputs = tf.keras.Input(shape=(max_seq_length,))\n\nembedding = tf.keras.layers.Embedding(\n    input_dim=vocab_length,\n    output_dim=embedding_dim,\n    input_length=max_seq_length\n)(inputs)\n\ngru = tf.keras.layers.GRU(units=embedding_dim)(embedding)\n\noutputs = tf.keras.layers.Dense(1, activation='sigmoid')(gru)\n\n\nmodel = tf.keras.Model(inputs, outputs)\n\n\nmodel.compile(\n    optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=[\n        'accuracy',\n        tf.keras.metrics.AUC(name='auc')\n    ]\n)\n\n\nbatch_size = 32\nepochs = 3\n\nhistory = model.fit(\n    X_train,\n    y_train,\n    validation_split=0.2,\n    batch_size=batch_size,\n    epochs=epochs,\n    callbacks=[\n        tf.keras.callbacks.ReduceLROnPlateau(),\n        tf.keras.callbacks.ModelCheckpoint('model.h5', save_best_only=True)\n    ]\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Results"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.line(\n    history.history,\n    y=['loss', 'val_loss'],\n    labels={'x': \"Epoch\", 'y': \"Loss\"},\n    title=\"Loss Over Time\"\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.line(\n    history.history,\n    y=['auc', 'val_auc'],\n    labels={'x': \"Epoch\", 'y': \"AUC\"},\n    title=\"AUC Over Time\"\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights('./model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps://youtu.be/NULf94GVu44"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}