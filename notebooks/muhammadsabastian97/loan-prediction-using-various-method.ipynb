{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Importing required libraries\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.impute import SimpleImputer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing required dataset\ndataset = pd.read_csv('../input/loan-prediction-problem-dataset/train_u6lujuX_CVtuZ9i.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Check the number of null values in each column\ndataset.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting data based on its category\ncat_data = []\nnum_data = []\n\nfor i,c in enumerate(dataset.dtypes):\n    if c == object:\n        cat_data.append(dataset.iloc[:, i])\n    else :\n        num_data.append(dataset.iloc[:, i])\n\ncat_data=pd.DataFrame(cat_data).transpose()\nnum_data=pd.DataFrame(num_data).transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filling the missing data\ncat_data = cat_data.apply(lambda x:x.fillna(x.value_counts().index[0]))\n\nimputer = SimpleImputer(missing_values= np.nan, strategy = 'mean')\nimputer.fit(num_data.values[:,(2,3)])\nnum_data.values[:,(2,3)] = imputer.transform(num_data.values[:,(2,3)])\n\n\nimputer_mf=SimpleImputer(missing_values=np.nan, strategy='most_frequent')\nimputer_mf.fit(num_data.values[:, 4:5])\nnum_data.values[:,4:5]=imputer_mf.transform(num_data.values[:,4:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check whether there is still a null value in the dataset\ncat_data.isnull().sum().any()\nnum_data.isnull().sum().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encoding the label and splitting data into independent and dependent variables\nlabelencoder = LabelEncoder()\ncat_data.values[:, 2] = labelencoder.fit_transform(cat_data.values[:, 2])\ncat_data.values[:, 4] = labelencoder.fit_transform(cat_data.values[:, 4])\ncat_data.values[:, 5] = labelencoder.fit_transform(cat_data.values[:, 5])\ncat_data.values[:, 6] = labelencoder.fit_transform(cat_data.values[:, 6])\ncat_data.Dependents=cat_data.Dependents.replace({'3+':'3'})\n\ntarget_values = {'Y': 1 , 'N' : 0}\n\ntarget = cat_data['Loan_Status']\ncat_data.drop('Loan_Status', axis=1, inplace=True)\n\ntarget = target.map(target_values)\n\ndata = pd.concat([cat_data, num_data, target], axis=1)\nX=data.iloc[:, 2:12]\ny=data.iloc[:,12]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encoding the 'Property_Area' column\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nlabelencoder_X = LabelEncoder()                     \nX.iloc[:, 4] = labelencoder_X.fit_transform(X.iloc[:, 4])     \ntransformer = ColumnTransformer(\n        [('Property_Area', OneHotEncoder(), [4])],\n        remainder='passthrough')\nX = np.array(transformer.fit_transform(X), dtype=np.float)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting data into train and test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n\n# Scaling the data\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\" LOGISTIC REGRESSION \"\"\"\nfrom sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state = 0)\nclassifier.fit(X_train, y_train)\ny_pred = classifier.predict(X_test)\n# Creating confusion matrix and calculating the accuracy score\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm_logreg = confusion_matrix(y_test, y_pred)\nas_logreg=accuracy_score(y_test, y_pred)\n\n\"\"\" K-NEAREST NEIGHBORS \"\"\"\nfrom sklearn.neighbors import KNeighborsClassifier\nclassifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\nclassifier.fit(X_train, y_train)\ny_pred = classifier.predict(X_test)\n# Creating confusion matrix and calculating the accuracy score\ncm_knn = confusion_matrix(y_test, y_pred)\nas_knn=accuracy_score(y_test, y_pred)\n\n\"\"\" SVM GAUSSIAN \"\"\"\nfrom sklearn.svm import SVC\nclassifier = SVC(kernel = 'rbf', random_state = 0)\nclassifier.fit(X_train, y_train)\ny_pred = classifier.predict(X_test)\n# Creating confusion matrix and calculating the accuracy score\ncm_svm_gaussian = confusion_matrix(y_test, y_pred)\nas_svm_gaussian = accuracy_score(y_test, y_pred)\n\n\"\"\" SVM NO KERNEL \"\"\"\nfrom sklearn.svm import SVC\nclassifier = SVC(kernel = 'linear', random_state = 0)\nclassifier.fit(X_train, y_train)\ny_pred = classifier.predict(X_test)\n# Creating confusion matrix and calculating the accuracy score\ncm_svm_nokernel = confusion_matrix(y_test, y_pred)\nas_svm_nokernel = accuracy_score(y_test, y_pred)\n\n\"\"\" NAIVE BAYES \"\"\"\nfrom sklearn.naive_bayes import GaussianNB\nclassifier = GaussianNB()\nclassifier.fit(X_train, y_train)\ny_pred = classifier.predict(X_test)\n# Creating confusion matrix and calculating the accuracy score\ncm_nb = confusion_matrix(y_test, y_pred)\nas_nb = accuracy_score(y_test, y_pred)\n\n\"\"\" DECISION TREE CLASSIFICATION \"\"\"\nfrom sklearn.tree import DecisionTreeClassifier\nclassifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\nclassifier.fit(X_train, y_train)\ny_pred = classifier.predict(X_test)\n# Creating confusion matrix and calculating the accuracy score\ncm_dtc = confusion_matrix(y_test, y_pred)\nas_dtc = accuracy_score(y_test, y_pred)\n\n\"\"\" RANDOM FOREST CLASSIFIER \"\"\"\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators = 500, criterion = 'entropy', random_state = 0)\nclassifier.fit(X_train, y_train)\ny_pred = classifier.predict(X_test)\n# Creating confusion matrix and calculating the accuracy score\ncm_rfc = confusion_matrix(y_test, y_pred)\nas_rfc = accuracy_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluating the best method to use in this loan prediction case\nscore={'as_logreg':as_logreg, 'as_knn':as_knn, 'as_svm_gaussian':as_svm_gaussian, 'as_svm_nokernel':as_svm_nokernel, 'as_nb':as_nb, 'as_dtc':as_dtc, 'as_rfc':as_rfc}\nscore_list=[]\nfor i in score:\n    score_list.append(score[i])\n    u=max(score_list)\n    if score[i]==u:\n        v=i  \n    print(f\"{i}={score[i]}\");   \nprint(f\"The best accuracy score in this case is {v} with accuracy score {u}\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}