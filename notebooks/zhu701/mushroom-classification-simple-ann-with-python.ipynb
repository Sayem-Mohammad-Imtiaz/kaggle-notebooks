{"cells":[{"metadata":{},"cell_type":"markdown","source":"The objective here is to build a model that succesfully classifies a mushroom as eatable or poisonous based on its features.\nSince I have recently taken a deep learning course from Udemy on deep learning (https://www.udemy.com/course/deeplearning/), I am building a simple Artificial Neural Network (ANN) model. This is a self-assigned homework to myself."},{"metadata":{},"cell_type":"markdown","source":"First let's import the dataset."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing\n\n# Importing the dataset\ndata= pd.read_csv('/kaggle/input/mushroom-classification/mushrooms.csv')\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since all the input variables are categorical, we can encode everything using LabelEncoder. For the target variable (class), 1 is poisonous and 0 is eatable. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encoding categorical data\nfrom sklearn.preprocessing import LabelEncoder\nlabelencoder=LabelEncoder()\nfor col in data.columns:\n    data[col] = labelencoder.fit_transform(data[col])\ndata.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we can seperate the input and target variables. As we have seen from above, the first variable is the target variable. The rest 22 variables are input variables. "},{"metadata":{"trusted":true},"cell_type":"code","source":"x = data.iloc[:, 1:23].values\ny = data.iloc[:, 0].values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next we split the dataset into train and set. We will use 80% for training and 20% for testing. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)\nX_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"There is no need for normalization/standardization because the variables are categorical. We will start building the ANN. We can use the trick to find the optimal units for output nodes - simply divide the number of input variables (22) by 2. "},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\n# Initialising the ANN\nclassifier = Sequential()\n\n# Adding the input layer \nclassifier.add(Dense(units = 11, kernel_initializer = 'uniform', activation = 'relu', input_dim = 22))\n\n# Adding the second hidden layer\nclassifier.add(Dense(units = 11, kernel_initializer = 'uniform', activation = 'relu'))\n\n# Adding the output layer\nclassifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n\n# Compiling the ANN\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\nclassifier.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting the ANN to the Training set\nhistory = classifier.fit(X_train, y_train, batch_size = 10, epochs = 50)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The accuracy rates are very high. We can use matplot to visulize the accuracy and loss for each epoch. "},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n# Checking the key names\nprint(history.history.keys())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Summarizing history for accuracy\nplt.plot(history.history['accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Summarizing history for loss\nplt.plot(history.history['loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's predict using the ANN model and create a confusion matrix to view the test results! "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting the test set results\ny_pred = classifier.predict(X_test) #these are probabilities\ny_pred = (y_pred > 0.5) #we need to convert it to binary\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\n\nprint(cm)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As shown above, we have succesfully predicted all the eatble and poisonous mushrooms in the test set. "},{"metadata":{},"cell_type":"markdown","source":"Note: Although the ANN model is very accurate, it does not tell us why and how it was able to reach such perfection, as there is no information on variable importance. "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}