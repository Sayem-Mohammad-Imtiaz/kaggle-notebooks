{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# import important pacakages\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# sci-kit learn imports\nfrom sklearn.preprocessing import LabelEncoder\n\n# Classifiers\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\n\n# used to check best classifier\nfrom sklearn.model_selection import cross_val_score\n\n# kfold for the data\nfrom sklearn.model_selection import RepeatedStratifiedKFold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluate a given model using cross-validation\ndef evaluate_model(model):\n    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n    return scores\n# models to check for best results\ndef get_models():\n    models = dict()\n    models['ExT'] = ExtraTreesClassifier(max_features = 'log2', min_samples_leaf =1, n_estimators = 1000)\n    models['Rnd'] = RandomForestClassifier(max_features = 'sqrt', min_samples_leaf =1, n_estimators = 1000)\n    models['Gb'] = GradientBoostingClassifier(max_features = 'log2', min_samples_leaf =2, n_estimators = 1000)\n    return models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# read the data using pandas\ndata = pd.read_csv('../input/mushroom-classification/mushrooms.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let look at the data to see what we have\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check data for null values\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we need to label encode the data\nle = []\nlabels = data.columns\nfor i in range(len(labels)):\n    le.append(LabelEncoder())\n    le[i].fit(data[labels[i]])\n    data[labels[i]] = le[i].transform(data[labels[i]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#split X and y from all the data\nX = data[data.columns[1:23]]\ny = data[data.columns[0]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the models to evaluate\nmodels = get_models()\n# evaluate the models and store results\nresults, names = list(), list()\nfor name, model in models.items():\n    scores = evaluate_model(model)\n    results.append(scores)\n    names.append(name)\n    print('>%s %.3f (%.3f)' % (name, np.mean(scores), np.std(scores)))\n# plot model performance for comparison\nplt.boxplot(results, labels=names, showmeans=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"100% across the board. It seems label encoding the data has done a very good job.\n\nPlease comment and vote.\n\nAll the best\nGmanik","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}