{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Dataset Açıklaması\nFeatures are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image.\nn the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34].\n\nThis database is also available through the UW CS ftp server:\nftp ftp.cs.wisc.edu\ncd math-prog/cpo-dataset/machine-learn/WDBC/\n\nAlso can be found on UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29\n\nAttribute Information:\n\n1. ID number\n2. Diagnosis (M = malignant, B = benign)\n3-32)\n\nTen real-valued features are computed for each cell nucleus:\n\n* a) radius (mean of distances from center to points on the perimeter)\n* b) texture (standard deviation of gray-scale values)\n* c) perimeter\n* d) area\n* e) smoothness (local variation in radius lengths)\n* f) compactness (perimeter^2 / area - 1.0)\n* g) concavity (severity of concave portions of the contour)\n* h) concave points (number of concave portions of the contour)\n* i) symmetry\n* j) fractal dimension (\"coastline approximation\" - 1)\n\nThe mean, standard error and \"worst\" or largest (mean of the three\nlargest values) of these features were computed for each image,\nresulting in 30 features. For instance, field 3 is Mean Radius, field\n13 is Radius SE, field 23 is Worst Radius.\n\nAll feature values are recoded with four significant digits.\n\nMissing attribute values: none\n\nClass distribution: 357 benign, 212 malignant"},{"metadata":{},"cell_type":"markdown","source":"### Kütüphaneleri Ekleyelim"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport os\n\n%matplotlib inline \nimport matplotlib.pyplot as plt\n\nimport seaborn as sns\n\nfrom plotly.offline import init_notebook_mode, iplot, plot\nimport plotly as py\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\n\nfrom sklearn import preprocessing\nfrom sklearn.datasets import make_regression\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import KFold, train_test_split, cross_val_predict, cross_val_score\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nfrom sklearn.linear_model import LogisticRegression\n\nfrom keras import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import SGD\n\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Verimizi yükleyelim."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/breast-cancer-wisconsin-data/data.csv')\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dataset İncelemesi"},{"metadata":{},"cell_type":"markdown","source":"İlk 5 gözlemi inceleyelim."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Rastgele 5 gözlemi inceleyelim."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.sample(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Veri setinin değişken ve gözlem sayısını öğrenelim."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Veri Ön İşleme (Data Preprocessing)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Bilgileri incelersek ; \n* 33 kolonun olduğunu, kolonların tiplerini ve bellek kullanımlarını,\n* 'Unnamed: 32' özniteliğinin tüm değerlerinin eksik olduğunu,\n* Geri kalan tüm özniteliklerin eksiksiz olduğunuz öğrenebiliriz."},{"metadata":{},"cell_type":"markdown","source":"Verimizi düzenleyelim."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop('id',axis=1,inplace=True)\ndf.drop('Unnamed: 32',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['diagnosis'] = df['diagnosis'].map({'M':1,'B':0})\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Veri setinin istatistik bilgilerini inceleyelim."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,5))\nsns.set_theme(style=\"darkgrid\")\nax = sns.countplot(x=\"diagnosis\", data=df)\nplt.title(\"Diagnosis M=1 , B=0\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Veriyi Ölçeklendirme (Scaling) ve Normalize Etme (Normalization)"},{"metadata":{},"cell_type":"markdown","source":"Veriyi ölçeklendirmek için min-maks ölçeklendirme kullanalım."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_normalized=df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in df.columns:\n    x = df_normalized[[i]].values.astype(float)\n    min_max_scaler = preprocessing.MinMaxScaler()\n    x_scaled = min_max_scaler.fit_transform(x)\n    df_normalized[i] = pd.DataFrame(x_scaled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_normalized.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Veriyi İnceleyelim"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 15))\n# define the mask to set the values in the upper triangle to True\nmask = np.triu(np.ones_like(df_normalized.corr(), dtype=np.bool))\nheatmap = sns.heatmap(df_normalized.corr(), mask=mask, vmin=-1, vmax=1, annot=True, cmap='BrBG')\nheatmap.set_title('Triangle Correlation Heatmap', fontdict={'fontsize':25}, pad=16);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8, 12))\nheatmap = sns.heatmap(df_normalized.corr()[['diagnosis']].sort_values(by='diagnosis', ascending=False), vmin=-1, vmax=1, annot=True, cmap='BrBG')\nheatmap.set_title('Features Correlating with Diagnosis', fontdict={'fontsize':18}, pad=16);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(df_normalized['concave points_worst'], df_normalized['perimeter_worst'], c=df_normalized['diagnosis'], cmap=plt.cm.Spectral)\nplt.colorbar()\nplt.xlabel('concave points_worst')\nplt.ylabel('perimeter_worst')\nplt.title('concave points_worst x perimeter_worst')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_mean=list(df.columns[1:])\n# split dataframe into two based on diagnosis\ndfM=df[df['diagnosis'] ==1]\ndfB=df[df['diagnosis'] ==0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist_data = [dfM['concave points_worst'],dfB['concave points_worst']]\n\ngroup_labels = ['M', 'B']\n\n# Create distplot with custom bin_size\nfig = ff.create_distplot(hist_data, group_labels, bin_size=.2)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams.update({'font.size': 8})\nfig, axes = plt.subplots(nrows=10, ncols=3, figsize=(15,20))\naxes = axes.ravel()\nfor idx,ax in enumerate(axes):\n    ax.figure\n    binwidth= (max(df[features_mean[idx]]) - min(df[features_mean[idx]]))/50\n    ax.hist([dfM[features_mean[idx]],dfB[features_mean[idx]]], bins=np.arange(min(df[features_mean[idx]]), max(df[features_mean[idx]]) + binwidth, binwidth) , alpha=0.5,stacked=True, label=['M','B'],color=['r','g'])\n    ax.legend(loc='upper right')\n    ax.set_title(features_mean[idx])\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Çıkarımlar;\n* Heatmap'de korelasyonlarını incelediğimizde diagnosis üzerinde en çok etkili olanların hangi değişkenler olduğunu tespit edebiliriz. \n* Histogramları incelerken M ve B değerlerinin yoğunlaşmalarının birbirlerine göre farklarını dikkate almalıyız. Eğer farklı yerlerde yoğunlaşıyorsa özniteliği kanser espitinde kullanabilriz. Örneği radius_mean özniteliğinin histogramındaki yoğunlaşma farklıyken, smoothness_mean özniteliğinin yoğunlaşması düzgündür."},{"metadata":{},"cell_type":"markdown","source":"### Cross Validation (KFold) Uygulaması"},{"metadata":{},"cell_type":"markdown","source":"Bu yöntemde veri kümesi k sayısı kadar eşit parçaya bölünür ve her parçanın hem eğitim hem de test için kullanılması sağlanır. Bu sayede test kümesi seçimi yapılırken oluşan yanlılık ortadan kaldırılmış olur."},{"metadata":{},"cell_type":"markdown","source":"Öncelikle klasik yöntem ile veri setini train ve test olarak ayırarak bir doğrusal regresyon analizi yapalım."},{"metadata":{"trusted":true},"cell_type":"code","source":"x = df_normalized.drop(\"diagnosis\", axis=1)\ny = df_normalized[\"diagnosis\"]\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, shuffle = False, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ayırdığımız train test verilerini kullanarak modelimizi eğitelim"},{"metadata":{},"cell_type":"markdown","source":"### Lojistik Regresyon (Logistic Regression)"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression()\nlr.fit(x_train, y_train)\n\ny_pred = lr.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Modelimizi eğittik. Accuracy değerine bakalım."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy Score: \",accuracy_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Modeli farklı gözlemlerle kombinleyerek tekrardan skorunu hesaplayalım ve ortalamalarını alalım."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Cross Validation Score: \",cross_val_score(lr, x_test, y_test, cv = 10).mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Klasik yöntem ile bölerek oluşturulan regresyon modelinin sonuçlarını inceledik. Şimdide çapraz doğrulama (Cross validation) yöntemiyle bölerek oluşturduğumuz verimizi modelimizde inceleyelim."},{"metadata":{"trusted":true},"cell_type":"code","source":"cv = KFold(n_splits=10, random_state=1, shuffle=True)\nmodel = LogisticRegression()\nscores = cross_val_score(model, x, y, scoring='accuracy', cv=cv, n_jobs=-1)\ncross_val_score(lr, x_test, y_test, cv = 10).mean()\nprint('Accuracy: %.3f (%.3f)' % (scores.mean(), scores.std()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Karar Ağacı (Decision Tree)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ndtGini = DecisionTreeClassifier(random_state = 42, criterion='gini')\ndtEntropy = DecisionTreeClassifier(random_state = 42, criterion='entropy')\n\ncv = KFold(n_splits=10, random_state=1, shuffle=True)\nscores = cross_val_score(dtEntropy, x, y, scoring='accuracy', cv=cv, n_jobs=-1)\ncross_val_score(lr, x_test, y_test, cv = 10).mean()\nprint('Entropy Accuracy: %.3f (%.3f)' % (scores.mean(), scores.std()))\n\nscores = cross_val_score(dtGini, x, y, scoring='accuracy', cv=cv, n_jobs=-1)\ncross_val_score(lr, x_test, y_test, cv = 10).mean()\nprint('Gini Accuracy: %.3f (%.3f)' % (scores.mean(), scores.std()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Yapay Sinir Ağları ( Artificial Neural Networks)"},{"metadata":{"trusted":true},"cell_type":"code","source":"NumerOfClasses = len(y_train.unique())\nRN = Sequential() # create network structure\nRN.add(Dense(10, input_shape = x_train.shape[1:], activation ='relu'))\nRN.add(Dense(NumerOfClasses, activation ='sigmoid'))\nRN.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import to_categorical\nsgd = SGD(lr=0.1, decay=1e-6, momentum=0.9)\nRN.compile(optimizer=sgd, loss='mean_squared_error', metrics=['accuracy'])\ntrainedRN = RN.fit(x_train, to_categorical(y_train), epochs=100, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = RN.evaluate(x_test, to_categorical(y_test),verbose=0)\nprint('Test Score:', score[0])\nprint('Test Accuracy:', score[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}