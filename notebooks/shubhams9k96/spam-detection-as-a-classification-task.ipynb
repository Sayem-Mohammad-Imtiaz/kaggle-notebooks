{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.ensemble import RandomForestClassifier\n\n\nfrom sklearn.metrics import (confusion_matrix, precision_recall_curve, auc,\n                             roc_curve, recall_score, classification_report, f1_score,\n                             precision_recall_fscore_support, roc_auc_score)\n\n\n\nsns.set_style('dark')\nsns.set_context('talk')# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\npd.set_option('display.max_colwidth', -1)\n        # Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Reading Data:"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/spam.csv', encoding = 'latin1')\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# last 3 cols have most values Nans. Dropping them\ndf.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Renaming columns\ndf.columns = ['label', 'text']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.width', 1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Modeling:\nTesting if the length as any relation with label"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['length'] = df['text'].apply(lambda row: len(row))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['length'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df['label'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encoding label to 0,1\ndf['label'] = df['label'].map({'spam' : 1, 'ham' :0})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df.label == 1].text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"So some words like Free, Winner, Prize etc are definitely in the spam messages, so if we test for these words first. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df.label.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"words = ['free', 'winner', 'prize', 'won', 'win']\ndef count_words(row):\n    count = 0\n    for word in words:\n        if word in row.lower():\n            count +=1\n    return count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['bad_words'] = df['text'].apply(count_words )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(['bad_words', 'label']).count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(df.corr(), annot = True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"This means words like them those have some relation with being spam or not. This means using frequency based word encoding will work here. "},{"metadata":{},"cell_type":"markdown","source":"## Data Modeling:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop(['label'], axis=1)\ny = df['label']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=12)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape, len(y_train))\nprint(X_test.shape, len(y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vectorizer = TfidfVectorizer(lowercase=True, min_df=20, use_idf=True, )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_tfidf = vectorizer.fit_transform(X_train.text)\ntest_tfidf = vectorizer.transform(X_test.text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_tfidf.shape)\nprint(test_tfidf.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training Model:"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = RandomForestClassifier(n_estimators=10, n_jobs=-1, class_weight='balanced')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.fit(train_tfidf, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = clf.predict_proba(test_tfidf)[:,1]\ny_pred_binary = clf.predict(test_tfidf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Metrics: "},{"metadata":{"trusted":true},"cell_type":"code","source":"fpr, tpr, thres = roc_curve(y_test, y_pred)\nplt.plot(fpr, tpr, label = 'AUC') \nplt.plot([0,1], [0,1], ':', label = 'Random') \nplt.legend() \nplt.grid() \nplt.ylabel(\"TPR\") \nplt.xlabel(\"FPR\") \nplt.title('ROC') \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LABELS = ['Ham', 'Spam']\nconf_matrix = confusion_matrix(y_test, y_pred_binary)\ncm = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\nsns.heatmap(cm, xticklabels=LABELS, yticklabels=LABELS, annot=True, cmap='Greens');\nplt.title(\"Confusion matrix\")\nplt.ylabel('True class')\nplt.xlabel('Predicted class')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"F1-Score : {:.2f}\".format(f1_score(y_test, y_pred_binary)))\nprint(\"AUC-ROC  : {:.2f}\".format(roc_auc_score(y_test, y_pred_binary)))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}