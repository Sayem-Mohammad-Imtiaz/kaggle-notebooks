{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n# import warnings\nimport warnings\n# ignore warnings\nwarnings.filterwarnings(\"ignore\")\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5e0bfddf848c7b5520397f4a11bf2bdb7a846687"},"cell_type":"code","source":"# read csv (comma separated value) into data\ndata = pd.read_csv('../input/column_2C_weka.csv')\nprint(plt.style.available) # look at available plot styles\nplt.style.use('ggplot')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"**MACHINE LEARNING (ML)**\n\nIn python there are some ML libraries like sklearn, keras or tensorflow. We will use sklearn."},{"metadata":{"_uuid":"a1a9872a1052794101cae30fc51cea7fd8708281"},"cell_type":"markdown","source":"**A. SUPERVISED LEARNING**\n\n* Supervised learning: It uses data that has labels. Example, there are orthopedic patients data that have labels normal and abnormal.\n* There are features(predictor variable) and target variable. Features are like pelvic radius or sacral slope(If you have no idea what these are like me, you can look images in google like what I did :) )Target variables are labels normal and abnormal\n* Aim is that as given features(input) predict whether target variable(output) is normal or abnormal\n* Classification: target variable consists of categories like normal or abnormal\n* Regression: target variable is continious like stock market\n* If these explanations are not enough for you, just google them. However, be careful about terminology: features = predictor variable = independent variable = columns = inputs. target variable = responce variable = class = dependent variable = output = result"},{"metadata":{"_uuid":"9dbe2fa81707596c05bfbc9a1e622c6a1fc62f92"},"cell_type":"markdown","source":"**EXPLORATORY DATA ANALYSIS (EDA)**\n\n* In order to make something in data, as you know you need to explore data. Detailed exploratory data analysis is in my Data Science Tutorial for Beginners\n* I always start with head() to see features that are pelvic_incidence, pelvic_tilt numeric, lumbar_lordosis_angle, sacral_slope, pelvic_radius and degree_spondylolisthesis and target variable that is class\n* head(): default value of it shows first 5 rows(samples). If you want to see for example 100 rows just write head(100)"},{"metadata":{"trusted":true,"_uuid":"934ffdd383e1539de57d16c584b8bec882653263"},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a7b64ce9f80bdbe74105aedbfe367d047ac1b7a"},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e76c047f318189a45a40264da78f8f22646413d8"},"cell_type":"markdown","source":"* length: 310 (range index)\n* Features are float\n* Target variables are object that is like string\n* Okey we have some ideas about data but lets look go inside data deeper\n* describe():  Why we need to see statistics like mean, std, max or min? \n*   In order to visualize data, values should be closer each other. As you can see values looks like closer. At least there is no incompatible values like mean of one feature is 0.1 and other is 1000. Also there are another reasons that I will mention next parts."},{"metadata":{"trusted":true,"_uuid":"506bd1330977809dbde21d557bf9fc44b206c26d"},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6a3130ef824cf5c400159da3847f7c82f4baf365"},"cell_type":"markdown","source":" pd.plotting.scatter_matrix:\n \n* green: normal and red: abnormal\n* c: color\n* figsize: figure size\n* diagonal: histohram of each features\n* alpha: opacity\n* s: size of marker\n* marker: marker type"},{"metadata":{"trusted":true,"_uuid":"5c1a1724c1f9ccc192db2803dc990afb1e008e77"},"cell_type":"code","source":"color_list = ['red' if i=='Abnormal' else 'green' for i in data.loc[:,'class']]\npd.plotting.scatter_matrix(data.loc[:, data.columns != 'class'],\n                          c=color_list,\n                          figsize=[15,20],\n                          diagonal='hist',\n                          alpha=0.5,\n                          s = 200,\n                          marker = 'x',\n                          edgecolor=\"black\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"73c7cd669b93e960c3fd5e612ddf390776ac00aa"},"cell_type":"markdown","source":"There are relations between each feature but how many normal(green) and abnormal(red) classes are there.\n\n*  Searborn library has countplot() that counts number of classes\n* Also you can print it with value_counts() method\n\nThis data looks like balanced. Actually there is no definiton or numeric value of balanced data but this data is balanced enough for us. \nNow lets learn first classification method KNN.\n "},{"metadata":{"trusted":true,"_uuid":"38f1554a687be95d99593eea0bb4b60a83d959da"},"cell_type":"code","source":"sns.countplot(x=\"class\", data=data)\ndata.loc[:,'class'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"466fc31a6d7a40f4f202050368ef1b794067f873"},"cell_type":"markdown","source":"**REGRESSION**\n* Supervised learning\n* We will learn linear and logistic regressions\n* This orthopedic patients data is not proper for regression so I only use two features that are sacral_slope and pelvic_incidence of abnormal\n* I consider feature is pelvic_incidence and target is sacral_slope\n* Lets look at scatter plot so as to understand it better\n* reshape(-1,1): If you do not use it shape of x or y becaomes (210,) and we cannot use it in sklearn, so we use shape(-1,1) and shape of x or y be (210, 1)."},{"metadata":{"trusted":true,"_uuid":"207885d598092fabfc20c297a5d57af3f8d4f15a"},"cell_type":"code","source":"# create data1 that includes pelvic_incidence that is feature and sacral_slope that is target variable\ndata1 = data[data['class'] == 'Abnormal']\nx = np.array(data1.loc[:,'pelvic_incidence']).reshape(-1,1)\ny = np.array(data1.loc[:,'sacral_slope']).reshape(-1,1)\n# Scatter\nplt.figure(figsize=[10,10])\nplt.scatter(x=x,y=y)\nplt.xlabel('pelvic_incidence')\nplt.ylabel('sacral_slope')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a3a2667ac9933b00296d979a1a3d37e37f6b4d52"},"cell_type":"markdown","source":"Now we have our data to make regression. In regression problems target value is continuously varying variable such as price of house or sacral_slope. Lets fit line into this points.\n\n\nLinear regression\n\n* y = ax + b where y = target, x = feature and a = parameter of model\n* We choose parameter of model(a) according to minimum error function that is lost function\n* In linear regression we use Ordinary Least Square (OLS) as lost function.\n* OLS: sum all residuals but some positive and negative residuals can cancel each other so we sum of square of residuals. It is called OLS\n* Score: Score uses R^2 method that is ((y_pred - y_mean)^2 )/(y_actual - y_mean)^2"},{"metadata":{"trusted":true,"_uuid":"123ca81ad7dea99c0496fcc5c6514e429b6156ed"},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nreg = LinearRegression()\n#Predict space\npredict_space = np.linspace(min(x), max(x)).reshape(-1,1)\n#Fitting\nreg.fit(x,y)\n#Predicting\npredicting = reg.predict(predict_space)\n#R^2\nprint('R^2 score: ',reg.score(x,y))\n# Plot regression line and scatter \nplt.plot(predict_space, predicting, color='green', linewidth=2)\nplt.scatter(x=x,y=y)\nplt.xlabel('pelvic_incidence')\nplt.ylabel('sacral_slope')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3035e4487a0be03cc20e191f3a13c70faac8744f"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}