{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"6554bd5c-cc6e-316b-3348-189e2a70723e"},"source":"Let's have a look at the input and the the type of data in each column."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7f277077-77e7-058e-d759-6e7ba9847fb9"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport matplotlib\n\n\n\ndf = pd.read_csv('../input/diabetes.csv')\ndf.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"98c1470f-d1f1-f059-25b8-750a5a9bb700"},"outputs":[],"source":"df.info()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4513531e-0fe0-7275-c6d0-e6451bbf4963"},"outputs":[],"source":"# There are no null values in the columns\ndf.isnull().sum()"},{"cell_type":"markdown","metadata":{"_cell_guid":"cf0760a8-5b6e-a202-de0d-6c1fbddb4e9b"},"source":"There are no null values in any of the columns of the dataset.\n\nNow let's look at the differences in the distributions of the features between those with and without diabetes. (For this I have used some ideas from: https://www.kaggle.com/flczcdy/titanic/exploratory-tutorial-titanic)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4b9387c4-b416-4cef-f35e-9b930ad11a4d"},"outputs":[],"source":"plt.style.use('ggplot')\n\ndef plot_attributes(train,test,features,lable1,lable2,plt,i,j):\n    alpha = 0.6\n    ax1 = plt.subplot2grid((2, 4), (i, j))\n    train[features].plot(kind='kde', color='#FA2379', label=lable1, alpha=alpha)\n    test[features].plot(kind='kde', label=lable2, alpha=alpha)\n    ax1.set_xlabel(features)\n    ax1.set_title(\"What's the distribution of \"+features+\"?\",fontsize=8)\n    plt.legend(loc=1,fontsize=8)\n    plt.tight_layout()\n    \ndef plot_KDE(diabetics,nondiabetics,col_names):\n    #plt.rc('font', size=13)\n    fig = plt.figure(figsize=(18, 8))\n\n    j = 0\n    i = 0\n\n    for features in col_names:\n        plot_attributes(diabetics,nondiabetics,features,\"diabetics\",\"non_diabetics\",plt,i,j)\n        j = j + 1\n        if j == 4:\n            j = 0\n            i = 1\n    \n            \ncol_names= list(df.columns.values)\ncol_names.remove('Outcome')\n\ndiabetics=df[df['Outcome']==1]\nnondiabetics=df[df['Outcome']==0]\n\nplot_KDE(diabetics, nondiabetics, col_names)"},{"cell_type":"markdown","metadata":{"_cell_guid":"86d300e4-abb3-8156-9511-a0afb561af7c"},"source":"The density distributions of 'Glucose','Age' and 'Pregnancies' are mainly different between people who have diabetes or not.  \nJust have a quick look to see if there are any patterns between the number of pregnancy and diabetics status:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c7045176-cff0-25a2-b74d-bad4b996170c"},"outputs":[],"source":"\nalpha=0.2\nfig = plt.figure(figsize=(6, 6))\nax1 = fig.add_subplot(111)\ndiabetics['Pregnancies'].value_counts().sort_index().plot(kind='bar', color='#FA2379', alpha=alpha,label=\"diabetics\")\nnondiabetics['Pregnancies'].value_counts().sort_index().plot(kind='bar', color='#23FA79', alpha=alpha,\n                                                             label=\"non-diabetics\")\nax1.set_ylabel('Frequency')\nax1.set_ylim((0,107))\nplt.legend(loc=1,fontsize=8)\nax1.set_title(\"Number of pregnancy histogram\", y=1.05)\nplt.grid()\nplt.show()\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e18faf7b-2393-46b4-b0a0-8f7158e78c0f"},"outputs":[],"source":"#How are the features correlated?\nprint(df.corr())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fde1d632-4ebd-0d18-98c2-c96d7528ebbb"},"outputs":[],"source":"plt.matshow(df.corr())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1ee6dab1-d47f-3d08-bd9e-9404d97091a9"},"outputs":[],"source":"df.describe()"},{"cell_type":"markdown","metadata":{"_cell_guid":"b4474a63-f28d-a6be-e31b-d0fb765164a8"},"source":"There are no significant correlations between the features. Also looking at the min and max shows that the data need scaling. \n\nPlus some zero values exists which doesn't make sense for example for BMI. This matter has been pointed out in this post: https://www.kaggle.com/lejustin/d/uciml/pima-indians-diabetes-database/feature-engineering-metric-comparison"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"323ac536-8ee9-9969-c58f-fe1d41352582"},"outputs":[],"source":"#Scale the data:\ndf_norm=df.copy()\n\nfeatures_to_normilize=[ 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction']\nfrom sklearn.preprocessing import MinMaxScaler\ndf_norm[features_to_normilize] = MinMaxScaler().fit_transform(df_norm[features_to_normilize])"},{"cell_type":"markdown","metadata":{"_cell_guid":"ecbdc62d-3248-838a-b29b-fdc1d2294c92"},"source":"Let's do some prediction. The code below is taken from :https://www.kaggle.com/lejustin/d/uciml/pima-indians-diabetes-database/feature-engineering-metric-comparison"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cba0ec5f-86c4-eee3-c6f3-3df7c1832465"},"outputs":[],"source":"\nfrom sklearn.model_selection import train_test_split\nX = df_norm.ix[:, df_norm.columns !='Outcome']\ny = df_norm.ix[:, -1]\ntrain_data, test_data, y_train, actual_test_prediction = train_test_split(X, y, test_size=0.2, random_state=1)\n\n# https://www.kaggle.com/lejustin/d/uciml/pima-indians-diabetes-database/feature-engineering-metric-comparison\n\n\nnormals = [0]*3\nvariables = ['Glucose', 'SkinThickness', 'BMI']\n\n# Generate imputation values with Gaussian randomness.\nfor n, v in zip(range(len(normals)), variables):\n    # Shift the mean up to account for skewness caused by zeros.\n    v_mean=train_data[v].mean()*1.5\n\n    # Use surrogate deviation.\n    # (Sometimes I get strange values when using .std(). Why?)\n    v_std = v_mean*0.1\n\n    normals[n] = np.random.normal(loc = v_mean, scale = v_std)\n\nprint(\"Imputing zeros in Glucose, SkinThickness, and BMI with\")\nprint(\"%f, %f, and %f\" % (normals[0], normals[1], normals[2]))\n\n# Impute.\ntrain_data = train_data.replace(to_replace = {'Glucose': {0: normals[0]},\n                                  'SkinThickness': {0: normals[1]},\n                                  'BMI': {0: normals[2]}})\n\nnormals = [0]*3\nvariables = ['Glucose', 'SkinThickness', 'BMI']\n\n# Generate imputation values with Gaussian randomness.\nfor n, v in zip(range(len(normals)), variables):\n    # Shift the mean up to account for skewness caused by zeros.\n    v_mean = test_data[v].mean()*1.5\n\n    # Use surrogate deviation.\n    # (Sometimes I get strange values when using .std(). Why?)\n    v_std = v_mean*0.1\n\n    normals[n] = np.random.normal(loc = v_mean, scale = v_std)\n\nprint(\"Imputing zeros in Glucose, SkinThickness, and BMI with\")\nprint(\"%f, %f, and %f\" % (normals[0], normals[1], normals[2]))\n\n# Impute.\nX_test = test_data.replace(to_replace = {'Glucose': {0: normals[0]},\n                                  'SkinThickness': {0: normals[1]},\n                                  'BMI': {0: normals[2]}})\n\nprint(\"DONE\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"05c4b842-a8a2-7e14-85cd-8ac4ffb997ab"},"source":"Some Functions for metric calculations which I have as a library:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b84a69cc-4751-368a-885c-3b05b441aa79"},"outputs":[],"source":"def calculate_prediction_scores(TP,FN,FP,TN):\n\n    # print TP,FN,FP,TN\n    precision=None\n    recall=None\n    result_dic=dict()\n\n    # recall (TPR)\n    try:\n        recall=TP/float(TP+FN)\n        result_dic['recall']=recall\n        result_dic['TPR'] = recall\n    except:\n        result_dic['TPR'] = 0\n\n    # FPR\n    try:\n        FPR=FP/float(FP+TN)\n        result_dic['FPR']=recall\n    except:\n        result_dic['FPR'] = 0\n\n\n    # precision\n    try:\n        precision = TP / float(TP + FP)\n        result_dic['precision']=precision\n    except:\n        result_dic['precision'] = np.nan\n\n    # f1\n    if precision is not None and recall is not None:\n        try:\n            f1 = (2*precision*recall) / float(precision+recall)\n            result_dic['f1'] = f1\n        except:\n            result_dic['f1'] = np.nan\n    else:\n        result_dic['f1']=np.nan\n\n    # accuracy\n    try:\n        accuracy = (TP+TN) / float(TP + FP +TN +FN)\n        result_dic['accuracy']=accuracy\n    except:\n        result_dic['accuracy'] = np.nan\n\n\n    # MCC\n    try:\n        top = (TP*TN) - (FP*FN)\n        bottom=(TP+FN)*(TP+FP)*(TN+FP)*(TN+FN)\n        bottoms= sqrt((bottom))\n        mcc=top/float(bottoms)\n        result_dic['mcc']=mcc\n    except:\n        result_dic['mcc'] = np.nan\n    return result_dic\n\n# given two binary classiifcation calcuulate tP,FP,..\ndef calculate_performance_for_binary_classification(actual_binary_list, predict_binary_list):\n\n    TP=0; FN=0; FP=0; TN=0;\n\n    for i in range(0,len(actual_binary_list)):\n        if actual_binary_list[i]==1 and predict_binary_list[i]==1:\n            TP=TP+1\n        if actual_binary_list[i] == 1 and predict_binary_list[i]==0:\n            FN = FN + 1\n        if actual_binary_list[i] == 0 and predict_binary_list[i] == 0:\n            TN = TN + 1\n        if actual_binary_list[i] == 0 and predict_binary_list[i] == 1:\n            FP = FP+1\n\n    dic_scores=calculate_prediction_scores(TP,FN,FP,TN)\n    return dic_scores"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e9293445-9545-5669-cd15-06276df7ccf1"},"outputs":[],"source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import roc_curve,roc_auc_score,auc\n\ndef plot_roc_curve(actual_test_prediction,Predictedprobabilities):\n\n    fpr, tpr, _ = roc_curve(actual_test_prediction, np.array(Predictedprobabilities))\n    roc_auc = auc(fpr, tpr)\n    plt.figure()\n    lw = 2\n    plt.plot(fpr, tpr, color='darkorange',\n             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic example')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n    \n# Create the random forest object which will include all the parameters\n# for the fit\nforest = RandomForestClassifier(n_estimators = 100)\n\n\n# Fit the training data to the Survived labels and create the decision trees\nforest_model = forest.fit(train_data,y_train)\n\n# Take the same decision trees and run it on the test data\nprediction_array = forest_model.predict(test_data)\nprob= forest.predict_proba(test_data)[:,1]\nplot_roc_curve(actual_test_prediction,prob)\ncalculations=calculate_performance_for_binary_classification(np.array(actual_test_prediction),prediction_array)\nprint(calculations)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3d6524d1-67ca-4ee4-afa0-828dc94a0b5a"},"outputs":[],"source":"def plot_feature_importance(X,y,h):\n    from sklearn.ensemble import ExtraTreesClassifier\n    # Build a forest and compute the feature importances\n    forest = ExtraTreesClassifier(n_estimators=250,\n                                  random_state=0)\n\n    forest.fit(X, y)\n    importances = forest.feature_importances_\n    std = np.std([tree.feature_importances_ for tree in forest.estimators_],axis=0)\n    indices = np.argsort(importances)[::-1]\n\n    print(\"Feature ranking:\")\n    lables=[]\n    for f in range(X.shape[1]):\n        l= h[indices[f]]\n        lables.append(l)\n        print(\"%d. feature %s (%f)\" % (f + 1,l, importances[indices[f]]))\n\n    # Plot the feature importances of the forest\n    plt.figure()\n    plt.title(\"Feature importances\")\n    plt.bar(range(X.shape[1]), importances[indices],\n           color=\"r\", yerr=std[indices], align=\"center\")\n    plt.xticks(range(X.shape[1]), lables,rotation=90)\n    plt.xlim([-1, X.shape[1]])\n    plt.show()\n\ncol_names= list(df.columns.values)\ncol_names.remove('Outcome')\nplot_feature_importance(X,y,col_names)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"68d5d5e1-40d7-d53e-1558-193045bab2a4"},"outputs":[],"source":"test_data2=test_data[['Glucose','Age','BMI']]\ntrain_data2=train_data[['Glucose','Age','BMI']]\n\n# Fit the training data to the Survived labels and create the decision trees\nforest_model = forest.fit(train_data2,y_train)\n\n# Take the same decision trees and run it on the test data\nprediction_array = forest_model.predict(test_data2)\nprob= forest.predict_proba(test_data2)[:,1]\nplot_roc_curve(actual_test_prediction,prob)\ncalculations=calculate_performance_for_binary_classification(np.array(actual_test_prediction),prediction_array)\nprint(calculations)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}