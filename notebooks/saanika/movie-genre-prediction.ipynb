{"cells":[{"metadata":{"_uuid":"b93d61427edaaa2003ae75a948a69ca881dfe05b"},"cell_type":"markdown","source":"**Import the necessary libraries**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport imblearn\nimport matplotlib.pyplot as plt\n%matplotlib inline \n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\n\nprint(\"Reading data\")\nprint(os.listdir(\"../input\"))\n\n##For data preprocessing\nfrom bs4 import BeautifulSoup\nimport re\nfrom nltk.corpus import stopwords\n\n##For Machine Learning\nfrom sklearn import svm\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score, f1_score\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ed6d3f8a4d6170fcecc3f4628874e2740744b86c"},"cell_type":"markdown","source":"** Load the dataset and view the data **"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/wiki_movie_plots_deduped.csv\")\ndf.tail()\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6d4ba027eb7678adcc22d209d63cb34cde22c466"},"cell_type":"markdown","source":"**Getting rid of the movies whose Genre is unkown**"},{"metadata":{"trusted":true,"_uuid":"49d0304f5e8c41bed7706251d5d846d386ce54b7"},"cell_type":"code","source":"df['Genre']=df['Genre'].replace('unknown',np.nan)\ndf=df.dropna(axis=0, subset=['Genre'])\nprint(df.tail())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b03deb3a54effc8616c4b2f4a2ec2767e0ba665d"},"cell_type":"markdown","source":"**Keeping only the Top 20 Movie Genres in terms of occurrence**"},{"metadata":{"trusted":true,"_uuid":"a0290a08619b2d200555b9f14195728e2d2da651"},"cell_type":"code","source":"print(len(df))\nprint(df.shape)\na=df['Genre'].value_counts()[:20]\nb=a.keys().tolist()\nprint(b)\ndf=df[df.Genre.isin(b)]\ndf=df.reset_index(drop=True)\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"25e3f3b161adb2fa8d57333ddd0682a0aa1e5828"},"cell_type":"markdown","source":"**Plot the number of occurrences of  most commonly occurring movies**"},{"metadata":{"trusted":true,"_uuid":"307c9dbbb94b82c9d7ee50fa87a686976e598c10","scrolled":true,"_kg_hide-output":false},"cell_type":"code","source":"sns.set(style=\"white\")\ngenre_to_count=pd.DataFrame({'Genre':a.index, 'Count':a.values})\nplt.figure(figsize=(15,10))\nsns.barplot(y=\"Genre\", x=\"Count\", data=genre_to_count,palette=\"Blues_d\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"relabeling:\ncomedy, drama as comedy \nromantic, comedy as romance\ncrime, drama as crime\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Genre'] = df['Genre'].replace({'comedy, drama': 'comedy', 'romantic comedy': 'romance', 'crime drama': 'crime', 'sci-fi': 'science fiction'})\ndf =df.drop(['Release Year','Title','Origin/Ethnicity','Cast','Director','Wiki Page'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Genre'] = df['Genre'].replace({'war':'action','animation':'family','musical':'family','mystery':'thriller','film noir':'crime','western':'action','adventure':'family','horror':'thriller'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style='white')\nfig, ax = plt.subplots(figsize=(6,10))\nsns.countplot(ax=ax, y=\"Genre\", data=df,palette=\"Blues_d\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d7007fa1130b3c68ba42c6ad00ce4d25144b46a9"},"cell_type":"code","source":"def plotToWords(raw_plot):\n    letters_only = re.sub(\"[^a-zA-Z]\", \" \", raw_plot)\n    lower_case = letters_only.lower()\n    words = lower_case.split()\n    stops = set(stopwords.words(\"english\"))\n    meaningful_words = [w for w in words if not w in stops]\n    return (\" \".join(meaningful_words))\n\ndef preprocess(dataframe):\n    clean_train_reviews = []\n    for i in range(0,len(dataframe)):\n        clean_train_reviews.append(plotToWords(dataframe.iloc[i]['Plot']))\n    dataframe['Plot']=clean_train_reviews\n    return dataframe\n\ndf=preprocess(df)\nprint(df[\"Plot\"][:10])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Benchmark before oversampling"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nX_train, X_test, y_train, y_test = train_test_split(df['Plot'], df['Genre'], random_state = 0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.preprocessing import LabelEncoder\ntfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1,3), max_features=6000)\nfeatures = tfidf.fit_transform(df.Plot).toarray()\nlabels = df.Genre\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodels = [\n    LinearSVC(multi_class='ovr'),\n    MultinomialNB(),\n    LogisticRegression(random_state=32,multi_class='ovr'),\n    RandomForestClassifier(n_estimators = 30, criterion = 'entropy', random_state = 42)\n]\nCV = 5\ncv_df = pd.DataFrame(index=range(CV * len(models)))\nentries = []\nfor model in models:\n    \n  model_name = model.__class__.__name__\n  accuracies = cross_val_score(model, features, labels, scoring='accuracy', cv=CV)\n  for fold_idx, accuracy in enumerate(accuracies):\n    entries.append((model_name, fold_idx, accuracy))\ncv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\nimport seaborn as sns\nfig, ax1 = plt.subplots(figsize=(6,10))\nfig, ax2 = plt.subplots(figsize=(6,10))\nsns.boxplot(ax=ax1,x='model_name', y='accuracy', data=cv_df)\nsns.stripplot(ax=ax2,x='model_name', y='accuracy', data=cv_df, \n              size=8, jitter=True, edgecolor=\"gray\", linewidth=2)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_df.groupby('model_name').accuracy.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Oversample randomly\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install google_trans_new","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from google_trans_new import google_translator\ntranslator = google_translator()  \n\ndef translatePlot(x):\n    print(x)        \n    translated = translator.translate(x, lang_tgt='ge') \n    english_translation = translator.translate(translated, lang_tgt='en')\n    return english_translation\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"translatePlot(df.loc[1,'Plot'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generateSamples(df):\n    minor_class = ['comedy','romance','horror','action','crime','thriller','western','science fiction','adventure',\n                        'musical','film noir','mystery','war','animation','family']\n    majority_count=df[df.Genre == 'drama'].shape[0]\n    majority_class='drama'\n    for genre in minor_class:\n        if genre in df.Genre.unique():\n            sample_size=majority_count-df[df.Genre == genre].shape[0]\n            temp = df[df.Genre == genre].sample(sample_size,random_state=2,replace=True)\n            temp['Genre']=genre\n            temp['Plot']= translatePlot(temp['Plot'])\n            df=pd.concat([df,temp])\n    return df\n        \n      \n        \n        \n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Classifying with Machine Learning"},{"metadata":{"_uuid":"497155be8f34e18be2c8e4c9ad699651188da89a"},"cell_type":"markdown","source":"## Use models for - \n* Linear Support Vector Classifier\n* Multinomial Naive Bayes \n* Logistic Regression\n* Plot how each of them performs on the dataset\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nexample_params = {\n        'n_estimators': 100,\n        'max_depth': 5,\n        'random_state': 13\n    }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.naive_bayes import MultinomialNB\nmodels = [\n    LinearSVC(multi_class='ovr'),\n    MultinomialNB(),\n    LogisticRegression(random_state=32,multi_class='ovr'),\n    RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42)\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.preprocessing import LabelEncoder\ndef score_model(d):\n    CV=5\n    cv = KFold(n_splits=CV, random_state=42,shuffle=True)\n    scores = []\n    entries = []\n    label_enc =LabelEncoder()\n    tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 3), max_features=4000)\n    cv_df = pd.DataFrame(index=range(CV * len(models)))\n    for model in models:\n        for train_fold_index, test_fold_index in cv.split(d.Plot,d.Genre):\n            X_train_fold, y_train_fold = d['Plot'].iloc[train_fold_index], d['Genre'].iloc[train_fold_index]\n            X_val_fold, y_val_fold = d['Plot'].iloc[test_fold_index], d['Genre'].iloc[test_fold_index]\n\n            d_new=generateSamples(pd.concat([X_train_fold, y_train_fold], axis=1))\n\n            X_train_fold_upsample, y_train_fold_upsample = d_new.Plot,d_new.Genre\n            features = tfidf.fit_transform(X_train_fold_upsample).toarray()\n            labels = label_enc.fit(y_train_fold_upsample)\n            labels = label_enc.transform(y_train_fold_upsample)\n            X_test = tfidf.transform(X_val_fold).toarray()\n            \n            model_name = model.__class__.__name__\n            clf = model.fit(features, labels)\n            prediction = model.predict(X_test)\n            score = accuracy_score(prediction, label_enc.transform(y_val_fold))\n            entries.append((model_name, score))\n    cv_df = pd.DataFrame(entries, columns=['model_name','accuracy'])\n    import seaborn as sns\n    sns.boxplot(x='model_name', y='accuracy', data=cv_df)\n    sns.stripplot(x='model_name', y='accuracy', data=cv_df, \n    size=8, jitter=True, edgecolor=\"gray\", linewidth=2)\n    plt.show()\n    return cv_df\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_df = score_model(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_df.groupby('model_name').accuracy.mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## If we test on our oversampled data as well - "},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(df['Plot'], df['Genre'], random_state = 0)\nd=generateSamples(pd.concat([X_train, y_train], axis=1))\nX_train,y_train = d.Plot,d.Genre\nfig, ax = plt.subplots(figsize=(6,10))\nsns.countplot(ax=ax, y=\"Genre\", data=d,palette=\"Blues_d\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0bdf841f8e05604f40cc89e0a0316050ebbca94c"},"cell_type":"code","source":"tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 3), max_features=4000)\nfeatures = tfidf.fit_transform(d.Plot).toarray()\nlabels = d.Genre\nfeatures.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ddfee0c17a0953b13dcd2124bb5b4b70fc4c9c1b"},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.naive_bayes import MultinomialNB\nmodels = [\n    LinearSVC(),\n    MultinomialNB(),\n    LogisticRegression(random_state=0),\n]\nCV = 5\ncv_df = pd.DataFrame(index=range(CV * len(models)))\nentries = []\nfor model in models:\n  model_name = model.__class__.__name__\n  accuracies = cross_val_score(model, features, labels, scoring='accuracy', cv=CV)\n  for fold_idx, accuracy in enumerate(accuracies):\n    entries.append((model_name, fold_idx, accuracy))\ncv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\nimport seaborn as sns\nsns.boxplot(x='model_name', y='accuracy', data=cv_df)\nsns.stripplot(x='model_name', y='accuracy', data=cv_df, \n              size=8, jitter=True, edgecolor=\"gray\", linewidth=2)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"291e9c4dac7c5919adc683dcaa37b8a8f8177dc2"},"cell_type":"markdown","source":"**The average accuracies are:**"},{"metadata":{"trusted":true,"_uuid":"2bb9407d39587c39a9b1cc3774398713c0b51771"},"cell_type":"code","source":"cv_df.groupby('model_name').accuracy.mean()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Adjust Weights of Minority Class"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(df['Plot'], df['Genre'], random_state = 5)\n\ntfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 3), max_features=4000)\nfeatures = tfidf.fit_transform(df.Plot).toarray()\nlabels = df.Genre","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils import class_weight\n\nentries= [] \n'''\nclass_weight = class_weight.compute_class_weight('balanced',\n                                                np.unique(y_train),\n                                                y_train)\nprint(class_weight)\n'''\nmodel = LogisticRegression(class_weight = 'balanced')\naccuracies = cross_val_score(model, features, labels, scoring='accuracy', cv=10)\nmodel_name = model.__class__.__name__\nfor fold_idx, accuracy in enumerate(accuracies):\n    entries.append((model_name, fold_idx, accuracy))\ncv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n\ncv_df.groupby('model_name').accuracy.mean()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## LSTM"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom nltk.corpus import stopwords\nSTOPWORDS = set(stopwords.words('english'))\n\nprint(tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hyperparamateres"},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab_size = 6000\nembedding_dim = 64\nmax_length = 300\ntrunc_type = 'post'\npadding_type = 'post'\noov_tok = '<OOV>'\ntraining_portion = .8","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.iloc[0,0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plots = []\ngenres = []\n\nfor i in range(len(df)):\n    genres.append(df.iloc[i,0])\n    plot = df.iloc[i,1]\n    for word in STOPWORDS:\n        token = ' ' + word + ' '\n        plot = plot.replace(token, ' ')\n        plot = plot.replace(' ', ' ')\n    plots.append(plot)\nprint(len(genres))\nprint(len(plots))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plots[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_size = int(len(plots) * training_portion)\n\ntrain_plots = plots[0: train_size]\ntrain_labels = genres[0: train_size]\n\nvalidation_plots = plots[train_size:]\nvalidation_labels = genres[train_size:]\n\nprint(train_size)\nprint(len(train_plots))\nprint(len(train_labels))\nprint(len(validation_plots))\nprint(len(validation_labels))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\ntokenizer.fit_on_texts(train_plots)\nword_index = tokenizer.word_index\ndict(list(word_index.items())[0:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_sequences = tokenizer.texts_to_sequences(train_plots)\nprint(train_sequences[10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\nprint(len(train_sequences[0]))\nprint(len(train_padded[0]))\n\nprint(len(train_sequences[1]))\nprint(len(train_padded[1]))\n\nprint(len(train_sequences[10]))\nprint(len(train_padded[10]))\n\n\nvalidation_sequences = tokenizer.texts_to_sequences(validation_plots)\nvalidation_padded = pad_sequences(validation_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n\nprint(len(validation_sequences))\nprint(len(validation_padded[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(validation_padded[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nle = LabelEncoder()\nY = le.fit_transform(genres)\nY = Y.reshape(-1,1)\nval_Y = Y[train_size:]\ntrain_Y = Y[0:train_size]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"\nmodel = tf.keras.Sequential([\n    # Add an Embedding layer expecting input vocab of size 5000, and output embedding dimension of size 64 we set at the top\n    tf.keras.layers.Embedding(vocab_size, embedding_dim),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim)),\n\n    tf.keras.layers.Dense(embedding_dim, activation='relu'),\n    # Add a Dense layer with 8 units and softmax activation.\n    # When we have multiple outputs, softmax convert outputs layers into a probability distribution.\n    tf.keras.layers.Dense(8, activation='softmax')\n])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nnum_epochs = 10\nhistory = model.fit(train_padded, train_Y, epochs=num_epochs, validation_data=(validation_padded, val_Y), verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def plot_graphs(history, string):\n  plt.plot(history.history[string])\n  plt.plot(history.history['val_'+string])\n  plt.xlabel(\"Epochs\")\n  plt.ylabel(string)\n  plt.legend([string, 'val_'+string])\n  plt.show()\n  \nplot_graphs(history, \"acc\")\nplot_graphs(history, \"loss\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}