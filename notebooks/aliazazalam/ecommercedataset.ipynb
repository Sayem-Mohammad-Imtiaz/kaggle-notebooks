{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import basic libraries\nimport pandas as pd\nimport numpy as np\nimport random as rnd\nimport csv\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nget_ipython().run_line_magic('matplotlib', 'inline')\n\n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom scipy import stats\nfrom sklearn.metrics import accuracy_score\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 1. Acquire Data\n#=================\ntrainData = pd.read_csv('../input/pakistans-largest-ecommerce-dataset/Pakistan Largest Ecommerce Dataset.csv',nrows=1000)\ntestData = pd.read_csv('../input/pakistans-largest-ecommerce-dataset/Pakistan Largest Ecommerce Dataset.csv', skiprows=range(1, 1000), nrows=1000)\ncombine=[trainData, testData]\nprint(trainData.shape)\nprint(testData.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preview the data\ntestData.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Analyze by describing data\nprint(trainData.columns.values)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Rename category name in both files\ntrainData.rename(columns={\" MV \": \"MV\", \"category_name_1\": \"category_name\"}, inplace = True)\ntestData.rename(columns={\" MV \": \"MV\", \"category_name_1\": \"category_name\"}, inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove unnamed feature columns from both testData and trainData\ntrainData.drop(trainData.columns[trainData.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\ntestData.drop(testData.columns[testData.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# View Data columns\nprint(trainData.shape)\nprint(testData.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets observe datatypes of features in the dataset\ntrainData.info()\nprint('_'*40)\ntestData.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# What is the distribution of numerical features\ntrainData.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check that columns have null values or not\ntrainData.count().sort_values()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# What is the distribution of categorical features\ntrainData.describe(include=['O'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Wrangle data\n# Removing unwanted features\ntrainData = trainData.drop(['sales_commission_code', 'MV','increment_id', 'sku', 'FY'], axis=1)\ntestData = testData.drop(['sales_commission_code', 'MV','increment_id', 'sku', 'FY'], axis=1)\ncombine = [trainData, testData]\n#view data\ntrainData.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check if any relationship exists between 'status' and 'BI Status' columns\ntrainData.groupby('BI Status')['status'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Replce REF to Unk (unknown) for better cleaning\ntrainData['BI Status'] = trainData['BI Status'].replace('#REF!', 'Unk')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check categories that are null\ntrainData['category_name'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Replacing the categories unicode label and NaN values with label 'Unknown'\ntrainData['category_name'] = trainData['category_name'].replace(r'\\\\N', 'Unknown', regex=True)\ntrainData['category_name'].fillna(\"Unknown\",inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check if any relationship exists between 'category' and 'status' columns\ntrainData.groupby('category_name')['status'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Status: We confirm the observation during problem definition that \n# Status=canceled had very high amount that payback to customers (classifying #1).\ntrainData[[\"status\",\"price\"]].groupby(['status'], as_index=False).mean(). sort_values(by='price', ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert the Status categorical status to ordinal.\ntitle_mapping = {\"complete\": 1, \"canceled\": 2, \"order_refunded\": 3, \"refund\": 4, \"received\": 5}\nfor dataset in combine:\n    dataset['status'] = dataset['status'].map(title_mapping)\n    dataset['status'] = dataset['status'].fillna(0)\n\ntrainData.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# View status records\ntrainData[\"status\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# What is the best-selling category?\n# The best selling category having max complete records is 'Beauty & Grooming'\ncomplete_dt = trainData[(trainData['status'] == 1)]\ncomplete_dt.groupby('category_name')['status'].value_counts().sort_values()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# View payment method records\ntrainData[\"payment_method\"].value_counts()\n# Visualize payment method and order status frequency\ntrainData.groupby(\"payment_method\")[\"status\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Correlating numerical features of payment_method and status\ng = sns.FacetGrid(trainData, col='payment_method')\ng.map(plt.hist, 'status', bins=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Correlating categorical and numerical features\ngrid = sns.FacetGrid(trainData, row='status', height=3, aspect=2)\ngrid.map(sns.pointplot, 'payment_method', 'Customer ID', 'category_name', palette='deep')\ngrid.add_legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert the payment_method categorical status to ordinal.\ntitle_mapping = {\"cod\": 1, \"mygateway\": 2, \"ublcreditcard\": 3, \"cashatdoorstep\":4, \"customercredit\": 5, \"customercredit\":6\n                 , \"mcblite\": 7, \"internetbanking\": 8\n                 , \"productcredit\": 9, \"marketingexpense\": 10}\nfor dataset in combine:\n    dataset['payment_method'] = dataset['payment_method'].map(title_mapping).astype(int)\n\n# view data\ntrainData[\"payment_method\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert the category_name categorical status to ordinal.\ntitle_mapping = {\"Beauty & Grooming\": 1, \"Soghaat\": 2, \"Men's Fashion\": 3, \"Women's Fashion\": 4\n                 , \"Mobiles & Tablets\": 5, \"Home & Living\": 6, \"Appliances\": 7, \"Unknown\": 8\n                , \"Kids & Baby\": 9, \"Computing\": 10,\"Health & Sports\": 11,\"Others\": 12\n                ,\"Entertainment\": 13,\"Books\": 14,\"Superstore\": 15}\nfor dataset in combine:\n    dataset['category_name'] = dataset['category_name'].map(title_mapping)\n    dataset['category_name'] = dataset['category_name'].fillna(0)\n\n# view data\ntestData[\"category_name\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create new feature combining existing features\n# Create a new feature for TotalPrice which combines price and qty_ordered. \n# This will enable us to drop price and qty_ordered from our datasets.\n\nfor dataset in combine:\n    dataset['TotalPrice'] = (dataset['price'] + dataset['qty_ordered'] + 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get corelation between payment method and total price\ntrainData[['payment_method', 'TotalPrice']].groupby(['payment_method'], as_index=False). mean().sort_values(by='TotalPrice', ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get corelation between payment method and total price\ntrainData[['status', 'TotalPrice']].groupby(['status'], as_index=False). mean().sort_values(by='TotalPrice', ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop price and qty_ordered features.\ntrainData = trainData.drop(['price', 'qty_ordered'], axis=1)\ntestData = testData.drop(['price', 'qty_ordered'], axis=1)\ncombine = [trainData, testData]\n\ntrainData.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainData['BI Status'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert the BI Status categorical status to ordinal.\nfor dataset in combine:\n    dataset['BI Status'] = dataset['BI Status'].map({\"Net\": 1, \"Gross\": 2, \"Valid\": 3, \"Unk\": 4}).astype(int)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Working with completed transactions\ndf_sales_segment = trainData.groupby('Customer ID')['TotalPrice'].sum().reset_index()\ndf_sales_segment.loc[df_sales_segment['TotalPrice'] > 5000000, :]\ndf_sales_segment","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Segmentation based on net amout spent by each customer on E-commerce store\ndf_sales_segment['sales_segment'] = ''\ndf_sales_segment.loc[df_sales_segment['TotalPrice'] <= 1000, 'sales_segment'] = 'very low'\ndf_sales_segment.loc[(df_sales_segment['TotalPrice'] > 1000) & (df_sales_segment['TotalPrice'] <= 10000), 'sales_segment'] = 'low'\ndf_sales_segment.loc[(df_sales_segment['TotalPrice'] > 10000) & (df_sales_segment['TotalPrice'] <= 50000), 'sales_segment'] = 'medium'\ndf_sales_segment.loc[df_sales_segment['TotalPrice'] > 50000, 'sales_segment'] = 'high'\ndf_sales_segment","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sales_segment_total = df_sales_segment.groupby('sales_segment')['TotalPrice'].sum().reset_index()\nsales_segment_total","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,6));\nsns.countplot(x='sales_segment', order=['very low','low', 'medium','high'], data=df_sales_segment)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainData.info()\ntestData.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now, lets do modeling for prediction\n# Based on supervised learning plus classification and regression, \n# we narrow down our choice of models to a few. These include:\n#    Logistic Regression\n#    KNN or k-Nearest Neighbors\n#    Support Vector Machines\n#    Naive Bayes classifier\n#    Decision Tree\n#    Random Forrest\n#    Perceptron\n#    Artificial neural network\n#    RVM or Relevance Vector Machine\n\n# X_train = trainData.drop(\"Survived\", axis=1)\n# Y_train = trainData[\"Survived\"]\n# X_test  = testData.drop(\"PassengerId\", axis=1).copy()\n# X_train.shape, Y_train.shape, X_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainData.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}