{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -U node2vec","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime\n\nimport warnings\nwarnings.filterwarnings('ignore')\nimport pandas as pd\nimport numpy as np\nimport json\nimport networkx as nx\nfrom networkx.drawing.nx_agraph import graphviz_layout\nfrom node2vec import Node2Vec\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\n\nimport re\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_files = []\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        if filename[-10:] == 'Tweets.CSV':\n            df = pd.read_csv(os.path.join(dirname, filename), index_col=None, header=0)\n            list_files.append(df)\n\ndf = pd.concat(list_files, axis=0, ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_by_country = df.groupby('is_quote').country_code.value_counts().unstack(0).reset_index()\ntweets_by_country = tweets_by_country.sort_values(by=False, ascending=False)\ntweets_by_country.columns = tweets_by_country.columns.astype(str)\ntweets_by_country['Total'] = tweets_by_country['False'] + tweets_by_country['True']\ntweets_by_country['PCT_False'] = tweets_by_country['False'] / tweets_by_country['Total']\ntweets_by_country['PCT_True'] = tweets_by_country['True'] / tweets_by_country['Total']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cmap = sns.cubehelix_palette(dark=.3, light=.8, as_cmap=True)\n\n# plt.figure(figsize=(10,10))\n# ax = sns.scatterplot(x='PCT_False', y='Total', data=tweets_by_country, alpha = 0.5, s = tweets_by_country['Total'])\n\n# for line in range(0,tweets_by_country.shape[0]):\n#      ax.text(tweets_by_country['PCT_False'][line], tweets_by_country['Total'][line], tweets_by_country['country_code'][line], \n#              horizontalalignment='left', size='small', color='black')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(figsize=(14, 5))\n\nsns.set_color_codes(\"pastel\")\nsns.barplot(x=\"country_code\", y=\"Total\", data=tweets_by_country[:20],\n            label=\"Total\", color=\"b\")\n\n\nsns.set_color_codes(\"muted\")\nsns.barplot(x=\"country_code\", y=\"True\", data=tweets_by_country[:20],\n            label=\"Quoted\", color=\"b\")\n\nax.legend(ncol=2, loc=\"lower right\", frameon=True)\nax.set(xlim=(0, 24), ylabel=\"\",\n       xlabel=\"Tweets quoted and not quoted by Country\")\nsns.despine(left=True, bottom=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ax = pd.to_datetime(df['account_created_at']).map(lambda x: datetime.date(x)).value_counts().plot(figsize=(14,5))\n# ax.set_xlim('2010-01-01','2020-03-30')\n# ax.set_title('Number of accounts created by day')\n# ax.set_xlabel('Day')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['hour'] = pd.to_datetime(df['created_at']).map(lambda x: x.hour)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = df['hour'].value_counts().sort_index().plot(figsize=(14,5), marker='o')\ndf[df['is_quote']==True]['hour'].value_counts().sort_index().plot(figsize=(14,5), marker='o', ax=ax)\ndf[df['is_quote']==False]['hour'].value_counts().sort_index().plot(figsize=(14,5), marker='o', ax=ax)\nax.set_title('Number of tweets by hour')\nax.set_xlabel('Hour')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf.groupby('is_quote').hour.value_counts(normalize=True).unstack(0).plot(figsize=(14,5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('hour').is_quote.value_counts(normalize=True).unstack(1)[True].plot(figsize=(14,5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['length_text'] = df['text'].map(lambda x: len(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_countries = tweets_by_country[:5]['country_code'].tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sort the dataframe by target\n# Use a list comprehension to create list of sliced dataframes\ntargets = [df.loc[df['country_code'] == val] for val in top_countries]\n\n# Iterate through list and plot the sliced dataframe\n\nf, ax = plt.subplots(figsize=(14, 6))\n\nfor target in targets:\n    sns.distplot(target[['length_text']], hist=True, rug=False, \n                 kde=False, hist_kws=dict(alpha=0.1), label=target['country_code'].unique())\n\nax.legend(ncol=1, loc=\"upper right\", frameon=True)\nax.set(xlim=(0, 400), ylabel=\"\",\n       xlabel=\"Distribution of length of tweets\")\nsns.despine(right=True, top=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cmap = sns.cubehelix_palette(dark=.3, light=.8, as_cmap=True)\n\nplt.figure(figsize=(10,10))\nax = sns.scatterplot(x='retweet_count', y='favourites_count', data=df, alpha = 0.5)\n\nfor line in range(0,tweets_by_country.shape[0]):\n     ax.text(df['retweet_count'][line], df['favourites_count'][line], df['country_code'][line], \n             horizontalalignment='left', size='small', color='black')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract(start, tweet):\n\n    words = tweet.split()\n    return [word[1:] for word in words if word[0] == start]\n\ndef strip_punctuation(s):\n    return s.translate(str.maketrans('','','!\"$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'))\n\ndef extract_hashtags(tweet):\n    hashtags = [strip_punctuation(tag) for tag in extract('#', tweet)]\n\n    result = []\n    for tag in hashtags:\n        if tag.lower() not in result:  \n            result.append(tag.lower())\n    return result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['hashtags'] = df['text'].apply(extract_hashtags)\ndf2 = df[['text', 'hashtags', 'country_code']]\ndf2 = df2[[len(p)>1 for p in df2['hashtags']]]\ndf2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country='US'\n\nlist_Hashtags = df2[df2.country_code==country]['hashtags'].tolist()\n                   \nH = nx.DiGraph()\n\nfor L in list_Hashtags:\n    for i in range(len(L)):\n        for j in range(i,len(L)):\n            H.add_edge(L[i], L[j])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of nodes: {}'.format(H.number_of_nodes()))\nprint('Number of edges: {}'.format(H.number_of_edges()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_strongly_cc(G, node):\n    \"\"\" get storngly connected component of node\"\"\" \n    for cc in nx.strongly_connected_components(G):\n        if node in cc:\n            return cc\n    else:\n        return set()\n\ndef get_weakly_cc(G, node):\n    \"\"\" get weakly connected component of node\"\"\" \n    for cc in nx.weakly_connected_components(G):\n        if node in cc:\n            return cc\n    else:\n        return set()\n    \n\ndef connected_component_subgraphs(G):\n    \"\"\" get all connected component of node\"\"\" \n    for c in nx.connected_components(G):\n        yield G.subgraph(c)\n        \n    \ndef get_strongly_gcc(G):\n    \"\"\" get the giant strongly connected component of G\"\"\" \n    SGcc = []\n    for node in G.nodes():\n        strong_component = get_strongly_cc(G, node)  \n        if len(strong_component) > len(SGcc):\n            SGcc = strong_component\n    return SGcc\n\ndef get_weakly_gcc(G):\n    \"\"\" get the giant weakly connected component of G\"\"\" \n    WGcc = []\n    for node in G.nodes():\n        strong_component = get_weakly_cc(G, node)  \n        if len(strong_component) > len(WGcc):\n            WGcc = strong_component\n    return WGcc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SGH1 = get_strongly_gcc(H)\nSGH1 = H.subgraph(SGH1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"degrees_h = H.degree()\n\nnodes_highest_degree = [n for (n, deg) in degrees_h if degrees_h[n] > 10]\nH_highest = H.subgraph(nodes_highest_degree)\n\ndegrees_highest = H_highest.degree()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of nodes: {}'.format(SGH1.number_of_nodes()))\nprint('Number of edges: {}'.format(SGH1.number_of_edges()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SGH2 = sorted(connected_component_subgraphs(H), key=len, reverse=True)[0]\n\nprint('Number of nodes: {}'.format(SGH2.number_of_nodes()))\nprint('Number of edges: {}'.format(SGH2.number_of_edges()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"degrees_h = SGH1.degree()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with plt.style.context('ggplot'):\n    \n    plt.loglog(sorted([n[1] for n in list(degrees_h)], reverse=True))\n    plt.title(\"Degree rank plot\")\n    plt.ylabel(\"degree\")\n    plt.xlabel(\"rank\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(num=None, figsize=(15, 15), dpi=50, facecolor='w', edgecolor='k')\n\npos = nx.spring_layout(H_highest)\n\n# nodes\nnx.draw_networkx_nodes(H_highest, pos, nodelist=dict(degrees_highest).keys(), \n                       node_size=[v * 3 for v in dict(degrees_highest).values()], alpha=0.5)\n\n# edges\nnx.draw_networkx_edges(H_highest, pos, width=0.3, alpha=0.3, edge_color='b')\n\n# labels\nnx.draw_networkx_labels(H_highest, pos, font_size=7, font_family='sans-serif')\n\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nodes = df[['user_id', 'country_code']].drop_duplicates().dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"edges = df[~df['reply_to_user_id'].isna()][['user_id', 'reply_to_user_id']].drop_duplicates()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nodes = pd.merge(nodes, edges.groupby('user_id').count().rename(columns={'reply_to_user_id': 'out'}), how='left',\n            left_on='user_id', right_on='user_id').fillna(0)\n\nnodes = pd.merge(nodes, edges.groupby('reply_to_user_id').count().rename(columns={'user_id': 'in'}), how='left',\n            left_on='user_id', right_on='reply_to_user_id').fillna(0)\n\nnodes = nodes[nodes['in'] > 0]\nnodes = nodes[nodes['out'] > 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nodes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"G = nx.from_pandas_edgelist(edges, 'user_id', 'reply_to_user_id', create_using=nx.DiGraph())\nnx.set_node_attributes(G, pd.Series(nodes['in'].to_list(), index=nodes.user_id).to_dict(), 'in')\nnx.set_node_attributes(G, pd.Series(nodes['out'].to_list(), index=nodes.user_id).to_dict(), 'out')\nnx.set_node_attributes(G, pd.Series(nodes['country_code'].to_list(), index=nodes.user_id).to_dict(), 'country')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of nodes: {}'.format(G.number_of_nodes()))\nprint('Number of edges: {}'.format(G.number_of_edges()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nodes_us = [x for x,y in G.nodes(data=True) if ('country' in y.keys() and 'US' in y['country'])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"G_US = G.subgraph(nodes_us)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"degrees_us = G_US.degree()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(num=None, figsize=(15, 15), dpi=50, facecolor='w', edgecolor='k')\n\npos = nx.spring_layout(G_US)\n\n# nodes\nnx.draw_networkx_nodes(G_US, pos, nodelist=dict(degrees_us).keys(), \n                       node_size=[v * 40 for v in dict(degrees_us).values()], alpha=0.5)\n\n# edges\nnx.draw_networkx_edges(G_US, pos, width=0.3, alpha=1, edge_color='b')\n\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of nodes: {}'.format(G_US.number_of_nodes()))\nprint('Number of edges: {}'.format(G_US.number_of_edges()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n2v_obj = Node2Vec(H_highest, dimensions=10, walk_length=5, num_walks=10, p=1, q=1, workers=1)\n#node2vec = Node2Vec(H, dimensions=64, walk_length=30, num_walks=200, workers=4) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n2v_model = n2v_obj.fit(window=3, min_count=1, batch_words=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom sklearn.manifold import TSNE\n\ndef get_embeddings(model, nodes):\n    \"\"\"Extract representations from the node2vec model\"\"\"\n    embeddings = [list(model.wv.get_vector(n)) for n in nodes]\n    embeddings = np.array(embeddings)\n    print(embeddings.shape)\n    return embeddings\n\ndef dim_reduction(embeddings, labels, frac=None, tsne_obj=TSNE(n_components=2)):\n    \"\"\"Dimensionality reduction with t-SNE. Sampling random instances is supported.\"\"\"\n    N = len(embeddings)\n    print(N)\n    if frac != None:\n        idx = np.random.randint(N, size=int(N*frac))\n        X = embeddings[idx,:]\n        X_labels = [labels[i] for i in idx]\n    else:\n        X = embeddings\n        X_labels = labels\n    X_embedded = tsne_obj.fit_transform(X)\n    print(\"t-SNE object was trained on %i records!\" % X.shape[0])\n    print(X_embedded.shape)\n    return X_embedded, X_labels\n\ndef visu_embeddings(X_embedded, X_labels=None, colors = ['r','b']):\n    if X_labels != None:\n        label_map = {}\n        for i, l in enumerate(usr_tsne_lab):\n            if not l in label_map:\n                label_map[l] = []\n            label_map[l].append(i)\n        fig, ax = plt.subplots(figsize=(15,15))\n        for i, lab in enumerate(label_map.keys()):\n            print(lab)\n            idx = label_map[lab]\n            x = list(X_embedded[idx,0])\n            y = list(X_embedded[idx,1])\n            #print(len(x),len(y))\n            ax.scatter(x, y, c=colors[i], label=lab, alpha=0.5, edgecolors='none')\n        plt.legend()\n    else:\n        plt.figure(figsize=(15,15))\n        x = list(X_embedded[:,0])\n        y = list(X_embedded[:,1])\n        plt.scatter(x, y, alpha=0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for node, _ in n2v_model.most_similar('coronavirus'):\n    # Show only players\n    if len(node) > 3:\n        print(node)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embeddings = [list(n2v_model.wv.get_vector(n)) for n in H_highest.nodes]\nembeddings = np.array(embeddings)\nprint(embeddings.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embeddings =get_embeddings(n2v_model, H_highest.nodes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"H_highest.nodes()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,15))\nx = list(embeddings[:,0])\ny = list(embeddings[:,1])\n\nfig, ax = plt.subplots(figsize=(15,15))\nax.scatter(x, y, alpha=0.5)\n\nfor i, txt in enumerate(list(Highest.nodes())):\n     if y[i] < -0.3*x[i] -0.1 or  y[i] > -0.3*x[i] + 0.3:\n        ax.annotate(txt, (x[i], y[i]))\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}