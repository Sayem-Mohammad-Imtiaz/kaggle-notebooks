{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport nltk\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn import naive_bayes\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f4bc04806e2a88e2a2aeb5c8af01d19768a5a0af"},"cell_type":"code","source":"df = pd.read_csv('../input/spam.csv', encoding = \"ISO-8859-1\")\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b3701611a8f9e66667f7beaefea02a96d4cbf50e"},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5c03cbf19f5267b223d4f6c8c248ed68b21f3280"},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5c38f2174272383fbcc4a2aba14f0774c076ff0c"},"cell_type":"code","source":"# Majority of the values in Unnamed: 2, Unnamed: 3 & Unnamed: 4 are null values\n# Dropping the three columns and renaming the columns v1 & v2\n\ndf.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1, inplace=True)\ndf.rename(columns={\"v1\":\"label\", \"v2\":\"sms\"}, inplace=True)\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"35773a6e7e6faf79423a9f702787253a6cfef609"},"cell_type":"code","source":"df.label.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fde1818bd98ca0bfa0fbacd7a8426b0edbd777e4"},"cell_type":"code","source":"# convert label to a numerical variable\ndf.label = pd.Categorical(df.label).codes\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4c6c740336ef6ff68ab8e6c8f8463251d8a414f1"},"cell_type":"code","source":"# Train the classifier if it is spam or ham based on the text\n# TFIDF Vectorizer\nstopset = set(stopwords.words('english'))\nvectorizer = TfidfVectorizer(use_idf=True, lowercase=True, strip_accents='ascii', stop_words=stopset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"82a27dd789009ae8ce233f9cb1c3a864a6acecad"},"cell_type":"code","source":"vectorizer.fit(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1f93406d409834fa33ebe9714370a54014f4005a"},"cell_type":"code","source":"y = df.label\n\nX = vectorizer.fit_transform(df.sms)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ffc79d5aee995dffa5fc71672c313cb2bc7479b4"},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"171dd0e1a91a99d789d78f5ceb22446028dde12b"},"cell_type":"markdown","source":"TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document)\n\nIDF(t) = log_e(Total number of documents / Number of documents with term t in it).\n\ntf-idf score=TF(t)*IDF(t)"},{"metadata":{"trusted":true,"_uuid":"cfbb77965585ca0c64f0816b585a0afd1b899053"},"cell_type":"code","source":"## Spliting the SMS to separate the text into individual words\nsplt_txt1=df.sms[0].split()\nprint(splt_txt1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"73ed9b67ad6064e762b143a15529bc241cc03599"},"cell_type":"code","source":"## Finding the most frequent word appearing in the SMS\nmax(splt_txt1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"917f736eea0c88b6cf70c555481e6384731b65c8"},"cell_type":"code","source":"## Count the number of words in the first SMS\nlen(splt_txt1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cae30f2dd8ad19a00b6e96d2a9751eee35f9a1d8"},"cell_type":"code","source":"X[0]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ab4c6e832b8e90242a7ec17f765ee1544372ab85"},"cell_type":"markdown","source":"It means in the first SMS there are 20 (len(splt_txt1)) words & out of which only 14 elements have been taken, that's why we'll get only 14 tf-idf values for the first the SMS.\n\nLikewise elements or words of all other SMSes are taken into consideration"},{"metadata":{"trusted":true,"_uuid":"55b8bd3031fbbbd9f2e9f9238afc459be5c2eaae"},"cell_type":"code","source":"print(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5027fa2717c6e7585d8638dca7d08d3e1de33a79"},"cell_type":"code","source":"## Spliting the SMS to separate the text into individual words\nsplt_txt2 = df.sms[1].split()\nprint(splt_txt2)\nprint(max(splt_txt2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"61410eed74f9e8a603d6cba87fa8cf9e65e52f5f"},"cell_type":"code","source":"## The most freaquent word across all the SMSes\nmax(vectorizer.get_feature_names())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c528da7a73a56083884b880c44aa59285b57a41"},"cell_type":"code","source":"print (y.shape)\nprint (X.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5433f6d4120e58260c12abd0916974584698b216"},"cell_type":"code","source":"##Split the test and train\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10, test_size = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c530c3b313ed88cdc7c8c4b49405e6438c2078d6"},"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0ae6d2b53b19c89c9741880a95287557afdfedfc"},"cell_type":"code","source":"## Let us try different models, and check how thye accuracy is for each of the models\n\nclf = naive_bayes.MultinomialNB()\nmodel = clf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f962b993a97bb956ebfe48efefe93921f1c1a818"},"cell_type":"code","source":"prediction = dict()\nprediction['Naive_Bayes'] = model.predict(X_test)\naccuracy_score(y_test, prediction[\"Naive_Bayes\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b667083434c4bc83061333c264442aed0fdf2fb3"},"cell_type":"code","source":"models = dict()\nmodels['Naive_Bayes'] = naive_bayes.MultinomialNB()\nmodels['SVC'] = SVC()\nmodels['KNC'] = KNeighborsClassifier()\nmodels['RFC'] = RandomForestClassifier()\nmodels['Adaboost'] = AdaBoostClassifier()\nmodels['Bagging'] = BaggingClassifier()\nmodels['ETC'] = ExtraTreesClassifier()\nmodels['GBC'] = GradientBoostingClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c7b47f45269caf32b4676a1c6fab4fcb2085b2c1"},"cell_type":"code","source":"results = dict()\naccuracies = dict()\n\nfor key, value in models.items():\n    value.fit(X_train, y_train)\n    output = value.predict(X_test)\n    accuracies[key] = accuracy_score(y_test, output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"086972bfb5fced13a8f90a9cfdbba10547e971ab"},"cell_type":"code","source":"accuracies","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"273838428b022bd6580256dd6b7b94f75b38d152"},"cell_type":"code","source":"# With the default values, Gradient Boost sems to be performing the best\n# Let's fine tune and make predictions\n\nparamGrid = dict(n_estimators=np.array([50, 100, 200,400,600,800,900]))\n\nmodel = GradientBoostingClassifier(random_state=10)\n\ngrid = GridSearchCV(estimator=model, param_grid=paramGrid)\n\ngrid_result = grid.fit(X_train, y_train)\n\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}