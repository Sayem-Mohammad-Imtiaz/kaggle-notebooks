{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport shutil\nimport math\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport seaborn as sns\n\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"print(tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_eval = pd.read_csv('/kaggle/input/house-price-prediction-challenge/train.csv')\ndf_test = pd.read_csv('/kaggle/input/house-price-prediction-challenge/test.csv')\n\ndf_train_eval.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_eval.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new = df_train_eval['ADDRESS'].str.split(',', n =1, expand = True)\ndf_train_eval['CITY'] = new[1]\ndf_train_eval.drop(columns='ADDRESS', axis = 1, inplace=True)\ndf_train_eval.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new1 = df_test['ADDRESS'].str.split(',', n =1, expand = True)\ndf_test['CITY'] = new[1]\ndf_test.drop(columns='ADDRESS', axis = 1, inplace=True)\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#splitting training set to train and evaluate\nnp.random.seed(seed=1)\nmask = np.random.rand(len(df_train_eval)) < 0.8\ndf_train = df_train_eval[mask]\ndf_eval = df_train_eval[~mask]\n\ndf_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df_train_eval)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(df_train_eval.corr())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Feature Engineering**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create Pandas Input Function\ndef create_input_fn(dataframe, Epochs):\n    return tf.compat.v1.estimator.inputs.pandas_input_fn(\n        x = dataframe,\n        y = dataframe['TARGET(PRICE_IN_LACS)'],\n        batch_size = 512,\n        num_epochs = Epochs,\n        shuffle = True,\n        queue_capacity = 1000,\n        num_threads = 1\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Defining the feature columns\ndef feature_cols():\n    long_buc = tf.feature_column.bucketized_column(\n        tf.feature_column.numeric_column('LONGITUDE'),\n        boundaries = np.arange(-38, 60, 4).tolist())\n    lat_buc = tf.feature_column.bucketized_column(\n        tf.feature_column.numeric_column('LATITUDE'),\n        boundaries = np.arange(-122, 153, 10).tolist())\n    \n    return [\n        tf.feature_column.numeric_column('SQUARE_FT'),\n        long_buc,\n        lat_buc,\n        tf.feature_column.indicator_column(\n            tf.feature_column.categorical_column_with_vocabulary_list(\n                'POSTED_BY', ['Owner', 'Dealer', 'Builder']\n            )\n        ),\n        tf.feature_column.indicator_column(\n            tf.feature_column.categorical_column_with_vocabulary_list(\n                'BHK_OR_RK', ['BHK', 'RK']\n            )\n        ),\n        tf.feature_column.indicator_column(\n            tf.feature_column.categorical_column_with_vocabulary_list(\n                'UNDER_CONSTRUCTION', df_train_eval['UNDER_CONSTRUCTION'].unique()\n            )\n        ),\n        tf.feature_column.indicator_column(\n            tf.feature_column.categorical_column_with_vocabulary_list(\n                'RERA', df_train_eval['RERA'].unique()\n            )\n        ),\n        tf.feature_column.indicator_column(\n            tf.feature_column.categorical_column_with_vocabulary_list(\n                'READY_TO_MOVE', df_train_eval['READY_TO_MOVE'].unique()\n            )\n        ),\n        tf.feature_column.indicator_column(\n            tf.feature_column.categorical_column_with_vocabulary_list(\n                'RESALE', df_train_eval['RESALE'].unique()\n            )\n        ),\n        tf.feature_column.numeric_column('BHK_NO.'),\n        tf.feature_column.embedding_column(\n            tf.feature_column.crossed_column([long_buc, lat_buc],hash_bucket_size=400), dimension = 10\n        ), \n        tf.feature_column.indicator_column(\n            tf.feature_column.categorical_column_with_hash_bucket('CITY', hash_bucket_size=4500)\n        )\n    ]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Train And Evaluate**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def serving_input_receiver_fn():\n    feature_placeholders = {\n        cols: tf.placeholder(tf.float32, [None, len(df_train_eval.columns)])\n    }\n    \n    features = {\n        key: tf.expand_dims(tensor, -1)\n        for key, tensor in feature_placeholders.items()\n    }\n    features[cols] = tf.squeeze(features[cols], axis = [2])\n    \n    return tf.estimator.export.ServingInputReceiver(features, feature_placeholders)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_eval(output_dir, num_steps):\n    optimizer = tf.compat.v1.train.FtrlOptimizer(learning_rate=0.02)\n    estimator = tf.compat.v1.estimator.LinearRegressor(\n        model_dir = output_dir, feature_columns=feature_cols(), optimizer = optimizer)\n    \n    #adding root mean square error evaluation metric\n    def eval_rmse(labels, predictions):\n        pred_values = tf.cast(predictions['predictions'], tf.float64)\n        return {'rmse': tf.compat.v1.metrics.root_mean_squared_error(labels, pred_values)}\n    estimator = tf.compat.v1.estimator.add_metrics(estimator, eval_rmse)\n    \n    train_spec = tf.estimator.TrainSpec(input_fn=create_input_fn(df_train, None), max_steps = num_steps)\n    \n    exporter = tf.estimator.LatestExporter('exporter', serving_input_receiver_fn)\n    \n    eval_spec = tf.estimator.EvalSpec(input_fn=create_input_fn(df_eval, 1), \n                                      steps=None,\n                                      start_delay_secs = 1,\n                                      throttle_secs = 5)\n    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outputdir = '/kaggle/working'\n\nshutil.rmtree(outputdir, ignore_errors=True) #this is set the output directory t start afresh everytime\ntf.compat.v1.summary.FileWriterCache.clear()\ntrain_eval(outputdir, 2000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}