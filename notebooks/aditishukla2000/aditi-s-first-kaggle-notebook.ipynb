{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nimport matplotlib.pyplot as plt \nimport seaborn as sn\nfrom sklearn import metrics\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.tree import export_graphviz\nfrom sklearn.model_selection import GridSearchCV\nimport pydotplus as pdot\nfrom IPython.display import Image\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-13T10:46:16.47099Z","iopub.execute_input":"2021-08-13T10:46:16.47141Z","iopub.status.idle":"2021-08-13T10:46:16.483852Z","shell.execute_reply.started":"2021-08-13T10:46:16.471371Z","shell.execute_reply":"2021-08-13T10:46:16.48271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install pydotplus","metadata":{"execution":{"iopub.status.busy":"2021-08-13T10:46:16.485689Z","iopub.execute_input":"2021-08-13T10:46:16.48598Z","iopub.status.idle":"2021-08-13T10:46:23.625639Z","shell.execute_reply.started":"2021-08-13T10:46:16.485953Z","shell.execute_reply":"2021-08-13T10:46:23.624563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"diabetes = pd.read_csv(\"/kaggle/input/pima-indians-diabetes-database/diabetes.csv\")\ndiabetes.info()\n\nprint(diabetes.shape)\n\nprint(diabetes.head(5))","metadata":{"execution":{"iopub.status.busy":"2021-08-13T10:46:23.628252Z","iopub.execute_input":"2021-08-13T10:46:23.628707Z","iopub.status.idle":"2021-08-13T10:46:23.656921Z","shell.execute_reply.started":"2021-08-13T10:46:23.628654Z","shell.execute_reply":"2021-08-13T10:46:23.65571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploratory Data Analysis: EDA","metadata":{}},{"cell_type":"markdown","source":"### EDA#1: Correlation Matrix","metadata":{}},{"cell_type":"code","source":"# Create Correlation Matrix\ncorrMatrix = diabetes.corr()\nsn.heatmap(corrMatrix, annot=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-13T10:46:23.658963Z","iopub.execute_input":"2021-08-13T10:46:23.65942Z","iopub.status.idle":"2021-08-13T10:46:24.331941Z","shell.execute_reply.started":"2021-08-13T10:46:23.659376Z","shell.execute_reply":"2021-08-13T10:46:24.330877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b> The correlation matrix suggests that there is notable positive corelation of value 0.47 between Glucose and Outcome. <b>","metadata":{}},{"cell_type":"markdown","source":"## Split predictors and target variable","metadata":{}},{"cell_type":"code","source":"# Split predictors and target variable\n\nX = diabetes.loc[:, diabetes.columns != 'Outcome']\ny = diabetes[\"Outcome\"]\n\n# Split data into Test & Training dataset\ntrain_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.20)","metadata":{"execution":{"iopub.status.busy":"2021-08-13T10:46:24.333289Z","iopub.execute_input":"2021-08-13T10:46:24.333671Z","iopub.status.idle":"2021-08-13T10:46:24.342182Z","shell.execute_reply.started":"2021-08-13T10:46:24.333638Z","shell.execute_reply":"2021-08-13T10:46:24.341063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Build a Confusion Matrix","metadata":{}},{"cell_type":"code","source":"##Importing the metrics  from sklearn import metrics \n##Defining the matrix to draw the confusion matrix from actual and  ##predicted class labels \ndef draw_cm( actual, predicted):\n    #Invoking confusion_matrix from metric package. The matrix  \n    #will be oriented as [1,0] i.e. the classes with label 1 will be  \n    #represented by the first row and 0 as second row  \n    cm = metrics.confusion_matrix( actual, predicted, [1,0])  \n    #Confusion will be plotted as heatmap for better visualization  \n    #The labels are configured to better interpretation from the plot  \n    sn.heatmap(cm, annot=True, fmt='.2f',  \n               xticklabels = [\"Diabetes-Yes\", \"Diabetes-No\"],  \n               yticklabels = [\"Diabetes-Yes\", \"Diabetes-No\"])  \n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-13T10:46:24.343475Z","iopub.execute_input":"2021-08-13T10:46:24.343764Z","iopub.status.idle":"2021-08-13T10:46:24.356326Z","shell.execute_reply.started":"2021-08-13T10:46:24.343736Z","shell.execute_reply":"2021-08-13T10:46:24.355178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Build / Train Random Forest Model","metadata":{}},{"cell_type":"code","source":"## Initializing the Random Forest Classifier with max_depth and n_estimators\nrf_classifier = RandomForestClassifier(max_depth=10, n_estimators=10)\nrf_classifier.fit(train_X, train_y)","metadata":{"execution":{"iopub.status.busy":"2021-08-13T10:46:24.357549Z","iopub.execute_input":"2021-08-13T10:46:24.357828Z","iopub.status.idle":"2021-08-13T10:46:24.407127Z","shell.execute_reply.started":"2021-08-13T10:46:24.357802Z","shell.execute_reply":"2021-08-13T10:46:24.406073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"### Calculate Precision, Recall, f1-score, Support values","metadata":{}},{"cell_type":"code","source":"pred_y = rf_classifier.predict(test_X)\nprint( metrics.classification_report( test_y, pred_y)) ","metadata":{"execution":{"iopub.status.busy":"2021-08-13T10:46:24.409448Z","iopub.execute_input":"2021-08-13T10:46:24.409771Z","iopub.status.idle":"2021-08-13T10:46:24.424659Z","shell.execute_reply.started":"2021-08-13T10:46:24.40974Z","shell.execute_reply":"2021-08-13T10:46:24.423732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Print confusion matrix","metadata":{}},{"cell_type":"code","source":"#Print confusion matrix\ncm = draw_cm(test_y, pred_y)","metadata":{"execution":{"iopub.status.busy":"2021-08-13T10:46:24.426407Z","iopub.execute_input":"2021-08-13T10:46:24.42671Z","iopub.status.idle":"2021-08-13T10:46:24.624273Z","shell.execute_reply.started":"2021-08-13T10:46:24.426682Z","shell.execute_reply":"2021-08-13T10:46:24.623106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Finding important Features","metadata":{}},{"cell_type":"code","source":"#Create a dataframe to store the features and their corresponding #importances \nfeature_rank = pd.DataFrame( {'feature': train_X.columns,  'importance': rf_classifier.feature_importances_  }) \n##Sorting the features based on their importances with most  ##important feature at top. \nfeature_rank = feature_rank.sort_values('importance', ascending =  False) \nplt.figure(figsize=(8, 6)) \n#plot the values \nsn.barplot( y = 'feature', x = 'importance', data = feature_rank[0:10]);","metadata":{"execution":{"iopub.status.busy":"2021-08-13T10:46:24.625516Z","iopub.execute_input":"2021-08-13T10:46:24.625804Z","iopub.status.idle":"2021-08-13T10:46:24.842867Z","shell.execute_reply.started":"2021-08-13T10:46:24.625778Z","shell.execute_reply":"2021-08-13T10:46:24.841815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Build / Train Decision Tree Classifier","metadata":{}},{"cell_type":"code","source":"## Building Decision Tree Classifier using Gini Criteria\nclf_tree = DecisionTreeClassifier(criterion = 'gini', max_depth = 4)\nclf_tree.fit(train_X, train_y)","metadata":{"execution":{"iopub.status.busy":"2021-08-13T10:46:24.844296Z","iopub.execute_input":"2021-08-13T10:46:24.844679Z","iopub.status.idle":"2021-08-13T10:46:24.857313Z","shell.execute_reply.started":"2021-08-13T10:46:24.844646Z","shell.execute_reply":"2021-08-13T10:46:24.856256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Calculate Precision, Recall, f1-score, Support values","metadata":{}},{"cell_type":"code","source":"pred_y = clf_tree.predict(test_X)\nprint( metrics.classification_report( test_y, pred_y)) ","metadata":{"execution":{"iopub.status.busy":"2021-08-13T10:46:24.858948Z","iopub.execute_input":"2021-08-13T10:46:24.859738Z","iopub.status.idle":"2021-08-13T10:46:24.874789Z","shell.execute_reply.started":"2021-08-13T10:46:24.859688Z","shell.execute_reply":"2021-08-13T10:46:24.87367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Displaying the tree\nexport_graphviz(clf_tree,\n               out_file = \"chd_tree.odt\",\n               feature_names = train_X.columns,\n               filled = True)\n\n## Create the image file\nchd_tree_graph = pdot.graphviz.graph_from_dot_file('chd_tree.odt')\nchd_tree_graph.write_jpg('chd_tree.png')\n## Render the png file\nImage(filename='chd_tree.png')","metadata":{"execution":{"iopub.status.busy":"2021-08-13T10:46:24.876372Z","iopub.execute_input":"2021-08-13T10:46:24.876989Z","iopub.status.idle":"2021-08-13T10:46:25.211194Z","shell.execute_reply.started":"2021-08-13T10:46:24.876944Z","shell.execute_reply":"2021-08-13T10:46:25.210178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Print confusion matrix\ncm = draw_cm(test_y, pred_y)","metadata":{"execution":{"iopub.status.busy":"2021-08-13T10:47:36.05985Z","iopub.execute_input":"2021-08-13T10:47:36.060569Z","iopub.status.idle":"2021-08-13T10:47:36.267159Z","shell.execute_reply.started":"2021-08-13T10:47:36.060508Z","shell.execute_reply":"2021-08-13T10:47:36.266086Z"},"trusted":true},"execution_count":null,"outputs":[]}]}