{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/heart-attack-analysis-prediction-dataset/heart.csv')\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df.duplicated()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Shape befroe drop duplicates {}'.format(df.shape))\ndf.drop_duplicates(inplace=True)\nprint('Shape befroe drop duplicates {}'.format(df.shape))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['thall'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploratory Data Analysis","metadata":{}},{"cell_type":"markdown","source":"1. age - age in years\n\n2. sex - sex (1 = male; 0 = female)\n\n3. cp - chest pain type (1 = typical angina; 2 = atypical angina; 3 = non-anginal pain; 4 = asymptomatic)\n\n4. trestbps - resting blood pressure (in mm Hg on admission to the hospital)\n\n5. chol - serum cholestoral in mg/dl\n\n6. fbs - fasting blood sugar > 120 mg/dl (1 = true; 0 = false)\n\n7. restecg - resting electrocardiographic results (0 = normal; 1 = having ST-T; 2 = hypertrophy)\n\n8. thalach - maximum heart rate achieved\n\n9. exang - exercise induced angina (1 = yes; 0 = no)\n\n10. oldpeak - ST depression induced by exercise relative to rest\n\n11. slope - the slope of the peak exercise ST segment (1 = upsloping; 2 = flat; 3 = downsloping)\n\n12. ca - number of major vessels (0-3) colored by flourosopy\n\n13. thal - 2 = normal; 1 = fixed defect; 3 = reversable defect\n\n14. num - the predicted attribute - diagnosis of heart disease (angiographic disease status) (Value 0 = < diameter narrowing; Value 1 = > 50% diameter narrowing)","metadata":{}},{"cell_type":"code","source":"num_feature = ['age', 'trtbps', 'chol', 'thalachh', 'oldpeak']\ncat_feature = ['sex', 'cp', 'fbs', 'restecg', 'exng', 'slp', 'caa', 'thall']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(13,13))\nplt.subplot(2,3,1)\nsns.violinplot(x = 'sex', y = 'output', data = df)\nplt.subplot(2,3,2)\nsns.violinplot(x = 'thall', y = 'output', data = df)\nplt.subplot(2,3,3)\nsns.violinplot(x = 'exng', y = 'output', data = df)\nplt.subplot(2,3,4)\nsns.violinplot(x = 'restecg', y = 'output', data = df)\nplt.subplot(2,3,5)\nsns.violinplot(x = 'cp', y = 'output', data = df)\nplt.xticks(fontsize=9, rotation=45)\nplt.subplot(2,3,6)\nsns.violinplot(x = 'fbs', y = 'output', data = df)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for idx, feature in enumerate(cat_feature):\n    sns.countplot(data=df, x=feature)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(10,10))\ndf_corr = df[num_feature].corr().transpose()\nmask = np.triu(np.ones_like(df_corr))\nsns.heatmap(df_corr,mask=mask,fmt=\".1f\",annot=True,cmap='YlGnBu')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(10,10))\ndf_corr = df[cat_feature].corr().transpose()\nmask = np.triu(np.ones_like(df_corr))\nsns.heatmap(df_corr,mask=mask,fmt=\".1f\",annot=True,cmap='YlGnBu')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(10,10))\ndf_corr = df.corr().transpose()\nmask = np.triu(np.ones_like(df_corr))\nsns.heatmap(df_corr,mask=mask,fmt=\".1f\",annot=True,cmap='YlGnBu')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for feature in num_feature:\n    sns.distplot(df[feature])\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data preprocessing and Modeling","metadata":{}},{"cell_type":"code","source":"X = df.drop(['output'], axis=1)\ny = df['output']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_cat = X[cat_feature].drop(['fbs'], axis=1)\ndf_num = X[num_feature]\ndf_cat.shape, df_num.shape, y.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_cat.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_num.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sex = {1: 'Male', 0: 'Female'}\ncp = {0: 'typical angina', 1: 'atypical angina', 2: 'non-anginal pain', 3: 'asymptomatic'}\nrestecg = {0: 'Normal_restecg', 1: 'Having ST-T', 2: 'Hypertrophy'}\nexng = {0: 'exang_no', 1: 'exang_yes'}\nslope = {0: 'upsloping', 1: 'flat', 2: 'downsloping'}\nca = {0: 'ca_level1', 1: 'ca_level2', 2: 'ca_level3'}\nthal = {0: None, 1: 'fixed defect', 2: 'Normal', 3: 'reversable defect'}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_cat = df_cat.replace({'sex': sex})\ndf_cat = df_cat.replace({'cp': cp})\ndf_cat = df_cat.replace({'restecg': restecg})\ndf_cat = df_cat.replace({'exng': exng})\ndf_cat = df_cat.replace({'slp': slope})\ndf_cat = df_cat.replace({'caa': ca})\ndf_cat = df_cat.replace({'thall': thal})\ndf_cat = df_cat.reset_index()\ndf_cat = df_cat.drop(['index'], axis=1)\ndf_cat","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_cat = pd.get_dummies(df_cat, columns=['sex', 'cp', 'restecg', 'exng', 'slp', 'caa', 'thall'])\ndf_cat.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Scaler for num feature\nfrom sklearn.preprocessing import StandardScaler\nstd_scale = StandardScaler()\ndf_num_scale = pd.DataFrame(std_scale.fit(df_num).transform(df_num))\ndf_num_scale.columns = df_num.columns\ndf_num_scale","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_ex = pd.concat([df_num_scale, df_cat], axis=1)\ndf_ex","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Shape before feature engineering has Rows = {0} and Columns = {1}'.format(df.shape[0], df.shape[1]))\nprint('Shape before Modeling has Rows = {0} and Columns = {1}'.format(df_ex.shape[0], df_ex.shape[1]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(df_ex, y, test_size=0.2, random_state=0)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nclf1 = LogisticRegression(random_state=0, penalty='l2').fit(X_train, y_train)\nclf1.score(X_test, y_test), clf1.score(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nclf2 = RandomForestClassifier(criterion='entropy', n_estimators=50, max_depth=2,random_state=0).fit(X_train, y_train)\nclf2.score(X_test, y_test), clf2.score(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\nclf3 = GradientBoostingClassifier(n_estimators=100, learning_rate=0.05, max_depth=1, random_state=0).fit(X_train, y_train)\nclf3.score(X_test, y_test), clf3.score(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nclf4 = GaussianNB().fit(X_train, y_train)\nclf4.score(X_test, y_test), clf4.score(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier\neclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gbc', clf3), ('gnb', clf4)], voting='hard')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfor clf, label in zip([clf1, clf2, clf3, clf4, eclf], ['Logistic Regression', 'Random Forest', 'GradientBoostingClassifier','naive Bayes', 'Ensemble']):\n    scores = cross_val_score(clf, X_train, y_train, scoring='accuracy', cv=5)\n    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}