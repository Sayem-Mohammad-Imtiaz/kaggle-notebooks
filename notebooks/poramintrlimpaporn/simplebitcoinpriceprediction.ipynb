{"cells":[{"metadata":{},"cell_type":"markdown","source":"**This is my personal notebook, I'm just trying out. But feel free to educate me! Any tip would be appreciated.**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#0. Get the data\nimport pandas as pd\ndata = pd.read_csv(\"/kaggle/input/bitcoin-historical-data/bitstampUSD_1-min_data_2012-01-01_to_2020-09-14.csv\")\ndata.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#1. Prepare the data\n#Take a look at missing data\nimport numpy as np\nmissing_values = data.isnull().sum() #how many values are missing\ntotal_cells = np.prod(data.shape)\ntotal_missings = missing_values.sum()\n\npercent_missings = (total_missings / total_cells) * 100\npercent_missings","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Drop missing values\ndata = data.dropna()\n#Or fill missing values with data.fillna(method='bfill', axis=0).fillna(0) in this case with the value before.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create the input data\nX = data.iloc[:, 0:7] #input data\nX.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create the target data\ny = data.iloc[:, 7]\ny.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#preprocess the input data\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_scaled = scaler.fit_transform(X)\n\n#1 day = 1,440 minutes\n#30 days = 43,200 minutes\n#60 days = 86,400 minutes\n#90 days = 129,600 minutes\nX_scaled = X_scaled[len(X_scaled) - 129600:] #data from the last 90 days\ny = y[len(y) - 129600:].values #convert from Series to ndarray.\nprint(\"X_scaled\\'s shape: {}\".format(X_scaled.shape))\nprint(\"y\\'s shape: {}\".format(y.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create the train, test, and validation set\nfrom sklearn.model_selection import train_test_split\nX_train_full,X_test, y_train_full,y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=1)\nX_train,X_valid, y_train,y_valid = train_test_split(X_train_full, y_train_full, test_size=0.15, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Regression MLPs (predict a single output given many features, one output neuron)\n\n(for more output = more output neurons a neuron per output)\n\n(No activation fn for the output neurons, so they are free to output any range of values)\n\n(loss fn is typically mse if lot of outliers, or else mae, or Huber loss (combination of mse and mae)) "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create a simple NN model\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom numpy.random import seed\nseed(1)\nmodel = keras.models.Sequential([\n    keras.layers.Dense(300, activation='relu', input_shape=(7,)),\n    keras.layers.Dense(100, activation='relu'),\n    keras.layers.Dense(1, activation='relu')\n])\n\noptimizer = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\nmodel.compile(loss='mean_squared_logarithmic_error', optimizer=optimizer, metrics=['mse'])\nhistory = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(X_test, y_test)[1] #(loss, metrics)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}