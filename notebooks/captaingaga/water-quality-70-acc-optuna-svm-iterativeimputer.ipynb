{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Imports","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn import ensemble\nfrom sklearn import metrics\nfrom sklearn import model_selection\nfrom sklearn import decomposition\nfrom sklearn import preprocessing\nfrom sklearn import base\nfrom sklearn import svm\n\nfrom sklearn import pipeline\nfrom functools import partial\nfrom skopt import space\nfrom skopt import gp_minimize\nfrom skopt import BayesSearchCV\n\nimport optuna","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Feature engineering","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/water-potability/water_potability.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def percent_missing(df):\n    \n    precent_nan = 100*df.isnull().sum() / len(df)\n    precent_nan = precent_nan[precent_nan>0].sort_values()\n    \n    return precent_nan","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"percent_missing(df)Ð¸","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imputer = IterativeImputer(estimator=ensemble.RandomForestRegressor(), imputation_order='ascending')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df.drop('Potability',axis=1)\ny = df['Potability']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imputer.fit(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Xtrans = imputer.transform(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dframe = pd.DataFrame(Xtrans,columns=df.columns[0:-1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dframe['Potability'] = y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"percent_missing(dframe)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(dframe,hue='Potability')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Standart RF","metadata":{}},{"cell_type":"code","source":"X = dframe.drop('Potability',axis=1)\ny = dframe['Potability']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = preprocessing.StandardScaler()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaled_X_train = scaler.fit_transform(X_train)\nscaled_X_test = scaler.transform(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifier = ensemble.RandomForestClassifier(n_jobs=-1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifier.fit(scaled_X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_preds = classifier.predict(scaled_X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix\nprint(classification_report(y_test,y_preds))\nconfusion_matrix(y_test,y_preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,8),dpi=150)\nfeat_importances = pd.Series(classifier.feature_importances_, index=X.columns)\nfeat_importances.nlargest(30).plot(kind='barh')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"RF + Bayesian Optimization with Gaussian Process","metadata":{}},{"cell_type":"code","source":"def optimize(params,param_names,x,y):\n    params = dict(zip(param_names,params))\n    model = ensemble.RandomForestClassifier(**params)\n    kf = model_selection.StratifiedKFold(n_splits=5)\n    accuracies = []\n    for idx in kf.split(X=x,y=y):\n        train_idx,test_idx = idx[0],idx[1]\n        \n        xtrain = x.iloc[train_idx]\n        ytrain = y.iloc[train_idx]\n        \n        xtest=x.iloc[test_idx]\n        ytest=y.iloc[test_idx]\n        \n        model.fit(xtrain,ytrain)\n        preds = model.predict(xtest)\n        fold_acc = metrics.accuracy_score(ytest,preds)\n        accuracies.append(fold_acc)\n    return -1.0 * np.mean(accuracies)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"param_space = [\n    space.Integer(2,30,name='max_depth'),\n    space.Integer(100,1500,name='n_estimators'),\n    space.Integer(1,20,name='min_samples_leaf'),\n    space.Categorical(['gini','entropy'],name='criterion'),\n    space.Real(0.01,1,prior='uniform',name='max_features')\n    \n]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"param_names= [\n    'max_depth',\n    'n_estimators',\n    'min_samples_leaf',\n    'criterion',\n    'max_features'\n]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimization_function = partial(\noptimize,\nparam_names=param_names,\nx=X,\ny=y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimization_function = partial(optimize,param_names=param_names,x=X,y=y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = gp_minimize(\noptimization_function,\ndimensions=param_space,\nn_calls=30,\nn_random_starts=10,\nverbose=0)\n\nprint(\ndict(zip(param_names,result.x))\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"RF + Optuna","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rf_objective(trial):\n    params = {\n        \"n_estimators\": trial.suggest_int('n_estimators', 10, 100),\n        \"max_depth\": trial.suggest_categorical(\"max_depth\", [7, 8, 9, 10, 11, 12, None]),\n        \"criterion\": trial.suggest_categorical('criterion', [\"gini\", \"entropy\"]),\n        \"min_samples_split\": trial.suggest_int('min_samples_split', 2, 5),\n        \"min_samples_leaf\": trial.suggest_categorical('min_samples_leaf', [1, 2]),\n        \"max_features\": trial.suggest_categorical('max_features', [\"auto\", \"sqrt\", \"log2\"]),\n        \"class_weight\": trial.suggest_categorical('class_weight', [\"balanced\"]),\n        \"random_state\": trial.suggest_categorical('random_state', [0]),\n        \"n_jobs\": trial.suggest_categorical('n_jobs', [-1]),\n    }\n    model = ensemble.RandomForestClassifier(**params)\n    model.fit(X_train, y_train)\n    return -accuracy_score(y_test, model.predict(X_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study.optimize(rf_objective, n_trials=200, timeout=3600 * 2)\nprint(f\"Best RandomForest accuracy: {-round(study.best_value, 4)} with parameters {study.best_params}\\n\\n\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"SVC","metadata":{}},{"cell_type":"code","source":"svc = svm.SVC()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svc.fit(scaled_X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svc_preds = svc.predict(scaled_X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix\nprint(classification_report(y_test,svc_preds))\nconfusion_matrix(y_test,svc_preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"SVC + Optuna","metadata":{}},{"cell_type":"code","source":"def svc_objective(trial):\n    params = {\n        \"C\": trial.suggest_float('C', 1e-10, 1e10, log=True),\n        \"kernel\": trial.suggest_categorical('kernel',['linear', 'poly', 'rbf', 'sigmoid']),\n        \"degree\": trial.suggest_int('degree',1,20,step=1 ),\n        \"gamma\": trial.suggest_categorical(\"gamma\",['scale', 'auto']),\n        \"max_iter\": trial.suggest_int('max_iter',1,10000,step=10),\n        \"decision_function_shape\": trial.suggest_categorical('decision_function_shape', ['ovo', 'ovr']),\n        \"class_weight\": trial.suggest_categorical('class_weight', [\"balanced\"]),\n        \"random_state\": trial.suggest_categorical('random_state', [0]),\n    }\n    model = svm.SVC(**params)\n    model.fit(scaled_X_train, y_train)\n    return -accuracy_score(y_test, model.predict(scaled_X_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"other_study = optuna.create_study()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"other_study.optimize(svc_objective, n_trials=500, timeout=3600 * 2)\nprint(f\"Best svc accuracy: {-round(other_study.best_value, 4)} with parameters {other_study.best_params}\\n\\n\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}