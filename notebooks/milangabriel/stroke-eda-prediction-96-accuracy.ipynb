{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Setting up the environment.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\r\nimport numpy as np\r\nimport seaborn as sns\r\nimport matplotlib.pyplot as plt\r\nprint('Priyatama is ready!')","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:13.680782Z","iopub.execute_input":"2021-09-10T06:22:13.681085Z","iopub.status.idle":"2021-09-10T06:22:13.687451Z","shell.execute_reply.started":"2021-09-10T06:22:13.681054Z","shell.execute_reply":"2021-09-10T06:22:13.68639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Reading the dataset.","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv')\r\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:13.707323Z","iopub.execute_input":"2021-09-10T06:22:13.708101Z","iopub.status.idle":"2021-09-10T06:22:13.74603Z","shell.execute_reply.started":"2021-09-10T06:22:13.707859Z","shell.execute_reply":"2021-09-10T06:22:13.744985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Exploratory data analysis.","metadata":{}},{"cell_type":"markdown","source":"## 3.1 Check for and deal with NA values.","metadata":{}},{"cell_type":"code","source":"sns.heatmap(df.isnull())","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:13.747975Z","iopub.execute_input":"2021-09-10T06:22:13.748283Z","iopub.status.idle":"2021-09-10T06:22:14.352183Z","shell.execute_reply.started":"2021-09-10T06:22:13.748244Z","shell.execute_reply":"2021-09-10T06:22:14.351334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = (df.isnull().sum())\r\nprint(a[a>0])\r\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:14.353391Z","iopub.execute_input":"2021-09-10T06:22:14.353739Z","iopub.status.idle":"2021-09-10T06:22:14.368728Z","shell.execute_reply.started":"2021-09-10T06:22:14.353688Z","shell.execute_reply":"2021-09-10T06:22:14.367514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"100*201/5110","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:14.371312Z","iopub.execute_input":"2021-09-10T06:22:14.371654Z","iopub.status.idle":"2021-09-10T06:22:14.379234Z","shell.execute_reply.started":"2021-09-10T06:22:14.371624Z","shell.execute_reply":"2021-09-10T06:22:14.378611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Around 4% of data points for BMI are blank, we can drop it.","metadata":{}},{"cell_type":"code","source":"df.dropna(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:14.380133Z","iopub.execute_input":"2021-09-10T06:22:14.38041Z","iopub.status.idle":"2021-09-10T06:22:14.399912Z","shell.execute_reply.started":"2021-09-10T06:22:14.380377Z","shell.execute_reply":"2021-09-10T06:22:14.399102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:14.40104Z","iopub.execute_input":"2021-09-10T06:22:14.40195Z","iopub.status.idle":"2021-09-10T06:22:14.408563Z","shell.execute_reply.started":"2021-09-10T06:22:14.401908Z","shell.execute_reply":"2021-09-10T06:22:14.407958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:14.409565Z","iopub.execute_input":"2021-09-10T06:22:14.410309Z","iopub.status.idle":"2021-09-10T06:22:14.459725Z","shell.execute_reply.started":"2021-09-10T06:22:14.410274Z","shell.execute_reply":"2021-09-10T06:22:14.458624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop('id', axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:14.461049Z","iopub.execute_input":"2021-09-10T06:22:14.461293Z","iopub.status.idle":"2021-09-10T06:22:14.467851Z","shell.execute_reply.started":"2021-09-10T06:22:14.461266Z","shell.execute_reply":"2021-09-10T06:22:14.466962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.2 Check and deal with unnecessary datapoints in all columns.","metadata":{}},{"cell_type":"code","source":"df.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:14.469215Z","iopub.execute_input":"2021-09-10T06:22:14.470069Z","iopub.status.idle":"2021-09-10T06:22:14.484807Z","shell.execute_reply.started":"2021-09-10T06:22:14.470023Z","shell.execute_reply":"2021-09-10T06:22:14.483889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.gender.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:14.488123Z","iopub.execute_input":"2021-09-10T06:22:14.488371Z","iopub.status.idle":"2021-09-10T06:22:14.502455Z","shell.execute_reply.started":"2021-09-10T06:22:14.488342Z","shell.execute_reply":"2021-09-10T06:22:14.501197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Only 1 datapoint has'gender' marked as other, we can drop it.","metadata":{}},{"cell_type":"code","source":"df2 = df[df.gender != 'Other']\r\ndf2.gender.value_counts().plot(kind='pie',autopct='%1.1f%%')","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:14.50393Z","iopub.execute_input":"2021-09-10T06:22:14.504228Z","iopub.status.idle":"2021-09-10T06:22:14.631058Z","shell.execute_reply.started":"2021-09-10T06:22:14.504201Z","shell.execute_reply":"2021-09-10T06:22:14.630109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax=plt.subplots(figsize=(20,5))\r\nsns.countplot(x=df2.age, palette='viridis')\r\nplt.xticks(rotation=90)\r\nplt.xlabel('\\n Age', fontsize=10, fontweight='bold')\r\nplt.ylabel('Count of Patients', fontsize=10, fontweight='bold')\r\nplt.title('Age of Different Patients', fontweight = 'bold', fontsize='15')\r\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:14.63232Z","iopub.execute_input":"2021-09-10T06:22:14.632742Z","iopub.status.idle":"2021-09-10T06:22:16.181804Z","shell.execute_reply.started":"2021-09-10T06:22:14.632715Z","shell.execute_reply":"2021-09-10T06:22:16.180664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Datapoints for patients younger than 2 years seem very few, we can drop it.","metadata":{}},{"cell_type":"code","source":"df3 = df2[~(df2['age'] <= 2)]","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:16.183592Z","iopub.execute_input":"2021-09-10T06:22:16.183989Z","iopub.status.idle":"2021-09-10T06:22:16.191012Z","shell.execute_reply.started":"2021-09-10T06:22:16.183947Z","shell.execute_reply":"2021-09-10T06:22:16.18997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig2, ax=plt.subplots(figsize=(20,5))\r\nsns.countplot(x=df3.age, palette='viridis')\r\nplt.xticks(rotation=90)\r\nplt.xlabel('\\n Age', fontsize=10, fontweight='bold')\r\nplt.ylabel('Count of Patients', fontsize=10, fontweight='bold')\r\nplt.title('Age of Different Patients', fontweight = 'bold', fontsize='15')\r\nplt.show()  ","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:16.19214Z","iopub.execute_input":"2021-09-10T06:22:16.192366Z","iopub.status.idle":"2021-09-10T06:22:17.31178Z","shell.execute_reply.started":"2021-09-10T06:22:16.192339Z","shell.execute_reply":"2021-09-10T06:22:17.310797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Range of age of data sample is vast.","metadata":{}},{"cell_type":"code","source":"stroke_0 = df3[~(df3['stroke'] == 1)]\r\nstroke_1 = df3[~(df3['stroke'] == 0)]\r\nsns.set(style=\"darkgrid\")\r\nfig3, (ax1, ax2) = plt.subplots(2,1, figsize=(15, 9))\r\n\r\nsns.histplot(x=stroke_0['age'], kde=True, color=\"skyblue\", ax=ax1)\r\nsns.histplot(x=stroke_1['age'], kde=True, color=\"olive\", ax=ax2)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:17.313281Z","iopub.execute_input":"2021-09-10T06:22:17.313572Z","iopub.status.idle":"2021-09-10T06:22:18.028268Z","shell.execute_reply.started":"2021-09-10T06:22:17.31354Z","shell.execute_reply":"2021-09-10T06:22:18.027118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### After ageof 40, the chances of Stroke increases significantly.","metadata":{}},{"cell_type":"code","source":"fig4, ax=plt.subplots(figsize=(20,5))\r\nlegend = ['No Stroke', 'Stroke']\r\nsns.set(style=\"darkgrid\")\r\nsns.histplot(x=df3['age'], hue=df3.stroke, palette='rocket')\r\nplt.xlabel('\\n Age', fontsize=10, fontweight='bold')\r\nplt.ylabel('Count of Patients', fontsize=10, fontweight='bold')\r\nplt.title('Age of Different Patients', fontweight = 'bold', fontsize='15')\r\nplt.show()  \r\n","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:18.030023Z","iopub.execute_input":"2021-09-10T06:22:18.030384Z","iopub.status.idle":"2021-09-10T06:22:18.497186Z","shell.execute_reply.started":"2021-09-10T06:22:18.030342Z","shell.execute_reply":"2021-09-10T06:22:18.496067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df3.hypertension.value_counts().plot(kind='barh')","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:18.499173Z","iopub.execute_input":"2021-09-10T06:22:18.499504Z","iopub.status.idle":"2021-09-10T06:22:18.736618Z","shell.execute_reply.started":"2021-09-10T06:22:18.499463Z","shell.execute_reply":"2021-09-10T06:22:18.734867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig5, ax=plt.subplots(figsize=(5,5))\r\nlegend1 = ['No Hypertension', 'Hypertension']\r\nsns.countplot(x=df3.gender,hue=df3.hypertension, palette='rocket')\r\nfor p in ax.patches:\r\n    ax.annotate(f'\\n{p.get_height()}', (p.get_x()+0.2, p.get_height()), ha='center', va='top', color='black', size=10)\r\nplt.xlabel('\\n Gender & Hypertension', fontsize=10, fontweight='bold')\r\nplt.ylabel('Count of Patients', fontsize=10, fontweight='bold')\r\nplt.title('Hypertension across Gender', fontweight = 'bold', fontsize='15')\r\nplt.show()  ","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:18.738093Z","iopub.execute_input":"2021-09-10T06:22:18.738333Z","iopub.status.idle":"2021-09-10T06:22:18.988118Z","shell.execute_reply.started":"2021-09-10T06:22:18.738306Z","shell.execute_reply":"2021-09-10T06:22:18.987042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig6, ax=plt.subplots(figsize=(20,5))\r\nax.set(facecolor='Grey')\r\nsns.set(style=\"whitegrid\")\r\nsns.histplot(x=df3['age'], hue=df3.hypertension, palette='rocket')\r\nplt.xlabel('\\n Age', fontsize=10, fontweight='bold')\r\nplt.ylabel('Count of Patients', fontsize=10, fontweight='bold')\r\nplt.title('Age of Different Patients v/s Hypertension', fontweight = 'bold', fontsize='15')\r\nplt.show()  \r\n","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:18.989643Z","iopub.execute_input":"2021-09-10T06:22:18.989928Z","iopub.status.idle":"2021-09-10T06:22:19.441597Z","shell.execute_reply.started":"2021-09-10T06:22:18.989898Z","shell.execute_reply":"2021-09-10T06:22:19.440419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### After age of 35, chances of Hypertension increases.","metadata":{}},{"cell_type":"code","source":"sns.set(style=\"darkgrid\")\r\nfig7, (ax1, ax2,ax3) = plt.subplots(3, 1, figsize=(15, 7))\r\n\r\nsns.histplot(x=df3['age'], hue=df3.hypertension,kde=True, color=\"skyblue\", ax=ax1)\r\nax1.set_xticks([])\r\nax1.set_xlabel('Age')\r\nsns.histplot(x=df3['age'], hue=df3.stroke,kde=True, color=\"olive\", ax=ax2)\r\nax2.set_xticks([])\r\nax2.set_xlabel(' ')\r\nsns.histplot(x=df3['age'], hue=df3.heart_disease,kde=True, color=\"gold\", ax=ax3)\r\nax3.set_xlabel('Age')\r\nplt.title(\"Hypertension - Stroke - Heart Disease v/s Age\", fontsize=15, fontweight='bold')","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:19.443221Z","iopub.execute_input":"2021-09-10T06:22:19.443464Z","iopub.status.idle":"2021-09-10T06:22:20.687553Z","shell.execute_reply.started":"2021-09-10T06:22:19.443436Z","shell.execute_reply":"2021-09-10T06:22:20.686324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### All health issues (Heart Disease, Stroke and Hypertension) increases after around age of 40.","metadata":{}},{"cell_type":"code","source":"df3.ever_married.value_counts().plot(kind='bar')","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:20.689181Z","iopub.execute_input":"2021-09-10T06:22:20.689535Z","iopub.status.idle":"2021-09-10T06:22:21.109678Z","shell.execute_reply.started":"2021-09-10T06:22:20.689501Z","shell.execute_reply":"2021-09-10T06:22:21.108778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig8, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 7))\r\n\r\nsns.set(style=\"darkgrid\")\r\n\r\nsns.countplot(x=stroke_0.ever_married, hue=stroke_0.gender, palette='viridis', ax=ax1)\r\nax1.set_xlabel('Marriage Status-No Stroke')\r\nfor p in ax1.patches:\r\n    ax1.annotate(f'\\n{p.get_height()}', (p.get_x()+0.2, p.get_height()), ha='center', va='top', color='black', size=10)\r\nax1.set_ylabel('Count of patient')\r\n\r\nsns.countplot(x=stroke_1.ever_married, hue=stroke_1.gender, palette='rocket', ax=ax2)\r\nax2.set_xlabel('Marriage Status-Stroke')\r\nax2.set_ylabel('')\r\nfor p in ax2.patches:\r\n    ax2.annotate(f'\\n{p.get_height()}', (p.get_x()+0.2, p.get_height()), ha='center', va='top', color='black', size=10)\r\nax2.set_yticks([])\r\nplt.show()  \r\n\r\n","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:21.111218Z","iopub.execute_input":"2021-09-10T06:22:21.111571Z","iopub.status.idle":"2021-09-10T06:22:21.53169Z","shell.execute_reply.started":"2021-09-10T06:22:21.111538Z","shell.execute_reply":"2021-09-10T06:22:21.53087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Female have a higher chance of having stroke be it married or not.","metadata":{}},{"cell_type":"code","source":"fig9, ax = plt.subplots(figsize=(5, 3))\r\n\r\nsns.set(style=\"darkgrid\")\r\n\r\nsns.countplot(x=df3['Residence_type'], hue=df3.stroke, palette='viridis')\r\nplt.title('Residence Type v/s Stroke', fontsize=15, fontweight='bold')\r\nplt.xlabel('Residence Type',fontsize=10, fontweight='bold')\r\nplt.ylabel('Patients',fontsize=10, fontweight='bold')\r\nfor p in ax.patches:\r\n    ax.annotate(f'{p.get_height()}', (p.get_x()+0.2, p.get_height()), ha='center', va='top', color='black', size=10)\r\nplt.show()  ","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:21.533135Z","iopub.execute_input":"2021-09-10T06:22:21.534222Z","iopub.status.idle":"2021-09-10T06:22:21.785635Z","shell.execute_reply.started":"2021-09-10T06:22:21.534169Z","shell.execute_reply":"2021-09-10T06:22:21.784325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Possibility of stroke is same beetween differentresidence types.","metadata":{}},{"cell_type":"code","source":"fig10, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 7))\r\n\r\nsns.set(style=\"darkgrid\")\r\n\r\nsns.countplot(x=stroke_0.gender, hue=stroke_0.Residence_type, palette='viridis',ax=ax1)\r\nax1.set_xlabel('Residence Type-No Stroke',fontsize=10, fontweight='bold')\r\nax2.set_yticks([])\r\nax1.set_ylabel('Patients',fontsize=10, fontweight='bold')\r\nfor p in ax1.patches:\r\n    ax1.annotate(f'\\n{p.get_height()}', (p.get_x()+0.2, p.get_height()), ha='center', va='top', color='black', size=10)\r\nax1.set_ylabel('Count of patient')\r\n\r\nsns.countplot(x=stroke_1.gender, hue=stroke_1.Residence_type, palette='rocket', ax=ax2)\r\nax2.set_xlabel('Residence Type-Stroke',fontsize=10, fontweight='bold')\r\nax2.set_ylabel('')\r\nfor p in ax2.patches:\r\n    ax2.annotate(f'\\n{p.get_height()}', (p.get_x()+0.2, p.get_height()), ha='center', va='top', color='black', size=10)\r\nax2.set_yticks([])\r\nplt.show()  \r\n\r\n","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:21.789471Z","iopub.execute_input":"2021-09-10T06:22:21.789714Z","iopub.status.idle":"2021-09-10T06:22:22.188391Z","shell.execute_reply.started":"2021-09-10T06:22:21.789688Z","shell.execute_reply":"2021-09-10T06:22:22.187109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig11, ax = plt.subplots(figsize=(5, 5))\r\nsns.set(style=\"darkgrid\")\r\n\r\nsns.barplot(x=df3.gender,y=df3.avg_glucose_level,hue=df3.stroke,estimator=np.average ,ci=None,palette='icefire')\r\nplt.xlabel('Gender & Stroke',fontsize=10, fontweight='bold')\r\nplt.ylabel('Average Glusoce Level',fontsize=10, fontweight='bold')\r\nplt.title('Average Glusoce Level v/s Gender',fontsize=15, fontweight='bold')\r\nfor p in ax.patches:\r\n    ax.annotate(f'\\n{round(p.get_height())}', (p.get_x()+0.2, p.get_height()), ha='center', va='top', color='black', size=10)\r\n\r\nplt.show()  \r\n","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:22.190333Z","iopub.execute_input":"2021-09-10T06:22:22.190588Z","iopub.status.idle":"2021-09-10T06:22:22.453186Z","shell.execute_reply.started":"2021-09-10T06:22:22.19056Z","shell.execute_reply":"2021-09-10T06:22:22.45223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Average glucose level around 145 & 125 for Male and Female respectively increase chances of stroke. ","metadata":{}},{"cell_type":"code","source":"fig12, ax = plt.subplots(figsize=(15, 5))\r\nsns.set(style=\"darkgrid\")\r\n\r\nsns.barplot(y=df3.smoking_status,x=df3.bmi,hue=df3.stroke,estimator=np.average ,ci=None,palette='icefire')\r\nplt.ylabel('Smoking Habit & Stroke',fontsize=10, fontweight='bold')\r\nplt.xlabel('Averge BMI',fontsize=10, fontweight='bold')\r\nplt.title('Smoking Habits v/s BMI',fontsize=15, fontweight='bold')\r\n\r\nplt.show()  \r\n","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:22.454905Z","iopub.execute_input":"2021-09-10T06:22:22.455143Z","iopub.status.idle":"2021-09-10T06:22:22.775651Z","shell.execute_reply.started":"2021-09-10T06:22:22.455117Z","shell.execute_reply":"2021-09-10T06:22:22.774701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Smoking habits seem to not be corelated with BMI.","metadata":{}},{"cell_type":"code","source":"fig13, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\r\n\r\nsns.countplot(x=stroke_0.smoking_status,hue=stroke_0.gender, palette='viridis',ax=ax1)\r\nax1.set_xlabel('Smoking Habits-No Stroke',fontsize=10, fontweight='bold')\r\nax2.set_yticks([])\r\nax1.set_ylabel('Patients',fontsize=10, fontweight='bold')\r\nfor p in ax1.patches:\r\n    ax1.annotate(f'\\n{p.get_height()}', (p.get_x()+0.2, p.get_height()), ha='center', va='top', color='black', size=10)\r\nax1.set_ylabel('Count of patient')\r\n\r\nsns.countplot(x=stroke_1.smoking_status,hue=stroke_1.gender, palette='rocket',ax=ax2)\r\nax2.set_xlabel('Smoking Habits-Stroke',fontsize=10, fontweight='bold')\r\nax2.set_ylabel('')\r\nfor p in ax2.patches:\r\n    ax2.annotate(f'\\n{p.get_height()}', (p.get_x()+0.2, p.get_height()), ha='center', va='top', color='black', size=10)\r\nax2.set_yticks([])\r\nplt.show()  \r\n\r\n","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:22.777258Z","iopub.execute_input":"2021-09-10T06:22:22.777501Z","iopub.status.idle":"2021-09-10T06:22:23.25335Z","shell.execute_reply.started":"2021-09-10T06:22:22.777474Z","shell.execute_reply":"2021-09-10T06:22:23.252439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Women that never smoke are more likely to have stroke than those that do. This could be due to passive smoking or other reasons that are not present in the dataset here.","metadata":{}},{"cell_type":"code","source":"fig, plt.subplots(figsize=(20, 5))\r\n\r\nsns.stripplot(y='smoking_status', x='bmi', data = df3,  hue='stroke')\r\nplt.title('BMI V/s Smoking Status', fontsize=15, fontweight='bold')\r\nplt.xlabel('BMI', fontsize=10, fontweight='bold')\r\nplt.ylabel('Smoking Status', fontsize=10, fontweight='bold')\r\nplt.show()  ","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:23.257585Z","iopub.execute_input":"2021-09-10T06:22:23.257936Z","iopub.status.idle":"2021-09-10T06:22:23.728563Z","shell.execute_reply.started":"2021-09-10T06:22:23.257903Z","shell.execute_reply":"2021-09-10T06:22:23.727867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Smoking habits & Stroke seem to not be corelated with BMI.","metadata":{}},{"cell_type":"code","source":"df3.stroke.value_counts().plot(kind='pie',autopct='%1.1f%%',fontsize=17)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:23.730699Z","iopub.execute_input":"2021-09-10T06:22:23.731295Z","iopub.status.idle":"2021-09-10T06:22:23.858377Z","shell.execute_reply.started":"2021-09-10T06:22:23.731254Z","shell.execute_reply":"2021-09-10T06:22:23.857446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The dataset has only 4% of the datapoints leading to 'Stroke' as outcome.","metadata":{}},{"cell_type":"markdown","source":"# 4. Feature Engineering.","metadata":{}},{"cell_type":"code","source":"data = df3.copy()","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:23.859728Z","iopub.execute_input":"2021-09-10T06:22:23.860077Z","iopub.status.idle":"2021-09-10T06:22:23.867991Z","shell.execute_reply.started":"2021-09-10T06:22:23.860034Z","shell.execute_reply":"2021-09-10T06:22:23.86579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.1. Encoding the categorical values.","metadata":{}},{"cell_type":"code","source":"object_cols = [col for col in data.columns if data[col].dtype == \"object\"]\r\nprint(*object_cols, sep=',')","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:23.869416Z","iopub.execute_input":"2021-09-10T06:22:23.869886Z","iopub.status.idle":"2021-09-10T06:22:23.884893Z","shell.execute_reply.started":"2021-09-10T06:22:23.869844Z","shell.execute_reply":"2021-09-10T06:22:23.883678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"object_nunique = list(map(lambda col: data[col].nunique(), object_cols))\r\nd = dict(zip(object_cols, object_nunique))\r\n\r\n# Print number of unique entries by column, in ascending order\r\nsorted(d.items(), key=lambda x: x[1])","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:23.886505Z","iopub.execute_input":"2021-09-10T06:22:23.886764Z","iopub.status.idle":"2021-09-10T06:22:23.908087Z","shell.execute_reply.started":"2021-09-10T06:22:23.886717Z","shell.execute_reply":"2021-09-10T06:22:23.907051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The maximum categorical values in a column are 5, so we can use ordinal encoding.","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import OrdinalEncoder\r\n\r\nordinal_encoder = OrdinalEncoder()\r\ndata[object_cols] =ordinal_encoder.fit_transform(data[object_cols])","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:23.909933Z","iopub.execute_input":"2021-09-10T06:22:23.910267Z","iopub.status.idle":"2021-09-10T06:22:24.065697Z","shell.execute_reply.started":"2021-09-10T06:22:23.910233Z","shell.execute_reply":"2021-09-10T06:22:24.064958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head(4)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:24.066879Z","iopub.execute_input":"2021-09-10T06:22:24.067796Z","iopub.status.idle":"2021-09-10T06:22:24.092253Z","shell.execute_reply.started":"2021-09-10T06:22:24.067728Z","shell.execute_reply":"2021-09-10T06:22:24.091146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig15,ax = plt.subplots(figsize=(7, 5))\r\nsns.heatmap(data.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:24.093995Z","iopub.execute_input":"2021-09-10T06:22:24.094286Z","iopub.status.idle":"2021-09-10T06:22:25.125385Z","shell.execute_reply.started":"2021-09-10T06:22:24.094259Z","shell.execute_reply":"2021-09-10T06:22:25.124329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = data.drop('stroke',axis = 1 )\r\ny=data.stroke","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:25.127652Z","iopub.execute_input":"2021-09-10T06:22:25.128055Z","iopub.status.idle":"2021-09-10T06:22:25.135801Z","shell.execute_reply.started":"2021-09-10T06:22:25.128011Z","shell.execute_reply":"2021-09-10T06:22:25.134701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\r\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.35, random_state=21)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:25.138051Z","iopub.execute_input":"2021-09-10T06:22:25.138333Z","iopub.status.idle":"2021-09-10T06:22:25.200389Z","shell.execute_reply.started":"2021-09-10T06:22:25.138304Z","shell.execute_reply":"2021-09-10T06:22:25.19971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.2.1 Feature selection with correlation and random forest classification","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\r\nfrom sklearn.metrics import f1_score,confusion_matrix\r\nfrom sklearn.metrics import accuracy_score\r\n\r\n#random forest classifier with n_estimators=10 (default)\r\nclf_rf = RandomForestClassifier(random_state=43)      \r\nclr_rf = clf_rf.fit(X_train,y_train)\r\n\r\nac = accuracy_score(y_valid,clf_rf.predict(X_valid))\r\nprint('Accuracy is: ',round(ac*100), ' %')\r\ncm = confusion_matrix(y_valid,clf_rf.predict(X_valid))\r\nsns.heatmap(cm,annot=True,fmt=\"d\")","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:25.201907Z","iopub.execute_input":"2021-09-10T06:22:25.203062Z","iopub.status.idle":"2021-09-10T06:22:26.180244Z","shell.execute_reply.started":"2021-09-10T06:22:25.202954Z","shell.execute_reply":"2021-09-10T06:22:26.179603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Accuracy is almost 95% and as it can be seen in confusion matrix, we make few wrong prediction. Now lets see other feature selection methods to find better results.","metadata":{}},{"cell_type":"markdown","source":"## 4.2.2. Univariate feature selection and random forest classification.","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest\r\nfrom sklearn.feature_selection import chi2\r\n# find best scored 5 features\r\nselect_feature = SelectKBest(chi2, k=5).fit(X_train, y_train)\r\nprint('Score list:', select_feature.scores_)\r\nprint('Feature list:', X_train.columns)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:26.181462Z","iopub.execute_input":"2021-09-10T06:22:26.182665Z","iopub.status.idle":"2021-09-10T06:22:26.205124Z","shell.execute_reply.started":"2021-09-10T06:22:26.182578Z","shell.execute_reply":"2021-09-10T06:22:26.203925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Best 5 feature to classify are hypertension, heart disease, married status, bmi and smoking status. So lets see what happens if we use only these best scored 5 feature.","metadata":{}},{"cell_type":"code","source":"X_train_2 = select_feature.transform(X_train)\r\nX_valid_2 = select_feature.transform(X_valid)\r\n#random forest classifier with n_estimators=10 (default)\r\nclf_rf_2 = RandomForestClassifier()      \r\nclr_rf_2 = clf_rf_2.fit(X_train_2,y_train)\r\nac_2 = accuracy_score(y_valid,clf_rf_2.predict(X_valid_2))\r\nprint('Accuracy is: ',round(ac_2*100), ' %')\r\ncm_2 = confusion_matrix(y_valid,clf_rf_2.predict(X_valid_2))\r\nsns.heatmap(cm_2,annot=True,fmt=\"d\")","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:26.207297Z","iopub.execute_input":"2021-09-10T06:22:26.207658Z","iopub.status.idle":"2021-09-10T06:22:26.915108Z","shell.execute_reply.started":"2021-09-10T06:22:26.207621Z","shell.execute_reply":"2021-09-10T06:22:26.914113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Accuracy is reduced to 94% and as it can be seen in confusion matrix, we make few wrong prediction.Although we use 5 features in selectkBest method accuracies degraded. Now lets see other feature selection methods to find better results.","metadata":{}},{"cell_type":"markdown","source":"## 4.2.3. Recursive feature elimination (RFE) with random forest","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import RFE\r\n# Create the RFE object and rank each pixel\r\nclf_rf_3 = RandomForestClassifier()      \r\nrfe = RFE(estimator=clf_rf_3, n_features_to_select=5, step=1)\r\nrfe = rfe.fit(X_train, y_train)\r\nprint('Chosen best 5 feature by rfe:',X_train.columns[rfe.support_])","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:26.916478Z","iopub.execute_input":"2021-09-10T06:22:26.916879Z","iopub.status.idle":"2021-09-10T06:22:29.48129Z","shell.execute_reply.started":"2021-09-10T06:22:26.916847Z","shell.execute_reply":"2021-09-10T06:22:29.480306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfe_col=X_train.columns[rfe.support_]\r\nrfe_col.values.tolist()","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:29.483517Z","iopub.execute_input":"2021-09-10T06:22:29.483871Z","iopub.status.idle":"2021-09-10T06:22:29.491769Z","shell.execute_reply.started":"2021-09-10T06:22:29.48383Z","shell.execute_reply":"2021-09-10T06:22:29.49074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_3 = X_train[rfe_col]\r\nX_valid_3 = X_valid[rfe_col]\r\n#random forest classifier with n_estimators=10 (default)\r\nclf_rf_3 = RandomForestClassifier()      \r\nclr_rf_3 = clf_rf_3.fit(X_train_3,y_train)\r\nac_3 = accuracy_score(y_valid,clf_rf_3.predict(X_valid_3))\r\nprint('Accuracy is: ',round(ac_3*100), ' %')\r\ncm_3 = confusion_matrix(y_valid,clf_rf_3.predict(X_valid_3))\r\nsns.heatmap(cm_3,annot=True,fmt=\"d\")","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:29.493857Z","iopub.execute_input":"2021-09-10T06:22:29.494294Z","iopub.status.idle":"2021-09-10T06:22:30.244686Z","shell.execute_reply.started":"2021-09-10T06:22:29.494226Z","shell.execute_reply":"2021-09-10T06:22:30.244042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### This model still gave an accuracy of 96%, and performed slightly better to detect stroke value \"1\".","metadata":{}},{"cell_type":"markdown","source":"## 4.2.4. Recursive feature elimination with cross validation and random forest classification","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import RFECV\r\n\r\n# The \"accuracy\" scoring is proportional to the number of correct classifications\r\nclf_rf_4 = RandomForestClassifier() \r\nrfecv = RFECV(estimator=clf_rf_4, step=1, cv=7,scoring='accuracy')\r\nrfecv = rfecv.fit(X_train, y_train)\r\n\r\nprint('Optimal number of features :', rfecv.n_features_)\r\nprint('Best features :', X.columns[rfecv.support_])","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:30.245725Z","iopub.execute_input":"2021-09-10T06:22:30.246531Z","iopub.status.idle":"2021-09-10T06:22:58.113503Z","shell.execute_reply.started":"2021-09-10T06:22:30.2465Z","shell.execute_reply":"2021-09-10T06:22:58.112364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfecv_col=X_train.columns[rfecv.support_]\r\nrfecv_col.values.tolist()\r\n\r\nX_train_4 = X_train[rfecv_col]\r\nX_valid_4 = X_valid[rfecv_col]\r\n\r\nrfecv_1 = rfecv.fit(X_train_4, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:22:58.114821Z","iopub.execute_input":"2021-09-10T06:22:58.115059Z","iopub.status.idle":"2021-09-10T06:23:19.920505Z","shell.execute_reply.started":"2021-09-10T06:22:58.115033Z","shell.execute_reply":"2021-09-10T06:23:19.919475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ac_4 = accuracy_score(y_valid,rfecv_1.predict(X_valid_4))\r\nprint('Accuracy is: ',round(ac_4*100), ' %')\r\ncm_4 = confusion_matrix(y_valid,rfecv_1.predict(X_valid_4))\r\nsns.heatmap(cm_4,annot=True,fmt=\"d\")","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:23:19.92222Z","iopub.execute_input":"2021-09-10T06:23:19.922474Z","iopub.status.idle":"2021-09-10T06:23:20.270815Z","shell.execute_reply.started":"2021-09-10T06:23:19.922447Z","shell.execute_reply":"2021-09-10T06:23:20.269786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot number of features VS. cross-validation scores\r\nplt.figure()\r\nplt.xlabel(\"Number of features selected\")\r\nplt.ylabel(\"Cross validation score of number of selected features\")\r\nplt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\r\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:23:20.27233Z","iopub.execute_input":"2021-09-10T06:23:20.27261Z","iopub.status.idle":"2021-09-10T06:23:20.557611Z","shell.execute_reply.started":"2021-09-10T06:23:20.272582Z","shell.execute_reply":"2021-09-10T06:23:20.556703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.2.5. Tree based feature selection and random forest classification","metadata":{}},{"cell_type":"code","source":"clf_rf_5 = RandomForestClassifier()      \r\nclr_rf_5 = clf_rf_5.fit(X,y)\r\nimportances = clr_rf_5.feature_importances_\r\nstd = np.std([tree.feature_importances_ for tree in clf_rf.estimators_],\r\n             axis=0)\r\nindices = np.argsort(importances)[::-1]\r\n\r\n# Print the feature ranking\r\nprint(\"Feature ranking:\")\r\n\r\nfor f in range(X.shape[1]):\r\n    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\r\n\r\n# Plot the feature importances of the forest\r\n\r\nplt.figure(1, figsize=(14, 5))\r\nplt.title(\"Feature importances\")\r\nplt.bar(range(X.shape[1]), importances[indices],\r\n       color=\"g\", yerr=std[indices], align=\"center\")\r\nplt.xticks(range(X.shape[1]), X.columns[indices],rotation=90)\r\nplt.xlim([-1, X.shape[1]])\r\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:23:20.558819Z","iopub.execute_input":"2021-09-10T06:23:20.559033Z","iopub.status.idle":"2021-09-10T06:23:21.38233Z","shell.execute_reply.started":"2021-09-10T06:23:20.559009Z","shell.execute_reply":"2021-09-10T06:23:21.381485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Since, all models are predicting the True Negatives close to zero, we will have to try other algorithms.","metadata":{}},{"cell_type":"markdown","source":"# 4.3. Model Selection.","metadata":{}},{"cell_type":"markdown","source":"## 4.3.1. Support Vector Machine.","metadata":{}},{"cell_type":"code","source":"from sklearn import svm\r\nsvm = svm.SVC(gamma='auto',C=10,kernel='linear')\r\nsvm = svm.fit(X_train,y_train)\r\nac_svm = accuracy_score(y_valid,svm.predict(X_valid))\r\nprint('Accuracy is: ',round(ac_svm*100), ' %')\r\ncm_svm = confusion_matrix(y_valid,svm.predict(X_valid))\r\nsns.heatmap(cm_svm,annot=True,fmt=\"d\")","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:23:21.383695Z","iopub.execute_input":"2021-09-10T06:23:21.384996Z","iopub.status.idle":"2021-09-10T06:24:28.325511Z","shell.execute_reply.started":"2021-09-10T06:23:21.384949Z","shell.execute_reply":"2021-09-10T06:24:28.324304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.3.2. Logistic Regression.","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\r\nlr=LogisticRegression(solver='liblinear',class_weight='balanced',multi_class='auto', C=80)\r\nlr = lr.fit(X_train,y_train)\r\nac_lr = accuracy_score(y_valid,lr.predict(X_valid))\r\nprint('Accuracy is: ',round(ac_lr*100), ' %')\r\ncm_lr = confusion_matrix(y_valid,lr.predict(X_valid))\r\nsns.heatmap(cm_lr,annot=True,fmt=\"d\")","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:24:28.326707Z","iopub.execute_input":"2021-09-10T06:24:28.32695Z","iopub.status.idle":"2021-09-10T06:24:28.65358Z","shell.execute_reply.started":"2021-09-10T06:24:28.326924Z","shell.execute_reply":"2021-09-10T06:24:28.652869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.3.3. Multinomial Naive Bayes.","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\r\nmnb=MultinomialNB()\r\nmnb = mnb.fit(X_train,y_train)\r\nac_mnb = accuracy_score(y_valid,mnb.predict(X_valid))\r\nprint('Accuracy is: ',round(ac_mnb*100), ' %')\r\ncm_mnb = confusion_matrix(y_valid,mnb.predict(X_valid))\r\nsns.heatmap(cm_mnb,annot=True,fmt=\"d\")","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:24:28.654688Z","iopub.execute_input":"2021-09-10T06:24:28.654901Z","iopub.status.idle":"2021-09-10T06:24:28.935616Z","shell.execute_reply.started":"2021-09-10T06:24:28.654877Z","shell.execute_reply":"2021-09-10T06:24:28.934973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.3.4. Gaussian Naive Bayes.","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\r\ngnb=GaussianNB()\r\ngnb = gnb.fit(X_train,y_train)\r\nac_gnb = accuracy_score(y_valid,gnb.predict(X_valid))\r\nprint('Accuracy is: ',round(ac_gnb*100), ' %')\r\ncm_gnb = confusion_matrix(y_valid,gnb.predict(X_valid))\r\nsns.heatmap(cm_gnb,annot=True,fmt=\"d\")","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:24:28.936789Z","iopub.execute_input":"2021-09-10T06:24:28.93715Z","iopub.status.idle":"2021-09-10T06:24:29.20892Z","shell.execute_reply.started":"2021-09-10T06:24:28.937107Z","shell.execute_reply":"2021-09-10T06:24:29.208267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Gaussian Naive Bayes returned the most correct predictions for True Negatives.\r\n### The accuracy is 86%, which can be improved with feature selection.","metadata":{}},{"cell_type":"markdown","source":"# 4.4. Feture Selction with Gaussian Naive Bayes.","metadata":{}},{"cell_type":"markdown","source":"## 4.4.1 Univariate feature selection and Gaussian Naive Bayes.","metadata":{}},{"cell_type":"code","source":"# As we already have found top 5 features, we will use them with Gaussian Naive Byes.\r\ngnb2 = GaussianNB()       \r\ngnb2 = gnb2.fit(X_train_2,y_train)\r\nac_gnb2 = accuracy_score(y_valid,gnb2.predict(X_valid_2))\r\nprint('Accuracy is: ',round(ac_gnb2*100), ' %')\r\ncm_gng2 = confusion_matrix(y_valid,gnb2.predict(X_valid_2))\r\nsns.heatmap(cm_gng2,annot=True,fmt=\"d\")","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:24:29.209946Z","iopub.execute_input":"2021-09-10T06:24:29.210587Z","iopub.status.idle":"2021-09-10T06:24:29.489115Z","shell.execute_reply.started":"2021-09-10T06:24:29.210555Z","shell.execute_reply":"2021-09-10T06:24:29.488123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Accuracy is still 86%, but predictions of True Negatives have improved.","metadata":{}},{"cell_type":"markdown","source":"## 4.4.2.. Recursive feature elimination (RFE) with GaussianNB.","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import RFE\r\n# Create the RFE object and rank each pixel\r\ngnb3 = GaussianNB()      \r\nrfe_2 = RFE(estimator=gnb3, n_features_to_select=5, step=1)\r\nrfe = rfe.fit(X_train, y_train)\r\nprint('Chosen best 5 feature by rfe:',X_train.columns[rfe.support_])","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:24:29.490602Z","iopub.execute_input":"2021-09-10T06:24:29.490844Z","iopub.status.idle":"2021-09-10T06:24:31.760907Z","shell.execute_reply.started":"2021-09-10T06:24:29.490819Z","shell.execute_reply":"2021-09-10T06:24:31.759932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The features suggested for GuassianNB are same as that for Random Forrest Classifier. ","metadata":{}},{"cell_type":"code","source":"gnb4 = GaussianNB()      \r\ngnb4 = gnb4.fit(X_train_3,y_train)\r\nac_gnb4 = accuracy_score(y_valid,gnb4.predict(X_valid_3))\r\nprint('Accuracy is: ',round(ac_gnb4*100), ' %')\r\ncm_gnb4 = confusion_matrix(y_valid,gnb4.predict(X_valid_3))\r\nsns.heatmap(cm_gnb4,annot=True,fmt=\"d\")","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:24:31.762526Z","iopub.execute_input":"2021-09-10T06:24:31.763088Z","iopub.status.idle":"2021-09-10T06:24:32.050278Z","shell.execute_reply.started":"2021-09-10T06:24:31.763045Z","shell.execute_reply":"2021-09-10T06:24:32.049645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The accuracy increased to 91%, but correct predictions of True Negatives reduced.","metadata":{}},{"cell_type":"markdown","source":"# 5. Conclusion.","metadata":{}},{"cell_type":"markdown","source":"## Though Random forrest classifier gave an accuracy of more than 90%, Gaussian Naive Bayes predict most correct True Negatives, which is the main result required from the model.","metadata":{}}]}