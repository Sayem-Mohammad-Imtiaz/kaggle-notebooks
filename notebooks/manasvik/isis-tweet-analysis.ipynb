{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"a9805c68-2302-6d5f-a6a2-a28f162909be"},"source":"I have done a basic analysis of the tweets for the most frequent words, most common locations and subjects of the tweets. Visualizations shown below. Suggestions are welcome."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"19ba9d0f-8631-54fa-5596-68028241f9d7"},"outputs":[],"source":"import pandas as pd\nimport numpy as np\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f69d3c87-ff4b-dd02-fc05-d52133f809ae"},"outputs":[],"source":"#import tweets \n\nisis = pd.read_csv('../input/tweets.csv')\nprint(isis.head())\nprint()\nprint(isis.describe())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"33bc3757-e1ae-8f1a-8f5f-27a8f0c6cd32"},"outputs":[],"source":"# Step 1. Basic Analysis\n\n# 1.1 most frequent words used in tweets\n## I will preprocess all the tweets to lowercase, remove stopwords such as the, in etc and also stem the words. Also, I wil try to separate hashtags to individual words wherever possible eg. \n## #AmazingDay ---> amazing day\n\ndef preprocess(tweet):\n    # A number of the tweets start with ENGLISH TRANSLATIONS: so i will remove it \n    tweet = re.sub(r'ENGLISH TRANSLATION:','',tweet)\n    #I will also strip the tweets of non-alphabetic characters except #\n    tweet = re.sub(r'[^A-Za-z# ]','',tweet)\n    \n    words = tweet.strip().split()\n  \n    hashtags = [word for word in words if re.match(r'#',word)!=None]\n    words = [word.lower() for word in words if word not in hashtags]\n    \n    # remove stopwords and stem words using porter stemmer\n    p_stem = PorterStemmer()\n    words = [p_stem.stem(word.lower()) for word in words if word not in stopwords.words('english')]\n    \n    for hashtag in hashtags:\n        hashtag = re.sub(r'#',hashtag,'')\n        words_tag = []\n        current_word = ''\n        for a in hashtag:\n            if a.isupper() and current_word!='':\n                words_tag.append(current_word)\n                current_word = ''+ a.lower()\n            else:\n                current_word = current_word + a.lower()\n        words_tag.append(current_word)\n        words.extend(words_tag)\n    words = list(set(words))\n    return words\n\n# using the above function I will add another column \"wordlist\" to the dataframe\n\nisis['wordlist'] = [preprocess(tweet) for tweet in isis['tweets']]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7fc9bbd5-2935-6655-0bcd-6d8306bd6d98"},"outputs":[],"source":"#Plot of frequency of various words used in the tweets\n\nall_words = [word for wordlist in isis['wordlist'] for word in wordlist]\nlength_all = len(all_words)\nwordcount = dict([(word,all_words.count(word)) for word in set(all_words)])\nprint(length_all)\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"38af72d3-7856-24ac-bc77-090ae7db5937"},"outputs":[],"source":"import operator\nwordcount = sorted(wordcount.items(), key = operator.itemgetter(1))\nwordcount.reverse()\n\n%matplotlib inline\n\nimport matplotlib.pyplot as plt\n\n#plotting the top 20 most frequent words\n\nwordcount = wordcount[2:] #since first two words are '' and 'rt'\ntop20 = wordcount[:20]\ntop20_words = [word for (word,count) in top20]\ntop20_freq = [count for (word,count) in top20]\nindexes = np.arange(len(top20_words))\nwidth = 0.7\nplt.figure(figsize=(15,15))\nplt.bar(indexes, top20_freq, width)\nplt.xticks(indexes + width/2 , top20_words)\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b7f81a05-52ad-ffb0-bcbe-ea0a4638cb42"},"outputs":[],"source":"# location analysis \nunique_locations = isis['location'].unique()\nunique_counts = dict([(loc,list(isis['location']).count(loc)) for loc in unique_locations])\nunique_counts = sorted(unique_counts.items(),key = operator.itemgetter(1))\nunique_counts.reverse()\nfor (loc,counts) in unique_counts:\n    print(loc,counts)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f18fdcc2-fb49-25f9-b9e9-bfd8838704aa"},"outputs":[],"source":"# subject of tweet analysis using pos tagging\n\ndef tweet_subject(tweet):\n    tweet = re.sub('ENGLISH TRANSLATION:','',tweet)\n    tweet = re.sub('ENGLISH TRANSLATIONS:','',tweet)\n    tokenized = nltk.word_tokenize(tweet.lower())\n    tagged = nltk.pos_tag(tokenized)\n    nouns = [(word) for (word,tag) in tagged if re.match(r'NN',tag)!=None]\n    return nouns\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bec9923f-a00a-7d7b-e7f9-cdfe2abac60e"},"outputs":[],"source":"isis['tweet_subjects'] = [tweet_subject(tweet) for tweet in isis['tweets']]\n#most frequent sujects\nall_subjects = [word for wordlist in isis['tweet_subjects'] for word in wordlist]\nall_subjects_counts =dict([(word,all_subjects.count(word)) for word in set(all_subjects) ])\nall_subjects_counts = sorted(all_subjects_counts.items(), key = operator.itemgetter(1))\nall_subjects_counts.reverse()\nprint('TOTAL UNIQUE SUBJECTS : ', len(all_subjects_counts))\nfor (a,b) in all_subjects_counts[:30]:\n    print(a,b)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1c027392-639e-192e-9be9-79544243462e"},"outputs":[],"source":"#plotting the top 20 most frequent words\n\ntop20_sub = all_subjects_counts[:20]\ntop20_words = [word for (word,count) in top20_sub]\ntop20_freq = [count for (word,count) in top20_sub]\nindexes = np.arange(len(top20_words))\nwidth = 0.7\nplt.figure(figsize=(20,20))\nplt.bar(indexes, top20_freq, width)\nplt.xticks(indexes + width/2 , top20_words)\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5478c947-c345-117d-3700-71ee2843fc59","collapsed":true},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}