{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8ded03d1-5f7a-a34a-defb-8860fe9bad53"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom nltk.stem import PorterStemmer\nfrom nltk.corpus import stopwords\n\nfrom sklearn.linear_model import LinearRegression,Ridge,Lasso,BayesianRidge\nfrom sklearn.svm import SVR\nfrom sklearn.neural_network import MLPRegressor\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e707ed1f-95b4-8e01-38e5-f3c44956ca8d"},"outputs":[],"source":"data = pd.read_csv('../input/fake.csv')\nprint(data.describe())\nprint(data.head())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"feb2ccbf-1254-b785-0381-df927ee3038a"},"outputs":[],"source":"#columns with missing values\ncolumn_names = list(data.columns)\nprint(column_names)\nfor column in column_names:\n    if data[column].count()<len(data):\n        print(column,data[column].count())\n        \n\n#filling in missing values\n#since title==thread_title for all existing (non-null) values of title I will simply be using thread_title \n\n\n#In case of text I will replace the missing values with '' to avoid any errors during tfidf calculation\ndata.loc[data['text'].isnull(),'text'] = ''\n\n\n#country.. replacing the missing values with the most frequent country i.e. US\ndata.loc[data['country'].isnull(),'country'] = 'US' \n\n\n\n#In case of author the simplest (although not the best) solution would be to replace the missing values\n#with the most frequent author.. in this case 'admin'\n\n#I have decided to replace the missing values based on the country of the author.. maybe not a very good \n#idea but worth a shot :P\n\ndata.loc[data['author'].isnull(),'author'] = data.loc[data['author'].isnull(),'country']\n\n\n\n#thread title.. similar to text.. replacing missing values with ''\n\ndata.loc[data['thread_title'].isnull(),'thread_title'] = ''\n\n\n#domain_rank Here I will go for median substitution However since nearly a third of the data is missing \n#in this column this might not be very fruitful\n\ndata.loc[data['domain_rank'].isnull(),'domain_rank'] = np.nanmedian(np.array(data['domain_rank']))"},{"cell_type":"markdown","metadata":{"_cell_guid":"ae239e8a-bed3-3ea2-8d1a-8b3cdd7da621"},"source":"Since features play a BIG role in the prediction accuracy I will be using the following features:\n\n *1. From tweet text*\n  \n - number of words\n - similarity score between tweet text and title of URL (using tfidf)\n \n *2. From tweet metadata*\n\n - Author name\n - likes\n - comments\n - shares\n - replies_count\n - country\n - participants_count\n - domain_rank\n - language"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7251c6bb-7b84-295e-8cee-ee563dca3b96"},"outputs":[],"source":"# starting with features from tweet content\npstem = PorterStemmer()\nstop = set(stopwords.words('english'))\n\ndef stemmer(text):\n    wordlist = text.strip().split()\n    pstem = PorterStemmer()\n    j = '';\n    for word in wordlist:\n        try:\n            j = j+pstem.stem(word)+' '\n        except: \n            print(text)\n    return j\n#converting all texts and thread_titles to lowercase\ndata['text_lower'] = data['text'].map(lambda x: re.sub(r'[^a-z ]','',x.lower()))\ndata['text_lower'] = data['text_lower'].map(lambda x: ' '.join([word for word in x.strip().split() if word not in stop ]))\ndata['text_lower'] = data['text_lower'].map(lambda x: stemmer(x))\n#data['text_lower'] = data['text_lower'].map(lambda x: ' '.join([pstem.stem(word) for word in x]))\n\ndata['thread_lower'] = data['thread_title'].map(lambda x: re.sub(r'[^a-z ]','',x.lower()))\ndata['thread_lower'] = data['thread_lower'].map(lambda x: ' '.join([word for word in x.strip().split() if word not in stop ]))\ndata['thread_lower'] = data['thread_lower'].map(lambda x: ' '.join([pstem.stem(word) for word in x.strip().split()]))\n\n#feature1- number of words\ndata['num_words'] = data['text_lower'].map(lambda x: len(str(x).strip().split()))\n "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2fc16752-4536-50f2-1fd3-bfd10326391b"},"outputs":[],"source":"#feature2 - similarity score between tweet text and title \n# I will be using sklearn for this\n\ndef similarity(t1,t2):\n    t = [t1,t2]\n    tfidf_vectorizer = TfidfVectorizer()\n    try:\n        vectors = tfidf_vectorizer.fit_transform(t)\n        vectors = vectors.toarray()\n        sim = cosine_similarity(vectors[0].reshape(1,-1),vectors[1].reshape(1,-1))[0]\n    except:\n        sim = 0 #error when empty vocabulary hence taking similarity as zero\n    return sim\n\ndata['similarity'] = [similarity(b['text_lower'],b['thread_lower']) for (a,b) in data.iterrows()]\ndata['similarity'].describe() "},{"cell_type":"markdown","metadata":{"_cell_guid":"d2a48f44-d187-0523-c800-71593aefdde2"},"source":"For features from tweet metadata most will be used as they are. For country and Language, since these are categorical values, I will map them to numbers."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"13f44af2-cf8b-5482-d169-c0d0181b5a93"},"outputs":[],"source":"#mapping country to numbers\ncountries = list(data['country'].unique())\ndata['country_number'] = data['country'].map(lambda x: countries.index(x))\ndata['country_number'].describe()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b2919dbd-5b44-89a7-1545-a1218d5ddc36"},"outputs":[],"source":"#mapping languages to numbers\nlanguages = list(data['language'].unique())\ndata['language_number'] = data['language'].map(lambda x: languages.index(x))\ndata['language_number'].describe()"},{"cell_type":"markdown","metadata":{"_cell_guid":"231d5fc2-b2d5-f203-611c-97c5cd86ef9d"},"source":"Thus the final features are: \n\n 1. Number of words\n 2. Similarity Scores\n 3. Country\n 4. Likes\n 5. Share\n 6. Comments\n 7. Retweets\n 8. Language_number"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c7d8ad17-d9a9-cb8a-86ab-1e818c446255"},"outputs":[],"source":"feature_list = ['num_words','similarity','country_number','likes','shares','comments','replies_count','participants_count','domain_rank','language_number']\ntarget1 = 'spam_score'\ntarget2 = 'type'"},{"cell_type":"markdown","metadata":{"_cell_guid":"2a4a85f5-8d85-82db-aa93-69dd156c46bc"},"source":"So I will start with the spam_score prediction"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dd9096e4-40c2-3bb9-fcbe-a8511715ef48"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}