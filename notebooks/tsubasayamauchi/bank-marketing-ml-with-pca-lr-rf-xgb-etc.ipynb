{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\n\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dataframe setting"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/bank-marketing-dataset/bank.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dataframe check"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe(include='object')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Target variable \"deposit\""},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = \"deposit\", data = df, label = \"Count\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Change to binary\ndf['deposit'] = df['deposit'].astype('category')\ndf['deposit'] = df['deposit'].cat.codes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the binary number : 0 : no, 1 : yes\nsns.countplot(x = \"deposit\", data = df, label = \"Count\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the existence of null number\nprint(df.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### [Categorical variables]"},{"metadata":{},"cell_type":"markdown","source":"\"job\""},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 5))\nsns.countplot(x = \"job\", data = df, label = \"Count\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Factrial plot\n\nsns.factorplot(x = \"job\", y = \"deposit\", data = df, kind = \"bar\", size = 12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Obs:\n* Some categories have same factorial level. It indicates that there are possibilities to integrate categories.\n* For exemple, \"blue-collar\" and \"entrepreneur\", \"service\" and \"housemaid\", \"technician\" and \"self-employed\".\n* However, we should consider the meanings of categories.\n* Maybe we can integrate \"service\" and \"housemaid\" as \"housemaid\" is possibly one of service.\n* Some \"technician\" could be \"self-employed\", then, we can think abount this integration.\n* On the ohter hand, it is difficult to consider that \"blue-collar\" and \"entrepreneur\" are similar categories. In my opinion, it is not good to integrate them.\n* If you want to integrate the categories and make the new variable, the following is the processing."},{"metadata":{"trusted":true},"cell_type":"code","source":"def fac_job(row):\n  if row['job'] == \"housemaid\":\n    val = \"service\"\n  elif row['job'] == \"technician\":\n    val = \"self-employed\" \n  else :\n    val = row['job']\n  return val","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['job.rev'] = df.apply(fac_job, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\"marital\""},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = \"marital\", data=df, hue = \"deposit\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.factorplot(x = \"marital\", y = \"deposit\", data = df, kind = \"bar\", size = 6)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Obs:\n* Obseving the figures, the categories are reasonable and could react separately to the target \"deposit\"."},{"metadata":{},"cell_type":"markdown","source":"\"education\""},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 5))\nsns.countplot(x = \"education\", data = df, hue = \"deposit\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.factorplot(x = \"education\", y = \"deposit\", data = df, kind = \"bar\", size = 6)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Obs:\n* If you want, we could integrate \"primary\" and \"secondary\" as they have similar factorial level. But I think the categories are reasonable.\n* We could make the class by number such as 1: primary, 2: secondary, 3: tertiary, however, it is difficult how to classify the \"unknown\". Then it might be treated as the categories separately."},{"metadata":{},"cell_type":"markdown","source":"\"default\""},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x =\"default\", data = df, hue = \"deposit\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.factorplot(x = \"default\", y = \"deposit\", data = df, kind = \"bar\", size = 6)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Obs:\n* Obseving the figures, \"yes\" and \"no\" have different factors. Then I analyze that \"default\" could improve to fit models."},{"metadata":{},"cell_type":"markdown","source":"\"housing\""},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = \"housing\", data = df, hue = \"deposit\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.factorplot(x = \"housing\", y = \"deposit\", data = df, kind = \"bar\", size = 6)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Obs:\n* Similarly, \"yes\" and \"no\" have different factors. Then I analyze that \"default\" could improve to fit models."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = \"loan\", data = df,label = \"Count\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.factorplot(x = \"loan\", y = \"deposit\", data = df, kind = \"bar\", size = 6)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Obs:\n* Similarly, \"yes\" and \"no\" have different factors. Then I analyze that \"default\" could improve to fit models."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = \"contact\", data = df, hue = \"deposit\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.factorplot(x = \"contact\", y = \"deposit\", data = df, kind = \"bar\", size = 6)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Obs:\n* \"cellular\" and \"telephone\" have similar factorial level and \"unknown\"'s level is very different from theirs. Then one possibility is to integrate them and make a category such as \"telecomunication\" for example. It makes the variable \"contact\" be binary.\n* However, I respect the original categories for now."},{"metadata":{},"cell_type":"markdown","source":"\"month\""},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = \"month\", data = df, hue= \"deposit\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.factorplot(x = \"month\", y = \"deposit\", data = df, kind = \"bar\", size = 10)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\"poutcome\""},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = \"poutcome\", data = df, hue= \"deposit\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.factorplot(x = \"poutcome\", y = \"deposit\", data = df, kind = \"bar\", size = 6)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Obs:\n* There are different factorial levels. Then I would like to respect the original categories."},{"metadata":{},"cell_type":"markdown","source":"### [Numerical variables]"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,5))\nsns.heatmap(df.corr(), annot=True, fmt = \".2f\", cmap = \"coolwarm\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,5))\nsns.pairplot(df.corr())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Obs :\n* We can recognize in the heatmap that there is a considebly high correlation between \"deposit\" and \"duration\", then \"duration\" should be importatn variable. However they are not correlated really linearly seeing the pairplot. \n* \"campaign\", \"pdays\" and \"previous\" correlate with deposit even though it is not high.\n* The correlation between \"pdays\" and \"previous\" is able to be observed, then we should be careful when we choose the variables to modeling as they could conflict some times and reduce the performance.\n* There are no normal distribution. The algorithm that accepts non-normality should work better."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Example to see the relation between \"depoist\" and \"duration\" by Box-plot\nsns.boxplot(x = \"deposit\", y = \"duration\", data = df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Example to see the relation between \"depoist\" and \"duration\" by Violin-plot\nsns.violinplot(x = \"deposit\", y = \"duration\", data = df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# PCA (Principal Components Analysis)"},{"metadata":{},"cell_type":"markdown","source":"As we could see that there is the significant correlation between \"pdays\" and \"previous\". As the number of variable is not large, there is doubt about the necessity of PCA. However, I would like to apply PCA for these two variable as a option to solve the problem of modeling with variables correlated each other."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nfeatures = ['pdays', 'previous']\n\nx_pca = df.loc[:, features].values\nx_pca = StandardScaler().fit_transform(x_pca)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\n\npca = PCA(n_components=2)\n\nprincipalComponents = pca.fit_transform(x_pca)\nprincipalDF = pd.DataFrame(data = principalComponents, columns=['PC1', 'PC2'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca.components_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca.explained_variance_ratio_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Concatenation of dataframes\ndf_all = pd.concat([principalDF, df], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,5))\nsns.heatmap(df_all.corr(), annot=True, fmt = \".2f\", cmap = \"coolwarm\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Obs: As we can see, PC1 (the first principal component) has better correlation with \"deposit\" than \"pdays\" and \"previous\". \"pdays\" and \"previous\" could be replaced with PC1 to test if the performance of algorithm will be better or not. Furthermore, PC1 represent 75.4% of these variables, then, it seems that PCA could extract main effect to deposit efficiently."},{"metadata":{},"cell_type":"markdown","source":"# Data processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Firstly, I select every variables to fit models but without the principal components (PC1 and PC2).\n* It is ideal to select specific variables before fitting models, however, if the number of variables is not huge, sometimes it is better to see how algorithms fit model with every variables and how much is performance. Some algorithms make the feature selection by regulations as well."},{"metadata":{"trusted":true},"cell_type":"code","source":"#### Without PCs\n\nvariables_selected = [\n    'age',\n    'job',\n    'marital',\n    'education',\n    'default',\n    'balance',\n    'housing',\n    'loan',\n    'contact',\n    'day',\n    'month',\n    'duration',\n    'campaign',\n    'pdays',\n    'previous',\n    'poutcome',\n    'deposit', # target variable\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_final = df_all[variables_selected]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# One-hot (creating dummies for categorical variables)\ndf_final = pd.get_dummies(df_final, columns=['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_final.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeling 1 (without Principal Component)"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df_final.deposit\nX = df_final.drop('deposit', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.shape, X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalization of data\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\nscaler = MinMaxScaler()\nX_norm = scaler.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_X_norm = pd.DataFrame(X_norm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_X_norm.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Classifiers\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\n\n# Metrics\nfrom sklearn.model_selection import  GridSearchCV\nfrom sklearn import model_selection\nfrom sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seed = 123\nk = 10\n\nkfolds = model_selection.KFold(n_splits=k, shuffle = True, random_state=seed)\n#kfolds = model_selection.StratifiedKFold(n_splits=k, random_state=seed)\n# In this case the proportion of responce \"yes\" and \"no\" is balanced well. If not, it is recommended to use \"StratifiedKFold()\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### KNN\n\nKNN = KNeighborsClassifier()\n\nparams = {\n    'n_neighbors' : list(range(2,40)),\n    'weights' : ['distance'],\n    'algorithm' : ['kd_tree']\n}\n\ngrid_knn = GridSearchCV(KNN, param_grid=params, cv = kfolds)\ngrid_knn.fit(X_norm, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(grid_knn.best_score_)\nprint(grid_knn.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### Decision Tree\n\nDT = DecisionTreeClassifier()\n\nparams = {\n    'criterion' : ['gini', 'entropy'],\n    'max_depth' : list(range(2, 15)),\n}\n\ngrid_dt = GridSearchCV(DT, param_grid=params, cv=kfolds)\ngrid_dt.fit(X_norm, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(grid_dt.best_score_)\nprint(grid_dt.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Logistic regression\n\nLR = LogisticRegression()\n\nparams = {\n    'penalty' : ['l1', 'l2'],\n    'C' : np.logspace(-4, 4, 100),\n    'solver' : ['liblinear']\n}\n\ngrid_lr = GridSearchCV(LR, param_grid=params, cv = kfolds)\ngrid_lr.fit(X_norm, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(grid_lr.best_score_)\nprint(grid_lr.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Random Forest\n\nRF = RandomForestClassifier()\n\nparams = {\n    \"n_estimators\": np.array([50, 100, 200, 300]), \n    \"max_depth\": [3, 6, 9, 12, 15, 18, 21],\n}\n\ngrid_rf = GridSearchCV(RF, param_grid=params, cv = kfolds)\ngrid_rf.fit(X_norm, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(grid_rf.best_score_)\nprint(grid_rf.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### XG Boost\n\nxgb = XGBClassifier(verbosity = 0) # verbosity = 0 : to hide warnings\n\nparams = {\n    'max_depth': [6, 9, 11, 13, 16, 19, 22], \n    'n_estimators': [100],\n    'learning_rate': [0.01, 0.05, 0.1]\n}\n\ngrid_xgb = GridSearchCV(xgb, param_grid=params, cv = kfolds)\ngrid_xgb.fit(X_norm, y)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(grid_xgb.best_score_)\nprint(grid_xgb.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### SVM\n\nsvm = SVC()\n\nparams = {\n    \"C\": [0.001, 0.01, 0.1, 1.],\n    \"kernel\": [\"linear\", \"poly\", \"rbf\"],\n    \"gamma\": [\"scale\", \"auto\"], \n}\n\ngrid_svm = GridSearchCV(svm, param_grid=params, cv = kfolds)\ngrid_svm.fit(X_norm, y)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(grid_svm.best_score_)\nprint(grid_svm.best_params_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeling with Principal Component \"PC1\""},{"metadata":{"trusted":true},"cell_type":"code","source":"#### With PC1 and \"job.rev\"\n\nvariables_selected = [\n    'age',\n    'job.rev', # categories reduced\n    'marital',\n    'education',\n    'default',\n    'balance',\n    'housing',\n    'loan',\n    'contact',\n    'day',\n    'month',\n    'duration',\n    'campaign',\n    #'pdays', # excluded\n    #'previous', # excluded\n    'PC1', # included\n    'poutcome',\n    'deposit', # target variable\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_final = df_all[variables_selected]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# One-hot (creating dummies for categorical variables)\ndf_final = pd.get_dummies(df_final, columns=['job.rev', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df_final.deposit\nX = df_final.drop('deposit', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalization of data\n\nscaler = MinMaxScaler()\nX_norm = scaler.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_X_norm = pd.DataFrame(X_norm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_X_norm.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### KNN\n\nKNN = KNeighborsClassifier()\n\nparams = {\n    'n_neighbors' : list(range(2,40)),\n    'weights' : ['distance'],\n    'algorithm' : ['kd_tree']\n}\n\ngrid_knn = GridSearchCV(KNN, param_grid=params, cv = kfolds)\ngrid_knn.fit(X_norm, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(grid_knn.best_score_)\nprint(grid_knn.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### Decision Tree\n\nDT = DecisionTreeClassifier()\n\nparams = {\n    'criterion' : ['gini', 'entropy'],\n    'max_depth' : list(range(2, 15)),\n}\n\ngrid_dt = GridSearchCV(DT, param_grid=params, cv=kfolds)\ngrid_dt.fit(X_norm, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(grid_dt.best_score_)\nprint(grid_dt.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Logistic regression\n\nLR = LogisticRegression()\n\nparams = {\n    'penalty' : ['l1', 'l2'],\n    'C' : np.logspace(-4, 4, 100),\n    'solver' : ['liblinear']\n}\n\ngrid_lr = GridSearchCV(LR, param_grid=params, cv = kfolds)\ngrid_lr.fit(X_norm, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(grid_lr.best_score_)\nprint(grid_lr.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Random Forest\n\nRF = RandomForestClassifier()\n\nparams = {\n    \"n_estimators\": np.array([50, 100, 200, 300]), \n    \"max_depth\": [3, 6, 9, 12, 15, 18, 21],\n}\n\ngrid_rf = GridSearchCV(RF, param_grid=params, cv = kfolds)\ngrid_rf.fit(X_norm, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(grid_rf.best_score_)\nprint(grid_rf.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### XG Boost\n\nxgb = XGBClassifier(verbosity = 0) # verbosity = 0 : to hide warnings\n\nparams = {\n    'max_depth': [6, 9, 11, 13, 16, 19, 22], \n    'n_estimators': [100],\n    'learning_rate': [0.01, 0.05, 0.1]\n}\n\ngrid_xgb = GridSearchCV(xgb, param_grid=params, cv = kfolds)\ngrid_xgb.fit(X_norm, y)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(grid_xgb.best_score_)\nprint(grid_xgb.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### SVM\n\nsvm = SVC()\n\nparams = {\n    \"C\": [0.001, 0.01, 0.1, 1.],\n    \"kernel\": [\"linear\", \"poly\", \"rbf\"], \n    \"gamma\": [\"scale\", \"auto\"],\n}\n\ngrid_svm = GridSearchCV(svm, param_grid=params, cv = kfolds)\ngrid_svm.fit(X_norm, y)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(grid_svm.best_score_)\nprint(grid_svm.best_params_)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}