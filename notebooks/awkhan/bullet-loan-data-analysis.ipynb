{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"version":3,"name":"ipython"},"mimetype":"text/x-python","version":"3.6.3","file_extension":".py","nbconvert_exporter":"python","pygments_lexer":"ipython3","name":"python"}},"cells":[{"metadata":{"_cell_guid":"1ffb4d9e-f7f3-4f36-87ba-99401ecd22ce","_uuid":"f0159bb523ed5c04fb2d6eb6c81c6808dbfb0b7c"},"execution_count":null,"outputs":[],"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"metadata":{},"cell_type":"markdown","source":"\n# Bullet Loan Analysis\n\nThis is an analysis of the bullet loan data provided here https://www.kaggle.com/zhijinzhai/loandata\n\nWe will perform some Exploratory Data Analysis and see if we can fit a model to predict loan repayment. We will compare Logistic Regressions to Random Forrest and Decision Trees.\n\nFrom the website we can obtain the context:\n\n\"This data set includes customers who have paid off their loans, who have been past due and put into collection without paying back their loan and interests, and who have paid off only after they were put in collection. The financial product is a bullet loan that customers should pay off all of their loan debt in just one time by the end of the term, instead of an installment schedule. Of course, they could pay off earlier than their pay schedule\"\n\nAnd the content of the data itself: \"Loan_id A unique loan number assigned to each loan customers\n\nLoan_status Whether a loan is paid off, in collection, new customer yet to payoff, or paid off after the collection efforts\n\nPrincipal Basic principal loan amount at the origination\n\nterms Can be weekly (7 days), biweekly, and monthly payoff schedule\n\nEffective_date When the loan got originated and took effects\n\nDue_date Since itâ€™s one-time payoff schedule, each loan has one single due date\n\nPaidoff_time The actual time a customer pays off the loan\n\nPastdue_days How many days a loan has been past due\"\n"},{"metadata":{"collapsed":true},"execution_count":null,"outputs":[],"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport datetime\nimport os\n\n%matplotlib inline"},{"metadata":{},"cell_type":"markdown","source":"### EDA"},{"metadata":{"collapsed":true},"execution_count":null,"outputs":[],"cell_type":"code","source":"loandf=pd.read_csv('../input/Loan payments data.csv')"},{"metadata":{},"execution_count":null,"outputs":[],"cell_type":"code","source":"loandf.head()"},{"metadata":{},"execution_count":null,"outputs":[],"cell_type":"code","source":"loandf.info()"},{"metadata":{},"cell_type":"markdown","source":"\n### EDA by columns\n#### 1.Loan_ID\n\nLoan_ID is just an identifier for each loan, and we will drop it from modeling\n#### 2. loan_status\n\nThis our target variable. Explore the variable.\n"},{"metadata":{},"execution_count":null,"outputs":[],"cell_type":"code","source":"loandf['loan_status'].unique()"},{"metadata":{},"execution_count":null,"outputs":[],"cell_type":"code","source":"sns.set_style('darkgrid')\nsns.countplot(loandf['loan_status'], palette='Spectral')"},{"metadata":{},"cell_type":"markdown","source":"We can see that there is an approximate 3:1:1 ratio between paidoff, collection, and collection_paidoff\n#### 3.Principal -orginal loan amount"},{"metadata":{},"execution_count":null,"outputs":[],"cell_type":"code","source":"loandf[['loan_status','Principal','Loan_ID']].groupby(['loan_status','Principal']).agg(['count'])"},{"metadata":{},"execution_count":null,"outputs":[],"cell_type":"code","source":"fig=plt.figure(figsize=(12,6))\nsns.distplot(loandf['Principal'], bins=40)"},{"metadata":{},"cell_type":"markdown","source":"we can see that most of the principal amount is at 1000 USD\n\n#### 4. Terms- payoff schedule"},{"metadata":{},"execution_count":null,"outputs":[],"cell_type":"code","source":"ax= sns.countplot(loandf['terms'], palette='Spectral')\nax.set_title('Term Counts')"},{"metadata":{},"execution_count":null,"outputs":[],"cell_type":"code","source":"fig, ax=plt.subplots(figsize=(12,4))\nsns.countplot(x='terms', hue='loan_status', data=loandf, palette='Spectral')\nax.set_title('Term counts by Loan Status')\nax.legend(loc='upper left')\n"},{"metadata":{"collapsed":true},"execution_count":null,"outputs":[],"cell_type":"code","source":"loandf['Days to pay']= (pd.DatetimeIndex(loandf['paid_off_time']).normalize()\n                        -pd.DatetimeIndex(loandf['effective_date']).normalize())/np.timedelta64(1,'D')"},{"metadata":{"collapsed":true},"execution_count":null,"outputs":[],"cell_type":"code","source":"loandf['paid_off_date'] = pd.DatetimeIndex(loandf['paid_off_time']).normalize()"},{"metadata":{},"execution_count":null,"outputs":[],"cell_type":"code","source":"fig, ax=plt.subplots(figsize=(15,6))\nax=sns.countplot(x='Days to pay',hue='terms',data=loandf)\nax.set_xticklabels(ax.get_xticklabels(),rotation=90)"},{"metadata":{},"execution_count":null,"outputs":[],"cell_type":"code","source":"fig, ax=plt.subplots(figsize=(15,6))\nax=sns.countplot(x='Days to pay', hue='terms', data=loandf[loandf['loan_status']== 'PAIDOFF'])\nax.set_xticklabels(ax.get_xticklabels(),rotation=90)"},{"metadata":{},"execution_count":null,"outputs":[],"cell_type":"code","source":"tmp = loandf.loc[(loandf['Days to pay'] > 30) & (loandf['loan_status'] == 'PAIDOFF')]\nprint(\"{}: Incorrect status: {} observations\")\nprint(tmp[['loan_status', 'terms', 'effective_date', 'due_date', 'paid_off_time']])"},{"metadata":{},"execution_count":null,"outputs":[],"cell_type":"code","source":"## exploring demographic\nfig, axs=plt.subplots(3,2, figsize=(20,15))\n\nsns.distplot(loandf['age'], ax=axs[0][0])\naxs[0][0].set_title(\"Total age distribution across dataset\")\n\nsns.boxplot(x='loan_status', y='age', data=loandf, ax=axs[0][1])\naxs[0][1].set_title(\"Age distribution by loan status\")\n\nsns.countplot(x='education', data=loandf, ax=axs[1][0])\naxs[1][0].set_title(\"Education count\")\n\n\nsns.countplot(x='education', data=loandf, hue='loan_status', ax=axs[1][1])\naxs[1][1].set_title(\"Education by loan status\")\naxs[1][1].legend(loc='upper right')\n\n\nsns.countplot(x='Gender', data=loandf, ax=axs[2][0])\naxs[2][0].set_title(\" Gender\")\n\nsns.countplot(x='Gender', data=loandf, hue='education', ax=axs[2][1])\naxs[2][1].set_title(\"Education of the gender\")"},{"metadata":{},"execution_count":null,"outputs":[],"cell_type":"code","source":"## exploring gender +education \npd.crosstab(loandf['loan_status'], loandf['Gender'] + \"_\" + loandf['education'], margins=True)"},{"metadata":{},"execution_count":null,"outputs":[],"cell_type":"code","source":"pd.crosstab(loandf['loan_status'],loandf['Gender']+\"_\"+loandf['education'],margins=True,normalize='all')"},{"metadata":{},"execution_count":null,"outputs":[],"cell_type":"code","source":"pd.crosstab(loandf['loan_status'],loandf['Gender']+\"_\"+loandf['education'],margins=True,normalize='index')"},{"metadata":{},"execution_count":null,"outputs":[],"cell_type":"code","source":"pd.crosstab(loandf['loan_status'],loandf['Gender']+\"_\"+loandf['education'],margins=True,normalize='columns')"},{"metadata":{},"cell_type":"markdown","source":"\n## Time to model!\n\nFirst lets fix the miseleading status loan records\n\nSecond change the categorical and variable to numerical we will merge collections and collections_paid off because we are interseted in those who paid on time!\n\nWe will convert education and gender to dummies\n\nWe will then perform Random Forest SVM and keras.\n"},{"metadata":{"collapsed":true},"execution_count":null,"outputs":[],"cell_type":"code","source":"loandf.loc[(loandf['loan_status'] =='PAIDOFF' ) &(loandf['Days to pay']>30),'loan_status']='COLLECTION_PAIDOFF'"},{"metadata":{},"execution_count":null,"outputs":[],"cell_type":"code","source":"smap= {\"PAIDOFF\": 1, \"COLLECTION\": 2, \"COLLECTION_PAIDOFF\": 2 }\nloandf['loan_status_trgt'] = loandf['loan_status'].map(smap)\n\nfig, axs=plt.subplots(1,2,figsize=(12,5))\n\nsns.countplot(x='loan_status',data=loandf,ax=axs[0])\naxs[0].set_title('Count with original targets')\n\nsns.countplot(x='loan_status_trgt', data=loandf, ax=axs[1])\naxs[1].set_title('Count with new targets')"},{"metadata":{"collapsed":true},"execution_count":null,"outputs":[],"cell_type":"code","source":"dummies=pd.get_dummies(loandf['education']).rename(columns=lambda x:'is_' +str(x))\nloandf=pd.concat([loandf,dummies],axis=1)\nloandf.drop(['education'],axis=1,inplace=True)\n"},{"metadata":{"collapsed":true},"execution_count":null,"outputs":[],"cell_type":"code","source":"dummies=pd.get_dummies(loandf['Gender']).rename(columns=lambda x:'is_' +str(x))\nloandf=pd.concat([loandf,dummies],axis=1)\nloandf.drop(['Gender'],axis=1,inplace=True)"},{"metadata":{"collapsed":true},"execution_count":null,"outputs":[],"cell_type":"code","source":"loandf.drop(['Loan_ID', 'loan_status', 'effective_date', 'due_date',\n             'paid_off_time', 'past_due_days', 'paid_off_date', 'Days to pay'], axis=1,inplace=True)"},{"metadata":{"collapsed":true},"execution_count":null,"outputs":[],"cell_type":"code","source":"dummyvar=['is_female','is_Master or Above']\nloandf.drop(dummyvar,axis=1, inplace=True)"},{"metadata":{"collapsed":true},"execution_count":null,"outputs":[],"cell_type":"code","source":"#create our inputs and target variable\nX=loandf.drop('loan_status_trgt',axis=1)\ny=loandf['loan_status_trgt']"},{"metadata":{"collapsed":true},"execution_count":null,"outputs":[],"cell_type":"code","source":"#import ML libraries\n\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import svm"},{"metadata":{"collapsed":true},"execution_count":null,"outputs":[],"cell_type":"code","source":"## funciton to evaluate our models\n\ndef eval_model(model, data, target, splitratio):\n    trainX, testX, trainY, testY = train_test_split(data, target, train_size=splitratio, random_state=0)\n    model.fit(trainX,trainY)\n    return model.score(testX,testY)"},{"metadata":{},"execution_count":null,"outputs":[],"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nnum_estimator=np.array([1,5,10,50,100,250,500])\nnum_sample=5\nnum_grid=len(num_estimator)\nscore_mean=np.zeros(num_grid)\nscore_sigma=np.zeros(num_grid)\nj=0\n\n\n\nprint(\"RandomForestClassification Starting\")\nfor x in num_estimator:\n    score_array = np.zeros(num_sample) # Initialize\n    for i in range(0,num_sample):\n        rf_class = RandomForestClassifier(n_estimators=x, n_jobs=1, criterion=\"gini\")\n        score_array[i] = eval_model(rf_class, X, y, 0.8)\n        print(\"Try {} with n_estimators = {} and score = {}\".format( i, x, score_array[i]))\n    score_mean[j], score_sigma[j] = np.mean(score_array), np.std(score_array)\n    j=j+1\n\nprint(\"RandomForestClassification Done!\")"},{"metadata":{},"execution_count":null,"outputs":[],"cell_type":"code","source":"fig = plt.figure(figsize=(12,6))\nplt.errorbar(num_estimator, score_mean, yerr=score_sigma, fmt='k.-')\nplt.xscale(\"log\")\nplt.xlabel(\"number of estimators\",size = 16)\nplt.ylabel(\"accuracy\",size = 16)\nplt.xlim(0.9,600)\nplt.ylim(0.3,0.8)\nplt.title(\"Random Forest Classifier\", size = 18)\nplt.grid(which=\"both\")"},{"metadata":{},"execution_count":null,"outputs":[],"cell_type":"code","source":"#SVM linear\n\nC_ar = np.array([0.5, 0.1, 1, 5, 10])\nscore_ar = np.zeros(len(C_ar))\ni=0\nfor C_val in C_ar:\n    svc_class = svm.SVC(kernel='linear', random_state=1, C = C_val)\n    score_array[i] = eval_model(svc_class, X, y, 0.8)\n    i=i+1\n\nscore_mu, score_sigma = np.mean(score_ar), np.std(score_ar)\n\nfig = plt.figure(figsize=(12,6))\nplt.errorbar(C_ar, score_ar, yerr=score_sigma, fmt='k.-')\nplt.xlabel(\"C assignment\",size = 16)\nplt.ylabel(\"accuracy\",size = 16)\nplt.title(\"SVM Classifier (Linear)\", size = 18)\nplt.grid(which=\"both\")"},{"metadata":{},"execution_count":null,"outputs":[],"cell_type":"code","source":"#adjusting our gamma\ngamma_ar = np.array([0.001, 0.01, 0.1, 1, 10])\nscore_ar = np.zeros(len(gamma_ar))\nscore_mean = np.zeros(len(gamma_ar))\nscore_sigma = np.zeros(len(gamma_ar))\ni=0\nfor l in gamma_ar:\n    svc_class = svm.SVC(kernel='rbf', random_state=1, gamma = l)\n    score_array[i] = eval_model(svc_class, X, y, 0.8)\n    score_mean[i], score_sigma[i] = np.mean(score_ar[i]), np.std(score_ar[i])\n    i=i+1\n\n\nfig = plt.figure(figsize=(12,6))\nplt.errorbar(gamma_ar, score_mean, yerr=score_sigma, fmt='k.-')\nplt.xscale('log')\nplt.xlabel(\"Gamma\",size = 16)\nplt.ylabel(\"accuracy\",size = 16)\nplt.title(\"SVM Classifier (RBF)\", size = 18)\nplt.grid(which=\"both\")"},{"metadata":{},"execution_count":null,"outputs":[],"cell_type":"code","source":"#keras\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nfrom keras.optimizers import SGD\n\n# Change to np.array type\nnew_x = np.array(X)\nnew_y = np.array(y)\n\n# fix random seed for reproducibility\nnp.random.seed(1234)\n\nmodel = Sequential()\nmodel.add(Dense(64, input_dim=7, init='uniform', activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"},{"metadata":{},"execution_count":null,"outputs":[],"cell_type":"code","source":"\n\nmodel.fit(new_x, new_y, epochs=150, batch_size=20)\nscores = model.evaluate(new_x, new_y)\nprint(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n\n"},{"metadata":{},"cell_type":"markdown","source":"\n## Results\n\nWe can see our SVM models did not work at all, but our RFC and keras models fitted with up to .57 accuracy\n"},{"metadata":{"collapsed":true},"execution_count":null,"outputs":[],"cell_type":"code","source":""}],"nbformat_minor":1,"nbformat":4}