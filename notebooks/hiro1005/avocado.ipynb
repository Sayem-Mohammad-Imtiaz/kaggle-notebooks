{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Data file\nimport numpy as np\nimport pandas as pd\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Import\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nimport seaborn as sns \n\nfrom sklearn.svm import SVR\nfrom sklearn.svm import LinearSVR\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressor #  KneighborsRegressorではない\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.model_selection import KFold\nfrom sklearn.linear_model import RANSACRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.ensemble import VotingRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom xgboost.sklearn import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"alldata = pd.read_csv('/kaggle/input/avocado-prices/avocado.csv')\nalldata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check 'year' coloum\nalldata['year'].value_counts()\n\n# Convert each 'year' column to Int\nalldata['year'] = alldata['year'].replace(\"2015\",0).replace(\"2016\",1).replace(\"2017\",2).replace(\"2018\",3)\n\n# Check 'region' coloum\nalldata['region'].value_counts()\n\n# Convert each 'region' column to Int\nalldata['region'] = alldata['region'].replace(\"Syracuse\",0).replace(\"Seattle\",1).replace(\"BuffaloRochester\",2).replace(\"Orlando\",3).replace(\"LasVegas\",4).replace(\"Tampa\",5).replace(\"Columbus\",6).replace(\"Denver\",7).replace(\"TotalUS\",8).replace(\"RichmondNorfolk\",9).replace(\"RaleighGreensboro\",10).replace(\"NorthernNewEngland\",11).replace(\"Northeast\",12).replace(\"Boston\",13).replace(\"MiamiFtLauderdale\",14).replace(\"Midsouth\",15).replace(\"Charlotte\",16).replace(\"Nashville\",17).replace(\"LosAngeles\",18).replace(\"Portland\",18).replace(\"Plains\",19).replace(\"SouthCentral\",20).replace(\"Philadelphia\",21).replace(\"California\",22).replace(\"CincinnatiDayton\",23).replace(\"GrandRapids\",24).replace(\"Louisville\",25).replace(\"Spokane\",26).replace(\"StLouis\",27).replace(\"Detroit\",28).replace(\"HartfordSpringfield\",29).replace(\"Atlanta\",30).replace(\"Indianapolis\",31).replace(\"West\",32).replace(\"SanDiego\",33).replace(\"Houston\",34).replace(\"GreatLakes\",35).replace(\"Pittsburgh\",36).replace(\"HarrisburgScranton\",37).replace(\"Albany\",38).replace(\"DallasFtWorth\",39).replace(\"Roanoke\",40).replace(\"Boise\",41).replace(\"Chicago\",42).replace(\"Sacramento\",43).replace(\"NewYork\",44).replace(\"Jacksonville\",45).replace(\"Southeast\",46).replace(\"PhoenixTucson\",47).replace(\"NewOrleansMobile\",48).replace(\"SanFrancisco\",49).replace(\"SouthCarolina\",50).replace(\"BaltimoreWashington\",51).replace(\"WestTexNewMexico\",52)\n\n# Check 'type' coloum\nalldata['type'].value_counts()\n\n# Convert each 'type' column to Int\nalldata['type'] = alldata['type'].replace(\"conventional\",0).replace(\"organic\",1)\n\n# Delete anyway\ndel alldata['XLarge Bags']\ndel alldata['Small Bags']\ndel alldata['Large Bags']\ndel alldata['4046']\ndel alldata['4225']\ndel alldata['4770']\ndel alldata['Total Bags']\ndel alldata['Unnamed: 0']\n\nalldata[\"Open Date\"] = pd.to_datetime(alldata[\"Date\"])\nalldata[\"Year\"] = alldata[\"Open Date\"].apply(lambda x:x.year)\nalldata[\"Month\"] = alldata[\"Open Date\"].apply(lambda x:x.month)\nalldata[\"Day\"] = alldata[\"Open Date\"].apply(lambda x:x.day)\nalldata[\"kijun\"] = \"2015-04-27\"\nalldata[\"kijun\"] = pd.to_datetime(alldata[\"kijun\"])\nalldata[\"BusinessPeriod\"] = (alldata[\"kijun\"] - alldata[\"Open Date\"]).apply(lambda x: x.days)\n\nalldata = alldata.drop('Open Date', axis=1)\nalldata = alldata.drop('kijun', axis=1)\n\ndel alldata['Date']\n\nalldata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_feature = alldata.drop(columns='AveragePrice')\ntrain_target = alldata['AveragePrice']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Searching for Effective feature（SelectKBest）\nfrom sklearn.feature_selection import SelectKBest, f_regression\n# Setting as search for especially 4 features\nselector = SelectKBest(score_func=f_regression, k=4) \nselector.fit(train_feature, train_target)\nmask_SelectKBest = selector.get_support()\n\n# Searching for Effective feature（SelectPercentile）\nfrom sklearn.feature_selection import SelectPercentile, f_regression\n# Setting as search for 40% features\nselector = SelectPercentile(score_func=f_regression, percentile=40) \nselector.fit(train_feature, train_target)\nmask_SelectPercentile = selector.get_support()\n\n# Searching for Effective feature（SelectFromModel）\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.ensemble import RandomForestRegressor\n# Setting as search for above median\nselector = SelectFromModel(RandomForestRegressor(n_estimators=100, random_state=42), threshold=\"median\")    \nselector.fit(train_feature, train_target)\nmask_SelectFromModel = selector.get_support()\n\n# Searching for Effective feature（RFE：n_features_to_select）\nfrom sklearn.feature_selection import RFE\nfrom sklearn.ensemble import RandomForestRegressor\n# Setting as search for only 2 features\nselector = RFE(RandomForestRegressor(n_estimators=100, random_state=42), n_features_to_select=2)\nselector.fit(train_feature, train_target)\nmask_RFE = selector.get_support()\n\nprint(train_feature.columns)\nprint(mask_SelectKBest)\nprint(mask_SelectPercentile)\nprint(mask_SelectFromModel)\nprint(mask_RFE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(train_feature, train_target, test_size=0.2, random_state=0, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\n# RandomForest==============\n\nrf = RandomForestRegressor(n_estimators=200, max_depth=5, max_features=0.5,  verbose=True, random_state=0, n_jobs=-1) # RandomForest のオブジェクトを用意する\nrf.fit(X_train, y_train)\nprint('='*20)\nprint('RandomForestRegressor')\nprint(f'accuracy of train set: {rf.score(X_train, y_train)}')\nprint(f'accuracy of test set: {rf.score(X_test, y_test)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# SVR（Support Vector Regression）==============\n\nsvr = SVR(verbose=True)\nsvr.fit(X_train, y_train)\nprint('='*20)\nprint('SVR')\nprint(f'accuracy of train set: {svr.score(X_train, y_train)}')\nprint(f'accuracy of test set: {svr.score(X_test, y_test)}')\n\n\n# LinearSVR==============\n\nlsvr = LinearSVR(verbose=True, random_state=0)\nlsvr.fit(X_train, y_train)\nprint('='*20)\nprint('LinearSVR')\nprint(f'accuracy of train set: {lsvr.score(X_train, y_train)}')\nprint(f'accuracy of test set: {lsvr.score(X_test, y_test)}')\n\n\n# SGDRegressor==============\n\nsgd = SGDRegressor(verbose=0, random_state=0)\nsgd.fit(X_train, y_train)\nprint('='*20)\nprint('SGDRegressor')\nprint(f'accuracy of train set: {sgd.score(X_train, y_train)}')\nprint(f'accuracy of test set: {sgd.score(X_test, y_test)}')\n\n\n# k-近傍法（k-NN）==============\n\nknn = KNeighborsRegressor()\nknn.fit(X_train, y_train)\nprint('='*20)\nprint('KNeighborsRegressor')\nprint(f'accuracy of train set: {knn.score(X_train, y_train)}')\nprint(f'accuracy of test set: {knn.score(X_test, y_test)}')\n\n\n# 決定木==============\n\ndecisiontree = DecisionTreeRegressor(max_depth=3, random_state=0)\ndecisiontree.fit(X_train, y_train)\nprint('='*20)\nprint('DecisionTreeRegressor')\nprint(f'accuracy of train set: {decisiontree.score(X_train, y_train)}')\nprint(f'accuracy of test set: {decisiontree.score(X_test, y_test)}')\n\n\n# LinearRegression (線形回帰)==============\n\nlr = LinearRegression()\nlr.fit(X_train, y_train)\nprint('='*20)\nprint('LinearRegression')\nprint(f'accuracy of train set: {lr.score(X_train, y_train)}')\nprint(f'accuracy of test set: {lr.score(X_test, y_test)}')\n# 回帰係数とは、回帰分析において座標平面上で回帰式で表される直線の傾き。 原因となる変数x（説明変数）と結果となる変数y（目的変数）の平均的な関係を、一次式y＝ax＋bで表したときの、係数aを指す。\nprint(\"回帰係数:\",lr.coef_)\nprint(\"切片:\",lr.intercept_)\n\n\n# RANSACRegressor==============\n\n# ロバスト回帰を行う（自然界のデータにはたくさんノイズがある。ノイズなどの外れ値があると、法則性をうまく見つけられないことがある。そんなノイズをうまく無視してモデルを学習させるのがRANSAC）\n#線形モデルをRANSACでラッピング　（外れ値の影響を抑える）\nfrom sklearn.linear_model import RANSACRegressor\n \nransac=RANSACRegressor(lr,#基本モデルは、LinearRegressionを流用\n                       max_trials=100,#イテレーションの最大数100\n                       min_samples=50,#ランダムに選択されるサンプル数を最低50に設定\n                       loss=\"absolute_loss\",#学習直線に対するサンプル店の縦の距離の絶対数を計算\n                       residual_threshold=5.0,#学習直線に対する縦の距離が5以内のサンプルだけを正常値\n                       random_state=0)\n \nransac.fit(X_train, y_train)\nprint('='*20)\nprint('RANSACRegressor')\nprint(f'accuracy of train set: {lr.score(X_train, y_train)}')\nprint(f'accuracy of test set: {lr.score(X_test, y_test)}')\nprint(\"RANSAC回帰係数:\",ransac.estimator_.coef_[0])\nprint(\"RANSAC切片:\",ransac.estimator_.intercept_)\n\n\n# RIDGE回帰==============\n\nridge = Ridge(random_state=0)\nridge.fit(X_train, y_train)\nprint('='*20)\nprint('Ridge')\nprint(f'accuracy of train set: {ridge.score(X_train, y_train)}')\nprint(f'accuracy of test set: {ridge.score(X_test, y_test)}')\n\n\n# LASSO回帰==============\n\nlasso = LassoCV(alphas = [1, 0.1, 0.001, 0.0005], verbose=True, random_state=0)\nlasso.fit(X_train, y_train)\nprint('='*20)\nprint('LassoCV')\nprint(f'accuracy of train set: {lasso.score(X_train, y_train)}')\nprint(f'accuracy of test set: {lasso.score(X_test, y_test)}')\n\n\n# ElasticNet==============\n\nen = ElasticNet(random_state=0)\nen.fit(X_train, y_train)\nprint('='*20)\nprint('ElasticNet')\nprint(f'accuracy of train set: {en.score(X_train, y_train)}')\nprint(f'accuracy of test set: {en.score(X_test, y_test)}')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}