{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Data file\nimport numpy as np\nimport pandas as pd\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Import\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nimport seaborn as sns \n\nfrom sklearn.svm import SVR\nfrom sklearn.svm import LinearSVR\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressor #  KneighborsRegressorではない\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.model_selection import KFold\nfrom sklearn.linear_model import RANSACRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.ensemble import VotingRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom xgboost.sklearn import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vg = pd.read_csv('/kaggle/input/videogamesales/vgsales.csv', header=0)\nvg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Missing data\ndef Missing_table(df):\n    # null_val = df.isnull().sum()\n    null_val = df.isnull().sum()[df.isnull().sum()>0].sort_values(ascending=False)\n    percent = 100 * null_val/len(df)\n    na_col_list = df.isnull().sum()[df.isnull().sum()>0].index.tolist() # 欠損を含むカラムをリスト化\n    list_type = df[na_col_list].dtypes.sort_values(ascending=False) #データ型\n    Missing_table = pd.concat([null_val, percent, list_type], axis = 1)\n    missing_table_len = Missing_table.rename(\n    columns = {0:'Missing data', 1:'%', 2:'type'})\n    return missing_table_len.sort_values(by=['Missing data'], ascending=False)\n\nMissing_table(vg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Delete rows and columns containing missing values\nvg.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Platform = pd.get_dummies(vg['Platform'])\nGenre = pd.get_dummies(vg['Genre'])\nPublisher = pd.get_dummies(vg['Publisher'])\ndel vg['Rank']\n\nvg['Year'].value_counts()\nvg[\"kijun\"] = 1980.0\nvg[\"release year\"] = vg[\"Year\"] - vg[\"kijun\"]\n\ndel vg['Year']\ndel vg['kijun']\ndel vg['Name']\n\ntotal_vg = pd.concat([vg, Platform, Genre, Publisher], axis=1)\n\ndel total_vg['Platform']\ndel total_vg['Genre']\ndel total_vg['Publisher']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_dataset(df):\n    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n    df.dropna(inplace=True)\n    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n    return df[indices_to_keep].astype(np.float64)\n  \nclean_dataset(total_vg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_feature = total_vg.drop(columns='Global_Sales')\ntrain_target = total_vg['Global_Sales']\n\nX_train, X_test, y_train, y_test = train_test_split(train_feature, train_target, test_size=0.2, random_state=0, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\n# RandomForest==============\n\nrf = RandomForestRegressor(n_estimators=200, max_depth=5, max_features=0.5,  verbose=True, random_state=0, n_jobs=-1) # RandomForest のオブジェクトを用意する\nrf.fit(X_train, y_train)\nprint('='*20)\nprint('RandomForestRegressor')\nprint(f'accuracy of train set: {rf.score(X_train, y_train)}')\nprint(f'accuracy of test set: {rf.score(X_test, y_test)}')\n\n# SVR（Support Vector Regression）==============\n\nsvr = SVR(verbose=True)\nsvr.fit(X_train, y_train)\nprint('='*20)\nprint('SVR')\nprint(f'accuracy of train set: {svr.score(X_train, y_train)}')\nprint(f'accuracy of test set: {svr.score(X_test, y_test)}')\n\n# LinearSVR==============\n\nlsvr = LinearSVR(verbose=True, random_state=0)\nlsvr.fit(X_train, y_train)\nprint('='*20)\nprint('LinearSVR')\nprint(f'accuracy of train set: {lsvr.score(X_train, y_train)}')\nprint(f'accuracy of test set: {lsvr.score(X_test, y_test)}')\n\n# SGDRegressor==============\n\nsgd = SGDRegressor(verbose=0, random_state=0)\nsgd.fit(X_train, y_train)\nprint('='*20)\nprint('SGDRegressor')\nprint(f'accuracy of train set: {sgd.score(X_train, y_train)}')\nprint(f'accuracy of test set: {sgd.score(X_test, y_test)}')\n\n# k-近傍法（k-NN）==============\n\nknn = KNeighborsRegressor()\nknn.fit(X_train, y_train)\nprint('='*20)\nprint('KNeighborsRegressor')\nprint(f'accuracy of train set: {knn.score(X_train, y_train)}')\nprint(f'accuracy of test set: {knn.score(X_test, y_test)}')\n\n# 決定木==============\n\ndecisiontree = DecisionTreeRegressor(max_depth=3, random_state=0)\ndecisiontree.fit(X_train, y_train)\nprint('='*20)\nprint('DecisionTreeRegressor')\nprint(f'accuracy of train set: {decisiontree.score(X_train, y_train)}')\nprint(f'accuracy of test set: {decisiontree.score(X_test, y_test)}')\n\n\n# LinearRegression (線形回帰)==============\n\nlr = LinearRegression()\nlr.fit(X_train, y_train)\nprint('='*20)\nprint('LinearRegression')\nprint(f'accuracy of train set: {lr.score(X_train, y_train)}')\nprint(f'accuracy of test set: {lr.score(X_test, y_test)}')\n# 回帰係数とは、回帰分析において座標平面上で回帰式で表される直線の傾き。 原因となる変数x（説明変数）と結果となる変数y（目的変数）の平均的な関係を、一次式y＝ax＋bで表したときの、係数aを指す。\nprint(\"回帰係数:\",lr.coef_)\nprint(\"切片:\",lr.intercept_)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}