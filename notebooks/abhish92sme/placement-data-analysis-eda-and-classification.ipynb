{"cells":[{"metadata":{},"cell_type":"markdown","source":"#                 **Campus Recruitment Data Analysis**\nIn this Note we use the data provided by Ben Rosan D on campus recruitment process and try to solve the question arise from the dataset.\nThese Questions are\n1. Which factor influenced a candidate in getting placed?\n1. Does percentage matters for one to get placed?\n1. Which degree specialization is much demanded by corporate?\n\nIn addition the these given questions there are some questions we have to solve these are\n1. Classification of Test data into Placed or Not Placed Category.\n1. Is there any correlation between the different exams percentage with each other (one to one) and with salary"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Importing the Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas import plotting\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.figure_factory as ff\nimport plotly.offline as py\nfrom plotly.offline import iplot\nimport plotly.graph_objs as go\nfrom plotly.offline import plot","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reading the Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/factors-affecting-campus-placement/Placement_Data_Full_Class.csv\")\ndf.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"placed=df.dropna()\nN_placed=df[df[\"status\"]==\"Not Placed\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"placed.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"N_placed.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Visualisation**"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig=plt.figure(figsize=(18,10))\nplt.subplot(1,3,1)\nplt.pie(df[\"gender\"].value_counts(),labels={\"Male\",\" Female\"},colors={\"cyan\", \"yellow\"},\n        shadow=True,autopct = '%.2f%%')\nplt.title(\"Total Student\")\nplt.subplot(1,3,2)\nplt.pie(placed[\"gender\"].value_counts(),labels={\"Male\",\" Female\"},colors={\"blue\", \"pink\"},\n        shadow=True,autopct = '%.2f%%')\nplt.title(\"Placed Student\")\nplt.subplot(1,3,3)\nplt.pie(N_placed[\"gender\"].value_counts(),labels={\"Male\",\" Female\"},colors={\"green\", \"orange\"},\n        shadow=True,autopct = '%.2f%%')\nplt.title(\"Not Placed Student\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above pie charts we can conclude the following points-\n* Male Students have a higher number of placed students in the aspect of their representation in the  total population.\n* Female Students have a lower number of placed students in the aspects of their representation in the total population."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data=df,kind=\"scatter\",hue=\"gender\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the above pairplot we can concludes the following points-\n* Mean of ssc percentage is around 60% for Male students and around 80% for Female students.\n* Mean of hsc percentage is around 60% for Male students and around 60% for Female students. \n* Mean of degree percentage is around 60% for Male students and around 65% for Female students.\n* Mean of mba percentage is around 55% for Male students and around 65% for Female students.\n* Mean of Entrance Test  percentage is around 55% for Male students and around 55% for Female students.\nThere is positive correlation between the different exam percentage.\nThere is not any correlation between salary and exam percentage.\nWe can also see that the mean average salary of male students are higher than mean average salary of female students."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data=df,kind=\"scatter\",hue=\"status\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above pair plot we can conclude that those students who consistently score lower percentages in their different examinations are not placed. It is strongly evident in the SSC, HSC  and Degree percentage but in Etest and Mba there is not good evidence to support the claim."},{"metadata":{"trusted":true},"cell_type":"code","source":"gen=px.scatter_3d(df,x=\"ssc_p\",y=\"hsc_p\",z=\"degree_p\",color=\"status\")\niplot(gen)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the above 3d plot the same information can be extracted that in the Not placed students there are more numbers of the students who scored less than 60 percentage in their SSC,HSC and Degree exam."},{"metadata":{"trusted":true},"cell_type":"code","source":"gen=px.scatter_3d(df,x=\"mba_p\",y=\"etest_p\",z=\"degree_p\",color=\"status\")\niplot(gen)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig=plt.figure(figsize=(12,6))\nsns.countplot(\"specialisation\", hue=\"status\", data=df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Marketing and Finance are the most demanded specialisation among the two specialisation according to the given data."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize =(18,6))\nsns.boxplot(\"salary\", \"gender\", data=df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above box plot we can say that there is more no of outlier in Male students than Female students in terms of Salary."},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize =(18,6))\nsns.boxplot(\"salary\", \"workex\", data=df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Classification**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(\"hsc_b\",inplace=True,axis=1)\ndf.drop(\"ssc_b\",inplace=True,axis=1)\ndf.drop(\"sl_no\",inplace=True,axis=1)\nX=df.iloc[:,:-2].values\nY=df.iloc[:,-2].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Encoding the data **"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlabelencoder_X=LabelEncoder()\nX[:,3]=labelencoder_X.fit_transform(X[:,3])\nX[:,0]=labelencoder_X.fit_transform(X[:,0])\nX[:,5]=labelencoder_X.fit_transform(X[:,5])\nX[:,6]=labelencoder_X.fit_transform(X[:,6])\nX[:,8]=labelencoder_X.fit_transform(X[:,8])\nY=labelencoder_X.fit_transform(Y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Train and Test Data split\nTrain = 60% of given data.\nTest= 40% of the given data."},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.4,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Standard Scaling of the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# *Decison Tree Classifier*"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nclassifier = DecisionTreeClassifier(criterion = 'entropy',)\nclassifier.fit(X_train, Y_train)\nY_pred = classifier.predict(X_test)\nfrom sklearn.metrics import roc_auc_score\nauc = roc_auc_score(Y_test, Y_pred)\nprint(auc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\nprint(classification_report(Y_test,Y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Confusion Matrix**"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(Y_test,Y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can say that our model predict\n* TP(Actual Yes and Predicted Yes)=51\n* FP(Actual No and Predicted Yes)=7\n* FN(Actual Yes and Predicted No) =8\n* TN (Actual No and Predicted No) =20"},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(Y_test, Y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We have a pretty decent accuracy of 82 percentage.**"},{"metadata":{},"cell_type":"markdown","source":"**Feature Importance**"},{"metadata":{"trusted":true},"cell_type":"code","source":"imp=classifier.feature_importances_*100\nFec=pd.DataFrame(imp,columns=[\"Importance\"])\n\nNam=[\"Gender\",\"SSC %\",\"HSC %\",\"HSC Stream\",\"Degree % \",\"Degree Stream\",\n              \"Work Ex\",\"Entrance %\",\" Specialisation\",\"Mba %\"]\nFec[\"Features\"]=Nam\nFec.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig=plt.figure(figsize=(12,6))\nsns.barplot(Fec.Features,Fec.Importance)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" From the above bar chart we know that If we have a 5 percentage minimum confidence bound then, \n     The important features which decide one probability of getting placed are- SSC%, HSC%, Degree%, MBA% .\n "},{"metadata":{},"cell_type":"markdown","source":"# Random Forest Classification "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n#Using Random Forest Algorithm\nrandom_forest = RandomForestClassifier(n_estimators=30,random_state=0)\nrandom_forest.fit(X_train, Y_train)\nY_pred = random_forest.predict(X_test)\nfrom sklearn.metrics import roc_auc_score\nauc = roc_auc_score(Y_test, Y_pred)\nprint(auc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\nprint(classification_report(Y_test,Y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(Y_test,Y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can say that our model predict\n* TP(Actual Yes and Predicted Yes)=52\n* FP(Actual No and Predicted Yes)=7\n* FN(Actual Yes and Predicted No) =8\n* TN (Actual No and Predicted No) =19"},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(Y_test, Y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imp=random_forest.feature_importances_*100\nFec=pd.DataFrame(imp,columns=[\"Importance\"])\n\nNam=[\"Gender\",\"SSC %\",\"HSC %\",\"HSC Stream\",\"Degree % \",\"Degree Stream\",\n              \"Work Ex\",\"Entrance %\",\" Specialisation\",\"Mba %\"]\nFec[\"Features\"]=Nam\nFec.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig=plt.figure(figsize=(12,6))\nsns.barplot(Fec.Features,Fec.Importance)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above bar chart we know that If we have a 5 percentage minimum confidence bound then, The important features which decide one probability of getting placed are- SSC%, HSC%, Degree%, MBA%, Work EX and Entrance % ."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}