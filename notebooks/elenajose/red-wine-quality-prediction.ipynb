{"cells":[{"metadata":{},"cell_type":"markdown","source":"## BUILDING A MACHINE LEARNING MODEL USING LOGISTIC REGRESSION\n\n#### PREDICTING THE QUALITY OF RED WINE BASED ON ITS PHYSIOCHEMICAL PROPERTIES\n\n###### This dataset is related to red variants of the Portuguese \"Vinho Verde\" wine and has been obtained from Kaggle. For more details, check the referene Cortez et al., 2009. The data is also available on UCI machine learning repository. A logistic regression model has been fit to the data to study the effect of certain pysiochemical properties of wine on its quality.\n\n###### The dataset has one target variable, the quality of wine, based on sensory data and 11 pysiochemical properties of 1599 observations.\n\n###### We begin by importing the required libraries and the dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#alias importing\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"red_wine = pd.read_csv(\"../input/red-wine-quality-cortez-et-al-2009/winequality-red.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Exploring the data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"red_wine.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"red_wine.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### Let us check the data type of the variables ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"red_wine.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### It can be seen that all the variables are of the float data type except the 'quality' variable because it contains integer quality ratings of the red wine. Since, 'quality' is our target variable, we move to see what its observations look like.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"red_wine.quality.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"red_wine.quality.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### The 'quality' variable is presently a continuous variable, but we want to convert it to a binary categorical variable to distinguish between good and bad quality wine. 'Quality' takes six unique integer values, these ratings range from 1 to 10. Let us categorise a 'good' quality wine as something with a value above 6.9 and the remaining as 'bad'.\n\n###### Using correlation, we can see how much does each of the pysiochemical properties of wine affect its quality.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"red_wine.corr()['quality'].sort_values(ascending=False).drop('quality')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"red_wine.corr()['quality'].drop('quality').plot(kind='bar',color='magenta', title='Graph 1.1 - Pearson Correlation');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### Alcohol has the highest positive effect on the quality of wine, whereas volatile acidity is the most negatively impacting it.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(red_wine.corr())\nplt.title('Graph 1.2 - Heatmap of Correlation');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### It can be seen that the alcohol content in the wine affects the quality the most. It has a positive Pearson correlation coefficient of 0.47, meaning if we increase the alcohol content in wine by one unit, the quality increases by 0.47 units or 47%.\n\n###### Before proceeding to do a binary classification of the target variable, let us check for missing values first using the 'isnull' function.\n\n### Cleaning the data\n\n###### We check for any missing values in our data and remove them.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"red_wine.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### We see that there are no missing values. (P.S. You rarely encounter such datasets with zero missing values)\n\n###### We next move on to do a binary classification of the target variable into 'good' and 'bad'. I learned using this code from a Kaggle kernel of the same dataset.\n\n### Pre-processing the data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Binary classification of the target variable into 'good' and 'bad'\nbins=(2,6.9,8)\ngroup_names=['bad','good']\nred_wine['quality']=pd.cut(red_wine['quality'],bins=bins,labels=group_names)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### We create 2 bins (group names), namely, 'good' and bad'. Any wine that has a quality rating above 6.9 has been categorised as 'good' and that below 6.9 as 'bad'. To achieve the same, we use the Pandas cut function.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"red_wine.quality.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### The 'quality' variable is now divided into two categories. Since, any ML algorithm deals with numeric data (float or integer), our next step is to code these two categories. This is done using the LabelEncoder function from the Preprocessing sub-library of the Sklearn library. Therefore, 'bad' is assigned 0 and 'good' 1.\n\n###### It is to be also noted, however, that LabelEncoder automatically gives higher weightage to higher labels, which holds true in our data, hence used.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_qual = LabelEncoder()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Assigning labels - Bad becomes 0 and good becomes 1 \nred_wine['quality'] = label_qual.fit_transform(red_wine['quality'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"red_wine.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### Note, we converted the 'quality' variable from an integer value to a categorical variable and then again to an integer.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"red_wine['quality'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### This shows that our data has 1382 bad quality wine and 217 good quality wine. We have an imbalanced target class.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting\nplt.style.use('fivethirtyeight')\nred_wine['quality'].value_counts().plot(kind='bar', title='Graph 1.3 - Count of good and bad quality wine');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### We move to defining our feature columns i.e. the (independent) variables that affect the quality (dependent variable) of wine.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"red_wine.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_columns=['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n       'pH', 'sulphates', 'alcohol']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### Assigning the target / dependent (y) and response / independent (X) variables.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#response variables and target variable\nX=red_wine[feature_columns]\ny=red_wine.quality","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### Before moving on to building the machine learning model, let us scale our data so that no single variable dominates our results. For this, we use the StandardScaler function from the Preprocessing sub-library of the Sklearn library.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler=StandardScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=scaler.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### Now that our pre-processing part is done, we move on to building our Machine Learning model using the Logistic Regression algorithm.\n\n### Model building - Logistic Regression\n\n###### We begin by splitting our data into 80% training and 20% testing data. This is achieved using the 'train_test_split' function from the 'model_selection' sub-library of the Sklearn library.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=13)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### We now call the 'LogisticRegression' function from the 'linear_model' sub-library of the Sklearn library.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"redwinelogit=LogisticRegression()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### We have defined the model as 'redwinelogit' which we now fit into the training data. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"redwinelogit.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### Let us check the accuracy score","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"redwinelogit.score(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"redwinelogit.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### We are getting an accuracy score of 88%.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"redwinelogit.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(redwinelogit.coef_)\nprint(redwinelogit.intercept_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### It can be seen that 'alcohol' has a coefficient of positive 0.82 which indicates that the alcohol level of wine has the highest effect on its quality. A coefficient (slope) of 0.82 means that if the alcohol content is increased by 1 unit, wine's quality increases by 0.82 units or 82%.\n\n###### It can also be seen that if the total sulphur dioxide content is increased by 1 unit, wine's quality will decrease by 52%.\n\n###### Since our target class is imbalanced, we do not rely alone on the accuracy rate. We make use of the precision-recall and receiver operating characteristic (ROC) curve to check the reliability of our model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test,redwinelogit.predict(X_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### The above result tells us that 271+13=284 observations are predicted correctly and 8+28=36 are predicted incorrectly.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test,redwinelogit.predict(X_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### The model predicts and classifies 279 out of the 320 observations (20% testing data of 1599 observations) into class 0 i.e. bad quality wine and the remaining 41 into class 1 i.e. good quality wine. Thus, 87% of the testing data has been classified into class 0 and 13% into class 1. It is due to an imbalanced target class that most of the observations have been predicted to be of bad quality.\n\n###### According to our model,\n\n###### False Positive (FP) is a wine that was predicted to be of good quality, but turns out to be actually bad\n###### False Negative (FN) is a wine that was predicted to be of bad quality, but turns out to be actually good\n###### So,\n###### Cost of FP > Cost of FN, therefore, higher weightage is given to precision at the cost of recall.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"precision, recall, _ = precision_recall_curve(y_test,redwinelogit.predict(X_test))\nplt.plot(recall,precision)\nplt.xlabel('Recall')\nplt.ylabel(\"Precision\")\nplt.title(\"Graph 1.4 - Precision Recall Curve\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot_roc_curve throwing an import error. Referred this method from a Medium article. Link given in sources section at the end.\nfrom sklearn.metrics import roc_auc_score, roc_curve","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logit_roc_auc = roc_auc_score(y_test, redwinelogit.predict(X_test))\nfpr, tpr, thresholds = roc_curve(y_test, redwinelogit.predict_proba(X_test)[:,1])\nplt.figure()\nplt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\nplt.plot([0, 1], [0, 1],'r-')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Graph 1.5 - Receiver Operating Characteristic')\nplt.legend(loc=\"lower right\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### We get an ROC AUC of 0.64 which indicates that our model is 64% accurate.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"###### Created by Elena Jose, under the guidance of Prof. Pitabas Mohanty (XLRI Jamshedpur)\n###### Sources: https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009\n###### https://www.kaggle.com/vishalyo990/prediction-of-quality-of-wine\n###### https://towardsdatascience.com/building-a-logistic-regression-in-python-step-by-step-becd4d56c9c8","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}