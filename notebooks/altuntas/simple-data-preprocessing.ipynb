{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import MinMaxScaler     #1. Rescale Data\nfrom sklearn.preprocessing import Binarizer        #2. Binarize Data (Make Binary)\nfrom sklearn.preprocessing import StandardScaler   #3. Standardize Data\n\nimport warnings\nwarnings.filterwarnings('ignore')\nimport os\nprint(os.listdir(\"../input\"))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"names = ['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age','Class']\n\ndf = pd.read_csv(\"../input/pima-indians-diabetes.csv\",names=names)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum() #we dont have any missing value I'll show later what we can do with missing values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#1. Rescale Data: It's make our data's values on the same scales.\n#Because many algorithms doesn't work when your data have different scales.\n\narray = df.values\nscaler = MinMaxScaler(feature_range=(0, 1)) #Making a scaler between 0 and 1\nrescalled_df = scaler.fit_transform(array)\n\n#Now we should convert this array to dataset, as most of us know first we write pd.DataFrame than we give names than we choose the column.\nrescalled_df = pd.DataFrame(rescalled_df)\nrescalled_df.columns = names\nrescalled_df.head() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#2. Binarize Data (Make Binary): It's make our data's 1 or 0, Ä±t's called binarizing your data or threshold your data.\n#I take a little look at this and it's usefull for making threshold pictures\n\narray = df.values\nbinarizer = Binarizer(threshold=0.0).fit(array)#We are giving array to Binarizer now Binarizer can know which values should 0 which values should be 1\nbinarized_df = binarizer.transform(array)#then we transform that values \n\n#Now we should convert this array to dataset, as most of us know first we write pd.DataFrame than we give names than we choose the column.\nbinarized_df = pd.DataFrame(binarized_df)\nbinarized_df.columns = names\nbinarized_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#3. Standardize Data:It's find which values are to bigger than and to smaller than the avarage.\n#then to bigger number's being bigger than 1 to smaller number's being smaller tahn 0\n\narray = df.values\nscaler = StandardScaler().fit(array)  #giving array to StandardScaler and it's finding avarage than making magic :)\nstandard_df = scaler.transform(array)\n\n#Now we should convert this array to dataset, as most of us know first we write pd.DataFrame than we give names than we choose the column.\nstandard_df = pd.DataFrame(standard_df)\nstandard_df.columns = names\nstandard_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 4-Outlier detection\ndef find_outlier(x):\n    q1 = np.percentile(x, 25)\n    q3 = np.percentile(x, 75)\n    iqr = q3-q1\n    floor = q1 - 1.5*iqr\n    ceiling= q3 + 1.5*iqr\n    outlier_indices = list(x.index[(x<floor)|(x>ceiling)])\n    outlier_values = list(x[(x<floor)|(x>ceiling)])\n    return outlier_indices, outlier_values\noutlier_age = np.sort(find_outlier(df.Age)) #These values are the outlier indices and values\nprint(outlier_age)\n\noutlier_df = df.drop(outlier_age[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#5-Interaction among features\n#here we make combo with featrues/columns, function take one column and multipcation with another one\nfrom itertools import combinations\nfrom sklearn.preprocessing import PolynomialFeatures\n   \ndef add_interations(df):\n    # Get features/columns names\n    combos = list(combinations(list(df.columns), 2))\n    colnames = list(df.columns) + ['_'.join(x) for x in combos]\n        \n    # Find interations\n    poly = PolynomialFeatures(interaction_only=True, include_bias=False)\n    df = poly.fit_transform(df)\n    df = pd.DataFrame(df)\n    df.columns = colnames\n        \n    return df\n    \ndf_combo = add_interations(df)\nprint(df_combo.shape)\ndf_combo.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now lets take a look what actually we did\n\n#0-Countplot of pure data\nplt.figure(figsize=(8,8))\nsns.countplot(x=df.Age)\nplt.xticks(rotation=90)\nplt.show()\n\n#1-Countplot of resacalled data\nplt.figure(figsize=(8,8))\nsns.countplot(x=rescalled_df.Age)\nplt.xticks(rotation=90)\nplt.show()\n\n#2-Countplot of binarized data\nplt.figure(figsize=(8,8))\nsns.countplot(x=binarized_df.Age)\nplt.xticks(rotation=90)\nplt.show()\n\n#3-Countplot of standardize Data\nplt.figure(figsize=(8,8))\nsns.countplot(x=standard_df.Age)\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Not much different after drop outlier_age but if you look at carefully you can see the different \nsns.jointplot(x=df.Age.unique(),y=df.Age.value_counts(),kind='reg')\nplt.show()\n\nsns.jointplot(x=outlier_df.Age.unique(),y=outlier_df.Age.value_counts(),kind='reg')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}