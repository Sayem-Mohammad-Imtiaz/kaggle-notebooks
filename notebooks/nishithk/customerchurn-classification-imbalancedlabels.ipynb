{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nchurn_data = pd.read_csv('../input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n\n#TotalCharges column has missing values - handle it\n#Just removing those rows since they're only 11 in number and look like erroneous data\nlen(churn_data[churn_data['TotalCharges'].str.strip()==\"\"])\n\nchurn_data = churn_data[churn_data['TotalCharges'].str.strip()!=\"\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encode_columns = ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService',\n                  'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', \n                  'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']\n\nfeatures = list(churn_data.columns)\nfeatures.remove('Churn')\nfeatures.remove('customerID')\n\nX = churn_data[features]\nX_encoded = pd.get_dummies(X, columns=encode_columns, drop_first=True)\n\n#Cast TotalCharges column from type object to float\nX_encoded['TotalCharges'] = X_encoded['TotalCharges'].astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#1. Build a logistic regression model\nimport statsmodels.api as sm\n\nX_encoded = sm.add_constant(X_encoded)\n\ny = churn_data.Churn\ny_encoded = y.map(lambda x:1 if x=='Yes' else 0)\n#It's an imbalanced dataset: 0: 5163, 1: 1869\ny_encoded.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#1. Logistic regression\nfrom sklearn.model_selection import train_test_split\n\n#X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=0)\n\n#logit = sm.Logit(y_train, X_train).fit()\n\n#Above throws singular matrix errors. Let's check the features for collinearity\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\ndef get_vif(X):\n    X_matrix = X.values\n    vif = [variance_inflation_factor(X_matrix, i) for i in range( X_matrix.shape[1] )]\n    vif_factors = pd.DataFrame()\n    vif_factors['col'] = X.columns\n    vif_factors['vif'] = vif\n    return vif_factors\n\nvif_factors = get_vif(X_encoded)\n\n#There are several features with VIF of infinity, which means they're exactly a linear combination of other features\n#Let's remove these Inf VIF features\nvif_factors_finite = vif_factors[vif_factors['vif']!=np.Inf]\n\n#Now lets check VIF of columns with large VIF\nlarge_vif_cols = vif_factors_finite[vif_factors_finite.vif > 4].col","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check correlation of these features\nimport seaborn as sn\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(14,12))\nsn.heatmap(X_encoded[large_vif_cols].corr(), annot=True)\n\n#Tenure/TotalCharges are highly correlated (0.83)\n#MonthlyCharges/InternetService_Fiber Optic are highly correlated (0.79)\n#MonthlyCharges/TotalCharges are also moderately correlated (0.65)\n#TotalCharges and MonthlyCharges also have moderate to high correlation with all features\n#So, we remove Tenure, TotalCharges and MonthlyCharges from the list of features\n\nnon_collinear_cols = list( set(large_vif_cols) - set(['Tenure', 'MonthlyCharges', 'TotalCharges']) )\n\nget_vif(X_encoded[non_collinear_cols])\n\n#Split the dataset for train/test again\nX_encoded_new = sm.add_constant(X_encoded[non_collinear_cols])\nX_train, X_test, y_train, y_test = train_test_split(X_encoded_new, y_encoded,\n                                                    test_size=0.2, random_state=0)\n\nlogit_2 = sm.Logit(y_train, X_train).fit()\n\nlogit_2.summary2()\n\n#p-values of OnlineBackup_Yes and DeviceProtection_Yes >> 0.05. Remove these\nsignificant_features = list(set(X_encoded_new.columns) - set(['OnlineBackup_Yes', 'DeviceProtection_Yes']))\nX_encoded_3 = X_encoded_new[significant_features]\n\nX_train, X_test, y_train, y_test = train_test_split(X_encoded_3, y_encoded,\n                                                    test_size=0.2, random_state=0)\n\n\nlogit_3 = sm.Logit(y_train, X_train).fit()\n\nlogit_3.summary2()\n\ny_pred = logit_3.predict(sm.add_constant(X_test))\n\ny_pred_df = pd.DataFrame({'actual':y_test, 'pred_prob_logit':y_pred})\ny_pred_df['predicted_logit'] = y_pred_df['pred_prob_logit'].apply(lambda x: 1 if x>0.5 else 0)\n#Let's check the precision and recall since its an imbalanced dataset\nfrom sklearn import metrics\n\nprint(metrics.confusion_matrix(y_pred_df.actual, y_pred_df.predicted_logit))\nprint(metrics.classification_report(y_pred_df.actual, y_pred_df.predicted_logit))\n\n#Recall for 1, i.e. positive cases is low, i.e. 0.46. Precision is ok, 0.83 (0) and 0.67 (1)\n\n#2. Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier(n_estimators=20, criterion='gini', random_state=0)\nrfc.fit(X_train, y_train)\n\ny_pred_rf = rfc.predict(X_test)\n\ny_pred_df['pred_prob_rf'] = y_pred_rf\ny_pred_df['predicted_rf'] = y_pred_df['pred_prob_rf'].apply(lambda x:1 if x>0.5 else 0)\n\nprint(metrics.confusion_matrix(y_pred_df.actual, y_pred_df.predicted_rf))\nprint(metrics.classification_report(y_pred_df.actual, y_pred_df.predicted_rf))\n\n#Precision for 1 actually degrades to 0.55, while recall improves marginally\n\n#3. SVM classification\nfrom sklearn.svm import SVC\n\nsvc = SVC(kernel='rbf', random_state=0)\nsvc.fit(X_train, y_train)\n\ny_pred_svm = svc.predict(X_test)\n\ny_pred_df['predicted_svm'] = y_pred_svm\n\nprint(metrics.confusion_matrix(y_pred_df.actual,y_pred_df.predicted_svm))\nprint(metrics.classification_report(y_pred_df.actual,y_pred_df.predicted_svm))\nprint(metrics.classification_report(y_pred_df.actual,y_pred_df.predicted_logit))\nprint(metrics.classification_report(y_pred_df.actual,y_pred_df.predicted_rf))\n\n#Improvement is still negligible\n\n#4. Naive Bayes classifier\nfrom sklearn.naive_bayes import GaussianNB\n\nnaive = GaussianNB()\nnaive.fit(X_train, y_train)\n\ny_pred_naive = naive.predict(X_test)\n\ny_pred_df['predicted_naive'] = y_pred_naive\n\nprint(metrics.classification_report(y_pred_df.actual,y_pred_df.predicted_naive))\n\n#Precision and Recall (and hence F1-score) improve. New F1-score is 0.86 (0) and 0.55 (1)\n\n#5. Gradient Boosting Classifier\nfrom sklearn.ensemble import GradientBoostingClassifier\n\ngbc = GradientBoostingClassifier()\n\ngbc.fit(X_train, y_train)\n\ny_pred_gbc = gbc.predict(X_test)\n\ny_pred_df['prediction_gbc'] = y_pred_gbc\n\nprint(metrics.classification_report(y_pred_df.actual, y_pred_df.prediction_gbc))\n\n#F1-score improves marginally from 0.86 to 0.87 for y=0\n\n#6. AdaBoost classifier\nfrom sklearn.ensemble import AdaBoostClassifier\n\nabc = AdaBoostClassifier()\nabc.fit(X_train, y_train)\n\ny_pred_abc = abc.predict(X_test)\n\ny_pred_df['predicted_abc'] = y_pred_abc\n\nprint(metrics.classification_report(y_pred_df.actual, y_pred_df.predicted_abc))\n\n#No improvements. Lastly, lets try XGBoost Classifier\nfrom xgboost import XGBClassifier\n\nxgb = XGBClassifier()\nxgb.fit(X_train, y_train)\n\ny_pred_xgb = xgb.predict(X_test)\n\ny_pred_df['predicted_xgb'] = y_pred_xgb\n\nprint(metrics.classification_report(y_pred_df.actual,y_pred_df.predicted_xgb))\n\n#Logistic regression looks like a good option compared  to other advanced classifiers\n#Let's try getting the optimum prob. threshold for logistic regression\n\nfpr, tpr, thresholds = metrics.roc_curve(y_pred_df.actual, y_pred_df.pred_prob_logit, \n                                        drop_intermediate=False)\n\ntpr_fpr = pd.DataFrame({'tpr':tpr, 'fpr':fpr, 'thresholds': thresholds})\n\ntpr_fpr['diff'] = tpr_fpr['tpr']-tpr_fpr['fpr']\n\ntpr_fpr.sort_values('diff', ascending=False)\n\n#Threshold of 0.29 gives the max tpr-fpr. Let's use the same\ny_pred_logit_new = y_pred_df['pred_prob_logit'].apply(lambda x: 1 if x > 0.29 else 0)\n\ny_pred_df['y_pred_logit_new'] = y_pred_logit_new\n\nprint(metrics.classification_report(y_pred_df.actual, y_pred_df.y_pred_logit_new))\n\n#We get F1-score of 0.81 (0) and 0.60 (1). Hence, best model performance so far\n\n#7. Logistic Regression with oversampling of the minority class\ny_encoded.value_counts()\n#0    5163\n#1    1869\n\n#8. Try oversampling the smaller (1) class label, then use optimal prob. threshold\n#using Youden's index\nfrom sklearn.utils import resample, shuffle\n\nchurn_data_yes = churn_data[churn_data.Churn=='Yes']\nchurn_data_no = churn_data[churn_data.Churn=='No']\n\nchurn_data_yes_resampled = resample(churn_data_yes, replace=True, \n                                    n_samples = len(churn_data_no))\n\nchurn_data_new = pd.concat([churn_data_yes_resampled, churn_data_no])\nchurn_data_new = shuffle(churn_data_new)\n\nX = churn_data_new[features]\ny = churn_data_new.Churn\ny_encoded = y.map(lambda x:1 if x=='Yes' else 0)\ny_encoded.value_counts()\n\nX_encoded = pd.get_dummies(X, columns=encode_columns, drop_first=True)\nX_encoded = sm.add_constant(X_encoded)\n\n#As earlier, use only the significant features\nX_encoded = X_encoded[significant_features]\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=0)\n\nlogit_resampled = sm.Logit(y_train, X_train).fit()\n\nlogit_resampled.summary2()\n\ny_pred_logit_res = logit_resampled.predict(X_test)\ny_pred_logit_res_binary = y_pred_logit_res.map(lambda x: 1 if x > 0.5 else 0)\n\n#Check the classification metrics of the logit model with oversampling\nfrom sklearn import metrics\nprint(metrics.accuracy_score(y_test, y_pred_logit_res_binary))\n#=> Accuracy of 74%\n\nprint(metrics.classification_report(y_test, y_pred_logit_res_binary))\n\n#=> F1score of 74% and 73 % => Major improvement!!","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Next, let's find the optimal prob. threshold for the new logit model\nfpr,tpr,thresholds = metrics.roc_curve(y_test, y_pred_logit_res, \n                                       drop_intermediate=False)\n\nnew_logit_df = pd.DataFrame({'fpr':fpr, 'tpr':tpr, 'thresholds':thresholds})\nnew_logit_df['diff'] = new_logit_df.tpr-new_logit_df.fpr\nnew_logit_df.sort_values(by='diff', ascending=False)\n\n#Threshold of 0.513 is optimal (gives max tpr-fpr)\ny_pred_logit_res_new = y_pred_logit_res.map(lambda x: 1 if x > 0.513 else 0)\n\nprint(metrics.accuracy_score(y_test, y_pred_logit_res_new))\n# => accuracy of 74.1%\nprint(metrics.classification_report(y_test, y_pred_logit_res_new))\n#Gives F1-score of 0.74\n#Marginally better F1-score, so we stick with the last model\nprint(metrics.accuracy_score(y_test, y_pred_logit_res_new))\n#Gives accuracy of 75.5%\n#Compare with earlier model with default 0.5 threshold\n#print(metrics.classification_report(y_test, y_pred_logit_res_binary))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}