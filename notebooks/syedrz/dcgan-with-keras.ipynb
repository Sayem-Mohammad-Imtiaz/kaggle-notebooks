{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Deep Convolutional Generative Adversarial Network\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport time\nimport imageio\nfrom keras.optimizers import Adam\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Reshape\nfrom keras.layers import Flatten\nfrom keras.layers import Conv2D\nfrom keras.layers import Conv2DTranspose\nfrom keras.layers import LeakyReLU\nfrom keras.layers import Dropout\nfrom keras.preprocessing.image import array_to_img, img_to_array, load_img\nfrom numpy.random import randn\nfrom numpy.random import randint\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# PARAMETERS "},{"metadata":{"trusted":true},"cell_type":"code","source":"n_images = 12000\nbatch_size = 128\nlatent_dim = 100\nn_epoch = 100\nimg_shape = (128, 128, 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dir = '../input/celeba-dataset/img_align_celeba/img_align_celeba/' \nimages = os.listdir(data_dir)\nimages = images[:n_images]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# PLOT IMAGES"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nfor i, name in enumerate(images[:16]):\n    plt.subplot(4, 4, i + 1)\n    img = plt.imread(data_dir + '/' + name)\n    plt.imshow(img)\n    plt.title(name)\n    plt.axis('off')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# GET DATA "},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_data(data_path) :\n    X = []\n    for filename in data_path :\n        img = img_to_array(load_img(data_dir + \"/\" + filename, target_size = img_shape[:2]))\n        X.append(img)\n    X = np.array(X).astype('float32')\n    #X = (X - 127.5) / 127.5\n    X = X / 255\n    return X\n\ndataset = get_data(images)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DISCRIMINATOR "},{"metadata":{"trusted":true},"cell_type":"code","source":"def define_discriminator(in_shape=(128,128,3)):\n    model = Sequential()\n    # normal\n    model.add(Conv2D(128, (5,5), padding='same', input_shape=in_shape))\n    model.add(LeakyReLU(alpha=0.2))\n    # downsample to 64x64\n    model.add(Conv2D(128, (5,5), strides=(2,2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    # downsample to 32x32\n    model.add(Conv2D(128, (5,5), strides=(2,2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    # downsample to 16x16\n    model.add(Conv2D(128, (5,5), strides=(2,2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    # downsample to 8x8\n    model.add(Conv2D(128, (5,5), strides=(2,2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    # classifier\n    model.add(Flatten())\n    model.add(Dropout(0.4))\n    model.add(Dense(1, activation='sigmoid'))\n    # compile model\n    opt = Adam(lr=0.0002, beta_1=0.5)\n    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# GENERATOR "},{"metadata":{"trusted":true},"cell_type":"code","source":"def define_generator(latent_dim):\n    model = Sequential()\n    # foundation for 8x8 feature maps\n    n_nodes = 128 * 8 * 8\n    model.add(Dense(n_nodes, input_dim=latent_dim))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Reshape((8, 8, 128)))\n    # upsample to 16x16\n    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    # upsample to 32x32\n    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    # upsample to 64x64\n    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    # upsample to 128x128\n    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    # output layer 128x128x3\n    model.add(Conv2D(3, (5,5), activation='tanh', padding='same'))\n    return model\n\n#input of G\ndef generate_latent_points(latent_dim, n_samples):\n    # generate points in the latent space\n    x_input = randn(latent_dim * n_samples)\n    # reshape into a batch of inputs for the network\n    x_input = x_input.reshape(n_samples, latent_dim)\n    return x_input\n\n# use the generator to generate n fake examples, with class labels\ndef generate_fake_samples(g_model, latent_dim, n_samples):\n    # generate points in latent space\n    x_input = generate_latent_points(latent_dim, n_samples)\n    # predict outputs\n    X = g_model.predict(x_input)\n    # create 'fake' class labels (0)\n    y = np.zeros((n_samples, 1))\n    return X, y","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# GAN "},{"metadata":{"_uuid":"3f4bc384-6758-41ed-b2ed-2259d5d3d5d5","_cell_guid":"22de1e24-b13f-4e9b-a9c0-bc0fe7166383","trusted":true},"cell_type":"code","source":"def define_gan(g_model, d_model):\n    # make weights in the discriminator not trainable\n    d_model.trainable = False\n    # connect them\n    model = Sequential()\n    # add generator\n    model.add(g_model)\n    # add the discriminator\n    model.add(d_model)\n    # compile model\n    opt = Adam(lr=0.0002, beta_1=0.5)\n    model.compile(loss='binary_crossentropy', optimizer=opt)\n    return model\n\n# retrive real samples\ndef get_real_samples(dataset, n_samples):\n    # choose random instances\n    ix = randint(0, dataset.shape[0], n_samples)\n    # retrieve selected images\n    X = dataset[ix]\n    # set 'real' class labels (1)\n    y = np.ones((n_samples, 1))\n    return X, y\n\n# create and save a plot of generated images\ndef show_generated(generated,epoch, n=5):\n    #[-1,1] -> [0,1] \n    #generated = (generated + 1)/ 2\n    #generated = (generated[:n*n] * 127.5) + 127.5\n    #generated = generated * 255\n    plt.figure(figsize=(10,10))\n    for i in range(n * n):\n        plt.subplot(n, n, i + 1)\n        #img = plt.imread(data_dir + '/' + name)\n        plt.imshow(generated[i])\n        #plt.title(name)\n        plt.axis('off')\n    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch+1))\n    plt.show()    \n\n# evaluate the discriminator and plot generated images\ndef summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples=100):\n    # prepare real samples\n    X_real, y_real = get_real_samples(dataset, n_samples)\n    # evaluate discriminator on real examples\n    _, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n    # prepare fake examples\n    x_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n    # evaluate discriminator on fake examples\n    _, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n    # summarize discriminator performance\n    print('>Accuracy [real: %.0f%%, fake: %.0f%%]' % (acc_real*100, acc_fake*100))\n    # show plot\n    show_generated(x_fake, epoch)    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# TRAIN "},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(g_model, d_model, gan_model, dataset, latent_dim=100, n_epochs=100, n_batch=128):\n    bat_per_epo = int(dataset.shape[0] / n_batch)\n    half_batch = int(n_batch / 2)\n    # manually enumerate epochs\n    start = time.time()\n    for i in range(n_epochs):\n        \n        # enumerate batches over the training set\n        for j in range(bat_per_epo):\n            # get randomly selected 'real' samples\n            X_real, y_real = get_real_samples(dataset, half_batch)\n            # update discriminator model weights\n            d_loss1, _ = d_model.train_on_batch(X_real, y_real)\n            # generate 'fake' examples\n            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n            # update discriminator model weights\n            d_loss2, _ = d_model.train_on_batch(X_fake, y_fake)\n            # prepare points in latent space as input for the generator\n            X_gan = generate_latent_points(latent_dim, n_batch)\n            # create inverted labels for the fake samples\n            y_gan = np.ones((n_batch, 1))\n            # update the generator via the discriminator's error\n            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n            # summarize loss on this batch\n        print('Epoch: %d,  Loss: D_real = %.3f, D_fake = %.3f,  G = %.3f' %   (i+1, d_loss1, d_loss2, g_loss))\n        # evaluate the model performance\n        if (i+1) % 10 == 0:\n            summarize_performance(i, g_model, d_model, dataset, latent_dim)     \n    print ('Total time for training {} epochs is {} sec'.format(n_epochs, (time.time()-start)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discriminator = define_discriminator()\ngenerator = define_generator(latent_dim)\n\n# create the gan\ngan = define_gan(generator, discriminator)\n\n# train model\ntrain(generator, discriminator, gan, dataset, latent_dim, n_epoch, batch_size)\n\n## TODO: Get better output images!","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CREATE GIF"},{"metadata":{"trusted":true},"cell_type":"code","source":"files = []\nn_iter = int(n_epoch / 10 -1)\nfor e in range(n_iter):\n    img_name = '../working/image_at_epoch_{:04d}.png'.format((e+1)*10)\n    files.append(imageio.imread(img_name))\nimageio.mimsave('dcgan_celebA_generation_animation.gif', files, fps=5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## You can see the GIF at the end of the kernel! "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}