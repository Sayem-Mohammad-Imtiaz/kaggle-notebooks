{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Predicting Whether an Instagram Account is Fake or Genuine\n\nAuthor: *Khoi Ngo*"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Overview of Steps to Accomplish Notebook"},{"metadata":{},"cell_type":"markdown","source":"## 0. Function Definitions"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.datasets import load_files\n\ndef load_train_data():\n    ''' Load data from csv files, Train data \n        Splits data into X (feature matrix) and y (labels)\n        \n        returns: X_train, y_train\n        \n    '''\n    train_data = pd.read_csv('../input/instagram-fake-spammer-genuine-accounts/train.csv', header = 0)\n    \n    X_train = train_data.drop(columns='fake')\n    y_train = train_data['fake']\n    \n    return X_train, y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.datasets import load_files\n\ndef load_test_data():\n    ''' Load data from csv files, Train and Test data \n        Splits data into X (feature matrix) and y (labels)\n        \n        returns: X_test, y_test\n        \n    '''\n    test_data = pd.read_csv('../input/instagram-fake-spammer-genuine-accounts/test.csv', header = 0)\n    \n    X_test = test_data.drop(columns='fake')\n    y_test = test_data['fake']\n    \n    return X_test, y_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_validate\n\n\ndef get_classifier_cv_score(model, X, y, scoring='accuracy', cv=7):\n    '''Calculate train and validation score of classifier (model) using cross-validation\n        \n        \n        model (sklearn classifier): Classifier to train and evaluate\n        X (numpy.array or pandas.DataFrame): Feature matrix\n        y (numpy.array or pandas.Series): Target vector\n        scoring (str): a scoring string accepted by sklearn.metrics.cross_validate()\n        cv (int): number of cross-validation folds see sklearn.metrics.cross_validate()\n        \n        returns: mean training score, mean validation score\n    \n    '''\n    scores = cross_validate(model, X, y, cv=cv, scoring=scoring, return_train_score=True)\n    train_scores = scores['train_score']\n    val_scores = scores['test_score']\n    \n    train_mean = np.mean(train_scores)\n    val_mean = np.mean(val_scores)\n    \n    return train_mean, val_mean","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_grid_search_result(grid_search):\n    '''Prints best parameters and mean training and validation scores of a grid search object.\n    \n        grid_search (sklearn GridSearchCV): Fitted GridSearchCV object\n        \n        scores are printed with 3 decimal places.\n        \n    '''\n    \n     #TODO: implement function body\n    \n    print(grid_search.best_params_)\n    \n    best_train = grid_search.cv_results_[\"mean_train_score\"][grid_search.best_index_]\n    print(\"best mean_train_score: {:.3f}\".format(best_train))\n        \n    best_test = grid_search.cv_results_[\"mean_test_score\"][grid_search.best_index_]\n    print(\"best mean_test_score: {:.3f}\".format(best_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\ndef plot_confusion_matrix(y_actual, y_pred, labels, title=''):\n    '''Creates a heatmap plot of the confusion matrix.\n    \n        y_actual (pandas.DataSeries or numpy.Array): Ground truth label vector\n        y_pred (pandas.DataSeries or numpy.Array): Predicted label vector\n        labels (list(str)): Class names used for plotting (ticklabels)\n        title (str): Plot title\n        \n        uses sklearn.metrics.confusion_matrix\n        \n    '''\n    data = confusion_matrix(y_actual, y_pred)\n    ax = sns.heatmap(data,\n                     annot=True,\n                     cbar=False,\n                     fmt='d',\n                     xticklabels = labels,\n                     yticklabels = labels)\n    ax.set_title(title)\n    ax.set_xlabel(\"predicted values\")\n    ax.set_ylabel(\"actual values\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. Load Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_data, y_data = load_train_data()\nprint(X_data.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Size: \",X_data.shape, \", Type: \", type(X_data))\nprint(\"Size: \",y_data.shape, \", Type: \", type(y_data))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Inspect Data"},{"metadata":{},"cell_type":"markdown","source":"### 2.1 Seeing Any Correlation in Features\n- We can see that there is no correlation among the features\n- They are roughly around 0 in each feature comparison."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_corr = X_data.corr(method='pearson')\nax = sns.heatmap(data_corr, vmin=-1, vmax=1, cmap='BrBG')\nax.set_title(\"Correlation Heatmap Between Features\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.2 Missing any Values\n- We can see that the features are all filled out and we do not need to modify the existing data"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_data.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.3 Checking if Imbalance in Labels\n- The labels is about 1:1 which means there is no imbalance in the labels. \n- If there was, the ratio would be more 2:1."},{"metadata":{"trusted":true},"cell_type":"code","source":"unique, freq = np.unique(y_data, return_counts = True) \n\nfor i, j in zip(unique, freq):\n    print(\"Label: \", i, \", Frequency: \", j)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Create training and test sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=37)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Compare Models Using Cross-Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\n\nmodel_list = [LogisticRegression(max_iter=600),\n              SVC(), \n              GaussianNB(),\n              RandomForestClassifier(random_state=55),\n              GradientBoostingClassifier(random_state=56)]\n\ntrain_scores = []\nval_scores = []\n\nfor model in model_list:\n    train, val = get_classifier_cv_score(model, X_train, y_train,'average_precision')\n    train_scores.append(train)\n    val_scores.append(val)\n    \nmodels_score = sorted(list(zip(val_scores, train_scores, model_list)), reverse=True)\n\nprint(\"-------------------------------------\")\nfor val, train, model in models_score:\n    print(\"Model: {} \".format(model.__class__.__name__))\n\n    print(\"train_score: {:.3f}\".format(train)) \n\n    print(\"validation_score: {:.3f}\".format(val)) \n\n    print(\"-------------------------------------\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- We will select the two best models to continue.\n- These models are Random Forest Classifier and Gradient Boosting Classifier."},{"metadata":{},"cell_type":"markdown","source":"## 5. Hyperparameter Tuning Using Grid Search"},{"metadata":{},"cell_type":"markdown","source":"### 5.1 Grid Search for RandomForestClassifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nimport os\n#if run on own computer\n#num_cpu = int(os.environ['NUMBER_OF_PROCESSORS'])\n\nmodel = RandomForestClassifier(random_state=55)\n\nparameters = {'n_estimators': [300, 500, 700, 1000],\n              'max_depth': [7, 9, 11, 13]}\n\n#if run on own computer\n#grid1 = GridSearchCV(model, parameters, cv=7, scoring='average_precision', n_jobs=num_cpu, return_train_score=True)\ngrid1 = GridSearchCV(model, parameters, cv=7, scoring='average_precision',return_train_score=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid1.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print_grid_search_result(grid1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5.2 Grid Search for Gradient Boosting Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = GradientBoostingClassifier(max_depth=5, random_state=56)\n\nparameters = {'n_estimators': [50, 100, 200],\n              'learning_rate': [0.001, 0.01, 0.1, 1.0, 10.0]}\n\n#if run on own computer\n#grid2 = GridSearchCV(model, parameters, cv=7, scoring='average_precision', n_jobs=num_cpu, return_train_score=True)\ngrid2 = GridSearchCV(model, parameters, cv=7, scoring='average_precision', return_train_score=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid2.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print_grid_search_result(grid2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6. Pipeline"},{"metadata":{},"cell_type":"markdown","source":"- Now we will use the best model from our grid search, which is Random Forest Classifier\n- We will apply a pipeline since we need to standardize our data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\npipeline = Pipeline([('preprocessing', StandardScaler()), ('classifier', grid1.best_estimator_)])\npipeline.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Test score: {:.3f}\".format(pipeline.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 7. Final Evaluation"},{"metadata":{},"cell_type":"markdown","source":"- Finally we have a working model to do a final evaluation on a reserve data"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_final, y_final = load_test_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Test score: {:.3f}\".format(pipeline.score(X_final, y_final)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\ny_pred = pipeline.predict(X_final)\nprint(classification_report(y_final, y_pred, target_names=[\"genuine\", \"fake\"]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = [\"genuine\", \"fake\"]\ntitle = \"Predicting Fake Instagram Account\"\nplot_confusion_matrix(y_final, y_pred, labels, title)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- We can see our model predicted around 91.5% fake accounts and 90.2% genuine accounts correctly\n- The model only predicted 11 accounts wrong"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}