{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport plotly.graph_objects as go\nimport plotly.express as px\n\nfrom sklearn import preprocessing\n\n\nimport seaborn as sns  # plotting & visualization lib\nimport matplotlib.pyplot as plt  #plot & visualization lib\n%config InlineBackend.figure_format = 'svg'\nimport os\nimport warnings # to ignore warnings\nwarnings.simplefilter('ignore')\nfrom mpl_toolkits.basemap import Basemap #this library is used to create maps\nprint(os.listdir(\"../input\"))\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-18T17:20:21.268502Z","iopub.execute_input":"2021-07-18T17:20:21.268872Z","iopub.status.idle":"2021-07-18T17:20:24.891806Z","shell.execute_reply.started":"2021-07-18T17:20:21.268792Z","shell.execute_reply":"2021-07-18T17:20:24.890927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#reading csv file \ndf = pd.read_csv('/kaggle/input/craigslist-carstrucks-data/vehicles.csv')\ndf","metadata":{"execution":{"iopub.status.busy":"2021-07-18T17:20:24.893217Z","iopub.execute_input":"2021-07-18T17:20:24.893588Z","iopub.status.idle":"2021-07-18T17:20:58.462647Z","shell.execute_reply.started":"2021-07-18T17:20:24.89355Z","shell.execute_reply":"2021-07-18T17:20:58.461713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-18T17:21:03.304363Z","iopub.execute_input":"2021-07-18T17:21:03.304723Z","iopub.status.idle":"2021-07-18T17:21:03.41564Z","shell.execute_reply.started":"2021-07-18T17:21:03.30468Z","shell.execute_reply":"2021-07-18T17:21:03.414697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking total no. of null values in each col\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-18T17:21:03.502627Z","iopub.execute_input":"2021-07-18T17:21:03.502888Z","iopub.status.idle":"2021-07-18T17:21:04.2091Z","shell.execute_reply.started":"2021-07-18T17:21:03.502863Z","shell.execute_reply":"2021-07-18T17:21:04.207224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#here we'll find the percentage of null values in the dataset\nnull_values=df.isnull().sum()\nnull_values=pd.DataFrame(null_values,columns=['null'])\nj=1\nsum_tot=len(df)\nnull_values['percent']=null_values['null']/sum_tot\nround(null_values*100,3).sort_values('percent',ascending=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T17:21:04.210947Z","iopub.execute_input":"2021-07-18T17:21:04.211411Z","iopub.status.idle":"2021-07-18T17:21:04.934014Z","shell.execute_reply.started":"2021-07-18T17:21:04.211361Z","shell.execute_reply":"2021-07-18T17:21:04.933224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#removing county columns as it is not useful and has almost 100 percent null values\ndel df['county']","metadata":{"execution":{"iopub.status.busy":"2021-07-18T17:21:04.935796Z","iopub.execute_input":"2021-07-18T17:21:04.936148Z","iopub.status.idle":"2021-07-18T17:21:04.943415Z","shell.execute_reply.started":"2021-07-18T17:21:04.936111Z","shell.execute_reply":"2021-07-18T17:21:04.942452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## I tried removing all the null values but in the end we'll end up deleting almost all the data so we need to impute/put some new values for the missing or null values in the dataset","metadata":{"execution":{"iopub.status.busy":"2021-07-18T05:13:31.034535Z","iopub.execute_input":"2021-07-18T05:13:31.03496Z","iopub.status.idle":"2021-07-18T05:13:31.854942Z","shell.execute_reply.started":"2021-07-18T05:13:31.034924Z","shell.execute_reply":"2021-07-18T05:13:31.853762Z"}}},{"cell_type":"code","source":"#here we'll find the total null values in the dataset\nnull_values=df.isnull().sum()\nnull_values=pd.DataFrame(null_values,columns=['null'])\nj=1\nsum_tot=len(df)\nnull_values['percent']=null_values['null']/sum_tot\nround(null_values*100,3).sort_values('percent',ascending=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T17:21:04.945578Z","iopub.execute_input":"2021-07-18T17:21:04.946053Z","iopub.status.idle":"2021-07-18T17:21:05.651276Z","shell.execute_reply.started":"2021-07-18T17:21:04.946017Z","shell.execute_reply":"2021-07-18T17:21:05.650445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#removing some columns that are not useful for anaylsis\ndf= df.drop(columns=['url','image_url','region_url', 'description','VIN'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T17:21:05.652639Z","iopub.execute_input":"2021-07-18T17:21:05.653006Z","iopub.status.idle":"2021-07-18T17:21:05.715945Z","shell.execute_reply.started":"2021-07-18T17:21:05.652967Z","shell.execute_reply":"2021-07-18T17:21:05.715007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Comparing paint_color,price on the map\n\nfigure = px.scatter_mapbox(df[df[\"type\"]==\"bus\"],lon=\"long\", lat=\"lat\",  hover_name=\"paint_color\", hover_data=[\"paint_color\", \"price\"],\n                        zoom=4, height=550)\nfigure.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n\nfigure.update_layout(mapbox_style=\"open-street-map\")\n\nfigure.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-18T17:21:05.717398Z","iopub.execute_input":"2021-07-18T17:21:05.717963Z","iopub.status.idle":"2021-07-18T17:21:06.690288Z","shell.execute_reply.started":"2021-07-18T17:21:05.71792Z","shell.execute_reply":"2021-07-18T17:21:06.689465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Analysing Price columns\n\nprint('The average value for price columns is', df.price.mean())\n\nprint('Top 10 most used prices number are')\nprint(df.price.value_counts().iloc[0:10])\nprint(\"Null values inside the price columns are\",df.price.isnull().sum())\n","metadata":{"execution":{"iopub.status.busy":"2021-07-18T17:21:06.691697Z","iopub.execute_input":"2021-07-18T17:21:06.692095Z","iopub.status.idle":"2021-07-18T17:21:06.708923Z","shell.execute_reply.started":"2021-07-18T17:21:06.692055Z","shell.execute_reply":"2021-07-18T17:21:06.708206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### I found that prices car were sold is mostly 0 which is not possible as they must be sold at some prices.we'll remove all the rows with 0 price points ","metadata":{"execution":{"iopub.status.busy":"2021-07-18T05:38:03.165781Z","iopub.execute_input":"2021-07-18T05:38:03.166403Z","iopub.status.idle":"2021-07-18T05:38:03.174291Z","shell.execute_reply.started":"2021-07-18T05:38:03.166358Z","shell.execute_reply":"2021-07-18T05:38:03.173071Z"}}},{"cell_type":"code","source":"sns.boxplot(data = df.price)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T17:21:10.227951Z","iopub.execute_input":"2021-07-18T17:21:10.228397Z","iopub.status.idle":"2021-07-18T17:21:10.842522Z","shell.execute_reply.started":"2021-07-18T17:21:10.228351Z","shell.execute_reply":"2021-07-18T17:21:10.841633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#removing vague/dirty values in price some values are above limit\nindex_value_useless_price= df.price.sort_values(ascending=False).iloc[0:65].index\nprint(index_value_useless_price)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T17:21:10.8438Z","iopub.execute_input":"2021-07-18T17:21:10.844102Z","iopub.status.idle":"2021-07-18T17:21:10.911332Z","shell.execute_reply.started":"2021-07-18T17:21:10.844073Z","shell.execute_reply":"2021-07-18T17:21:10.910362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2 = df.drop(df.index[[318592, 356716, 257840,  91576,  37410, 184704, 153082,  29386,\n             37409, 122470,    280, 230753, 193736, 288356, 307488, 358555,\n            137807, 207080, 241404,   1838, 379133, 136516, 303644, 286323,\n            286324, 303014, 288401, 288400, 353641, 300308, 105843, 283906,\n            327938,  68935, 286156, 377425, 384898, 377396, 367308, 155421,\n            362822, 384872, 367357, 377515, 362837, 194292, 362867, 367296,\n            356959, 283429,  26075, 213918, 219241, 233823,  91605, 232829,\n            233201,  91807,  83367,  87052, 416145,  95119, 307671, 307513,\n             79088]])","metadata":{"execution":{"iopub.status.busy":"2021-07-18T17:21:10.912953Z","iopub.execute_input":"2021-07-18T17:21:10.913279Z","iopub.status.idle":"2021-07-18T17:21:11.006906Z","shell.execute_reply.started":"2021-07-18T17:21:10.913245Z","shell.execute_reply":"2021-07-18T17:21:11.005883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### various dataset has vague price value such as 1234567, 11111111, and some above 3Billion, this expresses that these are useless values entered just to fill the price. We'll randomly remove first 500 extreme values. and also remove all the zero price value cars rows,\n\n##### These will help to remove outliers from the data","metadata":{"execution":{"iopub.status.busy":"2021-07-18T06:15:32.175467Z","iopub.execute_input":"2021-07-18T06:15:32.17587Z","iopub.status.idle":"2021-07-18T06:15:32.185625Z","shell.execute_reply.started":"2021-07-18T06:15:32.17583Z","shell.execute_reply":"2021-07-18T06:15:32.184446Z"}}},{"cell_type":"code","source":"#resetting the index\ndf2.reset_index()\ndf2","metadata":{"execution":{"iopub.status.busy":"2021-07-18T17:21:11.008451Z","iopub.execute_input":"2021-07-18T17:21:11.008803Z","iopub.status.idle":"2021-07-18T17:21:11.133321Z","shell.execute_reply.started":"2021-07-18T17:21:11.008766Z","shell.execute_reply":"2021-07-18T17:21:11.13235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#removing prices with 0 values\n\ndf2 = df2[df2.price !=0]\n    ","metadata":{"execution":{"iopub.status.busy":"2021-07-18T17:21:11.134957Z","iopub.execute_input":"2021-07-18T17:21:11.135334Z","iopub.status.idle":"2021-07-18T17:21:11.204651Z","shell.execute_reply.started":"2021-07-18T17:21:11.135292Z","shell.execute_reply":"2021-07-18T17:21:11.203804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#We found various values of odometer crossing 1Cr which is not possible. So we'll remvoe that\ndf2.odometer.sort_values(ascending=False).iloc[0:30]","metadata":{"execution":{"iopub.status.busy":"2021-07-18T17:21:11.290487Z","iopub.execute_input":"2021-07-18T17:21:11.290861Z","iopub.status.idle":"2021-07-18T17:21:11.35386Z","shell.execute_reply.started":"2021-07-18T17:21:11.290827Z","shell.execute_reply":"2021-07-18T17:21:11.352874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#various dirty or useless number can be found in odometer reading such as 99999999,2222222,1234567\n# which we can say is not useful to consider. We'll remove rows that has value of odometer above\n# 1000000\n\ndf2 = df2[df2.odometer<1000000]","metadata":{"execution":{"iopub.status.busy":"2021-07-18T17:21:11.461951Z","iopub.execute_input":"2021-07-18T17:21:11.462263Z","iopub.status.idle":"2021-07-18T17:21:11.546173Z","shell.execute_reply.started":"2021-07-18T17:21:11.462232Z","shell.execute_reply":"2021-07-18T17:21:11.545207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Some cars are have manufacturing year below 1965 which is not of any help to consider for our model\n# as value of car decreases in just 15 years\ndf2=df2[df2.year>1985]","metadata":{"execution":{"iopub.status.busy":"2021-07-18T17:21:11.632313Z","iopub.execute_input":"2021-07-18T17:21:11.632643Z","iopub.status.idle":"2021-07-18T17:21:11.709507Z","shell.execute_reply.started":"2021-07-18T17:21:11.632613Z","shell.execute_reply":"2021-07-18T17:21:11.708533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# again checking the null value percentage\n\nnull_values=df2.isnull().sum()\nnull_values=pd.DataFrame(null_values,columns=['null'])\nj=1\nsum_tot=len(df2)\nnull_values['percent']=null_values['null']/sum_tot\nround(null_values*100,3).sort_values('percent',ascending=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T17:21:14.974991Z","iopub.execute_input":"2021-07-18T17:21:14.975394Z","iopub.status.idle":"2021-07-18T17:21:15.419684Z","shell.execute_reply.started":"2021-07-18T17:21:14.975351Z","shell.execute_reply":"2021-07-18T17:21:15.418531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Analyzing the state columns\n\nplt.figure(figsize=(10,6))\nax = sns.countplot(x='state',data=df2,order=df2['state'].value_counts().index);\nax.set_xticklabels(ax.get_xticklabels(), fontsize=8);","metadata":{"execution":{"iopub.status.busy":"2021-07-18T17:21:15.421292Z","iopub.execute_input":"2021-07-18T17:21:15.421649Z","iopub.status.idle":"2021-07-18T17:21:16.470791Z","shell.execute_reply.started":"2021-07-18T17:21:15.421613Z","shell.execute_reply":"2021-07-18T17:21:16.469844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#analyzing state vs sell number\nplt.figure(figsize=(10,6))\nax = sns.countplot(x='year',data=df2);\nax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=\"right\",fontsize=6);","metadata":{"execution":{"iopub.status.busy":"2021-07-18T17:21:16.472532Z","iopub.execute_input":"2021-07-18T17:21:16.472879Z","iopub.status.idle":"2021-07-18T17:21:16.935764Z","shell.execute_reply.started":"2021-07-18T17:21:16.472843Z","shell.execute_reply":"2021-07-18T17:21:16.934553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"execution":{"iopub.status.busy":"2021-07-18T08:57:41.273527Z","iopub.execute_input":"2021-07-18T08:57:41.274061Z","iopub.status.idle":"2021-07-18T08:57:41.337054Z","shell.execute_reply.started":"2021-07-18T08:57:41.274012Z","shell.execute_reply":"2021-07-18T08:57:41.336091Z"}}},{"cell_type":"markdown","source":"### The graph indicates a decrese in listings of 2009 car models. This might be because of recession.\n","metadata":{}},{"cell_type":"code","source":"print (\"Total manufacturers we have are:\")\nprint (df['manufacturer'].unique())","metadata":{"execution":{"iopub.status.busy":"2021-07-18T17:21:16.937674Z","iopub.execute_input":"2021-07-18T17:21:16.938112Z","iopub.status.idle":"2021-07-18T17:21:16.988101Z","shell.execute_reply.started":"2021-07-18T17:21:16.938068Z","shell.execute_reply":"2021-07-18T17:21:16.986875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LEts see contribution of each manufacturer in producing the total cars\n\nplt.figure(figsize=(10,6))\nax = sns.countplot(x='manufacturer',data=df);\nax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=\"right\",fontsize=8);","metadata":{"execution":{"iopub.status.busy":"2021-07-18T17:21:16.989814Z","iopub.execute_input":"2021-07-18T17:21:16.990433Z","iopub.status.idle":"2021-07-18T17:21:18.105041Z","shell.execute_reply.started":"2021-07-18T17:21:16.990389Z","shell.execute_reply":"2021-07-18T17:21:18.104146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Ford has most no. of cars on the street followed by chevrolet and toyota.","metadata":{"execution":{"iopub.status.busy":"2021-07-18T09:12:36.852165Z","iopub.execute_input":"2021-07-18T09:12:36.852573Z","iopub.status.idle":"2021-07-18T09:12:36.857354Z","shell.execute_reply.started":"2021-07-18T09:12:36.852539Z","shell.execute_reply":"2021-07-18T09:12:36.855682Z"}}},{"cell_type":"code","source":"df2.fuel.unique()","metadata":{"execution":{"iopub.status.busy":"2021-07-18T17:21:18.106618Z","iopub.execute_input":"2021-07-18T17:21:18.107175Z","iopub.status.idle":"2021-07-18T17:21:18.171208Z","shell.execute_reply.started":"2021-07-18T17:21:18.107134Z","shell.execute_reply":"2021-07-18T17:21:18.170357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#CHecking which color is sold mostly in which type of cars.\n\ngasLabels = df2[df2[\"fuel\"]==\"gas\"].paint_color.value_counts().head(10).index\ngasValues = df[df[\"fuel\"]==\"gas\"].paint_color.value_counts().head(10).values\nhybridLabels = df[df[\"fuel\"]==\"hybrid\"].paint_color.value_counts().head(10).index\nhybridValues = df[df[\"fuel\"]==\"hybrid\"].paint_color.value_counts().head(10).values\ndieselLabels = df[df[\"fuel\"]==\"diesel\"].paint_color.value_counts().head(10).index\ndieselValues = df[df[\"fuel\"]==\"diesel\"].paint_color.value_counts().head(10).values\nelectricLabels = df[df[\"fuel\"]==\"electric\"].paint_color.value_counts().head(10).index\nelectricValues = df[df[\"fuel\"]==\"electric\"].paint_color.value_counts().head(10).values\n\n\nfrom plotly.subplots import make_subplots\n\n# Creating subplots for different domain\nfig = make_subplots(rows=1, cols=5, specs=[[{'type':'domain'}, {'type':'domain'}, {'type':'domain'}, {'type':'domain'}, {'type':'domain'}]])\nfig.add_trace(go.Pie(labels=gasLabels, values=gasValues, name=\"Gas Car\"),\n              1, 1)\nfig.add_trace(go.Pie(labels=dieselLabels, values=dieselValues, name=\"Diesel Car\"),\n              1, 2)\nfig.add_trace(go.Pie(labels=electricLabels, values=electricValues, name=\"Electric Car\"),\n              1, 3)\nfig.add_trace(go.Pie(labels=hybridLabels, values=hybridValues, name=\"hybrid Car\"),\n              1, 4)\nfig.update_traces(hole=.3, hoverinfo=\"label+percent+name\") #hole to create donut\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-18T17:21:18.175953Z","iopub.execute_input":"2021-07-18T17:21:18.178189Z","iopub.status.idle":"2021-07-18T17:21:19.038245Z","shell.execute_reply.started":"2021-07-18T17:21:18.178146Z","shell.execute_reply":"2021-07-18T17:21:19.037347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### We can see white is most preferred color as it is majority in all types of car. Second is black and silver which denotes customers must be either buying more white and black cars or it has some technical effect of producing car with such colors","metadata":{}},{"cell_type":"code","source":"#LEts deal with missing values\n\n\nprint('the missing values in condition columns is ', df2.condition.isnull().sum())\n\n#Assume car with year before 2019 is as new condition which we are adding\n# and car below 2017 as like new\n\ndf2.loc[df2.year>=2019, 'condition'] = df2.loc[df2.year>=2019, 'condition'].fillna('new')\ndf2.loc[df2.year<=2017, 'condition'] = df2.loc[df2.year<=2017, 'condition'].fillna('like new')","metadata":{"execution":{"iopub.status.busy":"2021-07-18T17:21:26.38853Z","iopub.execute_input":"2021-07-18T17:21:26.388866Z","iopub.status.idle":"2021-07-18T17:21:26.47484Z","shell.execute_reply.started":"2021-07-18T17:21:26.388835Z","shell.execute_reply":"2021-07-18T17:21:26.473923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculate correlation matrix\ncorr = df2.corr()# plot the heatmap\nsns.heatmap(corr, xticklabels=corr.columns, \n            yticklabels=corr.columns, annot=True)\n\n\n#no correlation exist between any columns","metadata":{"execution":{"iopub.status.busy":"2021-07-18T17:21:26.644135Z","iopub.execute_input":"2021-07-18T17:21:26.644406Z","iopub.status.idle":"2021-07-18T17:21:27.053421Z","shell.execute_reply.started":"2021-07-18T17:21:26.644379Z","shell.execute_reply":"2021-07-18T17:21:27.05252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2.condition.value_counts() # we've managed to remove null values","metadata":{"execution":{"iopub.status.busy":"2021-07-18T17:21:27.054987Z","iopub.execute_input":"2021-07-18T17:21:27.05534Z","iopub.status.idle":"2021-07-18T17:21:27.140242Z","shell.execute_reply.started":"2021-07-18T17:21:27.055304Z","shell.execute_reply":"2021-07-18T17:21:27.139243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#removing some more columns which has lot of unique values which will only confuse the model if \n# we used it\n#removing columns with null values above 40 percent\n\ndf4 = df2.drop(axis = 1, columns=['size', 'long', 'lat', 'model', 'region','posting_date','state'])\ndf4.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-18T17:21:27.142128Z","iopub.execute_input":"2021-07-18T17:21:27.142577Z","iopub.status.idle":"2021-07-18T17:21:27.448537Z","shell.execute_reply.started":"2021-07-18T17:21:27.142539Z","shell.execute_reply":"2021-07-18T17:21:27.447648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# As the data is stored wrt time we'll fill the data with forward fill method\n\ndf4['transmission'] = df4['transmission'].fillna(method='ffill')\ndf4['cylinders'] = df4['cylinders'].fillna(method='ffill')\ndf4['title_status'] = df4['title_status'].fillna(method='ffill')\ndf4['fuel'] = df4['fuel'].fillna(method='ffill')\ndf4['paint_color'] = df4['paint_color'].fillna(method='ffill')\ndf4['drive'] = df4['drive'].fillna(method='ffill')\ndf4['manufacturer'] = df4['manufacturer'].fillna(method='ffill')\ndf4['type'] = df4['type'].fillna(method='ffill')","metadata":{"execution":{"iopub.status.busy":"2021-07-18T17:21:27.449938Z","iopub.execute_input":"2021-07-18T17:21:27.450476Z","iopub.status.idle":"2021-07-18T17:21:27.729649Z","shell.execute_reply.started":"2021-07-18T17:21:27.450421Z","shell.execute_reply":"2021-07-18T17:21:27.728792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"## LABEL PROCESSING","metadata":{"execution":{"iopub.status.busy":"2021-07-18T12:11:52.623369Z","iopub.execute_input":"2021-07-18T12:11:52.623723Z","iopub.status.idle":"2021-07-18T12:11:52.62999Z","shell.execute_reply.started":"2021-07-18T12:11:52.623695Z","shell.execute_reply":"2021-07-18T12:11:52.629065Z"}}},{"cell_type":"code","source":"df4 = df4.drop(columns = ['id'], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T17:21:27.73129Z","iopub.execute_input":"2021-07-18T17:21:27.731636Z","iopub.status.idle":"2021-07-18T17:21:27.770201Z","shell.execute_reply.started":"2021-07-18T17:21:27.7316Z","shell.execute_reply":"2021-07-18T17:21:27.769064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Label encoding each string columns\nle = preprocessing.LabelEncoder()\ndf4['manufacturer'] = le.fit_transform(df4.manufacturer.astype(str))\ndf4['condition'] = le.fit_transform(df4.condition.astype(str))\ndf4['cylinders'] = le.fit_transform(df4.cylinders.astype(str))\ndf4['fuel'] = le.fit_transform(df4.fuel.astype(str))\ndf4['title_status'] = le.fit_transform(df4.title_status.astype(str))\ndf4['transmission'] = le.fit_transform(df4.transmission.astype(str))\ndf4['drive'] = le.fit_transform(df4.drive.astype(str))\ndf4['type'] = le.fit_transform(df4.type.astype(str))\ndf4['paint_color'] = le.fit_transform(df4.paint_color.astype(str))\n","metadata":{"execution":{"iopub.status.busy":"2021-07-18T17:21:27.772096Z","iopub.execute_input":"2021-07-18T17:21:27.772515Z","iopub.status.idle":"2021-07-18T17:21:28.992065Z","shell.execute_reply.started":"2021-07-18T17:21:27.77246Z","shell.execute_reply":"2021-07-18T17:21:28.990687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#splitting datasets\n\nfrom sklearn.model_selection import train_test_split\nfrom matplotlib import pyplot as plt\n\ny= df4.price\nX= df4.drop('price',axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nprint (X_train.shape, y_train.shape)\nprint (X_test.shape, y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T17:21:28.997302Z","iopub.execute_input":"2021-07-18T17:21:28.999522Z","iopub.status.idle":"2021-07-18T17:21:29.136157Z","shell.execute_reply.started":"2021-07-18T17:21:28.999481Z","shell.execute_reply":"2021-07-18T17:21:29.135248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-18T17:21:29.359949Z","iopub.execute_input":"2021-07-18T17:21:29.360273Z","iopub.status.idle":"2021-07-18T17:21:29.380935Z","shell.execute_reply.started":"2021-07-18T17:21:29.360241Z","shell.execute_reply":"2021-07-18T17:21:29.380191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Feature Scaling\n\nfrom sklearn.preprocessing import MinMaxScaler\nsc = MinMaxScaler()   \nX_train= sc.fit_transform(X_train)\nX_test= sc.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T17:21:33.711641Z","iopub.execute_input":"2021-07-18T17:21:33.712006Z","iopub.status.idle":"2021-07-18T17:21:33.764019Z","shell.execute_reply.started":"2021-07-18T17:21:33.711973Z","shell.execute_reply":"2021-07-18T17:21:33.763034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Write this line of code (if your dataframe name is df):\ndf4.to_csv('X_train_ML.csv',index=False)\n# Hit commit and run at the right hand corner of the kernel.\n# Wait till the kernel runs from top to bottom.\n# Checkout the 'Output' Tab from the Version tab. Or go to the snapshot of your kernel and checkout the 'Output' tab. Your csv file will be there","metadata":{"execution":{"iopub.status.busy":"2021-07-18T17:26:05.375819Z","iopub.execute_input":"2021-07-18T17:26:05.376171Z","iopub.status.idle":"2021-07-18T17:26:07.196132Z","shell.execute_reply.started":"2021-07-18T17:26:05.37614Z","shell.execute_reply":"2021-07-18T17:26:07.195147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.getcwd()","metadata":{"execution":{"iopub.status.busy":"2021-07-18T17:23:05.523653Z","iopub.execute_input":"2021-07-18T17:23:05.524004Z","iopub.status.idle":"2021-07-18T17:23:05.529113Z","shell.execute_reply.started":"2021-07-18T17:23:05.523973Z","shell.execute_reply":"2021-07-18T17:23:05.528284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#As random forest works best for such kind of data We'll go with random forest\n\n\nfrom sklearn.ensemble import RandomForestRegressor\n\nregressor = RandomForestRegressor(n_estimators=20, random_state=0)\nregressor.fit(X_train, y_train)\ny_pred = regressor.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T16:48:39.597468Z","iopub.execute_input":"2021-07-18T16:48:39.59783Z","iopub.status.idle":"2021-07-18T16:49:03.77849Z","shell.execute_reply.started":"2021-07-18T16:48:39.597786Z","shell.execute_reply":"2021-07-18T16:49:03.777393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import metrics\nfrom sklearn.metrics import mean_squared_error as MSE\n\nprint('Mean Absolute Error:', round(metrics.mean_absolute_error(y_test, y_pred),2))\nprint('Mean Squared Error:', round(metrics.mean_squared_error(y_test, y_pred),2))\nprint('Root Mean Squared Error:', round(np.sqrt(metrics.mean_squared_error(y_test, y_pred)),2))","metadata":{"execution":{"iopub.status.busy":"2021-07-18T16:49:03.77989Z","iopub.execute_input":"2021-07-18T16:49:03.780257Z","iopub.status.idle":"2021-07-18T16:49:03.791719Z","shell.execute_reply.started":"2021-07-18T16:49:03.780216Z","shell.execute_reply":"2021-07-18T16:49:03.790668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#lets try with 100 n_estimators first\nregressor = RandomForestRegressor(n_estimators=100, random_state=0)\nregressor.fit(X_train, y_train)\ny_pred = regressor.predict(X_test)\nprint('Mean Absolute Error:', round(metrics.mean_absolute_error(y_test, y_pred),2))\nprint('Mean Squared Error:', round(metrics.mean_squared_error(y_test, y_pred),2))\nprint('Root Mean Squared Error:', round(np.sqrt(metrics.mean_squared_error(y_test, y_pred)),2))","metadata":{"execution":{"iopub.status.busy":"2021-07-18T16:49:03.79367Z","iopub.execute_input":"2021-07-18T16:49:03.794035Z","iopub.status.idle":"2021-07-18T16:51:04.535347Z","shell.execute_reply.started":"2021-07-18T16:49:03.793995Z","shell.execute_reply":"2021-07-18T16:51:04.533526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom sklearn.model_selection import RandomizedSearchCV\n\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 200, stop = 1000, num = 10)]\n\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\n\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10]\n\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4]\n\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n\n# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\n\nprint(random_grid)\n\n\n\n\n# Use the random grid to search for best hyperparameters\n# First create the base model to tune\nrf = RandomForestRegressor()\n# Random search of parameters, using 3 fold cross validation, \n# search across 100 different combinations, and use all available cores\nrf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 10, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n# Fit the random search model\nrf_random.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T16:51:20.851341Z","iopub.execute_input":"2021-07-18T16:51:20.851659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Our best parameter for the randomforest is ')\nprint(rf_random.best_params_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, X_test, y_test):\n    predictions = model.predict(y_test)\n    errors = abs(predictions - y_test)\n    mape = 100 * np.mean(errors / y_test)\n    accuracy = 100 - mape\n    print('Model Performance')\n    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n    print('Accuracy = {:0.2f}%.'.format(accuracy))\n    return accuracy\n\n\n#We make the base model again just to check the accuracy \nbase_model = RandomForestRegressor(n_estimators = 10, random_state = 42)\nbase_model.fit(X_train,y_train)\nbase_accuracy = evaluate(base_model,X_test, y_test)\n\nbest_random = rf_random.best_estimator_\n\nrandom_accuracy = evaluate(best_random, X_test, y_test)\n\nprint('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy - base_accuracy) / base_accuracy))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Gridsearch Cross validation\n\n# Random search allowed us to narrow down the range for each hyperparameter. \n# Now that we know where to concentrate our search, we can explicitly specify every\n# combination of settings to try using gridsearch cross validation\n\n\nfrom sklearn.model_selection import GridSearchCV\n# Create the parameter grid based on the results of random search \nparam_grid = {\n    'bootstrap': [True],\n    'max_depth': [80, 90, 100, 110],\n    'max_features': [2, 3],\n    'min_samples_leaf': [3, 4, 5],\n    'min_samples_split': [8, 10, 12],\n    'n_estimators': [100, 200, 300, 1000]\n}\n# Create a based model\nrf = RandomForestRegressor()\n# Instantiate the grid search model\ngrid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n                          cv = 3, n_jobs = -1, verbose = 2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_search.fit(X_train, y_train)\n\ngrid_search.best_params_\n\nbest_grid = grid_search.best_estimator_\n\ngrid_accuracy = evaluate(best_grid, test_features, test_labels)\n\nprint('Improvement of {:0.2f}%.'.format( 100 * (grid_accuracy - base_accuracy) / base_accuracy))\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}