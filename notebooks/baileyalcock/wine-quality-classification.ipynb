{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\n\nIn this Investigation I will use LogisticRegression, DecisionTreeClassifier, and a RandomForestClassifier to predict information with my data. \n\n\nI originally chose to do the probability of wildfires, but that data wasn't very uniform and therefore couldn't make very accurate predictions. So now I am doing if a certain wine tpe will be ‘good’, ‘ok’, or ‘bad’. \n\n\nThe purpose of this investigation is to identify if a certain wine is of good, ok, or bad quality. I will be using fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulphur dioxide, total sulphur dioxide, density, pH, sulphates, alcohol, and in my predicting column, quality. \n\nHypotheses. Currently I am unsure how I will identify what makes the wine good, ok or bad so I will have to gather and explore my data first and then come up with a cut of for quality to identify what quality it is made of. I will use LogisticRegression, DecisionTreeClassifier, and a RandomForestClassifier and then assess which one is best as I am currently not sure which one will be the best and most accurate. I am also aiming for a 75% accuracy.\n","metadata":{}},{"cell_type":"markdown","source":"# Setting up\nThe below code contains necessary steps for setting up our machine learning environment. \n\nthe data column that I will use is fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulphur dioxide, total sulphur dioxide, density, pH, sulphates, alcohol, and in my predicting column, quality. \n\nI have decided to use so many and all of these as the whole makeup of the wine is relevant when talking about its quality, so I want to have as many possibilities available to get the best results. The predicted is the quality as I wan to use this machine learning program to identify how good or bad of quality is a certain wine type. pH will be very important as it determines the acid and base makeup of the wine and how bitter and the flavouring of the wine.\n\n","metadata":{}},{"cell_type":"code","source":"import os\nos.chdir('/kaggle/input/red-wine-quality-cortez-et-al-2009/')","metadata":{"execution":{"iopub.status.busy":"2021-06-29T07:02:14.250753Z","iopub.execute_input":"2021-06-29T07:02:14.251112Z","iopub.status.idle":"2021-06-29T07:02:14.259192Z","shell.execute_reply.started":"2021-06-29T07:02:14.251068Z","shell.execute_reply":"2021-06-29T07:02:14.258172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# Below are diffrent analytics libraries installed that will be used throughout the model\nimport pandas as pd\nimport numpy as np # linear algebra\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n\n#Below is the method and techniques that i will uses throughout my project to help predict data\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nfrom sklearn.model_selection import cross_val_score\n\n#Machine learning algorithms are even less straightforward than nonlinear regression, partly because machine learning dispenses with the constraint of fitting to a specific mathematical function, such as a polynomial. \n#There are two major categories of problems that are often solved by machine learning: regression and classification. Regression is for numeric data (e.g. What is the likely income for someone with a given address and profession?) and classification is for non-numeric data (e.g. Will the applicant default on this loan?).\n#Below are a few Regressions and Classifiers that will be used throughout the model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n#these below ensure that my LogisticRegression will work and run correctly\n%matplotlib inline\nplt.style.use('ggplot')\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2021-06-29T07:02:14.260867Z","iopub.execute_input":"2021-06-29T07:02:14.261405Z","iopub.status.idle":"2021-06-29T07:02:14.278353Z","shell.execute_reply.started":"2021-06-29T07:02:14.261364Z","shell.execute_reply":"2021-06-29T07:02:14.277524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_red = pd.read_csv(\"winequality-red.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-06-29T07:02:14.279644Z","iopub.execute_input":"2021-06-29T07:02:14.280192Z","iopub.status.idle":"2021-06-29T07:02:14.307242Z","shell.execute_reply.started":"2021-06-29T07:02:14.280148Z","shell.execute_reply":"2021-06-29T07:02:14.306593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Gather and explore the data\n\nThis data that I have selected is fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulphur dioxide, total sulphur dioxide, density, pH, sulphates, alcohol, and in my predicting column, quality. Fixed acidity is most acids involved with wine, volatile acidity is a wine fault or defect is an unpleasant characteristic of a wine often resulting from poor winemaking practices or storage conditions and leading to wine spoilage. Citric acid is an organic compound with the chemical formula HOC(CH₂CO₂H)₂ and is found as a component in wine. Residual sugar or 'RS' is the sugar from the grapes that's left over after fermentation. Chloride is an ion and is the anion Cl⁻. And is within wine.   Total Sulphur Dioxide (TSO2) is the portion of SO2 that is free in the wine plus the portion that is bound to other chemicals in the wine such as aldehydes, pigments, or sugars. The density, of a substance is its mass per unit volume. pH is a scale used to specify the acidity or basicity of an aqueous solution. Acidic solutions are measured to have lower pH values than basic or alkaline solutions. The sulfate or sulphate ion is a polyatomic anion with the empirical formula SO²⁻ ₄. Salts, acid derivatives, and peroxides of sulfate are widely used in industry and wine. An alcoholic drink is a drink that contains ethanol, a type of alcohol produced by fermentation of grains, fruits, or other sources of sugar and is also important in the taste and quality of wine. For most wine critics, quality refers to what they personally consider 'good' versus 'bad' wine, and correspondingly desirable versus aversive. This is usually framed within the context of conformity relative to established, learned norms for the wines concerned\n\n","metadata":{}},{"cell_type":"code","source":"#Below is my printed columns of what all my variables are\ndf = df_red\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-29T07:02:14.308271Z","iopub.execute_input":"2021-06-29T07:02:14.308721Z","iopub.status.idle":"2021-06-29T07:02:14.327536Z","shell.execute_reply.started":"2021-06-29T07:02:14.308679Z","shell.execute_reply":"2021-06-29T07:02:14.326844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare the data\n\nBefore we can separate our prediction target 'y' from the rest of the data, we need to do some preparation so that there aren't any rows with missing values as our machine learning model will not be able to handle them.\n\n## Select features and target then drop missing values\nChoosing our features first will help reduce the total number of rows we need to drop (remove).\n\nWe want to choose a selection of features that are:\n- Relevant to our predictions\n- Don't have many missing values\nI have also ensured that I have \nRemoves outliers if appropriate and discusses why this is.\nRemoves rows with missing/NaN values\nReduces training set data loss by pre-selecting features before dropping rows where applicable to selected model.\nReplaces unsuitable values or missing values instead of dropping rows where appropriate.\n\n","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-29T07:02:14.329598Z","iopub.execute_input":"2021-06-29T07:02:14.329921Z","iopub.status.idle":"2021-06-29T07:02:14.34489Z","shell.execute_reply.started":"2021-06-29T07:02:14.329878Z","shell.execute_reply":"2021-06-29T07:02:14.343861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['quality'].value_counts(sort = False)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T07:02:14.346581Z","iopub.execute_input":"2021-06-29T07:02:14.347044Z","iopub.status.idle":"2021-06-29T07:02:14.354204Z","shell.execute_reply.started":"2021-06-29T07:02:14.346847Z","shell.execute_reply":"2021-06-29T07:02:14.353442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#This is a histogrph which i cn use to better undersand my data and decide how i can slpit it up into 'good', 'ok', and 'bad'. \ndf['quality'].hist() ","metadata":{"execution":{"iopub.status.busy":"2021-06-29T07:02:14.355455Z","iopub.execute_input":"2021-06-29T07:02:14.355719Z","iopub.status.idle":"2021-06-29T07:02:14.556165Z","shell.execute_reply.started":"2021-06-29T07:02:14.355656Z","shell.execute_reply":"2021-06-29T07:02:14.55529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looks like the distribution is imbalanced, althougi will still group them into three categories 'good', 'ok' and 'bad'","metadata":{}},{"cell_type":"code","source":"#this is the code that i have used to split the data into good, ok and bad.\ndef gen_labels(df):\n    labels = ['bad', 'ok', 'good']\n    \n    if 1 <= df.loc['quality'] <= 5:\n        label = labels[0]\n    elif 5 < df.loc['quality'] < 7:\n        label = labels[1]\n    elif 7 <= df.loc['quality']<= 10:\n        label = labels[2]\n        \n    return label","metadata":{"execution":{"iopub.status.busy":"2021-06-29T07:02:14.557402Z","iopub.execute_input":"2021-06-29T07:02:14.557814Z","iopub.status.idle":"2021-06-29T07:02:14.565059Z","shell.execute_reply.started":"2021-06-29T07:02:14.557738Z","shell.execute_reply":"2021-06-29T07:02:14.564295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['label'] = df.apply(gen_labels, axis = 1)\n\ndf['label'] = df['label'].astype('category')\n\ndf['label'].value_counts()\n","metadata":{"execution":{"iopub.status.busy":"2021-06-29T07:02:14.566478Z","iopub.execute_input":"2021-06-29T07:02:14.566748Z","iopub.status.idle":"2021-06-29T07:02:14.701231Z","shell.execute_reply.started":"2021-06-29T07:02:14.566706Z","shell.execute_reply":"2021-06-29T07:02:14.700237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#### Taking too long\n# df['label'].hist()","metadata":{"execution":{"iopub.status.busy":"2021-06-29T07:02:14.703643Z","iopub.execute_input":"2021-06-29T07:02:14.704109Z","iopub.status.idle":"2021-06-29T07:02:14.706928Z","shell.execute_reply.started":"2021-06-29T07:02:14.703844Z","shell.execute_reply":"2021-06-29T07:02:14.706367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2021-06-29T07:02:14.708245Z","iopub.execute_input":"2021-06-29T07:02:14.708658Z","iopub.status.idle":"2021-06-29T07:02:14.719938Z","shell.execute_reply.started":"2021-06-29T07:02:14.708618Z","shell.execute_reply":"2021-06-29T07:02:14.719279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.groupby('label').mean()","metadata":{"execution":{"iopub.status.busy":"2021-06-29T07:02:14.721102Z","iopub.execute_input":"2021-06-29T07:02:14.721496Z","iopub.status.idle":"2021-06-29T07:02:14.746524Z","shell.execute_reply.started":"2021-06-29T07:02:14.721457Z","shell.execute_reply":"2021-06-29T07:02:14.745815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looks like the data is not easily distinguishable, we can further come to this conclusion by some swarm plots","metadata":{}},{"cell_type":"code","source":"sns.catplot(x='label', y='pH', hue='quality', data=df, kind = 'swarm')","metadata":{"execution":{"iopub.status.busy":"2021-06-29T07:02:14.747808Z","iopub.execute_input":"2021-06-29T07:02:14.748232Z","iopub.status.idle":"2021-06-29T07:02:16.855217Z","shell.execute_reply.started":"2021-06-29T07:02:14.748191Z","shell.execute_reply":"2021-06-29T07:02:16.854303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.catplot(x='label', y='fixed acidity', hue='quality', data=df, kind = 'swarm')","metadata":{"execution":{"iopub.status.busy":"2021-06-29T07:02:16.856657Z","iopub.execute_input":"2021-06-29T07:02:16.856997Z","iopub.status.idle":"2021-06-29T07:02:18.468682Z","shell.execute_reply.started":"2021-06-29T07:02:16.856937Z","shell.execute_reply":"2021-06-29T07:02:18.467833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Split data into training and testing data.\nSplitting the training set into two subsets is important because you need to have data that your model hasn't seen yet with actual values to compare to your predictions to be able to tell how well it is performing. \n\n## Separate Features From Target\nNow that we have a set of data (as a Pandas DataFrame) without any missing values, let's separate the features we will use for training from the target.\n\n\n","metadata":{}},{"cell_type":"markdown","source":"Before staring to build a model and start making predictions, standardizing and splitting the data into training and test set","metadata":{}},{"cell_type":"code","source":"def scale_and_split(df, test_sizre=0.3):\n    \n    target = df[['label']]\n    features = df.drop(['label', 'quality'], axis = 1)\n    labels = list(target.label.unique())\n    \n    scaler = StandardScaler()\n    features = scaler.fit_transform(features)\n    \n    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size = 0.3, random_state = 42)\n    \n    return X_train, X_test, y_train, y_test, labels","metadata":{"execution":{"iopub.status.busy":"2021-06-29T07:02:18.470135Z","iopub.execute_input":"2021-06-29T07:02:18.470445Z","iopub.status.idle":"2021-06-29T07:02:18.478861Z","shell.execute_reply.started":"2021-06-29T07:02:18.470386Z","shell.execute_reply":"2021-06-29T07:02:18.477802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n# Choose and Train a Model\nNow that we have data our model can digest, let's use it to train a model and make some predictions. We're going to use LogisticRegression, DecisionTreeClassifier, and a RandomForestClassifier which is different from the Decision Tree Regressor used in the [Intro to Machine Learning course](https://www.kaggle.com/learn/intro-to-machine-learning) in that it makes categorical predictions instead of continuous numerical predictions. \nFor an example of a Decision Tree Classifier working with a non-numerical 'y' and a more in-depth look at how they work, take a look at this Kaggle notebook (https://www.kaggle.com/chrised209/decision-tree-modeling-of-the-iris-dataset)\n\nOk, let's train our model and see what it looks like.\n\n","metadata":{}},{"cell_type":"code","source":"def evaluate_model(model, df):\n    \n    X_train, X_test, y_train, y_test, labels = scale_and_split(df)\n    \n    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n    print('Cross validation score - ', scores.mean()*100)\n    \n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n\n    accuracy = accuracy_score(y_test, y_pred) \n    print('Test accuracy - ',accuracy*100)\n    print('Confusion Matrix -\\n', confusion_matrix(y_test, y_pred, labels))","metadata":{"execution":{"iopub.status.busy":"2021-06-29T07:02:18.480436Z","iopub.execute_input":"2021-06-29T07:02:18.480796Z","iopub.status.idle":"2021-06-29T07:02:18.492855Z","shell.execute_reply.started":"2021-06-29T07:02:18.480732Z","shell.execute_reply":"2021-06-29T07:02:18.492035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr = LogisticRegression()\ndt = DecisionTreeClassifier(criterion='gini', max_depth=12, random_state=42)\nrc = RandomForestClassifier(n_estimators=100, max_depth=12 ,random_state=42)\n\nprint('\\nEvaluation results - Logistic Regression')\nevaluate_model(lr, df)\n\nprint('\\nEvaluation results - Decision Tree Classifier')\nevaluate_model(dt, df)\n\nprint('\\nEvaluation results - Random Forest Classifier')\nevaluate_model(rc, df)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T07:02:18.494303Z","iopub.execute_input":"2021-06-29T07:02:18.494603Z","iopub.status.idle":"2021-06-29T07:02:20.056369Z","shell.execute_reply.started":"2021-06-29T07:02:18.494518Z","shell.execute_reply":"2021-06-29T07:02:20.055626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Cross-validation is a statistical method used to estimate the skill of machine learning models. ... That k-fold cross validation is a procedure used to estimate the skill of the model on new data. There are common tactics that you can use to select the value of k for your dataset.\n\nAccuracy is defined as the percentage of correct predictions for the test data. It can be calculated easily by dividing the number of correct predictions by the number of total predictions.\n\nIn the field of machine learning and specifically the problem of statistical classification, a confusion matrix, also known as an error matrix,[9] is a specific table layout that allows visualization of the performance of an algorithm, typically a supervised learning one (in unsupervised learning it is usually called a matching matrix). Each row of the matrix represents the instances in an actual class while each column represents the instances in a predicted class, or vice versa – both variants are found in the literature","metadata":{}},{"cell_type":"markdown","source":"As the data is imbalanced, upmpling the minority class might help increasing the performance of the model.","metadata":{}},{"cell_type":"markdown","source":"\n\n# Evaluate model performance and tune hyperparameters\nNow that we have a sweet looking model, let's see how good it is at predicting passenger survival on our training set. \n\n\n\n","metadata":{}},{"cell_type":"code","source":"from sklearn.utils import resample","metadata":{"execution":{"iopub.status.busy":"2021-06-29T07:02:20.057829Z","iopub.execute_input":"2021-06-29T07:02:20.058108Z","iopub.status.idle":"2021-06-29T07:02:20.064428Z","shell.execute_reply.started":"2021-06-29T07:02:20.05806Z","shell.execute_reply":"2021-06-29T07:02:20.062078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_majority = df[df['label']!='good']\ndf_minority = df[df['label']=='good']\n \ndf_minority_upsampled = resample(df_minority, replace=True, n_samples=700, random_state=42)\n\ndf_upsampled = pd.concat([df_majority, df_minority_upsampled])\n\ndf_upsampled['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-06-29T07:02:20.065771Z","iopub.execute_input":"2021-06-29T07:02:20.066036Z","iopub.status.idle":"2021-06-29T07:02:20.086756Z","shell.execute_reply.started":"2021-06-29T07:02:20.065991Z","shell.execute_reply":"2021-06-29T07:02:20.085522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr = LogisticRegression()\ndt = DecisionTreeClassifier(criterion='gini', max_depth=12, random_state=42)\nrc = RandomForestClassifier(n_estimators=250, max_depth=12 ,random_state=42)\n\nprint('\\nEvaluation results on upsampled data - Logistic Regression')\nevaluate_model(lr, df_upsampled)\n\nprint('\\nEvaluation results on upsampled data - Decision Tree Classifier')\nevaluate_model(dt, df_upsampled)\n\nprint('\\nEvaluation results on upsampled data - Random Forest Classifier')\nevaluate_model(rc, df_upsampled)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T07:02:20.088052Z","iopub.execute_input":"2021-06-29T07:02:20.088307Z","iopub.status.idle":"2021-06-29T07:02:23.911662Z","shell.execute_reply.started":"2021-06-29T07:02:20.088241Z","shell.execute_reply":"2021-06-29T07:02:23.910695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is a significant improvement in the accuracy of decision tree classifier and random tree classifier after upsampling the minority class.","metadata":{}},{"cell_type":"markdown","source":"# Conclusion\nNow that you have some predictions it's important to talk about them. The accuracy of my data was Cross validation score -  78.17340560054672 and a Test accuracy -  76.32 which was very close and slightly better than my 75% goal. It is not as accurate as Harrison’s with a 99.97% but it is also more that some other people is 60%. I think it was does well but I only really needed to do Random Forest Classifier as this has consistently been the most accurate out of all of the ones I have used/ \n \nThe purpose of this investigation was to currently I am unsure how I will identify what makes the wine good, ok or bad so I will have to gather and explore my data first and then come up with a cut of for quality to identify what quality it is made of. And I think that I have achieved this well. \n","metadata":{}}]}