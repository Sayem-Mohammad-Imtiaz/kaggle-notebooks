{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-17T03:12:34.384122Z","iopub.execute_input":"2021-09-17T03:12:34.384515Z","iopub.status.idle":"2021-09-17T03:12:34.403429Z","shell.execute_reply.started":"2021-09-17T03:12:34.384456Z","shell.execute_reply":"2021-09-17T03:12:34.402603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TOC\n\n[PCA using numpy](#tag1)\n\n[Gradient descent](#tag2)\n\n[K-means](#tag3)\n\n[Naive Bayes](#tag4)\n\n[KNN](#tag5)","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/housesalesprediction/kc_house_data.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-17T03:12:40.008003Z","iopub.execute_input":"2021-09-17T03:12:40.008542Z","iopub.status.idle":"2021-09-17T03:12:40.188265Z","shell.execute_reply.started":"2021-09-17T03:12:40.008496Z","shell.execute_reply":"2021-09-17T03:12:40.186949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-09-17T03:12:40.906131Z","iopub.execute_input":"2021-09-17T03:12:40.906536Z","iopub.status.idle":"2021-09-17T03:12:40.919709Z","shell.execute_reply.started":"2021-09-17T03:12:40.906498Z","shell.execute_reply":"2021-09-17T03:12:40.918326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-09-17T03:12:41.877854Z","iopub.execute_input":"2021-09-17T03:12:41.878409Z","iopub.status.idle":"2021-09-17T03:12:41.888004Z","shell.execute_reply.started":"2021-09-17T03:12:41.878357Z","shell.execute_reply":"2021-09-17T03:12:41.886832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ndf.hist(figsize=(8,6));","metadata":{"execution":{"iopub.status.busy":"2021-09-17T03:12:42.604592Z","iopub.execute_input":"2021-09-17T03:12:42.605195Z","iopub.status.idle":"2021-09-17T03:12:45.112003Z","shell.execute_reply.started":"2021-09-17T03:12:42.605161Z","shell.execute_reply":"2021-09-17T03:12:45.111134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='tag1'></a>\n## PCA from Scratch","metadata":{}},{"cell_type":"markdown","source":"* Scale the matrix\n* Get covariate matrix\n* Singular Value Decomposition from the cov_matrix \n* Sort and find the n largest eigen vector and corresponding eigen values\n* Get the dot product of the scaled metrix with the eigen vector ","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler","metadata":{"execution":{"iopub.status.busy":"2021-09-17T03:12:54.794405Z","iopub.execute_input":"2021-09-17T03:12:54.794945Z","iopub.status.idle":"2021-09-17T03:12:54.798873Z","shell.execute_reply.started":"2021-09-17T03:12:54.794912Z","shell.execute_reply":"2021-09-17T03:12:54.797965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## scale\nnum_cols = [c for c in df.columns if df[c].dtypes!='object' and c!='price']\nsc = StandardScaler()\nnum_col_scale = sc.fit_transform(df[num_cols])\n\n## get covariate matrix\ncov_matrix = np.cov(num_col_scale.T)\n\n## eigen value decomposition\neigval, eigvec  = np.linalg.eig(cov_matrix)\n\n## calculate explained variance\nexplained_var = eigval / np.sum(eigval)\n\n## plot each component\nplt.plot(np.arange(len(explained_var)), np.cumsum(explained_var), 'bo')","metadata":{"execution":{"iopub.status.busy":"2021-09-17T03:13:22.291279Z","iopub.execute_input":"2021-09-17T03:13:22.291689Z","iopub.status.idle":"2021-09-17T03:13:22.529686Z","shell.execute_reply.started":"2021-09-17T03:13:22.291656Z","shell.execute_reply":"2021-09-17T03:13:22.528672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eigval","metadata":{"execution":{"iopub.status.busy":"2021-09-17T03:15:16.024639Z","iopub.execute_input":"2021-09-17T03:15:16.025083Z","iopub.status.idle":"2021-09-17T03:15:16.03177Z","shell.execute_reply.started":"2021-09-17T03:15:16.025045Z","shell.execute_reply":"2021-09-17T03:15:16.03078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## sort the eigen values from the largest to the smallest\nn_components = 2\nidx = eigval.argsort()[::-1]\neigval_sorted = eigval[idx][:2]\neigvec_sorted = np.atleast_1d(eigvec[:, idx])[:, :n_components]","metadata":{"execution":{"iopub.status.busy":"2021-09-17T03:16:50.578128Z","iopub.execute_input":"2021-09-17T03:16:50.578559Z","iopub.status.idle":"2021-09-17T03:16:50.584312Z","shell.execute_reply.started":"2021-09-17T03:16:50.57852Z","shell.execute_reply":"2021-09-17T03:16:50.583372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## transform all the num_col\nnum_col_scale.dot(eigval_sorted.T[0]).shape","metadata":{"execution":{"iopub.status.busy":"2021-09-17T03:20:05.948944Z","iopub.execute_input":"2021-09-17T03:20:05.949344Z","iopub.status.idle":"2021-09-17T03:20:05.965512Z","shell.execute_reply.started":"2021-09-17T03:20:05.949312Z","shell.execute_reply":"2021-09-17T03:20:05.964117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## get the dot product\npc1 = num_col_scale.dot(eigvec_sorted.T[0])\npc2 = num_col_scale.dot(eigvec_sorted.T[1])\n\nimport seaborn as sns\nsns.scatterplot(pc1, pc2, hue=df.price);","metadata":{"execution":{"iopub.status.busy":"2021-09-17T03:17:44.070201Z","iopub.execute_input":"2021-09-17T03:17:44.070808Z","iopub.status.idle":"2021-09-17T03:17:46.001576Z","shell.execute_reply.started":"2021-09-17T03:17:44.070771Z","shell.execute_reply":"2021-09-17T03:17:46.000506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='tag2'></a>\n## Gradient descent ","metadata":{}},{"cell_type":"markdown","source":"Reference: https://towardsdatascience.com/gradient-descent-from-scratch-e8b75fa986cc","metadata":{}},{"cell_type":"markdown","source":"Taking partial derivatives of m and b from the loss function of OLS:\n\n$$\\frac{\\partial f}{\\partial b} = \\frac{1}{n}\\Sigma^n_{i=1}[-2(y_i-(mx_i+b))]$$\n$$\\frac{\\partial f}{\\partial m} = \\frac{1}{n}\\Sigma^n_{i=1}[-2x_i(y_i-(mx+b))]$$","metadata":{}},{"cell_type":"markdown","source":"These are the gradients\n\nand to update m and b\n\n$m := m - \\lambda \\frac{ \\partial{f}}{\\partial{m}}$\n\n$b := b- \\lambda \\frac{\\partial{f}}{\\partial{b}}$","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\n\ndef gradient_descent(X, y, lr=0.001, epoch=20):\n    m, b= 0.3, 0.4\n    log, mse = [], []\n    \n    N = len(X)\n    \n    for _ in range(epoch):\n        f = y-(m*X + b)\n        \n        b -= lr*(-2*f.sum()/N)\n        \n        m -= lr*(-2*X.dot(f).sum()/N)\n        \n        log.append((m, b))\n        \n        mse.append(mean_squared_error(y, (m*X + b)))\n        \n    return m, b, log, mse","metadata":{"execution":{"iopub.status.busy":"2021-09-09T22:23:11.315294Z","iopub.execute_input":"2021-09-09T22:23:11.315847Z","iopub.status.idle":"2021-09-09T22:23:11.322939Z","shell.execute_reply.started":"2021-09-09T22:23:11.315798Z","shell.execute_reply":"2021-09-09T22:23:11.322259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = [np.random.randint(1,10,1) for _ in range(10)]\nX = np.asarray(X).reshape(-1)\ny = 0.44*X + 0.6","metadata":{"execution":{"iopub.status.busy":"2021-09-09T22:23:11.663837Z","iopub.execute_input":"2021-09-09T22:23:11.664229Z","iopub.status.idle":"2021-09-09T22:23:11.66899Z","shell.execute_reply.started":"2021-09-09T22:23:11.664196Z","shell.execute_reply":"2021-09-09T22:23:11.667904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(X, y, 'ro')","metadata":{"execution":{"iopub.status.busy":"2021-09-09T22:23:12.213751Z","iopub.execute_input":"2021-09-09T22:23:12.214358Z","iopub.status.idle":"2021-09-09T22:23:12.361125Z","shell.execute_reply.started":"2021-09-09T22:23:12.214311Z","shell.execute_reply":"2021-09-09T22:23:12.360475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m, b, log, mse = gradient_descent(X, y, epoch=30)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T22:24:53.08128Z","iopub.execute_input":"2021-09-09T22:24:53.081661Z","iopub.status.idle":"2021-09-09T22:24:53.096043Z","shell.execute_reply.started":"2021-09-09T22:24:53.081631Z","shell.execute_reply":"2021-09-09T22:24:53.095025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(np.arange(30), [i[0] for i in log])\nplt.xlabel('epoch')\nplt.ylabel('M value');","metadata":{"execution":{"iopub.status.busy":"2021-09-09T22:36:02.367961Z","iopub.execute_input":"2021-09-09T22:36:02.368459Z","iopub.status.idle":"2021-09-09T22:36:02.524391Z","shell.execute_reply.started":"2021-09-09T22:36:02.368424Z","shell.execute_reply":"2021-09-09T22:36:02.523637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(np.arange(30), [i[1] for i in log])\nplt.ylabel('b value');","metadata":{"execution":{"iopub.status.busy":"2021-09-09T22:36:03.163131Z","iopub.execute_input":"2021-09-09T22:36:03.163489Z","iopub.status.idle":"2021-09-09T22:36:03.305183Z","shell.execute_reply.started":"2021-09-09T22:36:03.16346Z","shell.execute_reply":"2021-09-09T22:36:03.304185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(np.arange(30), mse)\nplt.ylabel('MSE');","metadata":{"execution":{"iopub.status.busy":"2021-09-09T22:36:03.76186Z","iopub.execute_input":"2021-09-09T22:36:03.762212Z","iopub.status.idle":"2021-09-09T22:36:03.908229Z","shell.execute_reply.started":"2021-09-09T22:36:03.762184Z","shell.execute_reply":"2021-09-09T22:36:03.907165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='tag3'></a>\n## K means","metadata":{}},{"cell_type":"markdown","source":"Reference https://medium.com/@rishit.dagli/build-k-means-from-scratch-in-python-e46bf68aa875","metadata":{}},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2021-09-09T22:45:31.777557Z","iopub.execute_input":"2021-09-09T22:45:31.777981Z","iopub.status.idle":"2021-09-09T22:45:31.785496Z","shell.execute_reply.started":"2021-09-09T22:45:31.777942Z","shell.execute_reply":"2021-09-09T22:45:31.784255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(df.lat, df.long, 'ro');","metadata":{"execution":{"iopub.status.busy":"2021-09-09T22:46:31.820552Z","iopub.execute_input":"2021-09-09T22:46:31.821007Z","iopub.status.idle":"2021-09-09T22:46:32.040642Z","shell.execute_reply.started":"2021-09-09T22:46:31.820979Z","shell.execute_reply":"2021-09-09T22:46:32.039649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class KMeans:\n    \n    def __init__(self, k, tol= 0.0001, max_iter = 200):\n        self.k = k\n        self.tol = tol\n        self.max_iter = max_iter\n        \n    def fit(self, X, ):\n        \n        self.centroids = {}\n        \n        for i in range(self.k):\n            self.centroids[i] = X[random.choice(len(X))]\n            \n        for i in range(self.max_iter):\n            self.classes = {}\n            for j in range(self.k):\n                self.classes[j] = []\n                \n            for feature in X:\n                distances = [np.linalg.norm(feature - self.centroids[c]) for c in self.controids]\n                classes = distances.index(min(distances))\n            \n                self.classes[classes].append(feature)\n                \n            prev_centroids = dict(self.centroids)\n            \n            for class_ in self.classes:\n                self.centroids[class_] = np.average(self.classes[class_], axis=0)\n            \n            optimized = False\n            for c in self.centroids:\n                original_c = prev_centroids[c]\n                current_c = self.centroids[c]\n                \n                if np.sum((current_c - original_c)/original_c*100)> self.tol:\n                    print(np.sum((current_c -original_c )/original_c *100.0))\n                    optimized = False\n                    \n                    \n            if optimized:\n                break\n                \n    def predict(test_X):\n        distances = [np.linalg.norm(test_X - self.centroids[c]) for c in self.centroids]\n        \n        classes = distances.index(min(distances))\n        return classes","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='tag4'></a>\n\n## Naive Bayes Classifier","metadata":{}},{"cell_type":"markdown","source":"[ref1](https://github.com/eriklindernoren/ML-From-Scratch/blob/master/mlfromscratch/supervised_learning/naive_bayes.py)\n\n[ref2](https://github.com/tigju/Naive-Bayes-Classifier-from-scratch/blob/main/naive_bayes.ipynb)\n\n[ref3](https://chrisalbon.com/code/machine_learning/naive_bayes/naive_bayes_classifier_from_scratch/)","metadata":{}},{"cell_type":"code","source":"## this example is from : https://chrisalbon.com/code/machine_learning/naive_bayes/naive_bayes_classifier_from_scratch/\nimport pandas as pd\n\ndf = pd.read_csv('/kaggle/input/housesalesprediction/kc_house_data.csv')","metadata":{"execution":{"iopub.status.busy":"2021-09-21T14:26:38.285771Z","iopub.execute_input":"2021-09-21T14:26:38.286399Z","iopub.status.idle":"2021-09-21T14:26:38.290335Z","shell.execute_reply.started":"2021-09-21T14:26:38.286363Z","shell.execute_reply":"2021-09-21T14:26:38.289553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_nb = df[['bedrooms', 'floors', 'sqft_living', 'grade']]","metadata":{"execution":{"iopub.status.busy":"2021-09-21T14:16:58.471729Z","iopub.execute_input":"2021-09-21T14:16:58.472148Z","iopub.status.idle":"2021-09-21T14:16:58.477575Z","shell.execute_reply.started":"2021-09-21T14:16:58.472115Z","shell.execute_reply":"2021-09-21T14:16:58.476839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## for simplicity we use two claases\ndf_nb['grade'] = df_nb.grade.apply(lambda x: True if x > 8 else False)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T14:16:58.93148Z","iopub.execute_input":"2021-09-21T14:16:58.931834Z","iopub.status.idle":"2021-09-21T14:16:58.949173Z","shell.execute_reply.started":"2021-09-21T14:16:58.931803Z","shell.execute_reply":"2021-09-21T14:16:58.948168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_nb.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-09-21T14:16:59.950105Z","iopub.execute_input":"2021-09-21T14:16:59.950485Z","iopub.status.idle":"2021-09-21T14:16:59.958202Z","shell.execute_reply.started":"2021-09-21T14:16:59.95045Z","shell.execute_reply":"2021-09-21T14:16:59.957285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n$$ p (grade| condition) = \\frac{p(grade)p(condition|grade)}{p(condition)}$$\n\n### calculate prior","metadata":{}},{"cell_type":"markdown","source":"$p(grade)$ is prior ","metadata":{}},{"cell_type":"code","source":"\ncondition_cols = df_nb.columns[:5]\ncondition_cols\n","metadata":{"execution":{"iopub.status.busy":"2021-09-21T14:17:01.013526Z","iopub.execute_input":"2021-09-21T14:17:01.0139Z","iopub.status.idle":"2021-09-21T14:17:01.020712Z","shell.execute_reply.started":"2021-09-21T14:17:01.013868Z","shell.execute_reply":"2021-09-21T14:17:01.01966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"priors = pd.DataFrame(df_nb.groupby('grade')['bedrooms'].count()/df_nb.shape[0])","metadata":{"execution":{"iopub.status.busy":"2021-09-21T14:17:01.791921Z","iopub.execute_input":"2021-09-21T14:17:01.792258Z","iopub.status.idle":"2021-09-21T14:17:01.800583Z","shell.execute_reply.started":"2021-09-21T14:17:01.792229Z","shell.execute_reply":"2021-09-21T14:17:01.799013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"priors","metadata":{"execution":{"iopub.status.busy":"2021-09-21T14:17:04.605919Z","iopub.execute_input":"2021-09-21T14:17:04.606289Z","iopub.status.idle":"2021-09-21T14:17:04.616347Z","shell.execute_reply.started":"2021-09-21T14:17:04.606257Z","shell.execute_reply":"2021-09-21T14:17:04.615355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Likelihood","metadata":{}},{"cell_type":"markdown","source":"To get the likehood $p(condition|grade)$, we first assume that each feature distributed normally, so that using the normal distribution pdf we get \n\nhttps://en.wikipedia.org/wiki/Normal_distribution\n\n$$f(x) = -\\frac{1}{\\sigma \\sqrt{2\\pi}} e^{-\\frac{1}{2}(\\frac{x-\\mu}{\\theta})^2}$$","metadata":{}},{"cell_type":"code","source":"## to get the mean\ndf_mean = df_nb.groupby('grade').mean()\ndf_mean","metadata":{"execution":{"iopub.status.busy":"2021-09-21T14:17:06.407833Z","iopub.execute_input":"2021-09-21T14:17:06.408457Z","iopub.status.idle":"2021-09-21T14:17:06.423896Z","shell.execute_reply.started":"2021-09-21T14:17:06.408422Z","shell.execute_reply":"2021-09-21T14:17:06.42313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_variance = df_nb.groupby('grade').var()\ndf_variance","metadata":{"execution":{"iopub.status.busy":"2021-09-21T14:17:06.911504Z","iopub.execute_input":"2021-09-21T14:17:06.912067Z","iopub.status.idle":"2021-09-21T14:17:06.926035Z","shell.execute_reply.started":"2021-09-21T14:17:06.912034Z","shell.execute_reply":"2021-09-21T14:17:06.925239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## now we calculate the mean and variance for each condition\n\n## mean for grade=True\nbed_true_mean = df_mean['bedrooms'][df_variance.index==True].values[0]\nfloor_true_mean = df_mean['floors'][df_variance.index==True].values[0]\nsqft_true_mean = df_mean['sqft_living'][df_variance.index==True].values[0]\n\n## mean for grade=False\nbed_false_mean = df_mean['bedrooms'][df_variance.index==False].values[0]\nfloor_false_mean = df_mean['floors'][df_variance.index==False].values[0]\nsqft_false_mean = df_mean['sqft_living'][df_variance.index==False].values[0]\n\n## var for grade=True\nbed_true_var = df_variance['bedrooms'][df_variance.index==True].values[0]\nfloor_true_var = df_variance['floors'][df_variance.index==True].values[0]\nsqft_true_var = df_variance['sqft_living'][df_variance.index==True].values[0]\n\n## var for grade = False\nbed_false_var = df_variance['bedrooms'][df_variance.index==False].values[0]\nfloor_false_var = df_variance['floors'][df_variance.index==False].values[0]\nsqft_false_var = df_variance['sqft_living'][df_variance.index==False].values[0]\n","metadata":{"execution":{"iopub.status.busy":"2021-09-21T14:25:54.247644Z","iopub.execute_input":"2021-09-21T14:25:54.248006Z","iopub.status.idle":"2021-09-21T14:25:54.259379Z","shell.execute_reply.started":"2021-09-21T14:25:54.247976Z","shell.execute_reply":"2021-09-21T14:25:54.258607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n# Create a function that calculates p(x | y):\ndef p_x_given_y(x, mean_y, variance_y):\n\n    # Input the arguments into a probability density function\n    p = 1/(np.sqrt(2*np.pi*variance_y)) * np.exp((-(x-mean_y)**2)/(2*variance_y))\n    \n    # return p\n    return p","metadata":{"execution":{"iopub.status.busy":"2021-09-21T14:42:23.201369Z","iopub.execute_input":"2021-09-21T14:42:23.201756Z","iopub.status.idle":"2021-09-21T14:42:23.207009Z","shell.execute_reply.started":"2021-09-21T14:42:23.201722Z","shell.execute_reply":"2021-09-21T14:42:23.20592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Putting together \n\nSince the denominator of the equation $p(condition)$ is the marginal probability, and sometimes we can ignore the denominator and assume that the posterior is proportional to the denominator, thus","metadata":{}},{"cell_type":"markdown","source":"$p(grade|condition) \\propto p(grade) p(condition|grade)$","metadata":{}},{"cell_type":"code","source":"df_nb.head(1)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T14:42:24.354394Z","iopub.execute_input":"2021-09-21T14:42:24.354961Z","iopub.status.idle":"2021-09-21T14:42:24.368148Z","shell.execute_reply.started":"2021-09-21T14:42:24.35491Z","shell.execute_reply":"2021-09-21T14:42:24.366675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_nb.head(1)['bedrooms'].values[0]","metadata":{"execution":{"iopub.status.busy":"2021-09-21T14:42:24.565231Z","iopub.execute_input":"2021-09-21T14:42:24.565571Z","iopub.status.idle":"2021-09-21T14:42:24.57295Z","shell.execute_reply.started":"2021-09-21T14:42:24.565541Z","shell.execute_reply":"2021-09-21T14:42:24.571845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## numerator of posterior if classified as True\n\npriors[priors.index==True].values[0][0] * \\\np_x_given_y(df_nb.head(1)['bedrooms'].values[0], bed_true_mean, bed_true_var) *\\\np_x_given_y(df_nb.head(1)['floors'].values[0], floor_true_mean, floor_true_var) *\\\np_x_given_y(df_nb.head(1)['sqft_living'].values[0],sqft_true_mean, sqft_true_var)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T14:42:24.964697Z","iopub.execute_input":"2021-09-21T14:42:24.965258Z","iopub.status.idle":"2021-09-21T14:42:24.976071Z","shell.execute_reply.started":"2021-09-21T14:42:24.965208Z","shell.execute_reply":"2021-09-21T14:42:24.9748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## numerator of posterior if classified as false\n\npriors[priors.index==False].values[0][0] * \\\np_x_given_y(df_nb.head(1)['bedrooms'].values[0], bed_false_mean, bed_false_var) *\\\np_x_given_y(df_nb.head(1)['floors'].values[0], floor_false_mean, floor_false_var) *\\\np_x_given_y(df_nb.head(1)['sqft_living'].values[0],sqft_false_mean, sqft_false_var)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T14:43:38.362312Z","iopub.execute_input":"2021-09-21T14:43:38.362656Z","iopub.status.idle":"2021-09-21T14:43:38.372768Z","shell.execute_reply.started":"2021-09-21T14:43:38.362626Z","shell.execute_reply":"2021-09-21T14:43:38.372041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Therefore, the $p(condition|grade=F)$ is higher than $p(condition|grade=T)$","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='tag5'></a>\n\n## KNN\n","metadata":{}},{"cell_type":"markdown","source":"* For each data point, find the classes for the closesest N neighbours\n* Using majority vote to determine the classes","metadata":{}},{"cell_type":"code","source":"  \n# from __future__ import print_function, division\n# import numpy as np\n# from mlfromscratch.utils import euclidean_distance\n\n\n# class KNN:\n#     def __init__(self, k):\n#         self.k = k\n#     def _vote( self, neighbour_labels):\n#         counts = np.bincount(neighbour_labels.astype('int'))\n        \n#         return counts.argmax()\n    \n    \n#     def predict(self, X_train, X_test, y_train):\n        \n#         ## initialize\n        \n#         y_pred = np.empty(X_test.shape[0])\n        \n        \n#         ## get the neighbour label\n        \n#         for i, v in enumerate(X_test):\n#             ## sort the training samples by their distances\n#             idx = np.argsort([euclidean_distance(v, x) for x in X_train])[self.k:]\n            \n#             ## Extract the labels \n#             k_nearest = np.array([y_train[i] for i in idx])\n            \n#             y_pred[i] = self._vote(k_nearest)\n            \n#         return y_pred\n            \n            ","metadata":{"execution":{"iopub.status.busy":"2021-09-19T23:26:35.525782Z","iopub.execute_input":"2021-09-19T23:26:35.52625Z","iopub.status.idle":"2021-09-19T23:26:35.530922Z","shell.execute_reply.started":"2021-09-19T23:26:35.526216Z","shell.execute_reply":"2021-09-19T23:26:35.529567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}