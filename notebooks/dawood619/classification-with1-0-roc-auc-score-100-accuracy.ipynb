{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Basic EDA**\n* Logistic Regression\n* GridsearchCV,RandomizedsearchCV\n* GaussianNB\n* Support Vector Machine\n\n**Performance measurements**\n* Classification report,Confusion Matrix, precision, recall, F1 score, roc_auc_score, accuracy_score"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":1,"outputs":[{"output_type":"stream","text":"['mushrooms.csv']\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Import some common libraries used down the line"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":2,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"loading the dataset into pandas dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/mushrooms.csv\")\ndata.head()","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"  class cap-shape cap-surface   ...   spore-print-color population habitat\n0     p         x           s   ...                   k          s       u\n1     e         x           s   ...                   n          n       g\n2     e         b           s   ...                   n          n       m\n3     p         x           y   ...                   k          s       u\n4     e         x           s   ...                   n          a       g\n\n[5 rows x 23 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>cap-shape</th>\n      <th>cap-surface</th>\n      <th>cap-color</th>\n      <th>bruises</th>\n      <th>odor</th>\n      <th>gill-attachment</th>\n      <th>gill-spacing</th>\n      <th>gill-size</th>\n      <th>gill-color</th>\n      <th>stalk-shape</th>\n      <th>stalk-root</th>\n      <th>stalk-surface-above-ring</th>\n      <th>stalk-surface-below-ring</th>\n      <th>stalk-color-above-ring</th>\n      <th>stalk-color-below-ring</th>\n      <th>veil-type</th>\n      <th>veil-color</th>\n      <th>ring-number</th>\n      <th>ring-type</th>\n      <th>spore-print-color</th>\n      <th>population</th>\n      <th>habitat</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>p</td>\n      <td>x</td>\n      <td>s</td>\n      <td>n</td>\n      <td>t</td>\n      <td>p</td>\n      <td>f</td>\n      <td>c</td>\n      <td>n</td>\n      <td>k</td>\n      <td>e</td>\n      <td>e</td>\n      <td>s</td>\n      <td>s</td>\n      <td>w</td>\n      <td>w</td>\n      <td>p</td>\n      <td>w</td>\n      <td>o</td>\n      <td>p</td>\n      <td>k</td>\n      <td>s</td>\n      <td>u</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>e</td>\n      <td>x</td>\n      <td>s</td>\n      <td>y</td>\n      <td>t</td>\n      <td>a</td>\n      <td>f</td>\n      <td>c</td>\n      <td>b</td>\n      <td>k</td>\n      <td>e</td>\n      <td>c</td>\n      <td>s</td>\n      <td>s</td>\n      <td>w</td>\n      <td>w</td>\n      <td>p</td>\n      <td>w</td>\n      <td>o</td>\n      <td>p</td>\n      <td>n</td>\n      <td>n</td>\n      <td>g</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>e</td>\n      <td>b</td>\n      <td>s</td>\n      <td>w</td>\n      <td>t</td>\n      <td>l</td>\n      <td>f</td>\n      <td>c</td>\n      <td>b</td>\n      <td>n</td>\n      <td>e</td>\n      <td>c</td>\n      <td>s</td>\n      <td>s</td>\n      <td>w</td>\n      <td>w</td>\n      <td>p</td>\n      <td>w</td>\n      <td>o</td>\n      <td>p</td>\n      <td>n</td>\n      <td>n</td>\n      <td>m</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>p</td>\n      <td>x</td>\n      <td>y</td>\n      <td>w</td>\n      <td>t</td>\n      <td>p</td>\n      <td>f</td>\n      <td>c</td>\n      <td>n</td>\n      <td>n</td>\n      <td>e</td>\n      <td>e</td>\n      <td>s</td>\n      <td>s</td>\n      <td>w</td>\n      <td>w</td>\n      <td>p</td>\n      <td>w</td>\n      <td>o</td>\n      <td>p</td>\n      <td>k</td>\n      <td>s</td>\n      <td>u</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>e</td>\n      <td>x</td>\n      <td>s</td>\n      <td>g</td>\n      <td>f</td>\n      <td>n</td>\n      <td>f</td>\n      <td>w</td>\n      <td>b</td>\n      <td>k</td>\n      <td>t</td>\n      <td>e</td>\n      <td>s</td>\n      <td>s</td>\n      <td>w</td>\n      <td>w</td>\n      <td>p</td>\n      <td>w</td>\n      <td>o</td>\n      <td>e</td>\n      <td>n</td>\n      <td>a</td>\n      <td>g</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"(8124, 23)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"There are many features with non-numeric or categorical data. ML can be applied only on numeric values. so we have to convert it to numerical values for which you can use label encoder."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's check for missing null values\ndata.info()","execution_count":5,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 8124 entries, 0 to 8123\nData columns (total 23 columns):\nclass                       8124 non-null object\ncap-shape                   8124 non-null object\ncap-surface                 8124 non-null object\ncap-color                   8124 non-null object\nbruises                     8124 non-null object\nodor                        8124 non-null object\ngill-attachment             8124 non-null object\ngill-spacing                8124 non-null object\ngill-size                   8124 non-null object\ngill-color                  8124 non-null object\nstalk-shape                 8124 non-null object\nstalk-root                  8124 non-null object\nstalk-surface-above-ring    8124 non-null object\nstalk-surface-below-ring    8124 non-null object\nstalk-color-above-ring      8124 non-null object\nstalk-color-below-ring      8124 non-null object\nveil-type                   8124 non-null object\nveil-color                  8124 non-null object\nring-number                 8124 non-null object\nring-type                   8124 non-null object\nspore-print-color           8124 non-null object\npopulation                  8124 non-null object\nhabitat                     8124 non-null object\ndtypes: object(23)\nmemory usage: 1.4+ MB\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#let's see how many categories are available for predictions\ndata['class'].unique()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"array(['p', 'e'], dtype=object)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#converting categorical data (including Class column) into numeric using LabelEncoder\nfrom sklearn.preprocessing import LabelEncoder\nlablencoder = LabelEncoder()\n\nfor col in data.columns:\n    data[col] = lablencoder.fit_transform(data[col])\n\ndata.head()","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"   class  cap-shape   ...     population  habitat\n0      1          5   ...              3        5\n1      0          5   ...              2        1\n2      0          0   ...              2        3\n3      1          5   ...              3        5\n4      0          5   ...              0        1\n\n[5 rows x 23 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>cap-shape</th>\n      <th>cap-surface</th>\n      <th>cap-color</th>\n      <th>bruises</th>\n      <th>odor</th>\n      <th>gill-attachment</th>\n      <th>gill-spacing</th>\n      <th>gill-size</th>\n      <th>gill-color</th>\n      <th>stalk-shape</th>\n      <th>stalk-root</th>\n      <th>stalk-surface-above-ring</th>\n      <th>stalk-surface-below-ring</th>\n      <th>stalk-color-above-ring</th>\n      <th>stalk-color-below-ring</th>\n      <th>veil-type</th>\n      <th>veil-color</th>\n      <th>ring-number</th>\n      <th>ring-type</th>\n      <th>spore-print-color</th>\n      <th>population</th>\n      <th>habitat</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>5</td>\n      <td>2</td>\n      <td>4</td>\n      <td>1</td>\n      <td>6</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>7</td>\n      <td>7</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>4</td>\n      <td>2</td>\n      <td>3</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>5</td>\n      <td>2</td>\n      <td>9</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>7</td>\n      <td>7</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>8</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>7</td>\n      <td>7</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>5</td>\n      <td>3</td>\n      <td>8</td>\n      <td>1</td>\n      <td>6</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>7</td>\n      <td>7</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>4</td>\n      <td>2</td>\n      <td>3</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>5</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>7</td>\n      <td>7</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#we already saw how many types of classes we need to predict. Just 'p','e' in this case.\n#let's see how many observations are related to each class\nprint(data['class'].value_counts())","execution_count":8,"outputs":[{"output_type":"stream","text":"0    4208\n1    3916\nName: class, dtype: int64\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Pretty Good!! we have balanced set of observations for each class"},{"metadata":{"trusted":true},"cell_type":"code","source":"#visualizing the same using seaborn\nsns.countplot(data['class'])","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"<matplotlib.axes._subplots.AxesSubplot at 0x7fd620cf2898>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAFFNJREFUeJzt3X2QXfV93/H3x+LBSeMEYTaUSGqkOmoyIg+yu5Vp3D9cmICgrUUytgcmMSplImcGWnsmTQ2eNtjY6iSNHWJcmxmlyAiPY0W146J6lFIFSBy35mEVy4AgDFvARRqB1giwqWNayd/+cX+yr8Xu6h6zd++u9X7N3Nlzvud3zv3eGQ0fznOqCkmSBvWqUTcgSVpcDA5JUicGhySpE4NDktSJwSFJ6sTgkCR1YnBIkjoxOCRJnRgckqROThl1A8Nw1lln1cqVK0fdhiQtKnv27PlaVY2daNwPZHCsXLmSiYmJUbchSYtKkq8OMs5DVZKkTgwOSVInBockqRODQ5LUicEhSerE4JAkdWJwSJI6MTgkSZ0YHJKkTn4g7xyfC3//t24bdQtagPb83hWjbkEaOfc4JEmdGBySpE4MDklSJwaHJKkTg0OS1MnQgyPJkiRfTvL5Nr8qyb1JJpP8cZLTWv30Nj/Zlq/s28Z1rf5okouG3bMkaWbzscfxLuCRvvnfBW6sqp8CngOuavWrgOda/cY2jiRrgMuAc4H1wMeTLJmHviVJ0xhqcCRZDvwT4D+1+QDnA59pQ7YBl7bpDW2etvyCNn4DsL2qXqqqJ4BJYN0w+5YkzWzYexx/APwb4Ntt/rXA81V1pM3vB5a16WXAUwBt+Qtt/Hfq06wjSZpnQwuOJP8UOFRVe4b1Hcd936YkE0kmpqam5uMrJemkNMw9jjcBb0nyJLCd3iGqjwBnJDn2qJPlwIE2fQBYAdCW/xjwbH99mnW+o6q2VNV4VY2PjY3N/a+RJAFDDI6quq6qllfVSnont++qql8F7gbe2oZtBG5v0zvbPG35XVVVrX5Zu+pqFbAauG9YfUuSZjeKhxy+B9ie5IPAl4FbWv0W4JNJJoHD9MKGqtqXZAfwMHAEuLqqjs5/25IkmKfgqKo/B/68TT/ONFdFVdW3gLfNsP5mYPPwOpQWl/99w8+NugUtQH/ntx+cl+/xznFJUicGhySpE4NDktSJwSFJ6sTgkCR1YnBIkjoxOCRJnRgckqRODA5JUicGhySpE4NDktSJwSFJ6sTgkCR1YnBIkjoxOCRJnRgckqROhhYcSV6d5L4kX0myL8n7W/3WJE8k2ds+a1s9SW5KMpnkgSRv6NvWxiSPtc/Gmb5TkjR8w3wD4EvA+VX1YpJTgS8m+dO27Leq6jPHjb+Y3vvEVwNvBG4G3pjkTOB6YBwoYE+SnVX13BB7lyTNYGh7HNXzYps9tX1qllU2ALe19e4BzkhyDnARsLuqDrew2A2sH1bfkqTZDfUcR5IlSfYCh+j9x//etmhzOxx1Y5LTW20Z8FTf6vtbbaa6JGkEhhocVXW0qtYCy4F1SX4WuA74GeAfAGcC75mL70qyKclEkompqam52KQkaRrzclVVVT0P3A2sr6qD7XDUS8AngHVt2AFgRd9qy1ttpvrx37GlqsaranxsbGwYP0OSxHCvqhpLckab/iHgl4C/buctSBLgUuChtspO4Ip2ddV5wAtVdRC4A7gwydIkS4ELW02SNALDvKrqHGBbkiX0AmpHVX0+yV1JxoAAe4HfaON3AZcAk8A3gSsBqupwkg8A97dxN1TV4SH2LUmaxdCCo6oeAF4/Tf38GcYXcPUMy7YCW+e0QUnS98U7xyVJnRgckqRODA5JUicGhySpE4NDktSJwSFJ6sTgkCR1YnBIkjoxOCRJnRgckqRODA5JUicGhySpE4NDktSJwSFJ6sTgkCR1YnBIkjoZ5qtjX53kviRfSbIvyftbfVWSe5NMJvnjJKe1+ultfrItX9m3reta/dEkFw2rZ0nSiQ1zj+Ml4Pyq+gVgLbC+vUv8d4Ebq+qngOeAq9r4q4DnWv3GNo4ka4DLgHOB9cDH2+toJUkjMLTgqJ4X2+yp7VPA+cBnWn0bcGmb3tDmacsvSJJW315VL1XVE/TeSb5uWH1LkmY31HMcSZYk2QscAnYD/wt4vqqOtCH7gWVtehnwFEBb/gLw2v76NOv0f9emJBNJJqampobxcyRJDDk4qupoVa0FltPbS/iZIX7Xlqoar6rxsbGxYX2NJJ305uWqqqp6Hrgb+IfAGUlOaYuWAwfa9AFgBUBb/mPAs/31adaRJM2zYV5VNZbkjDb9Q8AvAY/QC5C3tmEbgdvb9M42T1t+V1VVq1/WrrpaBawG7htW35Kk2Z1y4iHft3OAbe0KqFcBO6rq80keBrYn+SDwZeCWNv4W4JNJJoHD9K6koqr2JdkBPAwcAa6uqqND7FuSNIuhBUdVPQC8fpr640xzVVRVfQt42wzb2gxsnuseJUndeee4JKkTg0OS1InBIUnqxOCQJHVicEiSOjE4JEmdGBySpE4MDklSJwaHJKkTg0OS1InBIUnqxOCQJHVicEiSOjE4JEmdGBySpE6G+QbAFUnuTvJwkn1J3tXq70tyIMne9rmkb53rkkwmeTTJRX319a02meTaYfUsSTqxYb4B8Ajwm1X1V0leA+xJsrstu7GqPtQ/OMkaem/9Oxf4CeDPkvy9tvhj9F49ux+4P8nOqnp4iL1LkmYwzDcAHgQOtulvJHkEWDbLKhuA7VX1EvBEe4XssTcFTrY3B5JkextrcEjSCMzLOY4kK+m9RvbeVromyQNJtiZZ2mrLgKf6VtvfajPVJUkjMPTgSPIjwGeBd1fV14GbgdcBa+ntkXx4jr5nU5KJJBNTU1NzsUlJ0jSGGhxJTqUXGp+qqj8BqKpnqupoVX0b+EO+ezjqALCib/XlrTZT/XtU1ZaqGq+q8bGxsbn/MZIkYMDgSHLnILXjlge4BXikqn6/r35O37BfBh5q0zuBy5KcnmQVsBq4D7gfWJ1kVZLT6J1A3zlI35KkuTfryfEkrwZ+GDirnYtIW/SjnPg8w5uAdwAPJtnbau8FLk+yFijgSeCdAFW1L8kOeie9jwBXV9XR1sc1wB3AEmBrVe3r8iMlSXPnRFdVvRN4N73LY/fw3eD4OvAfZ1uxqr7YN77frlnW2Qxsnqa+a7b1JEnzZ9bgqKqPAB9J8i+r6qPz1JMkaQEb6D6Oqvpokl8EVvavU1W3DakvSdICNVBwJPkkvUto9wJHW7kAg0OSTjKD3jk+DqypqhpmM5KkhW/Q+zgeAv72MBuRJC0Og+5xnAU8nOQ+4KVjxap6y1C6kiQtWIMGx/uG2YQkafEY9Kqqvxh2I5KkxWHQq6q+Qe8qKoDTgFOB/1NVPzqsxiRJC9OgexyvOTbdnkG1AThvWE1Jkhauzk/HrZ7/Alx0wsGSpB84gx6q+pW+2VfRu6/jW0PpSJK0oA16VdU/65s+Qu+pthvmvBtJ0oI36DmOK4fdiCRpcRj0RU7Lk3wuyaH2+WyS5cNuTpK08Ax6cvwT9N669xPt819bTZJ0khk0OMaq6hNVdaR9bgVmfbF3khVJ7k7ycJJ9Sd7V6mcm2Z3ksfZ3aasnyU1JJpM8kOQNfdva2MY/lmTj9/lbJUlzYNDgeDbJryVZ0j6/Bjx7gnWOAL9ZVWvo3fNxdZI1wLXAnVW1GrizzQNcTO8946uBTcDN0Asa4HrgjcA64PpjYSNJmn+DBse/AN4OPA0cBN4K/PPZVqiqg1X1V236G8Aj9N5TvgHY1oZtAy5t0xuA29p9IvcAZyQ5h979Irur6nBVPQfsBtYP2LckaY4NGhw3ABuraqyqfpxekLx/0C9JshJ4PXAvcHZVHWyLngbObtPLgKf6VtvfajPVj/+OTUkmkkxMTU0N2pokqaNBg+Pn2//tA1BVh+kFwQkl+RHgs8C7q+rr/cvai6Hm5OVQVbWlqsaranxsbNbTL5KkV2DQ4HhV/3mFdt7hhPeAJDmVXmh8qqr+pJWfaYegaH8PtfoBYEXf6stbbaa6JGkEBg2ODwNfSvKBJB8A/ifwH2ZboT0M8Rbgkar6/b5FO4FjV0ZtBG7vq1/Rrq46D3ihHdK6A7gwydIWXhe2miRpBAa9c/y2JBPA+a30K1X18AlWexPwDuDBJHtb7b3A7wA7klwFfJXeSXeAXcAlwCTwTeDK9t2HW1jd38bd0A6VSZJGYNBnVdGC4kRh0T/+i0BmWHzBNOMLuHqGbW0Ftg763ZKk4en8WHVJ0snN4JAkdWJwSJI6MTgkSZ0YHJKkTgwOSVInBockqRODQ5LUicEhSerE4JAkdWJwSJI6MTgkSZ0YHJKkTgwOSVInBockqZOhBUeSrUkOJXmor/a+JAeS7G2fS/qWXZdkMsmjSS7qq69vtckk1w6rX0nSYIa5x3ErsH6a+o1VtbZ9dgEkWQNcBpzb1vl4kiVJlgAfAy4G1gCXt7GSpBEZ+A2AXVXVF5KsHHD4BmB7Vb0EPJFkEljXlk1W1eMASba3sQO/iVCSNLdGcY7jmiQPtENZS1ttGfBU35j9rTZTXZI0IvMdHDcDrwPWAgeBD8/VhpNsSjKRZGJqamquNitJOs68BkdVPVNVR6vq28Af8t3DUQeAFX1Dl7faTPXptr2lqsaranxsbGzum5ckAfMcHEnO6Zv9ZeDYFVc7gcuSnJ5kFbAauA+4H1idZFWS0+idQN85nz1Lkr7X0E6OJ/k08GbgrCT7geuBNydZCxTwJPBOgKral2QHvZPeR4Crq+po2841wB3AEmBrVe0bVs+SpBMb5lVVl09TvmWW8ZuBzdPUdwG75rA1SdIr4J3jkqRODA5JUicGhySpE4NDktSJwSFJ6sTgkCR1YnBIkjoxOCRJnRgckqRODA5JUicGhySpE4NDktSJwSFJ6sTgkCR1YnBIkjoxOCRJnQwtOJJsTXIoyUN9tTOT7E7yWPu7tNWT5KYkk0keSPKGvnU2tvGPJdk4rH4lSYMZ5h7HrcD642rXAndW1WrgzjYPcDG994yvBjYBN0MvaOi9cvaNwDrg+mNhI0kajaEFR1V9ATh8XHkDsK1NbwMu7avfVj33AGckOQe4CNhdVYer6jlgNy8PI0nSPJrvcxxnV9XBNv00cHabXgY81Tduf6vNVJckjcjITo5XVQE1V9tLsinJRJKJqampudqsJOk48x0cz7RDULS/h1r9ALCib9zyVpup/jJVtaWqxqtqfGxsbM4blyT1zHdw7ASOXRm1Ebi9r35Fu7rqPOCFdkjrDuDCJEvbSfELW02SNCKnDGvDST4NvBk4K8l+eldH/Q6wI8lVwFeBt7fhu4BLgEngm8CVAFV1OMkHgPvbuBuq6vgT7pKkeTS04Kiqy2dYdME0Ywu4eobtbAW2zmFrkqRXwDvHJUmdGBySpE4MDklSJwaHJKkTg0OS1InBIUnqxOCQJHVicEiSOjE4JEmdGBySpE4MDklSJwaHJKkTg0OS1InBIUnqxOCQJHVicEiSOhlJcCR5MsmDSfYmmWi1M5PsTvJY+7u01ZPkpiSTSR5I8oZR9CxJ6hnlHsc/rqq1VTXe5q8F7qyq1cCdbR7gYmB1+2wCbp73TiVJ37GQDlVtALa16W3ApX3126rnHuCMJOeMokFJ0uiCo4D/nmRPkk2tdnZVHWzTTwNnt+llwFN96+5vte+RZFOSiSQTU1NTw+pbkk56p4zoe/9RVR1I8uPA7iR/3b+wqipJddlgVW0BtgCMj493WleSNLiR7HFU1YH29xDwOWAd8MyxQ1Dt76E2/ACwom/15a0mSRqBeQ+OJH8ryWuOTQMXAg8BO4GNbdhG4PY2vRO4ol1ddR7wQt8hLUnSPBvFoaqzgc8lOfb9f1RV/y3J/cCOJFcBXwXe3sbvAi4BJoFvAlfOf8uSpGPmPTiq6nHgF6apPwtcME29gKvnoTVJ0gAW0uW4kqRFwOCQJHVicEiSOjE4JEmdGBySpE4MDklSJwaHJKkTg0OS1InBIUnqxOCQJHVicEiSOjE4JEmdGBySpE4MDklSJwaHJKmTRRMcSdYneTTJZJJrR92PJJ2sFkVwJFkCfAy4GFgDXJ5kzWi7kqST06IIDmAdMFlVj1fV/wW2AxtG3JMknZQWS3AsA57qm9/fapKkeTbv7xwfliSbgE1t9sUkj46ynx8wZwFfG3UTC0E+tHHULejl/Pd5zPV5pVv4yUEGLZbgOACs6Jtf3mrfUVVbgC3z2dTJIslEVY2Pug9pOv77nH+L5VDV/cDqJKuSnAZcBuwccU+SdFJaFHscVXUkyTXAHcASYGtV7RtxW5J0UloUwQFQVbuAXaPu4yTlIUAtZP77nGepqlH3IElaRBbLOQ5J0gJhcGhWPupFC1GSrUkOJXlo1L2cjAwOzchHvWgBuxVYP+omTlYGh2bjo160IFXVF4DDo+7jZGVwaDY+6kXSyxgckqRODA7N5oSPepF08jE4NBsf9SLpZQwOzaiqjgDHHvXyCLDDR71oIUjyaeBLwE8n2Z/kqlH3dDLxznFJUifucUiSOjE4JEmdGBySpE4MDklSJwaHJKkTg0MagiTvS/KvR92HNAwGhySpE4NDmgNJrkjyQJKvJPnkcct+Pcn9bdlnk/xwq78tyUOt/oVWOzfJfUn2tu2tHsXvkWbjDYDSK5TkXOBzwC9W1deSnAn8K+DFqvpQktdW1bNt7AeBZ6rqo0keBNZX1YEkZ1TV80k+CtxTVZ9qj3lZUlV/M6rfJk3HPQ7plTsf+M9V9TWAqjr+PRE/m+QvW1D8KnBuq/8P4NYkvw4sabUvAe9N8h7gJw0NLUQGhzR8twLXVNXPAe8HXg1QVb8B/Ft6TyDe0/ZM/gh4C/A3wK4k54+mZWlmBof0yt0FvC3JawHaoap+rwEOJjmV3h4HbdzrqureqvptYApYkeTvAo9X1U3A7cDPz8svkDo4ZdQNSItdVe1Lshn4iyRHgS8DT/YN+XfAvfTC4V56QQLwe+3kd4A7ga8A7wHekeT/AU8D/35efoTUgSfHJUmdeKhKktSJwSFJ6sTgkCR1YnBIkjoxOCRJnRgckqRODA5JUicGhySpk/8P9inKOXV3890AAAAASUVORK5CYII=\n"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#seperate the features & response to feed to algorithms\nX = data.iloc[:,1:23]\ny = data.iloc[:,0]","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check the correlation of the data\ndata.corr()","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"                             class  cap-shape    ...     population   habitat\nclass                     1.000000   0.052951    ...       0.298686  0.217179\ncap-shape                 0.052951   1.000000    ...       0.063413 -0.042221\ncap-surface               0.178446  -0.050454    ...       0.021555  0.163887\ncap-color                -0.031384  -0.048203    ...      -0.144770  0.033925\nbruises                  -0.501530  -0.035374    ...       0.088137 -0.075095\nodor                     -0.093552  -0.021935    ...      -0.043623 -0.026610\ngill-attachment           0.129200   0.078865    ...       0.165575 -0.030304\ngill-spacing             -0.348387   0.013196    ...      -0.529253 -0.154680\ngill-size                 0.540024   0.054050    ...       0.147682  0.161418\ngill-color               -0.530566  -0.006039    ...      -0.034090 -0.202972\nstalk-shape              -0.102019   0.063794    ...       0.087383 -0.269216\nstalk-root               -0.379361   0.030191    ...      -0.306747 -0.007668\nstalk-surface-above-ring -0.334593  -0.030417    ...       0.079604 -0.058076\nstalk-surface-below-ring -0.298801  -0.032591    ...       0.046797 -0.039628\nstalk-color-above-ring   -0.154003  -0.031659    ...      -0.240261  0.042561\nstalk-color-below-ring   -0.146730  -0.030390    ...      -0.242792  0.041594\nveil-type                      NaN        NaN    ...            NaN       NaN\nveil-color                0.145142   0.072560    ...       0.124924 -0.040581\nring-number              -0.214366  -0.106534    ...      -0.242020  0.235835\nring-type                -0.411771  -0.025457    ...       0.211763 -0.212080\nspore-print-color         0.171961  -0.073416    ...      -0.126859  0.185954\npopulation                0.298686   0.063413    ...       1.000000 -0.174529\nhabitat                   0.217179  -0.042221    ...      -0.174529  1.000000\n\n[23 rows x 23 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>cap-shape</th>\n      <th>cap-surface</th>\n      <th>cap-color</th>\n      <th>bruises</th>\n      <th>odor</th>\n      <th>gill-attachment</th>\n      <th>gill-spacing</th>\n      <th>gill-size</th>\n      <th>gill-color</th>\n      <th>stalk-shape</th>\n      <th>stalk-root</th>\n      <th>stalk-surface-above-ring</th>\n      <th>stalk-surface-below-ring</th>\n      <th>stalk-color-above-ring</th>\n      <th>stalk-color-below-ring</th>\n      <th>veil-type</th>\n      <th>veil-color</th>\n      <th>ring-number</th>\n      <th>ring-type</th>\n      <th>spore-print-color</th>\n      <th>population</th>\n      <th>habitat</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>class</th>\n      <td>1.000000</td>\n      <td>0.052951</td>\n      <td>0.178446</td>\n      <td>-0.031384</td>\n      <td>-0.501530</td>\n      <td>-0.093552</td>\n      <td>0.129200</td>\n      <td>-0.348387</td>\n      <td>0.540024</td>\n      <td>-0.530566</td>\n      <td>-0.102019</td>\n      <td>-0.379361</td>\n      <td>-0.334593</td>\n      <td>-0.298801</td>\n      <td>-0.154003</td>\n      <td>-0.146730</td>\n      <td>NaN</td>\n      <td>0.145142</td>\n      <td>-0.214366</td>\n      <td>-0.411771</td>\n      <td>0.171961</td>\n      <td>0.298686</td>\n      <td>0.217179</td>\n    </tr>\n    <tr>\n      <th>cap-shape</th>\n      <td>0.052951</td>\n      <td>1.000000</td>\n      <td>-0.050454</td>\n      <td>-0.048203</td>\n      <td>-0.035374</td>\n      <td>-0.021935</td>\n      <td>0.078865</td>\n      <td>0.013196</td>\n      <td>0.054050</td>\n      <td>-0.006039</td>\n      <td>0.063794</td>\n      <td>0.030191</td>\n      <td>-0.030417</td>\n      <td>-0.032591</td>\n      <td>-0.031659</td>\n      <td>-0.030390</td>\n      <td>NaN</td>\n      <td>0.072560</td>\n      <td>-0.106534</td>\n      <td>-0.025457</td>\n      <td>-0.073416</td>\n      <td>0.063413</td>\n      <td>-0.042221</td>\n    </tr>\n    <tr>\n      <th>cap-surface</th>\n      <td>0.178446</td>\n      <td>-0.050454</td>\n      <td>1.000000</td>\n      <td>-0.019402</td>\n      <td>0.070228</td>\n      <td>0.045233</td>\n      <td>-0.034180</td>\n      <td>-0.282306</td>\n      <td>0.208100</td>\n      <td>-0.161017</td>\n      <td>-0.014123</td>\n      <td>-0.126245</td>\n      <td>0.089090</td>\n      <td>0.107965</td>\n      <td>0.066050</td>\n      <td>0.068885</td>\n      <td>NaN</td>\n      <td>-0.016603</td>\n      <td>-0.026147</td>\n      <td>-0.106407</td>\n      <td>0.230364</td>\n      <td>0.021555</td>\n      <td>0.163887</td>\n    </tr>\n    <tr>\n      <th>cap-color</th>\n      <td>-0.031384</td>\n      <td>-0.048203</td>\n      <td>-0.019402</td>\n      <td>1.000000</td>\n      <td>-0.000764</td>\n      <td>-0.387121</td>\n      <td>0.041436</td>\n      <td>0.144259</td>\n      <td>-0.169464</td>\n      <td>0.084659</td>\n      <td>-0.456496</td>\n      <td>0.321274</td>\n      <td>-0.060837</td>\n      <td>-0.047710</td>\n      <td>0.002364</td>\n      <td>0.008057</td>\n      <td>NaN</td>\n      <td>0.036130</td>\n      <td>-0.005822</td>\n      <td>0.162513</td>\n      <td>-0.293523</td>\n      <td>-0.144770</td>\n      <td>0.033925</td>\n    </tr>\n    <tr>\n      <th>bruises</th>\n      <td>-0.501530</td>\n      <td>-0.035374</td>\n      <td>0.070228</td>\n      <td>-0.000764</td>\n      <td>1.000000</td>\n      <td>-0.061825</td>\n      <td>0.137359</td>\n      <td>-0.299473</td>\n      <td>-0.369596</td>\n      <td>0.527120</td>\n      <td>0.099364</td>\n      <td>0.244188</td>\n      <td>0.460824</td>\n      <td>0.458983</td>\n      <td>0.083538</td>\n      <td>0.092874</td>\n      <td>NaN</td>\n      <td>0.119770</td>\n      <td>0.056788</td>\n      <td>0.692973</td>\n      <td>-0.285008</td>\n      <td>0.088137</td>\n      <td>-0.075095</td>\n    </tr>\n    <tr>\n      <th>odor</th>\n      <td>-0.093552</td>\n      <td>-0.021935</td>\n      <td>0.045233</td>\n      <td>-0.387121</td>\n      <td>-0.061825</td>\n      <td>1.000000</td>\n      <td>-0.059590</td>\n      <td>0.063936</td>\n      <td>0.310495</td>\n      <td>-0.129213</td>\n      <td>0.459766</td>\n      <td>-0.205215</td>\n      <td>0.118617</td>\n      <td>0.061820</td>\n      <td>0.174532</td>\n      <td>0.169407</td>\n      <td>NaN</td>\n      <td>-0.057747</td>\n      <td>0.111905</td>\n      <td>-0.281387</td>\n      <td>0.469055</td>\n      <td>-0.043623</td>\n      <td>-0.026610</td>\n    </tr>\n    <tr>\n      <th>gill-attachment</th>\n      <td>0.129200</td>\n      <td>0.078865</td>\n      <td>-0.034180</td>\n      <td>0.041436</td>\n      <td>0.137359</td>\n      <td>-0.059590</td>\n      <td>1.000000</td>\n      <td>0.071489</td>\n      <td>0.108984</td>\n      <td>-0.128567</td>\n      <td>0.186485</td>\n      <td>0.144063</td>\n      <td>-0.088916</td>\n      <td>-0.116177</td>\n      <td>0.099299</td>\n      <td>0.097160</td>\n      <td>NaN</td>\n      <td>0.897518</td>\n      <td>0.093236</td>\n      <td>-0.146689</td>\n      <td>-0.029524</td>\n      <td>0.165575</td>\n      <td>-0.030304</td>\n    </tr>\n    <tr>\n      <th>gill-spacing</th>\n      <td>-0.348387</td>\n      <td>0.013196</td>\n      <td>-0.282306</td>\n      <td>0.144259</td>\n      <td>-0.299473</td>\n      <td>0.063936</td>\n      <td>0.071489</td>\n      <td>1.000000</td>\n      <td>-0.108333</td>\n      <td>0.100193</td>\n      <td>0.080895</td>\n      <td>0.350548</td>\n      <td>-0.212359</td>\n      <td>-0.213775</td>\n      <td>0.274574</td>\n      <td>0.253505</td>\n      <td>NaN</td>\n      <td>0.073363</td>\n      <td>0.243014</td>\n      <td>-0.195897</td>\n      <td>0.047323</td>\n      <td>-0.529253</td>\n      <td>-0.154680</td>\n    </tr>\n    <tr>\n      <th>gill-size</th>\n      <td>0.540024</td>\n      <td>0.054050</td>\n      <td>0.208100</td>\n      <td>-0.169464</td>\n      <td>-0.369596</td>\n      <td>0.310495</td>\n      <td>0.108984</td>\n      <td>-0.108333</td>\n      <td>1.000000</td>\n      <td>-0.516736</td>\n      <td>0.214576</td>\n      <td>-0.344345</td>\n      <td>0.056310</td>\n      <td>0.010894</td>\n      <td>0.296548</td>\n      <td>0.278708</td>\n      <td>NaN</td>\n      <td>0.103809</td>\n      <td>-0.171362</td>\n      <td>-0.460872</td>\n      <td>0.622991</td>\n      <td>0.147682</td>\n      <td>0.161418</td>\n    </tr>\n    <tr>\n      <th>gill-color</th>\n      <td>-0.530566</td>\n      <td>-0.006039</td>\n      <td>-0.161017</td>\n      <td>0.084659</td>\n      <td>0.527120</td>\n      <td>-0.129213</td>\n      <td>-0.128567</td>\n      <td>0.100193</td>\n      <td>-0.516736</td>\n      <td>1.000000</td>\n      <td>-0.175699</td>\n      <td>0.315080</td>\n      <td>0.224287</td>\n      <td>0.257224</td>\n      <td>-0.058299</td>\n      <td>-0.074781</td>\n      <td>NaN</td>\n      <td>-0.097583</td>\n      <td>0.096054</td>\n      <td>0.629398</td>\n      <td>-0.416135</td>\n      <td>-0.034090</td>\n      <td>-0.202972</td>\n    </tr>\n    <tr>\n      <th>stalk-shape</th>\n      <td>-0.102019</td>\n      <td>0.063794</td>\n      <td>-0.014123</td>\n      <td>-0.456496</td>\n      <td>0.099364</td>\n      <td>0.459766</td>\n      <td>0.186485</td>\n      <td>0.080895</td>\n      <td>0.214576</td>\n      <td>-0.175699</td>\n      <td>1.000000</td>\n      <td>-0.163422</td>\n      <td>0.015193</td>\n      <td>-0.034399</td>\n      <td>0.223439</td>\n      <td>0.235794</td>\n      <td>NaN</td>\n      <td>0.162604</td>\n      <td>-0.293221</td>\n      <td>-0.291444</td>\n      <td>0.258831</td>\n      <td>0.087383</td>\n      <td>-0.269216</td>\n    </tr>\n    <tr>\n      <th>stalk-root</th>\n      <td>-0.379361</td>\n      <td>0.030191</td>\n      <td>-0.126245</td>\n      <td>0.321274</td>\n      <td>0.244188</td>\n      <td>-0.205215</td>\n      <td>0.144063</td>\n      <td>0.350548</td>\n      <td>-0.344345</td>\n      <td>0.315080</td>\n      <td>-0.163422</td>\n      <td>1.000000</td>\n      <td>-0.027065</td>\n      <td>0.087454</td>\n      <td>0.157140</td>\n      <td>0.159805</td>\n      <td>NaN</td>\n      <td>0.156213</td>\n      <td>-0.247357</td>\n      <td>0.210155</td>\n      <td>-0.536996</td>\n      <td>-0.306747</td>\n      <td>-0.007668</td>\n    </tr>\n    <tr>\n      <th>stalk-surface-above-ring</th>\n      <td>-0.334593</td>\n      <td>-0.030417</td>\n      <td>0.089090</td>\n      <td>-0.060837</td>\n      <td>0.460824</td>\n      <td>0.118617</td>\n      <td>-0.088916</td>\n      <td>-0.212359</td>\n      <td>0.056310</td>\n      <td>0.224287</td>\n      <td>0.015193</td>\n      <td>-0.027065</td>\n      <td>1.000000</td>\n      <td>0.437164</td>\n      <td>0.132708</td>\n      <td>0.142835</td>\n      <td>NaN</td>\n      <td>-0.090591</td>\n      <td>0.107904</td>\n      <td>0.390091</td>\n      <td>0.100764</td>\n      <td>0.079604</td>\n      <td>-0.058076</td>\n    </tr>\n    <tr>\n      <th>stalk-surface-below-ring</th>\n      <td>-0.298801</td>\n      <td>-0.032591</td>\n      <td>0.107965</td>\n      <td>-0.047710</td>\n      <td>0.458983</td>\n      <td>0.061820</td>\n      <td>-0.116177</td>\n      <td>-0.213775</td>\n      <td>0.010894</td>\n      <td>0.257224</td>\n      <td>-0.034399</td>\n      <td>0.087454</td>\n      <td>0.437164</td>\n      <td>1.000000</td>\n      <td>0.106933</td>\n      <td>0.110656</td>\n      <td>NaN</td>\n      <td>-0.077284</td>\n      <td>0.040006</td>\n      <td>0.394644</td>\n      <td>0.130974</td>\n      <td>0.046797</td>\n      <td>-0.039628</td>\n    </tr>\n    <tr>\n      <th>stalk-color-above-ring</th>\n      <td>-0.154003</td>\n      <td>-0.031659</td>\n      <td>0.066050</td>\n      <td>0.002364</td>\n      <td>0.083538</td>\n      <td>0.174532</td>\n      <td>0.099299</td>\n      <td>0.274574</td>\n      <td>0.296548</td>\n      <td>-0.058299</td>\n      <td>0.223439</td>\n      <td>0.157140</td>\n      <td>0.132708</td>\n      <td>0.106933</td>\n      <td>1.000000</td>\n      <td>0.491510</td>\n      <td>NaN</td>\n      <td>0.067377</td>\n      <td>0.084917</td>\n      <td>-0.048878</td>\n      <td>0.271533</td>\n      <td>-0.240261</td>\n      <td>0.042561</td>\n    </tr>\n    <tr>\n      <th>stalk-color-below-ring</th>\n      <td>-0.146730</td>\n      <td>-0.030390</td>\n      <td>0.068885</td>\n      <td>0.008057</td>\n      <td>0.092874</td>\n      <td>0.169407</td>\n      <td>0.097160</td>\n      <td>0.253505</td>\n      <td>0.278708</td>\n      <td>-0.074781</td>\n      <td>0.235794</td>\n      <td>0.159805</td>\n      <td>0.142835</td>\n      <td>0.110656</td>\n      <td>0.491510</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>0.065567</td>\n      <td>0.087580</td>\n      <td>-0.034284</td>\n      <td>0.254518</td>\n      <td>-0.242792</td>\n      <td>0.041594</td>\n    </tr>\n    <tr>\n      <th>veil-type</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>veil-color</th>\n      <td>0.145142</td>\n      <td>0.072560</td>\n      <td>-0.016603</td>\n      <td>0.036130</td>\n      <td>0.119770</td>\n      <td>-0.057747</td>\n      <td>0.897518</td>\n      <td>0.073363</td>\n      <td>0.103809</td>\n      <td>-0.097583</td>\n      <td>0.162604</td>\n      <td>0.156213</td>\n      <td>-0.090591</td>\n      <td>-0.077284</td>\n      <td>0.067377</td>\n      <td>0.065567</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>0.036380</td>\n      <td>-0.143673</td>\n      <td>-0.003600</td>\n      <td>0.124924</td>\n      <td>-0.040581</td>\n    </tr>\n    <tr>\n      <th>ring-number</th>\n      <td>-0.214366</td>\n      <td>-0.106534</td>\n      <td>-0.026147</td>\n      <td>-0.005822</td>\n      <td>0.056788</td>\n      <td>0.111905</td>\n      <td>0.093236</td>\n      <td>0.243014</td>\n      <td>-0.171362</td>\n      <td>0.096054</td>\n      <td>-0.293221</td>\n      <td>-0.247357</td>\n      <td>0.107904</td>\n      <td>0.040006</td>\n      <td>0.084917</td>\n      <td>0.087580</td>\n      <td>NaN</td>\n      <td>0.036380</td>\n      <td>1.000000</td>\n      <td>0.058312</td>\n      <td>0.338417</td>\n      <td>-0.242020</td>\n      <td>0.235835</td>\n    </tr>\n    <tr>\n      <th>ring-type</th>\n      <td>-0.411771</td>\n      <td>-0.025457</td>\n      <td>-0.106407</td>\n      <td>0.162513</td>\n      <td>0.692973</td>\n      <td>-0.281387</td>\n      <td>-0.146689</td>\n      <td>-0.195897</td>\n      <td>-0.460872</td>\n      <td>0.629398</td>\n      <td>-0.291444</td>\n      <td>0.210155</td>\n      <td>0.390091</td>\n      <td>0.394644</td>\n      <td>-0.048878</td>\n      <td>-0.034284</td>\n      <td>NaN</td>\n      <td>-0.143673</td>\n      <td>0.058312</td>\n      <td>1.000000</td>\n      <td>-0.487048</td>\n      <td>0.211763</td>\n      <td>-0.212080</td>\n    </tr>\n    <tr>\n      <th>spore-print-color</th>\n      <td>0.171961</td>\n      <td>-0.073416</td>\n      <td>0.230364</td>\n      <td>-0.293523</td>\n      <td>-0.285008</td>\n      <td>0.469055</td>\n      <td>-0.029524</td>\n      <td>0.047323</td>\n      <td>0.622991</td>\n      <td>-0.416135</td>\n      <td>0.258831</td>\n      <td>-0.536996</td>\n      <td>0.100764</td>\n      <td>0.130974</td>\n      <td>0.271533</td>\n      <td>0.254518</td>\n      <td>NaN</td>\n      <td>-0.003600</td>\n      <td>0.338417</td>\n      <td>-0.487048</td>\n      <td>1.000000</td>\n      <td>-0.126859</td>\n      <td>0.185954</td>\n    </tr>\n    <tr>\n      <th>population</th>\n      <td>0.298686</td>\n      <td>0.063413</td>\n      <td>0.021555</td>\n      <td>-0.144770</td>\n      <td>0.088137</td>\n      <td>-0.043623</td>\n      <td>0.165575</td>\n      <td>-0.529253</td>\n      <td>0.147682</td>\n      <td>-0.034090</td>\n      <td>0.087383</td>\n      <td>-0.306747</td>\n      <td>0.079604</td>\n      <td>0.046797</td>\n      <td>-0.240261</td>\n      <td>-0.242792</td>\n      <td>NaN</td>\n      <td>0.124924</td>\n      <td>-0.242020</td>\n      <td>0.211763</td>\n      <td>-0.126859</td>\n      <td>1.000000</td>\n      <td>-0.174529</td>\n    </tr>\n    <tr>\n      <th>habitat</th>\n      <td>0.217179</td>\n      <td>-0.042221</td>\n      <td>0.163887</td>\n      <td>0.033925</td>\n      <td>-0.075095</td>\n      <td>-0.026610</td>\n      <td>-0.030304</td>\n      <td>-0.154680</td>\n      <td>0.161418</td>\n      <td>-0.202972</td>\n      <td>-0.269216</td>\n      <td>-0.007668</td>\n      <td>-0.058076</td>\n      <td>-0.039628</td>\n      <td>0.042561</td>\n      <td>0.041594</td>\n      <td>NaN</td>\n      <td>-0.040581</td>\n      <td>0.235835</td>\n      <td>-0.212080</td>\n      <td>0.185954</td>\n      <td>-0.174529</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Many algorithms are sensitive to the scale of Features. It's better to standardize the data before we feed it to algos."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX=scaler.fit_transform(X)\nX","execution_count":12,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n  return self.partial_fit(X, y)\n/opt/conda/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n  return self.fit(X, **fit_params).transform(X)\n","name":"stderr"},{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"array([[ 1.02971224,  0.14012794, -0.19824983, ..., -0.67019486,\n        -0.5143892 ,  2.03002809],\n       [ 1.02971224,  0.14012794,  1.76587407, ..., -0.2504706 ,\n        -1.31310821, -0.29572966],\n       [-2.08704716,  0.14012794,  1.37304929, ..., -0.2504706 ,\n        -1.31310821,  0.86714922],\n       ...,\n       [-0.8403434 ,  0.14012794, -0.19824983, ..., -1.50964337,\n        -2.11182722,  0.28570978],\n       [-0.21699152,  0.95327039, -0.19824983, ...,  1.42842641,\n         0.28432981,  0.28570978],\n       [ 1.02971224,  0.14012794, -0.19824983, ...,  0.16925365,\n        -2.11182722,  0.28570978]])"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"split the data into training & test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2, random_state=42)","execution_count":13,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"![](http://)**1. Training Default Logistic Regression Model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression()\nlogreg.fit(X_train,y_train)","execution_count":14,"outputs":[{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='warn',\n          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n          tol=0.0001, verbose=0, warm_start=False)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\ny_pred = logreg.predict(X_test)\nprint(accuracy_score(y_test,y_pred))","execution_count":15,"outputs":[{"output_type":"stream","text":"0.9513846153846154\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"we got 95% accuracy with default Logistic Regression Model. Let's perform PCA on the data & see if that improves the accuracy score"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\npca = PCA(n_components=17)\npca.fit_transform(X)","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"array([[-0.5743219 , -0.97578135, -1.22176154, ..., -0.51996599,\n        -0.78254366,  1.12025933],\n       [-2.2821023 ,  0.27906633, -1.20049669, ..., -0.11307822,\n        -0.73093408, -0.01817413],\n       [-1.85803562, -0.27097236, -1.37237069, ...,  0.01652548,\n        -0.6561675 ,  0.10791396],\n       ...,\n       [-1.62151632, -0.75753671,  2.73357994, ..., -0.51961303,\n        -0.70768708,  0.22578534],\n       [ 3.67060561, -1.0327745 ,  0.1684595 , ..., -0.08688401,\n        -0.11464249, -0.14801392],\n       [-1.57520272, -1.2285814 ,  2.44722789, ...,  0.91606764,\n        -0.77988482, -0.30141893]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#split the data into training & test set based on PCA data\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2, random_state=42)","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg1 = LogisticRegression()\nlogreg1.fit(X_train,y_train)\ny_pred1 = logreg1.predict(X_test)\n\nprint(accuracy_score(y_test,y_pred1))","execution_count":18,"outputs":[{"output_type":"stream","text":"0.9513846153846154\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"so PCA does not have any effect on Logistict Regression model.\n**Let's fine tune the Model by changing its hyperparameters**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\n\nLR_model = LogisticRegression()\n\ntuned_parameters = {'C':[0.001, 0.01, 0.1, 1, 10, 100, 1000], 'penalty':['l1','l2']}","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\ngrid_search = GridSearchCV(LR_model,tuned_parameters, cv=10)\n\ngrid_search.fit(X_train, y_train)","execution_count":20,"outputs":[{"output_type":"execute_result","execution_count":20,"data":{"text/plain":"GridSearchCV(cv=10, error_score='raise-deprecating',\n       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='warn',\n          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n          tol=0.0001, verbose=0, warm_start=False),\n       fit_params=None, iid='warn', n_jobs=None,\n       param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'penalty': ['l1', 'l2']},\n       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n       scoring=None, verbose=0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(grid_search.best_params_)","execution_count":21,"outputs":[{"output_type":"stream","text":"{'C': 1000, 'penalty': 'l2'}\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"LR_model = LogisticRegression(C=1000, penalty='l1')\nLR_model.fit(X_train,y_train)\n\ny_train_pred = LR_model.predict(X_train)\nprint('accuracy on Train data',accuracy_score(y_train,y_train_pred))\n\ny_pred = LR_model.predict(X_test)\nprint('accuracy on Test data',accuracy_score(y_test,y_pred))","execution_count":22,"outputs":[{"output_type":"stream","text":"accuracy on Train data 0.9679950761655639\naccuracy on Test data 0.9661538461538461\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"**so we have got an accuracy of 96% with Fine Tuned Logistic Regression**\n\nLet's see some other models now"},{"metadata":{},"cell_type":"markdown","source":"**Gaussian Naive Bayes**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nGNB_model = GaussianNB()\n\nGNB_model.fit(X_train, y_train)","execution_count":23,"outputs":[{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"GaussianNB(priors=None, var_smoothing=1e-09)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = GNB_model.predict(X_test)\n\nprint(accuracy_score(y_test,y_pred))\nGNB_model.score(X_test,y_pred)","execution_count":24,"outputs":[{"output_type":"stream","text":"0.9218461538461539\n","name":"stdout"},{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"1.0"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Gaussian Naive Bayes model has 92% accuracy which is less than Logistic Regression Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of mislabeled points from %d points : %d\"\n      % (X_test.shape[0],(y_test!= y_pred).sum()))","execution_count":25,"outputs":[{"output_type":"stream","text":"Number of mislabeled points from 1625 points : 127\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"**Support Vector Machines**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nsvc_model = SVC()\n\nparams = {\n    'C':[1, 10, 100,500, 1000], 'kernel':['linear','rbf'],\n    'C': [1, 10, 100,500, 1000], 'gamma': [1,0.1,0.01,0.001, 0.0001], 'kernel': ['rbf'],\n}","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\nrnd_search = RandomizedSearchCV(svc_model,params,cv=10,scoring='accuracy',n_iter=20)\nrnd_search.fit(X_train, y_train)","execution_count":27,"outputs":[{"output_type":"execute_result","execution_count":27,"data":{"text/plain":"RandomizedSearchCV(cv=10, error_score='raise-deprecating',\n          estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n  shrinking=True, tol=0.001, verbose=False),\n          fit_params=None, iid='warn', n_iter=20, n_jobs=None,\n          param_distributions={'C': [1, 10, 100, 500, 1000], 'kernel': ['rbf'], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001]},\n          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n          return_train_score='warn', scoring='accuracy', verbose=0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(rnd_search.best_score_)","execution_count":28,"outputs":[{"output_type":"stream","text":"1.0\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred = rnd_search.predict(X_train)\nprint('accuracy on Train data',accuracy_score(y_train,y_train_pred))\ny_pred = rnd_search.predict(X_test)\nprint('accuracy on Test data',accuracy_score(y_test,y_pred))","execution_count":29,"outputs":[{"output_type":"stream","text":"accuracy on Train data 1.0\naccuracy on Test data 1.0\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"**We have got 100% accuracy using this SVM model**\n\nLet's see its precision, recall,f1score,roc_auc_scores to confirm it classifies perfectly"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix = metrics.confusion_matrix(y_test,y_pred)\nconfusion_matrix","execution_count":31,"outputs":[{"output_type":"execute_result","execution_count":31,"data":{"text/plain":"array([[843,   0],\n       [  0, 782]])"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"False Positive Rate, False Negative Rate are 0 which means it predicts/classified perfectly.\n\nTrue Positive rate = 843 (which means there are 843 observations with Class = 0, posionous)\nTrue Negative rate = 782 (which means there are 782 observations with Class = 1, edible)\n\ncheck the same below"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test.value_counts()","execution_count":32,"outputs":[{"output_type":"execute_result","execution_count":32,"data":{"text/plain":"0    843\n1    782\nName: class, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"auc_roc = metrics.classification_report(y_test,y_pred)\nauc_roc","execution_count":33,"outputs":[{"output_type":"execute_result","execution_count":33,"data":{"text/plain":"'              precision    recall  f1-score   support\\n\\n           0       1.00      1.00      1.00       843\\n           1       1.00      1.00      1.00       782\\n\\n   micro avg       1.00      1.00      1.00      1625\\n   macro avg       1.00      1.00      1.00      1625\\nweighted avg       1.00      1.00      1.00      1625\\n'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics.roc_auc_score(y_test,y_pred)","execution_count":34,"outputs":[{"output_type":"execute_result","execution_count":34,"data":{"text/plain":"1.0"},"metadata":{}}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}