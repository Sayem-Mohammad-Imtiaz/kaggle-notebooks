{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train=pd.read_csv(\"/kaggle/input/students-performance-in-exams/StudentsPerformance.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#First and Last five rows\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.tail(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Size of the dataset\nprint(\"The size of the dataset is\",train.size)\n#Shape of the dataset\nprint(\"The shape of the dataset is\",train.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Describing the dataset for numerical value\ntrain.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#describing data for categorical value\nlis=['gender','race/ethnicity','parental level of education','lunch','test preparation course']\nfor i in lis:\n    print(train[i].describe())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Unique value counts(ignoring null values) in each column, useful for categorical varaible, not required for continuous variable\ntrain.nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Null value detection\ntrain.isnull().any()\n#No null value in any of the features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Outliers will be present for continuous variable, and we can visualize it with boxplot\nimport seaborn as sns\nprint(sns.boxplot(x=train['math score']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(sns.boxplot(x=train['reading score']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(sns.boxplot(x=train['writing score']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#We can clearly see the two lines depict Q3 and Q1 and we can see in all three boxplots, outliers lies before Q1.\nq1_math=train['math score'].quantile(0.25)\nq3_math=train['math score'].quantile(0.75)\niqr_math=q3_math-q1_math\nprint(\"IQR of Math Score\",iqr_math)\nq1_reading=train['reading score'].quantile(0.25)\nq3_reading=train['reading score'].quantile(0.75)\niqr_reading=q3_reading-q1_reading\nprint(\"IQR of Reading Score\",iqr_reading)\nq1_writing=train['writing score'].quantile(0.25)\nq3_writing=train['writing score'].quantile(0.75)\niqr_writing=q3_writing-q1_writing\nprint(\"IQR of Writing Score\",iqr_writing)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Outlier based on IQR is where data lies behind or ahead of 1.5 times of IQR.\nfor i in train['math score']:\n    if ((i<(q1_math-(1.5*iqr_math)))==True):\n        print(i)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Outliers in Reading Score column\nfor i in train['reading score']:\n    if ((i<(q1_reading-(1.5*iqr_reading)))==True):\n        print(i)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Outliers in Writing Score column\nfor i in train['writing score']:\n    if ((i<(q1_writing-(1.5*iqr_writing)))==True):\n        print(i)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Data Normalisation on 'Reading Score' and 'Writing Score'\nfrom sklearn import preprocessing\nread=np.array(train['reading score'])\nnorm_read=preprocessing.normalize([read])\nprint(norm_read)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"write=np.array(train['writing score'])\nnorm_write=preprocessing.normalize([write])\nprint(norm_write)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_num=train['math score']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Since corelation is available for only continuous variable, we are separating these from original dataset\ntrain_num=pd.concat([train_num,train['reading score'],train['writing score']],axis=1)\ntrain_num","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Corelation for the varaibles\ncorrelation=train_num.corr()\ncorrelation","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualising Heatmap\nsns.heatmap(correlation,annot=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#For continuous variable\nsns.pairplot(train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#relplot for math score and reading score based upon gender\nsns.relplot(data=train, x=\"math score\", y=\"reading score\", hue=\"gender\")\n#Similarly we can make for whatever we want","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#For continuous variable of the dataset\nsns.displot(train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pima=pd.read_csv(\"/kaggle/input/pima-indians-diabetes-database/diabetes.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pima.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Standard Scaler\nfrom sklearn.preprocessing import StandardScaler,Binarizer,LabelEncoder\n#For Pima datasets\nscaler=StandardScaler().fit(pima)\npima_scaled=scaler.transform(pima)\n#Standardized Version of Pima Datasets\npima_scaled","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Function for Binarizing the feature values of Pima Dataset\ndef binarize(b):\n    a=pima[b].values\n    a_mean=a.mean()\n    print(a_mean)\n    a_shape=a.reshape(-1,1)\n    #Command for binarizing variable keeping the mean of the particular feature as the threshold\n    a_bin=Binarizer(a_mean)\n    pima[b]=a_bin.fit_transform(a_shape)\n    return pima[b]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Example for the glucose feature where we can see the datapoints are binarized as 0 and 1 with respective to the threshold.\nbinarize('Glucose')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#We can see clearly see in the Dataset the Glucose feature is binarized\npima.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Now for every features we can produce a binarized variable for pima datasets\nColumn=pima.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#We neglected the target value and Glucose feature and found for ather features\nfor i in range(1,8):\n    binarize(Column[i])\n#We can clearly see the mean values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Complete binarized pima dataset\npima.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Label Encoding Student Dataset's Categorical variable\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Function for encoding the feature values of Students Dataset\ndef encode(c):\n    d=train[c]\n    d_enc=LabelEncoder()\n    train[c]=d_enc.fit_transform(d)\n    return train[c]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Example for the gender feature where we can see the male and female are labeled as 1 and 0 respectively\nencode('gender')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Column1=train.columns\n#Similarly for all the other categorical variable we can see the respective labelled version\nfor i in range(1,5):\n    encode(Column1[i])\n#Labelled Version of Students Dataset.\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}