{"cells":[{"metadata":{"_uuid":"4619becab8e530ef9e5f353394b6ee61a1a8a3c9"},"cell_type":"markdown","source":"<h1> Exam results analysis and classification </h1>\n<h3> import basic libraries and load the dataset </h3>"},{"metadata":{"trusted":true,"_uuid":"66d04f483caa20b8912be8a3a5646fe0adae5093"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndata = pd.read_csv('../input/StudentsPerformance.csv')\ndata.head(6)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c605f22f21359fc0734792a7e42ab76a56388165"},"cell_type":"markdown","source":"<h3>Check dataset size and describe the numeric variables </h3>"},{"metadata":{"trusted":true,"_uuid":"9c5f7cbf9e5827063c43776aa9e10667947e0ddc"},"cell_type":"code","source":"print(data.shape)\nprint(data.describe())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5d4a5ec66a88e62153213849cb249e090357301d"},"cell_type":"markdown","source":"<h3>Call a pairplot to get the correlation between the numeric variables - math, reading and writing scores </h3> "},{"metadata":{"trusted":true,"_uuid":"ef1a7b62ee40bbce09321c4b91afdea1c54da178"},"cell_type":"code","source":"sns.pairplot(data[['math score', 'reading score', 'writing score']], height = 4)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eb6bbc40308477ad8e0b0a5041e0edcb005bd437"},"cell_type":"markdown","source":"<h3> add columns for grade marks for each exam:  </h3>\n<h5> >90 = A, >80 = B, >70 = C, >60 = D, >50 = E, <=50 = F </h5>"},{"metadata":{"trusted":true,"_uuid":"223c7d9b55fcdc00b3c9636a11ecec61596755f0"},"cell_type":"code","source":"def ScoreMark(score):\n    if ( score > 90 ):\n        mark = 'A'\n    elif ( score > 80):\n        mark = 'B'\n    elif ( score > 70):\n        mark = 'C'\n    elif ( score > 60):\n        mark = 'D'\n    elif ( score > 50):\n        mark = 'E'\n    else: \n        mark = 'F'\n    return mark\n\ndata['math mark'] = data['math score'].apply(lambda s: ScoreMark(s))\ndata['reading mark'] = data['reading score'].apply(lambda s: ScoreMark(s))\ndata['writing mark'] = data['writing score'].apply(lambda s: ScoreMark(s))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8cfae01d782ca2c68544004254383cf82fcfdd6d"},"cell_type":"markdown","source":"<h3> Plot histograms for the exam scores and marks </h3>"},{"metadata":{"trusted":true,"_uuid":"88a1ae197cd43725d56b3233a387fd16a5e2a46a"},"cell_type":"code","source":"\nfigure = plt.figure(figsize=(16,4))\nn = 1\nfor i in ['math score', 'reading score', 'writing score']:\n    ax = figure.add_subplot(1, 3, n)\n    ax.set_title(i)\n    data[i].hist()\n    n = n + 1\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4348bdb5102304133991d4baa74c5344ecfca00d"},"cell_type":"code","source":"figure = plt.figure(figsize=(16,4))\nn = 1\nfor i in ['math mark', 'reading mark', 'writing mark']:\n    ax = figure.add_subplot(1, 3, n)\n    ax.set_title(i)\n    data[i].value_counts().sort_index().plot(kind=\"bar\")\n    n = n + 1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d984096855310108a8ca599fc64e022cb8fbecae"},"cell_type":"markdown","source":"<h3> Define Boxplot function, to plot all three exam scores for different variables, check median and quartiles of the scores. </h3>"},{"metadata":{"trusted":true,"_uuid":"3b9fc3793ad312e0d60ed74be1e3d5d06bbafeac"},"cell_type":"code","source":"def boxpl(dt, x_cols, y_cols):\n    n = 1\n    x_cnt = len(x_cols)\n    y_cnt = len(y_cols)\n    figure = plt.figure(figsize=(17, 5 * x_cnt))\n    for x_ax in x_cols:\n        for i in y_cols:\n            ax = figure.add_subplot(x_cnt, y_cnt, n)\n            #ax.set_title(i)\n            g = sns.boxplot(x = dt[x_ax], y = dt[i])\n            g.set_xticklabels(g.get_xticklabels(), rotation=20)\n            n = n + 1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bb47eccc21601dae218f8e685bfe1252435601b0"},"cell_type":"markdown","source":"<h3> Check exam score quartiles allocation for gender and race </h3>"},{"metadata":{"trusted":true,"_uuid":"4cd4d519ec09b8484c0f5ed185767c7c590ec37e"},"cell_type":"code","source":"y_cols = ['math score', 'reading score', 'writing score']\nx_cols = ['gender', 'race/ethnicity']\nboxpl(data, x_cols, y_cols)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d7edd12ba0f00770ddbefd85bb45da54388594bc"},"cell_type":"markdown","source":"<h3> Check exam score quartiles allocation for test preparation course and lunch variables </h3>"},{"metadata":{"trusted":true,"_uuid":"74a27068dbad8d8e0681acd2affb0647a0157737"},"cell_type":"code","source":"y_cols = ['math score', 'reading score', 'writing score']\nx_cols = ['test preparation course', 'lunch']\nboxpl(data, x_cols, y_cols)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"98cdd30f72a831e6bc462b1e5b58f87d0b0b8c83"},"cell_type":"markdown","source":"<h3> Check Score quartiles allocation for parental level of education </h3>"},{"metadata":{"trusted":true,"_uuid":"0c1f9dd2ea2af8e54a7dfa73ab5b861e60e1efd6"},"cell_type":"code","source":"y_cols = ['math score', 'reading score', 'writing score']\nx_cols = [ 'parental level of education']\nboxpl(data, x_cols, y_cols)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"13ea1785f25308cd4ea5ac384eb371b051ad607e"},"cell_type":"markdown","source":"<h3> Define function that takes a grade mark and returns the number of students that have the given grade for each exam. </h3>"},{"metadata":{"trusted":true,"_uuid":"1a7b0526e1ad4924adb22b58ce09f394426ee567"},"cell_type":"code","source":"def getMarkData(dt, marks):\n    subDt = dt[(dt['math mark'].isin(marks)) | (dt['reading mark'].isin(marks)) | (dt['writing mark'].isin(marks))]\n    return subDt\n    \ndef MarkCounts(dt, marks):\n    subDt = getMarkData(dt, marks)\n    print('Math: ' + str(subDt[subDt['math mark'].isin(marks)].shape[0])\n      , '\\n'\n      , 'Writing: ' + str(subDt[subDt['writing mark'].isin(marks)].shape[0])\n      , '\\n'\n      , 'Reading: ' + str(subDt[subDt['reading mark'].isin(marks)].shape[0])\n      , '\\n'\n      , '\\n'\n      , 'Math and Reading: ' + str(subDt[(subDt['math mark'].isin(marks)) & (subDt['reading mark'].isin(marks))].shape[0])\n      , '\\n'\n      , 'Math and Writing: ' + str(subDt[(subDt['math mark'].isin(marks)) & (subDt['writing mark'].isin(marks))].shape[0])\n      , '\\n'\n      ,'Reading and Writing: ' + str(subDt[(subDt['reading mark'].isin(marks)) & (subDt['writing mark'].isin(marks))].shape[0])\n      , '\\n'\n      , '\\n',\n      'All: '+str(subDt[(subDt['math mark'].isin(marks))&(subDt['reading mark'].isin(marks))&(subDt['writing mark'].isin(marks))].shape[0])\n     )\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"815a1b7a734077ea0ebffb9a6a65171e6b442d3a"},"cell_type":"markdown","source":"<h3> Get number of students that have Failed (F), and number of students that have distinction results (A) in the exams. </h3>"},{"metadata":{"trusted":true,"_uuid":"6686dae5d0162088dcd3351d71541932e62aee10"},"cell_type":"code","source":"print('F')\nMarkCounts(data, ['F'])\nprint('\\n A')\nMarkCounts(data, ['A'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"34646c296562e8997a387827e603264ede1a1e0b"},"cell_type":"markdown","source":"<h2> Add relative rations per variable </h2> <h5>(for example, exam grades for females in total will give 1, and the number on plot will be percentage of females that have got the particular exam mark)</h5>\n<h3>\nPlot heatmap with math, reading and writing marks on x axis, and different variables on y axis, and showing the relative percentage of students that got the given score within the y variable value.\n</h3>\n<h4>\nPlot shows students of which of the variable values are getting better grades, and which of the variable values are getting less grades or even fail. </h4>\n"},{"metadata":{"trusted":true,"_uuid":"c1b26847e99173590c1cdd0b6246a1b2f8a1da8f"},"cell_type":"code","source":"# Relative ratios have been added.\n\nfigure = plt.figure(figsize=(18,20))\nn = 1\nfor k in ['gender', 'race/ethnicity', 'parental level of education', 'lunch', 'test preparation course']:\n    for i in ['math mark', 'reading mark', 'writing mark']:\n        tab = pd.crosstab(data[k], data[i])\n        tab['total'] = (tab['A'] + tab['B'] + tab['C'] + tab['D'] + tab['E'] + tab['F'])        \n        tab['A'] = round(tab['A'] / tab['total'], 2)\n        tab['B'] = round(tab['B'] / tab['total'], 2)\n        tab['C'] = round(tab['C'] / tab['total'], 2)\n        tab['D'] = round(tab['D'] / tab['total'], 2)\n        tab['E'] = round(tab['E'] / tab['total'], 2)\n        tab['F'] = round(tab['F'] / tab['total'], 2)\n        tab = tab.drop(columns=['total'])\n        ax = figure.add_subplot(5, 3, n)\n        #ax.set_title(i)\n        g = sns.heatmap(tab, annot=True, cmap='Purples', fmt='g')\n        g.set_yticklabels(g.get_yticklabels(), rotation=45)\n        n = n + 1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7d226054830017d545f66b5c5a21253ce692e7f3"},"cell_type":"markdown","source":"<h1> Predicting student exam failures with Classification methods </h1>"},{"metadata":{"_uuid":"d0a024df384707bec60534405bbada34af5901e9"},"cell_type":"markdown","source":"<h3>Import libraries from sklearn</h3>"},{"metadata":{"trusted":true,"_uuid":"6bae4382932b7bd16dffba5b739c16be8f8d25b7"},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm.libsvm import predict_proba\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import roc_curve\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"922849612882b77ff96841713facc30b5ea4b0d3"},"cell_type":"markdown","source":"<h3> modify the label: failed = 1 (if student has failed 1 or more exams) and failed = 0 (if student has not failed any exam) </h3>"},{"metadata":{"trusted":true,"_uuid":"7be610d6fc1e4fd54ba7f289678427dd1acda7f0"},"cell_type":"code","source":"\ndef hasFailed(dt):\n    if ((dt['math mark'] == 'F') | (dt['reading mark'] == 'F') | (dt['writing mark'] == 'F')):\n        return 1\n    else:\n        return 0\ndata['failed'] = data.apply(hasFailed, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"85c311c262e9a40436f7317fec3bc1ea546899c3"},"cell_type":"markdown","source":"<h3> Add one hot encoding: transform textual variables into binaries </h3>"},{"metadata":{"trusted":true,"_uuid":"c92d6d688284f5381aedff3a3f7b78e5c3642e5b"},"cell_type":"code","source":"classification_data = data[[\n                              'gender'\n                            , 'race/ethnicity'\n                            , 'parental level of education'\n                            , 'lunch'\n                            , 'test preparation course'\n                            , 'failed'\n                           ]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7ab677a129c27d58930b51179f15644e66783886"},"cell_type":"code","source":"text_columns = [\n  'gender'\n, 'race/ethnicity'\n, 'parental level of education'\n, 'lunch'\n, 'test preparation course'] \n\nclassification_data = pd.get_dummies(classification_data, columns=text_columns)\nclassification_data.head(6)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fc02988430d56cb8fd044b3a4a5f8e016e6c24e9"},"cell_type":"markdown","source":"<h3> split dataset into working train/test and validation datasets (80/20). models will be trained and tested on main working dataset, but for validation the models results we will use validation dataset </h3>"},{"metadata":{"trusted":true,"_uuid":"1ba1e20a1dcfc320015ae902a53638a1a7e263ea"},"cell_type":"code","source":"#Splitting data into main training and validation datasets, 80/20\nclassification_data.reset_index(level=[0], inplace=True)\ndata_train = classification_data.sample(int(np.floor(classification_data.shape[0] * 0.8)), random_state=999)\ndata_val = classification_data[np.logical_not(classification_data['index'].isin(data_train['index']))]\ndata_train = data_train.drop(columns = ['index'])\ndata_val = data_val.drop(columns = ['index'])\nprint(data_train[data_train['failed'] == 0].shape\n    , data_train[data_train['failed'] == 1].shape\n     , data_val.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"10449fde2b86d43dcd29e6ae4b001b4dc6d7115b"},"cell_type":"markdown","source":"<h3> working dataset is unbalanced, so we need balance it. \nWe will use oversampling method </h3>"},{"metadata":{"trusted":true,"_uuid":"13409dc6c7bddfd7b15ea73298da2fe0172c96a7"},"cell_type":"code","source":"#Oversampling: ge the needed oversample values\n\ndata_train_fail = data_train[data_train['failed'] == 1]\ndata_train_pass = data_train[data_train['failed'] == 0]\n\npass_n = data_train[data_train['failed'] == 0].shape[0]\nfail_n = data_train[data_train['failed'] == 1].shape[0]\ntimes_x = np.floor(pass_n / fail_n)\ndiff = int(pass_n - times_x * fail_n)\n\nprint(times_x, diff)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b0dae82bf692108b8c86eced785cfd0bfcf6df3"},"cell_type":"code","source":"#Oversampling: concatenating oversampled data together.\ndata_train_over = pd.concat([data_train_pass, \n                            data_train_fail,\n                            data_train_fail,\n                            data_train_fail,\n                            data_train_fail,\n                            data_train_fail.sample(diff, random_state = 999)])\nprint(data_train_over[data_train_over['failed'] == 0].shape\n    , data_train_over[data_train_over['failed'] == 1].shape\n     , data_train_over.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4542ef8c61ee8fe805e7b80604454d166e1352d5"},"cell_type":"markdown","source":"<h3> Split working dataset into test/train datasets and y labels </h3>"},{"metadata":{"trusted":true,"_uuid":"bc68f87fb5609d01c7b9b994241e21a0bf958bbf"},"cell_type":"code","source":"#test_train_sample\nX_train, X_test, y_train, y_test = train_test_split(\n    data_train_over[data_train_over.columns.difference(['failed'])],\n    data_train_over['failed'], test_size=0.3, random_state=999)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"996749f1a65325b019565d04c96f1786550f7ee7"},"cell_type":"markdown","source":"<h3> perform Gridsearch to find out best fitting parameters for random forest classifier </h3>"},{"metadata":{"trusted":true,"_uuid":"a2aa6a35a4e1d8ddc291aac4027437135fcc54a2"},"cell_type":"code","source":"\nparam_grid = { \n    'n_estimators': [8,9,10,11, 12,13, 14, 15, 16, 17, 18, 19, 20],\n    'max_depth' : [5, 10, 15, 17, 18, 19, 20, 21, 23, 25],\n#    'max_features': ['auto', 'sqrt', 'log2'],\n    'criterion' :['gini', 'entropy']\n}\n\nCV_rfc = GridSearchCV(estimator=RandomForestClassifier(random_state=1), param_grid=param_grid, cv= 5)\nCV_rfc.fit(X_train, y_train)\nCV_rfc.best_params_\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6536634188f373caa43b7fbb6c3c47f0515002a2"},"cell_type":"markdown","source":"<h3> fit the different models: SVM, SVM Poly, SVM rdf, random forest, decision tree, knn with various number of nearest neighbours. </h3>"},{"metadata":{"trusted":true,"_uuid":"dd7a159707f78b85d485a28e7b19f1367847f3b5"},"cell_type":"code","source":"\n# SVM\nsvm = SVC(kernel = \"linear\").fit(X_train, y_train)\nsvm_poly = SVC(kernel = \"poly\", degree = 2, gamma = \"auto\").fit(X_train, y_train)\nsvm_rbf = SVC(kernel = \"rbf\", gamma=\"auto\").fit(X_train, y_train)\n\n#Random Forest\nrf = RandomForestClassifier(n_estimators=19, max_depth = 15, criterion = 'gini', random_state = 999).fit(X_train, y_train)\n\n# Decision Tree\ndt = DecisionTreeClassifier(criterion = \"entropy\", random_state = 999).fit(X_train, y_train)\n\n# knn\nknn1 = KNeighborsClassifier(n_neighbors = 1).fit(X_train, y_train)\nknn3 = KNeighborsClassifier(n_neighbors = 3).fit(X_train, y_train)\nknn5 = KNeighborsClassifier(n_neighbors = 5).fit(X_train, y_train)\nknn7 = KNeighborsClassifier(n_neighbors = 7).fit(X_train, y_train)\nknn9 = KNeighborsClassifier(n_neighbors = 9).fit(X_train, y_train)\nknn11 = KNeighborsClassifier(n_neighbors = 11).fit(X_train, y_train)\nknn13 = KNeighborsClassifier(n_neighbors = 13).fit(X_train, y_train)\nknn25 = KNeighborsClassifier(n_neighbors = 25).fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0eafff5a0dd853adf0ec147e2cb4d21c541232b1"},"cell_type":"markdown","source":"<h3> run prediction on fitted model and get accuracy score. </h3> "},{"metadata":{"trusted":true,"_uuid":"178243c23c4f1759a46ff3bbba585ad25a49aec4"},"cell_type":"code","source":"acc1 = accuracy_score(y_test, svm.predict(X_test))\nacc2 = accuracy_score(y_test, svm_poly.predict(X_test))\nacc3 = accuracy_score(y_test, svm_rbf.predict(X_test))\n\nacc4 = accuracy_score(y_test, rf.predict(X_test))\n\nacc5 = accuracy_score(y_test, dt.predict(X_test))\n\nacc6 = accuracy_score(y_test, knn1.predict(X_test))\nacc7 = accuracy_score(y_test, knn3.predict(X_test))\nacc8 = accuracy_score(y_test, knn5.predict(X_test))\nacc9 = accuracy_score(y_test, knn7.predict(X_test))\nacc10 = accuracy_score(y_test, knn9.predict(X_test))\nacc11 = accuracy_score(y_test, knn11.predict(X_test))\nacc12 = accuracy_score(y_test, knn13.predict(X_test))\nacc13 = accuracy_score(y_test, knn25.predict(X_test))\n\nprint('\\n svm', acc1\n      , '\\n svm poly', acc2\n      , '\\n svm rbf', acc3\n      , '\\n random forest', acc4\n      , '\\n decision tree', acc5\n      , '\\n 1nn', acc6\n      , '\\n 3nn', acc7\n      , '\\n 5nn', acc8\n      , '\\n 7nn', acc9\n      , '\\n 9nn', acc10\n      , '\\n 11nn', acc11\n      , '\\n 13nn', acc12\n      , '\\n 25nn', acc13)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f001def18e7655c55168af8c4e166b22fb3a7f52"},"cell_type":"markdown","source":"<h3> Run models on validation dataset and see the results of accuracy there. </h3>"},{"metadata":{"trusted":true,"_uuid":"a649cb08a5f3143eccf729b3834c7024bb6b5c65"},"cell_type":"code","source":"val_x = data_val[data_val.columns.difference(['failed'])]\nval_y = data_val['failed']\ntrain_x = data_train[data_train.columns.difference(['failed'])]\ntrain_y = data_train['failed']\n\nprint('SVM rbf', accuracy_score(val_y, \n               SVC(kernel = \"rbf\", gamma=\"auto\").fit(train_x, train_y).predict(val_x)))\n\nprint('random forest', accuracy_score(val_y, \n               RandomForestClassifier(n_estimators=12, max_depth = 10, criterion = 'gini', random_state = 999).fit(train_x, train_y).predict(val_x)))\n\n\nprint('decision tree', accuracy_score(val_y, \n               DecisionTreeClassifier(criterion = \"entropy\", random_state = 999).fit(train_x, train_y).predict(val_x)))\n\n\nprint('3nn KNN', accuracy_score(val_y,\n               KNeighborsClassifier(n_neighbors = 3).fit(train_x, train_y).predict(val_x)))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c2a2557c3d3592a09e89d4753e1e4fe9e62b8a56"},"cell_type":"markdown","source":"<h3> Check Confusion matrix for each of those model predictions on validation data </h3>"},{"metadata":{"trusted":true,"_uuid":"d8db8fff76ad5896be8d2a47ed1e4acab4ef8040"},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\nprint('SVM rbf')\ny_pred = SVC(kernel = \"rbf\", gamma=\"auto\").fit(train_x, train_y).predict(val_x)\nconfusion_matrix_result = confusion_matrix(val_y, y_pred)\nprint(\"Confusion matrix:\\n%s\" % confusion_matrix_result)\ntn, fp, fn, tp = confusion_matrix_result.ravel()\nprint('True Negative: ' + str(tn), ', False Positive: ' + str(fp), ', False Negative: ' + str(fn), ', True Positive: ' + str(tp))\n\n\n\nprint(' \\n Random Forest')\ny_pred = RandomForestClassifier(n_estimators=12, max_depth = 10, criterion = 'gini', random_state = 999).fit(train_x, train_y).predict(val_x)\nconfusion_matrix_result = confusion_matrix(val_y, y_pred)\nprint(\"Confusion matrix:\\n%s\" % confusion_matrix_result)\ntn, fp, fn, tp = confusion_matrix_result.ravel()\nprint('True Negative: ' + str(tn), ', False Positive: ' + str(fp), ', False Negative: ' + str(fn), ', True Positive: ' + str(tp))\n\n\nprint(' \\n Decision Tree')\ny_pred = DecisionTreeClassifier(criterion = \"entropy\", random_state = 999).fit(train_x, train_y).predict(val_x)\nconfusion_matrix_result = confusion_matrix(val_y, y_pred)\nprint(\"Confusion matrix:\\n%s\" % confusion_matrix_result)\ntn, fp, fn, tp = confusion_matrix_result.ravel()\nprint('True Negative: ' + str(tn), ', False Positive: ' + str(fp), ', False Negative: ' + str(fn), ', True Positive: ' + str(tp))\n\n\nprint(' \\n KNN 3 nearest neighbours')\ny_pred = KNeighborsClassifier(n_neighbors = 3).fit(train_x, train_y).predict(val_x)\nconfusion_matrix_result = confusion_matrix(val_y, y_pred)\nprint(\"Confusion matrix:\\n%s\" % confusion_matrix_result)\ntn, fp, fn, tp = confusion_matrix_result.ravel()\nprint('True Negative: ' + str(tn), ', False Positive: ' + str(fp), ', False Negative: ' + str(fn), ', True Positive: ' + str(tp))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"35e666a9c3d90d072b29c0fcd28a4217ac410c50"},"cell_type":"markdown","source":"<h4>Seems that the model with the best accuracy score, SVM with rbf, only predicts negatives. Since the validation data is unbalanced, it gets high accuracy. In the other words, the best performing model in our case has same accuracy as the randomly predicting model - the one that only predicts negatives. </h4>"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}