{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this Notebook you will find a sentiment analysis for the covid19-tweets data package with vader.\nIt is my first \"bigger\" project, so if you've feedback or suggestions, feel free to reach out to me.\n\nUsed data: \n* https://www.kaggle.com/gpreda/covid19-tweets \n* https://www.kaggle.com/fernandol/countries-of-the-world \n* https://www.kaggle.com/okfn/world-cities"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data modification**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/covid19-tweets/covid19_tweets.csv\")\ndata = pd.DataFrame(df[[\"user_name\", \"user_location\", \"date\", \"text\"]])\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Non Ascii data will at the user_location column will be deleted to make it easier\n#All nan values will be replaced by unknown\n\n#def datacleaning(data):\ndata.fillna(\"unknown\", inplace = True)\ndata[data[\"user_location\"].str.contains(r'[^\\x00-\\x7F]+')]\ndata.info()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Sentiment value only store able as string? TODO -> Solution, need an INT value\n#def Sentimentanalysis(data)\nsid = SentimentIntensityAnalyzer()\n\ndata[\"sentiment\"] = \"\"\n\nfor index, row in data.iterrows():\n        data.at[index, \"sentiment\"] = sid.polarity_scores(str(row[\"text\"]))[\"compound\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndata[\"user_region\"] = \"\"\ncountries = pd.read_csv(\"../input/countries-of-the-world/countries of the world.csv\")\ncountries = countries[[\"Country\", \"Region\"]]\n\ncities = pd.read_csv(\"../input/world-cities/world-cities.csv\")\ncities = cities[[\"name\", \"country\"]]\n\ncities[\"country\"] = cities[\"country\"].str.rstrip()\ncountries[\"Country\"] = countries[\"Country\"].str.strip()\ndata[\"user_location\"] = data[\"user_location\"].str.strip()\n\nlocation = cities.join(countries.set_index(\"Country\"), on = \"country\")\nlocation.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Mapping of the region on the data dataframe to do region based evaluations \n#Created with the friendly help of ShivamSingla(@ssingla)\n#Processing time ~ 1 hour for (data(rows 179108) & location(rows ~ 23019))\n\nfrom tqdm.notebook import tqdm_notebook\n\ndef regionfinder(a):\n    for item in location.itertuples():\n        if item[1] in a:\n            return item[3]\n        elif item[2] in a:\n            return item[3]\n    return \"unknown\"   \n\ntqdm_notebook.pandas()\ndata[\"region\"] = data[\"user_location\"].progress_apply(regionfinder)\n\ndata.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Saving the data as csv to make it easier to work with the evaluations\ndata.to_csv(\"Aufbereitete Daten\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Evaluation**"},{"metadata":{},"cell_type":"markdown","source":"IÂ´ve decided to write the evaluation as an extra part because the region mapping on the data dataframe takes about 1 hour"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib as mlp\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2 = pd.read_csv(\"../input/aufbereitete-daten/Aufbereitete Daten\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Evaluation of the mean sentiment per region\n\nsentimentperregion= df2[[\"sentiment\", \"region\"]].groupby(\"region\").mean()\nsentimentperregion[[\"sentiment\"]].plot(kind = \"bar\", grid = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Evaluation of the mean sentiment change over time world wide\ndef Print(a):\n    print(a)\n\nsentimentovertime = df2[[\"date\", \"sentiment\"]]\nsentimentovertime[\"month\"] = sentimentovertime[\"date\"].apply(lambda x: str(x)[5:7])\nsentimentovertime = sentimentovertime.drop([\"date\"], axis = 1)\nsentimentovertime = sentimentovertime.groupby(\"month\").mean()\n\nsentimentovertime = sentimentovertime.dropna()\nsentimentovertime[[\"sentiment\"]].plot(figsize= (5, 10), kind = \"line\" ,grid = True)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}