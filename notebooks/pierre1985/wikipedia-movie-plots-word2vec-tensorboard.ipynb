{"cells":[{"metadata":{"_uuid":"5f14fab2143f3113f03dba4b0dc5028cdaf0a584"},"cell_type":"markdown","source":"# Déclarations"},{"metadata":{"trusted":true,"_uuid":"cfbbf23cee0fb77a3fe6bd44170c740f383efde7"},"cell_type":"code","source":"import os\nimport sys\nimport nltk\nimport pandas as pd\nimport tensorflow as tf\nimport numpy as np\nfrom tqdm import tqdm\nfrom gensim.models import word2vec\nfrom nltk.corpus import stopwords \nfrom tensorflow.contrib.tensorboard.plugins import projector\n\ntqdm.pandas()","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"fN_jpmww3Eym","_uuid":"660a5de937f7b71860e8f48430a0de24425575a8"},"cell_type":"markdown","source":"# Chargement du fichier CSV"},{"metadata":{"colab":{},"colab_type":"code","id":"1puNGABFwTCx","trusted":true,"_uuid":"76463bbd3ba33b3186b2af7f9559b70f3506cee2"},"cell_type":"code","source":"trainFile = \"../input/wiki_movie_plots_deduped.csv\"\n\npwd = os.getcwd()\nos.chdir(os.path.dirname(trainFile))\ndf = pd.read_csv(os.path.basename(trainFile))\nos.chdir(pwd)","execution_count":null,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"colab_type":"code","id":"J5l3HskCOcwP","outputId":"976f0286-a6a0-42d3-9d3a-f602ab645ac2","trusted":true,"_uuid":"8b4af39ac5400cdde9f837dac31c87ec93ed6eb6"},"cell_type":"code","source":"print(\"Nombre de lignes : {0}\".format(len(df)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bc160fd03f42bec2130c7025f8efa0d9af24ede4"},"cell_type":"markdown","source":"# Visualisation du jeu de données"},{"metadata":{"trusted":true,"_uuid":"10bb5bdd14f90936a3adf5b30c19861d3fdb7014"},"cell_type":"code","source":"dfAnalyze = df.copy()\ndfAnalyze.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"356c315d87b436fd94c09e4afb94997fcd1ddbf1"},"cell_type":"markdown","source":"### Nombre de films par date \nLe jeu de données est ordonné par année de sortie (Release Year). De ce fait les 2000 premiers enregistrements pris pour les tests vont de 1900 à 1935 (car classés par date).  \nCela va avoir une incidence sur la cohérence des mots proches entre le jeu de données réduit et le jeu de données complet (détails plus bas)."},{"metadata":{"trusted":true,"_uuid":"93a4955491093a0178cc956e092b72f4b1d1ae44"},"cell_type":"code","source":"hist = dfAnalyze.plot.hist()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cff446a5b5a3aba3369612ecf62c3c37271f8f6b"},"cell_type":"markdown","source":"### Nombre de films par pays"},{"metadata":{"trusted":true,"_uuid":"9dfae6b4321adc5042592120d30ec22bb1de2121"},"cell_type":"code","source":"columns = ['Release Year', 'Director','Cast', 'Genre', 'Wiki Page', 'Plot']\ndfPie = dfAnalyze.drop(columns, axis=1)\n\ndfPie = dfPie.groupby(['Origin/Ethnicity']).count().rename(columns= {'Title':'count'})\npie = dfPie.plot.pie(subplots=True, figsize=(7, 7))","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"KdfKwDFr399W","_uuid":"a43a773463589a0311273f3fc2e48253a4b73806"},"cell_type":"markdown","source":"# Réduction du jeu de données pour les tests\nPour la visualisation du kernel sur Kaggle, j'ai réduit le jeu de données. Cela a une incidence sur les résultats. J'ai donc mis en commentaires plus bas les résultats propres à l'ensemble du jeu de données."},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"colab_type":"code","id":"wZZjAIvV4Eom","outputId":"b7622f87-43e5-487d-b5f4-30cf7e9fff5b","trusted":true,"_uuid":"7934de167f178ca62be0882da07041a42398a3aa"},"cell_type":"code","source":"df = df.head(2000)\nprint(\"Nombre de lignes sélectionnées : {0}\".format(len(df)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a563e49ab8ce015718a2d3946bba2c68a4fac2ac"},"cell_type":"markdown","source":"# Nettoyage\n- Suppression des stop words anglais\n- Suppression des chaînes de caractères de longueur inférieure ou égale à 2"},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"e8c8e32825a5bfdf484d0b2aad581e09c0ad42be"},"cell_type":"code","source":"def tokenize_without_stop_words(text):\n    sentence = nltk.word_tokenize(text.lower())\n    sentence = [w for w in sentence if not w in stopwords.words('english')]\n    sentence = [w for w in sentence if len(w) > 2 ]\n    return sentence\n\nsentences = df.progress_apply(lambda row: tokenize_without_stop_words(row['Plot']), axis=1)\nsentences = sentences.tolist()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"977ad7ba440bf8c8e21085792f9645b42edbf8e7"},"cell_type":"markdown","source":"# Vectorization Word2Vc"},{"metadata":{"_uuid":"2b675d1938b4d26c21280b963fc59e9633220b53"},"cell_type":"markdown","source":"## Quelques informations sur la vectorization"},{"metadata":{"_uuid":"cc00edd6d097015eb04992653d15ab99db536918"},"cell_type":"markdown","source":"### Modèle\nEn utilisant tout le jeu de données, je ne garde que les mots présents au moins 750 fois (soit présent à 2%).  \nCela représente 1686 mots.  \nPour la visualisation le jeu de données est réduit et j'ai donc adapté le min_count."},{"metadata":{"trusted":true,"_uuid":"9dc6d41f1755943a3544c3b6b519d03eebc30c42"},"cell_type":"code","source":"model = word2vec.Word2Vec(sentences, min_count=50, workers=4)\nprint(model)\n\n# model = word2vec.Word2Vec(sentences, min_count=750, workers=4)\n# Result Full Dataset : Word2Vec(vocab=1686, size=100, alpha=0.025)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0dd47cc082c1880564bea433931fe237155c21f9"},"cell_type":"markdown","source":"### Visualisation du vocabulaire"},{"metadata":{"trusted":false,"_uuid":"5c3341969bb841e1c85c3aac503f1edc89362e5f"},"cell_type":"code","source":"#for entry in sorted(model.wv.vocab):\n#    print(entry)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6cee81845f8aedae4a4fae070e7f368a3d65c550"},"cell_type":"markdown","source":"### Tests de la cohérence en recherchant des mots proches\nAttention car ces tests de cohérence différent en fonction du nombre de lignes prises du jeu de données.   \nJ'ai mis en commentaire les 5 mots les plus proches en utilisant tout le jeu de données."},{"metadata":{"trusted":true,"_uuid":"e4dfc3fe92299e0f9a02fb6a91a68733c1221d5a"},"cell_type":"code","source":"print(model.wv.most_similar(['suicide'], topn=5))\n# Result Full Dataset : [('murder', 0.54288649559021), ('failed', 0.47224748134613037), ('rape', 0.4682120680809021), \n# ('murders', 0.4570953845977783), ('death', 0.3709148168563843)]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e377998272693eb43b99a7fa8646aff2745e66cc"},"cell_type":"markdown","source":"#### Mots proches de war\nAttention car en ne prenant par exemple que les 2000 premiers enregistrements les résultats sont complètement différents : le mot war se rattache à la guerre entre la France et l'Allemagne.    \nEn revanche avec tout le jeu de données, le mot war se rattache aux Etats-Unis, Japon...  \nCela vient du fait que les enregistrements sont classés par date et que les films traitent souvent de l'actualité."},{"metadata":{"trusted":true,"_uuid":"af1da44226adbf7061fa9c90286186f8492fc80e"},"cell_type":"code","source":"print(model.wv.most_similar(['war'], topn=5))\n# Result Full Dataset : [('u.s.', 0.597042441368103), ('army', 0.5714285969734192), ('china', 0.55967777967453), \n# ('union', 0.558294951915741), ('japan', 0.5436923503875732)]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"88840502fa5b806a6b184659f2f1bff10f108eb7"},"cell_type":"markdown","source":"# Transformation du modèle word2vec en modèle exploitable par tensorboard\n\nMerci à BrikerMan (https://gist.github.com/BrikerMan/7bd4e4bd0a00ac9076986148afc06507)  \nAvec l'apport personnel d'une correction (= purge des anciens nodes/graphes)"},{"metadata":{"trusted":true,"_uuid":"4c4642b660b4f20d8bad3317a8509adfd05b7948"},"cell_type":"code","source":"def transform_word2vec_to_tensor(model, output_path):\n    meta_file = \"w2x_metadata.tsv\"\n    placeholder = np.zeros((len(model.wv.index2word), 100))\n\n    with open(os.path.join(output_path,meta_file), 'wb') as file_metadata:\n        for i, word in enumerate(model.wv.index2word):\n            placeholder[i] = model[word]\n            # temporary solution for https://github.com/tensorflow/tensorflow/issues/9094\n            if word == '':\n                print(\"Emply Line, should replaced by any thing else, or will cause a bug of tensorboard\")\n                file_metadata.write(\"{0}\".format('<Empty Line>').encode('utf-8') + b'\\n')\n            else:\n                file_metadata.write(\"{0}\".format(word).encode('utf-8') + b'\\n')\n\n    # Correction : purge les anciens nodes/graphes\n    tf.reset_default_graph()\n    \n    sess = tf.InteractiveSession()\n\n    embedding = tf.Variable(placeholder, trainable = False, name = 'w2x_metadata')\n    tf.global_variables_initializer().run()\n\n    saver = tf.train.Saver()\n    writer = tf.summary.FileWriter(output_path, sess.graph)\n\n    # adding into projector\n    config = projector.ProjectorConfig()\n    embed = config.embeddings.add()\n    embed.tensor_name = 'w2x_metadata'\n    embed.metadata_path = meta_file\n\n    # Specify the width and height of a single thumbnail.\n    projector.visualize_embeddings(writer, config)\n    saver.save(sess, os.path.join(output_path,'w2x_metadata.ckpt'))\n\ndirectory = './output/'\nif not os.path.exists(directory):\n    os.makedirs(directory)\n\n# Pour la visualisation Kaggle, j'ai mis en commentaire transform_word2vec_to_tensor(model, directory). Il faut donc dé-commenter la ligne ci-dessous.\n#transform_word2vec_to_tensor(model, directory)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bd2b5d583525c48604a60f27fbae8108499e2627"},"cell_type":"markdown","source":"# Lecture dans tensorboard\n- Pour ma part, j'utilise anaconda. J'ai donc au préalable installé tensorboard (https://anaconda.org/conda-forge/tensorboard) avec tous ses dépendances.\n- Ensuite je me suis placé dans le répertoire contenant mon notebook et j'ai tapé la commande :  \n`tensorboard --logdir output --host localhost`  \nExemple : `tensorboard --logdir . --host localhost`\n- J'ouvre mon navigateur et je charge la page dont l'url est indiquée suite à l'exécution de la commande dans la console anaconda."},{"metadata":{"_uuid":"b283b2e4109650745e4c14924092d4d1a840ea65"},"cell_type":"markdown","source":"### Vue 3D du mot \"war\" à partir des 2000 premiers enregistrements du jeu de données\n\n![Small Dataset War](https://farm5.staticflickr.com/4805/44359366950_c42826e5e1_b.jpg)"},{"metadata":{"_uuid":"7c023f23cfbd7d4ba1a2dc8a9cb4ecf16cbcf45a"},"cell_type":"markdown","source":"### Vue 3D du mot \"war\" à partir de tout le jeu de données\n\n![Full Dataset War](https://farm5.staticflickr.com/4850/45263897465_c06d96d2dc_b.jpg)"},{"metadata":{"_uuid":"1bed0af8a139c6c4d3472b8c8743830efad70512"},"cell_type":"markdown","source":"### Vue 3D du mot \"suicide\" à partir de tout le jeu de données\n\n![Full Dataset Suicide](https://farm5.staticflickr.com/4841/32304879878_7836210f2a_z.jpg)"}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["RMq8dUqGwzsY"],"name":"E_Thematiques Keras.ipynb","provenance":[],"version":"0.3.2"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"}},"nbformat":4,"nbformat_minor":1}