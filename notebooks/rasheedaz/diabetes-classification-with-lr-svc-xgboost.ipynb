{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.gridspec import GridSpec\nimport matplotlib as mpl\nimport seaborn as sns\n\nfrom sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.svm import SVC\n\nfrom xgboost import XGBClassifier\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.style.use(\"seaborn-bright\")\nmpl.rcParams[\"figure.figsize\"] = (10, 10)\nsns.set_theme(style=\"whitegrid\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/diabetes-data-set/diabetes.csv')\nprint(data.columns)\ndata.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Splitting the data into training and test set, in order not to do double dibbing","metadata":{}},{"cell_type":"code","source":"#Tesing is we have missing values\nfor col in data.columns:\n    if data[col].isna().values.sum() > 0:\n        print(f\"Missing values in col: {col}\")\n#No outliers in this dataset\nsplitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\ntrain_data = None\ntest_data  = None\n\nfor train_ind, test_ind in splitter.split(data, data[\"Outcome\"]):\n    train_data = data.iloc[train_ind]\n    test_data = data.iloc[test_ind]\n\nprint(train_data.shape)\nprint(test_data.shape)\nprint(f\"Precentage of class 1 in train: {train_data['Outcome'].sum(axis=0)/train_data.shape[0]}\")\nprint(f\"Precentage of class 1 in test: {test_data['Outcome'].sum(axis=0)/test_data.shape[0]}\")\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data visualization","metadata":{}},{"cell_type":"code","source":"def visualizeDistribution(data, columnNames):\n    gs = GridSpec(3, 3)\n    axes = []\n    for i in range(0, 3):\n        for j in range(0, 3):\n            axes.append(plt.subplot(gs[i, j]))\n\n    for i in range(0, 3):\n        for j in range(0, 3):\n            data[columnNames[i*3 + j]].hist(ax=axes[i*3 +j], density=True);\n            data[columnNames[i*3 + j]].plot.kde(ax=axes[i*3 +j]);\n            axes[i*3 + j].set_yticks([])\n            axes[i*3 + j].set_xlabel(columnNames[i*3 + j])\n    #plt.title(\"Data Distribution using a Gaussian KDE\")\n    plt.show()\n    \ncolumnNames = list(data.columns)\nvisualizeDistribution(train_data, columnNames)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15, 15))\nsns.boxplot(data = train_data, ax = ax)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It is evident from the above two figures that: Insulin, DiabetesPedigreeFunction, Age and Pregnancies.","metadata":{}},{"cell_type":"code","source":"#replacing outliers in the above mentioned columns by their means value\nmeans = {}\noutliers = {}\ncolumnsOutliers =  ['Pregnancies','Insulin','DiabetesPedigreeFunction', 'Age']\nfor col in columnsOutliers:\n    means[col] = train_data[col].mean(axis=0)\n\nprint(means)\n\nfor col in columnsOutliers:\n    outlier = train_data[col].quantile(0.98)\n    outliers[col] = outlier\n\n    \ndef replacingOutliers(data, means, outliers, columnsOutliers, dataType):\n    print(\"Outliers tranformation for \" + dataType)\n    for col in columnsOutliers:\n        print(f\"Replacing in {col}: {np.sum(data[col] > outliers[col])}\")\n        data.loc[data.index[data[col] > outliers[col]]][col] = means[col]\n\nreplacingOutliers(train_data, means, outliers, columnsOutliers, \"train\")\nreplacingOutliers(test_data, means, outliers, columnsOutliers, \"test\")\n\nvisualizeDistribution(train_data, columnNames)\nfig, ax = plt.subplots(figsize=(15, 15))\nsns.boxplot(data = train_data, ax = ax)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# colors_diabetes = [\"red\", \"blue\"]\n#1 -> \"Diabetic\"\n#0 -> \"Not-Diabetic\"\ntrain_data.loc[train_data.index[train_data[\"Outcome\"] == 0]][\"Outcome\"] = \"Non-Diabetic\"\ncolumnNamesNoOutput = { key:value  for (key, value) in  enumerate(columnNames[0:len(columnNames)-1]) }\ncolumnNamesNoOutput\nprint(columnNamesNoOutput)\n\n\nwhile(True):\n    continueOrNot = int(input(\"Do you want to continue(1:cont, 0:break)\"))\n    if not continueOrNot:\n        break\n    col1 = int(input(\"Please input first column you want to see pair plot with(0 - 7):\"))\n    col2 = int(input(\"Please input second column you want to see pair plot with(0 - 7):\"))\n    if col1 in columnNamesNoOutput and col2 in columnNamesNoOutput:\n        sns.pairplot(train_data[[columnNamesNoOutput[col1], columnNamesNoOutput[col2], \"Outcome\"]], hue=\"Outcome\")\n        plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr = train_data[columnNamesNoOutput.values()].corr()# there is linear dependencies between-> glucode:Insulin, age:pregnancies and BMI: Insulin\ncorr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data transformation","metadata":{}},{"cell_type":"code","source":"X_train, y_train = np.array(train_data.drop(columns=[\"Outcome\"])), np.array(train_data[\"Outcome\"])\nX_test, y_test = np.array(test_data.drop(columns=[\"Outcome\"])), np.array(test_data[\"Outcome\"])\n\nstandardScalar = StandardScaler()\nstandardScalar.fit(X_train)\nstandardScalar.transform(X_train)\nstandardScalar.transform(X_test)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Logistic Regression","metadata":{}},{"cell_type":"code","source":"param_grid = [\n    {\"C\": [v for v in np.linspace(0.0001, 2, 10)]}\n]\n\nlogReg = LogisticRegression(random_state=42, penalty=\"l2\", max_iter=1000)\ngrid_search = GridSearchCV(logReg, param_grid, cv=5, scoring=\"neg_log_loss\", return_train_score=True)\ngrid_search.fit(X_train, y_train)\nprint(grid_search.best_params_)\nmodel = grid_search.best_estimator_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def results(model):\n    prediction = model.predict(X_train)\n    print(confusion_matrix(y_train, prediction))\n    print(classification_report(y_train, prediction))\n    prediction = model.predict(X_test)\n    print(confusion_matrix(y_test, prediction))\n    print(classification_report(y_test, prediction))\n\nresults(model)#Accuracy: 0.79 but bad recall score for diabetic class.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SVM for Classification","metadata":{}},{"cell_type":"code","source":"param_grid = [\n    {\"kernel\": [\"rbf\"], \"C\": [v for v in np.logspace(-3, 2, 10)],\n    \"gamma\": [v for v in np.logspace(-3, 2, 10)]}\n]\n\nsvc = SVC(kernel=\"rbf\", random_state=42)\ngrid_search = GridSearchCV(svc, param_grid, cv=5)\n\ngrid_search.fit(X_train, y_train)\nprint(grid_search.best_params_)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = grid_search.best_estimator_\nresults(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Using XGBoost","metadata":{}},{"cell_type":"code","source":"model = XGBClassifier(booster=\"gbtree\",n_estimator=[10], max_depth=3, objective='binary:logistic', use_label_encoder=False )\nmodel.fit(X_train, y_train)\nresults(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}