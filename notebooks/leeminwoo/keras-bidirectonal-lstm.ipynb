{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"../input/sunspots/Sunspots.csv\")\n\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#마지막 거 빼고는 쓸모가 없음\n#We need only the last column\ndata = data[\"Monthly Mean Total Sunspot Number\"]\n\n#Normalization\ndata = data / max(data)\n\n#to numpy\ndata = np.array(data)\nprint(data[:5])\nprint(data.shape) #3265,","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time_split = 3000\nwindow_size = 30\n\ntrain = data[:3000]\ntest_x = data[3000:]\nprint(len(test_x))\n\n'''\ntrain을 window_size만큼 잘라서 데이터셋 형성\nslice data\n\nif) window_size = 60\n\ntrain_x = data[0:59]  data[1:60]   ...  data[2540:2599]\ntrain_y = data[60]    data[61]     ...  data[3000]\n'''\n\ntrain_x = []\ntrain_y = []\nfor i in range(len(train) - window_size - 1) :\n    tmp_x = train[i : i+window_size]\n    tmp_y = train[i+window_size]\n    train_x.append(tmp_x)\n    train_y.append(tmp_y)\n\ntrain_x = np.array(train_x)\ntrain_x = train_x.reshape((-1, window_size, 1))\ntrain_y = np.array(train_y)\ntrain_y = train_y.reshape((-1, 1))\nprint(train_x.shape, train_y.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import LSTM, Bidirectional, Dense, Dropout\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.losses import Huber\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom tensorflow.keras.callbacks import Callback\n\n\nmodel = Sequential()\nmodel.add(Bidirectional(LSTM(64, return_sequences=True)))\nmodel.add(Bidirectional(LSTM(128, return_sequences=False)))\nmodel.add(Dense(32, activation = 'relu'))\nmodel.add(Dropout(0.1))\nmodel.add(Dense(1, activation = 'linear'))\n\noptimizer = Adam(lr = 1e-3)\nmodel.compile(loss = Huber(), optimizer = optimizer, metrics = [\"mae\"])\n\nwith tf.device('/gpu:0'):\n    model.fit(train_x, train_y, batch_size = 256, epochs = 100, verbose = 2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n#테스트를 위한 데이터셋 만들기\n#make data for test (window_size)\ntest_data = []\ntrain_y = train_y.reshape((-1))\nfor i in range(window_size) :\n    tmp_data = train_y[-window_size*2 + i : -window_size + i]\n    tmp_data = np.reshape(tmp_data, (1, window_size, 1))\n    predict = model.predict(tmp_data)\n    predict = predict.reshape((1))\n    test_data.append(predict)\n\n#predict\npredict_list = []\nfor i in range(len(test_x)) :\n    test_data = np.array(test_data).reshape((1, window_size, 1))\n    predict = model.predict(test_data)\n    predict = predict.reshape((1))\n    test_data = test_data.reshape((window_size))\n    predict_list.append(predict)\n    test_data = np.append(test_data[1:], predict)\n\npredict_list = np.array(predict_list)\npredict_list = predict_list.reshape((-1))\ntimes = list(range(len(data)))\nplt.plot(times, data)\nplt.plot(times[-len(test_x):], predict_list)\nplt.show()\n\nplt.plot(times[-len(test_x):], test_x)\nplt.plot(times[-len(test_x):], predict_list)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}