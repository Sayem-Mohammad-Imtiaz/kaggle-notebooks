{"cells":[{"metadata":{"_uuid":"14164d37ec40cb94931a563a5136ee90151f46c2"},"cell_type":"markdown","source":"### Conflicting Genetic Classifications:\n   The Dataset being used was gathered by ClinVar, a public resource used to collect information about genetic variants. ClinVar classifies each of these variants into one of three categories:\n   1. Likely Benign or Benign\n   2. VUS\n   3. Likely Pathogenic or Pathogenic\n   \nThe variants were categorized via manual testing by multiple labs. Conflicting categorizations have been assigned to the CLASS column, a 1 represents a conflicting categorizations by different labs while a 0 represents a consistent categorization."},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"3e9e97485adb5d7a726b28f5f98f2f93a0c2c429"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport sklearn as sk\nimport fractions\nimport re\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"44a28caefedd53818546435f6c5d79cbce588d14"},"cell_type":"markdown","source":"## EDA"},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"8c9eb6570676ddd9d673fe7a7f6216f91a733f44"},"cell_type":"code","source":"dataframe = pd.read_csv(\"../input/clinvar_conflicting.csv\", dtype={0: object, 38: str, 40: object})","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false,"_uuid":"e4da0d48245166df1f413d252f0c19f8742b304f"},"cell_type":"code","source":"print(dataframe.shape)\ndataframe.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f2a8de0bc09dc2cead906b2f5486958595dbd0f9"},"cell_type":"markdown","source":"In observing the CLASS variable we can see that it is heavily skewed towards consistent categorizations (CLASS = 0). This gives us context for observing the ratio of conflicting classifications as grouped by each variable."},{"metadata":{"scrolled":false,"trusted":false,"_uuid":"d7571c7e27101ef0a03cc73ee5311049e3d98acf"},"cell_type":"code","source":"#plotting a histogram of the different values of class to see if it's skewed\ng = dataframe.groupby('CLASS').size()\ng.plot(kind = 'bar')\nproportion_conflicting = g[1]/g.sum()\nprint(g)\n\nprint(\"The fraction of classifications that are conflicting is {}\".format(proportion_conflicting))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d37f22cc69d4e4d8c2ce13e22ea24ffdd9587fa3"},"cell_type":"markdown","source":"In order to accurately compare the proportions of the rate of conflicting classifications I've organized the proportion of conflicting classifications by mutation. What is interesting about these classifications is that the misclassification rate for single_nucleotide_variant (often abreviated SNP) is higher than that of the other mutations. SNP's are mutations in which only a single nucleotide is changed as opposed to deletions or insertions in which multiple alleles are affected. We can also see that Microsatellite variations have significantly different values than the others however due to the small sample size we cannot draw any firm conclusions from this."},{"metadata":{"scrolled":false,"trusted":false,"_uuid":"898309ae4912775e31fa61f5d2a38028bbef3487"},"cell_type":"code","source":"#Testing Categorical Variables\n\ngrouped = dataframe.groupby('CLNVC')\ngrouped_class = grouped['CLASS'].agg(np.mean)\n\nprint(\"Proportion of conflicting classifications by mutation {} \\n\".format(\n    grouped_class))\n\n#comparing proportion of each mutation conflicting to average\nprint(\"Proportion of conflicting classifications by mutation compared to average for data set {}\\n\".format(\n    grouped_class.apply(lambda grouped_class: grouped_class - proportion_conflicting)))\ngrouped.size()\n\ngrouped_class.plot(kind = \"bar\", ylim = [0,1], title = 'Proportion of conflicting classifications by mutation', figsize = (20,10))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"092d0804bb574c61f77d55b56e11495552e48d93"},"cell_type":"markdown","source":"I've performed a similar analysis to that done on the CLNVC variable on IMPACT. In comparing the proportion of conflicting classifications of each impact level we can clearly see that HIGH values have a lower conflicting classification rate than other values. (more information about the impact variable is explained at https://uswest.ensembl.org/info/genome/variation/prediction/predicted_data.html#consequences.) Essentially the IMPACT measures the predicted impact of the variant on phenotype. This analysis seems to indicate that variants that have a high impact on phenotype seems to lead to less conflicting results with regard to pathogeneity. This seems reasonable, however the results also indicate that there is essentially no difference between the misclassification of a LOW impact and MODERATE impact variation which would seem to deserve attention."},{"metadata":{"scrolled":false,"trusted":false,"_uuid":"3a1e075cdccba0e6e323897c2c0a34379d1c5e07"},"cell_type":"code","source":"#IMPACT\n\ngrouped_impact = dataframe.groupby('IMPACT')\ngrouped_impact_class = grouped_impact['CLASS'].agg(np.mean)\n\nprint(\"Proportion of conflicting classifications by impact level {} \\n \\n\".format(\n    grouped_impact_class))\n\n#comparing proportion of each IMPACT level conflicting to average\nprint(\"Proportion of conflicting classifications by impact level compared to average for data set{}\\n\".format(\n    grouped_impact_class.apply(lambda grouped_impact_class: grouped_impact_class - proportion_conflicting)))\n\nprint(grouped_impact.size())\n\ngrouped_impact_class.plot(kind = \"bar\", ylim = [0,1], title = 'Proportion of conflicting classifications by impact level',\n                          figsize = (20,10))","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"4e45ce58a98fa6538b54423bb1883396c02d679c"},"cell_type":"code","source":"#creating function for correlation plot\ndef plot_corr(df,size=10):\n    '''Function plots a graphical correlation matrix for each pair of columns in the dataframe.\n\n    Input:\n        df: pandas DataFrame\n        size: vertical and horizontal size of the plot'''\n    corr = df.corr()\n\n    # Set up the matplotlib figure\n    f, ax = plt.subplots(figsize=(20, 10))\n\n    # Generate a custom diverging colormap\n    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n    # Draw the heatmap with the mask and correct aspect ratio\n    sns.heatmap(corr, cmap=cmap, vmax= 1, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n    \n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"82ae66641ca38e7f27e64bf1b5e78d5b1bdb1ec1"},"cell_type":"markdown","source":"In the cell below I've created a purely numeric data frame that can be used for model creation, I've eliminated all non-numeric features, in addition to this I've removed the NA values from the data."},{"metadata":{"trusted":false,"_uuid":"4c33256e2d734d0236acc68260ce74f2466f29de"},"cell_type":"code","source":"#dropping all columns with over 20% NA\ndf=dataframe.replace({'':np.nan})\ndf = df.dropna(thresh=0.8*len(df), axis=1)\ndf.columns\n#dropping all columns that clearly don't play a role in outcome (ex: clinical name of diseases)\ndf = df.drop([\"CLNDISDB\", \"CLNDN\", \"Feature\", 'Consequence', 'BIOTYPE', 'SYMBOL', 'Feature_type', 'ORIGIN'], axis = 1)\n#removing all non numerical values\ndf_numeric = df.drop(['Amino_acids', 'Codons', 'MC', \"CLNHGVS\", 'REF', 'ALT', 'CLNVC', 'Allele', 'IMPACT', 'CHROM'], axis = 1)\n\n#converting variables with numeric values listed as strings to numeric\nfor i in [\"Protein_position\", \"CDS_position\", \"cDNA_position\"]:\n    df_numeric[i] = pd.to_numeric(df_numeric[i], errors = 'coerce')\n    \n\n#converting EXON to numeric values\ndf_numeric.EXON.fillna('0', inplace=True)\ndf_numeric['variant_exon'] = df_numeric.EXON.apply(lambda x: [float(s) for s in re.findall(r'\\b\\d+\\b', x)][0])\ndf_numeric = df_numeric.drop([\"EXON\"], axis = 1)\n\ndf_numeric.dropna(axis = 0, inplace = True)\ndf_numeric.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5d410c6279ecbcc9a139f8dc8133d054f52e52c9"},"cell_type":"markdown","source":"The correlation plot indicates that none of the values are highly correlated with the CLASS variable, this indicates that a model with a low risk of overfitting can't be created by training on a select subset of features."},{"metadata":{"scrolled":false,"trusted":false,"_uuid":"a65e0c32c4fa7f5dd896cd90f117c4df25058ff8"},"cell_type":"code","source":"plot_corr(df_numeric, size = 20)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0dabd6c957b46fbc315772fe9ed91da8f1799bc0"},"cell_type":"markdown","source":"Both the logistic regression model and SVM create models with roughly 75% accuracy in their predictions. Although these results aren't extraordinary it also seems unlikely that further tuning will lead to a large increase in accuracy as none of the features are highly correled with CLASS."},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"c49a800d07daf336ad1b1491eaa59997aa3f59da"},"cell_type":"code","source":"#splitting data into training and test sets\nfrom sklearn.model_selection import train_test_split\ndf_numeric_predictors = df_numeric.drop([\"CLASS\"], axis = 1)\ndf_numeric_outcome = df_numeric[\"CLASS\"]\nX_train, X_test, y_train, y_test = train_test_split(df_numeric_predictors, df_numeric_outcome, test_size=0.33, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false,"_uuid":"8e9e97baf25c89b6f0a0e054fd385247ecec2275"},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n#training the model using training sets\nregr = LogisticRegression().fit(X_train, y_train)\n#testing the model using testing sets\ny_pred = regr.predict(X_test)\n\ny_array = np.array(y_test)\nprint('Accuracy score: %.2f' % accuracy_score(y_array, y_pred))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"2998fcb011eb6b14f8e6f17525d4f1e84d9d7879"},"cell_type":"code","source":"from sklearn import svm\nclf = svm.SVC(gamma = 0.001)\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint('Accuracy score: %.2f' % accuracy_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"a3a520992ba553d9f24b1404d53b9fbf9abdb581"},"cell_type":"markdown","source":"## Conclusions\n    This data set showed some interesting results. Probably the most surprising was revealed during the EDA when we saw how strongly correlated SNP mutations were with misclassifications this can lead to interesting questions with regards to testing methods for SNP mutations and their consistency. A more accurate model could possibly have been created if the methods and features used were fine tuned but the central goal of this analysis was more along the lines of data exploration and noticing irregularities that could point towards further research."},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"c48a0aa36f814e26959e76ecdbfcb309d2d734b0"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"}},"nbformat":4,"nbformat_minor":1}