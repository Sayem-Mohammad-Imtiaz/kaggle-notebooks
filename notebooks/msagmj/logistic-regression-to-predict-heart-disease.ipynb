{"cells":[{"metadata":{},"cell_type":"markdown","source":"# LOGISTIC REGRESSION TO PREDICT HEART DISEASE.\n![](http://)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Introduction","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"World Health Organization has estimated 12 million deaths occur worldwide, every year due to Heart diseases. Half the deaths in the United States and other developed countries are due to cardio vascular diseases. The early prognosis of cardiovascular diseases can aid in making decisions on lifestyle changes in high risk patients and in turn reduce the complications. This research intends to pinpoint the most relevant/risk factors of heart disease as well as predict the overall risk using logistic regression.\n","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import metrics\nsns.set()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# reading data file","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data=pd.read_csv(\"/kaggle/input/heart-disease-prediction-using-logistic-regression/framingham.csv\")\ndata.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe(include=\"all\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Handling Missing Values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"education has 105 missing values.\n\ncigsPerDay has 29 missing values.\n\nBPMeds has 53 missing values.\n\ntotChol has 50 missing values.\n\nBMI has 19 missing values.\n\nheartRate has 1 missing values\n\nglucose has 388 missing values.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from statistics import mode ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First we will check whether the information is categorical or continuous.\n\nIf they are continuous null values can be replaced by mean(The Arithmetic Mean is the average of the numbers).\n\nIf they are categorical null values can be replaced by mode(The number which appears most often in a set of numbers).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"education\"].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"education is categorical.\nso we replace by mode.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"education\"]=data[\"education\"].fillna(mode(data[\"education\"]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"education\"].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"cigsPerDay\"].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"cigsPerDay seems to be continuous.\nso we replace by mean.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"cigsPerDay\"]=data[\"cigsPerDay\"].fillna(data[\"cigsPerDay\"].mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"cigsPerDay\"].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"BPMeds\"].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"BPMeds is categorical.\nso we replace by mode.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"BPMeds\"]=data[\"BPMeds\"].fillna(mode(data[\"BPMeds\"]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"BPMeds\"].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"totChol\"].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"totChol seems to be continuous.\nso we replace by mean.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"totChol\"]=data[\"totChol\"].fillna(data[\"totChol\"].mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"totChol\"].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"glucose\"].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"glucose seems to be continuous.\nso we replace by mean.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"glucose\"]=data[\"glucose\"].fillna(data[\"glucose\"].mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"BMI & heartRate still have null values but the number is too less .\n\nso we simply drop the rows.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data=data.dropna()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we checks if further null values are there.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Exploration","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe(include=\"all\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"when we see the dependent feature the mean is quite low around 0.15 ie the dataset is imbalanced.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"we try to see them separately","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_r=data.drop([\"TenYearCHD\"],axis=1)\ny_r=data[\"TenYearCHD\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Feature Selection","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bf=SelectKBest(score_func=chi2,k=10)\nfit=bf.fit(X_r,y_r)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfscores=pd.DataFrame(fit.scores_)\ndfcolumns=pd.DataFrame(X_r.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"featurescores=pd.concat([dfcolumns,dfscores],axis=1)\nfeaturescores.columns=[\"spec\",\"score\"]\nfeaturescores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(featurescores.nlargest(10,'score'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=data[[\"sysBP\",\"glucose\",\"age\",\"totChol\",\"cigsPerDay\",\"diaBP\",\"prevalentHyp\",\"diabetes\",\"BPMeds\",\"male\"]]\ny=data[\"TenYearCHD\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"TenYearCHD\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"to make it balance we have two option under sampling and over sampling ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"using both to understand and see difference","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# under sampling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.under_sampling import NearMiss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nm= NearMiss()\nX_res,y_res=nm.fit_sample(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_res.shape,y_res.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"now they seems to be balanced","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"we see datatypes of allcolumns using \".dtypes\" command","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Splitting and Logistic Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.33, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"feature scaling ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logisticRegr = LogisticRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logisticRegr.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = logisticRegr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = logisticRegr.score(X_test, y_test)\nprint(score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are getting accuracy of 72%.\nIt can be improved by cross validaation.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix = metrics.confusion_matrix(y_test,predictions)\nprint(confusion_matrix)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}