{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\n#print(os.listdir(\"../input\"))\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data preprocessing"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"hsales = pd.read_csv('../input/nyc-property-sales/nyc-rolling-sales.csv') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"21c7e826e5de3dd4c3f598f28400ed71eeb9200d"},"cell_type":"code","source":"hsales.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d919dc521f041ed2f10ea09bc5727eb4411455fa"},"cell_type":"code","source":"# let's check what we have \nhsales.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b3ba1307f07ecf1ac8700d5f04dbe3e075fe138b"},"cell_type":"markdown","source":"According to this official [page](https://www1.nyc.gov/assets/finance/downloads/pdf/07pdf/glossary_rsf071607.pdf), Ease-ment is \"is a right, such as a right of way, which allows an entity to make limited use of anotherâ€™s real property. For example: MTA railroad tracks that run across a portion of another property\". Also, the Unnamed column is not mentioned and was likely used for iterating through records. So, those two columns are removed for now. "},{"metadata":{"trusted":true,"_uuid":"531b570016e6487b527168e4b3e309732989fdea"},"cell_type":"code","source":"hsales.drop(['Unnamed: 0', 'EASE-MENT'],1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"adec8a6d1c1ef008507642ea581c253111ba7f51"},"cell_type":"code","source":"hsales.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5f7f7d6af9aa7ac64469ebee345a1a85dc6962a4"},"cell_type":"markdown","source":"It looks like empty records are not being treated as NA. We convert columns to their appropriate data types to obtain NAs."},{"metadata":{"trusted":true,"_uuid":"e75471dd3f27e6c22ebc69b8a6ca57e391e3f4df"},"cell_type":"code","source":"#First, let's check which columns should be categorical\nprint('Column name')\nfor col in hsales.columns:\n    if hsales[col].dtype=='object':\n        print(col, hsales[col].nunique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b544c391aad687247e27f094ccbdf889e70362c"},"cell_type":"code","source":"# LAND SQUARE FEET,GROSS SQUARE FEET, SALE PRICE, BOROUGH should be numeric. \n# SALE DATE datetime format.\n# categorical: NEIGHBORHOOD, BUILDING CLASS CATEGORY, TAX CLASS AT PRESENT, BUILDING CLASS AT PRESENT,\n# BUILDING CLASS AT TIME OF SALE, TAX CLASS AT TIME OF SALE,BOROUGH \n\nnumer = ['LAND SQUARE FEET','GROSS SQUARE FEET', 'SALE PRICE', 'BOROUGH']\nfor col in numer: # coerce for missing values\n    hsales[col] = pd.to_numeric(hsales[col], errors='coerce')\n\ncateg = ['NEIGHBORHOOD', 'BUILDING CLASS CATEGORY', 'TAX CLASS AT PRESENT', 'BUILDING CLASS AT PRESENT', 'BUILDING CLASS AT TIME OF SALE', 'TAX CLASS AT TIME OF SALE']\nfor col in categ:\n    hsales[col] = hsales[col].astype('category')\n\nhsales['SALE DATE'] = pd.to_datetime(hsales['SALE DATE'], errors='coerce')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ad9ec55105b12e4167f357a82f55e70f2cd2526e"},"cell_type":"markdown","source":"Our dataset is ready for checking missing values."},{"metadata":{"trusted":true,"_uuid":"5770f1480c69411091d433fa55904450593eacc9"},"cell_type":"code","source":"missing = hsales.isnull().sum()/len(hsales)*100\n\nprint(pd.DataFrame([missing[missing>0],pd.Series(hsales.isnull().sum()[hsales.isnull().sum()>1000])], index=['percent missing','how many missing']))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3863a41ad8d6d192073b399f73efa64f908891c1"},"cell_type":"markdown","source":"Around 30% of GROSS SF and LAND SF are missing. Furthermore, around 17% of SALE PRICE is also missing. Below graph indicates which parts of the table are missing values in yellow."},{"metadata":{"trusted":true,"_uuid":"d5a76044533e4b92164acd8e27dee7d1bc1cc0ce"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nplt.figure(figsize=(8,10))\nsns.heatmap(hsales.isnull(),cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Based on the missing values heatmap, we can see that some of the missing values in LAND SQUARE FEET exists in GROSS SQUARE FEET and vice versa. Assuming these two column values are close to each other, we can fill missing value from one another."},{"metadata":{"trusted":true},"cell_type":"code","source":"# let us check for outliers first\nhsales[['LAND SQUARE FEET','GROSS SQUARE FEET']].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are outliers in the lower and upper bound of the columns. We will set an upper bound of 75% for our dataset as maximum since 75th percentile of the dataset represents a good cutoff for majority of houses' square feet metrics."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot(x='LAND SQUARE FEET', y='GROSS SQUARE FEET', data=hsales[(hsales['LAND SQUARE FEET']<=3500)& (hsales['GROSS SQUARE FEET']<=2560)], kind='scatter')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is hard to notice any correlation from the scatter plot. Below is the correlation matrix."},{"metadata":{"trusted":true},"cell_type":"code","source":"hsales[(hsales['LAND SQUARE FEET']<=3500)& (hsales['GROSS SQUARE FEET']<=2560)][['LAND SQUARE FEET','GROSS SQUARE FEET']].corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see from the correlation matrix above, these two columns are positive correlated with r=0.79 (out of 1). We can now fill in the missing value from one column to another, which will help us reduce missing values. "},{"metadata":{"trusted":true},"cell_type":"code","source":"print(hsales[(hsales['LAND SQUARE FEET'].isnull()) & (hsales['GROSS SQUARE FEET'].notnull())].shape)\nprint(hsales[(hsales['LAND SQUARE FEET'].notnull()) & (hsales['GROSS SQUARE FEET'].isnull())].shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 1372 rows that can be filled in with their approximate values."},{"metadata":{"trusted":true},"cell_type":"code","source":"hsales['LAND SQUARE FEET'] = hsales['LAND SQUARE FEET'].mask((hsales['LAND SQUARE FEET'].isnull()) & (hsales['GROSS SQUARE FEET'].notnull()), hsales['GROSS SQUARE FEET'])\nhsales['GROSS SQUARE FEET'] = hsales['GROSS SQUARE FEET'].mask((hsales['LAND SQUARE FEET'].notnull()) & (hsales['GROSS SQUARE FEET'].isnull()), hsales['LAND SQUARE FEET'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"285bac6efd29981084ba241c26a45d7da53d517e"},"cell_type":"code","source":"#  Check for duplicates before\nprint(sum(hsales.duplicated()))\nhsales[hsales.duplicated(keep=False)].sort_values(['NEIGHBORHOOD', 'ADDRESS']).head(10)\n# df.duplicated() automatically excludes duplicates, to keep duplicates in df we use keep=False\n# in df.duplicated(df.columns) we can specify column names to look for duplicates only in those mentioned columns.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4e1bab31606d70e366fe9de5a550248eaad29fa5"},"cell_type":"markdown","source":"The dataframe has 765 duplicated rows (exluding the original rows). "},{"metadata":{"trusted":true,"_uuid":"6722203d52e0675a292b518391eb6095527ceb59"},"cell_type":"code","source":"hsales.drop_duplicates(inplace=True)\nprint(sum(hsales.duplicated()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing = hsales.isnull().sum()/len(hsales)*100\nprint(pd.DataFrame([missing[missing>0],pd.Series(hsales.isnull().sum()[hsales.isnull().sum()>1000])], index=['percent missing','how many missing']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can further impute the square footage of the missing observations from the existing Sale prices. However, doing so would mean some of the property square footages are being predicted by the SALE PRICE. We do not want this to happen because this might result in multicollinearity problem between square footage and SALE PRICE. Nonetheless, let us check how many missing square feet observations can be imputed from SALE PRICE. "},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The number of non-null prices for missing square feet observations:\\n\",((hsales['LAND SQUARE FEET'].isnull()) & (hsales['SALE PRICE'].notnull())).sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"non-overlapping observations that cannot be imputed:\",((hsales['LAND SQUARE FEET'].isnull()) & (hsales['SALE PRICE'].isnull())).sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hsales[hsales['COMMERCIAL UNITS']==0].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let us try to understand the columns. Above table shows descriptive statistics for the numeric columns.\n\n* There are zipcodes with 0 value\n* Can block/lot numbers go up to 16322?\n* Most of the properties have 2 unit and maximum of 1844 units? The latter might mean some company purchased a building. This should be treated as an outlier.\n* Other columns also have outliers which needs further investigation.\n* Year column has a year with 0\n* Most sales prices less than 10000 can be treated as gift or transfer fees."},{"metadata":{"trusted":true,"_uuid":"40ee0ddea4c9a038e395c99d1d192fadf791676a"},"cell_type":"code","source":"# for visualization purposes, we replace borough numbering with their string names\nhsales['BOROUGH'] = hsales['BOROUGH'].astype(str)\nhsales['BOROUGH'] = hsales['BOROUGH'].str.replace(\"1\", \"Manhattan\")\nhsales['BOROUGH'] = hsales['BOROUGH'].str.replace(\"2\", \"Bronx\")\nhsales['BOROUGH'] = hsales['BOROUGH'].str.replace(\"3\", \"Brooklyn\")\nhsales['BOROUGH'] = hsales['BOROUGH'].str.replace(\"4\", \"Queens\")\nhsales['BOROUGH'] = hsales['BOROUGH'].str.replace(\"5\", \"Staten Island\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hsales['BOROUGH'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"# house prices greater than 5 mln probably represents outliers.\nimport matplotlib.ticker as ticker\n\nsns.set_style(\"whitegrid\")\nplt.figure(figsize=(10,5))\nplotd = sns.distplot(hsales[(hsales['SALE PRICE']>100) & (hsales['SALE PRICE'] < 5000000)]['SALE PRICE'], kde=True, bins=100)\n\ntick_spacing=250000 # set spacing for each tick\nplotd.xaxis.set_major_locator(ticker.MultipleLocator(tick_spacing))\nplotd.set_xlim([-100000, 5000000]) # do not show negative values \nplt.xticks(rotation=30) # rotate x ticks by 30 degrees\nplt.axvline(hsales[(hsales['SALE PRICE']>100) & (hsales['SALE PRICE'] < 5000000)]['SALE PRICE'].mean(), c='red')\nplt.axvline(hsales[(hsales['SALE PRICE']>100) & (hsales['SALE PRICE'] < 5000000)]['SALE PRICE'].median(), c='blue')\nplt.text(250000,0.0000012, \"median\")\nplt.text(850000,0.0000010, \"mean\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can observe from the distribution plot, prices are skewed to the right. Most of the prices are around 315 and 700 thousands range. The mean is around 750,000 "},{"metadata":{"trusted":true},"cell_type":"code","source":"# The dataset seem to have lots of outliers, mainly due to commercial property sales\nsns.boxplot(x='RESIDENTIAL UNITS',data=hsales)\nplt.title('Average units per property')\nplt.show()\n#print('not included:', hsales[hsales['RESIDENTIAL UNITS']>10].shape[0], 'properties')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='COMMERCIAL UNITS',data=hsales)\nplt.title('Commercial units at property')\nplt.show()\n#print('not included:', hsales[hsales['COMMERCIAL UNITS']>20].shape[0], 'properties')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='TOTAL UNITS',data=hsales)\nplt.title('total units at property')\nplt.show()\n#print('not included:', hsales[hsales['TOTAL UNITS']>10].shape[0], 'properties')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='GROSS SQUARE FEET',data=hsales)\nplt.title('GROSS SQUARE FEET per property')\nplt.show()\n#print('not included:', hsales[hsales['GROSS SQUARE FEET']>20000].shape[0], 'properties')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Uneqaul values for total units:\", (hsales[\"TOTAL UNITS\"] != hsales['COMMERCIAL UNITS'] + hsales['RESIDENTIAL UNITS']).sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hsales[hsales[\"TOTAL UNITS\"] != hsales['COMMERCIAL UNITS'] + hsales['RESIDENTIAL UNITS']]['TOTAL UNITS'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"These uneqaul values for total unit counts are mostly equal to 1 which might mean they are not residential or commercial units."},{"metadata":{"trusted":true},"cell_type":"code","source":"hsales[(hsales[\"TOTAL UNITS\"] != hsales['COMMERCIAL UNITS'] + hsales['RESIDENTIAL UNITS']) & (hsales[\"TOTAL UNITS\"]==1)]['BUILDING CLASS CATEGORY'].value_counts()[:5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can observe those properties with 1 total units but with no residential or commercial units are parking, office or storages."},{"metadata":{},"cell_type":"markdown","source":"For visualization purposes, we will treat outliers seperately."},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = hsales[(hsales['COMMERCIAL UNITS']<20) & (hsales['TOTAL UNITS']<50) & (hsales['SALE PRICE']<5000000) & (hsales['SALE PRICE']>100000) & (hsales['GROSS SQUARE FEET']>0)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.boxplot(x='COMMERCIAL UNITS', y=\"SALE PRICE\", data=dataset)\nplt.title('Commercial Units vs Sale Price')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.boxplot(x='RESIDENTIAL UNITS', y='SALE PRICE', data=dataset)\nplt.title('Residential Units vs Sale Price')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset[dataset['YEAR BUILT']<1800]['YEAR BUILT'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset[dataset['YEAR BUILT']<1800]['BUILDING CLASS CATEGORY'].value_counts()[:15]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Above table brings some new insight into why some properties do not have a year or number of units in them. These are vacant lands, elevators, parking and garages. The question is, do they still have addresses?"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nplotd=sns.countplot(x=dataset[dataset['YEAR BUILT']>1900]['YEAR BUILT'])\n#tick_spacing=1 # set spacing for each tick\n#plotd.xaxis.set_major_locator(ticker.MultipleLocator(tick_spacing))\n#plotd.set_xlim([1900, 2020])\nplt.tick_params(labelbottom=False)\nplt.xticks(rotation=30) \nplt.title(\"Quantity of properties sold by year built\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most of the properties were built around 1920s.[](http://)"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.regplot(x='YEAR BUILT', y='SALE PRICE', data=dataset[dataset['YEAR BUILT']>1900][dataset['RESIDENTIAL UNITS']<=5], fit_reg=False, scatter_kws={'alpha':0.1})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Properties built before 1940 are higher in price."},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset[dataset['YEAR BUILT']>1900][dataset['RESIDENTIAL UNITS']<=5].plot.scatter(x='YEAR BUILT', y='SALE PRICE', c='RESIDENTIAL UNITS', cmap='coolwarm',figsize=(12,8),s=dataset[dataset['YEAR BUILT']>1900][dataset['RESIDENTIAL UNITS']<=5]['RESIDENTIAL UNITS']*10)\nplt.title('Sales Price vs year. bubble size for units')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"New properties  built after 2000 are sold for relatively cheaper prices compared to houses built in early 1900s."},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset[dataset['YEAR BUILT']>1900][dataset['RESIDENTIAL UNITS']<=5].plot.scatter(x='YEAR BUILT', y='SALE PRICE', c='GROSS SQUARE FEET', cmap='coolwarm',figsize=(12,8),s=dataset[dataset['YEAR BUILT']>1900][dataset['RESIDENTIAL UNITS']<=5]['GROSS SQUARE FEET']*.008)\nplt.title('Sales Price vs year. bubble size for gross square feet')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\norder = sorted(dataset['BUILDING CLASS CATEGORY'].unique())\nsns.boxplot(x='BUILDING CLASS CATEGORY', y='SALE PRICE', data=dataset, order=order)\nplt.xticks(rotation=90)\nplt.title('Sale Price Distribution by Bulding Class Category')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sales prices by borough\nplt.figure(figsize=(10,6))\nsns.boxplot(x='BOROUGH', y='SALE PRICE', data=dataset)\nplt.title('Sale Price Distribution by Borough')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most expensive properties are located in Manhattan with median sale price of over 2 million USD for a property. \nRelatively cheaper properties are in Bronx with median property prices of 500,000 USD."},{"metadata":{},"cell_type":"markdown","source":"# Map analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"import folium # library for interactive map drawing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from geopy.geocoders import Nominatim # get longitude and latitude based on the address\n# def get_lonlat(str_):\n#     geolocator = Nominatim()\n#     location = geolocator.geocode(str_, country_codes=\"US\")\n#     try:\n#         return location.latitude, location.longitude\n#     except:\n#         return np.nan, np.nan\n\n# import requests\n# response = requests.get('https://maps.googleapis.com/maps/api/geocode/json?address=1600+Amphitheatre+Parkway,+Mountain+View,+CA')\n# resp_json_payload = response.json()\n# print(resp_json_payload)\n\n# too many requests\n# lonlat = []\n# for val in addresses['ADDRESS']:\n#     locatn = get_lonlat(val)\n#     #print(val, locatn)\n#     lonlat.append(locatn)\n# lonlat=pd.DataFrame(lonlat, columns=[\"lon\",\"lat\"])\n# lonlat.to_csv(path_or_buf=\"/kaggle/working/lonlat.csv\",index=False)\n# print(\"saved\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"zipcodes = dataset[hsales[\"ZIP CODE\"]>0]\nzipcodes['ZIP']=zipcodes['ZIP CODE'].astype(str) # zipcodes should be str type because geojson file zipcodes are read as str ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"boroughs = zipcodes[['ZIP','BOROUGH']]\nboroughs.drop_duplicates('ZIP', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"us_zipcodes = pd.read_csv(\"../input/nyc-zipcode-geodata/uszipcodes_geodata.txt\", delimiter=',', dtype=str)\nzipcodes_agg=pd.merge(zipcodes.groupby('ZIP').agg(np.mean), us_zipcodes, how='left', on='ZIP')\nzipcodes_agg = pd.merge(zipcodes_agg, boroughs, how='left', on='ZIP')\nzipcodes_agg.loc[116,'LAT']=\"40.6933\"\nzipcodes_agg.loc[116,'LNG']=\"-73.9925\"\n#zipcodes_agg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from folium.plugins import MarkerCluster # for clustering the markers\nmap = folium.Map(location=[40.693943, -73.985880], default_zoom_start=12)\nmap.choropleth(geo_data=\"../input/nyc-zipcode-geodata/nyc-zip-code-tabulation-areas-polygons.geojson\", # I found this NYC zipcode boundaries by googling \n             data=zipcodes_agg, # my dataset\n             columns=['ZIP', 'SALE PRICE'], # zip code is here for matching the geojson zipcode, sales price is the column that changes the color of zipcode areas\n             key_on='feature.properties.postalCode', # this path contains zipcodes in str type, this zipcodes should match with our ZIP CODE column\n             fill_color='BuPu', fill_opacity=0.7, line_opacity=0.3,\n             legend_name='SALE PRICE')\n\n# add a marker for every record in the filtered data, use a clustered view\nmarker_cluster = MarkerCluster().add_to(map) # create marker clusters\nfor i in range(zipcodes_agg.shape[0]):\n    location = [zipcodes_agg['LAT'][i],zipcodes_agg['LNG'][i]]\n    tooltip = \"Zipcode:{}<br> Borough: {}<br> Click for more\".format(zipcodes_agg[\"ZIP\"][i], zipcodes_agg['BOROUGH'][i])\n    folium.Marker(location, \n                  popup=\"\"\"<i>Mean sales price: </i> <br> <b>${}</b> <br>\n                  <i>mean total units: </i><b><br>{}</b><br>\n                  <i>mean square feet: </i><b><br>{}</b><br>\"\"\".format(round(zipcodes_agg['SALE PRICE'][i],2), round(zipcodes_agg['TOTAL UNITS'][i],2), round(zipcodes_agg['GROSS SQUARE FEET'][i],2)), \n                  tooltip=tooltip).add_to(marker_cluster)\nmap","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The interactive map shows detailed average prices for each zip code. The most expensive zip codes are 10001 and 10016, 10025 which are located in Manhattan."},{"metadata":{"trusted":true},"cell_type":"code","source":"map = folium.Map(location=[40.693943, -73.985880], default_zoom_start=12)\nmap.choropleth(geo_data=\"../input/nyc-zipcode-geodata/nyc-zip-code-tabulation-areas-polygons.geojson\", # I found this NYC zipcode boundaries by googling \n             data=zipcodes, # my dataset\n             columns=['ZIP', 'SALE PRICE'], # zip code is here for matching the geojson zipcode, sales price is the column that changes the color of zipcode areas\n             key_on='feature.properties.postalCode', # this path contains zipcodes in str type, this zipcodes should match with our ZIP CODE column\n             fill_color='BuPu', fill_opacity=0.7, line_opacity=0.2,\n             legend_name='SALE PRICE')\n\n# add a marker for every record in the filtered data, use a clustered view\n# marker_cluster = MarkerCluster().add_to(map) # create marker clusters\n# for i in range(zipcodes_agg.shape[0]):\n#     location = [zipcodes_agg['LAT'][i],zipcodes_agg['LNG'][i]]\n#     tooltip = \"Zipcode:{}<br> Borough: {}<br> Click for more\".format(zipcodes_agg[\"ZIP\"][i], zipcodes_agg['BOROUGH'][i])\n#     folium.Marker(location, \n#                   popup=\"\"\"<i>Mean sales price: </i> <br> <b>${}</b> <br>\n#                   <i>mean total units: </i><b><br>{}</b><br>\n#                   <i>mean square feet: </i><b><br>{}</b><br>\"\"\".format(round(zipcodes_agg['SALE PRICE'][i],2), round(zipcodes_agg['TOTAL UNITS'][i],2), round(zipcodes_agg['GROSS SQUARE FEET'][i],2)), \n#                   tooltip=tooltip).add_to(marker_cluster)\nmap","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"map.save('mymap.html')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"More map analysis coming soon..."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}