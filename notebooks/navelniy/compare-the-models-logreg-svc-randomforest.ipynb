{"cells":[{"metadata":{"trusted":true,"_uuid":"5f9a4ea6c79f437680d7bc8a810dba92270f8db9"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn import svm\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn import linear_model\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import KFold\n\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"967768a6e7d3d83c49ee08a6f682a8bc8074c02e"},"cell_type":"code","source":"data = pd.read_csv('../input/WA_Fn-UseC_-Telco-Customer-Churn.csv')\ndata.SeniorCitizen = data.SeniorCitizen.map(lambda x: 'Yes' if x == 1 else 'No') # Convert values 1 and 0 to \"Yes\" and \"No\"\ndata['TotalCharges'] = data['TotalCharges'].replace(\" \", \"\")                     # Delete the whitespaces \ndata.TotalCharges = pd.to_numeric(data.TotalCharges)                             # Convert to float type","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"37fbfdf2f85904ad3e30c3796f31686ef8b801ad"},"cell_type":"code","source":"X = data.drop(['customerID','Churn'], axis=1)                                    # Drop dependent and ID features\nX.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a08ea2f5398802e2fccf71254357cf53a5850a66"},"cell_type":"code","source":"X.head(3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"168c4c6a1bd4b40176264beda4787b89906758df"},"cell_type":"markdown","source":"#### Split our data into the categorical and numerical features\n"},{"metadata":{"trusted":true,"_uuid":"57d1cb6e484627f1bea369dab3d4b5708a54c605"},"cell_type":"code","source":"categorical_columns = [c for c in X.columns if X[c].dtype.name == 'object']\nnumerical_columns   = [c for c in X.columns if X[c].dtype.name != 'object']\nprint('List of categorical columns: {:}.\\n \\nList of numerical: {:}'.format(categorical_columns, numerical_columns))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fb3634fb1c409cd5c7a35a2306f978ef2f485a1e"},"cell_type":"code","source":"X[categorical_columns].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"951ea3a31074b9ba28764e5b6ab2ca98e7e4ba23"},"cell_type":"code","source":"X[numerical_columns].describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e725e688f75acb610ff16e96a3aaba410a004da4"},"cell_type":"markdown","source":"#### As we can see, categorical features has no missing values, but TotalCharges  has 10 missing values in numerical features.  We can full missing values by mean value  in TotalCharges"},{"metadata":{"trusted":true,"_uuid":"19bd78aecaffce3edfdc4ec9e5ad1f4e12ae46f5"},"cell_type":"code","source":"X['TotalCharges'] = X['TotalCharges'].fillna(X['TotalCharges'].describe()['mean'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2ac386ce5d64d99533fbc46828f7664e419ac839"},"cell_type":"markdown","source":"#### Let's check linear dependence"},{"metadata":{"trusted":true,"_uuid":"9bfbaa9680ce01eb358ce10aa2e5de8b022e9f29"},"cell_type":"code","source":"data.corr() # Check linear dependence","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"461673cf4215d8fe473359ed486c4ab66cd0da0c"},"cell_type":"markdown","source":"#### Also we can see scatter plot with those features"},{"metadata":{"trusted":true,"_uuid":"a3b0c84676fdc62de61afc3183b645ff18145341"},"cell_type":"code","source":"def plotfeatures(col1, col2):\n\n    plt.figure(figsize=(10, 6))\n\n    plt.scatter(X[col1][data['Churn'] == 'Yes'],\n                X[col2][data['Churn'] == 'Yes'],\n                alpha=0.75,\n                color='red',\n                label='Yes')\n\n    plt.scatter(X[col1][data['Churn'] == 'No'],\n                X[col2][data['Churn'] == 'No'],\n                alpha=0.75,\n                color='blue',\n                label='No')\n\n    plt.xlabel(col1)\n    plt.ylabel(col2)\n    plt.legend(loc='best');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a215c79267f292cda928c10b020e8c596596286"},"cell_type":"code","source":"plotfeatures('tenure', 'TotalCharges')\nplotfeatures('MonthlyCharges', 'TotalCharges')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"950063585dce548e236b904c08c76bf4fd995756"},"cell_type":"markdown","source":"#### The features tensure and TotalCharges has high correlation (Spirman's coef r = 0.82). The features MonthlyCharges and TotalCharges also has a high correlation (r = 0.65). It's mean we have to add the new feature, which contains features with high Spearman's coef, but also we can check this: TotalCharges devided by tensure gives ~MouthlyCharges, it means you can use only MonthlyCharges. "},{"metadata":{"trusted":true,"_uuid":"ec9087030480553ef9a5405e205b4d5864c0e549"},"cell_type":"code","source":"data['MonthlyCharges_new'] = data['TotalCharges']/data['tenure']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"756260bc474a07c6625eac3346b9c4c4c6f31c87"},"cell_type":"code","source":"data.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cb746fa503e92e8a39febc05fb7730c908aa1d1d"},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aadba47cf8063f4047bdab679d2ca9d5de48e39a"},"cell_type":"markdown","source":"####  Split the categorical features to binary and nonbinary features. Then recode the binary features to {0, 1}, and the nonbinary features recode by function get_dummies."},{"metadata":{"trusted":true,"_uuid":"42060b76cf8cc470fdab995bc70504c9bbcf9928"},"cell_type":"code","source":"X = X.drop(['tenure','TotalCharges'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"956683fd09fbb3a6676b33341d589c3ea9a62ad4"},"cell_type":"code","source":"binary_columns    = [c for c in categorical_columns if X[str(c)].describe()['unique'] == 2]\nnonbinary_columns = [c for c in categorical_columns if X[str(c)].describe()['unique'] > 2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d8498ebff153cbda8e66b9903ca00cc5b0562c1c"},"cell_type":"code","source":"nonbinary_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d556d1d11c086e190d5a719c8317514231c4ddeb"},"cell_type":"code","source":"binary_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6aa9b35cdef5f3385e73a12430a0f35cdc9dbcdb"},"cell_type":"code","source":"for c in binary_columns:\n    top = X[str(c)].describe()['top']\n    top_items = X[c] == top\n    X.loc[top_items, c] = 0\n    X.loc[np.logical_not(top_items), c] = 1\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f507f54907f36a2f8af23ebf850905789b7bba36"},"cell_type":"code","source":"X_dummy = pd.get_dummies(X[nonbinary_columns])\nX = X.drop(nonbinary_columns, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c63c83f5aa5c420e0e90552c4743ad0cd58f65fc"},"cell_type":"markdown","source":"#### Scale numerical feature (MonthlyCharges)"},{"metadata":{"trusted":true,"_uuid":"3029b5a8e985ecdacc2fda95f307151450e53f8a"},"cell_type":"code","source":"X['MonthlyCharges'] = (X['MonthlyCharges'] - X['MonthlyCharges'].mean()) / X['MonthlyCharges'].std()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"98089c5478018caf081d72fa110967bc09dc8964"},"cell_type":"markdown","source":"#### Join all features together numerical and categorical (binary and nonbinary)"},{"metadata":{"trusted":true,"_uuid":"fe332510f9d3823463b05a67878fcb82005b3cbc"},"cell_type":"code","source":"X_full = pd.concat((X, X_dummy), axis=1)\n\ndata.at[data['Churn'] == 'No', 'Churn'] = 0\ndata.at[data['Churn'] == 'Yes', 'Churn'] = 1\ny = data.Churn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"085595934c4f362448e7252bc441df1c781b812c"},"cell_type":"code","source":"X_full.head(4)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a74f2881e34077293c189590705f9398acf46c63"},"cell_type":"markdown","source":"#### cross-validation with 5 Kflold"},{"metadata":{"trusted":true,"_uuid":"086a9cf5e24f9e76e5948fae08fb366c62e0c89e"},"cell_type":"code","source":"cv = KFold(n_splits=5, shuffle=True) ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5fc470b2f40e362bc60525780a3c19f7ded83826"},"cell_type":"markdown","source":"#### Build the logistic model with different metriks"},{"metadata":{"trusted":true,"_uuid":"f84362edf30c047dbc5b59052fa2b213bdf51ce9"},"cell_type":"code","source":"\nscoring = [ 'f1', 'precision', 'recall', 'roc_auc']\n\n\nfor score in scoring:\n    lr = linear_model.LogisticRegression()\n    scores = np.mean(cross_val_score(lr, X_full, y,\n                                 scoring=score,\n                                 cv=cv))\n\n    print('{} score: {}'.format(score, scores))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6456161f276ace1f777ad1aa42124837e8bae694"},"cell_type":"markdown","source":"#### RandomForest"},{"metadata":{"trusted":true,"_uuid":"657ffbb3786c8ba5589b2dd228e5a483bac62ae4"},"cell_type":"code","source":"from sklearn import ensemble\n# RandomForest can give important features. Then, this important features can use for a new model\n\nscoring = [ 'f1', 'precision', 'recall', 'roc_auc']\nfor score in scoring:\n    \n    rf = ensemble.RandomForestClassifier(n_estimators=100, random_state=11)\n    scores = np.mean(cross_val_score(rf, X_full, y,\n                             scoring=score,\n                             cv=cv))\n    \n    print('{} score: {}'.format(score, scores))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1f902055a28a554e9b9d20cf00553e47fa92158d"},"cell_type":"markdown","source":"#### Here we can figure out what is important features"},{"metadata":{"trusted":true,"_uuid":"0b4b554dc396ab40031ea16e63c1289e96b4d416"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_full, y, test_size = 0.3, random_state = 11)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71421192907e264b3fb01730cb6408842a27c7b5"},"cell_type":"code","source":"rf.fit(X_train,y_train)\nimportances = rf.feature_importances_\nindices = np.argsort(importances)[::-1]\n\nd_first = 30\nplt.figure(figsize=(8, 8))\nplt.title(\"Feature importances\")\nplt.bar(range(d_first), importances[indices[:d_first]], align='center')\nplt.xticks(range(d_first), np.array(X_full.columns)[indices[:d_first]], rotation=90)\nplt.xlim([-1, d_first]);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4479c270466c8cac6c24231864bc658095eb56c8"},"cell_type":"code","source":"best_features = indices[:15]\nbest_features_names = X_full.columns[best_features]\nprint(best_features_names)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7c024231fa2a99e2bc192d416fbfe4ada88688c7"},"cell_type":"markdown","source":"#### Create a new RandomForest model with first 15 important features"},{"metadata":{"trusted":true,"_uuid":"34c5b5ed0eef62e1a4317d7d4998b40dba5ceaad"},"cell_type":"code","source":"gbt = ensemble.RandomForestClassifier(n_estimators=100, random_state=11)\ngbt.fit(X_train[best_features_names], y_train)\n\nquality = np.mean(y_test == gbt.predict(X_test[best_features_names]))\nprint(quality)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"cd3140005c619f3b7a3ce9247f441a344e10fefe"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}