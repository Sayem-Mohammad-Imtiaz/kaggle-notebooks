{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns # data visualization library  \nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\ndata = pd.read_csv('../input/data.csv')\nimport warnings\nwarnings.filterwarnings('ignore')\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"781d616af92b2e342bf640aee7d404dabe48a543"},"cell_type":"markdown","source":"Column **id **and **Unnamed: 32** aren't needed for machine learning so, we have to drop it first"},{"metadata":{"trusted":true,"_uuid":"7465552b3c8705228ceab4de47841597d8ae1267","collapsed":true},"cell_type":"code","source":"df = data.drop(columns=['id','Unnamed: 32'])\nprint(\"Dataset size : \",df.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"125bee43e1ca4b170c3aff37a3e40bc1a6d22525"},"cell_type":"markdown","source":"## Explore the values\n"},{"metadata":{"trusted":true,"_uuid":"93926986053f4a9ba7ceb6c5460c44b61a02256d","collapsed":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e144c3a6c65cfc08da124c9e3e20b56395b8342a","collapsed":true},"cell_type":"code","source":"df.hist(figsize=(20,30),bins=50,xlabelsize=8,ylabelsize=8);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4e33f64574a93a14e5f725d91d9ab68c4d7c5db1"},"cell_type":"markdown","source":"# Training Dataset Preparation\n\nSince most of the Algorithm machine learning only accept array like as input, so we need to create an array from dataframe set to X and y\narray before running machine learning algorithm.<br>\nthe dataset is splitted by X the parameter and y for classification labels."},{"metadata":{"trusted":true,"_uuid":"4ede07bc23e8b5ed2f28e313679e46863ba4f3d1","collapsed":true},"cell_type":"code","source":"X=np.array(df.drop(columns=['diagnosis']))\ny=df['diagnosis'].values\nprint (\"X dataset shape : \",X.shape)\nprint (\"y dataset shape : \",y.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b1293d7df261487ac2a322a2d65b2071644a5389"},"cell_type":"markdown","source":"# Machine Learning Model\n\n## Import Machine Learning Library from Scikit-Learn\n\nMachine learning model used is Classification model, since the purpose of this Study case is to classify diagnosis between \"Malignant\"\n(M) Breast Cancer and \"Benign\" (B) Breast Cancer, we will be using 5 model of classification algorithm. <br>\n- Model 1 : Using Simple Logistic Regression\n- Model 2 : Using Support Vector Classifier\n- Model 3 : Using Decision Tree Classifier\n- Model 4 : Using Random Forest Classifier\n- Model 5 : Using Gradient Boosting Classifie"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e4812a1002b8329e9bf4e049fd1ff4f53d0fe5dd"},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a3008ceceec7ae4a0f0786c1ee67781e927f944c"},"cell_type":"code","source":"model_1 = LogisticRegression()\nmodel_2 = SVC()\nmodel_3 = DecisionTreeClassifier()\nmodel_4 = RandomForestClassifier()\nmodel_5 = GradientBoostingClassifier()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bc02e112f8623e43b92a595963d4b4eb8e1620c6"},"cell_type":"markdown","source":"# Model Fitting\n\nSince we need to fit the dataset into algorithm, so proper spliting dataset into training set and test set are required\n\n## Method 1. Train test split\n\nUsing Scikit learn built in tools to split data into training set and test set to check the result score of the model\ntrain_test_split configuration using 20% data to test and 80& data to train the model, random_state generator is 45"},{"metadata":{"trusted":true,"_uuid":"90e32cf4b3aeaf4c1599cc8c29f211e5567943f7","collapsed":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)\nprint (\"Train size : \",X_train.shape)\nprint (\"Test size : \",X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"42dd35caf74f6eccc1549c3eda3959ff178e690d"},"cell_type":"markdown","source":"## Fitting Training set into models"},{"metadata":{"trusted":true,"_uuid":"cffc11e779e59ad634fa8c3302e7fa9f1898d952","collapsed":true},"cell_type":"code","source":"model_1.fit(X_train,y_train)\nmodel_2.fit(X_train,y_train)\nmodel_3.fit(X_train,y_train)\nmodel_4.fit(X_train,y_train)\nmodel_5.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ba4fc8b6646f81fea2a41060da9d233271a708b5"},"cell_type":"markdown","source":"## Predict and show Score and F1 Score prediction using test data"},{"metadata":{"trusted":true,"_uuid":"934dcf2415b568a08e69ff9bc41551c54b9183b5","collapsed":true},"cell_type":"code","source":"# Predict data\ny_pred1=model_1.predict(X_test)\ny_pred2=model_2.predict(X_test)\ny_pred3=model_3.predict(X_test)\ny_pred4=model_4.predict(X_test)\ny_pred5=model_5.predict(X_test)\n#Show F1 Score\nfrom sklearn.metrics import f1_score\nf1_model1=f1_score(y_test,y_pred1,average='weighted',labels=np.unique(y_pred1))\nf1_model2=f1_score(y_test,y_pred2,average='weighted',labels=np.unique(y_pred2))\nf1_model3=f1_score(y_test,y_pred3,average='weighted',labels=np.unique(y_pred3))\nf1_model4=f1_score(y_test,y_pred4,average='weighted',labels=np.unique(y_pred4))\nf1_model5=f1_score(y_test,y_pred5,average='weighted',labels=np.unique(y_pred5))\nprint(\"F1 score Model 1 : \",f1_model1)\nprint(\"F1 score Model 2 : \",f1_model2)\nprint(\"F1 score Model 3 : \",f1_model3)\nprint(\"F1 score Model 4 : \",f1_model4)\nprint(\"F1 score Model 5 : \",f1_model5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3519b152612f6d497dac8b87c56418b27aa8cfd8"},"cell_type":"markdown","source":"## Method 2. Cross validation method\nUsing Cross validation will resulted in more reliability of the model. <br>\nin this case using StratifiedKFold from Scikit Learn, with n_split = 10 times and Shuffle = True."},{"metadata":{"trusted":true,"_uuid":"e33edd3e3cf94c28776393cd41995d25d1c21a4f","collapsed":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nskf = StratifiedKFold(n_splits=10, shuffle=True)\nskf.get_n_splits(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"96c9e0833c05744820ddfe935752af70b4322b33"},"cell_type":"code","source":"StratifiedKFold?","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d16e2e585d055a2c7a82f04c5de7023eea1ec39","collapsed":true},"cell_type":"code","source":"# Set Container to gather the cross validation result of the model\nscore_list_model1,score_list_model2,score_list_model3,score_list_model4,score_list_model5 = [],[],[],[],[]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d2427f07da6714e9d70e7e04b321f162a492ab37","collapsed":true},"cell_type":"code","source":"for train_index, test_index in skf.split(X,y):\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    model_1.fit(X_train, y_train)\n    model_2.fit(X_train, y_train)\n    model_3.fit(X_train, y_train)\n    model_4.fit(X_train, y_train)\n    model_5.fit(X_train, y_train)\n    y_pred1=model_1.predict(X_test)\n    y_pred2=model_2.predict(X_test)\n    y_pred3=model_3.predict(X_test)\n    y_pred4=model_4.predict(X_test)\n    y_pred5=model_5.predict(X_test)\n    score_list_model1.append(f1_score(y_test,y_pred1,average='weighted',labels=np.unique(y_pred1)))\n    score_list_model2.append(f1_score(y_test,y_pred2,average='weighted',labels=np.unique(y_pred2)))\n    score_list_model3.append(f1_score(y_test,y_pred3,average='weighted',labels=np.unique(y_pred3)))\n    score_list_model4.append(f1_score(y_test,y_pred4,average='weighted',labels=np.unique(y_pred4)))\n    score_list_model5.append(f1_score(y_test,y_pred5,average='weighted',labels=np.unique(y_pred5)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b66860e37e2fb5122c87ceb36cb94720e136968c","collapsed":true},"cell_type":"code","source":"score_table = pd.DataFrame({\"F1 Score model 1\" :score_list_model1,\"F1 Score model 2\" :score_list_model2,\"F1 Score model 3\" :score_list_model3,\"F1 Score model 4\" :score_list_model4,\"F1 Score model 5\" :score_list_model5})\n\nscore_table","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"73417b91a591335cab1d8c6ce82a71452e5a5f85","collapsed":true},"cell_type":"code","source":"final_1=np.mean(score_list_model1)\nfinal_2=np.mean(score_list_model2)\nfinal_3=np.mean(score_list_model3)\nfinal_4=np.mean(score_list_model4)\nfinal_5=np.mean(score_list_model5)\nprint(\"F1 Score Average Model_1 :\",final_1)\nprint(\"F1 Score Average Model_2 :\",final_2)\nprint(\"F1 Score Average Model_3 :\",final_3)\nprint(\"F1 Score Average Model_4 :\",final_4)\nprint(\"F1 Score Average Model_5 :\",final_5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8d2d769d3d9e6645c334fc159ccb6104a295bf7c"},"cell_type":"markdown","source":"# Conclusion\n\nAfter Testing 5 Model of machine learning classifier and testing both using train test split and cross validation method, conclude that\nModel 5 which is Gradient Boosting winc with crossvalidation F1 Score 0.96"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e841eef6e607e3822ec8de7d80e30aa44cffad96"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}