{"cells":[{"metadata":{},"cell_type":"markdown","source":"importing libraries","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport sklearn ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loading data ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"check missing any data ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ther is no missing data but we need to check if there reviews that conten empty space only \nso this for loop will search for any empty reviews and add it's id to a list(blanks)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"blanks = [] \nfor i , label , review in df.itertuples() :\n    if review.isspace() :\n        blanks.append(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(blanks))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"so there is no empty reviews \nnow our data is clean ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"sentiment\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we have the same amount of data for each cateogry \nnow we can split our data ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x = df[\"review\"]\ny = df[\"sentiment\"]\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size = .3 ,random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (f\"x_train shape is {x_train.shape}\")\nprint (f\"x_test shape is {x_test.shape}\")\nprint (f\"y_train shape is {y_train.shape}\")\nprint (f\"y_test shape is {y_test.shape}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"now we can make our model \nfirst we will extract features from text and foccusing in words which repeated many time by using TfidfVectorizer, then we will use LinearSVC() to make our classification \nand we will collect all this steps in pipeline ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline \nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.svm import LinearSVC","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Pipeline([(\"tdidf\" , TfidfVectorizer()) , (\"svc\" , LinearSVC())])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"now we will make our predictions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"evaluate our predictions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score,confusion_matrix,classification_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(y_test,predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test,predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test,predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}