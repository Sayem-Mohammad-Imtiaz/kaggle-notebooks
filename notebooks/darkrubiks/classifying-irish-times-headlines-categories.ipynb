{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Checking the Dataset"},{"metadata":{},"cell_type":"markdown","source":"### Context\nThis news dataset is a collection of 1.42 million news headlines published by The Irish Times based in Ireland.\n\nCreated over 159 Years ago the agency provides a long term birds eye view of the happenings of Europe.\n\nAgency Website: https://www.irishtimes.com\n\nThe historical reels can be explored thoroughly via the archives portal."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/ireland-historical-news/irishtimes-date-text.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cleaning the Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop_duplicates(inplace=True) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the next lines of code I separated the year, month and day into 3 other columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"year = [] \nmonth = [] \nday = [] \n\ndates = data.publish_date.values\n\nfor date in dates:\n    str_date = list(str(date))\n    year.append(int(\"\".join(str_date[0:4]))) \n    month.append(int(\"\".join(str_date[4:6])))\n    day.append(int(\"\".join(str_date[6:8])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['year'] = year\ndata['month'] = month\ndata['day'] = day\n\ndata.drop(['publish_date'] , axis=1,inplace=True) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Unique Headlines Categories: {}'.format(len(data.headline_category.unique())))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can merge some headlines categories, let's use the most common ones. "},{"metadata":{"trusted":true},"cell_type":"code","source":"set([category for category in data.headline_category if \".\" not in category] ) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.headline_category = data.headline_category.apply(lambda x: x.split(\".\")[0]) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nax = sns.countplot(data.headline_category) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Im going to use the WordNetLemmatizer and stopwords with punctuation for filtering the text."},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.corpus import stopwords \nfrom nltk.tokenize import WordPunctTokenizer\nfrom string import punctuation\nfrom nltk.stem import WordNetLemmatizer\nimport regex\n\nwordnet_lemmatizer = WordNetLemmatizer()\n\nstop = stopwords.words('english')\n\nfor punct in punctuation:\n    stop.append(punct)\n\ndef filter_text(text, stop_words):\n    word_tokens = WordPunctTokenizer().tokenize(text.lower())\n    filtered_text = [regex.sub(u'\\p{^Latin}', u'', w) for w in word_tokens if w.isalpha()]\n    filtered_text = [wordnet_lemmatizer.lemmatize(w, pos=\"v\") for w in filtered_text if not w in stop_words] \n    return \" \".join(filtered_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"filtered_text\"] = data.headline_text.apply(lambda x : filter_text(x, stop)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploring the Data"},{"metadata":{},"cell_type":"markdown","source":"## Date analysis "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nax = sns.lineplot(x=data.year.value_counts().index.values,y=data.year.value_counts().values)\nax = plt.title('Number of Published News by Year')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nax = sns.lineplot(x=data.month.value_counts().index.values,y=data.month.value_counts().values)\nax = plt.title('Number of Published News by Month')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nax = sns.lineplot(x=data.day.value_counts().index.values,y=data.day.value_counts().values)\nax = plt.title('Number of Published News by Day')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Word Clouds"},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud\n\ndef make_wordcloud(words,title):\n    cloud = WordCloud(width=1920, height=1080,max_font_size=200, max_words=300, background_color=\"white\").generate(words)\n    plt.figure(figsize=(20,20))\n    plt.imshow(cloud, interpolation=\"gaussian\")\n    plt.axis(\"off\") \n    plt.title(title, fontsize=60)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_text = \" \".join(data[data.headline_category == \"news\"].filtered_text) \nmake_wordcloud(all_text, \"News\") ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_text = \" \".join(data[data.headline_category == \"culture\"].filtered_text) \nmake_wordcloud(all_text, \"Culture\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_text = \" \".join(data[data.headline_category == \"opinion\"].filtered_text) \nmake_wordcloud(all_text, \"Opinion\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_text = \" \".join(data[data.headline_category == \"business\"].filtered_text) \nmake_wordcloud(all_text, \"Business\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_text = \" \".join(data[data.headline_category == \"sport\"].filtered_text) \nmake_wordcloud(all_text, \"Sport\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_text = \" \".join(data[data.headline_category == \"lifestyle\"].filtered_text) \nmake_wordcloud(all_text, \"Lifestyle\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see in the word clouds above, each category have very different words, that is very good for the next part which is text classification."},{"metadata":{},"cell_type":"markdown","source":"# Predicting the Headlines Categories"},{"metadata":{},"cell_type":"markdown","source":"Im using the TFIDF Vectorizer to create the input data for the Machine Learning algorithm."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidf = TfidfVectorizer(lowercase=False)\nml_data = tfidf.fit_transform(data['filtered_text'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ml_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['classification'] = data['headline_category'].replace(['news','culture','opinion','business','sport','lifestyle'],[0,1,2,3,4,5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(ml_data,data['classification'], stratify=data['classification'], test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I chose to work with the Logistic Regression."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, cohen_kappa_score, confusion_matrix\n\nmodel = LogisticRegression(solver='lbfgs',multi_class='auto', max_iter=1000)\nmodel.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here are the final results:"},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted = model.predict(x_test)\nprint(\"Test score: {:.2f}\".format(accuracy_score(y_test,predicted)))\nprint(\"Cohen Kappa score: {:.2f}\".format(cohen_kappa_score(y_test,predicted)))\nplt.figure(figsize=(15,10))\nax = sns.heatmap(confusion_matrix(y_test,predicted),annot=True)\nax = ax.set(xlabel='Predicted',ylabel='True',title='Confusion Matrix',\n            xticklabels=(['news','culture','opinion','business','sport','lifestyle']),\n            yticklabels=(['news','culture','opinion','business','sport','lifestyle']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Most Important Words for the classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_most_important_words(model,index,category):\n    base = {'news':0,'culture':1,'opinion':2,'business':3,'sport':4,'lifestyle':5}\n    t=pd.DataFrame(model.coef_[base[category]].T, index=tfidf.get_feature_names()) \n    return pd.concat([t.nlargest(5,0),t.nsmallest(5,0)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"index = tfidf.get_feature_names()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_most_important_words(model,index,'news')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_most_important_words(model,index,'culture')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_most_important_words(model,index,'opinion')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_most_important_words(model,index,'business')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_most_important_words(model,index,'sport')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_most_important_words(model,index,'lifestyle')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}