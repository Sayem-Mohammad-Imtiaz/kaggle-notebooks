{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score \nfrom sklearn.metrics import confusion_matrix, precision_recall_curve, roc_curve, auc, log_loss\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_original = pd.read_csv('/kaggle/input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv')\ndf_original.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_original.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we can see that Total Charges is object type so now we will convert this to float."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_original['TotalCharges'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#replacing blank spaces with none\ndf_original= df_original.replace(' ',np.nan)\n#coverting string to float datatype\ndf_original['TotalCharges'] = df_original['TotalCharges'].astype(float)\ndf_original['TotalCharges'].dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_original.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#percentage of missing value\n(df_original['TotalCharges'].isnull().sum()/df_original.shape[0])*100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we can see the percentage of missing values in Total Charges is even less than 1 percent. so we can delete it."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_original = df_original.dropna()\ndf_original.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#get all categorical columns from dataframe\ndf_categorical_col  = df_original.select_dtypes(include = 'object').columns\ndf_categorical_col","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#get all numerical columns from dataframe\ndf_numerical_col  = df_original.select_dtypes(exclude = 'object').columns\ndf_numerical_col","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# it will the statistical values of the numerical columns\ndf_original.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking data is balanced or imbalanced\ndf_original['Churn'].value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"slices_churn = df_original['Churn'].value_counts().tolist()\nlables = ['No', 'Yes']\ncolors = ['y', 'g']\nplt.pie(slices_churn, labels=lables, colors=colors, startangle=90, autopct='%.1f%%')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_original['SeniorCitizen'].value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsns.boxplot(data = df_original, y = 'MonthlyCharges', x = 'Churn')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(data = df_original, y = 'TotalCharges', x = 'Churn')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems quite interesting. In the plot of monthly charges, lower charges users are seems to have lower Churn rates. However, in the ploty of total charges, lower charge users are seems to have hihger Chrun rate."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=[8,6])\nplt.scatter(df_original[\"TotalCharges\"].values, range(df_original.shape[0]))\nplt.title(\"Distribution of Total Charges\")\nplt.xlabel(\"Total charges\");\nplt.ylabel(\"Number of Occurences\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"it seems there are very rare outliers, so we do not need to treat it."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_original.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = ['Churn','tenure','MonthlyCharges','TotalCharges' ]\nsns.pairplot(df_original[cols],hue = 'Churn')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df_original[df_original.Churn == 'Yes']\nsns.distplot(df['TotalCharges'], hist = False, kde = True, label='Yes')\n\ndf = df_original[df_original.Churn == 'No']\nsns.distplot(df['TotalCharges'], hist = False, kde = True, label='No')\n# Plot formatting\nplt.legend(prop={'size': 12})\nplt.title('Chrun Yes vs No')\nplt.xlabel('Total Charges')\nplt.ylabel('value')  \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df_original[df_original.Churn == 'Yes']\nsns.distplot(df['MonthlyCharges'], hist = False, kde = True, label='Yes')\n\ndf = df_original[df_original.Churn == 'No']\nsns.distplot(df['MonthlyCharges'], hist = False, kde = True, label='No')\n# Plot formatting\nplt.legend(prop={'size': 12})\nplt.title('Chrun Yes vs No')\nplt.xlabel('MonthlyCharges')\nplt.ylabel('Fequency ')  \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_original['SeniorCitizen'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='SeniorCitizen', hue=\"Churn\", data=df_original)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### shorter the contract period, higher probability of churn\nct  = pd.crosstab(df_original.Contract, df_original.Churn)\nct.plot(kind='bar')\nplt.title('Churn by Contract')\nplt.ylabel(\"# of chrun\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install plotly","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we will binarize the categorical columns having two values i.e. yes/no yes = 1, no = 0\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_values_columns = []\nfor i in df_original.columns:\n    length = len(df_original[i].unique())\n    unique_values_columns.append(length)\nprint(unique_values_columns)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#get all the unique values of columns\n#df_original.nunique()\ncol_unique_values = pd.Series(unique_values_columns, \n               index=df_original.columns.tolist(), name='col_unique_values')\ncol_unique_values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#get the columns values that has two unique values eg. yes/no, male/female\ncols_two_unique_values =col_unique_values[col_unique_values  == 2].index.tolist() \ncols_two_unique_values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ncols_two_unique_values[0:6]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_label = df_original.drop('Churn',axis = 1)\ndf_label.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# instantiate labelencoder object\nle = LabelEncoder()\nfor i in cols_two_unique_values[0:6]:\n    df_label[i] =le.fit_transform(df_label[i])\ndf_label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_label.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Churn is the target variable that is why we manually assign 0 to NO,Yes to 1 value\ndict = {'Yes':1,'No':0}\ndf_original['Churn_label']=df_original['Churn'].map(dict)\ndf_original.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_label['Churn_label']=df_original['Churn_label']\ndf_label.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#customer id seems to be irrelevent column so we are dropping it\ndf_label=df_label.drop('customerID', axis = 1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df =df_label.copy()\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dummification for the remainingg categorical columns\ncat_lable_col =col_unique_values[(col_unique_values >2) & col_unique_values[(col_unique_values <5)]] \n\ndf_label = pd.get_dummies(data = df_label,columns = cat_lable_col.index )\n\ndf_label.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_label.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# normalization for columns that has large variance\ndf_final = df_label[['TotalCharges','tenure','MonthlyCharges']]\ndf_normalized = (df_final- df_final.mean())/df_final.std()\ndf_label= df_label.drop(['TotalCharges','tenure','MonthlyCharges'],1)\ndf_label=pd.concat([df_label,df_normalized], axis = 1)\ndf_label.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Train test split and Base Model Fitting****"},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\nfrom sklearn.model_selection import train_test_split\nX = df_label.drop(['Churn_label'], axis = 1)\ny = df_label['Churn_label']\nx_train,x_test,y_train,y_test = train_test_split(X,y)\nglm_binom = sm.GLM(y_train,(sm.add_constant(x_train)), family=sm.families.Binomial())\nres = glm_binom.fit()\nprint(res.summary())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Base Logistic regression model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"### model fitting using logistic regression\nfrom sklearn.linear_model import LogisticRegression\n# initialize logistic regression\nlm = LogisticRegression()\nfitted=lm.fit(x_train, y_train)\ny_pred = lm.predict(x_test)\ny_pred_proba = lm.predict_proba(x_test)[:, 1]\nscores = lm.score(x_test, y_test)\nprint(\"Logistic Regression score is.:\" + str(lm.score(x_test,y_test)))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ny_pred_proba = lm.predict_proba(x_test)[:, 1]\n[fpr, tpr, thr] = metrics.roc_curve(y_test, y_pred_proba)\nprint('Train/Test split results:')\nprint(lm.__class__.__name__+\" accuracy is %2.3f\" % metrics.accuracy_score(y_test, y_pred))\nprint(lm.__class__.__name__+\" log_loss is %2.3f\" % metrics.log_loss(y_test, y_pred_proba))\nprint(lm.__class__.__name__+\" auc is %2.3f\" % metrics.auc(fpr, tpr))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Evalutation Using AUC/ROC**"},{"metadata":{"trusted":true},"cell_type":"code","source":"fpr, tpr, thres = metrics.roc_curve(y_test, y_pred)\nroc_auc = metrics.auc(fpr,tpr)\nplt.figure()\nlw = 2\nplt.plot(fpr, tpr, color='darkorange',\n         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic example')\nplt.legend(loc=\"lower right\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we can see our roc curve is 0.75."},{"metadata":{},"cell_type":"markdown","source":"**Model evaluation based on K-fold cross-validation using cross_validate() function**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Applying K fold cross validation\n\n\nscores_accuracy = cross_val_score(lm, X, y, cv=10, scoring='accuracy')\nscores_log_loss = cross_val_score(lm, X, y, cv=10, scoring='neg_log_loss')\nscores_auc = cross_val_score(lm, X, y, cv=10, scoring='roc_auc')\nprint('K-fold cross-validation results:')\nprint(lm.__class__.__name__+\" average accuracy is %2.3f\" % scores_accuracy.mean())\nprint(lm.__class__.__name__+\" average log_loss is %2.3f\" % -scores_log_loss.mean())\nprint(lm.__class__.__name__+\" average auc is %2.3f\" % scores_auc.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(24,12))\ncm_lr = confusion_matrix(y_test, y_pred)\nplt.subplot(2,3,2)\nplt.title(\"Logistic Regression Confusion Matrix\")\nprint(sns.heatmap(cm_lr,annot=True,cmap=\"Blues\",fmt=\"d\",cbar=False, annot_kws={\"size\": 24}))\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test,y_pred))\nprint(accuracy_score(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Accuracy is 65%**\n**Churn Rate    -->31%**\n**NonChurn Rate -->75%**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Hyperparameter tuning for Logistic Regression\nfrom sklearn.model_selection import GridSearchCV\npenalty = ['l1', 'l2']\nC = np.logspace(0, 4, 10)\nhyperparameters = {\n    'C':C,\n    'penalty':penalty\n}\n\nh_logmodel = GridSearchCV(lm, hyperparameters, cv=5, verbose=0)\nbest_logmodel=h_logmodel.fit(X,y)\nbest_logmodel.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### model fitting using logistic regression\nfrom sklearn.linear_model import LogisticRegression\n# initialize logistic regression\nlm = LogisticRegression(penalty='l2',C=166)\nfitted=lm.fit(x_train, y_train)\ny_pred = lm.predict(x_test)\ny_pred_proba = lm.predict_proba(x_test)[:, 1]\nscores = lm.score(x_test, y_test)\nprint(\"Logistic Regression score is.:\" + str(lm.score(x_test,y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"C","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}