{"cells":[{"metadata":{},"cell_type":"markdown","source":"Plan for the project:\n\n1. Loading the dataset: Load the data and import the libraries.\n2. Data Preprocessing:\n    1. Analysing missing data\n    2. Removing redundant columns.\n3. Visualising and counting sentiments of tweets for each airline\n4. Wordcloud plots for positive and negative tweets to visualise most frequent words for each.\n5. Analysing the reasons for negative tweets for each airline.\n6. Visualising negative tweet-sentiment relationship with dates.\n7. Predicting the tweet sentiments with tweet text data with:\n    Decision Tree Classifier\n    Random Forest Classifier\n8. Calculating accuracies, plotting the confusion matrix and comparing the models.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Importing required Libraries","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport os\nprint(os.listdir(\"../input/twitter-airline-sentiment/\"))\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom sklearn.model_selection import train_test_split\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/twitter-airline-sentiment/Tweets.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To analyse Dataframe","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Shape of the dataframe is\",df.shape)\nprint(\"The number of nulls in each column are \\n\", df.isna().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#percentage of Null values present \nprint(\"Percentage null or na values in df\")\n((df.isnull() | df.isna()).sum() * 100 / df.index.size).round(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"tweet_coord , airline_sentiment_gold, negativereason_gold have more than 90% missing data. It will be better to delete these columns as they will not provide any constructive information.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"del df['tweet_coord']\ndel df['airline_sentiment_gold']\ndel df['negativereason_gold']\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Airline sentiments for each airline","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Total number of tweets for each airline \\n \",df.groupby('airline')['airline_sentiment'].count().sort_values(ascending=False))\nairlines= ['US Airways','United','American','Southwest','Delta','Virgin America']\nplt.figure(1,figsize=(12, 12))\nfor i in airlines:\n    indices= airlines.index(i)\n    plt.subplot(2,3,indices+1)\n    new_df=df[df['airline']==i]\n    count=new_df['airline_sentiment'].value_counts()\n    Index = [1,2,3]\n    plt.bar(Index,count, color=['red', 'green', 'blue'])\n    plt.xticks(Index,['negative','neutral','positive'])\n    plt.ylabel('Mood Count')\n    plt.xlabel('Mood')\n    plt.title('Count of Moods of '+i)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most used words in Positive and Negative tweets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud,STOPWORDS\n\n# for negative sentiments\n\nnew_df=df[df['airline_sentiment']=='negative']\nwords = ' '.join(new_df['text'])\ncleaned_word = \" \".join([word for word in words.split()\n                            if 'http' not in word\n                                and not word.startswith('@')\n                                and word != 'RT'\n                            ])\nwordcloud = WordCloud(stopwords=STOPWORDS,\n                      background_color='black',\n                      width=3000,\n                      height=2500\n                     ).generate(cleaned_word)\nplt.figure(1,figsize=(12, 12))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()\n\n# for positive\n\nnew_df=df[df['airline_sentiment']=='positive']\nwords = ' '.join(new_df['text'])\ncleaned_word = \" \".join([word for word in words.split()\n                            if 'http' not in word\n                                and not word.startswith('@')\n                                and word != 'RT'\n                            ])\nwordcloud = WordCloud(stopwords=STOPWORDS,\n                      background_color='black',\n                      width=3000,\n                      height=2500\n                     ).generate(cleaned_word)\nplt.figure(1,figsize=(12, 12))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"analysis of positive sentiment and negative sentiment","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate highest frequency words in positive tweets\ndef freq(str): \n  \n    # break the string into list of words  \n    str = str.split()          \n    str2 = [] \n  \n    # loop till string values present in list str \n    for i in str:              \n  \n        # checking for the duplicacy \n        if i not in str2: \n  \n            # insert value in str2 \n            str2.append(i)  \n              \n    for i in range(0, len(str2)): \n        if(str.count(str2[i])>50): \n            print('Frequency of', str2[i], 'is :', str.count(str2[i]))\n        \nprint(freq(cleaned_word))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"for negative we try to check what is the reason for negative review.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#get the number of negative reasons\ndf['negativereason'].nunique()\n\nNR_Count=dict(df['negativereason'].value_counts(sort=False))\ndef NR_Count(Airline):\n    if Airline=='All':\n        a=df\n    else:\n        a=df[df['airline']==Airline]\n    count=dict(a['negativereason'].value_counts())\n    Unique_reason=list(df['negativereason'].unique())\n    Unique_reason=[x for x in Unique_reason if str(x) != 'nan']\n    Reason_frame=pd.DataFrame({'Reasons':Unique_reason})\n    Reason_frame['count']=Reason_frame['Reasons'].apply(lambda x: count[x])\n    return Reason_frame\ndef plot_reason(Airline):\n    \n    a=NR_Count(Airline)\n    count=a['count']\n    Index = range(1,(len(a)+1))\n    plt.bar(Index,count, color=['red','yellow','blue','green','black','brown','gray','cyan','purple','orange'])\n    plt.xticks(Index,a['Reasons'],rotation=90)\n    plt.ylabel('Count')\n    plt.xlabel('Reason')\n    plt.title('Count of Reasons for '+Airline)\n    \nplot_reason('All')\nplt.figure(2,figsize=(13, 13))\nfor i in airlines:\n    indices= airlines.index(i)\n    plt.subplot(2,3,indices+1)\n    plt.subplots_adjust(hspace=0.9)\n    plot_reason(i)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Is there a relationship between negative sentiments and date ?\nOur dataframe has data from 2015-02-17 to 2015-02-24\n\nIt will be interesting to see if the date has any effect on the sentiments of the tweets(especially negative !). We can draw various coclusions by visualizing this.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"date = df.reset_index()\n#convert the Date column to pandas datetime\ndate.tweet_created = pd.to_datetime(date.tweet_created)\n#Reduce the dates in the date column to only the date and no time stamp using the 'dt.date' method\ndate.tweet_created = date.tweet_created.dt.date\ndate.tweet_created.head()\ndf = date\nday_df = df.groupby(['tweet_created','airline','airline_sentiment']).size()\n# day_df = day_df.reset_index()\nday_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our next step will be to plot this and get better visualization for negative tweets.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"day_df = day_df.loc(axis=0)[:,:,'negative']\n\n#groupby and plot data\nax2 = day_df.groupby(['tweet_created','airline']).sum().unstack().plot(kind = 'bar', color=['red', 'green', 'blue','yellow','purple','orange'], figsize = (15,6), rot = 70)\nlabels = ['American','Delta','Southwest','US Airways','United','Virgin America']\nax2.legend(labels = labels)\nax2.set_xlabel('Date')\nax2.set_ylabel('Negative Tweets')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Preprocessing the tweet text data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now, we will clean the tweet text data and apply classification algorithms on it\n\ndef tweet_to_words(tweet):\n    letters_only = re.sub(\"[^a-zA-Z]\", \" \",tweet) \n    words = letters_only.lower().split()                             \n    stops = set(stopwords.words(\"english\"))                  \n    meaningful_words = [w for w in words if not w in stops] \n    return( \" \".join( meaningful_words )) \n\ndf['clean_tweet']=df['text'].apply(lambda x: tweet_to_words(x))\n\n# The data is split in the standard 80,20 ratio.\n\ntrain,test = train_test_split(df,test_size=0.2,random_state=42)\n\ntrain_clean_tweet=[]\n\nfor tweet in train['clean_tweet']:\n    train_clean_tweet.append(tweet)\n    \ntest_clean_tweet=[]\nfor tweet in test['clean_tweet']:\n    test_clean_tweet.append(tweet)\n    \n# using count vectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\nv = CountVectorizer(analyzer = \"word\")\ntrain_features= v.fit_transform(train_clean_tweet)\ntest_features=v.transform(test_clean_tweet)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using DT classifier and random forest classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Classifiers = [\n    DecisionTreeClassifier(),\n    RandomForestClassifier(n_estimators=200)]\n\ndense_features=train_features.toarray()\ndense_test= test_features.toarray()\nAccuracy=[]\nModel=[]\n\nfor classifier in Classifiers:\n    try:\n        fit = classifier.fit(train_features,train['airline_sentiment'])\n        pred = fit.predict(test_features)\n    except Exception:\n        fit = classifier.fit(dense_features,train['airline_sentiment'])\n        pred = fit.predict(dense_test)\n    accuracy = accuracy_score(pred,test['airline_sentiment'])\n    Accuracy.append(accuracy)\n    Model.append(classifier.__class__.__name__)\n    print('Accuracy of '+classifier.__class__.__name__+'is '+str(accuracy))\n    print(classification_report(pred,test['airline_sentiment']))\n    cm=confusion_matrix(pred , test['airline_sentiment'])\n    plt.figure()\n    plot_confusion_matrix(cm,figsize=(12,8), hide_ticks=True,cmap=plt.cm.Reds)\n    plt.xticks(range(2), ['Negative', 'Neutral', 'Positive'], fontsize=16,color='black')\n    plt.yticks(range(2), ['Negative', 'Neutral', 'Positive'], fontsize=16)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we you can see above we have plotted the confusion matrix for predicted sentiments and actual sentiments (negative,neutral and positive)\nRandom Forest Classifier gives us the best accuracy score, precision scores according to the classification report.\nThe confusion matrix shows the TP,TN,FP,FN for all the 3 sentiments(negative,neutral and positive),Here also Random Forest Classifier gives better results than the Decision Tree Classifier.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Vader baseline ahead","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\n\nanalyser = SentimentIntensityAnalyzer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentences = pd.read_csv(\"../input/twitter-airline-sentiment/Tweets.csv\")\n\nlen(sentences)\n\nsentences.columns\nsentences.head()\n\n# How does United stack up against its competitors (based on human scoring)?\nsentences.groupby(['airline', 'airline_sentiment']).size().unstack().plot(kind='bar',figsize=(11, 5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentences = sentences[['airline_sentiment', 'airline','text' ]] #this is all I need\nsentences.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentences = sentences[sentences['airline']=='United'] #filtering dataset for United\nprint(len(sentences))\nsentences = sentences.reset_index(drop = True)\nsentences.head(10)\n\nsentences.groupby('airline_sentiment').size().plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_sentiment_scores(sentence):\n    snt = analyser.polarity_scores(sentence)  #Calling the polarity analyzer\n    print(\"{:-<40} {}\".format(sentence, str(snt)))\nprint_sentiment_scores(\"United flight was a bad experience\")\n\n%time   #to calulate the time it takes the algorithm to compute a VADER score\n\ni=0 #counter\n\ncompval1 = [ ]  #empty list to hold our computed 'compound' VADER scores\n\n\nwhile (i<len(sentences)):\n\n    k = analyser.polarity_scores(sentences.iloc[i]['text'])\n    compval1.append(k['compound'])\n    \n    i = i+1\n    \n#converting sentiment values to numpy for easier usage\n\ncompval1 = np.array(compval1)\n\nlen(compval1)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}