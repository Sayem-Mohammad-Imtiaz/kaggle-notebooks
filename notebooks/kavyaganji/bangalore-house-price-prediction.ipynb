{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"markdown","source":"# **Bangalore House Price Prediction**"},{"metadata":{},"cell_type":"markdown","source":"**The main goal of this project is to find the price of the Bangalore house using their features.**"},{"metadata":{},"cell_type":"markdown","source":"##  **Import Libraries**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\n%matplotlib inline\nimport matplotlib \nmatplotlib.rcParams[\"figure.figsize\"] = (20,10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Load Dataset**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = pd.read_csv(\"../input/bengaluru-house-price-data/Bengaluru_House_Data.csv\")\ndf1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Exploratory Data Analysis**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the information of data\ndf1.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1['area_type'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1['area_type'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.scatterplot(df1['balcony'], df1['price'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df1['area_type'], hue='balcony', data=df1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot(x=df1['bath'], y=df1['price'], data=df1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.describe()\n# We have only 3 neumerical features - bath, balcony and price\n# 6 categorical features - area type, availability, size, society, and total_srft\n# Target Feature =======>>>>>> price >>>>>>\n# Price in lakh\n \n#observe 75% and max value it shows huge diff","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df1)\n\n# bath and price have slightly linear correlation with some outliers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# value count of each feature\ndef value_count(df1):\n  for var in df1.columns:\n    print(df1[var].value_counts())\n    print(\"--------------------------------\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"value_count(df1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# correlation heatmap\nnum_vars = [\"bath\", \"balcony\", \"price\"]\nsns.heatmap(df1[num_vars].corr(),cmap=\"coolwarm\", annot=True)\n \n# correlation of bath is greater than a balcony with price","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Data Cleaning: Handle NA values**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.isnull().mean()*100 # % of measing value\n\n#society has 41.3% missing value (need to drop)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualize missing value using heatmap to get idea where is the value missing\n \nplt.figure(figsize=(16,9))\nsns.heatmap(df1.isnull())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del_col = ['area_type','availability','society','balcony']\ndf2 = df1.drop(del_col, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop na value rows from df2\n# because there is very less % value missing\ndf3 = df2.dropna()\ndf3.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df3.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df3.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Feature Engineering**"},{"metadata":{},"cell_type":"markdown","source":"## **Working on size feature**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df3['size'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df3['bhk'] = df3['size'].apply(lambda x : int(x.split(' ')[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df3.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def is_float(x):\n    try:\n        float(x)\n    except:\n        return False\n    return True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df3[~df3['total_sqft'].apply(is_float)].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# here we observe that 'total_sqft' contain string value in diff format\n#float, int like value 1689.28,817 \n# range value: 540 - 740 \n# number and string: 142.84Sq. Meter, 117Sq. Yards, 1Grounds\n \n# best strategy is to convert it into number by spliting it\n\ndef convert_sqft_to_num(x):\n    tokens = x.split('-')\n    if len(tokens) == 2:\n        return (float(tokens[0])+float(tokens[1]))/2\n    try:\n        return float(x)\n    except:\n        return None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df4 = df3.copy()\ndf4['total_sqft'] = df4['total_sqft'].apply(convert_sqft_to_num)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df4.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df4.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df5 = df4.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df5['price_per_sqft'] = df5['price']* 100000 / df5['total_sqft']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df5.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df5.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Finding Outlier and Removing**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# function to create histogram, Q-Q plot and boxplot\n \n# for Q-Q plots\nimport scipy.stats as stats\n\ndef diagnostic_plots(df, variable):\n    # function takes a dataframe (df) and\n    # the variable of interest as arguments\n \n    # define figure size\n    plt.figure(figsize=(16, 4))\n \n    # histogram\n    plt.subplot(1, 3, 1)\n    sns.distplot(df[variable], bins=30)\n    plt.title('Histogram')\n \n    # Q-Q plot\n    plt.subplot(1, 3, 2)\n    stats.probplot(df[variable], dist=\"norm\", plot=plt)\n    plt.ylabel('Variable quantiles')\n \n    # boxplot\n    plt.subplot(1, 3, 3)\n    sns.boxplot(y=df[variable])\n    plt.title('Boxplot')\n \n    plt.show()\n    \nnum_var = [\"bath\",\"total_sqft\",\"bhk\",\"price\"]\nfor var in num_var:\n    print(\"******* {} *******\".format(var))\n    diagnostic_plots(df5, var)\n \n  # here we observe outlier using histogram,, qq plot and boxplot","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Explore Location Feature**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df5['location'] = df5['location'].apply(lambda x : x.strip())\n\nloc_status = df4.groupby('location')['location'].agg('count')\nloc_status.sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(loc_status[loc_status <=10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loc_status_less_10 = loc_status[loc_status <=10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df5['location'] = df5['location'].apply(lambda x : 'other' if x in loc_status_less_10 else x)\ndf5.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df5.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Outlier Remove**"},{"metadata":{},"cell_type":"markdown","source":"#### **As general, total_sqft per bedroom can't be less than 300**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df5[df5['total_sqft']/ df5['bhk'] <300 ].head()  #remove these rows","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df6 = df5[~(df5['total_sqft']/ df5['bhk'] <300) ]\nprint(df6.head())\ndf6.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### **price_per_sqft**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df6['price_per_sqft'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing outliers using help of 'price per sqrt'  taking std and mean per location\ndef remove_pps_outliers(df):\n  df_out = pd.DataFrame()\n  for key, subdf in df.groupby('location'):\n    m=np.mean(subdf.price_per_sqft)\n    st=np.std(subdf.price_per_sqft)\n    reduced_df = subdf[(subdf.price_per_sqft>(m-st)) & (subdf.price_per_sqft<=(m+st))]\n    df_out = pd.concat([df_out, reduced_df], ignore_index = True)\n  return df_out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df7 = remove_pps_outliers(df6)\ndf7.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### **plot a scatter plot for 2 and 3 bedroom**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def scatter_chart(df, location):\n    bhk2 = df[(df['location'] == location) & (df['bhk'] == 2)]\n    bhk3 = df[(df['location'] == location) & (df['bhk'] == 3)]\n    \n    matplotlib.rcParams['figure.figsize'] = (15,10)\n    \n    plt.scatter(bhk2['total_sqft'], bhk2['price_per_sqft'], label='2 BHK', s=50)\n    plt.scatter(bhk3['total_sqft'], bhk3['price_per_sqft'], marker='+',label= '3 BHK', s= 50, color='green')\n    plt.xlabel(\"Total Square Feat Area\")\n    plt.ylabel(\"Price per Sqft\")\n    plt.title(location)\n    plt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scatter_chart(df7, 'Rajaji Nagar')\n\n# in below scatterplot we observe that at same location price of\n# 2 bhk house is greater than 3 bhk so it is outlier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scatter_chart(df7, \"Hebbal\")\n\n# in below scatterplot we observe that at same location price of\n# 3 bhk house is less than 2 bhk so it is outlier","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### **remove 2 bedroom having value less than 1 bedroom**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def rm_bhk_outliers(df):\n    exclude_indices = np.array([])\n    for location, location_df in df.groupby('location'):\n        bhk_stats = {}\n        for bhk, bhk_df in location_df.groupby('bhk'):\n            bhk_stats[bhk] = {\n                'mean' : np.mean(bhk_df['price_per_sqft']),\n                'std'  : np.std(bhk_df['price_per_sqft']),\n                'count' : bhk_df.shape[0]\n            }\n            \n        for bhk, bhk_df in location_df.groupby('bhk'):\n            stats  = bhk_stats.get(bhk -1)\n            \n            if stats and stats['count'] > 5:\n                exclude_indices = np.append(exclude_indices, bhk_df[bhk_df['price_per_sqft'] < (stats['mean'])].index.values)\n    return df.drop(exclude_indices, axis='index')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df8 = rm_bhk_outliers(df7)\ndf8.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scatter_chart(df8, 'Rajaji Nagar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scatter_chart(df8, \"Hebbal\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib\nmatplotlib.rcParams[\"figure.figsize\"] = (20,10)\nplt.hist(df8.price_per_sqft,rwidth=0.8)\nplt.xlabel(\"Price Per Square Feet\")\nplt.ylabel(\"Count\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Outlier Removal Using Bathrooms Feature**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df8.bath.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(df8.bath,rwidth=0.8)\nplt.xlabel(\"Number of bathrooms\")\nplt.ylabel(\"Count\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df8[df8.bath>10]\n\n#It is unusual to have 2 more bathrooms than number of bedrooms in a home","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df8[df8.bath>df8.bhk+2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#if you have 4 bedroom home and even if you have bathroom in all 4 rooms plus one guest bathroom, you will have total bath = total bed + 1 max.\n\ndf9 = df8[df8.bath<df8.bhk+2]\ndf9.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df9.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df10 = df9.drop(['size','price_per_sqft'],axis='columns')\ndf10.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Use One Hot Encoding For Location**"},{"metadata":{},"cell_type":"markdown","source":"A one hot encoding is a representation of categorical variables as binary vectors.\n\nThis first requires that the categorical values be mapped to integer values.\nThen, each integer value is represented as a binary vector that is all zero values except the index of the integer, \nwhich is marked with a 1."},{"metadata":{"trusted":true},"cell_type":"code","source":"dummies = pd.get_dummies(df10.location)\ndummies.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df11 = pd.concat([df10,dummies.drop('other',axis='columns')],axis='columns')\ndf11.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df12 = df11.drop('location',axis='columns')\ndf12.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Build a Model Now...**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df12.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df12.drop(['price'],axis='columns')\nX.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df12.price\ny.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlr_clf = LinearRegression()\nlr_clf.fit(X_train,y_train)\nlr_clf.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Use K Fold cross validation to measure accuracy of our LinearRegression model**"},{"metadata":{},"cell_type":"markdown","source":"divides all the samples in k groups of samples, called folds (if k=n, this is equivalent to the Leave One Out strategy), of equal sizes (if possible). The prediction function is learned using k-1 folds, and the fold left out is used for test."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import ShuffleSplit\nfrom sklearn.model_selection import cross_val_score\n\ncv = ShuffleSplit(n_splits=6, test_size=0.2, random_state=10)\n\ncross_val_score(LinearRegression(), X, y, cv=cv)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that in 5 iterations we get a score above 80% all the time. This is pretty good but we want to test few other algorithms for regression to see if we can get even better score. We will use GridSearchCV for this purpose¶"},{"metadata":{},"cell_type":"markdown","source":"### **GridSearchCV**"},{"metadata":{},"cell_type":"markdown","source":"GridSearchCV is a library function that is a member of sklearn’s model_selection package. It helps to loop through predefined hyperparameters and fit your estimator (model) on your training set. So, in the end, you can select the best parameters from the listed hyperparameters."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nfrom sklearn.linear_model import Lasso\nfrom sklearn.tree import DecisionTreeRegressor\n\ndef find_best_model_using_gridsearchcv(X,y):\n    algos = {\n        'linear_regression' : {\n            'model': LinearRegression(),\n            'params': {\n                'normalize': [True, False]\n            }\n        },\n        'lasso': {\n            'model': Lasso(),\n            'params': {\n                'alpha': [1,2],\n                'selection': ['random', 'cyclic']\n            }\n        },\n        'decision_tree': {\n            'model': DecisionTreeRegressor(),\n            'params': {\n                'criterion' : ['mse','friedman_mse'],\n                'splitter': ['best','random']\n            }\n        }\n    }\n    scores = []\n    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=10)\n    for algo_name, config in algos.items():\n        gs =  GridSearchCV(config['model'], config['params'], cv=cv, return_train_score=False)\n        gs.fit(X,y)\n        scores.append({\n            'model': algo_name,\n            'best_score': gs.best_score_,\n            'best_params': gs.best_params_\n        })\n\n    return pd.DataFrame(scores,columns=['model','best_score','best_params'])\n\nfind_best_model_using_gridsearchcv(X,y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Based on above results we can say that Linear Regression gives the best score. Hence we will use that"},{"metadata":{},"cell_type":"markdown","source":"### **Test the model for few properties**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_price(location,sqft,bath,bhk):    \n    loc_index = np.where(X.columns==location)[0][0]\n\n    x = np.zeros(len(X.columns))\n    x[0] = sqft\n    x[1] = bath\n    x[2] = bhk\n    if loc_index >= 0:\n        x[loc_index] = 1\n\n    return lr_clf.predict([x])[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_price('1st Phase JP Nagar',1000, 2, 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_price('Indira Nagar', 1000, 2, 2 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_price('1st Phase JP Nagar', 1000, 3, 3)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}