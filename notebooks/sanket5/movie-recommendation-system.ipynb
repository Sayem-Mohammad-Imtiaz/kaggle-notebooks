{"cells":[{"metadata":{"trusted":true,"_uuid":"c1fdd129c1cbab68ae3e6bf2062575f01f80b87c"},"cell_type":"code","source":"import pandas as pd \nimport numpy as np \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport string\nimport re\nmovie_info_1=pd.read_csv('../input/tmdb-movie-metadata/tmdb_5000_credits.csv')\nmovie_info_2=pd.read_csv('../input/tmdb-movie-metadata/tmdb_5000_movies.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Get familier with structure and data of movie_info_1\nmovie_info_1.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Get familier with structure and data of movie_info_2\nmovie_info_2.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Merge the both Dataframe\nmovie_data = movie_info_2.merge(movie_info_1,left_on='id', right_on='movie_id')\n#Get the shape of the data\nmovie_data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* So we have almost **24** columns with the record size of **4803** .Now Lets check the Sample of dat to understand it better"},{"metadata":{"trusted":true},"cell_type":"code","source":"movie_data.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* ## Language Wise Movie Distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nbarplot_data = pd.DataFrame (movie_data['original_language'].value_counts() )\nbarplot_data.reset_index(inplace = True)\nbarplot_data.columns = ['language' , 'counts']\nplt.bar( x = 'language' , height = 'counts' ,data = barplot_data.head(10))\nplt.xlabel('Original Language')\nplt.ylabel('Movies Counts') \nplt.title('Language-Wise Movie Distribution')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* As we see that , There is highly right tail skewed distribution .It mean we have very high numbers of Viewver who are only watching 'English' movie ."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Movies popularity index wise histogram .\nplt.figure(figsize=(10,5))\nsns.distplot(movie_data['popularity'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check the status of the movie whether its release or not .\nplt.figure(figsize=(10,5))\nbarplot_2 = pd.DataFrame (movie_data['status'].value_counts() )\nbarplot_2.reset_index(inplace = True)\nbarplot_2.columns = ['status' , 'counts']\nplt.bar( x = 'status' , height = 'counts' ,data = barplot_2.head(10))\nplt.xlabel('status')\nplt.ylabel('Movies Counts') \nplt.title('Status-Wise Movie Distribution')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Almost more than 95% of movies are are having  status is ** RELEASE ** and rest of movies are fall under different category like **Rummored ,  Post productction **"},{"metadata":{"_uuid":"fe716df6e5e5a354ac53d556087147c0a64df2cc"},"cell_type":"markdown","source":"# **Content Based Filtering**\nIn this recommender system the content of the movie (overview) is used to find its similarity with other movies. Then the movies that are most likely to be similar are recommended.\n\n![](https://image.ibb.co/f6mDXU/conten.png)"},{"metadata":{"_uuid":"b0a813c803b0ba1f0204188ab2a63dc7f59ce2eb"},"cell_type":"markdown","source":"## **Plot description based Recommender**\n\nWe will compute pairwise similarity scores for all movies based on their plot descriptions and recommend movies based on that similarity score. The plot description is given in the **overview** feature of our dataset. \nLet's take a look at the data. .. \n\n#### **Data Pre-processing Steps** :\n\n* Basic Data Cleasing before going to Actual Implemention of Content Based Recommender Engine algorithm .\n    1.\tLowercase\n    2.\tNumber Removing \n    3.\tPunctuations\n    4.\tWhite Spaces\n    5.\tSingle Characters Handling\n    6.\tNull Value Handlings\n    7.\tStop Words Treatments\n    8.\tLemmatization\n    10.\tTokenization\n    12.\tTF-IDF\n    15.\tCosine similarity vs Cosine distance \n    16.\tDifferent distance measure\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lowercasing the Dataframe column\nmovie_data['overview'] = movie_data['overview'].apply(lambda x:str(x).lower())\n\n#Remove the Numbers from Overview columns\nmovie_data['overview'] = movie_data['overview'].apply(lambda x:re.sub(r\"\\d+\", \"\", x))\n\n#Remove all the Punctuation from the string \nmovie_data['overview'] = movie_data['overview'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n\n#Remove the strings which are having lenght less than 3 \nmovie_data['overview'] = movie_data['overview'].apply(lambda x: re.sub(r'\\b\\w{1,3}\\b', '', x))\n\n#Replace NaN with an empty string\nmovie_data['overview'] = movie_data['overview'].fillna('')\n\n#Remove all the mutliple space with singlular space\nmovie_data['overview'] = movie_data['overview'].apply(lambda x: re.sub('\\s+', ' ', x).strip() )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import these modules \nfrom nltk.stem import WordNetLemmatizer \n\nlemmatizer = WordNetLemmatizer() \n\n# a denotes adjective in \"pos\" \nmovie_data['overview'] = movie_data['overview'].apply(lambda x: lemmatizer.lemmatize(x, pos =\"a\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check the Sample After all data pre-processing is done\nmovie_data['overview'].head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"277a9bb5b00a6bd2469c45777f9c659066f402b3"},"cell_type":"markdown","source":"For any of you who has done even a  bit of text processing before knows we need to convert the word vector of each overview.\nNow we'll compute Term Frequency-Inverse Document Frequency (TF-IDF) vectors for each overview.\n\nNow if you are wondering what is term frequency , it is the relative frequency of a word in a document and is given as\n   **(term instances/total instances)**.\nInverse Document Frequency is the relative count of documents containing the term is given as \n**log(number of documents/documents with term)**\nThe overall importance of each word to the documents in which they appear is equal to **TF * IDF**\n\nThis will give you a matrix where each column represents a word in the overview vocabulary (all the words that appear in at least one document) and each column represents a movie, as before.This is done to reduce the importance of words that occur frequently in plot overviews and therefore, their significance in computing the final similarity score.\n\nFortunately, scikit-learn gives you a built-in TfIdfVectorizer class that produces the TF-IDF matrix in a couple of lines. That's great, isn't it? "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import TfIdfVectorizer from scikit-learn\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n#Define a TF-IDF Vectorizer Object. Remove all english stop words such as 'the', 'a'\ntfidf = TfidfVectorizer(stop_words='english')\n\n#Construct the required TF-IDF matrix by fitting and transforming the data\ntfidf_matrix = tfidf.fit_transform(movie_data['overview'])\n\n#Output the shape of tfidf_matrix\ntfidf_matrix.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6bde57434bf9a0e8f8b229d36901d75b77ff962f"},"cell_type":"markdown","source":"We see that over 22,000 different words were used to describe the 4800 movies in our dataset.\n\nWith this matrix in hand, we can now compute a similarity score. There are several candidates for this; such as the euclidean, the Pearson and the [cosine similarity scores](https://en.wikipedia.org/wiki/Cosine_similarity). There is no right answer to which score is the best. Different scores work well in different scenarios and it is often a good idea to experiment with different metrics.\n\nWe will be using the cosine similarity to calculate a numeric quantity that denotes the similarity between two movies. We use the cosine similarity score since it is independent of magnitude and is relatively easy and fast to calculate. Mathematically, it is defined as follows:\n![](data:image/png;base64,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)"},{"metadata":{"_uuid":"c1c138ae64648cb5a94127a06441d88dddc2bd9a"},"cell_type":"markdown","source":"Since we have used the TF-IDF vectorizer, calculating the dot product will directly give us the cosine similarity score. Therefore, we will use sklearn's **linear_kernel()** instead of cosine_similarities() since it is faster."},{"metadata":{"trusted":true,"_uuid":"5eb17d12220eecab4faf01bbfd13e79d8e446537"},"cell_type":"code","source":"# Import linear_kernel\nfrom sklearn.metrics.pairwise import linear_kernel\n\n# Compute the cosine similarity matrix\ncosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f5ca112fbbe25b11f0f3356a31d1604727242700"},"cell_type":"markdown","source":"We are going to define a function that takes in a movie title as an input and outputs a list of the 10 most similar movies. Firstly, for this, we need a reverse mapping of movie titles and DataFrame indices. In other words, we need a mechanism to identify the index of a movie in our metadata DataFrame, given its title."},{"metadata":{"trusted":true,"_uuid":"55df2df36be98e6dec5f617a5aa51b77c500faa4"},"cell_type":"code","source":"#Construct a reverse map of indices and movie titles\nindices = pd.Series(movie_data.index, index=movie_data['title_x']).drop_duplicates()\nindices.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"da5896c6ccfd44c3347af3097275d0aa707c1001"},"cell_type":"markdown","source":"We are now in a good position to define our recommendation function. These are the following steps we'll follow :-\n* Get the index of the movie given its title.\n* Get the list of cosine similarity scores for that particular movie with all movies. Convert it into a list of tuples where the first element is its position and the second is the similarity score.\n* Sort the aforementioned list of tuples based on the similarity scores; that is, the second element.\n* Get the top 10 elements of this list. Ignore the first element as it refers to self (the movie most similar to a particular movie is the movie itself).\n* Return the titles corresponding to the indices of the top elements."},{"metadata":{"trusted":true,"_uuid":"9c383fcbb916dce464b01adf980d26ad96aebe0e"},"cell_type":"code","source":"# Function that takes in movie title as input and outputs most similar movies\ndef get_recommendations(title, cosine_sim=cosine_sim):\n    # Get the index of the movie that matches the title\n    idx = indices[title]\n\n    # Get the pairwsie similarity scores of all movies with that movie\n    sim_scores = list(enumerate(cosine_sim[idx]))\n\n    # Sort the movies based on the similarity scores\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n\n    # Get the scores of the 10 most similar movies\n    sim_scores = sim_scores[1:11]\n\n    # Get the movie indices\n    movie_indices = [i[0] for i in sim_scores]\n\n    # Return the top 10 most similar movies\n    return movie_data['title_x'].iloc[movie_indices]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"14d722124f82e69cb444adcc589e396c75cbb4ff"},"cell_type":"code","source":"get_recommendations('The Dark Knight Rises')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Do the Relality Check\npd.options.display.max_colwidth = 1000\nmovie_data.loc[movie_data['title_x']=='The Dark Knight Rises' , 'overview']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movie_data.loc[movie_data['title_x']=='Batman Returns' , 'overview']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"902b9f1ab91921889c85e9008818dcc0b4710ccd"},"cell_type":"code","source":"get_recommendations('The Avengers')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movie_data.loc[movie_data['title_x']=='The Avengers' , 'overview']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movie_data.loc[movie_data['title_x']=='Avengers: Age of Ultron' , 'overview']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"146302c25776b2c0076e64663a5e2e41e977fd2c"},"cell_type":"markdown","source":"While our system has done a decent job of finding movies with similar plot descriptions, the quality of recommendations is not that great. \"The Dark Knight Rises\" returns all Batman movies while it is more likely that the people who liked that movie are more inclined to enjoy other Christopher Nolan movies. This is something that cannot be captured by the present system."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}