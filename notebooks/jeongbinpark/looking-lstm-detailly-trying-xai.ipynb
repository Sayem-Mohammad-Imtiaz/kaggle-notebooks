{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:blue;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n<h1 style=\"text-align: center;\n           padding: 10px;\n              color:white\">\nLooking LSTM Detailly !\n</h1>\n</div>","metadata":{}},{"cell_type":"markdown","source":"![](https://www.csail.mit.edu/sites/default/files/2020-08/FedTech-DeepLearning.jpg)","metadata":{}},{"cell_type":"markdown","source":"### This time, I try Looking LSTM Detailly ( Especially Model's Weights )! ","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:blue;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n<h1 style=\"text-align: center;\n           padding: 10px;\n              color:white\">\nImport Libraries and Load Datasets\n</h1>\n</div>","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom keras import models, layers\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\n\nimport matplotlib.font_manager as fm\nbest_font = fm.FontProperties(fname='../input/staatfont/Staatliches-Regular.ttf')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-30T06:34:57.659377Z","iopub.execute_input":"2021-06-30T06:34:57.659754Z","iopub.status.idle":"2021-06-30T06:34:57.664947Z","shell.execute_reply.started":"2021-06-30T06:34:57.65972Z","shell.execute_reply":"2021-06-30T06:34:57.663915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### I use bitcoin price dataset.\n### LSTM Showing great accuracy in Time series predict!","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:blue;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n<h1 style=\"text-align: center;\n           padding: 10px;\n              color:white\">\nData processing and make simple model\n</h1>\n</div>","metadata":{}},{"cell_type":"code","source":"data =pd.read_csv(\"../input/bitcoin-historical-data/bitstampUSD_1-min_data_2012-01-01_to_2021-03-31.csv\")\ndata = data[['Timestamp','Open']]\ndata['Timestamp'] = pd.to_datetime(data['Timestamp'],unit='s').dt.date\ndata = data.dropna()\ndata = data.groupby('Timestamp').mean()\n\ndata = data.reset_index(drop=True)\ndata.columns=['price']\n\nscaler = MinMaxScaler()\ndata['price'] = scaler.fit_transform(np.array(data['price']).reshape(-1,1))\n\nX = []\ny = []\nfor i in range(len(data)-5):\n    X.append(list(data.loc[i:i+4,\"price\"]))\n    y.append(data.loc[i+5,\"price\"])\n    \nX = np.array(X)\ny = np.array(y)\nX = X.reshape(-1,5,1)\n\nmodel = models.Sequential()\nmodel.add(layers.LSTM(5,input_shape=X.shape[1:]))\nmodel.add(layers.Dense(1))\nmodel.compile(optimizer='adam',loss='MSE')\nmodel.summary()\nmodel.fit(X, y, epochs=5,verbose=2,validation_split=0.3)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T06:34:57.671714Z","iopub.execute_input":"2021-06-30T06:34:57.672284Z","iopub.status.idle":"2021-06-30T06:35:12.440243Z","shell.execute_reply.started":"2021-06-30T06:34:57.672233Z","shell.execute_reply":"2021-06-30T06:35:12.439321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### I use only Price data and Windowing size is 5\n### I just make simple model.\n### If you want more great performance, Try increase Windowing size and NN","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:blue;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n<h1 style=\"text-align: center;\n           padding: 10px;\n              color:white\">\nLook at model's Weights\n</h1>\n</div>","metadata":{}},{"cell_type":"code","source":"names = [weight.name for layer in model.layers for weight in layer.weights]\nweights = model.get_weights()\n\nnp.set_printoptions(suppress=True)\nfor name, weight in zip(names, weights):\n    print(name, weight.shape)\n    print(weight)\n\n    layer_type = name.split('/')[1]\n    if layer_type == 'kernel:0':\n        kernel_0 = weight\n    if layer_type == 'recurrent_kernel:0':\n        recurrent_kernel_0 = weight\n    elif layer_type == 'bias:0':\n        bias_0 = weight\n    print()","metadata":{"execution":{"iopub.status.busy":"2021-06-30T06:35:12.442074Z","iopub.execute_input":"2021-06-30T06:35:12.442494Z","iopub.status.idle":"2021-06-30T06:35:12.459288Z","shell.execute_reply.started":"2021-06-30T06:35:12.442448Z","shell.execute_reply":"2021-06-30T06:35:12.457855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The LSTM Model has 3 weights\n### 1. kernel\n### 2. recurrent_kernel\n### 3. bias","metadata":{}},{"cell_type":"markdown","source":"![](https://www.oreilly.com/library/view/neural-networks-and/9781492037354/assets/mlst_1413.png)","metadata":{}},{"cell_type":"markdown","source":"### This image help to understand LSTM's contruction","metadata":{}},{"cell_type":"code","source":"kernel_weights = weights[0]\nrecurrent_kernel_weights = weights[1]\nbias = weights[2]\n\nn = 1\nunits = 5  # LSTM layers\n\n# (1, 20) embedding dims, units * 4\nWi = kernel_weights[:, 0:units]\nWf = kernel_weights[:, units:2 * units]\nWc = kernel_weights[:, 2 * units:3 * units]\nWo = kernel_weights[:, 3 * units:]\n\n# (5, 20) units, units * 4\nUi = recurrent_kernel_weights[:, 0:units]\nUf = recurrent_kernel_weights[:, units:2 * units]\nUc = recurrent_kernel_weights[:, 2 * units:3 * units]\nUo = recurrent_kernel_weights[:, 3 * units:]\n\n# (20,) units * 4\nbi = bias[0:units]\nbf = bias[units:2 * units]\nbc = bias[2 * units:3 * units]\nbo = bias[3 * units:]\n\ndef sigmoid(x):\n    return 1 / (1 + np.exp(-x))","metadata":{"execution":{"iopub.status.busy":"2021-06-30T06:35:12.461595Z","iopub.execute_input":"2021-06-30T06:35:12.4619Z","iopub.status.idle":"2021-06-30T06:35:12.471319Z","shell.execute_reply.started":"2021-06-30T06:35:12.461871Z","shell.execute_reply":"2021-06-30T06:35:12.470041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Wf: ',Wf,'\\nWi: ',Wi,'\\nWo: ',Wo,'\\nWc: ',Wc,)\n\nprint('\\nUf: ',Uf,'\\nUi: ',Ui,'\\nUo: ',Uo,'\\nUc: ',Uc,)\n\nprint('\\nbf: ',bf,'\\nbi: ',bi,'\\nbo: ',bo,'\\nbc: ',bc,)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T06:35:12.473068Z","iopub.execute_input":"2021-06-30T06:35:12.473466Z","iopub.status.idle":"2021-06-30T06:35:12.490428Z","shell.execute_reply.started":"2021-06-30T06:35:12.473432Z","shell.execute_reply":"2021-06-30T06:35:12.489095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"![](https://wikimedia.org/api/rest_v1/media/math/render/svg/2db2cba6a0d878e13932fa27ce6f3fb71ad99cf1)","metadata":{}},{"cell_type":"markdown","source":"### Using weights, We can know Cell_state values(Ct) and Hidden_state(ht) values","metadata":{}},{"cell_type":"code","source":"ht_1 = np.zeros(n * units).reshape(n, units)\nCt_1 = np.zeros(n * units).reshape(n, units)\n\nresults = []\nfor t in range(0, len(X[2000,:])):\n    xt = np.array(X[2000,t])\n    ft = sigmoid(np.dot(xt, Wf) + np.dot(ht_1, Uf) + bf)  # forget gate\n    it = sigmoid(np.dot(xt, Wi) + np.dot(ht_1, Ui) + bi)  # input gate\n    ot = sigmoid(np.dot(xt, Wo) + np.dot(ht_1, Uo) + bo)  # output gate\n    Ct = ft * Ct_1 + it * np.tanh(np.dot(xt, Wc) + np.dot(ht_1, Uc) + bc)\n    ht = ot * np.tanh(Ct)\n\n    ht_1 = ht  # hidden state, previous memory state\n    Ct_1 = Ct  # cell state, previous carry state\n\n    results.append(ht)\n    print(t,': ht', ht)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T06:35:12.492216Z","iopub.execute_input":"2021-06-30T06:35:12.49296Z","iopub.status.idle":"2021-06-30T06:35:12.511126Z","shell.execute_reply.started":"2021-06-30T06:35:12.492891Z","shell.execute_reply":"2021-06-30T06:35:12.50998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.predict(X[2000:2001])","metadata":{"execution":{"iopub.status.busy":"2021-06-30T06:35:12.512413Z","iopub.execute_input":"2021-06-30T06:35:12.512706Z","iopub.status.idle":"2021-06-30T06:35:12.899513Z","shell.execute_reply.started":"2021-06-30T06:35:12.512678Z","shell.execute_reply":"2021-06-30T06:35:12.898578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Using this calculation, We can get same values with model's predict\n### last hidden_state value(ht[4]) == model.predict value","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:blue;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n<h1 style=\"text-align: center;\n           padding: 10px;\n              color:white\">\nWhich column will have the biggest impact?\n</h1>\n</div>","metadata":{}},{"cell_type":"markdown","source":"### I want to know that Which columns have the biggest impact.\n### So, I calculate this LSTM process","metadata":{}},{"cell_type":"code","source":"ht_1 = np.zeros(n * units).reshape(n, units)\nCt_1 = np.zeros(n * units).reshape(n, units)\n\nh_t_value = []\n\ninfluence_h_t_value = []\nfor t in range(0, len(X[1000,:])):\n    xt = np.array(X[1000,t])\n    ft = sigmoid(np.dot(xt, Wf) + np.dot(ht_1, Uf) + bf)  # forget gate\n    influence_ft = (np.dot(ht_1, Uf))/(np.dot(xt, Wf) + np.dot(ht_1, Uf) + bf) * ft\n\n    it = sigmoid(np.dot(xt, Wi) + np.dot(ht_1, Ui) + bi)  # input gate\n    influence_it = (np.dot(ht_1, Ui))/(np.dot(xt, Wi) + np.dot(ht_1, Ui) + bi) * it\n\n    ot = sigmoid(np.dot(xt, Wo) + np.dot(ht_1, Uo) + bo)  # output gate\n    influence_ot = np.dot(ht_1, Uo) / (np.dot(xt, Wo) + np.dot(ht_1, Uo) + bo) * ot\n\n    gt =  np.tanh(np.dot(xt, Wc) + np.dot(ht_1, Uc) + bc)\n    influence_gt =np.dot(ht_1, Uc) / (np.dot(xt, Wc) + np.dot(ht_1, Uc) + bc) * gt\n    \n    Ct = ft * Ct_1 + it * gt\n    influence_ct = influence_ft * Ct_1 + influence_it * influence_gt\n    ht = ot * np.tanh(Ct)\n    influence_ht = influence_ot * (influence_ct/Ct) * ht\n    \n    influence_h_t_value.append(influence_ht)\n\n    ht_1 = ht  # hidden state, previous memory state\n    Ct_1 = Ct  # cell state, previous carry state\n    \n    h_t_value.append(ht)\n    \ninfluence_h_t_value.append(h_t_value[-1])\nfor i in range(len(influence_h_t_value)-1,0,-1):\n    influence_h_t_value[i] = influence_h_t_value[i] - influence_h_t_value[i-1]\n    \ninfluence_h_t_value = influence_h_t_value[1:]","metadata":{"execution":{"iopub.status.busy":"2021-06-30T06:35:12.901063Z","iopub.execute_input":"2021-06-30T06:35:12.901434Z","iopub.status.idle":"2021-06-30T06:35:12.917285Z","shell.execute_reply.started":"2021-06-30T06:35:12.901402Z","shell.execute_reply":"2021-06-30T06:35:12.916048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"impact_columns = np.dot(influence_h_t_value,weights[3]) + (weights[4]/5)\n\nfor i in range(len(impact_columns)):\n    print('columns_number : ',i, 'impact value : ', float(impact_columns[i]))\n    \nprint('\\nSum of value : ', float(sum(np.dot(influence_h_t_value,weights[3]) + (weights[4]/5))))\n\nprint('\\nkeras model_predict : ', float(model.predict(X[1000:1001])))","metadata":{"execution":{"iopub.status.busy":"2021-06-30T06:35:12.922698Z","iopub.execute_input":"2021-06-30T06:35:12.923346Z","iopub.status.idle":"2021-06-30T06:35:12.980844Z","shell.execute_reply.started":"2021-06-30T06:35:12.923294Z","shell.execute_reply":"2021-06-30T06:35:12.979739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### I've used three days to do this. 😴","metadata":{}},{"cell_type":"markdown","source":"### Then, Why am i obsessed with the impact?","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:blue;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n<h1 style=\"text-align: center;\n           padding: 10px;\n              color:white\">\nTrying on NLP ! ( Review Data )\n</h1>\n</div>","metadata":{}},{"cell_type":"markdown","source":"### I just try that on NLP","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('../input/womens-ecommerce-clothing-reviews/Womens Clothing E-Commerce Reviews.csv')\ndata = data[['Review Text','Rating']]\ndata = data.dropna()\npositive = data[(data['Rating'] == 5)].sample(2370,random_state=100)\nnegative = data[(data['Rating'] == 2) | (data['Rating'] == 1)]\ndata = pd.concat([negative,positive])\ndata = data.reset_index(drop=True)\n\ndata['Rating'] = data['Rating'].apply(lambda x : 1 if x==5 else 0)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T06:35:12.982773Z","iopub.execute_input":"2021-06-30T06:35:12.98313Z","iopub.status.idle":"2021-06-30T06:35:13.157874Z","shell.execute_reply.started":"2021-06-30T06:35:12.983097Z","shell.execute_reply":"2021-06-30T06:35:13.156816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### I used Womens Clothing E-Commerce Reviews dataset","metadata":{}},{"cell_type":"code","source":"data.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T06:35:13.159289Z","iopub.execute_input":"2021-06-30T06:35:13.159613Z","iopub.status.idle":"2021-06-30T06:35:13.170613Z","shell.execute_reply.started":"2021-06-30T06:35:13.159582Z","shell.execute_reply":"2021-06-30T06:35:13.169393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.tail(5)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T06:37:00.116285Z","iopub.execute_input":"2021-06-30T06:37:00.11663Z","iopub.status.idle":"2021-06-30T06:37:00.131021Z","shell.execute_reply.started":"2021-06-30T06:37:00.116601Z","shell.execute_reply":"2021-06-30T06:37:00.129714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Rating mean that 0 is Negative review, and 1 is Positive review","metadata":{}},{"cell_type":"code","source":"import re\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import PorterStemmer\n\ndef data_processing(text):\n    return_arr = []\n    text = re.sub(r\"[^a-zA-Z]\",\" \",text)\n    text = re.sub(r\" {2,}\",\" \",text)\n    text = text.lower()\n    words = word_tokenize(text)\n    s = PorterStemmer()\n    stopword = stopwords.words('english')\n    for t in words:\n        if t not in stopword:\n            return_arr.append(t)\n            \n    return_arr = [s.stem(w) for w in return_arr]\n    return return_arr\n\ndata['processing'] = data['Review Text'].apply(data_processing)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T06:35:13.172271Z","iopub.execute_input":"2021-06-30T06:35:13.172703Z","iopub.status.idle":"2021-06-30T06:35:21.852452Z","shell.execute_reply.started":"2021-06-30T06:35:13.172666Z","shell.execute_reply":"2021-06-30T06:35:21.851429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### I only use alphabet text, (delete special character or number)\n### And, delete stopwords, changing analogous term.","metadata":{}},{"cell_type":"code","source":"len_arr = []\nfor i in range(len(data)):\n    len_arr.append(len(data.loc[i,'processing']))\n    \nimport seaborn as sns\nsns.histplot(len_arr)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T06:35:21.853861Z","iopub.execute_input":"2021-06-30T06:35:21.854242Z","iopub.status.idle":"2021-06-30T06:35:22.155636Z","shell.execute_reply.started":"2021-06-30T06:35:21.854208Z","shell.execute_reply":"2021-06-30T06:35:22.154245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def data_processing2(text):\n    return_arr = []\n    text = re.sub(r\"[^a-z]\",\" \",text)\n    text = re.sub(r\" {2,}\",\" \",text)\n    return text\n\nnegative_sentences = data[data['Rating'] ==0]['processing']\npositive_sentences = data[data['Rating'] ==1]['processing']\n\nnegative_sentences = str(list(negative_sentences))\nnegative_sentences = data_processing2(negative_sentences)\n\nnegative_sentences = negative_sentences.split(' ')\nnegative_sentences = pd.DataFrame(negative_sentences)[0].value_counts()\nnegative_sentences = pd.DataFrame(negative_sentences)\n\npositive_sentences = str(list(positive_sentences))\npositive_sentences = data_processing2(positive_sentences)\n\npositive_sentences = positive_sentences.split(' ')\npositive_sentences = pd.DataFrame(positive_sentences)[0].value_counts()\npositive_sentences = pd.DataFrame(positive_sentences)\n\ncon = pd.concat([negative_sentences,positive_sentences],axis=1)\n\ncon.columns = ['negative','positive']\n\ncon = con.dropna()\n\ncon['negative_value'] = con[['negative','positive']].apply(lambda x : x[0]/(x[0]+x[1]) *-1,axis=1)\ncon['positive_value'] = con[['negative','positive']].apply(lambda x : x[1]/(x[0]+x[1]),axis=1)\n\ncon['total_value'] = con['negative_value'] + con['positive_value']\ncon = con.reset_index()\ncon = con.drop(['negative','positive','negative_value','positive_value'],axis=1)\nword_index =con['index'].to_list()\ncon = np.array(con)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T06:35:22.157406Z","iopub.execute_input":"2021-06-30T06:35:22.158165Z","iopub.status.idle":"2021-06-30T06:35:22.621874Z","shell.execute_reply.started":"2021-06-30T06:35:22.158085Z","shell.execute_reply":"2021-06-30T06:35:22.620796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### And, I just use, Rate of Negative words, and Positive word \n\n### It mean\n\n### Negative Rate : -1 * Negatvie Counts / (Negative Counts + Positive Counts)\n### Positive Rate : 1 * Positive Counts / (Negative Counts + Positive Counts)\n\n### After Sum Two : Negative Rate + Positive Rate","metadata":{}},{"cell_type":"code","source":"con[:10]","metadata":{"execution":{"iopub.status.busy":"2021-06-30T06:41:49.654795Z","iopub.execute_input":"2021-06-30T06:41:49.655178Z","iopub.status.idle":"2021-06-30T06:41:49.661363Z","shell.execute_reply.started":"2021-06-30T06:41:49.655147Z","shell.execute_reply":"2021-06-30T06:41:49.660364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\nX = []\nfor sen in tqdm(data['processing']):\n    word_arr =[]\n    for word in sen:\n        if word in word_index:\n            word_arr.append(float(con[con[:,0] ==word,1]))\n        else:\n            word_arr.append(0)\n    X.append(word_arr)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T06:35:22.624046Z","iopub.execute_input":"2021-06-30T06:35:22.624494Z","iopub.status.idle":"2021-06-30T06:35:39.207605Z","shell.execute_reply.started":"2021-06-30T06:35:22.624448Z","shell.execute_reply":"2021-06-30T06:35:39.206791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = pd.DataFrame(X)\nX = X.fillna(0)\nX = X.loc[:,:50]\nX= X.to_numpy()\ny = np.array(data['Rating'])\nX = X.reshape(4740,51,1)\nX.shape, y.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-30T06:35:39.208578Z","iopub.execute_input":"2021-06-30T06:35:39.208839Z","iopub.status.idle":"2021-06-30T06:35:39.25829Z","shell.execute_reply.started":"2021-06-30T06:35:39.208813Z","shell.execute_reply":"2021-06-30T06:35:39.257047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Embedding, Dense,LSTM\nfrom tensorflow.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(LSTM(51,input_shape=X.shape[1:],activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-30T06:35:39.259652Z","iopub.execute_input":"2021-06-30T06:35:39.260058Z","iopub.status.idle":"2021-06-30T06:35:39.361961Z","shell.execute_reply.started":"2021-06-30T06:35:39.260024Z","shell.execute_reply":"2021-06-30T06:35:39.360908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Just use simple LSTM Model","metadata":{}},{"cell_type":"code","source":"model.fit(X,y, batch_size=128, epochs=15, validation_split=0.3)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T06:35:39.363031Z","iopub.execute_input":"2021-06-30T06:35:39.363309Z","iopub.status.idle":"2021-06-30T06:36:12.258024Z","shell.execute_reply.started":"2021-06-30T06:35:39.363282Z","shell.execute_reply":"2021-06-30T06:36:12.256841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"names = [weight.name for layer in model.layers for weight in layer.weights]\nweights = model.get_weights()\n\nkernel_weights = weights[0]\nrecurrent_kernel_weights = weights[1]\nbias = weights[2]\n\nn = 1\nunits = 51  # LSTM layers\n\nWi = kernel_weights[:, 0:units]\nWf = kernel_weights[:, units:2 * units]\nWc = kernel_weights[:, 2 * units:3 * units]\nWo = kernel_weights[:, 3 * units:]\n\nUi = recurrent_kernel_weights[:, 0:units]\nUf = recurrent_kernel_weights[:, units:2 * units]\nUc = recurrent_kernel_weights[:, 2 * units:3 * units]\nUo = recurrent_kernel_weights[:, 3 * units:]\n\nbi = bias[0:units]\nbf = bias[units:2 * units]\nbc = bias[2 * units:3 * units]\nbo = bias[3 * units:]","metadata":{"execution":{"iopub.status.busy":"2021-06-30T06:36:12.259424Z","iopub.execute_input":"2021-06-30T06:36:12.259755Z","iopub.status.idle":"2021-06-30T06:36:12.270986Z","shell.execute_reply.started":"2021-06-30T06:36:12.259722Z","shell.execute_reply":"2021-06-30T06:36:12.269647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_plot(number):\n    ht_1 = np.zeros(n * units).reshape(n, units)\n    Ct_1 = np.zeros(n * units).reshape(n, units)\n\n    h_t_value = []\n\n    influence_h_t_value = []\n    for t in range(0, len(X[number,:])):\n        xt = np.array(X[number,t])\n        ft = sigmoid(np.dot(xt, Wf) + np.dot(ht_1, Uf) + bf)  # forget gate\n        influence_ft = (np.dot(ht_1, Uf))/(np.dot(xt, Wf) + np.dot(ht_1, Uf) + bf) * ft\n\n        it = sigmoid(np.dot(xt, Wi) + np.dot(ht_1, Ui) + bi)  # input gate\n        influence_it = (np.dot(ht_1, Ui))/(np.dot(xt, Wi) + np.dot(ht_1, Ui) + bi) * it\n\n        ot = sigmoid(np.dot(xt, Wo) + np.dot(ht_1, Uo) + bo)  # output gate\n        influence_ot = np.dot(ht_1, Uo) / (np.dot(xt, Wo) + np.dot(ht_1, Uo) + bo) * ot\n\n        gt =  np.tanh(np.dot(xt, Wc) + np.dot(ht_1, Uc) + bc)\n        influence_gt =np.dot(ht_1, Uc) / (np.dot(xt, Wc) + np.dot(ht_1, Uc) + bc) * gt\n\n        Ct = ft * Ct_1 + it * gt\n        influence_ct = influence_ft * Ct_1 + influence_it * influence_gt\n        ht = ot * np.tanh(Ct)\n        influence_ht = influence_ot * (influence_ct/Ct) * ht\n\n        influence_h_t_value.append(influence_ht)\n\n        ht_1 = ht  # hidden state, previous memory state\n        Ct_1 = Ct  # cell state, previous carry state\n\n        h_t_value.append(ht)\n\n    influence_h_t_value.append(h_t_value[-1])\n    for i in range(len(influence_h_t_value)-1,0,-1):\n        influence_h_t_value[i] = influence_h_t_value[i] - influence_h_t_value[i-1]\n\n    influence_h_t_value = influence_h_t_value[1:]\n\n    impact_columns = np.dot(influence_h_t_value,weights[3]) + (weights[4]/units)\n\n    if model.predict(X[number:number+1]) > 0.5:\n        b_color = 'lightgreen'\n    else:\n        b_color ='lightcyan'\n\n    fig = plt.figure(figsize=(15,3),facecolor=b_color)\n\n    for k in range(len(data.loc[number,'processing'])):\n        s = data.loc[number,'processing'][k]\n        va = round(float(impact_columns[k]),2)\n        if va > 0.5:\n            color ='green'\n        elif va< -0.3:\n            color ='blue'\n        else:\n            color ='black'\n\n        if k < 17:\n            plt.text(s=s, x=k*0.7, y=0,font=best_font,fontsize=20,color=color,va='center',ha='center')\n            plt.text(s=va,x=k*0.7, y=-0.1,font=best_font,fontsize=20,color=color,va='center',ha='center')\n        elif k < 34:\n            plt.text(s=s, x=k*0.7 - 17*0.7, y=-0.2,font=best_font,fontsize=20,color=color,va='center',ha='center')\n            plt.text(s=va,x=k*0.7- 17*0.7, y=-0.3,font=best_font,fontsize=20,color=color,va='center',ha='center')\n        else:\n            plt.text(s=s, x=k*0.7 - 34*0.7, y=-0.4,font=best_font,fontsize=20,color=color,va='center',ha='center')\n            plt.text(s=va,x=k*0.7- 34*0.7, y=-0.5,font=best_font,fontsize=20,color=color,va='center',ha='center')\n\n    plt.xlim(0,10)\n    plt.ylim(-0.5,0.1)\n    plt.axis('off')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-30T06:36:12.272499Z","iopub.execute_input":"2021-06-30T06:36:12.272822Z","iopub.status.idle":"2021-06-30T06:36:12.299849Z","shell.execute_reply.started":"2021-06-30T06:36:12.272791Z","shell.execute_reply":"2021-06-30T06:36:12.298696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### If influence value is more than 0.5 : Green color\n### If influence value is lower than -0.5 : blue color\n\n### The background color mean too","metadata":{}},{"cell_type":"markdown","source":"### ( I don't consider activation function like sigmoid )","metadata":{}},{"cell_type":"code","source":"make_plot(489)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T06:36:12.301353Z","iopub.execute_input":"2021-06-30T06:36:12.301743Z","iopub.status.idle":"2021-06-30T06:36:12.902911Z","shell.execute_reply.started":"2021-06-30T06:36:12.301708Z","shell.execute_reply":"2021-06-30T06:36:12.901726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"make_plot(2243)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T06:36:12.904222Z","iopub.execute_input":"2021-06-30T06:36:12.904538Z","iopub.status.idle":"2021-06-30T06:36:13.351224Z","shell.execute_reply.started":"2021-06-30T06:36:12.904496Z","shell.execute_reply":"2021-06-30T06:36:13.350274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"make_plot(2378)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T06:36:13.3524Z","iopub.execute_input":"2021-06-30T06:36:13.352851Z","iopub.status.idle":"2021-06-30T06:36:13.790667Z","shell.execute_reply.started":"2021-06-30T06:36:13.352817Z","shell.execute_reply":"2021-06-30T06:36:13.789979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"make_plot(2628)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T06:36:13.793539Z","iopub.execute_input":"2021-06-30T06:36:13.793973Z","iopub.status.idle":"2021-06-30T06:36:14.241639Z","shell.execute_reply.started":"2021-06-30T06:36:13.793926Z","shell.execute_reply":"2021-06-30T06:36:14.240618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"make_plot(4560)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T06:36:14.243309Z","iopub.execute_input":"2021-06-30T06:36:14.243911Z","iopub.status.idle":"2021-06-30T06:36:14.687315Z","shell.execute_reply.started":"2021-06-30T06:36:14.243866Z","shell.execute_reply":"2021-06-30T06:36:14.686274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"make_plot(4339)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T06:36:14.688797Z","iopub.execute_input":"2021-06-30T06:36:14.689413Z","iopub.status.idle":"2021-06-30T06:36:15.137491Z","shell.execute_reply.started":"2021-06-30T06:36:14.689366Z","shell.execute_reply":"2021-06-30T06:36:15.136413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### I expect if you use word2vec or FastText. etc Can get more meaningful accuracy.\n### If you have Good idea, feel free to review comments plz.\n### I always welcom feedback","metadata":{}},{"cell_type":"markdown","source":"### reference\n* http://docs.likejazz.com/lstm/\n* http://colah.github.io/posts/2015-08-Understanding-LSTMs/","metadata":{}}]}