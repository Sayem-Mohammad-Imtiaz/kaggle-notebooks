{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns  # visualization tool\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/pokemon-challenge/pokemon.csv')\ndata.head(10)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#shows last 5 rows\ndata.tail()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#give number of rows and columns in a tuble\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#correlation map\nf,ax = plt.subplots(figsize=(12, 12))\nsns.heatmap(data.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Line Plot\n# color = color, label = label, linewidth = width of line, alpha = opacity, grid = grid, linestyle = sytle of line\ndata.Speed.plot(kind = 'line', color = 'g',label = 'Speed',linewidth=1,alpha = 0.5,grid = True,linestyle = ':')\ndata.Defense.plot(color = 'r',label = 'Defense',linewidth=1, alpha = 0.5,grid = True,linestyle = '-.')\nplt.legend(loc='upper right')     # legend = puts label into plot\nplt.xlabel('x axis')              # label = name of label\nplt.ylabel('y axis')\nplt.title('Line Plot')            # title = title of plot\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scatter Plot \n# x = attack, y = defense\ndata.plot(kind='scatter', x='Attack', y='Defense',alpha = 0.5,color = 'red')\nplt.xlabel('Attack')              # label = name of label\nplt.ylabel('Defence')\nplt.title('Attack Defense Scatter Plot')            # title = title of plot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Histogram\n# bins = number of bar in figure\ndata.Speed.plot(kind = 'hist',bins = 50,figsize = (10,10))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# clf() = cleans it up again you can start a fresh\ndata.Speed.plot(kind = 'hist',bins = 50)\nplt.clf()\n# We cannot see plot due to clf()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"series = data['Defense']        # data['Defense'] = series\nprint(type(series))\ndata_frame = data[['Defense']]  # data[['Defense']] = data frame\nprint(type(data_frame))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1 - Filtering Pandas data frame\nx = data['Defense']>200     # There are only 3 pokemons who have higher defense value than 200\ndata[x]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This is also same with previous code line. Therefore we can also use '&' for filtering.\ndata[(data['Defense']>200) & (data['Attack']>100)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#List comprehension example\n# lets classify pokemons whether they have high or low speed. Our threshold is average speed.\nthreshold = sum(data.Speed)/len(data.Speed)\ndata[\"speed_level\"] = [\"high\" if i > threshold else \"low\" for i in data.Speed]\ndata.loc[:10,[\"speed_level\",\"Speed\"]] # we will learn loc more detailed later","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Cleaning Data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#to call Type 1\n#we can use data['Type 1']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#value_counts(): Frequency counts\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For example lets look frequency of pokemom types\nprint(data['Type 1'].value_counts(dropna = False))  # if there are nan values that also be counted\n# As it can be seen below there are 112 water pokemon or 70 grass pokemonprint","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#outliers: the value that is considerably higher or lower from rest of the data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**VISUAL EXPLORATORY DATA ANALYSIS¶**\nBox plots: visualize basic statistics like outliers, min/max or quantiles"},{"metadata":{"trusted":true},"cell_type":"code","source":"# For example: compare attack of pokemons that are legendary  or not\n# Black line at top is max\n# Blue line at top is 75%\n# Green line is median (50%)\n# Blue line at bottom is 25%\n# Black line at bottom is min\n# Circles are outliers\ndata.boxplot(column='Attack',by = 'Legendary')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n**TIDY DATA**\nWe tidy data with melt(). \nWe melt the data to visualize with seaborn library"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Firstly I create new data from pokemons data to explain melt nore easily.\ndata_new = data.head()    # I only take 5 rows into new data\ndata_new\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets melt\n# id_vars = what we do not wish to melt\n# value_vars = what we want to melt\nmelted = pd.melt(frame=data_new,id_vars = 'Name', value_vars= ['HP','Attack','Defense'])\nmelted","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**\nPIVOTING DATA¶**\nReverse of melting."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Index is name\n# I want to make that columns are variable\n# Finally values in columns are value\nmelted.pivot(index = 'Name', columns = 'variable',values='value')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**CONCATENATING DATA¶******\nWe can concatenate two dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Firstly let's create 2 data frame in a vertical way\ndata1 = data.head()\ndata2= data.tail()\nconc_data_row = pd.concat([data1,data2],axis =0,ignore_index =True) # axis = 0 : adds dataframes in row\nconc_data_row","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now let's create 2 data frame in a horizontal way\ndata1 = data['Attack'].head()\ndata2= data['Defense'].head()\ndata3=data['Name'].head()\nconc_data_col = pd.concat([data3,data1,data2],axis =1) # axis = 1 : adds dataframes in column\nconc_data_col","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**DATA TYPES**\nThere are 5 basic data types: object(string),boolean, integer, float and categorical.\nWe can make conversion data types like from str to categorical or from int to float\nWhy is category important:\n\n* make dataframe smaller in memory\n* can be utilized for anlaysis especially for sklearn"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets convert object(str) to categorical and int to float.\ndata['Type 1'] = data['Type 1'].astype('category')\ndata['Speed'] = data['Speed'].astype('float')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# As you can see Type 1 is converted from object to categorical\n# And Speed ,s converted from int to float\ndata.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**\nMISSING DATA and TESTING WITH ASSERT**\nIf we encounter with missing data, what we can do:\n\n* leave as is\n* drop them with dropna()\n* fill missing value with fillna()\n* fill missing values with test statistics like mean\n* Assert statement: check that you can turn on or turn off when you are done with your testing of the program"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets look at does pokemon data have nan value\n# As you can see there are 800 entries. However Type 2 has 414 non-null object so it has 386 null object.\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets chech Type 2\ndata[\"Type 2\"].value_counts(dropna =False)\n# As you can see, there are 386 NAN value","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets drop nan values\ndata1=data   # also we will use data to fill missing value so I assign it to data1 variable\ndata1[\"Type 2\"].dropna(inplace = True)  # inplace = True means we do not assign it to new variable. Changes automatically assigned to data\n# So does it work ?","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Lets check with assert statement\n# Assert statement:\nassert 1==1 # return nothing because it is true","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# In order to run all code, we need to make this line comment\n# assert 1==2 # return error because it is false","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert  data['Type 2'].notnull().all() # returns nothing because we drop nan values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"Type 2\"].fillna('empty',inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert  data['Type 2'].notnull().all() # returns nothing because we do not have nan values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # With assert statement we can check a lot of thing. For example\n# assert data.columns[1] == 'Name'\n# assert data.Speed.dtypes == np.int","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**\nVISUAL EXPLORATORY DATA ANALYSIS\n* Plot**\n* Subplot\n* Histogram:\n    * bins: number of bins\n    * range(tuble): min and max values of bins\n    * normed(boolean): normalize or not\n    * cumulative(boolean): compute cumulative distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting all data \ndata1 = data.loc[:,[\"Attack\",\"Defense\",\"Speed\"]]\ndata1.plot()\n# it is confusing\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# subplots\ndata1.plot(subplots = True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# scatter plot  \ndata1.plot(kind = \"scatter\",x=\"Attack\",y = \"Defense\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#hist plot \ndata1.plot(kind = \"hist\",y = \"Defense\",bins = 50,range= (0,250),density = True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# histogram subplot with non cumulative and cumulative\nfig, axes = plt.subplots(nrows=2,ncols=1)\ndata1.plot(kind = \"hist\",y = \"Defense\",bins = 50,range= (0,250),density = True,ax = axes[0])\ndata1.plot(kind = \"hist\",y = \"Defense\",bins = 50,range= (0,250),density = True,ax = axes[1],cumulative = True)\nplt.savefig('graph.png')\nplt\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**\nINDEXING PANDAS TIME SERIES¶**\n* datetime = object\n* parse_dates(boolean): Transform date to ISO 8601 (yyyy-mm-dd hh:mm:ss ) format"},{"metadata":{"trusted":true},"cell_type":"code","source":"time_list = [\"1992-03-08\",\"1992-04-12\"]\nprint(type(time_list[1])) # As you can see date is string\n# however we want it to be datetime object\ndatetime_object = pd.to_datetime(time_list)  #it becomes datetime index\nprint(type(datetime_object))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# close warning\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# In order to practice lets take head of pokemon data and add it a time list\ndata2 = data.head()\ndate_list = [\"1992-01-10\",\"1992-02-10\",\"1992-03-10\",\"1993-03-15\",\"1993-03-16\"]\ndatetime_object = pd.to_datetime(date_list)\ndata2[\"date\"] = datetime_object\n\ndata2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets make date as index\ndata2= data2.set_index(\"date\")\ndata2 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now we can select according to our date index\nprint(data2.loc[\"1993-03-16\"])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data2.loc[\"1992-03-10\":\"1993-03-15\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**\nRESAMPLING PANDAS TIME SERIES**\n* Resampling: statistical method over different time intervals\n* Needs string to specify frequency like \"M\" = month or \"A\" = year\n* Downsampling: reduce date time rows to slower frequency like from daily to weekly\n* Upsampling: increase date time rows to faster frequency like from daily to hourly\n* Interpolate: Interpolate values according to different methods like ‘linear’, ‘time’ or index’\n* https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.interpolate."},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will use data2 that we create at previous part\n#resample to the years and take the average of them\ndata2.resample(\"A\").mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets resample with month\ndata2.resample(\"M\").mean()\n# As you can see there are a lot of nan because data2 does not include all months","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# In real life (data is real. Not created from us like data2) we can solve this problem with interpolate\n# We can interpolete from first value\ndata2.HP.resample(\"M\").first().interpolate(\"linear\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Or we can interpolate with mean()\ndata2.resample(\"M\").mean().interpolate(\"linear\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**MANIPULATING DATA FRAMES WITH PANDAS\n**\n\nINDEXING DATA FRAMES"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.set_index(\"#\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# indexing using square brackets\ndata[\"HP\"][1]\n#otherwise it shoould be data[\"HP\"][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using column attribute and row label\ndata.HP[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using loc accessor\ndata.loc[1,[\"HP\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Selecting only some columns\ndata[[\"HP\",\"Attack\"]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**\nSLICING DATA FRAME**\n* Difference between selecting columns\n* Series and data frames\n* Slicing and indexing series\n* Reverse slicing\n* From something to end"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Difference between selecting columns: series and dataframes\nprint(type(data[\"HP\"]))     # series\nprint(type(data[[\"HP\"]]))   # data frames","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Slicing and indexing series\ndata.loc[1:10,\"HP\":\"Defense\"]   # 10 and \"Defense\" are inclusive\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reverse slicing \ndata.loc[10:1:-1,\"HP\":\"Defense\"] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# From something to end\ndata.loc[1:10,\"Speed\":] ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**\nFILTERING DATA FRAMES**\nCreating boolean series Combining filters Filtering column based others"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating boolean series\nboolean = data.HP > 200\ndata[boolean]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Combining filters\nfirst_filter = data.HP > 150\nsecond_filter = data.Speed > 35\ndata[first_filter & second_filter]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filtering column based others\n#hıza göre filtrelediğim pokemonların canını göster\ndata.HP[data.Speed<15]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**\nTRANSFORMING DATA**\n* Plain python functions\n* Lambda function: to apply arbitrary python function to every element\n* Defining column using other columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plain python functions\ndef div(n):\n    return n/2\ndata.HP.apply(div)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Or we can use lambda function\ndata.HP.apply(lambda n : n/2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining column using other columns\ndata[\"total_power\"] = data.Attack + data.Defense\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**\nINDEX OBJECTS AND LABELED DATA**\nindex: sequence of label"},{"metadata":{"trusted":true},"cell_type":"code","source":"# our index name is this:\nprint(data.index.name)\n# lets change it\ndata.index.name = \"index_name\"\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Overwrite index\n# if we want to modify index we need to change all of them.\ndata.head()\n# first copy of our data to data3 then change index \ndata3 = data.copy()\n# lets make index start from 100. It is not remarkable change but it is just example\ndata3.index = range(100,900,1)\ndata3.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We can make one of the column as index. I actually did it at the beginning of manipulating data frames with pandas section\n# It was like this\n# data= data.set_index(\"#\")\n# also you can use \n# data.index = data[\"#\"]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n**HIERARCHICAL INDEXING¶**\nSetting indexing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets read data frame one more time to start from beginning\ndata = pd.read_csv('/kaggle/input/pokemon-challenge/pokemon.csv')\ndata.head(10)\n\n# As you can see there is index. However we want to set one or more column to be index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setting index : type 1 is outer type 2 is inner index\ndata1 = data.set_index([\"Type 1\",\"Type 2\"]) \ndata1.head(20)\n# data1.loc[\"Fire\",\"Flying\"] # howw to use indexes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**\nPIVOTING DATA FRAMES¶**\npivoting: reshape tool\neskiden feature column olarak kullandığımız isimleri artık sample, value yapacağız, pandas özelliği"},{"metadata":{"trusted":true},"cell_type":"code","source":"dic = {\"treatment\":[\"A\",\"A\",\"B\",\"B\"],\"gender\":[\"F\",\"M\",\"F\",\"M\"],\"response\":[10,45,5,9],\"age\":[15,4,72,65]}\ndf = pd.DataFrame(dic)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pivoting\ndf.pivot(index=\"treatment\",columns = \"gender\",values=\"response\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**\nSTACKING and UNSTACKING DATAFRAME¶**\nunstack\n* deal with multi label indexes\n* level: position of unstacked index\n* swaplevel: change inner and outer level index position"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = df.set_index([\"treatment\",\"gender\"])\ndf1\n# lets unstack it","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# level determines indexes\ndf1.unstack(level=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.unstack(level=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# change inner and outer level index position\ndf2 = df1.swaplevel(0,1)\ndf2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**MELTING DATA FRAMES¶**\nReverse of pivoting"},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df.pivot(index=\"treatment\",columns = \"gender\",values=\"response\")\npd.melt(df,id_vars=\"treatment\",value_vars=[\"age\",\"response\"]) #hiçbir şey yazmazsak default olarak variable ve value ekliyor","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**CATEGORICALS AND GROUPBY**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will use df\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# according to treatment take means of other features\ndf.groupby(\"treatment\").mean()   # mean is aggregation / reduction method\n# there are other methods like sum, std,max or min","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we can only choose one of the feature\ndf.groupby(\"treatment\").age.max() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Or we can choose multiple features\ndf.groupby(\"treatment\")[[\"age\",\"response\"]].min() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()\n# as you can see gender is object\n# However if we use groupby, we can convert it categorical data. \n# Because categorical data uses less memory, speed up operations like groupby\n#df[\"gender\"] = df[\"gender\"].astype(\"category\")\n#df[\"treatment\"] = df[\"treatment\"].astype(\"category\")\n#df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}