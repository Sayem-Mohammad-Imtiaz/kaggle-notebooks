{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport re\nimport datetime\nimport missingno as msno","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Data Preparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/netflix-shows/netflix_titles.csv')\ndf.info()\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Convert datetime to Dtype 'datetime64'"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['date_added'] = pd.to_datetime(df['date_added'])\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df['Hour'] = df['date_added'].apply(lambda time: time.hour)\ndf['Date'] = df['date_added'].apply(lambda x: x.day)\ndf['Day of Week'] = df['date_added'].apply(lambda x: x.dayofweek)\ndf['Month'] = df['date_added'].apply(lambda x: x.month)\ndf['Year'] = df['date_added'].apply(lambda x: x.year)\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check Missing Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"msno.matrix(df);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"msno.bar(df);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#missing value\nmiss = pd.Series(df.isnull().sum(), name='count')\npercent_miss = pd.Series(round(df.isnull().sum()/df.shape[0]*100,2), name='percent')\npd.DataFrame([miss, percent_miss]).T.sort_values(by = 'percent', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Unique values for each columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"uni = [df[col].nunique() for col in df.columns]  #df.nunique().to_list()\nunique = dict(zip(df.columns,uni))\nsorted(unique.items(), key=lambda x:x[1],reverse=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Replace Missing Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.director.fillna('Unknown', inplace=True)\ndf.director","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df.country.isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#replace nan\ndf.loc[38, 'country'] = 'Thailand'\n\nmiss_col = df.columns[df.isnull().any()].to_list()\nmiss_col.remove('date_added')\nprint('Missing columns:',miss_col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in miss_col:\n    df[col].fillna('Unknown', inplace=True)\n\n#drop rows which have date_added is NaN\ndf.dropna(subset =['date_added'], axis=0, inplace=True)\n\n#check missing value\ndf.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Analysis\n\n## Recommendation System (content-based filtering)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#create column name 'text' which combine all texts together\ndf['text'] =  df['title'] + ' ' + df['director'] + ' ' + df['cast'] + ' ' + df['rating'] + ' '+ df['listed_in'] + ' ' + df['description'] \n\n#drop if duplicate data \ndf.drop_duplicates(subset=['text'], inplace=True)\n\n#reset index\ndf.reset_index(drop=True,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sample text\ndf.text.sample(1).tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction import text\n\n#add stop word\nmy_words = set(['Unknown'])\n\nmy_stop_words = text.ENGLISH_STOP_WORDS.union(my_words)\n\ntfidfvectorizer = TfidfVectorizer(analyzer='word' , stop_words='english')\n\ntfidf_term_vectors = tfidfvectorizer.fit_transform(df['text'])\n\nprint(tfidf_term_vectors.shape)\n\ntfidf_term_vectors.todense()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import metrics\nfrom sklearn.metrics.pairwise import linear_kernel, euclidean_distances, manhattan_distances, cosine_similarity\n\n# Compute the metrics\nlinear_ke = linear_kernel(tfidf_term_vectors, tfidf_term_vectors)\n\neuclidean = euclidean_distances(tfidf_term_vectors, tfidf_term_vectors) \n\nmanhattan = manhattan_distances(tfidf_term_vectors, tfidf_term_vectors)\n\ncosine = cosine_similarity(tfidf_term_vectors, tfidf_term_vectors) #same as linear_kernel\n\nprint(linear_ke.shape)\n\nlinear_ke","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"indices = pd.Series(df.index, index=df['title']).drop_duplicates()\nindices","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_recommendations(title, metric):\n    \n    idx = indices[title]\n\n    # Get the pairwsie similarity scores of all movies with that movie\n    pairwsie = list(enumerate(metric[idx]))\n\n    # Sort the movies based on the similarity scores\n    pairwsie = sorted(pairwsie, key=lambda x: x[1], reverse=True)\n\n    # Get the scores of the 10 most similar movies\n    scores = pairwsie[1:11]\n\n    # Get the movie indices\n    movie_indices = [i[0] for i in scores]\n\n    # Return the top 10 most similar movies\n    return df['title'].iloc[movie_indices]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.title.unique().tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"name = 'Avengers: Infinity War'\n\nmetric = [linear_ke, euclidean, manhattan]\n\nfor i in metric:\n    print(get_recommendations(name, i),'\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Clean data by lower text and remove space "},{"metadata":{"trusted":true},"cell_type":"code","source":"df['text2'] = df['text'].apply(lambda x: str.lower(x.replace(\" \", \"\")))\ndf['text2']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf_term_vectors2 = tfidfvectorizer.fit_transform(df['text2'])\n\nlinear_ke2 = linear_kernel(tfidf_term_vectors2, tfidf_term_vectors2)\neuclidean2 = euclidean_distances(tfidf_term_vectors2, tfidf_term_vectors2) \nmanhattan2 = manhattan_distances(tfidf_term_vectors2, tfidf_term_vectors2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"name = 'Avengers: Infinity War'\n\nmetric = [linear_ke2, euclidean2, manhattan2]\n\nfor i in metric:\n    print(get_recommendations(name, i),'\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"set1 = get_recommendations('Avengers: Infinity War', linear_ke)\nset2 = get_recommendations('Avengers: Infinity War', linear_ke2)\n\nset1=set(set1)\nset2=set(set2)\n\nintersec = set1.intersection(set2)\nintersec","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"set1 = get_recommendations('Avengers: Infinity War', euclidean)\nset2 = get_recommendations('Avengers: Infinity War', euclidean2)\n\nset1=set(set1)\nset2=set(set2)\n\nintersec = set1.intersection(set2)\nintersec","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"set1 = get_recommendations('Avengers: Infinity War', manhattan)\nset2 = get_recommendations('Avengers: Infinity War', manhattan2)\n\nset1=set(set1)\nset2=set(set2)\n\nintersec = set1.intersection(set2)\nintersec","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"different metric and different cleaning text has a different result"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}