{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Using EDA and Machine Learning to Predict Heart Disease"},{"metadata":{},"cell_type":"markdown","source":"Task:\n    \n    Given various parameters about a patient, can we predict whether or not they have heart disease?"},{"metadata":{},"cell_type":"markdown","source":"**In this notebook we are going to perform Exploratory Data Analysis and use various Machine Learning Models to predict whether the patient has heart disease or not depending on the values of various features. I will be using Bokeh and a little bit of Seaborn to plot the graphs.**\n\n**Please Upvote if you like the notebook and do provide your valuable feedback.**"},{"metadata":{},"cell_type":"markdown","source":"#### Loading the libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Loading the dataset"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/heart-disease-uci/heart.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Features"},{"metadata":{},"cell_type":"markdown","source":"Let's have a look at what each of these columns means:\n\n1. **age** -> Age of the person.\n2. **sex** -> Sex of the person.  (1 = male; 0 = female)\n3. **cp** -> Chest Pain Type. It can take values of 0, 1, 2, 3.\n4. **trestbps** -> Resting Blood Presssure (Measured in mm Hg on admission to the hospital). It can take continuous values from 94 to 200.  \n5. **chol** -> Serum Cholestrol in mg/dl. It also takes continuous values.\n6. **fbs** -> Fasting Blood Sugar. It can take value of either 1 or 0.\n7. **restecg** -> Resting Electrocardiographic Results. It can take value of 0, 1 or 2.\n8. **thalach** -> Maximum Heart Rate achieved. It can take continuous value from 71 to 202.\n9. **exang** -> Exercise Induced Angina. It can take value either of 0 or 1.\n10. **oldpeak** -> ST depression induced by exercise relative to rest. It takes continuous decimal values.\n11. **slope** -> the slope of the peak exercise ST segment. It can take value of either 0, 1 or 2.\n12. **ca** -> Number of major vessels colored by flourosopy. It can take value of either 0, 1, 2, 3 or 4. \n13. **thal** -> 3 = normal; 6 = fixed defect; 7 = reversable defect\n14. **target** -> Indicates the presence or absence of heart disease. (= the predicted attribute)"},{"metadata":{},"cell_type":"markdown","source":"For performing EDA, I will be using [Bokeh](https://bokeh.org)."},{"metadata":{"trusted":true},"cell_type":"code","source":"from bokeh.io import output_notebook\nfrom bokeh.io import show\nfrom bokeh.plotting import figure\nfrom bokeh.transform import cumsum\nfrom bokeh.palettes import Spectral6\nfrom bokeh.models import ColumnDataSource\nfrom bokeh.layouts import gridplot\nfrom math import pi","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_notebook()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Is Dataset Balanced ?"},{"metadata":{},"cell_type":"markdown","source":"The first step before we start performing EDA, preprocessing the data, building the ML model is to check whether the variable to predict i.e 'target' is balanced or not. By checking this we can get to know which evaluation metrics will be better suited for this particular dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['target'].value_counts()[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unique = [\"0\", '1']\ntop = [df['target'].value_counts()[0], df['target'].value_counts()[1]]\nsource = ColumnDataSource(data = dict(Target = unique, counts = top, color = Spectral6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p = figure(\n    x_range = unique,\n    plot_height = 500,\n    plot_width = 500,\n    x_axis_label = 'Target',\n    y_axis_label = 'Count(Target)',\n    title = 'Count of People Having Heart Disease and Not Having Heart Disease',\n    tools = \"hover\", tooltips=\"@Target: @counts\"\n)\n\np.vbar(\n    x = 'Target',\n    top = 'counts',\n    bottom = 0,\n    width = 0.9,\n    source = source,\n    color = 'color'\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target = {\n            'No Heart Disease' : df['target'].value_counts()[0], \n          'Have Heart Disease' : df['target'].value_counts()[1]\n         }\n\ndata = pd.Series(target).reset_index(name = 'value').rename(columns = {'index':'target'})\ndata['angle'] = data['value']/data['value'].sum() * 2 * pi\ndata['color'] = ['skyblue', 'salmon']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p1 = figure(\n            plot_height = 500, \n            plot_width = 500, \n            title = \"Proportion of People Having Heart Disease and not Having Heart Disease\", \n            toolbar_location = None,\n            tools = \"hover\", \n            tooltips = \"@target: @value\", \n            x_range = (-0.5, 1.0)\n            )\n\np1.wedge(\n        x = 0, y = 1, radius = 0.4,\n        start_angle = cumsum('angle', include_zero=True), \n        end_angle = cumsum('angle'),\n        line_color = \"white\", \n        fill_color = 'color', \n        legend_field = 'target', \n        source = data\n        )\n\np1.legend.location = \"top_right\"\n\np1.legend.label_text_font_size = '5pt'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show(gridplot([[p], [p1]]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Percentage of people having Heart Disease\", round(df['target'].value_counts()[1] / (df['target'].value_counts()[0] + df['target'].value_counts()[1]), 2) * 100)\nprint(\"Percentage of people not having Heart Disease\", round(df['target'].value_counts()[0] / (df['target'].value_counts()[0] + df['target'].value_counts()[1]), 2) * 100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that the dataset is balanced as there is no major difference between the proportion of people having heart disease and those not having heart disease."},{"metadata":{},"cell_type":"markdown","source":"Next we need to check whether there are null values present in the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So we don't have any null values present which saves us a lot of time :)"},{"metadata":{},"cell_type":"markdown","source":"# 2. Exploratory Data Analysis(EDA)"},{"metadata":{},"cell_type":"markdown","source":"First let's classify these columns as Catergorical or Continuous. For Categorical variables we will print out the unique categories for that particular column."},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_var = []\ncontinuous_var = []\n\nfor column in df.columns:\n    if len(df[column].unique()) <= 10:\n        print(f\"{column} : {df[column].unique()}\")\n        categorical_var.append(column)\n        print()\n    else:\n        continuous_var.append(column)\n        \nprint(\"Categorical Variables are: \", categorical_var)\nprint(\"Continuous Variables are: \", continuous_var)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Now we will explore the relation of these categorical variables with the target.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def count_of_each_category(column_name):\n    \"\"\"\n    A function which will plot the count of each category for a particular column using bokeh.\n    \"\"\"\n    values = {}\n    for i in df[column_name].value_counts().index:\n        values[i] = df[column_name].value_counts()[i]\n    column = list(values.keys())\n    top = list(values.values())\n    source = ColumnDataSource(data = dict(Classes = column, counts = top, color = Spectral6))\n\n    p2 = figure(\n        plot_height = 400,\n        plot_width = 400,\n        x_axis_label = column_name,\n        y_axis_label = 'Count(Classes)',\n        tools=\"hover\", tooltips=\"@Classes: @counts\"\n    )\n\n    p2.vbar(\n        x = 'Classes',\n        top = 'counts',\n        bottom = 0,\n        width = 0.9,\n        source = source,\n        color = 'color'\n    )\n    \n    return p2\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Sex vs Target"},{"metadata":{"trusted":true},"cell_type":"code","source":"p2 = count_of_each_category('sex')\nshow(p2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For analyzing how much proportion of male or female have heart disease. \n\nsex_vs_target = df.groupby(['sex', 'target'])['sex'].count().to_list()\n\nunique = [0, 1]\ncondition = ['Have Heart Disease', 'No Heart Disease']\ncolors = [\"#e84d60\", \"#718dbf\"]\ndata = {\n        'Classes' : unique,\n        'Have Heart Disease' : [sex_vs_target[1], sex_vs_target[3]],\n        'No Heart Disease'   : [sex_vs_target[0], sex_vs_target[2]]\n        }\n\np3 = figure(plot_height = 400, plot_width = 400, title = \"Sex vs Target\",\n           )\n\np3.vbar_stack(condition, x ='Classes', width = 0.9, color = colors, source = data,\n             legend_label = condition)\n\np3.legend.location = \"top_left\"\n\np3.legend.label_text_font_size = '7pt'\nshow(p3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We might think that more number of men have heart disease but if we observe closely, we can see that more proportion of female have heart disease as compared to men."},{"metadata":{},"cell_type":"markdown","source":"### Chest Pain vs Target"},{"metadata":{},"cell_type":"markdown","source":"Different Chest Pain Types:\n\n0: Typical angina: chest pain related decrease blood supply to the heart\n\n1: Atypical angina: chest pain not related to heart\n\n2: Non-anginal pain: typically esophageal spasms (non heart related)\n\n3: Asymptomatic: chest pain not showing signs of disease\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"p4 = count_of_each_category('cp')\nshow(p4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For analyzing what proportion of different chest pain types patient have heart disease. \n\ncp_vs_target = df.groupby(['cp', 'target'])['cp'].count().to_list()\n\nunique = [0, 1, 2, 3]\ncondition = ['Have Heart Disease', 'No Heart Disease']\ncolors = [\"#e84d60\", \"#718dbf\"]\ndata = {\n        'Classes' : unique,\n        'Have Heart Disease' : [cp_vs_target[1], cp_vs_target[3], cp_vs_target[5],cp_vs_target[7]],\n        'No Heart Disease'   : [cp_vs_target[0], cp_vs_target[2], cp_vs_target[4], cp_vs_target[6]]\n        }\n\np5 = figure(plot_height = 400, plot_width = 400, title = \"Chest Pain vs Target\")\n\np5.vbar_stack(condition, x ='Classes', width = 0.9, color = colors, source = data, legend_label = condition)\n\np5.legend.location = \"top_right\"\n\np5.legend.label_text_font_size = '7pt'\nshow(p5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It's really shocking to know that majority of the asymptomatic (Type 3) cases and Non-anginal pain patients (Type 2) ended up having heart disease."},{"metadata":{},"cell_type":"markdown","source":"### Fasting Blood Sugar vs Target "},{"metadata":{},"cell_type":"markdown","source":"FBS > 120 mg/dl (1 = true; 0 = false). \n\nThose whose Fasting Blood Sugar is greater than 120 indicates that the patient is diabetic."},{"metadata":{"trusted":true},"cell_type":"code","source":"p6 = count_of_each_category('fbs')\nshow(p6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For analyzing how much proportion of diabetic and non-diabetic patients have heart disease. \n\nfbs_vs_target = df.groupby(['fbs', 'target'])['fbs'].count().to_list()\n\nunique = [0, 1]\ncondition = ['Have Heart Disease', 'No Heart Disease']\ncolors = [\"#e84d60\", \"#718dbf\"]\ndata = {\n        'Classes' : unique,\n        'Have Heart Disease' : [fbs_vs_target[1], fbs_vs_target[3]],\n        'No Heart Disease'   : [fbs_vs_target[0], fbs_vs_target[2]]\n        }\n\np7 = figure(plot_height = 400, plot_width = 400, title = \"Fasting Blood Sugar vs Target\")\n\np7.vbar_stack(condition, x ='Classes', width = 0.9, color = colors, source = data, legend_label = condition)\n\np7.legend.location = \"top_right\"\n\np7.legend.label_text_font_size = '7pt'\nshow(p7)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Restecg vs Target"},{"metadata":{},"cell_type":"markdown","source":"0: Nothing to note\n\n1: ST-T Wave abnormality can range from mild symptoms to severe problems signals non-normal heart beat\n\n2: Possible or definite left ventricular hypertrophy. Enlarged heart's main pumping chamber\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"p8 = count_of_each_category('restecg')\nshow(p8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"restecg_vs_target = df.groupby(['restecg', 'target'])['restecg'].count().to_list()\n\nunique = [0, 1, 2]\ncondition = ['Have Heart Disease', 'No Heart Disease']\ncolors = [\"#e84d60\", \"#718dbf\"]\ndata = {\n        'Classes' : unique,\n        'Have Heart Disease' : [restecg_vs_target[1], restecg_vs_target[3], restecg_vs_target[5]],\n        'No Heart Disease'   : [restecg_vs_target[0], restecg_vs_target[2], restecg_vs_target[4]]\n        }\n\np9 = figure(plot_height = 400, plot_width = 400, title = \"Restecg vs Target\")\n\np9.vbar_stack(condition, x ='Classes', width = 0.9, color = colors, source = data, legend_label = condition)\n\np9.legend.location = \"top_right\"\n\np9.legend.label_text_font_size = '7pt'\nshow(p9)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A large proportion of people having restecg of type 1 actually have heart disease. We must take care of ST-T Wave abnormality as it can range from mild symptoms to severe problems."},{"metadata":{},"cell_type":"markdown","source":"### Exercise Induced Angina vs Target"},{"metadata":{},"cell_type":"markdown","source":"exang means exercise induced angina (1 = yes; 0 = no). Angina is a type of chest pain caused by reduced blood flow to the heart"},{"metadata":{"trusted":true},"cell_type":"code","source":"p10 = count_of_each_category('exang')\nshow(p10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"exang_vs_target = df.groupby(['exang', 'target'])['exang'].count().to_list()\n\nunique = [0, 1]\ncondition = ['Have Heart Disease', 'No Heart Disease']\ncolors = [\"#e84d60\", \"#718dbf\"]\ndata = {\n        'Classes' : unique,\n        'Have Heart Disease' : [restecg_vs_target[1], restecg_vs_target[3]],\n        'No Heart Disease'   : [restecg_vs_target[0], restecg_vs_target[2]]\n        }\n\np11 = figure(plot_height = 400, plot_width = 400, title = \"Exang vs Target\")\n\np11.vbar_stack(condition, x ='Classes', width = 0.9, color = colors, source = data, legend_label = condition)\n\np11.legend.location = \"top_right\"\n\np11.legend.label_text_font_size = '7pt'\nshow(p11)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Slope vs Target"},{"metadata":{},"cell_type":"markdown","source":"slope - the slope of the peak exercise ST segment\n\n0: Upsloping: better heart rate with excercise (uncommon)\n\n1: Flatsloping: minimal change (typical healthy heart)\n\n2: Downslopins: signs of unhealthy heart"},{"metadata":{"trusted":true},"cell_type":"code","source":"p12 = count_of_each_category('slope')\nshow(p12)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"slope_vs_target = df.groupby(['slope', 'target'])['slope'].count().to_list()\n\nunique = [0, 1, 2]\ncondition = ['Have Heart Disease', 'No Heart Disease']\ncolors = [\"#e84d60\", \"#718dbf\"]\ndata = {\n        'Classes' : unique,\n        'Have Heart Disease' : [slope_vs_target[1], slope_vs_target[3], slope_vs_target[5]],\n        'No Heart Disease'   : [slope_vs_target[0], slope_vs_target[2], slope_vs_target[4]]\n        }\n\np13 = figure(plot_height = 400, plot_width = 400, title = \"Slope vs Target\")\n\np13.vbar_stack(condition, x ='Classes', width = 0.9, color = colors, source = data, legend_label = condition)\n\np13.legend.location = \"top_left\"\n\np13.legend.label_text_font_size = '5pt'\nshow(p13)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As type 2 means Downslopins which is a sign of unhealthy heart, most patients with type 2 slope had Heart Disease."},{"metadata":{},"cell_type":"markdown","source":"### Ca vs Target"},{"metadata":{},"cell_type":"markdown","source":"ca - number of major vessels (0-3) colored by flourosopy\n\ncolored vessel means the doctor can see the blood passing through\n\nthe more blood movement the better (no clots)"},{"metadata":{"trusted":true},"cell_type":"code","source":"p14 = count_of_each_category('ca')\nshow(p14)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ca_vs_target = df.groupby(['ca', 'target'])['ca'].count().to_list()\n\nunique = [0, 1, 2, 3, 4]\ncondition = ['Have Heart Disease', 'No Heart Disease']\ncolors = [\"#e84d60\", \"#718dbf\"]\ndata = {\n        'Classes' : unique,\n        'Have Heart Disease' : [ca_vs_target[1], ca_vs_target[3], ca_vs_target[5], ca_vs_target[7], ca_vs_target[9]],\n        'No Heart Disease'   : [ca_vs_target[0], ca_vs_target[2], ca_vs_target[4], ca_vs_target[6], ca_vs_target[8]]\n        }\n\np15 = figure(plot_height = 400, plot_width = 400, title = \"Ca vs Target\")\n\np15.vbar_stack(condition, x ='Classes', width = 0.9, color = colors, source = data, legend_label = condition)\np15.legend.location = \"top_right\"\n\np15.legend.label_text_font_size = '7pt'\nshow(p15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see a large proportion of patients having 'ca' value of type 0 and type 4 had Heart Disease."},{"metadata":{},"cell_type":"markdown","source":"**Now we will see the relation of the Continuous Variables with the target.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_cont_var(column_name):\n    \"\"\"\n    A function which makes histogram for continuous variables.\n    \"\"\"\n    hist1, edges1 = np.histogram(df[df[\"target\"] == 0][column_name], density = True, bins = 40)\n    hist2, edges2 = np.histogram(df[df[\"target\"] == 1][column_name], density = True, bins = 40)\n\n    p = figure(\n        plot_height = 500,\n        plot_width = 500,\n        x_axis_label = column_name,\n        title = column_name.capitalize() + ' vs Target'\n    )\n\n    p.quad(\n        bottom = 0,\n        top = hist1,\n        left = edges1[:-1],\n        right = edges1[1:],\n        line_color = 'white',\n        color = 'blue', # Blue represents patients not having heart disease.\n        alpha = 0.6\n    )\n\n    p.quad(\n        bottom = 0,\n        top = hist2,\n        left = edges2[:-1],\n        right = edges2[1:],\n        line_color = 'white',\n        color = 'red', # Red represents patients having heart disease.\n        alpha = 0.6\n    )\n\n\n\n    return p\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Age vs Target"},{"metadata":{"trusted":true},"cell_type":"code","source":"p16 = plot_cont_var('age')\nshow(p16)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is no particular age at which the person is more prone to having heart disease, which proves that age is just a number."},{"metadata":{"trusted":true},"cell_type":"code","source":"continuous_var","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Resting Blood Pressure vs Target"},{"metadata":{},"cell_type":"markdown","source":"Resting Blood Pressure (in mm Hg on admission to the hospital) anything above 130-140 is typically cause for concern"},{"metadata":{"trusted":true},"cell_type":"code","source":"p17 = plot_cont_var('trestbps')\nshow(p17)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Those patients having Blood Pressure in the range of 120 to 160 have the highest chance of having heart disease"},{"metadata":{},"cell_type":"markdown","source":"###  Cholestoral vs Target"},{"metadata":{"trusted":true},"cell_type":"code","source":"p18 = plot_cont_var('chol')\nshow(p18)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that patient having Cholestrol level greater than 200 had heart disease."},{"metadata":{},"cell_type":"markdown","source":"### Thalach vs Target"},{"metadata":{},"cell_type":"markdown","source":"maximum heart rate achieved"},{"metadata":{"trusted":true},"cell_type":"code","source":"p19 = plot_cont_var('thalach')\nshow(p19)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The patients having maximum heart rate greater than 150 are at a greater risk of having heart disease."},{"metadata":{},"cell_type":"markdown","source":"# 3. Correlation Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# I have used seaborn for plotting correlation matrix as its \n# much faster and much more easier than bokeh ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix = df.corr()\nfig, ax = plt.subplots(figsize=(15, 15))\nax = sns.heatmap(corr_matrix,\n                 annot = True,\n                 linewidths = 0.5,\n                 fmt = \".2f\",\n                 cmap = \"YlGnBu\");\nbottom, top = ax.get_ylim()\nax.set_ylim(bottom + 0.5, top - 0.5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The correlation between the features with target is not that clear in the correlation matrix as there are a large number of features, lets visualize it in another way."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop('target', axis=1).corrwith(df.target).plot(kind = 'bar', grid = True, \n                                                   figsize = (12, 8), \n                                                   title = \"Correlation with Target\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that 'fbs' and 'chol' are least related with 'target' whereas other features are highly correlated with the 'target' variable."},{"metadata":{},"cell_type":"markdown","source":"# 3. Data Pre-processing"},{"metadata":{},"cell_type":"markdown","source":"As we can see that there a number of continuous variables, we need to scale the data so that the continuous variables don't get majority of the weight or in other words, become the deciding factor to predict whether the patient has heart disease. We would also need to convert some categorical variable into dummy variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas import get_dummies\n\ncategorical_var.remove('target') # Removing the 'target' column from the list of categorical variables.\ndataframe = pd.get_dummies(df, columns = categorical_var)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataframe.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataframe.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before we scale the data, we need to split the data into train and test. We can not apply scaling before splitting because test set is the real world data which the trained model would have never seen. Therefore, we will scale the test data according to the train data"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = dataframe.drop('target', axis = 1)\ny = dataframe['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_std = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_std","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that both X_train and X_test has been scaled. Now we can apply Machine Learning Algorithms."},{"metadata":{},"cell_type":"markdown","source":"# 4. Training Machine Learning Algorithms"},{"metadata":{},"cell_type":"markdown","source":"Before we train any model, I will create a function which will help to evaluate the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluation(model, x_train_std, y_train, x_test, y_test, train = True):\n    if train == True:\n        pred = model.predict(x_train_std)\n        classifier_report = pd.DataFrame(classification_report(y_train, pred, output_dict = True))\n        print(\"Train Result:\\n================================================\")\n        print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(f\"F1 Score: {round(f1_score(y_train, pred), 2)}\")\n        print(\"_______________________________________________\")\n        print(f\"CLASSIFICATION REPORT:\\n{classifier_report}\")\n        print(\"_______________________________________________\")\n        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")\n        \n    if train == False:\n        pred = model.predict(x_test)\n        classifier_report = pd.DataFrame(classification_report(y_test, pred, output_dict = True))\n        print(\"Test Result:\\n================================================\")\n        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(f\"F1 Score: {round(f1_score(y_test, pred), 2)}\")\n        print(\"_______________________________________________\")\n        print(f\"CLASSIFICATION REPORT:\\n{classifier_report}\")\n        print(\"_______________________________________________\")\n        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression(solver = 'liblinear')\nlr.fit(X_train_std, y_train)\n\nevaluation(lr, X_train_std, y_train, X_test, y_test, True)\nevaluation(lr, X_train_std, y_train, X_test, y_test, False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Through Logistic Regression we were able to achieve Training Accuracy of 88.55 % and Testing Accuracy of 86.84 %."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_score_lr = round(accuracy_score(y_train, lr.predict(X_train_std)) * 100, 2)\ntest_score_lr = round(accuracy_score(y_test, lr.predict(X_test)) * 100, 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier(n_estimators = 400)\nrfc.fit(X_train_std, y_train)\n\nevaluation(rfc, X_train_std, y_train, X_test, y_test, True)\nevaluation(rfc, X_train_std, y_train, X_test, y_test, False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Through Random Forest Classifier we were able to achieve Training Accuracy of 100 % and Testing Accuracy of 84.21 %."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_score_rfc = round(accuracy_score(y_train, rfc.predict(X_train_std)) * 100, 2)\ntest_score_rfc = round(accuracy_score(y_test, rfc.predict(X_test)) * 100, 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we will determine the right number of n_estimators to be used:"},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_scores = []\nfor i in range(1, 1000, 100):\n    rfc = RandomForestClassifier(n_estimators = i)\n    rfc.fit(X_train_std, y_train)\n    accuracy_scores.append(accuracy_score(y_test, rfc.predict(X_test)))\nprint(accuracy_scores)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that having 500 number of trees gives the highest accuracy hence we have used 500 above."},{"metadata":{},"cell_type":"markdown","source":"### K Nearest Neighbor"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Deciding the right number of Neighbors."},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_scores = []\n\nfor i in range(1, 10):\n    knn = KNeighborsClassifier(n_neighbors = i)\n    knn.fit(X_train_std, y_train)\n    accuracy_scores.append(accuracy_score(y_test, knn.predict(X_test)))\n    \nprint(accuracy_scores)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For now we will take the number of neighbors to be 9. "},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(n_jobs = 9)\nknn.fit(X_train_std, y_train)\n\nevaluation(knn, X_train_std, y_train, X_test, y_test, True)\nevaluation(knn, X_train_std, y_train, X_test, y_test, False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_score_knn = round(accuracy_score(y_train, knn.predict(X_train_std)) * 100, 2)\ntest_score_knn = round(accuracy_score(y_test, knn.predict(X_test)) * 100, 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Support Vector Machine"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\nsvm = SVC(kernel='rbf', gamma=0.1, C=1.0)\nsvm.fit(X_train_std, y_train)\n\nevaluation(svm, X_train_std, y_train, X_test, y_test, True)\nevaluation(svm, X_train_std, y_train, X_test, y_test, False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_score_svm = round(accuracy_score(y_train, svm.predict(X_train_std)) * 100, 2)\ntest_score_svm = round(accuracy_score(y_test, svm.predict(X_test)) * 100, 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Summary"},{"metadata":{"trusted":true},"cell_type":"code","source":"models = {\n           'Train Accuracy': [train_score_lr, train_score_rfc, train_score_knn, train_score_svm],\n          'Test Accuracy' : [test_score_lr, test_score_rfc, test_score_knn, test_score_svm]\n         }\n\nmodels = pd.DataFrame(models, index = ['Logistic Regression', 'Random Forest Classifier', 'K-Nearest Neighbor', 'Support Vector Machine'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Hyperparameter Tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression with Hyperparameter Tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n        \"C\": np.logspace(-4, 4, 20), # For Regularization\n          \"solver\": [\"liblinear\"]}\n\nlr = LogisticRegression()\n\nlr_cv = GridSearchCV(lr, params, scoring = \"accuracy\", n_jobs = -1, verbose = 1, cv = 5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_cv.fit(X_train_std, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_params = lr_cv.best_params_\nprint(f\"Best parameters: {best_params}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression(**best_params)\n\nlr.fit(X_train_std, y_train)\n\nevaluation(lr, X_train_std, y_train, X_test, y_test, True)\nevaluation(lr, X_train_std, y_train, X_test, y_test, False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_score_lr = round(accuracy_score(y_train, lr.predict(X_train_std)) * 100, 2)\ntest_score_lr = round(accuracy_score(y_test, lr.predict(X_test)) * 100, 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### K-nearest neighbors with Hyperparameter Tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_score = []\ntest_score = []\nneighbors = range(1, 30)\n\nfor k in neighbors:\n    model = KNeighborsClassifier(n_neighbors = k)\n    model.fit(X_train_std, y_train)\n    train_score.append(accuracy_score(y_train, model.predict(X_train_std)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 8))\n\nplt.plot(neighbors, train_score, label=\"Train score\")\n# plt.plot(neighbors, test_score, label=\"Test score\")\nplt.xticks(np.arange(1, 31, 1))\nplt.xlabel(\"Number of Neighbors\")\nplt.ylabel(\"Model Score\")\nplt.legend()\n\nprint(f\"Maximum KNN score on the train data: {max(train_score)*100:.2f}%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors = 27)\nknn.fit(X_train_std, y_train)\n\nevaluation(knn, X_train_std, y_train, X_test, y_test, True)\nevaluation(knn, X_train_std, y_train, X_test, y_test, False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}