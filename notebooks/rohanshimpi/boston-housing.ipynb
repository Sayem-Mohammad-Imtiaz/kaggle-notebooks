{"cells":[{"cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"a8780a14-3954-4ec8-ba4b-e85eae399799","_uuid":"86671962ecb70e8cdc5832e0d3792aad9e72873d"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\n\nfrom sklearn.cross_validation import ShuffleSplit\nfrom sklearn.cross_validation import train_test_split\nimport sklearn.learning_curve as curves\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.cross_validation import ShuffleSplit\nfrom sklearn.metrics import make_scorer\nfrom sklearn.grid_search import GridSearchCV\n# Import supplementary visualizations code visuals.py\n#import visuals as vs\n\n# Pretty display for notebooks\n%matplotlib inline\nimport matplotlib.pyplot as pl\n# Any results you write to the current directory are saved as output.\n\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))","execution_count":null},{"cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"86f15c09-bcaa-4e2d-84f1-0f5e5ac305eb","_uuid":"f3039c42b5daf4fd80c2276e7b0c7b3978229699"},"outputs":[],"source":"# Load the Boston housing dataset\ndata = pd.read_csv('../input/housing.csv')\nprices = data['MEDV']\nfeatures = data.drop('MEDV', axis = 1)\n\n# Success\nprint('Boston housing dataset has {} data points with {} variables each.'.format(*data.shape))","execution_count":null},{"cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"a98169f2-da1f-4db4-b5fc-336e34153725","_uuid":"ee27f1b81aa302913c440d129059de2ba9b30318"},"outputs":[],"source":"minimum_price = np.min(prices)\nmaximum_price = np.max(prices)\nmean_price = np.mean(prices)\nmedian_price = np.median(prices)\nstd_price = np.std(prices)\n\n# Show the calculated statistics\nprint(\"Statistics for Boston housing dataset:\\n\")\nprint(\"Minimum price: ${:,.2f}\".format(minimum_price))\nprint(\"Maximum price: ${:,.2f}\".format(maximum_price))\nprint(\"Mean price: ${:,.2f}\".format(mean_price))\nprint(\"Median price ${:,.2f}\".format(median_price))\nprint(\"Standard deviation of prices: ${:,.2f}\".format(std_price))","execution_count":null},{"cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"8c1ca9b3-37aa-4673-bb8a-f790e937c4c6","_uuid":"85f77ae0175988316d3be91ae319af51f95ff746"},"outputs":[],"source":"from sklearn.metrics import r2_score\ndef performance_metric(y_true, y_predict):\n    \"\"\" Calculates and returns the performance score between \n        true and predicted values based on the metric chosen. \"\"\"\n    \n    # TODO: Calculate the performance score between 'y_true' and 'y_predict'\n    score = r2_score(y_true, y_predict)\n    \n    # Return the score\n    return score","execution_count":null},{"cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"9862552c-9ca4-49a6-89c5-8f5a19cb3722","_uuid":"0cdd49de345cae2262b6410a612f7d46a7c2b670"},"outputs":[],"source":"# Calculate the performance of this model\nscore = performance_metric([3, -0.5, 2, 7, 4.2], [2.5, 0.0, 2.1, 7.8, 5.3])\nprint(\"Model has a coefficient of determination, R^2, of {:.3f}.\".format(score))","execution_count":null},{"cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"0cb175cc-a698-4523-8fba-a93c7edc51e3","_uuid":"b6139e9e4f60c9976d631da3109a851e53836b2d"},"outputs":[],"source":"# TODO: Shuffle and split the data into training and testing subsets\nX_train, X_test, y_train, y_test = train_test_split(features, prices, random_state=0, test_size=0.2)","execution_count":null},{"cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"939b208b-bc40-421d-ac01-5a538e8e4b73","_uuid":"ba013d286ec793965b0914b46b1aa808488394cb"},"outputs":[],"source":"def ModelLearning(X, y):\n    \"\"\" Calculates the performance of several models with varying sizes of training data.\n        The learning and testing scores for each model are then plotted. \"\"\"\n    \n    # Create 10 cross-validation sets for training and testing\n    cv = ShuffleSplit(X.shape[0], n_iter = 10, test_size = 0.2, random_state = 0)\n\n    # Generate the training set sizes increasing by 50\n    train_sizes = np.rint(np.linspace(1, X.shape[0]*0.8 - 1, 9)).astype(int)\n\n    # Create the figure window\n    fig = pl.figure(figsize=(10,7))\n\n    # Create three different models based on max_depth\n    for k, depth in enumerate([1,3,6,10]):\n        \n        # Create a Decision tree regressor at max_depth = depth\n        regressor = DecisionTreeRegressor(max_depth = depth)\n\n        # Calculate the training and testing scores\n        sizes, train_scores, test_scores = curves.learning_curve(regressor, X, y, \\\n            cv = cv, train_sizes = train_sizes, scoring = 'r2')\n        \n        # Find the mean and standard deviation for smoothing\n        train_std = np.std(train_scores, axis = 1)\n        train_mean = np.mean(train_scores, axis = 1)\n        test_std = np.std(test_scores, axis = 1)\n        test_mean = np.mean(test_scores, axis = 1)\n\n        # Subplot the learning curve \n        ax = fig.add_subplot(2, 2, k+1)\n        ax.plot(sizes, train_mean, 'o-', color = 'r', label = 'Training Score')\n        ax.plot(sizes, test_mean, 'o-', color = 'g', label = 'Testing Score')\n        ax.fill_between(sizes, train_mean - train_std, \\\n            train_mean + train_std, alpha = 0.15, color = 'r')\n        ax.fill_between(sizes, test_mean - test_std, \\\n            test_mean + test_std, alpha = 0.15, color = 'g')\n        \n        # Labels\n        ax.set_title('max_depth = %s'%(depth))\n        ax.set_xlabel('Number of Training Points')\n        ax.set_ylabel('Score')\n        ax.set_xlim([0, X.shape[0]*0.8])\n        ax.set_ylim([-0.05, 1.05])\n    \n    # Visual aesthetics\n    ax.legend(bbox_to_anchor=(1.05, 2.05), loc='lower left', borderaxespad = 0.)\n    fig.suptitle('Decision Tree Regressor Learning Performances', fontsize = 16, y = 1.03)\n    fig.tight_layout()\n    fig.show()","execution_count":null},{"cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"5668a94a-1b37-47b5-b4d1-9be1ae55cfe3","_uuid":"bcf5e2d0648c91010d73e23aad7c8cabfae4dcab"},"outputs":[],"source":"def ModelComplexity(X, y):\n    \"\"\" Calculates the performance of the model as model complexity increases.\n        The learning and testing errors rates are then plotted. \"\"\"\n    \n    # Create 10 cross-validation sets for training and testing\n    cv = ShuffleSplit(X.shape[0], n_iter = 10, test_size = 0.2, random_state = 0)\n\n    # Vary the max_depth parameter from 1 to 10\n    max_depth = np.arange(1,11)\n\n    # Calculate the training and testing scores\n    train_scores, test_scores = curves.validation_curve(DecisionTreeRegressor(), X, y, \\\n        param_name = \"max_depth\", param_range = max_depth, cv = cv, scoring = 'r2')\n\n    # Find the mean and standard deviation for smoothing\n    train_mean = np.mean(train_scores, axis=1)\n    train_std = np.std(train_scores, axis=1)\n    test_mean = np.mean(test_scores, axis=1)\n    test_std = np.std(test_scores, axis=1)\n\n    # Plot the validation curve\n    pl.figure(figsize=(7, 5))\n    pl.title('Decision Tree Regressor Complexity Performance')\n    pl.plot(max_depth, train_mean, 'o-', color = 'r', label = 'Training Score')\n    pl.plot(max_depth, test_mean, 'o-', color = 'g', label = 'Validation Score')\n    pl.fill_between(max_depth, train_mean - train_std, \\\n        train_mean + train_std, alpha = 0.15, color = 'r')\n    pl.fill_between(max_depth, test_mean - test_std, \\\n        test_mean + test_std, alpha = 0.15, color = 'g')\n    \n    # Visual aesthetics\n    pl.legend(loc = 'lower right')\n    pl.xlabel('Maximum Depth')\n    pl.ylabel('Score')\n    pl.ylim([-0.05,1.05])\n    pl.show()\n","execution_count":null},{"cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"9bf0a255-5129-4e54-87b3-9f3f30d26f8f","_uuid":"65a4655808a3a8b90bc95802101ca16f87a9397c"},"outputs":[],"source":"def PredictTrials(X, y, fitter, data):\n    \"\"\" Performs trials of fitting and predicting data. \"\"\"\n\n    # Store the predicted prices\n    prices = []\n\n    for k in range(10):\n        # Split the data\n        X_train, X_test, y_train, y_test = train_test_split(X, y, \\\n            test_size = 0.2, random_state = k)\n        \n        # Fit the data\n        reg = fitter(X_train, y_train)\n        \n        # Make a prediction\n        pred = reg.predict([data[0]])[0]\n        prices.append(pred)\n        \n        # Result\n        print(\"Trial {}: ${:,.2f}\".format(k+1, pred))\n\n    # Display price range\n    print(\"\\nRange in prices: ${:,.2f}\".format(max(prices) - min(prices)))","execution_count":null},{"cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"d4b3b91a-8f6e-4b8c-8721-6538bb9209c2","_uuid":"4c9fc2d01a80d5561c2787b3a2ea7b3c0fd757f6"},"outputs":[],"source":"# Produce learning curves for varying training set sizes and maximum depths\nModelLearning(features, prices)","execution_count":null},{"cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"850be8c4-8965-4962-832d-92ba9ac3134a","_uuid":"c713033a8f365fc97615eabd136db8bba57052b9"},"outputs":[],"source":"ModelComplexity(X_train, y_train)","execution_count":null},{"cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"2e3a2c03-cd99-4420-8b66-bf62c5b1d24d","_uuid":"99807dc045af6abe38e1fb1d9b4accdaf70eb006"},"outputs":[],"source":"def fit_model(X, y):\n    \"\"\" Performs grid search over the 'max_depth' parameter for a \n        decision tree regressor trained on the input data [X, y]. \"\"\"\n    \n    # Create cross-validation sets from the training data\n    # sklearn version 0.18: ShuffleSplit(n_splits=10, test_size=0.1, train_size=None, random_state=None)\n    # sklearn versiin 0.17: ShuffleSplit(n, n_iter=10, test_size=0.1, train_size=None, random_state=None)\n    cv_sets = ShuffleSplit(X.shape[0], n_iter = 10, test_size = 0.20, random_state = 0)\n\n    # TODO: Create a decision tree regressor object\n    regressor = DecisionTreeRegressor()\n\n    # TODO: Create a dictionary for the parameter 'max_depth' with a range from 1 to 10\n    params = {'max_depth':np.arange(1,11)}\n\n    # TODO: Transform 'performance_metric' into a scoring function using 'make_scorer' \n    scoring_fnc = make_scorer(performance_metric, greater_is_better=True)\n\n    # TODO: Create the grid search cv object --> GridSearchCV()\n    # Make sure to include the right parameters in the object:\n    # (estimator, param_grid, scoring, cv) which have values 'regressor', 'params', 'scoring_fnc', and 'cv_sets' respectively.\n    grid = GridSearchCV(estimator=regressor, param_grid=params, scoring=scoring_fnc,cv=cv_sets)\n\n    # Fit the grid search object to the data to compute the optimal model\n    grid = grid.fit(X, y)\n\n    # Return the optimal model after fitting the data\n    return grid.best_estimator_","execution_count":null},{"cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"a4eac1f5-faba-4bf5-8f29-635b26a6f4fb","_uuid":"ceec87d7c30ef65f6adec279d5bf73316f366c12"},"outputs":[],"source":"# Fit the training data to the model using grid search\nreg = fit_model(X_train, y_train)\n\n# Produce the value for 'max_depth'\nprint(\"Parameter 'max_depth' is {} for the optimal model.\".format(reg.get_params()['max_depth']))","execution_count":null},{"cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"b51f0fb7-855d-4ba9-bdb7-7da507985cf0","_uuid":"026f16a361e52ca624b2f84db6d13418d38ba24c"},"outputs":[],"source":"","execution_count":null}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"},"language_info":{"nbconvert_exporter":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"name":"python","file_extension":".py","version":"3.6.1","mimetype":"text/x-python"}},"nbformat_minor":1,"nbformat":4}