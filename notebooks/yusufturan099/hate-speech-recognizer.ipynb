{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# PREPARING DATA","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# %% [code]\n# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Sat Jul 14 13:13:34 2018\n\n@author: kcy\n\"\"\"\nimport pandas as pd\nimport numpy as np\n\n#import twitter data\ndata = pd.read_csv(r\"/kaggle/input/twitter-sentiment-analysis-hatred-speech/train.csv\",encoding = \"latin1\")\n\ndata_drop = data[data.label==0].index                                    # dropping 0 labelled tweets to balance our dataset\ndata = data.drop(data_drop[0:22000]).reset_index().drop(\"index\",axis=1)\n\n\nimport re                                                                # Regular Expression Library\nimport nltk as nlp  \nnlp.download(\"stopwords\")                                                # Download stopwords (Irrelevant Words) to folder named \"Corpus\"\nfrom nltk.corpus import stopwords                                        # Import Stopwords we downloaded\n\nnlp.download('punkt')\n\ndescription_list = []                                                    # We will put all words' last version into this list.\nfor description in data.tweet:\n    description = re.sub(\"[^a-zA-Z]\",\" \",description)                    # Drop all characters excluded letters(a-z) and replace them whith \" \" (space)\n    description = description.lower()                                    # Turn all letters to lowercase\n    description = nlp.word_tokenize(description)                         # Advance version of Split Funtion\n    lemma = nlp.WordNetLemmatizer()                                      # Sort words by grouping inflected or variant forms of the same word.\n    description = [ lemma.lemmatize(word) for word in description]\n    description = \" \".join(description)\n    description_list.append(description)\n\n#bag of words\n\nfrom sklearn.feature_extraction.text import CountVectorizer             \nmax_features = 3000                                                     # We will choose most frequent 3000 words\n\ncount_vectorizer = CountVectorizer(max_features=max_features,stop_words = \"english\")\n\nsparce_matrix = count_vectorizer.fit_transform(description_list).toarray() # Sparce Matrix\n\nprint(\"en sik kullanilan {} kelimeler: {}\".format(max_features,count_vectorizer.get_feature_names()))\n\n# %%\ny = data.label                                                          # Hate or normal tweet classes\nx = pd.DataFrame(sparce_matrix)\n# train test split\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.1, random_state = 42)\n\nx_train = pd.DataFrame(x_train).reset_index().drop(\"index\",axis=1)\nx_test = pd.DataFrame(x_test).reset_index().drop(\"index\",axis=1)\ny__train = pd.DataFrame(y_train).reset_index().drop(\"index\",axis=1)\ny_test = pd.DataFrame(y_test).reset_index().drop(\"index\",axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV ,train_test_split\nRFC = RandomForestClassifier()\nparameters = { \"max_depth\" : [100,1000,2000], \"min_samples_split\" : [20,50,100]}\n#creating our grid to find best parameters\ntree_grid_search = GridSearchCV(RFC,param_grid=parameters,scoring=\"accuracy\",cv = 3)  \ntree_grid_search.fit(x_train,y_train) # adding data to grid search\nprint(\" best parameters :\", tree_grid_search.best_params_,\"\\n best score : \" ,tree_grid_search.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix\nRFC = RandomForestClassifier(max_depth=1000,min_samples_split=100)         # Use Best Parameters to train model\nRFC.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RFC_pred = RFC.predict(x_train)                                            # Predictions of train set\nRFC_pred_test = RFC.predict(x_test)                                        # Predictions of test set\nRFC_test_report = classification_report(y_test, RFC_pred_test)             # Test Report\nRFC_test_confusion = confusion_matrix(y_test, RFC_pred_test)               # COnfusion matrix of predictions of test set\n\nRFC_train_report = classification_report(y_train,RFC_pred)                 # Train Report\nRFC_train_confusion = confusion_matrix(y_train,RFC_pred)                   # COnfusion matrix of predictions of train set\nprint(\"RFC Confusion MAtrix :\\n  \",RFC_test_confusion)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Test Reports For RFC: \\n\",RFC_test_report)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import plot_precision_recall_curve,plot_roc_curve\nplot_precision_recall_curve(RFC,x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SAVE RFC","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\n# save the model to disk\nRVC_filename = 'finalized_RFC_model.sav'\npickle.dump(RFC, open(RVC_filename, 'wb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load the model from disk\nimport pickle\n\nRVC_filename = 'finalized_RFC_model.sav'\nfrom sklearn.metrics import classification_report, confusion_matrix\nloaded_RFC_model = pickle.load(open(RVC_filename, 'rb'))\nRVC = loaded_RFC_model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# TRAINING A SVC","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_svm_x, test_svm_x, train_svm_y, test_svm_y = train_test_split(x,y, test_size = 0.92, random_state = 42) # USE SMALL DATA FOR SVC!","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV ,train_test_split\nfrom sklearn.svm import SVC\nimport numpy as np\nsvc = SVC()\n#creating paramater dictionary\nparameters = {\"kernel\" : [\"linear\", \"rbf\", \"poly\"] , \"C\" : [0.1, 0.5, 1, 5], \"tol\" : [0.001, 0.1 ]}\n\ngrid_search = GridSearchCV(svc,param_grid=parameters,scoring=\"recall\",cv = 5) # creating our grid to find best parameters\ngrid_search.fit(train_svm_x,train_svm_y) # adding data to grid search\nprint(\" best parameters :\", grid_search.best_params_,\"\\n best score : \" ,grid_search.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nsvc = SVC(C=1, kernel=\"linear\",tol=0.1)                                  # Use Best Parameters to train model\nsvc.fit(x_train,y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svc_y_pred = svc.predict(x_train)                                        # Predictions of train set\nsvc_y_pred_test = svc.predict(x_test)                                    # Predictions of test set\nsvc_test_report = classification_report(y_test, svc_y_pred_test)         # Test Report\nsvc_test_confusion = confusion_matrix(y_test, svc_y_pred_test)           # COnfusion matrix of predictions of test set\n\nsvc_train_report = classification_report(y_train,svc_y_pred)             # Train Report\nsvc_train_confusion = confusion_matrix(y_train,svc_y_pred)               # COnfusion matrix of predictions of train set\nprint(\"SVC Confusion MAtrix \\n: \",svc_test_confusion)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Test Reports For SVC: \\n\",svc_test_report)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_precision_recall_curve(svc,x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SAVE SVC","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\n# save the model to disk\nSVC_filename = 'finalized_SVC_model.sav'\npickle.dump(svc, open(SVC_filename, 'wb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load the model from disk\nSVC_filename = 'finalized_SVC_model.sav'\nloaded_SVC_model = pickle.load(open(SVC_filename, 'rb'))\nsvc = loaded_SVC_model\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# TRAINING AN ARTIFICIAL NEURAL NETWORK","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluating the ANN\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom keras.models import Sequential # initialize neural network library\nfrom keras.layers import Dense # build our layers library\ndef build_classifier():\n    classifier = Sequential() # initialize neural network\n    classifier.add(Dense(units = 1500, kernel_initializer = 'uniform', activation = 'relu', input_dim = x_train.shape[1]))\n    classifier.add(Dense(units = 750, kernel_initializer = 'uniform', activation = 'relu'))\n    classifier.add(Dense(units = 250, kernel_initializer = 'uniform', activation = 'relu'))\n    classifier.add(Dense(units = 100, kernel_initializer = 'uniform', activation = 'relu'))\n    classifier.add(Dense(units = 25, kernel_initializer = 'uniform', activation = 'relu'))\n    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n    return classifier\nclassifier = KerasClassifier(build_fn = build_classifier, epochs = 15)\nclassifier.fit(x_train,y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ANN_pred = classifier.predict(x_train)                                  # Predictions of train set\nANN_pred_test = classifier.predict(x_test)                              # Predictions of test set\nclassifier.score(x_test,y_test)\n\nfrom sklearn.metrics import classification_report, confusion_matrix\nANN_test_report = classification_report(y_test, ANN_pred_test)          # Test Report\nANN_test_confusion = confusion_matrix(y_test, ANN_pred_test)            # COnfusion matrix of predictions of test set\n\nANN_train_report = classification_report(y_train,ANN_pred)              # Train Report\nANN_train_confusion = confusion_matrix(y_train,ANN_pred)                # COnfusion matrix of predictions of train set\n\nprint(\"ANN Confusion MAtrix: \\n \",ANN_test_confusion)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Test Report For ANN \\n\" ,ANN_test_report)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ENSEMBLE LEARNING","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### We will use 3 model's average answer to obtain maximum performance","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ensemble_test_predictions = ((pd.DataFrame(RFC_pred_test)+pd.DataFrame(svc_y_pred_test)+pd.DataFrame(ANN_pred_test))/3).round(0)  # taking average of all models' answers\nensemble_test_predictions.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ensemble_confsuion= confusion_matrix(y_test, ensemble_test_predictions)\n\nprint(\"Ensemble Model Confusion MAtrix: \\n \",ensemble_confsuion)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ensemble_test_report = classification_report(y_test, ensemble_test_predictions)\nprint(\"Test Report For Ensemble Learning \\n\" ,ensemble_test_report)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# COMPARISIONS OF 4 MODELS' PERFORMANCE","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n\nRandomFC = accuracy_score(y_test,RFC_pred_test)*100\nSVCC = accuracy_score(y_test,svc_y_pred_test)*100\nANN = accuracy_score(y_test,ANN_pred_test)*100\nEnsemble = accuracy_score(y_test,ensemble_test_predictions)*100\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nfig = sns.barplot([\"RFC\",\"SVC\",\"ANN\",\"ENSEMBLE\"],[RandomFC,SVCC,ANN,Ensemble])\nfig.set_title('Accurcy Scores of Models')\nfig.set(xlabel=\"Models\",ylabel=\"Acuuracy (%)\")\nfig.set(ylim=(80,100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RandomFC = precision_score(y_test,RFC_pred_test)*100\nSVCC = precision_score(y_test,svc_y_pred_test)*100\nANN = precision_score(y_test,ANN_pred_test)*100\nEnsemble = precision_score(y_test,ensemble_test_predictions)*100\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nfig = sns.barplot([\"RFC\",\"SVC\",\"ANN\",\"ENSEMBLE\"],[RandomFC,SVCC,ANN,Ensemble])\nfig.set_title('Precision Scores of Models')\nfig.set(xlabel=\"Models\",ylabel=\"Precision (%)\")\nfig.set(ylim=(80,100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RandomFC = recall_score(y_test,RFC_pred_test)*100\nSVCC = recall_score(y_test,svc_y_pred_test)*100\nANN = recall_score(y_test,ANN_pred_test)*100\nEnsemble = recall_score(y_test,ensemble_test_predictions)*100\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nfig = sns.barplot([\"RFC\",\"SVC\",\"ANN\",\"ENSEMBLE\"],[RandomFC,SVCC,ANN,Ensemble])\nfig.set_title('Recall Scores of Models')\nfig.set(xlabel=\"Models\",ylabel=\"Recall (%)\")\nfig.set(ylim=(60,100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\nRandomFC = f1_score(y_test,RFC_pred_test)*100\nSVCC = f1_score(y_test,svc_y_pred_test)*100\nANN = f1_score(y_test,ANN_pred_test)*100\nEnsemble = f1_score(y_test,ensemble_test_predictions)*100\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nfig = sns.barplot([\"RFC\",\"SVC\",\"ANN\",\"ENSEMBLE\"],[RandomFC,SVCC,ANN,Ensemble])\nfig.set_title('F1 Scores of Models')\nfig.set(xlabel=\"Models\",ylabel=\"F1 (%)\")\nfig.set(ylim=(70,90))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}