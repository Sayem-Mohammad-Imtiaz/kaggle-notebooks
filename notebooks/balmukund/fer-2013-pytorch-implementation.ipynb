{"cells":[{"metadata":{},"cell_type":"markdown","source":"This is the Pytorch implementation for fer-2013.\nSalient features inlcudes:-\n1. Albumentions data Augmentation\n2. One Cycle Policy\nAchived nearly 68.8 % Accuracy on test dataset","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!pip install albumentations","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import torch\nfrom torch.utils import data\nimport pandas as pd\nimport albumentations\nfrom albumentations import pytorch as AT\nfrom tqdm import tqdm\nimport math\nimport numpy as np\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\n%matplotlib inline \nimport torch.nn.functional as F\nimport torchvision.models as models\nfrom torch import nn\n#from torchsummary import summary\nfrom collections import OrderedDict\nimport torch.optim as optim","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"use_cuda = torch.cuda.is_available()\ndevice = torch.device(\"cuda\" if use_cuda else \"cpu\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv('../input/fer2013/fer2013.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Usage'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(df[df['Usage']=='Training']))\nprint(len(df[df['Usage']=='PublicTest']))\nprint(len(df[df['Usage']=='PrivateTest']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Converting pixes values to int**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['pixelss']=[[int(y) for y in x.split()] for x in df['pixels']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train=df[df['Usage']=='Training']\ndf_valid=df[df['Usage']=='PrivateTest']\ndf_test=df[df['Usage']=='PublicTest']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"z=np.array(df_train['pixelss'][0])\nzz=z.reshape(48,48)\nplt.imshow(zz, interpolation='nearest',cmap='gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"part={}\npart['train']= list(range(0,len(df_train)))\npart['valid']= list(range(0,len(df_valid)))\npart['test']= list(range(0,len(df_test)))\ntrain_labels=df_train['emotion'].tolist()\nvalid_labels=df_valid['emotion'].tolist()\ntest_labels=df_test['emotion'].tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Dataset(data.Dataset):\n  'Characterizes a dataset for PyTorch'\n  def __init__(self, dff, transforms):\n        'Initialization'\n        self.transforms = transforms\n        self.dff=dff\n\n  def __len__(self):\n        'Denotes the total number of samples'\n        return len(self.dff)\n\n  def __getitem__(self, index):\n        'Generates one sample of data'\n        # Select sample\n        #ID = self.list_IDs[index]\n\n        # Load data and get label\n        X = self.dff.iloc[index]['pixelss']\n        X = np.array(X).reshape(48,48,1)\n        y = self.dff.iloc[index]['emotion']\n\n        if self.transforms:\n          X = self.transforms(X)\n        \n        X = torch.cat((X,X,X),0)\n\n        return X, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {'batch_size': 64,'shuffle': True,'num_workers': 10}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class AlbumentationWrapper(object):\n    def __init__(self,split):\n        self.split=split\n        self.aug=albumentations.Compose([                                         \n    albumentations.Normalize((0.5), (0.5)),\n    AT.ToTensor()\n    ])\n\t\n        if self.split=='train':\n            self.aug=albumentations.Compose([\n                                             \n            #albumentations.Resize(48,48),\n    albumentations.HorizontalFlip(),\n    albumentations.Cutout(2,2,2,0.5),\n    albumentations.GaussNoise(),\n    #albumentations.ElasticTransform(),    \n    albumentations.Normalize((0.5), (0.5)),\n    AT.ToTensor()    \n    ])\n            \n    def __call__(self,img):\n        #img = np.array(img)\n        img = self.aug(image=img)['image']\n        return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transforms , validation_transforms=AlbumentationWrapper('train'), AlbumentationWrapper('test')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Loading datasets**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"training_set = Dataset(df_train, train_transforms)\ntraining_generator = data.DataLoader(training_set, **params)\n\nvalidation_set = Dataset(df_valid, validation_transforms)\nvalidation_generator = data.DataLoader(validation_set, **params)\n\ntest_set = Dataset(df_test, validation_transforms)\ntest_generator = data.DataLoader(test_set, **params)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**function for plotting the test accuracy and loss curve**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot(train_losses,train_acc,test_losses,test_acc, label):\n  fig, axs = plt.subplots(1,2,figsize=(20,8))\n  axs[0].plot(test_losses, label=label)\n  axs[0].set_title(\"Test Loss\")\n  axs[1].plot(test_acc, label=label)\n  axs[1].set_title(\"Test Accuracy\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Function for getting Learning rate at runtime**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Model Trainning Code**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(model, train_loader, optimizer,scheduler):\n  model.train()\n  pbar = tqdm(train_loader)\n  running_loss = 0.0\n  correct = 0\n  processed = 0\n  criterion = nn.CrossEntropyLoss()\n\n  for batch_idx, (data, target) in enumerate(pbar):\n    data, target = data.to(device), target.to(device)\n    optimizer.zero_grad()\n    y_pred = model(data)\n    loss = criterion(y_pred, target)\n    running_loss += loss.item()\n    train_loss.append(loss)\n    loss.backward()\n    optimizer.step()\n    scheduler.step()\n\n    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n    correct += pred.eq(target.view_as(pred)).sum().item()\n    processed += len(data)\n\n    #pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f} running_loss={running_loss} threshold={best_loss*(0.996)}')\n    train_acc.append(100*correct/processed)\n    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} le={get_lr(optimizer)} Accuracy={100*correct/processed:0.2f}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Model Test Code**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def test(model, test_loader):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    criterion = nn.CrossEntropyLoss()\n    with torch.no_grad():\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            test_loss += criterion(output, target).item()  # sum up batch loss\n            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n            new_target=target.view_as(pred)\n            correct += pred.eq(target.view_as(pred)).sum().item()\n\n    test_loss /= len(test_loader.dataset)\n    valid_loss.append(test_loss)\n\n    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))\n    \n    valid_acc.append(100. * correct / len(test_loader.dataset))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Custom Model**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self, dropout):\n        super(Net, self).__init__()\n        dropout_value = dropout\n        # Input Block\n        self.convblock1 = nn.Sequential(\n            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3, 3), padding=1, bias=False),\n            nn.ReLU(),\n            nn.BatchNorm2d(32),\n            # nn.Dropout(dropout_value)\n        ) \n\n        self.convblock2 = nn.Sequential(\n            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1, bias=False),\n            nn.ReLU(),\n            nn.BatchNorm2d(64),\n            # nn.Dropout(dropout_value)            \n        ) \n\n        # TRANSITION BLOCK 1\n        self.pool1 = nn.MaxPool2d(2, 2) # output_size = 24 RF=7\n        self.convblock3 = nn.Sequential(\n            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), padding=1, bias=False),\n            nn.ReLU(),\n            nn.BatchNorm2d(128),\n            # nn.Dropout(dropout_value)            \n        ) \n\n        self.convblock4 = nn.Sequential(\n            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3, 3), padding=1, bias=False),\n            nn.ReLU(),\n            nn.BatchNorm2d(256),\n        ) \n\n        self.convblock5 = nn.Sequential(\n            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=(1, 1), padding=1 , bias=False),\n            nn.ReLU(),\n            nn.BatchNorm2d(512),\n            # nn.Dropout(dropout_value)            \n        ) \n\n        # TRANSITION BLOCK 2\n        self.pool2 = nn.MaxPool2d(2, 2) # output_size = 12 RF=20\n\n        # CONVOLUTION BLOCK 2\n        self.convblock6 = nn.Sequential(\n            nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=(3, 3), padding=1, bias=False),\n            nn.ReLU(),\n            nn.BatchNorm2d(1024),\n            # nn.Dropout(dropout_value)            \n        ) \n\n        self.convblock7 = nn.Sequential(\n            nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=(3, 3), padding=1, bias=False),\n            nn.ReLU(),\n            nn.BatchNorm2d(1024),\n            # nn.Dropout(dropout_value)            \n        )\n\n        # TRANSITION BLOCK 3\n        self.pool3 = nn.MaxPool2d(2, 2) # output_size =6 RF=32\n\n        self.convblock8 = nn.Sequential(\n             nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=(3, 3), padding=1, bias=False),\n             nn.ReLU(),\n             nn.BatchNorm2d(512),\n             # nn.Dropout(dropout_value)            \n         ) \n\n        self.convblock9 = nn.Sequential(\n             nn.Conv2d(in_channels=512, out_channels=256, kernel_size=(3, 3), padding=0, bias=False),\n             nn.ReLU(),\n             nn.BatchNorm2d(256),\n             # nn.Dropout(dropout_value)            \n         )\n        # self.pool2 = nn.MaxPool2d(2, 2) # output_size = 2\n        self.gap = nn.Sequential(\n            nn.AvgPool2d(kernel_size=4)\n        ) \n        self.convblock10 = nn.Sequential(\n            nn.Conv2d(in_channels=256, out_channels=7, kernel_size=(1, 1), padding=0, bias=False)\n        ) \n\n    def forward(self, x):\n        x = self.convblock1(x)\n        x = self.convblock2(x)\n        x = self.pool1(x)\n        x = self.convblock3(x)        \n        x = self.convblock4(x)\n        x = self.convblock5(x)\n        x = self.pool2(x)\n        x = self.convblock6(x)\n        x = self.convblock7(x)\n        x = self.pool3(x)   \n        x = self.convblock8(x) \n        x = self.convblock9(x)    \n        x = self.gap(x)\n        x = self.convblock10(x)\n        x = x.view(-1, 7)\n        return F.log_softmax(x, dim=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=Net(1.0)\nmodel.to(device)\nepochs=32\noptimizer = optim.SGD(model.parameters(), lr=0.002, momentum=0.9, weight_decay=9e-4)\nscheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.02, steps_per_epoch=len(training_generator), pct_start=0.2, div_factor=10, cycle_momentum=False, epochs=epochs)\n\ninput_size=(3,48,48)\ntrain_acc = []\ntrain_loss = []\nvalid_acc = []\nvalid_loss = []\nfor epoch in range(epochs):\n    print(\"EPOCH: %s LR: %s \" % (epoch, get_lr(optimizer)))\n    train(model, training_generator, optimizer,scheduler)\n    test(model, validation_generator)\n    #scheduler.step()\nplot(train_loss,train_acc, valid_loss, valid_acc, 'Loss & Accuracy')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}