{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Approach \n* generally a person approach problem in their own specific way according to his previous experiences, So to be good at it   you should make your hands dirty with datasets,\n\n* what I have done firstly tried to look over data from relativey high top view.\n\n* Then Done feature selection and seen whether dataset was balanced or imbalanced. Generally it happened that medical         datasets are imbalanced.\n\n* Then selected a model and saw for some important things like whether missing values present, features are on same scale     or not, etc.\n\n* Now only two things remaining first fit data on model and evaluate model.\n\n* Its good to see confusion matrix since it gives a wider picture of the performance of model and you will find it intuitional.\n\n* Just see one time and post your notebook which would be (should be) better than this it will help you in posting things     in community.\n\n* \"upvote karo tabhi to bhai ki notebook chalegi\":p"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('whitegrid')\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/breast-cancer-wisconsin-data/data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['id','Unnamed: 32'],axis = 1,inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x = df['diagnosis'].unique(),y = df['diagnosis'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Distribution looks quite good ie. its a balanced dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()\ndf['diagnosis'] = encoder.fit_transform(df['diagnosis'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12,12))\nsns.heatmap(df.corr(),annot = True, cmap = 'coolwarm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df=df[df.corr()[df.corr()['diagnosis']>0.6].columns]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Our main training procedure \n* Machine learning is very easy just try and develop a kind of pattern in your mind about approaching tabular problems"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split,cross_val_score\nfrom sklearn.metrics import accuracy_score,confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier()\n\nnew_df.astype(float)\ny = new_df['diagnosis']\ndf = new_df.drop('diagnosis',axis = 1)\ndf2 = df.copy()\n\nX_train,X_test,y_train,y_test = train_test_split(df,y,test_size = 0.3,random_state = 42)\nmodel.fit(X_train,y_train)\npred_t = model.predict(X_train)\ntrain_score = accuracy_score(y_train,pred_t)\npred = model.predict(X_test)\nval_score = accuracy_score(y_test,pred)\nprint('train accuracy is {}'.format(train_score))\nprint('val accuracy is {}'.format(val_score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = cross_val_score(model,df2,y,scoring='accuracy',cv = 8)\nprint(score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"By seeing to confusion matrix we can be more sure that how our model is working and on what side our model should dominate its prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_test,pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"* Above results seems quite good but as we know by boosting techniques our accuracy generally increases lets try:)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\n\nmodel = XGBClassifier(n_estimator = 20)\nmodel.fit(X_train,y_train)\npred = model.predict(X_test)\nprint(confusion_matrix(y_test,pred))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}