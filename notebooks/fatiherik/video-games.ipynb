{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        df = pd.read_csv(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import cross_val_score, cross_val_predict\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\nfrom sklearn.preprocessing import LabelEncoder","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"look at first columns, shape,info and describe","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Year'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Platform'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Genre'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Publisher'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Publisher'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Year'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df['Year'].median())\nprint(df['Year'].mean())\nprint(df['Year'].mode())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Year']=df['Year'].fillna(df['Year'].median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Year'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Year'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Publisher']=df['Publisher'].replace(np.nan, df['Publisher'].mode()[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Publisher'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_labels = ['Platform', 'Genre', 'Publisher']\nnumerical_lables = ['Global_Sales']\nenc = LabelEncoder()\nencoded_df = pd.DataFrame(columns=['Platform', 'Genre', 'Publisher', 'Global_Sales'])\n\nfor label in categorical_labels:\n    temp_column = df[label]\n\n    encoded_temp_col = enc.fit_transform(temp_column)\n\n    encoded_df[label] = encoded_temp_col\n\nfor label in numerical_lables:\n    encoded_df[label] = df[label].values\n\nencoded_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoded_df['Platform'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoded_df['Publisher'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoded_df['Genre'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Linear regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#from sklearn import preprocessing\n#norm_encoded = preprocessing.normalize(encoded_df)\n#norm_encoded\n\n# bu yontem kullanilabilir mi? kullanilabilirse bagimli degiskeni de normalize edecek miyiz? cunku asagida standartscaler yaparken \n#global sales sutununu scaler etmemis.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = encoded_df.iloc[:, 0:3]\ny = encoded_df.iloc[:,3:]\n\nscalar = StandardScaler()\nx = scalar.fit_transform(x)\nx\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import statsmodels.api as sm\nxm=sm.add_constant(x)\nmodel = sm.OLS(y,xm).fit()\nprint_model = model.summary()\nprint(print_model)\n#print(xm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=42)\nlr = LinearRegression()\nlr.fit(x_train,y_train)\ny_predict = lr.predict(x_test)\n\nprint(lr.coef_)\nprint(lr.intercept_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(lr.predict([[26,10,359]]))\nprint(lr.predict([[1.21567658,  1.3482215 ,  0.3714072 ]]))\n# predict yaparken scaler edilmis degerleri mi yazacagiz? scaler edilmemis degerleri mi?","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"model evaluation for testing set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"mae=mean_absolute_error(y_predict, y_test)\nmse=mean_squared_error(y_predict, y_test)\nrmse=np.sqrt(mse)\nr2=r2_score(y_test,y_predict)\n\nprint('mae is  {}'.format(mae))\nprint('mse is  {}'.format(mse))\nprint('rmse is  {}'.format(rmse))\nprint('r2 is  {}'.format(r2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import matplotlib.pyplot as plt\nplt.scatter(y_test,y_predict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"linear_reg = LinearRegression()\ny_pred = cross_val_predict(linear_reg, x_test, y_test, cv=10)\n\nmae=mean_absolute_error(y_pred, y_test)\nmse=mean_squared_error(y_pred, y_test)\nrmse=np.sqrt(mse)\nr2=r2_score(y_test,y_pred)\n\nprint('mae is  {}'.format(mae))\nprint('mse is  {}'.format(mse))\nprint('rmse is  {}'.format(rmse))\nprint('r2 is  {}'.format(r2))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Polynomial Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import PolynomialFeatures\n\nfor i in range(1,6):\n\n    poly_features = PolynomialFeatures(degree=i)\n    \n    x_train_poly = poly_features.fit_transform(x_train)\n    x_test_poly = poly_features.fit_transform(x_test)\n\n    poly_model = LinearRegression()\n    poly_model.fit(x_train_poly, y_train)\n    \n    #coef and intercept\n    #print('for degree '+str(i)+':'+'coef: ' +str(poly_model.coef_)+' intercept: '+str(poly_model.intercept_))\n\n    # RMSE and r2 score for train data\n    y_train_pred = poly_model.predict(x_train_poly)\n    rmse_train = np.sqrt(mean_squared_error(y_train,y_train_pred))\n    r2_train = r2_score(y_train, y_train_pred)\n    print('train data for degree '+str(i)+' rmse_train:' +str(rmse_train)+' r2_train: '+str(r2_train))\n\n    # RMSE and r2 score for test data\n    y_test_pred = poly_model.predict(x_test_poly)\n    rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n    r2_test = r2_score(y_test, y_test_pred)\n    print('test data for degree '+str(i)+' rmse_train:' +str(rmse_test)+' r2_train: '+str(r2_test)+'\\n')\n    \n    \n    plt.plot(y_test,y_test_pred, color= \"green\",label = \"poly\")\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}