{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# loading dataset\nwine = pd.read_csv(\"../input/wine-quality/winequalityN.csv\")\nprint(wine.shape)\nprint(wine.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking for duplicate rows\n# getting duplicated rows except the first one based on all columns\nwine_duplicates = wine[wine.duplicated()]\nprint(wine_duplicates)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dropping duplicates\nwine.drop_duplicates(inplace=True)\nwine.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking for missing values\nwine.isnull().head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dropping rows with missing values\nwine.dropna(axis=0, inplace=True)\nwine.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking the datatypes\nwine.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# summary stats of numrical columns\nwine.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# loading packages\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating a box plot of type and quality\nsns.set_style(\"whitegrid\")\nsns.boxplot(x = 'type', y = 'quality', data = wine)\nplt.xlabel('type')\nplt.ylabel('quality')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# histogram plot numerical columns\ndef plot_histogram(df, cols, bins=4):\n    for col in cols:\n        fig = plt.figure(figsize=(8,8))\n        ax= fig.gca()\n        wine[col].plot.hist(ax = ax, bins = bins, color = 'blue')\n        ax.set_title('Histogram of ' + col)\n        ax.set_xlabel(col)\n        ax.set_ylabel('Number')\n        plt.show()\nnum_cols = ['fixed acidity','volatile acidity','citric acid','residual sugar', \n            'chlorides','free sulfur dioxide', 'total sulfur dioxide', 'density',\n            'pH', 'sulphates', 'alcohol']\nplot_histogram(wine, num_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# histogram of numerical columns\ndef hist_plot(vals, lab):\n    ## Distribution plot of values    \n    sns.displot(vals)\n    plt.title('Histogram of ' + lab)\n    plt.xlabel('Value')\n    plt.ylabel('Density')\n    \n\nfor col in num_cols:\n    hist_plot(wine[col], col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# scaling the numerical features\n# min-max scale the data between 0 and 1\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nwine[num_cols] = scaler.fit_transform(wine[num_cols])\nwine[num_cols].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wine.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# histogram of scaled numerical columns\ndef hist_plot(vals, lab):\n    ## Distribution plot of values    \n    sns.displot(vals)\n    plt.title('Histogram of scaled ' + lab)\n    plt.xlabel('Value')\n    plt.ylabel('Density')\n    \n\nfor col in num_cols:\n    hist_plot(wine[col], col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# transforming the numerical columns by using logarithm\nfor col in num_cols:\n    wine[col] = np.log1p(wine[col])\n# visualizing the distribution of log numerical columns\n    hist_plot(wine[col], col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wine.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\nx = wine.loc[:, num_cols]\nx.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create cluster feature\nkmeans = KMeans(n_clusters=6)\nx[\"Cluster\"] = kmeans.fit_predict(x)\nx[\"Cluster\"] = x[\"Cluster\"].astype(\"category\")\n\nx.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# boxplot with wine quality\nx[\"quality\"] = wine[\"quality\"]\nsns.catplot(x=\"quality\", y=\"Cluster\", data=x, kind=\"boxen\", height=6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.decomposition import PCA\n\n# Create principal components\npca = PCA()\nX_pca = pca.fit_transform(x[num_cols])\n\n# Convert to dataframe\ncomponent_names = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\nX_pca = pd.DataFrame(X_pca, columns=component_names)\n\nX_pca.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loadings = pd.DataFrame(\n    pca.components_.T,  # transpose the matrix of loadings\n    columns=component_names,  # so the columns are the principal components\n    index=x[num_cols].columns,  # and the rows are the original features\n)\nloadings","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting y\nXdf = wine.copy()\ny = Xdf.pop('quality')\n# mutual info for components\nfrom sklearn.feature_selection import mutual_info_regression\ndef make_mi_scores(X, y, discrete_features):\n    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features)\n    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores\nmi_scores = make_mi_scores(X_pca, y, discrete_features=False)\nmi_scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# attaching cluster to the wine data frame\nwine['Cluster'] = x['Cluster']\nnum_cols = ['fixed acidity','volatile acidity','citric acid','residual sugar', \n            'chlorides','free sulfur dioxide', 'total sulfur dioxide', 'density',\n            'pH', 'sulphates', 'alcohol', 'Cluster']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mutual information for the columns\nmi_scores = make_mi_scores(wine[num_cols], y, discrete_features=False)\nmi_scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating a scatter plot\ndef scatter_plot(df, cols, col_y):\n    for col in cols:\n        fig = plt.figure(figsize = (7,6))\n        ax = fig.gca()\n        wine.plot.scatter(x = col, y = col_y, ax = ax)\n        ax.set_title('Scatter plot of ' + col_y + ' vs ' + col)\n        ax.set_xlabel(col)\n        ax.set_ylabel(col_y)\n        plt.show()\nscatter_plot(wine, num_cols, 'quality')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating a correlation matrix\n# get correlations\nwine_corr = wine.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wine_corr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10, 8))\n# mask\nmask = np.triu(np.ones_like(wine_corr, dtype=np.bool))\n# adjust mask and df\nmask = mask[1:, :-1]\ncorr = wine_corr.iloc[1:,:-1].copy()\n# plot heatmap\nsns.heatmap(corr, mask=mask, annot=True, fmt=\".2f\", cmap='Blues',\n           vmin=-1, vmax=1, cbar_kws={\"shrink\": .8})\n# yticks\nplt.yticks(rotation=0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking for skewness of the label(quality)\n# histogram of sale price\ndef hist_plot(vals, lab):\n    ## Distribution plot of values\n    sns.displot(vals)\n    plt.title('Histogram of ' + lab)\n    plt.xlabel('Value')\n    plt.ylabel('Density')\n    \n#labels = np.array(auto_prices['price'])\nhist_plot(wine['quality'], 'Quality')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Linear regression\n# loading packages\nfrom sklearn import preprocessing\nimport sklearn.model_selection as ms\nfrom sklearn import linear_model\nimport sklearn.metrics as sklm\nimport numpy.random as nr\nimport scipy.stats as ss\nimport math","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# preparing the model matrix for train dataset\n# creating dummy variables from categorical variables\n##  encode the strings to numeric categories\nenc = preprocessing.LabelEncoder()\nenc.fit(wine['type'])\nenc_cat_feature = enc.transform(wine['type'])\n##  apply one hot encoding\nohe = preprocessing.OneHotEncoder()\nencoded = ohe.fit(enc_cat_feature.reshape(-1,1))\nFeatures = encoded.transform(enc_cat_feature.reshape(-1,1)).toarray()\nprint(Features.shape)\nFeatures[:2, :]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# adding numerical variables for the train dataset\nnum_features = wine[['fixed acidity','volatile acidity','citric acid','residual sugar', \n            'chlorides','free sulfur dioxide', 'total sulfur dioxide', 'density',\n             'sulphates', 'alcohol', 'Cluster']]\nFeatures = np.concatenate([Features, np.array(num_features)], axis = 1)\nprint(Features.shape)\nFeatures[:2,:]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating a numpy array of label values\nlabel = np.array(wine['quality'])\nlabel","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# splitting the dataset\n## Randomly sample cases to create independent training and test data\nnr.seed(9988)\nindx = range(Features.shape[0])\nindx = ms.train_test_split(indx, test_size = 200)\nx_train = Features[indx[0],:]\ny_train = np.ravel(label[indx[0]])\nx_test = Features[indx[1],:]\ny_test = np.ravel(label[indx[1]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# constructing the linear regression model\n## define and fit the linear regression model\nlin_mod = linear_model.LinearRegression(fit_intercept = False)\nlin_mod.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(lin_mod.intercept_)\nprint(lin_mod.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test scores\ny_score = lin_mod.predict(x_test)\ny_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluating the model\ndef print_metrics(y_true, y_predicted):\n    ## First compute R^2 \n    r2 = sklm.r2_score(y_true, y_predicted)\n  \n    \n    ## Print the usual metrics and the R^2 values\n    print('Mean Square Error      = ' + str(sklm.mean_squared_error(y_true, y_predicted)))\n    print('Root Mean Square Error = ' + str(math.sqrt(sklm.mean_squared_error(y_true, y_predicted))))\n    print('Mean Absolute Error    = ' + str(sklm.mean_absolute_error(y_true, y_predicted)))\n    print('Median Absolute Error  = ' + str(sklm.median_absolute_error(y_true, y_predicted)))\n    print('R^2                    = ' + str(r2))\n\n   \nprint_metrics(y_test, y_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def hist_resids(y_test, y_score):\n    ## first compute vector of residuals. \n    resids = np.subtract(y_test.reshape(-1,1), y_score.reshape(-1,1))\n    ## now make the residual plots\n    sns.distplot(resids)\n    plt.title('Histogram of residuals')\n    plt.xlabel('Residual value')\n    plt.ylabel('count')\n    \nhist_resids(y_test, y_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# residual plots vs predicted values\ndef resid_plot(y_test, y_score):\n    ## first compute vector of residuals. \n    resids = np.subtract(y_test.reshape(-1,1), y_score.reshape(-1,1))\n    ## now make the residual plots\n    sns.regplot(x=y_score, y=resids, fit_reg=False)\n    plt.title('Residuals vs. predicted values')\n    plt.xlabel('Predicted values')\n    plt.ylabel('Residual')\n\nresid_plot(y_test, y_score) ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}