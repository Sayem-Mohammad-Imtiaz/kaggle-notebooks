{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom sklearn.decomposition import PCA\nfrom sklearn import datasets\nfrom sklearn.preprocessing import scale\nfrom pyclustertend import hopkins ## the hopkins test\n\n\nfrom mpl_toolkits.mplot3d import Axes3D\nimport matplotlib.pyplot as plt\n\n\n\nheart_df = pd.read_csv(\"../input/heart.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this Kernel, I would like to show you an exemple of cluster tendency test. The aim of cluster tendency is to test if clustering is relevant in our dataset.\nA well know test for cluster tendency is the Hopkins Test. It check if observations are randomly distributed in the space or not.\n\nFirst, let's quickly look at our data table."},{"metadata":{"trusted":true},"cell_type":"code","source":"X = heart_df[heart_df.columns[~heart_df.columns.isin([\"target\"])]].values\ny = heart_df[heart_df.columns[heart_df.columns.isin([\"target\"])]].values.flatten()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hopkins(X, X.shape[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"the null hypothesis (no meaningfull cluster) happens when the hopkins test is around 0.5 and the hopkins test tends to 0 when meaningful cluster exists in the space. Usually, we can believe in the existence of clusters when the hopkins score is bellow 0.25.\n\nHere the value of the hopkins test is quite high but one could think there is cluster in our subspace. **BUT** the hopkins test is highly influenced by outliers, let's try once again with normalised data. "},{"metadata":{"trusted":true},"cell_type":"code","source":"hopkins(scale(X),X.shape[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here, we can see that the hopkins score is much more higher with normalised data."},{"metadata":{},"cell_type":"markdown","source":"### Confirmation : \n\nWe have made some hypothesis during this test : \n- there is no cluster in our dataset. \n\nNow, let's check if they are true using a PCA. "},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(n_components = 2)\n\nX_pca = pca.fit_transform(scale(X))\n\nlabels = heart_df.target.values\n\ncdict = {0 : \"green\", 1 : \"red\"}\nlabl = {0: \"healthy\", 1 : \"sick\"}\nmarker = {0 : \"o\", 1: \"*\"}\nalpha = {0: 0.5, 1: 0.5}\n\n#fig = plt.figure(figsize=(10, 10))\n#ax = fig.add_subplot(111, projection='3d')\n\nfig = plt.figure(figsize=(10, 10))\n\n\nfor l in np.unique(labels):\n    ix = np.where(labels == l)\n    plt.scatter(X_pca[ix,0],X_pca[ix,1], c = cdict[l], s=40, label = labl[l], marker = marker[l], alpha = alpha[l])\n\n#plt.scatter(X_pca[:,0],X_pca[:,1]);\nplt.xlabel(\"first principal component\")\nplt.xlabel(\"second principal component\")\nplt.title(\"PCA  : heart diseases\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see, our hypothesis seems true."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}