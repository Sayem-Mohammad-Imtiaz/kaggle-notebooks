{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Hi and welcome to this guide where you will see how easy classify Lego minifigures from  [LEGO Minifigures Classification](https://www.kaggle.com/ihelon/lego-minifigures-classification) dataset."},{"metadata":{},"cell_type":"markdown","source":"The task is that we send a picture to the neural network and the neural network returns the class of minifigures. So, if we send a picture of Ron Weasley  minifigure, then the neural network will return \"class 19\" and the name \"RON WEASLEY\"."},{"metadata":{},"cell_type":"markdown","source":"Here we will use pretrained neural network [DenseNet121](https://keras.io/api/applications/densenet/) from Keras, because it will done well with this task and I have not reason to train my own neural network if we can use existing models. We will also use [Dence](https://medium.com/datathings/dense-layers-explained-in-a-simple-way-62fe1db0ed75) and [Dropout](https://medium.com/analytics-vidhya/a-simple-introduction-to-dropout-regularization-with-code-5279489dda1e) layers, so if you don't know what is it just click and read. "},{"metadata":{},"cell_type":"markdown","source":"*Thank you for reading my works ‚ô•, you can also see my other guide:*\n\n-- [Guide for beginners. Breast cancer classification.](https://www.kaggle.com/izabellaleroy/guide-for-beginners-breast-cancer-classification)\n\n*Please, also like  the [LEGO Minifigures Classification](https://www.kaggle.com/ihelon/lego-minifigures-classification) dataset from [ihelon](https://www.kaggle.com/ihelon), because this is  very painstaking work to create the dataset.*"},{"metadata":{},"cell_type":"markdown","source":"**Let's go!**\n\nJust import all we will need."},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport cv2\nimport tensorflow as tf \nimport pandas as pd\nimport numpy as np\nfrom tensorflow.keras.models import  Model\nfrom tensorflow.keras.layers import Dropout, Dense\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.models import load_model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First of all let's look what we have in dataset.\n\nThere are pictures of Lego minifigures from different universes (Star Wars, Harry Potter, etc.) in our dataset. Each picture is 512x512 picsels. Figures are photographed from different angles and in different locations.\n\n**The code below is just to see a few images.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"images = [[],[],[]]\nindex = ['001', '002', '003']\n\nfor i in range(3):\n    images[i].append(mpimg.imread('../input/lego-minifigures-classification/star-wars/0001/' + index[i] + '.jpg'))\n    images[i].append(mpimg.imread('../input/lego-minifigures-classification/marvel/0001/' + index[i] + '.jpg'))\n    images[i].append(mpimg.imread('../input/lego-minifigures-classification/harry-potter/0001/' + index[i] + '.jpg'))\n\nfig, axs = plt.subplots(3,3, figsize=(18,18))\n\nfor i in range(3):\n    for j in range(3):\n        axs[i, j].imshow(images[i][j])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Download data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/lego-minifigures-classification/index.csv')\ndata","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Above we see that we already have labels for train and validation, so lets just split it."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set = data[data[\"train-valid\"] == 'train']\nvalidation_set = data[data[\"train-valid\"] == 'valid']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Let's already create the model.**\n\nDenceNet ([Densely Connected Convolutional Networks](https://arxiv.org/abs/1608.06993)) was created by Gao Huang, Zhuang Liu, Laurens van der Maaten, Kilian Q. Weinberger. This model has been trained on a very large amount of data and is able to distinguish many different objects.\n\nAs I already said, we will take a pre-trained DenceNet model, but change the last layer in it and also add our own output layer, so this model will classify what we need, in our case, Lego minifigures. \n\nSee the picture below:\n\n<img src=\"https://i.imgur.com/ed9PLCI.png\" width=\"500\">"},{"metadata":{"trusted":true},"cell_type":"code","source":"# take pretrained DenseNet\nbase_model = tf.keras.applications.DenseNet121()\n# Create new Dropout layer and sent there penultimate output from DenseNet \nmy_layer = Dropout(0.5)(base_model.layers[-2].output)\n# Count the nuber of unique classes in dataset\nnumber_of_classes = len(data['class_id'].unique())\n# Create new Dense layer and sent there output from Dropout layer\n# Note that in this Dense layer is \"number_of_classes\" neuron because we have \"number_of_classes\" classes \nmy_outputs = Dense(number_of_classes, activation=\"softmax\")(my_layer)\nmodel = Model(base_model.input, my_outputs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Note:* last Dense layer has \"number_of_classes\" neuron because we have \"number_of_classes\" classes, so the output from our model will be a vector with \"number_of_classes\" float numbers and the answer will be the index of the max element."},{"metadata":{},"cell_type":"markdown","source":"Now we must compile our model."},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='sparse_categorical_crossentropy',\n              optimizer=Adam(0.0001),\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The neural network accepts an image as input in the form of pixel values, so the code below simply transforms the images from the training and validation set into arrays of numbers and saves them. "},{"metadata":{"trusted":true},"cell_type":"code","source":"\nX_train = np.zeros((train_set.shape[0], 512, 512, 3))\n\nfor i in range(train_set.shape[0]):\n    image = cv2.imread('../input/lego-minifigures-classification/' + train_set[\"path\"].values[i])\n    image = cv2.resize(image, dsize=(512,512)) # resize in case if image was not 512x512 pixels\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    X_train[i] = image/255\n\nY_train = np.array(train_set[\"class_id\"])-1\n\nX_valid = np.zeros((validation_set.shape[0], 512, 512, 3))\n\nfor i in range(validation_set.shape[0]):\n    image = cv2.imread('../input/lego-minifigures-classification/' + validation_set[\"path\"].values[i])\n    image = cv2.resize(image, dsize=(512,512))\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    X_valid[i] = image/255\n\nY_valid = np.array(validation_set[\"class_id\"])-1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is lables in train set.\n\n*Note:* Labels must be from 0 to n, but in our dataset labels from 1 to n, so above wen we save Y_valid and Y_train we subtract 1. \nI draw your attention to this, because in the future when we receive the answer class we will have to add 1 for the right answer."},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before training the model, *let's create the checkpoint* for the model. It's mean that we will save only the best model. We do this because there may be a situation when, for example, we train the model for 50 epochs, but the best result was at 43 epochs, so if we do not save it, we will lose the best result and get only the final result from 50 epochs.\n\nThe model will be saved at Kaggle's work directory \"./kaggle/working\". We will name our best model just \"model.h5\". We will choose the best model by value accuracy score (monitor=\"val_accuracy\")."},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = ModelCheckpoint(filepath='model.h5', monitor=\"val_accuracy\", save_best_only=True, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's train our model!\n\n*Note: the function fit() has a parameter \"callbacks\" where we will pass our checkpoint.* "},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(\n    X_train, \n    Y_train, \n    epochs=50, \n    validation_data=(X_valid, Y_valid), \n    shuffle=True, \n    batch_size=4, \n    callbacks=checkpoint\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Great! Now we have a trained model. But the variable \"model\" contains not the best weights. But that weights for the model which trained for 50 epoch. So let's just download our saved, the best model from \"./kaggle/working/model.h5\"."},{"metadata":{"trusted":true},"cell_type":"code","source":"model = load_model(\"model.h5\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"That's all for now, below you can download and test your own picture or some pictures from the dataset!\nWrite comments or ask questions if something is not clear, also click like üòç if you liked it and read my other works!"},{"metadata":{"trusted":true},"cell_type":"code","source":"image = cv2.imread('../input/lego-minifigures-classification/harry-potter/0002/009.jpg') # read the image \nimage = cv2.resize(image, dsize=(512,512)) # resize in case if image was not 512x512 pixels\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)/255 # transform picture from BRG to the RGB format\n\nplt.imshow(image) # print image \n\nimage = np.reshape(image, (1, 512, 512, 3)) # resize to the needed for model shape - 1 picture 512 height 512 width 3 chanel(RGB)\n\nans = model.predict(image).argmax() # find index of max element\nans = ans+1 # don't forget to add 1 :) \nmetadata = pd.read_csv('../input/lego-minifigures-classification/metadata.csv') # download meta data, there are store real \n                                                                                #names of minifigures\n\nminifigure = metadata[\"minifigure_name\"][metadata[\"class_id\"] == ans].iloc[0] # find the name that matches the predicted class\nprint(f\"Class:\\t{ans}\\tMinifigure:\\t{minifigure}\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}