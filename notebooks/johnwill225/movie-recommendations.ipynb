{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Greetings !!!\n\nThis is the continuation of my first kernel [Avengers Vs DarkKnight Recommendation](https://www.kaggle.com/johnwill225/avengers-vs-darkknight-recommendations) where we have implemented Content based filtering. In this kernel We'll see about Collaborative Filtering, this approach builds a model from a userâ€™s past behaviors as well as similar decisions made by other users. This model is then used to predict items (or ratings for items) that the user may have an interest in.\n\nThere are two types of Collaborative Filtering,\n1. User based filtering\n2. Item based filtering"},{"metadata":{},"cell_type":"markdown","source":"#### User based filtering\nThis approach is often harder to scale because of the user count increase rapidly and recommendation for the new user is bit harder.\n\n#### Item based filtering\nThis approach is mostly preferred since the movie don't change much. We can rerun this model once a week unlike User based where we have to frequently run the model.\n\nIn this kernel, We look at the implementation of Item based filtering"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom scipy.sparse import csr_matrix\nfrom sklearn.neighbors import NearestNeighbors\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"movies = pd.read_csv(\"../input/movie-lens-small-latest-dataset/movies.csv\")\nratings = pd.read_csv(\"../input/movie-lens-small-latest-dataset/ratings.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ratings.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ratings dataset has \n* userId - unique for each user\n* movieId - using this feature ,we take the title of the movie from movies dataset\n* rating - Ratings given by each user to all the movies using this we are going to predict the top 10 similar movies"},{"metadata":{"trusted":true},"cell_type":"code","source":"movies.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Movie dataset has \n* movieId - once the recommendation is done, we get list of all similar movieId and get the title for each movie from this dataset. \n* genres -  which is not required for this filtering approach"},{"metadata":{"trusted":true},"cell_type":"code","source":"final_dataset = ratings.pivot(index='movieId',columns='userId',values='rating')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_dataset.fillna(0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In a real world, ratings are very sparse and data points are mostly collected from very popular movies and highly engaged users. So we will reduce the noise by adding some filters and qualify the movies for the final dataset.\n* To qualify a movie, minimum 10 users should have voted a movie.\n* To qualify a user, minimum 50 movies should have voted by the user.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"no_user_voted = ratings.groupby('movieId')['rating'].agg('count')\nno_movies_voted = ratings.groupby('userId')['rating'].agg('count')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f,ax = plt.subplots(1,1,figsize=(16,4))\n# ratings['rating'].plot(kind='hist')\nplt.scatter(no_user_voted.index,no_user_voted,color='mediumseagreen')\nplt.axhline(y=10,color='r')\nplt.xlabel('MovieId')\nplt.ylabel('No. of users voted')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_dataset = final_dataset.loc[no_user_voted[no_user_voted > 10].index,:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f,ax = plt.subplots(1,1,figsize=(16,4))\nplt.scatter(no_movies_voted.index,no_movies_voted,color='mediumseagreen')\nplt.axhline(y=50,color='r')\nplt.xlabel('UserId')\nplt.ylabel('No. of votes by user')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_dataset.loc[:,no_movies_voted[no_movies_voted > 50].index]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our final_dataset has dimensions of **2121 * 378** where most of the values are sparse. I took only small dataset but for\noriginal large dataset of movie lens which has more than **100000** features, this will sure hang our system when this has \nfeed to model. To reduce the sparsity we use csr_matric scipy lib. I'll give an example how it works"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample = np.array([[0,0,3,0,0],[4,0,0,0,2],[0,0,0,0,1]])\nsparsity = 1.0 - ( np.count_nonzero(sample) / float(sample.size) )\nprint(sparsity)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"csr_sample = csr_matrix(sample)\nprint(csr_sample)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* As you can see there is no sparse value in the csr_sample and values are assigned as rows and column index. for the 0th row and 2nd column , value is 3 . Look at the original dataset where the values at the right place. This is how it works using todense method you can take it back to original dataset.\n* Most of the sklearn works with sparse matrix. surely this will improve our performance"},{"metadata":{"trusted":true},"cell_type":"code","source":"csr_data = csr_matrix(final_dataset.values)\nfinal_dataset.reset_index(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We use cosine distance metric which is very fast and preferable than pearson coefficient. Please don't use euclidean distance which will not work when the values are equidistant."},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=20, n_jobs=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn.fit(csr_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_movie_recommendation(movie_name):\n    n_movies_to_reccomend = 10\n    movie_list = movies[movies['title'].str.contains(movie_name)]  \n    if len(movie_list):        \n        movie_idx= movie_list.iloc[0]['movieId']\n        movie_idx = final_dataset[final_dataset['movieId'] == movie_idx].index[0]\n        \n        distances , indices = knn.kneighbors(csr_data[movie_idx],n_neighbors=n_movies_to_reccomend+1)    \n        rec_movie_indices = sorted(list(zip(indices.squeeze().tolist(),distances.squeeze().tolist())),\\\n                               key=lambda x: x[1])[:0:-1]\n        \n        recommend_frame = []\n        \n        for val in rec_movie_indices:\n            movie_idx = final_dataset.iloc[val[0]]['movieId']\n            idx = movies[movies['movieId'] == movie_idx].index\n            recommend_frame.append({'Title':movies.iloc[idx]['title'].values[0],'Distance':val[1]})\n        df = pd.DataFrame(recommend_frame,index=range(1,n_movies_to_reccomend+1))\n        return df\n    \n    else:\n        \n        return \"No movies found. Please check your input\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_movie_recommendation('Iron Man')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_movie_recommendation('Iron Man 2')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our model works perfectly predicting the recommendation based on user behaviour and past search. So we conclude our \ncollaborative filtering here.\n\n**Please upvote this kernel, if you like it. Thanks**"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}