{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Power of Recommendation Engine\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Suppose You're planning to buy a laptop without any idea about the right configuration. So You would check with Your friends and colleagues for recommendation and they suggests laptops based on Your requirement , their knowledge and trending one. The same way Recommendation engine works. For instance, Amazon recommends You a laptop based on Your previous search , popularity and keeps on showing the best recommendation and tempt You to buy a laptop even if You drop the plan. All the major company has recommendation in their products such as Youtube shows recommendations based on Your interests and activity.\n\nWe'll explore how to implement it, before that there are two types of Recommendation Engine\n\n1. **Content Based Filtering**\n2. **Collabarative Based Filtering**\n\n#### Content Based Filtering\nThis algorithm recommends products which are similar to the ones that a user has liked in the past.\n\n#### Collabaratvie Based Filtering\nThe collaborative filtering algorithm uses “User Behavior” for recommending items."},{"metadata":{},"cell_type":"markdown","source":"*In this Kernel, we shall look at Content Based Filtering implementation*"},{"metadata":{},"cell_type":"markdown","source":"**Our task is When User search a movie, We'll recommend the top 10 similar movies**"},{"metadata":{},"cell_type":"markdown","source":"Implementation is so simple, We're going to combine all features and create a bulk of keywords for each movie from the given datasets and find similarity between each movie and popup the top similar movies"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nimport json\nfrom functools import reduce","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"credits = pd.read_csv(\"../input/tmdb-movie-metadata/tmdb_5000_credits.csv\")\nmovies = pd.read_csv(\"../input/tmdb-movie-metadata/tmdb_5000_movies.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dataset shape\nprint(\"Credits shape is {}\".format(credits.shape))\nprint(\"Movies shape is {}\".format(movies.shape))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(credits.columns)\nprint(movies.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"credits.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movies.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"movie_id in credits and id in movie datasets are same using that we'll combine both the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"final_dataset = pd.merge(movies,credits,left_on='id',right_on='movie_id',how='left')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Data Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"final_dataset.isnull().sum() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop homepage and release_date\nfinal_dataset.drop(['homepage','release_date','runtime'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_dataset['overview'].fillna('',inplace=True)\nfinal_dataset['tagline'].fillna('',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_dataset.isnull().sum() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# some of the columns are given in JSON format, We should convert this to Dictinary using json.loads method\n\ndef convertJson(y):\n    y = json.loads(y)\n    return \" \".join([val['name'] for val in y])\nfinal_dataset['genres'] = final_dataset['genres'].apply(convertJson)\nfinal_dataset['keywords'] = final_dataset['keywords'].apply(convertJson)\nfinal_dataset['production_companies'] = final_dataset['production_companies'].apply(convertJson)\nfinal_dataset['production_countries'] = final_dataset['production_countries'].apply(convertJson)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_dataset.drop(['id','spoken_languages','status','budget','popularity','revenue','vote_average','vote_count','crew'],inplace=True,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_dataset['genres']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Top 5 cast does better prediction\ndef get_cast(y):\n    y = json.loads(y)\n    return \" \".join([val['character']+\" \"+ val['name'] for val in y[:5]])\nfinal_dataset['cast'] = final_dataset['cast'].apply(get_cast)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = ['original_language','original_title','overview',\\\n              'production_countries','tagline','title_x','title_y','cast']\nfinal_dataset['title'] = final_dataset['title_x']\nfinal_dataset['keywords'] = final_dataset[['keywords','genres','production_companies'] + columns].apply(\" \".join,axis=1)\nfinal_dataset.drop(columns,inplace=True,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"All keywords are in english. Our model can understand only numbers so We'll convert the keywords into sparse matrix form using either CountVectorizer or TfidfVectorizer. CountVectorizer just counts the words appear, there is a high chances that missing the rare words which could have helped for predicting the model effectively. So We'll use TfidfVectorizer which counts the frequency of the words and normalize them and this is mostly recommended."},{"metadata":{"trusted":true},"cell_type":"code","source":"# stop words will remove the common english words like a,an,the,i,me,my etc which increase the words count and \n# create noise in our model \n\nc_vect = TfidfVectorizer()\nX = c_vect.fit_transform(final_dataset['keywords'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# There are other similiary distance metric available which are euclidean distance,manhattan distance, \n# Pearson coefficient etc. But for sparse matrix cosine similarity works better\ncosine_sim = cosine_similarity(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_movie_recommendation(movie_name):\n    idx = final_dataset[final_dataset['title'].str.contains(movie_name)].index\n    if len(idx):\n        sorted_list_indices = sorted(list(enumerate(cosine_sim[idx[0]])), key=lambda x: x[1], reverse=True)[1:11]\n        sorted_list_indices = list(map(lambda x:x[0],sorted_list_indices))\n        return sorted_list_indices\n    else : \n        return []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"title = \"The Avengers\"\nrecommended_movie_list = get_movie_recommendation(title)\nfinal_dataset.loc[recommended_movie_list,['title','genres']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_dataset.loc[[3, 65, 3854]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"title = \"The Dark Knight Rises\"\nrecommended_movie_list = get_movie_recommendation(title)\nfinal_dataset.loc[recommended_movie_list,['title','genres']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our system predicts exactly the similar movies for Avengers with list of all marvel movies and for dark knight with list of DC movies.\n\nMajor drawback of this approach is that it predicts the same lists of movie for all the user who search Avengers irrespective of their interest and their likes. So we need an algorithm to predict based on User behaviour for that We'll use collabrative filtering."},{"metadata":{"trusted":true},"cell_type":"markdown","source":"I'm writing my other kernel for collabarative filtering. Will update once it is completed.\n\n**Please upvote it if you like it. Thanks**"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}