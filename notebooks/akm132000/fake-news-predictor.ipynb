{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Loading Necessary Modules","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport matplotlib","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"PATH='/kaggle/input/fake-and-real-news-dataset'\nTRUE_FILE_PATH=os.path.join(PATH,'True.csv')\nFAKE_FILE_PATH=os.path.join(PATH,'Fake.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"true_data_df=pd.read_csv(TRUE_FILE_PATH)\ntrue_class=['True' for index in range(true_data_df.shape[0])]\nfake_data_df=pd.read_csv(FAKE_FILE_PATH)\nfake_class=['Fake' for index in range(fake_data_df.shape[0])]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis and pre processing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"labels=['True','Fake']\nclass_wise_counts=[true_data_df.shape[0],fake_data_df.shape[0]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matplotlib.rcParams['figure.figsize']=(10,10)\nplt.bar(labels,class_wise_counts,align='center', alpha=0.5,color='r')\nplt.xlabel('Classes')\nplt.ylabel('Counts')\nplt.title('Count vs Classes')\nplt.show()\nprint (\"Ratio of fake is to real news:\",(fake_data_df.shape[0]/true_data_df.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"true_data_df['class']=true_class\nfake_data_df['class']=fake_class","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fake_data_df['class']=fake_class","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"true_data_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fake_data_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_frame=pd.concat([true_data_df,fake_data_df],axis='rows')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_frame.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_frame.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_frame.date.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Date contains a lot of unique values so not much value can be extracted from it hence dropping it for now","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_frame.drop('date',axis='columns',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_frame.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Looking in subject feature ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_frame.subject.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"real_news_df=data_frame[data_frame.subject=='politicsNews']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"real_news_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(fake_subject_keys,fake_counts)=np.unique(data_frame[data_frame['class']=='Fake'].subject,return_counts=True)\n(true_subject_keys,true_counts)=np.unique(data_frame[data_frame['class']=='True'].subject,return_counts=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matplotlib.rcParams['figure.figsize']=(10,10)\nplt.bar(fake_subject_keys,fake_counts,align='center', alpha=0.5,color='g')\nplt.xlabel('Subjects')\nplt.ylabel('Counts')\nplt.title('FakeNewsCounts vs Subjects')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matplotlib.rcParams['figure.figsize']=(10,7)\nplt.bar(true_subject_keys,true_counts,align='center', alpha=0.5,color='b')\nplt.xlabel('Subjects')\nplt.ylabel('Counts')\nplt.title('TrueNewsCounts vs Subjects')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## So only politicalNews and worldnews are giving true news remaning all of them are giving fake news","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Converting the subject feature into one hot encoded features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"subject_dummies=pd.get_dummies(data_frame.subject)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_frame2=pd.concat([data_frame,subject_dummies],axis='columns')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cleaning the title and text seperatly","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"title_column=list(data_frame2.title)\ntext_column=list(data_frame2.text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"title_column[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cleaning the title and text columns using NLTK","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nimport string\nimport nltk\nfrom nltk import pos_tag\nfrom nltk.stem import WordNetLemmatizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stop_words=stopwords.words('english')\nstop_words.extend(string.punctuation)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.corpus import wordnet\n\ndef get_wordnet_pos(treebank_tag):\n\n    if treebank_tag.startswith('J'):\n        return wordnet.ADJ\n    elif treebank_tag.startswith('V'):\n        return wordnet.VERB\n    elif treebank_tag.startswith('N'):\n        return wordnet.NOUN\n    elif treebank_tag.startswith('R'):\n        return wordnet.ADV\n    else:\n        return wordnet.NOUN","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lemmatizer=WordNetLemmatizer()\n\ndef clean_data(text):\n    \n    clean_words=[]\n    words=word_tokenize(text)\n    for word in words:\n        if (word.lower() not in stop_words and word.isdigit()==False):\n            curr_word_pos_tag=pos_tag([word])\n            \n            simple_pos_tag=get_wordnet_pos(curr_word_pos_tag[0][1])\n            clean_words.append(lemmatizer.lemmatize(word,simple_pos_tag))\n    return clean_words\n\nclean_title_column=[clean_data(current_column) for current_column in title_column]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clean_title_column[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clean_text_column=[clean_data(current_column) for current_column in text_column]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Now we have a list of list where each item contains the words that are not stop words in the current text.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Vectorising them so that important words can be extracted from it for converting into features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"clean_title_column_list=[\" \".join(list_words) for list_words in clean_title_column]\nclean_text_column_list=[\" \".join(list_words) for list_words in clean_text_column]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_frame2['title']=clean_title_column_list\ndata_frame2['text']=clean_text_column_list","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Shuffling the dataframe so that we can split into train and test sets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils import shuffle\ndata_frame3 = shuffle(data_frame2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_frame3.reset_index(inplace=True, drop=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Splitting the data into 75% for training and 25% for testing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataframe=data_frame3.loc[:int(0.75*data_frame3.shape[0]),:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataframe=data_frame3.loc[int(0.75*data_frame3.shape[0]):,:]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yTrain=list(train_dataframe['class'])\nyTest=list(test_dataframe['class'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Since the subject features 'class' and 'subject' have already been taken care of hence dropping them. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataframe.drop(['class','subject'],axis=1,inplace=True)\ntest_dataframe.drop(['class','subject'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataframe.reset_index(inplace=True,drop=True)\ntest_dataframe.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_title_column=list(train_dataframe['title'])\ntrain_text_column=list(train_dataframe['text'])\ntest_title_column=list(test_dataframe['title'])\ntest_text_column=list(test_dataframe['text'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataframe.drop(['title','text'],axis=1,inplace=True)\ntest_dataframe.drop(['title','text'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Vectorisation for 'title' feature","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"count_vec=CountVectorizer(max_features=5000,ngram_range=(1,2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_title_sparse_matrix=count_vec.fit_transform(train_title_column)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_title_sparse_matrix=count_vec.transform(test_title_column)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_title_sparse_matrix.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Converting the sparse matrix to dataframe for train and test set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataframe_title = pd.DataFrame.sparse.from_spmatrix(train_title_sparse_matrix,columns=count_vec.get_feature_names())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataframe_title=pd.DataFrame.sparse.from_spmatrix(test_title_sparse_matrix,columns=count_vec.get_feature_names())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataframe_title.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataframe_title.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Adding the features extracted from the 'title' column as features to the train and test set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataframe1=pd.concat([train_dataframe,train_dataframe_title],axis='columns')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataframe1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataframe1=pd.concat([test_dataframe,test_dataframe_title],axis='columns')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataframe1.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Vectorisation for 'text' Column","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"count_vec_text=CountVectorizer(max_features=5000,ngram_range=(1,2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_text_sparse_matrix=count_vec_text.fit_transform(train_text_column)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_text_sparse_matrix=count_vec_text.transform(test_text_column)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Converting the sparse matrix to train and test set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataframe_text = pd.DataFrame.sparse.from_spmatrix(train_text_sparse_matrix,columns=count_vec_text.get_feature_names())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataframe_text.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataframe_text=pd.DataFrame.sparse.from_spmatrix(test_text_sparse_matrix,columns=count_vec_text.get_feature_names())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataframe_text.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Adding the features extracted from 'text' column to the train and test set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataframe2=pd.concat([train_dataframe1,train_dataframe_text],axis='columns')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataframe2=pd.concat([test_dataframe1,test_dataframe_text],axis='columns')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataframe2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataframe2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataframe2.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataframe2.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataframe2.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataframe2.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataframe2.shape,test_dataframe2.shape,yTrain.shape,yTest.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xTrain=train_dataframe2.values\nxTest=test_dataframe2.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xTrain.shape,xTest.shape,yTrain.shape,yTest.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Logisitc Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlr=LogisticRegression(max_iter=1000)\nlr.fit(xTrain,yTrain)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yPredicted=lr.predict(xTest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr.score(xTest,yTest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix,classification_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (confusion_matrix(yTest,yPredicted))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (classification_report(yTest,yPredicted))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_rf=RandomForestClassifier()\nclf_rf.fit(xTrain,yTrain)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_rf.score(xTest,yTest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yPredicted_rf=clf_rf.predict(xTest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (confusion_matrix(yTest,yPredicted_rf))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (classification_report(yTest,yPredicted_rf))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Multinomial Naive Bayes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_mnb=MultinomialNB()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_mnb.fit(xTrain,yTrain)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_mnb.score(xTest,yTest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yPredicted_mnb=clf_mnb.predict(xTest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(yTest,yPredicted_mnb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (classification_report(yTest,yPredicted_mnb))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}