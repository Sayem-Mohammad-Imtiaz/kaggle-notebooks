{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import datetime as dt\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport math","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom matplotlib import pyplot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.arima_model import ARIMA\nfrom sklearn.metrics import mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Any results you write to the current directory are saved as output.\nfor dirname, _, filenames in os.walk('/kaggle/input/nab/realTraffic/realTraffic/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Aproach 1 - Anomaly detection with Severity Level"},{"metadata":{"trusted":true},"cell_type":"code","source":"dirname0 = \"/kaggle/input/nab/realTraffic/realTraffic/\"\nfilename0 = \"TravelTime_387.csv\"\ndataframe = pd.read_csv(dirname0+filename0)#, usecols=[1])#, skipfooter=3)\ndataframe.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remap(x, in_min, in_max, out_min, out_max):\n    return (x - in_min) * (out_max - out_min) / (in_max - in_min) + out_min\n\ndataframe['prop_value'] = remap( dataframe.value.values, np.min (dataframe.value), np.max( dataframe.value), 0.0, 100.0  )\ndataframe.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pyod","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pyod.models.ocsvm import OCSVM   #PyOD is a comprehensive and scalable Python toolkit for detecting outlier objects\n\nrandom_state = np.random.RandomState(42)     # A fixed values is assigned, then no matter how many time you execute your code,values generated would be the same\n#Does this mean that later on the code the outliers 5% higher than maximum value of dataset?\noutliers_fraction = 0.05\nclassifiers = {\n        'One Classify SVM (SVM)':OCSVM(kernel='rbf', degree=3, gamma='auto', coef0=0.0, tol=0.001, nu=0.5, shrinking=True, cache_size=200, verbose=False, max_iter=-1, contamination=outliers_fraction)\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = dataframe['value'].values.reshape(-1,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import stats\nfor i, (clf_name, clf) in enumerate(classifiers.items()):\n    clf.fit(X)\n    # predict raw anomaly score\n    scores_pred = clf.decision_function(X) * -1        \n    # prediction of a datapoint category outlier or inlier\n    y_pred = clf.predict(X)\n    n_inliers = len(y_pred) - np.count_nonzero(y_pred)\n    n_outliers = np.count_nonzero(y_pred == 1)\n    \n    # copy of dataframe\n    dfx = dataframe[['value','prop_value']]\n    dfx['outlier'] = y_pred.tolist()\n    IX1 =  np.array(dfx['value'][dfx['outlier'] == 0]).reshape(-1,1)\n    OX1 =  dfx['value'][dfx['outlier'] == 1].values.reshape(-1,1)         \n    print('OUTLIERS : ',n_outliers,'INLIERS : ',n_inliers, clf_name)        \n    # threshold value to consider a datapoint inlier or outlier\n    threshold = stats.scoreatpercentile(scores_pred,100 * outliers_fraction)\ny = dfx['outlier'].values.reshape(-1,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tOut = stats.scoreatpercentile(dfx[dfx['outlier'] == 1]['value'], np.abs(threshold))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def severity_validation():\n    tOUT10 = tOut+(tOut*0.10)    \n    tOUT23 = tOut+(tOut*0.23)\n    tOUT45 = tOut+(tOut*0.45)\n    dfx['test_severity'] = \"None\"\n    for i, row in dfx.iterrows():\n        if row['outlier']==1:\n            if row['value'] <=tOUT10:\n                dfx['test_severity'][i] = \"Low Severity\" \n            elif row['value'] <=tOUT23:\n                dfx['test_severity'][i] = \"Medium Severity\" \n            elif row['value'] <=tOUT45:\n                dfx['test_severity'][i] = \"High Severity\" \n            else:\n                dfx['test_severity'][i] = \"Ultra High Severity\" \n\nseverity_validation()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfx.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Mean proportion of outlier values"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\" inline values proportion mean \",dfx[dfx['outlier']==0]['prop_value'].mean())\nprint(\" outlier values proportion mean\",dfx[dfx['outlier']==1]['prop_value'].mean())\nprint(\" outlier values max \",dfx[dfx['outlier']==1]['prop_value'].min())\n\n    \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Values com proportion more than **0.2376237623762376%** are bad."},{"metadata":{},"cell_type":"markdown","source":"# Approach 2 - timeseries"},{"metadata":{"trusted":true},"cell_type":"code","source":"dirname = \"/kaggle/input/nab/realTraffic/realTraffic/\"\nfilename = \"speed_t4013.csv\"\n\ndataframe = pd.read_csv(dirname+filename)#, usecols=[1])#, skipfooter=3)\ndataframe.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Any results you write to the current directory are saved as output.\nfor dirname, _, filenames in os.walk('/kaggle/input/nab/realKnownCause/realKnownCause/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\nfor dirname, _, filenames in os.walk('/kaggle/input/nab/realAdExchange/realAdExchange/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Any results you write to the current directory are saved as output.\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/nab/realAWSCloudwatch/realAWSCloudwatch/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df8 = pd.read_csv('/kaggle/input/nab/realAdExchange/realAdExchange/exchange-2_cpc_results.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = pd.read_csv('/kaggle/input/nab/realAWSCloudwatch/realAWSCloudwatch/ec2_cpu_utilization_825cc2.csv')\ndf2 = pd.read_csv('/kaggle/input/nab/realAWSCloudwatch/realAWSCloudwatch/ec2_cpu_utilization_ac20cd.csv')\ndf3 = pd.read_csv('/kaggle/input/nab/realAWSCloudwatch/realAWSCloudwatch/ec2_cpu_utilization_fe7f93.csv')\ndf4 = pd.read_csv('/kaggle/input/nab/realAWSCloudwatch/realAWSCloudwatch/ec2_cpu_utilization_77c1ca.csv')\n\ndf5 = pd.read_csv('/kaggle/input/nab/realAWSCloudwatch/realAWSCloudwatch/ec2_network_in_5abac7.csv')\n\ndf6 = pd.read_csv('/kaggle/input/nab/realAWSCloudwatch/realAWSCloudwatch/grok_asg_anomaly.csv')\n\ndf7 = pd.read_csv('/kaggle/input/nab/realAWSCloudwatch/realAWSCloudwatch/elb_request_count_8c0756.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df6.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df4.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = [dt.datetime.strptime(d,\"%Y-%m-%d %H:%M:%S\").date() for d in df4[\"timestamp\"]]\ny = df4[\"value\"]\n\nplt.plot(x,y)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fpath = \"../input/nab/realAWSCloudwatch/realAWSCloudwatch//\"\nfname = \"grok_asg_anomaly.csv\"\n\nfullPath = fpath + fname\n\ndef parser(x):\n\treturn dt.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\")\n \ndata = pd.read_csv(fullPath, header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"arimaM = ARIMA(data, order=(5,1,0))\narimaMfit = arimaM.fit(disp=0)\nprint(arimaMfit.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot residual errors\nerrors = pd.DataFrame(arimaMfit.resid)\nerrors.plot()\npyplot.show()\nerrors.plot(kind='kde')\npyplot.show()\nprint(errors.describe())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data.values\nsize = int(len(X) * 0.70)\nlimitCount = 50\ntrain, test = X[0:size], X[size:size+limitCount]\nhistory = [x for x in train]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = list()\nfor t in range(len(test)):\n\tmodel = ARIMA(history, order=(5,1,0))\n\tmodel_fit = model.fit(disp=0)\n\toutput = model_fit.forecast()\n\tyhat = output[0]\n\tpredictions.append(yhat)\n\tobs = test[t]\n\thistory.append(obs)\n\tprint('pred=%f, exp=%f' % (yhat, obs))\nerror = mean_squared_error(test, predictions)\nprint('Mean Squared Error: %.3f' % error)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot\npyplot.plot(test)\npyplot.plot(predictions, color='red')\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataframe = pd.read_csv(dirname+filename, usecols=[1], skipfooter=3)\ndataset = dataframe.values\ndataset = dataset.astype('float32')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert an array of values into a dataset matrix\ndef create_dataset(dataset, look_back=1):\n\tdataX, dataY = [], []\n\tfor i in range(len(dataset)-look_back-1):\n\t\ta = dataset[i:(i+look_back), 0]\n\t\tdataX.append(a)\n\t\tdataY.append(dataset[i + look_back, 0])\n\treturn np.array(dataX), np.array(dataY)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fix random seed for reproducibility\nnp.random.seed(7)\n# load the dataset\n# dataframe = pd.read_csv(dirname+filename, usecols=[1], skipfooter=3)\n# dataset = dataframe.values\n# dataset = dataset.astype('float32')\n# dataset = data.values\n# dataset = data.astype('float32')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# normalize the dataset\nscaler = MinMaxScaler(feature_range=(0, 1))\ndataset = scaler.fit_transform(dataset)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split into train and test sets\ntrain_size = int(len(dataset) * 0.67)\ntest_size = len(dataset) - train_size\ntrain, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reshape into X=t and Y=t+1\nlook_back = 3\ntrainX, trainY = create_dataset(train, look_back)\ntestX, testY = create_dataset(test, look_back)\ntrainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\ntestX = np.reshape(testX, (testX.shape[0], testX.shape[1], 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create and fit the LSTM network\nbatch_size = 1\nmodel = Sequential()\nmodel.add(LSTM(4, batch_input_shape=(batch_size, look_back, 1), stateful=True))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam')\nfor i in range(5):\n\tmodel.fit(trainX, trainY, epochs=1, batch_size=batch_size, verbose=2, shuffle=False)\n\tmodel.reset_states()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make predictions\ntrainPredict = model.predict(trainX, batch_size=batch_size)\nmodel.reset_states()\ntestPredict = model.predict(testX, batch_size=batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# invert predictions\ntrainPredict = scaler.inverse_transform(trainPredict)\ntrainY = scaler.inverse_transform([trainY])\ntestPredict = scaler.inverse_transform(testPredict)\ntestY = scaler.inverse_transform([testY])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# calculate root mean squared error\ntrainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\nprint('Train Score: %.2f RMSE' % (trainScore))\ntestScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\nprint('Test Score: %.2f RMSE' % (testScore))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# shift train predictions for plotting\ntrainPredictPlot = np.empty_like(dataset)\ntrainPredictPlot[:, :] = np.nan\ntrainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# shift test predictions for plotting\ntestPredictPlot = np.empty_like(dataset)\ntestPredictPlot[:, :] = np.nan\ntestPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot baseline and predictions\nplt.plot(scaler.inverse_transform(dataset))\nplt.plot(trainPredictPlot)\nplt.plot(testPredictPlot)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Final"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}