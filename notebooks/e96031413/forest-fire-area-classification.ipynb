{"cells":[{"metadata":{},"cell_type":"markdown","source":"### I rename the \"area\" column with \"label\" so that I can take it as a classification problem."},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport math\nimport numpy as np\nimport pandas as pd\nimport random\n\n# importing sklearn libraries\nfrom sklearn import neural_network, linear_model, preprocessing, svm, tree\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, mean_squared_error, r2_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.naive_bayes import GaussianNB\n\n# importing keras libraries\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n\nimport warnings\n\n# supressing the warning on the usage of Linear Regression model\nwarnings.filterwarnings(action=\"ignore\", module=\"scipy\", message=\"^internal gelsd\")\n%matplotlib inline\npd.set_option(\"display.max_rows\", 1000)    #設定最大能顯示1000rows\npd.set_option(\"display.max_columns\", 1000) #設定最大能顯示1000columns\nfrom pylab import mpl\nmpl.rcParams['font.sans-serif'] = ['Microsoft YaHei']\n# 指定默認字形：解決plot不能顯示中文問題\nmpl.rcParams['axes.unicode_minus'] = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forest_fires = pd.read_csv(\"/kaggle/input/forest-fires-data-set/forestfires.csv\")\nforest_fires.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Attribute Information:\n\nFor more information, read [Cortez and Morais, 2007].\n1. X - x-axis spatial coordinate within the Montesinho park map: 1 to 9\n2. Y - y-axis spatial coordinate within the Montesinho park map: 2 to 9\n3. month - month of the year: 'jan' to 'dec'\n4. day - day of the week: 'mon' to 'sun'\n5. FFMC - FFMC index from the FWI system: 18.7 to 96.20\n6. DMC - DMC index from the FWI system: 1.1 to 291.3\n7. DC - DC index from the FWI system: 7.9 to 860.6\n8. ISI - ISI index from the FWI system: 0.0 to 56.10\n9. temp - temperature in Celsius degrees: 2.2 to 33.30\n10. RH - relative humidity in %: 15.0 to 100\n11. wind - wind speed in km/h: 0.40 to 9.40\n12. rain - outside rain in mm/m2 : 0.0 to 6.4\n13. area - the burned area of the forest (in ha): 0.00 to 1090.84\n(this output variable is very skewed towards 0.0, thus it may make\nsense to model with the logarithm transform).\n\nThe descriptions given for FFMC, DMC, DC and ISI are not very informative, a quick google search finds the following URL: http://cwfis.cfs.nrcan.gc.ca/background/summary/fwi giving the following information:\n\nFine Fuel Moisture Code The Fine Fuel Moisture Code (FFMC) is a numeric rating of the moisture content of litter and other cured fine fuels. This code is an indicator of the relative ease of ignition and the flammability of fine fuel.\n\nDuff Moisture Code The Duff Moisture Code (DMC) is a numeric rating of the average moisture content of loosely compacted organic layers of moderate depth. This code gives an indication of fuel consumption in moderate duff layers and medium-size woody material.\n\nDrought Code The Drought Code (DC) is a numeric rating of the average moisture content of deep, compact organic layers. This code is a useful indicator of seasonal drought effects on forest fuels and the amount of smoldering in deep duff layers and large logs.\n\nInitial Spread Index The Initial Spread Index (ISI) is a numeric rating of the expected rate of fire spread. It combines the effects of wind and the FFMC on rate of spread without the influence of variable quantities of fuel.\n\nAre there any missing values in this data set?"},{"metadata":{"trusted":true},"cell_type":"code","source":"forest_fires.month.replace(('jan','feb','mar','apr','may','jun','jul','aug','sep','oct','nov','dec'),(1,2,3,4,5,6,7,8,9,10,11,12), inplace=True)\nforest_fires.day.replace(('mon','tue','wed','thu','fri','sat','sun'),(1,2,3,4,5,6,7), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forest_fires.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### If fire area > 0, set the value to 1 and change column name from area to label so that we can see it as a classification problem"},{"metadata":{"trusted":true},"cell_type":"code","source":"forest_fires['area'].values[forest_fires['area'].values > 0] = 1\nforest_fires = forest_fires.rename(columns={'area': 'label'})\nforest_fires","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forest_fires.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We can find the third highest correlation coefficients would be \"month\", \"DC\", \"temp\""},{"metadata":{"trusted":true},"cell_type":"code","source":"forest_fires.corr()['label'].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Machine Learning"},{"metadata":{},"cell_type":"markdown","source":"## Logistic Regression Classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Logistic Regression Classification\nimport pandas as pd\nfrom sklearn import model_selection\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nscaler = StandardScaler()\nscaler.fit(forest_fires.drop('label',axis=1))\nscaled_features = scaler.transform(forest_fires.drop('label',axis=1))\ndf_feat = pd.DataFrame(scaled_features,columns=forest_fires.columns[:-1])\ndf_feat.head()\n\nX = df_feat\ny = forest_fires['label']\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.30,random_state=101)\n\nlogmodel = LogisticRegression(solver='liblinear')\nlogmodel.fit(X_train,y_train)\n\npredictions = logmodel.predict(X_test)\n\nfrom sklearn import metrics\nlogmodel.score(X_train,y_train)\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, predictions))\nprint(\"Precision:\",metrics.precision_score(y_test, predictions))\nprint(\"Recall:\",metrics.recall_score(y_test, predictions))\n\n#使用混淆矩陣\nfrom sklearn.metrics import classification_report,confusion_matrix\nprint(confusion_matrix(y_test,predictions))\nprint(classification_report(y_test,predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes={0:'safe',1:'On Fire'}\nx_new=[[1, 4, 9 ,1 ,91.5, 130.1, 807.1, 7.5, 21.3, 35, 2.2, 0]]\ny_predict=logmodel.predict(x_new)\nprint(classes[y_predict[0]])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## K-Nearest"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nscaler.fit(forest_fires.drop('label',axis=1))\nscaled_features = scaler.transform(forest_fires.drop('label',axis=1))\ndf_feat = pd.DataFrame(scaled_features,columns=forest_fires.columns[:-1])\ndf_feat.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX = df_feat\ny = forest_fires['label']\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.30,random_state=101)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n#從k值=1開始測試\nknn = KNeighborsClassifier(n_neighbors=1)\nknn.fit(X_train,y_train)\npred = knn.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"error_rate = []\n\nfor i in range(1,60):\n    \n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train,y_train)\n    pred_i = knn.predict(X_test)\n    error_rate.append(np.mean(pred_i != y_test))\n\n\nplt.figure(figsize=(10,6))\nplt.plot(range(1,60),error_rate,color='blue', linestyle='dashed', marker='o',\n         markerfacecolor='red', markersize=10)\nplt.title('Error Rate vs. K Value')\nplt.xlabel('K')\nplt.ylabel('Error Rate')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors=7)\nknn.fit(X_train,y_train)\npred = knn.predict(X_test)\nprint('WITH K=7')\nprint('\\n')\nprint(confusion_matrix(y_test,pred))\nprint('\\n')\nprint(classification_report(y_test,pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors=17)\nknn.fit(X_train,y_train)\npred = knn.predict(X_test)\nprint('WITH K=17')\nprint('\\n')\nprint(confusion_matrix(y_test,pred))\nprint('\\n')\nprint(classification_report(y_test,pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, pred))\nprint(\"Precision:\",metrics.precision_score(y_test, pred))\nprint(\"Recall:\",metrics.recall_score(y_test, pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes={0:'safe',1:'On Fire'}\nx_new=[[1, 4, 9 ,1 ,91.5, 130.1, 807.1, 7.5, 21.3, 35, 2.2, 0]]\ny_predict=knn.predict(x_new)\nprint(classes[y_predict[0]])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Support Vector Machine\nfrom sklearn import metrics\nfrom sklearn.svm import SVC\n# fit a SVM model to the data\n\nX = forest_fires.drop('label', axis=1)\ny = forest_fires['label']\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3,random_state=101)\n\nsvc = SVC()\nsvc.fit(X_train, y_train)\n# make predictions\nprediction = svc.predict(X_test)\n# summarize the fit of the model\nprint(metrics.classification_report(y_test, prediction))\nprint(metrics.confusion_matrix(y_test, prediction))\n\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, prediction))\nprint(\"Precision:\",metrics.precision_score(y_test, prediction))\nprint(\"Recall:\",metrics.recall_score(y_test, prediction))\n\nclasses={0:'safe',1:'On Fire'}\nx_new=[[1, 4, 9 ,1 ,91.5, 130.1, 807.1, 7.5, 21.3, 35, 2.2, 0]]\ny_predict=svc.predict(x_new)\nprint(classes[y_predict[0]])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Decision Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Decision Tree Classifier\nfrom sklearn import metrics\nfrom sklearn.tree import DecisionTreeClassifier\n\nX = forest_fires.drop('label', axis=1)\ny = forest_fires['label']\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3,random_state=101)\n\nd_tree = DecisionTreeClassifier()\nd_tree.fit(X_train, y_train)\n\n# make predictions\npredicted = d_tree.predict(X_test)\n# summarize the fit of the model\nprint(metrics.classification_report(y_test, predicted))\nprint(metrics.confusion_matrix(y_test, predicted))\n\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, predicted))\nprint(\"Precision:\",metrics.precision_score(y_test, predicted))\nprint(\"Recall:\",metrics.recall_score(y_test, predicted))\n\nclasses={0:'safe',1:'On Fire'}\nx_new=[[1, 4, 9 ,1 ,91.5, 130.1, 807.1, 7.5, 21.3, 35, 2.2, 0]]\ny_predict=d_tree.predict(x_new)\nprint(classes[y_predict[0]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nfrom sklearn.neighbors import KNeighborsClassifier\nX = forest_fires.drop('label', axis=1)\ny = forest_fires['label']\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3,random_state=101)\n\n# fit a k-nearest neighbor model to the data\nknn = KNeighborsClassifier()\nknn.fit(X_train, y_train)\n\nprint(knn)\n# make predictions\npredicted = knn.predict(X_test)\n# summarize the fit of the model\nprint(metrics.classification_report(y_test, predicted))\nprint(metrics.confusion_matrix(y_test, predicted))\n\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, predicted))\nprint(\"Precision:\",metrics.precision_score(y_test, predicted))\nprint(\"Recall:\",metrics.recall_score(y_test, predicted))\n\nclasses={0:'safe',1:'On Fire'}\nx_new=[[1, 4, 9 ,1 ,91.5, 130.1, 807.1, 7.5, 21.3, 35, 2.2, 0]]\ny_predict=knn.predict(x_new)\nprint(classes[y_predict[0]])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Gaussian Naive Bayes"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gaussian Naive Bayes\nfrom sklearn import metrics\nfrom sklearn.naive_bayes import GaussianNB\n\nX = forest_fires.drop('label', axis=1)\ny = forest_fires['label']\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3,random_state=101)\n\n# fit a Naive Bayes model to the data\nG_NB = GaussianNB()\nG_NB.fit(X_train,y_train)\nprint(G_NB)\n# make predictions\n\npredict = G_NB.predict(X_test)\n# summarize the fit of the model\nprint(metrics.classification_report(y_test, predict))\nprint(metrics.confusion_matrix(y_test, predict))\n\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, predict))\nprint(\"Precision:\",metrics.precision_score(y_test, predict))\nprint(\"Recall:\",metrics.recall_score(y_test, predict))\n\nclasses={0:'safe',1:'On Fire'}\nx_new=[[1, 4, 9 ,1 ,91.5, 130.1, 807.1, 7.5, 21.3, 35, 2.2, 0]]\ny_predict=G_NB.predict(x_new)\nprint(classes[y_predict[0]])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Comparing different Algorithms"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compare Algorithms\nimport pandas\nimport matplotlib.pyplot as plt\nfrom sklearn import model_selection\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\n\n# load dataset\nX = forest_fires.drop('label', axis=1)\ny = forest_fires['label']\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3,random_state=101)\n\n# prepare configuration for cross validation test harness\nseed = 7\n# prepare models\nmodels = []\nmodels.append(('LR', LogisticRegression(max_iter=5000)))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('NB', GaussianNB()))\nmodels.append(('SVM', SVC()))\nmodels.append(('MLP', MLPClassifier()))\nmodels.append(('GradientBoost',GradientBoostingClassifier()))\nmodels.append(('AdaBoost',AdaBoostClassifier()))\nmodels.append(('Bagging',BaggingClassifier()))\nmodels.append(('RandomForest',RandomForestClassifier()))\nmodels.append(('ExtraTrees',ExtraTreesClassifier()))\n\n# evaluate each model in turn\nresults = []\nnames = []\nscoring = 'accuracy'\nfor name, model in models:\n    kfold = model_selection.KFold(n_splits=10)\n    cv_results = model_selection.cross_val_score(model, X, y,   cv=kfold, scoring=scoring)\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}