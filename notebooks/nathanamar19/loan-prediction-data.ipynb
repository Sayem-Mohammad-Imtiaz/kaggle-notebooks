{"cells":[{"metadata":{},"cell_type":"markdown","source":"##### Among all industries, the insurance domain has one of the largest uses of analytics & data science methods. This dataset provides you a taste of working on data sets from insurance companies – what challenges are faced there, what strategies are used, which variables influence the outcome, etc. This is a classification problem. The data has 615 rows and 13 columns.\n\n**Problem: Predict if a loan will get approved or not.**"},{"metadata":{},"cell_type":"markdown","source":"We are going to work on binary classification problem, where we got some information about sample of peoples , and we need to predict whether we should give some one a loan or not depending on his information . we actually have a few sample size (614 rows), so we will go with machine learning techniques to solve our problem ."},{"metadata":{},"cell_type":"markdown","source":"## The Dataset\nIn the Dataset we find the following variables:\n- Loan ID, the identifier code of each applicant.\n- Gender, Male or Female for each applicant.\n- Married, the maritage state.\n- Dependents, how many dependents does the applicant have?\n- Education, the level of education, graduate or non graduate\n- Self Employed, Yes or No in the case\n- Applicant Income\n- Coapplicant Income\n- Loan Amount\n- Loan Amount Term\n- Credit History, just Yes or No in the case\n- Property Area, urban, semiurban or rural area of the applicant’s property\n- Loan Status, Yes or No ( The independent Variable)"},{"metadata":{},"cell_type":"markdown","source":"## Import libraries"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/loan-prediction-problem-dataset/train_u6lujuX_CVtuZ9i.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's analyse our data with pandas profiling first"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pandas_profiling","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas_profiling import ProfileReport","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"design_report = ProfileReport(df)\ndesign_report.to_file(output_file='report.html')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"design_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have missing data , we will handle them as we go"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems that credit history is 1 or 0. So let's change it to binary"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Credit_History'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Credit_History'] = df['Credit_History'].astype('O')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe(include='O')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will drop ID because it's not important for our model"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop('Loan_ID',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Do we have any duplicate ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.duplicated().any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We got no duplicated rows"},{"metadata":{},"cell_type":"markdown","source":"#### Let's look at our target"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Loan_Status.value_counts().plot.bar(color='blue')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\nsns.countplot(df['Loan_Status']);\n\nprint('The percentage of Y class : %.2f' % (df['Loan_Status'].value_counts()[0] / len(df)))\nprint('The percentage of N class : %.2f' % (df['Loan_Status'].value_counts()[1] / len(df)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Credit_History\n\ngrid = sns.FacetGrid(df,col='Loan_Status', size=3.2, aspect=1.6)\ngrid.map(sns.countplot, 'Credit_History');\n\n# we didn't give a loan for most people who got Credit History = 0\n# but we did give a loan for most of people who got Credit History = 1\n# so we can say if you got Credit History = 1 , you will have better chance to get a loan\n\n# important feature","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gender\n\ngrid = sns.FacetGrid(df,col='Loan_Status', size=3.2, aspect=1.6)\ngrid.map(sns.countplot, 'Gender');\n\n# most males got loan and most females got one too so (No pattern)\n\n# i think it's not so important feature, we will see later","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Married\nplt.figure(figsize=(15,5))\nsns.countplot(x='Married', hue='Loan_Status', data=df);\n\n# most people who get married did get a loan\n# if you'r married then you have better chance to get a loan :)\n# good feature","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before analyse the dependents columns let's analyse the different value inside."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Dependents.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dependents\n\nplt.figure(figsize=(15,5))\nsns.countplot(x='Dependents', hue='Loan_Status', data=df);\n\n# first if Dependents = 0 , we got higher chance to get a loan ((very hight chance))\n# good feature","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Education\n\ngrid = sns.FacetGrid(df,col='Loan_Status', size=3.2, aspect=1.6)\ngrid.map(sns.countplot, 'Education');\n\n# If you are graduated or not, you will get almost the same chance to get a loan (No pattern)\n# Here you can see that most people did graduated, and most of them got a loan\n# on the other hand, most of people who did't graduate also got a loan, but with less percentage from people who graduated\n\n# not important feature","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Self_Employed\n\ngrid = sns.FacetGrid(df,col='Loan_Status', size=3.2, aspect=1.6)\ngrid.map(sns.countplot, 'Self_Employed');\n\n# No pattern (same as Education)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Property_Area\n\nplt.figure(figsize=(15,5))\nsns.countplot(x='Property_Area', hue='Loan_Status', data=df);\n\n# We can say, Semiurban Property_Area got more than 50% chance to get a loan\n\n# good feature","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Correlation"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(df.corr(),annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Processing our data"},{"metadata":{},"cell_type":"markdown","source":"Missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum().sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's separate the numerical columns from the categorical\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_data = []\nnum_data = []\n\nfor i,c in enumerate(df.dtypes):\n    if c == object:\n        cat_data.append(df.iloc[:, i])\n    else :\n        num_data.append(df.iloc[:, i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_data = pd.DataFrame(cat_data).transpose()\nnum_data = pd.DataFrame(num_data).transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# If you want to fill every column with its own most frequent value you can use\n\ncat_data = cat_data.apply(lambda x:x.fillna(x.value_counts().index[0]))\ncat_data.isnull().sum().any() # no more missing data ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fill every missing value with their previous value in the same column\n\nnum_data.fillna(method='bfill', inplace=True)\nnum_data.isnull().sum().any() # no more missing data ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Categorical columns\n"},{"metadata":{},"cell_type":"markdown","source":"we are going to use LabelEncoder :"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder  \nle = LabelEncoder()\ncat_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# transform the target column\n\ntarget_values = {'Y': 0 , 'N' : 1}\n\ntarget = cat_data['Loan_Status']\ncat_data.drop('Loan_Status', axis=1, inplace=True)\n\ntarget = target.map(target_values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# transform other columns\n\nfor i in cat_data:\n    cat_data[i] = le.fit_transform(cat_data[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_data.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can now contact our cat data, num data, and our target data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([cat_data, num_data, target], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = pd.concat([cat_data,num_data],axis=1)\ny = target","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import precision_score, recall_score, f1_score, log_loss, accuracy_score\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"    \nprint('X_train shape', X_train.shape)\nprint('y_train shape', y_train.shape)\nprint('X_test shape', X_test.shape)\nprint('y_test shape', y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Using Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LogisticRegression()\nmodel.fit(X_train,y_train)\ny_pred = model.predict(X_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def metrics(y_true,y_pred,retu=False):\n    pre = precision_score(y_true, y_pred)\n    rec = recall_score(y_true, y_pred)\n    f1 = f1_score(y_true, y_pred)\n    loss = log_loss(y_true, y_pred)\n    acc = accuracy_score(y_true, y_pred)\n    \n    if retu:\n        return pre, rec, f1, loss, acc\n    else:\n        print('  pre: %.3f\\n  rec: %.3f\\n  f1: %.3f\\n  loss: %.3f\\n  acc: %.3f' % (pre, rec, f1, loss, acc))\n    ","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"metrics(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Using Decision Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"tree = DecisionTreeClassifier(max_depth=2,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree.fit(X_train,y_train)\ny_pred_tree = tree.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics(y_test,y_pred_tree)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Using Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"forest = RandomForestClassifier()\nforest.fit(X_train,y_train)\ny_pred_forest = forest.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics(y_test,y_pred_forest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Look at parameters used by our current forest\nprint('Parameters currently in use:\\n')\nprint(forest.get_params())","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}