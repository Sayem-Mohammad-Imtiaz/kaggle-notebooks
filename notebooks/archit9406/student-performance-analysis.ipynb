{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Importing the data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"stu_por=pd.read_csv(\"../input/studentpor/student-por.csv\",sep=\";\")\nstu_mat=pd.read_csv(\"../input/studentmat/student-mat.csv\",sep=\";\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stu_por.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Merging two datasets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"stu=pd.concat([stu_por,stu_mat])\nstu[\"total_grades\"]=(stu[\"G1\"]+stu[\"G2\"]+stu[\"G3\"])/3","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dropping columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"stu=stu.drop([\"G1\",\"G2\",\"G3\"],axis=1)\nmax=stu[\"total_grades\"].max()\nmin=stu[\"total_grades\"].min()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ranging the grade in three parts\ndef marks(total_grades):\n    if(total_grades<7):\n        return(\"low\")\n    elif(total_grades>=7 and total_grades<14):\n        return(\"average\")\n    elif(total_grades>=14):\n        return(\"high\")\nstu[\"grades\"]=stu[\"total_grades\"].apply(marks)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ANALYZING THE DATA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"stu.dtypes\nstu.describe()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#describing categorical data\nstu.describe(include=\"all\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stu.info()\n\n#checking for null values\nstu.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#visualizing the grades\nplt.figure(figsize=(8,6))\nsns.countplot(stu[\"grades\"], order=[\"low\",\"average\",\"high\"], palette='Set1')\nplt.title('Final Grade - Number of Students',fontsize=20)\nplt.xlabel('Final Grade', fontsize=16)\nplt.ylabel('Number of Student', fontsize=16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#describing correlation\ncorr=stu.corr()\n\nplt.figure(figsize=(20,20))\nsns.heatmap(corr, annot=True, cmap=\"Reds\")\nplt.title('Correlation Heatmap', fontsize=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ANALYZING CATEGORICAL VARIABLES","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"using boxplots","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#comparing school with grades\nsns.boxplot(x=\"school\", y=\"total_grades\", data=stu)\n\nschool_counts=stu[\"school\"].value_counts().to_frame()\nschool_counts.rename(columns={\"school\":\"school_counts\"},inplace=True)\nschool_counts.index.name='school'\n\nschool_sns=sns.countplot(hue=stu[\"school\"],x=stu[\"grades\"],data=stu)\n\n#crosstab is expanded form of value counts the the factors inside any variables\nperc=(lambda col:col/col.sum())\nindex=[\"average\",\"high\",\"low\"]\nschooltab1=pd.crosstab(columns=stu.school,index=stu.grades)\n\nschool_perc=schooltab1.apply(perc).reindex(index)\n\nschool_perc.plot.bar(colormap=\"PiYG_r\",fontsize=15,figsize=(7,7))\nplt.title('Final Grade By school', fontsize=20)\nplt.ylabel('Percentage of Student Counts ', fontsize=16)\nplt.xlabel('Final Grade', fontsize=16)\nplt.show()\n\n#so by graph we know that school has impact on grades of students","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#comparing sex with grades\nsns.boxplot(x=\"sex\", y=\"total_grades\", data=stu)\nschool_counts=stu[\"sex\"].value_counts()\n#as the graph of sex nearly overlaps so it will not have impact on grades\nstu=stu.drop([\"sex\"],axis=1)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#comparing address with grades\nsns.boxplot(x=\"address\", y=\"total_grades\", data=stu)\nindex=[\"average\",\"high\",\"low\"]\naddresstab1=pd.crosstab(columns=stu.address,index=stu.grades)\n\naddress_perc=addresstab1.apply(perc).reindex(index)\n\naddress_perc.plot.bar(colormap=\"PiYG_r\",fontsize=15,figsize=(7,7))\nplt.title('Final Grade By address', fontsize=20)\nplt.ylabel('Percentage of Student Counts ', fontsize=16)\nplt.xlabel('Final Grade', fontsize=16)\nplt.show()\n#address is factor for the grades","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#comparing famsize with grades\nsns.boxplot(x=\"famsize\", y=\"total_grades\", data=stu)\nfamsizetab1=pd.crosstab(columns=stu.famsize,index=stu.grades)\n\nfamsize_perc=famsizetab1.apply(perc).reindex(index)\n\nfamsize_perc.plot.bar(colormap=\"PiYG_r\",fontsize=15,figsize=(7,7))\nplt.title('Final Grade By famsize', fontsize=20)\nplt.ylabel('Percentage of Student Counts ', fontsize=16)\nplt.xlabel('Final Grade', fontsize=16)\nplt.show()\n#famsize has great impact on grades","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#comparing pstatus with grades\nsns.boxplot(x=\"Pstatus\", y=\"total_grades\", data=stu)\nPstatustab1=pd.crosstab(columns=stu.Pstatus,index=stu.grades)\n\nPstatus_perc=Pstatustab1.apply(perc).reindex(index)\n\nPstatus_perc.plot.bar(colormap=\"PiYG_r\",fontsize=15,figsize=(7,7))\nplt.title('Final Grade By Pstatus', fontsize=20)\nplt.ylabel('Percentage of Student Counts ', fontsize=16)\nplt.xlabel('Final Grade', fontsize=16)\nplt.show()\n#it is not a good factor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#comparing jobs\nsns.boxplot(x=\"Mjob\", y=\"total_grades\", data=stu)\nsns.boxplot(x=\"Fjob\", y=\"total_grades\", data=stu)\nstu1=stu[[\"Fjob\",\"Mjob\",\"total_grades\"]]\njob_grp=stu1.groupby(['Mjob','Fjob'],as_index=False).mean()\njob_pivot=job_grp.pivot(index='Mjob',columns='Fjob',values='total_grades')\n\n#so father and mother jobs has great impact on grades","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#comparing reasons\nsns.boxplot(x=\"reason\", y=\"total_grades\", data=stu)\n#it has impact on the grades","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#comparing guardians\nsns.boxplot(x=\"guardian\", y=\"total_grades\", data=stu)\n\nguardiantab1=pd.crosstab(columns=stu.guardian,index=stu.grades)\nguardian_perc=guardiantab1.apply(perc).reindex(index)\nguardian_perc.plot.bar(colormap=\"BrBG\",fontsize=15,figsize=(7,7))\nplt.title('Final Grade By guardian', fontsize=20)\nplt.ylabel('Percentage of Student Counts ', fontsize=16)\nplt.xlabel('Final Grade', fontsize=16)\nplt.show()\n#so guardian has grat impact on grades","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#support of family and school\nsns.boxplot(x=\"schoolsup\", y=\"total_grades\", data=stu)\n#it is the important factor\nsns.boxplot(x=\"famsup\", y=\"total_grades\", data=stu)\nstu[[\"famsup\",\"total_grades\"]].groupby([\"famsup\"],as_index=False).mean()\n#famsup does not have great impact on grades \nstu=stu.drop([\"famsup\"],axis=1) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#comparing paid attributes\nsns.boxplot(x=\"paid\", y=\"total_grades\", data=stu)\npaidtab1=pd.crosstab(columns=stu.paid,index=stu.grades)\npaid_perc=paidtab1.apply(perc).reindex(index)\npaid_perc.plot.bar(colormap=\"BrBG\",fontsize=15,figsize=(7,7))\nplt.title('Final Grade By paid', fontsize=20)\nplt.ylabel('Percentage of Student Counts ', fontsize=16)\nplt.xlabel('Final Grade', fontsize=16)\nplt.show()\n#paid does not have much influence on grades so\nstu=stu.drop([\"paid\"],axis=1)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=\"activities\", y=\"total_grades\", data=stu)\n#is has graet impact on student perforamnce\nsns.boxplot(x=\"nursery\", y=\"total_grades\", data=stu)\n#it does not have great impact on performance\nstu=stu.drop([\"nursery\"],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#comparing if higher educatiob of students have impact on performance\nsns.boxplot(x=\"higher\", y=\"total_grades\", data=stu)\n\nsns.boxplot(x=\"internet\", y=\"total_grades\", data=stu)\n#internet also have great impact on performance of individual\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#high school romace impact on the performance of students\nsns.boxplot(x=\"romantic\", y=\"total_grades\", data=stu)\nromantictab1=pd.crosstab(columns=stu.romantic,index=stu.grades)\nromantic_perc=romantictab1.apply(perc).reindex(index)\nromantic_perc.plot.bar(colormap=\"BrBG\",fontsize=15,figsize=(7,7))\nplt.title('Final Grade By romantic', fontsize=20)\nplt.ylabel('Percentage of Student Counts ', fontsize=16)\nplt.xlabel('Final Grade', fontsize=16)\nplt.show()\n#so high school romance leads to decline in performance of students\n#beware of that","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#encoding categorical data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"stu.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stu1=pd.get_dummies(stu,columns=[\"school\",\"address\",\"famsize\",\"Pstatus\",\"Mjob\",\"Fjob\",\"reason\",\"guardian\", 'schoolsup', 'activities', 'higher', 'internet', 'romantic' ])\ntest_stu1=stu1[\"grades\"]\nteststu1=stu1[\"total_grades\"]\ntrain_stu1=stu1.drop(['total_grades','grades'],axis=1)\ntrain_stu=train_stu1.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_stu1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"teststu1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ANALYZING NUMERICAL VARIABLES","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import stats\n#comparing age with marks\nsns.regplot(x=\"age\",y=\"total_grades\",data=stu)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pearson coeffiecient\nstu[[\"age\",\"total_grades\"]].corr()\n#p-value\npearson_coef , p_value=stats.pearsonr(stu[\"age\"],stu[\"total_grades\"])\nprint(\"The Pearson Correlation Coefficient is\", pearson_coef, \" with a P-value of P =\", p_value)\n#age is not a good factor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#using backward elimination for finding optimal featrures\n\n#if p-value is greater than 0.6 than we will removethat feature\nimport statsmodels.api as sm\nX=np.append(arr=np.ones((1044,1)).astype(int),values=train_stu,axis=1)\nX_opt = X[:, [0, 1, 2, 3, 4,5,6,7,8,9,10,11,12,13]]\nregressor_ols=sm.OLS(endog=teststu1,exog=X_opt).fit()\nregressor_ols.summary()\n\nX_opt = X[:, [0,2,3,4,5,6,7,8,9,10,11,12,13]]\nregressor_ols=sm.OLS(endog=teststu1,exog=X_opt).fit()\nregressor_ols.summary()\n\nX_opt = X[:, [0,2,3,4,5,6,7,9,10,11,12,13]]\nregressor_ols=sm.OLS(endog=teststu1,exog=X_opt).fit()\nregressor_ols.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stu.describe()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stu.columns\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now we merge our training data\ntrain_x=np.concatenate((X_opt,X[:,14:49]),axis=1)\nstu[[\"Medu\",\"total_grades\"]].corr()\nstu[[\"Fedu\",\"total_grades\"]].corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_stu2=train_stu1.drop([\"age\",\"freetime\"],axis=1)\nnp1=[1 for i in range(0,1044)]\ntrain_stu2.insert(loc=0,column= \"noimprotance\", value=np1)\n#now after getting the proper features we will split the data\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_stu2.columns\ntrain_stu2.head(30)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Splitting the dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(train_x,test_stu1, test_size = 0.2, random_state = 0)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"TRAINING THE DATASET","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# =============================================================================\n# #random forest\n# =============================================================================\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier=RandomForestClassifier(n_estimators=80,criterion=\"entropy\",random_state=0)\nclassifier.fit(X_train,y_train)\n\n#predicting the test set re4sults\ny_pred_random=classifier.predict(X_test)\n\nimportances=classifier.feature_importances_\nfor i,features in zip(importances,[ 'noimportant','Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel',\n       'goout', 'Dalc', 'Walc', 'health', 'absences',\n       'total_grades', 'grades', 'school_GP', 'school_MS', 'address_R',\n       'address_U', 'famsize_GT3', 'famsize_LE3', 'Pstatus_A', 'Pstatus_T',\n       'Mjob_at_home', 'Mjob_health', 'Mjob_other', 'Mjob_services',\n       'Mjob_teacher', 'Fjob_at_home', 'Fjob_health', 'Fjob_other',\n       'Fjob_services', 'Fjob_teacher', 'reason_course', 'reason_home',\n       'reason_other', 'reason_reputation', 'guardian_father',\n       'guardian_mother', 'guardian_other', 'schoolsup_no', 'schoolsup_yes',\n       'activities_no', 'activities_yes', 'higher_no', 'higher_yes',\n       'internet_no', 'internet_yes', 'romantic_no', 'romantic_yes']):\n    print(\"{}:{}\".format(features,i))\nindices = np.argsort(importances)\n\n# Rearrange feature names so they match the sorted feature importances\nnames = [train_stu2.columns[i] for i in indices]\n\n# Barplot: Add bars\n\nplt.figure(figsize=(20,20))\nplt.bar(range(train_x.shape[1]), importances[indices],width=0.5)\n# Add feature names as x-axis labels\nplt.xticks(range(train_x.shape[1]),names, rotation=60, fontsize = 12)\n#from here we cam see that absences is the important features for determining the grades of students\n\n# Create plot title\nplt.title(\"Feature Importance\")\n# Show plot\nplt.show()\n\n#determinnig the confusion matrix\nfrom sklearn.metrics import confusion_matrix\ncm_random=confusion_matrix(y_test,y_pred_random)\n\n#determining the precision,recall and f1-score \nfrom sklearn.metrics import classification_report\nreport_random=classification_report(y_test,y_pred_random)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# =============================================================================\n# # Fitting Kernel SVM to the Training set\n# =============================================================================\nfrom sklearn.svm import SVC\nclassifier = SVC(kernel = 'rbf', random_state = 0)\nclassifier.fit(X_train, y_train)\n# Predicting the Test set results\ny_pred_SVC= classifier.predict(X_test)\ncm_SVC=confusion_matrix(y_test,y_pred_SVC)\n\n#determining the precision,recall and f1-score \nfrom sklearn.metrics import classification_report\nreport_SVC=classification_report(y_test,y_pred_SVC)\nprint(report_SVC)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# =============================================================================\n# #fitting logistic regression to the training set\n# =============================================================================\nfrom sklearn.linear_model import LogisticRegression\nclassifier=LogisticRegression(random_state=0)\nclassifier.fit(X_train,y_train)\n# Predicting the Test set results\ny_pred_logistic= classifier.predict(X_test)\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm_logistic= confusion_matrix(y_test, y_pred_logistic)\n\n#determining the precision,recall and f1-score \nfrom sklearn.metrics import classification_report\nreport_logistic=classification_report(y_test,y_pred_logistic)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# =============================================================================\n# #fitting the knn_calssifier to the training set\n# =============================================================================\nfrom sklearn.neighbors import KNeighborsClassifier\nclassifier=KNeighborsClassifier(n_neighbors=5,metric='minkowski',p=2)\nclassifier.fit(X_train,y_train)\n# Predicting the Test set results\ny_pred_knn= classifier.predict(X_test)\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm_knn= confusion_matrix(y_test, y_pred_knn)\n\n#determining the precision,recall and f1-score \nfrom sklearn.metrics import classification_report\nreport_knn=classification_report(y_test,y_pred_knn)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(report_random)\nprint(report_SVC)\nprint(report_logistic)\nprint(report_knn)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"SO BY CONFUSION MATRIX AND F-SCORE WE FIND OUT THAT RANDOM FOREST IS BEST CLASSIFIER FOR GIVEN PROBLEM.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}