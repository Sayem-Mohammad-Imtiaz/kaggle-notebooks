{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"traindata = pd.read_csv('/kaggle/input/sign-language-mnist/sign_mnist_train.csv')\ntestdata = pd.read_csv('/kaggle/input/sign-language-mnist/sign_mnist_test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(traindata.shape,testdata.shape)\ntrainlab = traindata['label'].values\ntestlab = testdata['label'].values\ntraindata = (traindata.iloc[:,1:].values).astype('float32')\ntestdata = (testdata.iloc[:,1:].values).astype('float32')\ntraindata = traindata.reshape(traindata.shape[0],1,28,28)\ntestdata = testdata.reshape(testdata.shape[0],1,28,28)\nprint(traindata.shape,testdata.shape,trainlab.shape,testlab.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torch.autograd import Variable","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainx = torch.tensor(traindata)/255.0\ntrainy = torch.tensor(trainlab)\ntestx = torch.tensor(testdata)/255.0\ntesty = torch.tensor(testlab)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = TensorDataset(trainx, trainy)\ntest = TensorDataset(testx, testy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader = DataLoader(train, batch_size=16, num_workers=2, shuffle=True)\ntest_loader = DataLoader(test, batch_size=16, num_workers=2, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.s = 1\n        self.c1 = nn.Conv2d(1,32,3)\n        self.c2 = nn.Conv2d(32,64,3)\n        self.c3 = nn.Conv2d(64,128,3)\n        \n        self.f2 = nn.Linear(512,26)\n    def forward(self, x):\n        x = self.c1(x)\n        x = F.max_pool2d(F.relu(x),(2,2))\n        x = self.c2(x)\n        x = F.max_pool2d(F.relu(x),(2,2))\n        x = self.c3(x)\n        x = F.max_pool2d(F.relu(x),(2,2))\n        if self.s == 1:\n            self.s = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n        self.f1 = nn.Linear(self.s,512)\n        x = x.view(-1,self.s)\n        x = F.relu(self.f1(x))\n        x = F.log_softmax(self.f2(x),dim = -1)\n        return x\n    \n      \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Net() \ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n\nif (device.type=='cuda'):\n    model.cuda() # CUDA\n\nmodel.to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for epoch in range(10):\n    run_loss = 0.0\n    for i, (data,target) in enumerate(train_loader):\n        #target = target.squeeze(1)\n        if (device.type=='cuda'):\n            inputs,labels= Variable(data.cuda()), Variable(target.cuda())\n        else:\n            inputs,labels= Variable(data), Variable(target)\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss =  F.cross_entropy(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        print('\\r Train Epoch: {} [{}/{} ({:.0f}%)] \\tLoss: {:.6f}'.format( epoch, i * len(data), len(train_loader.dataset),100. * i / len(train_loader), loss.item()), end='')\n    print(' ')\n    \nprint('Finished')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output = model(testx)\npred = output.data.max(1)[1]\nd = pred.eq(testy.data).cpu()\na=(d.sum().data.cpu().numpy())\nb=d.size()\nb=torch.tensor(b)\nb=(b.sum().data.cpu().numpy())\naccuracy = a/b\nprint('Accuracy:', accuracy*100)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}