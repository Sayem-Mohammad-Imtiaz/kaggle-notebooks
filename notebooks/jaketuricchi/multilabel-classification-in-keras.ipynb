{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Predicting COVID19 Hospital Stay Length"},{"metadata":{},"cell_type":"markdown","source":"The following project was completed by jaketuricchi as part of IBM's deep learning course. Below is an exert from Kaggle describing the data which can be found at: https://www.kaggle.com/nehaprabhavalkar/av-healthcare-analytics-ii"},{"metadata":{},"cell_type":"markdown","source":"Recent Covid-19 Pandemic has raised alarms over one of the most overlooked area to focus: Healthcare Management. While healthcare management has various use cases for using data science, patient length of stay is one critical parameter to observe and predict if one wants to improve the efficiency of the healthcare management in a hospital.<br>\nThis parameter helps hospitals to identify patients of high LOS risk (patients who will stay longer) at the time of admission. Once identified, patients with high LOS risk can have their treatment plan optimized to miminize LOS and lower the chance of staff/visitor infection. Also, prior knowledge of LOS can aid in logistics such as room and bed allocation planning.<br>\nSuppose you have been hired as Data Scientist of HealthMan â€“ a not for profit organization dedicated to manage the functioning of Hospitals in a professional and optimal manner.<br>\nThe task is to accurately predict the Length of Stay for each patient on case by case basis so that the Hospitals can use this information for optimal resource allocation and better functioning. "},{"metadata":{},"cell_type":"markdown","source":"The length of stay is divided into 11 different classes ranging from 0-10 days to more than 100 days."},{"metadata":{},"cell_type":"markdown","source":"# Data dictionary:"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dir='../input/av-healthcare-analytics-ii/healthcare'\nos.chdir(dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dictionary=pd.read_csv('train_data_dictionary.csv')\nprint(dictionary)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Import Packages"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport warnings \nimport seaborn as sns\nimport random\nwarnings.filterwarnings('ignore')\n%matplotlib inline\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data=pd.read_csv('train_data.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Exploration<br>\nBecause this is a modelling task I skip visualisation but I must still explore the data enough to understand preprocessing needs.<br>\nWhats the shape of the data?"},{"metadata":{"trusted":false},"cell_type":"code","source":"print(data.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What columns do we have?"},{"metadata":{"trusted":false},"cell_type":"code","source":"print(data.columns.tolist())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What type are the columns?"},{"metadata":{"trusted":false},"cell_type":"code","source":"print(data.dtypes)\nprint(data.dtypes.value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Quickly describe the data."},{"metadata":{"trusted":false},"cell_type":"code","source":"print(data.describe(include='object').T)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From here we can see that object values aren't too unique. This is good as it will make encoding simpler."},{"metadata":{},"cell_type":"markdown","source":"Is the outcome data balanced?"},{"metadata":{"trusted":false},"cell_type":"code","source":"data.Stay.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The data is not balanced. We'll need to pay attention to the scoring metrics and stratifying splitting. I won't bother up/down sampling for this current exercise."},{"metadata":{},"cell_type":"markdown","source":"Do some cols have NA's?"},{"metadata":{"trusted":false},"cell_type":"code","source":"print(data.isna().sum().sort_values(ascending=False))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets train on only complete data since the missing data is only a small fraction."},{"metadata":{"trusted":false},"cell_type":"code","source":"data=data.dropna()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Labelling and Sorting<br>\nLets ensure we have all columns correctly labelled. I think we have some categorical vars registering as numeric."},{"metadata":{"trusted":false},"cell_type":"code","source":"data=data.drop(['case_id'], axis=1) # This is unique so not useful\ncategorical_vars=['Hospital_code', 'City_Code_Hospital', 'Bed Grade', 'City_Code_Patient',\n                  'Hospital_type_code', 'Hospital_region_code', 'Department', 'Ward_Type', \n                  'Ward_Facility_Code', 'Type of Admission', 'Severity of Illness', 'Age',\n                  'Stay'] \ndata[categorical_vars] = data[categorical_vars].astype('category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(data.describe(include='category').T)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have a participant id column which will have many unique values but is not continuous. Multiple occurences of an id suggests multiple hospital trips<br>\nTo deal with this, lets convert it to n hospital trips."},{"metadata":{"trusted":false},"cell_type":"code","source":"     \ndata['patient_visits'] = data.groupby(['patientid'])['patientid'].transform('count')\ndata=data.drop(['patientid'], axis=1) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now for each patient instead of their id we have the number of hospital visits which is less unique<br>\nLets now check our unique values of categories"},{"metadata":{"trusted":false},"cell_type":"code","source":"cat_uniques = pd.DataFrame([[i, len(data[i].unique())] for i in data[categorical_vars].columns], columns=['Variable', 'Unique Values']).set_index('Variable')\nprint(cat_uniques)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some values such as hospiral code and city patient code have too many unique values. Lets group the less frequent values"},{"metadata":{"trusted":false},"cell_type":"code","source":"hospital_codes = data['Hospital_code'].value_counts(normalize=True)\nprint(hospital_codes)\nminorities_hospitals =hospital_codes.where(hospital_codes<0.04).dropna().index.values\ndata['Hospital_code']=np.where(data['Hospital_code'].isin(minorities_hospitals), '0',  data['Hospital_code'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"city_code_patients = data['City_Code_Patient'].value_counts(normalize=True)\nprint(city_code_patients)\nminorities_ccp =city_code_patients.where(city_code_patients<0.04).dropna().index.values\ndata['City_Code_Patient']=np.where(data['City_Code_Patient'].isin(minorities_ccp), '0',  data['City_Code_Patient'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Recheck unique cats"},{"metadata":{"trusted":false},"cell_type":"code","source":"cat_uniques = pd.DataFrame([[i, len(data[i].unique())] for i in data[categorical_vars].columns], columns=['Variable', 'Unique Values']).set_index('Variable')\nprint(cat_uniques)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we have a reasonable number of categories"},{"metadata":{},"cell_type":"markdown","source":"# Encoding<br>\nBecause most features are categorical vars we must label and one hot encode before training a model."},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()\nlabel_vars=['Hospital_type_code', 'Hospital_region_code', 'Department', 'Ward_Type',\n            'Ward_Facility_Code', 'Type of Admission', 'Severity of Illness', 'Age', 'Stay']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Encode labels"},{"metadata":{"trusted":false},"cell_type":"code","source":"for col in label_vars:\n    data[col] = le.fit_transform(data[col])\n    \n# Reset index\ndata=data.reset_index(drop=True)\ny=data.Stay","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get Dummies"},{"metadata":{"trusted":false},"cell_type":"code","source":"categorical_vars=['Hospital_code', 'City_Code_Hospital', 'Bed Grade', 'City_Code_Patient',\n                  'Hospital_type_code', 'Hospital_region_code', 'Department', 'Ward_Type', \n                  'Ward_Facility_Code', 'Type of Admission', 'Severity of Illness', 'Age'] \nX = pd.get_dummies(data, columns=categorical_vars).drop('Stay', axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Scaling"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nnumeric_cols=['Available Extra Rooms in Hospital', 'Visitors with Patient',\n              'Admission_Deposit', 'patient_visits']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"for col in data[numeric_cols].columns:\n    X[col] = scaler.fit_transform(X[[col]])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Splitting"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"strat_shuff_split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\nX.columns = X.columns.str.replace(' ', '_')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get the index values from the generator"},{"metadata":{"trusted":false},"cell_type":"code","source":"train_idx, test_idx = next(strat_shuff_split.split(X, y))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create the data sets"},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train = X.loc[train_idx, X.columns.values]\ny_train = data.loc[train_idx, 'Stay']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_test = X.loc[test_idx, X.columns.values]\ny_test = data.loc[test_idx, 'Stay']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ensure the train/test split is equal"},{"metadata":{"trusted":false},"cell_type":"code","source":"print(y_train.value_counts(normalize=True).sort_index())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Test"},{"metadata":{"trusted":false},"cell_type":"code","source":"print(y_test.value_counts(normalize=True).sort_index())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"del(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The proportion of classes in the train and test data are balanced."},{"metadata":{},"cell_type":"markdown","source":"Now lets use keras to get dummies for the y data"},{"metadata":{"trusted":false},"cell_type":"code","source":"num_classes = 11\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Baseline Keras Model<br>\nNow we will build a basic Keras model which will attempt"},{"metadata":{},"cell_type":"markdown","source":"Build model base"},{"metadata":{"trusted":false},"cell_type":"code","source":"model_base = Sequential()\nmodel_base.add(Dense(96,input_dim = 78 ,activation = 'relu'))\nmodel_base.add(Dense(11,activation='sigmoid'))\nmodel_base.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model_base.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fit the model"},{"metadata":{"trusted":false},"cell_type":"code","source":"model_base.fit(X_train, y_train, batch_size=5, epochs=10,\n              validation_data=(X_test, y_test),\n              shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Calculate ROC AUC. This is more informative than accuracy due to lack of balance in the outcome variable"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_pred_prob = model_base.predict(X_test)\ny_pred=model_base.predict_classes(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The model is achieving a high level of accuracy with only a very basic model arcitecture. Its worth noting that increasing the number of epochs does not add much to the loss or accuracy<br>\nscores but did however take considerably longer to compute. Further models may wish to reduce the epochs in favour of more complex model arcitecture."},{"metadata":{},"cell_type":"markdown","source":"# Building a More Complex Keras Model"},{"metadata":{"trusted":false},"cell_type":"code","source":"model_2 = Sequential()\nmodel_2.add(Dense(256,input_dim = 78 ,activation = 'relu'))\nmodel_2.add(Dense(128,activation = 'relu'))\nmodel_2.add(Dropout(0.5))\nmodel_2.add(Dense(64,activation = 'relu'))\nmodel_2.add(Dropout(0.2))\nmodel_2.add(Dense(32,activation = 'relu'))\nmodel_2.add(Dense(11,activation='sigmoid'))\nmodel_2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model_2.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fit the model"},{"metadata":{"trusted":false},"cell_type":"code","source":"model_2.fit(X_train, y_train, batch_size=5, epochs=3, # Lets reduce epochs here, it didnt help last time.\n              validation_data=(X_test, y_test),\n              shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Calculate ROC AUC. "},{"metadata":{"trusted":false},"cell_type":"code","source":"y_pred_prob = model_2.predict(X_test)\ny_pred=model_2.predict_classes(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Improvement!"},{"metadata":{},"cell_type":"markdown","source":"# Next Steps<br>\n* Play with adding with width (more nodes) or depth (more layers) to the NN model. My computer is stuggling considerably on a basic model so I'll leave that out for now.<br>\n* Tune parameters (e.g. try a different optimizer, lr or batch size)<br>\n* Consider using a complex pre-designed model which is fit for this current problem. These often perform better than self-made models<br>\n* Conduct more feature engineering. Currently I only encoded and sorted variables, but adding interactions, or perhaps polynomial features to numeric vars could be useful.<br>\n* Calculate a more detailed scoring output for multiclassification (note that some metrics don't work here)<br>\n* See how the NN model compares to other ML algorithms."},{"metadata":{},"cell_type":"markdown","source":"Great, we're working with complete data. Lets consider the distribution/skew of features."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}