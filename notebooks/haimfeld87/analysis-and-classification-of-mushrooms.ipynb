{"cells":[{"metadata":{"_uuid":"01b5ff1ae1951de06486c14513d875586425ae28","_cell_guid":"e5cbb8b6-ac94-4188-9cfd-6503d95706b5"},"cell_type":"markdown","source":" **Introduction**\n \nHere I will explore the data presented by \"UCI Machine Learning\" for mushroom classification. The goal of this dataset is to classify between edible (e) to poisonous (p) mushrooms. First, I will analyze the data, by showing it's characteristics, and then I will classify it to achieve maximum accuracy and precision. "},{"metadata":{"_uuid":"7dccb54f5a4b90c36e199b3cc6a784a7c951c750","_cell_guid":"d51fc2c5-840f-40e4-bd59-34425a8b8394"},"cell_type":"markdown","source":"**Python libraries**\n\nThe libraries for this kernel are:\n\n•\t[Numpy](http://http://www.numpy.org/)\n\n•\t[Pandas](http://pandas.pydata.org/)\n\n•\t[Seaborn](https://seaborn.pydata.org/)\n\n•\t[Matplotlib](https://matplotlib.org/)\n\n•\t[Graphviz](http://www.graphviz.org/)\n\n•\t[Scikit-Learn](http://scikit-learn.org/stable/index.html)\n\n\n\nNumpy will be used for linear algebra and fixing arrays, Pandas for data processing, Seaborn for cool visualizations, matplotlib for figures, graphviz for awesome graph visualization and Scikit-Learn for preprocessing and machine learning algorithms.\n\nImporting of those libraries:\n"},{"metadata":{"_uuid":"3db6b92c25102a307cf50278e172a93d4d4e6a0a","_cell_guid":"81bd9ed8-1cf1-4e1e-90d8-b573558016a3","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, auc, roc_curve\nfrom sklearn.tree import DecisionTreeClassifier, export_graphviz\nimport graphviz","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d0e9f92040ecad3bc487c617f480768336ae099f","_cell_guid":"4391cf7a-ee9e-4093-808f-a99b3b6ee724"},"cell_type":"markdown","source":"**Loading the data and initial exploration**"},{"metadata":{"_uuid":"f1a56f0a51ae20fce8bb831e3725522c0fea4c27","_cell_guid":"aec6b645-194f-4bd8-bd07-943a7cfc991b","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/mushrooms.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3e4183d8c3ce37f2974171d836fabb7857fcff98","_cell_guid":"6648befd-88f5-4311-809d-317a126068d0","trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c254eda71c7d8600bf700ef2e4a728589411f9ca","_cell_guid":"5b6b6afb-5b78-439d-b9bc-102d2a5f9fc7","trusted":true},"cell_type":"code","source":"df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"302f156b4c65869e03a977c14b3d12ebd4eda452","_cell_guid":"8e501224-cfb1-4af4-ba29-7ab39be29dae"},"cell_type":"markdown","source":"The data is categorial so I convert it with LabelEncoder to transfer to ordinal."},{"metadata":{"_uuid":"52f298a5ba9c9c050abbc37f270003517ed19d79","_cell_guid":"43354e65-daf2-41d8-a063-40fd96c450bb","trusted":true},"cell_type":"code","source":"labelencoder=LabelEncoder()\nfor column in df.columns:\n    df[column] = labelencoder.fit_transform(df[column])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a43ffd13f2d99e0e9a7eeeec08e76228400a92a0","_cell_guid":"aa32df7f-36b4-4930-bd5b-a8ed74a4e85e","trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"653c7c564194e24b3b40b0a5a8f61aa3327d4fc0","_cell_guid":"6594d31b-562b-454c-83a1-d9428428f786"},"cell_type":"markdown","source":"From the table above it can be seen that the column \"veil-type\" is 0 and not contributing to the data so I remove it."},{"metadata":{"_uuid":"6efc64622b480ec69a7a268b6a4657d265f338d0","_cell_guid":"adbd7dc2-5f49-4219-896e-fba98090650a","trusted":true},"cell_type":"code","source":"df=df.drop([\"veil-type\"],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d2870dbd397ef0c09d67c2f6459f3d8fcae29227","_cell_guid":"69715e5d-40ea-45bd-b03a-8e3c9370c75a"},"cell_type":"markdown","source":"**Quick look at the characteristics of the data**"},{"metadata":{"_uuid":"858dd5c7f7de0907e40b9ba344461aa0636dc534"},"cell_type":"markdown","source":"The violin plot below represents the distribution of the classification characteristics. It is possible to see that \"gill-color\" property of the mushroom breaks to two parts, one below 3 and one above 3, that may contribute to the classification. "},{"metadata":{"_uuid":"d19d878b396bdedc18d5ef47c279d06d2d6e5db4","_cell_guid":"6a8d7116-7125-4e0c-953b-617c9cb32e30","trusted":true},"cell_type":"code","source":"df_div = pd.melt(df, \"class\", var_name=\"Characteristics\")\nfig, ax = plt.subplots(figsize=(10,5))\np = sns.violinplot(ax = ax, x=\"Characteristics\", y=\"value\", hue=\"class\", split = True, data=df_div, inner = 'quartile', palette = 'Set1')\ndf_no_class = df.drop([\"class\"],axis = 1)\np.set_xticklabels(rotation = 90, labels = list(df_no_class.columns));","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"583120d81da76da19cdc9a811d5b304370b7cde0","_cell_guid":"6f77c4f2-7ac0-4c2e-b237-22a8c613a73a"},"cell_type":"markdown","source":"**Is the data balanced?**"},{"metadata":{"_uuid":"5d375e20a16a284de985a0aa086527de144f572d","_cell_guid":"f6808a70-a27b-435f-b6fd-815d892c0421","trusted":true},"cell_type":"code","source":"plt.figure()\npd.Series(df['class']).value_counts().sort_index().plot(kind = 'bar')\nplt.ylabel(\"Count\")\nplt.xlabel(\"class\")\nplt.title('Number of poisonous/edible mushrooms (0=edible, 1=poisonous)');","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1781edd7271f36cf79323d5bad7476560dbae17d","_cell_guid":"aaf66b48-fe0e-4b8f-9de5-aea8eee009cc"},"cell_type":"markdown","source":"The dataset is balanced :D"},{"metadata":{"_uuid":"383ce94dfd6c0bd9af96c5945c89354ef94bc19e","_cell_guid":"51d125cb-3a4f-4e80-b71b-a34833fbcf82"},"cell_type":"markdown","source":"Let's look at the correlation between the variables:"},{"metadata":{"_uuid":"f2b68e2d55b0911f75ee5fa520f98f697f8286ba","_cell_guid":"326d6907-b4e2-4323-83b4-cfb900c5a74d","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14,12))\nsns.heatmap(df.corr(),linewidths=.1,cmap=\"YlGnBu\", annot=True)\nplt.yticks(rotation=0);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3c9fad1ac6d693358f6208f5548c8b4317f0b157","_cell_guid":"28522242-0c35-4d6c-bd3b-3e285cf11bfe"},"cell_type":"markdown","source":"Usually the least correlating variable is the most important one for classification. In this case, \"gill-color\" has -0.53 so let's look at it closely:"},{"metadata":{"_uuid":"02b01a94999158c04d7e9db231aa99c0182409e7","_cell_guid":"d8905dc3-0361-405a-946e-c55a09baeade","trusted":true},"cell_type":"code","source":"df[['class', 'gill-color']].groupby(['gill-color'], as_index=False).mean().sort_values(by='class', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5272b110ed8027d5ea79c9ee8d8a6d79a778d437"},"cell_type":"markdown","source":"Lets look closely at the feature \"gill-color\" :"},{"metadata":{"trusted":true,"_uuid":"0f499400ff0ba2efc9a428f88d63b526a645757d"},"cell_type":"code","source":"new_var=df[['class', 'gill-color']]\nnew_var=new_var[new_var['gill-color']<=3.5]\nsns.factorplot('class', col='gill-color', data=new_var, kind='count', size=2.5, aspect=.8, col_wrap=4);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6e823cbf81810570531f6fe1eff0ba5fecbc192d"},"cell_type":"code","source":"new_var=df[['class', 'gill-color']]\nnew_var=new_var[new_var['gill-color']>3.5]\n\nsns.factorplot('class', col='gill-color', data=new_var, kind='count', size=2.5, aspect=.8, col_wrap=4);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"12dd2951c06aa9b19d1067a8ce464b39ebecad78","_cell_guid":"ab52dac7-4b23-4485-9c98-69aa128e61a3"},"cell_type":"markdown","source":"**Model, predict and estimate the result:**"},{"metadata":{"_uuid":"726e531f18fbc090f72b4c48295288e993f6cdc6","_cell_guid":"efe113a7-db9b-41d4-a259-b776076bf40a","trusted":true},"cell_type":"code","source":"X=df.drop(['class'], axis=1)\nY=df['class']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a0076b449a0a035766a15de898d8d9c274fba302","_cell_guid":"62a3ddf0-b8a9-426c-b702-5023e0b6e6a8","trusted":true},"cell_type":"code","source":"X_train, X_test,Y_train,Y_test = train_test_split(X,Y, test_size = 0.1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"29247af178b311f91bfae52462187f10184c12de","_cell_guid":"a11e6983-3830-4b1a-8fae-c4c0ceb715e8"},"cell_type":"markdown","source":"For the mushroom classification dataset, I chose to use decision tree classifier. I will use the default settings of the classifier and explain shortly how it works."},{"metadata":{"_uuid":"4105a82a24cb4b83bff000883146a06090b49db8","_cell_guid":"8d51b9cc-0854-4bf1-9853-be1e563967df"},"cell_type":"markdown","source":"**Decision tree classifier**\n\n\nClassification tree predict a qualative response, in contrast to regression tree that predict quantitive response. Classification tree predicts the observation that belong to the most common occurring class from the training data for each region. In order to grow the classification tree the algorithm uses recursive binary splitting. \n"},{"metadata":{"_uuid":"0d72dbf98af8f855e2bd52740c59bf9f7936dfd2","_cell_guid":"44439152-fec0-4bd4-9658-0074b83fc9a7"},"cell_type":"markdown","source":"The Gini index\n\nThe Gini index is a measure of inequality of a system that has values between 0 to 1 (while 0 is perfect equality and 1 is absolute inequality). In other words the Gini index is a measure that define the node purity (value of 0 is pure and value of 1 is not pure).\n\nThe Gini index is defined by:\n![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQ2xshC_PkgPeHxdBPNtyo1PlRuXrCdi7P7amZuKZQyKYs9P5ztyQ)\n\nwhile J is the classes, pi is the fraction of items labeled with class i in the set."},{"metadata":{"_uuid":"519d6aaed6c3f6b45ac26fa48fa480fa5d117594","_cell_guid":"7f72a8eb-e14f-4f49-8a09-15c758013c67","trusted":true},"cell_type":"code","source":"clf = DecisionTreeClassifier()\nclf = clf.fit(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e1627ea12d4723717a328e40b4e7dd4af300eebc","_cell_guid":"8910bb66-8df3-4457-833f-d07e4bfa1367","trusted":true},"cell_type":"code","source":"dot_data = export_graphviz(clf, out_file=None, \n                         feature_names=X.columns,  \n                         filled=True, rounded=True,  \n                         special_characters=True)  \ngraph = graphviz.Source(dot_data)  \ngraph ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ce62947c1c030dd63a82ffbcbe5b13168dd993f1"},"cell_type":"markdown","source":"**Feature importances**\n\nBy all methods examined before the feature that is most important is \"gill-color\"."},{"metadata":{"_uuid":"c5cb2accd16f14a8800c81744debddf88ad849d9","_cell_guid":"3873fa4e-1a2f-4cc4-8936-c51c7edd6dca","trusted":true},"cell_type":"code","source":"features_list = X.columns.values\nfeature_importance = clf.feature_importances_\nsorted_idx = np.argsort(feature_importance)\n\nplt.figure(figsize=(5,7))\nplt.barh(range(len(sorted_idx)), feature_importance[sorted_idx], align='center')\nplt.yticks(range(len(sorted_idx)), features_list[sorted_idx])\nplt.xlabel('Importance')\nplt.title('Feature importances')\nplt.draw()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7f1e190f02553098fe2432bfa09e2d0729b44c89","_cell_guid":"c6ef9135-c2cd-41d8-891b-b6f381b8fc4e","trusted":true},"cell_type":"code","source":"y_pred=clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e8b73e63ff81cc3c70583355ec03d41f90a6edf6","_cell_guid":"6a3ac34c-8321-43ef-87a7-93f172b0f80b","trusted":true},"cell_type":"code","source":"print(\"Decision Tree Classifier report \\n\", classification_report(Y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9adbfc1a1f346ed391ec8aa6e6d7be037ea17d8f","_cell_guid":"b1d89b5f-855f-4c81-a95c-818c9ccef8b2","trusted":true},"cell_type":"code","source":"cfm=confusion_matrix(Y_test, y_pred)\n\nsns.heatmap(cfm, annot = True,  linewidths=.5, cbar =None)\nplt.title('Decision Tree Classifier confusion matrix')\nplt.ylabel('True label')\nplt.xlabel('Predicted label');","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0fa862a6e37c3d8f0ea0467bdaef519cf7057c8b","_cell_guid":"efcba9c9-ce4d-4619-bc94-91e887f0a161"},"cell_type":"markdown","source":"**Decision Tree Classifier resulted 100% accuracy and precision!! That's clearly overfitting! :...(**\n\nIn the code below 10-fold cross validation is performed for different depths of the tree and the accuracy is computed. The accuracy on the test set seems to plateau when the depth is 10.\n\nLets see at which tree depth the model begins to overfit:"},{"metadata":{"_uuid":"9eba6d7b9eae613eea63d22214461fff84e85ebe","trusted":true},"cell_type":"code","source":"#code edited but taken from: https://www.r-bloggers.com/practical-machine-learning-with-r-and-python-part-5/\nfrom sklearn.cross_validation import KFold\ndef computeCVAccuracy(X,y,folds):\n    accuracy=[]\n    foldAcc=[]\n    depth=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n    for i in depth: \n        kf = KFold(len(X),n_folds=folds)\n        for train_index, test_index in kf:\n            X_train, X_test,Y_train,Y_test = train_test_split(X,Y, test_size = 0.1)\n            clf = DecisionTreeClassifier(max_depth = i).fit(X_train, Y_train)\n            score=clf.score(X_test, Y_test)\n            accuracy.append(score)     \n        foldAcc.append(np.mean(accuracy))  \n    return(foldAcc)\n    \n    \ncvAccuracy=computeCVAccuracy(X,Y,folds=10)\n\ndf1=pd.DataFrame(cvAccuracy)\ndf1.columns=['10-fold cv Accuracy']\ndf=df1.reindex(range(1,20))\ndf.plot()\nplt.title(\"Decision Tree - 10-fold Cross Validation Accuracy vs Depth of tree\")\nplt.xlabel(\"Depth of tree\")\nplt.ylabel(\"Accuracy\")\nplt.ylim([0.8,1])\nplt.xlim([0,20])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a0ba036668f9a0c255eff71f3518bdd34f90d466"},"cell_type":"markdown","source":"**Gaussian Naive Bayes (GaussianNB)**"},{"metadata":{"_uuid":"bb0e7594e9b63c0b28884f1f9d79518f15f9dd13","trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\n\nclf_GNB = GaussianNB()\nclf_GNB = clf_GNB.fit(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ce21cf75b1596f17feddce2b3b465bbc615184b9","trusted":true},"cell_type":"code","source":"y_pred_GNB=clf_GNB.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"909b8895dd62bea00ecf24e7192d8b37111d7672","trusted":true},"cell_type":"code","source":"cfm=confusion_matrix(Y_test, y_pred_GNB)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6b0d1348b73e3f95208574d87df489fb6c67740d","trusted":true},"cell_type":"code","source":"sns.heatmap(cfm, annot = True,  linewidths=.5, cbar =None)\nplt.title('Gaussian Naive Bayes confusion matrix')\nplt.ylabel('True label')\nplt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"317aede20c9e5f6a6cc64fde06777b1e4ac7c8f2","trusted":true},"cell_type":"code","source":"print(\"Test data- Gaussian Naive Bayes report \\n\", classification_report(Y_test, y_pred_GNB))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ef83b28858ccbd920f9a3820a413d985dae4bad7","_cell_guid":"801cea10-9630-4aa0-be9d-724b50dc5764","trusted":true},"cell_type":"code","source":"precision, recall, thresholds = precision_recall_curve(Y_test, y_pred_GNB)\narea = auc(recall, precision)\nplt.figure()\nplt.plot(recall, precision, label = 'Area Under Curve = %0.3f'% area)\nplt.legend(loc = 'lower left')\nplt.title('Precision-Recall curve')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.ylim([-0.1, 1.1])\nplt.xlim([-0.1, 1.1])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3c17df0827f0efddff55f8ecd6f5ebe304a275e9","_cell_guid":"147f2c91-fd18-4aae-83ed-818d0e72210f","trusted":true},"cell_type":"code","source":"def roc_curve_acc(Y_test, Y_pred,method):\n    false_positive_rate, true_positive_rate, thresholds = roc_curve(Y_test, Y_pred)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    plt.title('Receiver Operating Characteristic')\n    plt.plot(false_positive_rate, true_positive_rate, color='darkorange',label='%s AUC = %0.3f'%(method, roc_auc))\n    plt.legend(loc='lower right')\n    plt.plot([0,1],[0,1],'b--')\n    plt.ylim([-0.1, 1.1])\n    plt.xlim([-0.1, 1.1])\n    plt.ylabel('True Positive Rate')\n    plt.xlabel('False Positive Rate')\n\nroc_curve_acc(Y_test, y_pred_GNB, \"Gaussian Naive Bayes\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}