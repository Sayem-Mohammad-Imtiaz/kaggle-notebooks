{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport json as js\nimport urllib\nimport gzip\nimport nltk\n\nfrom nltk.stem import PorterStemmer\nfrom sklearn.model_selection import train_test_split\nfrom gensim.models import KeyedVectors\nfrom nltk.corpus import stopwords\n\nfrom keras.models import Model\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\nfrom keras.layers.merge import concatenate\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.preprocessing import sequence\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\n#import sys  \n\n#reload(sys)  \n#sys.setdefaultencoding('utf8')\n\n\nimport string\nfrom sklearn.feature_extraction.text import CountVectorizer\ndef clean_text(text):\n    #text = [w.strip() for w in text.readlines()]\n    #text.decode('unicode_escape').encode('ascii','ignore')\n    text = str(text)\n    #text = text.decode(\"utf8\")\n    \n    text =  text.split()\n    words = []\n    for word in text:\n      exclude = set(string.punctuation)\n      word = ''.join(ch for ch in word if ch not in exclude)\n      if word in stops:\n        continue\n      try: \n        words.append(ps.stem(word))\n      except UnicodeDecodeError:\n        words.append(word)\n    text = \" \".join(words)\n    \n    \n    return text.lower()\n\n\n#Process data\n\nstops = set(stopwords.words(\"english\"))\n\nps = PorterStemmer()\ndf = pd.read_csv('../input/fake.csv')\ndf[\"type\"]= df[\"type\"].replace(\"bs\",\"fake\")\ndf[\"type\"]= df[\"type\"].replace(\"conspiracy\",\"fake\")\n\ndf[\"type\"]= df[\"type\"].replace(\"satire\",\"real\")\ndf[\"type\"]= df[\"type\"].replace(\"bias\",\"real\")\ndf[\"type\"]= df[\"type\"].replace(\"hate\",\"real\")\ndf[\"type\"]= df[\"type\"].replace(\"junksci\",\"real\")\ndf[\"type\"]= df[\"type\"].replace(\"state\",\"real\")\n\ndf.type = df.type.map(dict(real=1, fake=0))\ndf","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = df[1:1000]\n\nX_train, X_test, y_train, y_test = train_test_split(df['title'], df.type, test_size=0.2)\n\nX_cleaned_train = [clean_text(x) for x in X_train]\n\nX_cleaned_test = [clean_text(x) for x in X_test]\n\n\n\nX_cleaned_train[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\n\nfrom keras.layers import Dense, LSTM, Dropout, Conv1D, MaxPooling1D\nfrom keras.layers.embeddings import Embedding\nfrom keras.preprocessing import sequence\nfrom keras.preprocessing.sequence import pad_sequences\n\nkVECTORLEN = 50\n\nmodel = Sequential()\nmodel.add(Embedding(5000, 500, input_length=50))\nmodel.add(LSTM(125))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(1, activation='relu'))\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nprint(model.summary())\n\n\n#test_sequence\n\ntrain_sequence = sequence.pad_sequences(train_sequence, maxlen=50)\ntest_sequence = sequence.pad_sequences(test_sequence, maxlen=50)\n\nhistory = model.fit(train_sequence, y_train, validation_data=(test_sequence, y_test), epochs=10, batch_size=64)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}