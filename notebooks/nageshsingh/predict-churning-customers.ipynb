{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load all the required libraries"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set_style('darkgrid')\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split,cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom xgboost import XGBClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import f1_score as f1\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score, recall_score, precision_score\nimport scikitplot as skplt\nfrom collections import Counter\n\nplt.rc('figure',figsize=(18,9))\n%pip install imbalanced-learn\nfrom imblearn.over_sampling import SMOTE","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"credit_data = pd.read_csv('/kaggle/input/credit-card-customers/BankChurners.csv')\ncredit_data = credit_data[credit_data.columns[:-2]]\ncredit_data.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = credit_data.drop('Attrition_Flag', axis=1)\ny = credit_data['Attrition_Flag']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis"},{"metadata":{},"cell_type":"markdown","source":"1. **Age distribution**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (18,10))\nplt.title(\"Age with Churned or not\", fontsize = 30)\nsns.countplot(data = credit_data, x = credit_data[\"Customer_Age\"], hue = \"Attrition_Flag\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that the distribution of customer ages in our dataset follows a fairly normal distribution, thus further use of the age feature can be done with the normality assumption."},{"metadata":{},"cell_type":"markdown","source":"**2. Percentage of existing and attrited customers**"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(7, 7))\ncount = Counter(y)\nax.pie(count.values(), labels=count.keys(), autopct=lambda p:f'{p:.2f}%')\nax.set_title('Percentage of existing and attrited/churned customers')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see only 16% of the data samples represent churn customers, so we will use SMOTE to upsample the churn samples to match them with the regular customer sample size in order to give the later selected models a better chance of catching on small details which will almost definitely be missed out with such a size difference."},{"metadata":{},"cell_type":"markdown","source":"**3. Gender wise Existing and Churned customers**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#countplot\nplt.figure(figsize = (12,8))\nplt.title(\"Gender wise Existing and Churned customers\")\nsns.countplot(data = credit_data, x = credit_data[\"Gender\"], hue = \"Attrition_Flag\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**4. Education Level in Existing and Churned Customers**"},{"metadata":{"trusted":true},"cell_type":"code","source":"gender = credit_data.loc[credit_data[\"Attrition_Flag\"] == \"Attrited Customer\", [\"Education_Level\"]].value_counts()\ngender_normal = credit_data.loc[credit_data[\"Attrition_Flag\"] == \"Attrited Customer\", [\"Education_Level\"]].value_counts().tolist()\ngender_churned = credit_data.loc[credit_data[\"Attrition_Flag\"] == \"Existing Customer\", [\"Education_Level\"]].value_counts().tolist()\nfig, ax = plt.subplots(1, 2, dpi = 200, figsize = (15,8))\nax[0].set_title(\"Education Level in Existing Customers\")\nax[0].pie(x = gender_normal, labels = gender.index, autopct='%.2f%%')\nax[1].set_title(\"Education Level in Churned Customers\")\nax[1].pie(x = gender_churned, labels = gender.index, autopct='%.2f%%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The features in our dataset have some correlation, for example, Months_on_book and Customer_age, Avg_Utilization_Ratio and Total_Revolving_Bal."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15, 8))\nsns.heatmap(X.corr(), annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## DATA PROCESSING\n"},{"metadata":{},"cell_type":"markdown","source":"Convert all the categorical variables into numerical variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"# #--------------let's convert some categorical variables into numerical--------------\n\n# #ordinal to numerical\nmap_education_level = {'High School':1,'Graduate':3,'Uneducated':0,'College':2,'Post-Graduate':4,'Doctorate':5}\nmap_income_level = {'$60K - $80K':3,'Less than $40K':1, '$80K - $120K':4,'$40K - $60K':2,'$120K +':5}\nmap_card_category = {'Blue':1,'Gold':3,'Silver':2,'Platinum':4}\nX['Education_Level'].replace(map_education_level,inplace=True)\nX['Income_Category'].replace(map_income_level,inplace=True)\nX['Card_Category'].replace(map_card_category,inplace=True)\n\n\n# #hot encoding of gender category\nX.insert(2,'Gender_M',X['Gender'],True)\nX.rename({'Gender':'Gender_F'},axis=1,inplace=True)\nX['Gender_M'].replace({'M':1,'F':0},inplace=True)\nX['Gender_F'].replace({'M':0,'F':1},inplace=True)\n\n\n# #hot encoding of marital status\nX.insert(7,'Single',X['Marital_Status'],True)\nX.insert(7,'Divorced',X['Marital_Status'],True)\nX.insert(7,'Unknown',X['Marital_Status'],True)\nX.rename({'Marital_Status':'Married'},axis=1,inplace=True)\nX['Married'].replace({'Single':0, 'Married':1, 'Divorced':0, 'Unknown':0},inplace=True)\nX['Single'].replace({'Single':1, 'Married':0, 'Divorced':0, 'Unknown':0},inplace=True)\nX['Divorced'].replace({'Single':0, 'Married':0, 'Divorced':1, 'Unknown':0},inplace=True)\nX['Unknown'].replace({'Single':0, 'Married':0, 'Divorced':0, 'Unknown':1},inplace=True)\n\n\ny.replace({'Existing Customer':0, 'Attrited Customer':1},inplace=True)\n\nX.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Handling missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(X.loc[X['Income_Category']!='Unknown']['Income_Category'])   # income is rightly skewed. so central value is median\nplt.show()\n\nplt.hist(X.loc[X['Education_Level']!='Unknown']['Education_Level'])   # education is normally distributed. so central value is mean\nplt.show()\n\n#Missing values in education column\neducatedDF = X.loc[X['Education_Level']!='Unknown']\nmean_education = educatedDF['Education_Level'].mean()\nX['Education_Level'].replace({'Unknown':mean_education},inplace=True)\n\n#Missing values in income column\nsalariedDF = X.loc[X['Income_Category']!='Unknown']\nmedian_salaries = salariedDF['Income_Category'].median()\nX['Income_Category'].replace({'Unknown':median_salaries},inplace=True)\n\nX.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Scaling Numeric Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"sc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Upsampling using SMOTE"},{"metadata":{"trusted":true},"cell_type":"code","source":"#-----Upsampling----\nfrom sklearn.utils import resample\nfrom collections import Counter\n\nprint(\"Before Upsampling:-\")\nprint(Counter(y_train))\n\n\n# Let's use SMOTE to oversample\nfrom imblearn.over_sampling import SMOTE\noversample = SMOTE()\nX_train_upsampled, y_train_upsampled = oversample.fit_resample(X_train,y_train)\n\nprint(\"After Upsampling:-\")\nprint(Counter(y_train_upsampled))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Building Classification models\n"},{"metadata":{},"cell_type":"markdown","source":"1. Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = RandomForestClassifier(n_estimators = 50, random_state = 0)\nclassifier.fit(X_train_upsampled, y_train_upsampled)\n\n# Predicting result for training set and validation set\npredict_val_rf = classifier.predict(X_test)\n\n# Model Performance\nprint(\"Accuracy : \", accuracy_score(y_test, predict_val_rf) *  100)\nprint(\"Recall : \", recall_score(y_test, predict_val_rf) *  100)\nprint(\"Precision : \", precision_score(y_test, predict_val_rf) *  100)\nprint(confusion_matrix(y_test, predict_val_rf))\nprint(classification_report(y_test, predict_val_rf))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. XG Boost"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = XGBClassifier()\nmodel.fit(X_train_upsampled, y_train_upsampled)\n\n# Predicting result for training set and validation set\npredict_val_rf2 = model.predict(X_test)\n\n# Model Performance\nprint(\"Accuracy : \", accuracy_score(y_test, predict_val_rf2) *  100)\nprint(\"Recall : \", recall_score(y_test, predict_val_rf2) *  100)\nprint(\"Precision : \", precision_score(y_test, predict_val_rf2) *  100)\nprint(confusion_matrix(y_test, predict_val_rf2))\nprint(classification_report(y_test, predict_val_rf2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3. Naive Bayes"},{"metadata":{"trusted":true},"cell_type":"code","source":"gaussian = GaussianNB()\ngaussian.fit(X_train_upsampled, y_train_upsampled)\n\n# Predicting result for training set and validation set\npredict_val_rf2 = gaussian.predict(X_test)\n\n# Model Performance\nprint(\"Accuracy : \", accuracy_score(y_test, predict_val_rf2) *  100)\nprint(\"Recall : \", recall_score(y_test, predict_val_rf2) *  100)\nprint(\"Precision : \", precision_score(y_test, predict_val_rf2) *  100)\nprint(confusion_matrix(y_test, predict_val_rf2))\nprint(classification_report(y_test, predict_val_rf2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"4. Support Vector Machines"},{"metadata":{"trusted":true},"cell_type":"code","source":"svc = SVC()\nsvc.fit(X_train_upsampled, y_train_upsampled)\n\n# Predicting result for training set and validation set\npredict_val_rf2 = svc.predict(X_test)\n\n# Model Performance\nprint(\"Accuracy : \", accuracy_score(y_test, predict_val_rf2) *  100)\nprint(\"Recall : \", recall_score(y_test, predict_val_rf2) *  100)\nprint(\"Precision : \", precision_score(y_test, predict_val_rf2) *  100)\nprint(confusion_matrix(y_test, predict_val_rf2))\nprint(classification_report(y_test, predict_val_rf2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}