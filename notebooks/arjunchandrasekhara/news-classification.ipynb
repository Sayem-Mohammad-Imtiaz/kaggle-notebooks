{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"be2b96e3-4276-ff65-c966-35d5d48f4a87"},"source":"**1. Importing all the required libraries**\n-------------------------------------------"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"aa036384-ade7-d3a3-db1b-96ce4cf18e5e"},"outputs":[],"source":"import re\nimport pandas as pd # CSV file I/O (pd.read_csv)\nfrom nltk.corpus import stopwords\nimport numpy as np\nimport sklearn\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score ,confusion_matrix"},{"cell_type":"markdown","metadata":{"_cell_guid":"0e341752-e8b9-48af-9ffe-55a45550f77d"},"source":"\n2. Function to get the words from the headlines\n-----------------------------------------------"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f0a745cb-eb01-d06b-dac8-e0fb30870fdc"},"outputs":[],"source":"def get_words( headlines ):               \n    headlines_onlyletters = re.sub(\"[^a-zA-Z]\", \" \",headlines) #Remove everything other than letters     \n    words = headlines_onlyletters.lower().split() #Convert to lower case, split into individual words    \n    stops = set(stopwords.words(\"english\"))  #Convert the stopwords to a set for improvised performance                 \n    meaningful_words = [w for w in words if not w in stops]   #Removing stopwords\n    return( \" \".join( meaningful_words )) #Joining the words"},{"cell_type":"markdown","metadata":{"_cell_guid":"cebbd18a-ae5b-a136-c772-96f0f25e080c"},"source":"3. Reading data and Splitting as train and test sets\n----------------------------------------------------"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"88f29439-7c0a-9ffd-8586-60f5d8765d2a"},"outputs":[],"source":"news = pd.read_csv(\"../input/uci-news-aggregator.csv\") #Importing data from CSV\nnews = (news.loc[news['CATEGORY'].isin(['b','e'])]) #Retaining rows that belong to categories 'b' and 'e'\nX_train, X_test, Y_train, Y_test = sklearn.model_selection.train_test_split(news[\"TITLE\"], news[\"CATEGORY\"], test_size = 0.2)\nX_train = np.array(X_train);\nX_test = np.array(X_test);\nY_train = np.array(Y_train);\nY_test = np.array(Y_test);\ncleanHeadlines_train = [] #To append processed headlines\ncleanHeadlines_test = [] #To append processed headlines\nnumber_reviews_train = len(X_train) #Calculating the number of reviews\nnumber_reviews_test = len(X_test) #Calculating the number of reviews"},{"cell_type":"markdown","metadata":{"_cell_guid":"76c5bed8-539b-d4ec-31dd-729ee21b6fbe"},"source":"4. Getting only the words from the headlines, removing the stopwords, numbers and special characters\n------------------------------------------------------------------------"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"81baf6ea-6346-abdb-b0c4-8d67973f2060"},"outputs":[],"source":"for i in range(0,number_reviews_train):\n    cleanHeadline = get_words(X_train[i]) #Processing the data and getting words with no special characters, numbers or html tags\n    cleanHeadlines_train.append( cleanHeadline )"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"948c5c5a-4c00-a029-255f-9b44c02fe8fe"},"outputs":[],"source":"for i in range(0,number_reviews_test):\n    cleanHeadline = get_words(X_test[i]) #Processing the data and getting words with no special characters, numbers or html tags\n    cleanHeadlines_test.append( cleanHeadline )"},{"cell_type":"markdown","metadata":{"_cell_guid":"9fe1fd84-5790-cb04-572d-08d661a935a1"},"source":"5. Creating the bag of words for each headline\n----------------------------------------------"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"32053453-c51f-b4d7-2b90-532cc0d554a3"},"outputs":[],"source":"vectorize = sklearn.feature_extraction.text.CountVectorizer(analyzer = \"word\",max_features = 1700)\nbagOfWords_train = vectorize.fit_transform(cleanHeadlines_train)\nX_train = bagOfWords_train.toarray()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4a5bd8b8-2ef1-2afd-5103-993f1a43f83b"},"outputs":[],"source":"bagOfWords_test = vectorize.transform(cleanHeadlines_test)\nX_test = bagOfWords_test.toarray()"},{"cell_type":"markdown","metadata":{"_cell_guid":"6f177139-c64c-f4d7-3d1d-cfceaf1a2ee6"},"source":"6. Using Naive Bayes for training and calculating the accuracy of the model\n------------------------------------------------------------------------"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ea5cb5ee-2105-f87f-05f7-6166ed938bbc"},"outputs":[],"source":"vocab = vectorize.get_feature_names()\nnb = MultinomialNB()\nnb.fit(X_train, Y_train)\nprint(nb.score(X_test, Y_test))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"51b5b0b3-d0b1-a54e-93e6-641c50e60d76"},"outputs":[],"source":"logistic_Regression = LogisticRegression()\nlogistic_Regression.fit(X_train,Y_train)\nY_predict = logistic_Regression.predict(X_test)\nprint(accuracy_score(Y_test,Y_predict))"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}