{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"![Rain In Australia](https://res-3.cloudinary.com/the-university-of-melbourne/image/upload/s---y185jhN--/c_limit,f_auto,q_75,w_1784/v1/pursuit-uploads/4be/f69/882/4bef6988217e9f3be436803052345f9b7fc2752087fa9e4d56c3dc600c07.jpg)"},{"metadata":{},"cell_type":"markdown","source":"# Problem Statement\ndataset is provided with data to predict the rain in Australia. our aim in this notebook to do the EDA with the data set provided. do feature engnineering, feature analysis and create a machinlearning model to predict the Rain."},{"metadata":{},"cell_type":"markdown","source":"# Read Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/weather-dataset-rattle-package/weatherAUS.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis"},{"metadata":{},"cell_type":"markdown","source":"Initial level analysis to understand the data and data type."},{"metadata":{"trusted":true,"_kg_hide-output":false,"_kg_hide-input":true},"cell_type":"code","source":"len(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df.select_dtypes('object').columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 7 Categorical data, and i belive Date columns must be data object for our detailed analysis"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df.select_dtypes('float64').columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 16 columns with Integer values. "},{"metadata":{},"cell_type":"markdown","source":"# Ploting"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import plotly.express as px\nimport seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df['Date']=pd.to_datetime(df['Date'],format='%Y-%m-%d')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df['Year']=df['Date'].dt.year\ndf['Month']=df['Date'].dt.month\ndf['day']=df['Date'].dt.day","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Explore Categorical Datatype"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"cat_columns = df.select_dtypes('object').columns.to_list()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"cat_columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"['Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday','RainTomorrow']  are the categorical values. we need to convert the categorical features with Onehot encoder or binary encoding techinque to convert it as numerical variables."},{"metadata":{},"cell_type":"markdown","source":"# Analysing Numerical features"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#lets get the list of Nuemrical feature column list\nnum_cols = df.select_dtypes('number').columns.to_list()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"num_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_cols.remove('Year')\nnum_cols.remove('Month')\nnum_cols.remove('day')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,8))\nsns.heatmap(df[num_cols].corr(), annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[['MinTemp','Temp3pm']].corr()['MinTemp'][1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"treshold=0.68\ncorr_cols=[]\nfor i in num_cols:\n    \n    for j in num_cols:\n        if i == j:\n            continue\n        #print(df[[i,j]].corr()[j])\n        if df[[i,j]].corr()[i][1] >= treshold:\n            print(\"{} is highly coorelated with {} at {:.2f}\".format(i,j,df[[i,j]].corr()[i][1] ))\n            corr_cols.append(j)\n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Set of highly coorelated features"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_cols=list(set(corr_cols))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"lets find the linearity between the highly coorelated Variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df[corr_cols], diag_kind='hist', kind='scatter')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Identify outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[num_cols].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above table we can see that the features like Rainfall, Evaporation, WindGustSpeed, WindSpeed9am, WindSpeed3pm has high outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"px.box(df, x=['Rainfall', 'Evaporation', 'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is clear that the above said features has the outliers. lets us use Interquaritle Range method to remove the Outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Rainfall Feature\nfor i in ['Rainfall', 'Evaporation', 'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm']:\n    IQR = df[i].quantile(0.75)-df[i].quantile(0.25)\n    lower_fence=df[i].quantile(0.25)-(IQR*1.5)\n    upper_fence=df[i].quantile(0.75)+(IQR*1.5)\n    print(\"{} has the upper fence : {:0.2f} & lower fence : {:0.2f}\".format(i,upper_fence,lower_fence))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering\n1. Remove outliers\n2. Handel null values"},{"metadata":{},"cell_type":"markdown","source":"Null Values in Numerical features"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[num_cols].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#percentate of null values in the data set\ndf[num_cols].isnull().sum()/len(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"in this case the numerical values has outliers which we need to deal with. so, let us fill the null values in numerical features with Median values."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['MinTemp'].mode()[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['MinTemp'].median()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in num_cols:\n    df[i].fillna(df[i].median(), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[num_cols].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"null values in the numerical columns has been removed. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets work on the Categorical features\ndf[cat_columns].isnull().sum()/len(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[cat_columns].isnull().sum()/len(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in cat_columns:\n    df[i].fillna(df[i].mode()[0], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[cat_columns].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All Null values in the Dataset has been handled."},{"metadata":{"trusted":true},"cell_type":"markdown","source":"1. Rainfall has the upper fence : 2.00 & lower fence : -1.20\n2. Evaporation has the upper fence : 14.60 & lower fence : -4.60\n3. WindGustSpeed has the upper fence : 73.50 & lower fence : 5.50\n4. WindSpeed9am has the upper fence : 37.00 & lower fence : -11.00\n5. WindSpeed3pm has the upper fence : 40.50 & lower fence : -3.50"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1=df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1['Rainfall']=df1['Rainfall'].apply(lambda x: np.where(x>2.00,2.00,x))\ndf1['Evaporation']=df1['Evaporation'].apply(lambda x: np.where(x>14.60,14.60,x))\ndf1['WindGustSpeed']=df1['WindGustSpeed'].apply(lambda x: np.where(x>73.50,73.50,x))\ndf1['WindSpeed9am']=df1['WindSpeed9am'].apply(lambda x: np.where(x>37.00,37.00,x))\ndf1['WindSpeed3pm']=df1['WindSpeed3pm'].apply(lambda x: np.where(x>40.50,40.50,x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before and after handling Outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.boxplot(column=['Rainfall','Evaporation','WindGustSpeed','WindSpeed9am','WindSpeed3pm'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.boxplot(column=['Rainfall','Evaporation','WindGustSpeed','WindSpeed9am','WindSpeed3pm'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Identify Target vairable"},{"metadata":{"trusted":true},"cell_type":"code","source":"y=df1['RainTomorrow']\nX=df1.drop(labels=['RainTomorrow','Date'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import label_binarize, OneHotEncoder, LabelEncoder\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.33, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder, MinMaxScaler","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Pipeline & Column Transformer\nCreate pipeline & Column Transforment to Transform the Categorical & Numerical Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"encode=OneHotEncoder()\nscaler = MinMaxScaler()\nfrom sklearn.compose import make_column_transformer, ColumnTransformer\n#encode.fit_transform(X_train[['Location']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.select_dtypes('float').columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_cols=['MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation', 'Sunshine',\n       'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am',\n       'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm',\n       'Temp9am', 'Temp3pm']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_cols=['Location','WindGustDir','WindDir9am','WindDir3pm','RainToday']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#column_transformer = make_column_transformer(\n#(encode,['Location','WindGustDir','WindDir9am','WindDir3pm','RainToday']),\n#remainder='passthrough')\ncolumn_transformer1 = ColumnTransformer(\n[('cat_feat',encode,cat_cols),\n('num_feat',scaler,num_cols)\n],\nremainder='passthrough')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=column_transformer1.fit_transform(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test =column_transformer1.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Target Variable\n\nLets encode the Target variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train=y_train.map({'Yes':1,'No':0})\ny_test=y_test.map({'Yes':1,'No':0})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create & Train Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=LogisticRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reports to test the model accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix, accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(confusion_matrix(y_test,y_pred), annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Result\nModel can predict the Rain with 83% accuracy Score"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}