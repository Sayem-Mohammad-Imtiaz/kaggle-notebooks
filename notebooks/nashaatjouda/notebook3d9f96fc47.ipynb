{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.options.mode.chained_assignment = None ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\n\ndata_frame=pd.read_csv(\"../input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\")\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_frame.head(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"positive_values = data_frame[(data_frame.review .notnull()) & (data_frame.sentiment == \"positive\")]\n\nprint(positive_values.head(15))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text_1=positive_values.review[0]\ntext_1\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The world cloud for the positive terms**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud,STOPWORDS \nfrom nltk.corpus import stopwords\nimport matplotlib.pyplot as plt\nwordcloud = WordCloud(width=700,height=400, max_font_size=80, max_words=100, background_color=\"white\").generate(text_1)\nf = plt.figure() \nf.set_figwidth(15) \nf.set_figheight(10) \nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.margins(x=0, y=0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"negative_values=data_frame[(data_frame.review .notnull()) & (data_frame.sentiment == \"negative\")]\n\nprint(negative_values.head(15))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text_2=negative_values.review[11]\n\ntext_2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The world cloud for the Negative terms**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nwordcloud = WordCloud(width=700,height=400, max_font_size=80, max_words=100, background_color=\"white\").generate(text_2)\n\n\nf = plt.figure() \nf.set_figwidth(15) \nf.set_figheight(10) \n\n \nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.margins(x=0, y=0)\n \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.figure(figsize=(6,3))\ndata_frame.sentiment.value_counts().plot(kind='bar', rot=360)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Summary & describtion of the dataset :"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_frame['sentiment'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_frame.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" spliting data into train and test set by using sklearnâ€™s train_test_split\n    "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain, test = train_test_split(data_frame,test_size=0.25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)\n\n#0.25*50000=12500\n#0.75*50000=37500\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Text preprocessing phase **"},{"metadata":{},"cell_type":"markdown","source":"1.Turn sentiment into categorical value"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlabelencoder = LabelEncoder()\ntrain['sentiment'] = labelencoder.fit_transform(train['sentiment'])\ntest['sentiment'] = labelencoder.fit_transform(test['sentiment'])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['sentiment'].head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" 2. Remove none text and special character"},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nimport string\npattern = re.compile(r'<br\\s*/><br\\s*/>>*|(\\-)|(\\\\)|(\\/)')\ndef preprocess_reviews(reviews):\n    reviews = [pattern.sub(\" \",item) for item in reviews]\n    return reviews\ntrain_clean = preprocess_reviews(train['review'])\ntest_clean = preprocess_reviews(test['review'])\ntrain['review'] = train_clean\ntest['review'] = test_clean\ndef remove_punctuation(input):\n    table = str.maketrans('','',string.punctuation)\n    return input.translate(table)\ntrain['review'] = train['review'].apply(remove_punctuation)\ntest['review'] = test['review'].apply(remove_punctuation)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['review']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" 3. Convert all text to lowercase"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['review'] = train['review'].str.lower()\ntest['review'] = test['review'].str.lower()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['review']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" 4. Remove line breaks"},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_linebreaks(input):\n    text = re.compile(r'\\n')\n    return text.sub(r' ',input)\ntrain['review'] = train['review'].apply(remove_linebreaks)\ntest['review'] = test['review'].apply(remove_linebreaks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['review']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"5. Tokenization"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom nltk.tokenize import word_tokenize\ntrain['review'] = train['review'].apply(word_tokenize)\ntest['review'] = test['review'].apply(word_tokenize)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['review']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"6. Remove stopword"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nfrom nltk.corpus import stopwords\ndef remove_stopwords(input1):\n    words = []\n    for word in input1:\n        if word not in stopwords.words('english'):\n            words.append(word)\n    return words\ntrain['review'] = train['review'].apply(remove_stopwords)\ntest['review'] = test['review'].apply(remove_stopwords)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['review']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"7. Lemmatization"},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.stem import WordNetLemmatizer\nlem = WordNetLemmatizer()\ndef lemma_wordnet(input):\n    return [lem.lemmatize(w) for w in input]\ntrain['review'] = train['review'].apply(lemma_wordnet)\ntest['review'] = test['review'].apply(lemma_wordnet)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['review']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"8. Combine individual words"},{"metadata":{"trusted":true},"cell_type":"code","source":"def combine_text(input):\n    combined = ' '.join(input)\n    return combined\ntrain['review'] = train['review'].apply(combine_text)\ntest['review'] = test['review'].apply(combine_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['review']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**TF-IDF**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn import feature_extraction\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn import linear_model,model_selection\n\nvectorizer = feature_extraction.text.TfidfVectorizer(norm = None)\nvectorizer.fit(train)\n\nX_train_tfidf = vectorizer.fit_transform(train['review'])\nX_test_tfidf = train['sentiment']\nY_train_tdidf =vectorizer.transform(test['review'])\n\n\n ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Rigde with TF-IDF"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nalpha = [500.0, 1500.0, 2500.0, 3000.0 ,3500.0]\nfor a in alpha:\n    ridge = linear_model.RidgeClassifier(a)\n    scores = model_selection.cross_val_score(ridge, X_train_tfidf, X_test_tfidf, cv=5, scoring='f1')\n    print(\"alpha: \",a)\n    print(scores)\n    print(np.mean(scores))\n    print('\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"MultinomialNB with TF-IDF"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.naive_bayes import MultinomialNB\nalpha = [175.0, 200.0, 225.0, 250.0, 300.0]\nfor a in alpha:\n    mnb = MultinomialNB(a)\n    scores = model_selection.cross_val_score(mnb, X_train_tfidf, X_test_tfidf, cv=5, scoring='f1')\n    print('alpha: ', a)\n    print(scores)\n    print(np.mean(scores))\n    print('\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Hashing**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.feature_extraction.text import HashingVectorizer\nhv = HashingVectorizer()\nhv.fit(train)\nX_train_hash = hv.fit_transform(train['review'])\nX_test_hash = train['sentiment']\nY_train_hash = hv.transform(test['review'])\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Rigde with Hash"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn import linear_model,model_selection\nalpha = [1.1, 1.2, 1.3, 1.4, 1.5, 2.0]\nfor a in alpha:\n    ridge = linear_model.RidgeClassifier(a)\n    scores = model_selection.cross_val_score(ridge, X_train_hash, X_test_hash, cv=5, scoring='f1')\n    print(\"alpha: \",a)\n    print(scores)\n    print(np.mean(scores))\n    print('\\n')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Bag of words**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(binary=True)\ncv.fit(train)\nX_train_bow = cv.fit_transform(train['review'])\nX_test_bow = train['sentiment']\nY_train_bow = cv.transform(test['review'])\nY_test = test['sentiment']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Rigde with bag of word"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import model_selection  \nfrom sklearn import linear_model\nalpha = [80.0, 90.0, 100.0, 110.0, 120.0]\nfor a in alpha:\n    ridge = linear_model.RidgeClassifier(a)\n    scores = model_selection.cross_val_score(ridge, X_train_bow, X_test_bow, cv=5, scoring='f1')\n    print(\"alpha: \",a)\n    print(scores)\n    print(np.mean(scores))\n    print('\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"MultinomialNB with bag of word"},{"metadata":{"trusted":true},"cell_type":"code","source":"alpha = [1e-10, 1e-5, 0.1, 1.0, 2.0]\nfor a in alpha:\n    mnb = MultinomialNB(a)\n    scores = model_selection.cross_val_score(mnb, X_train_bow, X_test_bow, cv=5, scoring='f1')\n    print('alpha: ', a)\n    print(scores)\n    print(np.mean(scores))\n    print('\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nridge = linear_model.RidgeClassifier(1.4)\nridge.fit(X_train_hash, X_test_hash)\ntest['sentiment_pred'] = ridge.predict(Y_train_hash)\ny_true = test['sentiment']\ny_pred = test['sentiment_pred']\naccuracy_score(y_true, y_pred)\nacc=accuracy_score(y_true, y_pred)\nprint(\"Accuricy score is :  \",acc )\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix \nprint(classification_report(y_true, y_pred, target_names = ['Bad Reviews','Good Reviews']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\ncm = confusion_matrix(y_true, y_pred)\n\n\nprint(cm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nplt.figure(figsize = (8,8))\nsns.heatmap(cm,cmap= \"Blues\", \n            linecolor = 'black', \n            linewidth = 1, \n            annot = True, \n            fmt='', \n            xticklabels = ['Bad Reviews','Good Reviews'], \n            yticklabels = ['Bad Reviews','Good Reviews'])\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"Review\":test['review'],'sentiment':test['sentiment'],'predected sentiment':test['sentiment_pred']}\nimport pandas as pd\nfrom sklearn.utils import shuffle\ndf = pd.DataFrame(d)\ndf.head(15)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}