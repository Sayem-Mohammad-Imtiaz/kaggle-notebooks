{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1><b>Mall Customer Segmentation Data Analysis</b></h1>"},{"metadata":{},"cell_type":"markdown","source":"<h3><b>Content</b></h3>\n<ul>\n    <a href='#1'><li>Introduction</li></a>\n    <a href='#2'><li>Import Library</li></a>\n    <a href='#3'><li>Data Exploratory Analysis</li></a>\n    <a href='#4'><li>Dimensionality Reduction</li></a>\n    <a href='#5'><li>Clustering</li></a>\n    <a href='#6'><li>KMeans</li></a>\n    <a href='#7'><li>Hierarchical Clustering</li></a>\n    <a href='#8'><li>DBSCAN</li></a>\n\n   <a href='#20'><li>References</li></a>\n   <a href='#21'><li>Conclusion</li></a>\n</ul>\n\n<p>Last Updated: <b>30/06/2019</b></p>\n<p><h2>If you like it, please upvote.</h2></p>"},{"metadata":{},"cell_type":"markdown","source":"<p id='1'><h3><b>Introduction</b></h3></p>"},{"metadata":{},"cell_type":"markdown","source":"<p>Hello to everyone,<br>\n<p>This data set was created for the purpose of learning only the customer segmentation concepts, also known as market basket analysis. A wide variety of analyzes will be created in this section. However, each case will be searched and machine learning algorithms will be used.</p>\n\n<p>Column List</p>\n<ul>\n    <li>Customer ID</li>    Unique ID assigned to the customer\n    <li>Gender</li>         Gender of the customer\n    <li>Age</li>            Age of the customer\n    <li>Annual Income</li>  Annual Income of the customee\n    <li>Spending Score</li> Score assigned by the mall based on customer behavior and spending nature\n</ul>\n\n"},{"metadata":{},"cell_type":"markdown","source":"<p id='2'><h3><b>Import Library</b></h3></p>\n<p>We need to install a wide variety of libraries. For this we will install <b>pandas, numpy, seaborn and matplotlib</b> libraries.</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p id='3'><h3><b>Data Exploratory Analysis</b></h3></p>\n<p>In the data discovery analysis, we will firstly recognize and analyze our data using a wide variety of functions in the pandas library.</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"data=pd.read_csv('../input/Mall_Customers.csv')\n#read csv for analysis","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()\n#we'll see the first five lines.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[['Gender','Age']].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.tail()\n#we'll see the last five lines.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.sample(5)\n#random data ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.sample(frac=0.1) \n#random data for frac Ä±t means %","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#it is a process that shows the property value in the data set and shows the numbers in the register values.\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<ul>\n    <li>Count : Shows the total number.</li>\n    <li>Mean  : Shows the average.</li>\n    <li>Std   :  Standard deviation value</li>\n    <li>Min   : Minimum value</li>\n    <li>%25   : First Quantile</li>\n    <li>%50   : Median or Second Quantile</li>\n    <li>%75   : Third Quantile</li>\n    <li>Max   : Maximum value</li>\n</ul>\n\n<p>What is quantile?</p>\n<ul>\n    <li>1,4,5,6,7,11,12,13,14,15,16,17</li>\n    <li>The median is the number that is in middle of the sequence. In this case It would be 11</li>\n    <li>The lower quartile is the median in between the smallest number and the median etc in between 1 and 11, which is 6</li>\n    <li>The upper quartile you find the median between the median and the largest number etc. betweeb 11 and 17,which will be 14 according to the question above.</li>\n</ul>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#It is a function that shows the analysis of numerical values.\ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#It shows the data types in the data set.\ndata.dtypes","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data.columns\n#show data's columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#rename data's columns\ndata.rename(columns={'Annual Income (k$)':'AnnualIncome','Spending Score (1-100)':'SpendingScore'},inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#need to understatand for data's columns\nfor i,col in enumerate(data.columns):\n    print((i+1),'. columns is :',col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#data row and columns count\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#count null values\ndata.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(list(data.isnull().any()))\n#every feature control check null value in this data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#data control null values\ndata.isnull().values.any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#data type control\ndata.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#data correlation\ndata.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.iloc[:,1:].corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(data.corr(),annot=True,fmt='.1f')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#need to drop customerID\ndata.drop('CustomerID',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#show data gender unique\ndata.Gender.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#show gender value counts\ndata.Gender.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#show graph data gender\nsns.countplot(data.Gender)\nplt.title('Gender Count')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels=data.Gender.unique()\ncolors=['gray','red']\nexplode=[0,0.1]\nvalues=data.Gender.value_counts().values\n\n#visualization\nplt.figure(figsize=(7,7))\nplt.pie(values,explode=explode,labels=labels,colors=colors,autopct='%1.1f%%')\nplt.title('Race/Ethnicity According Analysis',color='black',fontsize=10)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25,10))\nsns.barplot(x = \"AnnualIncome\", y = \"SpendingScore\", hue = \"Gender\", data = data)\nplt.xticks(rotation=45)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.hist(figsize=(18,12))\nplt.title('All Data Show Histogram System')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Male Age \nprint('Max  :',max(data[data['Gender']=='Male'].Age))\nprint('Min  :',min(data[data['Gender']=='Male'].Age))\nprint('Mean :',np.mean(data[data['Gender']=='Male'].Age))\nprint('Std  :',np.std(data[data['Gender']=='Male'].Age))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Female Age\nprint('Max  :',max(data[data['Gender']=='Female'].Age))\nprint('Min  :',min(data[data['Gender']=='Female'].Age))\nprint('Mean :',np.mean(data[data['Gender']=='Female'].Age))\nprint('Std  :',np.std(data[data['Gender']=='Female'].Age))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Male Income \nprint('Max  :',max(data[data['Gender']=='Male'].AnnualIncome))\nprint('Min  :',min(data[data['Gender']=='Male'].AnnualIncome))\nprint('Mean :',np.mean(data[data['Gender']=='Male'].AnnualIncome))\nprint('Std  :',np.std(data[data['Gender']=='Male'].AnnualIncome))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Female Age\nprint('Max  :',max(data[data['Gender']=='Female'].AnnualIncome))\nprint('Min  :',min(data[data['Gender']=='Female'].AnnualIncome))\nprint('Mean :',np.mean(data[data['Gender']=='Female'].AnnualIncome))\nprint('Std  :',np.std(data[data['Gender']=='Female'].AnnualIncome))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Male SpendingScore \nprint('Max  :',max(data[data['Gender']=='Male'].SpendingScore))\nprint('Min  :',min(data[data['Gender']=='Male'].SpendingScore))\nprint('Mean :',np.mean(data[data['Gender']=='Male'].SpendingScore))\nprint('Std  :',np.std(data[data['Gender']=='Male'].SpendingScore))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Female SpendingScore\nprint('Max  :',max(data[data['Gender']=='Female'].SpendingScore))\nprint('Min  :',min(data[data['Gender']=='Female'].SpendingScore))\nprint('Mean :',np.mean(data[data['Gender']=='Female'].SpendingScore))\nprint('Std  :',np.std(data[data['Gender']=='Female'].SpendingScore))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Age.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(data.Age.unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Age.value_counts()[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,7))\nsns.barplot(x=data.Age.value_counts().index,y=data.Age.value_counts().values)\nplt.xlabel('Age')\nplt.ylabel('Rate')\nplt.title('Age vs Rate State')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.plotting.scatter_matrix(data,figsize=(10,10))\nplt.figure()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"age_income=[]\nage_unique=data.Age.unique()\nfor age in age_unique:\n    age_income.append(sum(data[data['Age']==age].AnnualIncome))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Age show point plot\nf,ax1=plt.subplots(figsize=(25,10))\nsns.pointplot(x=np.arange(1,52),y=age_income,color='lime',alpha=0.8,label='Income')\nsns.pointplot(x=np.arange(1,52),y=age_unique,color='red',alpha=0.5,label='Age')\nplt.xlabel('Age & Income')\nplt.ylabel('Frequency')\nplt.title('Age & Income for Frequency')\nplt.xticks(rotation=90)\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"age_female_income=[]\nage_male_income=[]\nfor age in age_unique:\n    age_male_income.append(sum(data[np.logical_and(data['Gender']=='Male',data['Age']==age)].AnnualIncome))\n    age_female_income.append(sum(data[np.logical_and(data['Gender']=='Female',data['Age']==age)].AnnualIncome))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.kdeplot(age_female_income,shade=True,color='r')\nsns.kdeplot(age_male_income,shade=True,color='b')\nplt.xlabel('Values')\nplt.ylabel('Frequency')\nplt.title('Age Female & Age Male')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.violinplot(x=data['AnnualIncome'],y=data['Gender'])\nplt.title('AnnualIncome & Gender')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.violinplot(y=data['SpendingScore'],x=data['Gender'])\nplt.title('SpendingScore & Gender')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"age_female_spendingScore=[]\nage_male_spendingScore=[]\nfor age in age_unique:\n    age_male_spendingScore.append(sum(data[np.logical_and(data['Gender']=='Male',data['Age']==age)].SpendingScore))\n    age_female_spendingScore.append(sum(data[np.logical_and(data['Gender']=='Female',data['Age']==age)].SpendingScore))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style='whitegrid')\nsns.boxplot(age_female_spendingScore)\nplt.title('Female Spending Score')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style='whitegrid')\nsns.boxplot(age_male_spendingScore)\nplt.title('Male Spending Score')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['GenderValue']=[ 0 if gender=='Female' else 1 for gender in data.Gender]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['AgesBetween']= pd.cut(data['Age'],5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.AgesBetween.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"age_between=[]\nfor age in data.Age:\n    if((age>=17.948 and age<28.4)):\n        age_between.append(0)\n    elif((age>=28.4 and age<38.8)):\n        age_between.append(1)\n    elif((age>=38.8 and age<49.2)):\n        age_between.append(2)\n    elif((age>=49.2 and age<59.6)):\n        age_between.append(3)\n    elif((age>=59.6 and age<=70.0)):\n        age_between.append(4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(age_between)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"age_between[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"age_between=pd.DataFrame(data=age_between,index=range(0,200),columns=['AgeValueBetween'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=pd.concat([data,age_between],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(data.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(1 , figsize = (15 , 6))\nfor i,col in enumerate(['Age','AnnualIncome','SpendingScore','AgeValueBetween']):\n    i=i+1\n    plt.subplot(2 , 2,i)\n    plt.title(col)\n    sns.distplot(data[col] , bins = 30)\n    plt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,8))\nfor gender in data.Gender.unique():\n    plt.scatter(x='Age',y='AnnualIncome',data=data[data['Gender']==gender],s=100,alpha=.7)\n    plt.xlabel('Age')\n    plt.ylabel('AnnualIncome')\n    plt.title('Age & (AnnualIncome-SpendingScore)')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,8))\nfor gender in data.Gender.unique():\n    plt.scatter(x='Age',y='SpendingScore',data=data[data['Gender']==gender],s=100,alpha=.7)\n    plt.xlabel('Age')\n    plt.ylabel('SpendingScore')\n    plt.title('Age & SpendingScore')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,8))\nfor gender in data.Gender.unique():\n    plt.scatter(x='AnnualIncome',y='SpendingScore',data=data[data['Gender']==gender],s=100,alpha=.7)\n    plt.xlabel('AnnualIncome')\n    plt.ylabel('SpendingScore')\n    plt.title('AnnualIncome & SpendingScore')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data[['Age','AnnualIncome','SpendingScore']])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.factorplot(x=\"Gender\", y=\"AnnualIncome\", kind='violin',data=data)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Age.value_counts()[:3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"AnnualIncome_32=0\nAnnualIncome_35=0\nAnnualIncome_19=0\n\nAnnualIncome_32=sum(data[data['Age']==32].AnnualIncome)\nAnnualIncome_35=sum(data[data['Age']==35].AnnualIncome)\nAnnualIncome_19=sum(data[data['Age']==19].AnnualIncome)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title('First Popular Ages')\nsns.barplot(x=['19','35','32'],y=[AnnualIncome_19,AnnualIncome_35,AnnualIncome_32])\nplt.xlabel('Ages')\nplt.ylabel('Total AnnualIncome')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.factorplot(x=\"Gender\", y=\"SpendingScore\", kind='violin',data=data)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,8))\ndata[data['Gender']=='Male']['AnnualIncome'].value_counts().sort_index().plot.line(color='b')\ndata[data['Gender']=='Female']['SpendingScore'].value_counts().sort_index().plot.line(color='r')\nplt.xlabel('Gender')\nplt.ylabel('AnnualIncome & SpendingScore')\nplt.title('AnnualIncome-SpendingScore vs Frequency')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i,col in enumerate(['Age', 'AnnualIncome', 'SpendingScore','AgeValueBetween']):\n    plt.subplot(2,4,i+1)\n    plt.scatter([i for i in range(200)],data[col].values.tolist())\n    plt.title(col)\n    fig,ax=plt.gcf(),plt.gca()\n    fig.set_size_inches(15,10)\n    plt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.plotting.scatter_matrix(data,figsize=(10,10))\nplt.figure()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p>Good, they are gone now. To implement dimensionality reduction with PCA, I must scale the data.\n\nFor this purpose, I will apply logarithmic scaling on the data.\n\nAdditionally, I will delete some of the data points as they are stated as outliers in my assignment paper.</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(['Gender','AgesBetween'],axis=1,inplace=True)\ndata.drop(['GenderValue','AgeValueBetween'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_data=np.log(data)\ngood_data=log_data.drop([128,65,66,75,154])\ngood_data[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p id='4'><h3><b>Dimensionality Reduction</b></h3></p>\nNow it is time to implement PCA to the data set.\n\nBut, before that, I will investigate the explained variance ratio and resulting principal components:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\npca=PCA().fit(good_data)\nprint(pca.explained_variance_ratio_)\nprint()\nprint(good_data.columns.values.tolist())\nprint(pca.components_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p>First two components seem to cover around 86% of the data.</p>\n<p>To see the variance in a cumulative manner, I will plot a step graph like below:</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"cumulative=np.cumsum(pca.explained_variance_ratio_)\nplt.step([i for i in range(len(cumulative))],cumulative)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p>This plot too shows that 70% of the data can be expressed by the first two principal components.</p>\n\n<p>So, I will apply PCA to the data with number of components = 2.</p>\n\n<p>The reduced data can be seen on the plotting below.</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"pca=PCA(n_components=2)\npca.fit(good_data)\nreduced_data=pca.transform(good_data)\ninverse_data=pca.inverse_transform(reduced_data)\nplt.scatter(reduced_data[:,0],reduced_data[:,1],label='reduced')\nplt.xlabel('First Principal Component')\nplt.ylabel('Second Principal Component')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p>According to the principal components, data points with greater values on the x-axis represent the customers that are less likely to spend to Detergents_Paper category.</p>\n\n<p>Likewise, data points with greater values on the y-axis</p>\n\n<p>Now, I can constitute a DataFrame out of my reduced data with two dimensions:</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"reduced_data=pd.DataFrame(reduced_data,columns=['Dim1','Dim2'])\nreduced_data[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p id='5'><h3><b>Clustering</b></h3></p>\n<p>It is time to cluster the data so that we can extract information from them related to the customer annual spending behaviors.</p>"},{"metadata":{},"cell_type":"markdown","source":"<p id='6'><h3><b>K-Means</b></h3></p>\n<p>I will run K-Means starting from k=2 to k=10.\n\nI will collect the silhouette scores for each of the results. So that I can determine the best number of clusters.</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom matplotlib.colors import LinearSegmentedColormap\n\ncmap=LinearSegmentedColormap.from_list('BlRd',['blue','red','cyan'])\n\nsilhouette_scores=[]\nfor i in range(2,11):\n    cl=KMeans(n_clusters=i,random_state=0)\n    result=cl.fit_predict(reduced_data)\n    silhouette=silhouette_score(reduced_data,result)\n    silhouette_scores.append(silhouette)\n    plt.subplot(5,2,i-1)\n    plt.scatter(reduced_data.Dim1.values,reduced_data.Dim2.values,c=result,cmap=cmap)\n    plt.title(str(i)+' Clusters, Silhouette score :'+ str(silhouette)[:5])\n    fig,ax=plt.gcf(),plt.gca()\n    fig.set_size_inches(10,10)\n    plt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p>So colorful. Now I will plot a graph for the collected silhouette scores:</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot([i for i in range(2,11)],silhouette_scores)\nplt.xlabel('# of clusters')\nplt.ylabel('silhouette score')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p>The best number of clusters seem to be 6 (or maybe 9) or 2 in this case. So, I will save the corresponding plot for the later usage:</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"cl=KMeans(n_clusters=6,random_state=0)\nresult=cl.fit_predict(reduced_data)\nsilhouette=silhouette_score(reduced_data,result)\nplt.scatter(reduced_data.Dim1.values,reduced_data.Dim2.values,c=result,cmap=cmap)\nplt.title(str(2)+' Clusters, Silhouette score :'+str(silhouette)[:5])\nfig,ax=plt.gcf(),plt.gca()\nfig.set_size_inches(5,5)\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans=KMeans(n_clusters=6,init='k-means++',max_iter=300,random_state=0)\ny_kmeans=kmeans.fit_predict(reduced_data)\n\nreduced_data_X=reduced_data.as_matrix(columns=None)\n\nplt.scatter(reduced_data_X[y_kmeans==0,0],reduced_data_X[y_kmeans==0,1],s=100,c='red',label='X')\nplt.scatter(reduced_data_X[y_kmeans==1,0],reduced_data_X[y_kmeans==1,1],s=100,c='blue',label='X')\nplt.scatter(reduced_data_X[y_kmeans==2,0],reduced_data_X[y_kmeans==2,1],s=100,c='gray',label='X')\nplt.scatter(reduced_data_X[y_kmeans==3,0],reduced_data_X[y_kmeans==3,1],s=100,c='black',label='X')\nplt.scatter(reduced_data_X[y_kmeans==4,0],reduced_data_X[y_kmeans==4,1],s=100,c='brown',label='X')\nplt.scatter(reduced_data_X[y_kmeans==5,0],reduced_data_X[y_kmeans==5,1],s=100,c='pink',label='X')\nplt.scatter(kmeans.cluster_centers_[:,0],kmeans.cluster_centers_[:,1],s=300,c='yellow',label='centroids')\nplt.title('clusters of #')\nplt.legend()\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p id='7'><h3><b>Hierarchical Clustering</b></h3></p>\n<p>Here are the results of running hierarchical clustering on the data set. I will try all linkage methods possible to see the differences. Then I will plot dendrograms and clusters side by side.</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.cluster.hierarchy import linkage, dendrogram\nfrom scipy.cluster.hierarchy import fcluster\n\nmethods=['ward','single','complete','average','weighted','centroid','median']\n\nplot_id=0\nfor method in methods:\n    cl=linkage(reduced_data,method=method)\n    \n    for sw in ['dendrogram','clusters']:\n        if sw=='dendrogram':\n            plot_id+=1\n            plt.subplot(7,2,plot_id)\n            plt.title(method)\n            fig,ax=plt.gcf(),plt.gca()\n            dn=dendrogram(cl,truncate_mode='level',p=15)\n            plt.tight_layout()\n            fig.set_size_inches(10,15)\n        else:\n            plot_id+=1\n            labels=fcluster(cl,2,criterion='maxclust')\n            plt.subplot(7,2,plot_id)\n            plt.title(method)\n            plt.scatter(reduced_data.Dim1.values.tolist(),\n                       reduced_data.Dim2.values.tolist(),\n                       cmap=cmap,\n                       c=labels)\nplt.show()            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cl=linkage(reduced_data,method='ward')\nfig,ax=plt.gcf(),plt.gca()\ndn=dendrogram(cl,truncate_mode='level',p=15)\nplt.tight_layout()\nfig.set_size_inches(10,8)\nplt.axhline(y=8,c='k')\nplt.axhline(y=12,c='k')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p>This maximum of 20 seems to be a good distance for clustering. Doing so, we should have 6 clusters. I am saving the plot:</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"cl=linkage(reduced_data,method='ward')\nlabels=fcluster(cl,6,criterion='maxclust')\nplt.scatter(reduced_data.Dim1.values.tolist(),\n           reduced_data.Dim2.values.tolist(),\n           cmap=cmap,\n           c=labels)\nplt.show()\n#plt.savefig('img/hierarchical_fav.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cl=linkage(reduced_data,method='weighted')\nlabels=fcluster(cl,6,criterion='maxclust')\nplt.scatter(reduced_data.Dim1.values.tolist(),\n           reduced_data.Dim2.values.tolist(),\n           cmap=cmap,\n           c=labels)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p id='8'><h3><b>DBSCAN</b></h3></p>\n<p>Here is the toughest one. I will run this algorithm for epsilons 0.3 through 0.9 with step size of 0.2 and for minimum number of samples 3 through 8 with one increment per step.</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import DBSCAN\n\nplot_id=0\nfor eps in np.arange(0.3,0.9,0.2):\n    for min_samples in range(3,9):\n        plot_id+=1\n        cl=DBSCAN(eps=eps,min_samples=min_samples)\n        result=cl.fit_predict(reduced_data)\n        n_clusters=len([c for c in list(set(result)) if c!=-1])\n        plt.subplot(6,4,plot_id)\n        plt.scatter(reduced_data.Dim1.values.tolist(),\n                   reduced_data.Dim2.values.tolist(),\n                   cmap=cmap,\n                   c=result)\n        fig,ax=plt.gcf(),plt.gca()\n        fig.set_size_inches(15,20)\n        plt.title('eps: ' + str(eps)+', min_smp: ' + str(min_samples)+',\\n# of clusters: ' + str(n_clusters))\n        plt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p>None of them resembles the previous results with other algorithms to me.\n\nI think the last one, with one big group at the center may be useful since it groups customers that are like spending together and leaves the ones as outliers.</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"cl=DBSCAN(eps=0.7,min_samples=5)\nresult=cl.fit_predict(reduced_data)\nn_clusters=len([c for c in list(set(result)) if c!=-1])\nplt.scatter(reduced_data.Dim1.values.tolist(),\n           reduced_data.Dim2.values.tolist(),\n           cmap=cmap,\n           c=result)\nfig,ax=plt.gcf(),plt.gca()\nfig.set_size_inches(5,5)\nplt.title('eps :'+str(eps)+'min_smp :'+str(min_samples)+'n# of clusters :'+str(n_clusters))\nplt.tight_layout()\n#plt.savefig('img/dbscan_fav.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p id='20'><h3><b>References</b></h3></p>\n<p>https://www.kaggle.com/spscientist/students-performance-in-exams</p>\n<p>https://seaborn.pydata.org/</p>\n<p>https://www.kaggle.com/kanncaa1/seaborn-tutorial-for-beginners</p>\n<p>https://www.kaggle.com/biphili/seaborn-plot-to-visualize-iris-data</p>"},{"metadata":{},"cell_type":"markdown","source":"<p id='21'><h3><b>Conclusion</b></h3></p>\n<p>As a result, we have explained the seaborn library in a very detailed way and created a wide variety of graphs. If you like it, I expect your support. If you like <b>UPVOTED</b> I would be very happy if you do. If you have any questions, I am ready to answer your questions. At the bottom there are the kernel values that I have already done.</p>\n<p>https://www.kaggle.com/kralmachine/analyzing-the-heart-disease</p>\n<p>https://www.kaggle.com/kralmachine/data-visualization-of-suicide-rates</p>\n<p>https://www.kaggle.com/kralmachine/gradient-admission-eda-ml-0-92</p>\n<p>https://www.kaggle.com/kralmachine/football-results-from-1872-to-2018-datavisulation</p>\n<p>https://www.kaggle.com/kralmachine/pandas-tutorial-for-beginner</p>\n<p>https://www.kaggle.com/kralmachine/visual-analysis-of-world-happiness-in-2015</p>\n\n<p>Now that we have applied three clustering algorithms on the problem, we then interpret the resulting clusters. So that, the wholesale distributor may take necessary actions for each types of customers.</p>"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}