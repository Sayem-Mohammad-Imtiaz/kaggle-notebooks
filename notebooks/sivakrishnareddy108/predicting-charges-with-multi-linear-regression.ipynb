{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn\nimport math\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(r'/kaggle/input/insurance/insurance.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Checking data types of the columns**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['age'].isna().value_counts()\ndf.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def checkNull (data) :\n    columns = data.columns\n    for column in columns :\n        print('****Checking null values for '+ str(column) + ' ****')\n        print(data[column].isna().value_counts())\n        print('****Checking competed*****')\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking null values in the dataframe","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"checkNull(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corrMatrix = df.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (8,6))\nax= fig.add_subplot(111)\nsns.heatmap(corrMatrix,annot=True,ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[['sex','charges']].plot(kind = 'scatter',x='sex',y='charges')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finding out diffrent regions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['region'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking the if different regions have any affect on the charges or not","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['region'] == 'southeast'][['region','charges']].plot(kind='hist',title = 'southeast')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['region'] == 'southwest'][['region','charges']].plot(kind='hist',title = 'southwest')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['region'] == 'northwest'][['region','charges']].plot(kind='hist',title = 'northwest')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['region'] == 'northeast'][['region','charges']].plot(kind='hist',title = 'northeast')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As above seen the distribution is similar in all the regions .So it doesnot have a much of affect on charges. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Now lets check wheather smoking has some affect on charges or not !","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_smoking = df[['smoker','charges']]\n#df_smoker = df_smoking[df_smoking['smoker'] == 'yes']\ndf_smoking['smoker'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are total 274 smokers ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_smoking.replace({'yes' : 1,'no': 0},inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig1 = plt.figure(figsize = (12,6))\nfig1.subplots_adjust(wspace = 0.5)\nax1 = fig1.add_subplot(121)\nsns.boxplot(x='smoker',y='charges',data=df_smoking,palette='rainbow',ax =ax1,showfliers=False)\nax1.set_xticklabels(['Non-Smoker','Somker'])\nax1.set_xlabel('')\nax1.set_ylabel('Insurance Charges')\n\nax1 = fig1.add_subplot(122) \nsns.violinplot(data =df_smoking, x='smoker', y='charges',ax= ax1)\nax1.set_xticklabels(['Non-Smoker','Somker'])\nax1.set_xlabel('')\nax1.set_ylabel('Insurance Charges')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In above box plot and vilion plot we can see that the Average Insurance Amount paid to a non smoker is around $8000 to $9000, where as for smokers the Average Insurance Amount paid is far greater then the non smoker which is nearly $35000.\nSo the Smoker feature is very useful for predicting the insurance charges.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We can also see that the there is a posotive correlation between smoking and charges.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"mat = df_smoking.corr()\nsns.heatmap(mat,annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now lets see If Gender as any impact on insurance amount paid","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_gen = df[['sex','charges']]\nfig2 = plt.figure(figsize = (15,6))\nfig2.subplots_adjust(wspace = 0.5)\nax2 = fig2.add_subplot(121) \nsns.boxplot(data= df_gen,x = 'sex',y='charges',showfliers=False,ax=ax2)\nax2 = fig2.add_subplot(122)\nsns.violinplot(data =df_gen, x='sex', y='charges',ax=ax2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Both males and females have same average Insurance charges ,but for the females the threshold for the 3rd quartile nearly 16000 dollars and for males it is nearly 20000 dollars.I think gender will not have that much of a impact on charges as the smoking habit,but we still consider it as a feature for the model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_gen.replace({'male': 1,'female':0},inplace = True)\ndf_gen.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Correlation is also not that much strong.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Now let prepare the data for our model.By converting the categorical data to numerical.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_model =                  df.replace({\n                                        'southeast':0,\n                                        'northwest':1,\n                                        'southwest':2,\n                                        'northeast':3,\n                                        'male': 1,\n                                        'female':0,\n                                        'yes' : 1,\n                                        'no': 0\n                                         })\ndf_model.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"lets just have a quick look into the heatmap.Here SEX,CHILDREN,REGION have very weak correlation. \nWhere values nearer to +1 or -1 have strong correlation.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"figg = plt.figure(figsize = (10,8))\nax3 = figg.add_subplot(111) \nsns.heatmap(df_model.corr(),annot=True,ax=ax3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's get started with the preparing the test and train data. We will be taking 80% of data for tarining and 20% for with testing. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"total_data_count = df_new_model.shape[0]\ntrain_data_index = round(total_data_count*0.8) -1\ntrain_data = df_new_model.loc[:train_data_index,:]\ntest_data_index = train_data_index +1\ntest_data = df_new_model.loc[test_data_index:,:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we splited our training and testing data.Lets prepare the model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.shape\ntrain_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import linear_model\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error\n#reg = linear_model.LinearRegression() \n#x = df_new_model[['age','sex','bmi','children','smoker','region']]\n#x = df_model[['smoker']]\n#y = df_new_model[['charges']]\n#reg.fit(x,y)\n#print('The coefficients are ',reg.coef_)\n#print('The intercept is ',reg.intercept_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that we trained our model.Now lets test it. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_hat = reg.predict(test_data[['age','sex','bmi','children','smoker','region']])\nprint ('R2 score is ',r2_score(test_data['charges'],y_hat))\nprint('RMSE score is ',math.sqrt(mean_squared_error(test_data['charges'],y_hat)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"R2 score is average only but,RMSE is pretty high which is not right.\nI have to find why ?","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Previously I chnaged the smoker column data for 'Yes' to 1 and 'No' to 0, similarly also chaanged Gender column data for 'Male' to 1 and 'Female' to 0. This is popularly called as label encoding which has some diadvantages.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Now lets use the One Hot Encoding to the change the catgeorical columns into numerical columns using pandas get_dummies method.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_new_model = pd.get_dummies(df,columns=['smoker','sex','region'],prefix =['smoker','sex','region'])\ndf_new_model.head()\n#df_new_model.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"lets quickly check for the correlation.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig_new = plt.figure(figsize = (10,8))\nax_new = fig_new.add_subplot(111) \nsns.heatmap(df_new_model.corr(),annot=True,ax=ax_new)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now you see that we have converted the categorical columns to numerical columns using one hot encoding.Though our number of columns have increased.Lets build our model again and see if we can better score.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"total_data_count = df_new_model.shape[0]\ntrain_data_index = round(total_data_count*0.8) -1\ntrain_data = df_new_model.loc[:train_data_index,:]\ntest_data_index = train_data_index +1\ntest_data = df_new_model.loc[test_data_index:,:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import linear_model\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error\nreg = linear_model.LinearRegression() \nx = df_new_model[['age', 'bmi', 'children','smoker_no', 'smoker_yes',\n       'sex_female', 'sex_male', 'region_northeast', 'region_northwest',\n       'region_southeast', 'region_southwest']]\ny = df_new_model[['charges']]\nreg.fit(x,y)\nprint('The coefficients are ',reg.coef_)\nprint('The intercept is ',reg.intercept_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_hat = reg.predict(test_data[['age', 'bmi', 'children','smoker_no', 'smoker_yes',\n       'sex_female', 'sex_male', 'region_northeast', 'region_northwest',\n       'region_southeast', 'region_southwest']])\nprint ('R2 score is ',r2_score(test_data['charges'],y_hat))\nprint('RMSE score is ',math.sqrt(mean_squared_error(test_data['charges'],y_hat)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Still no significant improvement huh !","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Lets give a try using ploynomial regression.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We will be using multiple ploynomial regression model to check which degree polynomial gives best result.Here I will be using only few features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"total_data_count = df_new_model[['smoker_yes']].shape[0]\ntrain_data_index = round(total_data_count*0.8) -1\ntrain_data = df_new_model.loc[:train_data_index,:]\ntest_data_index = train_data_index +1\ntest_data = df_new_model.loc[test_data_index:,:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import PolynomialFeatures\nfrom sklearn import linear_model\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\n\ndef ployFuntion (degrees,train_data,test_data) :\n    for degree in degrees :\n        poly = PolynomialFeatures(degree)\n        train_x_poly = poly.fit_transform(train_data[['age','bmi','smoker_no', 'smoker_yes']])\n        test_x_poly = poly.fit_transform(test_data[['age','bmi','smoker_no', 'smoker_yes']])\n        reg = linear_model.LinearRegression()\n        reg.fit(train_x_poly,train_data['charges'])\n        y_hat = reg.predict(test_x_poly)\n        print('Degree of polynomial model used :',degree)\n        print ('R2 score is ',r2_score(test_data['charges'],y_hat))\n        print('RMSE score is ',math.sqrt(mean_squared_error(test_data['charges'],y_hat)))\n        print ('MAE score is ',mean_absolute_error(test_data['charges'],y_hat))\n        print ('*****************************')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ployFuntion(degrees = list(range(2,12)),train_data = train_data,test_data =test_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thank you all for giving time to my notebook.You guys can give suggestions in comments on how further I can increase the accuracy of the model.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"I got a suggestion that if I scale the features to smiliar range then it can do some improvement.\nLets scale our variables using StandardScalar. What it does is \nLet is consider feature X  (1,2,3,4,5...)\nAfter applying StandardScalar\nevery element of x will be converted using \nnew_x(i th element) = (x (i th) - mean)/standard deviation\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nstan = StandardScaler()\nstd_charges = stan.fit_transform(df_new_model[['charges']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nstan = StandardScaler()\nstd_bmi = stan.fit_transform(df_new_model[['bmi']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nstan = StandardScaler()\nstd_age = stan.fit_transform(df_new_model[['age']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_new_model['age'] = std_age\ndf_new_model['bmi'] = std_bmi\ndf_new_model['charges'] = std_charges","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So using both polynomial and Multilinear regression we can see that \nfor Polynomial regression at dergee of freedom '9'\nR2 score is  0.7185110926492733\nRMSE score is  0.5437599132780697\nfor Multilinear regression is \nR2 score is  0.7603054934267751\nRMSE score is  0.5017710322215123\n\nwhich is pretty good.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}