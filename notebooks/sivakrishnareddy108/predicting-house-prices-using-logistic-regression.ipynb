{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport numpy as np\n\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_housing = pd.read_csv(\"/kaggle/input/california-housing-prices/housing.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Description of each cloumn**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**longitude** :\tA measure of how far west a house is; a higher value is farther west\n\t\n**latitude**  :\t A measure of how far north a house is; a higher value is farther north\n\t\t\n**housingMedianAge** :\tMedian age of a house within a block; a lower number is a newer building\n\t\n**totalRooms** :  Total number of rooms within a block\n\t\n**totalBedrooms** :\tTotal number of bedrooms within a block\n\t\n**population** : Total number of people residing within a block\n\t\n**households** : Total number of households, a group of people residing within a home unit, for a block\n\t\n**medianIncome** : Median income for households within a block of houses \n\t\n**medianHouseValue** : Median house value for households within a block (measured in US Dollars)\n\t\n","attachments":{},"execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Checking the data types of the columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_housing.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len (df_housing)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_housing['ocean_proximity'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Coverting the column Ocean_proximity to string types seems to be the best as it contains only string values.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_housing['ocean_proximity'] = df_housing['ocean_proximity'].convert_dtypes()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_housing.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets now check if any column contains null values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in df_housing.columns:\n    print(col)\n    print(df_housing[col].isnull().value_counts())\n    print('#####################')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**total_bedrooms** columns have a total of 207 null values which we have remove before used for prediction","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_housing.dropna(inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets check if all the null values are removed or not.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in df_housing.columns:\n    print(col)\n    print(df_housing[col].isnull().value_counts())\n    print('#####################')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We cleared the rows that have null values.Any how before we have 20640 in which we have removed 207 records.That is not a such a significant loss of data though.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Now lets covnvert the **ocean_proximity** to categorical data using one hot encoding.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf_housing = pd.concat([df_housing,pd.get_dummies(df_housing['ocean_proximity'])],axis =1)\ndf_housing.drop('ocean_proximity',axis =1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfigure = plt.figure(figsize=(12,10))\nsns.heatmap(df_housing.corr(),annot =True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we are taking features that have posetive coorelation equal to or greater then 0.1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_housing.corr().loc[\"median_house_value\"] >=0.1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we are taking features that have posetive coorelation equal to or less then then -0.1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_housing.corr().loc[\"median_house_value\"] <=-0.1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So these all feature we will be considering for prediction.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_data=df_housing[['housing_median_age','total_rooms','median_income','median_house_value','<1H OCEAN','NEAR BAY','NEAR OCEAN','INLAND','latitude']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now lets preprocess the data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in ['housing_median_age','total_rooms','median_income','median_house_value','latitude'] :\n    df_data[col] =  df_data[col]/ df_data[col].max() \n  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train, validate, test = np.split(df_data.sample(frac=1), [int(.6*len(df_data)), int(.8*len(df_data))])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_Train = train[['housing_median_age','total_rooms','median_income','<1H OCEAN','NEAR BAY','NEAR OCEAN','INLAND','latitude']]\nY_Train = train[['median_house_value']]\nX_Val =validate[['housing_median_age','total_rooms','median_income','<1H OCEAN','NEAR BAY','NEAR OCEAN','INLAND','latitude']]\nY_Val = validate[['median_house_value']]\nX_Test =test[['housing_median_age','total_rooms','median_income','<1H OCEAN','NEAR BAY','NEAR OCEAN','INLAND','latitude']]\nY_Test = test[['median_house_value']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression \nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\nfrom sklearn.preprocessing import PolynomialFeatures\nimport matplotlib.pyplot as plt \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg_model = LinearRegression().fit(X_Train,Y_Train)\nY_hat_Val = reg_model.predict(X_Val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Mean Squared Error on Validation Set is : \",mean_squared_error(Y_Val,Y_hat_Val))\nprint(\"R2 score on Validation Set is : \",r2_score(Y_Val,Y_hat_Val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_hat_Test = reg_model.predict(X_Test)\nprint(\"Mean Squared Error on Test Set is : \",mean_squared_error(Y_hat_Test,Y_Test))\nprint(\"R2 score on Validation Set is : \",r2_score(Y_hat_Test,Y_Test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_hat_Train = reg_model.predict(X_Train)\nprint(\"Mean Squared Error on Train Set is : \",mean_squared_error(Y_hat_Train,Y_Train))\nprint(\"R2 score on Validation Train is : \",r2_score(Y_hat_Train,Y_Train))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Lets see a plot on how our model learns from data**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_Train = train[['housing_median_age','total_rooms','median_income','<1H OCEAN','NEAR BAY','NEAR OCEAN','INLAND','latitude']]\nY_Train = train[['median_house_value']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plot of how cross validation error varies as we increase the number of training samples gradually.As per the plot we can say that at after 4000 samples the gap the between cross validation and training error went gradually increasing which indicates the presence of high variance.In an ideal case it should decrease. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"But the difference between cross validation and training error is not greater then 0.0030.So I don't think that will effect the performance while making prediction on testing data. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"splited_train_X = np.split(X_Train,13)\nsplited_train_Y = np.split(Y_Train,13)\nerror_list_val =[]\nerror_list_train =[]\ntrain_len_list =[]\ntrain_set_len= 0\nfor X,Y in zip(splited_train_X,splited_train_Y) :\n    train_set_len = train_set_len + len(X)\n    reg_model = LinearRegression().fit(X,Y)\n    \n    y_hat_val = reg_model.predict(X_Val)\n    y_hat_train = reg_model.predict(X)\n    \n    error_list_val.append(mean_squared_error(y_hat_val,Y_Val))\n    error_list_train.append(mean_squared_error(y_hat_train,Y))\n    \n    train_len_list.append(train_set_len)\ndf_error_log_CV = pd.DataFrame({'Number of Training Sample': train_len_list,'Cross Validation Error': error_list_val})\ndf_error_log_Train = pd.DataFrame({'Number of Training Sample': train_len_list,'Training Error': error_list_train})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (8,5))\nax = fig.add_subplot(111)\ndf_error_log_Train.plot(x='Number of Training Sample',y='Training Error',ax=ax)\ndf_error_log_CV.plot(x='Number of Training Sample',y='Cross Validation Error',ax=ax)   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets find out how well does it performs on testing set.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"reg_model = LinearRegression().fit(X,Y)\ny_hat_test = reg_model.predict(X_Test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"MSE values on test set :\",mean_squared_error(y_hat_test,Y_Test))\nprint(\"r2 score on test set :\",r2_score(y_hat_test,Y_Test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Model is predicting is very well with good scores on test set.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Thanks for going through my note book. If you like my note book please give a upvote.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}