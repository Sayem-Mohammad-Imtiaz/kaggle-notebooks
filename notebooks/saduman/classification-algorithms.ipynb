{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"**<h3>INTRODUCTION</h3>**\n* In this kernel, I will compare using sklearn classification algorithms.\n* The data set I use contains information about bank customers.\n\nContent:\n* [Summarize the Dataset](#1)\n* [Train Test separating the Dataset](#2)\n* [Logistic Regression Classification](#3)\n* [K-Nearest Neighbour (KNN) Classification](#4)\n* [Support Vector Machine (SVM) Classification](#5)\n* [Naive Bayes Classification](#6)\n* [Decision Tree Classification](#7)\n* [Random Forest Classification](#8)\n* [Comparison of Algorithms](#8)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt #data visualization\nimport seaborn as sns #data visualization\nimport numpy as np\n\nimport warnings            \nwarnings.filterwarnings(\"ignore\") \n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=1></a>\n**<h3>Summarize the Dataset</h3>**\n* Now it is time to take a look at the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Load dataset\ndata=pd.read_csv('../input/churn-modelling/Churn_Modelling.csv')\n#data includes how many rows and columns\ndata.shape\nprint(\"Our data has {} rows and {} columns\".format(data.shape[0],data.shape[1]))\n#Features name in data\ndata.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#diplay first 5 rows\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"now let's delete the features i think i don't need"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(['RowNumber', 'CustomerId', 'Surname','Geography'], axis=1, inplace=True)\n\n#I replaced Gender feature from Male/Female to 1/0.\ndata.Gender = [1 if each == 'Male' else 0 for each in data.Gender] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking for missing values\nprint('Are there missing values? {}'.format(data.isnull().any().any()))\n#missing value control in features\ndata.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's check the target variable now"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=[5,5])\nsns.set(style='darkgrid')\nax = sns.countplot(x='Exited', data=data, palette='Set2')\ndata.loc[:,'Exited'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"dataset seemed to me unbalanced. Unbalanced data can mislead us in the learning process."},{"metadata":{},"cell_type":"markdown","source":"<a id=2></a>\n**<h3>Train Test separating the Dataset</h3>**\n* Now separete target feature (y) from other features (x_data)."},{"metadata":{"trusted":true},"cell_type":"code","source":"y = data.Exited.values\nx_data = data.drop(['Exited'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#we should normalize our features, features should dominate each other.\nx = (x_data - np.min(x_data)) / (np.max(x_data)-np.min(x_data))\nx.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.10, random_state=42)\n\nprint('x_train shape: ', x_train.shape)\nprint('y_train shape: ', y_train.shape)\nprint('x_test shape: ', x_test.shape)\nprint('y_test shape: ', y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=3></a>\n**<h3>Logistic Regression Classification</h3>**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlr=LogisticRegression()\nlr.fit(x_train,y_train)\n\ny_pred=lr.predict(x_test)\n\nfrom sklearn.metrics import classification_report,confusion_matrix\nlr_cm = confusion_matrix(y_test, y_pred)\nprint(\"confusion matrix:\\n\",lr_cm)\n\nprint('test accuracy: {}'.format(lr.score(x_test,y_test)))\nprint('Classification report: \\n',classification_report(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=4></a>\n**<h3>K-Nearest Neighbour (KNN) Classification</h3>**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#find k value\nfrom sklearn.neighbors import KNeighborsClassifier\n\nscore_list=[]\nfor each in range(1,15):\n    knn2=KNeighborsClassifier(n_neighbors=each)\n    knn2.fit(x_train,y_train)\n    score_list.append(knn2.score(x_test,y_test))\nplt.plot(range(1,15),score_list)\nplt.xlabel(\"k values\")\nplt.ylabel(\"accuracy\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#knn algorithm\n\nknn=KNeighborsClassifier(n_neighbors=13) #n_neighbors=k\nknn.fit(x_train,y_train)\nprediction=knn.predict(x_test)\n\nfrom sklearn.metrics import confusion_matrix\nknn_cm = confusion_matrix(y_test, prediction)\nprint(\"confusion matrix:\\n\",knn_cm)\n\nprint('test accuracy: {}'.format(knn.score(x_test,y_test)))\nprint('Classification report: \\n',classification_report(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=5></a>\n**<h3>Support Vector Machine (SVM) Classification</h3>**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#svm algorithm\nfrom sklearn.svm import SVC\nsvm = SVC(random_state=0)\nsvm.fit(x_train,y_train)\nprediction=svm.predict(x_test)\n\nfrom sklearn.metrics import confusion_matrix\nsvm_cm = confusion_matrix(y_test, prediction)\nprint(\"confusion matrix:\\n\",svm_cm)\n\nprint('test accuracy: {}'.format(svm.score(x_test,y_test)))\nprint('Classification report: \\n',classification_report(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=6></a>\n**<h3>Naive Bayes Classification</h3>**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#naive bayes algorithm\nfrom sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb.fit(x_train,y_train)\nprediction=nb.predict(x_test)\n\nfrom sklearn.metrics import confusion_matrix\nnb_cm = confusion_matrix(y_test, prediction)\nprint(\"confusion matrix:\\n\",nb_cm)\n\nprint('test accuracy: {}'.format(nb.score(x_test,y_test)))\nprint('Classification report: \\n',classification_report(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=7></a>\n**<h3>Decision Tree Classification</h3>**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#desicion tree algorithm\nfrom sklearn.tree import DecisionTreeClassifier\ncart = DecisionTreeClassifier()\ncart.fit(x_train,y_train)\nprediction=cart.predict(x_test)\n\nfrom sklearn.metrics import confusion_matrix\ncart_cm = confusion_matrix(y_test, prediction)\nprint(\"confusion matrix:\\n\",cart_cm)\n\nprint('test accuracy: {}'.format(cart.score(x_test,y_test)))\nprint('Classification report: \\n',classification_report(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=8></a>\n**<h3>Random Forest Classification</h3>**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#desicion tree algorithm\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators=100, random_state=3)\nrf.fit(x_train,y_train)\nprediction=rf.predict(x_test)\n\nfrom sklearn.metrics import confusion_matrix\nrf_cm = confusion_matrix(y_test, prediction)\nprint(\"confusion matrix:\\n\",rf_cm)\n\nprint('test accuracy: {}'.format(rf.score(x_test,y_test)))\nprint('Classification report: \\n',classification_report(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* we can make improvements in our model by playing with hypertuning parameters"},{"metadata":{},"cell_type":"markdown","source":"<a id=9></a>\n**<h3>Comparison of Algorithms</h3>**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = plt.figure(figsize=(15,15))\n\nax1 = fig.add_subplot(3, 3, 1) # row, column, position\nax1.set_title('Logistic Regression Classification')\n\nax2 = fig.add_subplot(3, 3, 2) # row, column, position\nax2.set_title('KNN Classification')\n\nax3 = fig.add_subplot(3, 3, 3)\nax3.set_title('SVM Classification')\n\nax4 = fig.add_subplot(3, 3, 4)\nax4.set_title('Naive Bayes Classification')\n\nax5 = fig.add_subplot(3, 3, 5)\nax5.set_title('Decision Tree Classification')\n\nax6 = fig.add_subplot(3, 3, 6)\nax6.set_title('Random Forest Classification')\n\n\nsns.heatmap(data=lr_cm, annot=True, linewidth=0.7, linecolor='cyan', fmt='.0f', ax=ax1, cmap='BuPu')\nsns.heatmap(data=knn_cm, annot=True, linewidth=0.7, linecolor='cyan', fmt='.0f', ax=ax2, cmap='BuPu')   \nsns.heatmap(data=svm_cm, annot=True, linewidth=0.7, linecolor='cyan', fmt='.0f', ax=ax3, cmap='BuPu')\nsns.heatmap(data=nb_cm, annot=True, linewidth=0.7, linecolor='cyan', fmt='.0f', ax=ax4, cmap='BuPu')\nsns.heatmap(data=cart_cm, annot=True, linewidth=0.7, linecolor='cyan', fmt='.0f', ax=ax5, cmap='BuPu')\nsns.heatmap(data=rf_cm, annot=True, linewidth=0.7, linecolor='cyan', fmt='.0f', ax=ax6, cmap='BuPu')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}