{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"We will perform sentiment analysis with IMDb. The workflow is as follows:\n1. EDA & cleaning\n2. Baseline linear model\n3. LSTM model","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nimport re\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\nimport collections\nimport itertools","metadata":{"execution":{"iopub.status.busy":"2021-08-31T14:06:34.734976Z","iopub.execute_input":"2021-08-31T14:06:34.735398Z","iopub.status.idle":"2021-08-31T14:06:39.744072Z","shell.execute_reply.started":"2021-08-31T14:06:34.735365Z","shell.execute_reply":"2021-08-31T14:06:39.74324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\")\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-31T14:06:39.745645Z","iopub.execute_input":"2021-08-31T14:06:39.745975Z","iopub.status.idle":"2021-08-31T14:06:41.305977Z","shell.execute_reply.started":"2021-08-31T14:06:39.745942Z","shell.execute_reply":"2021-08-31T14:06:41.305206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. EDA & cleaning","metadata":{}},{"cell_type":"code","source":"sns.countplot(df[\"sentiment\"])","metadata":{"execution":{"iopub.status.busy":"2021-08-31T14:06:41.30772Z","iopub.execute_input":"2021-08-31T14:06:41.308044Z","iopub.status.idle":"2021-08-31T14:06:41.485047Z","shell.execute_reply.started":"2021-08-31T14:06:41.308009Z","shell.execute_reply":"2021-08-31T14:06:41.484232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-08-31T14:06:41.486259Z","iopub.execute_input":"2021-08-31T14:06:41.486588Z","iopub.status.idle":"2021-08-31T14:06:41.504872Z","shell.execute_reply.started":"2021-08-31T14:06:41.486562Z","shell.execute_reply":"2021-08-31T14:06:41.50376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is no null data.","metadata":{}},{"cell_type":"markdown","source":"### Text cleaning","metadata":{}},{"cell_type":"code","source":"def preprocessing_text(texts):\n    texts = re.sub(r'<.*?>', '', texts)\n    texts = re.sub(r'[^a-zA-Z]', ' ', texts)\n    return ' '.join(x.lower() for x in texts.split())","metadata":{"execution":{"iopub.status.busy":"2021-08-31T14:06:43.124002Z","iopub.execute_input":"2021-08-31T14:06:43.124338Z","iopub.status.idle":"2021-08-31T14:06:43.128774Z","shell.execute_reply.started":"2021-08-31T14:06:43.124304Z","shell.execute_reply":"2021-08-31T14:06:43.127932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['review_cleaned'] = df['review'].apply(lambda x : preprocessing_text(x))","metadata":{"execution":{"iopub.status.busy":"2021-08-31T14:06:45.309541Z","iopub.execute_input":"2021-08-31T14:06:45.309862Z","iopub.status.idle":"2021-08-31T14:06:53.613219Z","shell.execute_reply.started":"2021-08-31T14:06:45.309831Z","shell.execute_reply":"2021-08-31T14:06:53.612392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Baseline linear model","metadata":{}},{"cell_type":"markdown","source":"Before we build time-consuming neural network model, simple classifier is tried.\nTfidf method is used for text vectorization.","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(df['review_cleaned'], df['sentiment'].map({'negative':0, 'positive':1}))\npipeline = Pipeline([('tfidf', TfidfVectorizer()),\n                    ('lr_clf', LogisticRegression())])\npipeline.fit(X_train, y_train)\n\ny_pred = pipeline.predict(X_test)\n\nprint(classification_report(y_test, y_pred))\n\nsns.heatmap(confusion_matrix(y_test, y_pred), \n            annot=True, fmt='.0f', \n            xticklabels=['Predicted negative', 'Predicted positive'], \n            yticklabels=['Negative', 'Positive'])","metadata":{"execution":{"iopub.status.busy":"2021-08-31T14:18:40.33817Z","iopub.execute_input":"2021-08-31T14:18:40.33854Z","iopub.status.idle":"2021-08-31T14:18:56.189178Z","shell.execute_reply.started":"2021-08-31T14:18:40.33851Z","shell.execute_reply":"2021-08-31T14:18:56.188436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Logistic regression provides 90% accuracy for test set, which is fast and adapted for such large datasets.","metadata":{}},{"cell_type":"markdown","source":"# 3. LSTM model","metadata":{}},{"cell_type":"markdown","source":"To quickly explore LSTM model, we firstly take only 500 characters. That is much faster way than taking full sentences.","metadata":{}},{"cell_type":"code","source":"df['review_cleaned_500'] = df['review_cleaned'].apply(lambda x:x[:500])\n\ndf['review_cleaned_500'][2]","metadata":{"execution":{"iopub.status.busy":"2021-08-31T12:03:36.099868Z","iopub.execute_input":"2021-08-31T12:03:36.100326Z","iopub.status.idle":"2021-08-31T12:03:36.149396Z","shell.execute_reply.started":"2021-08-31T12:03:36.100282Z","shell.execute_reply":"2021-08-31T12:03:36.148451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tokenize & Padding","metadata":{"execution":{"iopub.status.busy":"2021-08-31T02:26:42.678223Z","iopub.execute_input":"2021-08-31T02:26:42.678593Z","iopub.status.idle":"2021-08-31T02:26:42.682801Z","shell.execute_reply.started":"2021-08-31T02:26:42.678565Z","shell.execute_reply":"2021-08-31T02:26:42.681705Z"}}},{"cell_type":"markdown","source":"Let's convert tokens to ID. We will use keras Tokenizer which can filter punctuations and take only most-counted 10000 words.","metadata":{}},{"cell_type":"code","source":"tokenizer = Tokenizer(num_words=10000)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T12:03:44.927766Z","iopub.execute_input":"2021-08-31T12:03:44.928093Z","iopub.status.idle":"2021-08-31T12:03:44.932248Z","shell.execute_reply.started":"2021-08-31T12:03:44.928063Z","shell.execute_reply":"2021-08-31T12:03:44.931023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.fit_on_texts(df['review_cleaned_500'])\nseq = tokenizer.texts_to_sequences(df['review_cleaned_500'])\nX = pad_sequences(seq, padding='post')\n\nprint(f'X_shape: {X.shape}, X_min: {np.min(X)}, X_max: {np.max(X)}')","metadata":{"execution":{"iopub.status.busy":"2021-08-31T12:03:45.575591Z","iopub.execute_input":"2021-08-31T12:03:45.575968Z","iopub.status.idle":"2021-08-31T12:03:52.93514Z","shell.execute_reply.started":"2021-08-31T12:03:45.575936Z","shell.execute_reply":"2021-08-31T12:03:52.934211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Sentiment is converted to 0 (negative) or 1 (positive).","metadata":{}},{"cell_type":"code","source":"y = df['sentiment'].map({'negative' : 0, 'positive' : 1}).values","metadata":{"execution":{"iopub.status.busy":"2021-08-31T12:03:52.936595Z","iopub.execute_input":"2021-08-31T12:03:52.937127Z","iopub.status.idle":"2021-08-31T12:03:52.947797Z","shell.execute_reply.started":"2021-08-31T12:03:52.937088Z","shell.execute_reply":"2021-08-31T12:03:52.947078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's build the simple LSTM model using first 500 characters datasets.","metadata":{}},{"cell_type":"code","source":"X_train_valid, X_test, y_train_valid, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nX_train, X_valid, y_train, y_valid = train_test_split(X_train_valid, y_train_valid, test_size=0.2, random_state=42)\nprint(X_train.shape, X_valid.shape, X_test.shape, y_train.shape, y_valid.shape, y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T12:03:55.096436Z","iopub.execute_input":"2021-08-31T12:03:55.096811Z","iopub.status.idle":"2021-08-31T12:03:55.12873Z","shell.execute_reply.started":"2021-08-31T12:03:55.096779Z","shell.execute_reply":"2021-08-31T12:03:55.127893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train","metadata":{"execution":{"iopub.status.busy":"2021-08-31T12:03:59.360544Z","iopub.execute_input":"2021-08-31T12:03:59.360895Z","iopub.status.idle":"2021-08-31T12:03:59.365923Z","shell.execute_reply.started":"2021-08-31T12:03:59.360865Z","shell.execute_reply":"2021-08-31T12:03:59.365098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embed_size = 64\nmodel = keras.models.Sequential([\n    keras.layers.Embedding(input_dim=10000, output_dim=embed_size, input_shape=[None], mask_zero=True),\n    keras.layers.LSTM(64),\n    keras.layers.Dense(1, activation='sigmoid')\n])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-08-31T12:04:02.825288Z","iopub.execute_input":"2021-08-31T12:04:02.825629Z","iopub.status.idle":"2021-08-31T12:04:05.450022Z","shell.execute_reply.started":"2021-08-31T12:04:02.825594Z","shell.execute_reply":"2021-08-31T12:04:05.449188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer =keras.optimizers.Adam(learning_rate=0.001)\nmodel.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\nhistory = model.fit(X_train, y_train, batch_size=32, epochs=5, validation_data=(X_valid, y_valid))","metadata":{"execution":{"iopub.status.busy":"2021-08-31T12:04:05.494039Z","iopub.execute_input":"2021-08-31T12:04:05.494301Z","iopub.status.idle":"2021-08-31T12:05:25.136358Z","shell.execute_reply.started":"2021-08-31T12:04:05.494273Z","shell.execute_reply":"2021-08-31T12:05:25.135576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(history.history).plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This simple model is overfitted with training data as the validation loss increases.","metadata":{}},{"cell_type":"code","source":"y_pred = model.predict_classes(X_test)\n\nprint(classification_report(y_test, y_pred))\n\nsns.heatmap(confusion_matrix(y_test, y_pred), \n            annot=True, fmt='.0f', \n            xticklabels=['Predicted negative', 'Predicted positive'], \n            yticklabels=['Negative', 'Positive'])","metadata":{"execution":{"iopub.status.busy":"2021-08-31T11:52:36.176498Z","iopub.execute_input":"2021-08-31T11:52:36.176838Z","iopub.status.idle":"2021-08-31T11:52:38.385569Z","shell.execute_reply.started":"2021-08-31T11:52:36.176808Z","shell.execute_reply":"2021-08-31T11:52:38.384767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modified LSTM model","metadata":{}},{"cell_type":"markdown","source":"We added Dropout layers to prevent overfitting.","metadata":{}},{"cell_type":"code","source":"embed_size = 64\nmodel_v2 = keras.models.Sequential([\n    keras.layers.Embedding(input_dim=10000, output_dim=embed_size, input_shape=[None], mask_zero=True),\n    keras.layers.SpatialDropout1D(0.2),\n    keras.layers.LSTM(64, return_sequences=False, dropout=0.2, recurrent_dropout=0.2),\n    keras.layers.Dense(1, activation='sigmoid')\n])\nmodel_v2.summary()","metadata":{"execution":{"iopub.status.busy":"2021-08-31T12:05:39.727259Z","iopub.execute_input":"2021-08-31T12:05:39.727605Z","iopub.status.idle":"2021-08-31T12:05:39.869743Z","shell.execute_reply.started":"2021-08-31T12:05:39.727573Z","shell.execute_reply":"2021-08-31T12:05:39.868749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping_cb = keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\noptimizer = keras.optimizers.Adam(learning_rate=0.0001)\nmodel_v2.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\nhistory = model_v2.fit(X_train, y_train, epochs=20, batch_size=64, validation_data=(X_valid, y_valid), callbacks=[early_stopping_cb])","metadata":{"execution":{"iopub.status.busy":"2021-08-31T12:06:29.971037Z","iopub.execute_input":"2021-08-31T12:06:29.971363Z","iopub.status.idle":"2021-08-31T12:22:18.472824Z","shell.execute_reply.started":"2021-08-31T12:06:29.971333Z","shell.execute_reply":"2021-08-31T12:22:18.471982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(history.history).plot()","metadata":{"execution":{"iopub.status.busy":"2021-08-31T12:32:45.464225Z","iopub.execute_input":"2021-08-31T12:32:45.464576Z","iopub.status.idle":"2021-08-31T12:32:45.660618Z","shell.execute_reply.started":"2021-08-31T12:32:45.464539Z","shell.execute_reply":"2021-08-31T12:32:45.659669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looks better than first model.","metadata":{"execution":{"iopub.status.busy":"2021-08-31T13:52:44.777289Z","iopub.execute_input":"2021-08-31T13:52:44.777685Z","iopub.status.idle":"2021-08-31T13:52:44.789145Z","shell.execute_reply.started":"2021-08-31T13:52:44.777606Z","shell.execute_reply":"2021-08-31T13:52:44.787712Z"}}},{"cell_type":"code","source":"y_pred = model_v2.predict_classes(X_test)\n\nprint(classification_report(y_test, y_pred))\n\nsns.heatmap(confusion_matrix(y_test, y_pred), \n            annot=True, fmt='.0f', \n            xticklabels=['Predicted negative', 'Predicted positive'], \n            yticklabels=['Negative', 'Positive'])","metadata":{"execution":{"iopub.status.busy":"2021-08-31T12:33:18.06034Z","iopub.execute_input":"2021-08-31T12:33:18.060694Z","iopub.status.idle":"2021-08-31T12:33:27.121198Z","shell.execute_reply.started":"2021-08-31T12:33:18.060662Z","shell.execute_reply":"2021-08-31T12:33:27.120265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Use of full-sentences would increase accurcy. But it is time-consuming and seems difficult to overwhelm simple Logistic regression model.","metadata":{}}]}