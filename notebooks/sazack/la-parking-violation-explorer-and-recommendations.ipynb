{"cells":[{"metadata":{"_uuid":"2cae879d9bd2ee3f96cfef4ee6adf999c8d6478b"},"cell_type":"markdown","source":"**You can find the descriptive blog post regarding this kernel [here](https://www.linkedin.com/pulse/la-parking-roulette-data-science-approach-solving-sajak-upadhyaya/)**"},{"metadata":{"_uuid":"ed5ba597f24b795eda182270152ec444f33c8b2b","trusted":false},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport requests\nimport datetime as dt\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport folium\nfrom pyproj import Proj,transform\nfrom folium.plugins import FastMarkerCluster\nfrom folium.plugins import MarkerCluster\nfrom sklearn.cluster import DBSCAN","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"86c13e4cc6935e70bf4627bf04e6cc52e4cc9ea3","trusted":false},"cell_type":"code","source":"dataframe = pd.read_csv('../input/parking-citations.csv',nrows=50000)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dbf78fc7a61c7fa72cef67d2e26d41ab598556cc","trusted":false},"cell_type":"code","source":"dataframe.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"efac6ed5b3d15fcd5d636ad1a0a9d2e35b4d0cd9"},"cell_type":"markdown","source":"Since our primary focus is the location and type of violation along with the fine amount, we can disregard information such as Marked date and time, Plate expiry date, VIN, Make, Body style etc. We would keep the fine amount to get a sense of the amount of money being collected as fine to get a better idea on financial scale."},{"metadata":{"_uuid":"97418254ad55b5f505159caf6fa8bbf8c2457f5f","trusted":false},"cell_type":"code","source":"dataframe = dataframe.drop(['Ticket number','Meter Id','Marked Time','RP State Plate','Plate Expiry Date','Make','VIN','Body Style','Color','Route','Agency'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"36e12cf3bb58a32a45273c8830ee778a600fbec6"},"cell_type":"markdown","source":"As we can see, we have dates and times on a timestamp and a 24 hour format. So the next thing we do is to see the data types of each column and try to convert it into a suitable form fo our analysis."},{"metadata":{"_uuid":"180dc519e7b1d224fa88157c61fbe44820358da3","trusted":false},"cell_type":"code","source":"dataframe.dtypes","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6ecd9ae15112fac69de16b4fdf11f174af3383df"},"cell_type":"markdown","source":"Since the date in the column is in IS08601 standard and we only need the year,month and the day,we are going to parse it to remove the time part from the data."},{"metadata":{"_uuid":"8d9ed4fa5125e1821cfcb2d1f30e1bb30e3a58df","trusted":false},"cell_type":"code","source":"dataframe['Issue Date'] = pd.to_datetime(dataframe['Issue Date'], dayfirst=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f5c064407a3c839411bcc00b2a9c88d66c6051d2","trusted":false},"cell_type":"code","source":"dataframe = dataframe.sort_values(by='Issue Date')\ndataframe.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6cbad9230a777e5b2f0e0a54feca9d049a73fcb8"},"cell_type":"markdown","source":"The next thing for us would be to conver the issue time from a 24 hour format and a float data type."},{"metadata":{"_uuid":"c71488d646a750ddf7eb952a2a752ef15859b33d","trusted":false},"cell_type":"code","source":"dataframe['Issue time'].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3bd7da8cde59d16bf9f1d1ca396023018ae54ce5","trusted":false},"cell_type":"code","source":"dataframe = dataframe.dropna(subset=['Issue time'])\ndataframe['Issue time'] = dataframe['Issue time'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"69e6963b12c2a8c3d686b6dc95d93d58dd05f3a1","trusted":false},"cell_type":"code","source":"dataframe['Issue time'] = dataframe['Issue time'].apply(str)\nfor i,time in enumerate(dataframe['Issue time']):\n#     print(time)\n    length = len(time)\n    if(length==1):\n        time=\"000\"+ time\n    elif(length==2):\n        time = \"00\" + time\n    elif(length==3):\n        time = \"0\"+ time\n    else:\n        time = time\n#       \n    dataframe.at[i,\"Issue time\"] = time\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"725e4a63bea385b8cdfc1161ac27438a6bf12351","trusted":false},"cell_type":"code","source":"# dataframe = dataframe[dataframe['Issue time'].str.contains(':')]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cf847619c6eaf39853cb5c1ca51ec2709a2cfeaa","trusted":false},"cell_type":"code","source":"dataframe['Issue time']=pd.to_datetime(dataframe['Issue time'],format ='%H%M').dt.time","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fcf015b3d5c382cd275ace0d21ae2b55fd017f0d","trusted":false},"cell_type":"code","source":"dataframe.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5ddf5caccdbec6dfb6a91593ab6a6206c09d88ab"},"cell_type":"markdown","source":"We now try to bring a hypothesis into our analysis. We pick a specific time duration which is considered to be a rush hour and try to see if the count of parking citations are in any way correlated to the number of citations."},{"metadata":{"_uuid":"981463e1787350ffeccf232d440c72122b0f4395","trusted":false},"cell_type":"code","source":"from datetime import time\nmsrush = time(5,0,0)\nmerush = time(10,0,0)\nesrush = time(16,0,0)\neerush = time(21,0,0)\nprint(msrush)\nprint(merush)\nprint(esrush)\nprint(eerush)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5972ff462478187b511812d519a1dcb81a299ab8","trusted":false},"cell_type":"code","source":"dataframe['Rush hour'] = np.where(((dataframe['Issue time']>msrush) & (dataframe['Issue time']<merush)) | ((dataframe['Issue time']>esrush) & (dataframe['Issue time']<eerush)),\"1\",\"0\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b69089e22d0d3f51f91c31db74d2fedd79cda40c","trusted":false},"cell_type":"code","source":"dataframe.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"55782b03feb3483ae416802d9fb66232cbc7e1ce"},"cell_type":"markdown","source":"Exploring more into the database we now try to look various types of violation code and the number of offences commited."},{"metadata":{"_uuid":"9eeccb1c1d693a30c9fd48bf03cfc0ad9e831b86","trusted":false},"cell_type":"code","source":"counts = pd.DataFrame(dataframe['Violation code'].value_counts())\ncounts.plot(kind='bar',figsize=(20,15),fontsize=12)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"11ffdfd9b23d912654753ab944c9dbb01b253a37","trusted":false},"cell_type":"code","source":"print(\"The top 10 Violations are:\")\ncounts[0:10].plot(kind='bar',figsize=(20,15))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5bd5bf98d2c037a2d34cd1db2ed65127cef11ac2"},"cell_type":"markdown","source":"We now compare the number of rush hour violation to the number of number of non rush hour violation"},{"metadata":{"_uuid":"855016d38b70f3ec9dd1f8d739a5fdbf4b57991a","trusted":false},"cell_type":"code","source":"RushDF = pd.DataFrame(dataframe['Rush hour'].value_counts())\nRushDF.index=['No Rush','Rush']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2d7f03a868bfb7c52cfebbe6412edd67b43ea39e","trusted":false},"cell_type":"code","source":"RushDF.plot(kind='bar', title =\"Rush Hour Vs No Rush\",figsize=(15,8))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dbdfc0278ce4faebfe741ed2cae7511661015717"},"cell_type":"markdown","source":"As we can see some of the Fine amount have NaN as the value, our next approach would be to deal with those values. There are multiple ways to deal with this. One of the option would be to remove the values with NaN out of our analysis but it might lead us to miss out on other important information. Another way to handle the day, which we are going to use is to fill the NaN with the average fine across the parking citations."},{"metadata":{"_uuid":"983fd383af601ac45961afac97ca51a798f1e906","trusted":false},"cell_type":"code","source":"n_rows = dataframe.shape[0]\nmeanFine = dataframe['Fine amount'].mean()\nprint(meanFine)\nfor i in range(0,n_rows):\n    if np.isnan(dataframe['Fine amount'][i]) == True:\n        dataframe['Fine amount'][i] = meanFine","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4b53f4dee95921b91f229a7f96bf67ba94b49d02","trusted":false},"cell_type":"code","source":"dataframe = dataframe.dropna()\ndataframe.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e0ac879c4211c07ab69195d3c178f415f8826c32","trusted":false},"cell_type":"code","source":"dataframe['Fine amount'] = dataframe['Fine amount'].round(0).astype(int)\nrushfine = dataframe[dataframe['Rush hour'] ==\"0\"]['Fine amount'].values.sum()\nnrushfine = dataframe[dataframe['Rush hour'] ==\"1\"]['Fine amount'].values.sum()\nprint(\"Total Amount spent in Fines:\", rushfine + nrushfine )\nfineDF = pd.DataFrame([rushfine,nrushfine])\nfineDF.index=['Rush Hour','Non Rush Hour']\nfineDF.columns=['Amoount']\nfineDF.plot(kind = 'barh', figsize=(15,10), title=\"Rush Hour V/S Non Rush Hour Fine\", fontsize=14)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4636df0c163a919b60e9321a4b90d2d410733b87","trusted":false},"cell_type":"code","source":"start2013 = dt.datetime(2013,1,1)\nend2013 = dt.datetime(2013,12,31)\nstart2014 = dt.datetime(2014,1,1)\nend2014 = dt.datetime(2014,12,31)\nstart2015 = dt.datetime(2015,1,1)\nend2015 = dt.datetime(2015,12,31)\nstart2016 = dt.datetime(2016,1,1)\nend2016 = dt.datetime(2016,12,31)\nstart2017 = dt.datetime(2017,1,1)\nend2017 = dt.datetime(2017,12,31)\n# print(start2015,end2015)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"45893f7321fef2da73b2b62d8d42618a70df93f8","trusted":false},"cell_type":"code","source":"dataframe.dtypes","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a6f30b57a8739ada5cc74c9efb8494da2cd11f48","scrolled":true,"trusted":false},"cell_type":"code","source":"data2013 = dataframe[(dataframe['Issue Date']> start2013) & (dataframe['Issue Date']<= end2013)].shape[0]\ndata2014 = dataframe[(dataframe['Issue Date']> start2014) & (dataframe['Issue Date']<= end2014)].shape[0]\ndata2015 = dataframe[(dataframe['Issue Date']> start2015) & (dataframe['Issue Date']<= end2015)].shape[0]\ndata2016 = dataframe[(dataframe['Issue Date']> start2016) & (dataframe['Issue Date']<= end2016)].shape[0]\ndata2017 = dataframe[(dataframe['Issue Date']> start2017) & (dataframe['Issue Date']<= end2017)].shape[0]\n\nyearDF = pd.DataFrame([data2013,data2014,data2015,data2016,data2017])\nyearDF.index =(['2013','2014','2015','2016','2017'])\nyearDF.columns =(['Violation Counts'])\n\nyearDF.plot(kind= 'bar', figsize=(15,8))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2d1b0214f452181f7bf929d98788c869c4a5b552"},"cell_type":"markdown","source":"If you notice the Dataframe, the Latitude and Longitude are given on a in US Feet coordinates according to the NAD_1983_StatePlane_California_V_FIPS_0405_Feet projection. If we try and convert that, every entry with value 99999.0 lies somewhere in the Pacific ocean. So to ease our job in hand, we decided to proceed with only those coordinates whose lat long are not 99999."},{"metadata":{"_uuid":"a93bc85ff128f9a3404e7accbc020b9b0c582618","trusted":false},"cell_type":"code","source":"dataframe = dataframe[dataframe['Latitude'] != 99999.0]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ed726ea5ea7f45a8b7564187bea48d9c9f631a24","trusted":false},"cell_type":"code","source":"dataframe.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5c3ce240af76c0eba2a0f569480ac9a61ff15d9c","trusted":false},"cell_type":"code","source":"dataframe.head()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c0b3f9e538db582daea45a0390b587c2a26884f1","trusted":false},"cell_type":"code","source":"LAmap = folium.Map(location=[34.0522,-118.2437],zoom_start=10)\n# LAmap","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fcfba27add80baab9266b722344ec93b67a5b54d","trusted":false},"cell_type":"code","source":"pm = '+proj=lcc +lat_1=34.03333333333333 +lat_2=35.46666666666667 +lat_0=33.5 +lon_0=-118 +x_0=2000000 ' \\\n     '+y_0=500000.0000000002 +ellps=GRS80 +datum=NAD83 +to_meter=0.3048006096012192 +no_defs'\n\n# convert to lat/long\nx_in,y_in = dataframe['Latitude'].values, dataframe['Longitude'].values\ndataframe['Longitude'],dataframe['Latitude'] = transform(Proj(pm, preserve_units = True), Proj(\"+init=epsg:4326\"), x_in,y_in)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c240f3b382dc4ff361eebcd6cc88e601d92f7777","trusted":false},"cell_type":"code","source":"dataframe.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5d1f2eef193b158d055143f0cb9ac0bfff483a0e","trusted":false},"cell_type":"code","source":"mc = MarkerCluster()\nfor row in dataframe.itertuples():\n    mc.add_child(folium.Marker(location =[row.Latitude,row.Longitude],popup = row.Location))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"be51100a2226896f6ce9105c90cbe32279bbcfb5","scrolled":false,"trusted":false},"cell_type":"code","source":"LAmap.add_child(mc)\nLAmap","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"18145a5284c3c2a10fc97b8f6001ec5656b1a8a9","trusted":false},"cell_type":"code","source":"df_top_frequency = dataframe.groupby(['Location','Latitude', 'Longitude'])['Location'].agg(\n    {\"counts\": len}).sort_values(\n    \"counts\", ascending=False).head(10).reset_index()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0cfc76d7770fb56bc68d9dd164a16c76a26ee410","trusted":false},"cell_type":"code","source":"df_top_frequency.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9ebc09057d9083a7cd56856f7189631432f4424d"},"cell_type":"markdown","source":"The functions below leverages the Places API from Foursquare. Unfortunately I have not been able to make requests through kaggle, but it works if you download the kernel and run it on your local machine. Feel free to try."},{"metadata":{"_uuid":"6c60442bc47b2a143d864983b1104545c3b76439","trusted":false},"cell_type":"code","source":"CLIENT_ID = 'CNUE4BESOB1KV2MHPXRIE10RLRKXQCFOHYE2MCTS3MJSDUVI' # your Foursquare ID\nCLIENT_SECRET = 'UP3N3DIWT25YMXJ4NLEPMKOZYY4VPRBSLWRCFDAKNSOZVTUT' # your Foursquare Secret\nVERSION = '20190131' # Foursquare API version\n\nprint('Your credentails:')\nprint('CLIENT_ID: ' + CLIENT_ID)\nprint('CLIENT_SECRET:' + CLIENT_SECRET)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"588a7647df22ac42ed0bf970cb6d896d28f805f8","trusted":false},"cell_type":"code","source":"LIMIT=20\nradius = 500\ncategoryId = '4c38df4de52ce0d596b336e1'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"04219991c5a5009fd6e20f73966918baf98ce34e","trusted":false},"cell_type":"code","source":"def getNearbyVenues(names, latitudes, longitudes, radius=500):\n    \n    venues_list=[]\n    for name, lat, lng in zip(names, latitudes, longitudes):\n        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n            CLIENT_ID, \n            CLIENT_SECRET, \n            VERSION, \n            lat, \n            lng, \n            radius, \n            LIMIT)\n            \n        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n\n        venues_list.append([(\n            name, \n            v['venue']['name'], \n            v['venue']['location']['lat'], \n            v['venue']['location']['lng'],\n            v['venue']['location']['distance'],  \n            v['venue']['categories'][0]['name']) for v in results])\n\n    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n    nearby_venues.columns = ['Neighborhood', \n#                   'Neighborhood Latitude', \n#                   'Neighborhood Longitude', \n                  'Venue', \n                  'Venue Latitude', \n                  'Venue Longitude',\n                    'Distance',\n                  'Venue Category']\n    \n    return(nearby_venues)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5a7a9f367a2386c24adcfa723fa7fa6e8cc9a659","trusted":false},"cell_type":"code","source":"countparkings = getNearbyVenues(names=df_top_frequency['Location'],\n                                   latitudes=df_top_frequency['Latitude'],\n                                   longitudes=df_top_frequency['Longitude']\n                                  )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d85d2fdfc09f104c2ecb3efc41af911326d3ecd3"},"cell_type":"markdown","source":"Here we calculate the number of parking lots in each of the neighborhood from the highest number of violating."},{"metadata":{"_uuid":"fbec954c7e5deb20289f69d5ceaf03e0c373e351","trusted":false},"cell_type":"code","source":"df_top_freq = countparkings.groupby(['Neighborhood'])['Neighborhood'].agg(\n    {\"counts_parking\": len}).sort_values(\n    \"counts_parking\", ascending=False).head(10).reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"5f104f7c2d01661886f490a0bd66003ff1c80bae"},"cell_type":"code","source":"df_top_freq = df_top_freq.rename(index=str, columns={'Neighborhood':'Location'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"e9958bd89ad456f5fe93067b6453c295e84619c1"},"cell_type":"code","source":"finalDF = df_top_freq.merge(df_top_frequency)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"6c3394bb34e1e53147d575fdb6e2c97686cbd196"},"cell_type":"code","source":"finalDF.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"58fc1d2819e2408fbb27bd65719d9e097415d99a"},"cell_type":"code","source":"plt.scatter(finalDF['counts_parking'],finalDF['counts'])\nplt.xlabel(\"Number of Parking\")\nplt.ylabel(\"Number of offenses\")\nplt.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"9159335459e2fbbe7f183fbf750d3094efaad707"},"cell_type":"code","source":"finalDF['ratio'] = finalDF['counts'] / finalDF['counts_parking']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"f740e461dca53220479246796335d384632b056c"},"cell_type":"code","source":"finalDF.head(100)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ea19459b0263496f784ede5bec5920bb20812004"},"cell_type":"markdown","source":"Now that we have our final table with the ratio of parking tickets to number of parking space, we can now pick the worst location and conclude that we need a new parking lot in the neighborhood."},{"metadata":{"trusted":false,"_uuid":"3993330900cc7952e7cdc69a0fdd0a8fdf5f6642"},"cell_type":"code","source":"print(finalDF.loc[finalDF['ratio'].idxmax()])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}