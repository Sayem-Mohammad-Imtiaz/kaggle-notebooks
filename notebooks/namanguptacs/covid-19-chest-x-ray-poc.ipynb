{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install imutils\n# !pip install -U segmentation-models==0.2.1\n# !pip install keras==2.3.1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import VGG16,DenseNet121,ResNet50\nfrom tensorflow.keras.layers import Conv2D, SeparableConv2D, MaxPool2D, LeakyReLU, Activation, LSTM, ConvLSTM2D, Lambda, Reshape, BatchNormalization, Bidirectional\nfrom tensorflow.keras.layers import AveragePooling2D,MaxPooling2D,UpSampling2D,concatenate,Conv2DTranspose\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom imutils import paths\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport random\nimport shutil\nimport cv2\nimport os","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"dataset_path = './dataset'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Build a Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%bash\nrm -rf dataset\nmkdir -p dataset/covid\nmkdir -p dataset/normal","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"samples = 50","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"covid_dataset_path = '../input/covid-chest-xray'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# construct the path to the metadata CSV file and load it\ncsvPath = os.path.sep.join([covid_dataset_path, \"metadata.csv\"])\ndf = pd.read_csv(csvPath)\n\n# loop over the rows of the COVID-19 data frame\nfor (i, row) in df.iterrows():\n    # if (1) the current case is not COVID-19 or (2) this is not\n    # a 'PA' view, then ignore the row\n    if row[\"finding\"] != \"COVID-19\" or row[\"view\"] != \"PA\":\n        continue\n\n    # build the path to the input image file\n    imagePath = os.path.sep.join([covid_dataset_path, \"images\", row[\"filename\"]])\n\n    # if the input image file does not exist (there are some errors in\n    # the COVID-19 metadeta file), ignore the row\n    if not os.path.exists(imagePath):\n        continue\n\n    # extract the filename from the image path and then construct the\n    # path to the copied image file\n    filename = row[\"filename\"].split(os.path.sep)[-1]\n    outputPath = os.path.sep.join([f\"{dataset_path}/covid\", filename])\n\n    # copy the image\n    shutil.copy2(imagePath, outputPath)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pneumonia_dataset_path ='../input/chest-xray-pneumonia/chest_xray'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"basePath = os.path.sep.join([pneumonia_dataset_path, \"train\", \"NORMAL\"])\nimagePaths = list(paths.list_images(basePath))\n\n# randomly sample the image paths\nrandom.seed(42)\nrandom.shuffle(imagePaths)\nimagePaths = imagePaths[:samples]\n\n# loop over the image paths\nfor (i, imagePath) in enumerate(imagePaths):\n    # extract the filename from the image path and then construct the\n    # path to the copied image file\n    filename = imagePath.split(os.path.sep)[-1]\n    outputPath = os.path.sep.join([f\"{dataset_path}/normal\", filename])\n\n    # copy the image\n    shutil.copy2(imagePath, outputPath)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ceildiv(a, b):\n    return -(-a // b)\n\ndef plots_from_files(imspaths, figsize=(10,5), rows=1, titles=None, maintitle=None):\n    \"\"\"Plot the images in a grid\"\"\"\n    f = plt.figure(figsize=figsize)\n    if maintitle is not None: plt.suptitle(maintitle, fontsize=10)\n    for i in range(len(imspaths)):\n        sp = f.add_subplot(rows, ceildiv(len(imspaths), rows), i+1)\n        sp.axis('Off')\n        if titles is not None: sp.set_title(titles[i], fontsize=16)\n        img = plt.imread(imspaths[i])\n        plt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"normal_images = list(paths.list_images(f\"{dataset_path}/normal\"))\ncovid_images = list(paths.list_images(f\"{dataset_path}/covid\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plots_from_files(normal_images, rows=5, maintitle=\"Normal X-ray images\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plots_from_files(covid_images, rows=5, maintitle=\"Covid-19 X-ray images\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# initialize the initial learning rate, number of epochs to train for,\n# and batch size\nINIT_LR = 1e-3\nEPOCHS = 10\nBS = 8","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# grab the list of images in our dataset directory, then initialize\n# the list of data (i.e., images) and class images\nprint(\"[INFO] loading images...\")\nimagePaths = list(paths.list_images(dataset_path))\ndata = []\nlabels = []\n# loop over the image paths\nfor imagePath in imagePaths:\n    # extract the class label from the filename\n    label = imagePath.split(os.path.sep)[-2]\n    # load the image, swap color channels, and resize it to be a fixed\n    # 224x224 pixels while ignoring aspect ratio\n    image = cv2.imread(imagePath)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = cv2.resize(image, (224, 224))\n    # update the data and labels lists, respectively\n    data.append(image)\n    labels.append(label)\n# convert the data and labels to NumPy arrays while scaling the pixel\n# intensities to the range [0, 1]\ndata = np.array(data) / 255.0\nlabels = np.array(labels)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# perform one-hot encoding on the labels\nlb = LabelBinarizer()\nlabels = lb.fit_transform(labels)\nlabels = to_categorical(labels)\n# partition the data into training and testing splits using 80% of\n# the data for training and the remaining 20% for testing\n(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.20, stratify=labels, random_state=42)\n# initialize the training data augmentation object\ntrainAug = ImageDataGenerator(rotation_range=15, fill_mode=\"nearest\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Building a Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# load the VGG16 network, ensuring the head FC layer sets are left\n# off\nbaseModel = VGG16(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n# construct the head of the model that will be placed on top of the\n# the base model\nheadModel = baseModel.output\nheadModel = AveragePooling2D(pool_size=(4, 4))(headModel)\nheadModel = Flatten(name=\"flatten\")(headModel)\nheadModel = Dense(64, activation=\"relu\")(headModel)\nheadModel = Dropout(0.5)(headModel)\nheadModel = Dense(2, activation=\"softmax\")(headModel)\n# place the head FC model on top of the base model (this will become\n# the actual model we will train)\nmodel = Model(inputs=baseModel.input, outputs=headModel)\n# loop over all layers in the base model and freeze them so they will\n# *not* be updated during the first training process\nfor layer in baseModel.layers:\n    layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Training the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# compile our model\nprint(\"[INFO] compiling model...\")\nopt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\nmodel.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n\n# train the head of the network\nprint(\"[INFO] training head...\")\nH = model.fit_generator(\n    trainAug.flow(trainX, trainY, batch_size=BS),\n    steps_per_epoch=len(trainX) // BS,\n    validation_data=(testX, testY),\n    validation_steps=len(testX) // BS,\n    epochs=EPOCHS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot the training loss and accuracy\nN = EPOCHS\nplt.style.use(\"ggplot\")\nplt.figure()\nplt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\nplt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\nplt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\nplt.title(\"Training Loss and Accuracy on COVID-19 Dataset\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss/Accuracy\")\nplt.legend(loc=\"lower left\")\nplt.savefig(\"plot.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make predictions on the testing set\nprint(\"[INFO] evaluating network...\")\npredIdxs = model.predict(testX, batch_size=BS)\n# for each image in the testing set we need to find the index of the\n# label with corresponding largest predicted probability\npredIdxs = np.argmax(predIdxs, axis=1)\n# show a nicely formatted classification report\nprint(classification_report(testY.argmax(axis=1), predIdxs, target_names=lb.classes_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Confusion Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"# compute the confusion matrix and and use it to derive the raw\n# accuracy, sensitivity, and specificity\ncm = confusion_matrix(testY.argmax(axis=1), predIdxs)\ntotal = sum(sum(cm))\nacc = (cm[0, 0] + cm[1, 1]) / total\nsensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\nspecificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n# show the confusion matrix, accuracy, sensitivity, and specificity\nprint(cm)\nprint(\"acc: {:.4f}\".format(acc))\nprint(\"sensitivity: {:.4f}\".format(sensitivity))\nprint(\"specificity: {:.4f}\".format(specificity))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ResNet50"},{"metadata":{"trusted":true},"cell_type":"code","source":"baseModel = ResNet50(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n# construct the head of the model that will be placed on top of the\n# the base model\nheadModel = baseModel.output\nheadModel = AveragePooling2D(pool_size=(4, 4))(headModel)\nheadModel = Flatten(name=\"flatten\")(headModel)\nheadModel = Dense(64, activation=\"relu\")(headModel)\nheadModel = Dropout(0.5)(headModel)\nheadModel = Dense(2, activation=\"softmax\")(headModel)\n# place the head FC model on top of the base model (this will become\n# the actual model we will train)\nmodel = Model(inputs=baseModel.input, outputs=headModel)\n# loop over all layers in the base model and freeze them so they will\n# *not* be updated during the first training process\nfor layer in baseModel.layers:\n    layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# compile our model\nprint(\"[INFO] compiling model...\")\nopt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\nmodel.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n\n# train the head of the network\nprint(\"[INFO] training head...\")\nH = model.fit_generator(\n    trainAug.flow(trainX, trainY, batch_size=BS),\n    steps_per_epoch=len(trainX) // BS,\n    validation_data=(testX, testY),\n    validation_steps=len(testX) // BS,\n    epochs=EPOCHS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot the training loss and accuracy\nN = EPOCHS\nplt.style.use(\"ggplot\")\nplt.figure()\nplt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\nplt.plot(np.arange(0, N), H.history[\"valida_loss\"], label=\"val_loss\")\nplt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\nplt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\nplt.title(\"Training Loss and Accuracy on COVID-19 Dataset\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss/Accuracy\")\nplt.legend(loc=\"lower left\")\nplt.savefig(\"plot.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make predictions on the testing set\nprint(\"[INFO] evaluating network...\")\npredIdxs = model.predict(testX, batch_size=BS)\n# for each image in the testing set we need to find the index of the\n# label with corresponding largest predicted probability\npredIdxs = np.argmax(predIdxs, axis=1)\n# show a nicely formatted classification report\nprint(classification_report(testY.argmax(axis=1), predIdxs, target_names=lb.classes_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# compute the confusion matrix and and use it to derive the raw\n# accuracy, sensitivity, and specificity\ncm = confusion_matrix(testY.argmax(axis=1), predIdxs)\ntotal = sum(sum(cm))\nacc = (cm[0, 0] + cm[1, 1]) / total\nsensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\nspecificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n# show the confusion matrix, accuracy, sensitivity, and specificity\nprint(cm)\nprint(\"acc: {:.4f}\".format(acc))\nprint(\"sensitivity: {:.4f}\".format(sensitivity))\nprint(\"specificity: {:.4f}\".format(specificity))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Building CNN13 model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def cnn_model(bsize, epk):\n    img_dims = 224\n    INIT_LR = 1e-3\n    EPOCHS = epk\n    BS = bsize\n    \n    # Input layer\n    inputs = Input(shape=(224, 224, 3))\n\n    # 1st conv block\n    x = Conv2D(filters=64, kernel_size=(3, 3), activation='relu', trainable=False, padding='same')(inputs)\n    x = Conv2D(filters=64, kernel_size=(3, 3), activation='relu', trainable=False, padding='same')(x)\n    x = BatchNormalization()(x)\n    x = MaxPool2D(pool_size=(2, 2))(x)\n\n    # 2nd conv block\n    x = Conv2D(filters=128, kernel_size=(3, 3), activation='relu', trainable=True, padding='same')(x)\n    x = Conv2D(filters=128, kernel_size=(3, 3), activation='relu', trainable=True, padding='same')(x)\n    x = BatchNormalization()(x)\n    x = MaxPool2D(pool_size=(2, 2))(x)\n\n    # 3rd conv block\n    x = Conv2D(filters=256, kernel_size=(3, 3), activation='relu', trainable=True, padding='same')(x)\n    x = Conv2D(filters=256, kernel_size=(3, 3), activation='relu', trainable=True, padding='same')(x)\n    x = BatchNormalization()(x)\n    x = MaxPool2D(pool_size=(2, 2))(x)\n\n    # 4th conv block\n    x = Conv2D(filters=512, kernel_size=(3, 3), activation='relu', trainable=True, padding='same')(x)\n    x = Conv2D(filters=512, kernel_size=(3, 3), activation='relu', trainable=True, padding='same')(x)\n    x = Conv2D(filters=512, kernel_size=(3, 3), activation='relu', trainable=True, padding='same')(x)\n    x = BatchNormalization()(x)\n    x = MaxPool2D(pool_size=(2, 2))(x)\n\n    # 5th conv block\n    x = Conv2D(filters=512, kernel_size=(3, 3), activation='relu', trainable=True, padding='same')(x)\n    x = Conv2D(filters=512, kernel_size=(3, 3), activation='relu', trainable=True, padding='same')(x)\n    x = Conv2D(filters=512, kernel_size=(3, 3), activation='relu', trainable=True, padding='same')(x)\n    x = BatchNormalization()(x)\n    x = MaxPool2D(pool_size=(2, 2))(x)\n    x = AveragePooling2D(pool_size=(4, 4))(x)\n\n    # LSTM layer\n    x = Reshape((1, 512))(x)\n    x = (Bidirectional(LSTM(512, activation=\"relu\", return_sequences=True,trainable=True)))(x)\n    #x.trainable = False\n    #x.forward_layer.trainable = False\n    #x.backward_layer.trainable = False\n\n    # FC layer\n    x = Flatten(name=\"flatten\")(x)\n    x = Dense(units=64, activation='relu')(x)\n    x = Dropout(0.5)(x)\n\n    # Output layer\n    output = Dense(units=2, activation='softmax')(x)\n\n    model = Model(inputs=inputs, outputs=output)\n\n    # compile our model\n    opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n    model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n    # model.summary()\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_to_label_map = {'covid' : 1, 'normal' : 0}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fit_and_evaluate(t_x, val_x, t_y, val_y, EPOCHS, BATCH_SIZE=8):\n    model = None\n    model = cnn_model(BATCH_SIZE, EPOCHS)\n    trainAug = ImageDataGenerator(rotation_range=15, fill_mode=\"nearest\")\n    results = model.fit_generator(\n                    trainAug.flow(t_x, t_y, batch_size=BS),\n                    steps_per_epoch=len(val_x) // BS,\n                    validation_data=trainAug.flow(val_x, val_y, batch_size=BS),\n#                     validation_data=(val_x, val_y),\n                    validation_steps=len(val_x) // BS,\n                    epochs=EPOCHS)\n    \n    fig, ax = plt.subplots(1, 2, figsize=(10, 3))\n    ax = ax.ravel()\n    for i, met in enumerate(['accuracy', 'loss']):\n        ax[i].plot(results.history[met])\n        ax[i].plot(results.history['val_' + met])\n        ax[i].set_title('Model {}'.format(met))\n        ax[i].set_xlabel('epochs')\n        ax[i].set_ylabel(met)\n        ax[i].legend(['train', 'val'])\n    \n    prediction = model.predict(val_x, batch_size=BS)\n    test_result = np.argmax(val_y, axis=1)\n    prediction_result = np.argmax(prediction, axis=1)\n    confusion__matrix=confusion_matrix(test_result, prediction_result)\n    print(classification_report(test_result, prediction_result, target_names=class_to_label_map))\n    print(confusion__matrix)\n    \n    print(\"Val Score: \", model.evaluate(val_x, val_y))\n    return results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# n_folds=5\nepochs=10\nbatch_size=8\n\n# model_history = [] \n\n# for i in range(n_folds):\n#     print(\"Training on Fold: \",i+1)\nt_x, val_x, t_y, val_y = train_test_split(data, labels, test_size=0.20, stratify=labels, random_state = np.random.randint(1,1000, 1)[0])\n# fit_and_evaluate(t_x, val_x, t_y, val_y, epochs, batch_size)\n# print(\"=======\"*12, end=\"\\n\\n\\n\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Build CNN29"},{"metadata":{"trusted":true},"cell_type":"code","source":"def cnn29():\n    img_dims=224\n    inputs = Input(shape=(img_dims, img_dims, 3))\n\n    # 1st conv block\n    x = Conv2D(filters=64, kernel_size=(3, 3), activation='relu', trainable=False, padding='same')(inputs)\n    x = Conv2D(filters=64, kernel_size=(3, 3), activation='relu', trainable=False, padding='same')(x)\n    x = BatchNormalization()(x)\n    x = MaxPool2D(pool_size=(2, 2))(x)\n\n    # 2nd conv block\n    x = Conv2D(filters=128, kernel_size=(3, 3), activation='relu', trainable=False, padding='same')(x)\n    x = Conv2D(filters=128, kernel_size=(3, 3), activation='relu', trainable=False, padding='same')(x)\n    x = BatchNormalization()(x)\n    x = MaxPool2D(pool_size=(2, 2))(x)\n\n    # 3rd conv block\n    x = Conv2D(filters=256, kernel_size=(3, 3), activation='relu', trainable=False, padding='same')(x)\n    x = Conv2D(filters=256, kernel_size=(3, 3), activation='relu', trainable=False, padding='same')(x)\n    x = BatchNormalization()(x)\n    x = MaxPool2D(pool_size=(2, 2))(x)\n\n    # 4th conv block\n    x = Conv2D(filters=512, kernel_size=(3, 3), activation='relu', trainable=False, padding='same')(x)\n    x = Conv2D(filters=512, kernel_size=(3, 3), activation='relu', trainable=False, padding='same')(x)\n    x = Conv2D(filters=512, kernel_size=(3, 3), activation='relu', trainable=False, padding='same')(x)\n    x = BatchNormalization()(x)\n    x = MaxPool2D(pool_size=(2, 2))(x)\n\n    # 5th conv block\n    x = Conv2D(filters=512, kernel_size=(3, 3), activation='relu', trainable=False, padding='same')(x)\n    x = Conv2D(filters=512, kernel_size=(3, 3), activation='relu', trainable=False, padding='same')(x)\n    x = Conv2D(filters=512, kernel_size=(3, 3), activation='relu', trainable=False, padding='same')(x)\n    x = BatchNormalization()(x)\n    x = MaxPool2D(pool_size=(2, 2))(x)\n#     x = AveragePooling2D(pool_size=(4, 4))(x)\n\n    # LSTM layer\n    x = Reshape((49, 512))(x)\n    x = ((LSTM(512, activation=\"relu\", return_sequences=True, trainable=False)))(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    \n    # FC layer\n    x = Flatten(name=\"flatten\")(x)\n    x = Dense(units=64, activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n\n    # Output layer\n    output = Dense(units=2, activation='softmax')(x)\n\n    model = Model(inputs=inputs, outputs=output)\n#     opt = SGD(lr=0.01)\n    opt = Adam(lr=0.0001, decay=1e-6)\n    model.compile(loss='categorical_crossentropy',optimizer=opt, metrics=[\"accuracy\"])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fit_and_evaluate(t_x, val_x, t_y, val_y, EPOCHS, BATCH_SIZE=8):\n    model = None\n    model = cnn29()\n    trainAug = ImageDataGenerator(rotation_range=15, fill_mode=\"nearest\")\n    results = model.fit_generator(\n                    trainAug.flow(t_x, t_y, batch_size=BS),\n                    steps_per_epoch=len(val_x) // BS,\n                    validation_data=trainAug.flow(val_x, val_y, batch_size=BS),\n#                     validation_data=(val_x, val_y),\n                    validation_steps=len(val_x) // BS,\n                    epochs=EPOCHS)\n    \n    fig, ax = plt.subplots(1, 2, figsize=(10,3))\n    ax = ax.ravel()\n    for i, met in enumerate(['accuracy', 'loss']):\n        ax[i].plot(results.history[met])\n        ax[i].plot(results.history['val_' + met])\n        ax[i].set_title('Model {}'.format(met))\n        ax[i].set_xlabel('epochs')\n        ax[i].set_ylabel(met)\n        ax[i].legend(['train', 'val'])\n    \n    prediction = model.predict(val_x, batch_size=BS)\n    test_result = np.argmax(val_y, axis=1)\n    prediction_result = np.argmax(prediction, axis=1)\n    confusion__matrix=confusion_matrix(test_result, prediction_result)\n    print(classification_report(test_result, prediction_result, target_names=class_to_label_map))\n    print(confusion__matrix)\n    \n    print(\"Val Score: \", model.evaluate(val_x, val_y))\n    return results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fit_and_evaluate(t_x, val_x, t_y, val_y, epochs, batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from prettytable import PrettyTable\n#If you get a ModuleNotFoundError error , install prettytable using: pip3 install prettytable\nx = PrettyTable()\nx.field_names = [ \"Model\",  \"Test Accuracy\"]\nx.add_row([\"VGG16\", '100%'])\nx.add_row([\"ResNet50\", '74%'])\nx.add_row([\"CNN13\", '74%'])\nx.add_row([\"CNN29\", '74%'])\nprint(x)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}