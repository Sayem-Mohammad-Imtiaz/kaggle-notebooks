{"cells":[{"metadata":{},"cell_type":"markdown","source":" <font size=\"5\">Please do Vote up if you like my work,any help to upgrade this is appreciated.</font>\n* Linkedin : https://www.linkedin.com/in/pratikrandad/**"},{"metadata":{},"cell_type":"markdown","source":"<font size=\"3\">AIM:</font>\n\nIn this Project,On the basis of the mobile Specification like Battery power, 3G enabled , wifi ,Bluetooth, Ram etc we are predicting Price range of the mobile"},{"metadata":{},"cell_type":"markdown","source":"<font size=\"3\">Data:</font>\n\n* id:ID\n* battery_power:Total energy a battery can store in one time measured in mAh\n* blue:Has bluetooth or not\n* clock_speed:speed at which microprocessor executes instructions\n* dual_sim:Has dual sim support or not\n* fc:Front Camera mega pixels\n* four_g:Has 4G or not\n* int_memory:Internal Memory in Gigabytes\n* m_dep:Mobile Depth in cm\n* mobile_wt:Weight of mobile phone\n* n_cores:Number of cores of processor\n* pc:Primary Camera mega pixels\n* px_height:Pixel Resolution Height\n* px_width:Pixel Resolution Width\n* ram:Random Access Memory in Megabytes\n* sc_h:Screen Height of mobile in cm\n* sc_w:Screen Width of mobile in cm\n* talk_time:longest time that a single battery charge will last when you are\n* three_g:Has 3G or not\n* touch_screen:Has touch screen or not\n* wifi:Has wifi or not\n"},{"metadata":{},"cell_type":"markdown","source":"<font size=\"3\"> USE:</font>\n\n* This kind of prediction will help companies estimate price of mobiles to give tough competion to other mobile manufacturer\n* Also it will be usefull for Consumers to verify that they are paying best price for a mobile.\n<font size=\"3\">Applied Models:</font>\n\n* KNN Classifier\n* SVM(kernel=linear)\n* SVM(kernel=rbf)\n* Decision tree\n* Random forest"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**<font size=\"4\">Load Data</font>**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"dataset=pd.read_csv('/kaggle/input/mobile-price-classification/train.csv')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**<font size=\"4\">Data Analysis</font>**"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**<font size=\"4\">Data Visualisation</font>**"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr=dataset.corr(method='pearson')\nplt.figure(figsize=(19, 6))\nsns.heatmap(corr,cmap=\"YlGnBu\",annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"3\">RAM has the highest co-relation with phone price</font>"},{"metadata":{},"cell_type":"markdown","source":"<font size=\"4\">RAM vs Price</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x='price_range',y='ram',data=dataset)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"4\">Internal_memory vs Price</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x='price_range',y='int_memory',kind='swarm',data=dataset)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"4\">3G Phones vs Non 3G Phones</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib.pyplot import pie\nvalues=dataset['three_g'].value_counts().values\npie(values,labels=['3G Supported','3G Not Supported'],autopct='%1.1f%%' ,shadow=True,startangle=90)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"4\">4G Phones vs Non 4G Phones</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"values=dataset['four_g'].value_counts().values\npie(values,labels=['4G Supported','4G Not Supported'],autopct='%1.1f%%' ,shadow=True,startangle=90)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"4\">Battery Power vs Price Range</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='price_range',y='battery_power',data=dataset)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"4\">Data Pre-processing<font>"},{"metadata":{},"cell_type":"markdown","source":"<font size=\"3\">X & Y matrix</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"X=dataset.iloc[:,:-1].values\ny=dataset.iloc[:,-1].values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"4\">Training and Test Data Split</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 0)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"4\">Most Models like KNN work on Euclidean Distance, larger values will impact the result,hence scaling is required.</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\nX_train\nX_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"4\">KNN</font>"},{"metadata":{},"cell_type":"markdown","source":"<font size=\"3\">KNN with K=10</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nKNNclassifier=KNeighborsClassifier(n_neighbors=10)\nKNNclassifier.fit(X_train,y_train)\ny_pred = KNNclassifier.predict(X_test)\nfrom sklearn.metrics import accuracy_score\naccuracy_score(y_test,y_pred)*100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"4\">Finding Optimum value of K</font>"},{"metadata":{},"cell_type":"markdown","source":"<font size=\"4\">K-fold Cross Validation</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n# Creating odd list K for KNN\nneighbors = list(range(1,30))\n# empty list that will hold cv scores\ncv_scores = [ ]\n#perform 10-fold cross-validation\nfor K in neighbors:\n    knn = KNeighborsClassifier(n_neighbors = K)\n    scores = cross_val_score(knn,X_train,y_train,cv = 10,scoring =\n    \"accuracy\")\n    cv_scores.append(scores.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Changing to mis classification error\nmse = [1-x for x in cv_scores]\n# determing best k\noptimal_k = neighbors[mse.index(min(mse))]\nprint(\"The optimal no. of neighbors is {}\".format(optimal_k))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"3\">K value using Elbow Method</font>\n* Finding K value so that mis match between actual and predicted values is least"},{"metadata":{"trusted":true},"cell_type":"code","source":"mismatch=[]\nfor i in range(1,30):\n    classifier=KNeighborsClassifier(n_neighbors=i)\n    classifier.fit(X_train,y_train)\n    y_pred=classifier.predict(X_test)\n    mismatch.append(np.sum(y_pred != y_test))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(range(1,30),mismatch)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"3\">KNN with K=22, accuracy increased by 4%</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nKNNclassifier=KNeighborsClassifier(n_neighbors=22)\nKNNclassifier.fit(X_train,y_train)\ny_pred = KNNclassifier.predict(X_test)\nfrom sklearn.metrics import accuracy_score\naccuracy_score(y_test,y_pred)*100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"4\">SVM Model(kernel=linear)</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nSVMlinear=SVC(kernel='linear')\nSVMlinear.fit(X_train,y_train)\nSVMlinear_predict=SVMlinear.predict(X_test)\ny_pred = SVMlinear.predict(X_test)\naccuracy_score(y_test,y_pred)*100\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"4\">SVM Model(kernel=rbf)</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nSVMrbf=SVC(kernel='rbf')\nSVMrbf.fit(X_train,y_train)\nSVMrbf_predict=SVMrbf.predict(X_test)\ny_pred = SVMrbf.predict(X_test)\naccuracy_score(y_test,y_pred)*100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"4\">Naive Bayes Model</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nNB=GaussianNB()\nNB.fit(X_train,y_train)\nNB_predict=NB.predict(X_test)\ny_pred = NB.predict(X_test)\naccuracy_score(y_test,y_pred)*100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"4\">Decision Tree Model</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nDecisionTree=DecisionTreeClassifier(criterion='entropy',random_state=0)\nDecisionTree.fit(X_train,y_train)\nDecisionTree_predict=DecisionTree.predict(X_test)\ny_pred = DecisionTree.predict(X_test)\naccuracy_score(y_test,y_pred)*100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"4\">Finding Optimum value for No. of trees using K-fold cross validation</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\ntrees = list(range(1,20))\n# empty list that will hold cv scores\ncv_scores = [ ]\n#perform 10-fold cross-validation\nfor n in trees:\n    RFC = RandomForestClassifier(n_estimators = n,criterion='entropy',random_state=0)\n    scores = cross_val_score(RFC,X_train,y_train,cv = 10,scoring =\n    \"accuracy\")\n    cv_scores.append(scores.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Changing to mis classification error\nmse = [1-x for x in cv_scores]\n# determing best n\noptimal_n = trees[mse.index(min(mse))]\nprint(\"The optimal no. of trees is {}\".format(optimal_n))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nRFC=RandomForestClassifier(n_estimators=19,criterion='entropy',random_state=0)\nRFC.fit(X_train,y_train)\nRFC_predict=RFC.predict(X_test)\ny_pred = RFC.predict(X_test)\naccuracy_score(y_test,y_pred)*100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"5\">Conclusion:</font>\n<font size=\"5\">Linear SVM Classifier fits best for this model with 96% Accuracy</font>"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}