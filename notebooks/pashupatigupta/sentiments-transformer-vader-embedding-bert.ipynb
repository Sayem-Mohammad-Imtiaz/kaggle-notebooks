{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Pfizer Vaccine Tweets\n\nThis notebook has two parts. \n\n- Part 1 - Sentiment Analysis of tweets using HuggingFace Transformers (analogical to Optimus Prime!!) and NLTK VADER (Analogical to Darth Vader!!). Ignore the analogies if you aren't a fan of movies.\n- Part 2 - Senternce embedding generation using pretraine BERT.\n\n## Part 1 (Optimus Prime vs Darth Vader!!)"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from IPython.display import Image\nImage(filename='/kaggle/input/compare/img.jpg')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We all are familiar with Optimus Prime and Darth Vader. Let's see how good they are.\n\n> Just for for your reference I'm referring HuggingFace Transformer with Optimus Prime and NLTK's VADER with Darth Vader. Interesting Analogy. Isn't it?\n\nWe'll be doing sentiment analysis using both (HuggingFace Transformers and NLTK's VADER) and let's how they perform. And do they contradict each other?"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport plotly.graph_objects as go\nimport plotly.express as px\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport scipy.stats as stats\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/pfizer-vaccine-tweets/vaccination_tweets.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Basic EDA\n\nA generic function for basic EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"def basic_eda(df, row_limit=5, list_elements_limit=10):\n    ### rows and columns\n    print('Info : There are {} columns in the dataset'.format(df.shape[1]))\n    print('Info : There are {} rows in the dataset'.format(df.shape[0]))\n    \n    print(\"==================================================\")\n    \n    ## data types\n    print(\"\\nData type information of different columns\")\n    dtypes_df = pd.DataFrame(df.dtypes).reset_index().rename(columns={0:'dtype', 'index':'column_name'})\n    cat_df = dtypes_df[dtypes_df['dtype']=='object']\n    num_df = dtypes_df[dtypes_df['dtype']!='object']\n    print('Info : There are {} categorical columns'.format(len(cat_df)))\n    print('Info : There are {} numerical columns'.format(len(dtypes_df)-len(cat_df)))\n    \n    if list_elements_limit >= len(cat_df):\n        print(\"Categorical columns : \", list(cat_df['column_name']))\n    else:\n        print(\"Categorical columns : \", list(cat_df['column_name'])[:list_elements_limit])\n        \n    if list_elements_limit >= len(num_df):\n        print(\"Numerical columns : \", list(num_df['column_name']))\n    else:\n        print(\"Numerical columns : \", list(num_df['column_name'])[:list_elements_limit])\n    \n    #dtypes_df['dtype'].value_counts().plot.bar()\n    display(dtypes_df.head(row_limit))\n    \n    print(\"==================================================\")\n    print(\"\\nDescription of numerical variables\")\n    \n    #### Describibg numerical columns\n    desc_df_num = df[list(num_df['column_name'])].describe().T.reset_index().rename(columns={'index':'column_name'})\n    display(desc_df_num.head(row_limit))\n    \n    print(\"==================================================\")\n    print(\"\\nDescription of categorical variables\")\n    \n    desc_df_cat = df[list(cat_df['column_name'])].describe().T.reset_index().rename(columns={'index':'column_name'})\n    display(desc_df_cat.head(row_limit))\n    \n    return","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"basic_eda(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Sentiment Analysis : The Optimus Prime [HuggingFace Transformers]\n\n![HF](https://raw.githubusercontent.com/huggingface/transformers/master/docs/source/imgs/transformers_logo_name.png)\n\nTransformers is a library released by [huggingface](https://huggingface.co/transformers/quicktour.html). This library downloads pretrained models for Natural Language Understanding (NLU) tasks, such as analyzing the sentiment of a text, and Natural Language Generation (NLG), such as completing a prompt with new text or translating in another language.\n\nWe'll use the pretrained model find out the sentiment of a tweet in our dataset\n\nPros:\n\n- Good Accuracy\n- Very short and easy to use code\n- No fancy preprocessing needed\n- No finicking around with threshold values\n\nCons:\n\n- Significantly Slower\n- Only works with 2 classes out of the box \n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from transformers import pipeline\nsentiment_analysis = pipeline('sentiment-analysis')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transformer_sentiments = data.text.apply(sentiment_analysis)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = []\nscores = []\nfor sentiment in transformer_sentiments:\n    #print(f\"label: {sentiment[0]['label']}, with score: {round(sentiment[0]['score'], 4)}\")\n    labels.append(sentiment[0]['label'])\n    scores.append(round(sentiment[0]['score'], 4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['tf-sentiment'] = labels\ndata['tf-score'] = scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[['text', 'tf-sentiment', 'tf-score']].head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Sentiment Analysis : The Darth Vader [NLTK VADER]\n\n![nltk](https://static1.squarespace.com/static/538cea80e4b00f1fad490c1b/54668a77e4b00fb778d22a34/54668e11e4b00fb778d29051/1416008768215/?format=1500w)\n\nNLTK already has a built-in, pretrained sentiment analyzer called VADER (Valence Aware Dictionary and sEntiment Reasoner).\n\nVADER is pretrained, you can get results more quickly than with many other analyzers. However, VADER is best suited for language used in social media, like short sentences with some slang and abbreviations. It’s less accurate when rating longer, structured sentences, but it’s often a good launching point.\n\nPros:\n\n- Very Fast\n- Very short and easy to use code\n- No fancy preprocessing needed\n- Provides three classes\n\nCons:\n\n- Rule based algorithm doesn't consider context\n- less accuarate"},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.sentiment import SentimentIntensityAnalyzer\nsia = SentimentIntensityAnalyzer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_sentiment(tweet):\n    if sia.polarity_scores(tweet)[\"compound\"] > 0:\n        return \"POSITIVE\"\n    elif sia.polarity_scores(tweet)[\"compound\"] < 0:\n        return \"NEGATIVE\"\n    else:\n        return \"NEUTRAL\"        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vader_sentiments = data.text.apply(find_sentiment)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['vader-sentiment'] = vader_sentiments","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[['text', 'vader-sentiment']].head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Comparision of Transformer with VADER\n\nNow that we have both the sentiments let's compare the"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Make a df just for comparision\ndf = data[['text', 'tf-score', 'tf-sentiment', 'vader-sentiment']]\ndf.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Woah! Are they performing exactly opposite? Let's find out."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Distribution of classes : Optimus Prime\")\ncounts = df['tf-sentiment'].value_counts()\npercent = counts/sum(counts)\n\nfig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 5))\n\ncounts.plot(kind='bar', ax=ax1)\npercent.plot(kind='bar', ax=ax2)\nax1.set_ylabel('Counts : TF Sentiments', size=12)\nax2.set_ylabel('Percentage : TF Sentiments', size=12)\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Interestingly Transformer is clasifying most of the tweets as negative. Let's see about VADER."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Distribution of classes : Darth Vader\")\ncounts = df['vader-sentiment'].value_counts()\npercent = counts/sum(counts)\n\nfig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 5))\n\ncounts.plot(kind='bar', ax=ax1)\npercent.plot(kind='bar', ax=ax2)\nax1.set_ylabel('Counts : VADER Sentiments', size=12)\nax2.set_ylabel('Percentage : VADER Sentiments', size=12)\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Interesting! Let's see side by side."},{"metadata":{"trusted":true},"cell_type":"code","source":"def label_function(val):\n    return f'{val / 100 * len(df):.0f}\\n{val:.0f}%'\n\nfig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(16, 8))\n\ndf.groupby('vader-sentiment').size().plot(kind='pie', autopct=label_function, textprops={'fontsize': 12},\n                                  colors=['tomato', 'gold', 'skyblue'], ax=ax1)\ndf.groupby('tf-sentiment').size().plot(kind='pie', autopct=label_function, textprops={'fontsize': 12},\n                                 colors=['violet', 'lime'], ax=ax2)\nax1.set_ylabel('VADER Sentiments', size=12)\nax2.set_ylabel('Transformer Sentiments', size=12)\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Clearly there is a lot of difference! Let's dig down further!"},{"metadata":{"trusted":true},"cell_type":"code","source":"def same_or_diff(x):\n    if x[0]==x[1]:\n        return \"Same\"\n    else:\n        return \"Different\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Same or Different including the Neutral records\")\ndf['same_or_diff_w_neut'] = df[['tf-sentiment', 'vader-sentiment']].apply(same_or_diff, axis=1)\ndf.head(3)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"print(\"Same or Different including the Neutral records : Comparision\")\ncounts = df['same_or_diff_w_neut'].value_counts()\npercent = counts/sum(counts)\n\nfig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 5))\n\ncounts.plot(kind='bar', ax=ax1)\npercent.plot(kind='bar', ax=ax2)\nax1.set_ylabel('Number of records', size=12)\nax2.set_ylabel('Percentage or records', size=12)\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Same or Different after removing the Neutral records\")\ndfwn = df[df['vader-sentiment'] != 'NEUTRAL']\n# Just to ensure\nprint(\"==================================\\n\")\nprint(dfwn['vader-sentiment'].value_counts())\ndfwn['same_or_diff_wo_neut'] = dfwn[['tf-sentiment', 'vader-sentiment']].apply(same_or_diff, axis=1)\ndfwn.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Same or Different after removing the Neutral records : Comparision\")\ncounts = dfwn['same_or_diff_wo_neut'].value_counts()\npercent = counts/sum(counts)\n\nfig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 5))\n\ncounts.plot(kind='bar', ax=ax1)\npercent.plot(kind='bar', ax=ax2)\nax1.set_ylabel('Number of records', size=12)\nax2.set_ylabel('Percentage or records', size=12)\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Let's see at some records !!"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['color'] = df['same_or_diff_w_neut'].apply(lambda x : \"green\" if x == 'Same' else 'red')\n\nfig = go.Figure(data=[go.Table(\n    columnorder = [1,2,3,4],\n    columnwidth = [400, 100, 100, 120],\n    header=dict(values=['text', 'tf-sentiment', 'vader-sentiment', 'same_or_different'],\n                fill_color='paleturquoise',\n                line_color='black',\n                align='center',\n                height=40),\n    cells=dict(values=[df['text'],df['tf-sentiment'], df['vader-sentiment'], df['same_or_diff_w_neut']],\n               fill_color=[['lavender'], ['lavender'], ['lavender'], list(df.color)],\n               line_color='black',\n               align='left'))\n])\n\nfig.update_layout(height=700,\n                 title=\"Comparision across Transformer and VADER\")\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### We can clearly see the differences! "},{"metadata":{},"cell_type":"markdown","source":"## Part 2 - Sentence embedding generation of tweets using BERT"},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\nimport torch\nimport transformers as ppb\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Loading pretrained model/tokenizer\nmodel_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\ntokenizer = tokenizer_class.from_pretrained(pretrained_weights)\nmodel = model_class.from_pretrained(pretrained_weights)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Some utility functions\n# function to find max length\ndef find_max_len(tokenized):\n  max_len = 0\n  for i in tokenized.values:\n      if len(i) > max_len:\n          max_len = len(i)\n  return max_len\n\n\n# function to extract bert features\ndef get_bert_features(df, text_col):\n  tokenized = df[text_col].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n  max_len = find_max_len(tokenized)\n  print(\"Max Len = \",max_len)\n  padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n  attention_mask = np.where(padded != 0, 1, 0)\n\n  input_ids = torch.tensor(padded)  \n  attention_mask = torch.tensor(attention_mask)\n\n  with torch.no_grad():\n    last_hidden_states = model(input_ids, attention_mask=attention_mask)\n\n  features = last_hidden_states[0][:,0,:].numpy()\n\n  return features\n\n\n# Applying above function in batches to avoid RAM issues\ndef extract_features(df, text_col, batch_size=1000):\n    features = []\n    labels = []\n\n    no_of_batches = math.ceil(len(df)/batch_size)\n    print(\"\\nInitializing...\")\n    print(\"Total no of batches : \",str(no_of_batches))\n    batch_no = 1\n\n#     widgets = ['Generating BERT Embeddings: ', progressbar.AnimatedMarker()] \n#     bar = progressbar.ProgressBar(max_value=len(df), widgets=widgets).start() \n\n    for i in range (0,len(df),batch_size):\n        #time.sleep(0.2)\n        #bar.update(i)\n        print()\n        print(\"\\nGenerating features for batch\",str(batch_no),\"of\",str(no_of_batches))\n        dfn = df[i:i+batch_size]\n        tfeatures = get_bert_features(dfn, text_col)\n        tfeatures = list(tfeatures)\n        features.append(tfeatures)\n        batch_no = batch_no + 1\n\n    print(\"Done\")\n    features = np.concatenate(features)\n\n    return features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = extract_features(df=df, text_col = 'text', batch_size=1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embeddings = list(features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['embedding'] = embeddings\ndf = df[['text', 'embedding']].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure(data=[go.Table(\n    columnorder = [1,2],\n    columnwidth = [300,400],\n    header=dict(values=['text', 'embedding'],\n                fill_color='paleturquoise',\n                line_color='black',\n                align='center',\n                height=40),\n    cells=dict(values=[df['text'],df['embedding']],\n               fill_color=[['lavender'], ['lavender']],\n               line_color='black',\n               align='left'))\n])\n\nfig.update_layout(height=700,\n                 title=\"Embeddings generated using BERT\")\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Thanks for viewing this noteboook. If you found it interesting consider UPVOTING it."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}