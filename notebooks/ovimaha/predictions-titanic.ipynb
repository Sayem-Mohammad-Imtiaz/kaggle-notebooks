{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 style=\"text-align:center;color:blue\">Don't forget to Upvote if you like it.ðŸ˜Š</h1>","metadata":{}},{"cell_type":"markdown","source":"<center><h1>Importing Libraries</h1></center>","metadata":{}},{"cell_type":"markdown","source":"**Numpy : Python Library used for working with arrays<br>\nMatplotlib : Used for data visualizations. ex: to plot the relations between various factors<br>\nSeaborn: used for data visualization like matplotlib<br>\nPandas: used for data analysis and manipulation<br>**\n\n\n\n\n\n","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1>Importing Dataset</h1>","metadata":{}},{"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/titanic/train_and_test2.csv')\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1>Data Preprocessing</h1>","metadata":{}},{"cell_type":"markdown","source":"<h4>Remove unnecessary columns like zero.1,zero.2..... using pandas dropna() method<br>\nWe will rename '2urvived' column as 'Survived' using rename method</h4>","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop(['Passengerid','zero','zero.1','zero.2','zero.3','zero.4','zero.5','zero.6','zero.7','zero.8','zero.9','zero.10','zero.11','zero.12','zero.13','zero.14','zero.15','zero.16','zero.17','zero.18'],axis=1,inplace=True)\ndf.rename(columns={'2urvived':'Survived'},inplace=True) \ndf.head()","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Remove the rows having null values**","metadata":{}},{"cell_type":"code","source":"df.dropna(inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1>Data Visualization</h1>","metadata":{}},{"cell_type":"markdown","source":"**Heatmap of Co-Relation of various columns with each other\ndf.corr() shows the relation between various feature and we hence we can see the influence of the features on each other**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,10))\n# we keep annot=True to make the values appear of df.corr() appear on the heatmap\nsns.heatmap(df.corr(),annot=True,cmap=plt.cm.plasma)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Below we use pairplot method from seaborn library. It is used to plot graphs between the various features.**","metadata":{}},{"cell_type":"code","source":"sns.pairplot(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Let's see the various columns in df**","metadata":{}},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Building and Training the Model**","metadata":{}},{"cell_type":"markdown","source":"**We will split the data for training and testing using train_test_split**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nX=df.drop(['Survived'],axis=1)\nY=df['Survived']\nX_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.20,random_state=1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3>1)Logistic Regression</h3>","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlr=LogisticRegression(max_iter=300)\nlr.fit(X_train,y_train)\nyhat_lr=lr.predict(X_test)\nprint(\"Accuracy of Logistic Model is:\",accuracy_score(yhat_lr,y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3>Let's visualize the data using confusion matrix</h3>\n<span style=\"color:red\"><b>For those who don't know about Confusion Matrix:<br><br> A Confusion matrix is an N x N matrix used for evaluating the performance of a classification model, where N is the number of target classes. The matrix compares the actual target values with those predicted by the machine learning model. This gives us a holistic view of how well our classification model is performing and what kinds of errors it is making.</b></span>","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score,confusion_matrix\nax=confusion_matrix(yhat_lr,y_test)\nsns.heatmap(ax,annot=True,cmap=plt.cm.plasma)\nplt.xlabel('Predict')\nplt.ylabel('Actual')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3>2) K-Nearest Neighbor</h3>","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nKN=KNeighborsClassifier(n_neighbors=5)\nKN.fit(X_train,y_train)\nyhat=KN.predict(X_test)\nprint(\"Accuracy of K-Nearest Neighbor Model is:\",accuracy_score(yhat,y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3>3) Decision Tree</h3>","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ntree=DecisionTreeClassifier(random_state=0)\ntree.fit(X_train,y_train)\nyhat=tree.predict(X_test)\nprint(\"Accuracy of Decision Tree Classifier Model is:\",accuracy_score(yhat,y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3>4)Support Vector Machine(SVM) </h3>","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\nsvm=SVC(kernel='linear')\nsvm.fit(X_train,y_train)\nyhat=svm.predict(X_test)\nprint(\"Accuracy of Support Vector Machine Model is:\",accuracy_score(yhat,y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3>5)Random Forest Classifier</h3>","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrfc=RandomForestClassifier(n_estimators=200,criterion='entropy')\nrfc.fit(X_train,y_train)\n\nyhat=rfc.predict(X_test)\nprint(\"Accuracy of Random Forest Classifier Model is:\",accuracy_score(yhat,y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1>Best Model</h1>","metadata":{}},{"cell_type":"markdown","source":"<h3 style=\"color:blue\">We see that the best model for the prediction is Support Vector Machine with a accuracy of 0.8396</h3>","metadata":{}},{"cell_type":"markdown","source":"<center><h3>Thank you for reading my notebook and don't forget to upvote the notebook</h3></center>","metadata":{}}]}