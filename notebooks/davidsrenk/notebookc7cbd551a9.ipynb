{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.iloc[0,:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df['TotalCharges'] == \" \"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"11 from 7043 entries. There is two options drop them It is less than 0.2% or replace missing values by mean or use more advanced technique.","metadata":{}},{"cell_type":"code","source":"df = df.drop( index = df[df['TotalCharges'] == \" \"].index)\ndf.reset_index(inplace = False)\ndf\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"TotalCharges\"] =pd.to_numeric(df[\"TotalCharges\"])\ndf.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"basic view on numeric features distribution","metadata":{}},{"cell_type":"code","source":"df.Churn.unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.Churn.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"distribution of our dependent variable","metadata":{}},{"cell_type":"code","source":"import plotly.offline as py\nimport plotly.graph_objs as go\npy.init_notebook_mode(connected = True)\n\nlabels = ['No','Yes']\nvalues = df.Churn.value_counts()\n\nfig = go.Figure(data=[go.Pie(labels=labels, values=values\n                            )])\nfig.update_layout(title_text='Churn')\nfig.show()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"col = df.columns[1:-1] # first columns is customer ID and last is Churn\ncol","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"distribution of all variables depending on Churn","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport copy\n\na = 10  # number of rows\nb = 2  # number of columns\nc = 1  # initialize plot counter\n\nfig = plt.figure(figsize=(20,80))\n\nfor i in range(len(col)):\n    xx = copy.deepcopy(col)\n    plt.subplot(a, b, c)\n    plt.title('{}'.format(i))\n    plt.xlabel(xx[i])\n    sns.countplot(x=xx[i], hue=\"Churn\", data=df)\n    c = c + 1\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.boxplot(y=df.tenure, x=df.Churn)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.boxplot(y=df.MonthlyCharges, x=df.Churn)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.boxplot(y=df.TotalCharges, x=df.Churn)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"cathegoriacal variables to numeric. \n2 unique elemnets --> labelencoder, \nmore than 2 elements -->dummy encoder","metadata":{}},{"cell_type":"code","source":"obj_df = df.select_dtypes(include=['object']).copy()\nobj_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.pipeline import Pipeline\n\nclass MultiColumnLabelEncoder:\n    def __init__(self,columns = None):\n        self.columns = columns # array of column names to encode\n\n    def fit(self,X,y=None):\n        return self # not relevant here\n\n    def transform(self,X):\n        '''\n        Transforms columns of X specified in self.columns using\n        LabelEncoder(). If no columns specified, transforms all\n        columns in X.\n        '''\n        output = X.copy()\n        if self.columns is not None:\n            for col in self.columns:\n                output[col] = LabelEncoder().fit_transform(output[col])\n        else:\n            for colname,col in output.iteritems():\n                output[colname] = LabelEncoder().fit_transform(col)\n        return output\n\n    def fit_transform(self,X,y=None):\n        return self.fit(X,y).transform(X)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in df.columns:\n    print(df[i].unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = [\"gender\",\"Partner\", \"Dependents\", \"PhoneService\", \"PaperlessBilling\", \"Churn\"]\nencoded_df = MultiColumnLabelEncoder(columns = a).fit_transform(df)\nencoded_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"b = obj_df.drop([\"Churn\",\"customerID\", \"gender\",\"Partner\", \"Dependents\", \"PhoneService\", \"PaperlessBilling\"], axis =1)\nb = b.columns\nb =pd.Series(b)\n\nfinal_df = pd.get_dummies(columns=b ,data = encoded_df)\nfinal_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_df.corr()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_df.corr()['Churn'].sort_values(ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = final_df.drop(['Churn', 'customerID'],axis=1)\nY = final_df['Churn']\n\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=0)\nX_train.shape,X_test.shape,Y_train.shape,Y_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"spliting data set","metadata":{}},{"cell_type":"code","source":"#Logistic regression\nfrom sklearn.linear_model import LogisticRegression\n#from sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report, confusion_matrix\nmodel = LogisticRegression(max_iter = 200)\n\nmodel.fit(X_train,Y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction=model.predict(X_test)\nprediction[0:10]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_test[0:10]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(Y_test,prediction))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Model Accuracy:\",model.score(X_test,Y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\nfrom matplotlib import pyplot\n\n# predict probabilities\nlr_probs = model.predict_proba(X_test)\n# keep probabilities for the positive outcome only\nlr_probs = lr_probs[:, 1]\n# generate a no skill prediction\nns_probs = [0 for _ in range(len(Y_test))]\n# calculate scores\nns_auc = roc_auc_score(Y_test, ns_probs)\nlr_auc = roc_auc_score(Y_test, lr_probs)\n# summarize scores\nprint('Random choose: ROC AUC=%.3f' % (ns_auc))\nprint('Logistic: ROC AUC=%.3f' % (lr_auc))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculate roc curves\nns_fpr, ns_tpr, _ = roc_curve(Y_test, ns_probs)\nlr_fpr, lr_tpr, _ = roc_curve(Y_test, lr_probs)\n# plot the roc curve for the model\npyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='Random choose')\npyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n# axis labels\npyplot.xlabel('False Positive Rate')\npyplot.ylabel('True Positive Rate')\npyplot.title('ROC curve')\nplt.grid(True)\n# show the legend\npyplot.legend()\n# show the plot\npyplot.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# random forest\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nmodel_rf = RandomForestClassifier()\nparameters = {'max_depth': [2, 5,10], 'n_estimators':[10,100,1000]}\n\nclf = GridSearchCV(model_rf,parameters, scoring = 'precision', verbose = 10, n_jobs = -1 )\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf.fit(X_train,Y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_rfc= clf.predict(X_test)\npred_rfc[:10]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_test[:10]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(Y_test,pred_rfc))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Model Accuracy:\",clf.score(X_test,Y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\nfrom matplotlib import pyplot\n\n# predict probabilities\nlr_probs = clf.predict_proba(X_test)\n# keep probabilities for the positive outcome only\nlr_probs = lr_probs[:, 1]\n# generate a no skill prediction\nns_probs = [0 for _ in range(len(Y_test))]\n# calculate scores\nns_auc = roc_auc_score(Y_test, ns_probs)\nlr_auc = roc_auc_score(Y_test, lr_probs)\n# summarize scores\nprint('Random choose: ROC AUC=%.3f' % (ns_auc))\nprint('RandomForest: ROC AUC=%.3f' % (lr_auc))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculate roc curves\nns_fpr, ns_tpr, _ = roc_curve(Y_test, ns_probs)\nlr_fpr, lr_tpr, _ = roc_curve(Y_test, lr_probs)\n# plot the roc curve for the model\npyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='Random choose')\npyplot.plot(lr_fpr, lr_tpr, marker='.', label='RandomForest')\n# axis labels\npyplot.xlabel('False Positive Rate')\npyplot.ylabel('True Positive Rate')\npyplot.title('ROC curve')\nplt.grid(True)\n# show the legend\npyplot.legend()\n# show the plot\npyplot.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}