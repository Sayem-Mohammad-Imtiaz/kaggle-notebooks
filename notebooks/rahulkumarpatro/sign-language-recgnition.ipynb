{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nfrom sklearn.model_selection import train_test_split\nimport scikitplot as skplt\nimport time\nimport torch.nn.functional as F \nimport torch.optim as optim\nfrom torch.autograd import Variable","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/sign-language-mnist/sign_mnist_train/sign_mnist_train.csv')\ntest = pd.read_csv('/kaggle/input/sign-language-mnist/sign_mnist_test/sign_mnist_test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_counts  = train[\"label\"].value_counts().sort_index()\nlabel_counts.plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['label'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_fe=train.iloc[:,1:]  # neglecting the label column\ntrain_lab=train['label']  # taking the labels column\n\ntest_fe=test.iloc[:,1:]  # neglecting the label column\ntest_lab=test['label']  # taking the labels column\n# converting to numpy 1d array\n\ntrain_fe_numpy = train_fe.to_numpy()\ntrain_lab_numpy = train_lab.to_numpy()\ntest_fe_numpy = test_fe.to_numpy()\ntest_lab_numpy=test_lab.to_numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_fe.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_fe.iloc[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualising some training examples with it's labels:-->","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_img(data, label):\n    fig, axs = plt.subplots(2,2)\n    k = 0\n    for i in range(2):\n        for j in range(2):        \n            axs[i, j].imshow(data[k].reshape(28, 28))            \n            axs[i, j].set_ylabel(\"label:\" + str(label[k].item()))   \n            k +=4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_img(train_fe_numpy, train_lab_numpy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# These are the signs represented by labels:-","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"signs = {'0': 'A', '1': 'B', '2': 'C', '3': 'D', '4': 'E', '5': 'F', \n         '6': 'G', '7': 'H', '8': 'I', '10': 'K', '11': 'L', '12': 'M', \n         '13': 'N', '14': 'O', '15': 'P', '16': 'Q', '17': 'R', '18': 'S', \n         '19': 'T', '20': 'U', '21': 'V', '22': 'W', '23': 'X', '24': 'Y','25':'Z'}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# The dataset consists of 1D arrays for each image. If we want it to work correctly with CNN, we will need to reshape it into a 2D format. In this specific case, we have 784 pixels of each image that can be reshaped to 28*28.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# So Converting to 2D Format:-","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"reshaped_train = []\nfor i in train_fe_numpy:\n#     print(i)\n    reshaped_train.append(i.reshape(1, 28, 28))\ntrain_data = np.array(reshaped_train)\n\nreshaped_test = []\nfor i in test_fe_numpy:\n    reshaped_test.append(i.reshape(1,28,28))\ntest_data = np.array(reshaped_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Splitting the Dataset:->","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train1,test1,train_label,test_label=train_test_split(train_fe_numpy,train_lab_numpy, test_size=0.2,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train1.shape)\nprint(train_label.shape)\nprint(test1.shape)\nprint(test_label.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# To use Pytorch we must convert the input vectors to tensors from numpy..","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_tensor = torch.as_tensor(train1).type(torch.FloatTensor)\ntrain_label = torch.as_tensor(train_label)\n\ntest_tensor = torch.as_tensor(test1).type(torch.FloatTensor)\ntest_label = torch.as_tensor(test_label)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Convolution Neural Network Architecture:->","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class Convnet(nn.Module):\n    \n    def __init__(self):\n        super(Convnet, self).__init__()\n        \n        \n        self.conv1=nn.Conv2d(1,50,kernel_size=5)\n        self.pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2, padding = 0)\n         # L1 ImgIn shape=(?, 28, 28, 1)      # (n-f+2*p/s)+1\n        #    Conv     -> (?, 24, 24, 50)\n        #    Pool     -> (?, 12, 12, 50)\n        \n        \n        self.conv2 = nn.Conv2d(50,60, kernel_size = 5)\n        self.pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2, padding = 0)\n        # L2 ImgIn shape=(?, 12, 12, 50)\n        #    Conv      ->(?, 8, 8, 60)\n        #    Pool      ->(?, 4, 4, 60)\n        \n        \n        self.conv3 = nn.Conv2d(60, 80,  kernel_size = 3)\n        # L3 ImgIn shape=(?, 4, 4, 60)\n        #    Conv      ->(?, 2, 2, 80)\n       \n        \n        \n        self.batch_norm1 = nn.BatchNorm2d(50)\n        self.batch_norm2 = nn.BatchNorm2d(60)\n        \n#         self.dropout1 = nn.Dropout2d()\n        \n        # L4 FC 2*2*80 inputs -> 250 outputs\n        self.fc1 = nn.Linear(80*2*2, 250) \n        self.fc2 = nn.Linear(250, 25)\n        \n        \n    def forward(self,x):\n        x=self.conv1(x)\n        x = self.batch_norm1(x)\n        x=F.relu(x)\n        x=self.pool1(x)\n        \n        x=self.conv2(x)\n        x = self.batch_norm2(x)\n        x=F.relu(x)\n        x=self.pool2(x)\n        \n        x=self.conv3(x)\n        x=F.relu(x)\n        \n        x = x.view(-1,80*2*2)\n        \n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        \n        x = F.log_softmax(x, dim=1)\n        \n        return x     ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net=Convnet()\n\nnet.eval()  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training Process:-->\n* Do a forward pass\n* Calculate loss function\n* Calculate the gradients\n* Change the weights based on gradients","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Function For Getting Accuracy:->","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_accuracy(predictions, true_labels):\n    _, predicted = torch.max(predictions, 1)\n    corrects = (predicted == true_labels).sum()\n    accuracy = 100.0 * corrects/len(true_labels)\n    return accuracy.item()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Function For Training:->","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def training(loader,model,epochs,criteria,optimizer):\n    \n    tr_accuracy,tr_loss= [], []\n    \n    model.train()\n   \n    \n    for epoch in range(epochs):\n        \n        train_loss = 0 \n        train_accuracy = 0\n        total_batch = 0\n        \n        t0=time.time()\n        for data,labels in loader:\n             # zero the parameters gradient to not accumulate gradients from previous iteration\n            optimizer.zero_grad()\n            \n            \n#             print(data.shape)\n#             print(labels.shape)\n#             put data into the model\n#             model(data.permute(50,5,5,1))\n#             data=data.reshape(50,60,5,5)\n            predictions = net(data)\n            \n            # calculating loss\n            loss = criterion(predictions, labels)\n            \n            # calculating accuracy\n            accuracy = get_accuracy(predictions, labels)\n            \n            # computing gradients\n            loss.backward()\n            \n            # changing the weights\n            optimizer.step()\n            \n            total_batch+=1\n            train_loss += loss.item()\n            train_accuracy += accuracy\n            \n        tfin= time.time()-t0   \n        acc=train_accuracy/total_batch  \n        loss=train_loss/total_batch\n        tr_accuracy.append(acc)\n        tr_loss.append(loss)\n        \n        print(\"Epoch {}/{}\".format(epoch+1,epochs),\"Training Loss: {}\".format(loss),\"Training Accuracy: {}\".format(acc),\"Time: {} seconds\".format(tfin))\n        \n    return tr_accuracy, tr_loss   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_tensor.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# The Input shape of a Pytorch CNN Model is (Number of Batch,Number of Channels,Height of an Image,Width of an Image).\n# So Reshaping :->","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_tensor=train_tensor.reshape(21964,1,28,28) / 255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_tensor.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install torchsummary\nfrom torchsummary import summary","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training:->","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = torch.utils.data.TensorDataset(train_tensor, train_label)\ntrainloader = torch.utils.data.DataLoader(train_dataset, batch_size =50, shuffle = True)\n\nepochs = 30                                              # setting number of epochs\n\nnet = Convnet()                                          # initializing the  network\ncriterion = nn.CrossEntropyLoss()                        # setting criterion\noptimizer = torch.optim.SGD(net.parameters(), lr = 3e-4) # setting optimizer\n\ntr_acc, tr_loss = training(trainloader, net,epochs, criterion, optimizer)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Saving the model for Future Use :->","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(net, 'model_trained.pt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_tensor.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_tensor=test_tensor.reshape(5491,1,28,28) / 255","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Checking The Accuracy of Test Data:->","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"val_pred = net(test_tensor)\nval_loss = criterion(val_pred, test_label)\nval_accuracy = get_accuracy(val_pred, test_label)\n \nprint(\"Loss: \", (val_loss.item()), \"Accuracy: \", (val_accuracy))\n\n# to get class with the maximum score as prediction\n_, val_predicted = torch.max(val_pred.data,1)            \n\nskplt.metrics.plot_confusion_matrix(test_label, val_predicted, figsize=(20,20))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# So we saw that all the predictions are class balanced..","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}