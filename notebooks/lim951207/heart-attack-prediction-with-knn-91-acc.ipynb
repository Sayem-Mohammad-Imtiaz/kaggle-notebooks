{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nfrom pylab import rcParams\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:41:05.490902Z","iopub.execute_input":"2021-06-14T17:41:05.491464Z","iopub.status.idle":"2021-06-14T17:41:06.304875Z","shell.execute_reply.started":"2021-06-14T17:41:05.491383Z","shell.execute_reply":"2021-06-14T17:41:06.303769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set_style(\"darkgrid\")","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:41:06.306386Z","iopub.execute_input":"2021-06-14T17:41:06.306802Z","iopub.status.idle":"2021-06-14T17:41:06.311402Z","shell.execute_reply.started":"2021-06-14T17:41:06.306754Z","shell.execute_reply":"2021-06-14T17:41:06.310378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/heart-attack-analysis-prediction-dataset/heart.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:41:06.313587Z","iopub.execute_input":"2021-06-14T17:41:06.314242Z","iopub.status.idle":"2021-06-14T17:41:06.34096Z","shell.execute_reply.started":"2021-06-14T17:41:06.314195Z","shell.execute_reply":"2021-06-14T17:41:06.339977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Exploration","metadata":{}},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:41:06.342423Z","iopub.execute_input":"2021-06-14T17:41:06.342729Z","iopub.status.idle":"2021-06-14T17:41:06.37272Z","shell.execute_reply.started":"2021-06-14T17:41:06.342699Z","shell.execute_reply":"2021-06-14T17:41:06.371791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:41:06.373958Z","iopub.execute_input":"2021-06-14T17:41:06.374252Z","iopub.status.idle":"2021-06-14T17:41:06.433482Z","shell.execute_reply.started":"2021-06-14T17:41:06.374223Z","shell.execute_reply":"2021-06-14T17:41:06.432535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.columns","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:41:06.434755Z","iopub.execute_input":"2021-06-14T17:41:06.435052Z","iopub.status.idle":"2021-06-14T17:41:06.44111Z","shell.execute_reply.started":"2021-06-14T17:41:06.435022Z","shell.execute_reply":"2021-06-14T17:41:06.440142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:41:06.442419Z","iopub.execute_input":"2021-06-14T17:41:06.442809Z","iopub.status.idle":"2021-06-14T17:41:06.456167Z","shell.execute_reply.started":"2021-06-14T17:41:06.44278Z","shell.execute_reply":"2021-06-14T17:41:06.455084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['age'].nunique()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:41:06.45893Z","iopub.execute_input":"2021-06-14T17:41:06.45929Z","iopub.status.idle":"2021-06-14T17:41:06.471307Z","shell.execute_reply.started":"2021-06-14T17:41:06.459238Z","shell.execute_reply":"2021-06-14T17:41:06.470301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Number of Unique Values for Each Column**","metadata":{}},{"cell_type":"code","source":"for x in data.columns.values:\n    print(x+': '+str(data[x].nunique()))","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:41:06.473031Z","iopub.execute_input":"2021-06-14T17:41:06.47334Z","iopub.status.idle":"2021-06-14T17:41:06.490767Z","shell.execute_reply.started":"2021-06-14T17:41:06.47331Z","shell.execute_reply":"2021-06-14T17:41:06.489799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Create Copied Data for Visualization**","metadata":{}},{"cell_type":"code","source":"c_data = data.copy()\n\nc_data['sex'] = c_data['sex'].map({0:'Male', 1:'Female'})\nc_data['exng'] = c_data['exng'].map({0:'False', 1:'True'})\nc_data['cp'] = c_data['cp'].map({0:'typical angina', 1:'atypical angina', 2:'non-anginal pain', 3:'asymptomatic'})\nc_data['fbs'] = c_data['fbs'].map({0:'False', 1:'True'})\nc_data['output'] = c_data['output'].map({0:'Less Chance', 1:'More Chance'})\n\nc_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:41:06.491852Z","iopub.execute_input":"2021-06-14T17:41:06.492115Z","iopub.status.idle":"2021-06-14T17:41:06.519342Z","shell.execute_reply.started":"2021-06-14T17:41:06.492089Z","shell.execute_reply":"2021-06-14T17:41:06.518376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Visualization**","metadata":{}},{"cell_type":"markdown","source":"**Visualize Categorical Columns (Whose output is 1)**","metadata":{}},{"cell_type":"code","source":"def graph(name, u, title):\n    sns.countplot(x=c_data[name], hue=c_data['output'], ax=u)\n    \n    plt.setp(u.get_xticklabels(), rotation=0)\n    u.set_title(title, fontsize=11, fontdict={\"fontweight\": \"bold\"})\n    \n    for p in u.patches:\n        text = str(int(p.get_height()))\n        u.annotate(text, (p.get_x()+p.get_width()/2, p.get_height()+3),\n                   ha=\"center\", va='center', fontsize=10, fontweight=\"bold\")\n\nfig2, ax2 = plt.subplots(4,2, figsize=(15, 15), gridspec_kw={\"wspace\" : 0.4, \"hspace\" : 0.3, \"top\": 0.95})\n\ncolors=[\"#ff0000\",\"#ff8000\",\"#ffff00\",\"#80ff00\",\"#00ff00\", \"#00ff80\", \"#00ffff\", \"#0080ff\", \"#0000ff\", \"#8000ff\", \"#ff00ff\", \"#ff0080\"]\n\ngraph(\"sex\", ax2[0,0], 'sex')\ngraph(\"exng\", ax2[0,1], 'Exercise induced angina')\ngraph(\"cp\", ax2[1,0], 'Chest Pain Type')\ngraph(\"fbs\", ax2[1,1], 'Fasting Blood Sugar > 120 mg/dl')\ngraph('restecg', ax2[2,0], 'Resting Electrocardiographic Results')\ngraph('caa', ax2[2,1], 'Number of Major Vessels')\ngraph('slp', ax2[3,0], 'Slope')\ngraph('thall', ax2[3,1], 'Thal Rate')\n\nplt.rcParams['axes.axisbelow'] = True","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:41:06.520403Z","iopub.execute_input":"2021-06-14T17:41:06.520664Z","iopub.status.idle":"2021-06-14T17:41:08.273825Z","shell.execute_reply.started":"2021-06-14T17:41:06.520625Z","shell.execute_reply":"2021-06-14T17:41:08.27285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Age Visualization**","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(2, 1,figsize=(12,10))\na = sns.histplot(c_data['age'].loc[c_data['output']=='More Chance'], bins=10, binwidth=10, binrange=(10,80), color='red', ax=ax[0])\nfor p in a.patches:\n    a.annotate(format(p.get_height(), '.2f'), (p.get_x() + p.get_width() / 2., p.get_height()-1), ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')\nax[0].set_title('More Chance of Heart Attack', fontsize=11, fontdict={\"fontweight\": \"bold\"})\n\nb = sns.histplot(c_data['age'].loc[c_data['output']=='Less Chance'], bins=10, binwidth=10, binrange=(10,80), color='blue', ax=ax[1])\nfor p in b.patches:\n    b.annotate(format(p.get_height(), '.2f'), (p.get_x() + p.get_width() / 2., p.get_height()-1), ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')\nax[1].set_title('Less Chance of Heart Attack', fontsize=11, fontdict={\"fontweight\": \"bold\"})\n\nplt.rcParams['axes.axisbelow'] = True","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:41:08.275373Z","iopub.execute_input":"2021-06-14T17:41:08.2759Z","iopub.status.idle":"2021-06-14T17:41:08.784793Z","shell.execute_reply.started":"2021-06-14T17:41:08.27584Z","shell.execute_reply":"2021-06-14T17:41:08.783902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Graphs above show that numerically 50s have the most 'output = 1' counts which indicates more chance of heart attack. However, in percentage, 40s have higher percentgae of 'output = 1' ratio than any other age groups. Other age groups have less than 50% of having more chance of heart attack counts, while 40s have around 70%.","metadata":{"execution":{"iopub.status.busy":"2021-06-13T14:17:57.274962Z","iopub.execute_input":"2021-06-13T14:17:57.275403Z","iopub.status.idle":"2021-06-13T14:17:57.281298Z","shell.execute_reply.started":"2021-06-13T14:17:57.275348Z","shell.execute_reply":"2021-06-13T14:17:57.280096Z"}}},{"cell_type":"markdown","source":"**Visualization of the Continuous Features**","metadata":{}},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:41:08.7862Z","iopub.execute_input":"2021-06-14T17:41:08.786604Z","iopub.status.idle":"2021-06-14T17:41:08.80126Z","shell.execute_reply.started":"2021-06-14T17:41:08.786563Z","shell.execute_reply":"2021-06-14T17:41:08.800599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"con_data = data[['age', 'trtbps', 'chol', 'thalachh', 'oldpeak']]","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:41:08.802295Z","iopub.execute_input":"2021-06-14T17:41:08.802736Z","iopub.status.idle":"2021-06-14T17:41:08.815335Z","shell.execute_reply.started":"2021-06-14T17:41:08.80269Z","shell.execute_reply":"2021-06-14T17:41:08.81436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,8))\nmask = np.triu(np.ones_like(con_data.corr(), dtype=np.bool))\nsns.heatmap(data=con_data.corr(),annot=True,cmap='BrBG',mask=mask)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:41:08.816561Z","iopub.execute_input":"2021-06-14T17:41:08.817034Z","iopub.status.idle":"2021-06-14T17:41:09.146675Z","shell.execute_reply.started":"2021-06-14T17:41:08.816994Z","shell.execute_reply":"2021-06-14T17:41:09.145728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def graph1(name, u, title):\n    sns.kdeplot(x=con_data[name],hue=data['output'], ax=u, shade=True, palette=['#2271b1','#68de7c'])\n    u.set_title(title, fontsize=11, fontdict={\"fontweight\": \"bold\"})\n    \n\nfig2, ax2 = plt.subplots(3,2, figsize=(15, 15), gridspec_kw={\"wspace\" : 0.4, \"hspace\" : 0.3, \"top\": 0.95})\n\ncolors=[\"#ff0000\",\"#ff8000\",\"#ffff00\",\"#80ff00\",\"#00ff00\", \"#00ff80\", \"#00ffff\", \"#0080ff\", \"#0000ff\", \"#8000ff\", \"#ff00ff\", \"#ff0080\"]\n\ngraph1(\"age\", ax2[0,0], 'Age')\ngraph1(\"trtbps\", ax2[0,1], 'Resting Blood Pressure')\ngraph1(\"chol\", ax2[1,0], 'Cholestoral in mg/dl fetched via BMI sensor')\ngraph1(\"thalachh\", ax2[1,1], 'Thal Rate')\ngraph1('oldpeak', ax2[2,0], 'Previous Peak')\n\n\nplt.rcParams['axes.axisbelow'] = True","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:41:09.147774Z","iopub.execute_input":"2021-06-14T17:41:09.148038Z","iopub.status.idle":"2021-06-14T17:41:10.527779Z","shell.execute_reply.started":"2021-06-14T17:41:09.148012Z","shell.execute_reply":"2021-06-14T17:41:10.526796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Interpretation: When the green and blue curves are almost the same, it means the feature does not separate the outcomes. Larger the difference between two curves, More important of the feature**","metadata":{}},{"cell_type":"markdown","source":"# **Data Preprocessing**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:41:10.529097Z","iopub.execute_input":"2021-06-14T17:41:10.529604Z","iopub.status.idle":"2021-06-14T17:41:10.730849Z","shell.execute_reply.started":"2021-06-14T17:41:10.529566Z","shell.execute_reply":"2021-06-14T17:41:10.729909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = data.drop('output', axis=1)\ny = data['output']\n\nsc = StandardScaler()\nscaled_X = sc.fit_transform(X)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:41:10.732219Z","iopub.execute_input":"2021-06-14T17:41:10.732488Z","iopub.status.idle":"2021-06-14T17:41:10.744804Z","shell.execute_reply.started":"2021-06-14T17:41:10.732461Z","shell.execute_reply":"2021-06-14T17:41:10.743879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:41:10.74626Z","iopub.execute_input":"2021-06-14T17:41:10.746537Z","iopub.status.idle":"2021-06-14T17:41:10.755648Z","shell.execute_reply.started":"2021-06-14T17:41:10.746512Z","shell.execute_reply":"2021-06-14T17:41:10.754699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:41:10.756905Z","iopub.execute_input":"2021-06-14T17:41:10.757184Z","iopub.status.idle":"2021-06-14T17:41:10.765845Z","shell.execute_reply.started":"2021-06-14T17:41:10.757141Z","shell.execute_reply":"2021-06-14T17:41:10.764777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape, X_test.shape, y_train.shape, y_test.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:41:10.767351Z","iopub.execute_input":"2021-06-14T17:41:10.767934Z","iopub.status.idle":"2021-06-14T17:41:10.777891Z","shell.execute_reply.started":"2021-06-14T17:41:10.767891Z","shell.execute_reply":"2021-06-14T17:41:10.776955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Machine Learning**","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, roc_auc_score\nfrom sklearn import metrics","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:41:10.779395Z","iopub.execute_input":"2021-06-14T17:41:10.779773Z","iopub.status.idle":"2021-06-14T17:41:11.070052Z","shell.execute_reply.started":"2021-06-14T17:41:10.779743Z","shell.execute_reply":"2021-06-14T17:41:11.068974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1 = LogisticRegression(max_iter=1000)\nmodel1.fit(X_train, y_train)\npred1 = model1.predict(X_test)\nacc1 = accuracy_score(pred1, y_test)\nprint(classification_report(pred1, y_test))\nprint(acc1)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:41:11.073217Z","iopub.execute_input":"2021-06-14T17:41:11.073618Z","iopub.status.idle":"2021-06-14T17:41:11.093589Z","shell.execute_reply.started":"2021-06-14T17:41:11.073586Z","shell.execute_reply":"2021-06-14T17:41:11.092556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2 = GaussianNB()\nmodel2.fit(X_train, y_train)\npred2 = model2.predict(X_test)\nacc2 = accuracy_score(pred2, y_test)\nprint(classification_report(pred2, y_test))\nprint(acc2)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:41:11.095111Z","iopub.execute_input":"2021-06-14T17:41:11.095392Z","iopub.status.idle":"2021-06-14T17:41:11.106447Z","shell.execute_reply.started":"2021-06-14T17:41:11.095365Z","shell.execute_reply":"2021-06-14T17:41:11.10572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model3 = KNeighborsClassifier()\nmodel3.fit(X_train, y_train)\npred3 = model3.predict(X_test)\nacc3 = accuracy_score(pred3, y_test)\nprint(classification_report(pred3, y_test))\nprint(acc3)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:41:11.107611Z","iopub.execute_input":"2021-06-14T17:41:11.107891Z","iopub.status.idle":"2021-06-14T17:41:11.123799Z","shell.execute_reply.started":"2021-06-14T17:41:11.107865Z","shell.execute_reply":"2021-06-14T17:41:11.122927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model4= DecisionTreeClassifier(max_depth=10, min_samples_leaf=15)\nmodel4.fit(X_train, y_train)\npred4 = model4.predict(X_test)\nacc4 = accuracy_score(pred4, y_test)\nprint(classification_report(pred4, y_test))\nprint(acc4)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:41:11.124775Z","iopub.execute_input":"2021-06-14T17:41:11.12516Z","iopub.status.idle":"2021-06-14T17:41:11.137675Z","shell.execute_reply.started":"2021-06-14T17:41:11.125131Z","shell.execute_reply":"2021-06-14T17:41:11.136446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model5 = RandomForestClassifier()\nmodel5.fit(X_train, y_train)\npred5 = model5.predict(X_test)\nacc5 = accuracy_score(pred5, y_test)\nprint(classification_report(pred5, y_test))\nprint(acc5)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:41:11.138968Z","iopub.execute_input":"2021-06-14T17:41:11.139363Z","iopub.status.idle":"2021-06-14T17:41:11.348055Z","shell.execute_reply.started":"2021-06-14T17:41:11.139317Z","shell.execute_reply":"2021-06-14T17:41:11.347092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model6 = SVC()\nmodel6.fit(X_train, y_train)\npred6 = model6.predict(X_test)\nacc6 = accuracy_score(pred6, y_test)\nprint(classification_report(pred6, y_test))\nprint(acc6)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:41:11.349285Z","iopub.execute_input":"2021-06-14T17:41:11.349619Z","iopub.status.idle":"2021-06-14T17:41:11.364222Z","shell.execute_reply.started":"2021-06-14T17:41:11.349588Z","shell.execute_reply":"2021-06-14T17:41:11.363065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model7 = XGBClassifier()\nmodel7.fit(X_train, y_train)\npred7 = model7.predict(X_test)\nacc7 = accuracy_score(pred7, y_test)\nprint(classification_report(pred7, y_test))\nprint(acc7)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:41:11.365595Z","iopub.execute_input":"2021-06-14T17:41:11.365882Z","iopub.status.idle":"2021-06-14T17:41:11.447013Z","shell.execute_reply.started":"2021-06-14T17:41:11.365854Z","shell.execute_reply":"2021-06-14T17:41:11.445465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Model Comparison Table**","metadata":{}},{"cell_type":"code","source":"acc_table = pd.DataFrame({'Model': ['Logistic Regression',\n                                   'Naive Bayes',\n                                   'KNN',\n                                   'Decision Tree',\n                                   'Random Forest Tree',\n                                   'SVC',\n                                   'XGB'],\n                         'Accuracy Score': [acc1,\n                                           acc2,\n                                           acc3,\n                                           acc4,\n                                           acc5,\n                                           acc6,\n                                           acc7]})\nacc_table = acc_table.sort_values(by='Accuracy Score', ascending=False)\nacc_table.style.background_gradient(cmap='Blues')","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:41:11.450659Z","iopub.execute_input":"2021-06-14T17:41:11.452547Z","iopub.status.idle":"2021-06-14T17:41:11.498895Z","shell.execute_reply.started":"2021-06-14T17:41:11.452505Z","shell.execute_reply":"2021-06-14T17:41:11.497743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Best Model Parameter Tuning (KNN)**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.model_selection import RandomizedSearchCV\n\n\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n\nknn = KNeighborsClassifier()\n\nspace = dict()\nspace['n_neighbors'] = [4,5,6,7,8,10]\nspace['weights'] = ['uniform', 'distance']\nspace['leaf_size'] = [10,20,30,40,50]\nspace['algorithm'] = ['auto', 'ball_tree', 'kd_tree', 'brute']\n\nsearch = GridSearchCV(knn, space, scoring='accuracy', n_jobs=-1, cv=cv)\nresult = search.fit(X_train,y_train)\nprint('Best Score: %s' %result.best_score_)\nprint('Best HyperParameters: %s' %result.best_params_)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:41:11.500145Z","iopub.execute_input":"2021-06-14T17:41:11.500545Z","iopub.status.idle":"2021-06-14T17:41:23.155163Z","shell.execute_reply.started":"2021-06-14T17:41:11.500513Z","shell.execute_reply":"2021-06-14T17:41:23.154368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model3 = KNeighborsClassifier(n_neighbors=7, leaf_size=10)\nmodel3.fit(X_train, y_train)\npred3 = model3.predict(X_test)\nacc3 = accuracy_score(pred3, y_test)\nprint(classification_report(pred3, y_test))\nprint(acc3)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:41:23.156194Z","iopub.execute_input":"2021-06-14T17:41:23.156597Z","iopub.status.idle":"2021-06-14T17:41:23.173448Z","shell.execute_reply.started":"2021-06-14T17:41:23.156567Z","shell.execute_reply":"2021-06-14T17:41:23.172623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The Accuracy of the result did not change at all. However, I do not know why the best score from GridSearchCV returns less accuracy than the default KNN Classifier.","metadata":{}},{"cell_type":"markdown","source":"# **ROC Curve of KNN Model**","metadata":{}},{"cell_type":"code","source":"metrics.plot_roc_curve(model3, X_test, y_test)\nprint('roc_auc_score is: ', roc_auc_score(y_test, pred3))","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:41:57.284515Z","iopub.execute_input":"2021-06-14T17:41:57.284902Z","iopub.status.idle":"2021-06-14T17:41:57.491268Z","shell.execute_reply.started":"2021-06-14T17:41:57.284868Z","shell.execute_reply":"2021-06-14T17:41:57.490131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **KNN Visualization**","metadata":{}},{"cell_type":"markdown","source":"Need to find out which features are correlated the most","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,8))\nmask = np.triu(np.ones_like(data.corr(), dtype=np.bool))\nsns.heatmap(data=data.corr(),annot=True,cmap='BrBG',mask=mask)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:41:23.382078Z","iopub.execute_input":"2021-06-14T17:41:23.382364Z","iopub.status.idle":"2021-06-14T17:41:24.160502Z","shell.execute_reply.started":"2021-06-14T17:41:23.382336Z","shell.execute_reply":"2021-06-14T17:41:24.159607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Feature to Feature Correlations - Higher value indicates simillarity of both two features. Therefore, the less value the better.\n* Feature to Outcome Correlations - Higher value indicates the importance of feature \n\nChose feature cp and oldpeak because feature to feature correlation is -0.15 which is low and both of their feature to outcome correlations are high (0.43, -0.43)","metadata":{}},{"cell_type":"code","source":"from matplotlib.colors import ListedColormap\nfrom sklearn.metrics import accuracy_score, classification_report\n# filter warnings\nwarnings.filterwarnings(\"ignore\")\n\ndef accuracy(k, X_train, y_train, X_test, y_test):\n    # instantiate learning model and fit data\n    knn = KNeighborsClassifier(n_neighbors=k)    \n    knn.fit(X_train, y_train)\n\n    # predict the response\n    pred = knn.predict(X_test)\n\n    # evaluate and return  accuracy\n    return accuracy_score(y_test, pred)\n\ndef classify_and_plot(X, y):\n    ''' \n    split data, fit, classify, plot and evaluate results \n    '''\n    # split data into training and testing set\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n\n    # init vars\n    n_neighbors = 7\n    h           = .02  # step size in the mesh\n\n    # Create color maps\n    cmap_light = ListedColormap(['#FFAAAA', '#AAAAFF'])\n    cmap_bold  = ListedColormap(['#FF0000', '#0000FF'])\n\n    rcParams['figure.figsize'] = 5, 5\n        \n    clf = KNeighborsClassifier(n_neighbors)\n    clf.fit(X_train, y_train)\n\n        # Plot the decision boundary. For that, we will assign a color to each\n        # point in the mesh [x_min, x_max]x[y_min, y_max].\n    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                        np.arange(y_min, y_max, h))\n    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n\n        # Put the result into a color plot\n    Z = Z.reshape(xx.shape)\n    fig = plt.figure()\n    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n\n        # Plot also the training points, x-axis = 'Glucose', y-axis = \"BMI\"\n    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold, edgecolor='k', s=20)   \n    plt.xlim(xx.min(), xx.max())\n    plt.ylim(yy.min(), yy.max())\n    plt.title(\"0/1 outcome classification (k = %i)\" % (n_neighbors))\n    plt.show()\n\n        # evaluate\n    y_expected  = y_test\n    y_predicted = clf.predict(X_test)\n\n        # print results\n    print('----------------------------------------------------------------------')\n    print('Classification report')\n    print('----------------------------------------------------------------------')\n    print('\\n', classification_report(y_expected, y_predicted))\n    print('----------------------------------------------------------------------')\n    print('Accuracy = %5s' % round(accuracy(n_neighbors, X_train, y_train, X_test, y_test), 3))\n    print('----------------------------------------------------------------------')\n\n# we only take the best two features and prepare them for the KNN classifier\nrows_nbr = 303 # data.shape[0]\nX_prime  = np.array(data.iloc[:rows_nbr, [2,9]])\nX        = X_prime # preprocessing.scale(X_prime)\ny        = np.array(data.iloc[:rows_nbr, 13])\n\n# classify, evaluate and plot results\nclassify_and_plot(X, y)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:41:24.161772Z","iopub.execute_input":"2021-06-14T17:41:24.162056Z","iopub.status.idle":"2021-06-14T17:41:28.198252Z","shell.execute_reply.started":"2021-06-14T17:41:24.162026Z","shell.execute_reply":"2021-06-14T17:41:28.197243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**KNN Classification with only two features gives us 80% of accuracy which is pretty good**","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}