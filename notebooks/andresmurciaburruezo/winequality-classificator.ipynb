{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cargamos nuestro fichero  de datos winequality-red.csv, el cual descargamos a traves de la plataforma Kaggle, cuyo enlace esta en en la introducción\n# del ejercicio\n# El delimitador de nuestro fiche es la coma, y evitamos cargar la primera line\n# que corresponde al fichero\n\ndataset= np.loadtxt('/kaggle/input/red-wine-quality-cortez-et-al-2009/winequality-red.csv', delimiter=',',skiprows=1)\ndataset.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separamos las columnas con los datos de entrenamiento de los datos esperado\n# Siendo X las primeras 11 columnas las cuales son las variables de las cuales segun la combinación de cada una de las variables da el resultadoç\n# d es donde se encuentra contenida la columna del resultado  la cual es calidad que posee dicho vino\nX= dataset[:, 0:11]\nd = dataset[: , 11]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificamos que en X se encuentran las 1599 filas y las 11 columnas \nX.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificamos que en d se encuentran las 1599 filas y una unica columna\nd.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# COnvertimos una lista de valores a una matriz cuyos elementos son listas de un valor\nprint(d.shape)\nd=np.reshape(d,(-1,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Vamos a aescalar nuestros datos, de cara q eu todos los datos tengan una escala similar y no tengamos datos con diferente escalado\n\nscaler_X = MinMaxScaler()\nscaler_d = MinMaxScaler()\nX = scaler_X.fit_transform(X)\nd = scaler_d.fit_transform(d)\nd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Mostramos los datos que contiene X tras aplicarle el proceso de escalado\nX","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dividimos nuestra matrix X y el vector d en datos de entrenamiento y test\nfrom sklearn.model_selection import train_test_split\n# Queremos que la muestra del test sea el 75% de nuestros datos de cara a obtener una buena cantidad,\n# de datos para nuestro entrenamiento\nX_train, X_test, d_train, d_test = train_test_split(X,d, test_size=0.25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Comprobamos que efectivamente el tamaño de nuestro X_test , X_train\n# las exigencias que le hemos marcado\nprint(X_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Comenzamos a crear nuestro modelo \n\nmodelo = Sequential()\n# Establecemos que el input_dim=11 debido a que tenemos 11 variables a tener en cuenta para el desarrollo de nuestro modelo, luego para el activation,\n# seleccione relu debido a que con la cantidad de variables que tenemos y que algunos valores son altos, en estos casos elñ más adecuado es relu, otra opción podría ser el de sigmoid\n# pero con los resultados obtenidos tras las preubas, descubri que con relu se obtiene un mejor resultado a la hora de hacer la clasificación\nmodelo.add( Dense(12, input_dim=11, kernel_initializer='normal', activation='relu'))\n# Añadimos otra oculta de con valor 5\nmodelo.add( Dense(5, activation='relu',kernel_initializer='normal'))\n# Añadimos la capa de salida con 1\nmodelo.add( Dense(1, activation='relu'))\n\nmodelo.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# compilamos nuestro modelo\n# Para compilar seleccione el optimizer adam dado que como nos comento es el que para estos casos el que más se recomienda, dado que es un optimizador estocastico y \n# que es un metodo con estimaciones adaptativas\nmodelo.compile(loss='mse',optimizer='adam', metrics=['mse','mae'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Entrenamos nuestro modelo que para este caso he decidido hacerlo con 300 epochs y 50 de batch size\nhistory=modelo.fit(X_train, d_train, validation_data=(X_test, d_test),batch_size=50, epochs=300)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs_plot = range(1, len(history.history['mse'])+1, 1)\n\nplt.plot(epochs_plot, history.history['mse'], 'r--',label='Evolucion del Mean square Error')\nplt.plot(epochs_plot, history.history['mae'], 'r-',label='Precision')\nplt.plot(epochs_plot, history.history['val_mse'], 'b--',label='Validacion')\nplt.plot(epochs_plot, history.history['val_mae'], 'b-',label='Validacion')\n\nplt.title('Performance de mi red neuronal')\nplt.ylabel('Error')\nplt.xlabel('Época')\nplt.legend()\nplt.figure()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# vamos a hacer un prueba de nuestro modelo\n# nos invetamos el caso de que tenemos un vino con estas características\nX_new = np.array([[8.0,0.46,0.50,2.8,0.09300000000000001,19.0,95.0,0.99815,3.32,0.6,9.5]])\nX_new = scaler_X.transform(X_new)\nprint(X_new)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Imprimimos el resultado que se obtiene al pasarle este caso, y nos devuelve el resultado de la calidad que obtendría dicho vino\nd_new = modelo.predict(X_new)\n# Tenbemos que tener un factor importante en este caso, y es que el resultado que nos da, no es resultado real, porque para ver el resultado real le tremos que desescalar\n# de cara a ver la calidad autentica que obtendría\nprint(d_new)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Le aplicamos la transformación inversa para poder ver la calidad de este vino que le añadimos\n\n\nd_new = scaler_d.inverse_transform(d_new)\n# Tras aplicarle este inverse_transform ya estaría en la escala real.\nprint('Resultado redondeado = ',d_new.round(decimals=0, out=None))\nprint('Resultado con decimales = ',d_new)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}