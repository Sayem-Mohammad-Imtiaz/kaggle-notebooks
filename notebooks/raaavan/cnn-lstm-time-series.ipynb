{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-16T10:43:15.372324Z","iopub.execute_input":"2021-07-16T10:43:15.372849Z","iopub.status.idle":"2021-07-16T10:43:15.384167Z","shell.execute_reply.started":"2021-07-16T10:43:15.372731Z","shell.execute_reply":"2021-07-16T10:43:15.382964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Link to the EDA and naive time-series model\n## [Energy consumption in NL](https://www.kaggle.com/raaavan/bi-directional-lstm-ts)\n\n(still under construction, I work in this whenever I can)","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Bidirectional, Dense,Dropout,LSTM,Activation, RepeatVector, SimpleRNN\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\n\nfrom datetime import datetime\n\nimport matplotlib.pyplot as plt\n\nimport os, glob","metadata":{"execution":{"iopub.status.busy":"2021-07-16T10:43:15.386117Z","iopub.execute_input":"2021-07-16T10:43:15.386543Z","iopub.status.idle":"2021-07-16T10:43:20.444012Z","shell.execute_reply.started":"2021-07-16T10:43:15.386507Z","shell.execute_reply":"2021-07-16T10:43:20.443175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"years = ['2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020']\ncompanies = ['stedin', 'liander','enduris', 'enexis','westland-infra','rendo','coteq'] ","metadata":{"execution":{"iopub.status.busy":"2021-07-16T10:43:20.445786Z","iopub.execute_input":"2021-07-16T10:43:20.446112Z","iopub.status.idle":"2021-07-16T10:43:20.450704Z","shell.execute_reply.started":"2021-07-16T10:43:20.446078Z","shell.execute_reply":"2021-07-16T10:43:20.449647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = r'../input/dutch-energy/Electricity/' \n\nstedin=[]\nliander = []\nenduris = []\nenexis = []\nwestland_infra = []\nrendo = []\ncoteq = []\n\nfor company in companies:\n    all_files = glob.glob(f\"{path}/{company}*.csv\")\n    for file in all_files:\n        print(company, file)\n        for year in years:\n            if year in file:\n                print(f\"adding column year {year} to {file}\")\n        \n                comp_df = company\n                print(f\"processing for : {comp_df}\")\n                comp_df = pd.read_csv(file, index_col=None, header=0)\n                comp_df['year'] = year\n\n                if company == companies[0]:\n                    stedin.append(comp_df)\n\n                elif company == companies[1]:\n                    liander.append(comp_df)\n                    \n                elif company == companies[2]:\n                        enduris.append(comp_df)\n                        \n                elif company == companies[3]:\n                    enexis.append(comp_df)\n\n                elif company == companies[4]:\n                    westland_infra.append(comp_df)\n\n                elif company == companies[5]:\n                    rendo.append(comp_df)\n\n                elif company == companies[6]:\n                    coteq.append(comp_df)  \n\n\n                \n        print('-------------------------------')\n","metadata":{"execution":{"iopub.status.busy":"2021-07-16T10:43:20.452391Z","iopub.execute_input":"2021-07-16T10:43:20.453051Z","iopub.status.idle":"2021-07-16T10:43:33.355375Z","shell.execute_reply.started":"2021-07-16T10:43:20.453014Z","shell.execute_reply":"2021-07-16T10:43:33.354594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stedin_df = pd.concat(stedin, axis=0, ignore_index=True)\n# liander_df = pd.concat(liander, axis=0, ignore_index=True)\n# enduris_df = pd.concat(enduris, axis=0, ignore_index=True)\n# enexis_df = pd.concat(enexis, axis=0, ignore_index=True)\n# westland_infra_df = pd.concat(westland_infra, axis=0, ignore_index=True)\n# rendo_df = pd.concat(rendo, axis=0, ignore_index=True)\n# coteq_df = pd.concat(coteq, axis=0, ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T10:43:33.356561Z","iopub.execute_input":"2021-07-16T10:43:33.356915Z","iopub.status.idle":"2021-07-16T10:43:33.796033Z","shell.execute_reply.started":"2021-07-16T10:43:33.356877Z","shell.execute_reply":"2021-07-16T10:43:33.795185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stedin_df.info()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-16T10:43:33.79723Z","iopub.execute_input":"2021-07-16T10:43:33.797558Z","iopub.status.idle":"2021-07-16T10:43:34.449713Z","shell.execute_reply.started":"2021-07-16T10:43:33.797524Z","shell.execute_reply":"2021-07-16T10:43:34.448198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stedin_df.isna().sum()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-16T10:43:34.451Z","iopub.execute_input":"2021-07-16T10:43:34.451328Z","iopub.status.idle":"2021-07-16T10:43:35.086366Z","shell.execute_reply.started":"2021-07-16T10:43:34.451289Z","shell.execute_reply":"2021-07-16T10:43:35.08534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stedin_df = stedin_df.drop('STANDAARDDEVIATIE', 1)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-16T10:43:35.089447Z","iopub.execute_input":"2021-07-16T10:43:35.089804Z","iopub.status.idle":"2021-07-16T10:43:35.481037Z","shell.execute_reply.started":"2021-07-16T10:43:35.089767Z","shell.execute_reply":"2021-07-16T10:43:35.48011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stedin_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-16T10:43:35.482969Z","iopub.execute_input":"2021-07-16T10:43:35.483326Z","iopub.status.idle":"2021-07-16T10:43:35.510725Z","shell.execute_reply.started":"2021-07-16T10:43:35.48329Z","shell.execute_reply":"2021-07-16T10:43:35.509473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def normalization_mx(data):\n    \n    \"\"\"takes data and scales it \n    between 0 to 1\n    \"\"\"\n    \n    dataset = data.values.reshape(-1,1)\n\n    sclar = MinMaxScaler(feature_range=(0,1))\n    dataset = sclar.fit_transform(dataset)\n    return dataset\n\n\n\n\ndef normilization(data):\n    \n    \"\"\"takes data and scales it \n    between 0 to 1\n    \"\"\"\n    \n    dataset = data.iloc[:,11].astype('float32')\n    \n    max_value = np.max(dataset)\n    min_value = np.min(dataset)\n    \n    scalar = max_value - min_value\n    dataset = list(map(lambda x: (x-min_value) / scalar, dataset))\n    return np.array(dataset)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T10:43:35.512019Z","iopub.execute_input":"2021-07-16T10:43:35.512396Z","iopub.status.idle":"2021-07-16T10:43:35.51986Z","shell.execute_reply.started":"2021-07-16T10:43:35.512357Z","shell.execute_reply":"2021-07-16T10:43:35.518593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"norm_data = normilization(stedin_df)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T10:43:35.521265Z","iopub.execute_input":"2021-07-16T10:43:35.521725Z","iopub.status.idle":"2021-07-16T10:43:35.950849Z","shell.execute_reply.started":"2021-07-16T10:43:35.521688Z","shell.execute_reply":"2021-07-16T10:43:35.94996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_data(dataset, seq_len):\n    X_train = []\n    y_train = []\n    split_size = int(0.8 * len(dataset))\n    \n    for i in range(seq_len, len(dataset)):\n        X_train.append(dataset[i - seq_len: i, 0])\n        y_train.append(dataset[i, 0])\n\n   \n    X_test = X_train[split_size:]\n    y_test = y_train[split_size:]\n\n   \n    X_train = X_train[:split_size]\n    y_train = y_train[:split_size]\n\n    X_train = np.array(X_train)\n    y_train = np.array(y_train)\n\n    X_test = np.array(X_test)\n    y_test = np.array(y_test)\n\n    return [X_train, y_train, X_test, y_test]","metadata":{"execution":{"iopub.status.busy":"2021-07-16T10:43:35.952173Z","iopub.execute_input":"2021-07-16T10:43:35.952505Z","iopub.status.idle":"2021-07-16T10:43:35.961995Z","shell.execute_reply.started":"2021-07-16T10:43:35.952469Z","shell.execute_reply":"2021-07-16T10:43:35.961158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seq_len = 120 #choose sequence length\nlabel_len = 10 #choose labellen\n\nX_train, y_train, X_test, y_test = load_data(tf.expand_dims(norm_data, axis = 1), seq_len)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T10:43:35.963328Z","iopub.execute_input":"2021-07-16T10:43:35.963704Z","iopub.status.idle":"2021-07-16T10:49:48.14046Z","shell.execute_reply.started":"2021-07-16T10:43:35.963651Z","shell.execute_reply":"2021-07-16T10:49:48.139617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape,X_test.shape,y_train.shape,y_test.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-16T10:49:48.141724Z","iopub.execute_input":"2021-07-16T10:49:48.14206Z","iopub.status.idle":"2021-07-16T10:49:48.148414Z","shell.execute_reply.started":"2021-07-16T10:49:48.142027Z","shell.execute_reply":"2021-07-16T10:49:48.147603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout, MaxPooling1D, TimeDistributed, LSTM, BatchNormalization, Input, concatenate, Conv1D\n\ndef cnn_lstm(train_x, train_y, test_x):\n    \n    model=Sequential()\n    model.add(TimeDistributed(Conv1D(16, 2, padding = \"same\", strides = 1, activation = \"relu\"),input_shape=(None, train_x.shape[1], 1)))\n    model.add(TimeDistributed(MaxPooling1D(2)))\n    model.add(TimeDistributed(Flatten()))\n    model.add(LSTM(50, return_sequences = True))\n    model.add(LSTM(10))\n    model.add(Dense(1, activation = \"relu\"))\n    model.compile(optimizer = \"adam\",loss = \"mse\")\n    \n    model.summary()\n    # reshape from [samples, timesteps] into [samples, subsequences, timesteps, features]\n    history = model.fit(train_x.reshape(len(train_x), 1, train_x.shape[1], 1) ,train_y, batch_size=32, epochs=50, verbose=1, validation_split=0.3)\n    #prediction\n    pred = model.predict(test_x.reshape(len(test_x),1, test_x.shape[1], 1))\n    return model, pred, history","metadata":{"execution":{"iopub.status.busy":"2021-07-16T10:49:48.149987Z","iopub.execute_input":"2021-07-16T10:49:48.150585Z","iopub.status.idle":"2021-07-16T10:49:48.161272Z","shell.execute_reply.started":"2021-07-16T10:49:48.150545Z","shell.execute_reply":"2021-07-16T10:49:48.160517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnnlstm_model, cnnlstm_pred, cnn_history = cnn_lstm(X_train, y_train, X_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T10:49:48.162706Z","iopub.execute_input":"2021-07-16T10:49:48.16307Z","iopub.status.idle":"2021-07-16T12:09:44.387428Z","shell.execute_reply.started":"2021-07-16T10:49:48.163015Z","shell.execute_reply":"2021-07-16T12:09:44.386523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test","metadata":{"execution":{"iopub.status.busy":"2021-07-16T12:09:44.389209Z","iopub.execute_input":"2021-07-16T12:09:44.38961Z","iopub.status.idle":"2021-07-16T12:09:44.39757Z","shell.execute_reply.started":"2021-07-16T12:09:44.389567Z","shell.execute_reply":"2021-07-16T12:09:44.396531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ndef plot_curve(history):\n    plt.figure(figsize=(10, 6))\n\n    # — — — — — — — — — — — — — — — — — — — — — — — — — — — — — -\n    # Retrieve a list of list results on training and test data\n    # sets for each training epoch\n    # — — — — — — — — — — — — — — — — — — — — — — — — — — — — — -\n    loss=history.history['loss']\n    val_loss = history.history['val_loss']\n    epochs=range(len(loss)) # Get number of epochs\n    # — — — — — — — — — — — — — — — — — — — — — — — — \n    # Plot training and validation loss per epoch\n    # — — — — — — — — — — — — — — — — — — — — — — — — \n    plt.plot(epochs, loss, 'b', label = ' loss')\n    plt.plot(epochs, val_loss, 'r', label = 'val loss')\n     \n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.figure()\n    zoomed_loss = loss[25:]\n    zoomed_val_loss = val_loss[25:]\n    zoomed_epochs = range(25,50)\n    # — — — — — — — — — — — — — — — — — — — — — — — — \n    # Plot training and validation loss per epoch\n    # — — — — — — — — — — — — — — — — — — — — — — — — \n    plt.figure(figsize=(10, 6))\n\n    plt.plot(zoomed_epochs, zoomed_loss, 'b', label = 'loss')\n    plt.plot(zoomed_epochs, zoomed_val_loss, 'r', label = 'val loss')\n    plt.title('Training loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.figure()\n    \nplot_curve(cnn_history)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T12:09:44.399297Z","iopub.execute_input":"2021-07-16T12:09:44.39986Z","iopub.status.idle":"2021-07-16T12:09:44.76016Z","shell.execute_reply.started":"2021-07-16T12:09:44.399818Z","shell.execute_reply":"2021-07-16T12:09:44.759198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_predictions(test, predicted, title):\n    plt.figure(figsize=(16, 4))\n   \n    plt.plot(test, color='blue', label='Actual power consumption data')\n    plt.plot(predicted, alpha=0.7, color='red', label='Predicted power consumption data')\n    \n    plt.title(title)\n    plt.xlabel('Time')\n    plt.ylabel('Normalized power consumption scale')\n    \n    plt.legend()\n    plt.show()\n\n\nplot_predictions(y_test[:1000], tf.squeeze(cnnlstm_pred[:1000]), \"Predictions made by model\")","metadata":{"execution":{"iopub.status.busy":"2021-07-16T12:11:14.969669Z","iopub.execute_input":"2021-07-16T12:11:14.970033Z","iopub.status.idle":"2021-07-16T12:11:15.157566Z","shell.execute_reply.started":"2021-07-16T12:11:14.97Z","shell.execute_reply":"2021-07-16T12:11:15.156763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test[:10] - tf.squeeze(cnnlstm_pred[:10])","metadata":{"execution":{"iopub.status.busy":"2021-07-16T12:09:44.935476Z","iopub.execute_input":"2021-07-16T12:09:44.935853Z","iopub.status.idle":"2021-07-16T12:09:44.943753Z","shell.execute_reply.started":"2021-07-16T12:09:44.935814Z","shell.execute_reply":"2021-07-16T12:09:44.942803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.squeeze(cnnlstm_pred[:10])","metadata":{"execution":{"iopub.status.busy":"2021-07-16T12:09:44.945358Z","iopub.execute_input":"2021-07-16T12:09:44.945874Z","iopub.status.idle":"2021-07-16T12:09:44.95413Z","shell.execute_reply.started":"2021-07-16T12:09:44.945831Z","shell.execute_reply":"2021-07-16T12:09:44.953196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error,mean_absolute_error\ndef mean_absolute_percentage_error(y_true, y_pred):\n    \"\"\"MAPE\"\"\"\n    error=np.array(np.abs((y_true - y_pred) / y_true))\n    mse=np.mean(error,axis=0) * 100\n    return mse","metadata":{"execution":{"iopub.status.busy":"2021-07-16T12:09:44.95562Z","iopub.execute_input":"2021-07-16T12:09:44.956024Z","iopub.status.idle":"2021-07-16T12:09:44.962191Z","shell.execute_reply.started":"2021-07-16T12:09:44.955962Z","shell.execute_reply":"2021-07-16T12:09:44.961212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mean_absolute_percentage_error(y_test, cnnlstm_pred)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T12:09:44.966062Z","iopub.execute_input":"2021-07-16T12:09:44.966584Z","iopub.status.idle":"2021-07-16T12:09:44.972449Z","shell.execute_reply.started":"2021-07-16T12:09:44.966544Z","shell.execute_reply":"2021-07-16T12:09:44.971748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def eval_score(y_test, y_true):\n    mae = mean_absolute_error(y_test, y_true)\n    mse = mean_squared_error(y_test, y_true)\n     \n    \n    return f\"mae : {mae}, mse : {mse}\"","metadata":{"execution":{"iopub.status.busy":"2021-07-16T12:09:44.974896Z","iopub.execute_input":"2021-07-16T12:09:44.975144Z","iopub.status.idle":"2021-07-16T12:09:44.98378Z","shell.execute_reply.started":"2021-07-16T12:09:44.975119Z","shell.execute_reply":"2021-07-16T12:09:44.982968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eval_score(y_test, cnnlstm_pred)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T12:09:44.98496Z","iopub.execute_input":"2021-07-16T12:09:44.985293Z","iopub.status.idle":"2021-07-16T12:09:44.998412Z","shell.execute_reply.started":"2021-07-16T12:09:44.98526Z","shell.execute_reply":"2021-07-16T12:09:44.997394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evluation(real,pred,data,data_name):\n    \"\"\"Real: the true value\n       Pred: predicted value\n       Data: the name of data\"\"\"\n    dataset = data.iloc[:,11].astype('float32')\n    max_value = np.max(dataset)\n    min_value = np.min(dataset)\n    scalar = max_value - min_value\n    pred=pd.DataFrame(list(map(lambda x: x*scalar+min_value ,pred)))\n    real=pd.DataFrame(list(map(lambda x: x*scalar+min_value ,real)))\n    mse=mean_squared_error(real,pred)\n    print(\"MSE of %s is %f\"%(data_name,mse))\n    mae=mean_absolute_error(real,pred)\n    print(\"MAE of %s is %f\"%(data_name,mae))\n    rmse=np.sqrt(mean_squared_error(real,pred))\n    print(\"RMSE of %s is %f\"%(data_name,rmse))\n#     mape=mean_absolute_percentage_error(real,pred)\n#     print(\"MAPE of %s is %f\"%(data_name,mape))","metadata":{"execution":{"iopub.status.busy":"2021-07-16T12:09:44.999854Z","iopub.execute_input":"2021-07-16T12:09:45.000208Z","iopub.status.idle":"2021-07-16T12:09:45.007433Z","shell.execute_reply.started":"2021-07-16T12:09:45.000175Z","shell.execute_reply":"2021-07-16T12:09:45.00633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evluation(y_test, tf.squeeze(cnnlstm_pred), stedin_df, 'stedin-data')","metadata":{"execution":{"iopub.status.busy":"2021-07-16T12:09:45.008946Z","iopub.execute_input":"2021-07-16T12:09:45.009434Z","iopub.status.idle":"2021-07-16T12:10:37.906059Z","shell.execute_reply.started":"2021-07-16T12:09:45.009331Z","shell.execute_reply":"2021-07-16T12:10:37.904551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}