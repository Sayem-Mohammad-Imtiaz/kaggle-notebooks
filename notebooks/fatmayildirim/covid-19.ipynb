{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **COVID-19 **","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Covid-19 olarak adlandırılan Çin ‘in Hubei eyaletinin başkenti Wuhan’ da ortaya çıkan virüs için  22 Ocak 2020 ve 4 Haziran 2020 tarihleri aralığındaki dünya ülkelerinin ‘Covid Pozitif Hasta Sayısı’ , ‘İyileşen Hasta Sayısı’ , ‘Hayatını Kaybeden Hasta Sayısı’ değerlerini içermektedir.**","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nworld = pd.read_csv(\"../input/corona-virus-report/covid_19_clean_complete.csv\")\nworld.head(-5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"•\tÖncelikli olarak satır sayısı,veri tipi ve değişken isimleri öğrenilerek dataset hakkında genel bilgiye sahip olundu.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Satir Sayisi\nprint(\"Satır Sayısı:\\n\",world.shape[0:])\n\n# Sutun Adlari\nprint(\"Sütun Adlari:\\n\",world.columns.tolist())\n\n# Veri Tipleri\nprint(\"Veri Tipleri:\\n\",world.dtypes)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"•\tDataset üzerinde analiz , modelleme yapabilmek için eksik veri sayısı kontrol edildi. Bu gözlem sonucunda yalnızca ‘Who Region’ değişkeninde eksik veri olduğu gözlemlendi.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Eksik veri sayıları ve veri setindeki oranları \nimport matplotlib.pyplot as plt\nimport seaborn as sns\npd.concat([world.isnull().sum(), 100 * world.isnull().sum()/len(world)], \n              axis=1).rename(columns={0:'Missing Records', 1:'Percentage (%)'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Kategorik değişkenlerde boş alanlar;\n\n*  Tepe değer(mode) kullanılarak en fazla frekansa sahip olan değer ile eksik veriler doldurulabilir.\n \n*  Eksik/kayıp veriler etiketlenerek model ya da analiz için değerlendirilebilir.\n \n*  Lojistik regresyon ya da ANOVA gibi yöntemler ile eksik değerler tahmin edilebilir.\n\n'Who Region' kategorik bir değişken olduğu için o sutun içerisindeki boş alanlar 'Other' ile dolduruldu.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"world[\"WHO Region\"].fillna(\"Other\", inplace = True)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"world.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"'Who Region' değişkeni içerisinde \"Other\" değerinin de oluşturuldu görülüyor.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"world['WHO Region'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Eksik veri analizinden sonra dataframedeki sürekli değişkenler için describe metodu ile \"count,mean ,min ,max\" değerleri öğrenildi.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"world.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Veri seti içerisinden belli alanlar seçilerek yeni bir veriseti oluşturuldu.\ndf1=pd.Series(world['Country/Region'],name=\"Country\")\ndf2=pd.Series(world['Date'],name=\"Date\")\ndf3=pd.Series(world['Confirmed'],name=\"Confirmed\")\ndf4=pd.Series(world['Deaths'],name=\"Deaths\")\ndf5=pd.Series(world['Recovered'],name=\"Recovered\")\ndf_world=pd.concat([df1, df2,df3, df4,df5], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Türkiye için \"Deaths, Recovered ve Confirmed\" arasındaki ilişkiyi gözlemleyebilmek adına korelasyon grafiği oluşturuldu.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#türkiye için korelasyon grafiği\nturkey=df_world.copy()\nturkey_values = (turkey['Country'] == 'Turkey').astype(int)\nfields = list(turkey.columns[1:])  # everything except \"country name\"\ncorrelations = turkey[fields].corrwith(turkey_values)\ncorrelations.sort_values(inplace=True)\ncorrelations\nax = correlations.plot(kind='bar')\nax.set(ylim=[0, 0.5], ylabel='turkey correlation');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Aykırı değer gözlemi yapabilmek adına sürekli değişkenler için boxplotlar oluşturuldu. Aykırı değer analizi ile değişkenler içerisindeki değerlerin ortalama ile mi seyrettiği yoksa büyük farklılıkların mı olduğu sonucuna varırız.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\ndf_world.boxplot(column=['Confirmed','Deaths','Recovered'])\n\nfig,axs=plt.subplots(2,2) \naxs[0, 0].boxplot(df_world['Confirmed'])\naxs[0, 0].set_title('Hasta Sayısı')\n\naxs[0, 1].boxplot(df_world['Recovered'])\naxs[0, 1].set_title('İyileşen Hasta Sayısı')\n\naxs[1, 0].boxplot(df_world['Deaths'])\naxs[1, 0].set_title('Hayatını Kaybeden Hasta Sayısı')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Enlem ve boylam değerlerinin de olduğu yeni bir dataframe oluşturuldu. \n# Değerler 1/22/2020 - 25/05/2020 tarihleri aralığını içermektedir.\ndf_1=df_world\ndf_2=pd.Series(world['Long'],name=\"Long\")\ndf_3=pd.Series(world['Lat'],name=\"Lat\")\ndf_4=pd.Series(world['WHO Region'],name=\"Region\")\ndf_location=pd.concat([df_1,df_2,df_3,df_4], axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_location.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"İçerisinde ülkelerin koordinatlarının yer aldığı yeni dataframe ile harita üzerinden ülkelerin  ‘Covid Pozitif Hasta Sayısı’(Confirmed) , ‘İyileşen Hasta Sayısı’(Recovered) , ‘Hayatını Kaybeden Hasta Sayısı’(Deaths) değerleri görselleştirildi. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Zaman İçerisindeki Değişim\nimport plotly.express as px\nfig = px.choropleth(df_location, locations=\"Country\", locationmode='country names', color=np.log(df_location[\"Confirmed\"]), \n                    hover_name=\"Country\", animation_frame=df_location[\"Date\"],\n                    title='Zaman İçerisindeki Değişim', color_continuous_scale=px.colors.sequential.Purp)\nfig.update(layout_coloraxis_showscale=False)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import folium\n# World wide\ntemp = df_location[df_location['Date'] == max(df_location['Date'])]\nm = folium.Map(location=[0, 0], titles='Dünya Haritası Üzerinde Değerler',\n               min_zoom=1, max_zoom=4, zoom_start=1)\n\nfor i in range(0, len(temp)):\n    folium.Circle(\n        location=[temp.iloc[i]['Lat'], temp.iloc[i]['Long']],\n        color='crimson', fill='crimson',\n        tooltip =   '<li><bold>Country : '+str(temp.iloc[i]['Country'])+\n                    '<li><bold>Province : '+str(temp.iloc[i]['Region'])+\n                    '<li><bold>Confirmed : '+str(temp.iloc[i]['Confirmed'])+\n                    '<li><bold>Deaths : '+str(temp.iloc[i]['Deaths']),\n        radius=int(temp.iloc[i]['Confirmed'])**0.5).add_to(m)\nm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Bu kezde bar plotlar üzerinde 'Region' değişkeni görselleştirildi. Böylelikle bölgelere göre \"Test Sonucu Pozitif Olan Hasta Sayısı,İyileşen Hasta Sayısı,Hayatını Kaybeden Hasta Sayısı\" gözlemlenmiş oldu.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\nfig = px.bar(df_location.sort_values(\"Confirmed\"),\n            x='Region', y=\"Confirmed\",\n            hover_name=\"Region\",\n            hover_data=[\"Recovered\",\"Deaths\",\"Confirmed\"],\n            title='COVID-19: Test Sonucu Pozitif Olan Hasta Sayısı Bölgelere Göre',\n)\nfig.update_xaxes(title_text=\"Region\")\nfig.update_yaxes(title_text=\"Positif Test Sayısı(%)\")\nfig.show()\nfig = px.bar(df_location.sort_values(\"Recovered\"),\n            x='Region', y=\"Recovered\",\n            hover_name=\"Region\",\n            hover_data=[\"Confirmed\",\"Deaths\",\"Recovered\"],\n            title='COVID-19: İyileşen Hasta Sayısı Bölgelere Göre',\n)\nfig.update_xaxes(title_text=\"Region\")\nfig.update_yaxes(title_text=\"İyileşen Hasta Sayısı\")\nfig.show()\nfig = px.bar(df_location.sort_values(\"Deaths\"),\n            x='Region', y=\"Deaths\",\n            hover_name=\"Region\",\n            hover_data=[\"Confirmed\",\"Recovered\",\"Deaths\"],\n            title='COVID-19: Hayatını Kaybeden Hasta Sayısı Bölgelere Göre ',\n)\nfig.update_xaxes(title_text=\"Region\")\nfig.update_yaxes(title_text=\"Hayatını Kaybeden Hasta Sayısı\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Bu dataframe için 'Deaths ,Recovered ,Confirmed ' değişkenleri üzerinden 'Recovered'(İyileşen hasta sayısı) üzerine tahminleme yapılmıştır. \n\nVeri modellemeden önce normalize edildi.Bunu yaparken de MinMaxScaler kullanıldı.\n\n* Bu yöntemde, bir grup verinin içerisindeki en büyük ve en küçük değerler ele alınır. Diğer bütün veriler, bu değerlere göre normalleştirilir. \n\nBunun için beş farklı sınıflandırma ve regresyon algoritması seçilmiştir.\nBunlar;\n* SVR(Support Vector Regressions)\n* Lineer Regresyon\n* GaussianNB\n* KNN\n* Decision Tree\n\nBaşarı kıyaslamaları içinde ;\n* confusion matrix (karışıklık matrisi) \n* classification report(sınıflandırma raporları)  \n* MSE\n\nkullanıldı.\n\nBaşarı kıyaslamaları sonuçlarına bakıldığında en iyi sonuçlar Lineer Regresyon ve SVR ile elde edilmiştir.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n\nX = df_world.iloc[:,2:5]\ny = df_world['Recovered']\n\nfrom sklearn.preprocessing import MinMaxScaler\nmms = MinMaxScaler()\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.3, random_state=0)\nX_train = mms.fit_transform(X_train) \nX_test= mms.fit_transform(X_test)\nprint(\"Dataframe boyutu: \",df_world.shape)\nprint(\"Eğitim verisi boyutu: \",X_train.shape, y_train.shape)\nprint(\"Test verisi boyutu: \",X_test.shape,y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# type error için target typesı \"Label Encoder\" ile  multiclassa çevirdim.(Target=Y_train)\nfrom sklearn import preprocessing\nfrom sklearn import utils\n\nlab_enc = preprocessing.LabelEncoder()\nencoded = lab_enc.fit_transform(y)\nprint(utils.multiclass.type_of_target(y))\nprint(utils.multiclass.type_of_target(y_train.astype('int')))\nprint(utils.multiclass.type_of_target(encoded))\n\nlab_enc = preprocessing.LabelEncoder()\nY_train = lab_enc.fit_transform(y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn    import metrics, svm\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn import  linear_model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Her bir modelin doğruluk değeri ,sınıflandırma raporu , karışıklık matrisi ve MSE(Ortalama Kare Hata Regresyon Oranı) değerlerini hesaplamak için import edildi.\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lineer Regresyon\nprint(\"\\nLineer Regresyon\")\nlm = linear_model.LinearRegression()\nmodel = lm.fit(X_train, Y_train)\ny_true1 , y_pred1 =y_test,lm.predict(X_test)\nprint(\"\\nTahmin değerleri: \",y_pred1)\nplt.scatter(y_true1, y_pred1,c='orange')\nplt.scatter(y_true1, y_test,c='green')\nplt.xlabel(\"True Values\")\nplt.ylabel(\"Predictions\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lineer Regresyon\n#predictions multiclass olduğundan y_validation da multiclassa dönüştürüldü\nencoded_v = lab_enc.fit_transform(y_true1)\nutils.multiclass.type_of_target(y_true1.astype('int'))\nypred1= lab_enc.fit_transform(y_pred1)\nutils.multiclass.type_of_target(ypred1.astype('int'))\nconf=confusion_matrix(encoded_v, ypred1)\nprint(\"\\nConfusion matrix :\\n\",conf)\nprint(\"Accuracy score(Doğruluk değeri):\\n\",accuracy_score(encoded_v, ypred1))\nprint(\"\\nClassification Report:\\n\",classification_report(encoded_v, ypred1))\nprint(\"MSE:\",mean_squared_error(encoded_v, ypred1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# SVR(Support Vector Regressions)\nprint(\"SVR(Support Vector Regressions)\")\nclf = svm.SVR(gamma=\"auto\")\n# modelimizi eğitim verilerimiz ve buna karşılık gelen Y_train(target ) değerleri ile eğittik\nclf.fit(X_train, Y_train)\n# test değerlerimize karşılık gelecek olan tahmin değerlerimizi oluşturduk\ny_true2 , y_pred2 =y_test,clf.predict(X_test)\nprint(\"\\nTahmin değerleri: \",y_pred2)\nplt.scatter(y_true2, y_pred2,c='black')\nplt.scatter(y_true2, y_test,c='green')\nplt.xlabel(\"True Values\")\nplt.ylabel(\"Predictions\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#SVR\n#predictions multiclass olduğundan y_validation da multiclassa dönüştürüldü\nencoded_v1 = lab_enc.fit_transform(y_true2)\nutils.multiclass.type_of_target(y_true2.astype('int'))\nypred2= lab_enc.fit_transform(y_pred2)\nutils.multiclass.type_of_target(ypred2.astype('int'))\nconf=confusion_matrix(encoded_v1, ypred2)\nprint(\"\\nConfusion matrix :\\n\",conf)\nprint(\"Accuracy score(Doğruluk değeri):\\n\",accuracy_score(encoded_v1, ypred2))\nprint(\"\\nClassification Report:\\n\",classification_report(encoded_v1, ypred2))\nprint(\"MSE:\",mean_squared_error(encoded_v1, ypred2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Naive Bayes Algoritmasının Gaussian seçilmiştir çünkü veriler süreklidir.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# GaussianNB\nprint(\"GaussianNB\")\nclf = GaussianNB()\nclf.fit(X_train, Y_train)\ny_true3 , y_pred3=y_test,clf.predict(X_test)\nprint(\"\\nTahmin değerleri: \",y_pred3)\nplt.scatter(y_true3, y_pred3,c='grey')\nplt.scatter(y_true3, y_test,c='green')\nplt.xlabel(\"True Values\")\nplt.ylabel(\"Predictions\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# GaussianNB\n#predictions multiclass olduğundan y_validation da multiclassa dönüştürüldü\nencoded_v2 = lab_enc.fit_transform(y_true3)\nutils.multiclass.type_of_target(y_true3.astype('int'))\nypred3= lab_enc.fit_transform(y_pred3)\nutils.multiclass.type_of_target(ypred3.astype('int'))\nconf=confusion_matrix(encoded_v2, ypred3)\nprint(\"\\nConfusion matrix :\\n\",conf)\nprint(\"Accuracy score(Doğruluk değeri):\\n\",accuracy_score(encoded_v2, ypred3))\nprint(\"\\nClassification Report:\\n\",classification_report(encoded_v2, ypred3))\nprint(\"MSE:\",mean_squared_error(encoded_v2, ypred3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Decision Tree Classifier\nprint(\"Decision Tree Classifier\")\nclf = DecisionTreeClassifier()\nclf.fit(X_train, Y_train)\ny_true5 , y_pred5=y_test,clf.predict(X_test)\nprint(\"\\nTahmin değerleri: \",y_pred5)\nplt.scatter(y_true5, y_pred5,c='brown')\nplt.scatter(y_true5, y_test,c='green')\nplt.xlabel(\"True Values\")\nplt.ylabel(\"Predictions\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predictions multiclass olduğundan y_validation da multiclassa dönüştürüldü\nencoded_v4 = lab_enc.fit_transform(y_true5)\nutils.multiclass.type_of_target(y_true5.astype('int'))\nypred5= lab_enc.fit_transform(y_pred5)\nutils.multiclass.type_of_target(ypred5.astype('int'))\nconf=confusion_matrix(encoded_v4, ypred5)\nprint(\"\\nConfusion matrix :\\n\",conf)\nprint(\"Accuracy score(Doğruluk değeri):\\n\",accuracy_score(encoded_v4, ypred5))\nprint(\"\\nClassification Report:\\n\",classification_report(encoded_v4, ypred5))\nprint(\"MSE:\",mean_squared_error(encoded_v4, ypred5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# KNeighborsClassifier\nprint(\"KNeighbors Classifier\")\nclf = KNeighborsClassifier()\nclf.fit(X_train, Y_train)\ny_true7 , y_pred7=y_test,clf.predict(X_test)\nprint(\"\\nTahmin değerleri: \",y_pred7)\nplt.scatter(y_true7, y_pred7,c='blue')\nplt.scatter(y_true7, y_test,c='green')\nplt.xlabel(\"True Values\")\nplt.ylabel(\"Predictions\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predictions multiclass olduğundan y_validation da multiclassa dönüştürüldü\nencoded_v6 = lab_enc.fit_transform(y_true7)\nutils.multiclass.type_of_target(y_true7.astype('int'))\nypred7= lab_enc.fit_transform(y_pred7)\nutils.multiclass.type_of_target(ypred7.astype('int'))\nconf=confusion_matrix(encoded_v6, ypred7)\nprint(\"\\nConfusion matrix :\\n\",conf)\nprint(\"Accuracy score(Doğruluk değeri):\\n\",accuracy_score(encoded_v6, ypred7))\nprint(\"\\nClassification Report:\\n\",classification_report(encoded_v6, ypred7))\nprint(\"MSE:\",mean_squared_error(encoded_v6, ypred7))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}