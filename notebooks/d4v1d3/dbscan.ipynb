{"cells":[{"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input/realAWSCloudwatch/realAWSCloudwatch/\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","outputs":[],"metadata":{"_uuid":"754863590fc856a6d6f05f2571321c1aa2b6ec43","_cell_guid":"d0e8d300-9bfd-46c5-a98d-08d84344e7f6"},"cell_type":"code","execution_count":null},{"source":"import numpy as np\n\nfrom sklearn.cluster import DBSCAN\nfrom sklearn import metrics\nfrom sklearn.datasets.samples_generator import make_blobs\nfrom sklearn.preprocessing import StandardScaler\nimport warnings\nimport itertools\nimport pandas as pd\nimport numpy as np\nimport datetime as dt\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\n\nfpath = \"../input/\"\nfname = \"iap.csv\"\nfpath = \"../input/realAWSCloudwatch/realAWSCloudwatch/\"\nfname = \"ec2_cpu_utilization_825cc2.csv\"\n# fname = \"grok_asg_anomaly.csv\"\n\nfullPath = fpath + fname\n\ndef parser(x):\n\treturn dt.datetime.strptime(x, \"%Y-%m\")\n# return dt.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\")\n\n\ndata = pd.read_csv(fullPath)\ndata.plot()\n","outputs":[],"metadata":{"_uuid":"e19f38ba3db998770dbc30c0b996b7e28ccaf87d","_cell_guid":"75b885b3-ea33-4784-9357-b28165c85c41"},"cell_type":"code","execution_count":null},{"source":"\na = []\nx = []\ny=[]\nfor i in range(0, len(data)-1):\n    a.append([i,data[\"value\"][i]])    \n\nX = a\n\nX = StandardScaler().fit_transform(X)\nfor i in range(0,len(X)):\n    x.append(X[i][0])\n    y.append(X[i][1])\n\nplt.scatter(x,y)\nplt.show()\n","outputs":[],"metadata":{"_uuid":"da954ea66d76659fddd4722c4b9b3a74f124202c","_cell_guid":"7ad31c20-66f3-4059-b0ef-a977c4288d51"},"cell_type":"code","execution_count":null},{"source":"db = DBSCAN(eps=0.5, min_samples=200).fit(X)\ncore_samples_mask = np.zeros_like(db.labels_, dtype=bool)\ncore_samples_mask[db.core_sample_indices_] = True\nlabels = db.labels_\n\n# Number of clusters in labels, ignoring noise if present.\nn_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n\nprint('Estimated number of clusters: %d' % n_clusters_)\n\nunique_labels = set(labels)\nplt.figure(num=None, figsize=(10, 10), facecolor='w', edgecolor='k')\nfor k in unique_labels:\n    col=[0,0.5,1,1]\n    if k == -1:\n        col = [1, 0, 0, 1]\n    class_member_mask = (labels == k)\n\n    xy = X[class_member_mask & core_samples_mask]\n    plt.plot(xy[:, 0], xy[:, 1], 'o', color=tuple(col),markersize=5, alpha=0.5)\n\n    xy = X[class_member_mask & ~core_samples_mask]\n    plt.plot(xy[:, 0], xy[:, 1], 'o', color=tuple(col), markersize=5, alpha=0.5)\n\nplt.title('Estimated number of clusters: %d' % n_clusters_)\nplt.show()","outputs":[],"metadata":{"_uuid":"85c83e84b246a6715b9452349fa20d56b52bc5ae","_cell_guid":"e9afddcc-9ec5-46dd-b569-ed4780af9cfd"},"cell_type":"code","execution_count":null}],"metadata":{"language_info":{"version":"3.6.3","file_extension":".py","mimetype":"text/x-python","codemirror_mode":{"version":3,"name":"ipython"},"nbconvert_exporter":"python","pygments_lexer":"ipython3","name":"python"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat_minor":1,"nbformat":4}