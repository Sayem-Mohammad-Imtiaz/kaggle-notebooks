{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"cell_type":"markdown","source":"Apply the classification algorithms Naive Bayes, Logistic regression and K-Nearest neighbours on the attached imdb dataset of review texts and review sentiment.\n\nConvert the review text to Bag-of-Word (BOW) model with TF-IDF weights (text preprocessing should be applied first) and predict the review sentiment (positive or negative). Use label encoding to convert the sentiment feature to numerical values. The training/test split for the dataset should be 80/20.\n\nprint the accuracy score for each algorithm on the test dataset to find the most accurate model among the three created models."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\n\nimport re\nimport string\nnltk.download('wordnet')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imdb_df = pd.read_csv(\"../input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(imdb_df.shape)\nimdb_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Sampling data ML models will take a long time"},{"metadata":{"trusted":true},"cell_type":"code","source":"imdb_df = imdb_df.sample(frac=0.1, random_state=1)\nimdb_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Applying noise removal to the review column"},{"metadata":{"trusted":true},"cell_type":"code","source":"punct = \"\\n\\r\"+string.punctuation\n\ndef noise_removal(value):\n    return value.translate(str.maketrans('', '', punct))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before noise removal:"},{"metadata":{"trusted":true},"cell_type":"code","source":"imdb_df['review'].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After noise removal:"},{"metadata":{"trusted":true},"cell_type":"code","source":"imdb_df['review'].head().apply(noise_removal)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imdb_df['review'] = imdb_df['review'].apply(noise_removal)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Stop words removal on the review column & TF-IDF Term Weighting"},{"metadata":{"trusted":true},"cell_type":"code","source":"def tokenize(str_input):\n    words = re.sub(r\"(?u)[^A-Za-z]\", \" \", str_input).lower().split(\" \")\n    words = [stemmer.stem(word) for word in words if len(word)>2]\n    words = [wordnet_lemmatizer.lemmatize(word) for word in words if len(word)>2]\n    return words","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stemmer = PorterStemmer()\nwordnet_lemmatizer = WordNetLemmatizer()\n\nvectorizer = TfidfVectorizer(tokenizer=tokenize, stop_words='english')\n\nvectors = vectorizer.fit_transform(imdb_df['review'])\n\nfeature_names = vectorizer.get_feature_names()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(feature_names[:100])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"number of words = \", len(feature_names))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imdb_tfidf = pd.DataFrame(vectors.toarray(),columns=feature_names)\nimdb_tfidf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imdb_tfidf.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Converting sentiment column to numerical value"},{"metadata":{"trusted":true},"cell_type":"code","source":"imdb_df['sentiment'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sentiment_to_numerical(value):\n    return 1 if value == \"positive\" else 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentiment = imdb_df['sentiment'].apply(sentiment_to_numerical)\nsentiment.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(sentiment.shape)\nsentiment.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Multinomial Naive Bayes"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(imdb_tfidf, sentiment, test_size=0.2, random_state=0)\n\nprint(\"size of dataset: \",imdb_tfidf.shape)\nprint(\"size of training dataset: \",x_train.shape)\nprint(\"size of test dataset: \",x_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = MultinomialNB()\nbayes_clf = clf.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = bayes_clf.predict(x_test)\nprint(\"Accuracy = \",bayes_clf.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import linear_model\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"C = [0.01, 0.1, 0.2, 0.5, 0.8, 1, 5, 10, 20, 50]\nLRtrainAcc = []\nLRtestAcc = []\n\n\nfor param in C:\n    clf = linear_model.LogisticRegression(C=param)\n    clf.fit(x_train, y_train)\n    y_pred_train = clf.predict(x_train)\n    y_pred_test = clf.predict(x_test)\n    LRtrainAcc.append(accuracy_score(y_train, y_pred_train))\n    LRtestAcc.append(accuracy_score(y_test, y_pred_test))\n\nclf = linear_model.LogisticRegression(C=1.0)  \nprint(\"Accuracy= \",clf.fit(x_train, y_train).score(x_test,y_test))\nfig, ax1 = plt.subplots(1, 1, figsize=(12,6))\nax1.plot(C, LRtrainAcc, 'ro-', C, LRtestAcc,'bv--')\nax1.legend(['Training Accuracy','Test Accuracy'])\nax1.set_xlabel('C')\nax1.set_xscale('log')\nax1.set_ylabel('Accuracy')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### K-Nearest neighbor"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)\nclf.fit(x_train, y_train)\nY_predTrain = clf.predict(x_train)\nY_predTest = clf.predict(x_test)\nprint(accuracy_score(y_train, Y_predTrain))\nprint(accuracy_score(y_test, Y_predTest))\nprint(\"accuracy= \", clf.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Final Results\n\n- Multinomial Naive Bayes: 81.3 %\n- Logistic regression: 85%\n- K-Nearest neighbor classifier: 70%"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}