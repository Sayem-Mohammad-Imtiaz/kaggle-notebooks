{"cells":[{"metadata":{},"cell_type":"markdown","source":"># **Rent analysis and prediction with Pytorch and Sklearn** \n\n![](https://images.unsplash.com/photo-1483729558449-99ef09a8c325?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=600&q=60)\n\n> Lets first import our datasets and at the end of this hopefully we will know the prices of those houses in that image"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* We will be using plotly for plotting our graphs\n* It is a very simple easy to use python library , here is a link : [Plotly](https://plotly.com/python/)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We have two csv files here we will load them in pandas dataframe "},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = pd.read_csv(\"/kaggle/input/brasilian-houses-to-rent/houses_to_rent.csv\")\ndf2 = pd.read_csv(\"/kaggle/input/brasilian-houses-to-rent/houses_to_rent_v2.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking real quick what kind of data we have "},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Looks like we have a two dataframes where the data in the first one is seperated by city , not a city i.e in df1 and in the second dataframe we have name of specific cities i.e df2"},{"metadata":{"trusted":true},"cell_type":"code","source":"#hoa =  Homeowners association tax","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets just first check df1 where data is divided by city or not a city"},{"metadata":{},"cell_type":"markdown","source":"1. First of we need to remove that \"R\\$\" which is the symbol of South African Rand \n2. We need to replace the strings in columns by a number for eg. acept can be 1 and not acept can be 0\n3. There are also some ' - ' in our floor column we will assume them to be groung floor i.e floor = 0\n4. Then there is a \" , \" in the total column we need to remove that to convert them to int"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1_new=df1.replace(regex=[r'\\bR\\$'],value='')\ndf1_new = df1_new.replace('acept',1)\ndf1_new.replace('not acept',0,inplace=True)\ndf1_new.replace('furnished',1,inplace=True)\ndf1_new.replace('not furnished',0,inplace=True)\ndf1_new.replace('-',0,inplace=True)\ndf1_new.replace(regex=[r'\\b,'],value='',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Divide the new dataframe in two parts , where city = 1 and city = 0"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1_city = df1_new[df1_new['city']==1]\ndf1_notcity = df1_new[df1_new['city']==0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking that we did everything right"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1_city.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1_notcity.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No need of index columns dropping them "},{"metadata":{"trusted":true},"cell_type":"code","source":"df1_city = df1_city.copy().drop(columns=['Unnamed: 0'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1_notcity = df1_notcity.copy().drop(columns=['Unnamed: 0'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df1_city.dtypes)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### This is why we remove the \" , \" so that we can convert that number to int . If it is not removed python either considers it as a float or it can give us error in the future"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1_city['total']=df1_city['total'].astype(int)\ndf1_notcity['total']=df1_notcity['total'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"  df1_city.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1_notcity.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* ### We will plot a scatter plot here , we want to know how the total amount changes according to area of our property and also we will check weather having different number of rooms affect out total amount.\n* ### Plotting is very simple with plotly just pass a dataframe , what you want to be on x and  y axis also how you want to use color , here  we want to change our color according to the number of rooms .\n* ### Plotly takes care of everthing for you. We have two plots one for city and one not in city"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter(df1_notcity,x='area',y='total',trendline=\"lowess\",color='rooms',title=\"Not in city\")\nfig1 = px.scatter(df1_city,x='area',y='total',trendline=\"lowess\",color='rooms',title=\"In city\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. What we are basically trying to do below is to plot these two graphs side by side . This is just a very lazy method of doing it.\n2. This the correct method [plotly subplots](https://plotly.com/python/subplots/)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from plotly.subplots import make_subplots\nfrom plotly.offline import  init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\ntrace1 = fig['data'][0]\ntrace2 = fig1['data'][0]\n\nfig2 = make_subplots(rows=1, cols=2, shared_xaxes=False,subplot_titles=(\"Not in city\",\"In city\"))\nfig2.add_trace(trace1, row=1, col=1)\nfig2.add_trace(fig['data'][1], row=1, col=1)\nfig2.add_trace(trace2, row=1, col=2)\nfig2.add_trace(fig1['data'][1], row=1, col=2)\nfig2.update_layout(\n    title=\"Area vs Total Amount \\t Color: Rooms\",\n    xaxis_title=\"Area\",\n    yaxis_title=\"Total Amount\",\n    font=dict(\n        family=\"Courier New, monospace\",\n        size=18,\n        color=\"#7f7f7f\",\n        \n        \n    ))\niplot(fig2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. You can use you mouse to zoom in where you want to see *( If you see only a corner filled with dots zoom in with your mouse )* \n2. Hover the mouse to see the value at that point\n3. Here we see an interesting thing about plotly, our legend i.e color is according to our number of rooms , the more the rooms the brighter the color gets.\n4. We can see that in \\[*Not a city*\\] graph there aren't many places with large number of rooms .... *well not really anything ground breaking here*...but in the \\[*city*\\] graph we can clearly see the change in the color as the area increases the likelihood of having more rooms increses so the colors go more bright and also the total rent amount increses... *again not anything worth the Noble Prize* but a simple graph here can help us understand very easily.\n5. More expensive house have more number of rooms"},{"metadata":{},"cell_type":"markdown","source":"#### Another side by side plot but now we want to know does number of bathrooms in our property means something.\n> *I mean obviously people are going to buy a house with a bathroom but we want to know do more bathroom mean more money ..... just for fun* "},{"metadata":{},"cell_type":"markdown","source":"#### Also going through the dataset I found that in column hao , propety tax some of the values were not integers.<br>\n#### Column hoa had some values = 'Sem info' and column propery tax had some values='Incluso'<br>\n#### We won't be using these columns because we only need to analyze the total amount because in the end thats what we want to know how much money we need to give."},{"metadata":{"trusted":true},"cell_type":"code","source":"df1[df1['hoa']=='Sem info'].head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1[df1['property tax']=='Incluso'].head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig0 = px.scatter(df1_notcity,x='area',y='total',trendline=\"lowess\",color='bathroom',title=\"Not in city\")\nfig10 = px.scatter(df1_city,x='area',y='total',trendline=\"lowess\",color='bathroom',title=\"In city\")\ntrace12 = fig0['data'][0]\ntrace21 = fig10['data'][0]\n\nfig21 = make_subplots(rows=1, cols=2, shared_xaxes=False,subplot_titles=(\"Not in city\",\"In city\"))\nfig21.add_trace(trace12, row=1, col=1)\nfig21.add_trace(fig0['data'][1], row=1, col=1)\nfig21.add_trace(trace21, row=1, col=2)\nfig21.add_trace(fig10['data'][1], row=1, col=2)\nfig21.update_layout(\n    title=\"Area vs Total Amount \\t Color: Bathroom\",\n    xaxis_title=\"Area\",\n    yaxis_title=\"Total Amount\",\n    font=dict(\n        family=\"Courier New, monospace\",\n        size=18,\n        color=\"#7f7f7f\",\n        \n        \n    ))\niplot(fig21)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Again we see something similar to our \"rooms\" graph ... more expensive houses have more number of bathrooms"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig01 = px.scatter(df1_notcity,x='area',y='total',trendline=\"lowess\",color='furniture',title=\"Not in city\")\nfig101 = px.scatter(df1_city,x='area',y='total',trendline=\"lowess\",color='furniture',title=\"In city\")\ntrace121 = fig01['data'][0]\ntrace211 = fig101['data'][0]\n\nfig211 = make_subplots(rows=1, cols=2, shared_xaxes=False,subplot_titles=(\"Not in city\",\"In city\"))\nfig211.add_trace(trace121, row=1, col=1)\nfig211.add_trace(fig01['data'][1], row=1, col=1)\nfig211.add_trace(trace211, row=1, col=2)\nfig211.add_trace(fig101['data'][1], row=1, col=2)\nfig211.update_layout(\n    title=\"Area vs Total Amount \\t Color: Furniture\",\n    xaxis_title=\"Area\",\n    yaxis_title=\"Total Amount\",\n    font=dict(\n        family=\"Courier New, monospace\",\n        size=18,\n        color=\"#7f7f7f\",\n        \n        \n    ))\niplot(fig211)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Now we move on to another dataframe the one with specific city names . Here we will try to predict the total price of house"},{"metadata":{},"cell_type":"markdown","source":"Lets check how many unique cities we have"},{"metadata":{"trusted":true},"cell_type":"code","source":"uc = df2['city'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(uc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We do the same changes"},{"metadata":{"trusted":true},"cell_type":"code","source":"df2 = df2.replace('acept',1)\ndf2.replace('not acept',0,inplace=True)\ndf2.replace('furnished',1,inplace=True)\ndf2.replace('not furnished',0,inplace=True)\ndf2.replace('-',0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Now lets see a plot but colored according to different cities"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig3 = px.scatter(df2,x='area',y='total (R$)',trendline=\"lowess\",color='city',title=\"Area vs Total cost per city\")\n#fig3.show()\niplot(fig3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Again if you see tiny dots zoom in also you can click on the legend to enable disable the plot points of that particular city.\n1. Looks like Sao Polo is the most expensive city \n2. We don't have much data about Porto Alegre\n3. Also for the same area Sao Polo and Rio de Janeiro are more expensive than Belo Horizonte."},{"metadata":{},"cell_type":"markdown","source":"### Here we also see that there are some outliers most of our total price is under 35K except a few . Linear regression models are sometimes sensitive to outliers . We also seem to have more data for just one city Sao Paulo "},{"metadata":{},"cell_type":"markdown","source":"change the name of city to number and also storing the city name:number in a dict"},{"metadata":{"trusted":true},"cell_type":"code","source":"city_dict = {}\nfor i in range(0,len(uc)):\n    df2.replace(uc[i],i+1,inplace=True)\n    city_dict[uc[i]]=i+1\n    print(\"Now city {} is : {}\".format(uc[i],i+1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### In the above plot it looked there were different number of data samples per city"},{"metadata":{},"cell_type":"markdown","source":"What we are doing is we want to count the occurence of each city in df2\\['city'\\] column so we use value_counts() "},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Total length {}\\nNumber of Examples per city \\n{}\".format(len(df2),df2['city'].value_counts()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"city_dict","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### So what is the problem,I think that we have a dataset with unequal number of examples per city ... Like we saw earlier the number of examples per city are more for Sao Paulo is 5887 out of total 10692 , nearly half of them."},{"metadata":{},"cell_type":"markdown","source":"### Well most of the samples are of city São Paulo nearly half of them 5887 and least are of Campinas only 853"},{"metadata":{},"cell_type":"markdown","source":"### Also lets check the mean total amount we have to spend in each city"},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_total=[]\nfor i in range(0,len(uc)):\n    mean = df2[df2['city']==city_dict[uc[i]]]['total (R$)'].mean()\n    mean_total.append(mean)\n    print(\"Mean amount for city {}:{} is {:.2f}\".format(i+1,uc[i],mean))\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Well as expected São Paulo has heighest average = 6380 followed closely by Belo Horizonte at 6315\n* Least expensive is Porto Alegre at nearly 2990"},{"metadata":{"trusted":true},"cell_type":"code","source":"xdf = df2[['city','area','rooms','bathroom','floor','furniture']]\nxdf.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Now lets predict the prizes of these properties"},{"metadata":{"trusted":true},"cell_type":"code","source":"xdf1= xdf.to_numpy(dtype='float')\ny = df2['total (R$)'].to_numpy(dtype='float')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Standard train test split"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(xdf1,y,random_state=3,test_size=200)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Regression:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import svm\nclf = svm.SVR(kernel='linear')\nclf.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The accuracy of a regression model cannot be measured like a classfication model because it is very unlikely that it will output the same exact number as label data or true data . Instead we use something called an r squared errror , it is between 0 and 1 where 0 means our model captures no variation in data and 1 means it is perfect.\nHere is a good article that explains it [r2.](https://www.datasciencecentral.com/profiles/blogs/regression-analysis-how-do-i-interpret-r-squared-and-assess-the)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.score(x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our accuracy is 0.58 which is okay-ish ...... it is just very very okay. Also given that we have more data about  a particular city it is again okaaaay."},{"metadata":{},"cell_type":"markdown","source":"Beacuse city number of Sao Paulo = 1"},{"metadata":{},"cell_type":"markdown","source":"### But now lets try to build a neural network from pytorch .\n#### *I mean why else use deep learing but not  to complicate simple tasks* "},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader, TensorDataset\nimport torch.nn as nn\nfrom torch import Tensor\nfrom torch.optim import Adam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain =torch.from_numpy(x_train)\nytrain = torch.from_numpy(y_train)\nxtest =torch.from_numpy(x_test)\nytest = torch.from_numpy(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = TensorDataset(xtrain,ytrain)\ndataset_test = TensorDataset(xtest,ytest)\nloader = DataLoader(dataset,batch_size = 5)\ntest_loader = DataLoader(dataset_test,batch_size=5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Uptill now everything was pretty standard we imported libraries and then made a tensor dataset.\nNow we are going to create a model \n1. In pytorch you need to define you model in a class \n  1. Our number of inputs are 5 so the first layer self.layer1 ,it will take a vector of (5,1) as an input and output a vector of (25,1)\n  2. Then we define hidden layer similarly with help of  \"Linear(input,output)\" which is just a layer of neurons\n  3. Final output layer of just size = 1 \n2. Forward function is must ... it defines how the feed forward step will happen."},{"metadata":{"trusted":true},"cell_type":"code","source":"class NN(nn.Module):\n    def __init__(self):\n        super(NN,self).__init__()\n        self.layer1 = nn.Linear(6,25)\n        nn.ReLU()\n        self.layer2 = nn.Linear(25,25)\n        nn.ReLU()\n        self.layer3 = nn.Linear(25,25)\n        nn.ReLU()\n        self.layer4 = nn.Linear(25,1)\n    def forward(self,n):\n        out = self.layer1(n)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        \n        return out\n        \n        \n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* We import a loss function L1Loss() which is very robust againts outliers in datset.\n* An optimizer Adam."},{"metadata":{"trusted":true},"cell_type":"code","source":"#learning_rate = 0.01\nmodel = NN()\nmodel = model.double()\nmodel=model.cuda()\ncriterion = nn.L1Loss()\ncriterion.cuda()\noptimizer = Adam(model.parameters(),lr=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_steps = len(loader)\nloss_list = []\nnum_epochs=5\ntotal_train=0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Importing r2 score 'cause that how we measure them regression models"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import r2_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### This is our training loop :\n#### Looks complicated but is very simple\n1. We take values from our tensor loader i.e data and the label or true value\n2. We pass it through out model<br>\n(The loop to append in list o_list[] is because our batch size is 5 so model returns an output of size five , it is of five different inputs we append them in an output predicted  list , also append the labels)\n3. Now that our model has the output , we need to calculate loss so we pass  it to our loss criterion \n4. Loss is calculated ... we need to propogate it backward i.e backpropagation.\n5. Now calculate the gradients based on those loss and the optimizer will take a step ... hopefully in the right dorection towards the global minima.\n6. Print the output of each epoch"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.train()\n\nfor epoch in range(0,num_epochs):\n    o_list = []\n    ll = []\n    for i,(data,label) in enumerate(loader):\n        outp = model(data.cuda()) #1\n        [o_list.append(o) for o in outp]\n        [ll.append(l) for l in label]\n        loss = criterion(outp,label.reshape(-1,1).cuda()) #2\n        loss_list.append(loss) \n        optimizer.zero_grad()#3\n        loss.backward()#4\n        optimizer.step()#5\n        total_train+=1\n    print(\"-------------------* Output {} *------------------------\".format(epoch+1)) #6\n    print(\"Total steps {}/{}\\nLoss {}\\nR2 score {}\".format(i,total_steps,loss.item(),r2_score(o_list,ll)))  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let us test our NN on new unseen data"},{"metadata":{"trusted":true},"cell_type":"code","source":"o_list=[]\nll=[]\nmodel.eval()\nfor i,(data,label) in enumerate(test_loader):\n    outp = model(data.cuda())\n    [o_list.append(o.cpu().item()) for o in outp]\n    [ll.append(l.item()) for l in label]\n    total_train+=1\nprint(\"-------------------* Output *------------------------\")\nprint(\"Total steps {}/{}\\nR2 score {}\".format(i,len(test_loader),r2_score(o_list,ll)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Well accuracy is definately much worse than SVR ... but by finetuning the hyper-parameters heigher accuracy can be achieved. "},{"metadata":{"trusted":true},"cell_type":"code","source":"svm_pred = []\nfor i in x_test:\n    pred = clf.predict(i.reshape(1,-1))\n    svm_pred.append(pred.item())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Lets compare our Outputs by SVR and Neural Network with the True value with the help of our good old friend plotly"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig4 = px.line(x=range(0,200),y=ll)\nfig4.add_scatter(y=svm_pred,name=\"SVR Prediction\")\nfig4.add_scatter(y=o_list,name=\"Neural Network\")\nfig4.update_layout(\n    title=\"True vs Predicted\",\n    xaxis_title=\"Example number\",\n    yaxis_title=\"Total Amount R$\",\n    font=dict(\n        family=\"Courier New, monospace\",\n        size=18,\n        color=\"#7f7f7f\",))\n        \niplot(fig4)        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Blue line is true price"},{"metadata":{},"cell_type":"markdown","source":"### Looks like our neural network is good at predicting high values but not so good at lower ones . SVR really does a descent job of giving an output value... it is not perfect and it shouldn't be because we only want to give an estimate, real life property deals are influenced by many factors ranging from Real Estate agent's ablities to faith of people in their horoscope."},{"metadata":{},"cell_type":"markdown","source":"We can print each value and also check manually the differene"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(0,len(ll)):\n    print(\"Output of neural network: {:.2f} , Output of SVR: {:.2f} ,  True: {}\".format(svm_pred[i],o_list[i],ll[i]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}