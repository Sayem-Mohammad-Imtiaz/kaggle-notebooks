{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# Sentiment Analysis \n\nSentiment analysis is the interpretation and classification of emotions (positive, negative and neutral) within text data using text analysis techniques. Sentiment analysis allows businesses to identify customer sentiment toward products, brands or services in online conversations and feedback.\n\nThis notebook uses the data from amazon reviews in mobile phones.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/amazon-reviews-unlocked-mobile-phones/Amazon_Unlocked_Mobile.csv')\ndf = df.sample(frac=0.1, random_state=10)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Drop the missing values.\ndf.dropna(inplace=True)\n\n#remove any neutral rating equals to 3.\ndf = df[df['Rating']!=3]\n\n#Encode 4 star and 5 star as positively rated 1.\n#Encode 1 star and 2 star as poorely rated 0.\ndf['Positively Rated'] = np.where(df['Rating']>3,1,0)\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\nplt.style.use('fivethirtyeight')\nfig,(ax0,ax1) = plt.subplots(nrows=1,\n                            ncols=2,\n                            figsize = (20,12))\nax0.scatter(df['Rating'],df['Review Votes'])\nax0.set(title='Rating vs Review Votes',\n       xlabel='Rating',\n       ylabel='Review Votes')\nax1.plot(df['Rating']==4,df['Rating']==5)\nax1.set(title='Rating 4 vs Rating 5',\n       xlabel='Rating 4',\n       ylabel='Rating 5');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# most ratings are positive\ndf['Positively Rated'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = df['Reviews']\ny = df['Positively Rated']\n#spliting data into training and test set.\nX_train,X_test,y_train,y_test = train_test_split(X,y,random_state=0)\nprint('X_train first entry:\\n',X_train.iloc[0])\nprint('\\nX_train shape',X_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Positively Rated'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Count Vectorizer","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\n#fit the countVectorizer to the training data.\nvect = CountVectorizer()\nvect.fit(X_train)\n\n#getting every 2000 vocabulay features.\nvect.get_feature_names()[::2000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(vect.get_feature_names())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#transform the document in the training data to a document term matrix.\nX_train_vectorized = vect.transform(X_train)\nX_train_vectorized","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n#train the model.\nmodel = LogisticRegression()\nmodel.fit(X_train_vectorized,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score,roc_curve\n\n#predict the transform test document.\npredictions = model.predict(vect.transform(X_test))\nprint('AUC: ',roc_auc_score(y_test,predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#get the feature names as numpy array.\nfeature_names = np.array(vect.get_feature_names())\n\n#sort the coffecient from the model.\nsorted_coef_index = model.coef_[0].argsort()\n\n'''Find the 10 smallest and 10 largest coefficients.\n The 10 largest coefficients are being indexed using [:-11:-1] \n so the list returned is in order of largest to smallest.'''\n\nprint('Smallest Coefficient(Negative reviews): \\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\nprint('Largest Coeffiecient(Positive reviews): \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# TFIDF(Term Frequency-Inverse Document Frequency","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n# Fit the TfidfVectorizer to the training data specifiying a minimum document frequency of 5\nvect = TfidfVectorizer(min_df=5).fit(X_train)\nlen(vect.get_feature_names())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_vectorized = vect.transform(X_train)\n\nmodel = LogisticRegression()\nmodel.fit(X_train_vectorized, y_train)\n\npredictions = model.predict(vect.transform(X_test))\n\nprint('AUC: ', roc_auc_score(y_test, predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_names = np.array(vect.get_feature_names())\n\nsorted_tfidf_index = X_train_vectorized.max(0).toarray()[0].argsort()\n\nprint('Smallest tfidf:\\n{}\\n'.format(feature_names[sorted_tfidf_index[:10]]))\nprint('Largest tfidf: \\n{}'.format(feature_names[sorted_tfidf_index[:-11:-1]]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted_coef_index = model.coef_[0].argsort()\n\nprint('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\nprint('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# These reviews are treated the same by our current model\nprint(model.predict(vect.transform(['not an issue, phone is working',\n                                    'an issue, phone is not working'])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# n-grams","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit the CountVectorizer to the training data specifiying a minimum \n# document frequency of 5 and extracting 1-grams and 2-grams\nvect = CountVectorizer(min_df=5, ngram_range=(1,2)).fit(X_train)\n\nX_train_vectorized = vect.transform(X_train)\n\nlen(vect.get_feature_names())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LogisticRegression()\nmodel.fit(X_train_vectorized, y_train)\n\npredictions = model.predict(vect.transform(X_test))\n\nprint('AUC: ', roc_auc_score(y_test, predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_names = np.array(vect.get_feature_names())\n\nsorted_coef_index = model.coef_[0].argsort()\n\nprint('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\nprint('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# These reviews are now correctly identified\nprint(model.predict(vect.transform(['not an issue, phone is working',\n                                    'an issue, phone is not working'])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}