{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Signpost CNN Classification\n\nIn this kernel I’ll try to identify correctly which signpost we are seeing ( 43 types of signposts).\nIn order to do so I’ll use signpost image dataset as input to a CNN (since we have huge data set - no need for data augmentation  ) .\nAfter optimzation process - optimal layers are 2 + 2 FC layers.\nI also run semi grid search on dropout , filter size etc.."},{"metadata":{},"cell_type":"markdown","source":"# Import"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport pickle\nimport matplotlib.pyplot as plt\nfrom math import sqrt, ceil\nfrom timeit import default_timer as timer\nimport os\n\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, AvgPool2D, BatchNormalization, Reshape\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import LearningRateScheduler\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  Show input files "},{"metadata":{"trusted":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk('../input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Make sure we have enough samples per signpost(43 types) "},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('../input/traffic-signs-preprocessed/data1.pickle', 'rb') as f:\n    data = pickle.load(f, encoding='latin1')  # dictionary type\npd_check=pd.DataFrame({'y_train': data['y_train']})\npd_check2=pd_check.sort_values(by=['y_train'],ascending=True)\npd_check=pd_check2.set_index(np.arange(len(pd_check2.index)))\n#pd_check.reset_index(drop=True, col_level=0)\npd_check['y_train'].value_counts().plot(kind='bar',figsize=(15, 15),color=list('rgbkymc')) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load one of the data set :\n* Open file\n* Make y(train & val) as categorical list\n* Reshape X (test,val & test) to assure RGB image channels (3) comes last"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndata['y_train'] = to_categorical(data['y_train'], num_classes=43)\ndata['y_validation'] = to_categorical(data['y_validation'], num_classes=43)\n\nprint(\"x_train_pre_shape\" + \":\" ,data['x_train'].shape )\ndata['x_train'] = data['x_train'].transpose(0, 2, 3, 1)\ndata['x_validation'] = data['x_validation'].transpose(0, 2, 3, 1)\ndata['x_test'] = data['x_test'].transpose(0, 2, 3, 1)\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Show dataset size  "},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfor i, j in data.items():\n    if i == 'labels':\n        print(i + ':', len(j))\n    else: \n        print(i + ':', j.shape)\n\n       ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Showing some examples"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport random\nmatrix_hw=5\nstart_idx=random.randint(0,len(data['x_train'])-matrix_hw)\n\nexamples = data['x_train'][start_idx:start_idx+matrix_hw**2, :, :, :]\n#print(examples.shape)  # (81, 32, 32, 3)\n_, axs = plt.subplots(matrix_hw, matrix_hw) #n_row, n_col, figsize=(32, 32,3)\naxs = axs.flatten()\nfor img, ax in zip(examples, axs):\n    #print(mg)\n    low, high = np.min(img), np.max(img)\n    img = 255.0 * (img - low) / (high - low)\n    ax.imshow(img.astype('uint8'), cmap='gray')\nplt.axis('off')\nplt.gcf().set_size_inches(10, 10)\n#plt.title('Some examples of training data', fontsize=18)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define CNN parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGE_WIDTH    =32\nIMAGE_HEIGHT   =32\nIMAGE_SIZE     =(IMAGE_WIDTH, IMAGE_HEIGHT)\nIMAGE_CHANNELS =3\nDROP_OUT_VALUE =[0,0.1,0.2,0,0.1]\nPOOL_SIZE      =[2,2,2,3,3]\nepochs         = 5\nbatch_size      =5\nfilters        = [3,3,3,3,3]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define CNN model"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel = [0] * len(filters)\n\nfor i in range(len(model)):\n    model[i] = Sequential()\n    model[i].add(Conv2D(32, kernel_size=filters[i], activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))\n    model[i].add(BatchNormalization())\n    model[i].add(MaxPool2D(pool_size=(POOL_SIZE[i],POOL_SIZE[i])))\n    model[i].add(Dropout(DROP_OUT_VALUE[i]))\n    \n    model[i].add(Conv2D(64, kernel_size=filters[i], activation='relu'))\n    model[i].add(BatchNormalization())\n    model[i].add(MaxPool2D(pool_size=(POOL_SIZE[i],POOL_SIZE[i])))\n    model[i].add(Dropout(DROP_OUT_VALUE[i]))\n    \n    model[i].add(Flatten())\n    model[i].add(Dense(512, activation='relu'))\n    model[i].add(Dense(43, activation='softmax'))\n    model[i].compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n    model[i].summary()\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Early Stop\n\nTo prevent over fitting we will stop the learning after 5 epochs and val_loss value not decreased (1% defualt)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import EarlyStopping, ReduceLROnPlateau\nearlystop = EarlyStopping(patience=5)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Learning Rate Reduction\n\nWe will reduce the learning rate with some function"},{"metadata":{"trusted":true},"cell_type":"code","source":"annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** (x + epochs))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training Models\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nh = [0] * len(model)\n\nfor i in range(len(h)):\n    h[i] = model[i].fit(data['x_train'], data['y_train'],\n                        batch_size=batch_size, epochs = epochs,\n                        validation_data = (data['x_validation'], data['y_validation']),\n                        callbacks=[annealer,earlystop], verbose=1)\n    \n    print('Model with filters {0:d}x{0:d},dropout {1:.2f},pooling size {2:d}x{2:d} epochs={3:d}, training acc={4:.5f}, val acc={5:.5f}'.\\\n      format(filters[i],DROP_OUT_VALUE[i],POOL_SIZE[i], epochs, max(h[i].history['acc']), max(h[i].history['val_acc'])))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plotting accuracy per model"},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nplt.rcParams['figure.figsize'] = (15.0, 15.0) \nplt.rcParams['image.interpolation'] = 'nearest'\n\nfig = plt.figure()\nplt.subplot(2, 1, 1)\nplt.plot(h[4].history['acc'], '-o', linewidth=3.0)\nplt.plot(h[3].history['acc'], '-o', linewidth=3.0)\nplt.plot(h[2].history['acc'], '-o', linewidth=3.0)\nplt.plot(h[1].history['acc'], '-o', linewidth=3.0)\nplt.plot(h[0].history['acc'], '-o', linewidth=3.0)\nplt.legend(['M5', 'M4', 'M3', 'M2', 'M1'], loc='lower right', fontsize='xx-large', borderpad=2)\nplt.xlabel('Epoch', fontsize=20, fontname='Times New Roman')\nplt.ylabel('Training Accuracy', fontsize=20, fontname='Times New Roman')\nplt.yscale('linear')  # {\"linear\", \"log\", \"symlog\", \"logit\", ...}\nplt.ylim(0.85, 1.0)\nplt.xlim(0.5, 5.3) \nplt.title('Accuracy for different sizes of filters', fontsize=22)\nplt.tick_params(labelsize=18)\n\nplt.subplot(2, 1, 2)\n# plt.gca().set_title('Validation accuracy')\n\nplt.plot(h[4].history['val_acc'], '-o', linewidth=3.0)\nplt.plot(h[3].history['val_acc'], '-o', linewidth=3.0)\nplt.plot(h[2].history['val_acc'], '-o', linewidth=3.0)\nplt.plot(h[1].history['val_acc'], '-o', linewidth=3.0)\nplt.plot(h[0].history['val_acc'], '-o', linewidth=3.0)\nplt.legend(['M5', 'M4', 'M3', 'M2', 'M1'], loc='lower right', fontsize='xx-large', borderpad=2)\nplt.xlabel('Epoch', fontsize=20, fontname='Times New Roman')\nplt.ylabel('Validation Accuracy', fontsize=20, fontname='Times New Roman')\nplt.yscale('linear')  # {\"linear\", \"log\", \"symlog\", \"logit\", ...}\nplt.ylim(0.9, 1)\nplt.xlim(0.5, 5.3)\nplt.tick_params(labelsize=18)\n\n# Showing the plot\nplt.show()\n\n# Saving the plot\nfig.savefig('models_acc_cmp.png')\nplt.close()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predict Xtest "},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(model)):\n    temp = model[i].predict(data['x_test'])\n    temp = np.argmax(temp, axis=1)\n    temp = np.mean(temp == data['y_test'])\n    \n    print('data2 filter {0:d} testing accuracy = {1:.5f}'.format(filters[i], temp))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Show example for prediction "},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\n\n# Preparing image for predicting from test dataset\nx_input = data['x_test'][100:101]\nprint(x_input.shape)\ny_input = data['y_test'][100:101]\nprint(y_input)\n\nplt.rcParams['figure.figsize'] = (2.5, 2.5) # Setting default size of plots\nplt.imshow(x_input[0, :, :, :])\nplt.axis('off')\n\n# Showing the plot\nplt.show()\n\n# Getting scores from forward pass of input image\nscores = model[0].predict(x_input)\nprint(scores[0].shape) # (43,)\n\n# Scores is given for image with 43 numbers of predictions for each class\n# Getting only one class with maximum value\nprediction = np.argmax(scores)\nprint('ClassId:', prediction)\n\n# Defining function for getting texts for every class - labels\ndef label_text(file):\n    # Defining list for saving label in order from 0 to 42\n    label_list = []\n    \n    # Reading 'csv' file and getting image's labels\n    r = pd.read_csv(file)\n    # Going through all names\n    for name in r['SignName']:\n        # Adding from every row second column with name of the label\n        label_list.append(name)\n    \n    # Returning resulted list with labels\n    return label_list\n\n\n# Getting labels\nlabels = label_text('../input/traffic-signs-preprocessed/label_names.csv')\n\n# Printing label for classified Traffic Sign\nprint('Label:', labels[prediction])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Save Models"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(model)):\n    name = 'model-' + str(filters[i]) + 'x' + str(filters[i]) + '.h5'\n    model[i].save(name)\n\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}