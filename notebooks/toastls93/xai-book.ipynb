{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 모델 만들기"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBClassifier\nimport warnings\nwarnings.filterwarnings(action='ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 데이터 로드\ndataset = pd.read_csv('/kaggle/input/pima-indians-diabetes-database/diabetes.csv', delimiter=',')\n# dataset = np.loadtxt('/kaggle/input/pima-indians-diabetes-database/diabetes.csv', skiprows=1, delimiter=',')\nX = dataset.iloc[:, :8]\ny = dataset.iloc[:, 8]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 모델 학습 시키기\nmodel = XGBClassifier()\nmodel.fit(x_train, y_train)\n\n# 예측하기\ny_pred = model.predict(x_test)\npredictions = [round(value) for value in y_pred]\n\n# 평가하기\nacc = accuracy_score(y_test, predictions)\nprint(f\"Acc is {acc*100}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 예제 4.2 특정 환자에 대해 당뇨병을 진단하는 코드\nvalue = np.array([[1, 161, 72, 35, 0, 28.1, 0.527, 20]])\nl = model.predict_proba(value)\nprint(f\"No diabetes: {l[0][0]}, YES is {l[0][1]}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 의사결정 트리 시각화"},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport os\nfrom xgboost import plot_tree\nimport matplotlib.pyplot as plt\nfrom matplotlib.pylab import rcParams\nrcParams['figure.figsize']=200,200","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_tree(model)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 깊이 조절하기\nmodel_2 = XGBClassifier(max_depth=2)\nmodel_2.fit(x_train, y_train)\n\nplot_tree(model_2)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_4 = XGBClassifier(max_depth=4)\nmodel_4.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rcParams['figure.figsize']=40,40\nplot_tree(model_4)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 깊이에 따른 모델 정확도 평가\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 예측하기\ny_pred = model_2.predict(x_test)\npredictions = [round(value) for value in y_pred]\nacc = accuracy_score(y_test, predictions)\nprint(f\"model_2 is {acc*100}\")\n\n# 예측하기\ny_pred = model_4.predict(x_test)\npredictions = [round(value) for value in y_pred]\nacc = accuracy_score(y_test, predictions)\nprint(f\"model_4 is {acc*100}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* depth=2인 모델이 75%의 정확도를 가짐.\n* depth=4인 경우 과적합이 의심"},{"metadata":{},"cell_type":"markdown","source":"## 피쳐 중요도 구분하기\n\n\n각 피쳐들의 정보 이득값을 계산한다"},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import plot_importance\nfig, ax = plt.subplots(1, 2, figsize = (25, 10))\nplot_importance(model_2, ax = ax[0])\nplot_importance(model_4, ax = ax[1])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"p62\n\n**max_depth**에 따라서 feature importance의 값이 달라진다.\n\n\n* 즉(이미 알고 있었겠지만), importance_plot의 값 자체는 큰 의미가 없다\n* 또한 \"importance_plot의 순서가 당뇨병을 진단하는 우선순위라고 판단할 수 없다\"\n\n***그렇지만*** importance_plot의 순서가 당뇨병 진단에 영향을 미치는 정도를 구분한다는 해석은 가능하다\n\n--> 여러번 확인했을 때 항상 상위에 있다면 중요하다 이정도?"},{"metadata":{},"cell_type":"markdown","source":"## 4.5.2.3 부분 의존성 플롯 그리기\n\n이 방법은 model을 imput으로 넣지 않는다. \n\n즉, 부분 의존성 기법은 학습 데이터를 철저하게 분석해서 모델이 어떻게 학습할 것인지 예상하는 XAI기법이다\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from pdpbox import info_plots\nfrom pdpbox import pdp\npima_data = dataset\npima_features = dataset.columns[:8]\npima_target = dataset.columns[8]\n\nfig, ax, summary_df = info_plots.target_plot(\n    df = pima_data,\n    feature = 'Glucose',\n    feature_name = 'Glucose',\n    target = pima_target)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"위 그림에서 X축은 GTT수치, 왼쪽Y는 각 구간별 데이터 갯수, 오른쪽Y는 당뇨병 진단여부\n* 가장 왼쪽 막대 그래프는 GTT가 87미만인 경우 82개의 데이터가 존재하고, 이 그룹의 당뇨를 진단할 확률은 7.3%\n* 가장 우측 막대는 GTT가 164~199인 환자들의 당뇨 진단 확률은 82.6% 이다\n\n--> 기존 의학 지식과 관련하여 충분히 합리적인 결과가 나왔다"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax, summary_df = info_plots.target_plot(\n    df = pima_data,\n    feature = 'BloodPressure',\n    feature_name = 'BloodPressure',\n    target = pima_target)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* 80~120인 경우 고혈압이라고 할 수 있다. 고혈압의 당뇨 확률은 정상보다 10%가량 높다\n* 하지만 가장 높은 확률이 46.2%로 혈압만으로 당뇨를 진단하기에는 무리가 있다.\n\n--> 이제 XGB 모델과 비교를 통해, 데이터와 동일한 결과를 얻었는지 확인해보자"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax, summary_df = info_plots.actual_plot(\n    model = model_2,\n    X = pima_data[pima_features],\n    feature = 'Glucose',\n    feature_name = 'Glucose',\n    show_percentile = True\n)\n\nfig, ax, summary_df = info_plots.target_plot(\n    df = pima_data,\n    feature = 'Glucose',\n    feature_name = 'Glucose',\n    target = pima_target)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* model_2\n--> 통계량 만큼 잘 나오는 것 같다. \n\n\n* model_4\n**--> 통계량보다 편향 되어 있는것 같다.**\n글루코스가 144이상인 경우에만! 잘 작동하는것 같다.왜 그럴까?"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax, summary_df = info_plots.actual_plot(\n    model = model_4,\n    X = pima_data[pima_features],\n    feature = 'BloodPressure',\n    feature_name = 'BloodPressure',\n    show_percentile = True\n)\n\nfig, ax, summary_df = info_plots.target_plot(\n    df = pima_data,\n    feature = 'BloodPressure',\n    feature_name = 'BloodPressure',\n    target = pima_target)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* model_2\n--> 통계량과 어느정도 일치하는 모습을 보인다\n\n\n\n* model_4\n--> 혈압에 대한 정보를 반영하지 못하고 있다.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 이번에는 부분 의존 플랏을 그려본다\npdp_gc = pdp.pdp_isolate(\n    model = model_2,\n    dataset = pima_data,\n    model_features = pima_features,\n    feature = 'Glucose'\n)\n\n# plot정보 설정\nfig, ax = pdp.pdp_plot(\n    pdp_gc,\n    'Glucose',\n    plot_lines = False,\n    frac_to_plot=0.5,\n    plot_pts_dist = True\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"pdp_isolate는 'Glucose' 피쳐 하나에 대한 부분 의존성 수치를 반환한다.\n\n* info_plots.target_plot에서 확인한 것과 같이 'Glucose'가 증가할 수록 당뇨병 확률이 증가한다"},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot정보 설정\nfig, ax = pdp.pdp_plot(\n    pdp_gc,\n    'BloodPressure',\n    plot_lines = True,\n    frac_to_plot=0.5,\n    plot_pts_dist = True\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pdp_interaction = pdp.pdp_interact(\nmodel = model_4\n    ,dataset = pima_data\n    ,model_features= pima_features\n    ,features = ['BloodPressure', 'Glucose']\n)\n\nfig,ax = pdp.pdp_interact_plot(\n    pdp_interact_out=pdp_interaction\n    ,feature_names = ['BloodPressure', 'Glucose']\n    , plot_type ='contour'\n    , x_quantile = True\n    , plot_pdp = True\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* model_2\n\n--> X축에 평행한 모습을 보인다. 즉, 혈압보다는 GTT에 더 큰 영향을 받고 있다.\n\n* model_4\n\n--> 굉장히 들쭉날쭉한 모습이다. 기존에 살펴본 통계량과 매치가 전혀되지 않는다"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 이번에는 부분 의존 플랏을 그려본다\npdp_gc = pdp.pdp_isolate(\n    model = model_4,\n    dataset = pima_data,\n    model_features = pima_features,\n    feature = 'BloodPressure'\n)\n\n# plot정보 설정\nfig, ax = pdp.pdp_plot(\n    pdp_gc,\n    'BloodPressure',\n    plot_lines = False,\n    frac_to_plot=0.5,\n    plot_pts_dist = True\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* model_2 & model_4\n\n--> 혈압에 대해 공통적으로 당뇨병 진단에 음의 영향력을 보인다.\n\n이것은 이전에 살펴본 통계량과 전혀 다른 결과를 보이는 것이다!\n"},{"metadata":{},"cell_type":"markdown","source":"# 해석 결과가 상충한다면, 무엇이 옳은 해석일까?\n\n\n* feature importance는 방향이 존재하지 않는다. (양, 음의 영향력인지)\n* 피쳐의 scale에 따라 모델에 미치는 영향을 파악할 수 없다\n* 피쳐간 의존성이 존재하는 경우 결과를 신뢰할 수 없다\n\n--> 이런 한계를 개선하기 위해 pdp를 이용했었음\n\n분명 혈압이 상승하면 당뇨병 진단에 도움이 되는 것으로 보임.<br>\n하지만 지금까지 학습한 모델에서 혈압은 당뇨병 진단에 음의 영향을 보인다<br>\n\n<br><br>\np78. <br>\n우리가 가진 데이터의 최대치로는 '의학적인 고혈압'을 표시할 수 없다, <br>\n모델은 정상 범주 혈압을 학습해서 당뇨 진단에 음의 영향력을 발휘 했다고 해석할 수 있다 \n\n* 개인적인 생각\n\n\n1. 본 데이터의 혈압은 확장기 혈압(120/80 에서 80에 해당)이므로, 값이 높을수록 고혈압이 될 가능성이 존재\n2. 결국 모델은 혈압에 대한 정보를 반영하지 못했다\n3. 그럼에도 불구하고 model_4에서 혈압을 제외하면 정확도는 낮아진다\n4. logistic 모델을 적용하면 83%의 정확도로 가장 높은 결과를 얻을 수 있다 (model_2: 75%, model_4: 71%)\n\n--> **pdp로 통계량을 확인한 다음 내가 만든 모델이 통계량을 쫓아가는지 확인해야 할 듯!**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nclf = LogisticRegression(random_state=0).fit(x_train, y_train)\npred = clf.predict(x_test)\n\nlogReg_coeff = pd.DataFrame({'feature_name': pima_features, 'model_coefficient': clf.coef_.transpose().flatten()})\nlogReg_coeff","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = [round(value) for value in pred]\nacc = accuracy_score(y_test, predictions)\nprint(f\"logistic is {acc*100}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_re = dataset.loc[:, ['Pregnancies','Glucose', 'SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age']]\ny_re = dataset.iloc[:, 8]\n\nx_train_re, x_test_re, y_train_re, y_test_re = train_test_split(X_re, y_re, test_size = 0.1, random_state = 7)\n\nmodel_2_re = XGBClassifier(max_depth=2)\nmodel_2_re.fit(x_train_re, y_train_re)\n\n# 예측하기\ny_pred = model_2_re.predict(x_test_re)\npredictions = [round(value) for value in y_pred]\nacc = accuracy_score(y_test_re, predictions)\nprint(f\"model_2_re is {acc*100}\")\n\n# 예측하기\ny_pred = model_2.predict(x_test)\npredictions = [round(value) for value in y_pred]\nacc = accuracy_score(y_test, predictions)\nprint(f\"model_2 is {acc*100}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_re = dataset.loc[:, ['Pregnancies','Glucose', 'SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age']]\ny_re = dataset.iloc[:, 8]\n\nx_train_re, x_test_re, y_train_re, y_test_re = train_test_split(X_re, y_re, test_size = 0.1, random_state = 7)\n\nmodel_4_re = XGBClassifier(max_depth=4)\nmodel_4_re.fit(x_train_re, y_train_re)\n\n# 예측하기\ny_pred = model_4_re.predict(x_test_re)\npredictions = [round(value) for value in y_pred]\nacc = accuracy_score(y_test_re, predictions)\nprint(f\"model_4_re is {acc*100}\")\n\n# 예측하기\ny_pred = model_4.predict(x_test)\npredictions = [round(value) for value in y_pred]\nacc = accuracy_score(y_test, predictions)\nprint(f\"model_4 is {acc*100}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_tree(model_4_re)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}