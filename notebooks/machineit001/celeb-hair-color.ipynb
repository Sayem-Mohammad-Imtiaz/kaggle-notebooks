{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -U git+https://github.com/qubvel/efficientnet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install imgaug","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport glob\nimport os \nimport tqdm\nimport gc\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom keras.optimizers import Adam, SGD\nfrom keras.models import Model, load_model\nfrom keras.layers import *\nfrom keras.callbacks import *\nimport tensorflow as tf\n\nfrom keras.regularizers import l1\n\nfrom tensorflow.keras.utils import to_categorical\n\n\nfrom keras.layers import Activation\nfrom keras.utils.generic_utils import get_custom_objects\n\nimport cv2\nimport imgaug as ia\nfrom imgaug import augmenters as iaa\nimport keras\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.nasnet import  preprocess_input\n\nfrom keras import optimizers\n\n#from cutmix_keras import CutMixImageDataGenerator\nfrom keras.callbacks import LearningRateScheduler\n\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split, KFold, GridSearchCV\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.utils import to_categorical\nfrom keras.wrappers.scikit_learn import KerasClassifier\nimport itertools\n\nfrom keras.callbacks import EarlyStopping","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/celeba-dataset/list_attr_celeba.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1=df[[\"image_id\",\"Black_Hair\",'Blond_Hair',\"Brown_Hair\",\"Gray_Hair\"]]\ndf1.loc[df1['Black_Hair']==-1,\"Black_Hair\"]= np.nan\ndf1.loc[df1['Blond_Hair']==-1,'Blond_Hair']= np.nan\ndf1.loc[df1[\"Brown_Hair\"]==-1,\"Brown_Hair\"]= np.nan\ndf1.loc[df1[\"Gray_Hair\"]==-1,\"Gray_Hair\"]= np.nan","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"black=pd.DataFrame({\"Black_Hair\":df1['Black_Hair'].to_list()},index=df1['image_id']).dropna()\nbrown=pd.DataFrame({\"Black_Hair\":df1['Brown_Hair'].to_list()},index=df1['image_id']).dropna()\ngray=pd.DataFrame({\"Black_Hair\":df1['Gray_Hair'].to_list()},index=df1['image_id']).dropna()\nblond=pd.DataFrame({\"Black_Hair\":df1['Blond_Hair'].to_list()},index=df1['image_id']).dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"black_hair_value=0\nbrown_hair_value=2\ngray_hair_value=3\nblond_hair_value=1\n\nblack_label_images=black.index.to_list()\nblond_label_images=blond.index.to_list()\nbrown_label_images=brown.index.to_list()\ngray_label_images=gray.index.to_list()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"source='/kaggle/input/celeba-dataset/img_align_celeba/img_align_celeba/*.jpg'\nnames=sorted(glob.glob(source))\ntotal=len(black)+len(brown)+len(gray)+len(blond)\nlabels=[]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for j,i in tqdm.tqdm(enumerate((names))):   \n    #print(i.split(\"\\\\\")[1])\n    if i.split(\"/\")[6] in black_label_images:\n        labels.append(black_hair_value)\n    elif i.split(\"/\")[6] in blond_label_images:\n        labels.append(blond_hair_value)\n    elif i.split(\"/\")[6] in brown_label_images:\n        labels.append(brown_hair_value)\n    elif i.split(\"/\")[6] in gray_label_images:\n           labels.append(gray_hair_value)\n    else:\n            pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import efficientnet.keras as eff\nfrom efficientnet.keras import preprocess_input ,center_crop_and_resize\nmodel1 = eff.EfficientNetB5(weights='noisy-student',input_shape=(218,178,3),include_top=False)\nmodel1.trainable=True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def custom_gelu(x):\n    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\nget_custom_objects().update({'custom_gelu': Activation(custom_gelu)})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(model1.layers)):\n    model1.layers[i].activation=\"custom_gelu\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"newOutputs = model1.output\nx = GlobalAveragePooling2D()(newOutputs)\nx= Dense(800,activation=\"custom_gelu\")(x)\nx= Dense(500,activation=\"custom_gelu\")(x)\noutput = Dense(4, activation='softmax', name='predictions',use_bias=True)(x)\nnewModel1 = Model(model1.input, output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_label=np.array(labels)\nvalues=sorted(blond.append(gray.append(black.append(brown))).index.to_list())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_list=[]\nfor i in values:\n    image_list.append(\"/kaggle/input/celeba-dataset/img_align_celeba/img_align_celeba/\"+i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, image_path, labels,index,shuffle=False,augment=False,batch_size=16,n_classes=4,dims=(218, 178, 3)):\n        'Initialization'\n        self.image_path=image_path\n        self.labels=labels\n        self.index=index\n        self.shuffle=shuffle\n        self.augment=augment\n        self.batch_size=batch_size\n        self.dims=dims\n        self.n_classes=n_classes\n        self.on_epoch_end()\n    \n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.image_path) / self.batch_size))\n    \n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        print(index)\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        \n        #assert for no empty list\n        assert indexes!=[],\"Indexes cannot be empty caused with in this index ranges {0} and with {1}\".format(indexes,index)\n        # Find list of IDs\n        image_array = np.array([cv2.imread(self.image_path[k]) for k in indexes])\n        #assert shape of the array\n        assert image_array.shape==(len(image_array),*self.dims)\n        #labels\n        labels=[self.labels[k] for k in indexes]\n        #assert for labels \n        assert len(labels)!=0,\"Length cannot be zero\"\n        #convert to categorical\n        labels=keras.utils.to_categorical(labels, num_classes=self.n_classes)\n        return image_array,labels\n    \n    def on_epoch_end(self):\n        'Updates indexes before each epoch'\n        self.indexes = self.index\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(training_label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_label[7301*16:7302*16]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss',\n\t\t                                            patience=10,\n\t\t                                            verbose=1,\n\t\t                                            factor=0.5,\n\t\t                                            min_lr=0.0000001)\n\ndef step_decay_schedule(initial_lr=1e-3, decay_factor=0.75, step_size=10):\n    '''\n    Wrapper function to create a LearningRateScheduler with step decay schedule.\n    '''\n    def schedule(epoch):\n        return initial_lr * (decay_factor ** np.floor(epoch/step_size))\n    \n    return LearningRateScheduler(schedule,verbose=1)\n\nlr_sched = step_decay_schedule(initial_lr=3e-3, decay_factor=0.25, step_size=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit\nsss = StratifiedShuffleSplit(n_splits=1, test_size=0.09, random_state=0)\nfor train_index, test_index in sss.split(np.zeros(len(training_label)), training_label):\n    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n    print(\"Training length\",len(train_index),\"Testing length\",len(test_index))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data=DataGenerator(image_path=image_list,\n                         labels=training_label,\n                         index=train_index,\n                         shuffle=True,\n                         augment=False)\n# val_data=DataGenerator(images_paths=image_list,\n#                          labels=training_label,\n#                          ids=test_index,\n#                          shuffle=True,\n#                          augment=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"newModel1.compile(optimizers.Nadam(), loss=\"categorical_crossentropy\", metrics=[\"acc\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with tf.device('/CPU:0'):\n    EPOCHS = 10\n    h=newModel1.fit_generator(generator=train_data,\n                              epochs=EPOCHS,\n                              steps_per_epoch=len(train_data),\n                              #validation_data=train_data,\n                              #validation_steps =len(val_data),\n                              callbacks=[EarlyStopping(patience=2, restore_best_weights=True),\n                                   lr_sched,])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"keras.utils.plot_model(newModel1, to_file=\"model.png\", show_shapes=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for i in range(10):\n#     print(\"batch change\\n\")\n#     newModel1.fit(train_data[i][0],train_data[i][1],epochs=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        title='Normalized confusion matrix'\n    else:\n        title='Confusion matrix'\n    fig = plt.figure(figsize=(10,10))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()\n    \n## multiclass or binary report\n## If binary (sigmoid output), set binary parameter to True\ndef full_multiclass_report(model,\n                           x,\n                           y_true,\n                           classes,\n                           batch_size=32,\n                           binary=False):\n\n    # 1. Transform one-hot encoded y_true into their class number\n    if not binary:\n        y_true = np.argmax(y_true,axis=1)\n    \n    # 2. Predict classes and stores in y_pred\n    y_pred = model.predict(x, batch_size=batch_size)\n    y_pred= np.argmax(y_pred,axis=1)\n    \n    # 3. Print accuracy score\n    print(\"Accuracy : \"+ str(accuracy_score(y_true,y_pred)))\n    \n    print(\"\")\n    \n    # 4. Print classification report\n    print(\"Classification Report\")\n    print(classification_report(y_true,y_pred,digits=5))    \n    \n    # 5. Plot confusion matrix\n    cnf_matrix = confusion_matrix(y_true,y_pred)\n    return(cnf_matrix)\n\n\nmatrix=full_multiclass_report(newModel1,\n                       x_test,\n                       y_test1,\n                      range(3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(matrix,classes=range(3))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}