{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Agenda\n<ul>\n<li><a href=\"#sources\">Sources</a></li>\n<li><a href=\"#cleaning\">Data Cleaning</a></li>\n<li><a href=\"#eda\">Exploratory Data Analysis and some Feature Engineering</a></li>\n<li><a href=\"#model\">Modeling</a></li>\n<li><a href=\"#conc\">Conclusion</a></li>\n</ul>"},{"metadata":{},"cell_type":"markdown","source":"<a id='sources'></a>\n# Sources\n[Telco Customer Churn](https://www.kaggle.com/blastchar/telco-customer-churn)\n\n#### Some of these ideas are ispired by [Muslum Polat](https://www.kaggle.com/muslump/telco-customer-churn-analysis?fbclid=IwAR0gRroMTTbjUQCzxf6Rp2FxDVu4n16pTRTcRPnCr9mqRzbu6hF0AZM5bz4)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# For Loading and Manipulating the data\nimport numpy as np\nimport pandas as pd\nfrom itertools import combinations\n\n# For splitting, scaling and upsampling the data respectively\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.utils import resample\n\n# Models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\n\n# For Evaluation \nfrom sklearn.metrics import classification_report, confusion_matrix\n\n\n# For Visualization Purposes \nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\n\n# To display all the columns ( regardless of their number or their width )\npd.set_option('display.max_columns', None)\npd.set_option('display.max_colwidth', None)\n\n# To change the style of the plots ( so that we all can see the same thing :) )\nplt.style.use('seaborn')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"churn_df = pd.read_csv('/kaggle/input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='cleaning'></a>\n# Data Cleaning"},{"metadata":{},"cell_type":"markdown","source":"### First let's take a look at the data to know how to clean it"},{"metadata":{},"cell_type":"markdown","source":"Overall check on columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"churn_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# First of all let's change some columns names so that all the columns names are written in the same pattern\nchurn_df.rename(columns={'customerID':'CustomerID', 'gender':'Gender', 'tenure':'Tenure'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A closer look on columns types"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"churn_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before going on We can see that \"TotalCharges\" has an object type despite the fact that it's a numeric feature."},{"metadata":{},"cell_type":"markdown","source":"_Let's test what i call **\"Hidden NaNs\"**_"},{"metadata":{"trusted":true},"cell_type":"code","source":"\" \" in churn_df.values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> It looks like that we have bad hidden NaNs in our dataset :). We will deal with them later."},{"metadata":{},"cell_type":"markdown","source":"Statistical Summary"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"churn_df.describe().drop(columns='SeniorCitizen') # I droped SeniorCitizen from statistical description \n                                                  # as it will be considered a numeric column which it is not","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking Duplicates"},{"metadata":{"trusted":true},"cell_type":"code","source":"churn_df.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Summary: \n> ##### We can see that there are:\n   - _Useless columns_  : \"CustomerID\"\n   - _Hidden NaNs_ : \" \"\n   - _Wrong-format Columns_ : \n      - _toObject_ : \"SeniorCitizen\"\t( that is not important but i like it to be 'Yes' and 'No' )\n      - _toFloat_  : \"TotalCharges\""},{"metadata":{},"cell_type":"markdown","source":"_Useless Columns_"},{"metadata":{"trusted":true},"cell_type":"code","source":"churn_df.drop(columns='CustomerID', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Test**"},{"metadata":{"trusted":true},"cell_type":"code","source":"churn_df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"_Hidden NaNs_"},{"metadata":{"trusted":true},"cell_type":"code","source":"churn_df.replace(' ', np.nan, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Test**"},{"metadata":{"trusted":true},"cell_type":"code","source":"churn_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> we can see that there are 11 missing values in \"TotalCharges\" column ... Let's take a closer look at them."},{"metadata":{"trusted":true},"cell_type":"code","source":"churn_df[churn_df['TotalCharges'].isnull()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before deciding what to do..."},{"metadata":{"trusted":true},"cell_type":"code","source":"churn_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"churn_df['Churn'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"churn_df[churn_df['TotalCharges'].isnull()]['Churn'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> We can see that all the missing values have Churn = 'No'. For the whole data, we can see that 'No's are more than 'Yes's. So I think dropping these 11 missing values will not affect the data dramatically."},{"metadata":{"trusted":true},"cell_type":"code","source":"churn_df.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Test**"},{"metadata":{"trusted":true},"cell_type":"code","source":"churn_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"_Wrong-format Columns_"},{"metadata":{"trusted":true},"cell_type":"code","source":"# toObject               \nchurn_df[\"SeniorCitizen\"] = churn_df[\"SeniorCitizen\"].map({1:'Yes', 0:'No'})    \n\n# toFloat\nchurn_df[\"TotalCharges\"]  = churn_df[\"TotalCharges\"].astype(float) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Test**"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"churn_df[\"SeniorCitizen\"].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"churn_df[\"TotalCharges\"].dtype","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font color='green'>\n<h2><center> Now I think it is clean now :) </center></h2>"},{"metadata":{},"cell_type":"markdown","source":"<a id='eda'></a>\n# Now it's time for some Exploration"},{"metadata":{},"cell_type":"markdown","source":"<font color='blue'>\n    <h5> Some Helping Functions </h5>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def CountPlot(dataFrame, x, hue=None, ax=None):\n    # Main plot\n    ax = sns.countplot(data=dataFrame, x=x, hue=hue, ax=ax)\n    \n    ## Adding Annotation \n    # Total number of clients\n    n_clients = dataFrame.shape[0]\n    \n    # Looping over each column\n    for p in ax.patches:\n\n        loc    = p.get_x()\n        height = p.get_height()\n        width  = p.get_width()\n        pct    = '({:0.2f}%)'.format(100*height/n_clients)\n        \n        # Adding the exact height at the top\n        ax.text(loc+width/2, height+3 , str(height), weight = 'bold',ha=\"center\", fontsize=15)\n        \n        # Adding the percentage wrt the total number of clients at the middle of each column\n        ax.text(loc+width/2, int(0.5*height), pct, weight = 'bold',ha=\"center\", fontsize=15, color='w')\n        \n    # Adding title\n    ax.set_title(f\"{x} Distribution\", fontsize=25, color='brown')\n    \n    # Before editing the ticks we need to draw the plot first\n    plt.draw()\n    \n    # Editing axes labels and ticks\n    ax.set_xlabel(x, fontsize=20)\n    ax.set_xticklabels(ax.get_xticklabels(), fontsize=15)\n        \n    ax.set_ylabel('Number of Users', fontsize=20)\n    ax.set_yticklabels(ax.get_yticklabels(), fontsize=15);\n        \n    # Adding legend\n    if hue:\n        ax.legend(labels=list(dataFrame[hue].unique()),  prop={\"size\":20}, frameon=True, shadow=True);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ScatterPlot(dataFrame, x, y, hue=None, ax=None):\n    # Main plot\n    ax = sns.scatterplot(data=dataFrame, x=x, y=y, hue=hue, ax=ax, alpha=0.7)\n    \n    # Adding title\n    corr = dataFrame[x].corr(dataFrame[y])\n    ax.set_title(f\"{x} with {y} by {hue}\\n (Corr = {round(corr, 2)})\", fontsize=25, color='brown')\n    \n    # Before editing the ticks we need to draw the plot first\n    plt.draw()\n    \n    # Editing axes labels\n    ax.set_xlabel(x, fontsize=20)\n    ax.set_xticklabels(ax.get_xticklabels(), fontsize=15)\n    \n    ax.set_ylabel(y, fontsize=20)\n    ax.set_yticklabels(ax.get_yticklabels(), fontsize=15);\n    \n    # Adding legend\n    if hue:\n        ax.legend(prop={\"size\":13}, frameon=True, shadow=True);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def kdeplot_churn(dataFrame, col, ax=None):\n    # Main plot\n    ax = sns.kdeplot(dataFrame[col][dataFrame[\"Churn\"] == 'Yes'], color=\"Red\", ax=ax, shade=True)\n    ax = sns.kdeplot(dataFrame[col][dataFrame[\"Churn\"] == 'No'], color=\"Blue\", ax=ax, shade=True)\n    \n    # Adding title\n    ax.set_title(f\"Distribution of {col} by churn\", fontsize=17, color='brown')\n    \n    # Before editing the ticks we need to draw the plot first\n    plt.draw()\n    \n    # Editing axes labels\n    ax.set_xlabel(col, fontsize=15)\n    ax.set_xticklabels(ax.get_xticklabels(), fontsize=15)\n    \n    ax.set_ylabel('Density', fontsize=15)\n    ax.set_yticklabels(ax.get_yticklabels(), fontsize=15)\n    \n    # Adding legend\n    ax.legend([\"Churn\",\"Not Churn\"], loc='upper right', frameon=True, shadow=True);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First let's **\"Churn\"** distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"CountPlot(churn_df, 'Churn')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> It looks like that this data is **Imbalanced**"},{"metadata":{},"cell_type":"markdown","source":"Before dive deeper in exploration phase let's first **divide** our data into three dataframes:\n- Demographic \n- Services \n- Account"},{"metadata":{"trusted":true},"cell_type":"code","source":"Demographic_cols = ['Gender', 'SeniorCitizen', 'Partner', 'Dependents', 'Churn']\nServices_cols    = ['PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', \n                    'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Churn']\nAccount_cols_cat = ['Contract', 'PaperlessBilling', 'PaymentMethod', 'Churn']\nAccount_cols_num = ['Tenure', 'MonthlyCharges', 'TotalCharges', 'Churn']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Demographic Features..."},{"metadata":{},"cell_type":"markdown","source":"#### Univariate Exploration "},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(17, 12))\nfig.suptitle('Demographic Features Distributions', fontsize=40, weight='bold')\nfor i, col in enumerate(Demographic_cols[:-1]):\n    sorted_counts = churn_df[col].value_counts()\n    plt.subplot(2, 2, i+1)\n    plt.pie(sorted_counts, labels = sorted_counts.index, startangle = 90, autopct='%1.2f%%', \n                 counterclock = False, radius = 1.2, textprops={'fontsize': 14})\n    plt.title(f'{col} Distribution',fontsize=15, weight='bold', color='brown', loc='center')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Summary:\n- there is a balance in Gender and Partner columns.\n- But on the other hand the majority of people are young and have no dependents. So we should take this imbalance into our consideration when we judge the upcoming results."},{"metadata":{},"cell_type":"markdown","source":"#### Bivariate Exploration"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows = 2, ncols = 2, figsize = (22,20))\nfig.suptitle('Demographic Features Distributions by Churn', fontsize=40, weight='bold')\nfor i, col in enumerate(Demographic_cols[:-1]):\n    CountPlot(churn_df[Demographic_cols], col, hue=\"Churn\", ax=axes[i//2, i-(i//2)*2])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **We can see that:**\n- The churn rate :\n   - Is very close for both Male and Female.\n   - Is high for Senior Clients ($\\frac{476}{476+666} = {41.68}\\% $) compared to Younger ones ($\\frac{1393}{1393+4497} = {23.65}\\% $)\n   - Is high for Clients that have no partner ($\\frac{1200}{1200+2439} = {32.98}\\% $) compared to the ones that have a partner ($\\frac{669}{669+2724} = {19.72}\\% $)\n   - Also here is high for Clients that have no dependents ($\\frac{1543}{1543+3390} = {31.28}\\% $) compared to the ones that have a dependent ($\\frac{326}{326+1773} = {15.53}\\% $)"},{"metadata":{},"cell_type":"markdown","source":"### Feature Engineering For Demographic Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# I just need, for now, to convert the Gender column to ones and zeros\nchurn_df['Gender'] = np.where(churn_df['Gender'] == 'Male', 1, 0)\n\n# Detect if the client has neither Partner nor Dependents\nchurn_df['NoDep_NoPart'] = np.where((churn_df['Partner'] == 'No')|(churn_df['Dependents'] == 'No'), 1, 0)\n\n# Senior or not\nchurn_df['SeniorCitizen'] = np.where((churn_df['SeniorCitizen'] == 'Yes'), 1, 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's drop \"Partner\" and \"Dependents\" columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping the unnecessary columns ( according to the above analysis )\nchurn_df.drop(columns=[\"Partner\", \"Dependents\"], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Services Features..."},{"metadata":{},"cell_type":"markdown","source":"#### Univariate Exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(17, 17))\nfig.suptitle('Services Features Distributions', fontsize=40, weight='bold')\nfor i, col in enumerate(Services_cols[:-1]):\n    sorted_counts = churn_df[col].value_counts()\n    plt.subplot(3, 3, i+1)\n    plt.pie(sorted_counts, labels = sorted_counts.index, startangle = 90, autopct='%1.2f%%', \n                 counterclock = False, radius = 1.2, textprops={'fontsize': 14})\n    plt.title(f'{col} Distribution',fontsize=15, weight='bold', color='brown', loc='center')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Let's get the bivariate plots before jumping to any conclusions."},{"metadata":{},"cell_type":"markdown","source":"#### Bivariate Exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows = 3, ncols = 3, figsize = (32,30))\nfig.suptitle('Services Features Distributions by Churn', fontsize=50, weight='bold')\nfor i, col in enumerate(Services_cols[:-1]):\n    CountPlot(churn_df[Services_cols], col, hue=\"Churn\", ax=axes[i//3, i-(i//3)*3])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **According to the univariate distibutions, we can't rely on only the numbers. We should get the rate of churn for each one of them so that we could compare ( as we did in the demographic distributions ):**\n- The churn rate :\n   - Is very close for both Clients who have phone service ($\\frac{1699}{1699+4653} = {26.75}\\% $) and who hasn't ($\\frac{170}{170+510} = {25}\\% $).\n   - Is a little higher for Clients who have MultipleLines ($\\frac{850}{850+2117} = {28.65}\\% $) compared to other ones ($rate_{NoPhoneService}=\\frac{170}{170+510} = {25}\\% and rate_{No}=\\frac{849}{849+2536} = {25.08}\\%  $) May be it's expensive or something.\n   - Is relatively high for Clients that use Fiber optic in their internet Service ($\\frac{1297}{1297+1799} = {41.89}\\% $).\n   - Is relatively high for Clients that do not have Online Security, OnlineBackup, DeviceProtection,and TechSupport (41.78%, 39.94%, 39.14%,and 41.65% respectively).\n   - Also it's a little higher for the clients who do not have StreamingTV or StreamingMovies."},{"metadata":{},"cell_type":"markdown","source":"### Feature Engineering For Services Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Phone Service\nchurn_df['PhoneService'] = np.where(churn_df['PhoneService']=='Yes', 1, 0)\n\n# MultipleLines\nchurn_df['MultipleLines'] = np.where(churn_df['MultipleLines']=='Yes', 1, 0)\n\n# Has Fiber optic \nchurn_df['FiberOptic'] = np.where(churn_df['InternetService']=='Fiber optic', 1, 0)\n\n# Has no services ( other than MultipleLines, StreamingTV,and StreamingMovies )\nchurn_df['NoServ'] = np.where((churn_df['OnlineSecurity'] != 'No') | (churn_df['OnlineBackup'] != 'No') |\n                              (churn_df['DeviceProtection'] != 'No') | (churn_df['TechSupport'] != 'No'), 1, 0)\n\n# StreamingTV,and StreamingMovies\nchurn_df['NoStream'] = np.where((churn_df['StreamingTV'] != 'No') | (churn_df['StreamingMovies'] != 'No'), 1, 0)\n \n# number of services subscribed by each client\nchurn_df[\"SumOfIntServices\"]=(churn_df.iloc[:, 6:12]=='Yes').sum(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping....\nchurn_df.drop(columns=[\"InternetService\", \"OnlineSecurity\", \"OnlineBackup\", \"DeviceProtection\", \n                       \"TechSupport\", \"StreamingTV\", \"StreamingMovies\"], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Categorical Account Features..."},{"metadata":{},"cell_type":"markdown","source":"#### Univariate Exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(17, 10))\nfig.suptitle('Account Categorical Features Distributions', fontsize=40, weight='bold')\nfor i, col in enumerate(Account_cols_cat[:-1]):\n    sorted_counts = churn_df[col].value_counts()\n    plt.subplot(3, 1, i+1)\n    plt.pie(sorted_counts, labels = sorted_counts.index, startangle = 90, autopct='%1.2f%%', \n                 counterclock = False, radius = 1.2, textprops={'fontsize': 14})\n    plt.title(f'{col} Distribution',fontsize=15, weight='bold', color='brown', loc='center')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":">To Complete our story, Let's go to Bivariate Exploration."},{"metadata":{},"cell_type":"markdown","source":"#### Bivariate Exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows = 3, ncols = 1, figsize = (17,22))\nfig.suptitle('Account Categorical Features Distributions by Churn', fontsize=25, weight='bold')\nfor i, col in enumerate(Account_cols_cat[:-1]):\n    CountPlot(churn_df[Account_cols_cat], col, hue=\"Churn\", ax=axes[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **We can see that:**\n- Churn rate is :\n   - Is high for Clients that has a month-to-month contract ($\\frac{1655}{1655+2220} = {42.71}\\% $). That is reasonable by the way as he could make the contract more than that if he intended to stay longer.\n   - Is high for Clients that has paperless billing ($\\frac{1400}{1400+2768} = {33.59}\\% $). Maybe there is a problem in the website or something.\n   - Is very high for Clients that pay by electronic check ($\\frac{1071}{1071+1294} = {45.29}\\% $). May be the GUI or the website is not good enough."},{"metadata":{},"cell_type":"markdown","source":"### Feature Engineering..."},{"metadata":{"trusted":true},"cell_type":"code","source":"# According to the above note....\nchurn_df['MonthToMonth'] = np.where((churn_df['Contract'] == 'Month-to-month'), 1,0)\nchurn_df['PaperlessBilling'] = np.where((churn_df['PaperlessBilling'] == 'Yes'), 1,0)\nchurn_df['ElectronicCheck'] = np.where((churn_df['PaymentMethod'] == 'Electronic check'), 1,0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping...\nchurn_df.drop(columns=['Contract', 'PaymentMethod'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Numerical Account Features..."},{"metadata":{},"cell_type":"markdown","source":"#### Univariate Exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows = 1, ncols = 3, figsize = (17,6))\nfig.suptitle('Numerical Account Features Distributions by Churn', fontsize=25, weight='bold')\nfor i in range(3):\n    kdeplot_churn(churn_df, Account_cols_num[i], ax=axes[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> We can see that:\n - if the client stayed from 0 to nearly 20 months only he is more likely to churn.\n - if the monthly charges is between 60 to 120 dollars he is more likely to churn\n - there is a little difference between the two density curves for the total charges."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows = 3, ncols = 1, figsize = (15,30))\ncombs = list(combinations(Account_cols_num[:-1], 2))\nfor i in range(3):\n    ScatterPlot(churn_df, combs[i][0], combs[i-3][1], hue=Account_cols_num[-1], ax=axes[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **We can see that:**\n- _From the scatter plot:_\n    - There is no specific pattern between Tenure and MonthlyCharges.\n    - But we do see that there is a correlation between TotalCharges with both of MonthlyCharges and Tenure, which is reasonable by the way. So i will take only the tenure and monthly charges and drop the total charges.\n"},{"metadata":{},"cell_type":"markdown","source":"### Feature Engineering..."},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.qcut(churn_df[\"MonthlyCharges\"],3).unique()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# According to the above notes...\nchurn_df[\"tenure_L20\"]=pd.qcut(churn_df[\"Tenure\"],3)                       # 3 to get one of the categories (0.999, 14.0]   \nchurn_df[\"MonthlyCharges_60_120\"] = pd.qcut(churn_df[\"MonthlyCharges\"],3)  # 3 to get one of the categories (84.0, 118.75]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping \nchurn_df.drop(columns=[\"Tenure\", \"MonthlyCharges\", \"TotalCharges\"], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Final Touch"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"churn_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To avoid get_dummies trap you should put drop_first = True\nchurn_df = pd.get_dummies(data=churn_df, columns=['tenure_L20', 'MonthlyCharges_60_120'], drop_first=True)\n\n# As for Churn, we don't need LabelEncoder as it's only 'Yes' or 'No'\nchurn_df['Churn'] = np.where(churn_df['Churn']=='Yes', 1, 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**To check if i did something wrong**"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"churn_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"churn_df.isnull().sum()        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"churn_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font color='green'>\n<h2><center> Hoooooraaaay, It is time for Modeling :) </center></h2>"},{"metadata":{},"cell_type":"markdown","source":"<a id='model'></a>\n<font color='blue'>\n<h2><center> Modeling </center></h2>"},{"metadata":{},"cell_type":"markdown","source":"#### 1- First let's split the feature ( X ) from the target ( Y )"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = churn_df.drop(columns=['Churn'])\ny = churn_df['Churn']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2- Splitting the data to training and testing sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3- Scaling Transformation"},{"metadata":{"trusted":true},"cell_type":"code","source":"sc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 4- Building our Models"},{"metadata":{},"cell_type":"markdown","source":"- **Note:** Why here we care about precision ?. Because if the model predicts that a client has left the company but he actually hasn't (FP), that is very bad for the company."},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_precision(y_test, y_pred):\n    CM = confusion_matrix(y_test, y_pred)\n    TP = CM[1,1]\n    FP = CM[0,1]\n    precision = TP/(TP+FP)\n    \n    return precision","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"_Logistic Regression_"},{"metadata":{"trusted":true},"cell_type":"code","source":"lg_model = LogisticRegression(random_state=0)\nlg_model.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lg_acc = lg_model.score(x_test, y_test)\nprint(\"The logistic Regression model score on train set is: {}\".format(lg_model.score(x_train, y_train)))  # To test Overfitting\nprint(\"The logistic Regression model score on test set is: {}\".format(lg_acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = lg_model.predict(x_test)\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"_KNN_"},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_model = KNeighborsClassifier()\nknn_model.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_acc = knn_model.score(x_test, y_test)\nprint(\"The KNN model score on train set is: {}\".format(knn_model.score(x_train, y_train)))    \nprint(\"The KNN model score on test set is: {}\".format(knn_acc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> It seems that this model is slightly overfitting the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = knn_model.predict(x_test)\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"_Decision Tree_"},{"metadata":{"trusted":true},"cell_type":"code","source":"dt_model = DecisionTreeClassifier(random_state=0)\ndt_model.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt_acc = dt_model.score(x_test, y_test)\nprint(\"The Decision Tree model score on train set is: {}\".format(dt_model.score(x_train, y_train)))\nprint(\"The Decision Tree model score on test set is: {}\".format(dt_acc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Also here there is an overfitting"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = dt_model.predict(x_test)\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Let's see if we can make it better and get higher precision...**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create for loop to prune tree\nprecisions = []\naccuracies = []\nd_range = range(2, 20) \nfor d in d_range:\n    tree = DecisionTreeClassifier(random_state=0, max_depth=d)\n    tree.fit(x_train, y_train)\n    y_pred = tree.predict(x_test)\n    precisions.append(get_precision(y_test, y_pred))\n    accuracies.append(tree.score(x_test, y_test))\n    \n# Plot graph to see how individual accuracy scores changes with tree depth\nplt.plot(d_range, precisions)\nplt.plot(d_range, accuracies)\nplt.xlabel(\"Depth of Tree\")\nplt.ylabel(\"Precisions(Blue) & Accuracy(Green)\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"precisions","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> I think the best value here is max_depth = 4"},{"metadata":{"trusted":true},"cell_type":"code","source":"dt_model = DecisionTreeClassifier(random_state=0, max_depth=4)\ndt_model.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt_acc = dt_model.score(x_test, y_test)\nprint(\"The Decision Tree model score on train set is: {}\".format(dt_model.score(x_train, y_train)))\nprint(\"The Decision Tree model score on test set is: {}\".format(dt_acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = dt_model.predict(x_test)\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"_Random Forest_"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_model = RandomForestClassifier(oob_score=True, random_state=0, warm_start=True, n_jobs=-1)\nrf_model.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_acc = rf_model.score(x_test, y_test)\nprint(\"The Decision Tree model score on train set is: {}\".format(rf_model.score(x_train, y_train)))\nprint(\"The Decision Tree model score on test set is: {}\".format(rf_acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = rf_model.predict(x_test)\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Some Prunning**"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_model = RandomForestClassifier(oob_score=True, random_state=0, warm_start=True, n_jobs=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"precisions = []\naccuracies = []\n# Iterate through all of the possibilities for the number of trees\nn_range = range(50, 300, 10)\nfor n_trees in n_range:\n    rf_model.set_params(n_estimators=n_trees)  # Set number of trees\n    rf_model.fit(x_train, y_train)\n    y_pred = rf_model.predict(x_test)\n    precisions.append(get_precision(y_test, y_pred))\n    accuracies.append(rf_model.score(x_test, y_test))\n\nplt.plot(n_range, precisions, marker='o')\nplt.plot(n_range, accuracies)\nplt.xlabel(\"Number of Trees\")\nplt.ylabel(\"Precisions(Blue) & Accuracy(Green)\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"precisions","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> I think n_estimators = 250 is the best number"},{"metadata":{},"cell_type":"markdown","source":"<font color='green'>\nBest Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_model = RandomForestClassifier(n_estimators=250, oob_score=True, random_state=0, warm_start=True, n_jobs=-1)\nrf_model.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_acc = rf_model.score(x_test, y_test)\nprint(\"The Decision Tree model score on train set is: {}\".format(rf_model.score(x_train, y_train)))\nprint(\"The Decision Tree model score on test set is: {}\".format(rf_acc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Overfitting again."},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = rf_model.predict(x_test)\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"_SVM_"},{"metadata":{"trusted":true},"cell_type":"code","source":"svm_model = SVC(random_state=0, C=1.5)\nsvm_model.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svm_acc = svm_model.score(x_test, y_test)\nprint(\"The Decision Tree model score on train set is: {}\".format(svm_model.score(x_train, y_train)))\nprint(\"The Decision Tree model score on test set is: {}\".format(svm_acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = svm_model.predict(x_test)\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To calculate AUC\nfrom sklearn.metrics import roc_auc_score\n\nroc_auc_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='conc'></a>\n# Conclusion: \n> As we can see the best model from all of the above is the _SVM_ :\n- Accuracy  = 82%\n- **Precision = 70%**\n- Recall    = 52%\n- **F1-score  = 60%**\n- **AUC = 72%**"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}