{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Heart Failure Precition - Projekt Podstawy Uczenia Maszynowego Laboratorum"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Wczytujemy nasz zbór danych, jak możemy wywnioskować zbiór składa się z danych odnoszących się do 299 pacjentów. Posiadamy 12 różnych kolumn z informacjami na temat stanu zdrowia pacjenta oraz kolumnę `DEATH_EVENT` binarnie opisującą czy pacjent zmarł czy nie. (1 - jeżeli zmarł)"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"dataset = pd.read_csv(\"../input/heart-failure-clinical-data/heart_failure_clinical_records_dataset.csv\")\nprint(np.shape(dataset))\ndataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Skupmy się na chwilę na kolumnie `DEATH_EVENT` i sprawdźmy ile pacjentów zawartych w tabeli zmarło."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(dataset['DEATH_EVENT'].value_counts())\ndataset['DEATH_EVENT'].value_counts().plot.pie(explode=[0,0.1],shadow=True,autopct='%1.1f%%',\n                                              title = 'Is patient died')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Jak możemy zauważyć poniżej nasze dane tabelaryczne są pełne i nie zawierają żadnych pustych wpisów co ułatwia nam pracę."},{"metadata":{"trusted":true},"cell_type":"code","source":"np.where(pd.isnull(dataset))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Wszystkie pomiary to wartości liczbowe, dzięki temu nie musimy kodować zmiennych kategorycznych."},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.dtypes.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Teraz sprawdzimy czy wszystkie dane wyglądają na prawidłowe. Użyjemy do tego metody `describe()`. Na pierwszy rzut oka żadne skrajne wartości w kolumnach nie odbiegają znacząco od normy, ale warto przyjrzeć się im bliżej przy wizualizacji."},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['age'].plot.hist(title = \"Histogram of column AGE\")\nplt.xlabel('Age')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['creatinine_phosphokinase'].plot.hist(title = \"Histogram of column creatinine_phosphokinase\")\nplt.xlabel('Level of the CPK enzyme in the blood (mcg/L)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" dataset['diabetes'].value_counts().plot.pie(explode=[0,0.1],shadow=True,autopct='%1.1f%%',\n                                       title = 'Is patiernt diabetic')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['ejection_fraction'].plot.hist(title = \"Histogram of column EJECTION_FRACTION\")\nplt.xlabel('Percentage of blood leaving the heart at each heart contraction')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" dataset['high_blood_pressure'].value_counts().plot.pie(explode=[0,0.1],shadow=True,autopct='%1.1f%%',\n                                       title = 'Is patiernt having hypertention')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['platelets'].plot.hist(title = \"Histogram of column PLATELETS\")\nplt.xlabel('Platelets in the blood (kiloplatelets/mL)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['serum_creatinine'].plot.hist(title = \"Histogram of column SERUM_CREATININE\")\nplt.xlabel('Level of serum creatinine in the blood (mg/dL)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['serum_sodium'].plot.hist(title = \"Histogram of column SERUM_SODIUM\")\nplt.xlabel('Level of serum sodium in the blood (mEq/L)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" dataset['sex'].value_counts().plot.pie(explode=[0,0.1],shadow=True,autopct='%1.1f%%',\n                                       title= 'Is patient male')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" dataset['smoking'].value_counts().plot.pie(explode=[0,0.1],shadow=True,autopct='%1.1f%%',\n                                       title = 'Does patient smokes')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['time'].plot.hist(title = \"Histogram of column TIME\")\nplt.xlabel('Follow-up period (days)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Gdy zapoznaliśmy się już dokładniej z danymi, warto byłoby utworzyć macierz korelacji pomiędzy nimi. Z utworzonej poniżej macierzy widzimy że cztery pomiary które mają największą korelacje z wartością kolumny `DEATH_EVENT` to\n* `time`(-0.53) oraz `ejection_fraction`(-0,27) - Ujemna korelacja\n* `serum_creatinine` (0.29) oraz `age` (0.25) - Dodatnia korelacja"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = dataset.corr()\nf = plt.figure(figsize = (14,9))\nsns.heatmap(corr,vmax = 1,square = True,annot = True,vmin = -1)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Po ogólnej analizie naszego zbioru danych przechodzimy do porównania cech które najbardziej wpływają na śmierć z kolumną `DEATH_EVENT`\n\nJak można zauważyć na poniższym wykresie dla kreatyniny w surowicy, widzimy że przy pomiarach zbliżonych zeru pacjenci mieli dużo większą szansę na przeżycie. Przy wyższych wynikach różnica zanika, a dla pomiarów ponad 6tyś jednostek wszyscy pacjenci zmarli.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\n\nfig = px.histogram(dataset, x=\"serum_creatinine\",\n                   color=\"DEATH_EVENT\", marginal=\"rug\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Przy wykresie biorącym pod uwagę czas, możemy zauważyć że większość pacjentów zmarło podczas pierwszych 100 dni leczenia."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.histogram(dataset, x=\"time\",\n                   color=\"DEATH_EVENT\", marginal=\"rug\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Przy bardzo niskiej frakcji wyrzutowej pacjenci byli najbardziej narażeni na śmierć, przy wyższych wynikach śmiertelne przypadki stanowią już mały ułamek."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.histogram(dataset, x=\"ejection_fraction\",\n                   color=\"DEATH_EVENT\", marginal=\"rug\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Śmiertelność biorąc pod uwagę wiek i analizując poniższy wykres, jak można było się spodziewać, wzrasta wraz z ilością lat pacjenta. Powyżej 70lat wynosi ponad 50 punktów procentowych."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.histogram(dataset, x=\"age\",\n                   color=\"DEATH_EVENT\", marginal=\"rug\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Teraz gdy już zapoznaliśmy się bardzien z naszym zbiorem danych możemy przejść do podziału na zbiór treningowy oraz testowy. Niestety nie posiadamy zbyt dużo danych, podzielimy zbiór 80:20 aby nasz model miał wystarczającą ilość informacji do treningu."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nfeatures = ['time', 'serum_creatinine', 'ejection_fraction']\nx = dataset[features]\ny = dataset['DEATH_EVENT']\n\ntrain_x,test_x,train_y,test_y = train_test_split(x,y, test_size=0.2, random_state=30)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Na początek wypróbujmy model korzystający z regresji logistycznej. Domyślnie korzysta ona z normy L2. Parametr `solver` ustawimy na 'liblinear' ponieważ nasz zbiór jest mały a problem nie jest bardzo złożony. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\nmodel_lr = LogisticRegression(solver='liblinear')\nmodel_lr.fit(train_x,train_y)\nlr_predict =  model_lr.predict(test_x)\nlr_accuracy = accuracy_score(test_y, lr_predict)\nprint('Accuracy for model using  Linear Regression: ', lr_accuracy*100 , \"%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Warto przyjrzeć się tablicy pomyłek dla naszego naszego modelu. Jak widzimy poniżej nasz model radzi sobie nienajgorze. Na 60 przypadków 12 razy zdiagnozował że serce nie powinno stanąć, a w rzeczywistości było odwrotnie. Z racji że problem rozgrywa się o ludzkie życie lepiej było by czasami fałszywie zaalarmować o możliwości śmierci niż zapewnić że wszystko powinno być w porządku. Potrzebna nam większa czułość. W tym przypadku aby mierzyć poprawność naszego modelu możemy korzystać również z miary F-Beta która pozwala nam regulować balans miedzy precyzja a czułością, parametr Beta to waga czułości. Jak możemy zauważyć gdy traktujemy czułość jako 2 razy ważniejszą od precyzji nasz wynik jest bliski 0.6 co już nie jest tak satysfakcjonującym wynikiem jak powyższy."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import plot_confusion_matrix\nfrom sklearn.metrics import fbeta_score\n\nplt.figure()\nplot_confusion_matrix(model_lr,test_x, test_y)  \nplt.title(\"Confusion Matrix - Linear Regression Model\")\nplt.xticks(range(2), [\"Heart Not Failed\",\"Heart Fail\"], fontsize=16)\nplt.yticks(range(2), [\"Heart Not Failed\",\"Heart Fail\"], fontsize=16)\nplt.show()\n\nprint('F-Beta score for beta = 2 is ', fbeta_score(test_y, lr_predict, beta=2)*100, '%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Zmniejszenie siły regularyzacji poprawiłoby pośrednio naszą czułość ale model prawdopodobnie uległby przeuczeniu, dlatego też póki co spróbujemy wykorzystać inny model,mianowicie K-najbliższych sąsiadów, domyślnie k=5. Coś co od razu rzuca się w oczy to, to że trafność obu modeli jest równa (80%) natomiast miara F-Beta dla Beta=2 uległa poprawie. Model w tym przypadku jest bardziej czuły, co w naszym problemie jest bardzo istotne. Co ciekawe, zauważyłem że przy zmniejszeniu liczby sąsiadów miara F-Beta wzrasta jeszcze bardziej, ale jest to spowodowane, podobnie jak w przypadku zmiany siły regularyzacji, przeuczeniem modelu."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nmodel_kn = KNeighborsClassifier(n_neighbors=5)\nmodel_kn.fit(train_x,train_y)\nkn_predict =  model_kn.predict(test_x)\nkn_fbeta = fbeta_score(test_y, kn_predict, beta=2)\nkn_accuracy = accuracy_score(test_y, lr_predict)\nprint('Accuracy for model using K-Neighbors Classifier: ', kn_accuracy*100 , \"%\")\nprint('F-Beta score for beta = 2 is ', kn_fbeta*100, '%')\n\nplt.figure()\nplot_confusion_matrix(model_kn,test_x, test_y)  \nplt.title(\"Confusion Matrix - K-Neighbors Classifier\")\nplt.xticks(range(2), [\"Heart Not Failed\",\"Heart Fail\"], fontsize=16)\nplt.yticks(range(2), [\"Heart Not Failed\",\"Heart Fail\"], fontsize=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Spróbujmy w takim razie prosto zoptymalizować algorytm pod kątem miary F2. Model nie jest bardzo złożony więc jedynymi parametrami do optymalizacji w naszym algorytmie będą liczba sąsiadów (minimalnie 3, dla 1 model byłby na pewno przeuczony), oraz p czyli wybór metryki. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from optuna.samplers import TPESampler\nimport optuna\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\n\ndef create_model(trial):\n    n_neighbors = trial.suggest_int(\"n_neighbors\", 3, 15)\n    p = trial.suggest_int(\"p\", 1, 2)\n    \n    model = KNeighborsClassifier(\n        n_neighbors=n_neighbors, \n        p=p,\n    )\n    return model\n\nsampler = TPESampler(seed=30)\n\ndef objective(trial):\n    model = create_model(trial)\n    model.fit(train_x, train_y)\n    preds = model.predict(test_x)\n    return fbeta_score(test_y, preds, beta=2)\n\nstudy = optuna.create_study(direction=\"maximize\", sampler=sampler)\nstudy.optimize(objective, n_trials=200)\n\nkn_params = study.best_params\nkn = KNeighborsClassifier(**kn_params)\nkn.fit(train_x, train_y)\npreds = kn.predict(test_x)\n\n\nprint('Optimized KNeighborsClassifier accuracy: ', accuracy_score(test_y, preds))\nprint('Optimized KNeighborsClassifier f1-score', f1_score(test_y, preds))\nprint('Optimized KNeighborsClassifier f2-score', fbeta_score(test_y, preds,beta=2))\nprint('Optimized KNeighborsClassifier precision', precision_score(test_y, preds))\nprint('Optimized KNeighborsClassifier recall', recall_score(test_y, preds))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Po optymalizacji otrzymaliśmy model którego wynik miary F2 wynosi 70% a trafność 85%, czyli poprawiliśmy oba wyniki. Sprawdźmy tablicę pomyłek naszego modelu."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\nplot_confusion_matrix(kn,test_x, test_y)  \nplt.title(\"Confusion Matrix - K-Neighbors Classifier\")\nplt.xticks(range(2), [\"Heart Not Failed\",\"Heart Fail\"], fontsize=16)\nplt.yticks(range(2), [\"Heart Not Failed\",\"Heart Fail\"], fontsize=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Z racji małego zbioru danych zmiana nie jest bardzo widoczna, ale to wciąż jedno potencjalnie uratowane życie więcej, więc powinniśmy być zadowoloni z poprawy naszego wyniku. "},{"metadata":{},"cell_type":"markdown","source":"# Podsumowanie\n\nNajlepszym modelem z przeze mnie wybranych okazał się model korzystający z algorytmu KNeighborsClassifier (K-Najbliższych sąsiadów). Po optymalizacji udało się mu uzyskać wynik \n* `85%` trafności (accuracy score)\n* `75%` miary f1\n* `70%` miary fbeta przy beta=2\n\nNie są to może wyniki klasy światowej, ale jestem zadowolony że udało mi się zmaksymalizować możliwości modelu na miarę moich umiejętności. Dużo łatwiej pracowałoby się na zbiorze z większą ilością danych ale nie zawsze jest to możliwe. Patrząc na inne notebooki większość z nich przykładała dużą uwagę do accuracy co w przypadku naszego problemu nie ma tak dużego znaczenia jak miara f2, dlatego też postanowiłem na maksymalizacje tej miary."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}