{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/voicegender/voice.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**perfectly balance data......BRAVO**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['label'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"visulaing the data:-\n    as mostly are continous varriables plotting histogrm and boxplot will serve our purposes"},{"metadata":{},"cell_type":"markdown","source":"calculating outlier by interquetile formula"},{"metadata":{"trusted":true},"cell_type":"code","source":"def calc_limits(feature):\n    q1,q3=df[feature].quantile([0.25,0.75])\n    iqr=q3-q1\n    rang=1.5*iqr\n    return(q1-rang,q3+rang)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot(feature):\n    fig,axes=plt.subplots(1,2)\n    sns.boxplot(data=df,x=feature,ax=axes[0])\n    sns.distplot(a=df[feature],ax=axes[1],color='#ff4125')\n    fig.set_size_inches(15,5)\n    \n    lower,upper = calc_limits(feature)\n    l=[df[feature] for i in df[feature] if i>lower and i<upper] \n    print(\"Number of data points remaining if outliers removed : \",len(l))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot('meanfreq')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"outlier present in meanfreq and negatively skewed we have to normalize it\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot('sd')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot('median')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot('Q25')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot('IQR')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot('skew')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot('kurt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp=[]\nfor i in df['label']:\n    if i=='male':\n        temp.append(1)\n    else:\n        temp.append(0)\ndf['label']=temp","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**PERFORMING BIVARIATE ANALYSIS AND CHECKING CORELEATION BETWEEN VARIABLES**"},{"metadata":{"trusted":true},"cell_type":"code","source":"cor_mat=df[:].corr()\nplt.figure(figsize=(20,20))\nsns.heatmap(data=cor_mat,annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we will be dropping centroid because very high corrleation with other variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop('centroid',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"to breifly undersatnd data with other variables we will be plotting scatterplot"},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.PairGrid(df[['meanfreq','sd','median','Q25','IQR','sp.ent','sfm','meanfun','label']], hue = \"label\")\ng = g.map(plt.scatter).add_legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"removing outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in df.columns:\n    lower,upper=calc_limits(col)\n    df = df[(df[col] >lower) & (df[col]<upper)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"dropping useless variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_df=df.copy()\n\ntemp_df.drop(['skew','kurt','mindom','maxdom'],axis=1,inplace=True) # only one of maxdom and dfrange.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# feature enginerring"},{"metadata":{},"cell_type":"markdown","source":"3median=2mean+mode"},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_df['meanfreq']=temp_df['meanfreq'].apply(lambda x:x*2)\ntemp_df['median']=temp_df['meanfreq']+temp_df['mode']\ntemp_df['median']=temp_df['median'].apply(lambda x:x/3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The second new feature that I have added is a new feature to mesure the 'skewness'.\n\nFor this I have used the 'Karl Pearson Coefficent' which is calculated as shown below->\n..........................................................Coefficent = (Mean - Mode )/StandardDeviation......................................................"},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_df['pear_skew']=temp_df['meanfreq']-temp_df['mode']\ntemp_df['pear_skew']=temp_df['pear_skew']/temp_df['sd']\ntemp_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"noramlizing the faetures"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler=StandardScaler()\nscaled_df=scaler.fit_transform(temp_df.drop('label',axis=1))\nX=scaled_df\nY=df['label'].as_matrix()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.2,random_state=0)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# making our ANN model"},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.callbacks import History\nfrom keras.utils import plot_model\nfrom keras.optimizers import SGD\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**our neural net . i have found hidden layers by performing grid serach cv you can also use randomized serah to find best params and neural net**"},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier=Sequential()\nhistory = History()\n\n#number of input variables =20\n#first layer \n#input_dim is only for the first layer\nclassifier.add(Dense(output_dim=11,init='uniform',activation='relu',input_dim=16))\n#first Hidden layer\nclassifier.add(Dense(output_dim=11,init='uniform',activation='relu'))\n#Second Hidden\nclassifier.add(Dense(output_dim=6,init='uniform',activation='relu'))\n#output layer\nclassifier.add(Dense(output_dim=1,init='uniform',activation='sigmoid'))\n#Running the artificial neural network\nclassifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n#fitting\nclassifier.fit(X_train,y_train,batch_size=10,epochs=50,validation_split=0.1,callbacks=[history],shuffle=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sklearn.metrics as metrics\ny_pred=classifier.predict(X_test)\ny_pred = np.round(y_pred)\n\nprint('Accuracy we are able to achieve with our ANN is',metrics.accuracy_score(y_pred,y_test)*100,'%')\n\nplt.plot(history.history['loss'], color = 'red',label='Variaton Loss over the epochs',)\nplt.plot(history.history['accuracy'],color='cyan',label='Variation in Profit over the epochs')\n\nplt.xlabel('Epochs')\nplt.title('Loss/Accuracy VS Epoch')\nplt.ylabel('Loss/Accuracy')\nplt.legend(loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**IF YOU LIKE MY WORK PLAESE UPVOTE IT.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}