{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!pip install git+https://github.com/deepset-ai/haystack.git","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport json\nimport re\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dirs=[\"pmc_json\",\"pdf_json\"]\ndocs=[]\ncounts=0\nfor d in dirs:\n    print(d)\n    counts = 0\n    for file in tqdm(os.listdir(f\"../input/CORD-19-research-challenge/document_parses/{d}\")):#What is an f string?\n        file_path = f\"../input/CORD-19-research-challenge/document_parses/{d}/{file}\"\n        j = json.load(open(file_path,\"rb\"))\n        #Taking last 7 characters. it removes the 'PMC' appended to the beginning\n        #also paperid in pdf_json are guids and hard to plot in the graphs hence the substring\n        paper_id = j['paper_id']\n        paper_id = paper_id[-7:]\n        title = j['metadata']['title']\n\n        try:#sometimes there are no abstracts\n            abstract = j['abstract'][0]['text']\n        except:\n            abstract = \"\"\n            \n        full_text = \"\"\n        bib_entries = []\n        for text in j['body_text']:\n            full_text += text['text']\n                \n        docs.append([paper_id, title, abstract, full_text])\n        #comment this below block if you want to consider all files\n        #comment block start\n        counts = counts + 1\n        if(counts >= 100):\n            break\n        #comment block end    \ndf=pd.DataFrame(docs,columns=['paper_id','title','abstract','full_text'])\n\nprint(df.shape)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n# importing necessary dependencies\nfrom haystack import Finder\nfrom haystack.preprocessor.cleaning import clean_wiki_text\nfrom haystack.preprocessor.utils import convert_files_to_dicts, fetch_archive_from_http\nfrom haystack.reader.farm import FARMReader\nfrom haystack.reader.transformers import TransformersReader\nfrom haystack.utils import print_answers\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.6.2-linux-x86_64.tar.gz -q","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! tar -xzf elasticsearch-7.6.2-linux-x86_64.tar.gz","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! chown -R daemon:daemon elasticsearch-7.6.2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfrom subprocess import Popen, PIPE, STDOUT\nes_server = Popen(['elasticsearch-7.6.2/bin/elasticsearch'],\n                   stdout=PIPE, stderr=STDOUT,\n                   preexec_fn=lambda: os.setuid(1)  # as daemon\n                  )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! sleep 30","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from haystack.document_store.elasticsearch import ElasticsearchDocumentStore\ndocument_store = ElasticsearchDocumentStore(host=\"localhost\", username=\"\", password=\"\", index=\"document\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndocument_store.write_documents(df[['title', 'full_text']].rename(columns={'title':'name','full_text':'text'}).to_dict(orient='records'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from haystack.retriever.sparse import ElasticsearchRetriever\nretriever = ElasticsearchRetriever(document_store=document_store)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Alternative:\nreader = TransformersReader(model_name_or_path=\"distilbert-base-uncased-distilled-squad\", tokenizer=\"distilbert-base-uncased\", use_gpu=-1)\n# reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", use_gpu=True, context_window_size=500)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"finder = Finder(reader, retriever)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"question = \"What is the impact of coronavirus on babies?\"\nnumber_of_answers_to_fetch = 2\n\nprediction = finder.get_answers(question=question, top_k_retriever=10, top_k_reader=number_of_answers_to_fetch)\nprint(f\"Question: {prediction['question']}\")\nprint(\"\\n\")\nfor i in range(number_of_answers_to_fetch):\n    print(f\"#{i+1}\")\n    print(f\"Answer: {prediction['answers'][i]['answer']}\")\n    print(f\"Research Paper: {prediction['answers'][i]['meta']['name']}\")\n    print(f\"Context: {prediction['answers'][i]['context']}\")\n    print('\\n\\n')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}