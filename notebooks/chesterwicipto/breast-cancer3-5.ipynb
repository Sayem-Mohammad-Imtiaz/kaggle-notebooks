{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"##########################################################\n# 1. IMPORT ALL PACKAGES\n##########################################################\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport math\nfrom collections import Counter\nimport seaborn as sns\nimport matplotlib.pyplot as plt #for plotting\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import multilabel_confusion_matrix\n# importing mean()\nfrom statistics import mean\nfrom sklearn.svm import SVC","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##########################################################\n# 2. LOAD DATASET\n##########################################################\ndata = pd.read_csv(\"../input/breast-cancer-wisconsin-data/data.csv\",header=0)# header 0 means the first row is\n#name of the coloumn\n# Delete unused columns\ndata.drop([\"Unnamed: 32\",\"id\"], axis=1, inplace=True)\ndata.diagnosis = [1 if each == \"M\" else 0 for each in data.diagnosis]\n# Test select malignant data\nm_data = data.loc[data['diagnosis'] == 1]\n# Test select benign data\nb_data = data.loc[data['diagnosis'] == 0]\n# View sample data\nb_data.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##########################################################\n# 3. SHARE TO TEST AND TRAIN DATA\n##########################################################\nx = data.iloc[:, 1:]\ny = data['diagnosis'].tolist()\n# Share test and train data\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"urutan = list(np.sort(data[\"diagnosis\"].unique()))\nprint(urutan)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##########################################################\n# 4. TRAIN PERCEPTRON LEARNING ALGORITHM\n##########################################################\n# Create a perceptron object with the parameters over the data\nmodel_clf = Perceptron(max_iter=50, eta0=0.5, random_state=0)\n# Train the perceptron\nmodel_clf.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##########################################################\n# 5. APPLY THE TRAINED LEARNER TO TEST NEW DATA\n##########################################################\n# Apply the trained perceptron to make prediction of test data\ny_pred = model_clf.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##########################################################\n# 6. MULTI-CLASS CONFUSION MATRIX FOR EACH CLASS\n##########################################################\n# Actual and predicted classes\nlst_actual_class = y_test\nlst_predicted_class = y_pred\n# Class = digit labels 0, 1, 2, 3, 4, 5, 6, 7, 8, 9\nlst_classes = urutan # Must in order\n# Compute multi-class confusion matrix\narr_out_matrix = multilabel_confusion_matrix(lst_actual_class, lst_predicted_class, labels=lst_classes)\n# Temp store results\nstore_sens = [];\nstore_spec = [];\nstore_acc = [];\nstore_bal_acc = [];\nstore_prec = [];\nstore_fscore = [];\nstore_mcc = [];","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loop for each taget label\nfor no_class in range(len(lst_classes)):\n    arr_data = arr_out_matrix[no_class];\n    print(\"Predicted Performance of Digit Label/Class: {0}\".format(no_class));\n    tp = arr_data[1][1]\n    fp = arr_data[0][1]\n    tn = arr_data[0][0]\n    fn = arr_data[1][0]\n    sensitivity = round(tp/(tp+fn), 3);\n    specificity = round(tn/(tn+fp), 3);\n    accuracy = round((tp+tn)/(tp+fp+tn+fn), 3);\n    balanced_accuracy = round((sensitivity+specificity)/2, 3);\n    precision = round(tp/(tp + fp), 3)\n    fscore = round((2 * ((precision * sensitivity) / (precision + sensitivity))), 3)\n    mcc = round((((tp * tn)-(fp * fn))/ math.sqrt((tp + fp)*(tp + fn)*(tn + fp)*(tn + fn))),3)\n    store_sens.append(sensitivity);\n    store_spec.append(specificity);\n    store_acc.append(accuracy);\n    store_bal_acc.append(balanced_accuracy);\n    store_prec.append(precision);\n    store_fscore.append(fscore);\n    store_mcc.append(mcc);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##########################################################\n# 9. OVERALL - FINAL PREDICTION PERFORMANCE\n##########################################################\nprint(\"Overall Performance Prediction:\");\nprint(\"Sensitivity: {0}%\".format(round(mean(store_sens)*100, 4)));\nprint(\"Specificity: {0}%\".format(round(mean(store_spec)*100, 4)));\nprint(\"Accuracy: {0}%\".format(round(mean(store_acc)*100, 4)));\nprint(\"Balanced Accuracy: {0}%\".format(round(mean(store_bal_acc)*100, 4)));\nprint(\"Precision: {0}%\".format(round(mean(store_prec)*100, 4)));\nprint(\"F1-Score: {0}%\".format(round(mean(store_fscore)*100, 4)))\nprint(\"MCC: {0}\\n\".format(round(mean(store_mcc), 4)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##########################################################\n# 4. TRAIN RandomForest ALGORITHM\n##########################################################\n# Create a perceptron object with the parameters over the data\nmodel_clf = RandomForestClassifier(n_estimators=500, max_depth=5)\n# Train the perceptron\nmodel_clf.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##########################################################\n# 5. APPLY THE TRAINED LEARNER TO TEST NEW DATA\n##########################################################\n# Apply the trained perceptron to make prediction of test data\ny_pred = model_clf.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##########################################################\n# 6. MULTI-CLASS CONFUSION MATRIX FOR EACH CLASS\n##########################################################\n# Actual and predicted classes\nlst_actual_class = y_test\nlst_predicted_class = y_pred\n# Class = digit labels 0, 1, 2, 3, 4, 5, 6, 7, 8, 9\nlst_classes = urutan # Must in order\n# Compute multi-class confusion matrix\narr_out_matrix = multilabel_confusion_matrix(lst_actual_class, lst_predicted_class, labels=lst_classes)\n# Temp store results\nstore_sens = [];\nstore_spec = [];\nstore_acc = [];\nstore_bal_acc = [];\nstore_prec = [];\nstore_fscore = [];\nstore_mcc = [];","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loop for each taget label\nfor no_class in range(len(lst_classes)):\n    arr_data = arr_out_matrix[no_class];\n    print(\"Predicted Performance of Digit Label/Class: {0}\".format(no_class));\n    tp = arr_data[1][1]\n    fp = arr_data[0][1]\n    tn = arr_data[0][0]\n    fn = arr_data[1][0]\n    sensitivity = round(tp/(tp+fn), 3);\n    specificity = round(tn/(tn+fp), 3);\n    accuracy = round((tp+tn)/(tp+fp+tn+fn), 3);\n    balanced_accuracy = round((sensitivity+specificity)/2, 3);\n    precision = round(tp/(tp + fp), 3)\n    fscore = round((2 * ((precision * sensitivity) / (precision + sensitivity))), 3)\n    mcc = round((((tp * tn)-(fp * fn))/ math.sqrt((tp + fp)*(tp + fn)*(tn + fp)*(tn + fn))),3)\n    store_sens.append(sensitivity);\n    store_spec.append(specificity);\n    store_acc.append(accuracy);\n    store_bal_acc.append(balanced_accuracy);\n    store_prec.append(precision);\n    store_fscore.append(fscore);\n    store_mcc.append(mcc);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##########################################################\n# 9. OVERALL - FINAL PREDICTION PERFORMANCE\n##########################################################\nprint(\"Overall Performance Prediction:\");\nprint(\"Sensitivity: {0}%\".format(round(mean(store_sens)*100, 4)));\nprint(\"Specificity: {0}%\".format(round(mean(store_spec)*100, 4)));\nprint(\"Accuracy: {0}%\".format(round(mean(store_acc)*100, 4)));\nprint(\"Balanced Accuracy: {0}%\".format(round(mean(store_bal_acc)*100, 4)));\nprint(\"Precision: {0}%\".format(round(mean(store_prec)*100, 4)));\nprint(\"F1-Score: {0}%\".format(round(mean(store_fscore)*100, 4)))\nprint(\"MCC: {0}\\n\".format(round(mean(store_mcc), 4)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##########################################################\n# 4. TRAIN SVM ALGORITHM\n##########################################################\n# Create a SVM object with the parameters over the data\nmodel_clf = SVC(kernel = \"rbf\")\n# Train the perceptron\nmodel_clf.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##########################################################\n# 5. APPLY THE TRAINED LEARNER TO TEST NEW DATA\n##########################################################\n# Apply the trained perceptron to make prediction of test data\ny_pred = model_clf.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##########################################################\n# 6. MULTI-CLASS CONFUSION MATRIX FOR EACH CLASS\n##########################################################\n# Actual and predicted classes\nlst_actual_class = y_test\nlst_predicted_class = y_pred\n# Class = digit labels 0, 1, 2, 3, 4, 5, 6, 7, 8, 9\nlst_classes = urutan # Must in order\n# Compute multi-class confusion matrix\narr_out_matrix = multilabel_confusion_matrix(lst_actual_class, lst_predicted_class, labels=lst_classes)\n# Temp store results\nstore_sens = [];\nstore_spec = [];\nstore_acc = [];\nstore_bal_acc = [];\nstore_prec = [];\nstore_fscore = [];\nstore_mcc = [];","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loop for each taget label\nfor no_class in range(len(lst_classes)):\n    arr_data = arr_out_matrix[no_class];\n    print(\"Predicted Performance of Digit Label/Class: {0}\".format(no_class));\n    tp = arr_data[1][1]\n    fp = arr_data[0][1]\n    tn = arr_data[0][0]\n    fn = arr_data[1][0]\n    sensitivity = round(tp/(tp+fn), 3);\n    specificity = round(tn/(tn+fp), 3);\n    accuracy = round((tp+tn)/(tp+fp+tn+fn), 3);\n    balanced_accuracy = round((sensitivity+specificity)/2, 3);\n    precision = round(tp/(tp + fp), 3)\n    fscore = round((2 * ((precision * sensitivity) / (precision + sensitivity))), 3)\n    mcc = round((((tp * tn)-(fp * fn))/ math.sqrt((tp + fp)*(tp + fn)*(tn + fp)*(tn + fn))),3)\n    store_sens.append(sensitivity);\n    store_spec.append(specificity);\n    store_acc.append(accuracy);\n    store_bal_acc.append(balanced_accuracy);\n    store_prec.append(precision);\n    store_fscore.append(fscore);\n    store_mcc.append(mcc);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##########################################################\n# 9. OVERALL - FINAL PREDICTION PERFORMANCE\n##########################################################\nprint(\"Overall Performance Prediction:\");\nprint(\"Sensitivity: {0}%\".format(round(mean(store_sens)*100, 4)));\nprint(\"Specificity: {0}%\".format(round(mean(store_spec)*100, 4)));\nprint(\"Accuracy: {0}%\".format(round(mean(store_acc)*100, 4)));\nprint(\"Balanced Accuracy: {0}%\".format(round(mean(store_bal_acc)*100, 4)));\nprint(\"Precision: {0}%\".format(round(mean(store_prec)*100, 4)));\nprint(\"F1-Score: {0}%\".format(round(mean(store_fscore)*100, 4)))\nprint(\"MCC: {0}\\n\".format(round(mean(store_mcc), 4)))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}