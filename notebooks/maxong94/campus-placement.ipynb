{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Questions\n\n1) Which factor influenced a candidate in getting placed?\n\n2) Does percentage matters for one to get placed?\n\n3) Which degree specialization is much demanded by corporate?\n\n4) Play with the data conducting all statistical tests."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/factors-affecting-campus-placement/Placement_Data_Full_Class.csv\")\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Explanation for the columns: \n\nsl_no: serial number\n\ngender: male or female\n\nssc_p : secondary education percentage at 10th grade\n\nssc_b : board of education*, at central or others \n\nhsc_p : higher secondary education percentage, at 12th grade\n\nhsc_b: board of education, at central or others \n\nhsc_s : specialization in higher secondary education \n\ndegree_p : degree percentage\n\ndegree_t : field of degree\n\nworkex : work experience\n\netest_p: employability test percentage (conducted by college) \n\nspecialisation : post graduation (MBA) specialization\n\nmba_p : MBA percentage\n\nstatus: placed or not placed \n\nsalary: salary offered by coporate\n\n*board of education are the different curriculum/education system adapted by educational institutes"},{"metadata":{},"cell_type":"markdown","source":"## EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## There are empty data under the salary column, though i suspect that they are those that did not get placed. "},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df[\"status\"].value_counts())\nprint(df[\"status\"].value_counts(normalize = True))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Yup, these are just people that did not get placed. We can just fill the nan spots with 0.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"salary\"].fillna(0,inplace = True)\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(2,3,figsize = (12,8))\naxes = ax.flatten()\nsns.set()\ndf_percent= df[[\"ssc_p\",\"hsc_p\",\"degree_p\",\"etest_p\",\"mba_p\",\"status\"]]\nplaced = df_percent[df_percent[\"status\"] == \"Placed\"]\nnot_placed = df_percent[df_percent[\"status\"] == \"Not Placed\"]\ndf_scores = df_percent.drop([\"status\"],axis = 1)\nname_percentage = df_scores.columns.tolist()\ni = 0 \nfor i in np.arange(len(name_percentage)):\n    feature = name_percentage[i]\n    sns.kdeplot(data= placed[feature], ax = axes[i], shade = True,color = \"r\",legend = False)\n    sns.kdeplot(data= not_placed[feature], ax= axes[i],shade = True,legend = False)\n    axes[i].set_title(feature)\n    axes[i].legend([\"placed\",\"not_placed\"],loc = \"upper right\")\n    \n\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## It seems that from the distribution of scores, the mean for mba_p is almost the same for both placed and not_placed, indicating that it might not be a good feature in predicting placed/not placed"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(2,3,figsize = (12,8))\naxes = ax.flatten()\ncat = [\"degree_t\", \"specialisation\",\"gender\",\"workex\",\"hsc_s\",\"hsc_b\"]\nplt.tight_layout(3.0)\ni = 0 \nfor i in np.arange(len(cat)):\n    feature = cat[i]\n    sns.violinplot(y = \"degree_p\", x = feature, hue = \"status\",data = df, split = True, ax = axes[i])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Across different categories, those who got placed almost always have a higher mean degree percentage than those that did not get placed. This suggests a relationship between high degree percentage scores and getting placed"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(2,3,figsize = (12,8))\naxes = ax.flatten()\ncat = [\"degree_t\", \"specialisation\",\"gender\",\"workex\",\"hsc_s\",\"hsc_b\"]\nplt.tight_layout(3.0)\ni = 0 \nfor i in np.arange(len(cat)):\n    feature = cat[i]\n    sns.violinplot(y = \"mba_p\", x = feature, hue = \"status\",data = df, split = True, ax = axes[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"However, comparing the distribution of the mba scores across different categories with other scores (Eg:degree percentage scores), we can see that the mean score for those who got placed is comparable to those who did not get placed.\n\nAn exception is those who has a art specialization in high school.\n\n- This is another indication that mba scores are not as predictive of placement. "},{"metadata":{},"cell_type":"markdown","source":"To visualize the e_test percentage of those who got placed/not placed across different categorical features.\nThe e_test percentage is an employability test percentage conducted by college. \n\nAccording to the information given, \n\n\"Employability test (e_test) will be conducted by college to test whether the candidate is fit to work in a corporate( we have aptitude test, Group discussion as such for measuring the scores for this test)\"\n\nLet us see if the e_test percentage is predictive of placed/not placed"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(3,3,figsize = (12,12))\naxes = ax.flatten()\n# getting all the categorical features in a list \ncat = [\"degree_t\", \"specialisation\",\"gender\",\"workex\",\"hsc_s\",\"hsc_b\",\"ssc_b\"]\nplt.tight_layout(3.0)\ni = 0 \ngender_split= df[[\"gender\",\"status\",\"workex\"]]\n# calculating the denominator \ndenom = gender_split.groupby([\"status\"]).count().gender\n\nfor i in np.arange(len(cat)):\n    feature = cat[i]\n    df_concat = pd.concat([df[[\"status\",\"etest_p\"]],df[feature]],axis =1 )\n    df_concat_group = df_concat.groupby([\"status\",feature]).count()\n    # getting the percentage score within each status group \n    # check denom to understand more \n    df_concat_group[\"etest_p\"]= df_concat_group[\"etest_p\"]/denom\n    a = df_concat_group.reset_index()\n    sns.barplot(hue = feature,x = \"status\", y = \"etest_p\",data= a, ax = axes[i])\n    axes[i].set_ylabel(\"E_test Percentage within status group\")\n    axes[i].legend(loc = \"upper right\")\n    axes[i].set_title(f'{feature}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Interestingly, it seems that those that were placed did not always have a higher e_test percentage. \nFor example, comparing across work experience, those that were placed had lower e_test percentage than those that were not placed.\n\nUnder specialization, those that were placed had a lower e_test percentage than those that were not placed.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_placed = df[df[\"status\"] == \"Placed\"]\ndf_placed[df_placed[\"salary\"] == df_placed[\"salary\"].max()]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"quali = [i for i in list(df.columns) if df[i].dtypes == \"object\"]\nquanti=  [i for i in list(df.columns) if df[i].dtypes != \"object\"]\nquali.remove(\"status\")\n# because salary is directly correlated with status, we will drop it. We only get salary info after we know about status, so it makes no sense\n# to use it to predict status. \nquanti.remove(\"salary\")\nquanti.remove(\"sl_no\")\nprint(\"Quali features: \", quali)\nprint(\"=\"*40)\nprint(\"Quanti features: \", quanti)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cmap = sns.diverging_palette(220,10,as_cmap = True)\nsns.heatmap(df[quanti].corr(),annot = True,cmap = cmap)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df= pd.concat([df[quanti],df[quali]], axis = 1)\nnew_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelBinarizer\nX = new_df\ny = df[\"status\"]\nlb=  LabelBinarizer()\ny_trans = lb.fit_transform(y)\ny_transform = np.ravel(y_trans)\n\nX_train,X_test,y_train,y_test = train_test_split(X,y_transform,random_state = 42,test_size = 0.2)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Build pipeline "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\n\nquali_pipe = Pipeline(steps = [(\"encoder\", OneHotEncoder(handle_unknown = \"ignore\"))])\nquanti_pipe = Pipeline(steps =[(\"scaler\",StandardScaler())])\ntransformer = ColumnTransformer([(\"quali_pipe\",quali_pipe,quali),\n                           (\"quanti_pipe\",quanti_pipe,quanti)])\n\npipe = Pipeline(steps = [(\"transformer\",transformer),(\"logreg\",LogisticRegression(penalty = \"l2\",\n                                                                                  C = 0.23,\n                                                                                  class_weight = \"balance\",\n                                                                                  max_iter = 200))])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nparam_grid = {\"logreg__C\":[0.2,0.21,0.22,0.23]}\n\nsearch = GridSearchCV(pipe,\n                      param_grid, \n                      cv = 5,\n                      scoring = \"recall\")\nbest_model = search.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_model.best_estimator_.get_params()[\"logreg\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\ny_train_predict = best_model.predict(X_train)\ny_test_predict = best_model.predict(X_test)\nprint(classification_report(y_train,y_train_predict))\nprint(classification_report(y_test,y_test_predict))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting the feature_names of one hot encoded qualitative variables\n\nenc= best_model.best_estimator_[\"transformer\"].transformers[0][1][\"encoder\"]\nenc.fit_transform(X_train[quali])\nquali_features_transformed= enc.get_feature_names(quali).tolist()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# combining the features name together with quanti feature names \nfeature_names_in_model= quanti.copy()\nfeature_names_in_model.extend(quali_features_transformed)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"coef= best_model.best_estimator_[\"logreg\"].coef_\ncoef_list = coef.flatten().tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a dataframe of feature importances \na = pd.DataFrame(dict(zip(feature_names_in_model,coef_list),index = [0]))\na","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sorting the dataframe in decending order \ndescending_list = a.iloc[0].sort_values(ascending = False).index.tolist()\na_ordered_df = a[descending_list]\nsns.barplot(y = a_ordered_df.columns, \n           x = a_ordered_df.iloc[0],\n            orient = \"h\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Recall this is a classification problem with classes 0 and 1. Notice that the coefficients are both positive and negative. The positive scores indicate a feature that predicts class 1, whereas the negative scores indicate a feature that predicts class 0. \n\nBecause we standardized our quantitative features in our pipeline, we can use the magnitude of the coefficient as a rough gauge of feature importance. \n\n- Degree and work experience are ranked high in predicting class 1, which is getting placed, while specialization seems to be ranked highly in predicting class 0, which is not placed\n\n\n\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}