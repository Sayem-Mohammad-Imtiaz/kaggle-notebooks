{"nbformat":4,"cells":[{"source":"**Classification of mushrooms using the ensemble stacking technique**","metadata":{},"cell_type":"markdown"},{"source":"**Data Exploration**","metadata":{"_uuid":"5f324c49bb54afde2d6f52275596531bc8e909bd","_cell_guid":"01c5cae2-1eef-41e0-942a-0cd557fe4884"},"cell_type":"markdown"},{"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"metadata":{"collapsed":true,"_uuid":"e81a0218b72409574f9321fb193be10b64c8e998","_cell_guid":"a54d6be9-7ecb-443a-a887-f45498356b8b"},"cell_type":"code"},{"outputs":[],"source":"# import the csv into a dataframe\ndataframe = pd.read_csv('../input/mushrooms.csv')\ndataframe.head(5)","execution_count":null,"metadata":{"collapsed":true,"_uuid":"3130f862bd9d670ec3f2dec37a4c98fe806a960e","_cell_guid":"22bebd74-00c2-445c-ba68-eeb6a022ebf1"},"cell_type":"code"},{"outputs":[],"source":"# Apply one hot encoding on all the predictor variables (not dependent variable)\ndataframe[dataframe.columns[1:23]].head(5)\nLabledmushrooms = pd.get_dummies(dataframe[dataframe.columns[1:23]])\nLabledmushrooms.head(5)","execution_count":null,"metadata":{"collapsed":true,"_uuid":"c016b40c5ebd5bfd87fa2fbd324e5caf9db8dd5c","_cell_guid":"7be73844-b2ce-4194-91b7-72056fd81a8d"},"cell_type":"code"},{"outputs":[],"source":"# Convert the classification labels into binary digits\nfrom sklearn.preprocessing import LabelEncoder\n\nLabledmushrooms['class'] = LabelEncoder().fit_transform(dataframe['class'])\nLabledmushrooms.head(5)","execution_count":null,"metadata":{"collapsed":true,"_uuid":"780afdca90f61dc5f9301e07740d1c53c35e8809","_cell_guid":"916a45fa-69c8-40da-acb4-7281c10e8d47"},"cell_type":"code"},{"outputs":[],"source":"# split the dataframe into test and train (60% - train 40% - test)\n\nfrom sklearn.model_selection import train_test_split\n\ntrain, test = train_test_split(Labledmushrooms, test_size=0.4)","execution_count":null,"metadata":{"collapsed":true,"_uuid":"b7af1c936fab9e3bb0b9614cbc77487a0b485e37","_cell_guid":"046c304d-8a13-413b-bfa3-f1ce89fbe848"},"cell_type":"code"},{"source":"**Correlation - let's check which of these features are strongly correlated with class of mushrooms**","metadata":{"_uuid":"52142624835f779442ce8691ae969ab52d85ded4","_cell_guid":"e7ecec54-21c1-4738-abe0-f7a222bf4f10"},"cell_type":"markdown"},{"outputs":[],"source":"# check which features are highly correlated with 'class'\n\ndf_num_corr = train.corr()['class'][:-1] # -1 because the last row is class\ngolden_features_list = df_num_corr[abs(df_num_corr) > 0.5].sort_values(ascending=False)\nprint(\"There are {} strongly correlated values with class:\\n{}\".format(len(golden_features_list), golden_features_list))","execution_count":null,"metadata":{"collapsed":true,"_uuid":"e9b4aff4eb8f16cd4f8621e5aebf2a51089e8dc6","_cell_guid":"49984457-0b35-4d01-80cb-cd274777988f"},"cell_type":"code"},{"source":"**Modelling**","metadata":{"_uuid":"df4a7a731acaf575ce4edd9129563cdb8641d9b7","_cell_guid":"929fc0b6-ca24-48f4-88c7-4145d0ac340f"},"cell_type":"markdown"},{"outputs":[],"source":"from sklearn.cross_validation import KFold;\n# Some useful parameters which will come in handy later on\nntrain = train.shape[0]\nntest = test.shape[0]\nSEED = 0 # for reproducibility\nNFOLDS = 5 # set folds for out-of-fold prediction\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\n\n# Class to extend the Sklearn classifier\nclass SklearnHelper(object):\n    def __init__(self, clf, seed=0, params=None):\n        params['random_state'] = seed\n        self.clf = clf(**params)\n\n    def train(self, x_train, y_train):\n        self.clf.fit(x_train, y_train)\n\n    def predict(self, x):\n        return self.clf.predict(x)\n    \n    def fit(self,x,y):\n        return self.clf.fit(x,y)\n    \n    def feature_importances(self,x,y):\n        print(self.clf.fit(x,y).feature_importances_)\n","execution_count":null,"metadata":{"collapsed":true,"_uuid":"53eb1dddae30fd2a02738ff63f29025bec47329b","_cell_guid":"1f18efcc-2835-4fb4-800b-981dfa896d41"},"cell_type":"code"},{"outputs":[],"source":"# Class to extend XGboost classifer\ndef get_oof(clf, x_train, y_train, x_test):\n    oof_train = np.zeros((ntrain,))\n    oof_test = np.zeros((ntest,))\n    oof_test_skf = np.empty((NFOLDS, ntest))\n\n    for i, (train_index, test_index) in enumerate(kf):\n        x_tr = x_train[train_index]\n        y_tr = y_train[train_index]\n        x_te = x_train[test_index]\n\n        clf.train(x_tr, y_tr)\n\n        oof_train[test_index] = clf.predict(x_te)\n        oof_test_skf[i, :] = clf.predict(x_test)\n\n    oof_test[:] = oof_test_skf.mean(axis=0)\n    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)","execution_count":null,"metadata":{"collapsed":true,"_uuid":"7f5b02a0bc4795ccba82c098d42c048e513e134c","_cell_guid":"b8ebfa25-54a1-4b02-82f5-75c50e2d79fa"},"cell_type":"code"},{"outputs":[],"source":"# Put in our parameters for said classifiers\n# Random Forest parameters\nrf_params = {\n    'n_jobs': -1,\n    'n_estimators': 500,\n     'warm_start': True, \n     #'max_features': 0.2,\n    'max_depth': 6,\n    'min_samples_leaf': 2,\n    'max_features' : 'sqrt',\n    'verbose': 0\n}\n\n# Extra Trees Parameters\net_params = {\n    'n_jobs': -1,\n    'n_estimators':500,\n    #'max_features': 0.5,\n    'max_depth': 8,\n    'min_samples_leaf': 2,\n    'verbose': 0\n}\n\n# AdaBoost parameters\nada_params = {\n    'n_estimators': 500,\n    'learning_rate' : 0.75\n}\n\n# Gradient Boosting parameters\ngb_params = {\n    'n_estimators': 500,\n     #'max_features': 0.2,\n    'max_depth': 5,\n    'min_samples_leaf': 2,\n    'verbose': 0\n}\n\n# Support Vector Classifier parameters \nsvc_params = {\n    'kernel' : 'linear',\n    'C' : 0.025\n    }","execution_count":null,"metadata":{"collapsed":true,"_uuid":"6deec6a0a53772b26d5813907c801ebd0991bd46","_cell_guid":"cb3aa9dc-7cd0-4dd5-bb3c-29cbbe6002a6"},"cell_type":"code"},{"outputs":[],"source":"import re\nimport sklearn\nimport xgboost as xgb\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Going to use these 5 base models for the stacking\nfrom sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n                              GradientBoostingClassifier, ExtraTreesClassifier)\nfrom sklearn.svm import SVC","execution_count":null,"metadata":{"collapsed":true,"_uuid":"43dcc5df0f6f3df6600ca99ffb05326899a6bad8","_cell_guid":"7cde9c78-01aa-40fd-83df-f166e824830c"},"cell_type":"code"},{"outputs":[],"source":"rf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=svc_params)","execution_count":null,"metadata":{"collapsed":true,"_uuid":"5e08e0c4c2941a478201a4087327e5f1418327f7","_cell_guid":"a46c6d09-4a35-4da3-8912-682c77a610c1"},"cell_type":"code"},{"outputs":[],"source":"# Create Numpy arrays of train, test and target dataframes to feed into our models\ny_train = train['class'].ravel()\ntrain = train.drop(['class'], axis=1)\nx_train = train.values # Creates an array of the train data\nx_test = test.drop(['class'], axis=1).values # Creats an array of the test data","execution_count":null,"metadata":{"collapsed":true,"_uuid":"5101a0693e342e6cf943374aab1b2ac57543a99c","_cell_guid":"cc2021ba-897c-463f-a37a-270477d288ca"},"cell_type":"code"},{"outputs":[],"source":"# Create our OOF train and test predictions. These base results will be used as new features\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) # Gradient Boost\nsvc_oof_train, svc_oof_test = get_oof(svc,x_train, y_train, x_test) # Support Vector Classifier\n\nprint(\"Training is complete\")","execution_count":null,"metadata":{"collapsed":true,"_uuid":"90e694eccd42accf6ae77187265f7b2402ae9c21","_cell_guid":"b33814ed-6e1b-4aea-b713-ebb296534bce"},"cell_type":"code"},{"outputs":[],"source":"rf_feature = rf.feature_importances(x_train,y_train)\net_feature = et.feature_importances(x_train, y_train)\nada_feature = ada.feature_importances(x_train, y_train)\ngb_feature = gb.feature_importances(x_train,y_train)","execution_count":null,"metadata":{"collapsed":true,"_uuid":"5d452dc2fb3b625349767aae4a359ddba12827f6","_cell_guid":"8475fc91-a16b-443b-be7c-1b64becefc0b"},"cell_type":"code"},{"outputs":[],"source":"# simply copied these values from the previous result into arrays\n\nrf_features = [ 1.09933352e-03, 0.00000000e+00, 3.31604164e-04, 1.25604826e-04\n, 3.84436946e-04, 5.85765610e-04, 4.96563934e-03, 6.15687151e-05\n, 3.83359703e-03, 1.03188819e-03, 1.31974204e-03, 2.55374992e-04\n, 6.94622587e-04, 7.18087103e-04, 1.19924501e-03, 1.03416153e-03\n, 1.42208440e-04, 1.61936024e-04, 2.26738317e-03, 2.63980344e-03\n, 2.62849341e-02, 2.54988109e-02, 4.26665512e-03, 8.38218479e-03\n, 7.81849276e-02, 5.05969243e-03, 6.72418638e-04, 1.26698724e-01\n, 1.13648255e-02, 3.96953051e-03, 6.64036098e-03, 1.01236515e-03\n, 5.77700436e-04, 1.91641180e-02, 1.83704757e-02, 6.98676012e-02\n, 6.40741143e-02, 4.79758134e-02, 3.14467864e-04, 5.64966280e-04\n, 9.91736391e-04, 1.53130207e-04, 1.02566947e-03, 1.68234149e-04\n, 1.66311393e-04, 5.46101822e-04, 7.93828378e-04, 1.52942168e-03\n, 7.89890008e-05, 8.51535373e-03, 9.54730355e-03, 9.75651680e-03\n, 1.43539101e-02, 6.12520557e-03, 1.09756231e-02, 1.51545284e-03\n, 3.85428506e-03, 5.39394393e-02, 2.34922494e-02, 1.66239503e-04\n, 4.86265250e-03, 3.92016229e-02, 1.34092441e-02, 2.52800344e-03\n, 1.37016511e-03, 6.08798442e-04, 2.09458230e-04, 1.37640237e-03\n, 1.03338895e-03, 8.84882581e-04, 1.02425977e-03, 6.32664915e-03\n, 1.78083543e-04, 1.52618803e-03, 5.44017592e-04, 1.81727915e-04\n, 1.42783390e-03, 1.00475704e-03, 1.19912910e-03, 1.19165987e-03\n, 5.01796315e-03, 6.13223401e-04, 0.00000000e+00, 3.81358979e-04\n, 7.59864000e-05, 6.35769040e-04, 1.09889791e-04, 6.97684555e-04\n, 4.73405978e-03, 6.68991835e-03, 7.58643949e-03, 6.03251183e-04\n, 2.04044709e-02, 6.00950973e-04, 3.75201096e-02, 6.78084129e-05\n, 4.85935645e-02, 1.08687474e-02, 9.43236950e-03, 5.76559360e-05\n, 5.74750743e-03, 8.66434826e-04, 1.25750033e-02, 7.46856542e-05\n, 7.65403378e-04, 1.00052881e-03, 2.94397492e-03, 5.14232177e-03\n, 1.77456026e-02, 3.52087039e-03, 4.78182954e-03, 5.84478834e-03\n, 8.26626082e-04, 2.10138323e-03, 3.97095313e-03, 6.72934184e-03\n, 1.09090762e-03]\net_features = [ 1.88703460e-03, 0.00000000e+00, 4.31585124e-04, 4.73182972e-04\n, 3.92765398e-04, 6.13083998e-04, 4.28778412e-03, 9.88414829e-05\n, 4.26284687e-03, 1.83935199e-03, 1.19673300e-03, 3.73001924e-04\n, 6.33520218e-04, 1.33975768e-03, 9.37675125e-04, 1.16082203e-03\n, 1.03928661e-04, 1.68635461e-04, 2.99017100e-03, 3.87697817e-03\n, 2.95108606e-02, 3.04136756e-02, 5.32162431e-03, 9.25042383e-03\n, 8.03515201e-02, 5.48359938e-03, 9.10315345e-04, 1.34070374e-01\n, 1.40089574e-02, 3.91140227e-03, 3.76257570e-03, 8.37739272e-04\n, 5.41948148e-04, 1.52514343e-02, 1.95611466e-02, 6.10942175e-02\n, 5.65501187e-02, 3.88718039e-02, 3.33591450e-04, 4.18850413e-04\n, 8.90619363e-04, 1.58992629e-04, 1.89350978e-03, 4.51715241e-05\n, 1.54153629e-04, 8.42735773e-04, 4.69539738e-04, 1.75509160e-03\n, 1.48491081e-04, 1.21229590e-02, 1.18750841e-02, 9.81544616e-03\n, 1.45702111e-02, 6.10788362e-03, 1.24407466e-02, 1.44588195e-03\n, 3.16254057e-03, 4.28487696e-02, 2.05583705e-02, 3.24089302e-04\n, 4.79289529e-03, 3.66126661e-02, 1.06137255e-02, 3.13491734e-03\n, 9.51405752e-04, 9.53167951e-04, 3.12308238e-05, 1.09342660e-03\n, 1.22142293e-03, 1.83581057e-03, 1.18761003e-03, 5.13867576e-03\n, 2.10528116e-04, 2.64282997e-03, 1.11620301e-03, 5.11776457e-06\n, 1.12419974e-03, 2.49029997e-03, 9.01295155e-04, 1.61212185e-03\n, 7.32676075e-03, 9.75825258e-04, 0.00000000e+00, 2.49237247e-04\n, 1.76010336e-04, 1.25850676e-03, 2.87055660e-04, 6.14717492e-04\n, 5.05107522e-03, 5.53740164e-03, 7.13153963e-03, 9.81913488e-04\n, 1.62319669e-02, 7.41505912e-04, 3.73063568e-02, 0.00000000e+00\n, 4.56401409e-02, 1.07350774e-02, 8.96201707e-03, 3.16362129e-05\n, 5.91316149e-03, 1.27347115e-03, 1.56709352e-02, 3.40078372e-06\n, 1.19733297e-03, 1.08854281e-03, 2.64565608e-03, 4.28184505e-03\n, 2.17512228e-02, 3.38783548e-03, 8.47367727e-03, 8.30029339e-03\n, 1.06849795e-03, 2.74104547e-03, 4.00403308e-03, 1.07437645e-02\n, 1.39282369e-03]\nada_features = [0.002,  0.0,     0.0,     0.0,     0.0,     0.0,     0.002,  0.0,     0.002,  0.002,  0.0,\n  0.002,  0.0,     0.0,     0.006,  0.0,     0.0,     0.0,     0.016,  0.0,     0.064,\n  0.056,  0.01,   0.024,  0.026,  0.01,   0.0,     0.024,  0.016,  0.0,     0.0,     0.0,\n  0.0,     0.024,  0.008,  0.042,  0.042,  0.022,  0.0,     0.0,     0.0,     0.0,     0.0,\n  0.0,     0.0,     0.0,     0.0,     0.002,  0.0,     0.006,  0.004,  0.002,  0.006,  0.0,\n  0.0,     0.002,  0.006,  0.096,  0.018,  0.0,     0.004,  0.0,     0.014,  0.104,  0.0,\n  0.0,     0.0,     0.0,     0.0,     0.0,     0.0,     0.004,  0.0,     0.0,     0.0,     0.0,\n  0.0,     0.016,  0.002,  0.0,     0.006,  0.0,     0.0,     0.0,     0.0,     0.0,     0.0,\n  0.0,     0.002,  0.028,  0.002,  0.002,  0.0,     0.0,     0.018,  0.0,     0.0,     0.004,\n  0.006,  0.0,     0.034,  0.002,  0.046,  0.0,     0.0,     0.134,  0.0,     0.0,     0.006,\n  0.002,  0.014,  0.0,     0.0,     0.0,     0.0,     0.0,     0.008,]\ngb_features = [ 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00\n, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.28091635e-04\n, 0.00000000e+00, 3.33626202e-04, 0.00000000e+00, 0.00000000e+00\n, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00\n, 0.00000000e+00, 0.00000000e+00, 1.48842261e-03, 0.00000000e+00\n, 1.49765891e-03, 3.14086275e-03, 2.39605782e-03, 0.00000000e+00\n, 1.41862357e-03, 2.62634061e-03, 7.00943804e-05, 9.51542919e-02\n, 9.50364670e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00\n, 0.00000000e+00, 1.50038698e-03, 4.35033617e-04, 1.53458912e-03\n, 1.92855525e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00\n, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00\n, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00\n, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.54267174e-03\n, 6.69786227e-04, 2.09815378e-02, 4.75223795e-04, 4.92955745e-03\n, 0.00000000e+00, 7.28823904e-05, 1.07702935e-04, 2.24355593e-04\n, 0.00000000e+00, 0.00000000e+00, 7.32165126e-05, 7.01669444e-03\n, 0.00000000e+00, 7.00675774e-05, 0.00000000e+00, 0.00000000e+00\n, 5.11722172e-05, 0.00000000e+00, 0.00000000e+00, 1.39902130e-04\n, 0.00000000e+00, 0.00000000e+00, 1.07821302e-04, 0.00000000e+00\n, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00\n, 2.53114380e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00\n, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.87603256e-04\n, 2.27648462e-04, 7.21009716e-05, 1.58350366e-04, 0.00000000e+00\n, 0.00000000e+00, 1.08798568e-04, 1.19355102e-04, 0.00000000e+00\n, 7.11436910e-04, 0.00000000e+00, 1.25399658e-05, 0.00000000e+00\n, 4.19736455e-03, 1.01651638e-04, 2.48571766e-04, 0.00000000e+00\n, 0.00000000e+00, 1.29542836e-03, 0.00000000e+00, 0.00000000e+00\n, 0.00000000e+00, 5.16168159e-05, 6.99296103e-05, 0.00000000e+00\n, 2.58644603e-06, 0.00000000e+00, 0.00000000e+00, 5.16310735e-04\n, 0.00000000e+00]","execution_count":null,"metadata":{"collapsed":true,"_uuid":"d475ae4c7cb7d90020ae1cc61fd99a8e57486af0","_cell_guid":"c0e1fd06-d54b-411d-88eb-116289cada42"},"cell_type":"code"},{"outputs":[],"source":"cols = train.columns.values\n# Create a dataframe with features\nfeature_dataframe = pd.DataFrame( {'features': cols,\n     'Random Forest feature importances': rf_features,\n     'Extra Trees  feature importances': et_features,\n      'AdaBoost feature importances': ada_features,\n    'Gradient Boost feature importances': gb_features\n    })","execution_count":null,"metadata":{"collapsed":true,"_uuid":"a7b11890ff8f8486caee68c67e3c602e4018e0ad","_cell_guid":"cace8658-d2da-41e8-9aae-0eab86bff51a"},"cell_type":"code"},{"outputs":[],"source":"# Scatter plot \ntrace = go.Scatter(\n    y = feature_dataframe['Random Forest feature importances'].values,\n    x = feature_dataframe['features'].values,\n    mode='markers',\n    marker=dict(\n        sizemode = 'diameter',\n        sizeref = 1,\n        size = 25,\n#       size= feature_dataframe['AdaBoost feature importances'].values,\n        #color = np.random.randn(500), #set color equal to a variable\n        color = feature_dataframe['Random Forest feature importances'].values,\n        colorscale='Portland',\n        showscale=True\n    ),\n    text = feature_dataframe['features'].values\n)\ndata = [trace]\n\nlayout= go.Layout(\n    autosize= True,\n    title= 'Random Forest Feature Importance',\n    hovermode= 'closest',\n#     xaxis= dict(\n#         title= 'Pop',\n#         ticklen= 5,\n#         zeroline= False,\n#         gridwidth= 2,\n#     ),\n    yaxis=dict(\n        title= 'Feature Importance',\n        ticklen= 5,\n        gridwidth= 2\n    ),\n    showlegend= False\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig,filename='scatter2010')\n\n# Scatter plot \ntrace = go.Scatter(\n    y = feature_dataframe['Extra Trees  feature importances'].values,\n    x = feature_dataframe['features'].values,\n    mode='markers',\n    marker=dict(\n        sizemode = 'diameter',\n        sizeref = 1,\n        size = 25,\n#       size= feature_dataframe['AdaBoost feature importances'].values,\n        #color = np.random.randn(500), #set color equal to a variable\n        color = feature_dataframe['Extra Trees  feature importances'].values,\n        colorscale='Portland',\n        showscale=True\n    ),\n    text = feature_dataframe['features'].values\n)\ndata = [trace]\n\nlayout= go.Layout(\n    autosize= True,\n    title= 'Extra Trees Feature Importance',\n    hovermode= 'closest',\n#     xaxis= dict(\n#         title= 'Pop',\n#         ticklen= 5,\n#         zeroline= False,\n#         gridwidth= 2,\n#     ),\n    yaxis=dict(\n        title= 'Feature Importance',\n        ticklen= 5,\n        gridwidth= 2\n    ),\n    showlegend= False\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig,filename='scatter2010')\n\n# Scatter plot \ntrace = go.Scatter(\n    y = feature_dataframe['AdaBoost feature importances'].values,\n    x = feature_dataframe['features'].values,\n    mode='markers',\n    marker=dict(\n        sizemode = 'diameter',\n        sizeref = 1,\n        size = 25,\n#       size= feature_dataframe['AdaBoost feature importances'].values,\n        #color = np.random.randn(500), #set color equal to a variable\n        color = feature_dataframe['AdaBoost feature importances'].values,\n        colorscale='Portland',\n        showscale=True\n    ),\n    text = feature_dataframe['features'].values\n)\ndata = [trace]\n\nlayout= go.Layout(\n    autosize= True,\n    title= 'AdaBoost Feature Importance',\n    hovermode= 'closest',\n#     xaxis= dict(\n#         title= 'Pop',\n#         ticklen= 5,\n#         zeroline= False,\n#         gridwidth= 2,\n#     ),\n    yaxis=dict(\n        title= 'Feature Importance',\n        ticklen= 5,\n        gridwidth= 2\n    ),\n    showlegend= False\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig,filename='scatter2010')\n\n# Scatter plot \ntrace = go.Scatter(\n    y = feature_dataframe['Gradient Boost feature importances'].values,\n    x = feature_dataframe['features'].values,\n    mode='markers',\n    marker=dict(\n        sizemode = 'diameter',\n        sizeref = 1,\n        size = 25,\n#       size= feature_dataframe['AdaBoost feature importances'].values,\n        #color = np.random.randn(500), #set color equal to a variable\n        color = feature_dataframe['Gradient Boost feature importances'].values,\n        colorscale='Portland',\n        showscale=True\n    ),\n    text = feature_dataframe['features'].values\n)\ndata = [trace]\n\nlayout= go.Layout(\n    autosize= True,\n    title= 'Gradient Boosting Feature Importance',\n    hovermode= 'closest',\n#     xaxis= dict(\n#         title= 'Pop',\n#         ticklen= 5,\n#         zeroline= False,\n#         gridwidth= 2,\n#     ),\n    yaxis=dict(\n        title= 'Feature Importance',\n        ticklen= 5,\n        gridwidth= 2\n    ),\n    showlegend= False\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig,filename='scatter2010')","execution_count":null,"metadata":{"collapsed":true,"_uuid":"c60e08bc2b1ab4f4ea9ca6535c114eb2166d2d00","_cell_guid":"fc73664e-0962-4d97-bce7-0d2b704152a4"},"cell_type":"code"},{"outputs":[],"source":"# Create the new column containing the average of values\n\nfeature_dataframe['mean'] = feature_dataframe.mean(axis= 1) # axis = 1 computes the mean row-wise\nfeature_dataframe.head(3)","execution_count":null,"metadata":{"collapsed":true,"_uuid":"56ad530f40a6e8197e821303160523369fd84beb","_cell_guid":"6a388b78-cb27-400d-8f9d-5994975c8515"},"cell_type":"code"},{"outputs":[],"source":"y = feature_dataframe['mean'].values\nx = feature_dataframe['features'].values\ndata = [go.Bar(\n            x= x,\n             y= y,\n            width = 0.5,\n            marker=dict(\n               color = feature_dataframe['mean'].values,\n            colorscale='Portland',\n            showscale=True,\n            reversescale = False\n            ),\n            opacity=0.6\n        )]\n\nlayout= go.Layout(\n    autosize= True,\n    title= 'Barplots of Mean Feature Importance',\n    hovermode= 'closest',\n#     xaxis= dict(\n#         title= 'Pop',\n#         ticklen= 5,\n#         zeroline= False,\n#         gridwidth= 2,\n#     ),\n    yaxis=dict(\n        title= 'Feature Importance',\n        ticklen= 5,\n        gridwidth= 2\n    ),\n    showlegend= False\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig, filename='bar-direct-labels')","execution_count":null,"metadata":{"collapsed":true,"_uuid":"7faf7fe0fbe85611753d6539901bc8f9fa906de1","_cell_guid":"aa86ddc8-cb33-4d64-9bf2-e3b61728e488"},"cell_type":"code"},{"outputs":[],"source":"base_predictions_train = pd.DataFrame( {'RandomForest': rf_oof_train.ravel(),\n     'ExtraTrees': et_oof_train.ravel(),\n     'AdaBoost': ada_oof_train.ravel(),\n      'GradientBoost': gb_oof_train.ravel()\n    })\nbase_predictions_train.head()","execution_count":null,"metadata":{"collapsed":true,"_uuid":"6ea05d73f798c1ea37c45bb6b3203da84e109121","_cell_guid":"5eda7ff0-26de-4ec4-8399-4f7b88f833fa"},"cell_type":"code"},{"outputs":[],"source":"data = [\n    go.Heatmap(\n        z= base_predictions_train.astype(float).corr().values ,\n        x=base_predictions_train.columns.values,\n        y= base_predictions_train.columns.values,\n          colorscale='Viridis',\n            showscale=True,\n            reversescale = True\n    )\n]\npy.iplot(data, filename='labelled-heatmap')","execution_count":null,"metadata":{"collapsed":true,"_uuid":"790db9380438aa1b5bec0e78d9d697a0371232e3","_cell_guid":"1596d5bc-bbf4-4923-b56d-d9589df256c9"},"cell_type":"code"},{"outputs":[],"source":"x_train = np.concatenate(( et_oof_train, rf_oof_train, ada_oof_train, gb_oof_train, svc_oof_train), axis=1)\nx_test = np.concatenate(( et_oof_test, rf_oof_test, ada_oof_test, gb_oof_test, svc_oof_test), axis=1)","execution_count":null,"metadata":{"collapsed":true,"_uuid":"80a5b69eeb6102e59dc61defd801c53214eae8aa","_cell_guid":"86f4ac1f-94c2-422e-9148-19791179f1da"},"cell_type":"code"},{"outputs":[],"source":"gbm = xgb.XGBClassifier(\n    #learning_rate = 0.02,\n n_estimators= 2000,\n max_depth= 4,\n min_child_weight= 2,\n #gamma=1,\n gamma=0.9,                        \n subsample=0.8,\n colsample_bytree=0.8,\n objective= 'binary:logistic',\n nthread= -1,\n scale_pos_weight=1).fit(x_train, y_train)\npredictions = gbm.predict(x_test)","execution_count":null,"metadata":{"collapsed":true,"_uuid":"f3d026553235fe38cd12c8747a071a50260852ce","_cell_guid":"148ec945-2ebf-4608-8ed2-31bbce07bbca"},"cell_type":"code"},{"outputs":[],"source":"test['predicted'] = predictions\ntest.head(50)","execution_count":null,"metadata":{"collapsed":true,"_uuid":"d7b0b85d471061ca37dc23cf2e04087a09344a4d","_cell_guid":"2ebde7d5-818f-41bf-a79a-3efb0bf83404"},"cell_type":"code"},{"outputs":[],"source":"from sklearn.metrics import precision_recall_fscore_support\nprecision_recall_fscore_support(test['class'], test['predicted'],average='macro')","execution_count":null,"metadata":{"collapsed":true,"_uuid":"7a013c176cfa5cd15e4076fa831b4a1045543724","_cell_guid":"2a3fcbf3-9234-4284-91d8-7d1597571492"},"cell_type":"code"},{"outputs":[],"source":"n_folds = 5\nearly_stopping = 10\nparams = {'eta': 0.02, 'max_depth': 5, 'subsample': 0.7, 'colsample_bytree': 0.7, 'objective': 'binary:logistic', 'seed': 99, 'silent': 1, 'eval_metric':'auc', 'nthread':4}\n\nxg_train = xgb.DMatrix(x_train, label=y_train);\n\ncv = xgb.cv(params, xg_train, 5000, nfold=n_folds, early_stopping_rounds=early_stopping, verbose_eval=1)","execution_count":null,"metadata":{"collapsed":true,"_uuid":"b2df02591470391aae3779e89332f710bc0ce492","_cell_guid":"9364b90f-3a32-4879-8880-00883c54a0ad"},"cell_type":"code"}],"nbformat_minor":1,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","version":"3.6.4","mimetype":"text/x-python","file_extension":".py","pygments_lexer":"ipython3","nbconvert_exporter":"python"}}}