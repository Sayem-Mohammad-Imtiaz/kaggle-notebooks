{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Used cars price prediction with different models","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* В этой работе на примере датасета **Used Cars Dataset** попробуем решить задачу регрессии (предсказания цены на подержанные автомобили) с помощью простой линейной модели, решающих деревьев и градиентного бустинга.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# импортируем необходимые для начала библиотеки\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Загрузка и предобработка данных","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# загрузим данные из .csv файла в таблицу\ndata = pd.read_csv('../input/craigslist-carstrucks-data/vehicles.csv')\ndf = data.copy()\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# посмотрм на расперделение числовых данных в таблице\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# посмотрим основную информацию о таблице\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# визуально посмотрим на распределение незаполненных значений по признакам\nfig, ax = plt.subplots(figsize=(14,10))\nsns.heatmap(df.isnull(), cbar=False, cmap=\"Greys_r\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# посмотрим на количество строк в таблице\nlen(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# удалим признаки с наибольшим количеством незаполненных данных, \n# а также не влияющие на итоговую классификацию\ndf.drop(columns=['id', 'url', 'region', 'region_url', \n                 'vin', 'size', 'image_url', \n                 'description', 'county', \n                 'state', 'lat', 'long'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.impute import SimpleImputer\n\n# заменим пропуски в столбце 'odometer' средним значением по столбцу\nimr = SimpleImputer(strategy='mean')\nimr = imr.fit(df[['odometer']])\nimputed_data = imr.transform(df[['odometer']])\ndf['odometer'] = pd.DataFrame(imputed_data)\ndf['odometer'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# удалим строки с пропусками в данных\ndf.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ещё раз визуально проверим распределение незаполненных значений по признакам\nfig, ax = plt.subplots(figsize=(14,10))\nsns.heatmap(df.isnull(), cbar=False, cmap=\"Greys_r\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# посмотрим на значения в целевой переменной\ndf['price'].value_counts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# удалим из таблицы объекты с экстремальными значениями по целевой переменной\ndf = df[df['price'] > 1000]\ndf = df[df['price'] < 50000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# посмотрим на количество оставшихся строк после обработки\nlen(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# посмотрим на получившуюся в итоге таблицу с данными\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\n\n# создадим функцию, кодирующую числовыми значениями категориальные признаки\ndef encode_features(dataframe):\n    result = dataframe.copy()\n    encoders = {}\n    for column in result.columns:\n        if result.dtypes[column] == np.object:\n            encoders[column] = preprocessing.LabelEncoder()\n            result[column] = encoders[column].fit_transform(result[column])\n    return result, encoders\n\n# обработаем все столбцы кроме 'description'\nencoded_df, encoders = encode_features(df) \nencoded_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# построим гистограммы различных признаков для оценки корректности данных\nencoded_df.hist(figsize=(18, 8), layout=(3,5), bins=20)\nprint('Features\\' hists plotted')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# построим на матрице корреляций зависимость между признаками, а также между признаками и целевой переменной\nplt.subplots(figsize=(17, 15))\nsns.heatmap(encoded_df.corr(), square = True, annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# отделим целевую переменную от признаков\ny = np.array(encoded_df['price'])\ndel encoded_df['price']\nX = encoded_df.values\nX.shape, y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# разобьём данные на обучающие и испытательные наборы\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\n# стандартизируем значения признаков\nstdsc = StandardScaler()\nX_train = stdsc.fit_transform(X_train)\nX_test = stdsc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Обучение моделей","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Linear regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfrom sklearn.metrics import r2_score, mean_absolute_error\nfrom sklearn.linear_model import LinearRegression\n\nlinreg = LinearRegression()\nlinreg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# делаем предсказания и выводим метрики\npreds = linreg.predict(X_test)\nprint('R2 linreg: ', r2_score(y_test, preds))\nprint('MAE linreg: ', mean_absolute_error(y_test, preds))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Stochastic gradient descent","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfrom sklearn.linear_model import SGDRegressor\n\nsgd = SGDRegressor()\nsgd.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# делаем предсказания и выводим метрики\npreds = sgd.predict(X_test)\nprint('R2 sgd: ', r2_score(y_test, preds))\nprint('MAE sgd: ', mean_absolute_error(y_test, preds))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Decision tree","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfrom sklearn.tree import DecisionTreeRegressor\n\ntree = DecisionTreeRegressor()\ntree.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# делаем предсказания и выводим метрики\npreds = tree.predict(X_test)\nprint('R2 tree: ', r2_score(y_test, preds))\nprint('MAE tree: ', mean_absolute_error(y_test, preds))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Gradient boosting regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfrom sklearn.ensemble import GradientBoostingRegressor\n\ngbreg = GradientBoostingRegressor()\ngbreg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# делаем предсказания и выводим метрики\npreds = gbreg.predict(X_test)\nprint('R2 gbreg: ', r2_score(y_test, preds))\nprint('MAE gbreg: ', mean_absolute_error(y_test, preds))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Extreme gradient boosting","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# зарузим tensorboard для визуализации поцессов обучения\n!jupyter nbextension enable --py widgetsnbextension\n%load_ext tensorboard","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%tensorboard --logdir logs\n\nfrom sklearn.model_selection import GridSearchCV\nimport xgboost as xgb\n\n# переберём параметры XGBRegressor с помощью GridSearchCV\n# визуализируем процесс обучения с помощью tensorboard\nalg = xgb.XGBRegressor() \ngrid = {'n_estimators': [60, 100, 120, 140], \n        'learning_rate': [0.01, 0.1],\n        'max_depth': [5, 7],\n        'reg_lambda': [0.5]}\ngs = GridSearchCV(estimator=alg, param_grid=grid, cv=5, n_jobs=-1)\n%time gs.fit(X_train, y_train)\nprint('Best score: ', gs.best_score_)\nprint('Best parameters: ', gs.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# инициализируем алгоритм с лучшими параметрами и обучаем модель\nxgbreg = gs.best_estimator_\nxgbreg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# делаем предсказания и выводим метрики\npreds = xgbreg.predict(X_test)\nprint('R2 xgbreg: ', r2_score(y_test, preds))\nprint('MAE xgbreg: ', mean_absolute_error(y_test, preds))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random forest","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfrom sklearn.ensemble import RandomForestRegressor \n\nrnfst = RandomForestRegressor()\nrnfst.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# делаем предсказания и выводим метрики\npreds = rnfst.predict(X_test)\nprint('R2 rnfst: ', r2_score(y_test, preds))\nprint('MAE rnfst: ', mean_absolute_error(y_test, preds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# посмотрим на гистограмме на распределение абсолютной ошибки\nplt.hist(y_test - preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# наложим друг на друга гистограммы результатов предсказаний и истинных значений\nplt.hist(y_test)\nplt.hist(preds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Наилучшие результаты с R2=0.88 получились в результате применения модели случайных лесов, но она также и одна из самых затратных по времени.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Сохранение модели","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\n\n# сохраняем модель случайных лесов\nfile = open('RandomForest_model.pickle','wb')\npickle.dump(rnfst, file)\nfile.close()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}