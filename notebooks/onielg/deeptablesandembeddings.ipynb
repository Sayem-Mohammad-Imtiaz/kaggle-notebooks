{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Predicting Used Cars Price with Deep Tables and Embeddings"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.style.use('seaborn-whitegrid')\n\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom sklearn.model_selection import KFold, train_test_split\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import Normalizer\nfrom keras.models import Sequential\nfrom keras.models import Model as KerasModel\nfrom keras.layers import Input, Dense, Activation, Reshape,  Conv1D, MaxPooling1D, Flatten\n#Merge,\nfrom keras.layers import Concatenate\nfrom keras.layers.embeddings import Embedding\nfrom keras.callbacks import ModelCheckpoint\n\nimport pickle\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom lightgbm import LGBMRegressor\n\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\n\nimport warnings\nwarnings.simplefilter('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow._api.v2.compat.v1 as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/craigslist-carstrucks-data/vehicles.csv')\ndf.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"df= df.drop(columns=['id','url', 'region_url',  'image_url', 'description',\n                     'lat', 'long','region','posting_date','Unnamed: 0','paint_color'], axis=1)\n\n'vin','county',","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TARGET_COLS = ['price']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerics = ['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']\ncategorical_columns = []\nfeatures = df.columns.values.tolist()\nfor col in features:\n    if df[col].dtype in numerics: continue\n    categorical_columns.append(col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for cat_var in categorical_columns:\n    print (cat_var, df[cat_var].nunique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[df[\"odometer\"]>=3000000.0].shape\ndf.drop(df[df[\"odometer\"]>=3000000.0].index,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"excellent_odo_mean = df[df['condition'] == 'excellent']['odometer'].mean()\ngood_odo_mean = df[df['condition'] == 'good']['odometer'].mean()\nlike_new_odo_mean = df[df['condition'] == 'like new']['odometer'].mean()\nsalvage_odo_mean = df[df['condition'] == 'salvage']['odometer'].mean()\nfair_odo_mean = df[df['condition'] == 'fair']['odometer'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[df.year>=2019, 'condition'] = df.loc[df.year>=2019, 'condition'].fillna('new')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[df['odometer'] <= like_new_odo_mean, 'condition'] = df.loc[df['odometer'] <= like_new_odo_mean, 'condition'].fillna('like new')\n\ndf.loc[df['odometer'] >= fair_odo_mean, 'condition'] = df.loc[df['odometer'] >= fair_odo_mean, 'condition'].fillna('fair')\n\ndf.loc[((df['odometer'] > good_odo_mean) & \n       (df['odometer'] <= excellent_odo_mean)), 'condition'] = df.loc[((df['odometer'] > good_odo_mean) & \n       (df['odometer'] <= excellent_odo_mean)), 'condition'].fillna('excellent')\n\ndf.loc[((df['odometer'] > like_new_odo_mean) & \n       (df['odometer'] <= good_odo_mean)), 'condition'] = df.loc[((df['odometer'] > like_new_odo_mean) & \n       (df['odometer'] <= good_odo_mean)), 'condition'].fillna('good')\n\ndf.loc[((df['odometer'] > good_odo_mean) & \n       (df['odometer'] <= fair_odo_mean)), 'condition'] = df.loc[((df['odometer'] > good_odo_mean) & \n       (df['odometer'] <= fair_odo_mean)), 'condition'].fillna('salvage')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Odometer - fill with mean\ndf['odometer'] = df.groupby(['year'], sort=False)['odometer'].apply(lambda x: x.fillna(x.mean()))\ndf['odometer'] = df['odometer'].fillna(method=\"ffill\")\ndf['odometer'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df['paint_color'] = df['paint_color'].fillna(method='ffill')\ndf['drive'] = df['drive'].fillna(method='ffill')\ndf['type'] = df['type'].fillna(method='ffill')\ndf['cylinders'] = df['cylinders'].fillna(method='ffill')\ndf['condition'] = df.groupby(['year'], sort=False)['condition'].apply(lambda x: x.fillna(x.mode()))\ndf['type'] = df.groupby(['year'], sort=False)['type'].apply(lambda x: x.fillna(x.mode()))\ndf['condition'] = df['condition'].fillna(method='ffill')\ndf['type'] = df['type'].fillna(method='ffill')\n\n#data['paint_color'].fillna(data['paint_color'].mode()[0], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(df[df[\"year\"].isna()].index,inplace=True)\ndf['year'] = (df['year']-1900).astype(int)\ndf['odometer'] = df['odometer'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Price\nrr=sorted(df[\"price\"])\nquantile1, quantile3= np.percentile(rr,[10,90])\n#print(quantile1,quantile3)\n\ndf=df[(df.price < 31500) & (df.price >= 390 )]\n#df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df.drop([\"size\"],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['year'] = df['year'].astype(float)\ndf['odometer'] = df['odometer'].astype(float)\ndf['price'] = df['price'].astype(float)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import pandas_profiling as pp\n#pp.ProfileReport(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(df[df[\"manufacturer\"].isna()].index,inplace=True)\ndf.drop(df[df[\"model\"].isna()].index,inplace=True)\ndf.drop(df[df[\"fuel\"].isna()].index,inplace=True)\ndf.drop(df[df[\"title_status\"].isna()].index,inplace=True)\ndf.drop(df[df[\"transmission\"].isna()].index,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df= df.drop(columns=['VIN'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"null_values_per_variable = 100 * (df.isnull().sum()/df.shape[0]).round(3)#.reset_index()\nnull_values_per_variable.sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(df, df[TARGET_COLS], test_size=0.2, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Embeddings from Fast AI"},{"metadata":{},"cell_type":"markdown","source":"### Neural Network with Embeddings"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(10)\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, Concatenate, Reshape, Dropout\nfrom keras.layers.embeddings import Embedding\n\nfrom sklearn.model_selection import StratifiedKFold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerics = ['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']\ncategorical_columns = []\nfeatures = df.columns.values.tolist()\nfor col in features:\n    if df[col].dtype in numerics: continue\n    categorical_columns.append(col)\n\nfor cat_var in categorical_columns:\n    print (cat_var, df[cat_var].nunique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"other_cols = [c for c in X_train.columns if (not c in categorical_columns)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"other_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# add both categorical and numerical variables\ncols_use = categorical_columns + other_cols\n\nX_train = X_train[cols_use]\nX_test = X_test[cols_use]\n\ncol_vals_dict = {c: list(X_train[c].unique()) for c in X_train.columns}\n\nembed_cols = []\nfor c in col_vals_dict:\n    if len(col_vals_dict[c])>2:\n        embed_cols.append(c)\n        print(c + ': %d values' % len(col_vals_dict[c])) #look at value counts to know the embedding dimensions\n\nprint('\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getVar(categorical_var):\n    no_of_unique_cat  = df[categorical_var].nunique()\n    embedding_size = min(np.ceil((no_of_unique_cat)/2), 50 )\n    embedding_size = int(embedding_size)\n    vocab  = no_of_unique_cat #+1\n    return vocab,embedding_size,no_of_unique_cat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_embedding_network():\n    \n    inputs = []\n    embeddings = []\n    \n    # Manufacturer\n    input_manufacturer_cat = Input(shape=(1,))\n    vocab,embedding_size, no_of_unique_cat = getVar('manufacturer')\n    embedding = Embedding(vocab, embedding_size, input_length=1)(input_manufacturer_cat)\n    embedding = Reshape(target_shape=(embedding_size,))(embedding)\n    inputs.append(input_manufacturer_cat)\n    embeddings.append(embedding)\n    \n    #model\n    input_model_cat = Input(shape=(1,))\n    vocab,embedding_size, no_of_unique_cat = getVar('model')\n    embedding = Embedding(vocab, embedding_size, input_length=1)(input_model_cat)\n    embedding = Reshape(target_shape=(embedding_size,))(embedding)\n    inputs.append(input_model_cat)\n    embeddings.append(embedding)\n    \n    #condition\n    input_condition_cat = Input(shape=(1,))\n    vocab,embedding_size, no_of_unique_cat = getVar('condition')\n    embedding = Embedding(vocab, embedding_size, input_length=1)(input_condition_cat)\n    embedding = Reshape(target_shape=(embedding_size,))(embedding)\n    inputs.append(input_condition_cat)\n    embeddings.append(embedding)    \n    \n    #cylinders\n    input_cylinders_cat = Input(shape=(1,))\n    vocab,embedding_size, no_of_unique_cat = getVar('cylinders')\n    embedding = Embedding(vocab, embedding_size, input_length=1)(input_cylinders_cat)\n    embedding = Reshape(target_shape=(embedding_size,))(embedding)\n    inputs.append(input_cylinders_cat)\n    embeddings.append(embedding)\n    \n    #fuel\n    input_fuel_cat = Input(shape=(1,))\n    vocab,embedding_size, no_of_unique_cat = getVar('fuel')\n    embedding = Embedding(vocab, embedding_size, input_length=1)(input_fuel_cat)\n    embedding = Reshape(target_shape=(embedding_size,))(embedding)\n    inputs.append(input_fuel_cat)\n    embeddings.append(embedding)    \n    \n    #title_status\n    input_title_status_cat = Input(shape=(1,))\n    vocab,embedding_size, no_of_unique_cat = getVar('title_status')\n    embedding = Embedding(vocab, embedding_size, input_length=1)(input_title_status_cat)\n    embedding = Reshape(target_shape=(embedding_size,))(embedding)\n    inputs.append(input_title_status_cat)\n    embeddings.append(embedding)    \n\n    #transmission\n    input_transmission_cat = Input(shape=(1,))\n    vocab,embedding_size, no_of_unique_cat = getVar('transmission')\n    embedding = Embedding(vocab, embedding_size, input_length=1)(input_transmission_cat)\n    embedding = Reshape(target_shape=(embedding_size,))(embedding)\n    inputs.append(input_transmission_cat)\n    embeddings.append(embedding)    \n\n    #drive\n    input_drive_cat = Input(shape=(1,))\n    vocab,embedding_size, no_of_unique_cat = getVar('drive')\n    embedding = Embedding(vocab, embedding_size, input_length=1)(input_drive_cat)\n    embedding = Reshape(target_shape=(embedding_size,))(embedding)\n    inputs.append(input_drive_cat)\n    embeddings.append(embedding)   \n    \n    #type\n    input_type_cat = Input(shape=(1,))\n    vocab,embedding_size, no_of_unique_cat = getVar('type')\n    embedding = Embedding(vocab, embedding_size, input_length=1)(input_type_cat)\n    embedding = Reshape(target_shape=(embedding_size,))(embedding)\n    inputs.append(input_type_cat)\n    embeddings.append(embedding)     \n\n    #paint_color\n#     input_paint_color_cat = Input(shape=(1,))\n#     vocab,embedding_size, no_of_unique_cat = getVar('paint_color')\n#     embedding = Embedding(vocab, embedding_size, input_length=1)(input_paint_color_cat)\n#     embedding = Reshape(target_shape=(embedding_size,))(embedding)\n#     inputs.append(input_paint_color_cat)\n#     embeddings.append(embedding)\n    \n    #state\n    input_state_cat = Input(shape=(1,))\n    vocab,embedding_size, no_of_unique_cat = getVar('state')\n    embedding = Embedding(vocab, embedding_size, input_length=1)(input_state_cat)\n    embedding = Reshape(target_shape=(embedding_size,))(embedding)\n    inputs.append(input_state_cat)\n    embeddings.append(embedding)\n\n    #Numeric Variables\n    input_numeric = Input(shape=(3,))\n    embedding_numeric = Dense(8)(input_numeric) \n    inputs.append(input_numeric)\n    embeddings.append(embedding_numeric)\n    \n\n    x = Concatenate()(embeddings)\n    x = Dense(80, activation='relu')(x)\n    x = Dropout(.35)(x)\n    x = Dense(20, activation='relu')(x)\n    x = Dropout(.15)(x)\n    x = Dense(10, activation='relu')(x)\n    x = Dropout(.15)(x)\n    output = Dense(1, activation='sigmoid')(x)\n    \n    model = Model(inputs, output)\n\n    model.compile(loss='mean_squared_error', optimizer='adam')\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"K = 8\nruns_per_fold = 3\nn_epochs = 15\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NN = build_embedding_network()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NN.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#NN.summary()\nfrom tensorflow import keras\nkeras.utils.plot_model(NN, show_shapes=True, rankdir=\"LR\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #X_train['paint_color'].value_counts()\n# X_train['paint_color']=X_train['paint_color'].astype('object')\n# X_train['paint_color'] = X_train['paint_color'].fillna(method='ffill')\n# np.unique(X_train['type'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## https://www.kaggle.com/aquatic/entity-embedding-neural-net\n\n#converting data to list format to match the network structure\ndef preproc(X_train, X_val, X_test,embed_cols):\n\n    input_list_train = []\n    input_list_val = []\n    input_list_test = []\n    \n    #the cols to be embedded: rescaling to range [0, # values)\n    for c in embed_cols:\n        print(\"NEW COL :\" + c)\n        #raw_vals = np.unique(X_train[c])\n        raw_vals = X_train[c].unique()\n        \n        #print(\"Raw_vals\" + c + str(len(raw_vals)))\n        val_map = {}\n        for i in range(len(raw_vals)):\n            val_map[raw_vals[i]] = i  \n        #print(\"FIN COLUMNS0\")    \n        input_list_train.append(X_train[c].map(val_map).values)\n        input_list_val.append(X_val[c].map(val_map).fillna(0).values)\n        input_list_test.append(X_test[c].map(val_map).fillna(0).values)\n        #print(\"FIN COLUMNS1\")    \n     \n    #the rest of the columns\n    #print(\"OTHER COLUMNS\")\n    other_cols = [c for c in X_train.columns if (not c in categorical_columns)]\n    \n    from sklearn.preprocessing import MinMaxScaler\n    scaler =  MinMaxScaler()\n    X_train[other_cols] = scaler.fit_transform(X_train[other_cols])\n    X_val[other_cols] =  scaler.fit_transform(X_val[other_cols])\n    X_test[other_cols] =  scaler.fit_transform(X_test[other_cols])\n    \n    input_list_train.append(np.array(X_train[other_cols].values,dtype=np.float))\n    input_list_val.append(np.array(X_val[other_cols].values,dtype=np.float))\n    input_list_test.append(np.array(X_test[other_cols].values,dtype=np.float))\n    \n    return input_list_train, input_list_val, input_list_test  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainX, ValX, trainy, Valy = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\nproc_X_train_f, proc_X_val_f, proc_X_test_f = preproc(trainX, ValX, X_test,categorical_columns)\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\n\nNN.fit(proc_X_train_f,trainy, epochs=2, validation_data=proc_X_val_f)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# len(X_train.columns)\n# other_cols = [c for c in X_train.columns if (not c in categorical_columns)]\n# X_train[other_cols].columns\n\n# proc_X_train_f, proc_X_val_f, proc_X_test_f = preproc(trainX, ValX, X_test,categorical_columns)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = NN.predict(proc_X_val_f)\nrms = sqrt(mean_squared_error(prediction, Valy.values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = NN.predict(proc_X_test_f)\nrms = sqrt(mean_squared_error(prediction, y_test.values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rms","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(prediction),len(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfembeddings = pd.DataFrame()\niLayer = 10\nfor each in categorical_columns:    \n    #print(iLayer)\n    dftemp = pd.DataFrame(NN.layers[iLayer].get_weights()[0],\n             columns=[each + str(a) for a in range(NN.layers[iLayer].get_weights()[0].shape[1])])\n    dftemp[each + 'orig'] = df[each].unique()\n    X_train = pd.merge(X_train,dftemp,how='inner', left_on=each, right_on=each + 'orig')\n    \n    #dfembeddings = pd.concat([dfembeddings,dftemp],axis=1)\n    iLayer = iLayer + 1\n    \n#dfembeddings.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfembeddings = pd.DataFrame()\niLayer = 10\nfor each in categorical_columns:    \n    #print(iLayer)\n    dftemp = pd.DataFrame(NN.layers[iLayer].get_weights()[0],\n             columns=[each + str(a) for a in range(NN.layers[iLayer].get_weights()[0].shape[1])])\n    dftemp[each + 'orig'] = df[each].unique()\n    X_test = pd.merge(X_test,dftemp,how='inner', left_on=each, right_on=each + 'orig')\n    \n    #dfembeddings = pd.concat([dfembeddings,dftemp],axis=1)\n    iLayer = iLayer + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.shape,X_train.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# manufacturer: 40 values\n# model: 15288 values\n# condition: 6 values\n# cylinders: 8 values\n# fuel: 5 values\n# title_status: 6 values\n# transmission: 3 values\n# drive: 3 values\n# type: 13 values\n# paint_color: 12 values\n# state: 51 values\n\n# manufacturer = NN.layers[0].get_weights()[0]\n# model = models[1].layers[0].get_weights()[0]\n# condition = models[2].layers[0].get_weights()[0]\n# cylinders = models[3].layers[0].get_weights()[0]\n# fuel = models[4].layers[0].get_weights()[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Light GBM"},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n    'boosting_type': 'gbdt',\n    'objective': 'regression',\n    'metric': {'l2', 'l1'},\n    'num_leaves': 31,\n    'learning_rate': 0.05,\n    'feature_fraction': 0.9,\n    'bagging_fraction': 0.8,\n    'bagging_freq': 5,\n    'verbose': 0\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"excludecols = ['stateorig','manufacturerorig','conditionorig','cylindersorig',\n               'fuelorig','title_statusorig','modelorig',\n               'transmissionorig','driveorig','typeorig','stateorig']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"excludecols = excludecols + categorical_columns\ncols = [col for col in X_train.columns if col not in excludecols]\ncols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create dataset for lightgbm\ntrainX, ValX, trainy, Valy = train_test_split(X_train[cols], y_train, test_size=0.2, random_state=0)\n\n#other_cols = [c for c in df.columns if (not c in categorical_columns)]\n#proc_X_train_f, proc_X_val_f, proc_X_test_f = preproc(trainX, ValX, X_test,categorical_columns,other_cols)\n\nlgb_train = lgb.Dataset(trainX, trainy)\nlgb_eval = lgb.Dataset(ValX, Valy, reference=lgb_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Starting training...')\n# train\ngbm = lgb.train(params,\n                lgb_train,\n                num_boost_round=20,\n                valid_sets=lgb_eval,\n                early_stopping_rounds=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = gbm.predict(X_test[cols], num_iteration=gbm.best_iteration)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rms = sqrt(mean_squared_error(y_pred, y_test.values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rms","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Approach 2 - DeepTables"},{"metadata":{"trusted":true},"cell_type":"code","source":"no_of_unique_cat  = df['manufacturer'].nunique()\nno_of_unique_cat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install deeptables","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom deeptables.models import deeptable, deepnets\nfrom deeptables.datasets import dsutils\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#y = df.pop('price')\nX = df\ny = y.astype('float64')\nconf = deeptable.ModelConfig(\n    metrics=['RootMeanSquaredError'],\n    nets=['dnn_nets'],\n    #fixed_embedding_dim=True,\n    #stacking_op = 'add',\n    #output_use_bias = False,\n    categorical_columns = categorical_columns,\n    embeddings_output_dim = 20,\n    dnn_params={\n        'hidden_units': ((300, 0.3, True), (300, 0.3, True)),\n        'dnn_activation': 'relu',\n    },\n    earlystopping_patience=5,\n)\n\ndt = deeptable.DeepTable(config=conf)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nmodel, history = dt.fit(X_train, y_train, epochs=100)\n\nscore = dt.evaluate(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## finish","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}