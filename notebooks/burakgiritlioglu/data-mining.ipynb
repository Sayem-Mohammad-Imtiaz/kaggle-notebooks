{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Import Libraries that I found from google, because before start code I wanted to make sure they work. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns  # Provides a high level interface for drawing attractive and informative statistical graphics\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\n\nimport statsmodels.api as sm\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix\n\ndef annot_plot(ax,w,h):                                    # function to add data to plot\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    for p in ax.patches:\n         ax.annotate(f\"{p.get_height() * 100 / df.shape[0]:.2f}%\", (p.get_x() + p.get_width() / 2., p.get_height()),\n         ha='center', va='center', fontsize=11, color='black', rotation=0, xytext=(0, 10),\n         textcoords='offset points')   \n            \n# warning library\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.preprocessing import StandardScaler\n\n#from sklearn.neighbors import KNeighborsClassifier, NeighborhoodComponentsAnalysis, LocalOutlierFactor\nfrom sklearn.decomposition import PCA\n           \n%matplotlib inline\nsns.set()\nfrom subprocess import check_output\n\n\n#def annot_plot_num(ax,w,h):                                    # function to add data to plot\n #   ax.spines['top'].set_visible(False)\n  #  ax.spines['right'].set_visible(False)\n   # for p in ax.patches:\n    #    ax.annotate('{0:.1f}'.format(p.get_height()), (p.get_x()+w, p.get_height()+h))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Data Loading","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/ibm-watson-marketing-customer-value-data/WA_Fn-UseC_-Marketing-Customer-Value-Analysis.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Before analyzing and visualize the data I had to change the variables of Independent Variable(Response). I changed yes and no to 1 and 0. Because only this way I can compare this column with other dependent variables.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Response = df.Response.apply(lambda X : 0 if X == 'No' else 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" # Data Visualize and Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes.groupby(df.dtypes.values).count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Analyze the code with Plots","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# First I wanted to see Response  ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.countplot('Response',data = df)\nplt.ylabel('Total number of Response')\nannot_plot(ax,0.09,1) #I found this function in kaggle examples. I imported the function 'Import Library Part'\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Then I wanted to see the other columns.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef plot_hist(var,tot):\n    ax = sns.countplot(var,data = df)\n    plt.ylabel(tot)\n    annot_plot(ax,0.09,1) #I found this function in kaggle examples. I imported the function 'Import Library Part'\n    plt.show()\n\nstrvar=[\"State\", \"Coverage\", \"Education\", \"EmploymentStatus\", \"Gender\",\"Location Code\", \"Marital Status\", \"Policy\", \"Policy Type\", \"Renew Offer Type\", \"Sales Channel\", \"Vehicle Size\", \"Vehicle Class\"]\ntotal=[\"Total number of State\", \"Total number of Coverage\", \"Total number of Education\", \"Total number of EmploymentStatus\",\"Total number of Gender\", \"Total number of Location Code\", \"Total number of Marital Status\", \"Total number of Policy\",\n        \"Total number of Policy Type\", \"Total number of Renew Offer Type\",\"Total number of Sales Channel\",\"Total number of Vehicle Size\", \"Total number of Vehicle Class\"]\nfor n,i in zip(strvar,total):\n    plot_hist(n,i)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# In this part of the code, I created the for loop to see the correlation btw response and the other string valued dependent values.","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\ndef plot_hist(var,tot):\n    ax = sns.countplot('Response',hue = var ,data = df)\n    plt.ylabel(tot)\n    annot_plot(ax,0.09,1)\n    plt.show()\n\nstrvar=[\"State\", \"Coverage\", \"Education\", \"EmploymentStatus\", \"Gender\",\"Location Code\", \"Marital Status\", \"Policy\", \"Policy Type\", \"Renew Offer Type\", \"Sales Channel\", \"Vehicle Size\", \"Vehicle Class\"]\ntotal=[\"Total number of State\", \"Total number of Coverage\", \"Total number of Education\", \"Total number of EmploymentStatus\",\"Total number of Gender\", \"Total number of Location Code\", \"Total number of Marital Status\", \"Total number of Policy\",\n        \"Total number of Policy Type\", \"Total number of Renew Offer Type\",\"Total number of Sales Channel\",\"Total number of Vehicle Size\", \"Total number of Vehicle Class\"]\nfor n,i in zip(strvar,total):\n    plot_hist(n,i)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# In this part I wanted to see the correlation btw response and numeric valued dependent values.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def plot(var):\n    plt.figure(figsize=(12,6))\n    sns.boxplot(y = var, x = 'Response', data = df)\n    plt.ylabel(var)\n    plt.show()\n\nnumvar=[\"Income\",\"Total Claim Amount\"]\nfor n in numvar:\n    plot(n)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Fixing","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# First I dropped some columns that I decided to drop before. Then I changed the string values with numerics. Because only this way I can use them properly.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop(['Customer','Effective To Date','Gender','Policy','Vehicle Class'], axis = 1)\n\ndf[\"Coverage\"] = [0 if i == \"Basic\" else 1 if i == \"Extended\"\n                      else 2 for i in df[\"Coverage\"]]\ndf[\"State\"] = [0 if i == \"California\" else 1 if i == \"Oregon\" else 2 if i == \"Arizona\" else 3 if i == \"Nevada\"\n                      else 4 for i in df[\"State\"]]\ndf[\"Education\"] = [0 if i == \"Bachelor\" else 1 if i == \"College\" else 2 if i == \"High School or Below\" else 3 if i == \"College\" \n                   else 4 if i == \"Master\" else 5 for i in df[\"Education\"]]\ndf[\"EmploymentStatus\"] = [0 if i == \"Employed\" else 1 if i == \"Unemployed\" else 2 if i == \"Medical Leave\" else 3 if i == \"Medical Leave\" \n                  else 4 if i == \"Disabled\" else 5 for i in df[\"EmploymentStatus\"]]\ndf[\"Location Code\"] = [0 if i == \"Suburban\" else 1 if i == \"Rural\"\n                      else 2 for i in df[\"Location Code\"]]\ndf[\"Marital Status\"] = [0 if i == \"Married\" else 1 if i == \"Single\"\n                      else 2 for i in df[\"Marital Status\"]]\ndf[\"Policy Type\"] = [0 if i == \"Personal Auto\" else 1 if i == \"Corporate Auto\"\n                      else 2 for i in df[\"Policy Type\"]]\ndf[\"Renew Offer Type\"] = [0 if i == \"Offer1\" else 1 if i == \"Offer2\" else 2 if i == \"Offer3\"\n                      else 3 for i in df[\"Renew Offer Type\"]]\ndf[\"Sales Channel\"] = [0 if i == \"Agent\" else 1 if i == \"Branch\" else 2 if i == \"Call Center\"\n                      else 3 for i in df[\"Sales Channel\"]]   \ndf[\"Vehicle Size\"] = [0 if i == \"Medsize\" else 1 if i == \"Small\" \n                      else 2 for i in df[\"Vehicle Size\"]] \n\ndf.head()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot(var):\n    sns.countplot(x= var,data = df)\n    plt.xticks(rotation = 60)\n    plt.show()\nstrvar=[\"State\", \"Coverage\", \"Education\", \"EmploymentStatus\",\"Location Code\", \"Marital Status\", \"Policy Type\", \"Renew Offer Type\", \"Sales Channel\", \"Vehicle Size\"]\nfor i in strvar:\n    plot(i)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Linear Regression without test and train datasets.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X1 = df[[\"Coverage\",\"Education\",\"EmploymentStatus\",\"Marital Status\",\"Policy Type\",\"Renew Offer Type\",\"Renew Offer Type\", \"Sales Channel\",\n         \"Vehicle Size\"]]\ny1 = df[\"Response\"]\n\n# Fit and make the predictions by the model\nmodel = sm.OLS(y1, X1).fit()\npredictions = model.predict(X1)\n\n# Print out the statistics\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X1 = df[[\"Education\",\"EmploymentStatus\",\"Marital Status\",\"Policy Type\",\"Renew Offer Type\", \"Sales Channel\",\"Vehicle Size\"]]\ny1 = df[\"Response\"]\n\n# Fit and make the predictions by the model\nmodel1 = sm.OLS(y1, X1).fit()\npredictions = model1.predict(X1)\n\n# Print out the statistics\nmodel1.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X1 = df[[\"Coverage\",\"EmploymentStatus\",\"Marital Status\",\"Policy Type\",\"Renew Offer Type\", \"Sales Channel\",\"Vehicle Size\"]]\ny1 = df[\"Response\"]\n\n# Fit and make the predictions by the model\nmodel2 = sm.OLS(y1, X1).fit()\npredictions = model2.predict(X1)\n\n# Print out the statistics\nmodel2.summary()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X1 = df[[\"Coverage\",\"Education\",\"Marital Status\",\"Policy Type\",\"Renew Offer Type\", \"Sales Channel\",\"Vehicle Size\"]]\ny1 = df[\"Response\"]\n\n# Fit and make the predictions by the model\nmodel3 = sm.OLS(y1, X1).fit()\npredictions = model3.predict(X1)\n\n# Print out the statistics\nmodel3.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X1 = df[[\"Coverage\",\"Education\",\"EmploymentStatus\",\"Policy Type\",\"Renew Offer Type\", \"Sales Channel\",\"Vehicle Size\"]]\ny1 = df[\"Response\"]\n\n# Fit and make the predictions by the model\nmodel4 = sm.OLS(y1, X1).fit()\npredictions = model4.predict(X1)\n\n# Print out the statistics\nmodel4.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X1 = df[[\"Coverage\",\"Education\",\"EmploymentStatus\",\"Marital Status\",\"Renew Offer Type\", \"Sales Channel\",\"Vehicle Size\"]]\ny1 = df[\"Response\"]\n\n# Fit and make the predictions by the model\nmodel5 = sm.OLS(y1, X1).fit()\npredictions = model5.predict(X1)\n\n# Print out the statistics\nmodel5.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X1 = df[[\"Coverage\",\"Education\",\"EmploymentStatus\",\"Marital Status\",\"Policy Type\", \"Sales Channel\",\"Vehicle Size\"]]\ny1 = df[\"Response\"]\n\n# Fit and make the predictions by the model\nmodel6 = sm.OLS(y1, X1).fit()\npredictions = model6.predict(X1)\n\n# Print out the statistics\nmodel6.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nX1 = df[[\"Coverage\",\"Education\",\"EmploymentStatus\",\"Marital Status\",\"Policy Type\",\"Renew Offer Type\",\"Vehicle Size\"]]\ny1 = df[\"Response\"]\n\n# Fit and make the predictions by the model\nmodel7 = sm.OLS(y1, X1).fit()\npredictions = model7.predict(X1)\n\n# Print out the statistics\nmodel7.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nX1 = df[[\"Coverage\",\"Education\",\"EmploymentStatus\",\"Marital Status\",\"Policy Type\",\"Renew Offer Type\", \"Sales Channel\"]]\ny1 = df[\"Response\"]\n\n# Fit and make the predictions by the model\nmodel8 = sm.OLS(y1, X1).fit()\npredictions = model8.predict(X1)\n\n# Print out the statistics\nmodel8.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create Test and Train","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# I’ve created two variables called X and y where X contains independent variables whereas y merely contains output variable which is Response.I’ve split up the dataset into four parts, 2 for test sets and rests for the train sets through %30 of the dataset for test and %70 for train sets. After creating an object from LogisticRegression()class, I’ve fitted the model and predict y^values by using x_test.All in all, I have found confusion matrix and accuracy score.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df[[\"Coverage\",\"Education\",\"EmploymentStatus\",\"Marital Status\",\"Policy Type\",\"Renew Offer Type\", \"Sales Channel\",\"Vehicle Size\"]]\nX1 = df[[\"Education\",\"EmploymentStatus\",\"Marital Status\",\"Policy Type\",\"Renew Offer Type\", \"Sales Channel\",\"Vehicle Size\"]]\nX2 = df[[\"Coverage\",\"EmploymentStatus\",\"Marital Status\",\"Policy Type\",\"Renew Offer Type\", \"Sales Channel\",\"Vehicle Size\"]]\nX3 = df[[\"Coverage\",\"Education\",\"Marital Status\",\"Policy Type\",\"Renew Offer Type\", \"Sales Channel\",\"Vehicle Size\"]]\nX4 = df[[\"Coverage\",\"Education\",\"EmploymentStatus\",\"Policy Type\",\"Renew Offer Type\", \"Sales Channel\",\"Vehicle Size\"]]\nX5 = df[[\"Coverage\",\"Education\",\"EmploymentStatus\",\"Marital Status\",\"Renew Offer Type\", \"Sales Channel\",\"Vehicle Size\"]]\nX6 = df[[\"Coverage\",\"Education\",\"EmploymentStatus\",\"Marital Status\",\"Policy Type\", \"Sales Channel\",\"Vehicle Size\"]]\nX7 = df[[\"Coverage\",\"Education\",\"EmploymentStatus\",\"Marital Status\",\"Policy Type\",\"Renew Offer Type\",\"Vehicle Size\"]]\nX8 = df[[\"Coverage\",\"Education\",\"EmploymentStatus\",\"Marital Status\",\"Policy Type\",\"Renew Offer Type\", \"Sales Channel\"]]\ny = df[\"Response\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100)\nX1_train, X1_test, y1_train, y1_test = train_test_split(X1, y, test_size=0.3, random_state=100)\nX2_train, X2_test, y2_train, y2_test = train_test_split(X2, y, test_size=0.3, random_state=100)\nX3_train, X3_test, y3_train, y3_test = train_test_split(X3, y, test_size=0.3, random_state=100)\nX4_train, X4_test, y4_train, y4_test = train_test_split(X4, y, test_size=0.3, random_state=100)\nX5_train, X5_test, y5_train, y5_test = train_test_split(X5, y, test_size=0.3, random_state=100)\nX6_train, X6_test, y6_train, y6_test = train_test_split(X6, y, test_size=0.3, random_state=100)\nX7_train, X7_test, y7_train, y7_test = train_test_split(X7, y, test_size=0.3, random_state=100)\nX8_train, X8_test, y8_train, y8_test = train_test_split(X8, y, test_size=0.3, random_state=100)\n#print(X_train)\n#print(y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# For analyse the data with Logistic Regression Model, First string columns had to be make categorical. For doing it first they needed to turned numeric values. Then with get_dummies function they created as categorical.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.get_dummies(df,columns = [\"Coverage\"])\ndf = pd.get_dummies(df,columns = [\"State\"])\ndf = pd.get_dummies(df,columns = [\"Education\"])\ndf = pd.get_dummies(df,columns = [\"EmploymentStatus\"])\ndf = pd.get_dummies(df,columns = [\"Location Code\"])\ndf = pd.get_dummies(df,columns = [\"Marital Status\"])\ndf = pd.get_dummies(df,columns = [\"Policy Type\"])\ndf = pd.get_dummies(df,columns = [\"Renew Offer Type\"])\ndf = pd.get_dummies(df,columns = [\"Sales Channel\"])\ndf = pd.get_dummies(df,columns = [\"Vehicle Size\"])\ndf.head()\n\n#build the model\nlog = LogisticRegression(solver='liblinear')\nmodel = log.fit(X_train,y_train)\ny_pred = log.predict(X_test)\n\nconf = confusion_matrix(y_test,y_pred)\nprint(conf)\n\nprint(classification_report(y_test, y_pred))\n\nacc = accuracy_score(y_test,y_pred)\nprint(\"accuracy = \",acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#build the model\nlog = LogisticRegression(solver='liblinear')\nmodel = log.fit(X1_train,y1_train)\ny1_pred = log.predict(X1_test)\n\nconf = confusion_matrix(y1_test,y1_pred)\nprint(conf)\n\nprint(classification_report(y1_test, y1_pred))\n\nacc = accuracy_score(y1_test,y1_pred)\nprint(\"accuracy = \",acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#build the model\nlog = LogisticRegression(solver='liblinear')\nmodel = log.fit(X2_train,y2_train)\ny2_pred = log.predict(X2_test)\n\nconf = confusion_matrix(y2_test,y2_pred)\nprint(conf)\n\nprint(classification_report(y2_test, y2_pred))\n\nacc = accuracy_score(y2_test,y2_pred)\nprint(\"accuracy = \",acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#build the model\nlog = LogisticRegression(solver='liblinear')\nmodel = log.fit(X3_train,y3_train)\ny3_pred = log.predict(X3_test)\n\nconf = confusion_matrix(y3_test,y3_pred)\nprint(conf)\n\nprint(classification_report(y3_test, y3_pred))\n\nacc = accuracy_score(y3_test,y3_pred)\nprint(\"accuracy = \",acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#build the model\nlog = LogisticRegression(solver='liblinear')\nmodel = log.fit(X4_train,y4_train)\ny4_pred = log.predict(X4_test)\n\nconf = confusion_matrix(y4_test,y4_pred)\nprint(conf)\n\nprint(classification_report(y4_test, y4_pred))\n\nacc = accuracy_score(y4_test,y4_pred)\nprint(\"accuracy = \",acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#build the model\nlog = LogisticRegression(solver='liblinear')\nmodel = log.fit(X5_train,y5_train)\ny5_pred = log.predict(X5_test)\n\nconf = confusion_matrix(y5_test,y5_pred)\nprint(conf)\n\nprint(classification_report(y5_test, y5_pred))\n\nacc = accuracy_score(y5_test,y5_pred)\nprint(\"accuracy = \",acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#build the model\nlog = LogisticRegression(solver='liblinear')\nmodel = log.fit(X6_train,y6_train)\ny6_pred = log.predict(X6_test)\n\nconf = confusion_matrix(y6_test,y6_pred)\nprint(conf)\n\nprint(classification_report(y6_test, y6_pred))\n\nacc = accuracy_score(y6_test,y6_pred)\nprint(\"accuracy = \",acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#build the model\nlog = LogisticRegression(solver='liblinear')\nmodel = log.fit(X7_train,y7_train)\ny7_pred = log.predict(X7_test)\n\nconf = confusion_matrix(y7_test,y7_pred)\nprint(conf)\n\nprint(classification_report(y7_test, y7_pred))\n\nacc = accuracy_score(y7_test,y7_pred)\nprint(\"accuracy = \",acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#build the model\nlog = LogisticRegression(solver='liblinear')\nmodel = log.fit(X8_train,y8_train)\ny8_pred = log.predict(X8_test)\n\nconf = confusion_matrix(y8_test,y8_pred)\nprint(conf)\n\nprint(classification_report(y8_test, y8_pred))\n\nacc = accuracy_score(y8_test,y8_pred)\nprint(\"accuracy = \",acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decision Tree","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# I used same test and train dataframes because after using them I can compare the findings btw two different model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = DecisionTreeClassifier()\nclassifier.fit(X_train, y_train)\n\ny_pred = classifier.predict(X_test)\n\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\n\nacc = accuracy_score(y_test,y_pred)\nprint(\"accuracy = \",acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = DecisionTreeClassifier()\nclassifier.fit(X1_train, y1_train)\n\ny1_pred = classifier.predict(X1_test)\n\nprint(confusion_matrix(y1_test, y1_pred))\nprint(classification_report(y1_test, y1_pred))\n\nacc = accuracy_score(y1_test,y1_pred)\nprint(\"accuracy = \",acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = DecisionTreeClassifier()\nclassifier.fit(X2_train, y2_train)\n\ny2_pred = classifier.predict(X2_test)\n\nprint(confusion_matrix(y2_test, y2_pred))\nprint(classification_report(y2_test, y2_pred))\n\nacc = accuracy_score(y2_test,y2_pred)\nprint(\"accuracy = \",acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = DecisionTreeClassifier()\nclassifier.fit(X3_train, y3_train)\n\ny3_pred = classifier.predict(X3_test)\n\nprint(confusion_matrix(y3_test, y3_pred))\nprint(classification_report(y3_test, y3_pred))\n\nacc = accuracy_score(y3_test,y3_pred)\nprint(\"accuracy = \",acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = DecisionTreeClassifier()\nclassifier.fit(X4_train, y4_train)\n\ny4_pred = classifier.predict(X4_test)\n\nprint(confusion_matrix(y4_test, y4_pred))\nprint(classification_report(y4_test, y4_pred))\n\nacc = accuracy_score(y4_test,y4_pred)\nprint(\"accuracy = \",acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = DecisionTreeClassifier()\nclassifier.fit(X5_train, y5_train)\n\ny5_pred = classifier.predict(X5_test)\n\nprint(confusion_matrix(y5_test, y5_pred))\nprint(classification_report(y5_test, y5_pred))\n\nacc = accuracy_score(y5_test,y5_pred)\nprint(\"accuracy = \",acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = DecisionTreeClassifier()\nclassifier.fit(X6_train, y6_train)\n\ny_pred = classifier.predict(X6_test)\n\nprint(confusion_matrix(y6_test, y6_pred))\nprint(classification_report(y6_test, y6_pred))\n\nacc = accuracy_score(y6_test,y6_pred)\nprint(\"accuracy = \",acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = DecisionTreeClassifier()\nclassifier.fit(X7_train, y7_train)\n\ny7_pred = classifier.predict(X7_test)\n\nprint(confusion_matrix(y7_test, y7_pred))\nprint(classification_report(y7_test, y7_pred))\n\nacc = accuracy_score(y7_test,y7_pred)\nprint(\"accuracy = \",acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = DecisionTreeClassifier()\nclassifier.fit(X8_train, y8_train)\n\ny8_pred = classifier.predict(X8_test)\n\nprint(confusion_matrix(y8_test, y8_pred))\nprint(classification_report(y8_test, y8_pred))\n\nacc = accuracy_score(y8_test,y8_pred)\nprint(\"accuracy = \",acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Linear Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlin_reg = LinearRegression()\nmodel = lin_reg.fit(X_train,y_train)\n\nprint(f'Coefficients: {lin_reg.coef_}')\nprint(f'Intercept: {lin_reg.intercept_}')\nprint(f'R^2 score: {lin_reg.score(X, y)}')\nprint(f'R^2 score for train: {lin_reg.score(X_train, y_train)}')\nprint(f'R^2 score for test: {lin_reg.score(X_test, y_test)}')\n\nX_sm = X\nX_sm = sm.add_constant(X_sm)\nlm = sm.OLS(y,X_sm).fit()\nlm.summary()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}