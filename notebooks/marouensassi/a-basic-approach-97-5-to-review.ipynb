{"cells":[{"metadata":{},"cell_type":"markdown","source":"# A Basic Approach of a beginner getting <span style=\"color:red\">97,5% </span>."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"load the Data "},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df0 = pd.read_csv('../input/credit-card-customers/BankChurners.csv')\ndf0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df= df0.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Start Exploratory analysis of the Data : \n\nin this Step we need to collect some information from our Data. Graph Visualisation(Heatmap, box, bar,Line...) will help us a lot in this Step. \nTake notes of :\n\n   * Data Type  (Numerical/Categorical) \n   \nand check : \n\n   * Missing Data \n   * Distribution \n   * Relation between Features (Correlations)             \n   * Outleirs \n   * Balance / Imbalance Data  \n   \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":" # delet some unusefull Columns \ndel df['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2']\ndel df['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1']\ndel df['CLIENTNUM']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\ncount=pd.value_counts(df['Attrition_Flag']).tolist()\nplt.figure(figsize=(5,5))\nplt.title(\"Percentage of Attrited Customer and Existing Customer\")\nplt.pie(x=count,labels=[\"Attrited Customer\",\"Existing Customers\"],autopct='%.2f%%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nplt.figure(figsize=(28,11))\nplt.title(\"Distribution of Age with respect to Churned or not\")\nsns.countplot(data=df,x=df[\"Customer_Age\"],hue=\"Attrition_Flag\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ncats = ['Gender','Education_Level','Marital_Status', 'Income_Category', 'Card_Category','Attrition_Flag']\n\nfig, axis = plt.subplots(len(cats) // 3,3, figsize=(20,12))\nfig.suptitle('The distibution of the Churners')\n\nindex = 0\nfor i in range(len(cats) // 3):\n      for j in range(3):\n            \n            ax = sns.countplot(ax=axis[i][j] ,x=df[cats[index]], hue=df['Attrition_Flag'],palette=\"Set1\")\n            ax.legend(title='Customer',loc='upper right',labels=['Existing', 'attired'])\n            for p in ax.patches:\n                height = p.get_height()\n                ax.text(p.get_x()+p.get_width()/2.,\n                        height + 3,\n                        '{:1.2f}%'.format(height/len(df)*100),\n                        ha=\"center\") ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Création de sous-ensembles positifs et négatifs\n\nnumr = ['Months_Inactive_12_mon','Contacts_Count_12_mon','Credit_Limit',\n                  'Total_Amt_Chng_Q4_Q1','Total_Trans_Ct','Total_Ct_Chng_Q4_Q1']\n\nexisting_df = df[df['Attrition_Flag'] == 'Existing Customer']\nattired_df = df[df['Attrition_Flag'] == 'Attrited Customer']\n\n\nfor col in numr:\n    plt.figure()\n    sns.distplot(existing_df[col], label='existing')\n    sns.distplot(attired_df[col], label=' attired')\n    plt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n\n\nfig, axis = plt.subplots(len(cats) // 3,3, figsize=(20,12))\nfig.suptitle('The distibution of the numr')\nsns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n\n\nindex = 0\nfor i in range(len(cats) // 3):\n      for j in range(3):\n            \n            ax = sns.boxplot(ax=axis[i][j] ,x=df[numr[index]])\n            index += 1\n            #sns.set_theme(style=\"dark\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#outlier cleanup\nfrom scipy import stats\nimport numpy as np\ncolumns = [\"Customer_Age\", 'Dependent_count', 'Months_on_book',\n       'Total_Relationship_Count', 'Months_Inactive_12_mon',\n       'Contacts_Count_12_mon', 'Credit_Limit', 'Total_Revolving_Bal',\n       'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt',\n       'Total_Trans_Ct', 'Total_Ct_Chng_Q4_Q1', 'Avg_Utilization_Ratio']\nprint(df.shape)\nfor column in columns : \n    z = np.abs(stats.zscore(df[column]))\n    df=df[(z < 3)]\nprint(df.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing & Feature engineering\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cat=df.select_dtypes(include=[object])\ndf_numr=df.select_dtypes(exclude=[object])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# one hot encoding of object category data\nobj_data=pd.get_dummies(df_cat.drop(columns=['Attrition_Flag']),drop_first=True)\nobj_data\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# joining our numr dataframe and object dataframe\ndf=pd.concat([obj_data,df_numr],axis=1)\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# splitting dependent and independent feature \n\nY=pd.get_dummies(df_cat['Attrition_Flag'],drop_first=True)\nX=df\n\nprint(X.shape)\nprint(Y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dividing dataset into training and testing set \nfrom sklearn.model_selection import train_test_split\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\nprint(X_train.shape,y_train.shape,X_test.shape,y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.combine import SMOTETomek\nfrom collections import Counter \n\n\nsmk=SMOTETomek(random_state=42)\nxres,yres=smk.fit_sample(X_train,y_train.values.ravel())\n\nprint(yres.shape, xres.shape)\nprint('Old Shape {}'.format(Counter(Y)))\nprint('Resampled Shape {}'.format(Counter(yres)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# BUILDING MODELS & EVALUATION\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier \nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.pipeline import make_pipeline\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn.ensemble.gradient_boosting import GradientBoostingClassifier\nfrom sklearn.ensemble.forest import ExtraTreesClassifier\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom sklearn.preprocessing import PolynomialFeatures, StandardScaler ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocessor =  make_pipeline(SelectKBest(f_classif, k=10) ,PolynomialFeatures(2))\n\n\nAdaBoost = make_pipeline(preprocessor,AdaBoostClassifier(random_state=0))\nSVM= make_pipeline(preprocessor, StandardScaler(), SVC(random_state=0))\nGBoost = make_pipeline(preprocessor, StandardScaler(), GradientBoostingClassifier())\nRandomForest = make_pipeline( preprocessor, RandomForestClassifier())\nXGB = make_pipeline( preprocessor, XGBClassifier())\nExtree = make_pipeline( preprocessor, ExtraTreesClassifier())\n\ndict_of_models = {'AdaBoost':AdaBoost,\n                  'SVM':SVM,\n                  'GBoost':GBoost,\n                  'RandomForest':RandomForest,\n                  'XGB':XGB,\n                  'Extree':Extree}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score, confusion_matrix, classification_report\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluation(model_1):\n    \n    #np.seterr(divide='ignore', invalid='ignore')\n    model_1.fit(xres, yres)\n    ypred = model_1.predict(X_test)\n    cm = confusion_matrix(y_test, ypred)\n    #sns.heatmap(cm,annot=True, annot_kws={\"size\": 16})\n    N, train_score, val_score = learning_curve(model_1, xres, yres,\n                                              cv=4, scoring='f1',\n                                               train_sizes=np.linspace(0.1, 1, 10))\n    \n    \n    plt.figure(figsize=(12, 8))\n    plt.plot(N, train_score.mean(axis=1), label='train score')\n    plt.plot(N, val_score.mean(axis=1), label='validation score')\n    plt.legend()\n    \n    \n    print(confusion_matrix(y_test, ypred))\n    print(classification_report(y_test, ypred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfor name, model in dict_of_models.items():\n    print(name)\n    evaluation(model)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Choose the Best MODEL and Tune Hyperparamater"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nparams = {\"max_depth\" : [6,7,8],\n          \"min_child_weight\" : [1,2,3],\n          'gamma ':[0],\n          'subsample':[0.6,0.7,0.8],\n          #'colsample_bytree':\n         }\n    \n         \n\nclf = XGBClassifier()\ngrid= GridSearchCV (clf, params,scoring=\"recall\", cv = 3)\n\ngrid_result = grid.fit(xres, yres)\n\n\n\n\n#Summary \n#print(\"classifcation report: \",classification_report(y_test, y_pred))\nprint(\"Best: %f using %s \" % (grid_result.best_score_, grid_result.best_params_) )\nmeans = grid_result.cv_results_[\"mean_test_score\"]\nstds = grid_result.cv_results_[\"std_test_score\"]\nparams = grid_result.cv_results_[\"params\"]\n\nfor mean, stdev, param in zip (means, stds, params):\n    print(\"%f (%f) with : %r\" % (mean, stdev, param))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import*\nfrom sklearn.model_selection import* \nfrom sklearn.preprocessing import*\n\n\nxgb = XGBClassifier(gamma = 0, max_depth=7, min_child_weight= 1, subsample= 0.8) \nxgb.fit(xres, yres)\ny_pred = xgb.predict(X_test)\n\nacc = accuracy_score(y_test, y_pred)\nmse = mean_squared_error(y_test.values, y_pred)\n\nprint(\"Acc  : \", acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(xgb.feature_importances_, index=X_train.columns).plot.bar(figsize=(12, 8))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}