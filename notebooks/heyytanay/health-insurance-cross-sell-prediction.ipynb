{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"color:aqua; background-color:black\">Health Insurance Cross Sell Prediction: Multi-Model Comparison</h1>\n\nThis is only a model comparison notebook. I have done EDA by using DABL only.\n\n\n<p style=\"color:red\">If you like my work, please upvote it!</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"! pip install -q dabl","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport dabl\n\n\nfrom IPython import display\n\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.metrics import roc_auc_score\n\nimport warnings\n\nwarnings.simplefilter(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/health-insurance-cross-sell-prediction/train.csv\")\ntest = pd.read_csv(\"../input/health-insurance-cross-sell-prediction/test.csv\")\nsub = pd.read_csv(\"../input/health-insurance-cross-sell-prediction/sample_submission.csv\")\n\ntrain = train.drop(['id'], axis=1)\ntest = test.drop(['id'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dabl.plot(train, target_col='Response')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Gender'] = train['Gender'].map({'Male':1, 'Female':0})\ntrain['Vehicle_Age'] = train['Vehicle_Age'].map({'> 2 Years':0, '1-2 Year':1, '< 1 Year':2})\ntrain['Vehicle_Damage'] = train['Vehicle_Damage'].map({'Yes':1, 'No':0})\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the data\nsplit_pcent = 0.20\nsplit = int(len(train) * split_pcent)\n\ndata = train.sample(frac=1).reset_index(drop=True)\n\nvalid = data[:split]\ntrain = data[split:]\n\ntX, tY = train.drop(['Response'], axis=1).values, train['Response'].values\nvX, vY = valid.drop(['Response'], axis=1).values, valid['Response'].values\n\nprint(tX.shape[0], vX.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"names = [\"Logistic Regression\", \"Nearest Neighbors\", \n         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n         \"Naive Bayes\", \"QDA\"]\n\nclassifiers = [\n    LogisticRegression(),\n    KNeighborsClassifier(3),\n    DecisionTreeClassifier(max_depth=5),\n    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n    MLPClassifier(alpha=1, max_iter=1000),\n    AdaBoostClassifier(),\n    GaussianNB(),\n    QuadraticDiscriminantAnalysis()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's do the classification and store the name of the classifier and it's test score into a dictionary\n\nroc_results = {}\nacc_results = {}\n\nfor name, clf in zip(names, classifiers):\n    # Fit on the traning data\n    clf.fit(tX, tY)\n    \n    # Store the validation accuracy\n    val_acc = clf.score(vX, vY)\n    acc_results[name] = val_acc\n    \n    # Get the test time prediction\n    preds = clf.predict(vX)\n    \n    # Calculate Test ROC_AUC\n    roc_score = roc_auc_score(vY, preds)\n    \n    # Store the results in a dictionary\n    roc_results[name] = roc_score\n    \n    print(f\"Classifier: {name} | val_acc: {val_acc:.4f} | roc_auc: {roc_score:.4f}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sort the Model Accuracies based on the test score\nsort_clf = dict(sorted(acc_results.items(), key=lambda x: x[1], reverse=True))\n\n# Get the names and the corresponding scores\nclf_names = list(sort_clf.keys())[::-1]\nclf_scores = list(sort_clf.values())[::-1]\n\n# Plot the per-model performance\nfig = px.bar(\n    x=clf_scores,\n    y=clf_names,\n    color=clf_names,\n    labels={'x':'Validation Accuracy Score', 'y':'Models'},\n    title=f\"Model Performance [ Best Model: {clf_names[-1]} | Accuracy: {clf_scores[-1]:.2f} ]\"\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}