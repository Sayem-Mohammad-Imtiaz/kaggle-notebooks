{"cells":[{"metadata":{},"cell_type":"markdown","source":"In questo notebook si vuole costruire un modello tramite Ridge Regression che, conoscendo i volumi di vendita di una casa produttrice di videogiochi in nordamerica, predica il volumi di vendita di un videogioco che sta per essere rilasciato in Europa.\n\nIl dataset che andremo ad usare è il seguente:"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nimport pandas as pd\n\n\ndf = pd.read_csv('../input/videogamesales/vgsales.csv')\ntrain, test = train_test_split(df, test_size=0.2, random_state=0)\nprint(f\"Dimensione del dataset di training: {train.size}\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.xlabel(\"NA sales\")\nplt.ylabel(\"EU sales\")\nplt.xscale(\"symlog\")\nplt.scatter(train.NA_Sales, train.EU_Sales)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Proviamo ad applicare una regressione lineare, osservando come cambia il modello al variare del grado."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\n\nimport numpy as np\n\n\n# Configurazione necessaria per disegnare i grafici\nX_seq = np.linspace(train.NA_Sales.values.min(),train.NA_Sales.values.max(),300).reshape(-1,1) # crea dei valori adatti per il plot della curva ideale\nfig, axs = plt.subplots(3, 3, figsize=(20, 10)) # divide la figura in 9 quadranti\nfor ax in axs.flat:\n        ax.set(xlabel=\"NA sales\", ylabel=\"EU sales\", xscale=\"symlog\") # associa le etichette agli assi dei grafici e ne imposta la scala dell'asse x\nfor ax in fig.get_axes():\n    ax.label_outer() # \"Raggruppa\" le etichette degli assi: mostra solo quelle degli assi più esterni\n\n\nresults = []\n    \nfor degree in range(1,10):\n    model = make_pipeline(\n      PolynomialFeatures(degree=degree),\n      LinearRegression()\n    )\n    model.fit(train.NA_Sales.values.reshape(-1,1), train.EU_Sales)\n    \n    # Valuta il modello appena ottenuto\n    train_score = model.score(train.NA_Sales.values.reshape(-1,1), train.EU_Sales)\n    test_score = model.score(test.NA_Sales.values.reshape(-1,1), test.EU_Sales)\n    norm = np.linalg.norm(model.named_steps[\"linearregression\"].coef_)\n    results.append([train_score, test_score, norm])\n    \n    plot = axs[(degree-1) // 3, (degree-1) % 3]\n    plot.scatter(train.NA_Sales,train.EU_Sales)\n    plot.plot(X_seq,model.predict(X_seq),color=\"black\")\n    plot.set_title(\"Polynomial regression with degree \"+str(degree))\n\nres_df = pd.DataFrame(data=results, columns=[\"training score\", \"validation score\", \"norm\"])\nres_df[[\"training score\", \"validation score\", \"norm\"]]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Possiamo notare che il grado 3 è quello che sembra approssimare più correttamente l'andamento dei dati. Dal grado 4 in poi invece è evidente un overfitting, che porta la curva a non avere un andamento regolare ma a farsi \"guidare\" eccessivamente dai dati di training."},{"metadata":{},"cell_type":"markdown","source":"Vediamo come si comporta una Ridge regression applicata al nostro dataset al variare di alpha.\nPer semplicità ridurrò il numero di gradi considerati, mostrando solo i gradi 1, 3, 5 e 7."},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\nfrom sklearn.linear_model import Ridge\n\nalphas = np.logspace(-10, 0.1, 200)\n\n# Configurazione necessaria per disegnare i grafici\nX_seq = np.linspace(train.NA_Sales.values.min(),train.NA_Sales.values.max(),300).reshape(-1,1) # crea dei valori adatti per il plot della curva ideale\nfig, axs = plt.subplots(2, 4, figsize=(30, 10)) # divide la figura in quadranti\n\nfor ax in fig.get_axes():\n    ax.label_outer() # \"Raggruppa\" le etichette degli assi: mostra solo quelle degli assi più esterni\n\n\nfor degree in range(1, 8, 2):\n    results = []\n    \n    for alpha in alphas:\n        model = make_pipeline(\n          PolynomialFeatures(degree=degree),\n          Ridge(alpha, normalize=True)\n        )\n        model.fit(train.NA_Sales.values.reshape(-1,1), train.EU_Sales)\n\n        # Valuta il modello appena ottenuto\n        train_score = model.score(train.NA_Sales.values.reshape(-1,1), train.EU_Sales)\n        test_score = model.score(test.NA_Sales.values.reshape(-1,1), test.EU_Sales)\n        norm = np.linalg.norm(model.named_steps[\"ridge\"].coef_)\n        results.append([alpha, train_score, test_score, norm])\n    \n    res_df = pd.DataFrame(data=results, columns=[\"alpha\", \"training score\", \"validation score\", \"norm\"])\n    res_df[[\"alpha\", \"training score\", \"validation score\", \"norm\"]]\n    \n    # scores / alpha\n    plot = axs[0, (degree-1) // 2]\n    plot.set(xlabel=\"Alpha\", ylabel=\"Score\", xscale=\"log\")\n    plot.plot(res_df[\"alpha\"], res_df[\"validation score\"], label=\"Validation\")\n    plot.plot(res_df[\"alpha\"], res_df[\"training score\"], label=\"Training\")\n    plot.set_title(\"Ridge regression with degree \"+str(degree))\n    plot.legend()\n    \n    \n    # norm / alpha\n    plot = axs[1, (degree-1) // 2]\n    plot.set(xlabel=\"Alpha\", ylabel=\"Norm\", xscale=\"log\")\n    plot.plot(res_df[\"alpha\"], res_df[\"norm\"])\n    plot.set_title(\"Ridge regression with degree \"+str(degree))\n    \n    \n#     min_score = res_df[\"validation score\"].min()\n#     max_score = res_df[\"validation score\"].max()\n#     print(\"min score: {}, max score: {} [delta {}]\\n\".format(min_score, max_score, max_score - min_score ))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Osservazioni sui risultati\n- Nel caso specifico, aumentare il valore di alpha non porta un grande beneficio nello score.\n- Si può notare come aumentare il valore di alpha oltre ad una certa soglia porta ad un netto peggioramento dello score sia sui dati di training che su quelli di validazione, questo perché cercare di ammorbidire troppo la curva causa un forte underfitting.\n- Un alpha alto dovrebbe diminuire il valore della norma dei coefficienti, ma si può osservare che l'andamento non è regolare: è necessario quindi testare accuratamente il valore di alpha più adatto.\n- Più il grado del polinomio è alto (e quindi più la regressione è soggetta ad overfitting) e più alpha ha un effetto positivo sullo score.\n- Nel caso di grado 1 l'aumento di alpha generalizza meglio il modello: lo score sui dati di training peggiora ma migliora la capacità predittiva sui dati di test.\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}