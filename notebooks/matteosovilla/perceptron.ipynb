{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Perceptron\nIl notebook contiene l'implementazione di un perceptron binario. La classe espone i metodi `fit`, `score` e `predict`, che funzionano in maniera analoga a quelli forniti da un tipico modello sklearn. Il codice è commentato con ulteriori dettagli"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nfrom tqdm import trange\n\"\"\"\ntrange serve a disegnare barre di avanzamento. \nPer esempi di uso si rimanda a https://medium.com/better-programming/python-progress-bars-with-tqdm-by-example-ce98dbbc9697\n\"\"\"\nfrom numpy import sign\n\nclass Perceptron:\n\n  def __init__(self, random_state=None, max_step=100, rate=0.0001):\n    \"\"\"\n    random_state permette di rendere ripetibili i risultati ottenuti pur utilizzando una componente casuale.\n    come criterio di stop si considera il numero massimo di passi, si potrebbero valutare criteri più fini\n    basandosi sugli score del modello (es: negli ultimi N passi il miglioramento è stato minore di una soglia)\n    \"\"\"\n    self.rate = rate\n    self.rng = np.random.RandomState(seed=random_state)\n    self.max_step = max_step\n    self.rate = rate\n    self.best_score = 0\n\n  def _perceptron_step(self, x, y):\n    \"\"\"\n    passo base del perceptron, aggiorna i diversi pesi w in base al rate\n    \"\"\"\n    for i, p in enumerate(x):\n      # aggiungo 1 per la costante b\n      p = np.append([1.0], p)\n      t = y[i]\n      o = self._output(p)\n      if o != t:\n        self.w = self.w + self.rate * (t - o) * p\n\n  def _output(self, p):\n    return sign(np.dot(p, self.w))\n\n  def score(self, x, y):\n    \"\"\"\n    score restituisce l'accuratezza media, ovvero il numero di casi correttamente etichettati diviso per il numero totale di test\n    \"\"\"\n    correct = 0\n    for i, p in enumerate(x):\n      p = np.append([1.0], p)\n      if self._output(p) == y[i]:\n        correct += 1\n    return correct / len(y)\n  \n  def fit(self, x, y):\n    \"\"\"\n    fit genera casualmente un vettore di pesi w e ripete max_pass volte il perceptron.\n    mantiene il miglior valore di w\n    \"\"\"\n    # + 1 perchè un peso corrisponde alla costante b (traslazione della retta)\n    self.w = self.rng.random_sample(x.shape[1] + 1)\n    with trange(self.max_step) as t:\n      for i in t:\n        self._perceptron_step(x, y)\n        score = self.score(x, y)\n        t.set_description(f\"step {i}\")\n        t.set_postfix(score=score)\n        if score > self.best_score:\n          self.best_score = score\n          self.best_w = self.w\n        if score == 100:\n          break\n    self.w = self.best_w\n  \n  def predict(self, x):\n    y = []\n    for p in x:\n      y.append(self._output(p))\n    return np.array(y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Applicazione ad un dataset\nApplico ora il perceptron ad un dataset. Si tratta dei dati relativi ai primi 10 minuti di partita nelle leghe più alte del videogioco League of Legends.\nDallo stato del gioco al 10 minuto è richiesto di predire la vittoria di una delle due squadre.\n\n> NOTA: la fase di training impiega poco più di 5 minuti per completarsi"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n\n\nfrom sklearn.model_selection import train_test_split\n\n\ndf = pd.read_csv('../input/league-of-legends-diamond-ranked-games-10-min/high_diamond_ranked_10min.csv')\n\n# devo preprocessare i dati perché le classi siano +1 e -1\ndf[\"blueWins\"] = df[\"blueWins\"].replace([0],-1)\ndf = df.drop(columns=['gameId'])\n\ndisplay(df.head())\n\ntrain, test = train_test_split(df, test_size=0.2, random_state=0)\n\n# separo i dati sulle vittorie dal resto del dataset\ny_train = train[\"blueWins\"].values\ny_test = test[\"blueWins\"].values\nx_train = train.drop(columns=['blueWins']).values\nx_test = test.drop(columns=['blueWins']).values\n\nprint(f\"Dimensione del dataset di training: {train.size}\\n\")\n\nmodel = Perceptron(random_state=1, max_step=1000, rate=0.000001)\nmodel.fit(x_train, y_train)\nscore = model.score(x_test, y_test)\n\nprint(f\"Score finale: {score}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Si è ottenuto un modello capace di prevedere correttamente il risultato della partita in più del 70% dei casi, il che suggerisce una buona dipendenza del risultato del match dalle sue prime fasi di gioco."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}