{"cells":[{"metadata":{"_execution_state":"idle","_uuid":"e18384bf55f7da0c169a2cf63f0eb612257ea224","_cell_guid":"eba1d8ac-0984-afda-7f43-224d990b8861","trusted":true,"collapsed":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nimport sklearn\nfrom collections import Counter\nimport glob\nimport pickle\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential, Model\nfrom keras.layers import Lambda, Dense, Dropout, Activation, Flatten, Input, Reshape\nfrom keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, UpSampling2D\nfrom mpl_toolkits.axes_grid1 import AxesGrid\nfrom sklearn.metrics import confusion_matrix\nfrom keras import backend as K\nfrom keras.losses import mse, binary_crossentropy\nfrom keras.optimizers import SGD, Adam\nfrom random import shuffle\n\ntrain = True\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_execution_state":"idle","_uuid":"a6be663d0d62477f827298ba2fb776f79cc6c692","_cell_guid":"5dd1c1a3-f144-8518-1e41-4217d0690f62","trusted":true,"collapsed":true},"cell_type":"code","source":"pic_size = 64\ndef load_data_set(df, n):\n    pics, labels = [], []\n    i = 0\n    for pic in df['image_id']:\n        if i > n:\n            break\n        else:\n            i+=1\n        pic_url = \"../input/celeba-dataset/img_align_celeba/img_align_celeba/\"+pic\n        temp = cv2.imread(pic_url)\n        temp = cv2.resize(temp, (pic_size,pic_size)).astype('float32') / 255.\n        pics.append(temp)\n        labels.append(df[df['image_id'] == pic].values)\n    X = np.array(pics)\n    y = np.array(labels)\n    y = y.reshape(y.shape[0], y.shape[2])\n    print(\"Data set\", X.shape, y.shape)\n    return X, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"30398c32f755c56f0402fe12fd88de923e81abf1","scrolled":true,"collapsed":true},"cell_type":"code","source":"attr = pd.read_csv(\"../input/celeba-dataset/list_attr_celeba.csv\")\nfeature_dict = {k:v for v,k in enumerate(attr.columns)}\nn = 10000\nX, y = load_data_set(attr, n)\n\nprint(feature_dict)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a13387794c8a5efd973ea157787e978836f087e2","_cell_guid":"7e21a1e1-14e4-8937-f9d9-98956f7a6f45","trusted":true,"collapsed":true},"cell_type":"code","source":"def sampling(args):\n    \"\"\"Reparameterization trick by sampling fr an isotropic unit Gaussian.\n    # Arguments:\n        args (tensor): mean and log of variance of Q(z|X)\n    # Returns:\n        z (tensor): sampled latent vector\n    \"\"\"\n\n    z_mean, z_log_var = args\n    batch = K.shape(z_mean)[0]\n    dim = K.int_shape(z_mean)[1]\n    # by default, random_normal has mean=0 and std=1.0\n    epsilon = K.random_normal(shape=(batch, dim))\n    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n\ndef create_VAE(input_shape):\n    image_size = input_shape[1]\n    original_dim = image_size * image_size\n    inputs = Input(shape=input_shape)\n    print(inputs.shape)\n    x = Conv2D(32, (3, 3), padding='same', activation='relu')(inputs)\n    print(x.shape)\n    x = Conv2D(32, (3, 3), padding='same', activation='relu')(x)\n    print(x.shape)\n    x = AveragePooling2D(pool_size=(2, 2))(x)\n    print(x.shape)\n    x = Dropout(0.2)(x)\n    \n    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n    print(x.shape)\n    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n    print(x.shape)\n    x = AveragePooling2D(pool_size=(2, 2))(x)\n    print(x.shape)\n    x = Dropout(0.2)(x)\n    \n    x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n    print(x.shape)\n    x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n    print(x.shape)\n    x = AveragePooling2D(pool_size=(2, 2))(x)\n    print(x.shape)\n    x = Dropout(0.2)(x)\n    \n    x = Flatten()(x)\n    print(x.shape)\n    x = Dense(pic_size, activation='relu')(x)\n    print(x.shape)\n    \n    latent_dim = 20\n    \n    latent_mean = Dense(latent_dim)(x)\n    print(latent_mean.shape)\n    latent_log_variance = Dense(latent_dim)(x)\n    print(latent_log_variance.shape)\n    \n    latent_sample = Lambda(sampling)([latent_mean, latent_log_variance])\n    print(latent_sample.shape)\n    \n    encoder = Model(inputs, [latent_mean, latent_log_variance, latent_sample])\n    \n    latent_inputs = Input(shape=(latent_dim,))\n    print(latent_inputs.shape)\n    x = Dense(8*8*pic_size, activation='relu')(latent_inputs)\n    print(x.shape)\n    x = Reshape((8,8,pic_size))(x)\n    print(x.shape)\n    x = UpSampling2D((2, 2))(x)\n    print(x.shape)\n    x = Conv2D(256, (3, 3), padding='same', activation='relu')(x)\n    print(x.shape)\n    x = Conv2D(256, (3, 3), padding='same', activation='relu')(x)\n    print(x.shape)\n    \n    x = UpSampling2D((2, 2))(x)\n    print(x.shape)\n    x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n    print(x.shape)\n    x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n    print(x.shape)\n    \n    x = UpSampling2D((2, 2))(x)\n    print(x.shape)\n    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n    print(x.shape)\n    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n    print(x.shape)\n    \n    outputs = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n    print(outputs.shape)\n    \n    decoder = Model(latent_inputs, outputs)\n    outputs = decoder(encoder(inputs)[2])\n    vae = Model(inputs, outputs)\n    \n    reconstruction_loss = binary_crossentropy(inputs, outputs) * original_dim\n    reconstruction_loss = K.mean(reconstruction_loss)\n    print(reconstruction_loss)\n    kl_loss = 1 + latent_log_variance - K.square(latent_mean) - K.exp(latent_log_variance)\n    kl_loss = K.sum(kl_loss, axis=-1)\n    kl_loss *= -0.5\n    print(kl_loss)\n    vae_loss = K.mean(reconstruction_loss + kl_loss)\n    print(vae_loss)\n    vae.add_loss(vae_loss)\n    return vae, encoder, decoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9efaf78fdc67c337177028afb2390d7c9efbcd5","collapsed":true},"cell_type":"code","source":"vae, encoder, decoder = create_VAE(input_shape=(pic_size,pic_size,3))\nvae.compile(optimizer='adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6d7811c07dbba5dbf70a07b8755b0d38490c51e0","scrolled":false,"collapsed":true},"cell_type":"code","source":"if train:\n    #vae.load_weights(\"../input/myweights/CVAE.h5\")\n    epochs = 100\n    for i in range(0,epochs):\n        print(i)\n        vae.fit(X, batch_size=32, epochs=1, verbose = 0)\n        vae.save_weights(\"CVAE.h5\")\n        encoder.save_weights(\"CVE.h5\")\n        decoder.save_weights(\"CVD.h5\")\n    vae.fit(X, batch_size=32, epochs=1, verbose = 1)\nelse:\n    vae.load_weights(\"../input/myweights/CVAE.h5\")\n    vae.fit(X, batch_size=32, epochs=1, verbose = 1)\n    vae.save_weights(\"CVAE.h5\")\n    encoder.save_weights(\"CVE.h5\")\n    decoder.save_weights(\"CVD.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ad89780b01467bf0f9c0e828a7817cee6165d93","collapsed":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\n\nimage_test = X[6]\nimage_reconstruction = vae.predict(np.expand_dims(image_test, axis = 0))[0]\n\nz = np.array(encoder.predict(X)[2])\n\npca = PCA(n_components=20).fit(z)\nz_pca = pca.transform(z)\nz_female = z_pca[y[:,feature_dict['Male']] == -1]\nz_avg_female_pca = np.mean(z_female, axis = 0)\nX_avg_female = decoder.predict(np.expand_dims(pca.inverse_transform(z_avg_female_pca), axis = 0))[0]\n\nz_male = z_pca[y[:,feature_dict['Male']] == 1]\nz_avg_male_pca = np.mean(z_male, axis = 0)\nX_avg_male = decoder.predict(np.expand_dims(pca.inverse_transform(z_avg_male_pca), axis = 0))[0]\n\nz_glasses = z_pca[y[:,feature_dict['Eyeglasses']] == 1]\nz_avg_glasses_pca = np.mean(z_glasses, axis = 0)\nX_avg_glasses = decoder.predict(np.expand_dims(pca.inverse_transform(z_avg_glasses_pca), axis = 0))[0]\n\nz_not_glasses = z_pca[y[:,feature_dict['Eyeglasses']] == -1]\nz_avg_not_glasses_pca = np.mean(z_not_glasses, axis = 0)\n\nz_reconstruction_w_glasses_pca = z_pca[6] + z_avg_glasses_pca - z_avg_not_glasses_pca\nX_reconstruction_w_glasses = decoder.predict(np.expand_dims(pca.inverse_transform(z_reconstruction_w_glasses_pca), axis = 0))[0]\n\nz_reconstruction_not_man_pca = z_pca[6] - z_avg_male_pca\nX_reconstruction_not_man_pca = decoder.predict(np.expand_dims(pca.inverse_transform(z_reconstruction_not_man_pca), axis = 0))[0]\n\nz_reconstruction_woman_pca = z_reconstruction_not_man_pca + z_avg_female_pca\nX_reconstruction_woman_pca = decoder.predict(np.expand_dims(pca.inverse_transform(z_reconstruction_woman_pca), axis = 0))[0]\n\nfig  = plt.figure(figsize=(20,20))\n\nplt.subplot(2,4,1)\nplt.imshow(cv2.cvtColor(image_test, cv2.COLOR_BGR2RGB))\nplt.subplot(2,4,2)\nplt.imshow(cv2.cvtColor(image_reconstruction, cv2.COLOR_BGR2RGB))\nplt.subplot(2,4,3)\nplt.imshow(cv2.cvtColor(X_avg_female, cv2.COLOR_BGR2RGB))\nplt.subplot(2,4,4)\nplt.imshow(cv2.cvtColor(X_avg_male, cv2.COLOR_BGR2RGB))\nplt.subplot(2,4,5)\nplt.imshow(cv2.cvtColor(X_avg_glasses, cv2.COLOR_BGR2RGB))\nplt.subplot(2,4,6)\nplt.imshow(cv2.cvtColor(X_reconstruction_w_glasses, cv2.COLOR_BGR2RGB))\nplt.subplot(2,4,7)\nplt.imshow(cv2.cvtColor(X_reconstruction_not_man_pca, cv2.COLOR_BGR2RGB))\nplt.subplot(2,4,8)\nplt.imshow(cv2.cvtColor(X_reconstruction_woman_pca, cv2.COLOR_BGR2RGB))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b75ac433b7c05faa62d3dc1e78d89ca9847d6a15"},"cell_type":"code","source":"vae.save_weights(\"CVAE.h5\")\nencoder.save_weights(\"CVE.h5\")\ndecoder.save_weights(\"CVD.h5\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"_change_revision":0,"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"_is_fork":false},"nbformat":4,"nbformat_minor":1}