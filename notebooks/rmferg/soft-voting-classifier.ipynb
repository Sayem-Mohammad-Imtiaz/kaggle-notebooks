{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"6f61a65a-2f55-61e4-8e4f-aa3ab34371ce"},"source":"We'll try to predict diabetes outcomes (0, 1) using an unweighted soft voting ensemble classifier (sklearn's VotingClassifier class with `voting='soft'`).  For a given sample, this outputs the class label with highest averaged probability predicted by the component classifiers.  The component classifiers used here will be:\n\n - Decision tree\n - Gaussian naive Bayes\n - RBF kernel support vector machine\n - K-nearest neighbors"},{"cell_type":"markdown","metadata":{"_cell_guid":"ca15d60c-979a-6af6-3330-f1956dc1587a"},"source":"Read in data.  Split into training and testing subsets (70/30) and z-score standardize the features."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"22e92d5d-a96e-90a1-e07e-8e2256017689"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import roc_auc_score, accuracy_score\n\n\ndf = pd.read_csv('../input/diabetes.csv')\n\n\nX = df.loc[:, ['Pregnancies','Glucose','BloodPressure','SkinThickness',\n           'Insulin','BMI', 'DiabetesPedigreeFunction','Age']].values\ny = df.loc[:, 'Outcome'].values\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n\nsc = StandardScaler()\nsc.fit(X_train)\nX_train_std = sc.transform(X_train)\nX_test_std = sc.transform(X_test)"},{"cell_type":"markdown","metadata":{"_cell_guid":"e3c7eecb-a4bb-670f-431c-fa25069618c2"},"source":"We'll try to optimize some of the classifiers' hyperparameters (the SVM's C and gamma, max tree depth, and k for the KNN) using a 5-fold cross-validation grid search on our training set.  Print out best accuracy score, hyperparameters of best classifier, and run time.  Then, we'll evaluate the best classifier on the test set."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e442c6e3-4caf-87d4-84f0-2a89a7de4260"},"outputs":[],"source":"import time\nt0 = time.clock()\n\ntree = DecisionTreeClassifier(random_state=1)\nsvm = SVC(probability=True, kernel='rbf')\nknn = KNeighborsClassifier(p=2, metric='minkowski')\nnb = GaussianNB()\neclf = VotingClassifier(estimators=[('tree', tree), ('svm', svm), ('knn', knn),('nb', nb)], voting='soft')\nparam_range10 = [.001, .01, 1, 10, 100]\nparam_range1 = list(range(3, 8))\nparam_grid = [{'svm__C':param_range10, 'svm__gamma':param_range10, 'tree__max_depth':param_range1, \n               'knn__n_neighbors':param_range1}]\n\ngs = GridSearchCV(estimator=eclf, param_grid=param_grid, scoring='accuracy', cv=5)\ngs = gs.fit(X_train_std, y_train)\n\nprint('Best accuracy score: %.3f \\nBest parameters: %s' % (gs.best_score_, gs.best_params_))\n\nclf = gs.best_estimator_\nclf.fit(X_train_std, y_train)\nt1 = time.clock()\nprint('Running time: %.3f' % (t1-t0))"},{"cell_type":"markdown","metadata":{"_cell_guid":"9c261ae5-8b47-5d16-8877-98e73ebe17d1"},"source":"Our best classifier is ~77% accurate.  Let's test it out."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d087fd6e-8433-4572-df23-093a252ab8ac"},"outputs":[],"source":"from sklearn.metrics import confusion_matrix\n\ny_pred = clf.predict(X_test_std)\nprint('ROC AUC: %.3f \\nAccuracy: %.3f \\nConfusion Matrix:' % (roc_auc_score(y_true=y_test, y_score=y_pred),\n                                         accuracy_score(y_true=y_test, y_pred=y_pred)))\nprint(confusion_matrix(y_true=y_test, y_pred=y_pred))"},{"cell_type":"markdown","metadata":{"_cell_guid":"0692fd08-18af-4560-07a6-a84962113b75"},"source":"Accuracy actually bumped up a bit to 80% in our test set.  The confusion matrix tells us that the classifier is weak in recall (~.6) relative to precision (~.8)."}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}