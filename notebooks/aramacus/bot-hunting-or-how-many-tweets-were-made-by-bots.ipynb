{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Recent [research](https://www.scs.cmu.edu/news/nearly-half-twitter-accounts-discussing-reopening-america-may-be-bots) by Carnegie Mellon University have proposed that bots may be responsible for up to 50% of tweets for particular topics. Could bots be trying to push certain narritives about particular stocks too and is it possible to find these bots? In this notebook I show my attempt to answer this question by finding bots based on a set of common-sense features and criterias. Then I compare how the Bots tweet compare to average in terms of sentiment correlation with stock price. Suspected bot tweets have significantly higher correlation to stock price than the average sentiment across all writers in the dataset.\n\n\n<a id=\"top\"></a>\n\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n    \n<center><h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background-color:#1E90FF; border:0; color:#FFF5EE' role=\"tab\" aria-controls=\"home\">Content</h2></center>\n\n1. [Data Exploration](#1)\n2. [Average Sentiment and Stock Price](#2)\n3. [Feature Engineering](#3)\n4. [\"If it tweets like a bot, it is a bot\"](#4)\n5. [How does Bot sentiment correlates with Stock Price?](#5)\n    \n    \nIf you are interested in playing with time series, check out my [dataset on electricity prices and demand](https://www.kaggle.com/aramacus/electricity-demand-in-victoria-australia) in Victoria (Australian state). And please upvote it if you like it.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"pip install yfinance","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\nimport yfinance as yf\n\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\n\nimport re\nimport os\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_columns', 30)\nsns.set_context(\"paper\", font_scale=2)\n\nPATH = \"/kaggle/input/tweets-about-the-top-companies-from-2015-to-2020/\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"1\"></a><center><h2 style='background-color:#1E90FF; border:0; color:#FFF5EE'>Data Exploration</h2></center>","metadata":{}},{"cell_type":"code","source":"company = pd.read_csv(os.path.join(PATH, \"Company.csv\"))\ncompany = company.set_index(\"ticker_symbol\").to_dict()[\"company_name\"]\ncompany","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tweet = pd.read_csv(os.path.join(PATH, \"Tweet.csv\"))\ntweet.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It would be convenient to convert \"post_date\" to the datetime format right away.","metadata":{}},{"cell_type":"code","source":"tweet['datetime'] = pd.to_datetime(tweet['post_date'], unit='s')\ntweet = tweet.drop(['post_date'], axis=1, inplace=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"company_tweet = pd.read_csv(os.path.join(PATH, \"Company_Tweet.csv\"))\ncompany_tweet.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Some of the tweets mention more than one company of interest:","metadata":{}},{"cell_type":"code","source":"company_tweet.loc[company_tweet['ticker_symbol'] == 'GOOGL', 'ticker_symbol'] = 'GOOG'\nprint(\"Total records: {} | Unique tweet indexes: {}\".format(len(company_tweet), company_tweet['tweet_id'].nunique()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tweet.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lets count missing values in tweet table.","metadata":{}},{"cell_type":"code","source":"tweet.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Less than 2% of tweet records have no poster credentials. Drop missing values and count uniqie writers.","metadata":{}},{"cell_type":"code","source":"tweet = tweet.dropna()\nprint(f\"Number of writers: {tweet['writer'].nunique()}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lets calculate the number of duplicates among all the tweets.","metadata":{}},{"cell_type":"code","source":"print(\"Percent of duplicated tweets: {:.2f} %\".format(sum(tweet['body'].duplicated())/len(tweet) * 100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To get a better sense about writer activity, lets build a histogram for tweet numbers by writers.","metadata":{}},{"cell_type":"code","source":"stats = tweet[['writer', 'tweet_id']].groupby('writer').agg(\"count\").rename(columns={'tweet_id' : 'tweet_count'})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set_context(\"paper\", font_scale=2)\n\nplt.figure(figsize=(12, 8))\n\nsns.histplot(data=stats, x='tweet_count', bins=50, log_scale=True)\nplt.yscale('log')\nplt.title(\"Posts count histogram\")\nplt.xlabel(\"Number of users\")\nplt.ylabel(\"Tweet count\")\nNone","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"2\"></a><center><h2 style='background-color:#1E90FF; border:0; color:#FFF5EE'>Average Sentiment and Stock Price</h2></center>","metadata":{}},{"cell_type":"markdown","source":"First, lets use NLTK Sentiment Intensity Analyser to evaluate the sentiment for each tweet. Even though Sentiment Analyser does not compain when fed a raw text, lets help it a bit with a mild tweet text cleanup.","metadata":{}},{"cell_type":"code","source":"sentiment_nltk = SentimentIntensityAnalyzer()\n\n# Mild cleaning: remove weblinks, $ticker_symbol, # symbol from hashtags, remove excessive spaces\ntweet['prep_body'] = tweet['body'].replace(r\"https?:\\S+|http?:\\S+|www?:\\S+\", '', regex=True).replace(r\"[@#\\$][a-zA-Z]+\", '', regex=True).replace(r\"\\s\\s+\", ' ', regex=True).str.strip()\n\ntweet['positive_sentiment'] = tweet['prep_body'].apply(lambda x: sentiment_nltk.polarity_scores(x)['pos'])\ntweet['negative_sentiment'] = tweet['prep_body'].apply(lambda x: sentiment_nltk.polarity_scores(x)['neg'])\ntweet['total_sentiment'] = tweet['prep_body'].apply(lambda x: sentiment_nltk.polarity_scores(x)['compound'])\n\ntweet.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It is interesting to look again on duplicates in prepared tweets, after hashtags and weblinks were dropped.","metadata":{}},{"cell_type":"code","source":"print(\"Percent of cleaned duplicated tweets: {:.2f} %\".format(sum(tweet['prep_body'].duplicated())/len(tweet) * 100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After pre-processing the proportion of duplicated tweets increased from 10.35% to 25.25%. This indicates templates in about 15% of tweets, which could indicate bots.<br>\n\nNext, lets get the stock prices using Yahoo Finance API. For the sake of simplicity, consider only Closing price.","metadata":{}},{"cell_type":"code","source":"tweet['date'] = tweet['datetime'].dt.date\n\nprices = yf.download(tickers=\" \".join([st for st in company.keys() if st != \"GOOGL\"]),\n    start=tweet['date'].min().strftime('%Y-%m-%d'),\n    end=tweet['date'].max().strftime('%Y-%m-%d'),\n    interval='1d'\n).reset_index()\n\nprices = prices.drop([\"Adj Close\", \"Volume\", \"Open\", \"High\", \"Low\"], axis=1)\n\nprices.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Aggregate sentiment from tweet by date and matrch with prices by date.","metadata":{}},{"cell_type":"code","source":"stats = tweet[['date', 'positive_sentiment', 'negative_sentiment', 'total_sentiment']].groupby('date').mean()\n\nprices['date'] = prices['Date'].dt.date\nprices = prices.drop(['Date'], axis=1)\nstats = prices.join(stats, how='inner', on='date')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Calculate sentiment-price correlation coefficient for closing prices","metadata":{}},{"cell_type":"code","source":"price_cols = [('Close', ticker) for ticker in company.keys() if ticker != 'GOOGL']\nsentim_cols = ['positive_sentiment', 'negative_sentiment', 'total_sentiment']\nstats[price_cols + sentim_cols].corr().loc[sentim_cols, price_cols].style.background_gradient(cmap='coolwarm')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To further illustrate this correlation, below are the plots with normalized stock price and an overall positive sentiment as a function of date.","metadata":{}},{"cell_type":"code","source":"colors = {\"AMZN\" : \"tab:red\", \n          \"GOOG\" : \"tab:blue\", \n          \"AAPL\" : \"tab:orange\", \n          \"MSFT\" : \"tab:purple\", \n          \"TSLA\" : \"tab:green\"}\n\nplt.figure(figsize=(15, 5))\n\nt = \"AMZN\"\n\nsns.lineplot(x=stats[\"date\"], y=stats[(\"Close\", t)]/max(stats[(\"Close\", t)]), color=colors[t], label=company[t])\nsns.lineplot(x=stats[\"date\"], y=stats[\"positive_sentiment\"]/max(stats[\"positive_sentiment\"]), color=\"tab:cyan\", label=\"Positive Sentiment\")\nplt.title(company[t])\nplt.xlabel(\"Date\")\nplt.ylabel(\"Arbitrary units\")\nNone","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 5))\n\nt = \"GOOG\"\n\nsns.lineplot(x=stats[\"date\"], y=stats[(\"Close\", t)]/max(stats[(\"Close\", t)]), color=colors[t], label=company[t])\nsns.lineplot(x=stats[\"date\"], y=stats[\"positive_sentiment\"]/max(stats[\"positive_sentiment\"]), color=\"tab:cyan\", label=\"Positive Sentiment\")\nplt.title(company[t])\nplt.xlabel(\"Date\")\nplt.ylabel(\"Arbitrary units\")\nNone","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 5))\n\nt = \"AAPL\"\n\nsns.lineplot(x=stats[\"date\"], y=stats[(\"Close\", t)]/max(stats[(\"Close\", t)]), color=colors[t], label=company[t])\nsns.lineplot(x=stats[\"date\"], y=stats[\"positive_sentiment\"]/max(stats[\"positive_sentiment\"]), color=\"tab:cyan\", label=\"Positive Sentiment\")\nplt.title(company[t])\nplt.xlabel(\"Date\")\nplt.ylabel(\"Arbitrary units\")\nNone","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 5))\n\nt = \"MSFT\"\n\nsns.lineplot(x=stats[\"date\"], y=stats[(\"Close\", t)]/max(stats[(\"Close\", t)]), color=colors[t], label=company[t])\nsns.lineplot(x=stats[\"date\"], y=stats[\"positive_sentiment\"]/max(stats[\"positive_sentiment\"]), color=\"tab:cyan\", label=\"Positive Sentiment\")\nplt.title(company[t])\nplt.xlabel(\"Date\")\nplt.ylabel(\"Arbitrary units\")\nNone","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 5))\n\nt = \"TSLA\"\n\nsns.lineplot(x=stats[\"date\"], y=stats[(\"Close\", t)]/max(stats[(\"Close\", t)]), color=colors[t], label=company[t])\nsns.lineplot(x=stats[\"date\"], y=stats[\"positive_sentiment\"]/max(stats[\"positive_sentiment\"]), color=\"tab:cyan\", label=\"Positive Sentiment\")\nplt.title(company[t])\nplt.xlabel(\"Date\")\nplt.ylabel(\"Arbitrary units\")\nNone","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Summary\n\nThere seems to be a fair bit of correlation between stock prices and sentiment. In terms of total sentiment, which consists of both positive and negative tweets, the correlation is between 44 and 54%.\n<p>For all stocks considered, mean daily positive sentiment had a higher correlation to prices compared to total mean daily sentiment with ranges between 50 and 55%. In general, negative sentiment had less of a correlation to prices with a notable exception of Tesla, that had much less correlation.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"3\"></a><center><h2 style='background-color:#1E90FF; border:0; color:#FFF5EE'>Feature Engineering</h2></center>","metadata":{}},{"cell_type":"markdown","source":"In case of twitter, an idea of influencing stock price via sentiment manipulation can be implemented via bot networks. Below I try to identify at least some of the accounts that could be bots.<br>\nTo keep track of writers tweeting patters, lets introduce a \"posters\" table, which will be filled in as this exploration proceeds. The first feature that may tell something about the writer is what is their peak hourly tweet rate.","metadata":{}},{"cell_type":"code","source":"tweet['hour'] = tweet['datetime'].dt.hour\ndata = tweet[['writer', 'hour', 'date', 'tweet_id']].groupby(['writer', 'hour', 'date']).count().reset_index().rename(columns={'tweet_id' : 'tweet_rate'})\n\ntweet = tweet.drop(['hour'], axis=1)\n\nindmax = data.groupby('writer').agg({'tweet_rate' : 'idxmax'})\nposters = data.iloc[indmax.tweet_rate].sort_values(by='tweet_rate').set_index('writer')\nposters = posters.drop(['hour', 'date'], axis=1).rename(columns={'tweet_rate' : 'max_tweet_rate'})\nposters","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next, lets get a mean tweet rate by each poster during each hour, from 0am to 23pm.","metadata":{}},{"cell_type":"code","source":"hours = data[['writer', 'hour', 'tweet_rate']].groupby(['writer', 'hour']).mean().sort_values(by='tweet_rate')\nhours = hours.reset_index().pivot(index='writer', columns='hour', values='tweet_rate').fillna(0)\nhours.columns.name = None\nposters = posters.join(hours, how='outer')\nposters.sort_values(by='max_tweet_rate').head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plot sample writers average hourly tweet rate (while active)","metadata":{}},{"cell_type":"code","source":"sns.set_context(\"paper\", font_scale=1)\n\ncolumns = list(range(24))\n\nnrows = 2\nncols = 3\nfig, axs = plt.subplots(nrows, ncols, figsize=(17, 12))\n\nsample_writers = ['PeteStock11', 'JimAndrews518', 'computer_hware', 'larryne', 'MarleyJayBiz', 'politicalHEDGE']\n\nfor i, writer in enumerate(sample_writers):\n    c = i // 2\n    r = i - nrows * c\n    \n    posters.loc[writer, columns].plot(kind='bar', ax=axs[r, c])\n    axs[r, c].set_title(writer)\n    axs[r, c].set_ylabel(\"average tweet rate\")\n    axs[r, c].set_xlabel(\"hour\")\n    \nplt.show()\nNone","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Average time between subsequent tweets\nToo short time between succesive tweets can indicate a machine authorship. To account for long abscence, such as vocations, limit to shortest 75% of time intervals (in seconds). For writers with only one tweet, assign the maximum value to the time between tweets \"mean_diff_sec\".","metadata":{}},{"cell_type":"code","source":"def in_qrange(ser, q):\n    return ser.between(*ser.quantile(q=q))\n\ntweet['timediff'] = tweet.sort_values('datetime', ascending=False).groupby(['writer']).datetime.diff(-1).dt.seconds.fillna(np.inf)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = tweet.loc[tweet['timediff'].transform(in_qrange, q=[0, 0.75]), ['writer', 'timediff']].groupby('writer').agg(['mean']).rename(columns={'mean' : 'mean_diff_sec'})\ndata.columns = data.columns.droplevel()\n\ntweet = tweet.drop(['timediff'], axis=1)\n\nposters = posters.join(data, on='writer', how='left').fillna(max(data['mean_diff_sec']))\nposters.loc[posters['mean_diff_sec'] == 0, 'mean_diff_sec'] = max(data['mean_diff_sec'])\nposters.sort_values(by='mean_diff_sec').head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fraction of non-original tweets","metadata":{}},{"cell_type":"code","source":"data = tweet.loc[tweet['prep_body'].duplicated(), ['writer', 'tweet_id']].groupby('writer').count().rename(columns={'tweet_id' : 'duplicate_posts'})\n\nposters = posters.join(tweet[['writer', 'tweet_id']].groupby('writer').count().rename(columns={'tweet_id' : 'total_posts'}), how='left')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"posters = posters.join(data, how='left').fillna(0)\nposters['duplicate_posts'] = posters['duplicate_posts']/posters['total_posts']\nposters.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Some of the conclusion whenever a poster is a bot or not can be drawn based on the collected features. For example: \n\n* abnormal hourly tweet rate (\"max_tweet_rate\") \n* too short mean time between successive tweets (\"mean_diff_sec\")\n* lack of hours with no tweets (too few hour columns, \"0\" to \"23\", when tweet rate was 0)\n* all tweets are among the duplicates (\"duplicate_posts\" = 1.0)\n\nWith a crude criteria, such as abnormal endurance (\"max_tweet_rate\" of 100 or more) or extreme typing speed (\"mean_diff_sec\" of 5 or less) or no sleep abilty (no hour columns with tweet rate of 3), some bots can be found.","metadata":{}},{"cell_type":"code","source":"columns = list(range(24))\nbot_check = pd.DataFrame(index=posters.index)\n\nbot_check[\"max_tweet_rate\"] = (posters[\"max_tweet_rate\"] > 100).astype(np.int8)\nbot_check[\"mean_diff_sec\"] = (posters[\"mean_diff_sec\"] < 10).astype(np.int8)\nbot_check[\"abscence_hours\"] = ((posters[columns] == 0).astype(int).sum(axis=1) < 3).astype(np.int8)\nbot_check[\"all_duplicates\"] = (posters[\"duplicate_posts\"] == 1).astype(np.int8)\n\nbot_check.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"max hourly tweet rate > 100 : {} writers\".format(sum(bot_check[\"max_tweet_rate\"])))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"mean time between tweets sec < 5 seconds : {} writers\".format(sum(bot_check[\"mean_diff_sec\"])))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"less than 3 hours of not tweeting : {} writers\".format(sum(bot_check[\"abscence_hours\"])))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"not a single original post : {} writers\".format(sum(bot_check[\"all_duplicates\"])))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"4\"></a><center><h2 style='background-color:#1E90FF; border:0; color:#FFF5EE'>\"If it tweets like a bot, it is a bot\"</h2></center>\n\nBootstraping: find all tweets from writers with at least a two flag in \"bot_check\". All other writers from \"bot_check\" that tweeted one of such tweets get a flag for \"tweet_like_a_bot\". Re-count writres with at least two flags.","metadata":{}},{"cell_type":"code","source":"bot_check[bot_check.sum(axis=1) > 1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On the first count, there are only 25 writers with two ore more flags.","metadata":{}},{"cell_type":"code","source":"bot_tweets = tweet.loc[tweet['writer'].isin(bot_check[bot_check.sum(axis=1) > 1].index), 'prep_body'].unique()\nbot_check['tweet_like_bot'] = bot_check.index.isin(tweet.loc[tweet['prep_body'].isin(bot_tweets), 'writer'].unique()).astype(np.int8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Percent of bots : {:.2f}%\".format(sum(bot_check.sum(axis=1) > 1)/len(posters)*100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bots = bot_check.loc[bot_check.sum(axis=1) > 1].index\ntweet['group'] = 'user'\ntweet.loc[tweet.writer.isin(bots), 'group'] = 'bot'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Summary\n\nThere seems to be 21.41%, or 29996 bots of 140131 uniqie writers in the dataset. This number was obtained via a two stage process. Firstly, four features were calculated for each writer:\n\n* abnormal hourly tweet rate (\"max_tweet_rate\") \n* too short mean time between successive tweets (\"mean_diff_sec\")\n* lack of hours with no tweets (too few hour columns, \"0\" to \"23\", when tweet rate was 0)\n* all tweets are among the duplicates (\"duplicate_posts\" = 1.0)\n\nNext, writers with at least two flags were deemed to be bots. At this stage there were only 25 such writers. Next, all their tweets were found and stored in the table \"bot_tweets\". Then, an additional feature, that determines whenever a writer posted one of the tweets from \"bot_tweets\". Finally, with five features writers were tallied again and those with at least two flags were deemed to be bots.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"5\"></a><center><h2 style='background-color:#1E90FF; border:0; color:#FFF5EE'>How does Bot sentiment correlates with Stock Price?</h2></center>","metadata":{}},{"cell_type":"code","source":"stats = tweet[tweet['group']==\"bot\"][['date', 'positive_sentiment', 'negative_sentiment', 'total_sentiment']].groupby('date').mean()\n\nstats = prices.join(stats, how='inner', on='date')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"price_cols = [('Close', ticker) for ticker in company.keys() if ticker != 'GOOGL']\nsentim_cols = ['positive_sentiment', 'negative_sentiment', 'total_sentiment']\nstats[price_cols + sentim_cols].corr().loc[sentim_cols, price_cols].style.background_gradient(cmap='coolwarm')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set_context(\"paper\", font_scale=2)\n\nplt.figure(figsize=(15, 5))\n\nt = \"AMZN\"\n\nsns.lineplot(x=stats[\"date\"], y=stats[(\"Close\", t)]/max(stats[(\"Close\", t)]), color=colors[t], label=company[t])\nsns.lineplot(x=stats[\"date\"], y=stats[\"positive_sentiment\"]/max(stats[\"positive_sentiment\"]), color=\"tab:olive\", label=\"Bots, Positive Sentiment\")\nplt.title(company[t])\nplt.xlabel(\"Date\")\nplt.ylabel(\"Arbitrary units\")\nNone","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 5))\n\nt = \"GOOG\"\n\nsns.lineplot(x=stats[\"date\"], y=stats[(\"Close\", t)]/max(stats[(\"Close\", t)]), color=colors[t], label=company[t])\nsns.lineplot(x=stats[\"date\"], y=stats[\"positive_sentiment\"]/max(stats[\"positive_sentiment\"]), color=\"tab:olive\", label=\"Bots, Positive Sentiment\")\nplt.title(company[t])\nplt.xlabel(\"Date\")\nplt.ylabel(\"Arbitrary units\")\nNone","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 5))\n\nt = \"AAPL\"\n\nsns.lineplot(x=stats[\"date\"], y=stats[(\"Close\", t)]/max(stats[(\"Close\", t)]), color=colors[t], label=company[t])\nsns.lineplot(x=stats[\"date\"], y=stats[\"positive_sentiment\"]/max(stats[\"positive_sentiment\"]), color=\"tab:olive\", label=\"Bots, Positive Sentiment\")\nplt.title(company[t])\nplt.xlabel(\"Date\")\nplt.ylabel(\"Arbitrary units\")\nNone","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 5))\n\nt = \"MSFT\"\n\nsns.lineplot(x=stats[\"date\"], y=stats[(\"Close\", t)]/max(stats[(\"Close\", t)]), color=colors[t], label=company[t])\nsns.lineplot(x=stats[\"date\"], y=stats[\"positive_sentiment\"]/max(stats[\"positive_sentiment\"]), color=\"tab:olive\", label=\"Bots, Positive Sentiment\")\nplt.title(company[t])\nplt.xlabel(\"Date\")\nplt.ylabel(\"Arbitrary units\")\nNone","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 5))\n\nt = \"TSLA\"\n\nsns.lineplot(x=stats[\"date\"], y=stats[(\"Close\", t)]/max(stats[(\"Close\", t)]), color=colors[t], label=company[t])\nsns.lineplot(x=stats[\"date\"], y=stats[\"positive_sentiment\"]/max(stats[\"positive_sentiment\"]), color=\"tab:olive\", label=\"Bots, Positive Sentiment\")\nplt.title(company[t])\nplt.xlabel(\"Date\")\nplt.ylabel(\"Arbitrary units\")\nNone","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Summary\n\nBots combined seem to be astonishingly more impactful than average for Google, Microsoft and Amazon in terms of positive sentiment and total sentiment. For these companies total sentiment by bot tweets seems to be up to 20-25% more impactful than average. For Apple total bot sentiment exhibits 10% increase compared to average, still a formidable effect. The correlation is significantly reduced for Tesla, where it differs from the average by only 1%.\n\n<p> Interestingly, there is a significant difference between negative sentiment from bot tweets compared to overall negative sentiment in terms of correlation to stock prices. Average negative sentiment was positively correlated with stock prices, while negative bot sentiment was negatively correlated to stock prices.\n    \n**Please upvote this notebook if you found this short exploration usefull or interesting.**","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}