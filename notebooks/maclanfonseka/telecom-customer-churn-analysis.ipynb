{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#importing libraries\nimport pandas as pd #data processing\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#load the data \nmydataset = pd.read_csv(\"../input/telecocustomerchurn/Telco-Customer-Churn.csv\")\nmydataset.head()\n\n#get the number of rows and cols\nmydataset.shape\n\n#datatypes of column \nprint(mydataset.dtypes)\n\n#get count of empty cells in cols\nprint(mydataset.isna().sum())\n\n#check for any missing null values\nprint (mydataset.isnull().values.any())\n\n#view satistics of my dataset\nprint(mydataset.describe())\n\n#converting TotalCharges into float type\nmydataset['TotalCharges'] = pd.to_numeric(mydataset['TotalCharges'], errors='coerce')\nmydataset['TotalCharges'] = mydataset['TotalCharges'].fillna(mydataset['TotalCharges'].median())\n\n# Convert SeniorCitizen from integer to string\nmydataset['SeniorCitizen'] = mydataset['SeniorCitizen'].apply(lambda x: 'Yes' if x==1 else 'No')\n\n#count of churn\nprint (mydataset['Churn'].value_counts())\n\n#visualzing the churn rate \nsns.countplot(mydataset['Churn'])\n\n\n#print all values of data types and their unique values \nfor column in mydataset.columns:\n    if mydataset[column].dtypes==object:\n        print(str(column)+ ' : '+ str(mydataset[column].unique()))\n        print (mydataset[column].value_counts())\n        print('------------------------------')\n        \n\n# Exploratory analysis on non-continuous features\nplt.figure(figsize=(15, 18))\n\nplt.subplot(4, 2, 1)\nsns.countplot('gender', data=mydataset, hue='Churn')\n\nplt.subplot(4, 2, 2)\nsns.countplot('SeniorCitizen', data=mydataset, hue='Churn')\n\nplt.subplot(4, 2, 3)\nsns.countplot('Partner', data=mydataset, hue='Churn')\n\nplt.subplot(4, 2, 4)\nsns.countplot('Dependents', data=mydataset, hue='Churn')\n\nplt.subplot(4, 2, 5)\nsns.countplot('PhoneService', data=mydataset, hue='Churn')\n\nplt.subplot(4, 2, 6)\nsns.countplot('PaperlessBilling', data=mydataset, hue='Churn')\n    \nplt.subplot(4, 2, 7)\nsns.countplot('StreamingMovies', data=mydataset, hue='Churn')\n\nplt.subplot(4, 2, 8)\nsns.countplot('StreamingTV', data=mydataset, hue='Churn')\n\nplt.figure(figsize=(15, 18))\n\nplt.subplot(4, 2, 1)\nsns.countplot('InternetService', data=mydataset, hue='Churn')\n\nplt.subplot(4, 2, 2)\nsns.countplot('DeviceProtection', data=mydataset, hue='Churn')\n\nplt.subplot(4, 2, 3)\nsns.countplot('TechSupport', data=mydataset, hue='Churn')\n\nplt.subplot(4, 2, 4)\nsns.countplot('OnlineSecurity', data=mydataset, hue='Churn')\n\nplt.subplot(4, 2, 5)\nsns.countplot('OnlineBackup', data=mydataset, hue='Churn')\n\nplt.subplot(4, 2, 6)\nsns.countplot('MultipleLines', data=mydataset, hue='Churn')\n\nplt.subplot(4, 2, 7)\ng = sns.countplot('PaymentMethod', data=mydataset, hue='Churn')\ng.set_xticklabels(g.get_xticklabels(), rotation=45);\n\nplt.subplot(4, 2, 8)\ng = sns.countplot('Contract', data=mydataset, hue='Churn')\ng.set_xticklabels(g.get_xticklabels(), rotation=45);\n\n\n\"\"\"It seems that the gender column doesn't have a big effect on the Chur rate.\n\nChurn: 50.73% Males, 49.26% Females\nNot Churn: 50.24% Males, 49.75% Females\n\nWe can drop the varibale 'gender' as it doesn't effect on churning'\"\"\"\n\n#remove some useless columns\nmydataset = mydataset.drop('customerID', axis = 1)\nmydataset = mydataset.drop('gender', axis =1)\n\n#get correlation between data\nmydataset.corr()\n\n#visualization of correlated data\nplt.figure(figsize=(10,10))\nsns.heatmap(mydataset.corr(), annot=True, cmap='coolwarm')\n#Due ToatlCharges highly correlated with MonthlyChrage and tenure, remove TotalCharge\nmydataset = mydataset.drop('TotalCharges', axis =1)\n\n\n# Create dummy variables for features with more than two classes\ndummy_data = pd.get_dummies(mydataset,drop_first=True)\nprint(dummy_data.head())\nprint(dummy_data.dtypes)\n\n#selecting features \nX = dummy_data.iloc[:, 0:28].values\nY = dummy_data.iloc[:, -1].values\n\n\n\"\"\"#transform data\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np\nfor column in mydataset.columns:\n    if mydataset[column].dtypes==np.number:\n        continue\n    mydataset[column]= LabelEncoder().fit_transform(mydataset[column])\n\nmydataset.head()\nY_stat = mydataset.iloc[:,-1]\nX_stat = mydataset.iloc[:,0:17]\"\"\"\n\nimport statsmodels.api as sm\nlogit_model = sm.Logit(Y,X)\nresult = logit_model.fit()\nprint(result.summary())\n\n\n\n#split the data into 75% training and 25% testing\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.25, random_state = 0)\n\n#preprocessing\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\n\n\n#logistic regression\nfrom sklearn.linear_model import LogisticRegression\nlogistic_reg = LogisticRegression(random_state = 0)\nlogistic_reg.fit(X_train, Y_train)\ny_pred = logistic_reg.predict(X_test)\nacc_lg = accuracy_score(Y_test, y_pred)\nprint(\"Accuracy: {}\".format(acc_lg))\nprint()\nprint(classification_report(Y_test,y_pred))\ncnf_matrix = metrics.confusion_matrix(Y_test,y_pred)\nprint(cnf_matrix)\n\n#Decision Trees\nfrom sklearn.tree import DecisionTreeClassifier\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\ny_pred = decision_tree.predict(X_test)\nacc_dt = accuracy_score(Y_test, y_pred)\nprint(\"Accuracy: {}\".format(acc_dt))\n#print(tree.plot_tree(decision_tree))\nprint()\nprint(classification_report(Y_test,y_pred))\ncnf_matrix = metrics.confusion_matrix(Y_test,y_pred)\nprint(cnf_matrix)\n\n\"\"\"\nfrom sklearn import tree\nfrom IPython.display import Image\nimport pydotplus\n\nfeatures =pd.concat( [dummy_data], axis=1)\nfeatures=features.drop('Churn', axis=1)\ndot_data= tree.export_graphviz(decision_tree,out_file=None,\n                filled=True, rounded=True,\n                special_characters=True, feature_names=features.columns)\n\ngraph = pydotplus.graph_from_dot_data(dot_data)  \n#Image(graph.create_png())\"\"\"\n\ndecision_tree = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\ndecision_tree  = decision_tree.fit(X_train,Y_train)\ny_pred = decision_tree.predict(X_test)\nacc_dt_new = accuracy_score(Y_test, y_pred)\nprint(\"Accuracy: {}\".format(acc_dt_new))\nprint(classification_report(Y_test,y_pred))\n\n#Support Vector Machine\nfrom sklearn.svm import SVC\nsvc_cl = SVC(kernel = 'rbf', random_state = 0)\nsvc_cl.fit(X_train, Y_train)\ny_pred = svc_cl.predict(X_test)\nacc_svm = accuracy_score(Y_test, y_pred)\nprint(\"Accuracy: {}\".format(acc_svm))\nprint()\nprint(classification_report(Y_test,y_pred))\ncnf_matrix = metrics.confusion_matrix(Y_test,y_pred)\nprint(cnf_matrix)\n\n\n#Naive Bayes \nfrom sklearn.naive_bayes import GaussianNB\ngaussian = GaussianNB()\ngaussian.fit(X_train, Y_train)\ny_pred = gaussian.predict(X_test)\nacc_nb = accuracy_score(Y_test, y_pred)\nprint(\"Accuracy: {}\".format(acc_nb))\nprint()\nprint(classification_report(Y_test,y_pred))\ncnf_matrix = metrics.confusion_matrix(Y_test,y_pred)\nprint(cnf_matrix)\n\nmodels_acc = pd.DataFrame({\n    'Models': ['Decision Tree', 'Logistic Regression', \n               'Support Vector Machine','Naive Bayes'],\n    'Accuracy': [acc_dt_new,acc_lg,acc_svm,acc_nb] })\n\nprint( models_acc.sort_values(by='Accuracy',ascending=False))\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}