{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Ingest"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\ndata=pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().values.any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data.isnull().T.any().T]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.hist(bins = 10, figsize=(18, 16), color=\"#2c5af2\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Eda"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Correlation Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set() \ncorr_matrix = data.corr()\ncorr_matrix\n\nplt.figure(figsize=(25,25))\nsns.heatmap(corr_matrix, annot=True, linewidths=.5, cmap=\"YlGnBu\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modle"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import linear_model\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"y=data['SalePrice'].values\ny=y.reshape(-1,1)\nX=data[['OverallQual','TotalBsmtSF','1stFlrSF','GarageArea','GarageArea','GrLivArea']].values\nXX=data[['OverallQual','TotalBsmtSF','1stFlrSF','GarageArea','GarageArea','GrLivArea']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"XX=data[['OverallQual','TotalBsmtSF','1stFlrSF','GarageArea','GarageArea','GrLivArea']]\nXX.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"XX.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Split Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\nprint(X_train.shape, y_train.shape)\nprint(X_test.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fit the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"lm =  RandomForestClassifier()\nlm.fit(X_train, y_train)\npredictions = lm.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plot Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\nplt.scatter(y_test, predictions)\nplt.xlabel(\"Actual Income\")\nplt.ylabel(\"Predicted Income\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Print Accuracy of Linear Regression Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualize Regression Lasso (Regression) Model Accuracy with Yellowbrick"},{"metadata":{"trusted":true},"cell_type":"code","source":"from yellowbrick.regressor import PredictionError\nfrom sklearn.linear_model import Lasso\nlasso = Lasso()\nvisualizer = PredictionError(lasso)\nvisualizer.fit(X_train, y_train)\nvisualizer.score(X_test, y_test)\ng = visualizer.poof()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plot Cross-validation Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score, cross_val_predict\nfrom sklearn import metrics\nscores = cross_val_score(clf, X, y, cv=10)\nscores","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualize"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Ridge\nfrom sklearn.model_selection import KFold\nfrom yellowbrick.model_selection import CVScores\n\n# Create a new figure and axes\n_, ax = plt.subplots()\ncv = KFold(10)\n\noz = CVScores(linear_model.LinearRegression(), ax=ax, cv=cv, scoring='r2')\n\noz.fit(X, y)\noz.poof()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion"},{"metadata":{},"cell_type":"markdown","source":"1. Using heat maps to select data is always validï¼Œalthough I don't know the true meaning of features\n2. Using heatmap to pick features is very effective,especially when there are a lot features.\n3. Analyze accuracy using the cross_val_score method to clearly see accuracy fluctuations. Through this I found that my model always has a very large error in several predictions. \n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}