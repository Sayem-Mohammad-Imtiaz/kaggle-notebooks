{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#importing required librabries\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split,StratifiedKFold,GridSearchCV\nfrom sklearn.metrics import classification_report,confusion_matrix,roc_auc_score,roc_curve,recall_score,accuracy_score,precision_score\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom warnings import filterwarnings\nfilterwarnings('ignore')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Loading data","metadata":{}},{"cell_type":"code","source":"#loading the data using pandas\ndf = pd.read_csv ('/kaggle/input/pima-indians-diabetes-database/diabetes.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#preview the data\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Understanding Data","metadata":{}},{"cell_type":"code","source":"# preview the shape of data\ndf.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#previewing the datatypes of data\ndf.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# statistical analysis\ndf.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Univariant Analysis","metadata":{}},{"cell_type":"code","source":"#Check for Outlier detections on all the independent features\nfor i in df.columns[:-1]:\n    sns.boxplot(df[i],orient='v')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Above plot show no abnormal outliers. So, not need to treat for outliers","metadata":{}},{"cell_type":"code","source":"# Check the distribution of data across the independent features\nfor i in df.columns[:-1]:\n    sns.distplot(df[i])\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data processing","metadata":{}},{"cell_type":"markdown","source":"#### Check for Missing Value","metadata":{}},{"cell_type":"code","source":"#Check for missing value\ndf.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- No missing value present in the data \n- No need of missing value treatment","metadata":{}},{"cell_type":"markdown","source":"### Spliting the data","metadata":{}},{"cell_type":"code","source":"#outcome is the feature to classify\ny=df.pop('Outcome')\n# rest of the columns will be independent features\nX=df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Spliting the data using stratified splitting\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42,stratify=y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#preview the X train data\nX_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#preview y train data\ny_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# shapes of the train and test data\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Scaling","metadata":{}},{"cell_type":"code","source":"## Scaling the data using standard scaler to normalize the data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Instantiation of standardscaler\nscaler=StandardScaler()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Applying fit and transform on training data using standard scaler object","metadata":{}},{"cell_type":"code","source":"# fit and transform train dat using standardscalar object\nX_train=pd.DataFrame(scaler.fit_transform(X_train),columns=X_train.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#preview after scaling\nX_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Apply only transform on test data to prevent memory leakage using existing scaler object","metadata":{}},{"cell_type":"code","source":"# transform test dat using same standardscalar object\nX_test=scaler.transform(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking the distribution of data across the independent features after scaling\nfor i in X_train.columns:\n    sns.distplot(df[i])\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## KNN Classifier","metadata":{}},{"cell_type":"code","source":"#created dataframe to store results\ndf_output=pd.DataFrame({})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Instantiation of Knn classifier\nknn=KNeighborsClassifier(n_jobs=-1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#fit training data on knn model\nknn.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## created a evaluation function to print Classification report, ROC curve, Accuracy,Specificity,Sensitivity, Recall,Precision,F1score\ndef evaluation(df_output,X_test,y_test,model,ModelName):\n    y_pred = model.predict(X_test)\n    y_pred_prob = model.predict_proba(X_test)[:,1] \n    print(\"-\"*15,\"Evaluation Details on Test data set\",\"-\"*15,\"\\n\")\n    print(\"-\"*10,\"Confusion matrix\",\"-\"*10,\"\\n\")\n    cm=confusion_matrix(y_pred,y_test)\n    print(cm,\"\\n\")\n    total=sum(sum(cm))\n    accuracy=(cm[0,0]+cm[1,1])/total\n    sensitivity=cm[1,1]/(cm[1,0]+cm[1,1])\n    specificity=cm[0,0]/(cm[0,1]+cm[0,0])\n    precision=precision_score(y_test,y_pred)\n    recall=recall_score(y_test,y_pred)\n    f1score= 2*((precision * recall)/(precision + recall))\n    print(\"-\"*10,\"Sensitivity  Specificity f1- score recall precision\",\"-\"*10)\n    print(\"Accuracy: {} \\nSensitivity: {} \\nSpecificity: {} \\nF1-score: {} \\nRecall: {} \\nPrecision: {}\\n\".format(accuracy,sensitivity,specificity,f1score,precision,recall))\n    \n    print(\"-\"*10,\"classification report\",\"-\"*10,\"\\n\")\n    print(classification_report(y_pred,y_test))\n    accuracy=accuracy_score(y_pred,y_test)\n    print(\"Accuracy score : \",accuracy,\"\\n\")\n    area=roc_auc_score(y_test,y_pred_prob)\n    print(\"Area under ROC curve : \", area,\"\\n\")\n    fpr,tpr,thrs=roc_curve(y_test,y_pred_prob,drop_intermediate=False)\n    plt.plot(fpr,tpr,label='ROC curve (area = %0.2f)' %area)\n    plt.plot([1,0],[1,0],'k--',color='r')\n    plt.title(\"ROC Curve\")\n    plt.legend(loc=4)# to print legend at lower right\n    plt.show()\n    threshold=thrs[np.argmax(tpr-fpr)]\n    print(\"Threshold \",thrs[np.argmax(tpr-fpr)])\n    df_output= df_output.append(pd.DataFrame({'ModelName':ModelName,'Accuracy': accuracy,'Sensitivity':sensitivity,'Specificity':specificity,'precision':precision,'recall':recall,'f1score':f1score,'roc_value': area,'threshold': threshold}, index=[0]),ignore_index=True)\n    return df_output","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# evaluate base knn model\ndf_output=evaluation(df_output,X_test,y_test,knn,'KNN_base')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Hypertuning KNN","metadata":{}},{"cell_type":"code","source":"## Function to do hypertuning of model\ndef hypertunemodel(params,basemodel,X_train,y_train,cv_num=5):\n    skf=StratifiedKFold(n_splits=cv_num,random_state=42,shuffle=True)\n    print(\"Hypertuning model started\")\n    model_cv=GridSearchCV(basemodel,param_grid=params,n_jobs=-1,cv=skf,return_train_score=True,scoring='roc_auc',verbose=2)\n    model_results=model_cv.fit(X_train,y_train)\n    print(\"Best roc_auc score\",model_results.best_score_)\n    print(model_cv.best_params_)\n    print(\"Hypertuning model finished\")\n    return model_cv,model_results","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# hyperparameters for hypertuning knn model\nknn_params={'n_neighbors':range(5,26),'weights':['uniform', 'distance'],'algorithm':['auto', 'ball_tree', 'kd_tree', 'brute'],'p':[1,2,3]}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#hypertuning the KNN model\nmodel_knn_cv,model_knn_results=hypertunemodel(knn_params,knn,X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#best model after hypertuning (gridsearchcv)\nbest_knn_model=model_knn_cv.best_estimator_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#hyperparameters value in the best knn model\nmodel_knn_cv.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# evaluate best hypertuned knn model\ndf_output=evaluation(df_output,X_test,y_test,best_knn_model,'KNN_hypertuned')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Decision Tree Classifier","metadata":{}},{"cell_type":"code","source":"#Instantiation of decision tree classifier\ndtc=DecisionTreeClassifier(random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#fit training data on decision tree model\ndtc.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# evaluate base decision tree model\ndf_output=evaluation(df_output,X_test,y_test,dtc,'DecisionTree')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Hyper tunning Decision tree","metadata":{}},{"cell_type":"code","source":"# hyperparameters for hypertuning decision tree model\ndtc_params={'criterion':['gini','entropy'],'max_depth':[4,8],'min_samples_leaf':range(1, 11, 2),'min_samples_split': range(1, 11, 2)}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#hypertuning the decision tree model\nmodel_dtc_cv,model_dct_results=hypertunemodel(dtc_params,dtc,X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#best decision tree model after hypertuning (gridsearchcv)\nbest_dtc_model=model_dtc_cv.best_estimator_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#hyperparameters value in the best decision tree model\nmodel_dtc_cv.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# evaluate best hypertuned decision tree model\ndf_output=evaluation(df_output,X_test,y_test,best_dtc_model,'DecisionTree_hypertuned')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_output","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### SVC","metadata":{}},{"cell_type":"code","source":"#Instantiation of svc classifier\nsvc=SVC(random_state=42,probability=True)\n#fit training data on svc model\nsvc.fit(X_train,y_train)\n# evaluate base svc model\ndf_output=evaluation(df_output,X_test,y_test,svc,'SVC_base')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Hypertuning SVC","metadata":{}},{"cell_type":"code","source":"## hyperparameters for hypertuning svc model\nsvm_params={'kernel':['linear', 'poly', 'rbf', 'sigmoid'],'C':[0.01,0.1,1],'gamma':['scale', 'auto'] }\n#hypertuning the svc model\nmodel_svc_cv,model_svc_results=hypertunemodel(svm_params,svc,X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#best svc model after hypertuning ( through gridsearchcv)\nbest_svc_model=model_svc_cv.best_estimator_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#hyperparameters value in the best svc model\nmodel_svc_cv.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# evaluate best hypertuned decision tree model\ndf_output=evaluation(df_output,X_test,y_test,best_svc_model,'SVC_hypertuned')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_output","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Random Forest","metadata":{}},{"cell_type":"code","source":"#Instantiation of random forest classifier\nrfc=RandomForestClassifier(n_jobs=-1)\n#fit training data on random forest classifier model\nrfc.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# evaluate base random forest classifier model\ndf_output=evaluation(df_output,X_test,y_test,rfc,'RandomForest_base')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Hypertuning Randomforest","metadata":{}},{"cell_type":"code","source":"## hyperparameters for hypertuning random forest classifier model\nrfc_params={'max_depth': [4,8],'min_samples_leaf': range(1, 11, 2),'criterion' :[\"gini\", \"entropy\"],'min_samples_split': range(1, 11, 2),'n_estimators': [100,200],'max_features': [\"auto\", \"sqrt\", \"log2\"]}\n#hypertuning the random forest classifier model\nmodel_rfc_cv,model_rfc_results=hypertunemodel(rfc_params,rfc,X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#best random forest classifier model after hypertuning ( through gridsearchcv)\nbest_rfc_model=model_rfc_cv.best_estimator_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#hyperparameters value in the best random forest classifier model\nmodel_rfc_cv.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# evaluate best hypertuned random forest classifier model\ndf_output=evaluation(df_output,X_test,y_test,best_rfc_model,'RFC_hypertuned')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_output","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Conclusion","metadata":{}},{"cell_type":"markdown","source":"- Based on the above results\n - SVC hypertuned model gives best ROC score of all the models.\n - Random Forest classifier provides the second best ROC score\n- But based on sensitivity and specificity which needs to be high\n  - Random forest classifier is the best model to use for this classification","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}