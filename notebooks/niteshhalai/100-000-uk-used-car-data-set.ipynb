{"cells":[{"metadata":{},"cell_type":"markdown","source":"Work in progress..\n\nThe final output of this notebook is to create a model to predict car prices.\n\nDuring the process, I will perform some data cleaning and EDA. Note that I have very little knowledge about cars and models and their features, (I only know how to start a car and drive it..), so if I am going in a very wrong direction, be sure to point it out.","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I will first combine the different datasets as I would only want to work with one dataframe. I am hoping that the feature names are matching. (Surely, there must be a more effecient way of doing this..):","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"unclean_focus = pd.read_csv('/kaggle/input/used-car-dataset-ford-and-mercedes/unclean focus.csv')\ncclass = pd.read_csv('/kaggle/input/used-car-dataset-ford-and-mercedes/cclass.csv')\nbmw = pd.read_csv('/kaggle/input/used-car-dataset-ford-and-mercedes/bmw.csv')\nmerc = pd.read_csv('/kaggle/input/used-car-dataset-ford-and-mercedes/merc.csv')\nhyundi = pd.read_csv('/kaggle/input/used-car-dataset-ford-and-mercedes/hyundi.csv')\nfocus = pd.read_csv('/kaggle/input/used-car-dataset-ford-and-mercedes/focus.csv')\nvauxhall = pd.read_csv('/kaggle/input/used-car-dataset-ford-and-mercedes/vauxhall.csv')\nunclean_cclass = pd.read_csv('/kaggle/input/used-car-dataset-ford-and-mercedes/unclean cclass.csv')\nvw = pd.read_csv('/kaggle/input/used-car-dataset-ford-and-mercedes/vw.csv')\naudi = pd.read_csv('/kaggle/input/used-car-dataset-ford-and-mercedes/audi.csv')\nford= pd.read_csv('/kaggle/input/used-car-dataset-ford-and-mercedes/ford.csv')\nskoda = pd.read_csv('/kaggle/input/used-car-dataset-ford-and-mercedes/skoda.csv')\ntoyota = pd.read_csv('/kaggle/input/used-car-dataset-ford-and-mercedes/toyota.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What is unclean_focus/focus and unclean_cclass/cclass? I would like to compare these two pairs.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"unclean_focus.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"focus.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I am going to drop the two 'unclean' datasets and going to combine the rest.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"audi.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bmw.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vw.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cclass.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some columns are missing in various datasets, however, i will go ahead and combine them.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cclass['csv'] = 'cclass'\nbmw['csv'] = 'bmw'\nmerc['csv'] = 'merc'\nhyundi['csv'] = 'hyundi'\nfocus['csv'] = 'focus'\nvauxhall['csv'] = 'vauxhall'\nvw['csv'] = 'vw'\naudi['csv'] = 'audi'\nford['csv'] = 'ford'\nskoda['csv'] = 'skoda'\ntoyota['csv'] = 'toyota'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_original = cclass.append([bmw, merc, hyundi, focus, vauxhall, vw, audi, ford, skoda, toyota], ignore_index=False, verify_integrity=False, sort=False)\ndf = cclass.append([bmw, merc, hyundi, focus, vauxhall, vw, audi, ford, skoda, toyota], ignore_index=False, verify_integrity=False, sort=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data cleaning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are two tax columns.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['tax(£)'].notnull() == True]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[(df['tax(£)'].notnull() == True) & (df['tax'].notnull()==True)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I will replace Nan values in tax columns with 0 and simply add them.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['tax(£)'].fillna(value=0, inplace=True)\ndf['tax'].fillna(value=0, inplace=True)\ndf['tax'] = df['tax(£)'] + df['tax']\ndf.drop(labels='tax(£)', axis=1, inplace=True)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some initial observations about the dataset:\n\n* The oldest year is 1970 while mean 25th percantile is 2016. This inidcates that few of the cars are old models.\n* At least 50% of the cars fall within years 2016 to 2019.\n* The maximum year is 2060. Is this an error?\n* The range of mileage is very high. Possibly some outliers.\n* There seems to be some missing values in mpg and also in engine size and tax in guise of 0's.\n* The range of price is also high. Price and its relation with other features will be the main focus of this notebook.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Some general univariate visualisations","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def univariate_plots(column, data=df):\n    if data[column].dtype not in ['int64', 'float64']:\n        f, axes = plt.subplots(1,1,figsize=(15,5))\n        sns.countplot(x=column, data = data)\n        plt.xticks(rotation=90)\n        plt.suptitle(column,fontsize=20)\n        plt.show()\n    else:\n        g = sns.FacetGrid(data, margin_titles=True, aspect=4, height=3)\n        g.map(plt.hist,column,bins=100)\n        plt.show()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in df.columns:\n    univariate_plots(column)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are a lot of car models in the data set. I will add a column with the main csv file name so as to make use of those as fetures as well. I will see how I can use this column.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['model'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The following are the outliers in the year (I will consider everything under 1990 and over 2020 as outlier. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"(df[(df['year']>2020) | (df['year']<1990)]).describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The outlier years don't seem to have anything special, so I will just transform these to 2017 as this is the mean in terms of year of the rest of the data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"(df[(df['year']<2020) | (df['year']>1990)]).describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert_year(year):\n    if year > 2020 or year < 1990:\n        year = 2017 \n    else:\n        year = year\n    \n    return year","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['year'] = df['year'].apply(convert_year)\ndf[(df['year']>2020) | (df['year']<1990)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The majority of the cars have manual transmission, while automatic and semi-automatic have almost similar distribution.But what about 'Other'?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['transmission'] == 'Other']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for model in df[df['transmission'] == 'Other']['model'].unique():\n    print(model)\n    print(df[df['model'] == model]['transmission'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert_transmission(transmission, model = df['model']):\n    if transmission not in ['Manual','Semi-Auto','Automatic']:\n        transmission = df[df['model'] == model]['transmission'].value_counts().reset_index()['index'][0]\n    else:\n        transmission = transmission\n    \n    return transmission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['transmission'] = df['transmission'].apply(convert_transmission)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Bivariate analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_columns = []\n\nfor column in df_original.columns:\n    if df_original[column].dtype == 'object':\n        categorical_columns.append(column)\n        \ndf_original = pd.get_dummies(df_original,columns=categorical_columns, dtype=int, drop_first=True)\ndf_original.fillna(0, inplace=True)\n\ny = df_original['price']\nX = df_original.drop(labels = ['price'], axis = 1)\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=True)\n\nmodel = LinearRegression().fit(X_train, y_train)\ny_pred = model.predict(X_test)\n\nfrom sklearn import metrics\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\nprint('r2_score:', metrics.r2_score (y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\n\ncategorical_columns = []\n\nfor column in df.columns:\n    if df[column].dtype == 'object':\n        categorical_columns.append(column)\n        \ndf = pd.get_dummies(df,columns=categorical_columns, dtype=int, drop_first=True)\ndf.fillna(0, inplace=True)\n\ny = df['price']\nX = df.drop(labels = ['price'], axis = 1)\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=True)\n\nmodels = [DecisionTreeRegressor(), LinearRegression(), Ridge(),  Lasso()]\n\nfor model in models:\n    \n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n\n    from sklearn import metrics\n    print('Model:', model)\n    print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n    print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n    print('r2_score:', metrics.r2_score (y_test, y_pred))\n    print('-------------------------------------')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}