{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-09-18T11:13:32.354221Z","iopub.execute_input":"2021-09-18T11:13:32.354528Z","iopub.status.idle":"2021-09-18T11:13:32.640074Z","shell.execute_reply.started":"2021-09-18T11:13:32.354471Z","shell.execute_reply":"2021-09-18T11:13:32.63936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Importing Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt\nimport scipy\nimport os\nimport pickle\nimport librosa\nimport librosa.display\nfrom IPython.display import Audio\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport tensorflow as tf\nfrom tensorflow import keras","metadata":{"execution":{"iopub.status.busy":"2021-09-18T11:13:32.641703Z","iopub.execute_input":"2021-09-18T11:13:32.642048Z","iopub.status.idle":"2021-09-18T11:13:32.647672Z","shell.execute_reply.started":"2021-09-18T11:13:32.642009Z","shell.execute_reply":"2021-09-18T11:13:32.646661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/gtzan-dataset-music-genre-classification/Data/features_3_sec.csv\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-18T11:13:32.648794Z","iopub.execute_input":"2021-09-18T11:13:32.649883Z","iopub.status.idle":"2021-09-18T11:13:32.84638Z","shell.execute_reply.started":"2021-09-18T11:13:32.649843Z","shell.execute_reply":"2021-09-18T11:13:32.845535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-18T11:13:32.847662Z","iopub.execute_input":"2021-09-18T11:13:32.847983Z","iopub.status.idle":"2021-09-18T11:13:32.857642Z","shell.execute_reply.started":"2021-09-18T11:13:32.847941Z","shell.execute_reply":"2021-09-18T11:13:32.856765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dtypes","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-09-18T11:13:32.86113Z","iopub.execute_input":"2021-09-18T11:13:32.861409Z","iopub.status.idle":"2021-09-18T11:13:32.870354Z","shell.execute_reply.started":"2021-09-18T11:13:32.861372Z","shell.execute_reply":"2021-09-18T11:13:32.869352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=df.drop(labels=\"filename\",axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-09-18T11:13:32.872197Z","iopub.execute_input":"2021-09-18T11:13:32.872784Z","iopub.status.idle":"2021-09-18T11:13:32.882772Z","shell.execute_reply.started":"2021-09-18T11:13:32.872741Z","shell.execute_reply":"2021-09-18T11:13:32.882148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Understanding the audio files","metadata":{}},{"cell_type":"code","source":"audio_recording=\"/kaggle/input/gtzan-dataset-music-genre-classification/Data/genres_original/country/country.00050.wav\"\ndata,sr=librosa.load(audio_recording)\nprint(type(data),type(sr))","metadata":{"execution":{"iopub.status.busy":"2021-09-18T11:13:32.885482Z","iopub.execute_input":"2021-09-18T11:13:32.885874Z","iopub.status.idle":"2021-09-18T11:13:32.896893Z","shell.execute_reply.started":"2021-09-18T11:13:32.88584Z","shell.execute_reply":"2021-09-18T11:13:32.896186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"librosa.load(audio_recording,sr=45600)","metadata":{"execution":{"iopub.status.busy":"2021-09-18T11:13:32.898028Z","iopub.execute_input":"2021-09-18T11:13:32.898683Z","iopub.status.idle":"2021-09-18T11:13:34.439056Z","shell.execute_reply.started":"2021-09-18T11:13:32.898642Z","shell.execute_reply":"2021-09-18T11:13:34.438279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With the help of IPython.display.Audio we can play audio in the notebook. It is a library used for playing the audio in the jupyterlab. ","metadata":{}},{"cell_type":"code","source":"import IPython\nIPython.display.Audio(data,rate=sr)","metadata":{"execution":{"iopub.status.busy":"2021-09-18T11:13:34.443034Z","iopub.execute_input":"2021-09-18T11:13:34.445573Z","iopub.status.idle":"2021-09-18T11:13:34.513189Z","shell.execute_reply.started":"2021-09-18T11:13:34.445516Z","shell.execute_reply":"2021-09-18T11:13:34.512505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualising audio files","metadata":{}},{"cell_type":"markdown","source":"### Plotting Raw wave files","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,4))\nlibrosa.display.waveplot(data,color=\"#2B4F72\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-18T11:13:34.51443Z","iopub.execute_input":"2021-09-18T11:13:34.515142Z","iopub.status.idle":"2021-09-18T11:13:34.842841Z","shell.execute_reply.started":"2021-09-18T11:13:34.515053Z","shell.execute_reply":"2021-09-18T11:13:34.842168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Waveforms are visual representations of sound as time on the x-axis and amplitude on the y-axis. They are great for allowing us to quickly scan the audio data and visually compare and contrast which genres might be more similar than others.","metadata":{}},{"cell_type":"markdown","source":"### Spectrogram\nA spectrogram is a visual way of representing the signal loudness of a signal over time at various frequencies present in a particular waveform. Not only can one see whether there is more or less energy at, for example, 2 Hz vs 10 Hz, but one can also see how energy levels vary over time.\nSpectrograms are sometimes called sonographs, voiceprints, or voicegrams. When the data is represented in a 3D plot, they may be called waterfalls. In 2-dimensional arrays, the first axis is frequency while the second axis is time","metadata":{}},{"cell_type":"code","source":"stft=librosa.stft(data)\nstft_db=librosa.amplitude_to_db(abs(stft))\nplt.figure(figsize=(14,6))\nlibrosa.display.specshow(stft,sr=sr,x_axis='time',y_axis='hz')\nplt.colorbar()","metadata":{"execution":{"iopub.status.busy":"2021-09-18T11:13:34.844077Z","iopub.execute_input":"2021-09-18T11:13:34.844412Z","iopub.status.idle":"2021-09-18T11:13:36.483013Z","shell.execute_reply.started":"2021-09-18T11:13:34.844373Z","shell.execute_reply":"2021-09-18T11:13:36.482225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stft=librosa.stft(data)\nstft_db=librosa.amplitude_to_db(abs(stft))\nplt.figure(figsize=(14,6))\nlibrosa.display.specshow(stft_db,sr=sr,x_axis='time',y_axis='hz')\nplt.colorbar()","metadata":{"execution":{"iopub.status.busy":"2021-09-18T11:13:36.484314Z","iopub.execute_input":"2021-09-18T11:13:36.484662Z","iopub.status.idle":"2021-09-18T11:13:37.854266Z","shell.execute_reply.started":"2021-09-18T11:13:36.484626Z","shell.execute_reply":"2021-09-18T11:13:37.853418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Spectral Roll-Off\nSpectral Rolloff is the frequency below which a specified percentage of the total spectral energy, e.g. 85%, lies\nlibrosa.feature.spectral_rolloff computes the rolloff frequency for each frame in a signal.","metadata":{}},{"cell_type":"code","source":"spectral_rolloff=librosa.feature.spectral_rolloff(data+0.01,sr=sr)[0]\nplt.figure(figsize=(14,6))\nlibrosa.display.waveplot(data,sr=sr,alpha=0.4,color=\"#2B4F72\")","metadata":{"execution":{"iopub.status.busy":"2021-09-18T11:13:37.855832Z","iopub.execute_input":"2021-09-18T11:13:37.856086Z","iopub.status.idle":"2021-09-18T11:13:38.50206Z","shell.execute_reply.started":"2021-09-18T11:13:37.856055Z","shell.execute_reply":"2021-09-18T11:13:38.501358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Chroma Feature\nIt is a powerful tool for analyzing music features whose pitches can be meaningfully categorized and whose tuning approximates to the equal-tempered scale. One main property of chroma features is that they capture harmonic and melodic characteristics of music while being robust to changes in timbre and instrumentation","metadata":{}},{"cell_type":"code","source":"import librosa.display as lplt\nchroma = librosa.feature.chroma_stft(data,sr=sr)\nplt.figure(figsize=(14,6))\nlplt.specshow(chroma,sr=sr,x_axis=\"time\",y_axis=\"chroma\",cmap=\"coolwarm\")\nplt.colorbar()\nplt.title(\"Chroma Features\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-18T11:13:38.505249Z","iopub.execute_input":"2021-09-18T11:13:38.505455Z","iopub.status.idle":"2021-09-18T11:13:38.987932Z","shell.execute_reply.started":"2021-09-18T11:13:38.505431Z","shell.execute_reply":"2021-09-18T11:13:38.987223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Zero Crossing Rate\nZero crossing is said to occur if successive samples have different algebraic signs. The rate at which zero-crossings occur is a simple measure of the frequency content of a signal. Zero-crossing rate is a measure of the number of times in a given time interval/frame that the amplitude of the speech signals passes through a value of zero.","metadata":{}},{"cell_type":"code","source":"start=1000\nend=1200\nplt.figure(figsize=(12,4))\nplt.plot(data[start:end],color=\"#2B4F72\")\nplt.grid()","metadata":{"execution":{"iopub.status.busy":"2021-09-18T11:13:38.989151Z","iopub.execute_input":"2021-09-18T11:13:38.989491Z","iopub.status.idle":"2021-09-18T11:13:39.200227Z","shell.execute_reply.started":"2021-09-18T11:13:38.989454Z","shell.execute_reply":"2021-09-18T11:13:39.199521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"zero_cross_rate=librosa.zero_crossings(data[start:end],pad=False)\nprint(\"the numbert of zero_crossings is :\", sum(zero_cross_rate))","metadata":{"execution":{"iopub.status.busy":"2021-09-18T11:13:39.201344Z","iopub.execute_input":"2021-09-18T11:13:39.202116Z","iopub.status.idle":"2021-09-18T11:13:39.209563Z","shell.execute_reply.started":"2021-09-18T11:13:39.202076Z","shell.execute_reply":"2021-09-18T11:13:39.208617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Extraction\nPreprocessing of data is required before we finally train the data. We will try and focus on the last column that is ‘label’ and will encode it with the function LabelEncoder() of sklearn.preprocessing.","metadata":{}},{"cell_type":"code","source":"class_list=df.iloc[:,-1]\nconverter=LabelEncoder()","metadata":{"execution":{"iopub.status.busy":"2021-09-18T11:13:39.21102Z","iopub.execute_input":"2021-09-18T11:13:39.211943Z","iopub.status.idle":"2021-09-18T11:13:39.219473Z","shell.execute_reply.started":"2021-09-18T11:13:39.211906Z","shell.execute_reply":"2021-09-18T11:13:39.218759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y=converter.fit_transform(class_list)\ny","metadata":{"execution":{"iopub.status.busy":"2021-09-18T11:13:39.220654Z","iopub.execute_input":"2021-09-18T11:13:39.221078Z","iopub.status.idle":"2021-09-18T11:13:39.233034Z","shell.execute_reply.started":"2021-09-18T11:13:39.22104Z","shell.execute_reply":"2021-09-18T11:13:39.232076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df.iloc[:,:-1])","metadata":{"execution":{"iopub.status.busy":"2021-09-18T11:13:39.234919Z","iopub.execute_input":"2021-09-18T11:13:39.235197Z","iopub.status.idle":"2021-09-18T11:13:39.257405Z","shell.execute_reply.started":"2021-09-18T11:13:39.235162Z","shell.execute_reply":"2021-09-18T11:13:39.256382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Scaling the features\nStandard scaler is used to standardize features by removing the mean and scaling to unit variance.\nThe standard score of sample x is calculated as:\nz = (x - u) / s","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfit=StandardScaler()\nX=fit.fit_transform(np.array(df.iloc[:,:-1],dtype=float))","metadata":{"execution":{"iopub.status.busy":"2021-09-18T11:13:39.258957Z","iopub.execute_input":"2021-09-18T11:13:39.25946Z","iopub.status.idle":"2021-09-18T11:13:39.275016Z","shell.execute_reply.started":"2021-09-18T11:13:39.259422Z","shell.execute_reply":"2021-09-18T11:13:39.274267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dividing Training and Testing Dataset","metadata":{}},{"cell_type":"code","source":"X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.33)","metadata":{"execution":{"iopub.status.busy":"2021-09-18T11:13:39.27626Z","iopub.execute_input":"2021-09-18T11:13:39.276539Z","iopub.status.idle":"2021-09-18T11:13:39.283831Z","shell.execute_reply.started":"2021-09-18T11:13:39.276487Z","shell.execute_reply":"2021-09-18T11:13:39.282987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(y_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-18T11:13:39.28535Z","iopub.execute_input":"2021-09-18T11:13:39.285772Z","iopub.status.idle":"2021-09-18T11:13:39.292063Z","shell.execute_reply.started":"2021-09-18T11:13:39.285737Z","shell.execute_reply":"2021-09-18T11:13:39.291101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(y_train)","metadata":{"execution":{"iopub.status.busy":"2021-09-18T11:13:39.293607Z","iopub.execute_input":"2021-09-18T11:13:39.293939Z","iopub.status.idle":"2021-09-18T11:13:39.300997Z","shell.execute_reply.started":"2021-09-18T11:13:39.293905Z","shell.execute_reply":"2021-09-18T11:13:39.300171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Building the model\n","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential","metadata":{"execution":{"iopub.status.busy":"2021-09-18T11:13:39.302499Z","iopub.execute_input":"2021-09-18T11:13:39.303062Z","iopub.status.idle":"2021-09-18T11:13:39.308062Z","shell.execute_reply.started":"2021-09-18T11:13:39.303026Z","shell.execute_reply":"2021-09-18T11:13:39.307299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def trainModel(model,epochs,optimizer):\n    batch_size=128\n    model.compile(optimizer=optimizer,loss='sparse_categorical_crossentropy',metrics='accuracy')\n    return model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=epochs,batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2021-09-18T11:13:39.309384Z","iopub.execute_input":"2021-09-18T11:13:39.30982Z","iopub.status.idle":"2021-09-18T11:13:39.316278Z","shell.execute_reply.started":"2021-09-18T11:13:39.309787Z","shell.execute_reply":"2021-09-18T11:13:39.31559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plotValidate(history):\n    print(\"Validation Accuracy\",max(history.history[\"val_accuracy\"]))\n    pd.DataFrame(history.history).plot(figsize=(12,6))\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-18T11:13:39.317535Z","iopub.execute_input":"2021-09-18T11:13:39.317819Z","iopub.status.idle":"2021-09-18T11:13:39.327816Z","shell.execute_reply.started":"2021-09-18T11:13:39.317786Z","shell.execute_reply":"2021-09-18T11:13:39.327082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2021-09-18T11:15:19.979752Z","iopub.execute_input":"2021-09-18T11:15:19.980025Z","iopub.status.idle":"2021-09-18T11:15:19.983433Z","shell.execute_reply.started":"2021-09-18T11:15:19.979996Z","shell.execute_reply":"2021-09-18T11:15:19.982768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=tf.keras.models.Sequential([\n    tf.keras.layers.Dense(512,activation='relu',input_shape=(X_train.shape[1],)),\n    tf.keras.layers.Dropout(0.2),\n    \n    tf.keras.layers.Dense(256,activation='relu'),\n    keras.layers.Dropout(0.2),\n    \n    tf.keras.layers.Dense(128,activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    \n    tf.keras.layers.Dense(64,activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    \n    tf.keras.layers.Dense(10,activation='softmax'),\n])\n\nprint(model.summary())\nmodel_history=trainModel(model=model,epochs=600,optimizer='adam')","metadata":{"execution":{"iopub.status.busy":"2021-09-18T11:23:19.457235Z","iopub.execute_input":"2021-09-18T11:23:19.457514Z","iopub.status.idle":"2021-09-18T11:25:30.993794Z","shell.execute_reply.started":"2021-09-18T11:23:19.457486Z","shell.execute_reply":"2021-09-18T11:25:30.993081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Evaluation","metadata":{}},{"cell_type":"code","source":"test_loss,test_acc=model.evaluate(X_test,y_test,batch_size=128)\nprint(\"The test loss is \",test_loss)\nprint(\"The best accuracy is: \",test_acc*100)","metadata":{"execution":{"iopub.status.busy":"2021-09-18T11:27:47.971302Z","iopub.execute_input":"2021-09-18T11:27:47.971922Z","iopub.status.idle":"2021-09-18T11:27:48.068402Z","shell.execute_reply.started":"2021-09-18T11:27:47.971884Z","shell.execute_reply":"2021-09-18T11:27:48.067675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For the CNN model, we had used the Adam optimizer for training the model. The epoch that was chosen for the training model is 600.\nAll of the hidden layers are using the RELU activation function and the output layer uses the softmax function. The loss is calculated using the sparse_categorical_crossentropy function.\nDropout is used to prevent overfitting.\nWe chose the Adam optimizer because it gave us the best results after evaluating other optimizers.\nThe model accuracy can be increased by further increasing the epochs but after a certain period, we may achieve a threshold, so the value should be determined accordingly.","metadata":{}},{"cell_type":"markdown","source":"The model accuracy can be increased by further increasing the epochs but after a certain period, we may achieve a threshold, so the value should be determined accordingly.\nThe accuracy we achieved for the test set is 92.14 percent which is very decent.\nSo we come to the conclusion that Neural Networks are very effective in machine learning models. Tensorflow is very useful in implementing Convolutional Neural Network (CNN) that helps in the classifying process.","metadata":{}}]}