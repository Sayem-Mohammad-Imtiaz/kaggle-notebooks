{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Dirty chai\nAccording to [this website](https://www.thespruceeats.com/dirty-chai-definition-765697#:~:text=Dirty%20chai%20is%20a%20popular,and%20a%20chai%20tea%20latte.) Chai with Espresso (aka Dirty chai) \"packs a double whammy of caffeine from the black tea and shot or two of espresso. The average caffeine level of a 12-ounce dirty chai latte is 160 milligrams (versus 50 to 70 milligrams for a chai latte).\"\n\nThat sounds like my kind of Chai! Lets explore this awesome dataset while hyped up on caffene!","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt\nimport seaborn as sns\nimport os\nfrom tqdm.notebook import tqdm\nimport datetime as dt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!ls -GFlash --color ../input/chai-time-data-science/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"thumb = pd.read_csv('../input/chai-time-data-science/Anchor Thumbnail Types.csv')\neps = pd.read_csv('../input/chai-time-data-science/Episodes.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Read in all Cleaned Subtitles and Parse","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cleaned_st_files = os.listdir('../input/chai-time-data-science/Cleaned Subtitles/')\n\ndef add_duration(df):\n    df['colon_count'] = df['Time'].str.count(':')\n    df.loc[df['colon_count'] == 1, 'Time'] = '0:' + df.loc[df['colon_count'] == 1]['Time']\n    df['Time_dt'] = df['Time'].apply(lambda x: dt.datetime.strptime(x, \"%H:%M:%S\"))\n    df['Duration'] = (df['Time_dt'] - dt.datetime(1900, 1, 1)) \\\n        .apply(lambda x: x.total_seconds()).astype('int')\n    return df\n\nc_fs = []\nfor f in tqdm(cleaned_st_files):\n    df = pd.read_csv(f'../input/chai-time-data-science/Cleaned Subtitles/{f}')\n    df = add_duration(df)\n    df['E'] = f.replace('.csv','')\n    c_fs.append(df)\nall_subs = pd.concat(c_fs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_subs['Duration'].plot(kind='hist', figsize=(15, 5), bins=20,\n                          title='Duration of Single Subtitle')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Longest subtitle?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"all_subs.sort_values('Duration')['Text'].values[-1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# First word someone says in subtitle section","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"all_subs['first_word'] = all_subs['Text'].str.split(' ', expand=True)[0]\nall_subs['first_word_clean'] = all_subs['first_word'].str.lower().str.replace(',','').str.replace('.','')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_subs['first_word_clean'].value_counts().head(20) \\\n    .sort_values().plot(kind='barh', figsize=(15, 8),\n                        title='First word spoken in subtitle section')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Simple Sentiment Analysis\nReference: https://medium.com/analytics-vidhya/simplifying-social-media-sentiment-analysis-using-vader-in-python-f9e6ec6fc52f","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install vaderSentiment > /dev/null\nfrom vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\nanalyser = SentimentIntensityAnalyzer()\nall_subs['Polarity_Scores'] = all_subs['Text'].apply(lambda x: analyser.polarity_scores(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_subs['neg_score'] = all_subs['Polarity_Scores'].apply(lambda x: x['neg'])\nall_subs['neu_score'] = all_subs['Polarity_Scores'].apply(lambda x: x['neu'])\nall_subs['pos_score'] = all_subs['Polarity_Scores'].apply(lambda x: x['pos'])\nall_subs['compound_score'] = all_subs['Polarity_Scores'].apply(lambda x: x['compound'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15, 5))\nall_subs['neg_score'].plot(kind='hist',\n                           bins=50,\n                           alpha=0.5,\n                           title='Distribution of Sentiment Scores')\nall_subs['pos_score'].plot(kind='hist',\n                           bins=50,\n                           alpha=0.5)\nall_subs['neu_score'].plot(kind='hist',\n                           bins=50,\n                           alpha=0.5)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}