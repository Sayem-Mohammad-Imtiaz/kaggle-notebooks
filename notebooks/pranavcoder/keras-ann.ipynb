{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"file_extension":".py","nbconvert_exporter":"python","pygments_lexer":"ipython3","name":"python","version":"3.6.1","codemirror_mode":{"name":"ipython","version":3},"mimetype":"text/x-python"}},"nbformat":4,"cells":[{"metadata":{"_uuid":"1f8223be7895579760c8f03a559987f863f74ea6","_cell_guid":"73d2b9c3-a4b1-49a0-a3c8-0f456d162466"},"execution_count":null,"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","outputs":[]},{"metadata":{},"execution_count":null,"cell_type":"code","source":"diabetes = pd.read_csv(\"../input/diabetes.csv\")","outputs":[]},{"metadata":{},"execution_count":null,"cell_type":"code","source":"diabetes.head()","outputs":[]},{"metadata":{},"execution_count":null,"cell_type":"code","source":"diabetes.isnull().sum()","outputs":[]},{"metadata":{"collapsed":true},"execution_count":null,"cell_type":"code","source":"X = diabetes.iloc[:,:-1].values\nY = diabetes.iloc[:,-1].values","outputs":[]},{"metadata":{"collapsed":true},"execution_count":null,"cell_type":"code","source":"from mlxtend.preprocessing import one_hot\nY = one_hot(Y)","outputs":[]},{"metadata":{},"execution_count":null,"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2)","outputs":[]},{"metadata":{},"execution_count":null,"cell_type":"code","source":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\ndef build():\n    seq = Sequential()\n    seq.add(Dense(units = 200, activation = 'relu', kernel_initializer = 'uniform', input_dim = 8))\n    seq.add(Dense(units = 200, activation = 'relu', kernel_initializer = 'uniform'))\n    seq.add(Dense(units = 200, activation = 'relu', kernel_initializer = 'uniform'))\n    seq.add(Dense(units = 2, activation = 'softmax', kernel_initializer = 'uniform'))\n    seq.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n    return seq","outputs":[]},{"metadata":{},"execution_count":null,"cell_type":"code","source":"from keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score, KFold\n\n#kfold = KFold(n_splits=10, shuffle=True)\n\nclassifier = KerasClassifier(build_fn = build, batch_size = 32, nb_epoch= 20)\ncsv = cross_val_score(estimator= classifier, X = X_train, y = Y_train, cv = 10, n_jobs=-1)\n\nmean = csv.mean()\nstd = csv.std()\n\nclassifier.fit(X_train, Y_train)","outputs":[]},{"metadata":{},"execution_count":null,"cell_type":"code","source":"print(\"Accuracy: {}%\\n\".format(classifier.score(X_test, Y_test) *100))","outputs":[]},{"metadata":{},"execution_count":null,"cell_type":"code","source":"classifier.predict(X_test)","outputs":[]},{"metadata":{"collapsed":true},"execution_count":null,"cell_type":"code","source":"","outputs":[]}],"nbformat_minor":1}