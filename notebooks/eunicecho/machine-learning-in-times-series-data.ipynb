{"cells":[{"metadata":{},"cell_type":"markdown","source":"# UCI Human Activity Recognition Using Smartphones Dataset Version 1.0\n\nRather than using the 'test.csv' and 'train.csv' of the given competition dataset, I would like to use the raw data - containing time information & without signal transform - and practice signal processing and model construction.\n\nThe data is available from below link : \nhttps://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones\n\nThis is the link of the codes I've learned a lot from :\nhttps://github.com/taspinar\n\n\n1. Introduction\n\nThe experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data. \n\nThe sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used. From each window, a vector of features was obtained by calculating variables from the time and frequency domain. See 'features_info.txt' for more details. \n\n\n- Triaxial acceleration from the accelerometer (total acceleration) and the estimated body acceleration.\n- Triaxial Angular velocity from the gyroscope. \n- A 561-feature vector with time and frequency domain variables. \n- Its activity label. \n- An identifier of the subject who carried out the experiment."},{"metadata":{},"cell_type":"markdown","source":"> 2. Import module and dataset"},{"metadata":{"_uuid":"2212698e-dd2d-4ff4-9f96-9150322d90e6","_cell_guid":"06863205-833f-4a45-bcb6-ae8d689728b9","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport keras\nfrom keras.layers import Dense, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.models import Sequential\nfrom keras.callbacks import History \nimport os\nimport pywt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_signals(filename):\n    with open(filename, 'r') as fp:\n        data = fp.read().splitlines()\n        data = map(lambda x: x.rstrip().lstrip().split(), data)\n        data = [list(map(float, line)) for line in data]\n        data = np.array(data, dtype=np.float32)\n    return data\n \ndef read_labels(filename):        \n    with open(filename, 'r') as fp:\n        activities = fp.read().splitlines()\n        activities = list(map(int, activities))\n    return np.array(activities)\n \ndef randomize(dataset, labels):\n    permutation = np.random.permutation(labels.shape[0])\n    shuffled_dataset = dataset[permutation, :, :]\n    shuffled_labels = labels[permutation]\n    return shuffled_dataset, shuffled_labels\n \n####\n \nINPUT_FOLDER_TRAIN = './UCI_HAR/train/InertialSignals/'\nINPUT_FOLDER_TEST = './UCI_HAR/test/InertialSignals/'\n \nINPUT_FILES_TRAIN = ['body_acc_x_train.txt', 'body_acc_y_train.txt', 'body_acc_z_train.txt', \n                     'body_gyro_x_train.txt', 'body_gyro_y_train.txt', 'body_gyro_z_train.txt',\n                     'total_acc_x_train.txt', 'total_acc_y_train.txt', 'total_acc_z_train.txt']\n \nINPUT_FILES_TEST = ['body_acc_x_test.txt', 'body_acc_y_test.txt', 'body_acc_z_test.txt', \n                     'body_gyro_x_test.txt', 'body_gyro_y_test.txt', 'body_gyro_z_test.txt',\n                     'total_acc_x_test.txt', 'total_acc_y_test.txt', 'total_acc_z_test.txt']\n \n#####\n \ntrain_signals, test_signals = [], []\nfor input_file in INPUT_FILES_TRAIN:\n    signal = read_signals(INPUT_FOLDER_TRAIN + input_file)\n    train_signals.append(signal)\ntrain_signals = np.transpose(np.array(train_signals), (1, 2, 0))\n \nfor input_file in INPUT_FILES_TEST:\n    signal = read_signals(INPUT_FOLDER_TEST + input_file)\n    test_signals.append(signal)\ntest_signals = np.transpose(np.array(test_signals), (1, 2, 0))\n \n#####\n \nLABELFILE_TRAIN = './UCI_HAR/train/y_train.txt'\nLABELFILE_TEST = './UCI_HAR/test/y_test.txt'\ntrain_labels = read_labels(LABELFILE_TRAIN)\ntest_labels = read_labels(LABELFILE_TEST)\n \n#####\n \ntrain_data, train_labels = randomize(train_signals, train_labels)\ntest_data, test_labels = randomize(test_signals, test_labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3. Contiuous Wavelet Transform"},{"metadata":{"trusted":true},"cell_type":"code","source":"scales = range(1,128)\nwaveletname = 'morl'\ntrain_size = len(train_data)\ntest_size= len(test_data)\n \ntrain_data_cwt = np.ndarray(shape=(train_size, 127, 127, 9))\n \nfor ii in range(0,train_size):\n    if ii % 1000 == 0:\n        print(ii)\n    for jj in range(0,9):\n        signal = train_data[ii, :, jj]\n        coeff, freq = pywt.cwt(signal, scales, waveletname, 1)\n        coeff_ = coeff[:,:127]\n        train_data_cwt[ii, :, :, jj] = coeff_\n \ntest_data_cwt = np.ndarray(shape=(test_size, 127, 127, 9))\nfor ii in range(0,test_size):\n    if ii % 100 == 0:\n        print(ii)\n    for jj in range(0,9):\n        signal = test_data[ii, :, jj]\n        coeff, freq = pywt.cwt(signal, scales, waveletname, 1)\n        coeff_ = coeff[:,:127]\n        test_data_cwt[ii, :, :, jj] = coeff_\n \ntrain_labels = list(map(lambda x: int(x) - 1, train_labels))\ntest_labels = list(map(lambda x: int(x) - 1, test_labels))\n \nx_train = train_data_cwt\ny_train = list(train_labels[:train_size])\nx_test = test_data_cwt\ny_test = list(test_labels[:test_size])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"4. Model : CNN"},{"metadata":{"_uuid":"32639aeb-6773-4ce4-b9fb-3c9cfce13b79","_cell_guid":"1d01f258-2999-4314-9365-e4f6f4bc8283","trusted":true},"cell_type":"code","source":"history = History()\n\ninput_shape = (127, 127, 9)\n \nbatch_size = 16\nnum_classes = 7\nepochs = 10\n \nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\n \ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)\n \n \nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1), activation='relu', input_shape=input_shape))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Conv2D(64, (5, 5), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\n \nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adam(),\n              metrics=['accuracy'])\n \n \nmodel.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test, y_test),\n          callbacks=[history])\n \ntrain_score = model.evaluate(x_train, y_train, verbose=0)\nprint('Train loss: {}, Train accuracy: {}'.format(train_score[0], train_score[1]))\ntest_score = model.evaluate(x_test, y_test, verbose=0)\nprint('Test loss: {}, Test accuracy: {}'.format(test_score[0], test_score[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I'll add on more signal processing technique later on."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}