{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport plotly.express as px\nfrom wordcloud import WordCloud, ImageColorGenerator\nfrom plotly.offline import iplot\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport nltk\nimport re\nimport string\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n\nplt.rcParams['figure.figsize'] = 8, 5\nplt.style.use(\"fivethirtyeight\")\npd.options.plotting.backend = \"plotly\"\n\ndata = pd.read_csv('../input/covid19-tweets/covid19_tweets.csv')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"text = \",\".join(review for review in data.text if 'COVID' not in review and 'https' not in review and 'Covid' not in review)\nwordcloud = WordCloud(max_words=200, colormap='Set3',background_color=\"black\").generate(text)\nplt.figure(figsize=(15,10))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.figure(1,figsize=(12, 12))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# A small look at the Data","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"data.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Some quick questions from the data","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('How many posts are made with #covid19? -> {}\\n'.format(data.shape[0]))\nprint('How many unique users have posted? -> {}\\n'.format(data.user_name.nunique()))\nprint('How many unique locations were the posts made from? -> {}\\n'.format(data.user_location.nunique()))\nprint('How many users have more than 1 million followers(higher chances of spread)? -> {}\\n'.format(data[data['user_followers']>1000000].user_name.nunique()))\nprint('How many users are verified(denoting a known person)? -> {}\\n'.format(data[data['user_verified']==True].user_name.nunique()))\nprint('How many tweets are re-tweets? -> {}'.format(data[data['is_retweet']==True].shape[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style='font-size:18px;'>Ahead in the notebook I will work on proving each of these questions with the help of appropriate visualizations.</p>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Description of data","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"sns.heatmap(data.drop('is_retweet', axis=1).corr())\nplt.title('Correlation in data')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Missing values in the data","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = data.isnull().sum().reset_index().plot(kind='bar', x=0, y='index', color=0)\nfig.update_layout(title='Mising Values Plot', xaxis_title='Count', yaxis_title='Column Names')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style='font-size:16px'>In the description of this dataset it was mentioned tht the tweets crawled have a hashtag of covid19 and so it can be considered that the missing values in the hashtag column contain #covid19 by default<br><br>\nThe user location and user description won't be contributing much to the sentiment of the tweets either. So there is no such need to fix them.</p>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Distributions of the data","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = px.box(data, y=\"user_followers\", color=\"user_verified\",\n                   title=\"User Followers Distribution\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style='font-size:18px'>The above box plot is not much interpretable to get information from them about the distribution, so let's plot a kdeplot and check the distribution.</p>","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"sns.FacetGrid(data, hue=\"user_verified\", height=6,).map(sns.kdeplot, \"user_followers\" ,shade=True).add_legend()\nplt.title('User Follower kdeplot')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"sns.FacetGrid(data, hue=\"user_verified\", height=6,).map(sns.kdeplot, \"user_friends\" ,shade=True).add_legend()\nplt.title('User Friends kdeplot')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"sns.FacetGrid(data, hue=\"user_verified\", height=6,).map(sns.kdeplot, \"user_favourites\" ,shade=True).add_legend()\nplt.title('User Favourites kdeplot')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style='font-size:18px'>All the above variables show a highly skewed distribution and this can be expected since it is twitter data and the number of users with a known personality and high number of followers will be much lesser.</p>","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = data.source.value_counts().reset_index().head(10).plot(kind='bar',x='index',y='source',color='source')\nfig.update_layout(title='Top 10 sources of tweets', xaxis_title='Sources', yaxis_title='')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['text_length'] = data['text'].str.len()\nfig = px.violin(data, y=\"text_length\", color=\"user_verified\",\n                   title=\"Text Length Distribution\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = data.user_location.value_counts().reset_index().head(10).plot(kind='bar',x='index',y='user_location',color='user_location')\nfig.update_layout(title='Top 10 location of tweets', xaxis_title='Locations', yaxis_title='')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def clean_text(text):\n    text = text.lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text\n\n#Source: https://www.kaggle.com/tamilsel/exploring-covid-19-tweets-and-sentiment-analysis\n\ndef text_preprocessing(text):\n    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n    nopunc = clean_text(text)\n    tokenized_text = tokenizer.tokenize(nopunc)\n    combined_text = ' '.join(tokenized_text)\n    return combined_text\n\ndata['text'] = data['text'].apply(text_preprocessing)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"data['hashtag_count'] = data['hashtags'].str.split(',').str.len()\ndata['hashtag_count'] = data['hashtag_count'].fillna(0.0)\nfig = data.hashtag_count.value_counts().reset_index().head(7).plot(kind='bar', x='index', y='hashtag_count', color='hashtag_count')\nfig.update_layout(title='Hashtag Count Distribution', xaxis_title='Hashtag Counts', yaxis_title='')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Exploring the text data","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = data['text'].str.split().str.len().plot(kind='hist')\nfig.update_layout(title='Word Count Distribution', xaxis_title='Word Count', yaxis_title='')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def get_top_n_words(corpus, n=None):\n    vec = CountVectorizer().fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]\n\ncommon_words = get_top_n_words(data['text'], 15)\n    \ndf1 = pd.DataFrame(common_words, columns = ['text' , 'count'])\nfig = df1.plot(kind='bar', x='text', y='count', color='count')\nfig.update_layout(yaxis_title='Count', title='Top 15 words before removing stop words')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#Source: https://www.kdnuggets.com/2019/05/complete-exploratory-data-analysis-visualization-text-data.html\n\ndef get_top_n_words(corpus, n=None):\n    vec = CountVectorizer(stop_words = 'english').fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]\n\ncommon_words = get_top_n_words(data['text'], 15)\n    \ndf1 = pd.DataFrame(common_words, columns = ['text' , 'count'])\nfig = df1.plot(kind='bar', x='text', y='count', color='count')\nfig.update_layout(yaxis_title='Count', title='Top 15 words after removing stop words')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def get_top_n_bigram(corpus, n=None):\n    vec = CountVectorizer(ngram_range=(2, 2)).fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]\n\ncommon_words = get_top_n_bigram(data['text'], 20)\n\ndf1 = pd.DataFrame(common_words, columns = ['text' , 'count'])\nfig = df1.plot(kind='bar', y='text', x='count', color='count')\nfig.update_layout(yaxis_title='Count', title='Top 20 bigrams before removing stop words')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def get_top_n_bigram(corpus, n=None):\n    vec = CountVectorizer(ngram_range=(2, 2), stop_words='english').fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]\n\ncommon_words = get_top_n_bigram(data['text'], 20)\n\ndf1 = pd.DataFrame(common_words, columns = ['text' , 'count'])\nfig = df1.plot(kind='bar', y='text', x='count', color='count')\nfig.update_layout(yaxis_title='Count', title='Top 20 bigrams after removing stop words')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def get_top_n_trigram(corpus, n=None):\n    vec = CountVectorizer(ngram_range=(3, 3)).fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]\n\ncommon_words = get_top_n_trigram(data['text'], 15)\n\ndf1 = pd.DataFrame(common_words, columns = ['text' , 'count'])\nfig = df1.plot(kind='bar', y='text', x='count', color='count')\nfig.update_layout(yaxis_title='Count', title='Top 15 trigrams before removing stop words')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def get_top_n_trigram(corpus, n=None):\n    vec = CountVectorizer(ngram_range=(3, 3), stop_words='english').fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]\n\ncommon_words = get_top_n_trigram(data['text'], 15)\n\ndf1 = pd.DataFrame(common_words, columns = ['text' , 'count'])\nfig = df1.plot(kind='bar', y='text', x='count', color='count')\nfig.update_layout(yaxis_title='Count', title='Top 15 trigrams after removing stop words')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Sentiment Score analysis","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"model = SentimentIntensityAnalyzer()\n\ndef sentiment_score(txt):\n    return model.polarity_scores(txt)['compound']\n\ndata[\"sentiment_score\"] = data[\"text\"].apply(sentiment_score)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = px.violin(data, y=\"sentiment_score\", color=\"user_verified\",\n                   title=\"Sentiment Score Distribution\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df = data[data['sentiment_score']>0.5]\n\nfig = df['user_location'].value_counts().reset_index().head(10).plot(kind='bar', y='user_location', x='index', color='user_location')\nfig.update_layout(title='Location of most positive tweets', xaxis_title='Location', yaxis_title='')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df = data[data['sentiment_score']<0.5]\n\nfig = df['user_location'].value_counts().reset_index().head(10).plot(kind='bar', y='user_location', x='index', color='user_location')\nfig.update_layout(title='Location of most negative tweets', xaxis_title='Location', yaxis_title='')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"data['date'] = pd.to_datetime(data['date'])\ndata['day'] = data['date'].dt.day\n\ndf = data[['day','sentiment_score']].copy()\ndf['avg_sentiment'] = df.groupby('day')['sentiment_score'].transform('mean')\ndf.drop('sentiment_score',axis=1,inplace=True)\ndf = df.drop_duplicates().sort_values('day')\n\ndf.plot(x='day', y='avg_sentiment', title='Sentiment of posts vs days in a month')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = px.scatter(data[data['user_followers']<20000000], x='sentiment_score', y='user_followers', color='user_followers')\nfig.update_layout(title='Sentiment_score vs User_followers')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}