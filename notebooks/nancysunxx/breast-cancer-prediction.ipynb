{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this kernel, we will conduct EDA to select important variables for breast cancer prediction and apply several models(logistic/ decision tree/ random forest/ SVM) to find out the best models. Enjoy! ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#supress warning \nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import tree\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/breast-cancer-wisconsin-data/data.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Attribute Information:\n\n1) ID number  \n2) Diagnosis (M = malignant, B = benign)\n\n\nTen real-valued features are computed for each cell nucleus:  \n\na) radius (mean of distances from center to points on the perimeter)  \nb) texture (standard deviation of gray-scale values)  \nc) perimeter  \nd) area  \ne) smoothness (local variation in radius lengths)  \nf) compactness (perimeter^2 / area - 1.0)  \ng) concavity (severity of concave portions of the contour)  \nh) concave points (number of concave portions of the contour)  \ni) symmetry  \nj) fractal dimension (\"coastline approximation\" - 1)  \n\nThe mean, standard error and \"worst\" or largest (mean of the three\nlargest values) of these features were computed for each image,\nresulting in 30 features. For instance, field 3 is Mean Radius, field\n13 is Radius SE, field 23 is Worst Radius.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#remove last columns, also we don't need id\ndata.drop(data.columns[len(data.columns)-1], axis=1, inplace=True)\ndata.drop('id', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis (EDA)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.diagnosis.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_style('whitegrid')\ndata.diagnosis.value_counts().plot(kind='bar',color=[\"lightblue\", \"salmon\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_val=[]\ncontinuous_val=[]\nfor c in data.columns:\n    #print('==================')\n    #print(f\"{c}:{data[c].unique()}\")\n    if len(data[c].unique()) <= 10:\n        categorical_val.append(c)\n    else:\n        continuous_val.append(c)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(categorical_val)\nprint(continuous_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,50))\nfor i, column in enumerate(continuous_val,1):\n    plt.subplot(10,3,i)\n    sns.distplot(data[data['diagnosis']=='M'][column],rug=False,label=\"M\")\n    sns.distplot(data[data['diagnosis']=='B'][column],rug=False,label='B')\n    plt.xlabel(column)\n    plt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can found malignant and benign tumors show different distribution in some columns:  \nradius_mean: malignant tumors has lager radius mean.  \nperimeter_mean: malignant tumors has lager perimeter mean.  \narea_mean: malignant tumors has lager area mean.\ncompactness_mean: malignant tumors has lager compactness mean.  \nconcavity_mean: malignant tumors has lager concavity_mean.  \nconcavity_points_mean: malignant tumors has lager concavity_points_mean.  \n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = data.replace({'diagnosis':{\"M\":1,\"B\":0}})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix=df.corr()\nfig, ax = plt.subplots(figsize=(15,15))\nax = sns.heatmap(corr_matrix, annot=True, linewidths=0.5, fmt='.2f',cmap='YlGnBu')\nbottom, top = ax.get_ylim()\nax.set_ylim(bottom+0.5, top-0.5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some columns are correlated with each other. For example, area_mean, perimeter_mean and area_mean basically are same things. Thus, we can just keep 1 column to avoid collinearity. For other simulate columns, we'll do the same thing.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"col_drop = ['perimeter_mean','radius_mean','compactness_mean',\n            'concave points_mean','radius_se','perimeter_se',\n            'radius_worst','perimeter_worst','compactness_worst',\n            'concave points_worst','compactness_se','concave points_se',\n            'texture_worst','area_worst','concavity_worst']\ndf2 = df.drop(col_drop,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15,15))\nax = sns.heatmap(df2.corr(), annot=True, linewidths=0.5, fmt='.2f',cmap='YlGnBu')\nbottom, top = ax.get_ylim()\nax.set_ylim(bottom+0.5, top-0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = df2.drop('diagnosis',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Calculate VIF \n#from statsmodels.stats.outliers_influence import variance_inflation_factor\n\n#vif = pd.DataFrame()\n#vif[\"features\"] = x.columns\n#vif[\"VIF Factor\"] = [variance_inflation_factor(x.values, i) for i in range(x.shape[1])]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#vif","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#while vif[vif['VIF Factor'] > 10]['VIF Factor'].any():    \n#    remove = vif.sort_values('VIF Factor',ascending=0)['features'][1] \n    #print(remove)\n    #print(continuous_val)\n#    x.drop(remove,axis=1,inplace=True)\n#    vif = pd.DataFrame()\n#    vif[\"features\"] = x.columns\n#    vif[\"VIF Factor\"] = [variance_inflation_factor(x.values, i) for i in range(x.shape[1])]\n#    print(vif)\n#    print('======================')\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.drop('diagnosis',axis=1).corrwith(df.diagnosis).plot(kind='bar',grid=True,figsize=(12,8),\n                                                       title='Correlation with diagnosis')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see lots of features are highly correlated with diagnosis. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Model Preparation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#there is no categorical variable other than our dependent variables, so we don't have to creat dummy variables for our models.\ncategorical_val","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#store variable names \ncol_sc = list(df2.columns)\ncol_sc.remove('diagnosis')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col_sc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#scale our data\n#from sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\ndf2[col_sc] = sc.fit_transform(df2[col_sc])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Applying Machine Learning Algorithms","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n\ndef score(m, x_train, y_train, x_test, y_test, train=True):\n    if train:\n        pred=m.predict(x_train)\n        print('Train Result:\\n')\n        print(f\"Accuracy Score: {accuracy_score(y_train, pred)*100:.2f}%\")\n        print(f\"Precision Score: {precision_score(y_train, pred)*100:.2f}%\")\n        print(f\"Recall Score: {recall_score(y_train, pred)*100:.2f}%\")\n        print(f\"F1 score: {f1_score(y_train, pred)*100:.2f}%\")\n        print(f\"Confusion Matrix:\\n {confusion_matrix(y_train, pred)}\")\n    elif train == False:\n        pred=m.predict(x_test)\n        print('Test Result:\\n')\n        print(f\"Accuracy Score: {accuracy_score(y_test, pred)*100:.2f}%\")\n        print(f\"Precision Score: {precision_score(y_test, pred)*100:.2f}%\")\n        print(f\"Recall Score: {recall_score(y_test, pred)*100:.2f}%\")\n        print(f\"F1 score: {f1_score(y_test, pred)*100:.2f}%\")\n        print(f\"Confusion Matrix:\\n {confusion_matrix(y_test, pred)}\")\n            \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from sklearn.model_selection import train_test_split\n\nx = df2.drop('diagnosis',axis=1)\ny = df2['diagnosis']\n\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## M1: Logistic Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlogreg = LogisticRegression()\nlogreg = logreg.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score(logreg, x_train, y_train, x_test, y_test, train=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score(logreg, x_train, y_train, x_test, y_test, train=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The result looks pretty great. How about we tuning our model to prevent over-fitting issue and make the model become more general to unseen samples?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#C represents the strength of the regularization. higher values of C correspond to less regularization\nC = [1, .5, .25, .1, .05, .025, .01, .005, .0025] \nl1_metrics = np.zeros((len(C), 5)) \nl1_metrics[:,0] = C\n\nfor index in range(0, len(C)):\n    logreg = LogisticRegression(penalty='l1', C=C[index], solver='liblinear') \n    logreg = logreg.fit(x_train, y_train)\n    pred_test_Y = logreg.predict(x_test)\n    l1_metrics[index,1] = np.count_nonzero(logreg.coef_) \n    l1_metrics[index,2] = accuracy_score(y_test, pred_test_Y) \n    l1_metrics[index,3] = precision_score(y_test, pred_test_Y) \n    l1_metrics[index,4] = recall_score(y_test, pred_test_Y)\n    \ncol_names = ['C','Non-Zero Coeffs','Accuracy','Precision','Recall'] \nprint(pd.DataFrame(l1_metrics, columns=col_names))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We finally choose C=0.25 because it got best performance with fewer parameters.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg_t = LogisticRegression(penalty='l1', C=0.25, solver='liblinear')\nlogreg_t = logreg_t.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score(logreg_t, x_train, y_train, x_test, y_test, train=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score(logreg_t, x_train, y_train, x_test, y_test, train=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Great! This model got slightly better in test sample than the original one. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## M2: Decision Tree","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import tree\n\ntree1 = tree.DecisionTreeClassifier()\ntree1 = tree1.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score(tree1, x_train, y_train, x_test, y_test, train=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score(tree1, x_train, y_train, x_test, y_test, train=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Seems like an over-fitting issue. Again, let's try pruning the tree.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#decide the tree depth!\ndepth_list = list(range(2,15))\ndepth_tuning = np.zeros((len(depth_list), 4)) \ndepth_tuning[:,0] = depth_list\n\nfor index in range(len(depth_list)):\n    mytree = tree.DecisionTreeClassifier(max_depth=depth_list[index]) \n    mytree = mytree.fit(x_train, y_train)\n    pred_test_Y = mytree.predict(x_test)\n    depth_tuning[index,1] = accuracy_score(y_test, pred_test_Y) \n    depth_tuning[index,2] = precision_score(y_test, pred_test_Y) \n    depth_tuning[index,3] = recall_score(y_test, pred_test_Y)\n    \ncol_names = ['Max_Depth','Accuracy','Precision','Recall'] \nprint(pd.DataFrame(depth_tuning, columns=col_names))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Max depth = 3 seems a good choice!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"tree2 = tree.DecisionTreeClassifier(max_depth=3)\ntree2 = tree2.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score(tree2, x_train, y_train, x_test, y_test, train=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score(tree2, x_train, y_train, x_test, y_test, train=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, we can plot the tree!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import graphviz\nexported = tree.export_graphviz( decision_tree=tree2,\n                                out_file=None,\n                                feature_names=x.columns,\n                                precision=1,\n                                class_names=['B','M'], \n                                filled = True)\ngraph = graphviz.Source(exported) \ndisplay(graph)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## M3: Ramdom Forest ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nforest = RandomForestClassifier(n_estimators=1000, random_state= 42)\nforest = forest.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score(forest, x_train, y_train, x_test, y_test, train=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score(forest, x_train, y_train, x_test, y_test, train=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, go with tuning! The article of random forest here provides details in hyperparameter tuning: https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\n\nn_estimators = [int(x) for x in np.linspace(start=200, stop=2000, num=10)]\nmax_features = ['auto', 'sqrt']\nmax_depth = [int(x) for x in np.linspace(10, 110, num=11)]\nmax_depth.append(None)\nmin_samples_split = [2, 5, 10]\nmin_samples_leaf = [1, 2, 4]\nbootstrap = [True, False]\n\nrandom_grid = {'n_estimators': n_estimators, 'max_features': max_features,\n               'max_depth': max_depth, 'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf, 'bootstrap': bootstrap}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_grid","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forest2 = RandomForestClassifier(random_state=42)\n\n#Random search of parameters, using 3 fold cross validation, search across 100 different combinations, and use all available cores\nrf_random = RandomizedSearchCV(estimator = forest2, param_distributions=random_grid,\n                              n_iter=100, cv=3, verbose=2, random_state=42, n_jobs=-1)\n\nrf_random.fit(x_train,y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_random.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forest3 = RandomForestClassifier(bootstrap=True,\n                                 max_depth=20, \n                                 max_features='sqrt', \n                                 min_samples_leaf=2, \n                                 min_samples_split=2,\n                                 n_estimators=1200)\nforest3 = forest3.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score(forest3, x_train, y_train, x_test, y_test, train=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score(forest3, x_train, y_train, x_test, y_test, train=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## M4: SVM ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The important parameters details in SVM model can be founded in here: https://medium.com/all-things-ai/in-depth-parameter-tuning-for-svc-758215394769 ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\nsvm = SVC()\nsvm = svm.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score(svm, x_train, y_train, x_test, y_test, train=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score(svm, x_train, y_train, x_test, y_test, train=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nsvm_model = SVC()\n\nparams = {\"C\":(0.1, 0.5, 1, 2, 5, 10, 20), \n          \"gamma\":(0.001, 0.01, 0.1, 0.25, 0.5, 0.75, 1), \n          \"kernel\":('poly', 'rbf')}\n\nsvm_grid = GridSearchCV(svm_model, params, n_jobs=-1, cv=5, verbose=1, scoring=\"accuracy\")\nsvm_grid.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svm_grid.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svm2 = SVC(C=2, gamma=0.01, kernel='rbf')\nsvm2 = svm2.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score(svm2, x_train, y_train, x_test, y_test, train=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score(svm2, x_train, y_train, x_test, y_test, train=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"In this kernel, we try to select the useful parameters by conducting visualization analysis. We also check the correlation matrix to avoid collinearity. After that, we use logistic, decision tree, random forest and SVM models for prediction, we even tune all this model to prevent over-fitting issue. Comparing the outcome, the logistic model gives the most precise prediction for our test data. \n\n\nThanks for your time!  \nIf this kernel is helpful, please upvote and write comments below to let me know. It would be such a great motivation for me:)","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}