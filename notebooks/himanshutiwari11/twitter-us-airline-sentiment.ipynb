{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6b10eb79c3b300ae20021cb5e2b951a72fbee064"},"cell_type":"code","source":"# Importing the dataset\ndataset = pd.read_csv('../input/Tweets.csv')\n\ndataset.info()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#accessing name of airline\nairline_name = list(dataset['airline'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1fadb30560d8e71080a9cc776f8e68b495f415b7"},"cell_type":"code","source":"#plotting airline sentiment count\nfor i in range(6):\n    plt.subplot(3,2,i+1)\n    df = dataset[dataset['airline']==airline_name[i]]\n    y = df['airline_sentiment'].value_counts()\n    x = y.index\n    plt.bar(x,y)\n    plt.ylabel('Count')\n    plt.xlabel('Sentiment Type')\n    plt.title('Count of Sentiment of '+airline_name[i])\nplt.subplots_adjust(wspace=0.6,hspace=1.4)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c1372a0472e45571acdeecdca7c699e6ccecf6e4"},"cell_type":"code","source":"#plotting negative reasons\nfor i in range(6):\n    df = dataset[dataset['airline']==airline_name[i]]\n    y = df['negativereason'].value_counts()\n    x = y.index\n    plt.bar(x,y)\n    plt.ylabel('Reason Count')\n    plt.xlabel('Reason Name')\n    plt.xticks(x,rotation=90)\n    plt.title('Count of Moods of '+airline_name[i])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"780c9b5e9490bd12a49d542e350fb987db9a7a98"},"cell_type":"code","source":"#importing another library\nfrom wordcloud import WordCloud\n#for all words\ncorpus = []\ntext_series = dataset['text']\nfor i in text_series.index:\n    text = text_series[i].lower()\n    text = text.split()    \n    ps = PorterStemmer()\n    text = [ps.stem(word) for word in text if not word in set(stopwords.words('english'))]\n    text = ' '.join(text)\n    text = re.sub('@[a-zA-Z]+','', text)\n    corpus.append(text)\n    \nall_words = ' '.join([word for word in corpus])\n\nwordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(all_words)\n\nplt.figure(figsize=(10, 7))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fd87effec1377d21723e33edb1b8f5ab1cbed2c1"},"cell_type":"code","source":"corpus1 = []\ntext_series1 = dataset[dataset['airline_sentiment']=='negative']['text']\nfor i in text_series1.index:\n    text = text_series1[i].lower()\n    text = text.split()  \n    ps = PorterStemmer()\n    text = [ps.stem(word) for word in text if not word in set(stopwords.words('english'))]\n    text = ' '.join(text)\n    text = re.sub('@[a-zA-Z]+','', text)\n    corpus1.append(text)\n    \nall_words1 = ' '.join([word for word in corpus1])\n\nwordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(all_words1)\n\nplt.figure(figsize=(10, 7))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"505dd94abde7445e8077e88969010fde3b489642"},"cell_type":"code","source":"# Creating the Bag of Words model\nfrom sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(max_features = 1500)\nX = cv.fit_transform(corpus).toarray()\ny = dataset.iloc[:, 1].values\n\n# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n\n# Fitting Naive Bayes to the Training set\nfrom sklearn.naive_bayes import GaussianNB\nclassifier = GaussianNB()\nclassifier.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_pred = classifier.predict(X_test)\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix, f1_score\ncm = confusion_matrix(y_test, y_pred)\nf1_score = f1_score(y_test, y_pred, average='micro')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"35ac2aec9983c0f705ce4de5d455e6c6712be0f3"},"cell_type":"code","source":"print(f1_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c649115c943b09247264ca1d3adb330628432108"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}