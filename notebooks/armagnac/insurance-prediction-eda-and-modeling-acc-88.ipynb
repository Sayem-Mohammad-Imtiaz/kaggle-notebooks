{"cells":[{"metadata":{},"cell_type":"markdown","source":"\n<h1><center>Insurance Prediction. Data analysis and modeling.</center></h1>\n\n<center><img src=\"https://www.outlookindia.com/outlookmoney/public/uploads/article/gallery/9f5518fc9b70672aaba65aa3af600c32.jpg\"></center>\n"},{"metadata":{},"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:blue; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Quick navigation</center></h2>\n\n* [1. Basic Data Analysis](#1)\n* [2. Feature engineering (In progress)](#2)\n* [3. Modeling (In progress)](#3)"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"1\"></a>\n<h2 style='background:blue; border:0; color:white'><center>1. Basic Data Analysis</center><h2>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objs as go\nimport matplotlib.pyplot as plt\n\nimport seaborn as sns\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n\nimport optuna\nfrom optuna.samplers import TPESampler\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.manifold import TSNE\n\n!pip install pyod\n\nfrom pyod.models.copod import COPOD","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/health-insurance-cross-sell-prediction/train.csv')\ntest = pd.read_csv('/kaggle/input/health-insurance-cross-sell-prediction/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"#### train"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.drop(['id'], axis=1)\ntest = test.drop(['id'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = make_subplots(rows=1, cols=2)\n\ntraces = [\n    go.Bar(\n        x=['Male', 'Female'], \n        y=[\n            len(train[train['Gender']=='Male']),\n            len(train[train['Gender']=='Female'])\n        ], \n        name='Train Gender',\n        text = [\n            str(round(100 * len(train[train['Gender']=='Male']) / len(train), 2)) + '%',\n            str(round(100 * len(train[train['Gender']=='Female']) / len(train), 2)) + '%'\n        ],\n        textposition='auto'\n    ),\n    go.Bar(\n        x=['Male', 'Female'], \n        y=[\n            len(test[test['Gender']=='Male']),\n            len(test[test['Gender']=='Female'])\n        ], \n        name='Test Gender',\n        text=[\n            str(round(100 * len(test[test['Gender']=='Male']) / len(test), 2)) + '%',\n            str(round(100 * len(test[test['Gender']=='Female']) / len(test), 2)) + '%'\n        ],\n        textposition='auto'\n    ),\n\n]\n\nfor i in range(len(traces)):\n    fig.append_trace(traces[i], (i // 2) + 1, (i % 2)  +1)\n\nfig.update_layout(\n    title_text='Train/test gender column',\n    height=400,\n    width=700\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = make_subplots(rows=1, cols=2)\n\ntraces = [\n    go.Bar(\n        x=['Yes', 'No'], \n        y=[\n            len(train[train['Driving_License']==1]),\n            len(train[train['Driving_License']==0])\n        ], \n        name='Train Driving_License',\n        text = [\n            str(round(100 * len(train[train['Driving_License']==1]) / len(train), 2)) + '%',\n            str(round(100 * len(train[train['Driving_License']==0]) / len(train), 2)) + '%'\n        ],\n        textposition='auto'\n    ),\n    go.Bar(\n        x=['Yes', 'No'], \n        y=[\n            len(test[test['Driving_License']==1]),\n            len(test[test['Driving_License']==0])\n        ], \n        name='Test Driving_License',\n        text=[\n            str(round(100 * len(test[test['Driving_License']==1]) / len(test), 2)) + '%',\n            str(round(100 * len(test[test['Driving_License']==0]) / len(test), 2)) + '%'\n        ],\n        textposition='auto'\n    ),\n\n]\n\nfor i in range(len(traces)):\n    fig.append_trace(traces[i], (i // 2) + 1, (i % 2)  +1)\n\nfig.update_layout(\n    title_text='Train/test Driving_License column',\n    height=400,\n    width=700\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = make_subplots(rows=1, cols=2)\n\ntraces = [\n    go.Bar(\n        x=['Yes', 'No'], \n        y=[\n            len(train[train['Previously_Insured']==1]),\n            len(train[train['Previously_Insured']==0])\n        ], \n        name='Train Previously_Insured',\n        text = [\n            str(round(100 * len(train[train['Previously_Insured']==1]) / len(train), 2)) + '%',\n            str(round(100 * len(train[train['Previously_Insured']==0]) / len(train), 2)) + '%'\n        ],\n        textposition='auto'\n    ),\n    go.Bar(\n        x=['Yes', 'No'], \n        y=[\n            len(test[test['Previously_Insured']==1]),\n            len(test[test['Previously_Insured']==0])\n        ], \n        name='Test Previously_Insured',\n        text = [\n            str(round(100 * len(test[test['Previously_Insured']==1]) / len(test), 2)) + '%',\n            str(round(100 * len(test[test['Previously_Insured']==0]) / len(test), 2)) + '%'\n        ],\n        textposition='auto'\n    ),\n\n]\n\nfor i in range(len(traces)):\n    fig.append_trace(traces[i], (i // 2) + 1, (i % 2)  +1)\n\nfig.update_layout(\n    title_text='Train/test Previously_Insured column',\n    height=400,\n    width=700\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = make_subplots(rows=1, cols=2)\n\ntraces = [\n    go.Bar(\n        x=['Yes', 'No'], \n        y=[\n            len(train[train['Vehicle_Damage']=='Yes']),\n            len(train[train['Vehicle_Damage']=='No'])\n        ], \n        name='Train Vehicle_Damage',\n        text = [\n            str(round(100 * len(train[train['Vehicle_Damage']=='Yes']) / len(train), 2)) + '%',\n            str(round(100 * len(train[train['Vehicle_Damage']=='No']) / len(train), 2)) + '%'\n        ],\n        textposition='auto'\n    ),\n    go.Bar(\n        x=['Yes', 'No'], \n        y=[\n            len(test[test['Vehicle_Damage']=='Yes']),\n            len(test[test['Vehicle_Damage']=='No'])\n        ], \n        name='Test Vehicle_Damage',\n        text = [\n            str(round(100 * len(test[test['Vehicle_Damage']=='Yes']) / len(test), 2)) + '%',\n            str(round(100 * len(test[test['Vehicle_Damage']=='No']) / len(test), 2)) + '%'\n        ],\n        textposition='auto'\n    ),\n\n]\n\nfor i in range(len(traces)):\n    fig.append_trace(traces[i], (i // 2) + 1, (i % 2)  +1)\n\nfig.update_layout(\n    title_text='Train/test Vehicle_Damage column',\n    height=400,\n    width=700\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = make_subplots(rows=1, cols=2)\n\ntraces = [\n    go.Bar(\n        x=['> 2 Years', '1-2 Year', '< 1 Year'], \n        y=[\n            len(train[train['Vehicle_Age']=='> 2 Years']),\n            len(train[train['Vehicle_Age']=='1-2 Year']),\n            len(train[train['Vehicle_Age']=='< 1 Year'])\n        ], \n        name='Train Vehicle_Age',\n        text = [\n            str(round(100 * len(train[train['Vehicle_Age']=='> 2 Years']) / len(train), 2)) + '%',\n            str(round(100 * len(train[train['Vehicle_Age']=='1-2 Year']) / len(train), 2)) + '%',\n            str(round(100 * len(train[train['Vehicle_Age']=='< 1 Year']) / len(train), 2)) + '%'\n        ],\n        textposition='auto'\n    ),\n    go.Bar(\n        x=['> 2 Years', '1-2 Year', '< 1 Year'], \n        y=[\n            len(test[test['Vehicle_Age']=='> 2 Years']),\n            len(test[test['Vehicle_Age']=='1-2 Year']),\n            len(test[test['Vehicle_Age']=='< 1 Year'])\n        ], \n        name='Test Vehicle_Age',\n        text = [\n            str(round(100 * len(test[test['Vehicle_Age']=='> 2 Years']) / len(test), 2)) + '%',\n            str(round(100 * len(test[test['Vehicle_Age']=='1-2 Year']) / len(test), 2)) + '%',\n            str(round(100 * len(test[test['Vehicle_Age']=='< 1 Year']) / len(test), 2)) + '%'\n        ],\n        textposition='auto'\n    ),\n\n]\n\nfor i in range(len(traces)):\n    fig.append_trace(traces[i], (i // 2) + 1, (i % 2)  +1)\n\nfig.update_layout(\n    title_text='Train/test Vehicle_Age column',\n    height=400,\n    width=700\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = make_subplots(rows=1, cols=2)\n\ntraces = [\n    go.Histogram(\n        x=train['Age'], \n        name='Train Age'\n    ),\n    go.Histogram(\n        x=test['Age'], \n        name='Test Age'\n    ),\n\n]\n\nfor i in range(len(traces)):\n    fig.append_trace(traces[i], (i // 2) + 1, (i % 2)  +1)\n\nfig.update_layout(\n    title_text='Train/test Age column distribution',\n    height=500,\n    width=900\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = make_subplots(rows=1, cols=2)\n\ntraces = [\n    go.Histogram(\n        x=train['Annual_Premium'], \n        name='Train Annual_Premium'\n    ),\n    go.Histogram(\n        x=test['Annual_Premium'], \n        name='Test Annual_Premium'\n    ),\n\n]\n\nfor i in range(len(traces)):\n    fig.append_trace(traces[i], (i // 2) + 1, (i % 2)  +1)\n\nfig.update_layout(\n    title_text='Train/test Annual_Premium column distribution',\n    height=500,\n    width=800\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = make_subplots(rows=1, cols=2)\n\ntraces = [\n    go.Histogram(\n        x=train['Policy_Sales_Channel'], \n        name='Train Policy_Sales_Channel'\n    ),\n    go.Histogram(\n        x=test['Policy_Sales_Channel'], \n        name='Test Policy_Sales_Channel'\n    ),\n\n]\n\nfor i in range(len(traces)):\n    fig.append_trace(traces[i], (i // 2) + 1, (i % 2)  +1)\n\nfig.update_layout(\n    title_text='Train/test Policy_Sales_Channel column distribution',\n    height=500,\n    width=800\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = make_subplots(rows=1, cols=2)\n\ntraces = [\n    go.Histogram(\n        x=train['Vintage'], \n        name='Train Vintage'\n    ),\n    go.Histogram(\n        x=test['Vintage'], \n        name='Test Vintage'\n    ),\n\n]\n\nfor i in range(len(traces)):\n    fig.append_trace(traces[i], (i // 2) + 1, (i % 2)  +1)\n\nfig.update_layout(\n    title_text='Train/test Vintage column distribution',\n    height=500,\n    width=800\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"tr = train['Region_Code'].value_counts().reset_index()\nx_tr = tr['index'].tolist()\ny_tr = tr['Region_Code'].tolist()\nte = test['Region_Code'].value_counts().reset_index()\nx_te = te['index'].tolist()\ny_te = te['Region_Code'].tolist()\n\nfig = make_subplots(rows=2, cols=1)\n\ntraces = [\n    go.Bar(\n        x=x_tr, \n        y=y_tr, \n        name='Train Region_Code'\n    ),\n    go.Bar(\n        x=x_te, \n        y=y_te, \n        name='Test Region_Code'\n    )\n]\n\nfor i in range(len(traces)):\n    fig.append_trace(traces[i], (i // 1) + 1, (i % 1)  +1)\n\nfig.update_layout(\n    title_text='Train / test Region_Code',\n    height=900,\n    width=800\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = make_subplots(rows=1, cols=1)\n\ntraces = [\n    go.Bar(\n        x=['Yes', 'No'], \n        y=[\n            len(train[train['Response']==1]),\n            len(train[train['Response']==0])\n        ], \n        name='Train Response'\n    ),\n]\n\nfor i in range(len(traces)):\n    fig.append_trace(traces[i], (i // 2) + 1, (i % 2)  +1)\n\nfig.update_layout(\n    title_text='Train Response column',\n    height=400,\n    width=400\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### As we can see from initial analysis all columns presented in dataset have exactly the same ditribution. Let's do feature engineering and modeling next."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = px.histogram(\n    train, \n    \"Age\", \n    color='Response',\n    nbins=100, \n    title='Age & Response ditribution', \n    width=700,\n    height=500\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = px.histogram(\n    train, \n    \"Age\", \n    color='Response',\n    nbins=100, \n    title='Age & Response ditribution', \n    width=700,\n    height=500\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = px.histogram(\n    train[train['Response'] == 1], \n    \"Age\", \n    nbins=100, \n    title='Age distribution for positive response', \n    width=700,\n    height=500\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = make_subplots(rows=1, cols=2)\n\ntraces = [\n    go.Bar(\n        x=['Declined', 'Accepted'], \n        y=[\n            len(train[(train['Gender']=='Male') & (train['Response']==0)]),\n            len(train[(train['Gender']=='Male') & (train['Response']==1)])\n        ], \n        name='Gender: Male'\n    ),\n    go.Bar(\n        x=['Declined', 'Accepted'],  \n        y=[\n            len(train[(train['Gender']=='Female') & (train['Response']==0)]),\n            len(train[(train['Gender']=='Female') & (train['Response']==1)])\n        ], \n        name='Gender: Female'\n    ),\n\n]\n\nfor i in range(len(traces)):\n    fig.append_trace(traces[i], (i // 2) + 1, (i % 2)  +1)\n\nfig.update_layout(\n    title_text='Train gender/response dependencies',\n    height=400,\n    width=700\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = make_subplots(rows=1, cols=2)\n\ntraces = [\n    go.Bar(\n        x=['Declined', 'Accepted'], \n        y=[\n            len(train[(train['Previously_Insured']==0) & (train['Response']==0)]),\n            len(train[(train['Previously_Insured']==0) & (train['Response']==1)])\n        ], \n        name='Previously_Insured: Previously Not Insured'\n    ),\n    go.Bar(\n        x=['Declined', 'Accepted'],  \n        y=[\n            len(train[(train['Previously_Insured']==1) & (train['Response']==0)]),\n            len(train[(train['Previously_Insured']==1) & (train['Response']==1)])\n        ], \n        name='Previously_Insured: Previously Insured'\n    ),\n\n]\n\nfor i in range(len(traces)):\n    fig.append_trace(traces[i], (i // 2) + 1, (i % 2)  +1)\n\nfig.update_layout(\n    title_text='Train previously_insured/response dependencies',\n    height=400,\n    width=700\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = make_subplots(rows=1, cols=2)\n\ntraces = [\n    go.Bar(\n        x=['Declined', 'Accepted'], \n        y=[\n            len(train[(train['Vehicle_Damage']=='No') & (train['Response']==0)]),\n            len(train[(train['Vehicle_Damage']=='No') & (train['Response']==1)])\n        ], \n        name='Vehicle_Damage: No'\n    ),\n    go.Bar(\n        x=['Declined', 'Accepted'],  \n        y=[\n            len(train[(train['Vehicle_Damage']=='Yes') & (train['Response']==0)]),\n            len(train[(train['Vehicle_Damage']=='Yes') & (train['Response']==1)])\n        ], \n        name='Vehicle_Damage: Yes'\n    ),\n\n]\n\nfor i in range(len(traces)):\n    fig.append_trace(traces[i], (i // 2) + 1, (i % 2)  +1)\n\nfig.update_layout(\n    title_text='Train vehicle_damage/response dependencies',\n    height=400,\n    width=700\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = make_subplots(rows=1, cols=3)\n\ntraces = [\n    go.Bar(\n        x=['Declined', 'Accepted'], \n        y=[\n            len(train[(train['Vehicle_Age']=='> 2 Years') & (train['Response']==0)]),\n            len(train[(train['Vehicle_Age']=='> 2 Years') & (train['Response']==1)])\n        ], \n        name='Vehicle_Age: > 2 Years'\n    ),\n    go.Bar(\n        x=['Declined', 'Accepted'], \n        y=[\n            len(train[(train['Vehicle_Age']=='1-2 Year') & (train['Response']==0)]),\n            len(train[(train['Vehicle_Age']=='1-2 Year') & (train['Response']==1)])\n        ], \n        name='Vehicle_Age: 1-2 Year'\n    ),\n    go.Bar(\n        x=['Declined', 'Accepted'], \n        y=[\n            len(train[(train['Vehicle_Age']=='< 1 Year') & (train['Response']==0)]),\n            len(train[(train['Vehicle_Age']=='< 1 Year') & (train['Response']==1)])\n        ], \n        name='Vehicle_Age: < 1 Year'\n    ),\n\n]\n\nfor i in range(len(traces)):\n    fig.append_trace(traces[i], (i // 3) + 1, (i % 3)  +1)\n\nfig.update_layout(\n    title_text='Train/test Vehicle_Age/Response dependencies',\n    height=400,\n    width=800\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = px.histogram(\n    train, \n    \"Annual_Premium\", \n    color='Response',\n    nbins=100, \n    title='Annual_Premium & Response ditribution', \n    width=700,\n    height=500\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = px.histogram(\n    train[train['Response'] == 1], \n    \"Annual_Premium\", \n    nbins=100, \n    title='Annual_Premium distribution for positive response', \n    width=700,\n    height=500\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = px.histogram(\n    train, \n    \"Vintage\", \n    color='Response',\n    nbins=100, \n    title='Vintage & Response ditribution', \n    width=700,\n    height=500\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = px.histogram(\n    train[train['Response'] == 1], \n    \"Vintage\", \n    nbins=100, \n    title='Vintage distribution for positive response', \n    width=700,\n    height=500\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"2\"></a>\n<h2 style='background:blue; border:0; color:white'><center>2. Feature Engineering</center><h2>"},{"metadata":{},"cell_type":"markdown","source":"#### 1) Convert columns with text values"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.loc[train['Gender'] == 'Male', 'Gender'] = 1\ntrain.loc[train['Gender'] == 'Female', 'Gender'] = 0\ntest.loc[test['Gender'] == 'Male', 'Gender'] = 1\ntest.loc[test['Gender'] == 'Female', 'Gender'] = 0\n\ntrain.loc[train['Vehicle_Age'] == '> 2 Years', 'Vehicle_Age'] = 2\ntrain.loc[train['Vehicle_Age'] == '1-2 Year', 'Vehicle_Age'] = 1\ntrain.loc[train['Vehicle_Age'] == '< 1 Year', 'Vehicle_Age'] = 0\ntest.loc[test['Vehicle_Age'] == '> 2 Years', 'Vehicle_Age'] = 2\ntest.loc[test['Vehicle_Age'] == '1-2 Year', 'Vehicle_Age'] = 1\ntest.loc[test['Vehicle_Age'] == '< 1 Year', 'Vehicle_Age'] = 0\n\ntrain.loc[train['Vehicle_Damage'] == 'Yes', 'Vehicle_Damage'] = 1\ntrain.loc[train['Vehicle_Damage'] == 'No', 'Vehicle_Damage'] = 0\ntest.loc[test['Vehicle_Damage'] == 'Yes', 'Vehicle_Damage'] = 1\ntest.loc[test['Vehicle_Damage'] == 'No', 'Vehicle_Damage'] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in train.columns:\n    train[col] = train[col].astype(np.int32)\n\ntrain","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"f = plt.figure(figsize=(13, 11))\nplt.matshow(train.corr(), fignum=f.number)\nplt.xticks(range(train.shape[1]), train.columns, fontsize=14, rotation=75)\nplt.yticks(range(train.shape[1]), train.columns, fontsize=14)\ncb = plt.colorbar()\ncb.ax.tick_params(labelsize=14)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Correlation for every feature with target"},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in train.columns:\n    if col == 'Response':\n        continue\n    print(col, train[col].corr(train['Response']))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = px.scatter(\n    train, \n    x=\"Annual_Premium\", \n    y=\"Age\", \n    color=\"Response\",\n    width=600,\n    height=600,\n    title='Annual_premium vs Age scatter'\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"3\"></a>\n<h2 style='background:blue; border:0; color:white'><center>3. Modeling</center><h2>"},{"metadata":{},"cell_type":"markdown","source":"#### Let's try unsupervised learning first. We will us kmeans clustering algorithm to check scores."},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.drop(['Response'], axis=1)\ny = train['Response']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans = KMeans(n_clusters=2, random_state=666).fit(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['cluster'] = kmeans.labels_\ntrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['cluster'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Kmeans accuracy: ', accuracy_score(train['Response'], train['cluster']))\nprint('Kmeans f1_score: ', f1_score(train['Response'], train['cluster']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Now let's try to use COPOD anomaly detection model and check results"},{"metadata":{"trusted":true},"cell_type":"code","source":"response = train['Response']\ntrain = train.drop(['Response', 'cluster'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = COPOD(contamination=0.15)\nclf.fit(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cluster = clf.predict(train)\ntrain['cluster'] = cluster\ntrain['Response'] = response\ntrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['cluster'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('COPOD accuracy: ', accuracy_score(train['Response'], train['cluster']))\nprint('COPOD f1_score: ', f1_score(train['Response'], train['cluster']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's build our first version of classifier and use Logistic Regression"},{"metadata":{},"cell_type":"markdown","source":"### Now we will create validation set"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=666)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Positive cases % in validation set: ', round(100 * len(y_test[y_test == 1]) / len(y_test), 3), '%')\nprint('Positive cases % in train set: ', round(100 * len(y_train[y_train == 1]) / len(y_train), 3), '%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### So we can see that our sets are well balanced by target column and we can use our validation set for testing."},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"model = LogisticRegression(random_state=666)\nmodel.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = model.predict(X_test)\nprint('Simple Logistic Regression accuracy: ', accuracy_score(y_test, preds))\nprint('Simple Logistic Regression f1_score: ', f1_score(y_test, preds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_test, preds)\n\nax= plt.subplot()\nsns.heatmap(cm, annot=True, ax = ax, fmt='g')\n\nax.set_xlabel('Predicted labels')\nax.set_ylabel('True labels')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train.drop(['Region_Code', 'Vintage', 'Driving_License'], axis=1)\nX_test = X_test.drop(['Region_Code', 'Vintage', 'Driving_License'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LogisticRegression(random_state=666)\nmodel.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = model.predict(X_test)\nprint('Simple Logistic Regression accuracy: ', accuracy_score(y_test, preds))\nprint('Simple Logistic Regression f1_score: ', f1_score(y_test, preds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_test, preds)\n\nax= plt.subplot()\nsns.heatmap(cm, annot=True, ax = ax, fmt='g')\n\nax.set_xlabel('Predicted labels')\nax.set_ylabel('True labels')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### After removing some columns predictions become better but still not good."},{"metadata":{},"cell_type":"markdown","source":"#### Let's build LightGBM with default parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"from lightgbm import LGBMClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LGBMClassifier(random_state=666)\nmodel.fit(X_train, y_train)\n\npreds = model.predict(X_test)\nprint('Simple LGBM accuracy: ', accuracy_score(y_test, preds))\nprint('Simple LGBM Regression f1_score: ', f1_score(y_test, preds))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Still not good. Let's try to optimize hyperparameters. to save time we will run optimization for 5 rounds but will take parameters that I got from previous versions."},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model(trial):\n    max_depth = trial.suggest_int(\"max_depth\", 2, 30)\n    n_estimators = trial.suggest_int(\"n_estimators\", 1, 500)\n    learning_rate = trial.suggest_uniform('learning_rate', 0.0000001, 1)\n    num_leaves = trial.suggest_int(\"num_leaves\", 2, 5000)\n    min_child_samples = trial.suggest_int('min_child_samples', 3, 200)\n    model = LGBMClassifier(\n        learning_rate=learning_rate, \n        n_estimators=n_estimators, \n        max_depth=max_depth,\n        num_leaves=num_leaves, \n        min_child_samples=min_child_samples,\n        random_state=0\n    )\n    return model\n\nsampler = TPESampler(seed=0)\ndef objective(trial):\n    model = create_model(trial)\n    model.fit(X_train, y_train)\n    preds = model.predict(X_test)\n    score = f1_score(y_test, preds)\n    return score\n\nstudy = optuna.create_study(direction=\"maximize\", sampler=sampler)\nstudy.optimize(objective, n_trials=5)\n\n#lgb_params = study.best_params\nlgb_params = {'max_depth': 26, 'n_estimators': 271, 'learning_rate': 0.6545636603165619, 'num_leaves': 2145, 'min_child_samples': 14}\nlgb_params['random_state'] = 0\nlgb = LGBMClassifier(**lgb_params)\nlgb.fit(X_train, y_train)\npreds = lgb.predict(X_test)\nprint('Optimized LightGBM: ', accuracy_score(y_test, preds))\nprint('Optimized LightGBM f1-score', f1_score(y_test, preds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_test, preds)\n\nax= plt.subplot()\nsns.heatmap(cm, annot=True, ax = ax, fmt='g')\n\nax.set_xlabel('Predicted labels')\nax.set_ylabel('True labels')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\n\ndef create_model(trial):\n    max_depth = trial.suggest_int(\"max_depth\", 2, 30)\n    n_estimators = trial.suggest_int(\"n_estimators\", 1, 500)\n    learning_rate = trial.suggest_uniform('learning_rate', 0.0000001, 1)\n    gamma = trial.suggest_uniform('gamma', 0.0000001, 1)\n    model = XGBClassifier(learning_rate=learning_rate, n_estimators=n_estimators, max_depth=max_depth, gamma=gamma, random_state=0)\n    return model\n\ndef objective(trial):\n    model = create_model(trial)\n    model.fit(X_train, y_train)\n    preds = model.predict(X_test)\n    score = f1_score(y_test, preds)\n    return score\n\nstudy = optuna.create_study(direction=\"maximize\", sampler=sampler)\nstudy.optimize(objective, n_trials=1)\n\n#xgb_params = study.best_params\nxgb_params = {\n    'max_depth': 30, \n    'n_estimators': 136, \n    'learning_rate': 0.9867989680498112, \n    'gamma': 0.044733094210744555\n}\nxgb_params['random_state'] = 0\nxgb = XGBClassifier(**xgb_params)\nxgb.fit(X_train, y_train)\npreds = xgb.predict(X_test)\nprint('Optimized XGBClassifier accuracy: ', accuracy_score(y_test, preds))\nprint('Optimized XGBClassifier f1-score', f1_score(y_test, preds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_test, preds)\n\nax= plt.subplot()\nsns.heatmap(cm, annot=True, ax = ax, fmt='g')\n\nax.set_xlabel('Predicted labels')\nax.set_ylabel('True labels')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm /cm.astype(np.float).sum(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score\nprint(precision_score(y_test, preds))\nprint(recall_score(y_test, preds))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Work in Progress"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_preds = preds.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.get(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#cm = confusion_matrix(y_test, preds)\n\nfn_rate = confusion_matrix(y_test, preds_df)[1][0]\nprint(fn_rate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.query('Age < 40 and Age > 30')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.loc[(X_test['Age'] > 35) & (X_test['Age'] < 40) & (X_test['Previously_Insured'] == 1) ].size / X_test.size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_test.loc[(X_test['Age'] > 40) & (X_test['Age'] < 45) & (X_test['Vehicle_Age'] == 2) ].size / X_test.size * 100)\nprint(X_train.loc[(X_train['Age'] > 40) & (X_train['Age'] < 45) & (X_train['Vehicle_Age'] == 2) ].size / X_train.size * 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.loc[(X_test['Previously_Insured'] == 0) ].size / X_test.size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmax(preds_proba[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_argmax = [np.argmax(a) for a in preds_proba]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all(preds_argmax == preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##################################################################","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# save original test data \nx_test_orig = X_test.copy()\ny_test_orig = y_test.copy()\npreds_orig = preds.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set to Test data\n# X_test = x_test_orig\n# y_test = y_test_orig\n# preds = preds_orig\n\n# Set to Train data\nX_test = X_train\ny_test = y_train\npreds = xgb.predict(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_df = pd.Series(preds)\npreds_df.index = y_test.index.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 0. Data segments data generator\nMIN_VAL = 0\nMAX_VAL = 100\nINTERVAL = 10\n\nconditions = []\nfor i in range(MIN_VAL, MAX_VAL, INTERVAL):\n    conditions.append((i, i+INTERVAL))\n    \nfor condition in conditions:\n    cur_filter = 'Age > %d and Age <= %d' % (condition[0], condition[1])\n#     cur_filter = 'Annual_Premium > %d and Annual_Premium <= %d' % (condition[0], condition[1])\n#     cur_filter = 'Annual_Premium > %d and Annual_Premium < %d and Age >30 and Age <=40' % (condition[0], condition[1])\n    filtered_indexes = X_test.query(cur_filter).index\n#     print(\"%d - %d\" % (condition[0], condition[1]))\n    print(\"Age %d - %d,%d,%.3f,%.3f\" % (condition[0], condition[1], X_test.loc[filtered_indexes].shape[0], X_test.loc[filtered_indexes].shape[0] / X_test.shape[0] * 100, accuracy_score(y_test.loc[filtered_indexes], preds_df.loc[filtered_indexes]),))\n#     print('Segment size:', X_test.loc[filtered_indexes].shape[0])\n#     print('Representing %.2f%%' % (X_test.loc[filtered_indexes].shape[0] / X_test.shape[0] * 100,))\n#     print('Segment accuracy: %.2f' % (accuracy_score(y_test.loc[filtered_indexes], preds_df.loc[filtered_indexes]),))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 0.1 Generate deep combinations segments\nimport itertools\n\ninteresting_segs = \"\"\"Age > 20 and Age <= 25\nAge > 25 and Age <= 30\nAge > 40 and Age <= 45\nAge > 45 and Age <= 50\nAnnual_Premium > 2000 and Annual_Premium <= 3000\nPolicy_Sales_Channel == 157\nPolicy_Sales_Channel == 156\nPolicy_Sales_Channel == 124\nPolicy_Sales_Channel == 26\nPolicy_Sales_Channel == 152\nPreviously_Insured == 0\nPreviously_Insured == 1\nVehicle_Age == 0\nVehicle_Age == 1\nVehicle_Damage == 0\nVehicle_Damage == 1\"\"\".splitlines()\n\ncombinations = itertools.combinations(interesting_segs, 4)\nfilters = [' and '.join(c) for c in combinations]\nfilters = [f for f in filters if \\\n           f.count('Age ') <= 2 and f.count('Annual') <= 2 \\\n         and f.count('Policy') <=1 and f.count('_Age') <= 1 and f.count('_Damage') <= 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(filters)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for cur_filter in filters:\n    filtered_indexes = X_test.query(cur_filter).index\n    print(\"%s,%d,%.3f,%.3f\" % (cur_filter, X_test.loc[filtered_indexes].shape[0], X_test.loc[filtered_indexes].shape[0] / X_test.shape[0] * 100, accuracy_score(y_test.loc[filtered_indexes], preds_df.loc[filtered_indexes]),))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1. Filter data by segment\n#condition = 'Annual_Premium > 2000 and Annual_Premium <= 3000'# and Age > 30 and Age <= 40' # and Vehicle_Age == 2' # Annual_Premium < 10000'\ncondition = 'Annual_Premium > 2000 and Annual_Premium <= 3000 and Policy_Sales_Channel == 157 and Vehicle_Damage == 1' #Age > 35 and Age <= 40'# and Age > 30 and Age <= 40' # and Vehicle_Age == 2' # Annual_Premium < 10000'\n\nfiltered_indexes = X_test.query(condition).index\n# negation_indexes = X_test.loc[~X_test.index.isin(filtered_indexes)].index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2. Show segment size and %\nprint('Segment size:', X_test.loc[filtered_indexes].shape[0])\nprint('Representing %.2f%%' % (X_test.loc[filtered_indexes].shape[0] / X_test.shape[0] * 100,))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 3. Show accuracy for segment vs overall accuracy\nprint('All data accuracy: %.3f' % (accuracy_score(y_test, preds_df),))\nprint('Segment accuracy: %.3f' % (accuracy_score(y_test.loc[filtered_indexes], preds_df.loc[filtered_indexes]),))\nprint('All data recall: %.3f' % (recall_score(y_test, preds_df),))\nprint('Segment recall: %.3f' % (recall_score(y_test.loc[filtered_indexes], preds_df.loc[filtered_indexes]),))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 3.5. Show prediction distribution for segment\nfig = px.histogram(\n    preds_df.loc[filtered_indexes], \n    color = (preds_df.loc[filtered_indexes] == y_test.loc[filtered_indexes]),\n    nbins=100, \n    title='Segment prediction distribution', \n    width=700,\n    height=500\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 4. Show proba() distribution for segment\npreds_proba = xgb.predict_proba(X_test)\npreds_proba_df = pd.DataFrame(data=preds_proba, columns=[0,1])\npreds_proba_df.index = y_test.index.tolist()\n\nfig = px.histogram(\n    preds_proba_df.loc[filtered_indexes],\n    nbins=100, \n    title='Segment probabilities distribution', \n    width=700,\n    height=500\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 5. Change argmax to another logic\ndef calc_segment_pred(row):\n    if row[1] > 0.27:\n        return 1\n    return 0\n\nall_preds_modified_df = preds_proba_df.apply(calc_segment_pred, axis=1)\n\n# Change predictions\nfinal_modified_preds_df = preds_df.copy()\n# print('Modified Segment accuracy: %.2f%%' % (accuracy_score(y_test.loc[filtered_indexes], final_modified_preds_df.loc[filtered_indexes]),))\nfinal_modified_preds_df.loc[filtered_indexes] = all_preds_modified_df.loc[filtered_indexes]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 6. Measure Recall\nprint('All data recall: %.3f%%' % (recall_score(y_test, preds_df),))\n\noriginal_segment_recall = recall_score(y_test.loc[filtered_indexes], preds_df.loc[filtered_indexes])\nprint('Original Segment recall: %.3f%%' % (original_segment_recall,))\n\nmodified_segment_recall = recall_score(y_test.loc[filtered_indexes], final_modified_preds_df.loc[filtered_indexes])\nprint('Modified Segment recall: %.3f%%' % (modified_segment_recall,))\n\nprint('Modified all data recall: %.3f%%' % (recall_score(y_test, final_modified_preds_df),))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 6. Measure Accuracy\nprint('All data accuracy: %.3f%%' % (accuracy_score(y_test, preds_df),))\nprint('Original Segment accuracy: %.3f%%' % (accuracy_score(y_test.loc[filtered_indexes], preds_df.loc[filtered_indexes]),))\nprint('Modified Segment accuracy: %.3f%%' % (accuracy_score(y_test.loc[filtered_indexes], final_modified_preds_df.loc[filtered_indexes]),))\nprint('Modified all data accuracy: %.3f%%' % (accuracy_score(y_test, final_modified_preds_df),))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 7. confusion matrix for segment\ncm = confusion_matrix(y_test.loc[filtered_indexes], final_modified_preds_df.loc[filtered_indexes])\n\nax= plt.subplot()\nsns.heatmap(cm, annot=True, ax = ax, fmt='g')\n\nax.set_xlabel('Predicted labels')\nax.set_ylabel('True labels')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 7. confusion matrix for original segment\ncm_orig = confusion_matrix(y_test.loc[filtered_indexes], preds_df.loc[filtered_indexes])\n\nax= plt.subplot()\nsns.heatmap(cm_orig, annot=True, ax = ax, fmt='g')\n\nax.set_xlabel('Predicted labels')\nax.set_ylabel('True labels')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 6.5 business metrics\n# print('%d more customers would get calls and buy insurance' % ((modified_segment_recall - original_segment_recall) * X_test.loc[filtered_indexes].shape[0],))\nprint('%d more customers would get calls and buy insurance (%d now vs. %d before)' % (cm[1][1] - cm_orig[1][1], cm[1][1], cm_orig[1][1]))\nprint('%d more calls (%d now vs. %d before) would be wasted by people that would not buy' % (cm[0][1] - cm_orig[0][1], cm[1][1] + cm[0][1], cm_orig[1][1] + cm_orig[0][1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n# Function: Plotting Confusion Matrix\ndef _plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Greens):\n    from sklearn.metrics import precision_score, recall_score, roc_auc_score, accuracy_score, roc_curve, auc, confusion_matrix\n    import itertools\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title, fontsize = 14)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"black\")\n\n    plt.ylabel('True Class', fontsize = 14)\n    plt.xlabel('Predicted Class', fontsize = 14)\n\n    plt.tick_params(axis='both', which='major', labelsize=14)\n    plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n# Function: Finding thresholds\ndef _threshold_finder(model, X, y_true):\n    from scipy import interp\n    from sklearn.preprocessing import scale\n    from sklearn.metrics import roc_auc_score, classification_report, accuracy_score, roc_curve, confusion_matrix, average_precision_score, precision_recall_curve\n    from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold, train_test_split\n    from xgboost import XGBClassifier\n    import itertools\n    import glmnet\n    \"\"\"\n    a function to find the optimal threshold for binary classification\n    model: a trained model object (such as xgboost, glmnet, ...)\n    X: the test set of features (pandas dataframe or numpy array)\n    y_true: the true class labels (list or array of 0's and 1's)    \n    \"\"\"\n    \n    y_predict_proba = model.predict_proba(X)[:, 1]\n    fpr, tpr, thresholds = roc_curve(y_true, y_predict_proba)\n    auc = roc_auc_score(y_true, y_predict_proba)\n    precision, recall, thresholds2 = precision_recall_curve(y_true, y_predict_proba)\n    \n    class_names = [0, 1]\n    youden_idx = np.argmax(np.abs(tpr - fpr))\n    youden_threshold = thresholds[youden_idx]\n    y_pred_youden = (y_predict_proba > youden_threshold).astype(int)\n    cnf_matrix = confusion_matrix(y_true, y_pred_youden)\n    np.set_printoptions(precision=2)\n    \n    f1 = []\n    for i in range(len(precision)):\n        f1.append(2 * (precision[i] * recall[i]) / (precision[i] + recall[i]))\n        \n    queue_rate = []\n    for thr in thresholds2:\n        queue_rate.append((y_predict_proba >= thr).mean()) \n\n    plt.figure(figsize = (10, 5))\n    plt.subplot(1,2,1)\n    plt.plot(fpr, tpr, color = \"red\", label = F\"AUC = {auc:.3f}\")\n    plt.plot(fpr[youden_idx], tpr[youden_idx], marker = \"o\", color = \"navy\", ms =10, label =F\"Youden Threshold = {youden_threshold:.2f}\" )\n    plt.axvline(x = fpr[youden_idx], ymin = fpr[youden_idx], ymax = tpr[youden_idx], color = \"navy\", ls = \"--\")\n    plt.plot([0,1], [0,1] , color = \"black\", ls = \"--\")\n    plt.xlim([-0.01, 1.01])\n    plt.ylim([-0.01, 1.01])\n    plt.xlabel('1 - Specificity' , fontsize=12)\n    plt.ylabel('Sensitivity' , fontsize=12)\n    plt.tick_params(axis='both', which='major', labelsize=12)\n    plt.legend( prop={'size':12} , loc = 4)\n\n    plt.subplot(1,2,2)\n    _plot_confusion_matrix(cnf_matrix, classes=class_names, normalize = False, cmap=plt.cm.Reds, title = F\"Youden Threshold = {youden_threshold:.2f}\\nAccuracy = {accuracy_score(y_true, y_pred_youden)*100:.2f}%\")\n    plt.show()\n    \n    plt.figure(figsize = (12, 5))\n    plt.subplot(1,2,1)\n    plt.plot(thresholds, 1-fpr, label = \"1 - Specificity\")\n    plt.plot(thresholds, tpr, label = \"Sensitivity\")\n    plt.xlabel(\"Threshold\", fontsize = 12)\n    plt.ylabel(\"Score\", fontsize = 12)\n    plt.legend(loc = 0)\n    plt.xlim([0.025, thresholds[np.argmin(abs(tpr + fpr - 1))]+0.2])\n    plt.axvline(thresholds[np.argmin(abs(tpr + fpr - 1))], color=\"k\", ls = \"--\")\n    plt.title(F\"Threshold = {thresholds[np.argmin(abs(tpr + fpr - 1))]:.3f}\", fontsize = 12)\n    \n    plt.subplot(1,2,2)\n    plt.plot(thresholds2, precision[1:], label = \"Precision\")\n    plt.plot(thresholds2, recall[1:], label = \"Recall\")\n    plt.plot(thresholds2, f1[1:], label = \"F1-Score\")\n    plt.plot(thresholds2, queue_rate, label = \"Queue Rate\")\n    plt.legend(loc = 0)\n    plt.xlim([0.025, thresholds2[np.argmin(abs(precision-recall))] + 0.2])\n    plt.xlabel(\"Threshold\", fontsize = 12)\n    plt.ylabel(\"Score\", fontsize = 12)\n    plt.axvline(thresholds2[np.argmin(abs(precision-recall))], color=\"k\", ls = \"--\")\n    plt.title(label = F\"Threshold = {thresholds2[np.argmin(abs(precision-recall))]:.3f}\", fontsize = 12)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_threshold_finder(xgb, X_test.loc[filtered_indexes], y_test.loc[filtered_indexes])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import scikitplot as skplt\nimport matplotlib.pyplot as plt\n\n# y_test= # ground truth labels\n# preds = # predicted probabilities generated by sklearn classifier\nskplt.metrics.plot_roc(y_test.loc[filtered_indexes], preds_proba_df.loc[filtered_indexes])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import scikitplot as skplt\nimport matplotlib.pyplot as plt\n\n# y_test= # ground truth labels\n# preds = # predicted probabilities generated by sklearn classifier\nskplt.metrics.plot_roc(y_test.loc[filtered_indexes], final_modified_preds_df.loc[filtered_indexes])\nplt.show()dd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#######################################","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.loc[preds_df != y_test].to_csv('failed_training_samples.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_df = pd.Series(preds)\npreds_df.index = y_test.index.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setup as pandas series\npreds_argmax_df = pd.Series(preds_argmax)\npreds_argmax_df.index = y_test.index.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(y_test.loc[filtered_indexes], preds_argmax_df.loc[filtered_indexes])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(y_test.loc[filtered_indexes], preds_df.loc[filtered_indexes])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(accuracy_score(\n#     y_test[:],\n#     preds[:]))\n#cm_test = confusion_matrix(y_test, preds)\n#print(cm_test[1][0] / sum(cm_test[1]))\n\n#age_threshold = 60\n\n# condition = 'Age > 50 and Annual_Premium > 100000'\n\n\n# print(len(filtered_indexes))\n# print(len(negation_indexes))\n# print(len(filtered_indexes) + len(negation_indexes) == len(X_test))\n#X_test.loc[X_test.query(condition).index]\n\n# print(accuracy_score(\n#     y_test.loc[filtered_indexes],\n#     preds_df.loc[filtered_indexes]))\n\n# printing FN Rate\n\ncm_test = confusion_matrix(y_test.loc[filtered_indexes], preds_df.loc[filtered_indexes])\n#print(cm_test[1][0] / sum(cm_test[1]))\n\ncm_test /cm_test.astype(np.float).sum(axis=1)\n\n\nprint('All Data acc:' + str(accuracy_score(y_test, preds)))\nprint('Data slice acc:' + str(accuracy_score(y_test.loc[filtered_indexes], preds_df.loc[filtered_indexes])))\n\n#cm_test = confusion_matrix(y_test.loc[negation_indexes], preds_df.loc[negation_indexes])\n#print(cm_test[1][0] / sum(cm_test[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(accuracy_score(\n    y_test.loc[filtered_indexes],\n    preds_df.loc[filtered_indexes]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filtered on selected data segment\ncm = confusion_matrix(y_test.loc[filtered_indexes], preds_df.loc[filtered_indexes])\n\nax= plt.subplot()\nsns.heatmap(cm, annot=True, ax = ax, fmt='g')\n\nax.set_xlabel('Predicted labels')\nax.set_ylabel('True labels')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filtered on rest of data\ncm = confusion_matrix(y_test.loc[negation_indexes], preds_df.loc[negation_indexes])\n\nax= plt.subplot()\nsns.heatmap(cm, annot=True, ax = ax, fmt='g')\n\nax.set_xlabel('Predicted labels')\nax.set_ylabel('True labels')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_preds = pd.DataFrame(preds)\nnew_preds.insert(0, 'id', X_test.index)\nnew_preds.set_index('id')\nnew_preds.reindex()\n#new_preds = new_preds.drop(columns=['id'])\n#new_preds = pd.Series(new_preds)\n#new_preds = new_preds.T.squeeze()\nnew_preds.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_preds.loc[filtered_indexes]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.query('Age > 50')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test[X_test.query('Age > 50').index]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#my_preds[X_test['Gender'] == 1] = preds[X_test['Gender'] == 1]\nmy_preds[X_test['Gender'] == 1] = preds[X_test['Gender'] == 1]\nprint(accuracy_score(y_test, preds))\nprint(accuracy_score(y_test, my_preds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.loc[X_test['Gender'] == 1].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.to_csv(r'C:\\temp\\x_test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(preds).to_csv('preds.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(y_test).to_csv('y_true.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(X_train, y_train, X_test, y_test, preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}