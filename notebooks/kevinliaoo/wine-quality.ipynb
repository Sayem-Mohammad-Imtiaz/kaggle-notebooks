{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\n\n# Load dataframe\ndf = pd.read_csv('/kaggle/input/red-wine-quality-cortez-et-al-2009/winequality-red.csv')\n\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert target values to a binary classification task \nbins = (0, 6, 9)\nlabels = [0, 1]\ndf.quality = pd.cut(df.quality, bins=bins, labels=labels)\n\ndf.quality.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data visualizing\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n\n# Correlation matrix \nsns.heatmap(df.corr());","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot a histogram for all variables\ndf.hist(bins=50, figsize=(20, 15))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt \n\nplt.scatter(\n    x = df['fixed acidity'], y = df['volatile acidity'], c = df.quality, \n    alpha = 0.3\n)\nplt.xlabel('Fixed acidity')\nplt.ylabel('Volatile acidity')\nplt.legend() \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(\n    x = df['density'], y = df['alcohol'], c = df.quality, \n    alpha = 0.3\n)\nplt.xlabel('Density')\nplt.ylabel('Alcohol')\nplt.legend() \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(\n    x = df['density'], y = df['pH'], c = df.quality, \n    alpha = 0.3\n)\nplt.xlabel('Density')\nplt.ylabel('pH')\nplt.legend() \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(\n    x = df['alcohol'], y = df['pH'], c = df.quality, \n    alpha = 0.3\n)\nplt.xlabel('Alcohol')\nplt.ylabel('pH')\nplt.legend() \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (10,6))\nsns.barplot(x = 'quality', y = 'fixed acidity', data = df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (10,6))\nsns.barplot(x = 'quality', y = 'volatile acidity', data = df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train Machine Learning models"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop(['quality'], axis=1)\ny = df.quality","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\n# Scale data \nscaler = StandardScaler() \nX = pd.DataFrame(data=scaler.fit_transform(X), columns=X.columns)\n\nX.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n\nX_train, X_test, y_train, y_test = train_test_split(X, y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression \nfrom sklearn.metrics import accuracy_score, f1_score\n\nlogistic = LogisticRegression() \nlogistic.fit(X_train, y_train)\n\npreds = logistic.predict(X_test)\n\nprint(\"Accuracy: {}\".format(accuracy_score(y_test, preds)))\nprint(\"F1 score: {}\".format(f1_score(y_test, preds)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Supported Vector Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC \n\nsvc = SVC() \nsvc.fit(X_train, y_train)\n\npreds = svc.predict(X_test)\n\nprint(\"Accuracy: {}\".format(accuracy_score(y_test, preds)))\nprint(\"F1 score: {}\".format(f1_score(y_test, preds)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Finding best parameters for our SVC model\nparam = {\n    'C': [0.1,0.8,0.9,1,1.1,1.2,1.3,1.4],\n    'kernel':['linear', 'rbf'],\n    'gamma' :[0.1,0.8,0.9,1,1.1,1.2,1.3,1.4]\n}\n\ngrid_svc = GridSearchCV(SVC(), param_grid=param, scoring='accuracy', cv=3)\n\ngrid_svc.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_svc.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = grid_svc.best_estimator_\n\npreds = model.predict(X_test)\n\nprint(\"Accuracy: {}\".format(accuracy_score(y_test, preds)))\nprint(\"F1 score: {}\".format(f1_score(y_test, preds)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nforest = RandomForestClassifier() \nforest.fit(X_train, y_train)\n\npreds = forest.predict(X_test)\n\nprint(\"Accuracy: {}\".format(accuracy_score(y_test, preds)))\nprint(\"F1 score: {}\".format(f1_score(y_test, preds)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n    'n_estimators': np.arange(50, 201, 20), \n    'max_depth': np.arange(10, 51, 10)\n}\n\ngrid_forest = GridSearchCV(RandomForestClassifier(), param_grid=params, scoring='accuracy', cv=3)\n\ngrid_forest.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_forest.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = grid_forest.best_estimator_\n\npreds = model.predict(X_test)\n\nprint(\"Accuracy: {}\".format(accuracy_score(y_test, preds)))\nprint(\"F1 score: {}\".format(f1_score(y_test, preds)))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}