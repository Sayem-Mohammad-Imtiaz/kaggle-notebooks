{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"90c1f629-54bc-7ec1-9463-adf1a0e03017"},"source":"# Exporing aviation accidents data\n\nLink to kagge: https://www.kaggle.com/khsamaha/aviation-accident-database-synopses\n\n## Dataset purpose\nIn some comment I've read interesting questions about this dataset:\n\n> * Which is the type accident often to happen? Which are the features relevant?\n* What is season that there are more accident?\n* The amateur have a influence on accident or injury severity?\n* Do they take too long to make preliminary reports?\n* What do scheme have more accident?\n* Where are there more accident? - deprecated\n* What do aircraft have more accident? -deprecated\n* How do accidents evolve in the time of aviation in the United States?\n\nCredits:\n* I took some useful functions from https://www.kaggle.com/helgejo/titanic/an-interactive-data-science-tutorial\n\n**NOTE** this is a work in progress\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3499eba5-cbb2-ed7d-7516-b20843955f87"},"outputs":[],"source":"# Python libraries\nimport math\nimport re\nimport datetime\n\n\n# Handle table-like data and matrices\nimport numpy as np\nimport pandas as pd\n\n# Modelling Algorithms\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier , GradientBoostingClassifier\n\n# Modelling Helpers\nfrom sklearn.preprocessing import StandardScaler, Imputer , Normalizer , scale\nfrom sklearn.cross_validation import train_test_split , StratifiedKFold\nfrom sklearn.feature_selection import RFECV\n\n# Visualisation\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\nimport seaborn as sns\n\n# Configure visualisations\n%matplotlib inline\nmpl.style.use( 'ggplot' )\nsns.set_style( 'white' )\npylab.rcParams[ 'figure.figsize' ] = 12 , 10"},{"cell_type":"markdown","metadata":{"_cell_guid":"b3ace54c-0cb5-ad72-2185-3904e93ba2c8"},"source":"### Plot and data study helpers"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"423d9243-da1f-9c79-807c-d83475c73d5e"},"outputs":[],"source":"def plot_histograms( df , variables , n_rows , n_cols ):\n    fig = plt.figure( figsize = ( 16 , 12 ) )\n    for i, var_name in enumerate( variables ):\n        ax=fig.add_subplot( n_rows , n_cols , i+1 )\n        df[ var_name ].hist( bins=10 , ax=ax )\n        ax.set_title( 'Skew: ' + str( round( float( df[ var_name ].skew() ) , ) ) ) # + ' ' + var_name ) #var_name+\" Distribution\")\n        ax.set_xticklabels( [] , visible=False )\n        ax.set_yticklabels( [] , visible=False )\n    fig.tight_layout()  # Improves appearance a bit.\n    plt.show()\n\ndef plot_distribution( df , var , target , **kwargs ):\n    row = kwargs.get( 'row' , None )\n    col = kwargs.get( 'col' , None )\n    facet = sns.FacetGrid( df , hue=target , aspect=4 , row = row , col = col )\n    facet.map( sns.kdeplot , var , shade= True )\n    facet.set( xlim=( df[ var ].min() , df[ var ].max() ) )\n    facet.add_legend()\n\ndef plot_categories( df , cat , target , **kwargs ):\n    row = kwargs.get( 'row' , None )\n    col = kwargs.get( 'col' , None )\n    facet = sns.FacetGrid( df , row = row , col = col )\n    facet.map( sns.barplot , cat , target )\n    facet.add_legend()\n\ndef plot_correlation_map( df ):\n    corr = df.corr()\n    _ , ax = plt.subplots( figsize =( 12 , 10 ) )\n    cmap = sns.diverging_palette( 220 , 10 , as_cmap = True )\n    _ = sns.heatmap(\n        corr, \n        cmap = cmap,\n        square=True, \n        cbar_kws={ 'shrink' : .9 }, \n        ax=ax, \n        annot = True, \n        annot_kws = { 'fontsize' : 12 }\n    )\n\ndef describe_more( df ):\n    var = [] ; l = [] ; t = []\n    for x in df:\n        var.append( x )\n        l.append( len( pd.value_counts( df[ x ] ) ) )\n        t.append( df[ x ].dtypes )\n    levels = pd.DataFrame( { 'Variable' : var , 'Levels' : l , 'Datatype' : t } )\n    levels.sort_values( by = 'Levels' , inplace = True )\n    return levels\n\ndef plot_variable_importance( X , y ):\n    tree = DecisionTreeClassifier( random_state = 99 )\n    tree.fit( X , y )\n    plot_model_var_imp( tree , X , y )\n    \ndef plot_model_var_imp( model , X , y ):\n    imp = pd.DataFrame( \n        model.feature_importances_  , \n        columns = [ 'Importance' ] , \n        index = X.columns \n    )\n    imp = imp.sort_values( [ 'Importance' ] , ascending = True )\n    imp[ : 10 ].plot( kind = 'barh' )\n    print (model.score( X , y ))\n    \ndef category_values(dataframe, categories):\n    for c in categories:\n        print('\\n', dataframe.groupby(by=c)[c].count().sort_values(ascending=False))\n        print('Nulls: ', dataframe[c].isnull().sum())"},{"cell_type":"markdown","metadata":{"_cell_guid":"ae0b299f-aec2-f610-a0d9-6ecb8b7cf35d"},"source":"## Loading data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5178729a-545f-481d-a830-432437107ee8"},"outputs":[],"source":"df = pd.read_csv('../input/AviationDataEnd2016UP.csv', sep=',', header=0, encoding = 'iso-8859-1')\n\ndf.sample(10)"},{"cell_type":"markdown","metadata":{"_cell_guid":"12478e1e-eb07-ec9a-1606-08c1a79ec874"},"source":"### Getting info on the fields types"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fa0b3bbb-6a10-dcc7-6c01-e12273a1d9c0"},"outputs":[],"source":"df.info()"},{"cell_type":"markdown","metadata":{"_cell_guid":"f75b8064-2a7e-930f-ab5e-a4c58c758a58"},"source":"Let's see what kind of numeric data we have"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b8d7b80d-1ad9-24d9-3e7c-016a7a96c5a7"},"outputs":[],"source":"df.describe()"},{"cell_type":"markdown","metadata":{"_cell_guid":"de618f25-1646-bc36-b3c7-9be68285d26c"},"source":"### Getting some counts on how many different values are there for each feature"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5344fa6a-8423-cde9-a479-a6639484e0c1"},"outputs":[],"source":"describe_more(df)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"93554b78-d73d-f01b-158e-401dcbf6c268"},"outputs":[],"source":"# splitting date field in the components\n\ndf['Year'] = df['Event.Date'].apply(lambda d: datetime.datetime.strptime(d, \"%Y-%m-%d\").year)\ndf['Month'] = df['Event.Date'].apply(lambda d: datetime.datetime.strptime(d, \"%Y-%m-%d\").month)\ndf['Day'] = df['Event.Date'].apply(lambda d: datetime.datetime.strptime(d, \"%Y-%m-%d\").day)\n\ndf = df[df['Year'] >= 1982]"},{"cell_type":"markdown","metadata":{"_cell_guid":"339c3efe-f8b1-8a87-79ff-ac1f2c2496bb"},"source":"### Looking at some categories\nI try to list some unique values in the categories fields to subsequently plot some data distribution over those."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6d8e2db9-4940-44ac-616a-200f0ebd89bc"},"outputs":[],"source":"categories = ['Investigation.Type',\n             'Aircraft.Damage',\n             'Aircraft.Category',\n             'Amateur.Built',\n             'Number.of.Engines',\n             'Engine.Type',\n             'FAR.Description',\n             'Schedule',\n             'Purpose.of.Flight',\n             'Weather.Condition',\n             'Broad.Phase.of.Flight',\n             'Report.Status',\n             'Air.Carrier']\n\nfor c in categories:\n    print(c , df[c].unique())"},{"cell_type":"markdown","metadata":{"_cell_guid":"afce9a26-73f7-1f3a-0ac6-027a6e29c89c"},"source":"### Counting the number of different values for each category feature"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1a8c0211-b2e2-59a2-4002-88f480dcf022"},"outputs":[],"source":"category_values(df, categories)"},{"cell_type":"markdown","metadata":{"_cell_guid":"861e47cf-3ce7-35ea-af3f-a27d85ac6dd1"},"source":"## Filling Null values\n\nThe data is full of Null values. I'll try to fix the nulls copying data from the rest of the dataset when possible. For the rest I'll put 'unknown' strings."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"089e315c-ca69-8b91-3687-08e1a8a22681"},"outputs":[],"source":"# null damages can't be defined\ndf[df['Aircraft.Damage'].isnull()]\ndf['Aircraft.Damage'].fillna('Unknown', inplace=True)\n\n# Fixing phase of flight nulls\ndf['Broad.Phase.of.Flight'].fillna('UNKNOWN', inplace=True)\n\n# Fixing weather conditions\ndf['Weather.Condition'].fillna('UNK', inplace=True)\n\n# null categories can't be defined\ndf['Aircraft.Category'].fillna('Unknown', inplace=True)\n\n# can't define purpose of flight\ndf['Purpose.of.Flight'].fillna('Unknown', inplace=True)\n\n# don't know ho to set missing schedules \ndf['Schedule'].fillna('UNK', inplace=True)\n\n# don't know ho to set missing FAR.Description\ndf['FAR.Description'].fillna('Unknown', inplace=True)\n\n# don't know ho to set missing Aircraft.Damage\ndf['Aircraft.Damage'].fillna('Unknown', inplace=True)\n\n# don't know ho to set missing Air Carriers\ndf['Air.Carrier'].fillna('Unknown', inplace=True)\n\n# don't know ho to set missing Makers\ndf['Make'].fillna('UNKNOWN', inplace=True)\n\n# don't know ho to set missing Models\ndf['Model'].fillna('Unknown', inplace=True)\n\n# don't know ho to set missing airport names\ndf['Airport.Name'].fillna('Unknown', inplace=True)\n\n# don't know ho to set missing Models\ndf['Airport.Code'].fillna('Unknown', inplace=True)\n\n# don't know ho to set missing Locations\ndf['Location'].fillna('Unknown', inplace=True)"},{"cell_type":"markdown","metadata":{"_cell_guid":"e86678c4-4c3c-4d04-2ebf-e74c62acd2bc"},"source":"### Amateur producers\nInstead of putting an 'unknown' value in the Amateur.Built field, I've collected all the producers and all the amateurs brands/names from the rest of the dataset and filled the null cells searching in the resulting two lists. For the remaining marks that are not present anywhere in the dataset I chose to set them as amateurs."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e3784d69-ac9d-9e6d-7d13-a87583c0609f"},"outputs":[],"source":"# Extracting producers and amateurs\nproducers = [x for x in df['Make'][df['Amateur.Built']== 'No'].unique() ]\namateurs  = [x for x in df['Make'][df['Amateur.Built']== 'Yes'].unique() ]\n\n# -----------------------------------------------\n# Function that fixes the null in amateur.built\ndef fix_amateur_built(ab, m):\n    if type(ab) == str:\n        return ab\n    else:\n        if m in producers:\n            return 'No'\n        else:\n            return 'Yes'\n# Fix for Amateur.Built field      \nam_built = df.apply(lambda x: fix_amateur_built(x['Amateur.Built'], x['Make']), axis=1)\ndf = df.assign(AmateurBuilt = am_built, index=df.index)"},{"cell_type":"markdown","metadata":{"_cell_guid":"b17f3614-b9a1-42ed-ae21-4fad48d015b9"},"source":"### Number of engines\nFor the balloons I'll set this value to 0.\nFor the remaining, I'll make some assumptions and aproximations based on the rest of the values."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b77815a7-5923-4c2c-1bb9-ffb290064e78"},"outputs":[],"source":"# Function that fixes the null in number.of.engines\ndef fix_number_of_engines(noe, m):\n    if noe >= 0:\n        return noe\n    else:\n        # Setting number of engines at the mean number of engines for the producer\n        r = np.round(df['Number.of.Engines'][df['Make']==m].mean())\n        return r\n\n# Setting 0 engines for balloons\ndf['Number.of.Engines'][df['Number.of.Engines'].isnull() & (df['Make'].str.contains('balloon', case=False))] = 0.0\n# Correcting number of engines\nnum_engines = df.apply(lambda x: fix_number_of_engines(x['Number.of.Engines'], x['Make']), axis=1)\ndf = df.assign(NumberofEngines = num_engines, index=df.index)\n# Still some null after number of engines correction\ndf['NumberofEngines'].fillna(1, inplace=True)"},{"cell_type":"markdown","metadata":{"_cell_guid":"032c064b-0afb-2afa-5111-383b9f855a0b"},"source":"### Engine types\nTaking engine types from the rest of the data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1235bbf8-c5ad-19db-0948-1c9dbf298485"},"outputs":[],"source":"# Function that fixes the engine types\ndef fix_engine_type(et, model):\n    if type(et) == str:\n        return et\n    else:\n        # Setting engine type at the mode of engines for the model\n        e = (df['Engine.Type'][df['Model']==model].mode())\n        return  e[0] if e.count() > 0 else 'Unknown'\n# Fix for Engine.Type field      \nen_type = df.apply(lambda x: fix_engine_type(x['Engine.Type'], x['Model']), axis=1)\ndf = df.assign(EngineType = en_type, index=df.index)"},{"cell_type":"markdown","metadata":{"_cell_guid":"bc3a500b-9af6-dbb0-2296-c41d5d17e078"},"source":"### Aircraft Category\nTaking Aircraft Categories from the rest of the data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b9f9e182-f14b-3a5b-92d5-e4daa970e52f"},"outputs":[],"source":"# Function that fixes the Aircraft.Category\ndef fix_aircraft_category(cat, model):\n    if type(cat) == str:\n        return cat\n    else:\n        # Setting aircraft category at the mode of caterogories for the model\n        e = (df['Aircraft.Category'][df['Model']==model].mode())\n        return  e[0] if e.count() > 0 else 'Unknown'\n# Fix for Aircraft.Category field      \naircraft_cat = df.apply(lambda x: fix_aircraft_category(x['Aircraft.Category'], x['Model']), axis=1)\ndf = df.assign(AircraftCategory = aircraft_cat, index=df.index)"},{"cell_type":"markdown","metadata":{"_cell_guid":"de1cfa50-4eba-3fb7-c6df-362210511f11"},"source":"### Country\nIt seems that null countries are all outside U.S."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"30b1a629-91ee-c290-3cf4-da38c64ab9dd"},"outputs":[],"source":"# null countries are outside US\ndf[df['Country'].isnull()]\ndf['Country'].fillna('Foreign', inplace=True)"},{"cell_type":"markdown","metadata":{"_cell_guid":"777339b3-e397-1722-4346-139bbea2b344"},"source":"### Injuries\nI add a colunm that represents the total number of injuries in the accidents."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9403903e-3f6a-c23e-8f94-63c71ab15ee9"},"outputs":[],"source":"df['Injuries'] = df['Total.Fatal.Injuries'] + df['Total.Serious.Injuries'] + df['Total.Minor.Injuries']"},{"cell_type":"markdown","metadata":{"_cell_guid":"bd2a7d23-bb00-729f-cb30-b2c74ed6c16d"},"source":"### Checking if all nulls have been fixed"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"76a20130-3237-3613-fb59-ae4901e51b26"},"outputs":[],"source":"#category_values(df, ['AircraftCategory', 'Country', 'EngineType', 'NumberofEngines', 'AmateurBuilt'])\n#df['EngineType'].sample(100)\n\n#df.groupby(by=['Location']).count()\ndf.isnull().sum()"},{"cell_type":"markdown","metadata":{"_cell_guid":"ad502709-c295-94b9-d840-9030fb50cb7a"},"source":"### Dropping columns that I will not use \nThere are some columns that I think are not so useful and others that have been replaced by \"sanitized\" ones."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"499cd2d5-9371-d404-90f5-96277c6fff1b"},"outputs":[],"source":"df = df.drop(['Number.of.Engines', 'Aircraft.Category', 'Engine.Type', 'Amateur.Built', 'index'], axis='columns')\ndf = df.drop(['Publication.Date'], axis='columns')"},{"cell_type":"markdown","metadata":{"_cell_guid":"8d3f731a-adce-8e4c-02b4-93c3344f4fa3"},"source":"## Now some visualization\nA better way to understand what's inside the data is to put some features in charts.\n\nTODO: comment"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"606fa900-d8c5-04fd-b430-0ae379f15e05"},"outputs":[],"source":"plot_correlation_map(df)"},{"cell_type":"markdown","metadata":{"_cell_guid":"437ae9c9-483c-b30b-8e1e-f9d1f58284e7"},"source":"An observation: the number of uninjuried seems to be very related to the number of engines. Could it mean that a second engine helps in some kind of accident?"},{"cell_type":"markdown","metadata":{"_cell_guid":"7276f5f0-eb95-ad83-cd09-e07b75268d2b"},"source":"### Time series charts\nLet's see on the timeline some events.\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"35d2c7c4-0a43-b9a9-da57-adc229672fbd"},"outputs":[],"source":"# For the time series charts I start sorting data\ndf = df.sort_values(by=['Year', 'Month', 'Day'], ascending=True)\n\nyears = np.arange(1982, 2017)\n\nsns.set(style=\"darkgrid\")\n\nplt.subplot(211)\n\ng = sns.countplot(x=\"Year\", data=df, palette=\"GnBu_d\", order=years)\ng.set_xticklabels(labels=years)\na = plt.setp(g.get_xticklabels(), rotation=90)"},{"cell_type":"markdown","metadata":{"_cell_guid":"e2f1d68c-6aa0-b70a-afc5-642a42bc1860"},"source":"## Linear regression on number of incidents\n\nGiven the histogram before, it should be easy to make a linear regression to predict next years' incidents."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a9a2934d-1e49-b85d-2e60-f634f1968c3f"},"outputs":[],"source":"from sklearn.linear_model import LinearRegression, Ridge, Lasso\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import cross_val_score\n\n\nevents_per_year = df.groupby(by='Year').count()['Event.Id']\nevents_per_year.drop(2017, axis=0, inplace=True)\n\nX = [ [y] for y in events_per_year.index.values]\ny = [ [e] for e in events_per_year.as_matrix()]\n\n\ndegrees = [1,2,3]\nlr_pred_X = [[y] for y in range(1982, 2020)]\nfor i in range(len(degrees)):\n    polynomial_features = PolynomialFeatures(degree=degrees[i],\n                                             include_bias=False)\n    linear_regression = LinearRegression()\n    pipeline = Pipeline([(\"polynomial_features\", polynomial_features),\n                         (\"linear_regression\", linear_regression)])\n    pipeline.fit(X, y)\n\n    # Evaluate the models using crossvalidation\n    scores = cross_val_score(pipeline, X, y,\n                             scoring=\"neg_mean_squared_error\", cv=10)\n    lr_pred=pipeline.predict(lr_pred_X)\n    plt.plot(lr_pred_X, lr_pred, alpha=.3)\n    \n    print(\"Score for degree %d: %.3f - prediction for 2017 is %d\" % (i, pipeline.score(X, y), lr_pred[35]))\n\nplt.plot(X, y)\nplt.title(\"Linear regression with polynomial features\")\nplt.legend(labels=degrees)\n\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"804370f5-9b3d-c9a4-db7f-b229c32b7d46"},"source":"## Conclusions\n\nSo far, I only wanted to work on the ways I can clean the data and on trying a linear regression on a dataset with only one feature.\n\nI'll try to understand better the dataset contents and to imagine some other interesting visualizations and predictions."}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}