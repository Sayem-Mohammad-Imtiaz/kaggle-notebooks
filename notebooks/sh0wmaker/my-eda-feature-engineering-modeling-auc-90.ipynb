{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n\n# Contents of the Notebook :\n \n# Part1: Exploratory Data Analysis(EDA):\n#### 1)Analysis of the features.\n\n#### 2)Finding any relations or trends considering multiple features.\n\n# Part2: Feature Engineering and Data Cleaning:\n\n#### 1)Converting features into suitable form for modeling.\n\n# Part3: Predictive Modeling\n#### 1)Running Basic Algorithms.\n\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport matplotlib as mpl\nimport matplotlib.pyplot as plt \nimport seaborn as sns \nimport warnings \nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-06-21T05:35:18.220309Z","iopub.execute_input":"2021-06-21T05:35:18.220748Z","iopub.status.idle":"2021-06-21T05:35:19.073972Z","shell.execute_reply.started":"2021-06-21T05:35:18.220661Z","shell.execute_reply":"2021-06-21T05:35:19.073005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Check ","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('../input/heart-attack-analysis-prediction-dataset/heart.csv')\ndata.head()\n# output = target ","metadata":{"execution":{"iopub.status.busy":"2021-06-21T05:35:19.07793Z","iopub.execute_input":"2021-06-21T05:35:19.078265Z","iopub.status.idle":"2021-06-21T05:35:19.121857Z","shell.execute_reply.started":"2021-06-21T05:35:19.078235Z","shell.execute_reply":"2021-06-21T05:35:19.120255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The target value is column 'output' !!! ","metadata":{}},{"cell_type":"code","source":"data.describe(include='all')","metadata":{"execution":{"iopub.status.busy":"2021-06-21T05:35:19.123495Z","iopub.execute_input":"2021-06-21T05:35:19.123781Z","iopub.status.idle":"2021-06-21T05:35:19.184008Z","shell.execute_reply.started":"2021-06-21T05:35:19.123753Z","shell.execute_reply":"2021-06-21T05:35:19.183008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-21T05:35:19.185684Z","iopub.execute_input":"2021-06-21T05:35:19.186091Z","iopub.status.idle":"2021-06-21T05:35:19.196434Z","shell.execute_reply.started":"2021-06-21T05:35:19.186056Z","shell.execute_reply":"2021-06-21T05:35:19.195246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Great! There is no missing valeus in our data.\n\nNow let's check out all the data **dtypes** and **unique values** before EDA. We are going to conducte separately according to dtypes.","metadata":{}},{"cell_type":"code","source":"# dtypes \ndata.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-06-21T05:35:19.198066Z","iopub.execute_input":"2021-06-21T05:35:19.1984Z","iopub.status.idle":"2021-06-21T05:35:19.209963Z","shell.execute_reply.started":"2021-06-21T05:35:19.198369Z","shell.execute_reply":"2021-06-21T05:35:19.209093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Also check out the unique valeus in each columns\n\ndict = {}\nfor i in list(data.columns):\n    dict[i] = data[i].value_counts().shape[0]\n\npd.DataFrame(dict, index=['unique count']).transpose()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-21T05:35:19.211304Z","iopub.execute_input":"2021-06-21T05:35:19.211825Z","iopub.status.idle":"2021-06-21T05:35:19.235122Z","shell.execute_reply.started":"2021-06-21T05:35:19.211791Z","shell.execute_reply":"2021-06-21T05:35:19.234162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we can seperate our columns into categorical features and continouse features. \n\n**Categorical Features**:   sex, exng, caa, cp, fbs, restecg, slp, thall\n\n**Continous Features**:   age, trbps, chol, thalachh, oldpeak\n\n**Target Feature**:   output","metadata":{}},{"cell_type":"markdown","source":"# Part1: Exploratory Data Analysis(EDA):","metadata":{}},{"cell_type":"markdown","source":"* **Age** : Age of the patient\n* **Sex** : Sex of the patient\n* **exang**: exercise induced angina (1 = yes; 0 = no)\n* **cp** : Chest Pain type chest pain type\n\n     -Value 1: typical angina\n\n     -Value 2: atypical angina\n\n     -Value 3: non-anginal pain\n\n     -Value 4: asymptomatic\n* **ca**: number of major vessels (0-3)\n* **trtbps** : resting blood pressure (in mm Hg)\n* **chol** : cholestoral in mg/dl fetched via BMI sensor\n* **fbs** : (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)\n* **rest_ecg** : resting electrocardiographic results\n\n     -Value 0: normal\n\n     -Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)\n\n     -Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\n\n* **thalach** : maximum heart rate achieved\n* **target** : 0= less chance of heart attack 1= more chance of heart attack","metadata":{}},{"cell_type":"markdown","source":"**First of all, we will going to check out all the features of our data**","metadata":{}},{"cell_type":"markdown","source":"## Every Categorical Features Distribution\n\n**Categorical Features**:   sex, exng, caa, cp, fbs, restecg, slp, thall\n","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(18,15))\ngs = fig.add_gridspec(3,3)\n\n\n\nax0 = fig.add_subplot(gs[0,0])\nax1 = fig.add_subplot(gs[0,1])\nax2 = fig.add_subplot(gs[0,2])\nax3 = fig.add_subplot(gs[1,0])\nax4 = fig.add_subplot(gs[1,1])\nax5 = fig.add_subplot(gs[1,2])\nax6 = fig.add_subplot(gs[2,0])\nax7 = fig.add_subplot(gs[2,1])\nax8 = fig.add_subplot(gs[2,2])\n\nax_sex = ax0\nsns.countplot(x='sex', data=data, ax=ax_sex, palette='YlGnBu')\nsns.despine()\n\nax_exng = ax1\nsns.countplot(x='exng',data=data, ax=ax_exng, palette='YlGnBu')\nsns.despine()\n\nax_caa = ax2\nsns.countplot(x='caa', data=data, ax=ax_caa, palette='YlGnBu')\nsns.despine()\n\nax_cp = ax3\nsns.countplot(x='cp', data=data, ax=ax_cp, palette='YlGnBu')\nsns.despine()\n\nax_fbs = ax4\nsns.countplot(x='fbs',data=data, ax=ax_fbs, palette='YlGnBu')\nsns.despine()\n\nax_restecg = ax5\nsns.countplot(x='restecg',  data=data, ax=ax_restecg, palette='YlGnBu')\nsns.despine()\n\nax_slp = ax6\nsns.countplot(x='slp',  data=data, ax=ax_slp, palette='YlGnBu')\nsns.despine()\n\nax_thall = ax7\nsns.countplot(x='thall',  data=data, ax=ax_thall, palette='YlGnBu')\nsns.despine()\n\nax8.spines[\"bottom\"].set_visible(False)\nax8.spines[\"left\"].set_visible(False)\nax8.spines[\"top\"].set_visible(False)\nax8.spines[\"right\"].set_visible(False)\nax8.tick_params(left=False, bottom=False)\nax8.set_xticklabels([])\nax8.set_yticklabels([])\n\n\nplt.show();","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-21T05:35:19.237885Z","iopub.execute_input":"2021-06-21T05:35:19.238683Z","iopub.status.idle":"2021-06-21T05:35:20.390553Z","shell.execute_reply.started":"2021-06-21T05:35:19.238633Z","shell.execute_reply":"2021-06-21T05:35:20.389278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Categorical Features & Target Feature","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(18,15))\ngs = fig.add_gridspec(3,3)\n\"\"\"sns.set_style(\"white\")\nsns.set_context(\"poster\", font_scale = 0.5)\"\"\"\n\nax0 = fig.add_subplot(gs[0,0])\nax1 = fig.add_subplot(gs[0,1])\nax2 = fig.add_subplot(gs[0,2])\nax3 = fig.add_subplot(gs[1,0])\nax4 = fig.add_subplot(gs[1,1])\nax5 = fig.add_subplot(gs[1,2])\nax6 = fig.add_subplot(gs[2,0])\nax7 = fig.add_subplot(gs[2,1])\nax8 = fig.add_subplot(gs[2,2])\n\nax_sex = ax0\nsns.countplot(x='sex', hue='output', data=data, ax=ax_sex, palette='YlGnBu')\nsns.despine()\n\nax_exng = ax1\nsns.countplot(x='exng', hue='output', data=data, ax=ax_exng, palette='YlGnBu')\nsns.despine()\n\nax_caa = ax2\nsns.countplot(x='caa', hue='output', data=data, ax=ax_caa, palette='YlGnBu')\nsns.despine()\n\nax_cp = ax3\nsns.countplot(x='cp', hue='output', data=data, ax=ax_cp, palette='YlGnBu')\nsns.despine()\n\nax_fbs = ax4\nsns.countplot(x='fbs', hue='output', data=data, ax=ax_fbs, palette='YlGnBu')\nsns.despine()\n\nax_restecg = ax5\nsns.countplot(x='restecg', hue='output', data=data, ax=ax_restecg, palette='YlGnBu')\nsns.despine()\n\nax_slp = ax6\nsns.countplot(x='slp', hue='output', data=data, ax=ax_slp, palette='YlGnBu')\nsns.despine()\n\nax_thall = ax7\nsns.countplot(x='thall', hue='output', data=data, ax=ax_thall, palette='YlGnBu')\nsns.despine()\n\nax8.spines[\"bottom\"].set_visible(False)\nax8.spines[\"left\"].set_visible(False)\nax8.spines[\"top\"].set_visible(False)\nax8.spines[\"right\"].set_visible(False)\nax8.tick_params(left=False, bottom=False)\nax8.set_xticklabels([])\nax8.set_yticklabels([])\n\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-21T05:35:20.394718Z","iopub.execute_input":"2021-06-21T05:35:20.395079Z","iopub.status.idle":"2021-06-21T05:35:21.58549Z","shell.execute_reply.started":"2021-06-21T05:35:20.395049Z","shell.execute_reply":"2021-06-21T05:35:21.584324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('1)', data.groupby(['sex', 'output'])['output'].count())\nprint('')\nprint('')\nprint('2)', data.groupby(['exng', 'output'])['output'].count())\nprint('')\nprint('')\nprint('3)', data.groupby(['caa', 'output'])['output'].count())\nprint('')\nprint('')\nprint('4)', data.groupby(['cp', 'output'])['output'].count())\nprint('')\nprint('')\nprint('5)', data.groupby(['fbs', 'output'])['output'].count())\nprint('')\nprint('')\nprint('6)', data.groupby(['restecg', 'output'])['output'].count())\nprint('')\nprint('')\nprint('7)', data.groupby(['slp', 'output'])['output'].count())\nprint('')\nprint('')\nprint('8)', data.groupby(['thall', 'output'])['output'].count())\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-21T05:35:21.587972Z","iopub.execute_input":"2021-06-21T05:35:21.588435Z","iopub.status.idle":"2021-06-21T05:35:21.629745Z","shell.execute_reply.started":"2021-06-21T05:35:21.588387Z","shell.execute_reply":"2021-06-21T05:35:21.628698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Continous Features & Target","metadata":{}},{"cell_type":"markdown","source":"**Continous Features**:   age, trbps, chol, thalachh, oldpeak","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(18,15))\ngs = fig.add_gridspec(2,3)\n\nax0 = fig.add_subplot(gs[0,0])\nax1 = fig.add_subplot(gs[0,1])\nax2 = fig.add_subplot(gs[0,2])\nax3 = fig.add_subplot(gs[1,0])\nax4 = fig.add_subplot(gs[1,1])\n\n\nax_age = ax0\nsns.kdeplot(x='age', hue='output', data=data, fill=True, alpha=.5, linewidth=0, ax=ax_age, palette='YlGnBu', shade=True)\nsns.despine()\n\nax_trtbps = ax1\nsns.kdeplot(x='trtbps', hue='output', data=data, fill=True, alpha=.5, linewidth=0, ax=ax_trtbps, palette='YlGnBu', shade=True)\nsns.despine()\n\nax_chol = ax2\nsns.kdeplot(x='chol', hue='output', data=data, fill=True, alpha=.5, linewidth=0, ax=ax_chol, palette='YlGnBu', shade=True)\nsns.despine()\n\nax_thalachh = ax3\nsns.kdeplot(x='thalachh', hue='output', data=data, fill=True, alpha=.5, linewidth=0, ax=ax_thalachh, palette='YlGnBu', shade=True)\nsns.despine()\n\nax_oldpeak = ax4\nsns.kdeplot(x='oldpeak', hue='output', data=data, fill=True, alpha=.5, linewidth=0, ax=ax_oldpeak, palette='YlGnBu', shade=True)\nsns.despine()\n\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-21T05:35:21.631436Z","iopub.execute_input":"2021-06-21T05:35:21.631885Z","iopub.status.idle":"2021-06-21T05:35:22.658341Z","shell.execute_reply.started":"2021-06-21T05:35:21.631819Z","shell.execute_reply":"2021-06-21T05:35:22.657162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Check Out the Outlier in Continous Features","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(18,15))\ngs = fig.add_gridspec(2,3)\n\nax0 = fig.add_subplot(gs[0,0])\nax1 = fig.add_subplot(gs[0,1])\nax2 = fig.add_subplot(gs[0,2])\nax3 = fig.add_subplot(gs[1,0])\nax4 = fig.add_subplot(gs[1,1])\n\n\nax_age = ax0\nsns.boxplot(x='age',data=data, ax=ax_age, palette='YlGnBu')\nsns.despine()\n\nax_trtbps = ax1\nsns.boxplot(x='trtbps',data=data, ax=ax_trtbps, palette='YlGnBu')\nsns.despine()\n\nax_chol = ax2\nsns.boxplot(x='chol',data=data, ax=ax_chol, palette='YlGnBu')\nsns.despine()\n\nax_thalachh = ax3\nsns.boxplot(x='thalachh',data=data, ax=ax_thalachh, palette='YlGnBu')\nsns.despine()\n\nax_oldpeak = ax4\nsns.boxplot(x='oldpeak',data=data, ax=ax_oldpeak, palette='YlGnBu')\nsns.despine()\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-21T05:35:22.659666Z","iopub.execute_input":"2021-06-21T05:35:22.659991Z","iopub.status.idle":"2021-06-21T05:35:23.17817Z","shell.execute_reply.started":"2021-06-21T05:35:22.65996Z","shell.execute_reply":"2021-06-21T05:35:23.177304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can check out that there is some outlier in continous features. ","metadata":{}},{"cell_type":"markdown","source":"## Target Feature","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(14,8))\ngs = fig.add_gridspec(3,4)\nsns.set_style(\"white\")\nsns.set_context(\"poster\", font_scale = 0.5)\n\nax_target = fig.add_subplot(gs[:2,:2])\nsns.countplot(x='output', data=data, ax=ax_target, palette='YlGnBu')\nsns.despine()\n\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-21T05:35:23.179275Z","iopub.execute_input":"2021-06-21T05:35:23.17969Z","iopub.status.idle":"2021-06-21T05:35:23.325084Z","shell.execute_reply.started":"2021-06-21T05:35:23.179648Z","shell.execute_reply":"2021-06-21T05:35:23.32407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f,ax = plt.subplots(1,2, figsize=(15,8))\n\n\ndata.loc[data['output'] == 0].plot.hist(ax=ax[0], bins=20, edgecolor='black', color='lightgray')\nax[0].set_title('Age & target = 0')\n\ndata.loc[data['output'] == 1].plot.hist(ax=ax[1], bins=20, edgecolor='black', color='red')\nax[1].set_title('Age & target=1')\n\nplt.show();","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-21T05:35:23.326667Z","iopub.execute_input":"2021-06-21T05:35:23.32707Z","iopub.status.idle":"2021-06-21T05:35:25.412525Z","shell.execute_reply.started":"2021-06-21T05:35:23.327037Z","shell.execute_reply":"2021-06-21T05:35:25.411356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Correlation Between Features ","metadata":{}},{"cell_type":"code","source":"data.corr()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-21T05:35:25.414017Z","iopub.execute_input":"2021-06-21T05:35:25.414337Z","iopub.status.idle":"2021-06-21T05:35:25.443568Z","shell.execute_reply.started":"2021-06-21T05:35:25.414306Z","shell.execute_reply":"2021-06-21T05:35:25.442371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(14,8))\nsns.heatmap(data.corr(), annot=True, cmap='YlGnBu')\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-21T05:35:25.444946Z","iopub.execute_input":"2021-06-21T05:35:25.445486Z","iopub.status.idle":"2021-06-21T05:35:26.665117Z","shell.execute_reply.started":"2021-06-21T05:35:25.445453Z","shell.execute_reply":"2021-06-21T05:35:26.664029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Part2: Feature Engineering and Data Cleaning:\nFirst devide the columns into Categorical feature and Continuous Features.\n\nI am going to use dummies values to categorical features and use StandardScaler to numerical features","metadata":{}},{"cell_type":"code","source":"cat_columns = ['sex','exng','caa','cp','fbs','restecg','slp','thall']\ncon_columns = [\"age\",\"trtbps\",\"chol\",\"thalachh\",\"oldpeak\"]\ntarget_column = [\"output\"]\n","metadata":{"execution":{"iopub.status.busy":"2021-06-21T05:35:26.66636Z","iopub.execute_input":"2021-06-21T05:35:26.666665Z","iopub.status.idle":"2021-06-21T05:35:26.671204Z","shell.execute_reply.started":"2021-06-21T05:35:26.666634Z","shell.execute_reply":"2021-06-21T05:35:26.670265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Categorical Features","metadata":{}},{"cell_type":"code","source":"# Categorical Features \ndata = pd.get_dummies(data=data, columns=cat_columns)\ndata.columns","metadata":{"execution":{"iopub.status.busy":"2021-06-21T05:35:26.6725Z","iopub.execute_input":"2021-06-21T05:35:26.672806Z","iopub.status.idle":"2021-06-21T05:35:26.703064Z","shell.execute_reply.started":"2021-06-21T05:35:26.672774Z","shell.execute_reply":"2021-06-21T05:35:26.701949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Continuous Features\n\nWe found out some outlier in the continous features. So first before we start feature engineering, let's del all the outliers in the continous features. \n\n### But !!! Since the data is so small!! The result was bette when I didn't delect the outliers. ","metadata":{}},{"cell_type":"code","source":"\"\"\"# delect Outlier \ndef outliers_iqr(data):\n    q1, q3 = np.percentile(data, [25, 75])\n    iqr = q3 - q1\n    lower_bound = q1 - (iqr * 1.5)\n    upper_bound = q3 + (iqr * 1.5)\n    \n    return np.where((data > upper_bound)|(data < lower_bound))\n\n# delete 'trtbps', 'chol', 'thalachh', 'oldpeak'\ntrtbps_outlier = outliers_iqr(data['trtbps'])[0]\nchol_outlier = outliers_iqr(data['chol'])[0]\nthalachh_outlier = outliers_iqr(data['thalachh'])[0]\noldpeak_outlier = outliers_iqr(data['oldpeak'])[0]\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-06-21T05:35:26.705779Z","iopub.execute_input":"2021-06-21T05:35:26.706156Z","iopub.status.idle":"2021-06-21T05:35:26.713787Z","shell.execute_reply.started":"2021-06-21T05:35:26.706124Z","shell.execute_reply":"2021-06-21T05:35:26.712772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"data.loc[trtbps_outlier, 'trtbps']\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-06-21T05:35:26.715376Z","iopub.execute_input":"2021-06-21T05:35:26.715827Z","iopub.status.idle":"2021-06-21T05:35:26.732546Z","shell.execute_reply.started":"2021-06-21T05:35:26.715778Z","shell.execute_reply":"2021-06-21T05:35:26.73158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"data.loc[chol_outlier, 'chol']\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-06-21T05:35:26.73424Z","iopub.execute_input":"2021-06-21T05:35:26.734964Z","iopub.status.idle":"2021-06-21T05:35:26.744254Z","shell.execute_reply.started":"2021-06-21T05:35:26.734923Z","shell.execute_reply":"2021-06-21T05:35:26.743343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"data.loc[thalachh_outlier, 'thalachh']\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-06-21T05:35:26.745667Z","iopub.execute_input":"2021-06-21T05:35:26.746396Z","iopub.status.idle":"2021-06-21T05:35:26.758578Z","shell.execute_reply.started":"2021-06-21T05:35:26.746346Z","shell.execute_reply":"2021-06-21T05:35:26.75755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"data.loc[oldpeak_outlier, 'oldpeak']\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-06-21T05:35:26.759998Z","iopub.execute_input":"2021-06-21T05:35:26.760605Z","iopub.status.idle":"2021-06-21T05:35:26.772249Z","shell.execute_reply.started":"2021-06-21T05:35:26.76057Z","shell.execute_reply":"2021-06-21T05:35:26.771158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"# Concatenate all the array \nlead_outlier_index = np.concatenate((trtbps_outlier,\n                                     chol_outlier,\n                                     thalachh_outlier,\n                                     oldpeak_outlier), axis=None)\n\nprint(len(lead_outlier_index))\nlead_outlier_index\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-06-21T05:35:26.777Z","iopub.execute_input":"2021-06-21T05:35:26.777356Z","iopub.status.idle":"2021-06-21T05:35:26.785413Z","shell.execute_reply.started":"2021-06-21T05:35:26.777326Z","shell.execute_reply":"2021-06-21T05:35:26.784275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"# Put into 'lead_not_outlier_index' which is not the outliers data \nlead_not_outlier_index = []\n\nfor i in data.index:\n    if i not in lead_outlier_index:\n        lead_not_outlier_index.append(i)\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-06-21T05:35:26.787059Z","iopub.execute_input":"2021-06-21T05:35:26.787342Z","iopub.status.idle":"2021-06-21T05:35:26.79859Z","shell.execute_reply.started":"2021-06-21T05:35:26.787315Z","shell.execute_reply":"2021-06-21T05:35:26.797467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"data = data.loc[lead_not_outlier_index]\ndata = data.reset_index(drop=True)\ndata.columns\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-06-21T05:35:26.800074Z","iopub.execute_input":"2021-06-21T05:35:26.80039Z","iopub.status.idle":"2021-06-21T05:35:26.81311Z","shell.execute_reply.started":"2021-06-21T05:35:26.800359Z","shell.execute_reply":"2021-06-21T05:35:26.811781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now!! We delected all the outliers in the continous columns. \n\nLet's use the StandardScaler to do the feature engineering. ","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import RobustScaler\n\nscaler = RobustScaler()\ndata[con_columns] = scaler.fit_transform(data[con_columns])\n\ndata[con_columns]","metadata":{"execution":{"iopub.status.busy":"2021-06-21T05:35:26.814704Z","iopub.execute_input":"2021-06-21T05:35:26.81527Z","iopub.status.idle":"2021-06-21T05:35:26.986243Z","shell.execute_reply.started":"2021-06-21T05:35:26.815215Z","shell.execute_reply":"2021-06-21T05:35:26.985225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-21T05:35:26.987512Z","iopub.execute_input":"2021-06-21T05:35:26.987798Z","iopub.status.idle":"2021-06-21T05:35:27.012122Z","shell.execute_reply.started":"2021-06-21T05:35:26.98777Z","shell.execute_reply":"2021-06-21T05:35:27.011354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['output'].value_counts","metadata":{"execution":{"iopub.status.busy":"2021-06-21T05:35:27.013115Z","iopub.execute_input":"2021-06-21T05:35:27.013508Z","iopub.status.idle":"2021-06-21T05:35:27.025136Z","shell.execute_reply.started":"2021-06-21T05:35:27.013477Z","shell.execute_reply":"2021-06-21T05:35:27.024345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"NOW! The feature engineering is clear! Next we are going to split the train-test set and go modeling ~!","metadata":{}},{"cell_type":"markdown","source":"## Train - Valid - Test split","metadata":{}},{"cell_type":"code","source":"x = data.drop('output', axis=1)\ny = data['output'].values","metadata":{"execution":{"iopub.status.busy":"2021-06-21T05:35:27.026133Z","iopub.execute_input":"2021-06-21T05:35:27.026527Z","iopub.status.idle":"2021-06-21T05:35:27.038201Z","shell.execute_reply.started":"2021-06-21T05:35:27.026498Z","shell.execute_reply":"2021-06-21T05:35:27.037383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x,y,\n                                                    test_size=0.1,\n                                                    random_state=52,\n                                                    shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-21T05:35:27.039187Z","iopub.execute_input":"2021-06-21T05:35:27.039589Z","iopub.status.idle":"2021-06-21T05:35:27.119684Z","shell.execute_reply.started":"2021-06-21T05:35:27.03956Z","shell.execute_reply":"2021-06-21T05:35:27.118714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Part3: Predictive Modeling\n\n## 1) Running Basic Algorithms\n\nWe have gained some insights from the EDA part. But with that, we cannot accurately predict or tell whether a heart attack will occur or not.. So now we will predict by using some great Classification Algorithms. Following are the algorithms I will use to make the model:\n\n1) Logistic Regression\n\n2) Support Vector Machines(Linear and radial)\n\n3) Random Forest\n\n4) LightGBM\n\n5) KNeighborClassifier\n\n6) XGBoost","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier\n\nfrom sklearn.metrics import f1_score","metadata":{"execution":{"iopub.status.busy":"2021-06-21T05:35:27.121642Z","iopub.execute_input":"2021-06-21T05:35:27.122093Z","iopub.status.idle":"2021-06-21T05:35:28.750229Z","shell.execute_reply.started":"2021-06-21T05:35:27.122062Z","shell.execute_reply":"2021-06-21T05:35:28.74906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 1. LogisticRegression\n\nlr = LogisticRegression()\n\nlr.fit(x_train, y_train)\n\ny_pred = lr.predict(x_test)\n\nprint(f\"Logistic Regression F1 Score: {f1_score(y_test, y_pred, average='micro')}\")","metadata":{"execution":{"iopub.status.busy":"2021-06-21T05:35:28.751729Z","iopub.execute_input":"2021-06-21T05:35:28.752069Z","iopub.status.idle":"2021-06-21T05:35:28.780094Z","shell.execute_reply.started":"2021-06-21T05:35:28.752036Z","shell.execute_reply":"2021-06-21T05:35:28.778693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 2. Support Vector Machine\n\nsvc = SVC(probability=True)\n\nsvc.fit(x_train, y_train)\n\ny_pred = svc.predict(x_test)\n\nprint(f\"Support Vector Machine F1 Score: {f1_score(y_test, y_pred, average='micro')}\")","metadata":{"execution":{"iopub.status.busy":"2021-06-21T05:35:28.782351Z","iopub.execute_input":"2021-06-21T05:35:28.782978Z","iopub.status.idle":"2021-06-21T05:35:28.822132Z","shell.execute_reply.started":"2021-06-21T05:35:28.782922Z","shell.execute_reply":"2021-06-21T05:35:28.820985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 3. Rnadom Forest\n\nrf = RandomForestClassifier()\n\nrf.fit(x_train, y_train)\n\ny_pred = rf.predict(x_test)\n\nprint(f\"RandomForest F1 Score: {f1_score(y_test, y_pred, average='micro')}\")","metadata":{"execution":{"iopub.status.busy":"2021-06-21T05:35:28.823549Z","iopub.execute_input":"2021-06-21T05:35:28.823861Z","iopub.status.idle":"2021-06-21T05:35:29.052187Z","shell.execute_reply.started":"2021-06-21T05:35:28.823832Z","shell.execute_reply":"2021-06-21T05:35:29.051099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 4. LightGBM\n\nlgb = LGBMClassifier()\n\nlgb.fit(x_train, y_train)\n\ny_pred = lgb.predict(x_test)\n\nprint(f\"LightGBM F1 Score: {f1_score(y_test, y_pred, average='micro')}\")","metadata":{"execution":{"iopub.status.busy":"2021-06-21T05:35:29.053574Z","iopub.execute_input":"2021-06-21T05:35:29.054197Z","iopub.status.idle":"2021-06-21T05:35:29.147287Z","shell.execute_reply.started":"2021-06-21T05:35:29.054149Z","shell.execute_reply":"2021-06-21T05:35:29.146213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 5. KNeighborsClassifier \n\nknn = KNeighborsClassifier()\n\nknn.fit(x_train, y_train)\n\ny_pred = knn.predict(x_test)\n\nprint(f\"KNeighborsClassifier F1 Score: {f1_score(y_test, y_pred, average='micro')}\")","metadata":{"execution":{"iopub.status.busy":"2021-06-21T05:35:29.151723Z","iopub.execute_input":"2021-06-21T05:35:29.152165Z","iopub.status.idle":"2021-06-21T05:35:29.168264Z","shell.execute_reply.started":"2021-06-21T05:35:29.152127Z","shell.execute_reply":"2021-06-21T05:35:29.167077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### If you liked the notebook, consider giving an upvote. \n### Feel free to give me any comments !!!","metadata":{}}]}