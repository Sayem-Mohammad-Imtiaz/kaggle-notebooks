{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Business Problem","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Association Rules\n\nIt is a rule-based machine learning technique used to find patterns (relationships, structures) in the data.\n\nAssociation analysis applications are among the most common applications in data science. It will also coincide as referral systems.\n\nThese applications may have come up in the following ways, such as \"the person who bought that product also bought this product\", \"those who viewed that ad also looked at these ads\", or \"the next video recommended for you\".\n\nThese scenarios are the most frequently encountered scenarios within the scope of e-commerce data science data mining studies.\n\n\n# Apriori Algoritması\n\nIt is the most used method in this field.\n\nAssociation rule analysis is carried out by examining some metrics:\nX: product\nY: product\nN: total trade\n\n*Support: It gives the fraction of transactions which contains product X and Y. Basically Support tells us about the frequently bought products or the combination of products bought frequently.\nSupport(X, Y) = Freq(X,Y)/N\n\n*Confidence: It tells us how often the products X and Y occur together, given the number times X occurs.\nConfidence(X, Y) = Freq(X,Y) / Freq(X)\n\n*Lift: Lift indicates the strength of a rule over the random occurrence of A and B. It basically tells us the strength of any rule.\nLift = Support (X, Y)/( Support(X) * Support(Y) ) \n\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 1. Understanding the Data","execution_count":null},{"metadata":{"jupyter":{"outputs_hidden":true},"trusted":true},"cell_type":"code","source":"#!pip install mlxtend","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/supermarket/GroceryStoreDataSet.csv', names=['products'], header=None)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Data Preparation¶","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"I will use the Apriori algorithm to perform an association analysis.\n\nThe apriori method of the mlxtend library accepts the dataset as a True-False dataframe. I will use the data conversion methods of the mlxtend library again to convert the data. Therefore, I will convert the raw data set to the format that these methods will require.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Step1: I converted the data into list format. I separated the objects in each line with ','.\n\ndata = list(df[\"products\"].apply(lambda x : x.split(',')))\ndata","execution_count":null,"outputs":[]},{"metadata":{"jupyter":{"outputs_hidden":true},"trusted":true},"cell_type":"code","source":"pip install mlxtend","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Step2: I will apply the method of converting the data of mlxtend library into True-False\n# dataframe.\n# First, I install the mlxtend library for those who do not have it installed.\n\nfrom mlxtend.preprocessing import TransactionEncoder\nte = TransactionEncoder()\nte_data = te.fit(data).transform(data)\ndf = pd.DataFrame(te_data,columns=te.columns_)\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Implementing Apriori Algorithm","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"In the output of the Apriori algorithm, we get the frequencies of each combination in the whole data set. For example, in the output below, only the frequency (frequency) of \"BISCUIT\" in the whole dataset is 0.35, while the frequency (frequency) of \"BISCUIT and BREAD\" in the whole dataset is 0.20.\n\nThe apriori algorithm was given a min_support value of 0.2. Thus, product associations that are below 0.2 support value in combinations have been eliminated. If the verbose argument is 1, it will tell us how many combinations there are. In our example, 42 combinations were formed. In the last case, we have 16 combinations. Thus, our combination of 42-16 = 26 remained below the value of 0.2 support and was considered as an insignificant rate that we would not add to our comments.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from mlxtend.frequent_patterns import apriori\nfreq_items = apriori(df,min_support=0.20,use_colnames = True, verbose = 1)\nfreq_items","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Birliktelik Analizi Uygulama","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"I will apply the association analysis to the combination of mlxtend's association_rules method and the data set that we have support values. I will interpret my latest output according to the values of \"support\" and \"confidence\" and suggest a sample action idea.\n\nInterpretation of Sample Association Analysis Output:\n\nThe probability of BISCUIT and BREAD being seen together is 20% since support = 0.20.\nWhen BISCUIT is taken, the probability of getting BREAD is around 57% since confidence = 0.571429.\n\nBy giving \"min_threshold = 0.3\", it is ensured that the values with \"confidence\" value below 0.3 are not brought.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from mlxtend.frequent_patterns import association_rules\ndf_res = association_rules(freq_items, metric = \"confidence\", min_threshold = 0.3)\ndf_res","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. Preparation for Data Filtering\n\nIn this section, taking the lowest and highest confidence values, these values will be used in data filtering and the idea of action will be proposed.\n\nLet's find the highest confidence value. The output shows that the highest confidence value is 0.80.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"conf_max = df_res['confidence'].max()\nconf_max","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's find the lowest confidence value. The output shows that the lowest confidence value is 0.307.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"conf_min = df_res[\"confidence\"].min()\nconf_min","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6. Data Filtering\n\nData with the lowest, highest and 0.5 confidence value are filtered. It is ranked in ascending order according to \"confidence\" value.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_filt = df_res[ (df_res[\"confidence\"] == conf_min) | (df_res[\"confidence\"] == conf_max) | (df_res[\"confidence\"] == 0.5 )]\ndf_filt.sort_values(\"confidence\", ascending = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Comments and Action Advice","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Based on the above output;\n\nLine 1:\na). The probability of taking Bread and Biscuits together is 20% as support = 0.2.\nb). The probability of getting Biscuits when buying bread is 30% since confidence = 0.307692.\nc). The probability of taking the biscuit alone is 35%, since the consequent support = 0.35.\n\nLine 5:\na). The probability of taking coffee and cereal together is 20% as support = 0.2.\nb). The probability of taking Cereal when taking coffee is 50% since confidence = 0.5.\n\nLine 7:\na). The probability of taking milk and bread together is 20% since support = 0.2.\nb). When milk is taken, the probability of taking Bread is 80% since confidence = 0.8.\n\nComments :\n30% of customers who buy bread also get Biscuits. Cereal was also bought in half of the coffee sales. Milk and Bread were taken together in 20% of all purchases.\n\nAction Proposal:\nCustomers who buy milk are quite likely to buy bread (80%). This means; customers who buy milk also buy bread, and will likely keep their way to the bread aisle after receiving milk. Milk and bread departments can be located in distant locations within the market, and many departments may be required to pass through the bread department of the customer who purchases milk. Thus, the possibility of purchasing any product during the customer's journey can be increased.\n\nCustomers who buy bread seem a bit less likely to buy biscuits (30%). The probability of taking the biscuit alone seems to be low (35%). To increase the sale of biscuits, a biscuit stand can be placed right next to the bread shelf and the ones with cheap prices are placed in the foreground, and the price can be drawn with a dark label to attract the attention of the customer.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}