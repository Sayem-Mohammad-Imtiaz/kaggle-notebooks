{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Plan:\n\nWe will treat each column in two phases:\n### Data preprocessing:\n* Imputing missing values.\n* Handling categorical data.\n    \n### Data Visualization\n\nThen we will test several model and choose the one with the best performance:\n* Model creation: Logistic Regression-SVM-Gradient Boosting-KNN-RandomForest-XGBoost classifier.\n* Hyperparameter tuning.\n* Use the model to predict target column in Test set."},{"metadata":{},"cell_type":"markdown","source":"Lets get started, first lets import our typical libraries:"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nprint(\"Setup complete\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's import our train and test data."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#training data\ntrain = pd.read_csv(\"../input/hr-analytics-job-change-of-data-scientists/aug_train.csv\")\n#testing data\ntest = pd.read_csv('../input/hr-analytics-job-change-of-data-scientists/aug_test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's take a closer look to our data."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the first glence we can see that most of the data is categorical, and we have several missing values in different columns.\nLet's take a look at the number of missing values in each column:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train data missing values: \\n\",train.isna().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Test data missing values: \\n\",test.isna().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# City:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"city\"].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that every city has a specific number, with a prefix \"city_\", so first we have to delete the prefix then transform the data from object type to integer."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['city'] = train['city'].map(lambda row: row.replace('city_',''))\ntest['city'] = test['city'].map(lambda row: row.replace('city_',''))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['city'] = train['city'].astype(int)\ntest['city'] = test['city'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The result:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train[\"city\"].unique())\nprint(\"We have {} unique variables:\".format(len(train[\"city\"].unique())))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,8))\ng = sns.distplot(train.city,kde=False, color=\"red\")\ng = (g.set(xlim=(0,185),xticks=range(0,190,10)))\nplt.xlabel(\"City Number\")\nplt.ylabel(\"Distribution\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Most common cities are:\\n\",train['city'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['city'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that candidates from the city number **103** are the majority."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.sort_values(by='city')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And here we can see that each city has specific city_development_index, so deleting this column won't make any difference to the model, however we can visualize what is the development index for the cities with the majority of candidates:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.loc[train.city == 103,'city_development_index']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So the city with the majority of candidates is a well developped city, but do we have a relationship between the city development index and the chance of the candidate looking for another job?"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['city'] = train['city'].astype(np.int8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lineplot(x='target', y='city_development_index',data=train)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The candidates from cities with low development index tend to look for a job change and vice versa. Now let's just drop this column from both train and test data."},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.drop(labels='city_development_index', axis=1)\ntest = test.drop(labels='city_development_index', axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Gender:"},{"metadata":{},"cell_type":"markdown","source":"It is obvious we have to encode the caregorical data and take care of missing data, there are a lot of ways to handle gender missing values such as replacing them with the gender most common, deleting those rows...etc\nBut I prefer to fill the gender missing values with \"Other\" since we may have candidates identify as non-binary.\nFirst lets take a lot at our gender column:"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.violinplot(x='gender', y='target', palette='Set2', data=train)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It looks like more men don't look for a job change but actually we can't conclude that from this violinplot since most of the candidates are men."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['gender'].hist()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's fill the missing values with 'Other':"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['gender'] = train['gender'].fillna('Other')\ntest['gender'] = test['gender'].fillna('Other')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since we don't have any missing values left in the gender column, let's encode the column, I will use for this one LabelEncoder of sklearn:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_encoder = LabelEncoder()\ntrain[\"gender\"] = label_encoder.fit_transform(train[\"gender\"])\ntest[\"gender\"] = label_encoder.fit_transform(test[\"gender\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Female : 0\n#### Male : 1\n#### Other : 2"},{"metadata":{},"cell_type":"markdown","source":"Lets have a look at what we have achieved so far:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Relevent experience:"},{"metadata":{},"cell_type":"markdown","source":"Before making any decision we have to look at the values of this column:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['relevent_experience'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['relevent_experience'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So it only has two values, and no missing data."},{"metadata":{},"cell_type":"markdown","source":"### Encoding:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"relevent_experience\"] = train[\"relevent_experience\"].map({\"Has relevent experience\":1, \"No relevent experience\":0})\ntest[\"relevent_experience\"] = test[\"relevent_experience\"].map({\"Has relevent experience\":1, \"No relevent experience\":0})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Enrolled university:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['enrolled_university'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This column has missing values, lets take care of them before encoding."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='enrolled_university', data=train)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='enrolled_university', data=test)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Most of the candidates had no university enrollment"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lineplot(x='enrolled_university', y='target', palette='Set2', data=train)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### We can see that most of candidates had no enrollment more likely aren't looking for a job change."},{"metadata":{},"cell_type":"markdown","source":"We can't tell if the missing data is left out or the candidates had no enrollment, but also we don't want to create a new value (like 'OTHER') because it can create a pattern that doesn't exist.\nI will fill the missing values with the no_enrollment value."},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"enrolled_university\"]=train[\"enrolled_university\"].fillna('no_enrollment')\ntest[\"enrolled_university\"]=test[\"enrolled_university\"].fillna('no_enrollment')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Encode:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"enrolled_university\"] = label_encoder.fit_transform(train[\"enrolled_university\"])\ntest[\"enrolled_university\"] = label_encoder.fit_transform(test[\"enrolled_university\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Education level:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['education_level'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['education_level'].hist()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most candidates are graduates."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lineplot(x='education_level', y='target', palette='Set2', data=train)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Graduates and Masters are most likely to look for a job change, but people with Phd or primary school aren't."},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"education_level\"]=train[\"education_level\"].fillna('Other')\ntest[\"education_level\"]=test[\"education_level\"].fillna('Other')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"education_level\"] = label_encoder.fit_transform(train[\"education_level\"])\ntest[\"education_level\"] = label_encoder.fit_transform(test[\"education_level\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Major Discipline:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['major_discipline'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['major_discipline'].hist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most of our candidates are STEM majors."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['major_discipline'] = train['major_discipline'].fillna('Other')\ntest['major_discipline'] = test['major_discipline'].fillna('Other')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"major_discipline\"] = label_encoder.fit_transform(train[\"major_discipline\"])\ntest[\"major_discipline\"] = label_encoder.fit_transform(test[\"major_discipline\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Experience:"},{"metadata":{},"cell_type":"markdown","source":"#### The experience variable is an object indicating the minimum or maximum years of experience a candidate had, so deleting the operators won't make a big difference."},{"metadata":{},"cell_type":"markdown","source":"First we have to convert the column to string."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['experience'] = train['experience'].astype(str)\ntest['experience'] = test['experience'].astype(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['experience'] = train['experience'].apply(lambda col: col.replace('>',''))\ntrain['experience'] = train['experience'].apply(lambda col: col.replace('<',''))\ntest['experience'] = test['experience'].apply(lambda col: col.replace('>',''))\ntest['experience'] = test['experience'].apply(lambda col: col.replace('<',''))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Delete the symbols."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets fill the missing values with 0."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['experience'] = train['experience'].apply(lambda col: col.replace('nan','0'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['experience'] = test['experience'].apply(lambda col: col.replace('nan','0'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Convert the values to Integer."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['experience'] = pd.to_numeric(train['experience'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['experience'] = pd.to_numeric(test['experience'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Company size:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['company_size'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### We have 5938 missing values in the company_size column, before encoding categorical data we have to handle the missing values."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(y='company_size', data=train)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### We can see that most candidates work in small companies (between 50-500)"},{"metadata":{},"cell_type":"markdown","source":"Identify each interval with a number:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['company_size'] = train['company_size'].map({\"50-99\":0, \"<10\":1, \"10000+\":2, \"5000-9999\":3, \"1000-4999\":4, \"10/49\":5, \"100-500\":6, \"500-999\":7})\ntest['company_size'] = test['company_size'].map({\"50-99\":0, \"<10\":1, \"10000+\":2, \"5000-9999\":3, \"1000-4999\":4, \"10/49\":5, \"100-500\":6, \"500-999\":7})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"30% of candidates didn't mention if they had experience or not, so we will assume that these candidates have no experience."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['company_size'] = train['company_size'].fillna(8)\ntest['company_size'] = test['company_size'].fillna(8)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Company type:"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(y='company_type', data=train)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Most of candidates work in Private limited company type (pvt ltd)"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['company_type'] = train['company_type'].map({\"Pvt Ltd\":0, \"Funded Startup\":1, \"Early Stage Startup\":2, \"Public Sector\":3, \"NGO\":4, \"Other\":5})\ntest['company_type'] = test['company_type'].map({\"Pvt Ltd\":0, \"Funded Startup\":1, \"Early Stage Startup\":2, \"Public Sector\":3, \"NGO\":4, \"Other\":5})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.violinplot(x='company_size', y='company_type',data=train)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Private limited companies are of different sizes, from less than ten people to +10 000! So we can't really find a relation between company size and type.\n#### We will fill missing values in company_type with 0(private limited comapany)."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['company_type'] = train['company_type'].fillna(0)\ntest['company_type'] = test['company_type'].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Last new job:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['last_new_job'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We assume that missing values are from candidates that had no job."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['last_new_job'] = train['last_new_job'].fillna('never')\ntest['last_new_job'] = test['last_new_job'].fillna('never')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.violinplot(x='last_new_job', y='target', data=train)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Less the years difference between the last job and the current, more likely a candidate will look for a job change. The same goes for candidates that had only one job OR are looking for a job for the first time in their career."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['last_new_job'] = train['last_new_job'].map({\"1\":1, \">4\": 5, \"never\":0, \"4\":4, \"3\":3, \"2\":2})\ntest['last_new_job'] = test['last_new_job'].map({\"1\":1, \">4\": 5, \"never\":0, \"4\":4, \"3\":3, \"2\":2})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.catplot(y=\"target\",x=\"last_new_job\",data=train, kind=\"bar\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So we have taken care of all categorical data and missing values, lets take a look at what we have done so far:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### pre modeling steps:"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = train['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(['target'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = test.astype(np.int8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.astype(np.int8)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Models testing:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn import svm\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nimport xgboost as xgb\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn import metrics\nfrom sklearn.model_selection import KFold, cross_val_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets try different models and see what works best:"},{"metadata":{"trusted":true},"cell_type":"code","source":"KFold_Score = pd.DataFrame()\nclassifiers = ['Linear SVM', 'LogisticRegression', 'RandomForestClassifier', 'XGBoostClassifier','GradientBoostingClassifier']\nmodels = [svm.SVC(kernel='linear'),\n          LogisticRegression(max_iter = 1000),\n          RandomForestClassifier(n_estimators=200, random_state=0),\n          xgb.XGBClassifier(n_estimators=100),\n          GradientBoostingClassifier(random_state=0)\n         ]\nj = 0\n#for i in models:\n    #model = i\n    #cv = KFold(n_splits=5, random_state=0, shuffle=True)\n    #KFold_Score[classifiers[j]] = (cross_val_score(model, train, np.ravel(pred), scoring = 'accuracy', cv=cv))\n    #j = j+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#mean = pd.DataFrame(KFold_Score.mean(), index= classifiers\n#KFold_Score = pd.concat([KFold_Score,mean.T])\n#KFold_Score.index=['Fold 1','Fold 2','Fold 3','Fold 4','Fold 5','Mean']\n#KFold_Score.T.sort_values(by=['Mean'], ascending = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I commented the code because it takes great amount of time to run and commit."},{"metadata":{},"cell_type":"markdown","source":"We can see that Gradient Boosting gives the best result."},{"metadata":{},"cell_type":"markdown","source":"# Hyperparameter Tuning:"},{"metadata":{},"cell_type":"markdown","source":"Lets initialize our model with these parameters:"},{"metadata":{"trusted":true},"cell_type":"code","source":"mymodel = GradientBoostingClassifier(learning_rate=0.1, min_samples_split=500,min_samples_leaf=50,max_depth=8,max_features='sqrt',subsample=0.8,random_state=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We shouldn't use the enrollee_id since it is unique for each candidate."},{"metadata":{"trusted":true},"cell_type":"code","source":"predictors = [x for x in train.columns if x not in [\"enrollee_id\"]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First we have to look for an optimal number of estimators:"},{"metadata":{"trusted":true},"cell_type":"code","source":"param_test1 = {'n_estimators':range(10,100,10)}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Grid search:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nCV_gbc = GridSearchCV(estimator=mymodel, param_grid=param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv= 5)\nCV_gbc.fit(train[predictors],pred)\nCV_gbc.best_params_, CV_gbc.best_score_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see that here we got 90 as the optimal estimators for 0.1 learning rate, it is close to 100 so we will increase the learning rate to 0.2. (I tried working with number of estimators as 90 but when I increased the learning rate I got slightly better results, I won't include the whole process because it will take a lot of time to run)"},{"metadata":{"trusted":true},"cell_type":"code","source":"mymodel0 = GradientBoostingClassifier(learning_rate=0.2, min_samples_split=500,min_samples_leaf=50,max_depth=8,max_features='sqrt',subsample=0.8,random_state=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nCV_gbc0 = GridSearchCV(estimator=mymodel0, param_grid=param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv= 5)\nCV_gbc0.fit(train[predictors],pred)\nCV_gbc0.best_params_, CV_gbc0.best_score_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The next step is to find the max_depth and min_samples_split."},{"metadata":{"trusted":true},"cell_type":"code","source":"param_test2 = {'max_depth':range(5,9,1), 'min_samples_split':range(400,1000,100)}\ngbc = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.2, n_estimators=70, max_features='sqrt', subsample=0.8, random_state=10), \nparam_grid = param_test2, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\ngbc.fit(train[predictors],pred)\ngbc.best_params_, gbc.best_score_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So we got a maximum depth of 6 and minimum samples split is 700."},{"metadata":{},"cell_type":"markdown","source":"min_samples_leaf:"},{"metadata":{"trusted":true},"cell_type":"code","source":"param_test3 = {'min_samples_split':range(400,1000,100), 'min_samples_leaf':range(30,71,10)}\ngsearch3 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.2, n_estimators=70,max_depth=6, max_features='sqrt', subsample=0.8, random_state=10), \nparam_grid = param_test3, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\ngsearch3.fit(train[predictors],pred)\ngsearch3.best_params_, gsearch3.best_score_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets write a function that returns the accuracy, auc score and the importance of each variable:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_validate","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"AUC represents the probability that a random positive  example is positioned to the right of a random negative example. AUC ranges in value from 0 to 1. A model whose predictions are 100% wrong has an AUC of 0.0; one whose predictions are 100% correct has an AUC of 1.0. [https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc]"},{"metadata":{"trusted":true},"cell_type":"code","source":"def modelfit(alg, dtrain, pred, predictors, performCV=True, printFeatureImportance=True, cv_folds=5):\n    #Fit the algorithm on the data\n    alg.fit(dtrain[predictors], pred)\n        \n    #Predict training set:\n    dtrain_predictions = alg.predict(dtrain[predictors])\n    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n    \n    #Perform cross-validation:\n    if performCV:\n        cv_score = cross_validate(alg, dtrain[predictors], pred, cv=cv_folds, scoring='roc_auc')\n    \n    #Print model report:\n    print(\"\\nModel Report\")\n    print(\"Accuracy :\",metrics.accuracy_score(pred.values, dtrain_predictions))\n    print(\"AUC Score (Train):\", metrics.roc_auc_score(pred, dtrain_predprob))\n    print(\"cv Score: \", np.mean(cv_score['test_score']))\n        \n    #Print Feature Importance:\n    if printFeatureImportance:\n        feat_imp = pd.Series(alg.feature_importances_, predictors).sort_values(ascending=False)\n        feat_imp.plot(kind='bar', title='Feature Importances')\n        plt.ylabel('Feature Importance Score')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets run the function on the model we got till now:"},{"metadata":{"trusted":true},"cell_type":"code","source":"modelfit(gsearch3.best_estimator_, train, pred, predictors)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param_test4 = {'max_features':range(7,20,2)}\ngsearch4 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.2, n_estimators=70,max_depth=6, min_samples_split=800, min_samples_leaf=40, subsample=0.8, random_state=10),\nparam_grid = param_test4, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\ngsearch4.fit(train[predictors],pred)\ngsearch4.best_params_, gsearch4.best_score_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nWith this we have the final tree-parameters as:\n\n    min_samples_split: 800\n    min_samples_leaf: 40\n    max_depth: 6\n    max_features: 11\n"},{"metadata":{},"cell_type":"markdown","source":"The next step would be try different subsample values."},{"metadata":{"trusted":true},"cell_type":"code","source":"param_test5 = {'subsample':[0.6,0.7,0.75,0.8,0.85,0.9]}\ngsearch5 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.2, n_estimators=70,max_depth=6,min_samples_split=800, min_samples_leaf=40, subsample=0.8, random_state=10,max_features=11),\nparam_grid = param_test5, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\ngsearch5.fit(train[predictors],pred)\ngsearch5.best_params_, gsearch5.best_score_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We got 0.8 as the optimum subsample value.\nNow, we need to lower the learning rate and increase the number of estimators to see if we get better results."},{"metadata":{"trusted":true},"cell_type":"code","source":"gbm_tuned_1 = GradientBoostingClassifier(learning_rate=0.1, n_estimators=140,max_depth=6, min_samples_split=800,min_samples_leaf=40, subsample=0.8, random_state=10, max_features=11)\nmodelfit(gbm_tuned_1, train, pred, predictors)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see a slight improvement in Accuracy and cv score, lets descrease the learning rate and increase number of estimators one more time."},{"metadata":{"trusted":true},"cell_type":"code","source":"gbm_tuned_2 = GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,max_depth=6, min_samples_split=800,min_samples_leaf=40, subsample=0.8, random_state=10, max_features=11)\nmodelfit(gbm_tuned_2, train, pred, predictors)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gbm_tuned_3 = GradientBoostingClassifier(learning_rate=0.005, n_estimators=1500,max_depth=6, min_samples_split=800,min_samples_leaf=40, subsample=0.8, random_state=10, max_features=11)\nmodelfit(gbm_tuned_3, train, pred, predictors)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gbm_tuned_4 = GradientBoostingClassifier(learning_rate=0.005, n_estimators=1800,max_depth=6, min_samples_split=800,min_samples_leaf=40, subsample=0.8, random_state=10, max_features=11)\nmodelfit(gbm_tuned_4, train, pred, predictors)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"increasing the number of estimators got us a slightly better model."},{"metadata":{},"cell_type":"markdown","source":"Lets fit the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"gbm_tuned_4.fit(train,pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Make predictions on test set:"},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = gbm_tuned_3.predict(test[predictors])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Save results to the task submission file::"},{"metadata":{"trusted":true},"cell_type":"code","source":"output = pd.DataFrame({'enrollee_id ': test.enrollee_id , 'target': preds})\noutput.to_csv('./sample_submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}