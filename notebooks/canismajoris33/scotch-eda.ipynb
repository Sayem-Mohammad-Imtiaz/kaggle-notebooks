{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt \n\n\n\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# A quick EDA of a Scotch Whisky Dataset.\n"},{"metadata":{},"cell_type":"markdown","source":"I wanted to try and clean up this Dataset in a way which allows me to find good value Whiskys, especially from Distilleries or regions which I prefer. \n\nLet's start with a quick look at the data."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"scotch_data = pd.read_csv('../input/22000-scotch-whisky-reviews/scotch_review.csv')\nscotch_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scotch_data.columns\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ultimately I would like to find Scotch with good score to price ratios."},{"metadata":{"trusted":true},"cell_type":"code","source":"#scotch_data.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It appears as though the entire \"Currency\" column is listed in dollars, this should be easy to confirm."},{"metadata":{"trusted":true},"cell_type":"code","source":"scotch_data['currency'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2247 rows with 2247 instances of '$', we can drop this column. "},{"metadata":{"trusted":true},"cell_type":"code","source":"scotch_data.drop('currency', axis=1, inplace=True)\nscotch_data.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It appears as though we have a redundant built in index which is unnamed, we can drop this too."},{"metadata":{"trusted":true},"cell_type":"code","source":"scotch_data.drop('Unnamed: 0', axis=1,inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I think ABV should be it's own column, it appears that most of the name entries end with the ABV%, let's see if this is consistant throughout the dataset.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(scotch_data['name'].str.endswith('%').value_counts())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our data contains 2247 rows but only 2186 end with %. Let's find those which don't before we try to separate out the ABV."},{"metadata":{"trusted":true},"cell_type":"code","source":"problem_locations = scotch_data['name'].loc[lambda df: df.str.endswith('%') == False]\nproblems = []\nproblems = problem_locations.index.values\nprint(problems)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.options.display.max_colwidth = 150\ndisplay(problem_locations)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It would have been nice to have some sort of uniformity in the name syntax, but we can make this work."},{"metadata":{"trusted":true},"cell_type":"code","source":"scotch_data['name'].str.replace(\"ABV\", \"\") # We already know the percentages are ABV, and we are going to create a new column anyway.\nscotch_data['name'].str.rstrip(\" \") # Remove any whitespace leftover from the removal of ABV.\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The column is now looking more slightly more uniform, we can remove the ABVs from name and move them  into their own column where they belong.\n\nNote: For anyone wondering why ABV is relevant, I generally prefer bottlings to be â‰¥ 43% to allow for the addition of water to open them up. Additionally cask strength bottlings like those with ABVs in the 50s or 60s are usually watered down to a more palatable AVB which means more pours from the same sized bottle. "},{"metadata":{"trusted":true},"cell_type":"code","source":"scotch_data['ABV'] = scotch_data['name'].str.rpartition(',')[2]\nscotch_data['name'] = scotch_data['name'].str.rpartition(',')[0]\n\n\nscotch_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The rpartition function handled the ABV problem beautifully. The dataset is looking cleaner, but there are still some ugly column names like review.point, we can easily clean these up."},{"metadata":{"trusted":true},"cell_type":"code","source":"scotch_data['Score'] = scotch_data['review.point']\nscotch_data.drop('review.point', axis=1,inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scotch_data = scotch_data.rename(columns={'name': 'Name', 'category': 'Category', 'price' : 'Price', 'description' : 'Description'})\n#Capitalizing the columns.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"At this point I downloaded the cleaned dataset into an excel file to give it a quick look over and see if I spotted any inconsistencies or major discrepancies. I noticed a few of the very expensive bottlings had strange formatting and so I fixed them via their indicies, more information is provided below.\n\nThis clearly would not be a viable option in a larger dataset, but it took me only a minute to look over this particular set. "},{"metadata":{"trusted":true},"cell_type":"code","source":"scotch_data.loc[[19,95,410,1000,1215], 'Price'] = '15000'\n\n#Price for item 576 was listed at 44/liter, the standard bottle size is 750ml so we just did 44*.75 to come up with a price of $33.\n\nscotch_data.loc[576, 'Price'] = '33'\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"When I tried converting the prices into integers, I ran into trouble with a few very expensive scotches which had prices written with commas. I considered using pd.to_numeric with errors= 'coerce', but that would mean either manually re-entering the prices or removing those scotches from the list, which I don't want to do at this time (Even though I assume they will be major outliers in the future). Instead, we can just remove the commas from all entries. \n\nI need to create a list of the indexes of these problematic prices."},{"metadata":{"trusted":true},"cell_type":"code","source":"messed_up_entries = scotch_data[scotch_data['Price'].str.contains(\"/set\")] \nprint(messed_up_entries.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scotch_data['Price'] = scotch_data['Price'].str.replace(',', '').astype(float)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scotch_data['Price'].round(decimals=0)\nscotch_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nplt.figure(figsize=(25,15)) \nplt.title('Score distribution for different types of Whisky', fontdict={'fontsize': 40})\nsns.set(font_scale=2)\nsns.swarmplot(x='Category', y='Score', data=scotch_data)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The vast majority of our data are comprised of Single Malts, which refers to bottlings that come from one particular distillery. We do however have enough data to see that all types of Whisky have a somewhat similar distribution, with a slight exception for Single Grain Whisky which is lacking any bottling that recieived a score greater than 95."},{"metadata":{},"cell_type":"markdown","source":"We can take a look to see if there is any clear relationship between Score and Price, which seems like a reasonable assumption to make. "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25,15))\nplt.title('Score vs Price',fontdict={'fontsize': 40})\nsns.set(font_scale=2)\nb = sns.scatterplot(x='Price', y='Score', data=scotch_data, hue='Category', s=75)\nb.set(xlim=(0,150))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I limited the X axis here due to some extremely high priced Whiskys, which were clear outliers; likely a rare old bottling sold at auction and not a bottle which is available in stores. \n\nFrom this data there really doesn't seem to be much of a relationship between Price and Score. If we look at the cheaply priced Whiskys we can see that it's dominated mostly by blends, which is not surprising. At all prices there are bottles with scores from around 80 to 85, but there seems to be an increase in quality initially at around \\\\$30, at which point we start to see an increase in scores between 85 and 90 points, and again at a \\\\$50 price point where we start to see multiple scores greater than 90. \n\nAs I had expected, there isn't much of a relationship between price and score, beyond a particular price point."},{"metadata":{},"cell_type":"markdown","source":"I'm interested in taking a look at just the entries from Islay, as this is my preferred region due to the smoky profile of the whiskys distilled there. The data isn't organized in a way where I could select by region, so I'll need to get a bit creative."},{"metadata":{"trusted":true},"cell_type":"code","source":"#A list of all of the Islay distilleries, although port charlotte and port ellen are not \n#currently producing, there may be an old bottle or two kicking around.\n\nnon_islay = []\n\nislay_dist = ['Ardbeg', 'Bowmore', 'Bruichladdich', 'Bunnahabhain', 'Caol Ila', 'Kilchomin', 'Lagavulin','Laphroaig','Port Charlotte', 'Port Ellen']\n\ndf_filtered = scotch_data[scotch_data['Name'].str.contains('Laphroaig|Ardbeg|Bowmore|Bunnahabhain|Caol Ila|Port Ellen|Port Charlotte|Kilchomin|Lagavulin|Bruichladdich')]\n\ndf_filtered.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"Creating a new column to measure a Score to Price ratio.\"\"\"\n\nscotch_data['Score to Price'] = round((scotch_data['Score']/scotch_data['Price']),4)\n\ndf_filtered['Score to Price'] = round((df_filtered['Score']/df_filtered['Price']), 4)\ndf_filtered.sort_values('Score to Price', ascending=True)\n\n\n\"\"\"I decided I was unwilling to spend more than $300 on a bottle, so I filtered out the more expensive bottlings.\"\"\"\n\ndf_filtered = df_filtered[df_filtered['Price'] <= 300]\ndf_filtered.sample(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"At this point, I am looking to graph my filtered dataframe with Islay Whiskys only, I dropped the outliers (the collector bottles over \\\\$10,000) and look at the bottles within a reasonable price range, we will look at \\\\$300 and below."},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"We are going to create a new column by iterating over the Name column to find Distilleries.\"\"\"\n\ndist_list = []\n\nfor idx, row in df_filtered.iterrows():\n    if 'Ardbeg' in row.Name:\n        dist_list.append('Ardbeg')\n    elif 'Bowmore' in row.Name:\n        dist_list.append('Bowmore')\n    elif 'Bruichladdich' in row.Name:\n        dist_list.append('Bruichladdich')\n    elif 'Bunnahabhain' in row.Name:\n        dist_list.append('Bunnahabhain')\n    elif 'Caol Ila' in row.Name:\n        dist_list.append('Caol Ila')\n    elif 'Kilchomin' in row.Name:\n        dist_list.append('Kilchomin') \n    elif 'Lagavulin' in row.Name:\n        dist_list.append('Lagavulin')\n    elif 'Laphroaig' in row.Name:\n        dist_list.append('Laphroaig')\n    elif 'Port Charlotte' in row.Name:\n        dist_list.append('Port Charlotte')\n    elif 'Port Ellen' in row.Name:\n        dist_list.append('Port Ellen')\n\nm = np.array(dist_list)\n\ndf_filtered['Distillery'] = m\n\ndf_filtered.sample(10)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nplt.figure(figsize=(25,15))\nplt.title('Score vs Price', fontdict={'fontsize':40})\nsns.set(font_scale=2)\ng = sns.scatterplot(x='Price', y='Score', data=df_filtered, hue='Distillery', s=125)\ng.set(xlim=(0,150))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"One last quick look at the top 21 Whiskys from Islay with a Score to Price ratio of 1.5 or greater."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_top = df_filtered[df_filtered['Score to Price'] > 1.5]\ndf_top.head(21)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ultimately I am happy with this cleaned up data as it will help me find the best value Whiskys by distillery whenever I am in the market for a new bottle.\n\nI would certainly appreciate constructive comments and insights as I am relatively new to this sort of work and looking to start a career in Data science. "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}