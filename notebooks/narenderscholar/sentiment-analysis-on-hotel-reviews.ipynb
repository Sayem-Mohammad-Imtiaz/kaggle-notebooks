{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np                        ## Matrix functions\nimport matplotlib.pyplot as plt           ## PLotting\nimport pandas as pd                       ## To Work WIth Dataframes \nimport plotly.express as px               ## For Interactive Visualization\nimport plotly.graph_objects as go         ## For Detailed visual plots\nfrom collections import Counter         \nfrom plotly.subplots import make_subplots ## To Plot Subplots\nfrom wordcloud import WordCloud           ## To Generate Wordcloud\nfrom datetime import datetime             ## Work with timeseries data\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"review = pd.read_csv('../input/trip-advisor-hotel-reviews/tripadvisor_hotel_reviews.csv')\nreview.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"review.apply(lambda x: sum(x.isnull()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data Cleaning","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"review['Review']= review['Review'].apply(lambda x : str(x).replace('\\n', ' '))\nreview['Review']= review['Review'].apply(lambda x : x.lower())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ratings distribution","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"review.apply(lambda x: len(x.unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"review.groupby(by='Rating')['Review'].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extracting meaningful words from reviews","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nfrom nltk.tokenize import word_tokenize\n\nreview['Words'] = review['Review'].apply(word_tokenize)\n\nfrom nltk.corpus import stopwords \n\nStopWords = set(stopwords.words('english'))\n\ndef clean_words(x):\n    words = []\n    for i in x:\n        if i.isalnum() and i not in StopWords:\n            words.append(i)\n    return words\n\nreview['Words'] = review['Words'].apply(clean_words)\nreview['Word Count'] = review['Words'].apply(lambda x : len(x))\ndel StopWords","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Review length by Rating","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.histogram(review, x='Word Count', color='Rating',\n            barmode = 'overlay', nbins=50, marginal = 'box')\nfig.update_layout(title = \"Word Count Distribution in Reviews by Ratings.\",\n                 xaxis_title = \"Word Count\",\n                 yaxis_title = \"No of Reviews\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"review.drop('Word Count', axis = 1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Most common words by rating","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"most_common = dict()\n\nfor group, data in review.groupby(by='Rating'):\n    words = []\n    for i in data['Words'].tolist():\n        words.extend(i)\n    words = nltk.FreqDist(words)\n    words = words.most_common(10)\n    most_common['{}'.format(group)] = words\nprint(\"Most Common Words by ratings and their word-counts:\")\npd.DataFrame(most_common)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Parts Of Speech","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"review['POS'] = review['Words'].apply(nltk.pos_tag)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adjectives","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_adjective(x):\n    adj = set(['JJ', 'JJR', 'JJS'])\n    word = []\n    for i in x:\n        if i[1] in adj:\n            word.append(i[0])\n    return word\n\nreview['ADJ'] = review['POS'].apply(get_adjective)\n\nmost_common = dict()\nfor group, data in review.groupby(by='Rating'):\n    words = []\n    for i in data['ADJ'].tolist():\n        words.extend(i)\n    words = nltk.FreqDist(words)\n    words = words.most_common(10)\n    most_common['{}'.format(group)] = words\nprint(\"Most Common Adjectives by ratings:\")\npd.DataFrame(most_common)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Nouns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_noun(x):\n    noun = set(['NN', 'NNS', 'NNP', 'NNPS'])\n    word = []\n    for i in x:\n        if i[1] in noun:\n            word.append(i[0])\n    return word\n\nreview['Noun'] = review['POS'].apply(get_noun)\n\nreview.drop('POS', axis = 1, inplace = True)\n\nmost_common = dict()\nfor group, data in review.groupby(by='Rating'):\n    words = []\n    for i in data['Noun'].tolist():\n        words.extend(i)\n    words = nltk.FreqDist(words)\n    words = words.most_common(10)\n    most_common['{}'.format(group)] = words\nprint(\"Most Common Nouns by ratings:\")\npd.DataFrame(most_common)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Common Bigrams","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"most_common = dict()\nfor group, data in review.groupby(by='Rating'):\n    words = []\n    for i in data['Words'].tolist():\n        words.extend(i)\n    bigram = list(nltk.bigrams(words))\n    bigram = nltk.FreqDist(bigram)\n    bigram = bigram.most_common(10)\n    most_common['{}'.format(group)] = bigram\n\nprint(\"Most Common Bi-grams by Ratings:\")\npd.DataFrame(most_common)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Polarity And Subjectivity","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from textblob import TextBlob\n\nreview['Subjectivity'] = review['Review'].apply(lambda x : TextBlob(x).sentiment.subjectivity)\nreview['Polarity'] = review['Review'].apply(lambda x : TextBlob(x).sentiment.polarity)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.histogram(review, x='Subjectivity', barmode='overlay', color='Rating')\nfig.update_layout(title = \"Subjectivity distribution in reviews of different ratings.\",\n                 xaxis_title = \"Subjectivity\",\n                 yaxis_title = \"Number of Reviews\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.histogram(review, x='Polarity', barmode='overlay', color='Rating')\n\nfig.update_layout(title = \"Polarity distribution in reviews of different ratings.\",\n                 xaxis_title = \"Subjectivity\",\n                 yaxis_title = \"Number of Reviews\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"PREDICTIONS"},{"metadata":{"trusted":true},"cell_type":"code","source":"# I. Tf-idf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text  import TfidfVectorizer\ntf = TfidfVectorizer(stop_words = 'english', ngram_range = (1,2),\n                    min_df = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = review['Review']\ny = review['Rating']\n\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y, random_state = 1)\n\ntf_x_train = tf.fit_transform(x_train)\ntf_x_test = tf.transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nperformance = {'Model' : [],\n              'Accuracy Score' : [],\n              'Precision Score' : [],\n              'Recall Score' : [],\n              'f1 Score' : []}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlr= LogisticRegression()\nlr.fit(tf_x_train, y_train)\npred = lr.predict(tf_x_test)\n\nperformance['Model'].append('LogisticRegression')\nperformance['Accuracy Score'].append(accuracy_score(y_test, pred))\nperformance['Precision Score'].append(precision_score(y_test, pred, average='macro'))\nperformance['Recall Score'].append(recall_score(y_test, pred, average='macro'))\nperformance['f1 Score'].append(f1_score(y_test, pred, average='macro'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\n\nsgd = SGDClassifier()\nsgd.fit(tf_x_train, y_train)\npred = sgd.predict(tf_x_test)\n\nperformance['Model'].append('SGD')\nperformance['Accuracy Score'].append(accuracy_score(y_test, pred))\nperformance['Precision Score'].append(precision_score(y_test, pred, average='macro'))\nperformance['Recall Score'].append(recall_score(y_test, pred, average='macro'))\nperformance['f1 Score'].append(f1_score(y_test, pred, average='macro'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\n\nmnb = MultinomialNB()\nmnb.fit(tf_x_train, y_train)\npred = mnb.predict(tf_x_test)\n\nperformance['Model'].append('Multinomial NB')\nperformance['Accuracy Score'].append(accuracy_score(y_test, pred))\nperformance['Precision Score'].append(precision_score(y_test, pred, average='macro'))\nperformance['Recall Score'].append(recall_score(y_test, pred, average='macro'))\nperformance['f1 Score'].append(f1_score(y_test, pred, average='macro'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import BernoulliNB\n\nbnb = BernoulliNB()\nbnb.fit(tf_x_train, y_train)\npred = bnb.predict(tf_x_test)\n\nperformance['Model'].append('Bernoulli NB')\nperformance['Accuracy Score'].append(accuracy_score(y_test, pred))\nperformance['Precision Score'].append(precision_score(y_test, pred, average='macro'))\nperformance['Recall Score'].append(recall_score(y_test, pred, average='macro'))\nperformance['f1 Score'].append(f1_score(y_test, pred, average='macro'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier()\nrfc.fit(tf_x_train, y_train)\npred = rfc.predict(tf_x_test)\n\nperformance['Model'].append('Random Forest')\nperformance['Accuracy Score'].append(accuracy_score(y_test, pred))\nperformance['Precision Score'].append(precision_score(y_test, pred, average='macro'))\nperformance['Recall Score'].append(recall_score(y_test, pred, average='macro'))\nperformance['f1 Score'].append(f1_score(y_test, pred, average='macro'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Voted Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statistics import mode\n\nclass voted_classifier():\n    def __init__(self):\n        self.classifiers = [lr, sgd, mnb, bnb, rfc]\n        \n    def classify(self, features):\n        names = ['lr', 'sgd', 'mnb', 'bnb', 'rfc']\n        i = 0 \n        votes = pd.DataFrame()\n        for classifier in self.classifiers:\n            pred = classifier.predict(features)\n            votes[names[i]] = pred\n            i+=1\n        return votes.mode(axis = 1)[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vc = voted_classifier()\npred = vc.classify(tf_x_test)\n\nperformance['Model'].append('Voted Classifier')\nperformance['Accuracy Score'].append(accuracy_score(y_test, pred))\nperformance['Precision Score'].append(precision_score(y_test, pred, average='macro'))\nperformance['Recall Score'].append(recall_score(y_test, pred, average='macro'))\nperformance['f1 Score'].append(f1_score(y_test, pred, average='macro'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(performance)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}