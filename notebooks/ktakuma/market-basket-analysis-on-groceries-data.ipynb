{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load the Dataset\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom mlxtend.preprocessing import TransactionEncoder\n\n# Load transactions from pandas.\ndf = pd.read_csv(\"/kaggle/input/groceries-dataset/Groceries_dataset.csv\")\n\n# Print the header\nprint(df.head(10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Grouping each observation by customer\ndf_grouped=df.groupby(['Member_number','Date'])['itemDescription'].apply(sum)\ndf_grouped","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a list of transaction\ntransactions = [a[1]['itemDescription'].tolist() for a in list(df.groupby(['Member_number','Date']))]\ntransactions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encoding transactions\nte = TransactionEncoder()\nte_ary = te.fit(transactions).transform(transactions)\nte.columns_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntransactions = pd.DataFrame(te_ary, columns=te.columns_)\npf = transactions.describe()\npf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pf.iloc[0]-pf.iloc[3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f = pf.iloc[0]-pf.iloc[3]\na = f.tolist()\nb = list(f.index)\nitem = pd.DataFrame([[a[r],b[r]]for r in range(len(a))], columns=['Count','Item'])\nitem = item.sort_values(['Count'], ascending=False).head(50)\ntransactions","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Simplest Metric"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Computing Support for Single Items\nprint(transactions.mean().sort_values(ascending=False))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Condifence & Lift"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print first five items\nprint(transactions.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Computing support.\nsupportWmOv = np.logical_and(transactions['whole milk'], transactions['other vegetables']).mean()\nsupportWm = transactions['whole milk'].mean()\nsupportOv = transactions['other vegetables'].mean()\n\n# Compute and print confidence and lift.\nconfidence = supportWmOv / supportWm\nlift = supportWmOv / (supportWm * supportOv)\n\n# Print results.\nprint(supportOv, confidence, lift)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Computing Leverage"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compute and print leverage\nleverage = supportWmOv - supportWm * supportOv\nprint(leverage)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Computing Conviction"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compute support for NOT \"almonds\"\nsupport_n_Ov = 1.0 - onehot['other vegetables'].mean()\n\n# Compute support for \"asparagus\" and NOT \"almonds\"\nsupportWm_n_Ov = supportWm - supportWmOv\n\n# Compute conviction\nconviction = supportWm*support_n_Ov / supportWmOv\nprint(conviction)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Calculating Metrics"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's define the functions to calculate the metrics from the original data.\nfrom itertools import permutations\n\ndef supportA(itemA, df):\n    return float(df[itemA].mean())    \n\ndef supportB(itemB, df):\n    return float(df[itemB].mean())\n\ndef confidence(itemA,itemB,df):\n    return float(np.logical_and(df[itemA],df[itemB]).mean() /(df[itemA].mean()))\n\ndef lift(itemA,itemB,df):\n    return float(np.logical_and(df[itemA],df[itemB]).mean() /(df[itemA].mean() * df[itemB].mean()))\n\ndef leverage(itemA,itemB,df):\n    return np.logical_and(df[itemA],df[itemB]).mean() - (df[itemA].mean()*df[itemB].mean())\n\ndef conviction(itemA, itemB, df):\n    # Compute support for A and B\n    supportAB = np.logical_and(df[itemA], df[itemB]).mean()\n    # Compute support for A\n    supportA = df[itemA].mean()\n    # Compute support for not B\n    supportnB = 1.0 - df[itemB].mean()\n    # Compute support for A not B\n    supportAnB = supportA - supportAB\n    # Compute conviction\n    return float(supportA*supportnB / supportAnB)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"item_pairs = list()\nfor itemA,itemB in permutations(onehot,2):\n    item_pairs.append(list((itemA,itemB, #names\n                            onehot[itemA].sum(),onehot[itemB].sum(), #individual count\n                            np.logical_and(onehot[itemA],onehot[itemB]).sum(), #pair count\n                            supportA(itemA, onehot),\n                            supportB(itemB, onehot),\n                            confidence(itemA,itemB,onehot), #confidence\n                            lift(itemA,itemB,onehot), #lift\n                            leverage(itemA,itemB,onehot), # leverage\n                            conviction(itemA, itemB, onehot)\n                            ))) # ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"item_pairs = pd.DataFrame(item_pairs,columns = ['itemA','itemB',\n                                                'countItemA','countItemB',\n                                                'countItemA&B',\n                                                'Antecedent Support',\n                                                'Consequent Support',\n                                                'Confidence',\n                                                'Lift',\n                                                'Leverage',\n                                                'Conviction'])\n\nitem_pairs.sample(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Performing Multi-Metric Filtering"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select subset of rules with low consequent support.\n#rules = item_pairs[item_pairs['Consequent Support'] < 0.05]\n#print(len(rules))\n#rules","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# Select subset of rules with lift > 1.5.\n#rules_2 = rules[rules['Lift'] > 1.5]\n#print(len(rules_2))\n#rules_2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Apriori Algorithm"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import Apriori algorithm\nfrom mlxtend.frequent_patterns import apriori","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compute frequent itemsets\nfrequent_itemsets = apriori(transactions, min_support = 0.0005,max_len = 4, use_colnames = True)\n\n# Print number of itemsets\nprint(len(frequent_itemsets))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Print frequent itemsets\nprint(frequent_itemsets.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Apriori and Computing Association Rule "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import Apriori algorithm\nfrom mlxtend.frequent_patterns import apriori, association_rules\n\n# Compute association rules\nArules = association_rules(frequent_itemsets,\n                           metric = \"support\",\n                           min_threshold = 0.001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Arules","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Raise the threshold\n# Compute association rules\nArules_2 = association_rules(frequent_itemsets,\n                           metric = \"support\",\n                           min_threshold = 0.010)\n\nArules_2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Raise the threshold\n# Compute association rules\nArules_3 = association_rules(frequent_itemsets,\n                           metric = \"support\",\n                           min_threshold = 0.050)\n\nArules_3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(nrows=3, ncols=1, sharex=True, figsize=(10,5))\nsns.boxenplot(x='antecedent support', data=Arules, linewidth=0.9, color=\"royalblue\", ax=ax[0])\nsns.boxenplot(x='support', data=Arules, linewidth=0.9, color=\"royalblue\", ax=ax[1])\nsns.boxenplot(x='confidence', data=Arules, linewidth=0.9, color=\"royalblue\", ax=ax[2])\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filtered_rules = Arules[(Arules['antecedent support'] > 0.06) &\n                        (Arules['support'] > 0.002) &\n                        (Arules['confidence'] > 0.04) &\n                        (Arules['lift'] > 1.00)]\n\nfiltered_rules","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}