{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:left\"> Table of Contents </h1>\n\n#### 1) Introduction\n\n#### 2) Load Required Libraries\n\n#### 3) Read Data\n\n#### 4) SweetViz (AutoEDA)\n\n>       Method 1: To visualize in html format\n\n>       Method 2: To visualize in kaggle notebook\n\n>       Method 3: To visualize in Google Colab notebook\n\n>       Method 4: Split and Compare (Dataset comparisons)\n\n>       Method 5: Target Analysis\n\n>       Method 6: Skip Variables\n\n>       Method 7: Comparing categories within a column - Such as Sex, Embarked and Pclass","metadata":{}},{"cell_type":"markdown","source":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:center; border-radius: 15px 50px;\"> 1) Introduction </h1>","metadata":{}},{"cell_type":"markdown","source":"##### **1) Exploratory Data Analysis** is a process where we tend to analyze the dataset and summarize the main characteristics of the dataset often using visual \n\nmethods. EDA is really important because if you are not familiar with the dataset you are working on, then you won’t be able to infer something from that data. \n\nHowever, EDA generally takes a lot of time.\n\n>    In this notebook, we will work on **Automating EDA using Sweetviz.** It is a python library that generates beautiful, high-density visualizations to start your EDA. Let us explore Sweetviz in detail.\n\n>    **Pandas Profiling** will not work properly when you have many features in your dataset (Advanced Housing Price) and ran out of memory. **SweetViz** works much better than pandas profiling.\n\n\n#### **2) Sweetviz 2.0**\n\n - is an open-source pandas-based library to perform the primary EDA task without much hassle or with **just two lines of code.** It also generates a summarised report with great visualizations.\n\n - Sweetviz is an open source Python library that generates beautiful, high-density visualizations to kickstart EDA (Exploratory Data Analysis) with a single line of code. Output is a fully self-contained HTML application.\n\n - The system is built around quickly visualizing target values and comparing datasets. Its goal is to help quick analysis of target characteristics, training vs testing data, and other such data characterization tasks.\n\n>    **Target analysis:** shows how a target value (e.g. \"Survived\" in the Titanic dataset) relates to other features\n\n>    **Dataset comparisons:** between datasets (e.g. \"Train vs Test\") and intra-set (e.g. \"Male vs Female\")\n\n>    **Correlation/associations:** full integration of numerical and categorical data correlations and associations, all in one graph and table\n\n>    **Visualize and compare:**\n\n       - Distinct datasets (e.g. training vs test data)\n       \n       - Intra-set characteristics (e.g. male versus female)\n\n>    **Mixed-type associations:**\n\n       - Sweetviz integrates associations for,to provide maximum information for all data types.\n       \n         - numerical (Pearson's correlation)\n         \n         - categorical (uncertainty coefficient)\n         \n         - categorical-numerical (correlation ratio)\n       \n>    **Type inference:** automatically detects numerical, categorical and text features, with optional manual overrides\n\n>    **Summary information:**\n\n      - Type, unique values, missing values, duplicate rows, most frequent values\n      \n      - Numerical analysis:\n      \n      - min/max/range, quartiles, mean, mode, standard deviation, sum, median absolute deviation, coefficient of variation, kurtosis, skewness\n      \n#### There are 3 main functions for creating reports:\n\n   - **analyze(…)**\n\n   - **compare(…)**\n       \n   - **compare_intra(…)**","metadata":{}},{"cell_type":"code","source":"from IPython.display import Image","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Image('../input/imagespandas-profiling/sweetviz_05.png',width=500,height=500)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Image('../input/imagespandas-profiling/sweetviz_06.png',width=800,height=800)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=color:blue align=\"left\"> Creating a report: </h2>\n\n<h3 style=color:green align=\"left\"> Step 1: Installing Sweetviz </h3>\n\n        pip install sweetviz\n\n<h3 style=color:green align=\"left\"> Step 2: Load the pandas dataframe(s) </h3>\n\n       import sweetviz\n \n       import pandas as pd\n \n       train = pd.read_csv(\"/kaggle/input/mobile-price-classification/train.csv\")\n \n       test = pd.read_csv(\"/kaggle/input/mobile-price-classification/test.csv\")\n \n \n<h3 style=color:green align=\"left\"> Step 3: create the report </h3>\n\n - **analyze()** for a single dataset (Sweetviz has a function named Analyze() which analyzes the whole dataset and provides a detailed report with visualization)\n\n - **compare()** to compare 2 datasets (e.g. Test versus Train)\n\n - **compare_intra()** to compare 2 sub-populations within a same dataset\n \n \n<h3 style=color:green align=\"left\"> Step 4: generate output </h3>\n\n - report.show_html()\n \n - With the default options, this will create a file **\"SWEETVIZ_REPORT.html\"** and pop open a browser. If you are operating inside a notebook, that file will be generated but the browser may not pop up **(using show_notebook()** is recommended for notebooks, see documentation).","metadata":{}},{"cell_type":"markdown","source":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:center; border-radius: 15px 50px;\"> 2) Load Required Libraries </h1>","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:center; border-radius: 15px 50px;\"> 3) Read Data </h1>","metadata":{}},{"cell_type":"code","source":"mobile_train = pd.read_csv(\"/kaggle/input/mobile-price-classification/train.csv\")\nmobile_test = pd.read_csv(\"/kaggle/input/mobile-price-classification/test.csv\")\n\ntitanic_train = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntitanic_test = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n\nnetflix = pd.read_csv(\"/kaggle/input/netflix-shows/netflix_titles.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(mobile_train.head(3))\ndisplay(mobile_test.head(3))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(titanic_train.head(3))\ndisplay(titanic_test.head(3))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(netflix.head(3))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Size of mobile price train dataset:', mobile_train.shape)\nprint('\\nSize of mobile price test dataset:', mobile_test.shape)\nprint('\\nSize of titanic train dataset:', titanic_train.shape)\nprint('\\nSize of titanic test dataset:', titanic_test.shape)\nprint('\\nSize of netflix dataset:', netflix.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Missing Values in mobile price train:\\n\\n', mobile_train.isnull().sum())\nprint('\\n\\nMissing Values in mobile price test:\\n\\n', mobile_test.isnull().sum())\nprint('\\n\\nMissing Values in titanic train:\\n\\n', titanic_train.isnull().sum())\nprint('\\n\\nMissing Values in titanic test:\\n\\n', titanic_test.isnull().sum())\nprint('\\n\\nMissing Values in netflix:\\n\\n', netflix.isnull().sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Mobile Price Classification:\\n\\n', mobile_train.info())\nprint('\\n\\nTitanic:\\n\\n', titanic_train.info())\nprint('\\n\\nNetflix:\\n\\n', netflix.info())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mobile_train['price_range'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mobile_train['wifi'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"netflix['type'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"netflix['type'] = netflix['type'].map({'Movie':0, 'TV Show':1})","metadata":{}},{"cell_type":"code","source":"netflix['rating'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"netflix['rating'] = netflix['rating'].fillna(netflix['rating'].mode()[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:center; border-radius: 15px 50px;\"> 4) SweetViz (AutoEDA) </h1>","metadata":{}},{"cell_type":"code","source":"!pip install sweetviz","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sweetviz as sv","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=color:blue align=\"left\"> Generate the Profiling Report in five ways </h2>\n\n--------------------\n\n<h3 style=color:green align=\"left\"> Method 1: To visualize in html format </h3>\n\n\n##### import sweetviz as sv\n##### my_report = sv.analyze(df)\n##### my_report.show_html()        # Default arguments will generate to \"SWEETVIZ_REPORT.html\"\n\n--------------------------\n\n<h3 style=color:green align=\"left\"> Method 2: To visualize in kaggle notebook </h3>\n\n##### import sweetviz as sv\n##### my_report = sv.analyze(df)\n##### my_report.show_notebook(w=\"100%\", h=\"full\")      # if working in Kaggle\n\n------------------------\n\n<h3 style=color:green align=\"left\"> Method 3: To visualize in Google Colab notebook </h3>\n\n##### import sweetviz as sv\n##### my_report = sv.analyze(df)\n##### my_report.show_notebook() # if working in colab\n\n-----------------------\n\n<h3 style=color:green align=\"left\"> Method 4: Split and Compare (Dataset comparisons) </h3>\n\n#### a) Comparision single (train) Datframe by Split\n#### b) Comparision two (train and test) Datframes\n\n----------------------\n\n<h3 style=color:green align=\"left\"> Method 5: Target Analysis </h3>\n\n#### a) Analyze single (train) Dataframe wrt Target feature\n#### b) Compare two Dataframes (train and test) wrt Target feature\n\n---------------------\n\n<h3 style=color:green align=\"left\"> Method 6: Skip Variables </h3>\n\n---------------------\n\n<h3 style=color:green align=\"left\"> Method 7: Comparing categories within a column - Such as Sex, Embarked and Pclass </h3>\n\n--------------------","metadata":{}},{"cell_type":"markdown","source":"<h1 style=\"background-color:orange; font-family:newtimeroman; font-size:200%; text-align:center; border-radius: 15px 50px;\"> Method 1: To visualize in html format </h1>","metadata":{}},{"cell_type":"code","source":"# Analyzing data\nmy_report = sv.analyze(mobile_train)\n\n# Generating report\n# Default name is SWEETVIZ_REPORT.html\nmy_report.show_html('EDA_Report.html', open_browser=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### For reading html file **EDA_Report.html** follow steps\n\n - Top Right corner expand **Add data**\n \n - Check under **output / kaggle/working / EDA_Report.html**","metadata":{}},{"cell_type":"code","source":"import IPython\nIPython.display.HTML(\"EDA_Report.html\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:orange; font-family:newtimeroman; font-size:200%; text-align:center; border-radius: 15px 50px;\"> Method 2: To visualize in kaggle notebook </h1>","metadata":{}},{"cell_type":"code","source":"my_report1 = sv.analyze(mobile_train)\nmy_report1.show_notebook(w=\"100%\", h=\"full\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:orange; font-family:newtimeroman; font-size:200%; text-align:center; border-radius: 15px 50px;\"> Method 3: To visualize in Google Colab notebook </h1>","metadata":{}},{"cell_type":"code","source":"my_report2 = sv.analyze(mobile_train)\nmy_report2.show_notebook()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_report3 = sv.analyze(netflix)\nmy_report3.show_notebook()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_report3.show_html('EDA_Report_Netflix.html', open_browser=False)\nIPython.display.HTML(\"EDA_Report_Netflix.html\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:orange; font-family:newtimeroman; font-size:200%; text-align:center; border-radius: 15px 50px;\"> Method 4: Split and Compare (Dataset comparisons) </h1>\n\n- Other than this Sweetviz can also be used to visualize the **comparison of test and train data.** For comparison let us divide this data into 2 parts, **first 1000 rows for train dataset and rest 1000 rows for the test dataset.**\n\n- **Compare()** function of Sweetviz is used for comparison of the dataset. The commands given below will create and compare our test and train dataset.","metadata":{}},{"cell_type":"markdown","source":"<h1 style=\"background-color:yellow; font-family:newtimeroman; font-size:180%; text-align:left;\"> a) Comparision single (train) Datframe by Split </h1>","metadata":{}},{"cell_type":"markdown","source":"### Mobile Price Classification","metadata":{}},{"cell_type":"code","source":"# Spliting the data into two datasets\ndata1 = mobile_train[0:1000]\ndata2 = mobile_train[1000:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"report_comp1 = sv.compare([data1,'DATA1'],[data2,'DATA2']) \nreport_comp1.show_notebook()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"report_comp1.show_html(filepath = 'report.html', open_browser=True, layout = 'vertical', scale=0.7)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"report_comp1.show_notebook(w=None, h=None, scale=None, layout='vertical')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Netflix","metadata":{}},{"cell_type":"code","source":"X = netflix.drop(['type','show_id'], axis=1)\ny = netflix['type']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data split using 80/20 split ratio\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y , test_size=0.2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Comparision Report\nreport_comp1 = sv.compare([X_train, 'Train'],[X_test,'Test']) \nreport_comp1.show_notebook()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:yellow; font-family:newtimeroman; font-size:180%; text-align:left;\"> b) Comparision two Datframes (train and test) </h1>\n\n- To compare two data sets, simply use the compare() function. Its parameters are the same as analyze(), except with an inserted second parameter to cover the comparison dataframe. It is recommended to use the [dataframe, \"name\"] format of parameters to better differentiate between the base and compared dataframes. (e.g. [my_df, \"Train\"] vs my_df)\n\n             my_report = sv.compare([my_dataframe, \"Training Data\"], [test_df, \"Test Data\"], \"Survived\", feature_config)","metadata":{}},{"cell_type":"code","source":"my_comp2 = sv.compare([mobile_train, 'Train'], [mobile_test, \"Test\"])\nmy_comp2.show_notebook()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:orange; font-family:newtimeroman; font-size:200%; text-align:center; border-radius: 15px 50px;\"> Method 5: Target Analysis </h1>\n\n- We can also perform **target analysis**, but currently, it only **supports numerical or binary targets,** rather than categorical targets. Let’s consider **wifi** as a target:","metadata":{}},{"cell_type":"markdown","source":"<h1 style=\"background-color:yellow; font-family:newtimeroman; font-size:190%; text-align:left;\"> a) Analyze single (train) Dataframe wrt Target feature </h1>","metadata":{}},{"cell_type":"markdown","source":"        my_report3 = sv.analyze(titanic_train, \"Survived\")\n        \n        my_report3.show_notebook()\n        \n        \n        \n        my_report4 = sv.analyze([titanic_train, 'Train'], target_feat='Survived')\n        \n        my_report4.show_notebook()","metadata":{}},{"cell_type":"code","source":"my_report4 = sv.analyze([titanic_train, 'Train'], target_feat='Survived')\nmy_report4.show_notebook()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:yellow; font-family:newtimeroman; font-size:190%; text-align:left;\"> b) Compare two Dataframes (train and test) wrt Target feature </h1>","metadata":{}},{"cell_type":"markdown","source":"     my_comp3 = sv.compare(titanic_train,titanic_test,'Survived')\n\n     my_comp3.show_notebook()\n     \n     \n\n     my_comp4 = sv.compare([titanic_train, \"Train\"], [titanic_test, \"Test\"], target_feat='Survived')\n\n     my_comp4.show_notebook()","metadata":{}},{"cell_type":"code","source":"my_comp4 = sv.compare([titanic_train, \"Train\"], [titanic_test, \"Test\"], target_feat='Survived')\nmy_comp4.show_notebook()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:orange; font-family:newtimeroman; font-size:200%; text-align:center; border-radius: 15px 50px;\"> Method 6: Skip Variables </h1>","metadata":{}},{"cell_type":"code","source":"# Generally can skip unwanted features like S.No / PassengerId / Name / Id. \n# force_cat : selected features to be considered as categorical variables eventhough they are integer in nature\n\nfeature_config = sv.FeatureConfig(skip=['PassengerId', 'Name'], force_cat=['Ticket', 'Pclass'])\nmy_comp5 = sv.compare([titanic_train, 'Train'], [titanic_test, 'Test'], 'Survived', feature_config)\nmy_comp5.show_notebook()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_config1 = sv.FeatureConfig(skip=['show_id', 'description'], force_cat=['director', 'release_year', 'type', 'rating'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:orange; font-family:newtimeroman; font-size:200%; text-align:center; border-radius: 15px 50px;\"> Method 7: Comparing categories within a column - Such as Sex, Embarked and Pclass </h1>\n\n### Comparing two subsets of the same dataframe (e.g. Male vs Female)\n- Another way to get great insights is to use the comparison functionality to **split your dataset into 2 sub-populations.**\n\n- Support for this is built in through the **compare_intra()** function. This function takes a boolean series as one of the arguments, as well as an explicit \"name\" tuple for naming the **(true, false)** resulting datasets. Note that internally, this **creates 2 separate dataframes** to represent each resulting group. As such, it is more of a shorthand function of doing such processing manually.\n\n             my_report = sv.compare_intra(my_dataframe, my_dataframe[\"Sex\"] == \"male\", [\"Male\", \"Female\"], feature_config)\n             ","metadata":{}},{"cell_type":"code","source":"my_comp6 = sv.compare_intra(titanic_train, titanic_train[\"Sex\"] == 'male', ['Male', 'Female'], 'Survived', feature_config)\nmy_comp6.show_notebook()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:orange; font-family:newtimeroman; font-size:200%; text-align:center; border-radius: 15px 50px;\"> Method 8: Optional arguments </h1>","metadata":{}},{"cell_type":"markdown","source":"### 8.1) pairwise_analysis:\n- Correlations and other associations can take exponential time (n^2) to complete. The default setting (\"auto\") will run without warning until a data set contains \"association_auto_threshold\" features. Past that threshold, you need to explicitly pass the parameter pairwise_analysis=\"on\" (or =\"off\") since processing that many features would take a long time. This parameter also covers the generation of the association graphs (based on Drazen Zaric's concept):","metadata":{}},{"cell_type":"code","source":"my_report5 = sv.analyze(netflix, pairwise_analysis=\"off\")\nmy_report5.show_notebook()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 8.2) feat_cfg:\n- A FeatureConfig object representing features to be **skipped, or to be forced** a certain type in the analysis. The arguments can either be a single string or list of strings. Parameters are **skip, force_cat, force_num and force_text.** The \"force_\" arguments override the built-in type detection. They can be constructed as follows:\n\n           feature_config = sv.FeatureConfig(skip=\"PassengerId\", force_text=[\"Age\"])\n           \n           \n#### a) skip and force_cat --> refer **Method 6: Skip Variables**","metadata":{}},{"cell_type":"code","source":"feature_config3 = sv.FeatureConfig(skip=\"show_id\", force_text=[\"release_year\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:180%; text-align:center; border-radius: 15px 50px;\"> If you like the kernal... Don't forget to upvote and comment!!!!!!!!!!!!!!!!! </h1>","metadata":{}}]}