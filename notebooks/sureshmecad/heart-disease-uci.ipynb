{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> A heart attack occurs when the flow of blood to the heart is blocked. The blockage is most often a buildup of fat, cholesterol and other substances, which form a plaque in the arteries that feed the heart (coronary arteries). From WHO statistics every year 17.9 million dying from heart attack. The medical study says that human life style is the main reason behind this heart problem. Apart from this there are many key factors which warns that the person may/maynot getting chance of heart attack.\n\n> <img style=\"float: centre;\" src=\"https://img.lovepik.com/photo/50074/6189.jpg_wh860.jpg\" width=\"600px\"/>\n\n> This dataset contain some medical information of patients which tells whether that person getting a heart attack chance is less or more. Using the information explore the dataset and classify the target variable using different Machine Learning models and findout which algorithm suitable for this dataset."},{"metadata":{},"cell_type":"markdown","source":"|Variable              |Description                                                        |\n|----------------------|-------------------------------------------------------------------|\n|age                   |age                                                                |\n|sex                   |sex                                                                |\n|cp                    |chest pain type (4 values)                                         |\n|trestbps              |resting blood pressure                                             |\n|chol                  |serum cholestoral in mg/dl                                         |\n|fbs                   |fasting blood sugar > 120 mg/dl                                    |\n|restecg               |resting electrocardiographic results (values 0,1,2)                |\n|thalach               |maximum heart rate achieved                                        |\n|exang                 |exercise induced angina                                            |\n|oldpeak               |oldpeak = ST depression induced by exercise relative to rest       |\n|slope                 |the slope of the peak exercise ST segment                          |\n|ca                    |number of major vessels (0-3) colored by flourosopy                |\n|thal                  |thal: 3 = normal; 6 = fixed defect; 7 = reversable defect          |"},{"metadata":{},"cell_type":"markdown","source":"### The list bellow tells us what each variable represents and the type of data (**float** or **categorical**) it should contain:\n\n1. **age**, **Float**\n - Age is the most important risk factor in developing cardiovascular or heart diseases, with approximately a tripling of risk with each decade of life. Coronary fatty streaks can begin to form in adolescence. It is estimated that 82 percent of people who die of coronary heart disease are 65 and older. Simultaneously, the risk of stroke doubles every decade after age 55.\n\n- **sex** - **Category**\n  - 0 = female\n  - 1 = male\n  \n - Men are at greater risk of heart disease than pre-menopausal women. Once past menopause, it has been argued that a woman’s risk is similar to a man’s although more recent data from the WHO and UN disputes this. If a female has diabetes, she is more likely to develop heart disease than a male with diabetes.\n\n- **cp**, chest pain, **Category**\n  - 1 = typical angina,\n  - 2 = atypical angina,\n  - 3 = non-anginal pain,\n  - 4 = asymptomatic\n  \n - Angina is chest pain or discomfort caused when your heart muscle doesn’t get enough oxygen-rich blood. It may feel like pressure or squeezing in your chest. The discomfort also can occur in your shoulders, arms, neck, jaw, or back. Angina pain may even feel like indigestion.\n  \n- **restbp**, resting blood pressure (in mm Hg), **Float**\n\n - **Resting Blood Pressure:** Over time, high blood pressure can damage arteries that feed your heart. High blood pressure that occurs with other conditions, such as obesity, high cholesterol or diabetes, increases your risk even more.\n\n- **chol**, serum cholesterol in mg/dl, **Float**\n\n - **Serum Cholesterol:** A high level of low-density lipoprotein (LDL) cholesterol (the “bad” cholesterol) is most likely to narrow arteries. A high level of triglycerides, a type of blood fat related to your diet, also ups your risk of a heart attack. However, a high level of high-density lipoprotein (HDL) cholesterol (the “good” cholesterol) lowers your risk of a heart attack.\n\n- **fbs**, fasting blood sugar, **Category**\n  - 0 = >=120 mg/dl\n  - 1 = <120 mg/dl\n  \n - **Fasting Blood Sugar:** Not producing enough of a hormone secreted by your pancreas (insulin) or not responding to insulin properly causes your body’s blood sugar levels to rise, increasing your risk of a heart attack.\n  \n- **restecg**, resting electrocardiographic results, **Category**\n  - 1 = normal\n  - 2 = having ST-T wave abnormality\n  - 3 = showing probable or definite left ventricular hypertrophy\n  \n - **Resting ECG:** For people at low risk of cardiovascular disease, the USPSTF concludes with moderate certainty that the potential harms of screening with resting or exercise ECG equal or exceed the potential benefits. For people at intermediate to high risk, current evidence is insufficient to assess the balance of benefits and harms of screening.\n  \n- **thalach**,  maximum heart rate achieved, **Float**\n\n - **Max heart rate achieved:** The increase in cardiovascular risk, associated with the acceleration of heart rate, was comparable to the increase in risk observed with high blood pressure. It has been shown that an increase in heart rate by 10 beats per minute was associated with an increase in the risk of cardiac death by at least 20%, and this increase in the risk is similar to the one observed with an increase in systolic blood pressure by 10 mm Hg.\n\n- **exang**, exercise induced angina, **Category**\n  - 0 = no\n  - 1 = yes\n  \n - **Exercise induced angina:** The pain or discomfort associated with angina usually feels tight, gripping or squeezing, and can vary from mild to severe. Angina is usually felt in the center of your chest but may spread to either or both of your shoulders, or your back, neck, jaw or arm. It can even be felt in your hands. o Types of Angina a. Stable Angina / Angina Pectoris b. Unstable Angina c. Variant (Prinzmetal) Angina d. Microvascular Angina.\n  \n- **oldpeak**, ST depression induced by exercise relative to rest. **Float**\n\n - **Peak exercise ST segment:** A treadmill ECG stress test is considered abnormal when there is a horizontal or down-sloping ST-segment depression ≥ 1 mm at 60–80 ms after the J point. Exercise ECGs with up-sloping ST-segment depressions are typically reported as an ‘equivocal’ test. In general, the occurrence of horizontal or down-sloping ST-segment depression at a lower workload (calculated in METs) or heart rate indicates a worse prognosis and higher likelihood of multi-vessel disease. The duration of ST-segment depression is also important, as prolonged recovery after peak stress is consistent with a positive treadmill ECG stress test. Another finding that is highly indicative of significant CAD is the occurrence of ST-segment elevation > 1 mm (often suggesting transmural ischemia); these patients are frequently referred urgently for coronary angiography.\n\n- **slope**, the slope of the peak exercise ST segment, **Category**\n  - 1 = upsloping\n  - 2 = flat\n  - 3 = downsloping\n- **ca**, The number of major blood vessels(0-3) supplying blood to heart blocked, **Float**\n- **thal**, thalium heart scan, **Category**\n  - 3 = normal (no cold spots)\n  - 6 = fixed defect (cold spots during rest and exercise)\n  - 7 = reversible defect (when cold spots only appear during exercise)\n- (target) (predicted attribute): diagnosis of heart disease (angiographic disease status) — Value 0: < 50% diameter narrowing — Value 1: > 50% diameter narrowing"},{"metadata":{},"cell_type":"markdown","source":"### Table of Contents\n1) Import Packages\n\n2) EDA\n\n3) Preparing ML models\n\n4) Models evaluation\n - SVM\n - Naive Bayes\n - Logistic Regression\n - Decision Tree\n - Random Forest\n - LightGBM\n - XGboost\n\n5) Ensembling\n\n6) Conclusion"},{"metadata":{},"cell_type":"markdown","source":"<h1 style=color:blue align=\"left\"> 1. Load Required Libraries </h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd                                  # pandas is used to load and manipulate data and for One-Hot Encoding\nimport numpy as np                                   # numpy is used to calculate the mean and standard deviation\n\nimport matplotlib.pyplot as plt                      # matplotlib is for drawing graphs\n%matplotlib inline\nimport matplotlib.colors as colors\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\n\nplt.style.use(\"fivethirtyeight\")\nsns.set_style(\"darkgrid\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split                # split  data into training and testing sets\n\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC                                         # this will make a support vector machine for classificaiton\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nimport lightgbm as lgb\n\nfrom sklearn.model_selection import GridSearchCV                    # this will do cross validation\nfrom sklearn.preprocessing import scale                             # scale and center data\n\nfrom sklearn.metrics import confusion_matrix, classification_report # this creates a confusion matrix\nfrom sklearn.decomposition import PCA                               # to perform PCA to plot the data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 style=color:blue align=\"blue\"> 2. Read the data </h1>"},{"metadata":{},"cell_type":"markdown","source":"### EDA by PANDAS PROFILING"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/heart-disease-uci/heart.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas_profiling as pp\npp.ProfileReport(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(df.head())\ndisplay(df.tail())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Rows             :\", df.shape[0])\nprint(\"\\nColumn         :\", df.shape[1])\nprint(\"\\nFeatures       :\", df.columns.tolist())\nprint(\"\\nMissing Values :\", df.isnull().sum().sum())\nprint(\"Data types       :\", df.info())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 style=color:blue align=\"left\"> 3. EDA(Exploratory Data Analysis) </h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# missing values\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### a. age"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['age'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.tight_layout()\nsns.distplot(df['age'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### b. sex"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df['sex'].nunique())\nprint('\\n')\nprint(df['sex'].value_counts().to_frame())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- 0 = female\n\n- 1 = male"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='sex', data=df, palette='Set2')\n\n# Get current axis on current figure\nax = plt.gca()\n\n# ylim max value to be set\ny_max = df['sex'].value_counts().max() \nax.set_ylim([0, 220])\n\n# Iterate through the list of axes' patches\nfor p in ax.patches:\n    ax.text(p.get_x() + p.get_width()/2., p.get_height(), '%d' % int(p.get_height()), \n            fontsize=12, color='black', ha='center', va='bottom')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.tight_layout()\nsns.distplot(df['sex'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### c. cp(chest pain)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df['cp'].nunique())\nprint('\\n',df['cp'].value_counts().sort_index(ascending=True).to_frame())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- 1 = typical angina\n\n- 2 = atypical angina\n\n- 3 = non-anginal pain\n\n- 4 = asymptomatic"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='cp', data=df, palette='pastel')\n\n# Get current axis on current figure\nax = plt.gca()\n\n# ylim max value to be set\ny_max = df['cp'].value_counts().max() \nax.set_ylim([0, 150])\n\n# Iterate through the list of axes' patches\nfor p in ax.patches:\n    ax.text(p.get_x() + p.get_width()/2., p.get_height(), '%d' % int(p.get_height()), \n            fontsize=12, color='black', ha='center', va='bottom')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.tight_layout()\nsns.distplot(df['cp'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### d. fbs(fasting blood sugar)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df['fbs'].nunique())\nprint('\\n', df['fbs'].value_counts().to_frame())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- 0 = >=120 mg/dl\n\n- 1 = <120 mg/dl"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='fbs', data=df, palette=\"viridis\")\n\n# Get current axis on current figure\nax = plt.gca()\n\n# ylim max value to be set\ny_max = df['fbs'].value_counts().max() \nax.set_ylim([0, 280])\n\n# Iterate through the list of axes' patches\nfor p in ax.patches:\n    ax.text(p.get_x() + p.get_width()/2., p.get_height(), '%d' % int(p.get_height()), \n            fontsize=12, color='black', ha='center', va='bottom')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.tight_layout()\nsns.distplot(df['fbs'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### e. restecg(resting blood pressure (in mm Hg))"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df['restecg'].nunique())\nprint('\\n', df['restecg'].value_counts().sort_index(ascending=True).to_frame())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- 1 = normal\n\n- 2 = having ST-T wave abnormality\n\n- 3 = showing probable or definite left ventricular hypertrophy"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='restecg', data=df, palette='viridis')\n\n# Get current axis on current figure\nax = plt.gca()\n\n# ylim max value to be set\ny_max = df['restecg'].value_counts().max() \nax.set_ylim([0, 170])\n\n# Iterate through the list of axes' patches\nfor p in ax.patches:\n    ax.text(p.get_x() + p.get_width()/2., p.get_height(), '%d' % int(p.get_height()), \n            fontsize=12, color='black', ha='center', va='bottom')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.tight_layout()\nsns.distplot(df['restecg'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### f. exang(exercise induced angina)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df['exang'].nunique())\nprint('\\n', df['exang'].value_counts().to_frame())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- 0 = no\n\n- 1 = yes"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='exang', data=df, palette='viridis')\n\n# Get current axis on current figure\nax = plt.gca()\n\n# ylim max value to be set\ny_max = df['exang'].value_counts().max() \nax.set_ylim([0, 300])\n\n# Iterate through the list of axes' patches\nfor p in ax.patches:\n    ax.text(p.get_x() + p.get_width()/2., p.get_height(), '%d' % int(p.get_height()), \n            fontsize=12, color='black', ha='center', va='bottom')\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.tight_layout()\nsns.distplot(df['exang'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### g. slope(the slope of the peak exercise ST segment)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df['slope'].nunique())\nprint('\\n', df['slope'].value_counts().sort_index(ascending=True).to_frame())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- 1 = upsloping\n\n- 2 = flat\n\n- 3 = downsloping"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='slope', data=df, palette='viridis')\n\n# Get current axis on current figure\nax = plt.gca()\n\n# ylim max value to be set\ny_max = df['slope'].value_counts().max() \nax.set_ylim([0, 150])\n\n# Iterate through the list of axes' patches\nfor p in ax.patches:\n    ax.text(p.get_x() + p.get_width()/2., p.get_height(), '%d' % int(p.get_height()), \n            fontsize=12, color='black', ha='center', va='bottom')\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.tight_layout()\nsns.distplot(df['slope'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### h. ca(The number of major blood vessels(0-3) supplying blood to heart blocked)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df['ca'].nunique())\nprint('\\n', df['ca'].value_counts().to_frame())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='ca', data=df, palette='viridis')\n\n# Get current axis on current figure\nax = plt.gca()\n\n# ylim max value to be set\ny_max = df['ca'].value_counts().max() \nax.set_ylim([0, 180])\n\n# Iterate through the list of axes' patches\nfor p in ax.patches:\n    ax.text(p.get_x() + p.get_width()/2., p.get_height(), '%d' % int(p.get_height()), \n            fontsize=12, color='black', ha='center', va='bottom')\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.tight_layout()\nsns.distplot(df['ca'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### i. thal(thalium heart scan)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df['thal'].nunique())\nprint('\\n', df['thal'].value_counts().sort_index(ascending=True).to_frame())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- 3 = normal (no cold spots)\n\n- 6 = fixed defect (cold spots during rest and exercise)\n\n- 7 = reversible defect (when cold spots only appear during exercise)"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='thal', data=df, palette='viridis')\n\n# Get current axis on current figure\nax = plt.gca()\n\n# ylim max value to be set\ny_max = df['thal'].value_counts().max() \nax.set_ylim([0, 180])\n\n# Iterate through the list of axes' patches\nfor p in ax.patches:\n    ax.text(p.get_x() + p.get_width()/2., p.get_height(), '%d' % int(p.get_height()), \n            fontsize=12, color='black', ha='center', va='bottom')\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.tight_layout()\nsns.distplot(df['thal'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### j. target"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df['target'].nunique())\nprint('\\n', df['target'].value_counts().to_frame())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Value 0: < 50% diameter narrowing\n\n- Value 1: > 50% diameter narrowing"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='target', data=df, palette='viridis')\n\n# Get current axis on current figure\nax = plt.gca()\n\n# ylim max value to be set\ny_max = df['target'].value_counts().max() \nax.set_ylim([0, 180])\n\n# Iterate through the list of axes' patches\nfor p in ax.patches:\n    ax.text(p.get_x() + p.get_width()/2., p.get_height(), '%d' % int(p.get_height()), \n            fontsize=12, color='black', ha='center', va='bottom')\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.tight_layout()\nsns.distplot(df['target'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of people has Heart-attack according gender & age\ndf_Gender_Age = df.groupby(['sex','age'])['target'].count().reset_index().sort_values(by='target',ascending=False)\ndf_Gender_Age.head(10).style.background_gradient(cmap='coolwarm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of people has heart-attack according to chest-pain & Gender\ndf_pain_gender = df.groupby(['sex','cp'])['target'].count().reset_index().sort_values(by='target',ascending=False)\ndf_pain_gender.head(10).style.background_gradient(cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of people have heart-attack according Gender & Resting_blood_pressure\ndf_Sex_Restbp = df.groupby(['sex','trestbps'])['target'].count().reset_index().sort_values(by='target',ascending=False)\ndf_Sex_Restbp.head(10).style.background_gradient(cmap='coolwarm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of people have Heart-attack according Cholesterol & Gender\ndf_Sex_Chole = df.groupby(['sex','chol'])['target'].count().reset_index().sort_values(by='target',ascending=False)\ndf_Sex_Chole.head(10).style.background_gradient(cmap='OrRd')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of people has Heart-attack according Fasting_blood_sugar and Gender\ndf_Sex_fbs = df.groupby(['sex','fbs'])['target'].count().reset_index().sort_values(by='target',ascending=False)\ndf_Sex_fbs.style.background_gradient(cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of people has Heart-attack according to ECG_results and Gender\ndf_Sex_ECG = df.groupby(['sex','restecg'])['target'].count().reset_index().sort_values(by='target',ascending=False)\ndf_Sex_ECG.style.background_gradient(cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number people has Heart-attack according to Maximum_heart_rate and Gender\ndf_Sex_Max = df.groupby(['sex','thalach'])['target'].count().reset_index().sort_values(by='target',ascending=False)\ndf_Sex_Max.head(10).style.background_gradient(cmap='summer')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of people has Heart_attack according to Exercise_induced_angina and Gender\ndf_Sex_Excer = df.groupby(['sex','exang'])['target'].count().reset_index().sort_values(by='target',ascending=False)\ndf_Sex_Excer.style.background_gradient(cmap='cool')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of people has Heart_attack according his ST_depression and Gender\ndf_Sex_depression = df.groupby(['sex','oldpeak'])['target'].count().reset_index().sort_values(by='target',ascending=False)\ndf_Sex_depression.head(10).style.background_gradient(cmap='Oranges')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of people has Heart_attack according to slope and Gender\ndf_Sex_Slope = df.groupby(['sex','slope'])['target'].count().reset_index().sort_values(by='target',ascending=False)\ndf_Sex_Slope.head(10).style.background_gradient(cmap='afmhot')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of people has Heart_attack according to Major_vessels and Gender\ndf_Sex_Vessels = df.groupby(['sex','ca'])['target'].count().reset_index().sort_values(by='target',ascending=False)\ndf_Sex_Vessels.head(10).style.background_gradient(cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of people has Heart_attack according to Thalassemia_types and Gender\ndf_Sex_thal = df.groupby(['sex','thal'])['target'].count().reset_index().sort_values(by='target',ascending=False)\ndf_Sex_thal.head(20).style.background_gradient(cmap='GnBu')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Correlation"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,10))\nsns.heatmap(df.corr(), annot=True, linewidth=0.2)\nplt.title(\"Correlation Matrix\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr()['target'].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = df.drop('target', axis=1)\na.corrwith(df.target).plot(kind='bar', grid=True, figsize=(12, 8), color=['salmon'])\n\nplt.title(\"Correlation with target\", size=22)\nplt.xticks(size=18)\nplt.yticks(size=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- **chol and fbs** are **very least** correlated with target"},{"metadata":{},"cell_type":"markdown","source":"<h2 style=color:green align=\"left\"> c. Find Outliers </h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,9))\nsns.boxplot(data=df)\n\nplt.title(\"Outliers\", fontsize=20, fontweight='bold')\n\nplt.xticks(fontsize=16)\nplt.yticks(fontsize=16)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style=color:green align=\"left\"> d. Skew and Kurtosis </h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.skew()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['chol'])\nSkew_chol = df['chol'].skew()\nplt.title(\"Skew:\"+str(Skew_chol))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['trestbps'])\nSkew_trestbps = df['trestbps'].skew()\nplt.title(\"Skew:\"+str(Skew_trestbps))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['fbs'])\nSkew_fbs = df['fbs'].skew()\nplt.title(\"Skew:\"+str(Skew_fbs))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['cp'])\nSkew_cp = df['cp'].skew()\nplt.title(\"Skew:\"+str(Skew_cp))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['oldpeak'])\nSkew_oldpeak = df['oldpeak'].skew()\nplt.title(\"Skew:\"+str(Skew_oldpeak))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop('target', axis=1).copy() # alternatively: X = df_no_missing.iloc[:,:-1].copy()\nX.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df['target'].copy()\ny.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X['cp'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.get_dummies(X, columns=['cp']).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_encoded = pd.get_dummies(X, columns=['cp',\n                                       'restecg',\n                                       'slope', \n                                       'thal'])\nX_encoded.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 style=color:blue align=\"left\"> 4. Model Building and Evaluation </h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\nX_train_scaled = scale(X_train)\nX_test_scaled = scale(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ML models\n- Here I take different machine learning algorithm and try to find algorithm which predict accurately.\n\n 1. Logistic Regression\n 2. Naive Bayes\n 3. Random Forest Classifier\n 4. Extreme Gradient Boost\n 5. K-Nearest Neighbour\n 6. Decision Tree\n 7. Support Vector Machine"},{"metadata":{},"cell_type":"markdown","source":"## 2. Naive Bayes"},{"metadata":{"trusted":true},"cell_type":"code","source":"GNB = GaussianNB()\nGNB.fit(X_train_scaled, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting the Test set results\ny_pred_GNB = GNB.predict(X_test_scaled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confusion Matrix\ncf_matrix = confusion_matrix(y_test, y_pred_GNB)\nprint('Confusion Matrix \\n', cf_matrix)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 7. SVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_svm = SVC(random_state=42)\nclf_svm.fit(X_train_scaled, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predicting X_test\npred_svm = clf_svm.predict(X_test_scaled)\npred_svm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Confusion Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confusion Matrix\ncf_matrix = confusion_matrix(y_test, pred_svm)\nprint('Confusion Matrix \\n', cf_matrix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.tight_layout()\nsns.heatmap(cf_matrix, cmap='coolwarm', annot=True, linewidth=1, fmt=\"d\", center=None, square=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Classification Report"},{"metadata":{"trusted":true},"cell_type":"code","source":"# classification Report\nprint(classification_report(y_test, pred_svm))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Optimize Parameters with Cross Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = [\n  {'C': [1, 10, 100, 1000], \n   'gamma': [0.001, 0.0001], \n   'kernel': ['rbf']},\n ]\n\noptimal_params = GridSearchCV(\n        SVC(), \n        param_grid,\n        cv=5,\n        verbose=0 # NOTE: If you want to see what Grid Search is doing, set verbose=2\n    )\n\noptimal_params.fit(X_train_scaled, y_train)\nprint(optimal_params.best_params_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Building, Evaluating, Drawing, and Interpreting the Final Support Vector Machine"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_svm = SVC(random_state=42, C=1, gamma=0.01)\nclf_svm.fit(X_train_scaled, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predicting X_test\npred_svm = clf_svm.predict(X_test_scaled)\npred_svm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Confusion Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confusion Matrix\ncf_matrix = confusion_matrix(y_test, pred_svm)\nprint('Confusion Matrix \\n', cf_matrix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.tight_layout()\nsns.heatmap(cf_matrix, cmap='coolwarm', annot=True, linewidth=1, fmt=\"d\", center=None, square=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Classification Report"},{"metadata":{"trusted":true},"cell_type":"code","source":"# classification Report\nprint(classification_report(y_test, pred_svm))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\npca = PCA() # By default, PCA() centers the data, but does not scale it.\nX_train_pca = pca.fit_transform(X_train_scaled)\n\nper_var = np.round(pca.explained_variance_ratio_* 100, decimals=1)\nlabels = ['PC' + str(x) for x in range(1, len(per_var)+1)]\n \nplt.bar(x=range(1,len(per_var)+1), height=per_var, tick_label=labels)\nplt.ylabel('Percentage of Explained Variance')\nplt.xlabel('Principal Component')\nplt.title('Scree Plot')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pc1 = X_train_pca[:, 0] \npc2 = X_train_pca[:, 1]\n\n## NOTE:\n# pc1 contains the x-axis coordinates of the data after PCA\n# pc2 contains the y-axis coordinates of the data after PCA\n\n## Now we fittthe SVM to the x and y-axis coordinates of the data after PCA dimension reduction...\nclf_svm.fit(np.column_stack((pc1, pc2)), y_train)\n\n# Now create a matrix of points that we can use to show the decision regions.\n# The matrix will be a little bit larger than the transformed PCA points so that we can plot all of the PCA points on it without them being on the edge\nx_min = pc1.min() - 1\nx_max = pc1.max() + 1\n\ny_min = pc2.min() - 1\ny_max = pc2.max() + 1\n\nxx, yy = np.meshgrid(np.arange(start=x_min, stop=x_max, step=0.1),\n                     np.arange(start=y_min, stop=y_max, step=0.1))\n\n# now we will classify every point in that matrix with the SVM. Points on one side of the classification boundary\n# will get 0, and points on the other side will get 1.\nZ = clf_svm.predict(np.column_stack((xx.ravel(), yy.ravel())))\n\n# Right now, Z is just a long array of lots of 0s and 1s, which reflect how each point in the mesh was classified.\n# We use reshape() so that each classification (0 or 1) corresponds to a specific point in the matrix.\nZ = Z.reshape(xx.shape)\n\nfig, ax = plt.subplots(figsize=(10,10))\n# now we will use contourf() to draw a filled contour plot using the matrix values and classifications. \n# The contours will be filled according to the predicted classifications (0s and 1s) in Z\nax.contourf(xx, yy, Z, alpha=0.1)\n\n# now create custom colors for the actual data points\ncmap = colors.ListedColormap(['#e41a1c', '#4daf4a'])\n\n# now darw the actual data points - these will be colored by their known (not predcited) classifications\n\n# NOTE: setting alpha=0.7 lets us see if we are covering up a point \nscatter = ax.scatter(pc1, pc2, c=y_train, \n               cmap=cmap, \n               s=100, \n               edgecolors='k', ## 'k' = black\n               alpha=0.7)\n\n# now create a legend\nlegend = ax.legend(scatter.legend_elements()[0], \n                   scatter.legend_elements()[1],\n                    loc=\"upper right\")\nlegend.get_texts()[0].set_text(\"No HD\")\nlegend.get_texts()[1].set_text(\"Yes HD\")\n\n# now add axis labels and titles\nax.set_ylabel('PC2')\nax.set_xlabel('PC1')\nax.set_title('Decison surface using the PCA transformed/projected features')\n\n# plt.savefig('svm.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- The pink side of the graph on the left is the area were all datapoints will be predicted to **not have heart disease.**\n\n- The yellow side of the graph on the right is the area where all datapoints will be predicted to **have heart disease.**\n\n- The the dots are datapoints in the training dataset and are color coded by their known classifications: **red** is for those that **did not have heart disease** and **green** is for those that **did have heart disease.**"},{"metadata":{},"cell_type":"markdown","source":"<h1 style=color:blue align=\"left\"> Deployment on Heroku </h1>"},{"metadata":{},"cell_type":"markdown","source":"1.Build and Train the model using SVM\nUsing SVM (Support Vector Machines) we build and train a model using human cell records, and classify cells to predict whether the samples are Effected or Not-Affected.\n\n2.Flask Creation\n - Heart-Disease-Prediction.ipynb — This contains code for the machine learning model to predict heart disease based on the class.\n \n - app.py — This contains Flask APIs that receives cells details through GUI or API calls, computes the predicted value based on our model and returns it\n\n - templates & static — This folders contains the HTML template and CSS styling to allow user to enter cells details and displays the predicted output.\n \n3.Backend creation using model.pkl file\nUse this pretrained model and connect it with our Flask application. Use this for prediction for model and to show the output\n\n4. Adding form to flask app\n\n5.Integrating web application with machine learning backend."},{"metadata":{},"cell_type":"markdown","source":"Try to click on below link & it will take you through new window:\n\n1. Enter all parameters\n2. Click on Submit button\n3. Output get it as affected by disease or not\n\nhttps://heartdeseaseprediction.herokuapp.com/"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}