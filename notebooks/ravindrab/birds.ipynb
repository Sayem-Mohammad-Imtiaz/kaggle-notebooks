{"cells":[{"metadata":{"id":"Tpzldj7NgzE8","outputId":"4fff3a62-d4f5-434b-814a-d746a1a63685","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport os\nimport shutil\nimport glob\nimport cv2\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.applications import *\nfrom tensorflow.keras.callbacks import *\nfrom tensorflow.keras.initializers import *\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.python.client import device_lib","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"id":"kWA7XmdQgzFB","trusted":true},"cell_type":"code","source":"PATH = \"/kaggle/input/100-bird-species/consolidated/\"","execution_count":null,"outputs":[]},{"metadata":{"id":"truuwXMWgzFD","outputId":"09d02add-eb9a-4083-89fb-36cd485adbb2","trusted":true},"cell_type":"code","source":"classes = os.listdir(PATH)\nlen(classes)","execution_count":null,"outputs":[]},{"metadata":{"id":"3GqMb2d8gzFF","outputId":"0ed35138-6189-4844-8012-b31360a4a3e5","trusted":true},"cell_type":"code","source":"classes","execution_count":null,"outputs":[]},{"metadata":{"id":"LEtDXKB6gzFH","trusted":true},"cell_type":"code","source":"images = []\nlabel = []\nfor bird in classes:\n    x = os.listdir(PATH+bird)\n    for i in x:\n#         print(Path+dish+\"/\"+i)\n#         img = cv2.imread(Path+dish+\"/\"+i, cv2.IMREAD_UNCHANGED)\n#         resized = cv2.resize(img, (224,224), interpolation = cv2.INTER_AREA)\n#         cv2.imwrite(Path+dish+\"/\"+i, resized)\n        images.append(bird+'_'+i)\n        label.append(bird)","execution_count":null,"outputs":[]},{"metadata":{"id":"VcQTCXvNgzFJ","outputId":"9c5fe7f7-69b0-45e8-caa1-0373563e8cc5","trusted":true},"cell_type":"code","source":"print(len(images),  len(label))","execution_count":null,"outputs":[]},{"metadata":{"id":"k3zYRjowgzFL","outputId":"af685af2-fd70-4fa2-f4ba-4c8cd39798b1","trusted":true},"cell_type":"code","source":"df_train = pd.DataFrame(list(zip(images, label)), columns=['Image', 'Bird'])\ndf_train.Bird.unique()","execution_count":null,"outputs":[]},{"metadata":{"id":"doWlX90UgzFN","outputId":"496f1a0a-7d70-4e8f-cd8b-282cb7e558d9","trusted":true},"cell_type":"code","source":"df_train.Bird.hist()","execution_count":null,"outputs":[]},{"metadata":{"id":"VeRQ7KCAgzFQ","outputId":"5da741c0-ce0d-4a82-d4f1-44a552345365","trusted":true},"cell_type":"code","source":"# Augment data\nbatch_size = 256\ntrain_input_shape = (224//2, 224//2, 3)\nn_classes = len(classes)\n\ntrain_datagen = ImageDataGenerator(validation_split=0.2,\n                                   rescale=1./255.,\n                                   rotation_range=15,\n                                   width_shift_range=0.1,\n                                   height_shift_range=0.1,\n#                                    shear_range=0.7,\n                                   zoom_range=0.5,\n                                   #horizontal_flip=True,\n                                   #vertical_flip=True,\n                                  )\n\ntrain_generator = train_datagen.flow_from_directory(directory=PATH,\n                                                    class_mode='categorical',\n                                                    target_size=train_input_shape[0:2],\n                                                    batch_size=batch_size,\n                                                    subset=\"training\",\n                                                    shuffle=True,\n                                                    classes=classes\n                                                   )\n\nvalid_generator = train_datagen.flow_from_directory(directory=PATH,\n                                                    class_mode='categorical',\n                                                    target_size=train_input_shape[0:2],\n                                                    batch_size=batch_size,\n                                                    subset=\"validation\",\n                                                    shuffle=True,\n                                                    classes=classes\n                                                   )\n\nSTEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\nSTEP_SIZE_VALID = valid_generator.n//valid_generator.batch_size\nprint(\"Total number of batches =\", STEP_SIZE_TRAIN, \"and\", STEP_SIZE_VALID)","execution_count":null,"outputs":[]},{"metadata":{"id":"gBveCu_ugzFR","outputId":"f3e5c866-3ee4-4863-e82b-72bee3cd2c60","trusted":true},"cell_type":"code","source":"base_model = ResNet50(weights='imagenet', include_top=False, input_shape=train_input_shape)\n\nfor layer in base_model.layers:\n    layer.trainable = True\n# Add layers at the end\nX = base_model.output\nX = Flatten()(X)\n\nX = Dense(512, kernel_initializer='he_uniform')(X)\nX = Dropout(0.5)(X)\nX = BatchNormalization()(X)\nX = Activation('relu')(X)\n\nX = Dense(16, kernel_initializer='he_uniform')(X)\nX = Dropout(0.5)(X)\nX = BatchNormalization()(X)\nX = Activation('relu')(X)\n\noutput = Dense(n_classes, activation='softmax')(X)\nmodel = Model(inputs=base_model.input, outputs=output)","execution_count":null,"outputs":[]},{"metadata":{"id":"R_yWZaNtgzFT","trusted":true},"cell_type":"code","source":"optimizer = Adam(lr=0.0001)\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizer, \n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"id":"41j4DwrPgzFV","trusted":true},"cell_type":"code","source":"n_epoch = 20\n\nearly_stop = EarlyStopping(monitor='val_loss', patience=20, verbose=1, \n                           mode='auto', restore_best_weights=True)\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, \n                              verbose=1, mode='auto')","execution_count":null,"outputs":[]},{"metadata":{"id":"DyciCsBIgzFW","outputId":"cbf71c8f-1669-430f-c4d3-7741e5fec6db","trusted":true},"cell_type":"code","source":"# Train the model - all layers\nhistory1 = model.fit_generator(generator=train_generator, steps_per_epoch=STEP_SIZE_TRAIN,\n                              validation_data=valid_generator, validation_steps=STEP_SIZE_VALID,\n                              epochs=n_epoch,\n                              shuffle=True,\n                              verbose=1,\n                              callbacks=[reduce_lr],\n                              use_multiprocessing=True,\n                              workers=8\n                             )\n# Freeze core ResNet layers and train again \nfor layer in model.layers[-6:]:\n   layer.trainable = False\n\nfor layer in model.layers:\n    layer.trainable = True\n\noptimizer = Adam(lr=0.0001)\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizer, \n              metrics=['accuracy'])\n\nn_epoch = 20\nhistory2 = model.fit_generator(generator=train_generator, steps_per_epoch=STEP_SIZE_TRAIN,\n                              validation_data=valid_generator, validation_steps=STEP_SIZE_VALID,\n                              epochs=n_epoch,\n                              shuffle=True,\n                              verbose=1,\n                              callbacks=[reduce_lr, early_stop],\n                              use_multiprocessing=True,\n                              workers=8                             \n                              )","execution_count":null,"outputs":[]},{"metadata":{"id":"WrRUGHBKgzFa","trusted":true},"cell_type":"code","source":"# Merge history1 and history2\nhistory = {}\nhistory['loss'] = history1.history['loss'] + history2.history['loss']\nhistory['acc'] = history1.history['accuracy'] + history2.history['accuracy']\nhistory['val_loss'] = history1.history['val_loss'] + history2.history['val_loss']\nhistory['val_acc'] = history1.history['val_accuracy'] + history2.history['val_accuracy']\nhistory['lr'] = history1.history['lr'] + history2.history['lr']","execution_count":null,"outputs":[]},{"metadata":{"id":"Y1nQ8QmCgzFb","trusted":true},"cell_type":"code","source":"# Plot the training graph\nimport matplotlib.pyplot as plt\ndef plot_training(history):\n    acc = history['acc']\n    val_acc = history['val_acc']\n    loss = history['loss']\n    val_loss = history['val_loss']\n    epochs = range(len(acc))\n\n    fig, axes = plt.subplots(1, 2, figsize=(15,5))\n    \n    axes[0].plot(epochs, acc, 'r-', label='Training Accuracy')\n    axes[0].plot(epochs, val_acc, 'b--', label='Validation Accuracy')\n    axes[0].set_title('Training and Validation Accuracy')\n    axes[0].legend(loc='best')\n\n    axes[1].plot(epochs, loss, 'r-', label='Training Loss')\n    axes[1].plot(epochs, val_loss, 'b--', label='Validation Loss')\n    axes[1].set_title('Training and Validation Loss')\n    axes[1].legend(loc='best')\n    \n    plt.show()\n    \nplot_training(history)","execution_count":null,"outputs":[]},{"metadata":{"id":"vL7n8ZmngzFd","trusted":true},"cell_type":"code","source":"score = model.evaluate_generator(valid_generator)\nprint(\"Prediction accuracy on CV data =\", score[1])","execution_count":null,"outputs":[]},{"metadata":{"id":"R2PicsqbgzFe","trusted":true},"cell_type":"code","source":"def showClassficationReport_Generator(model, valid_generator, STEP_SIZE_VALID):\n    # Loop on each generator batch and predict\n    y_pred, y_true = [], []\n    for i in range(STEP_SIZE_VALID):\n        (X,y) = next(valid_generator)\n        y_pred.append(model.predict(X))\n        y_true.append(y)\n    \n    # Create a flat list for y_true and y_pred\n    y_pred = [subresult for result in y_pred for subresult in result]\n    y_true = [subresult for result in y_true for subresult in result]\n    \n    # Update Truth vector based on argmax\n    y_true = np.argmax(y_true, axis=1)\n    y_true = np.asarray(y_true).ravel()\n    \n    # Update Prediction vector based on argmax\n    y_pred = np.argmax(y_pred, axis=1)\n    y_pred = np.asarray(y_pred).ravel()\n    \n    # Confusion Matrix\n    fig, ax = plt.subplots(figsize=(10,10))\n    conf_matrix = confusion_matrix(y_true, y_pred, labels=np.arange(n_classes))\n    conf_matrix = conf_matrix/np.sum(conf_matrix, axis=1)\n    sns.heatmap(conf_matrix, annot=True, fmt=\".2f\", square=True, cbar=False, \n                cmap=plt.cm.jet, xticklabels=tick_labels, yticklabels=tick_labels,\n                ax=ax)\n    ax.set_ylabel('Actual')\n    ax.set_xlabel('Predicted')\n    ax.set_title('Confusion Matrix')\n    plt.show()\n    \n    print('Classification Report:')\n    print(classification_report(y_true, y_pred, labels=np.arange(n_classes), target_names=df.Cuisine.unique().tolist()))\n\nshowClassficationReport_Generator(model, valid_generator, STEP_SIZE_VALID)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}