{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Rain prediction in Australia\n\n**Task type:** Classification\n\n**ML algorithm used:** Random Forest Classifier\n\n**Metrics:** Accuracy, ROC-AUC\n\n**Other methods used:** GridSearchCV, precision/recall balancing","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://www.abc.net.au/cm/rimage/11665138-3x2-xlarge.jpg?v=3\" height=500 width=500>","metadata":{"papermill":{"duration":0.01761,"end_time":"2021-03-07T17:40:02.664561","exception":false,"start_time":"2021-03-07T17:40:02.646951","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns \nimport matplotlib.pyplot as plt\n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.execute_input":"2021-03-07T17:40:02.706996Z","iopub.status.busy":"2021-03-07T17:40:02.706348Z","iopub.status.idle":"2021-03-07T17:40:03.80499Z","shell.execute_reply":"2021-03-07T17:40:03.803905Z"},"papermill":{"duration":1.122917,"end_time":"2021-03-07T17:40:03.805165","exception":false,"start_time":"2021-03-07T17:40:02.682248","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns \n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.pipeline import Pipeline\n","metadata":{"execution":{"iopub.execute_input":"2021-03-07T17:40:03.845309Z","iopub.status.busy":"2021-03-07T17:40:03.844735Z","iopub.status.idle":"2021-03-07T17:40:03.849248Z","shell.execute_reply":"2021-03-07T17:40:03.848688Z"},"papermill":{"duration":0.027378,"end_time":"2021-03-07T17:40:03.849361","exception":false,"start_time":"2021-03-07T17:40:03.821983","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Load data","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/weather-dataset-rattle-package/weatherAUS.csv')","metadata":{"execution":{"iopub.execute_input":"2021-03-07T17:40:03.920142Z","iopub.status.busy":"2021-03-07T17:40:03.919572Z","iopub.status.idle":"2021-03-07T17:40:04.373536Z","shell.execute_reply":"2021-03-07T17:40:04.372483Z"},"papermill":{"duration":0.474541,"end_time":"2021-03-07T17:40:04.373678","exception":false,"start_time":"2021-03-07T17:40:03.899137","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.execute_input":"2021-03-07T17:40:04.427646Z","iopub.status.busy":"2021-03-07T17:40:04.425504Z","iopub.status.idle":"2021-03-07T17:40:04.533523Z","shell.execute_reply":"2021-03-07T17:40:04.533918Z"},"papermill":{"duration":0.143652,"end_time":"2021-03-07T17:40:04.534087","exception":false,"start_time":"2021-03-07T17:40:04.390435","status":"completed"},"scrolled":true,"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Let's see how many zero values are there for each column.**","metadata":{"papermill":{"duration":0.017159,"end_time":"2021-03-07T17:40:04.569433","exception":false,"start_time":"2021-03-07T17:40:04.552274","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# 2. Data preprocessing","metadata":{}},{"cell_type":"code","source":"zeros_cnt = df.isnull().sum().sort_values(ascending=False)\npercent_zeros = (df.isnull().sum() / df.isnull().count()).sort_values(ascending=False)\n\nmissing_data = pd.concat([zeros_cnt, percent_zeros], axis=1, keys=['Total', 'Percent'])\nmissing_data\n#missing_data.T","metadata":{"execution":{"iopub.execute_input":"2021-03-07T17:40:04.608839Z","iopub.status.busy":"2021-03-07T17:40:04.608019Z","iopub.status.idle":"2021-03-07T17:40:04.905996Z","shell.execute_reply":"2021-03-07T17:40:04.905255Z"},"papermill":{"duration":0.319698,"end_time":"2021-03-07T17:40:04.906119","exception":false,"start_time":"2021-03-07T17:40:04.586421","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Let's drop those features where the missing/total coefficient is higher than 15%.**","metadata":{"papermill":{"duration":0.017616,"end_time":"2021-03-07T17:40:04.941529","exception":false,"start_time":"2021-03-07T17:40:04.923913","status":"completed"},"tags":[]}},{"cell_type":"code","source":"dropList = list(missing_data[missing_data['Percent'] > 0.15].index)\ndropList\ndf.drop(dropList, axis=1, inplace=True)","metadata":{"execution":{"iopub.execute_input":"2021-03-07T17:40:04.982324Z","iopub.status.busy":"2021-03-07T17:40:04.981521Z","iopub.status.idle":"2021-03-07T17:40:04.994494Z","shell.execute_reply":"2021-03-07T17:40:04.994866Z"},"papermill":{"duration":0.035949,"end_time":"2021-03-07T17:40:04.995019","exception":false,"start_time":"2021-03-07T17:40:04.95907","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Location'].unique()","metadata":{"execution":{"iopub.execute_input":"2021-03-07T17:40:05.04251Z","iopub.status.busy":"2021-03-07T17:40:05.041812Z","iopub.status.idle":"2021-03-07T17:40:05.048975Z","shell.execute_reply":"2021-03-07T17:40:05.048541Z"},"papermill":{"duration":0.036363,"end_time":"2021-03-07T17:40:05.049079","exception":false,"start_time":"2021-03-07T17:40:05.012716","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df.head()\ndf.shape","metadata":{"execution":{"iopub.execute_input":"2021-03-07T17:40:05.088835Z","iopub.status.busy":"2021-03-07T17:40:05.088337Z","iopub.status.idle":"2021-03-07T17:40:05.093598Z","shell.execute_reply":"2021-03-07T17:40:05.093189Z"},"papermill":{"duration":0.026337,"end_time":"2021-03-07T17:40:05.093701","exception":false,"start_time":"2021-03-07T17:40:05.067364","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**A pairplot helps visualize dependencies and correlation between features. Some of them have quite obvious links.**","metadata":{}},{"cell_type":"code","source":"sns.pairplot(df[:1000])","metadata":{"execution":{"iopub.execute_input":"2021-03-07T17:40:05.141269Z","iopub.status.busy":"2021-03-07T17:40:05.139659Z","iopub.status.idle":"2021-03-07T17:40:29.128201Z","shell.execute_reply":"2021-03-07T17:40:29.128635Z"},"papermill":{"duration":24.016508,"end_time":"2021-03-07T17:40:29.128789","exception":false,"start_time":"2021-03-07T17:40:05.112281","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We can see some pretty straightforward correlations with almost linear-shaped distribution.**","metadata":{}},{"cell_type":"code","source":"df.head()\ndf.drop(['Date'], axis=1, inplace=True)\ndf.drop(['Location'], axis=1, inplace=True)","metadata":{"execution":{"iopub.execute_input":"2021-03-07T17:40:29.263349Z","iopub.status.busy":"2021-03-07T17:40:29.262474Z","iopub.status.idle":"2021-03-07T17:40:29.284145Z","shell.execute_reply":"2021-03-07T17:40:29.284691Z"},"papermill":{"duration":0.092727,"end_time":"2021-03-07T17:40:29.284841","exception":false,"start_time":"2021-03-07T17:40:29.192114","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.execute_input":"2021-03-07T17:40:29.74377Z","iopub.status.busy":"2021-03-07T17:40:29.743034Z","iopub.status.idle":"2021-03-07T17:40:29.851266Z","shell.execute_reply":"2021-03-07T17:40:29.852224Z"},"papermill":{"duration":0.226665,"end_time":"2021-03-07T17:40:29.852412","exception":false,"start_time":"2021-03-07T17:40:29.625747","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Let's encode categorical features using one-hot-encoding.**","metadata":{}},{"cell_type":"code","source":"ohe = pd.get_dummies(data=df, columns=['WindGustDir','WindDir9am','WindDir3pm'])\nohe.info()","metadata":{"execution":{"iopub.execute_input":"2021-03-07T17:40:30.080672Z","iopub.status.busy":"2021-03-07T17:40:30.080027Z","iopub.status.idle":"2021-03-07T17:40:30.494353Z","shell.execute_reply":"2021-03-07T17:40:30.493395Z"},"papermill":{"duration":0.525039,"end_time":"2021-03-07T17:40:30.494492","exception":false,"start_time":"2021-03-07T17:40:29.969453","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import preprocessing\nfrom numpy import array\n\nohe['RainToday'] = df['RainToday'].astype(str)\nohe['RainTomorrow'] = df['RainTomorrow'].astype(str)\n\nlb = preprocessing.LabelBinarizer()\n\nohe['RainToday'] = lb.fit_transform(ohe['RainToday'])\nohe['RainTomorrow'] = lb.fit_transform(ohe['RainTomorrow'])","metadata":{"execution":{"iopub.execute_input":"2021-03-07T17:40:30.70252Z","iopub.status.busy":"2021-03-07T17:40:30.665512Z","iopub.status.idle":"2021-03-07T17:40:32.251321Z","shell.execute_reply":"2021-03-07T17:40:32.250832Z"},"papermill":{"duration":1.691812,"end_time":"2021-03-07T17:40:32.251462","exception":false,"start_time":"2021-03-07T17:40:30.55965","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ohe = ohe.dropna()\n#ohe.drop('Location', axis=1, inplace=True)\ny = ohe['RainTomorrow']\nX = ohe.drop(['RainTomorrow'], axis=1)","metadata":{"execution":{"iopub.execute_input":"2021-03-07T17:40:32.387579Z","iopub.status.busy":"2021-03-07T17:40:32.386671Z","iopub.status.idle":"2021-03-07T17:40:32.426613Z","shell.execute_reply":"2021-03-07T17:40:32.426112Z"},"papermill":{"duration":0.109868,"end_time":"2021-03-07T17:40:32.426741","exception":false,"start_time":"2021-03-07T17:40:32.316873","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Model building","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)","metadata":{"execution":{"iopub.execute_input":"2021-03-07T17:40:32.565307Z","iopub.status.busy":"2021-03-07T17:40:32.562469Z","iopub.status.idle":"2021-03-07T17:40:32.590398Z","shell.execute_reply":"2021-03-07T17:40:32.589916Z"},"papermill":{"duration":0.098484,"end_time":"2021-03-07T17:40:32.590527","exception":false,"start_time":"2021-03-07T17:40:32.492043","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV","metadata":{"execution":{"iopub.execute_input":"2021-03-07T17:40:32.725996Z","iopub.status.busy":"2021-03-07T17:40:32.725322Z","iopub.status.idle":"2021-03-07T17:40:32.727709Z","shell.execute_reply":"2021-03-07T17:40:32.728229Z"},"papermill":{"duration":0.072661,"end_time":"2021-03-07T17:40:32.728355","exception":false,"start_time":"2021-03-07T17:40:32.655694","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.info()","metadata":{"execution":{"iopub.execute_input":"2021-03-07T17:40:32.865215Z","iopub.status.busy":"2021-03-07T17:40:32.864183Z","iopub.status.idle":"2021-03-07T17:40:32.889624Z","shell.execute_reply":"2021-03-07T17:40:32.889182Z"},"papermill":{"duration":0.096872,"end_time":"2021-03-07T17:40:32.889748","exception":false,"start_time":"2021-03-07T17:40:32.792876","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Please uncomment this part of code to use grid search for hyperparameter tuning for the model. The model below uses the outcome of the GridSearch operation with best parameters.**","metadata":{}},{"cell_type":"code","source":"#param_grid = { \n#    'n_estimators': [100, 200],\n#    'max_features': ['auto'],\n#    'max_depth' : [4,5,8,10],\n#    'criterion' :['gini', 'entropy']\n#}\n#RFC = RandomForestClassifier()\n\n#cv_RFC = GridSearchCV(estimator=RFC, param_grid=param_grid, cv=2)\n#cv_RFC.fit(X_train, y_train)","metadata":{"execution":{"iopub.execute_input":"2021-03-07T17:40:33.026322Z","iopub.status.busy":"2021-03-07T17:40:33.025646Z","iopub.status.idle":"2021-03-07T17:40:33.028573Z","shell.execute_reply":"2021-03-07T17:40:33.028136Z"},"papermill":{"duration":0.073287,"end_time":"2021-03-07T17:40:33.028678","exception":false,"start_time":"2021-03-07T17:40:32.955391","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#cv_RFC.best_params_\n#sorted(zip(cv_RFC.best_estimator_.feature_importances_,ohe.columns))","metadata":{"execution":{"iopub.execute_input":"2021-03-07T17:40:33.167069Z","iopub.status.busy":"2021-03-07T17:40:33.166494Z","iopub.status.idle":"2021-03-07T17:40:33.169608Z","shell.execute_reply":"2021-03-07T17:40:33.169189Z"},"papermill":{"duration":0.075697,"end_time":"2021-03-07T17:40:33.169718","exception":false,"start_time":"2021-03-07T17:40:33.094021","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipe = Pipeline([('scaler', StandardScaler()), ('RFC', RandomForestClassifier(criterion='gini', \n                                                                              max_depth=10, \n                                                                              max_features='auto',\n                                                                              n_estimators=200))])","metadata":{"execution":{"iopub.execute_input":"2021-03-07T17:40:33.310153Z","iopub.status.busy":"2021-03-07T17:40:33.309385Z","iopub.status.idle":"2021-03-07T17:40:33.312307Z","shell.execute_reply":"2021-03-07T17:40:33.311878Z"},"papermill":{"duration":0.075785,"end_time":"2021-03-07T17:40:33.312416","exception":false,"start_time":"2021-03-07T17:40:33.236631","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipe.fit(X_train, y_train)","metadata":{"execution":{"iopub.execute_input":"2021-03-07T17:40:33.45107Z","iopub.status.busy":"2021-03-07T17:40:33.449876Z","iopub.status.idle":"2021-03-07T17:40:46.526787Z","shell.execute_reply":"2021-03-07T17:40:46.527206Z"},"papermill":{"duration":13.14985,"end_time":"2021-03-07T17:40:46.527364","exception":false,"start_time":"2021-03-07T17:40:33.377514","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Model evaluation","metadata":{}},{"cell_type":"code","source":"pipe.score(X_train, y_train)","metadata":{"execution":{"iopub.execute_input":"2021-03-07T17:40:46.668129Z","iopub.status.busy":"2021-03-07T17:40:46.66693Z","iopub.status.idle":"2021-03-07T17:40:48.261305Z","shell.execute_reply":"2021-03-07T17:40:48.261751Z"},"papermill":{"duration":1.667626,"end_time":"2021-03-07T17:40:48.261904","exception":false,"start_time":"2021-03-07T17:40:46.594278","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Cross validation scores on the whole dataset:**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\ncross_val_score(pipe, X, y, cv=3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = pipe.predict(X_test)\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\n\n#confusion_matrix(y_test, y_pred)\naccuracy_score(y_test, y_pred)","metadata":{"execution":{"iopub.execute_input":"2021-03-07T17:40:48.405166Z","iopub.status.busy":"2021-03-07T17:40:48.404287Z","iopub.status.idle":"2021-03-07T17:40:49.09202Z","shell.execute_reply":"2021-03-07T17:40:49.091553Z"},"papermill":{"duration":0.762307,"end_time":"2021-03-07T17:40:49.092143","exception":false,"start_time":"2021-03-07T17:40:48.329836","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, f1_score\n\n#recall_score(y_test, y_pred)\n#precision_score(y_test, y_pred)\nf1_score(y_test, y_pred)","metadata":{"execution":{"iopub.execute_input":"2021-03-07T17:40:49.235812Z","iopub.status.busy":"2021-03-07T17:40:49.234943Z","iopub.status.idle":"2021-03-07T17:40:49.249664Z","shell.execute_reply":"2021-03-07T17:40:49.249265Z"},"papermill":{"duration":0.090173,"end_time":"2021-03-07T17:40:49.249774","exception":false,"start_time":"2021-03-07T17:40:49.159601","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Plotting precision-recall & ROC curves.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\n\nns_probs = [0 for _ in range(len(y_test))]\nlr_probs = pipe.predict_proba(X_test)\nlr_probs = lr_probs[:, 1]\n\nns_auc = roc_auc_score(y_test, ns_probs)\nlr_auc = roc_auc_score(y_test, lr_probs)\n\nprint('No Skill: ROC AUC=%.3f' % (ns_auc))\nprint('RFC: ROC AUC=%.3f' % (lr_auc))\n\n# calculate roc curves\nns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\nlr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n# plot the roc curve for the model\nplt.plot(ns_fpr, ns_tpr, linestyle='--', label='Dummy Classifer')\nplt.plot(lr_fpr, lr_tpr, marker='.', label='RFC')\n# axis labels\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\n# show the legend\nplt.legend()\n# show the plot\nplt.show()","metadata":{"execution":{"iopub.execute_input":"2021-03-07T17:40:49.396144Z","iopub.status.busy":"2021-03-07T17:40:49.395247Z","iopub.status.idle":"2021-03-07T17:40:50.272155Z","shell.execute_reply":"2021-03-07T17:40:50.272567Z"},"papermill":{"duration":0.955946,"end_time":"2021-03-07T17:40:50.272711","exception":false,"start_time":"2021-03-07T17:40:49.316765","status":"completed"},"scrolled":true,"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Let's plot a graph to identify the threshold influence on the scores**","metadata":{"papermill":{"duration":0.068029,"end_time":"2021-03-07T17:40:50.411417","exception":false,"start_time":"2021-03-07T17:40:50.343388","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_curve\ny_scores = pipe.predict_proba(X_train)[:,1]\n#y_scores\n\nprecisions, recalls, thresholds = precision_recall_curve(y_train, y_scores)\n\ndef plot_prc (precisions, recalls, thresholds):\n    plt.plot(thresholds, precisions[:-1], 'b--', label='Precision')\n    plt.plot(thresholds, recalls[:-1], 'g-', label='Recall')\n    plt.xlabel('Thresholds')\n    plt.legend(loc='center left')\n    plt.ylim([0,1])\n\nplot_prc(precisions, recalls, thresholds)","metadata":{"execution":{"iopub.execute_input":"2021-03-07T17:40:50.554948Z","iopub.status.busy":"2021-03-07T17:40:50.554445Z","iopub.status.idle":"2021-03-07T17:40:52.693372Z","shell.execute_reply":"2021-03-07T17:40:52.69292Z"},"papermill":{"duration":2.21443,"end_time":"2021-03-07T17:40:52.693518","exception":false,"start_time":"2021-03-07T17:40:50.479088","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#y_pred = clf.predict(X_test)  # default threshold is 0.5\ny_pred1 = (pipe.predict_proba(X_train)[:,1] >= 0.8).astype(int) # set threshold as 0.3\nprecision_score(y_train, y_pred1)","metadata":{"execution":{"iopub.execute_input":"2021-03-07T17:40:52.840945Z","iopub.status.busy":"2021-03-07T17:40:52.840415Z","iopub.status.idle":"2021-03-07T17:40:54.812389Z","shell.execute_reply":"2021-03-07T17:40:54.811815Z"},"papermill":{"duration":2.049033,"end_time":"2021-03-07T17:40:54.812523","exception":false,"start_time":"2021-03-07T17:40:52.76349","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Here we can clearly see the balance between precision & recall. \nSo if we want a higher recall, we can shift a threshold to a higher value.**\n\n**However, you should decide on the threshold with a thorough analysis not to miss-out on the model performance later.**","metadata":{"papermill":{"duration":0.072278,"end_time":"2021-03-07T17:40:54.958618","exception":false,"start_time":"2021-03-07T17:40:54.88634","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# 6. Conclusion","metadata":{}},{"cell_type":"markdown","source":"**So, we have build a quite simple Random Forest Classifier using the features from dataset applying one-hot-encoding to the categorical features.**\n\n**The accuracy-score for the out-of-the-box model is around 85% which is not bad. The AUC score is 0.862.**\n\n**We have also conducted an experiment with shifting the decision boundary for the model which resulted in a precision score spike. This is the technique you can use to manually set the threshold for the trained classifier.**","metadata":{}}]}