{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First, we will import several libraries. `scikit-learn` (**sklearn**) contains helpful statistical models, and we'll use the `matplotlib.pyplot` library for visualizations. Of course, we will use `numpy` and `pandas` for data manipulation throughout."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import r2_score\nfrom sklearn.decomposition import PCA # Principal Component Analysis module\nfrom sklearn.cluster import KMeans # KMeans clustering \nimport matplotlib.pyplot as plt # Python defacto plotting library\nimport seaborn as sns # More snazzy plotting library\n%matplotlib inline \n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/tmdb-movie-metadata/tmdb_5000_movies.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will define the regression and classification outcomes. Specifically, we will use the `revenue` column as the target for regression. For classification, we will construct an indicator of profitability for each movie."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['profitable'] = df.revenue > df.budget\ndf['profitable'] = df['profitable'].astype(int)\n\nregression_target = 'revenue'\nclassification_target = 'profitable'\n\ndf['profitable'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For simplicity, we will proceed by analyzing only the rows without any missing data. Now, we will remove rows with any infinite or missing values."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.replace([np.inf, -np.inf], np.nan)\ndf = df.dropna(how=\"any\")\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some variables in the dataset are already numeric and perhaps useful for regression and classification. In this exercise, we will store the names of these variables for future use. We will also take a look at some of the continuous variables and outcomes by plotting each pair in a scatter plot. Finally, we will evaluate the skew of each variable."},{"metadata":{"trusted":true},"cell_type":"code","source":"continuous_covariates = ['budget', 'popularity', 'runtime', 'vote_count', 'vote_average']\noutcomes_and_continuous_covariates = continuous_covariates + [regression_target, classification_target]\nplotting_variables = ['budget', 'popularity', regression_target]\n\naxes = pd.plotting.scatter_matrix(df[plotting_variables], alpha=0.15, \\\n       color=(0,0,0), hist_kwds={\"color\":(0,0,0)}, facecolor=(1,0,0))\nplt.show()\nprint(df[outcomes_and_continuous_covariates].skew())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It appears that the variables `budget`, `popularity`, `runtime`, `vote_count`, and `revenue` are all right-skewed. In this exercise, we will transform these variables to eliminate this skewness. Specifically, we will use the `np.log10()` method. Because some of these variable values are exactly 0, we will add a small positive value to each to ensure it is defined; this is necessary because log(0) is negative infinity."},{"metadata":{"trusted":true},"cell_type":"code","source":"for covariate in ['budget', 'popularity', 'runtime', 'vote_count', 'revenue']:\n    df[covariate] = df[covariate].apply(lambda x: np.log10(1+x))\nprint(df[outcomes_and_continuous_covariates].skew())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's now save our dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_csv(\"movies_clean.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\ndf = pd.read_csv('movies_clean.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this part, we will primarily use the two models we recently discussed: linear/logistic regression and random forests to perform prediction and classification. We will use these methods to predict revenue, and we will use logistic regression to classify whether a movie was profitable.\n\nNow, we will instantiate regression and classification models. Code is provided that prepares the covariates and outcomes we will use for data analysis."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define all covariates and outcomes from `df`.\nregression_target = 'revenue'\nclassification_target = 'profitable'\nall_covariates = ['budget', 'popularity', 'runtime', 'vote_count', 'vote_average']\n\nregression_outcome = df[regression_target]\nclassification_outcome = df[classification_target]\ncovariates = df[all_covariates]\n\n# Instantiate all regression models and classifiers.\nlinear_regression = LinearRegression()\nlogistic_regression = LogisticRegression()\nforest_regression = RandomForestRegressor(max_depth=4, random_state=0)\nforest_classifier = RandomForestClassifier(max_depth=4, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will now create two functions that compute a model's score. For regression models, we will use correlation as the score. For classification models, we will use accuracy as the score."},{"metadata":{"trusted":true},"cell_type":"code","source":"def correlation(estimator, X, y):\n    predictions = estimator.fit(X, y).predict(X)\n    return r2_score(y, predictions)\n    \ndef accuracy(estimator, X, y):\n    predictions = estimator.fit(X, y).predict(X)\n    return accuracy_score(y, predictions)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we will compute the cross-validated performance for the linear and random forest regression models."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nlinear_regression_scores = cross_val_score(linear_regression, covariates, regression_outcome, cv=10, scoring=correlation)\nforest_regression_scores = cross_val_score(forest_regression, covariates, regression_outcome, cv=10, scoring=correlation)\n\n# Plot Results\nplt.axes().set_aspect('equal', 'box')\nplt.scatter(linear_regression_scores, forest_regression_scores)\nplt.plot((0, 1), (0, 1), 'k-')\n\nplt.xlim(0, 1)\nplt.ylim(0, 1)\nplt.xlabel(\"Linear Regression Score\")\nplt.ylabel(\"Forest Regression Score\")\n\n# Show the plot.\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will compute cross-validated performance for the linear and random forest classification models."},{"metadata":{"trusted":true},"cell_type":"code","source":"logistic_regression_scores = cross_val_score(logistic_regression, covariates, classification_outcome, cv=10, scoring=accuracy)\nforest_classification_scores = cross_val_score(forest_classifier, covariates, classification_outcome, cv=10, scoring=accuracy)\n\n# Plot Results\nplt.axes().set_aspect('equal', 'box')\nplt.scatter(logistic_regression_scores, forest_classification_scores)\nplt.plot((0, 1), (0, 1), 'k-')\n\nplt.xlim(0, 1)\nplt.ylim(0, 1)\nplt.xlabel(\"Linear Classification Score\")\nplt.ylabel(\"Forest Classification Score\")\n\n# Show the plot.\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We saw that predicting revenue was only moderately successful. It might be the case that predicting movies that generated precisely no revenue is difficult. In the next three exercises, we will exclude these movies, and rerun the analyses to determine if the fits improve. In this exercise, we will rerun the regression analysis for this subsetted dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"positive_revenue_df = df[df[\"revenue\"] > 0]\n\nregression_outcome = positive_revenue_df[regression_target]\nclassification_outcome = positive_revenue_df[classification_target]\ncovariates = positive_revenue_df[all_covariates]\n\nlinear_regression = LinearRegression()\nlogistic_regression = LogisticRegression()\nforest_regression = RandomForestRegressor(max_depth=4, random_state=0)\nforest_classifier = RandomForestClassifier(max_depth=4, random_state=0)\nlinear_regression_scores = cross_val_score(linear_regression, covariates, regression_outcome, cv=10, scoring=correlation)\nforest_regression_scores = cross_val_score(forest_regression, covariates, regression_outcome, cv=10, scoring=correlation)\nlogistic_regression_scores = cross_val_score(logistic_regression, covariates, classification_outcome, cv=10, scoring=accuracy)\nforest_classification_scores = cross_val_score(forest_classifier, covariates, classification_outcome, cv=10, scoring=accuracy)\n\nnp.mean(forest_regression_scores)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will compute the cross-validated performance for the linear and random forest regression models for positive revenue movies only."},{"metadata":{"trusted":true},"cell_type":"code","source":"logistic_regression_scores = cross_val_score(logistic_regression, covariates, classification_outcome, cv=10, scoring=accuracy)\nforest_classification_scores = cross_val_score(forest_classifier, covariates, classification_outcome, cv=10, scoring=accuracy)\n\nplt.axes().set_aspect('equal', 'box')\nplt.scatter(logistic_regression_scores, forest_classification_scores)\nplt.plot((0, 1), (0, 1), 'k-')\nplt.xlim(0, 1)\nplt.ylim(0, 1)\nplt.xlabel(\"Linear Regression Score\")\nplt.ylabel(\"Forest Regression Score\")\n\nplt.show();\n\nforest_classifier.fit(positive_revenue_df[all_covariates], positive_revenue_df[classification_target])\nsorted(list(zip(all_covariates, forest_classifier.feature_importances_)), key=lambda tup: tup[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will compute cross-validated performance for the linear and random forest classification models for positive revenue movies only."},{"metadata":{"trusted":true},"cell_type":"code","source":"logistic_regression_scores = cross_val_score(logistic_regression, covariates, classification_outcome, cv=10, scoring=accuracy)\nforest_classification_scores = cross_val_score(forest_classifier, covariates, classification_outcome,cv=10, scoring=accuracy)\n\n# Plot Results\nplt.axes().set_aspect('equal', 'box')\nplt.scatter(logistic_regression_scores, forest_classification_scores)\nplt.plot((0, 1), (0, 1), 'k-')\n\nplt.xlim(0, 1)\nplt.ylim(0, 1)\nplt.xlabel(\"Linear Classification Score\")\nplt.ylabel(\"Forest Classification Score\")\n\n# Show the plot.\nplt.show()\n# Print the importance of each covariate in the random forest classification.\nforest_classifier.fit(positive_revenue_df[all_covariates], classification_outcome)\nfor row in zip(all_covariates, forest_classifier.feature_importances_,):\n        print(row)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"credits = pd.read_csv(\"../input/tmdb-movie-metadata/tmdb_5000_credits.csv\")\nmovies_df = pd.read_csv(\"../input/tmdb-movie-metadata/tmdb_5000_movies.csv\")\nprint(\"Credits: \",credits.shape)\nprint(\"Movies Dataframe: \",movies_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"credits_column_renamed = credits.rename(index=str,columns={\"movie_id\":\"id\"})\nmovies_df_merge = movies_df.merge(credits_column_renamed,on='id')\nmovies_cleaned_df = movies_df_merge.drop(columns=['homepage','title_x','title_y','status','production_countries'])\nmovies_cleaned_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using Weighted average for each movie's Average Rating"},{"metadata":{"trusted":true},"cell_type":"code","source":"# calculate all the components based on the above formula\nv = movies_cleaned_df['vote_count']\nR = movies_cleaned_df['vote_average']\nC = movies_cleaned_df['vote_average'].mean()\nm = movies_cleaned_df['vote_count'].quantile(0.70)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movies_cleaned_df['weighted_average']= ((R*v)+(C*m))/(v+m)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movie_sorted_ranking = movies_cleaned_df.sort_values('weighted_average',ascending=False)\nmovie_sorted_ranking[['original_title', 'vote_count', 'vote_average', 'weighted_average', 'popularity']].head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nweight_average=movie_sorted_ranking.sort_values('weighted_average',ascending=False)\nplt.figure(figsize=(12,6))\naxis1=sns.barplot(x=weight_average['weighted_average'].head(10), y=weight_average['original_title'].head(10), data=weight_average)\nplt.xlim(4, 10)\nplt.title('Best Movies by average votes', weight='bold')\nplt.xlabel('Weighted Average Score', weight='bold')\nplt.ylabel('Movie Title', weight='bold')\nplt.savefig('best_movies.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"popularity=movie_sorted_ranking.sort_values('popularity',ascending=False)\nplt.figure(figsize=(12,6))\nax=sns.barplot(x=popularity['popularity'].head(10), y=popularity['original_title'].head(10), data=popularity)\n\nplt.title('Most Popular by Votes', weight='bold')\nplt.xlabel('Score of Popularity', weight='bold')\nplt.ylabel('Movie Title', weight='bold')\nplt.savefig('best_popular_movies.png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Recommendation based on scaled weighted average and popularity score(Priority is given 50% to both)\n**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaling = MinMaxScaler()\nmovies_scaled_df = scaling.fit_transform(movies_cleaned_df[['weighted_average','popularity']])\nmovies_normalized = pd.DataFrame(movies_scaled_df,columns=['weighted_average','popularity'])\nmovies_normalized.head()\nmovies_cleaned_df[['normalized_weight_average','normalized_popularity']]= movies_normalized","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movies_cleaned_df['score'] = movies_cleaned_df['normalized_weight_average']*0.5+movies_cleaned_df['normalized_popularity']*0.5\nmovies_scored_df = movies_cleaned_df.sort_values(['score'],ascending=False)\nmovies_scored_df[['original_title', 'normalized_weight_average', 'normalized_popularity', 'score']].head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scored_df = movies_cleaned_df.sort_values('score', ascending=False)\n\nplt.figure(figsize=(16,6))\n\nax = sns.barplot(x=scored_df['score'].head(10), y=scored_df['original_title'].head(10), data=scored_df, palette='deep')\n\n#plt.xlim(3.55, 5.25)\nplt.title('Best Rated & Most Popular Blend', weight='bold')\nplt.xlabel('Score', weight='bold')\nplt.ylabel('Movie Title', weight='bold')\n\nplt.savefig('scored_movies.png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  R^2 method"},{"metadata":{"trusted":true},"cell_type":"code","source":"import io\nimport os\nimport matplotlib.pyplot as plt\nimport numpy as np \nimport pandas as pd \n\nimport json #converting JSON to lists for dataframe\nimport warnings\nwarnings.filterwarnings('ignore')\nimport base64\nimport codecs\nfrom IPython.display import HTML\n\n%matplotlib inline\nmovie1 = pd.read_csv(\"../input/tmdb-movie-metadata/tmdb_5000_movies.csv\")\nmovie2 = pd.read_csv(\"../input/tmdb-movie-metadata/tmdb_5000_credits.csv\")\n\nmovies = movie1.merge(movie2,left_on='id',right_on='movie_id',how='left')# merging the two csv files\ncounts = movies[(movies['vote_average']==0)]['vote_count'] # get vote counts for all movies that have a rating of 0.0\n\nprint(\"Unique vote counts for movies with 0.0 rating\")\nfor u in set(counts):\n    print(u)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movies = movies[(movies['vote_average']!=0)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def to_list(df, feature_names_list): #df: dataframe, feature_names: list of all features to convert from JSON to list\n    for feature_name in feature_names_list:\n        print(\"Current:\", feature_name)\n        #STEP 1: convert JSON format to a list\n        df[feature_name]=df[feature_name].apply(json.loads)\n        #Two cases here: Feature is crew, or feature is not crew\n        if feature_name == 'crew': #if crew, due to large size, want to limit to most influential members: director, editor, cinematographer, screenplay, and composer\n            for index,i in zip(df.index,df[feature_name]):\n                feature_list_1=[]\n                limit = 10\n                if len(i) < 10:\n                    limit = len(i)\n                for j in range(limit): #top 10 crew members\n                    feature_list_1.append((i[j]['name'])) # the key 'name' contains the name of the a sub-feature (ex: sci-fi in genres)\n                df.loc[index,feature_name]= str(feature_list_1)\n        \n        elif feature_name == 'cast': #Another special case. Only want top 5 cast members (most infulential)\n            for index,i in zip(df.index,df[feature_name]):\n                feature_list_1=[]\n                if len(i) > 5:\n                    limit = 5\n                else:\n                    limit = len(i)\n                for j in range(limit): #top 5 (JSON format already has this sorted)\n                    feature_list_1.append((i[j]['name']))\n                df.loc[index,feature_name]= str(feature_list_1)\n        else:    \n            for index,i in zip(df.index,df[feature_name]):\n                feature_list_1=[]\n                for j in range(len(i)):\n                    feature_list_1.append((i[j]['name']))\n                df.loc[index,feature_name]= str(feature_list_1)\n    \n        #STEP 2: clean up and transform into unsorted list\n        df[feature_name] = df[feature_name].str.strip('[]').str.replace(' ','').str.replace(\"'\",'')\n        df[feature_name] = df[feature_name].str.split(',')\n        \n        #STEP 3: Sort list elements\n        for i,j in zip(df[feature_name],df.index):\n            features_list_2=i\n            features_list_2.sort()\n            df.loc[j,feature_name]=str(features_list_2)\n        df[feature_name]=df[feature_name].str.strip('[]').str.replace(' ','').str.replace(\"'\",'')\n        lst = df[feature_name].str.split(',')\n        if len(lst) == 0:\n            df[feature_name] = None\n        else:\n            df[feature_name]= df[feature_name].str.split(',')\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movies = to_list(movies, ['genres', 'keywords', 'production_companies', 'cast', 'crew'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"to_drop = []\nfor i in movies.index:\n    if (movies['production_companies'][i] == [''] and movies['cast'][i] == [''] and \n        movies['crew'][i] == ['']):\n        to_drop.append(i)\nprint('Dropping', str(len(to_drop)), 'movies.')\nmovies = movies.drop(to_drop, axis = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movies_shortened = movies[['id','original_title','genres','cast', 'crew', 'production_companies', 'keywords', 'vote_average']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(12,10))\nn, bins, patches = plt.hist(movies_shortened['vote_average'], 30, density=1, facecolor='g', alpha=0.75)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_list(df, feature_name): #create a list of all unique feature values\n    #Step 1: track all ratings associated with each feature in a dictionary\n    feature_dict = {}\n    for index, row in df.iterrows():\n        feat = row[feature_name]\n        for sub_feat in feat:\n            if sub_feat not in feature_dict:\n                feature_dict[sub_feat] = (df['vote_average'][index], 1) #\n            else:\n                feature_dict[sub_feat] = (feature_dict[sub_feat][0] + (df['vote_average'][index]), feature_dict[sub_feat][1] + 1)\n    #Step 2: calculate average ratings for each feature\n    for key in feature_dict:\n        feature_dict[key] = feature_dict[key][0]/feature_dict[key][1] #average of all vote_averages\n       \n    #Step 3: create and sort a list of tuples (dictionary value, key)\n    lst = list()\n    for name in feature_dict:\n        lst.append((feature_dict[name],name))\n    lst = sorted(lst)\n    #step 4: create a list of only the feature names, from lowest rating to highest rating\n    feature_list = list()\n    ratings_list = list()\n    for element in lst:\n        feature_list.append(element[1])\n        ratings_list.append(element[0])\n    \n    #get the variance of the ratings. This is helpful for determining the usefulness of the information (to be displayed in below plot)\n    var = round(np.var(ratings_list),3)\n    \n    #before returning the list, do a quick visualization to show that generate_list works\n    fig, ax = plt.subplots(figsize=(6,5))\n    if feature_name != 'genres':\n        n = 50 # sample at intervals of n\n    else:\n        n = 1\n    X = [] #sample for associated movie(s) rating average\n    Y = [] #sample for feature names\n    for i in range(0, len(feature_list) - 1, n):\n        X.append(ratings_list[i])\n        Y.append(feature_list[i])\n    \n    y_pos = np.arange(len(Y))\n    ax.barh(y_pos, X, align='center')\n    #ax.set_yticklabels(Y)\n    ax.invert_yaxis()  # labels read top-to-bottom\n    \n    ax.set_xlabel('Overall average movie ratings')\n    ax.set_ylabel(feature_name + ' sample list index')\n    ax.set_title(feature_name + ' to associated movie(s) performance (' + str(int(len(feature_list)/n)) + ' samples), variance: ' + str(var))\n    \n    plt.show()\n    \n    return feature_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"genres_list = generate_list(movies_shortened, 'genres')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cast_list = generate_list(movies_shortened, 'cast')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"crew_list = generate_list(movies_shortened, 'crew')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prod_companies_list = generate_list(movies_shortened, 'production_companies')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"keywords_list = generate_list(movies_shortened, 'keywords')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movies_shortened = movies_shortened[['id', 'original_title', 'cast', 'crew', 'production_companies', 'keywords','vote_average']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_bin_array(this_list, all_features):\n    bin_list = []\n    for element in all_features:\n        if element in this_list:\n            bin_list.append(1)\n        else:\n            bin_list.append(0)\n    return bin_list\nmovies_shortened['cast'] = movies_shortened['cast'].apply(lambda x: calculate_bin_array(x, cast_list))\nmovies_shortened['crew'] = movies_shortened['crew'].apply(lambda x: calculate_bin_array(x, crew_list))\nmovies_shortened['production_companies'] = movies_shortened['production_companies'].apply(lambda x: calculate_bin_array(x, prod_companies_list))\nmovies_shortened['keywords'] = movies_shortened['keywords'].apply(lambda x: calculate_bin_array(x, keywords_list))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_bin(mov):\n    cast_bin = mov[2]\n    cast_index = []\n    # create arrays of indeces where bin number is one\n    for i in range(len(cast_bin)):\n        if cast_bin[i] == 1:\n            cast_index.append(i)\n    \n    crew_bin = mov[3]\n    crew_index = []\n    for i in range(len(crew_bin)):\n        if crew_bin[i] == 1:\n            crew_index.append(i)\n    \n    prod_bin = mov[4]\n    prod_index = []\n    for i in range(len(prod_bin)):\n        if prod_bin[i] == 1:\n            prod_index.append(i)\n    \n    keywords_bin = mov[5]\n    keywords_index = []\n    for i in range(len(keywords_bin)):\n        if keywords_bin[i] == 1:\n            keywords_index.append(i)\n    \n    font = {'family': 'serif',\n        'color':  'red',\n        'weight': 'normal',\n        'size': 10,\n        }\n    \n    fig, ax = plt.subplots(4,1,figsize=(5,1))\n    plt.subplots_adjust(hspace = 5)\n    ax[0].scatter(cast_index, np.zeros_like(cast_index), vmin=-2)\n    ax[0].set_title('Cast', loc = 'left', fontdict=font)\n    ax[0].set_xlim(0,len(cast_bin))\n    ax[0].set_yticks([])\n    ax[0].set_xticks([])\n    \n    ax[1].scatter(crew_index, np.zeros_like(crew_index), vmin=-2)\n    ax[1].set_title('Crew', loc = 'left', fontdict=font)\n    ax[1].set_xlim(0,len(crew_bin))\n    ax[1].set_yticks([])\n    ax[1].set_xticks([])\n    \n    ax[2].scatter(prod_index, np.zeros_like(prod_index), vmin=-2)\n    ax[2].set_title('Production companies', loc = 'left', fontdict=font)\n    ax[2].set_xlim(0,len(prod_bin))\n    ax[2].set_yticks([])\n    ax[2].set_xticks([])\n    \n    ax[3].scatter(keywords_index, np.zeros_like(keywords_index), vmin=-2)\n    ax[3].set_title('Keywords', loc = 'left', fontdict=font)\n    ax[3].set_xlim(0,len(keywords_bin))\n    ax[3].set_yticks([])\n    ax[3].set_xticks([])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movies_sample = movies_shortened.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_arr(arr, n_splits): \n      \n    # looping till length l \n    for i in range(0, len(arr), n_splits):  \n        yield arr[i:i + n_splits] \n\ndef find_concentration(arr, n = 100): # n is the number of concentration points to find\n    #seperate array into batches\n    batches = list(split_arr(arr,int(len(arr)/n)))\n    concentrations = []\n    for i in range(len(batches)):\n        point = 0\n        num_ones = 0\n        for j in range(len(batches[i])):\n            if batches[i][j] == 1:\n                point += j + (i * int(len(arr)/n)) # adding correction for batches\n                num_ones += 1\n        if num_ones > 0:\n            point = point/num_ones\n            concentrations.append((point,num_ones))\n    return concentrations","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def to_concentrations(df, feature_names):\n    for feature_name in feature_names:\n        print('feature: ', feature_name)\n        df[feature_name] = df[feature_name].apply(lambda x: find_concentration(x))\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movies_shortened = to_concentrations(movies_shortened, ['cast', 'crew', 'production_companies', 'keywords'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def w_avg(arr):\n    weight = 0 #weight\n    s = 0 # position*weight\n    for element in arr:\n        s += (element[0] * element[1])\n        weight += element[1]\n    return s/weight #weighted average","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def to_weighted_avg(df, feature_names):\n    for feature_name in feature_names:\n        print('Current: ', feature_name)\n        df[feature_name] = df[feature_name].apply(lambda x: w_avg(x))\n    return df\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movies_shortened = to_weighted_avg(movies_shortened, ['cast', 'crew', 'production_companies', 'keywords'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movies_shortened['vote_average'] = movies['vote_average']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feat_df = movies_shortened[['cast', 'crew', 'production_companies', 'keywords']]\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nfeat_scaled = pd.DataFrame(scaler.fit_transform(feat_df.astype(float)))\nfeat_scaled.index = feat_df.index\nfeat_scaled.columns = feat_df.columns\n\n#Seperate dataframe for target\ntarget_df = pd.DataFrame()\ntarget_df['ratings'] =  movies_shortened['vote_average']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(2,2, figsize=(24,20))\nax[0,0].scatter(target_df['ratings'], feat_scaled['cast'], facecolor='blue')\nax[0,0].set_xlabel('rating')\nax[0,0].set_ylabel('cast normalized')\nax[0,0].set_title('cast')\n\nax[1,0].scatter(target_df['ratings'], feat_scaled['crew'], facecolor='green')\nax[1,0].set_xlabel('rating')\nax[1,0].set_ylabel('crew normalized')\nax[1,0].set_title('crew')\n\nax[0,1].scatter(target_df['ratings'], feat_scaled['production_companies'], facecolor='red')\nax[0,1].set_xlabel('rating')\nax[0,1].set_ylabel('production companies normalized')\nax[0,1].set_title('Production Companies')\n\nax[1,1].scatter(target_df['ratings'], feat_scaled['keywords'], facecolor='orange')\nax[1,1].set_xlabel('rating')\nax[1,1].set_ylabel('keywords normalized')\nax[1,1].set_title('keywords')\n\nfig.suptitle(\"Corrlation between a movie's features and its rating\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ndef train_test_val_split(df_feat, df_target, train_frac):\n    train_features, test_features, train_target, test_target = train_test_split(df_feat, df_target, test_size = train_frac) #splitting training from rest of the dataset\n    return (train_features, train_target), (test_features, test_target)\n(features_train, target_train), (features_test, target_test) = train_test_val_split(feat_scaled, target_df,0.7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import BayesianRidge\nreg = BayesianRidge()\nreg.fit(features_train.values, target_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_pred = reg.predict(features_test.values)\nplt.axis([0,10,0,10])\nplt.scatter(target_test, target_pred)\n\nindex_arr = [n for n in range(11)]\nplt.plot(index_arr,'r--')             \nplt.xlabel(\"Movie Ratings\")\nplt.ylabel(\"Predicted Ratings\")\nplt.title(\"Movie ratings vs Predicted ratings\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import r2_score\n\nscore = r2_score(target_test, target_pred)\n\nprint(\"R^2 Score for predictions:\", score)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}