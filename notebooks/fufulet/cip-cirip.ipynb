{"cells":[{"metadata":{},"cell_type":"markdown","source":"#  <h1 > Birds classification</h1>"},{"metadata":{},"cell_type":"markdown","source":"# Imports"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nfrom IPython.display import Image, display\nimport random\nimport math\n\nimport tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.utils import plot_model \nfrom tensorflow.keras.layers import Input, Dense, Dropout, Flatten, Activation,Concatenate\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import backend, models","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# reading data"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nbatch_size=128\nwidth=100\ntrain_dir='../input/100-bird-species/train/';\ntest_dir='../input/100-bird-species/test/'\nvalid_dir='../input/100-bird-species/valid/';\n\ngenerator=ImageDataGenerator(rescale=1./255 )\ntrain_data=generator.flow_from_directory(train_dir, target_size=(width,width),batch_size=batch_size)\nvalid_data=generator.flow_from_directory(valid_dir, target_size=(width,width),batch_size=batch_size)\ntest_data=generator.flow_from_directory(test_dir, target_size=(width,width),batch_size=batch_size)\n\ntrain_steps_per_epoch=math.ceil(train_data.samples/batch_size)\nvalid_steps_per_epoch=math.ceil(valid_data.samples/batch_size)\ntest_steps_per_epoch=math.ceil(test_data.samples/batch_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(32, (3, 3), input_shape=(width, width, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Dropout(0.5))\n\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n\nmodel.add(Conv2D(256, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(250, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history=model.fit(train_data,\n                  steps_per_epoch =train_steps_per_epoch, \n                  validation_data=valid_data,\n                  epochs=23,\n                  validation_steps=valid_steps_per_epoch)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Let's the results**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot accuracy vs epoch\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot loss values vs epoch\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Evaluate against test data.\nscores = model.evaluate(test_data, verbose=1)\nprint('Test loss:', scores[0])\nprint('Test accuracy:', scores[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Thoughts"},{"metadata":{},"cell_type":"markdown","source":"<h2>Althought in the epoch=23 the accuracy=81.9% we can see that accuracy on validation data don't really went up so much since epoch 15.</h2>\n<h2> As a result, we could stopped the training were val_accuracy wasn't changing</h2>\n<h2> Since ~epoch 19 our model is overfitting, training accuracy high, validation accuracy dropping </h2>\n"},{"metadata":{},"cell_type":"markdown","source":"<h2> What we could do to avoid overfitting ? </h2>\n\n* use data augumentation\n* change the model, model smaller\n"},{"metadata":{},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}