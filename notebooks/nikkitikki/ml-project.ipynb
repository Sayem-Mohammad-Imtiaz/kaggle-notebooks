{"cells":[{"metadata":{},"cell_type":"markdown","source":"State all imports over here"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler, scale\nfrom sklearn.datasets import load_iris\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import KFold\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.feature_selection import RFE\nfrom sklearn.model_selection import validation_curve","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Importing the Dataset"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"client_info = pd.read_csv('../input/credit-card-approval-prediction/application_record.csv')\nclient_record = pd.read_csv('../input/credit-card-approval-prediction/credit_record.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data Pre-processing\n\n* Dropping Columns\n        1. OCCUPATION_TYPE: Lot of Missing Values\n        2. CNT_CHILDREN : Highly Correlated to CNT_FAMILY_MEMBERS\n        3. DAYS_BIRTH : Highly Correlated to DAYS_EMPLOYED\n        4. FLAG_MOBIL : 1 for every data point\n        5. FLAG_WORK_PHONE : Similar distribution to FLAG_PHONE\n        \n* Creating Dummies of Categorical Data\n    \n* Defining Response Variable, Dropping MONTHS_BALANCE\n    \n* Sampling the data set\n    \n* Normalising/ Scaling/ Standardising the data\n\n* DAYS_EMPLOYED > 0 -> Unemployed -> Assign same value to all data points"},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"Dropping Columns\"\"\"\nclient_info = client_info.drop(['OCCUPATION_TYPE', \"CNT_CHILDREN\", \"DAYS_BIRTH\", \"FLAG_MOBIL\", \"FLAG_WORK_PHONE\"], axis=1)\n\n\n\"\"\"Creating Dummies\"\"\"\nclient_info = pd.get_dummies(client_info, columns = [\"CODE_GENDER\", \"FLAG_OWN_CAR\", \"FLAG_OWN_REALTY\", \"NAME_EDUCATION_TYPE\", \"NAME_HOUSING_TYPE\", \"NAME_INCOME_TYPE\", \"NAME_FAMILY_STATUS\", \"NAME_HOUSING_TYPE\"], drop_first=True)\n\n\n\"\"\"Handling DAYS_EMPLOYED\"\"\"\nclient_info[\"DAYS_EMPLOYED\"] = np.where(client_info[\"DAYS_EMPLOYED\"] > 0, 1, client_info[\"DAYS_EMPLOYED\"])\n\n\n\"\"\"Defining Response Variable\"\"\"\nclient_record = client_record.drop([\"MONTHS_BALANCE\"], axis = 1)\nclient_record['STATUS'] = np.where((client_record['STATUS'] == 'X') | (client_record['STATUS'] == 'C'), -1, client_record['STATUS'])\nclient_record['STATUS'] = pd.to_numeric(client_record['STATUS'])\nclient_record = client_record.groupby([\"ID\"]).mean()\nclient_record[\"STATUS\"] = np.where(client_record['STATUS']>0, 1, 0)\n\n\n\"\"\"Merging the 2 datasets\"\"\"\ndata = client_record.merge(client_info, how='left', on='ID')\ndata = data.dropna()\ndata = data.reset_index()\ndata = data.drop(columns=['index'])\ndata = data.set_index('ID')\ndata = data.astype('float64')\nprint(data[\"STATUS\"].value_counts())\n\n\n\"\"\"Sampling the data\"\"\"\ndata = data.sample(frac = 1)\n\n\n\"\"\"Creating numpy arrays\n   Appending Normalised/Standardised Columns\"\"\"\n\ny = data.pop(\"STATUS\")\ny = y.to_numpy()\n\n\n\"\"\"Normalising/ Scaling/ Standardising\"\"\"\n\n# Normalise\nX = MinMaxScaler().fit_transform(data)\n\n\"\"\"# Scaling\nX = scale(data)\"\"\"\n\n\"\"\"\n# Standardise\n\"\"\"\n\n\"\"\"# Robust Scaling\nX = RobustScaler().fit_transform(data)\"\"\"\n\n\npca_em = PCA(n_components=20).fit_transform(X)\n#PCA_components = pd.DataFrame(pca_em)\n#plt.scatter(PCA_components[0], PCA_components[1], alpha=.1, color='blue')\n#plt.xlabel('PCA 1')\n#plt.ylabel('PCA 2')\nX = pca_em\n#tsne_em = TSNE(n_components=2).fit_transform(pca_em)\n#print(tsne_em)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Simple Logestic Regression function \n* inputs : numpy array \n* returns : predicted value"},{"metadata":{"trusted":true},"cell_type":"code","source":"def Mylogistic(X_train,X_test,y_train,y_test):\n    clf = LogisticRegression(max_iter=3000).fit(X_train, y_train)\n    return(clf.predict(X_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Implementing K folds\n* inputs : {X, y : numpy array, ratio:int}\n* returns :\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def split(X,y,ratio):\n    \n    kf = KFold(n_splits=ratio)\n    \n    \"\"\"rfe_selector = RFE(estimator=LogisticRegression(max_iter = 3000), n_features_to_select = 35, step=1)\n    rfe_selector.fit(X, y)\n    sec = rfe_selector.support_\n    X = X[:, sec]\"\"\"\n    \n    for train_index, test_index in kf.split(X):\n        \n        X_train, X_test = X[train_index], X[test_index]\n        y_train, y_test = y[train_index], y[test_index]\n        ypred = Mylogistic(X_train,X_test,y_train,y_test)\n        print(accuracy_score(y_test, ypred))\n        print(confusion_matrix(y_test, ypred))\n        \n    \n    train_scores, valid_scores = validation_curve(LogisticRegression(max_iter = 3000), X, y, scoring=\"accuracy\", cv=10)\n    plt.plot(train_scores)\n    plt.plot(valid_scores)\n    plt.show()\n    \n    return \n\nsplit(X, y, 10)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}