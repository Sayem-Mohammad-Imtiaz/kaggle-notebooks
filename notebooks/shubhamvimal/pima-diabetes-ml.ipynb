{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport itertools","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diab=pd.read_csv('/kaggle/input/pima-indians-diabetes-database/diabetes.csv')\ndiab.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diab.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='Outcome',data=diab)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import svm\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outcome = diab['Outcome']\ndata = diab[diab.columns[:8]]\ntrain,test = train_test_split(diab,test_size=0.25,random_state=0,stratify=diab['Outcome'])# stratify the outcome\nx_train = train[train.columns[:8]]\nx_test = test[test.columns[:8]]\ny_train = train['Outcome']\ny_test = test['Outcome']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = []\nclassifiers = ['Linear SVM','Radial SVM','Logistic Regression','KNN','Decision Tree']\nmodels = [svm.SVC(kernel='linear'),svm.SVC(kernel='rbf'),LogisticRegression(),KNeighborsClassifier(n_neighbors=3),DecisionTreeClassifier()]\nfor i in models:\n    model = i\n    model.fit(x_train,y_train)\n    prediction = model.predict(x_test)\n    accuracy.append(metrics.accuracy_score(prediction,y_test))\nmodels_dataframe = pd.DataFrame(accuracy,index=classifiers)   \nmodels_dataframe.columns = ['Accuracy']\nmodels_dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation Matrix\nax = sns.heatmap(diab[diab.columns[:8]].corr(),annot=True,cmap='inferno')\nax.set_ylim(8.0,0.0)\nfig=plt.gcf()\nfig.set_size_inches(10,8)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random Forest Classifier\nfrom sklearn.ensemble import RandomForestClassifier \nmodel= RandomForestClassifier(n_estimators=100,random_state=0)\nX=diab[diab.columns[:8]]\nY=diab['Outcome']\nmodel.fit(X,Y)\npd.Series(model.feature_importances_,index=X.columns).sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler #Standardisation\n\n# Taking Top 5 from above result\ndiab2 = diab[['Glucose','BMI','Age','DiabetesPedigreeFunction','Outcome']]\nfeatures = diab2[diab2.columns[:4]]\nfeatures_standard = StandardScaler().fit_transform(features)\n\nx=pd.DataFrame(features_standard,columns = [['Glucose','BMI','Age','DiabetesPedigreeFunction']])\nx['Outcome'] = diab2['Outcome']\n\ntrain1,test1=train_test_split(x,test_size=0.25,random_state=0,stratify=x.iloc[:,-1])\nx1_train = train1[train1.columns[:4]]\nx1_test = test1[test1.columns[:4]]\ny1_train = train1.iloc[:,-1]\ny1_test = test1.iloc[:,-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = []\nclassifiers = ['Linear SVM','Radial SVM','Logistic Regression','KNN','Decision Tree']\nmodels = [svm.SVC(kernel='linear'),svm.SVC(kernel='rbf'),LogisticRegression(),KNeighborsClassifier(n_neighbors=3),DecisionTreeClassifier()]\nfor i in models:\n    model = i\n    model.fit(x1_train,y1_train)\n    prediction = model.predict(x1_test)\n    accuracy.append(metrics.accuracy_score(prediction,y1_test))\nnew_models_dataframe = pd.DataFrame(accuracy,index=classifiers)   \nnew_models_dataframe.columns = ['New Accuracy']  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_models_dataframe=new_models_dataframe.merge(models_dataframe,left_index=True,right_index=True,how='left')\nnew_models_dataframe['Increase']=new_models_dataframe['New Accuracy']-new_models_dataframe['Accuracy']\nnew_models_dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold #for K-fold cross validation\nfrom sklearn.model_selection import cross_val_score #score evaluation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kfold = KFold(n_splits=10, random_state=22) # k=10, split the data into 10 equal parts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xyz = []\naccuracy1 = []\nclassifiers = ['Linear Svm','Radial Svm','Logistic Regression','KNN','Decision Tree']\nmodels = [svm.SVC(kernel='linear'),svm.SVC(kernel='rbf'),LogisticRegression(),KNeighborsClassifier(n_neighbors=3),DecisionTreeClassifier()]\nfor i in models:\n    model = i\n    cv_result = cross_val_score(model,x[x.columns[:4]],x.iloc[:,-1], cv = kfold,scoring = \"accuracy\")\n    cv_result = cv_result\n    xyz.append(cv_result.mean())\n    accuracy1.append(cv_result)\nnew_models_dataframe2 = pd.DataFrame(xyz,index=classifiers)   \nnew_models_dataframe2.columns = ['CV Mean']    \nnew_models_dataframe2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier #for Voting Classifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"linear_svc = svm.SVC(kernel='linear',C=0.1,gamma=10,probability=True)\nradial_svm = svm.SVC(kernel='rbf',C=0.1,gamma=10,probability=True)\nlr = LogisticRegression(C=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ensemble_lin_rbf = VotingClassifier(estimators=[('Linear_svm', linear_svc), ('Radial_svm', radial_svm)],voting='soft', weights=[2,1]).fit(x1_train,y1_train)\nprint('The accuracy for Linear and Radial SVM is:',ensemble_lin_rbf.score(x1_test,y1_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ensemble_lin_lr=VotingClassifier(estimators=[('Linear_svm', linear_svc), ('Logistic Regression', lr)], \n                       voting='soft', weights=[2,1]).fit(x1_train,y1_train)\nprint('The accuracy for Linear SVM and Logistic Regression is:',ensemble_lin_lr.score(x1_test,y1_test))\n\nensemble_rad_lr=VotingClassifier(estimators=[('Radial_svm', radial_svm), ('Logistic Regression', lr)], \n                       voting='soft', weights=[1,2]).fit(x1_train,y1_train)\nprint('The accuracy for Radial SVM and Logistic Regression is:',ensemble_rad_lr.score(x1_test,y1_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ensemble_rad_lr_lin=VotingClassifier(estimators=[('Radial_svm', radial_svm), ('Logistic Regression', lr),('Linear_svm',linear_svc)], \n                       voting='soft', weights=[2,1,3]).fit(x1_train,y1_train)\nprint('The ensembled model with all the 3 classifiers is:',ensemble_rad_lr_lin.score(x1_test,y1_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}