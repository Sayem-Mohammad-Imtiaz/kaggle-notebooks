{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom keras.utils import np_utils\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/mnist-in-csv/mnist_train.csv')\ntest = pd.read_csv('/kaggle/input/mnist-in-csv/mnist_test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.array(train.iloc[:,1:]) # (60000,784)\ny_train = np.array(train['label'])   # (60000,)\n\nX_test = np.array(test.iloc[:,1:]) # (10000,784)\ny_test = np.array(test['label']) # (10000,)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"digit_1 = X_train[0].reshape(28,28)\nplt.imshow(digit_1)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"digit_1 = X_train[25].reshape(28,28)\nplt.imshow(digit_1)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = np_utils.to_categorical(y_train,10)\ny_test = np_utils.to_categorical(y_test,10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_input   = 784 # input layer (28x28 pixels) \nn_hidden1 = 512 # 1st hidden layer\nn_hidden2 = 256 # 2nd hidden layer\nn_hidden3 = 128 # 3rd hidden layer\nn_output  = 10  # output layer (0-9)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learning_rate = 1e-4\nn_iterations = 1000\nbatch_size = 128\ndropout = 0.5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = tf.placeholder(\"float\", [None, n_input])\nY = tf.placeholder(\"float\", [None, n_output])\nkeep_prob = tf.placeholder(tf.float32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weights = {\n    'w1' : tf.Variable(tf.truncated_normal([n_input,n_hidden1], stddev=0.1)),\n    'w2' : tf.Variable(tf.truncated_normal([n_hidden1,n_hidden2], stddev=0.1)),\n    'w3' : tf.Variable(tf.truncated_normal([n_hidden2,n_hidden3], stddev=0.1)),\n    'out' : tf.Variable(tf.truncated_normal([n_hidden3,n_output], stddev=0.1)), \n}\n\nbiases = {\n    'b1' : tf.Variable(tf.constant(0.1, shape=[n_hidden1])),\n    'b2' : tf.Variable(tf.constant(0.1, shape=[n_hidden2])),\n    'b3' : tf.Variable(tf.constant(0.1, shape=[n_hidden3])),\n    'out' : tf.Variable(tf.constant(0.1, shape=[n_output])),\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"layer_1 = tf.add(tf.matmul(X, weights['w1']), biases['b1'])\nlayer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\nlayer_3 = tf.add(tf.matmul(layer_2, weights['w3']), biases['b3'])\nlayer_drop = tf.nn.dropout(layer_3, keep_prob)\noutput_layer = tf.matmul(layer_3, weights['out']) + biases['out']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=output_layer))\ntrain_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n\ncorrect_pred = tf.equal(tf.argmax(output_layer,1), tf.argmax(Y,1))\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"init = tf.global_variables_initializer()\nsess = tf.Session()\nsess.run(init)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(n_iterations):\n\n    sess.run(train_step, feed_dict={\n        X: X_train, Y: y_train, keep_prob: dropout\n    })\n    \n    #print loss and accuracy (per minibatch)\n    if i%100 == 0:\n        minibatch_loss, minibatch_accuracy = sess.run(\n            [cross_entropy, accuracy],\n            feed_dict={X: X_train, Y: y_train, keep_prob: 1.0}\n        )\n        print(\"Iteration\", str(i),\"\\t| Loss=\",str(minibatch_loss),\"\\t| Accuracy=\",str(minibatch_accuracy))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_accuracy = sess.run(accuracy, feed_dict={X: X_test, Y: y_test, keep_prob: 1.0})\nprint(\"\\nAccuracy on test set:\",test_accuracy)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}