{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"##########################################################\n# 1. IMPORT ALL PACKAGES\n##########################################################\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport math\nfrom collections import Counter\nimport seaborn as sns\nimport matplotlib.pyplot as plt #for plotting\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import multilabel_confusion_matrix\n# importing mean()\nfrom statistics import mean","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########################################################### 2. LOAD DATASET\n##########################################################\ndata = pd.read_csv(\"../input/breast-cancer-wisconsin-data/data.csv\",header=0)# header 0 means the first row is name of the coloumn\n# Delete unused columns\ndata.drop([\"Unnamed: 32\",\"id\"], axis=1, inplace=True)\n# Change label M(ganas = malignant) = 1 dan B(jinak = benign) = 0\ndata.diagnosis = [1 if each == \"M\" else 0 for each in data.diagnosis]\n# Test select malignant data\nm_data = data.loc[data['diagnosis'] == 1]\n# Test select benign data\nb_data = data.loc[data['diagnosis'] == 0]\n# View sample data\nb_data.head(1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Check all classes/labels in trainiing data\nall_label = set(data['diagnosis'].tolist())\nprint(\"All labels: {0}\".format(all_label))\n\n\n# Data distribution for each class\ndst_data = Counter(data['diagnosis'])\nprint(dst_data)\n# Plot distribution\nsns.countplot(data['diagnosis'])\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"##########################################################\n# 3. SHARE TO TEST AND TRAIN DATA\n##########################################################\nx = data.iloc[:, 1:]\ny = data['diagnosis'].tolist()\n# Share test and train data\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)\n\ndata.iloc[0:1, 1:].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 6. TRAIN RANDOM FOREST ALGORITHM\n##########################################################\n# Create a RandomForestClassifier object with the parameters over the data\n# n_estimators (default=100) = the number of trees in the forest.\n# max_depth (default=None) = the maximum depth of the tree.\nmodel_clf = RandomForestClassifier(n_estimators=500, max_depth=2, random_state=0)\n\n# Train the Random Forest algorithm\nmodel_clf.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# 6. APPLY THE TRAINED LEARNER TO TEST NEW DATA\n##########################################################\n# Apply the trained perceptron to make prediction of test data\ny_pred = model_clf.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##########################################################\n# 6. CONFUSION MATRIX\n##########################################################\n# Actual and predicted classes\nlst_actual_class = y_test\nlst_predicted_class = y_pred\n# label M(ganas = malignant) = 1 dan B(jinak = benign) = 0\nlst_classes = [0, 1]\n# Compute binary-class confusion matrix\ntn, fp, fn, tp = confusion_matrix(lst_actual_class, lst_predicted_class, labels=lst_classes).ravel()\nsensitivity = round(tp/(tp+fn), 3);\nspecificity = round(tn/(tn+fp), 3);\nprecision = round(tp/(tp+fp), 3);\naccuracy = round((tp+tn)/(tp+fp+tn+fn), 3);\nf1score = round((precision*sensitivity)/(precision+sensitivity), 3);\nbalanced_accuracy = round((sensitivity+specificity)/2, 3);\nmcc = round(((tp*tn)-(fp*fn))/(math.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))), 3);\nprint(\"TP={0}, FP={1}, TN={2}, FN={3}\".format(tp, fp, tn, fn));\nprint(\"Sensitivity: {0}\".format(sensitivity));\nprint(\"Specificity: {0}\".format(specificity));\nprint(\"Accuracy: {0}\".format(accuracy));\nprint(\"Balanced Accuracy: {0}\".format(balanced_accuracy));\nprint(\"MCC: {0}\".format(mcc));\nprint(\"Precision: {0}\".format(precision));\nprint(\"F1 score: {0}\".format(f1score));\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}