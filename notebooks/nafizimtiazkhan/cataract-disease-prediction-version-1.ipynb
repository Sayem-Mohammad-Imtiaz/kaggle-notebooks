{"cells":[{"metadata":{"papermill":{"duration":0.014161,"end_time":"2020-08-19T19:55:58.042598","exception":false,"start_time":"2020-08-19T19:55:58.028437","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Data pre-process"},{"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2020-08-19T19:55:58.082394Z","iopub.status.busy":"2020-08-19T19:55:58.081518Z","iopub.status.idle":"2020-08-19T19:55:59.269657Z","shell.execute_reply":"2020-08-19T19:55:59.26886Z"},"papermill":{"duration":1.21262,"end_time":"2020-08-19T19:55:59.269862","exception":false,"start_time":"2020-08-19T19:55:58.057242","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"!pip install --upgrade pip\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom tqdm import tqdm\nimport cv2 as cv\nfrom random import shuffle\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.utils import plot_model\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D\nimport tensorflow_addons as tfa\nimport tensorflow as tf\n%matplotlib inline \nimport numpy as np\nimport pandas as pd\nimport os\nimport glob\nimport matplotlib\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nfrom imblearn.over_sampling import SMOTE\nimport pandas as pd\nfrom sklearn import linear_model\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn import metrics\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import svm\nfrom sklearn import tree\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import AdaBoostClassifier\n!pip install catboost\nfrom catboost import CatBoostClassifier\nimport xgboost as xgb\nfrom sklearn.ensemble import GradientBoostingClassifier\n!pip install scikit-plot\nimport scikitplot as skplt\nfrom sklearn import svm\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import accuracy_score\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom itertools import cycle\nfrom sklearn import svm, datasets\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom scipy import interp\nfrom sklearn.metrics import roc_auc_score\n# Compute ROC curve and ROC area for each class\nevaluation = pd.DataFrame({'Model': [],\n                           'Accuracy(train)':[],\n                           'Precision(train)':[],\n                           'Recall(train)':[],\n                           'F1_score(train)':[],\n                           'Specificity(train)':[],\n                           'Accuracy(test)':[],\n                           'Precision(test)':[],\n                           'Recalll(test)':[],\n                           'F1_score(test)':[],\n                           'Specificity(test)':[],\n                          })\nIMG_SIZE = 224\nBATCH_SIZE = 32\nNO_EPOCHS = 50\nNUM_CLASSES = 2\nDATA_FOLDER = \"../input/ocular-disease-recognition-odir5k/ODIR-5K/ODIR-5K/Training Images\"\n#TEST_IMG=\"../input/ocular-disease-recognition-odir5k/ODIR-5K/ODIR-5K/Testing Images\"\ndata_df = pd.read_excel(open(\"../input/ocular-disease-recognition-odir5k/ODIR-5K/ODIR-5K/data.xlsx\", 'rb'), sheet_name='Sheet1')  \ndata_df.columns = [\"id\", 'age', \"sex\", \"left_fundus\", \"right_fundus\", \"left_diagnosys\", \"right_diagnosys\", \"normal\",\n                  \"diabetes\", \"glaucoma\", \"cataract\", \"amd\", \"hypertension\", \"myopia\", \"other\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df.shape","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.015044,"end_time":"2020-08-19T19:56:05.207439","exception":false,"start_time":"2020-08-19T19:56:05.192395","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Train images\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def has_cataract_mentioned(text):\n    if 'cataract' in text:\n        return 1\n    else:\n        return 0\nprint(data_df.loc[(data_df.cataract==1)].shape)\nprint(data_df.loc[data_df.cataract==0].shape)\nprint(data_df.loc[(data_df.cataract==1)]['left_diagnosys'].value_counts())\nprint(data_df.loc[(data_df.cataract==1)]['right_diagnosys'].value_counts())\nprint(data_df)\n\ndata_df['le_cataract'] = data_df['left_diagnosys'].apply(lambda x: has_cataract_mentioned(x))\ndata_df['re_cataract'] = data_df['right_diagnosys'].apply(lambda x: has_cataract_mentioned(x))\nprint(data_df['le_cataract'].value_counts())\nprint(data_df['re_cataract'].value_counts())\n\n\ncataract_le_list = data_df.loc[(data_df.cataract==1) & (data_df.le_cataract==1)]['left_fundus'].values\ncataract_re_list = data_df.loc[(data_df.cataract==1) & (data_df.re_cataract==1)]['right_fundus'].values\nprint(len(cataract_le_list), len(cataract_re_list))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"non_cataract_le_list = data_df.loc[(data_df.cataract==0) & (data_df.left_diagnosys==\"normal fundus\")]['left_fundus'].sample(150, random_state=314).values\nnon_cataract_re_list = data_df.loc[(data_df.cataract==0) & (data_df.right_diagnosys==\"normal fundus\")]['right_fundus'].sample(150, random_state=314).values\n#non_cataract_re_list = data_df.loc[(data_df.cataract==0) & (data_df.right_diagnosys==\"normal fundus\")]['right_fundus'].values\nprint(len(non_cataract_le_list), len(non_cataract_re_list))\nnon_cataract_re_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# non_cataract_le_list = data_df.loc[(data_df.cataract==0) & (data_df.left_diagnosys==\"normal fundus\")]['left_fundus'].values\n# non_cataract_re_list = data_df.loc[(data_df.cataract==0) & (data_df.right_diagnosys==\"normal fundus\")]['right_fundus'].values\n# print(len(non_cataract_le_list), len(non_cataract_re_list))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cataract_list = np.concatenate((cataract_le_list, cataract_re_list), axis = 0)\nnon_cataract_list = np.concatenate((non_cataract_le_list, non_cataract_re_list), axis = 0)\nprint(len(non_cataract_list), len(cataract_list))\nprint(len(os.listdir(DATA_FOLDER)))\n\ndef label_image(label):\n    if label == 1:\n        return 1\n    elif label == 0: \n        return 0\n\ndef process_data(data_image_list, DATA_FOLDER, is_cataract):\n    data_df = []\n    for img in tqdm(data_image_list):\n        path = os.path.join(DATA_FOLDER,img)\n        label = label_image(is_cataract)\n        img = cv.imread(path,cv.IMREAD_COLOR)\n        img = cv.resize(img, (IMG_SIZE,IMG_SIZE))\n        data_df.append([np.array(img),np.array(label)])\n    shuffle(data_df)\n    return data_df\ncat_df = process_data(cataract_list, DATA_FOLDER, 1)\nprint(cat_df)\ncat_no_df = process_data(non_cataract_list, DATA_FOLDER, 0)\nprint(cat_no_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_df[234]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_images(data, isTest=False):\n    f, ax = plt.subplots(5,5, figsize=(15,15))\n    for i,data in enumerate(data[:25]):\n        img_num = data[1]\n        img_data = data[0]\n        label = np.argmax(img_num)\n        if label  == 0: \n            str_label='Cataract'\n        elif label == 1: \n            str_label='No Cataract'\n        if(isTest):\n            str_label=\"None\"\n        ax[i//5, i%5].imshow(img_data)\n        ax[i//5, i%5].axis('off')\n        ax[i//5, i%5].set_title(\"Label: {}\".format(str_label))\n    plt.show()\n\n#show_images(cat_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = cat_df + cat_no_df\nshuffle(train)\n#show_images(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE,IMG_SIZE,3)\ny = np.array([i[1] for i in train])\ny","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p = X[0].flatten()\np\nq = pd.Series(p)\nq\ncols = np.arange(q.shape[0])\ndf = pd.DataFrame(columns = cols)\ndf\n\nx=0\nfor i in range(X.shape[0]):\n    df.loc[x] = X[i].flatten()\n    x = df.shape[0] + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['label']=0\ndf.shape\n#df.head(10)\n#print(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()\nX = df.loc[:, df.columns != 'label']\nprint(X.shape)\nprint(y.shape)\ny","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=43)\ny_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Before SMOTE')\nprint(X_train.shape)\nprint(y_train.shape)\nasome = pd.DataFrame(y_train)\n# print(asome.value_counts())\n\n\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.fit_transform(X_test)\n\nsm = SMOTE()\nX_train, y_train = sm.fit_resample(X_train, y_train)\n\n\nprint('After SMOTE')\nprint(X_train.shape)\nprint(y_train.shape)\nasome = pd.DataFrame(y_train)\nprint(asome.value_counts())\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape[1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf =svm.SVC(kernel='rbf',degree=10)\nclf.fit(X_train, y_train)\nacc_train=format(accuracy_score(clf.predict(X_train), y_train),'.3f')\nprecision_train=format(precision_score(y_train, clf.predict(X_train), average='binary'),'.3f')\nrecall_train=format(recall_score(y_train,clf.predict(X_train), average='binary'),'.3f')\nf1_train=format(f1_score(y_train,clf.predict(X_train), average='binary'),'.3f')\ntn, fp, fn, tp = confusion_matrix(clf.predict(X_train), y_train).ravel()\nspecificity = tn / (tn+fp)\nspecificity_train=format(specificity,'.3f')\n\nacc_test=format(accuracy_score(clf.predict(X_test), y_test),'.3f')\nprecision_test=format(precision_score(y_test, clf.predict(X_test), average='binary'),'.3f')\nrecall_test=format(recall_score(y_test,clf.predict(X_test), average='binary'),'.3f')\nf1_test=format(f1_score(y_test,clf.predict(X_test), average='binary'),'.3f')\ntn, fp, fn, tp = confusion_matrix(clf.predict(X_test), y_test).ravel()\nspecificity = tn / (tn+fp)\nspecificity_test=format(specificity,'.3f')\n\nr = evaluation.shape[0]\nevaluation.loc[r] = ['SVM',acc_train,precision_train,recall_train,f1_train,specificity_train,acc_test,precision_test,recall_test,f1_test,specificity_test]\nevaluation.sort_values(by = 'Accuracy(test)', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p=y_train\nq=y_test\n\ny_train = pd.DataFrame(y_train)\ny_train=y_train.replace([0,1], [\"Negative\",\"Positive\"])\n\npred_train=clf.predict(X_train)\npred_train=pd.DataFrame(pred_train)\npred_train=pred_train.replace([0,1], [\"Negative\",\"Positive\"])\n\n\npred_test=clf.predict(X_test)\ny_score = pred_test\ny_test = pd.DataFrame(y_test)\ny_test=y_test.replace([0,1], [\"Negative\",\"Positive\"])\npred_test=pd.DataFrame(pred_test)\n\npred_test=pred_test.replace([0,1], [\"Negative\",\"Positive\"])\n\nskplt.metrics.plot_confusion_matrix(\n    y_train, \n    pred_train,\n    figsize=(7,4),\n    title_fontsize='18',\n    text_fontsize='16',\n    title =' ',\n    cmap='BuGn'\n    )\n\nskplt.metrics.plot_confusion_matrix(\n    y_test, \n    pred_test,\n    figsize=(7,4),\n    title_fontsize='18',\n    text_fontsize='16',\n    title =' ',\n    cmap='BuGn'\n    )\ny_train=p\ny_test=q","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_classes = 2\nroc_y_test = [None] * len(y_test);    \nfor i in range(0, len(y_test)):    \n    roc_y_test[i] = y_test[i]; \n    \ny_score[50]=2\nroc_y_test[50]=2\ny_test\nfrom sklearn.preprocessing import label_binarize\ny_score = label_binarize(y_score, classes=[1, 0])\nroc_y_test = label_binarize(roc_y_test, classes=[1, 0])\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(roc_y_test[:, i], y_score[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n# Compute micro-average ROC curve and ROC area\nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(roc_y_test.ravel(), y_score.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\nlw = 2\nall_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n\nmean_tpr = np.zeros_like(all_fpr)\nfor i in range(n_classes):\n    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n\nmean_tpr /= n_classes\nfpr[\"macro\"] = all_fpr\ntpr[\"macro\"] = mean_tpr\nroc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\nplt.figure()\nplt.plot(fpr[\"micro\"], tpr[\"micro\"],\n         label='micro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"micro\"]),\n         color='deeppink', linestyle=':', linewidth=4)\n\nplt.plot(fpr[\"macro\"], tpr[\"macro\"],\n         label='macro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"macro\"]),\n         color='navy', linestyle=':', linewidth=4)\n\ncolors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(i, roc_auc[i]))\n\nplt.plot([0, 1], [0, 1], 'k--', lw=lw)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend(loc=\"lower right\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf =RandomForestClassifier(n_estimators=10, random_state=500)\nclf.fit(X_train, y_train)\nacc_train=format(accuracy_score(clf.predict(X_train), y_train),'.3f')\nprecision_train=format(precision_score(y_train, clf.predict(X_train), average='binary'),'.3f')\nrecall_train=format(recall_score(y_train,clf.predict(X_train), average='binary'),'.3f')\nf1_train=format(f1_score(y_train,clf.predict(X_train), average='binary'),'.3f')\ntn, fp, fn, tp = confusion_matrix(clf.predict(X_train), y_train).ravel()\nspecificity = tn / (tn+fp)\nspecificity_train=format(specificity,'.3f')\n\nacc_test=format(accuracy_score(clf.predict(X_test), y_test),'.3f')\nprecision_test=format(precision_score(y_test, clf.predict(X_test), average='binary'),'.3f')\nrecall_test=format(recall_score(y_test,clf.predict(X_test), average='binary'),'.3f')\nf1_test=format(f1_score(y_test,clf.predict(X_test), average='binary'),'.3f')\ntn, fp, fn, tp = confusion_matrix(clf.predict(X_test), y_test).ravel()\nspecificity = tn / (tn+fp)\nspecificity_test=format(specificity,'.3f')\n\nr = evaluation.shape[0]\nevaluation.loc[r] = ['Random Forest',acc_train,precision_train,recall_train,f1_train,specificity_train,acc_test,precision_test,recall_test,f1_test,specificity_test]\nevaluation.sort_values(by = 'Accuracy(test)', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p=y_train\nq=y_test\n\ny_train = pd.DataFrame(y_train)\ny_train=y_train.replace([0,1], [\"Negative\",\"Positive\"])\n\npred_train=clf.predict(X_train)\npred_train=pd.DataFrame(pred_train)\npred_train=pred_train.replace([0,1], [\"Negative\",\"Positive\"])\n\n\npred_test=clf.predict(X_test)\ny_score = pred_test\ny_test = pd.DataFrame(y_test)\ny_test=y_test.replace([0,1], [\"Negative\",\"Positive\"])\npred_test=pd.DataFrame(pred_test)\n\npred_test=pred_test.replace([0,1], [\"Negative\",\"Positive\"])\n\nskplt.metrics.plot_confusion_matrix(\n    y_train, \n    pred_train,\n    figsize=(7,4),\n    title_fontsize='18',\n    text_fontsize='16',\n    title =' ',\n    cmap='BuGn'\n    )\n\nskplt.metrics.plot_confusion_matrix(\n    y_test, \n    pred_test,\n    figsize=(7,4),\n    title_fontsize='18',\n    text_fontsize='16',\n    title =' ',\n    cmap='BuGn'\n    )\ny_train=p\ny_test=q","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_classes = 2\nroc_y_test = [None] * len(y_test);    \nfor i in range(0, len(y_test)):    \n    roc_y_test[i] = y_test[i]; \n    \ny_score[50]=2\nroc_y_test[50]=2\ny_test\nfrom sklearn.preprocessing import label_binarize\ny_score = label_binarize(y_score, classes=[1, 0])\nroc_y_test = label_binarize(roc_y_test, classes=[1, 0])\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(roc_y_test[:, i], y_score[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n# Compute micro-average ROC curve and ROC area\nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(roc_y_test.ravel(), y_score.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\nlw = 2\nall_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n\nmean_tpr = np.zeros_like(all_fpr)\nfor i in range(n_classes):\n    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n\nmean_tpr /= n_classes\nfpr[\"macro\"] = all_fpr\ntpr[\"macro\"] = mean_tpr\nroc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\nplt.figure()\nplt.plot(fpr[\"micro\"], tpr[\"micro\"],\n         label='micro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"micro\"]),\n         color='deeppink', linestyle=':', linewidth=4)\n\nplt.plot(fpr[\"macro\"], tpr[\"macro\"],\n         label='macro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"macro\"]),\n         color='navy', linestyle=':', linewidth=4)\n\ncolors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(i, roc_auc[i]))\n\nplt.plot([0, 1], [0, 1], 'k--', lw=lw)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend(loc=\"lower right\")\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}