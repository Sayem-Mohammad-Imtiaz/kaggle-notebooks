{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n#import data \ndata=pd.read_excel(\"games.xlsx\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#if the number of moves<10, it's drop in database\ndata=data.drop(data.loc[data['turns']<=10].index)\ndata=data.reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#missing data check\ndata.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Missing Values \n#IterativeImputer\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\ntestmissing = data.iloc[:9000,2:4]\ntrainmissing = data.iloc[9000:,2:4]\nimp = IterativeImputer(random_state=0)\nimp.fit(trainmissing)\ndata.iloc[:9000,2:4] = np.round(imp.transform(testmissing))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Label Encoder and OneHotEncoder\nfrom sklearn import preprocessing\nle = preprocessing.LabelEncoder()\n\n#rated\ndata.iloc[:,1] = le.fit_transform(data.iloc[:,1])\n\n#victory status\nohe = preprocessing.OneHotEncoder()\nvicstatus = data.iloc[:,4].to_numpy()\nvicstatus = vicstatus.reshape(-1,1)\nohe_vicstatus = ohe.fit_transform(vicstatus).toarray()\ndfvicstatus=pd.DataFrame(data=ohe_vicstatus,columns=[\"draw\",\"mate\",\"outoftime\",\"resign\"])\n\n#opening_eco\neco = data['opening_eco']\nfor i in range(len(eco)):  \n    eco[i]=eco[i].replace(\"A\",\"1\")\n    eco[i]=eco[i].replace(\"B\",\"2\")\n    eco[i]=eco[i].replace(\"C\",\"3\")\n    eco[i]=eco[i].replace(\"D\",\"4\")\n    eco[i]=eco[i].replace(\"E\",\"5\")\n\neco=pd.to_numeric(eco)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#attributes and label dataset\nX = pd.concat([data[\"rated\"],data[\"game_time\"],data[\"turns\"],dfvicstatus,data[\"black_rating\"],data[\"white_rating\"]],axis=1)\n\ny = data[\"winner\"]\ny = le.fit_transform(y) #Label Encoder applied to label set\nclasses =[\"black\",\"draw\",\"white\"] # label classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Standard Scaler\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_sc = sc.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#KFold uygulamasÄ±\nfrom sklearn.model_selection import cross_val_score,cross_val_predict\nfrom sklearn.metrics import confusion_matrix , ConfusionMatrixDisplay ,classification_report\n#function for comparing models\ndef output(est,X,color):\n   \n    for model in est:\n        accu = cross_val_score(estimator = model, X = X, y=y,cv=5)\n        y_pred = cross_val_predict(model,X,y,cv=5)\n        conf_matrix = confusion_matrix(y, y_pred)\n        disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix,display_labels=[\"black\",\"draw\",\"white\"])\n        disp.plot(cmap=color)\n        disp.ax_.set_title(model)\n        print(\"-------- \",model,\" report -------- \\n\")\n        print(classification_report(y,y_pred,target_names=classes))\n        print(\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import some models\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression(random_state=0)\n\nfrom sklearn.tree import DecisionTreeClassifier\nclf = DecisionTreeClassifier(random_state=0)\n\nfrom sklearn.naive_bayes import GaussianNB\ngnb = GaussianNB()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Some models applied to Grid Search CV\n\"\"\"Random Forest Grid_SearchCv \"\"\"\nfrom sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier()\n\nparameters = [{'n_estimators': [50,100,150,200], 'criterion':['gini',\"entropy\"]}]\ngrids = GridSearchCV(estimator = rfc, param_grid = parameters, scoring = 'accuracy', cv = 5, n_jobs = -1)\ngrids.fit(X_sc, y)\nbest_accuracy , best_parameter = grids.best_score_ , grids.best_params_\nprint('En iyi acc: ', best_accuracy)\nprint('En iyi acc veren parametreler: ', best_parameter,\"\\n\")\ngrid_rfc = RandomForestClassifier(n_estimators=150,criterion=\"entropy\")\n\n\n\"\"\"KNN Grid_SearchCv \"\"\"\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier()\n\nparameters = [{'n_neighbors': [3,5,7,9,11,13,15,17,19,21], 'weights':['uniform',\"distance\"],\"metric\" : [\"euclidean\",\"manhattan\",\"minkowski\"]}]\ngrids = GridSearchCV(estimator = knn, param_grid = parameters, scoring = 'accuracy', cv = 5, n_jobs = -1)\ngrids.fit(X_sc, y)\nbest_accuracy , best_parameter = grids.best_score_ , grids.best_params_\nprint('En iyi acc: ', best_accuracy)\nprint('En iyi acc veren parametreler: ', best_parameter,\"\\n\")\ngrid_knn = KNeighborsClassifier(n_neighbors=21,weights=\"distance\",metric=\"manhattan\")\n\n\n\"\"\"SVM Grid_SearchCv \"\"\"\nfrom sklearn.svm import SVC\nsvm = SVC()\n\nparameters = [{'C': [0.25, 0.5, 0.75, 1], 'kernel':['linear']}, {'C': [0.25, 0.5, 0.75, 1], 'kernel':['rbf'], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5]}]\ngrids = GridSearchCV(estimator = svm, param_grid = parameters, scoring = 'accuracy', cv = 5, n_jobs = -1)\ngrids.fit(X_sc, y)\nbest_accuracy , best_parameter = grids.best_score_ , grids.best_params_\nprint('En iyi acc: ', best_accuracy)\nprint('En iyi acc veren parametreler: ', best_parameter,\"\\n\")\ngrid_svm = SVC(C=0.75,kernel=\"linear\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#printing results\n#not parameters on models\nest = [logreg,clf,rfc,knn,svm,gnb]\noutput(est,X_sc,\"pink\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Three models applied to Grid Search CV \ngrid_est = [grid_rfc,grid_knn,grid_svm]\noutput(grid_est,X_sc,\"hot\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Linear Discriminant Analysis\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\nlda = LDA(n_components = 2)\nX_lda = lda.fit_transform(X_sc, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#LDA and Grid Search CV\ngrid_lda_est = [logreg,clf,grid_rfc,grid_knn,grid_svm,gnb]\noutput(grid_lda_est,X_lda,\"bone\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}