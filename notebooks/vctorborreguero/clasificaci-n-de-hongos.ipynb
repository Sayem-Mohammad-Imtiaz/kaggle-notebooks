{"cells":[{"metadata":{},"cell_type":"markdown","source":"# INTRODUCCIÓN","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Este set de datos nos propone determinar si un hongo es o no tóxico a partir de sus principales características. Para ello, nos serviremos en paralelo los algoritmos *Random Forest* y *BackPropagation*. El objetivo de este trabajo es comparar los resultados expuestos por cada método, así como sus respectivas prestaciones. Con este fin, intentaremos ajustar los hiperparámetros de cada uno de los algoritmos en busca de su mejor rendimiento.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# **PREPARACIÓN DE LOS DATOS**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"+ Extraemos el path del DataFrame (DF).","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Cargamos el DF","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/mushroom-classification/mushrooms.csv\")\n\nprint(\"Rows: \", df.shape[0])\nprint(\"Columns: \", df.shape[1],\"\\n\",\"\\n\" )\nprint(df.head())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Se muestran las dimensiones del conjunto, así como las primeras lineas del DF.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* Convertimos el conjunto de valores de cada atributo (strings) en valores numéricos.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\n\nle=preprocessing.LabelEncoder()\n\nfor column in df.columns:\n    df[column] = le.fit_transform(df[column])\n        \nprint(df.head())\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Se muestra las primeras lineas del DF después de dicha operación.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* Separamos las etiquetas de clase de las características de cada individuo dentro del DF:\n        X: conjunto de individuos sin etiquetar\n        Y: conjunto de etiquetas de clase","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df[['cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor',\n       'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color',\n       'stalk-shape', 'stalk-root', 'stalk-surface-above-ring',\n       'stalk-surface-below-ring', 'stalk-color-above-ring',\n       'stalk-color-below-ring', 'veil-type', 'veil-color', 'ring-number',\n       'ring-type', 'spore-print-color', 'population', 'habitat']]\nY = df[\"class\"]\n\nprint(\"conjunto de individuos sin etiquetar:\",\"\\n\",\"\\n\",X,\"\\n\",\"\\n\",\"\\n\",\"\\n\")\nprint(\"conjunto de etiquetas de clase:\",\"\\n\",\"\\n\",Y,\"\\n\")\n ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"+ Realizamos una partición del conjunto según las condiciones siguientes:\n         El tamaño de los conjuntos de prueba y entrenamiento equivale respectivamente a uno y dos tercios del tamaño del DF original. \n         Separamos los conjuntos de prueba/entranamiento de manera aleatoria y fijamos dicha repartición.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=1/3, random_state=0)\n\nprint(\"x_train:\",\"\\n\",\"\\n\",x_train,\"\\n\",\"\\n\",\"\\n\",\"\\n\")\nprint(\"x_test:\",\"\\n\",\"\\n\",x_test,\"\\n\",\"\\n\",\"\\n\",\"\\n\")\nprint(\"y_train:\",\"\\n\",\"\\n\",y_train,\"\\n\",\"\\n\",\"\\n\",\"\\n\")\nprint(\"y_test:\",\"\\n\",\"\\n\",y_test,\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"La salida nos indica que el tamaño de los conjuntos de prueba y entrenamiento es respectivamente de 2708 y 5416 individuos.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":" # **RANDOM FOREST**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"+ Ajustamos el aprendizaje con los siguientes hiperparámetros:\n        Número de árboles en el bosque: 10\n        Árboles calculados en cada itéración: 3610 ( = int(2/3 * X.shape[0]) )\n        \n        \n+ Entrenamos el clasificador con el conjunto previamente definido.\n\n+ Sometemos el conjunto de prueba al clasificador.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nclf_rf=RandomForestClassifier(n_estimators= 10,max_features = 'sqrt',max_samples = 2/3, random_state=0)\n\nclf_rf.fit(x_train, y_train)\n\ny_pred=clf_rf.predict(x_test)\n\nprint(\"y_pred:\",\"\\n\",\"\\n\",y_test,\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Se muestran las primeras lineas dela estimación de *Random Forest* sobre el conjunto de prueba.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"+ Exhibimos la matriz de confusión y los principales estimadores.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\n\nprint(\"Matriz de confusión:\",\"\\n \",\"\\n \",confusion_matrix(y_test,y_pred),\"\\n \",\"\\n \",\"\\n \",\"\\n \")\n\nprint(\"Rendimiento\",\":\\n\", classification_report(y_test,y_pred), \"\\n \" )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Obtenemos estos resultados para un caso particular, en el que fijamos la repartición de conjuntos de prueba/entrenamiento y los árboles obtenidos por aprendizaje. Lo cierto es que cuando cuando corremos el código varias veces dejando variar estos dos parámetros, nos damos cuenta de que los tres indicadores (precisión, recall y f1) son iguales o muy próximos a 1 en la mayoría de los casos, hasta con bosques de un solo un árbol. A pesar de ello, decidimos priorizar la matriz de confusión a estos tres indicadores para configurar un bosque de 10 árboles. Y es que, al tratarse de un asunto sanitario y no un problema de optimización productiva, como sucede en otros casos, estimamos que el objetivo del algoritmo es el de minimizar el número de casos en los que un hongo venenoso se presenta como comestible. Con 10 árboles, la probabilidad de este caso es ínfima. Por último, dados que los resultados son satisfactorios con un bosque pequeño, el tiempo de ejecución del algoritmo es bastante corto. Rechazamos así la posibilidad de realizar podas, dejando de lado hyperparámetros como *max_depth*, *min_impurity_split* o *min_samples_split*.\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# BACKPROPAGATION","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"La capa de entrada  22 neuronas (número de características de un hongo). La capa de salida posée una sola (output binario).","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"+ Ajustamos el aprendizaje con los siguientes hiperparámetros:\n        Número de neuronas en la capa intermediaria: 100 \n        Tipo de conexión utilizada: Total\n        Función de activación: Rectificador\n        Número máximo de ciclos de entrenamiento: 200\n        Método de resolución: Método de cuasi-Newton\n         \n        \n+ Entrenamos el clasificador con el conjunto previamente definido.\n\n+ Sometemos el conjunto de prueba al clasificador.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\n\nclf_rn= MLPClassifier(hidden_layer_sizes=(100),activation=\"relu\",solver=\"lbfgs\", max_iter=200, random_state=0) \n\nclf_rn.fit(x_train, y_train)\n\ny_pred_rn=clf_rn.predict(x_test)\n\nprint(\"y_pred_rn:\",\"\\n\",\"\\n\",y_test,\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Se muestran las primeras lineas de la estimación de *BackPropagation* sobre el conjunto de prueba.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"+ Exhibimos la matriz de confusión y los principales estimadores junto con el error cuadrático medio.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\nprint(\"Matriz de confusión\",\"\\n\",\"\\n\",confusion_matrix(y_test,y_pred_rn),\"\\n \",\"\\n \",\"\\n \",\"\\n \" )\nprint(\"Indicadores\",\"\\n\",\"\\n\", classification_report(y_test,y_pred_rn),\"\\n \",\"\\n \",\"\\n \",\"\\n \" )\nprint(\"Error cuadrático medio:\",\"\\n\",\"\\n\",mean_squared_error(y_test, y_pred_rn),\"\\n\" )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"En comparación a *Random Forest*, los hiperparámetros son más numerosos y su elección puede llegar a resultar poco fundamentada. Escogemos el método de activación de cuasi-Newton por ser sensiblemente más rápido, además de presentar una eficacidad más alta. Por esta última razón, elegimos también el rectificador como función de activación. En cuanto a la duración del entrenamiento, elegimos establecer un máximo de 200 ciclos para no limitar el aprendizaje. Variando el máximo de ciclos de entrenamiento, que desencadena un mensaje de alerta, conseguimos estimar el número medio de ciclos en torno a los 100. Al no introducir información sobre el tipo de conexión utilizado, suponemos que el perceptrón está totalmente conectado, suposición en coherencia con la aparente falta de hipótesis. Con respecto al número de neuronas de la capa intermediaria, su elección sea quizás la que más condicione el resultado. Con la comparación a *Random Forest* en mente, intentamos buscar un equilibrio entre exactitud de los resultados y velocidad de convergencia, fijando en 100 el número de neuronas. Aún así, *BackPropagation* resulta más lento y errático que *Random Forest*. A pesar de que la precisión, el recall y el f1 casi siempre son óptimos, el error cuadrático refleja un rendimiento inferior.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# CONCLUSIÓN","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Como ya adelantábamos, el rendimiento sobre este set de *Random Forest* parece estar un paso por encima del de *BackPropagation*, tanto en exactitud como en velocidad. Eso sí, cabe destacar la habitual coincidencia entre los resultados presentados por ambos métodos.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}