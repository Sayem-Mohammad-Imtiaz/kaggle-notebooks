{"cells":[{"metadata":{"papermill":{"duration":0.017763,"end_time":"2020-10-24T18:13:19.392307","exception":false,"start_time":"2020-10-24T18:13:19.374544","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# TABLE OF CONTENTS\n\n* [1. INTRODUCTION](#section-one)\n* [2. SETUP](#section-two)\n    - [2.1 Download/Draw Packages](#subsection-two-one)\n    - [2.2 Import and Wrangle Data](#subsection-two-two)\n* [3. STORY](#section-three)\n    - [3.1 Question 1: When are the plateau and inflection points for your chosen country? How do these dates affect your portfolio allocation and selection?](#subsection-three-one)\n    - [3.2 Question 2: What do you learn from the general negative runs in your chosen country? Which specific negative run is the closest (in nature and context) to Covid19? What do you learn from this specific run? What are the caveats?](#subsection-three-two)\n      - [3.2.1 How do we calculate the duration (peak-to-peak, peak-to-trough, and trough-to-peak) and maximum drawdown (loss) for each negative run?](#subsection-three-two-one)\n      - [3.2.2 How do the different types of market downturns (by severity) behave?](#subsection-three-two-two)\n* [4. CONCLUSION](#section-four)"},{"metadata":{"papermill":{"duration":0.015978,"end_time":"2020-10-24T18:13:19.424846","exception":false,"start_time":"2020-10-24T18:13:19.408868","status":"completed"},"tags":[]},"cell_type":"markdown","source":"<a id=\"section-one\"></a>\n# 1. INTRODUCTION\n\nThe first part of this notebook tests the infection and plateau points of Singapore pedametic situation in the next two years.Then we apply the relative results to the portfolo allocation and selection. The second part of this notebook focus on all negative runs of Singapore stock market from 1995 to 2020, which we believe is an important indicator for the portfolio allocation."},{"metadata":{"papermill":{"duration":0.016162,"end_time":"2020-10-24T18:13:19.457525","exception":false,"start_time":"2020-10-24T18:13:19.441363","status":"completed"},"tags":[]},"cell_type":"markdown","source":"<a id=\"section-two\"></a>\n# 2. SETUP"},{"metadata":{"papermill":{"duration":0.016208,"end_time":"2020-10-24T18:13:19.490224","exception":false,"start_time":"2020-10-24T18:13:19.474016","status":"completed"},"tags":[]},"cell_type":"markdown","source":"<a id=\"subsection-two-one\"></a>\n## 2.1 Download/Draw Packages"},{"metadata":{"execution":{"iopub.execute_input":"2020-10-24T18:13:19.530358Z","iopub.status.busy":"2020-10-24T18:13:19.529717Z","iopub.status.idle":"2020-10-24T18:13:20.361517Z","shell.execute_reply":"2020-10-24T18:13:20.360821Z"},"papermill":{"duration":0.854684,"end_time":"2020-10-24T18:13:20.361637","exception":false,"start_time":"2020-10-24T18:13:19.506953","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Data Wrangling\nimport numpy as np\nimport pandas as pd\nimport datetime as dt\n\n# Visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n### new\n# data wrangling\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime, date, timedelta\n\n# data visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\n# offline interactive visualization\nfrom plotly.offline import plot, iplot, init_notebook_mode\ninit_notebook_mode(connected=True)\n\n# regression\nimport statsmodels.api as sm\nfrom statsmodels.formula.api import ols\nimport statsmodels.graphics.api as smg\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\n# color pallette\n# Hexademical code RRGGBB (True Black #000000, True White #ffffff)\ncnf, dth, rec, act = '#393e46', '#ff2e63', '#21bf73', '#fe9801' ","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.016379,"end_time":"2020-10-24T18:13:20.397611","exception":false,"start_time":"2020-10-24T18:13:20.381232","status":"completed"},"tags":[]},"cell_type":"markdown","source":"<a id=\"subsection-two-two\"></a>\n## 2.2 Import and Wrangle Data"},{"metadata":{"execution":{"iopub.execute_input":"2020-10-24T18:13:20.440081Z","iopub.status.busy":"2020-10-24T18:13:20.439134Z","iopub.status.idle":"2020-10-24T18:13:20.497824Z","shell.execute_reply":"2020-10-24T18:13:20.49829Z"},"papermill":{"duration":0.083858,"end_time":"2020-10-24T18:13:20.498436","exception":false,"start_time":"2020-10-24T18:13:20.414578","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Import and wrangle with stock_ret dataset\nstock_ret = pd.read_csv('../input/stimonthly/STI-Month.csv')\nstock_ret['Date'] = pd.to_datetime(stock_ret['Date'],dayfirst=True)\n# stock_ret.tail()\n\n# Calculate monthly Total Returns for the STI (excluding dividends)\nstock_ret['mth_return'] = stock_ret['Close']/stock_ret['Close'].shift(1) - 1\n\n# Analysis post 1995 (i.e., 1995 Nov onwards)\nstock_ret['cum_return'] = np.cumprod(stock_ret['mth_return']+1)\n# stock_ret.info()\n# stock_ret.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Worldometer data\nworldometer_data = pd.read_csv('../input/corona-virus-report/worldometer_data.csv')\n# Replace missing values '' with NAN and then 0\nworldometer_data = worldometer_data.replace('', np.nan).fillna(0)\n# Correcting Country name \nworldometer_data['Country/Region'].replace({'USA':'US', 'UAE':'United Arab Emirates', 'S. Korea':'South Korea', \\\n                                           'UK':'United Kingdom'}, inplace=True)\n\n# Grouped by day, country\nfull_grouped = pd.read_csv('../input/corona-virus-report/full_grouped.csv')\n# Merge in population data\nfull_grouped = full_grouped.merge(worldometer_data[['Country/Region', 'Population']], how='left', on='Country/Region')\nfull_grouped['Date'] = pd.to_datetime(full_grouped['Date'], format = '%Y-%m-%d')\n#full_grouped.tail()\n# After check it, breakdown to SG only, create another dataframe called \"full_grouped_SG_Only\":\nfull_grouped_SG_Only = full_grouped.loc[full_grouped[\"Country/Region\"].isin(['Singapore'])]\n\n\n# golbal data\nglobal_data=full_grouped.groupby('Date')[['Confirmed','Deaths','Recovered','Active','Population']].sum()\nglobal_data.reset_index(inplace=True)\n# global_data.tail()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.016958,"end_time":"2020-10-24T18:13:20.534529","exception":false,"start_time":"2020-10-24T18:13:20.517571","status":"completed"},"tags":[]},"cell_type":"markdown","source":"<a id=\"section-three\"></a>\n# 3. STORY"},{"metadata":{"papermill":{"duration":0.017016,"end_time":"2020-10-24T18:13:20.568709","exception":false,"start_time":"2020-10-24T18:13:20.551693","status":"completed"},"tags":[]},"cell_type":"markdown","source":"<a id=\"subsection-three-one\"></a>\n## 3.1 Question 1: When are the plateau and inflection points for your chosen country? How do these dates affect your portfolio allocation and selection?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Collapse Country, Date observations to Date observations and reindex\n# Similar to world chart, can wtire a function to do this and just call, but notebook not scrip so make it clear, write it out\nactive_singapore_trend = full_grouped_SG_Only.groupby('Date')['Recovered', 'Deaths', 'Active'].sum().reset_index()\n\n# Melt the data by the value_vars, bascially keep the date and make status as one column, cases become another column\nactive_singapore_trend = active_singapore_trend.melt(id_vars=\"Date\", value_vars=['Deaths', 'Active', 'Recovered'],\n                 var_name='Case', value_name='Count')\n\n# Plot the general chart in the ways that as time goes by, what is the case situation\nfig = px.area(active_singapore_trend, x=\"Date\", y=\"Count\", color='Case', height=600, width=700,\n             title='Cases over time', color_discrete_sequence = [rec, dth, act])\nfig.update_layout(xaxis_rangeslider_visible=True)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# date = date of the most recent subwave of covid19 to project into the future\n# date format yyyy-mm-dd, e.g., '2020-07-04'\n\ndef plot_country(country, date): \n    temp = full_grouped[full_grouped['Country/Region']==country]\n    temp['recent_wave'] = np.where(temp['Date'] >= date,1,0)\n\n    fig = px.line(temp, x='Date', y='Confirmed', color='recent_wave', \\\n                  title = 'Infections for ' + str(country), height=600)      \n    fig.show()\n    \n    fig = px.line(temp, x='Date', y='Recovered', color='recent_wave', \\\n              title = 'Recovered Patients ' + str(country), height=600)      \n    fig.show()\n    \n    return country, date","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country, date = plot_country('Singapore', '2020-04-01')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generate the global trend of active, recover and death chart\n# Collapse Country, Date observations to Date observations and reindex\nactive_total_trend = full_grouped.groupby('Date')['Recovered', 'Deaths', 'Active'].sum().reset_index()\n\n# Melt the data by the value_vars, bascially keep the date and make status as one column, cases become another column\nactive_total_trend = active_total_trend.melt(id_vars=\"Date\", value_vars=['Recovered', 'Deaths', 'Active'],\n                 var_name='Case', value_name='Count')\n\n# Plot the general chart in the ways that as time goes by, what is the case situation\nfig = px.area(active_total_trend, x=\"Date\", y=\"Count\", color='Case', height=600, width=700,\n             title='Cases over time', color_discrete_sequence = [rec, dth, act])\nfig.update_layout(xaxis_rangeslider_visible=True)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_world(date): \n    temp = global_data[:]\n    temp['recent_wave'] = np.where(temp['Date'] >= date,1,0)\n\n    fig = px.line(temp, x='Date', y='Confirmed', color='recent_wave', \\\n                  title = 'Infections (World)', height=600)      \n    fig.show()\n    \n    fig = px.line(temp, x='Date', y='Recovered', color='recent_wave', \\\n              title = 'Recovered Patients (World) ', height=600)      \n    fig.show()\n    \n    return date\ndate = plot_world('2020-03-20')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Note:\n\nThese two graph did not give us specific indication on specific situation in SG compare to the world unless to take closer look into the numbers on Y axis. Therefore, we use the later part to have better explaination on the graph."},{"metadata":{},"cell_type":"markdown","source":"Model:  \n\\begin{align*}\n\\mathrm{S} \\overset{\\beta I}{\\longrightarrow} \\mathrm{I} \\overset{\\gamma}{\\longrightarrow} \\mathrm{R}  \\\\\n\\end{align*}\n\n$\\beta$: Effective contact rate or transmission rate [per day basis]  \n$\\gamma$: Recovery(and mortality) rate [per day basis]  \n\nOrdinary Differential Equation (ODE):  \n\\begin{align*}\n& \\frac{\\mathrm{d}S}{\\mathrm{d}T}= - \\beta S I / N \\\\\n& \\frac{\\mathrm{d}I}{\\mathrm{d}T}= \\beta S I / N - \\gamma I  \\\\\n& \\frac{\\mathrm{d}R}{\\mathrm{d}T}= \\gamma I  \\\\\n\\end{align*}\n\nWhere $N=S+I+R$ is the total population, $T$ is the elapsed time from the start date."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calibrate model\n\ndef estimate_sir_param(country, date):\n    \n    # Assume everyone is at risk\n    # Identify the maximum population and the latest date in the time series for the country\n    population  = full_grouped[full_grouped['Country/Region']==country][\"Population\"].max()\n    latest_date = full_grouped[full_grouped['Country/Region']==country][\"Date\"].max()\n    \n    time_series_length = (latest_date - datetime.strptime(date,'%Y-%m-%d')).days + 1\n\n    temp = full_grouped[full_grouped['Country/Region']==country]\n    temp['recent_wave'] = np.where(temp['Date'] >= date,1,0)\n    \n    # Initialize Numpy arrays for total population (the maximum population), \n    # susceptible population (empty), and change in time (i.e., 1 day)\n    N  = np.array([population] * time_series_length)\n    S  = np.array([])\n    dt = np.array([1] * (time_series_length-1))\n\n    # Apply the condition N = S+I+(R+D)\n    # Filter time-series to those of the recent wave\n    I = np.array(temp[temp['recent_wave']==1]['Active'])\n    R = np.array(temp[temp['recent_wave']==1]['Recovered'])\n    D = np.array(temp[temp['recent_wave']==1]['Deaths'])\n\n    # R includes both Recovered and Death for brevity\n    S = N - I - (R + D)\n\n    ## 1. Estimate beta\n    \n    x = (S * I) / N\n    \n    # Copy all elements except the last\n    x = x[:-1].copy()\n    \n    # Take the first difference\n    dS = np.diff(S)\n    y = dS/dt\n\n    # Fit into a linear regression\n    results = sm.OLS(y, x, missing='drop').fit()\n    beta = results.params\n    print(results.summary())\n    print('\\n')\n    print('*'*80)\n    print(f\"Transmission rate or Beta is: {beta}\")\n    print('*'*80)\n    \n    ## 2. Estimate gamma\n    \n    x = I[:-1].copy()\n    dR = np.diff(R+D)\n    y = dR/dt\n\n    results = sm.OLS(endog=y, exog=x, missing='drop').fit()\n    gamma = results.params\n    print (results.summary())\n    print('\\n')\n    print('*'*80)\n    print(f\"Recovery (and Mortality) rate or Gamma is: {gamma}\")\n    print('*'*80)\n    \n    #3. Calculate R\n\n    print('\\n')\n    print('*'*80)\n    print(f\"Reproduction number or R is: {-beta/gamma}\")\n    print('*'*80)\n    \n    return -beta.astype('float'), gamma.astype('float'), datetime.strptime(date,'%Y-%m-%d').date()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"beta, gamma, date = estimate_sir_param(\"Singapore\", date)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are able to see although the DW test is not as significant, the rest test are okay for Singapore"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calibrate model\n\ndef estimate_global_sir_param(date):\n    \n    # Assume everyone is at risk\n    # Identify the maximum population and the latest date in the time series for the country\n    population  = global_data[\"Population\"].max()\n    latest_date = global_data[\"Date\"].max()\n    \n    time_series_length = (latest_date - datetime.strptime(date,'%Y-%m-%d')).days + 1\n\n    temp = global_data[:]\n    temp['recent_wave'] = np.where(temp['Date'] >= date,1,0)\n    \n    # Initialize Numpy arrays for total population (the maximum population), \n    # susceptible population (empty), and change in time (i.e., 1 day)\n    N  = np.array([population] * time_series_length)\n    S  = np.array([])\n    dt = np.array([1] * (time_series_length-1))\n\n    # Apply the condition N = S+I+(R+D)\n    # Filter time-series to those of the recent wave\n    I = np.array(temp[temp['recent_wave']==1]['Active'])\n    R = np.array(temp[temp['recent_wave']==1]['Recovered'])\n    D = np.array(temp[temp['recent_wave']==1]['Deaths'])\n\n    # R includes both Recovered and Death for brevity\n    S = N - I - (R + D)\n\n    ## 1. Estimate beta\n    \n    x = (S * I) / N\n    \n    # Copy all elements except the last\n    x = x[:-1].copy()\n    \n    # Take the first difference\n    dS = np.diff(S)\n    y = dS/dt\n\n    # Fit into a linear regression\n    results = sm.OLS(y, x, missing='drop').fit()\n    beta = results.params\n    print(results.summary())\n    print('\\n')\n    print('*'*80)\n    print(f\"Transmission rate or Beta is: {beta}\")\n    print('*'*80)\n    \n    ## 2. Estimate gamma\n    \n    x = I[:-1].copy()\n    dR = np.diff(R+D)\n    y = dR/dt\n\n    results = sm.OLS(endog=y, exog=x, missing='drop').fit()\n    gamma = results.params\n    print (results.summary())\n    print('\\n')\n    print('*'*80)\n    print(f\"Recovery (and Mortality) rate or Gamma is: {gamma}\")\n    print('*'*80)\n    \n    #3. Calculate R\n\n    print('\\n')\n    print('*'*80)\n    print(f\"Reproduction number or R is: {-beta/gamma}\")\n    print('*'*80)\n    \n    return -beta.astype('float'), gamma.astype('float'), datetime.strptime(date,'%Y-%m-%d').date()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"beta, gamma, date = estimate_global_sir_param('2020-03-20')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are able to observed that although Beta's DB test fails, the rest test still okay to use the character."},{"metadata":{"trusted":true},"cell_type":"code","source":"def sir_model(I0=0.01, beta=0.6, gamma=0.1, days=365, date=date.today()):\n    \"\"\"\n    Function will take in initial state for infected population,\n    Transmission rate (beta) and recovery rate(gamma) as input.\n    \n    The function returns the maximum percentage of infectious population,\n    the number of days to reach the maximum (inflection point),\n    the maximum percentage of population infected,\n    the number of days to reach 80% of the maximum percentage of population infected.\n    \n    \"\"\"\n    ## Initialize model parameters\n    N = 1          #Total population in percentage, i.e., 1 = 100%\n    I = I0         #Initial state of I default value 1% of population, i.e., I0 = 0.01\n    S = N - I      #Initial state of S\n    R = 0          #Initial State of R\n    C = I          #Initial State of Total Cases\n    beta  = beta   #Transmission Rate\n    gamma = gamma  #Recovery Rate\n\n    ## Initialize empty lists\n    inf  = []       # List of Infectious population for each day\n    day  = []       # Time period in day\n    suc  = []       # List of Susceptible population for each day\n    rec  = []       # List of Recovered population for each day\n    conf = []       # List of Total Cases population for each day\n    \n    ## Project into the future\n    for i in range(days):\n        day.append(i)\n        inf.append(I)\n        suc.append(S)\n        rec.append(R)\n        conf.append(C)\n\n        new_inf= I*S*beta/N            #New infections equation (1)   \n        new_rec= I*gamma               #New Recoveries equation (2)\n        \n        I=I+new_inf-new_rec            #Total infectious population for next day\n        S=max(min(S - new_inf, N), 0)  #Total infectious population for next day\n        R=min(R + new_rec, N)          #Total recovered population for next day\n        \n        C=C+new_inf                    #Total confirmed cases for next day\n\n    ## Pinpoint important milestones    \n    max_inf = round(np.array(inf).max()*100,2)        #Peak infectious population in percentage\n    inflection_day = inf.index(np.array(inf).max())   #Peak infectious population in days\n    max_conf = round(np.array(conf).max()*100,2)      #Overall infected population in percentage\n    plateau_day = np.array(np.where(np.array(conf) >= 0.8*np.array(conf).max())).min()   #Peak infectious population in days\n        \n    print(f\"Maximum Infectious population at a time :{max_inf}%\")\n    print(f\"Number of Days to Reach Maximum Infectious Population (Inflection Point):{inflection_day} days or {date + timedelta(days=inflection_day)}\")\n    print(f\"Total Infected population :{max_conf}%\")\n    print(f\"Number of Days to Reach 80% of the Projected Confirmed Cases (Plateau Point):{plateau_day} days or {date + timedelta(days=plateau_day.item())}\")\n\n    ## Visualize the model outputs\n    sns.set(style=\"darkgrid\")\n    plt.figure(figsize=(10,6))\n    plt.title(f\"SIR Model: R = {round(beta/gamma,2)}\", fontsize=18)\n    sns.lineplot(day,inf, label=\"Infectious\")\n    sns.lineplot(day,suc,label=\"Succeptible\")\n    sns.lineplot(day,rec, label=\"Recovered\")\n    \n    plt.legend()\n    plt.xlabel(\"Time (in days)\")\n    plt.ylabel(\"Fraction of Population\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compute the SIR Model for Singapore\nsir_model(I0=0.000874, beta = 0.03839909, gamma = 0.0380892, days=730, date = date)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compute the SIR model for the world\nsir_model(I0=0.001042, beta = 0.03996787, gamma = 0.02675253, days=1000, date = date)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Conclusion is, SG situation is much better than the world, however, SG economy is affected by the world.\n\nTherefore, for portfolio allocation, we need to dive deeper into negative runs figure."},{"metadata":{"papermill":{"duration":0.019606,"end_time":"2020-10-24T18:13:21.303704","exception":false,"start_time":"2020-10-24T18:13:21.284098","status":"completed"},"tags":[]},"cell_type":"markdown","source":"<a id=\"subsection-three-two\"></a>\n## 3.2 Question 2: What do you learn from the general negative runs in your chosen country? Which specific negative run is the closest (in nature and context) to Covid19? What do you learn from this specific run? What are the caveats?"},{"metadata":{"execution":{"iopub.execute_input":"2020-10-24T18:13:20.627491Z","iopub.status.busy":"2020-10-24T18:13:20.626514Z","iopub.status.idle":"2020-10-24T18:13:20.629337Z","shell.execute_reply":"2020-10-24T18:13:20.628724Z"},"papermill":{"duration":0.043195,"end_time":"2020-10-24T18:13:20.629447","exception":false,"start_time":"2020-10-24T18:13:20.586252","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Calculate the negative runs in the STI (i.e., from one peak to another)\n# Initialize an empty list for cumulative returns from one peak to another \nstock_ret_2010 = stock_ret\nstock_ret_2010 = stock_ret_2010[stock_ret_2010['Date']>=\"2010-01-01\"]\n\ndef neg_run_func(stock_ret):\n    neg_run = []\n\n    # Store the previous maximum cumulative return\n    max_cum_ret_now = stock_ret['cum_return'].iloc[0]   \n\n    # enumerate() method adds counter (t) to an iterable (stock_ret['mth_return']) and \n    # returns a tuple (t, stock_ret['mth_return'])\n    for t, val in enumerate(stock_ret['mth_return']):\n\n        # First return in the monthly return series\n        if t == 0:\n\n            # If monthly return is negative\n            if val < 0:\n\n                # Append the negative return to neg_run list\n                neg_run.append(val)\n\n            else:\n\n                # Append a zero to neg_run list\n                neg_run.append(0)\n\n        # Not the first return in the monthly return series\n        else:\n\n            # If the cumulative return at time t is less than the previous maximum cumulative return\n            # i.e., the previous all time high\n            if stock_ret['cum_return'].iloc[t] < max_cum_ret_now:\n\n                # cumulate/compound the return at time t with the return at time t-1\n                # i.e., tally the loss\n                neg_run.append((1 + neg_run[t-1])*(1 + val) - 1) \n\n            # If the cumulative return at time t is more than the previous maximum cumulative return\n            else:\n\n                # stop the loss tally and append a zero to the negative run list\n                neg_run.append(0)                                \n\n                # replace the previous all time high with the new high\n                max_cum_ret_now = stock_ret['cum_return'].iloc[t]\n\n    # Add the variable to the dataframe stock_ret\n    stock_ret['neg_run'] = neg_run\n    \n    return stock_ret\n\nstock_ret = neg_run_func(stock_ret)\nstock_ret_2010 = neg_run_func(stock_ret_2010)\n# stock_ret.tail(10)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-10-24T18:13:20.674283Z","iopub.status.busy":"2020-10-24T18:13:20.673673Z","iopub.status.idle":"2020-10-24T18:13:20.976204Z","shell.execute_reply":"2020-10-24T18:13:20.975573Z"},"papermill":{"duration":0.329292,"end_time":"2020-10-24T18:13:20.976315","exception":false,"start_time":"2020-10-24T18:13:20.647023","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Plot the STI time series\nsns.lineplot(x='Date', y='Close', data=stock_ret, color='red')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the STI time series after 2010\nsns.lineplot(x='Date', y='Close', data=stock_ret_2010, color='red')","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-10-24T18:13:21.028423Z","iopub.status.busy":"2020-10-24T18:13:21.027458Z","iopub.status.idle":"2020-10-24T18:13:21.262936Z","shell.execute_reply":"2020-10-24T18:13:21.262302Z"},"papermill":{"duration":0.26798,"end_time":"2020-10-24T18:13:21.263049","exception":false,"start_time":"2020-10-24T18:13:20.995069","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Plot the peak-to-peak negative run\nsns.lineplot(x='Date', y='neg_run', data=stock_ret, color='red')\nprint(stock_ret[stock_ret[\"mth_return\"] < 0].count())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the peak-to-peak negative run after 2010\nsns.lineplot(x='Date', y='neg_run', data=stock_ret_2010, color='red')\nprint(stock_ret_2010[stock_ret_2010[\"mth_return\"] < 0].count())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Implication from this graph as negative runs from 2008 is too long and not suitable for calculation and it's only half a size from 2008's situation. Therefore, we are approximate situation from 2010+ for this negative run in 2019. The reason behind is that the netative runs from the 2002 SARS is similar to current situation which did not take as long as 2008's negative run which hurting SG economy badly to recover."},{"metadata":{"papermill":{"duration":0.019959,"end_time":"2020-10-24T18:13:22.119055","exception":false,"start_time":"2020-10-24T18:13:22.099096","status":"completed"},"tags":[]},"cell_type":"markdown","source":"<a id=\"subsection-three-two-one\"></a>\n### 3.2.1 How do we calculate the duration (peak-to-peak, peak-to-trough, and trough-to-peak) and maximum drawdown (loss) for each negative run?"},{"metadata":{"execution":{"iopub.execute_input":"2020-10-24T18:13:21.355056Z","iopub.status.busy":"2020-10-24T18:13:21.354218Z","iopub.status.idle":"2020-10-24T18:13:21.357114Z","shell.execute_reply":"2020-10-24T18:13:21.356571Z"},"papermill":{"duration":0.033473,"end_time":"2020-10-24T18:13:21.357222","exception":false,"start_time":"2020-10-24T18:13:21.323749","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Subs the 2010 and after negative runs for later calculation as it better our prediction for future\nstock_ret = stock_ret_2010\n\n# Recap that a neg_run is the peak-to-peak run \n# Identify and label each neg_run sequentially (e.g., the 10th neg_run is tagged as 10)\n# The label serves as the groupby variable to examine the characteristics of each run\n\n# Initialize label value\nlabel = 1\n\n# Initialize the indicator value of whether stock_ret['neg_run'] (or loss tally) is within a peak-to-peak run\nwithin_negative_run = False\n\n# Initialize an empty list for negative run number\nneg_run_num = []\n\n# Identify and label each cycle of negative run, which ends with a zero\n# The cumulative return (or loss tally) during the cycle is negative\nfor i in stock_ret['neg_run']:\n    \n    # Loss tally is negative\n    if i < 0:\n        \n        # Append the label to neg_run_num list\n        neg_run_num.append(label)\n        \n        # Switch the state for within_negative_run\n        within_negative_run = True\n        \n    # Loss tally is zero - negative run ends\n    else:\n        \n        # Append a zero to neg_run_num list\n        neg_run_num.append(0)\n        \n        # Increment label value by 1 if within_negative_run is True\n        # This happens only for a 'new' cycle of negative run\n        # The label doesn't increment by 1 in market run-up after the exit from a negative run\n        # i.e., reaching new all-time highs after exiting from a cycle of negative run\n        if within_negative_run:\n            label += 1\n            within_negative_run = False\n            \nstock_ret['neg_run_num'] = neg_run_num","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-10-24T18:13:21.533692Z","iopub.status.busy":"2020-10-24T18:13:21.406556Z","iopub.status.idle":"2020-10-24T18:13:22.078589Z","shell.execute_reply":"2020-10-24T18:13:22.077952Z"},"papermill":{"duration":0.701304,"end_time":"2020-10-24T18:13:22.078726","exception":false,"start_time":"2020-10-24T18:13:21.377422","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Identify and label each peak (previous all time high) to trough (the lowest point) within each peak-to-peak run\n# This is also known as the maximum drawdown\n# The integer label runs sequentially (e.g., the 10th peak-to-trough is tagged as 10)\n\n# Initialize the label value\nlabel = 1\n\n# Initialize the search status of whether the lowest point within a negative run has been discovered\nis_neg_run_min = False\n\n# Initialize an empty list for peak-to-trough run number\npeak_trough_num = []\n\nfor t, val in enumerate(stock_ret['neg_run_num']):\n    \n    # Identify the lowest point (i.e., cumulated returns) within a negative run\n    trough = min(stock_ret[stock_ret['neg_run_num']==val]['neg_run'])\n    \n    # Recap that if the cumulative return at time t is more than the previous maximum cumulative return\n    # The loss tally will stop with a zero appended to the negative run list (i.e., the negative run has ended)\n    # neg_run_num will also be appended with a zero when neg_run is zero\n\n    # While still within a peak-to-peak negative run\n    if val > 0:\n        \n        # Append zero to peak_trough_num if the lowest point has been discovered\n        if is_neg_run_min:\n            peak_trough_num.append(0)\n            \n        # Lowest point within a negative run has not been discovered\n        else:\n            if stock_ret.iloc[t]['neg_run'] == trough:\n                is_neg_run_min = True\n                peak_trough_num.append(val)\n            else:\n                peak_trough_num.append(val)\n                \n    # Out of the peak-to-peak negative run\n    else:\n        is_neg_run_min = False\n        peak_trough_num.append(val)\n            \nstock_ret['peak_trough_num'] = peak_trough_num","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-10-24T18:13:22.173062Z","iopub.status.busy":"2020-10-24T18:13:22.171381Z","iopub.status.idle":"2020-10-24T18:13:22.609587Z","shell.execute_reply":"2020-10-24T18:13:22.609006Z"},"papermill":{"duration":0.470562,"end_time":"2020-10-24T18:13:22.609719","exception":false,"start_time":"2020-10-24T18:13:22.139157","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Groupby's to check out the durations and maximum loss or drawdown of each market decline identified\n# There are 82 peak-to-peak negative runs\n\n# By peak-to-peak run number, count the number of months \nrun_len = stock_ret[stock_ret['neg_run_num']>0].groupby('neg_run_num').count()['neg_run']\n\n# By peak-to-peak run number, count lowest cumulative returns (i.e., maximum drawdown)\nmaximum_drawdown = stock_ret[stock_ret['neg_run_num']>0].groupby('neg_run_num').min()['neg_run']\n\n# By peak-to-trough run number, count the number of months\npeak_trough_dur = stock_ret[stock_ret['peak_trough_num']>0].groupby('peak_trough_num').count()['neg_run']\n\nfig, ax = plt.subplots(3)\nax[0].plot(run_len.sort_values(ascending=False).reset_index(drop=True))\nax[0].set_title(\"Time between Two Peaks (Months)\")\nax[1].plot(peak_trough_dur.sort_values(ascending=False).reset_index(drop=True))\nax[1].set_title(\"Time to Maximum Drawdown (Months)\")\nax[2].plot(maximum_drawdown.sort_values(ascending=False).reset_index(drop=True))\nax[2].set_title(\"Maximum Drawdown (%)\")\nfig.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-10-24T18:13:22.665514Z","iopub.status.busy":"2020-10-24T18:13:22.664894Z","iopub.status.idle":"2020-10-24T18:13:22.66931Z","shell.execute_reply":"2020-10-24T18:13:22.668808Z"},"papermill":{"duration":0.038477,"end_time":"2020-10-24T18:13:22.669427","exception":false,"start_time":"2020-10-24T18:13:22.63095","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Store groupby results in a new dataframe with the 82 runs\ndeclines_df = pd.DataFrame()\n\ndeclines_df['run_len'] = run_len\ndeclines_df['maximum_drawdown'] = maximum_drawdown\ndeclines_df['peak_trough_dur'] = peak_trough_dur\n\n# declines_df.tail(10)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.021645,"end_time":"2020-10-24T18:13:22.713386","exception":false,"start_time":"2020-10-24T18:13:22.691741","status":"completed"},"tags":[]},"cell_type":"markdown","source":"<a id=\"subsection-three-two-two\"></a>\n### 3.2.2 How do the different types of market downturns (by severity) behave? "},{"metadata":{"execution":{"iopub.execute_input":"2020-10-24T18:13:22.765273Z","iopub.status.busy":"2020-10-24T18:13:22.76452Z","iopub.status.idle":"2020-10-24T18:13:22.76745Z","shell.execute_reply":"2020-10-24T18:13:22.766857Z"},"papermill":{"duration":0.032342,"end_time":"2020-10-24T18:13:22.767554","exception":false,"start_time":"2020-10-24T18:13:22.735212","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Create 6 buckets by the magnitude of drawdown\ndrawdown_bin = []\nfor i in maximum_drawdown:\n    if i >= 0.00:\n        drawdown_bin.append(0)\n    elif i >= -0.05:\n        drawdown_bin.append(1)\n    elif i >= -0.10:\n        drawdown_bin.append(2)\n    elif i >= -0.20:\n        drawdown_bin.append(3)\n    elif i >= -0.30:\n        drawdown_bin.append(4)\n    else:\n        drawdown_bin.append(5)\n\ndeclines_df['drawdown_bin'] = drawdown_bin\n# declines_df.tail(10)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-10-24T18:13:22.8191Z","iopub.status.busy":"2020-10-24T18:13:22.81814Z","iopub.status.idle":"2020-10-24T18:13:22.822348Z","shell.execute_reply":"2020-10-24T18:13:22.821888Z"},"papermill":{"duration":0.032851,"end_time":"2020-10-24T18:13:22.822461","exception":false,"start_time":"2020-10-24T18:13:22.78961","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Overall means for drawdown metrics\nnp.mean(declines_df)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-10-24T18:13:22.876237Z","iopub.status.busy":"2020-10-24T18:13:22.875224Z","iopub.status.idle":"2020-10-24T18:13:22.879505Z","shell.execute_reply":"2020-10-24T18:13:22.879004Z"},"papermill":{"duration":0.034582,"end_time":"2020-10-24T18:13:22.879612","exception":false,"start_time":"2020-10-24T18:13:22.84503","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Count the number of drawdowns in each drawdown bucket\ndeclines_df.groupby('drawdown_bin').count()['run_len']","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-10-24T18:13:22.937805Z","iopub.status.busy":"2020-10-24T18:13:22.937099Z","iopub.status.idle":"2020-10-24T18:13:23.089179Z","shell.execute_reply":"2020-10-24T18:13:23.088605Z"},"papermill":{"duration":0.187249,"end_time":"2020-10-24T18:13:23.089305","exception":false,"start_time":"2020-10-24T18:13:22.902056","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Plot the number of declines in each magnitude bucket in probability term\n\n# Calculate the probability of being in a drawdown bin relative to all drawdown bins\nprob_bucket = declines_df.groupby('drawdown_bin').count()['run_len']/sum(declines_df.groupby('drawdown_bin').count()['run_len'])\n\n# Plot the probabilities for each drawdown bin\nfig, ax = plt.subplots(figsize=(10,6))\nbin_names = ['-5% or Better','-5% to -10%','-10% to -20%','-20% to -30%', '-30% or Worse']\nsns.barplot(x=prob_bucket, y=bin_names);\nax.set_xlabel(\"Probability\",fontsize=14)\nax.set_ylabel(\"Drawdown Bin\",fontsize=14)\n\n# Probability is between 0 and 1 - limit the range of possible value for x-axis\nax.set_xlim(0, 1)\n\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-10-24T18:13:23.143667Z","iopub.status.busy":"2020-10-24T18:13:23.143028Z","iopub.status.idle":"2020-10-24T18:13:23.146611Z","shell.execute_reply":"2020-10-24T18:13:23.146007Z"},"papermill":{"duration":0.033799,"end_time":"2020-10-24T18:13:23.146737","exception":false,"start_time":"2020-10-24T18:13:23.112938","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# What happens after the market has already dropped by 5%\n\n# Calculate the probability for \nworst_probs = prob_bucket[1:]/sum(prob_bucket[1:])\n\n# probability of decline more than 10%\nprint(\"The probability of a further decline of more than 10% is\", sum(worst_probs[1:]))     \n","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-10-24T18:13:23.204382Z","iopub.status.busy":"2020-10-24T18:13:23.203744Z","iopub.status.idle":"2020-10-24T18:13:23.207394Z","shell.execute_reply":"2020-10-24T18:13:23.206895Z"},"papermill":{"duration":0.036996,"end_time":"2020-10-24T18:13:23.207498","exception":false,"start_time":"2020-10-24T18:13:23.170502","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Calculate the mean maximum drawdown for each drawdown bucket of negative runs \ndeclines_df.groupby('drawdown_bin').mean()['maximum_drawdown']","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-10-24T18:13:23.269929Z","iopub.status.busy":"2020-10-24T18:13:23.269051Z","iopub.status.idle":"2020-10-24T18:13:23.272865Z","shell.execute_reply":"2020-10-24T18:13:23.272242Z"},"papermill":{"duration":0.04008,"end_time":"2020-10-24T18:13:23.273031","exception":false,"start_time":"2020-10-24T18:13:23.232951","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Calculate the metrics of each drawdown bucket and store in a dataframe for plots\n\n# Calculate the peak-to-peak and peak-to-trough duration for each run\nduration_df = declines_df.groupby('drawdown_bin').mean()[['peak_trough_dur','run_len']]\nduration_df.reset_index(inplace=True)\n\n# Time to recover (in months)\nduration_df['recover_dur'] = duration_df['run_len'] - duration_df['peak_trough_dur']\n\n# Time to recover relative to time to the trough\nduration_df['recover_to_peak_trough_ratio'] = duration_df['recover_dur'] / duration_df['peak_trough_dur']","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-10-24T18:13:23.328179Z","iopub.status.busy":"2020-10-24T18:13:23.327469Z","iopub.status.idle":"2020-10-24T18:13:23.481281Z","shell.execute_reply":"2020-10-24T18:13:23.48175Z"},"papermill":{"duration":0.184319,"end_time":"2020-10-24T18:13:23.481895","exception":false,"start_time":"2020-10-24T18:13:23.297576","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Plot the metrics\nfig, ax = plt.subplots(figsize=(10,6))\nbin_names = ['-5% or Better','-5% to -10%','-10% to -20%','-20% to -30%', '-30% or Worse']\nsns.barplot(x=bin_names, y=duration_df['recover_dur'])\nax.set_xlabel(\"Market Decline Bin\",fontsize=14)\nax.set_ylabel(\"Recovery Time in Months\",fontsize=14)\n\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-10-24T18:13:23.593685Z","iopub.status.busy":"2020-10-24T18:13:23.592709Z","iopub.status.idle":"2020-10-24T18:13:23.596586Z","shell.execute_reply":"2020-10-24T18:13:23.596104Z"},"papermill":{"duration":0.039535,"end_time":"2020-10-24T18:13:23.596717","exception":false,"start_time":"2020-10-24T18:13:23.557182","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Print out the duration df to see the time needs to be used to recover\nduration_df","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.025498,"end_time":"2020-10-24T18:13:23.648007","exception":false,"start_time":"2020-10-24T18:13:23.622509","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Market decline of more than 30% (5th bins) takes disproportionately more time to recover than market decline of more than 30%. For example, market downturns of -30% or worse take an average of 2.1977 times longer than the time to from the peak to the trough to recover."},{"metadata":{"execution":{"iopub.execute_input":"2020-10-24T18:13:23.70639Z","iopub.status.busy":"2020-10-24T18:13:23.705749Z","iopub.status.idle":"2020-10-24T18:13:23.709121Z","shell.execute_reply":"2020-10-24T18:13:23.708387Z"},"papermill":{"duration":0.035713,"end_time":"2020-10-24T18:13:23.709265","exception":false,"start_time":"2020-10-24T18:13:23.673552","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Calculate the Number and percentage of negative months\nprint(\"The number of negative monthly returns: \", len([i for i in stock_ret['mth_return'] if i<0]))\nprint(\"The number of monthly returns: \", stock_ret.shape[0])\nprint(\"The fraction of negative monthly returns: \", len([i for i in stock_ret['mth_return'] if i<0])/stock_ret.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-10-24T18:13:23.767492Z","iopub.status.busy":"2020-10-24T18:13:23.766874Z","iopub.status.idle":"2020-10-24T18:13:23.770336Z","shell.execute_reply":"2020-10-24T18:13:23.769404Z"},"papermill":{"duration":0.034299,"end_time":"2020-10-24T18:13:23.770449","exception":false,"start_time":"2020-10-24T18:13:23.73615","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Calculate the Mean length of drawdown\nprint(\"The average length of peak-to-trough market downturn: \", np.mean(declines_df['peak_trough_dur']), \"months\")","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.026204,"end_time":"2020-10-24T18:13:23.823412","exception":false,"start_time":"2020-10-24T18:13:23.797208","status":"completed"},"tags":[]},"cell_type":"markdown","source":"<a id=\"section-four\"></a>\n# 4. CONCLUSION"},{"metadata":{"papermill":{"duration":0.028126,"end_time":"2020-10-24T18:13:23.878128","exception":false,"start_time":"2020-10-24T18:13:23.850002","status":"completed"},"tags":[]},"cell_type":"markdown","source":"- Base on the predicted Covid-19 situation in the next coming two years, we believe that the padamedic situation in Singapore is fully controlled since the beta/gamma ratio is only 1.01 and maximum infectious population is only 0.09%.\n\n- Therefore, we think it is a positive sign for Singapore based industries, as well as our portfolio with Singapore companies. However,the Singapore stock market reached its peak at 2018 and then it takes more than 140 months to recover and till now it is still below the previous peak. \n\n- In addition, there are 6 negative runs from 1995 to 2020, 3 of 6 have average more than -57% drawdown. \n\n- And the ratio of recover to peak-through of the last negative run is 8.75, which indicates that the recovery time is 8.75 times longer than the time from peak to trough.\n\n- Therefore, from the negative-run prospective, we believe Singapore stock market is not an optimal investment location, and our suggestion is to keep more cash and seek oppotunities overseas. \n\n- Furthermore, we estimate the potential reason for such situation in Singapore stock market is that the liquidity of Singapore stock market is much lower than other world's main stock markets so that it reached the trough within 16 months during the financial crisis at 2008 but hasn't recovered till today."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}