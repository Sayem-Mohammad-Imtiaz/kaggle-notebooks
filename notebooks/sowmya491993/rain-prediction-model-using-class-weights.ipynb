{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#Libraries required\n# Import Dependencies\n%matplotlib inline\n\n# Start Python Imports\nimport math, time, random, datetime\n\n# Data Manipulation\nimport numpy as np\nimport pandas as pd\n\n# Visualization \nimport matplotlib.pyplot as plt\nimport missingno\nimport seaborn as sns\nplt.style.use('seaborn-whitegrid')\n\n# Machine learning\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import model_selection, tree, preprocessing, metrics, linear_model\nfrom sklearn.linear_model import LinearRegression, LogisticRegression, SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n#ignore warnings for now\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Download the data**  \nThe data has been downloaded from kaggle datasets : https://www.kaggle.com/jsphyg/weather-dataset-rattle-package"},{"metadata":{},"cell_type":"markdown","source":"**Load the data**  \nLoad the data into the notebook (file : weatherAUS.csv)"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/weatherAUS.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's see how our data looks like\nprint('Weather dataframe dimension: ',data.shape)\ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We can see that there are lot of NaN values in the dataframe.  \n# Let's check which column has maximum Nan values\nprint(data.count().sort_values())\n\n#Graph to find missing values in the dataframe\nimport missingno\nmissingno.matrix(data, figsize = (30,10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Feature Selection**\n1. From the above result we can see that the columns **Sunshine,Evaporation,Cloud3pm,Cloud9am** have more Nan or null values, they have less than 60% data, hence we are not including these columns.  \n2. Also, we donot need **Location** column because we are trying to predict whether it will rain or not tommorrow and this analysis is not based on location.  \n3. **Date** column can also be removed since the feature is not required for our prediction model.\n4. We must remove **RISK_MM** feature since here we are trying to predict 'RainTommorrow'. RISK_MM is amount of rainfall in millimeters for the next day. It includes all forms of precipitation that reach the ground, such as rain, drizzle, hail and snow. Since it contains information about the future, and information directly about the target variable, including it would leak the future information to the model. Instead the variable itself can be actually used to determine whether or not it rained to create the binary target. For example, if RISKMM was greater than 0, then the RainTomorrow target variable is equal to Yes. Hence, using it as a predictor to build a model and then testing on this dataset would give the false appearance of a high accuracy."},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(columns = ['Sunshine','Evaporation','Cloud3pm','Cloud9am','Location','Date','RISK_MM'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data.shape)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can also write a function to track the missing values in each of the columns as below:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_missing_values(df,columns):\n    missing_vals = {}\n    df_length = len(df)\n    for column in columns:\n        total_column_values = df[column].value_counts().sum()\n        missing_vals[column] = df_length - total_column_values\n    return missing_vals\n\nmissing_values = find_missing_values(data,data.columns)\nmissing_values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's see how to deal with missing values or Nan values"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.dropna(axis = 'index',how='any')\nprint(data.shape)\n\nmissing_values = find_missing_values(data,data.columns)\nmissing_values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final = pd.DataFrame()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"DATA TRANSFORMATION"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Data transformation\n#For the categorical columns, we will change the value 'Yes' and 'No' to '1' and '0' respectively\ndata['RainTomorrow'].replace({'No': 0, 'Yes': 1},inplace = True)\ndata['RainToday'].replace({'No': 0, 'Yes': 1},inplace = True)\n\n#See unique values and convert them to int using pd.getDummies()\ncategorical_columns = ['WindGustDir', 'WindDir3pm', 'WindDir9am']\nfor col in categorical_columns:\n    print(np.unique(data[col]))\n# transform the categorical columns\nfinal = pd.get_dummies(data, columns=categorical_columns)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now lets standardise the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nscaler = preprocessing.MinMaxScaler()\nscaler.fit(final)\nfinal = pd.DataFrame(scaler.transform(final), index=final.index, columns=final.columns)\nfinal.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**FEATURE EXPLORATION**"},{"metadata":{},"cell_type":"markdown","source":"**Feature 1 : 'RainTommorrow' (Target variable)**  \n\nDescription : Did it rain the next day?  \nValues : 'Yes' , 'No'  \nThis is the dependent variable we want our machine learning model to predict, based on other independent variables  "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now we will just see how many times it rained the next day?\nfig = plt.figure(figsize = (20,3))\nsns.countplot(y='RainTomorrow', data=final);\nprint(final.RainTomorrow.value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the graph we can know the ratio of cases where the next day is predicted as rainy day or not. From here, it gives a clue that - in future if our machine learning model is predicting more RainTomorrow = 'No' than number of RainTomorrow = 'Yes' with our test data, it means that we should check on the model. It basically gives us information about the bias or balance of targets in our data.\nThe table above the graph presents frequency counts for the binary variable."},{"metadata":{},"cell_type":"markdown","source":"**Feature 2: MinTemp**\n\nDescription : Minimum temperature in degree celsius"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_values['MinTemp']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.MinTemp.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"since it is a continuous value, let's do binning and put this to a sepearate dataframe final_bin for visualization purpose"},{"metadata":{"trusted":true},"cell_type":"code","source":"final_bin = pd.DataFrame()\nfinal_bin['RainTomorrow'] = final['RainTomorrow']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_bin['MinTemp'] = pd.cut(data['MinTemp'],bins = 5) #discretising the float numbers into categorical","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_bin.MinTemp.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now lets see a function to create count and distribution for any variable we want"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_count_dist(df,label_column,target_column,figsize=(20,5)):\n        fig = plt.figure(figsize=figsize)\n        plt.subplot(1,2,1)\n        sns.countplot(y=target_column, data = df);\n        plt.subplot(1,2,2)\n        sns.distplot(data.loc[data[label_column] == 1][target_column],\n                    kde_kws={\"label\" : \"Yes\"});\n        sns.distplot(data.loc[data[label_column] == 0][target_column],\n                    kde_kws={\"label\" : \"No\"});\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Calling the function above we will visualise the MinTemp bin counts as well as the MinTemp distribution versus RainTomorrow\nplot_count_dist(df= final_bin, label_column = 'RainTomorrow', target_column = 'MinTemp', figsize = (20,10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"The left plot shows how many different values does MinTemp has. The right plot means that when MinTemp is between 0.0 - 0.3, the target RainTomorrow being 'No' is more and when MinTemp is greater than 0.6 the target RainTomorrow being 'Yes' is more. "},{"metadata":{},"cell_type":"markdown","source":"**Feature 3 : MaxTemp**"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Description : The maximum temperature in degrees celsius"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's cross check the missing values\nmissing_values['MaxTemp']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['MaxTemp'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"since it is a continuous value, let's do binning and put this to our final_bin dataframe."},{"metadata":{"trusted":true},"cell_type":"code","source":"final_bin['MaxTemp'] = pd.cut(data['MaxTemp'],bins = 5) #discretising the float numbers into categorical","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_bin['MaxTemp'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Calling the function above we will visualise the MaxTemp bin counts as well as the MaxTemp distribution versus RainTomorrow\nplot_count_dist(df= final_bin, label_column = 'RainTomorrow', target_column = 'MaxTemp', figsize = (20,10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The left plot shows how many different values does MinTemp has.The right plot means that when MaxTemp is between 0.0 - 0.4, the target RainTomorrow being 'Yes' is more and when MinTemp is greater than 0.4 the target RainTomorrow being 'No' is more."},{"metadata":{},"cell_type":"markdown","source":"**Feature 4 : Rainfall**"},{"metadata":{},"cell_type":"markdown","source":"Description : The amount of Rainfall in mm recorded for the day"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's cross check the missing values\nmissing_values['Rainfall']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Rainfall'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"There are {} unique minimum temperature values.\".format(len(data.Rainfall.unique())))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"since it is a continuous value, let's do binning and put this to our final_bin datafarme"},{"metadata":{"trusted":true},"cell_type":"code","source":"final_bin['Rainfall'] = pd.cut(data['Rainfall'],bins = 5) #discretising the float numbers into categorical","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_bin['Rainfall'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Calling the function above we will visualise the MaxTemp bin counts as well as the MaxTemp distribution versus RainTomorrow\nplot_count_dist(df= final_bin, label_column = 'RainTomorrow', target_column = 'Rainfall', figsize = (20,10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The left plot shows that most of the values for rainfall in mm lies in between  -0.001 to 0.2 and the right plot shows it is obvious that current day's rainfall of nearly '0'mm indicates that mostly there will be no rainfall next day."},{"metadata":{},"cell_type":"markdown","source":"**Feature 5 : WindGustDir**"},{"metadata":{},"cell_type":"markdown","source":"Description : The direction of the strongest wind gust in the 24 hours to midnight"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_values['WindGustDir']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have already transformed this categorical variable using dummies, for the system to understand. So let's go ahead and visualise the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"WindGustDir_table = pd.crosstab(index=data[\"WindGustDir\"], columns=data[\"RainTomorrow\"])\nWindGustDir_table","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"WindGustDir_table.plot(kind=\"bar\", figsize=(15,8),stacked=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The insights convey the chances of being RainTomorrow = 'NO' is when wind blows in direction of East,Southeast and South Southeast mostly.and the chances of being RainTomorrow = 'Yes' is when it is North, West and Northwest."},{"metadata":{"trusted":true},"cell_type":"markdown","source":"**Feature 5 : WindGustSpeed**"},{"metadata":{},"cell_type":"markdown","source":"Description : The speed (km/h) of the strongest wind gust in the 24 hours to midnight"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_values['WindGustSpeed']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_count_dist(df= final, label_column = 'RainTomorrow', target_column = 'WindGustSpeed', figsize = (20,10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"The left plot provides unique values and its numbers of WindGustSpeed whereas right plot explains if there is a WindGustSpeed of 0-50 the currentday, then the next day mostly it will not rain. Otherwisw when WindGustSpeed is greater than 50 it says that the next day can see rain."},{"metadata":{},"cell_type":"markdown","source":"**Feature 6 : WindDir9am**"},{"metadata":{},"cell_type":"markdown","source":"Description : Direction of the wind at 9am"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_values['WindDir9am']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have already transformed this categorical variable using dummies, for the system to understand. So let's go ahead and visualise the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"WindDir9am_table = pd.crosstab(index=data[\"WindDir9am\"], columns=data[\"RainTomorrow\"])\nWindDir9am_table","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"WindDir9am_table.plot(kind=\"bar\", figsize=(15,8),stacked=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For RainTomorrow being ‘No’, the wind at morning mostly blows in direction of East,Southeast and South South-east, for RainTomorrow being ‘Yes’, the wind mostly blows in North North-West,North and North North-East."},{"metadata":{},"cell_type":"markdown","source":"**Feature 7 : WindDir3pm**"},{"metadata":{},"cell_type":"markdown","source":"Description : Direction of the wind at 3pm"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_values['WindDir3pm']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have already transformed this categorical variable using dummies, for the system to understand. So let's go ahead and visualise the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"WindDir3pm_table = pd.crosstab(index=data[\"WindDir3pm\"], columns=data[\"RainTomorrow\"])\nWindDir3pm_table","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"WindDir3pm_table.plot(kind=\"bar\", figsize=(15,8),stacked=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For RainTomorrow being ‘Yes’ the wind at evening mostly blows in North, West and West-Northwest and for RainTomorrow being ‘No’, the wind mostly blows in direction of South, SouthEast, West-Southwest."},{"metadata":{},"cell_type":"markdown","source":"**Feature 8 : WindSpeed9am**"},{"metadata":{},"cell_type":"markdown","source":"Description : Wind speed (km/hr) averaged over 10 minutes prior to 9am"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_values['WindSpeed9am']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_count_dist(df= final, label_column = 'RainTomorrow', target_column = 'WindSpeed9am', figsize = (20,10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The left plot shows the unique values of WindSpeed9am and their. The frequencyright plot means that for WindSpeed9am of 0-20 km/hr the target RainTomorrow being 'No' is more and having greater than 20 km/hr, the target RainTomorrow being 'Yes' is more."},{"metadata":{},"cell_type":"markdown","source":"**Feature 9 : WindSpeed3pm**"},{"metadata":{},"cell_type":"markdown","source":"Description : Wind speed (km/hr) averaged over 10 minutes prior to 3pm"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_values['WindSpeed3pm']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_count_dist(df= final, label_column = 'RainTomorrow', target_column = 'WindSpeed3pm', figsize = (20,10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The left graph shows the frequencies of unique values in WindSpeed3pm and right graph tells that if the WindSpeed3pm reaches 20 km/hr then the target RainTomorrow being 'Yes' is more, greater than 25 km/hr means the target RainTomorrow being ‘No’ has more chance."},{"metadata":{},"cell_type":"markdown","source":"**Feature 10 : Humidity9am**"},{"metadata":{},"cell_type":"markdown","source":"Description : Humidity at 9am in %"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_values['Humidity9am']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_count_dist(df= final, label_column = 'RainTomorrow', target_column = 'Humidity9am', figsize = (20,10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The left plot shows the frequencies of unique humidity values and right graph means that if Humidity9am is between 0-70 %, then target RainTomorrow will be 'No' and if Humidity9am is more than 70 % the current day then RainTomorrow being 'Yes' is more. And also, we can see that at 100% humidity the case of RainTomorrow = 'Yes' is twice as that of case where RainTomorrow = 'No'."},{"metadata":{},"cell_type":"markdown","source":"**Feature 11 : Humidity3pm**"},{"metadata":{},"cell_type":"markdown","source":"Description : Humidity at 3pm in %"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_values['Humidity3pm']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_count_dist(df= final, label_column = 'RainTomorrow', target_column = 'Humidity3pm', figsize = (20,10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The left graph gives the frequencies of unique values for Humidity3pm and right graph clearly draws a line which seperates the Humidity3pm as two ranges where 1. 0-60% - RainTomorrow being 'No' is evident and 2. greater than 60% - RainTomorrow being 'Yes' is evident."},{"metadata":{},"cell_type":"markdown","source":"**Feature 12 : Pressure9am**"},{"metadata":{},"cell_type":"markdown","source":"Description : Atmospheric pressure reduced to mean sea level at 9am, measured in hpa"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_values['Pressure9am']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final['Pressure9am'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"since it is a floating value, let's do binning and put this to our final_bin dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"final_bin['Pressure9am'] = pd.cut(data['Pressure9am'],bins = 5) #discretising the float numbers into categorical","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_bin['Pressure9am'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_count_dist(df= final_bin, label_column = 'RainTomorrow', target_column = 'Pressure9am', figsize = (20,10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The graph on the left provides histogram with bins for Pressure9am and the plot on left illustrates that pressure of 0-1015 hpa has more chances of RainTomorrow being 'Yes' and pressure greater the above range means target RainTomorrow being 'No'."},{"metadata":{},"cell_type":"markdown","source":"**Feature 13 : Pressure3pm**"},{"metadata":{},"cell_type":"markdown","source":"Description : Atmospheric pressure reduced to mean sea level at 3pm, measured in hpm"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_values['Pressure3pm']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final['Pressure3pm'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"since it is a floating value, let's do binning and put this to our final_bin dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"final_bin['Pressure3pm'] = pd.cut(data['Pressure3pm'],bins = 5) #discretising the float numbers into categorical\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_bin['Pressure3pm'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_count_dist(df= final_bin, label_column = 'RainTomorrow', target_column = 'Pressure3pm', figsize = (20,10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The graph on the left provides binned histogram for Humidity9am and the plot on left illustrates that pressure of 0-1012 hpa has more chances of RainTomorrow being 'Yes' and pressure greater the above range means target RainTomorrow being 'No'."},{"metadata":{},"cell_type":"markdown","source":"**Feature 14 : Temp9am**"},{"metadata":{},"cell_type":"markdown","source":"Description : Temperature at 9am, measured in degrees Celsius"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_values['Temp9am']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final['Temp9am'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"since it is a continuous value, let's do binning and put this to our final_bin dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"final_bin['Temp9am'] = pd.cut(data['Temp9am'],bins = 5) #discretising the float numbers into categorical","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_bin['Temp9am'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_count_dist(df= final_bin, label_column = 'RainTomorrow', target_column = 'Temp9am', figsize = (20,10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The graph on the left shows the binned histogram for Temp9am and we can see the most frequent temperature being in [14.22,22.88]. The right graph conveys that temperature between 7 and 15 degree Celsius mostly results in RainTomorrow being 'Yes', otherwise results in RainTomorrow being ‘No’."},{"metadata":{},"cell_type":"markdown","source":"**Feature 15 : Temp3pm**"},{"metadata":{},"cell_type":"markdown","source":"Description : Temperature at 3pm, measured in degree Celsius"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_values['Temp3pm']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final['Temp3pm'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"since it is a continuous value, let's do binning and put this to our final_bin dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"final_bin['Temp3pm'] = pd.cut(data['Temp3pm'],bins = 5) #discretising the float numbers into categorical\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_bin['Temp3pm'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_count_dist(df= final_bin, label_column = 'RainTomorrow', target_column = 'Temp3pm', figsize = (20,10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The graph on the left shows the binned histogram for Temp9am and we can see the most frequent temperature being in [19.7,28.7]. The right graph conveys that temperature between 0 and 19 degree Celsius mostly results in RainTomorrow being 'Yes'. Temperature grater than 20 degree celsius results in mostly target RainTomorrow being 'No'."},{"metadata":{},"cell_type":"markdown","source":"**Feature 16 : RainToday**"},{"metadata":{},"cell_type":"markdown","source":"Description : Precipitation of current day. Boolean: 1 if precipitation (in mm) in the 24 hours to 9am exceeds 1mm, otherwise 0"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now we will just see how many times it rained the current day?\nfig = plt.figure(figsize = (20,3))\nsns.countplot(y='RainToday', data=final);\nprint(final.RainToday.value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the graph we can know the ratio of cases where the next day is predicted as rainy day or not. The table above the graph presents frequency counts for the binary values 'Yes' and 'No' for RainToday."},{"metadata":{"trusted":true},"cell_type":"code","source":"final.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**CORRELATION MATRIX**"},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(figsize=(18, 18))\nsns.heatmap(data.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)\nplt.xticks(rotation=90)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below are the insights drawn from correlation matrix:\n*\tMinTemp and MaxTemp are highly correlated with r=0.7  \n*\tHumidity3pm and Humidity 9am are highly correlated with r=0.6  \n*\tTemp9am and MinTemp are highly correlated with r=0.9  \n*\tTemp9am and MaxTemp are highly correlated with r=0.9  \n*\tTemp3pm and MinTemp are highly correlated with r=0.6  \n*\tTemp3pm and MaxTemp are highly correlated with r=0.9  \n*\tAlso, Pressure & temperature and Humidity and temperature were negatively correlated.  "},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Now we are done with pre-processing and have a basic ides of what each features are and how they are related to the target variable RainTomorrow.\nLet's just see which are the important features to predict RainTomorrow"},{"metadata":{"trusted":true},"cell_type":"code","source":"final_bin.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's get hold of the independent variables and assign them as X\n\nX = final.loc[:, final.columns != 'RainTomorrow']\ny = final['RainTomorrow']\nX.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# PCA to find the best number of features based on explained variance for each attribute\n#Fitting the PCA algorithm with our Data\nfrom sklearn.decomposition import PCA\npca = PCA().fit(X)\n#Plotting the Cumulative Summation of the Explained Variance\nplt.figure()\nplt.plot(np.cumsum(pca.explained_variance_ratio_))\nplt.xlabel('Number of Components')\nplt.ylabel('Variance (%)') #for each component\nplt.title('WeatherAUS Dataset Explained Variance')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using SelectKBest to get the top features!\nfrom sklearn.feature_selection import SelectKBest, chi2\nselector = SelectKBest(chi2, k=40)\nselector.fit(X, y)\nX_new = selector.transform(X)\nprint(X.columns[selector.get_support(indices=True)]) #top 40 columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = final[['MaxTemp', 'Rainfall', 'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm',\n       'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Temp3pm',\n       'RainToday', 'WindGustDir_E', 'WindGustDir_ENE', 'WindGustDir_ESE',\n       'WindGustDir_N', 'WindGustDir_NNW', 'WindGustDir_NW', 'WindGustDir_W',\n       'WindGustDir_WNW', 'WindDir3pm_E', 'WindDir3pm_ENE', 'WindDir3pm_ESE',\n       'WindDir3pm_N', 'WindDir3pm_NNW', 'WindDir3pm_NW', 'WindDir3pm_SE',\n       'WindDir3pm_SW', 'WindDir3pm_W', 'WindDir3pm_WNW', 'WindDir9am_E',\n       'WindDir9am_ENE', 'WindDir9am_ESE', 'WindDir9am_N', 'WindDir9am_NNE',\n       'WindDir9am_NNW', 'WindDir9am_NW', 'WindDir9am_SE', 'WindDir9am_SSE',\n       'WindDir9am_W', 'WindDir9am_WNW']] # let's use all 40 features\ny = final[['RainTomorrow']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Split the data into train and test data\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let us start building our predictive models"},{"metadata":{},"cell_type":"markdown","source":"**Model 1 : Logistic Regression**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nimport time\nt0=time.time()\nlogreg = LogisticRegression(random_state=0, class_weight={0:0.3,1:0.7})\nlogreg = logreg.fit(X_train,y_train)\ny_predLR = logreg.predict(X_test)\nscore = accuracy_score(y_test,y_predLR)\nprint('Accuracy :',score)\nprint('Time taken :' , time.time()-t0)\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Model 2 : Decision Tree**"},{"metadata":{"trusted":true},"cell_type":"code","source":"t0=time.time()\n#X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25)\ndt = DecisionTreeClassifier(random_state=0,class_weight={0:0.3,1:0.7})\ndt.fit(X_train,y_train)\ny_predDT = dt.predict(X_test)\nscore = accuracy_score(y_test,y_predDT)\nprint('Accuracy :',score)\nprint('Time taken :' , time.time()-t0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Model 3 : RandomForest**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nt0=time.time()\nrf = RandomForestClassifier(n_estimators=100, max_depth=4,random_state=0,class_weight={0:0.3,1:0.7})\nrf.fit(X_train,y_train)\ny_predRF = rf.predict(X_test)\nscore = accuracy_score(y_test,y_predRF)\nprint('Accuracy :',score)\nprint('Time taken :' , time.time()-t0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Model 4 : BalancedBagging Classifier**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.ensemble import BalancedBaggingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n#Creating an object of the classifier.\nbbc = BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(),\n                                sampling_strategy='auto',\n                                replacement=False,\n                                random_state=0)\n\n#Training the classifier.\nbbc.fit(X_train, y_train)\ny_predBBC = bbc.predict(X_test)\nscore = accuracy_score(y_test,y_predBBC)\nprint('Accuracy :',score)\nprint('Time taken :' , time.time()-t0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **CONFUSION MATRICES**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\npred_models = []\npred_models.append(('LogisticRegression', y_predLR))\npred_models.append(('DecisionTree', y_predDT))\npred_models.append(('RandomForest', y_predRF))\npred_models.append(('BalancedBaggingClassifier', y_predBBC))\n\n\nfor name, pred_model in pred_models:\n    cm = confusion_matrix(y_test, pred_model)\n    #print(cm)\n    plt.figure(figsize = (3,3))\n    sns.heatmap(cm,fmt=\"d\",annot=True,xticklabels=[\"No\",\"Yes\"],yticklabels=[\"No\",\"Yes\"],cbar=False)\n    plt.title(name+\" \"+\"Confusion Matrix\")\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"Actuals\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RESULTS ACHIEVED:\n\n•\tAs discussed about the gaps in previous work, the kernels aimed to measure the performance of machine learning models based on accuracy and most of the model’s recall was about 50%. This meant that when it actually did rain the next day, the model was only right 50% of the time.\nIn this work, recall of score as high as 68.26 % has been achieved which means that the predictions we make when it actually did rain next day are correct 68% of the time. We can see an increase of recall score by **18.26 %**.\n\n•\tThe average accuracy obtained in the previous kernels are 85%. In this work, even though the recall score was increased, it is managed to gain an accuracy of score 82.66 %.\n\n•\tA better understanding of data has been achieved by exploratory analysis of each and every variable (all 17 features). Also, it is very clear about the relationship and variance of each of the independent variables which helps to predict the dependent variable.\n\n•\tFor Dimensionality reduction, to find out the number of best features to be included in the machine learning model was found using Principal Component Analysis (PCA), in order to get best performance. From the graph obtained, it is evident that out of 62 features (after feature engineering) 40 features had to be used to explain 90% of the variance in the target variable.\n\n•\tLogistic regression outstood as the best predictive model to predict the class labels for this dataset having the best accuracy and recall scores. It suppressed the power of ensemble models by predicting the class labels in as less as 1.34 sec when compared to the Bagging classifier which took 16 sec to predict the target class. \n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}