{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Compare various clustering algorithms on the iris dataset\n\n* **k-Means and Mini Batch k-Means**\naccuracy: 0.89 ... \nsilhouette:  0.696\n\n* **DBSCAN and Optics**\naccuracy: with 3 clusters there are 114 outliers with DBSCAN and similar w OPTICS (?!)\n\n* **Affinity Propagation**\naccuracy: 0.90 ... \nsilhouette:  0.696\n\n* **Mean Shift**\naccuracy: 0.79 ... \nsilhouette:  0.635\n\n* **Spectral Clustering**\naccuracy: 0.84 ... \nsilhouette:  0.661\n\n* **Agglomerative Clustering**\naccuracy: 0.89 ... \nsilhouette:  0.688\n\n* **Gaussian Mixture Clustering**\naccuracy: 0.97 ... \nsilhouette:  0.606\n\n* **Birch**\nfinds only 2 clusters\n\n\n* Based on https://scikit-learn.org/stable/modules/clustering.html\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np  \nimport pandas as pd \nimport matplotlib.pyplot as plt\n\nfrom sklearn.cluster import KMeans, DBSCAN, AffinityPropagation, MeanShift, estimate_bandwidth, SpectralClustering\nfrom sklearn.cluster import AgglomerativeClustering, OPTICS, cluster_optics_dbscan, Birch, MiniBatchKMeans\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn import metrics\nfrom sklearn.mixture import GaussianMixture\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"# Read dataset\n\ndf = pd.read_csv(\"../input/iris-flower-dataset/IRIS.csv\")\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('species').size().plot.bar()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.copy()\nX = X.drop('species', axis=1)\nX.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalize X\n\nmms = MinMaxScaler()\nmms.fit(X)\nXnorm = mms.transform(X)\nXnorm.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ELBOW method for finding the optimal # of clusters k"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Not knowing the number of clusters (3) we try a range such 1,10\n# For the ELBOW method check with and without init='k-means++'\n\nSum_of_squared_distances = []\nfor k in range(1,10):\n    km = KMeans(n_clusters=k, init='k-means++')\n    km = km.fit(Xnorm)\n    Sum_of_squared_distances.append(km.inertia_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(range(1,10), Sum_of_squared_distances, 'bx-')\nplt.xlabel('k')\nplt.ylabel('Sum_of_squared_distances')\nplt.title('Elbow Method For Optimal k')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Knowing from the ELBOW method that k=3 ...\n\nkmeans3 = KMeans(n_clusters=3, init='k-means++').fit(Xnorm) \n\nKM_clustered = Xnorm.copy()\nKM_clustered = pd.DataFrame(KM_clustered)\nKM_clustered.loc[:,'Cluster'] = kmeans3.labels_ # append labels to points\n\nframes = [df['species'], KM_clustered['Cluster']]\nresult = pd.concat(frames, axis = 1)\nprint(result.shape)\nresult.sample(5)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Assigning a label to each cluster\n* As there's no relation between a cluster number and the true label we need to map a cluster to the one label which appears most in that cluster\n\n* These corrected predicted labels are needed below to calculate model performance vs the the true labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"for ClusterNum in range(3):\n\n    OneCluster = pd.DataFrame(result[result['Cluster'] == ClusterNum].groupby('species').size())\n    OneCluster.columns=['Size']\n    \n    NewDigit = OneCluster.index[OneCluster['Size'] == OneCluster['Size'].max()].tolist()\n    NewDigit[0]\n\n    rowIndex = result.index[result['Cluster'] == ClusterNum]\n    result.loc[rowIndex, 'TransLabel'] = NewDigit[0]\n    \n    print(ClusterNum, NewDigit[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check performance of classification to 3 clusters\n\nprint('K-Means performance')\nprint('-'*60)\n\nCorrect = (df['species'] == result['TransLabel']).sum()\nAccuracy = round(Correct/df.shape[0],3)\nprint('Accuracy ', Accuracy)\n\n# METRICS for clustering algorithms\n\nprint('silhouette: ', round(metrics.silhouette_score(Xnorm, result['TransLabel'],metric='sqeuclidean'),3))\nprint('homogeneity_score: ', round(metrics.homogeneity_score(df['species'], result['TransLabel']),3))\nprint('completeness_score: ', round(metrics.completeness_score(df['species'], result['TransLabel']),3))\nprint('v_measure_score: ', round(metrics.v_measure_score(df['species'], result['TransLabel']),3))\nprint('adjusted_rand_score: ', round(metrics.adjusted_rand_score(df['species'], result['TransLabel']),3))\nprint('adjusted_mutual_info_score: ', round(metrics.adjusted_mutual_info_score(df['species'], result['TransLabel']),3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DBSCAN"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compute DBSCAN\n# played with eps and min samples ... till I got num clustrers = 3 and lowest number of noise (114 ?!?)\n\ndb = DBSCAN(eps=0.078).fit(Xnorm)\ncore_samples_mask = np.zeros_like(db.labels_, dtype=bool)\ncore_samples_mask[db.core_sample_indices_] = True\nlabels = db.labels_\n\n# Number of clusters in labels, ignoring noise if present.\nn_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\nn_noise_ = list(labels).count(-1)\n\nprint('Estimated number of clusters: %d' % n_clusters_)\nprint('Estimated number of noise points: %d' % n_noise_)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Affinity Propagation"},{"metadata":{"trusted":true},"cell_type":"code","source":"af = AffinityPropagation(preference=-3).fit(Xnorm)\ncluster_centers_indices = af.cluster_centers_indices_\nlabels = af.labels_\n\nn_clusters_ = len(cluster_centers_indices)\n\nprint('Estimated number of clusters: %d' % n_clusters_)\n\nClustered = Xnorm.copy()\nClustered = pd.DataFrame(Clustered)\nClustered.loc[:,'Cluster'] = af.labels_ # append labels to points\nframes = [df['species'], Clustered['Cluster']]\nresult = pd.concat(frames, axis = 1)\nfor ClusterNum in range(3):\n\n    OneCluster = pd.DataFrame(result[result['Cluster'] == ClusterNum].groupby('species').size())\n    OneCluster.columns=['Size']\n    \n    NewDigit = OneCluster.index[OneCluster['Size'] == OneCluster['Size'].max()].tolist()\n    NewDigit[0]\n\n    rowIndex = result.index[result['Cluster'] == ClusterNum]\n    result.loc[rowIndex, 'TransLabel'] = NewDigit[0]\n    \n    print(ClusterNum, NewDigit[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check performance of classification to 3 clusters\n\nprint('Affinity propagation performance')\nprint('-'*60)\n\nCorrect = (df['species'] == result['TransLabel']).sum()\nAccuracy = round(Correct/df.shape[0],3)\nprint('Accuracy ', Accuracy)\n\n# METRICS for clustering algorithms\n\nprint('silhouette: ', round(metrics.silhouette_score(Xnorm, result['TransLabel'],metric='sqeuclidean'),3))\nprint('homogeneity_score: ', round(metrics.homogeneity_score(df['species'], result['TransLabel']),3))\nprint('completeness_score: ', round(metrics.completeness_score(df['species'], result['TransLabel']),3))\nprint('v_measure_score: ', round(metrics.v_measure_score(df['species'], result['TransLabel']),3))\nprint('adjusted_rand_score: ', round(metrics.adjusted_rand_score(df['species'], result['TransLabel']),3))\nprint('adjusted_mutual_info_score: ', round(metrics.adjusted_mutual_info_score(df['species'], result['TransLabel']),3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Mean Shift"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compute clustering with MeanShift\n\n# The following bandwidth can be automatically detected using\nbandwidth = estimate_bandwidth(Xnorm, quantile=0.2) # Manually set the quantile to get num clusters = 3\n\nms = MeanShift(bandwidth=bandwidth, bin_seeding=True)\nms.fit(Xnorm)\nlabels = ms.labels_\ncluster_centers = ms.cluster_centers_\n\nlabels_unique = np.unique(labels)\nn_clusters_ = len(labels_unique)\nprint(\"number of estimated clusters : %d\" % n_clusters_)\n\nClustered = Xnorm.copy()\nClustered = pd.DataFrame(Clustered)\nClustered.loc[:,'Cluster'] = ms.labels_ # append labels to points\nframes = [df['species'], Clustered['Cluster']]\nresult = pd.concat(frames, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for ClusterNum in range(3):\n\n    OneCluster = pd.DataFrame(result[result['Cluster'] == ClusterNum].groupby('species').size())\n    OneCluster.columns=['Size']\n    \n    NewDigit = OneCluster.index[OneCluster['Size'] == OneCluster['Size'].max()].tolist()\n    NewDigit[0]\n\n    rowIndex = result.index[result['Cluster'] == ClusterNum]\n    result.loc[rowIndex, 'TransLabel'] = NewDigit[0]\n    \n    print(ClusterNum, NewDigit[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check performance of classification to 3 clusters\n\nprint('Mean shift performance')\nprint('-'*60)\n\nCorrect = (df['species'] == result['TransLabel']).sum()\nAccuracy = round(Correct/df.shape[0],3)\nprint('Accuracy ', Accuracy)\n\n# METRICS for clustering algorithms\n\nprint('silhouette: ', round(metrics.silhouette_score(Xnorm, result['TransLabel'],metric='sqeuclidean'),3))\nprint('homogeneity_score: ', round(metrics.homogeneity_score(df['species'], result['TransLabel']),3))\nprint('completeness_score: ', round(metrics.completeness_score(df['species'], result['TransLabel']),3))\nprint('v_measure_score: ', round(metrics.v_measure_score(df['species'], result['TransLabel']),3))\nprint('adjusted_rand_score: ', round(metrics.adjusted_rand_score(df['species'], result['TransLabel']),3))\nprint('adjusted_mutual_info_score: ', round(metrics.adjusted_mutual_info_score(df['species'], result['TransLabel']),3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Spectral Clustering"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compute clustering with SpectralClustering\n\nsc = SpectralClustering(n_clusters = 3)\nsc.fit(Xnorm)\nlabels = ms.labels_\n\nlabels_unique = np.unique(labels)\nn_clusters_ = len(labels_unique)\nprint(\"number of estimated clusters : %d\" % n_clusters_)\n\nClustered = Xnorm.copy()\nClustered = pd.DataFrame(Clustered)\nClustered.loc[:,'Cluster'] = sc.labels_ # append labels to points\n#Clustered.sample(5)\n\nframes = [df['species'], Clustered['Cluster']]\nresult = pd.concat(frames, axis = 1)\n#print(result.shape)\n#result.sample(5)\nfor ClusterNum in range(3):\n\n    OneCluster = pd.DataFrame(result[result['Cluster'] == ClusterNum].groupby('species').size())\n    OneCluster.columns=['Size']\n    \n    NewDigit = OneCluster.index[OneCluster['Size'] == OneCluster['Size'].max()].tolist()\n    NewDigit[0]\n\n    rowIndex = result.index[result['Cluster'] == ClusterNum]\n    result.loc[rowIndex, 'TransLabel'] = NewDigit[0]\n    \n    print(ClusterNum, NewDigit[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check performance of classification to 3 clusters\n\nprint('Spectral clustering performance')\nprint('-'*60)\n\nCorrect = (df['species'] == result['TransLabel']).sum()\nAccuracy = round(Correct/df.shape[0],3)\nprint('Accuracy ', Accuracy)\n\n# METRICS for clustering algorithms\n\nprint('silhouette: ', round(metrics.silhouette_score(Xnorm, result['TransLabel'],metric='sqeuclidean'),3))\nprint('homogeneity_score: ', round(metrics.homogeneity_score(df['species'], result['TransLabel']),3))\nprint('completeness_score: ', round(metrics.completeness_score(df['species'], result['TransLabel']),3))\nprint('v_measure_score: ', round(metrics.v_measure_score(df['species'], result['TransLabel']),3))\nprint('adjusted_rand_score: ', round(metrics.adjusted_rand_score(df['species'], result['TransLabel']),3))\nprint('adjusted_mutual_info_score: ', round(metrics.adjusted_mutual_info_score(df['species'], result['TransLabel']),3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Agglomerative Clustering\n\nsc = AgglomerativeClustering(n_clusters = 3)\nsc.fit(Xnorm)\nlabels = sc.labels_\n\nlabels_unique = np.unique(labels)\nn_clusters_ = len(labels_unique)\nprint(\"number of estimated clusters : %d\" % n_clusters_)\n\nClustered = Xnorm.copy()\nClustered = pd.DataFrame(Clustered)\nClustered.loc[:,'Cluster'] = sc.labels_ # append labels to points\n#Clustered.sample(5)\n\nframes = [df['species'], Clustered['Cluster']]\nresult = pd.concat(frames, axis = 1)\n#print(result.shape)\n#result.sample(5)\nfor ClusterNum in range(3):\n\n    OneCluster = pd.DataFrame(result[result['Cluster'] == ClusterNum].groupby('species').size())\n    OneCluster.columns=['Size']\n    \n    NewDigit = OneCluster.index[OneCluster['Size'] == OneCluster['Size'].max()].tolist()\n    NewDigit[0]\n\n    rowIndex = result.index[result['Cluster'] == ClusterNum]\n    result.loc[rowIndex, 'TransLabel'] = NewDigit[0]\n    \n    print(ClusterNum, NewDigit[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check performance of classification to 3 clusters\n\nprint('Agglomerative clustering performance')\nprint('-'*60)\n\nCorrect = (df['species'] == result['TransLabel']).sum()\nAccuracy = round(Correct/df.shape[0],3)\nprint('Accuracy ', Accuracy)\n\n# METRICS for clustering algorithms\n\nprint('silhouette: ', round(metrics.silhouette_score(Xnorm, result['TransLabel'],metric='sqeuclidean'),3))\nprint('homogeneity_score: ', round(metrics.homogeneity_score(df['species'], result['TransLabel']),3))\nprint('completeness_score: ', round(metrics.completeness_score(df['species'], result['TransLabel']),3))\nprint('v_measure_score: ', round(metrics.v_measure_score(df['species'], result['TransLabel']),3))\nprint('adjusted_rand_score: ', round(metrics.adjusted_rand_score(df['species'], result['TransLabel']),3))\nprint('adjusted_mutual_info_score: ', round(metrics.adjusted_mutual_info_score(df['species'], result['TransLabel']),3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Gaussian mixture\n\n* Tried w covariance_type='tied' acc = 0.9, 'full' DEFAULT acc = 0.97,  'diag' acc = 0.93,  'spherical' acc = 0.89"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gaussian Mixture clustering\n\nsc = GaussianMixture(n_components=3, covariance_type='full')\ny_pred = sc.fit_predict(Xnorm)\nprint(\"number of estimated clusters : %d\" % len(set(y_pred)))\n\nClustered = Xnorm.copy()\nClustered = pd.DataFrame(Clustered)\nClustered.loc[:,'Cluster'] = y_pred # append labels to points\n#Clustered.sample(5)\n\nframes = [df['species'], Clustered['Cluster']]\nresult = pd.concat(frames, axis = 1)\n#print(result.shape)\n#result.sample(5)\nfor ClusterNum in range(3):\n\n    OneCluster = pd.DataFrame(result[result['Cluster'] == ClusterNum].groupby('species').size())\n    OneCluster.columns=['Size']\n    \n    NewDigit = OneCluster.index[OneCluster['Size'] == OneCluster['Size'].max()].tolist()\n    NewDigit[0]\n\n    rowIndex = result.index[result['Cluster'] == ClusterNum]\n    result.loc[rowIndex, 'TransLabel'] = NewDigit[0]\n    \n    print(ClusterNum, NewDigit[0])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check performance of classification to 3 clusters\n\nprint('Gaussian mixture clustering performance')\nprint('-'*60)\n\nCorrect = (df['species'] == result['TransLabel']).sum()\nAccuracy = round(Correct/df.shape[0],3)\nprint('Accuracy ', Accuracy)\n\n# METRICS for clustering algorithms\n\nprint('silhouette: ', round(metrics.silhouette_score(Xnorm, result['TransLabel'],metric='sqeuclidean'),3))\nprint('homogeneity_score: ', round(metrics.homogeneity_score(df['species'], result['TransLabel']),3))\nprint('completeness_score: ', round(metrics.completeness_score(df['species'], result['TransLabel']),3))\nprint('v_measure_score: ', round(metrics.v_measure_score(df['species'], result['TransLabel']),3))\nprint('adjusted_rand_score: ', round(metrics.adjusted_rand_score(df['species'], result['TransLabel']),3))\nprint('adjusted_mutual_info_score: ', round(metrics.adjusted_mutual_info_score(df['species'], result['TransLabel']),3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Birch"},{"metadata":{"trusted":true},"cell_type":"code","source":"sc = Birch(n_clusters = 3)\nsc.fit(Xnorm)\nlabels = sc.labels_\n\nlabels_unique = np.unique(labels)\nn_clusters_ = len(labels_unique)\nprint(\"number of estimated clusters : %d\" % n_clusters_)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Mini Batch K-Means"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Mini Batch K-Means Clustering\n\nsc = MiniBatchKMeans(n_clusters = 3)\nsc.fit(Xnorm)\nlabels = sc.labels_\n\nlabels_unique = np.unique(labels)\nn_clusters_ = len(labels_unique)\nprint(\"number of estimated clusters : %d\" % n_clusters_)\n\nClustered = Xnorm.copy()\nClustered = pd.DataFrame(Clustered)\nClustered.loc[:,'Cluster'] = sc.labels_ # append labels to points\n#Clustered.sample(5)\n\nframes = [df['species'], Clustered['Cluster']]\nresult = pd.concat(frames, axis = 1)\n#print(result.shape)\n#result.sample(5)\nfor ClusterNum in range(3):\n\n    OneCluster = pd.DataFrame(result[result['Cluster'] == ClusterNum].groupby('species').size())\n    OneCluster.columns=['Size']\n    \n    NewDigit = OneCluster.index[OneCluster['Size'] == OneCluster['Size'].max()].tolist()\n    NewDigit[0]\n\n    rowIndex = result.index[result['Cluster'] == ClusterNum]\n    result.loc[rowIndex, 'TransLabel'] = NewDigit[0]\n    \n    print(ClusterNum, NewDigit[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check performance of classification to 3 clusters\n\nprint('Mini Batch K-Means clustering performance')\nprint('-'*60)\n\nCorrect = (df['species'] == result['TransLabel']).sum()\nAccuracy = round(Correct/df.shape[0],3)\nprint('Accuracy ', Accuracy)\n\n# METRICS for clustering algorithms\n\nprint('silhouette: ', round(metrics.silhouette_score(Xnorm, result['TransLabel'],metric='sqeuclidean'),3))\nprint('homogeneity_score: ', round(metrics.homogeneity_score(df['species'], result['TransLabel']),3))\nprint('completeness_score: ', round(metrics.completeness_score(df['species'], result['TransLabel']),3))\nprint('v_measure_score: ', round(metrics.v_measure_score(df['species'], result['TransLabel']),3))\nprint('adjusted_rand_score: ', round(metrics.adjusted_rand_score(df['species'], result['TransLabel']),3))\nprint('adjusted_mutual_info_score: ', round(metrics.adjusted_mutual_info_score(df['species'], result['TransLabel']),3))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}