{"cells":[{"metadata":{"_uuid":"3ee7d3b409f59cd02b6c29f9fc229b688026559b"},"cell_type":"markdown","source":"# 智能手机的人类活动识别 (Tensorflow) "},{"metadata":{"_uuid":"67be7f369b0b262127a542f17607b1a010e70dd7"},"cell_type":"markdown","source":"人类活动识别数据库是根据30名参加日常生活活动（ADL）的研究参与者的录音资料建立的，同时携带了带有嵌入式惯性传感器的腰挂式智能手机。目标是将活动分类为所执行的六项活动之一。\n\n### 实验描述\n\n这项实验是在一组年龄在19-48岁之间的30名志愿者中进行的。每个人在腰上佩戴智能手机（三星Galaxy S II）进行了六项活动（步行，步行，用餐，步行，坐，站立，放置）。使用嵌入式加速度计和陀螺仪，我们以50Hz的恒定速率捕获3轴线性加速度和3轴角速度。这些实验已经过视频记录以手动标记数据。所获得的数据集已被随机分成两组，其中70％的志愿者被选中用于生成训练数据和30％的测试数据。\n\n传感器信号（加速度计和陀螺仪）通过应用噪声滤波器进行预处理，然后在2.56秒和50％重叠（128个读数/窗口）的固定宽度滑动窗口中进行采样。具有重力和身体运动分量的传感器加速度信号通过巴特沃斯低通滤波器分离成体加速度和重力。假定重力仅具有低频分量，因此使用具有0.3Hz截止频率的滤波器。从每个窗口，通过计算来自时间和频率域的变量获得特征向量。"},{"metadata":{"_uuid":"6f03a90b855c0a7f47cbd9bfb657e68cd33d1f1d"},"cell_type":"markdown","source":"## Import Libraries and dataset"},{"metadata":{"_cell_guid":"fb9a25bb-348f-44fb-9c01-d43abd1194e6","_uuid":"fab2d73031681c928648f63be6244cd32d74b1af","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.manifold import TSNE\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import rgb2hex\nfrom matplotlib.cm import get_cmap\n\n# 使用plotly  交互式图表\nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.graph_objs as go\ninit_notebook_mode(connected=True)\n\nimport pdb\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"09fdfd51ef1e81bcdcaec7cec6a0bb7a52ce0e1a","collapsed":true,"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/train.csv\") # (7352, 563)\ntest = pd.read_csv(\"../input/test.csv\") # (2947, 563)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"69c6afb5f8f61e647457447332050accfd664091","trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dd23c96493a6eb5bab2752a48487eef1aaf252b8"},"cell_type":"markdown","source":"## Preprocessing"},{"metadata":{"_uuid":"84de79f5de387fb9c21a876050fa01cfe1f730a1"},"cell_type":"markdown","source":"Random shuffle the dataset, because the raw dataset have the data from same subject & activities grouped together. "},{"metadata":{"_uuid":"91435715d2c0d6954275784454e30e9586f6ef74","collapsed":true,"trusted":true},"cell_type":"code","source":"train = train.sample(frac=1)\ntest = test.sample(frac=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fb99c519a8e01332492a9e2dd96806b292f40ba8"},"cell_type":"markdown","source":"Drop the last two columns:'subject' and 'Activity', the 'Activity' is our target label"},{"metadata":{"_uuid":"7ca45cc02b3a3dd1301cb555e47d7965125f1250","collapsed":true,"trusted":true},"cell_type":"code","source":"Y_train = train.Activity\ntrain = train.drop(['Activity','subject'], axis=1) #(7352, 561)\n\nY_test = test.Activity\ntest = test.drop(['Activity','subject'], axis=1) #(2947, 561)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b1c10d076132d836cdf99a982e2a31b080194d44"},"cell_type":"markdown","source":"## Labels Distributed"},{"metadata":{"trusted":true,"_uuid":"bdd46a7246b874179cfd544ea21d3c2c51eac200"},"cell_type":"code","source":"# Plotting data\nlabel_counts = Y_train.value_counts()\n\n# Get colors\nn = label_counts.shape[0]\ncolormap = get_cmap('summer')\ncolors = [rgb2hex(colormap(col)) for col in np.arange(0, 1.01, 1/(n-1))]\n\n# Create plot\ndata = go.Bar(x = label_counts.index,\n              y = label_counts,\n              marker = dict(color = colors))\n\nlayout = go.Layout(title = 'Smartphone Activity Label Distribution',\n                   xaxis = dict(title = 'Activity'),\n                   yaxis = dict(title = 'Count'))\n\nfig = go.Figure(data=[data], layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"685ad9dc5c937de67cdc80a9aa7e5ca83bca5627"},"cell_type":"markdown","source":"## KMeans cluster"},{"metadata":{"_uuid":"c456b07608fbcac905db66f4ac537edded557e89","collapsed":true,"trusted":true},"cell_type":"code","source":"# initit the centroid\ndef generate_initial_centroid(samples, num_cluster):\n  '''\n  This is the first step of K-means. \n  samples: tensor (num_samples, num_features)\n  num_cluster: K, number of clusters.\n  \n  '''\n  num_samples = tf.shape(samples)[0]\n  random_indices = tf.random_shuffle(tf.range(0, num_samples))\n  centroid_indices = tf.slice(random_indices, [0], [num_cluster])\n  init_centroid = tf.gather(samples, centroid_indices)\n  \n  return init_centroid\n  ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1a2042d6e25690335bb5594a7f792393886459c8"},"cell_type":"markdown","source":"*Test the initial cluster generating function*"},{"metadata":{"_uuid":"b8315ccbe693eb8d5de767e1c46c9adccaee7b74","trusted":true},"cell_type":"code","source":"init_test = train.iloc[:1500].values\n\ninit_placeholder = tf.placeholder(tf.float32, [1500, 561])\ninit_res = generate_initial_centroid(init_placeholder, 6)\nwith tf.Session() as sess:\n  init_centroid = sess.run(init_res, feed_dict={init_placeholder:init_test})\n  \nprint(\"The expected shape is (6, 561) and the generated shape is {0}\".format(init_centroid.shape))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2ab3b7aaf910dd8a11b1b6c363d168e1e1a2d20b"},"cell_type":"markdown","source":"### Assgin each sample to its nearest centroid"},{"metadata":{"_uuid":"a6f4abff2e23da8f8ab9a8cba9930ac121d2d0a1","trusted":true},"cell_type":"code","source":"# Check broadcasting rules. \n\na = np.array([[[1,2,3],[4,5,6]]]) # (1,2,3) -- (1, num_samples, num_features)\nb = np.array([[[1,1,1]],[[4,4,4]]]) # (2,1,3) -- (num_centroids, 1, num_features)\nprint(\"The result of a - b is \\n{0}\".format(a - b))\nprint(\"The shape of a - b is {0}\".format((a-b).shape))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a7c74b8cb53cb2b750f11637f73e8efae253e7f3","collapsed":true,"trusted":true},"cell_type":"code","source":"def assign_to_nearest(samples, centroids):\n  \"\"\"\n  This function assign each sample to its nearest centroid. \n  samples: tensor, (num_samples, num_features)\n  centroids: tensor, (num_centroids, num_features)\n  \"\"\"\n  expend_samples = tf.expand_dims(samples, 0) # samples become (1, num_samples, num_features)\n  expend_centroid = tf.expand_dims(centroids, 1) # centroid become (num_centroid, 1, num_features)\n  \n  ## each entry represents how far a sample to a centroid. \n  distances = tf.reduce_sum(tf.square(tf.subtract(expend_samples, expend_centroid)), 2) # distance: (num_centroid, num_samples)\n  \n  ## which centorid each sample is assigned to. \n  nearest_index = tf.argmin(distances, 0) # nearest_index:(num_samples)\n  \n  return nearest_index","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fc1bbf3dc3fca6e1e791df54b9b232e3fe3d65de","trusted":true},"cell_type":"code","source":"assign_samples = tf.constant(np.array([[1,2,3],[4,5,6]]))\nassign_centroid = tf.constant(np.array([[1,1,1],[4,4,4]]))\nwith tf.Session() as sess:\n  assign_nearest_index = assign_to_nearest(assign_samples, assign_centroid)\n  assign_res = sess.run(assign_nearest_index)\n\nprint(\"The expected output is (0,1), and the actual output is {0}\".format(assign_res))\nprint(\"The first sample (1,2,3) should be assigned to centroid (1,1,1)\")\nprint(\"The second sample (4,5,5) should be assigned to centroid (4,4,4)\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"62b2a92cc76ba43c8cc89fe9961b659d7431b74a"},"cell_type":"markdown","source":"### Get new centroids by averaging out the assignment."},{"metadata":{"_uuid":"331399343098832740992c00ef9c2edb4e1f7f2f","collapsed":true,"trusted":true},"cell_type":"code","source":"def update_centroid(samples, nearest_index, num_clusters):\n  \"\"\"\n  samples: tensor, (num_samples, num_features)\n  nearest_index: tensor, (num_samples)\n  num_clusters: int\n  \"\"\"\n  \n  nearest_index = tf.to_int32(nearest_index)\n  partitions = tf.dynamic_partition(samples, nearest_index, num_clusters)\n  new_centroids = tf.concat([tf.reduce_mean(partition, 0, keep_dims=True) for partition in partitions], axis=0)\n  \n  return new_centroids, nearest_index","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d4af9a907efe43c31a1667b64b122f1267964d29"},"cell_type":"markdown","source":"*Test the update function*"},{"metadata":{"_uuid":"b1848aa7738c57477034fb58e95f4a1ba7ba125c","trusted":true},"cell_type":"code","source":"# Test the function: update_centroid.\nwith tf.Session() as sess:\n  new_cent, _ = update_centroid(assign_samples, assign_res, 2)\n  update_res = sess.run(new_cent)\n  \nprint(\"The expected new centroids are (1,2,3), (4,5,6)\")\nprint(\"The actual new centroids are \\n{0}\".format(update_res))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c5717332b2af9a0421bddd5c44006570b540ca21"},"cell_type":"markdown","source":"### Run the K-means algorithm"},{"metadata":{"_uuid":"100303ba13d9cf325f179cb3b867017cccd1afdb","collapsed":true,"trusted":true},"cell_type":"code","source":"k_means_placeholder = tf.placeholder(tf.float32, shape=(7352, 561))\nupdated_centroids = tf.placeholder(tf.float32, shape=(6, 561))\n\ninit_centroids = generate_initial_centroid(k_means_placeholder, num_cluster=6)\n\n\nnearest_index = assign_to_nearest(k_means_placeholder,updated_centroids)\nupdated_centroid = update_centroid(k_means_placeholder, nearest_index, 6)\n\nwith tf.Session() as sess:\n  centroids = sess.run(init_centroids, feed_dict={k_means_placeholder:train})\n  for i in range(0, 300):\n    \n    centroids,nearest_index = sess.run(updated_centroid, feed_dict={k_means_placeholder:train,\n                                                         updated_centroids:centroids})\n    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"721269103cb1b1fb64f626e4ae8b7553353ecfa9","trusted":true},"cell_type":"code","source":"print(nearest_index)\nprint(Y_train.values)\n\ntsne_data = train.copy()\nscl = StandardScaler()\ntsne_data = scl.fit_transform(tsne_data)\n\ntsne = TSNE(random_state=3)\ntsne_transformed = tsne.fit_transform(tsne_data)\n\n# Get colors\nn = label_counts.shape[0]\ncolormap = get_cmap('viridis')\ncolors = [rgb2hex(colormap(col)) for col in np.arange(0, 1.01, 1/(n-1))]\n\nplt.figure(figsize=(20,15))\n\nfor i, group in enumerate(label_counts.index):\n    # Mask to separate sets\n    mask = (nearest_index==i)\n    plt.scatter(x=tsne_transformed[mask][:,0], y=tsne_transformed[mask][:,1], c=colors[i], alpha=0.5, label=group)\n\nplt.title('KMeans Cluster Visualisation')\nplt.show()\n    \npd.crosstab(nearest_index, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8e611a086838d80e419148541b171742a4f87fab"},"cell_type":"markdown","source":"## Plot Activities"},{"metadata":{"trusted":true,"_uuid":"7ef26b116ea12a0f60293089c4739a1d6e253cbe"},"cell_type":"code","source":"### Plot Activities\n# Get colors\nn = label_counts.shape[0]\ncolormap = get_cmap('viridis')\ncolors = [rgb2hex(colormap(col)) for col in np.arange(0, 1.01, 1/(n-1))]\n\nplt.figure(figsize=(20,15))\n\nfor i, group in enumerate(label_counts.index):\n    # Mask to separate sets\n    mask = (Y_train==group).values\n    plt.scatter(x=tsne_transformed[mask][:,0], y=tsne_transformed[mask][:,1], c=colors[i], alpha=0.5, label=group)\nplt.title('TSNE Activity Visualisation')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"be52ee00f079a305eba5370edef47735866b13a1"},"cell_type":"markdown","source":"Take out message:\n\n1) We can see that basically walking activities are separated out from the passive activities. Cluster 0 and Cluster 3 are filled with walking activities, while the rest clusters represent the passive activities. \n\n2) Cluster 0 has more 'walking' and 'walking upstairs' in it, while majority of samples of cluster 3 are 'walking downstairs'. That means 'walking downstairs' are easier to separate out from the other two, while the 'walking' and 'walking upstair' are very easy to get mixed.\n\n3) Cluster 2 and 5 are filled with 'laying', and cluster 1 and 4 are filled with sitting and standing. Laying is clearly easier to distinguished from the other two. And it seems that k-means algorithm has difficulites identifying sitting and standing. "},{"metadata":{"_uuid":"b40dfc768c3b6ae0df51260a452532c41db4b8b6"},"cell_type":"markdown","source":"## Neural Network Model"},{"metadata":{"_uuid":"5bd46b8c149ce3ab31efdc0e998fc9f424983ec9"},"cell_type":"markdown","source":"One-hot encoded our target label"},{"metadata":{"_uuid":"0ea2129f7e155ab18a65949609a6e709f7346649","trusted":true},"cell_type":"code","source":"Y_train = pd.get_dummies(Y_train)\nY_test = pd.get_dummies(Y_test)\n\ntrain = train.as_matrix()\ntest = test.as_matrix()\n\nY_train = Y_train.as_matrix()\nY_test = Y_test.as_matrix()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"70eb03913c4dfb9b87f92631e4c5380535dabba8","collapsed":true,"trusted":true},"cell_type":"code","source":"FEATURE_DIM = 561\nLEARNING_RATE = 0.001\nLABEL_DIM = 6\nBATCH_SIZE = 64\nNUM_EPOCH = 100","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d37a84f9dcc6a6f3f2dc71c96b43fd8f35cbfa4c"},"cell_type":"markdown","source":"### Network Object"},{"metadata":{"_uuid":"6f3e9236d1c73861f9777c56c2552195b9722f74","collapsed":true,"trusted":true},"cell_type":"code","source":"class Neural_Network():\n  \n  def __init__(self, feature_dim = FEATURE_DIM, label_dim = LABEL_DIM):\n    self.feature_dim = feature_dim\n    self.label_dim = label_dim\n    \n    \n  def build_network(self, learning_rate=LEARNING_RATE):\n    \n    self.train_X = tf.placeholder(tf.float32, [None, self.feature_dim])\n    self.train_Y = tf.placeholder(tf.float32, [None, self.label_dim])\n    \n    self.layer_1 = self.dense_layer(self.train_X, self.feature_dim, \n                                    1024, activation=tf.nn.relu, name='layer_1')\n    self.layer_2 = self.dense_layer(self.layer_1, 1024, 512, \n                                   activation=tf.nn.relu, name='layer_2')\n    self.layer_3 = self.dense_layer(self.layer_2, 512, 64, \n                                   activation=tf.nn.relu, name='layer_3')\n    self.output = self.dense_layer(self.layer_3, 64, 6, name='output')\n    \n    self.loss = tf.reduce_mean(\n        tf.nn.softmax_cross_entropy_with_logits(logits=self.output, labels = self.train_Y))\n    \n    self.optimizer = tf.train.AdamOptimizer(learning_rate)\n    \n    self.train_step = self.optimizer.minimize(self.loss)\n    \n    self.accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(self.output,1), \n                                                    tf.argmax(self.train_Y, 1)),'float'))\n    \n  def dense_layer(self, inputs, input_size, output_size, name, activation=None):\n    \n    W = tf.get_variable(name=name+'_w',shape=(input_size, output_size), \n                        initializer=tf.contrib.layers.xavier_initializer())\n    b = tf.get_variable(name=name+'_b', shape=(output_size))\n    out = tf.matmul(inputs, W) + b\n    \n    if activation:\n      return activation(out)\n    else:\n      return out\n    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"486c3025c54ff57fbc8489cf88b8503c52d75098"},"cell_type":"markdown","source":"### Data Object"},{"metadata":{"_uuid":"c500c9eaec7d560d908d7f96e858446efd51fe42","collapsed":true,"trusted":true},"cell_type":"code","source":"class Data():\n  \n  def __init__(self, train_X, train_Y, batch_size=BATCH_SIZE):\n    \n    self.train_X = train_X\n    self.train_Y = train_Y\n    self.batch_size = batch_size\n    self.num_batch = self.train_X.shape[0]//batch_size\n    \n  def generate_batch(self):\n    \n    for i in range(self.num_batch):\n      \n      x = self.train_X[(i*self.batch_size):(i+1)*self.batch_size, :]\n      y = self.train_Y[(i*self.batch_size):(i+1)*self.batch_size]\n      \n      yield x, y \n    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6fab212879e1cf23694e45f25fa755910e9922ee"},"cell_type":"markdown","source":"### Training Object"},{"metadata":{"_uuid":"e292eed3cbf7fed5ca3378a8424c3d8e10fa4c64","collapsed":true,"trusted":true},"cell_type":"code","source":"class Learn():\n  \n  def __init__(self, train_X, train_Y, test_X, test_Y, \n               batch_size=BATCH_SIZE, epoch = NUM_EPOCH):\n    \n    self.batch_size = batch_size\n    self.epoch = epoch\n    \n    self.network = Neural_Network()\n    self.network.build_network(learning_rate=0.001)\n    self.data = Data(train_X, train_Y, self.batch_size)\n    self.test_X = test_X\n    self.test_Y = test_Y\n  \n  def run_training(self):\n    init = tf.initialize_all_variables()\n    \n    with tf.Session() as sess:\n      \n      sess.run(init)\n      \n      training_loss = []\n      counter, tmp_loss = 0, 0\n      \n      for i in range(self.epoch):\n        \n        for x, y in self.data.generate_batch():\n          \n          feed_dict = {self.network.train_X:x, self.network.train_Y:y}\n        \n          _, loss = sess.run([self.network.train_step, self.network.loss], \n                             feed_dict=feed_dict)\n          \n          if counter % 100 == 0 and counter!=0:\n            training_loss.append(tmp_loss/100)\n            tmp_loss = 0\n          else:\n            tmp_loss += loss\n            \n          counter += 1\n          \n        print(\"Epoch {0}, loss is {1}\".format(i, loss))\n        \n        \n        \n      self.training_loss = training_loss\n      acc = sess.run([self.network.accuracy], feed_dict={self.network.train_X:self.test_X,\n                                                        self.network.train_Y:self.test_Y})\n      print(\"The testing accuracy is {0}\".format(acc))\n      \n  def plot_training_loss(self):\n    plt.plot(self.training_loss)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"930b20483d81f760a3d5a8e746b08838eb106cc9","trusted":true},"cell_type":"code","source":"tf.reset_default_graph()\n\nlearner = Learn(train, Y_train, test, Y_test, epoch=NUM_EPOCH)\nlearner.run_training()\nlearner.plot_training_loss()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"385bd275675f55845e1b861fcfc9ef861abde99d","collapsed":true},"cell_type":"markdown","source":"可见，随着Epoch增加，loss值快速降低并逐渐趋向稳定，训练效果良好，最后在测试集的准确值为95%左右。"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"de2c3480bcf9a695a892fc062409b908f92f48c6"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}