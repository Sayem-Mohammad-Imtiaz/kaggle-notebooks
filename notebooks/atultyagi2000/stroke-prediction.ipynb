{"cells":[{"metadata":{},"cell_type":"markdown","source":"Importing requirements"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.model_selection import train_test_split\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Read data from csv"},{"metadata":{"trusted":true},"cell_type":"code","source":"data=pd.read_csv('../input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Drop unnecessary index"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(\"id\",axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Visualize the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# data plot function\ndef plot_bar(temp1):\n    for temp in temp1:\n        data_temp=data[[temp,'stroke']].groupby([temp] , as_index=False).mean().sort_values(by='stroke', ascending=False)\n        plt.bar(data_temp[temp],data_temp.stroke)\n        plt.ylabel('stroke')\n        plt.xlabel(temp)\n        plt.subplot()\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_bar([\"gender\",'work_type','Residence_type','smoking_status','ever_married','heart_disease','hypertension'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fin all the catagorical data"},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical = (data.dtypes == \"object\")\ncategorical_list = list(categorical[categorical].index)\nprint(categorical_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gender_encode=LabelEncoder()\nmarried_encode=LabelEncoder()\nwork_type_encode=LabelEncoder()\nResidence_type_encode=LabelEncoder()\nsmoking_status_encode=LabelEncoder()\ndata['gender']=gender_encode.fit_transform(data['gender'])\ndata['ever_married']=married_encode.fit_transform(data['ever_married'])\ndata['work_type']=work_type_encode.fit_transform(data['work_type'])\ndata['Residence_type']=Residence_type_encode.fit_transform(data['Residence_type'])\ndata['smoking_status']=smoking_status_encode.fit_transform(data['smoking_status'])\ndata.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(19,12)) \nsns.heatmap(data.corr(), annot=True, cmap='Dark2_r', linewidths = 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"FIND NULL VALUES"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"REPLACE NULL VAUES"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['bmi'] = data['bmi'].fillna(0)\ndata1=data[data['bmi']!=0]\ndata2=data[data['bmi']==0]\ntemp1_Y=data1['bmi']\ntemp1_X=data1.drop(['bmi'] , axis=1)\ntemp2_Y=data2['bmi']\ntemp2_X=data2.drop(['bmi'] , axis=1)\n\nsk=StandardScaler()\ntemp1_X = sk.fit_transform(temp1_X)\ntemp2_X = sk.transform(temp2_X)\n\nfrom sklearn.ensemble import RandomForestRegressor\nmod=RandomForestRegressor()\n\nmod.fit(temp1_X,temp1_Y)\npred=mod.predict(temp2_X)\n\nk=0\nfor i in range(len(data['bmi'])):\n    if(data['bmi'][i]==0.0):\n        data['bmi'][i]=pred[k]\n        k=k+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ROUND OFF THE AGE"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['age'] = data['age'].apply(lambda x : round(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**FIND BEST MODEL**"},{"metadata":{"trusted":true},"cell_type":"code","source":"Y = data[\"stroke\"]\nX=data.drop(['stroke'] , axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class evaluate_all_model:\n    from sklearn.model_selection import train_test_split\n    from sklearn.linear_model import LinearRegression\n    from sklearn.neighbors import KNeighborsClassifier\n    from sklearn.linear_model import LogisticRegression\n    from sklearn.tree import DecisionTreeClassifier\n    from sklearn.ensemble import RandomForestClassifier\n    from sklearn.svm import SVC\n    from sklearn.naive_bayes import GaussianNB\n    from sklearn.naive_bayes import MultinomialNB\n    from sklearn.naive_bayes import BernoulliNB\n    from sklearn.naive_bayes import CategoricalNB\n    from sklearn.cluster import KMeans\n    from sklearn.ensemble import GradientBoostingClassifier\n    from sklearn.preprocessing import StandardScaler\n    from xgboost import XGBClassifier\n    from sklearn.metrics import confusion_matrix, accuracy_score\n    from sklearn.model_selection import train_test_split\n\n    import time\n    def __init__(self,x,y):\n        self.x=x\n        self.y=y\n        self.train_test_split()\n        self.define_models()\n        self.evaluate_model()\n        print(\"best model base on Accuracy\")\n        print(self.best_model)\n        \n    def train_test_split(self):\n        self.X_train, self.X_test, self.y_train,self.y_test = train_test_split(self.x, self.y, test_size=0.33, random_state=3)\n        sc=StandardScaler()\n        self.X_train = sc.fit_transform(self.X_train)\n        self.X_test = sc.transform(self.X_test)\n    def define_models(self):\n        self.models={'LogisticRegression': self.LogisticRegression(),\n    'RandomForestClassifier': self.RandomForestClassifier(),\n     'KNeighborsClassifier': self.KNeighborsClassifier(),\n    'DecisionTreeClassifier': self.DecisionTreeClassifier(),\n    'SupportVectorMachine':self.SVC(),\n    'GaussianNB': self.GaussianNB(),\n    'BernoulliNB': self.BernoulliNB(),\n    'GradientBoostingClassifier': self.GradientBoostingClassifier()\n                    }\n        \n        self.modelNames =['LogisticRegression', 'RandomForestClassifier','KNeighborsClassifier','DecisionTreeClassifier','SupportVectorMachine',\n                         'GaussianNB','BernoulliNB','GradientBoostingClassifier']\n        self.trainScores = []\n        self.testScores = []\n        self.Time_taken=[]\n        self.best_model_score=0\n        self.best_model={}\n        self.less_time=123\n        \n        \n    def evaluate_model(self):\n        for i in self.models:\n            start = self.time.time()\n            \n            model=self.models[i]\n            model.fit(self.X_train,self.y_train)\n            train_score = model.score(self.X_train, self.y_train)\n            self.trainScores.append(train_score)\n            print(f'Model:- {i}')\n            print(f'training score:- {train_score}')\n            test_score = model.score(self.X_test, self.y_test)\n            self.testScores.append(test_score)\n            print(f'test Score:- {test_score}')\n            \n            y_predictions = model.predict(self.X_test)\n            conf_matrix = confusion_matrix(y_predictions, self.y_test)\n            print(f'Confussion Matrix: \\n{conf_matrix}\\n')\n            \n            tn = conf_matrix[0,0]\n            fp = conf_matrix[0,1]\n            tp = conf_matrix[1,1]\n            fn = conf_matrix[1,0]\n            accuracy  = (tp + tn) / (tp + fp + tn + fn)\n            precision = tp / (tp + fp)\n            recall    = tp / (tp + fn)\n            f1score  = 2 * precision * recall / (precision + recall)\n            specificity = tn / (tn + fp)\n            print(f'Accuracy : {accuracy}')\n            print(f'Precision: {precision}')\n            print(f'Recall   : {recall}')\n            print(f'F1 score : {f1score}')\n            print(f'Specificity : {specificity}')\n\n            end = self.time.time()\n            time_taken=end-start\n            self.Time_taken.append(time_taken)\n            print(f'Time required {end-start}')\n            print(\"***************************************************************************\")\n            print(\"____________________________________________________________________________\")\n            print(\"\\n\\n\\n\")\n            if(float(test_score)>self.best_model_score):\n                self.best_model[\"model Name\"]=i\n                self.best_model[\"Time Required on train and test\"]=time_taken\n                self.best_model[\"Accuracy on train data\"]=train_score\n                self.best_model[\"Accuracy on test data\"]=accuracy\n                self.best_model_score=test_score\n                \n            if(time_taken<self.less_time):\n                self.less_time=time_taken\n    def plot_bar(self):\n        plt.bar(np.arange(len(self.trainScores)), self.trainScores, color='blue', width=0.25, edgecolor='white', label='train')\n        plt.bar([x + 0.25 for x in np.arange(len(self.trainScores))], self.testScores, color='red', width=0.25, edgecolor='white', label='Test')\n        plt.xlabel('Models', fontweight='bold', size = 24)\n        plt.ylabel('Scores', fontweight='bold', size = 24)\n        plt.xticks([r - 0.25 for r in range(len(self.trainScores))], self.modelNames, rotation = 60)\n        plt.legend()\n        plt.show()\n    def get_data(self):\n        self.temp_dict={}\n        self.temp_dict[\"Model\"]=self.modelNames\n        self.temp_dict[\"Training Score\"]=self.trainScores\n        self.temp_dict[\"Accuracy on Test\"]=self.testScores\n        self.temp_dict[\"Time Taken\"]=self.Time_taken\n        return self.temp_dict   \n    def get_dataframe(self):\n        return pd.DataFrame.from_dict(self.get_data()) \n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"atul=evaluate_all_model(X,Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"atul.get_dataframe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"atul.plot_bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}