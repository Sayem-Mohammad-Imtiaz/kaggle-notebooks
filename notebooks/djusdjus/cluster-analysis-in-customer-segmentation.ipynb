{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Importing packages and dataset","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nfrom mpl_toolkits.mplot3d import axes3d\nplt.style.use('ggplot')\nfrom sklearn.cluster import KMeans, AgglomerativeClustering\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import silhouette_samples, silhouette_score, pairwise_distances\nimport scipy.cluster.hierarchy as sch\nimport scipy.stats as stats","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(16)\n# importing dataset\n\ndf = pd.read_csv(\"../input/customer-segmentation-tutorial-in-python/Mall_Customers.csv\")\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# making dataframe of numerical variables\nnv = df.iloc[:,[2,3,4]]\n\n# basic descriptive statistics\nnv.describe().round(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Boxplots of numerical variables","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (10,7))\n\nnv.boxplot(fontsize = 12, color = \"blue\")\n\nax.set(title = \"Boxplots\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that there is a potentional outlier that is out of the box for our varibale *Annual income (k$)*.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Data visualisation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,7))\n\nax.scatter(df[\"Age\"], df[\"Annual Income (k$)\"], c = \"blue\")\n\nax.set(title = \"Scatterplot 1\", xlabel = \"Age\", ylabel = \"Annual Income (k$)\");\n\nax.set_xlim(0,80)\nax.set_ylim(0,140);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From this scatterplot with variables *Age* and *Annual Income(k$)* we can't really notice any potentional clusters that differ significantly","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (10,7))\n\nax.scatter(df[\"Annual Income (k$)\"], df[\"Spending Score (1-100)\"], c = \"blue\")\n\nax.set(title = \"Scatterplot 2\", xlabel = \"Annual Income (k$)\", ylabel = \"Spending Score (1-100)\");\n\nax.set_xlim(0,140)\nax.set_ylim(0,100);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From this scatterplot with variables *Age* and *Spending score(1-100)* we can notice about 5 potentional clusters:\n1. cluster with high spending score and low annual income\n2. cluster with high spending score and high annual income\n3. cluster with mid range spending score and mid range income\n4. cluster with low spending score and low annual income\n5. cluster with low spending score and high annual income","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (10,7))\n\nax.scatter(df[\"Age\"],df[\"Spending Score (1-100)\"], c = \"blue\")\n\nax.set(title = \"Scatterplot 3\", xlabel = \"Age\", ylabel = \"Spending Score (1-100)\");\n\nax.set_xlim(0,80)\nax.set_ylim(0,100);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From this scatterplot with variables *Age* and *Spending score(1-100)* we can notice about 3 potentional clusters:\n1. cluster with younger customers and higher spending score\n2. cluster with older customers and mid range spending score\n3. cluster with older customers and low spending score","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (15,14))\nax = fig.add_subplot(111, projection='3d')\n\nax.set(title = \"3D Scatterplot 1\", xlabel = \"Age\", ylabel = \"Annual Income (k$)\", zlabel = \"Spending Score (1-100)\")\n\nx = nv[\"Age\"]\ny = nv[\"Annual Income (k$)\"]\nz = nv[\"Spending Score (1-100)\"]\n\nax.scatter(x,y,z, marker=\"o\", c = \"blue\", s=150, edgecolors= \"black\");\n\nax.view_init(30, 45)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Standardization and outliers\n\nPerforming standardization of numerical variables","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler().fit(nv)\nstd = scaler.transform(nv)\n\ndf_std = pd.DataFrame(std)\n\ndf_std.rename(columns = {0:\"Std Age\", \n                         1:\"Std Annual Income (k$)\", \n                         2: \"Std Spending Score (1-100)\"}, inplace = True)\n\ndf_2 = pd.concat([df,df_std], axis = 1)\ndf_2.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Outliers\nWhen i made boxplots of out variables, we saw that we had one potentional outlier for our variable *Annual Inocme*. We can now see if there is an outlier by looking at standardized values of our variables. If we see data point that goes above value of absolute 3, then we know that it is outlier. We can now find min and max of our varibale *Std Annual Income (k$)* and see if there is outlier.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_std[\"Std Annual Income (k$)\"].min() , df_std[\"Std Annual Income (k$)\"].max()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that min and max values are below the absolute 3 and we conclude we don't have outliers.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Elbow method","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"wcss = []\n\nfor i in range(1,10):\n    km = KMeans(n_clusters=i)\n    km.fit(df_std)\n    wcss.append(km.inertia_)\n    \ndf_wcss = pd.DataFrame(wcss).rename(columns = {0:\"WCSS\"})\ndf_wcss[\"Number of Clusters\"] = pd.DataFrame([i for i in range(1,10)])\ndf_wcss[\"Change %\"] = df_wcss[\"WCSS\"].pct_change()\ndf_wcss = df_wcss[[\"Number of Clusters\", \"WCSS\", \"Change %\"]].round(4)\ndf_wcss","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From dataframe we can see that the biggest diffrences are between 4th and 5th cluster, then 2nd and 3rd. It is hard to say which should we take as optimal cluster number. I decided for number 4. Also in the next line we can se a graphical representation of it.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (10,7))\n\nax.plot(df_wcss[\"Number of Clusters\"], wcss, c = \"blue\")\n\nax.set(title= \"Elbow method\", ylabel = \"WCSS\", xlabel = \"Number of Clusters\")\n\nax.set_xlim(0,9)\nax.set_ylim(0,600);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Silhouette analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = []\n\nn_clusters = [2, 3, 4, 5, 6, 7, 8, 9]\n\nfor n in n_clusters:\n    fig, (ax1, ax2) = plt.subplots(1, 2)\n    fig.set_size_inches(18, 7)\n\n   \n    ax1.set_xlim([-0.2, 1])\n    ax1.set_ylim([0, len(df_std) + (n + 1) * 10])\n\n    clusterer = KMeans(n_clusters = n, random_state=10)\n    cluster_labels = clusterer.fit_predict(df_std)\n\n\n    silhouette_avg = silhouette_score(df_std, cluster_labels)\n    print(\"For n  number of clusters =\", n,\n          \"Average silhouette score is: \", silhouette_avg)\n    scores.append(silhouette_avg)\n\n    sample_silhouette_values = silhouette_samples(df_std, cluster_labels)\n\n    y_lower = 10\n    for i in range(n):\n        ith_cluster_silhouette_values = \\\n            sample_silhouette_values[cluster_labels == i]\n\n        ith_cluster_silhouette_values.sort()\n\n        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n        y_upper = y_lower + size_cluster_i\n\n        color = cm.nipy_spectral(float(i) / n)\n        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n                          0, ith_cluster_silhouette_values,\n                          facecolor=color, edgecolor=color, alpha=0.7)\n\n        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n\n        y_lower = y_upper + 10  \n\n    ax1.set_title(\"Silhouette graph for various cllusters\")\n    ax1.set_xlabel(\"Silhouette coefficient\")\n    ax1.set_ylabel(\"Cluster\")\n\n    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n\n    ax1.set_yticks([])  \n    ax1.set_xticks([-0.2,-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n\n    colors = cm.nipy_spectral(cluster_labels.astype(float) / n)\n    ax2.scatter(df_std[\"Std Annual Income (k$)\"], df_std[\"Std Spending Score (1-100)\"], marker='.', s=180, lw=0, alpha=0.7,\n                c=colors, edgecolor='k')\n\n    centers = clusterer.cluster_centers_\n    ax2.scatter(centers[:, 1], centers[:, 2], marker='o',\n                c=\"white\", alpha=1, s=200, edgecolor='k')\n\n    for i, c in enumerate(centers):\n        ax2.scatter(c[1], c[2], marker='$%d$' % i, alpha=1,\n                    s=100, edgecolor='k')\n\n    ax2.set_title(\"Scattterplot\")\n    ax2.set_xlabel(\"Std Annual Income (k$)\")\n    ax2.set_ylabel(\"Std Spending Score (1-100)\")\n\n    plt.suptitle((\"Silhouette analysis\"\n                  \" for n of clusters = %d\" % n),\n                 fontsize=14, fontweight='bold')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_scores = pd.DataFrame(scores).rename(columns = {0:\"Coefficient\"})\ndf_scores[\"Number of Clusters\"] = [i for i in range(2,10)]\ndf_scores[[\"Number of Clusters\",\"Coefficient\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize =(10,5))\n\nax.plot([i for i in range (2,10)], scores, c = \"blue\")\nax.set(xlabel = \"Number of Clusters\", ylabel = \"Silhouette score\", title = \"Silhouette coefficients\")\n\nax.set_xlim(2,9)\nax.set_ylim(0,1);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that the highest coefficient is for number of clusters 6 and it is 0.4274. For number of clusters 4 the coefficient is 0.4040. There is no big difference between these options. It is hard to tell which number to use. We see that we also have some negative coefficients at every number of clusters except in case of two clusters.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## K-means","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans = KMeans(n_clusters = 4)\nkc = kmeans.fit_predict(df_std)\n\ncentroids = pd.DataFrame(kmeans.cluster_centers_)\ncentroids.rename(inplace = True, \n                 columns = {0:\"Std Age\", \n                            1:\"Std Annual Income(k$)\", \n                            2:\"Std Spending Score (1-100)\"})\n\ndf_cluster = pd.concat([df, pd.DataFrame(kc)], axis = 1).rename(columns = {0:\"Cluster\"})\ndf_cluster.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We got our new column *Cluster* that represents in which cluster our obsevation is placed.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cluster.groupby(\"Cluster\").count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that most of our customers are placed in cluster 3 with 65 observations then 57 in 0, etc.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# position of our centroids\ncentroids.T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Kolmogorov smirnov normality test","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\" K-S test normality for 'Age' by clusters: \\n\")\n\nfor i in range (0,4):\n    statistics = stats.kstest(df_cluster[\"Age\"].values[df_cluster[\"Cluster\"].values == i], 'norm')\n    print(f\"For cluster {i} statistic is: {statistics}\")\n   \n\n\n\nprint(\"\\n K-S test normality for 'Annual Income (k$)' by clusters: \\n\")  \n\nfor i in range(0,4):\n    statistics = stats.kstest(df_cluster[\"Annual Income (k$)\"][df_cluster[\"Cluster\"] == i], 'norm')\n    print(f\"For cluster {i} statistic is: {statistics}\")\n    \n\n    \n    \nprint(\"\\n K-S test normality for 'Spending Score (1-100)' by clusters: \\n\")\n\nfor i in range(0,4):\n    statistics = stats.kstest(df_cluster[\"Spending Score (1-100)\"][df_cluster[\"Cluster\"] == i], 'norm')\n    print(f\"For cluster {i} statistic is: {statistics}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that our variables are not normaly distributed. To analyze if there is statisticly signigicant difference between our clusters we are going to use nonparametric test Kruskal Wallis because our variables are not normaly distributed","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Kruskal Wallis test","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### KW test for 'Age'","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"stats.kruskal(df_cluster[\"Age\"][df_cluster[\"Cluster\"] == 0],\n              df_cluster[\"Age\"][df_cluster[\"Cluster\"] == 1],\n              df_cluster[\"Age\"][df_cluster[\"Cluster\"] == 2],\n              df_cluster[\"Age\"][df_cluster[\"Cluster\"] == 3])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"P value is very low, we reject null hypothesis, and we conclude that there is statistically significant difference between clusters for 'Age'","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### KW test for 'Annual Income (k$)'","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"stats.kruskal(df_cluster[\"Annual Income (k$)\"][df_cluster[\"Cluster\"] == 0],\n              df_cluster[\"Annual Income (k$)\"][df_cluster[\"Cluster\"] == 1],\n              df_cluster[\"Annual Income (k$)\"][df_cluster[\"Cluster\"] == 2],\n              df_cluster[\"Annual Income (k$)\"][df_cluster[\"Cluster\"] == 3])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"P value is again very low and we conclude that there is statistically significant difference between clusters for 'Annual Income (k$)'","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### KW test for 'Spending Score (1-100)'","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"stats.kruskal(df_cluster[\"Spending Score (1-100)\"][df_cluster[\"Cluster\"] == 0],\n              df_cluster[\"Spending Score (1-100)\"][df_cluster[\"Cluster\"] == 1],\n              df_cluster[\"Spending Score (1-100)\"][df_cluster[\"Cluster\"] == 2],\n              df_cluster[\"Spending Score (1-100)\"][df_cluster[\"Cluster\"] == 3])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"P value is again very low and we conclude that there is statistically significant difference between clusters for 'Spending Score(1-100)'","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We saw that Kruskal Wallis test showed us clustering went well and we got a well formed clusters that differ one from each other, and that is what we want.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Plotting","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize= (10,7))\n\nax.scatter(df_std[\"Std Age\"], df_std[\"Std Annual Income (k$)\"], c = kc, s = 50, cmap = \"brg\")\nax.scatter(centroids.T.iloc[0:1], centroids.T.iloc[1:2], marker =\"p\", s = 170, c = \"black\")\n\nax.set(title = \"Scatterplot Clusters 1\", \n       xlabel = \"Std Age\", \n       ylabel = \"Std Annual Income (k$)\")\n\nax.set_xlim(-3, 3)\nax.set_ylim(-3, 3);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize= (10,7))\n\nax.scatter(df_std[\"Std Annual Income (k$)\"], df_std[\"Std Spending Score (1-100)\"], c = kc, s = 50, cmap = \"brg\")\nax.scatter(centroids.T.iloc[1:2], centroids.T.iloc[2:3], marker =\"p\", s = 170, c = \"black\")\n\nax.set(title = \"Scatterplot Clusters 2\", \n       xlabel = \"Std Annual Income (k$)\", \n       ylabel = \"Std Spending Score (1-100)\")\n\nax.set_xlim(-3, 3)\nax.set_ylim(-3, 3);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize= (10,7))\n\nax.scatter(df_std[\"Std Age\"], df_std[\"Std Spending Score (1-100)\"], c = kc, s = 50, cmap = \"brg\")\n\nax.set(title = \"Scatterplot Clusters 3\", \n       xlabel = \"Std Age\", \n       ylabel = \"Std Spending Score\")\n\nax.scatter(centroids.T.iloc[0:1], centroids.T.iloc[2:3], marker =\"p\", s = 170, c = \"black\")\n\nax.set_xlim(-3, 3)\nax.set_ylim(-3, 3);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (15,14))\nax = fig.add_subplot(111, projection='3d')\n\nax.set(title = \"3D Scatterplot\", \n       xlabel = \"Std Age\", \n       ylabel = \"Std Annual Income (k$)\", \n       zlabel = \"Std Spending Score (1-100)\")\n\nx = df_std[\"Std Age\"]\ny = df_std[\"Std Annual Income (k$)\"]\nz = df_std[\"Std Spending Score (1-100)\"]\n\nax.scatter(x,y,z, marker=\"o\", c = kc, s=150, cmap=\"brg\", edgecolors= \"black\")\n\nax.scatter(centroids[\"Std Age\"], centroids[\"Std Annual Income(k$)\"], centroids[\"Std Spending Score (1-100)\"], \n           marker = \"p\", s = 300, c = \"black\")\n\n\nax.view_init(35,55)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the graphs we can see our 4 clusters:\n* Brown cluster consisting of young customers which have high values of spending score and high values of annual income\n* Blue cluster consisting also of young customers with mid-high values of spending score, but low annual income\n* Green cluster consisting of older clients with mid values of spending score and low-mid annual income\n* Purple cluster consisting of persons with mid-high age, low spending score and high annual income","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Hierarchical clustering","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (10,7))\n\ndendrogram = sch.dendrogram(sch.linkage(df_std, method = \"ward\"))\nax.set(title = \"Dendrogram Ward Method\", xlabel = \"Customers\", ylabel = \"Distance\")\n\nplt.axhline(15, c = \"black\", linestyle=\"--\")\nplt.axhline(11, c = \"black\", linestyle=\"--\")\nplt.axhline(7, c = \"black\", linestyle=\"--\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On the dendrogram are placed 3 horizontal lines. \n* First one cuts the dendrogram into 2 clusters, \n* second line cuts into 4 clusters and \n* third line cuts dendrogram into 6 clusters. \n\nAgain it is hard to decide which one would be optimal number of clusters. We can see that the distance (wcss in ward method) rises at number of clusters 6 suddenly(third line). This indicates that we could have taken 6 as a number of clusters in our analysis. But also there is a big gap at other lines too.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}