{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Import Library/Packages\n\n* Keras -> Model/Prediction/Layers\n* numpy -> Hesaplamalar ve pandas'a yardımcı olması için \n* pandas -> Data için\n* matplotlib -> Görselleştirmek için","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from keras.layers import Conv2D, LeakyReLU, Dense, Flatten, Dropout, MaxPool2D # Layers\nfrom keras.models import Sequential # Sequential Model\nfrom keras.optimizers import Adam,RMSprop # optimizer\nfrom keras.preprocessing.image import ImageDataGenerator # data generator\nfrom keras.callbacks import ReduceLROnPlateau ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading Dataset\n\n#### MNIST dataset:\n\n* 60000 tane el yazması 0-9'a kadar sayılar bulunmaktadır.\n* Her fotoğraf 28*28 px'den oluşmaktadır ve gri renktedir.\n* Her pixel 0-255 arasında bir değer almaktadır. '0' siyahı, '255' beyazı temsil etmektedir.\n* Her bir sayının label'i 0-9 olarak tanımlanmıştır.\n* Data 758 sütun'dan oluşmaktadır. İlk sütun label olarak tanımlanmıştır, diğer 784 tane sütun ise pixellerden oluşmaktadır.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/mnist-in-csv/mnist_train.csv\")\ntest = pd.read_csv(\"../input/mnist-in-csv/mnist_test.csv\")\nprint(\"\\n\",train.info())\nprint(test.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)\ntrain.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prepare Train and Test ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = train.drop(['label'], axis=1) # x_train'e label dışındaki tüm px değerlerimi alıyorum\ny_train = train.label # label değeri yani sayının değerini \nx_test = test.drop(['label'], axis=1) # x_train ile aynı şekilde \ny_test = test.label # y_train ile aynı şekilde ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"x_train shape before reshape:\", x_train.shape)\nprint(\"x_test shape before reshape:\", x_test.shape)\nprint(\"y_train shape before reshape:\", y_train.shape)\nprint(\"y_test shape before reshape:\", y_test.shape)\n\nx_train = np.array(x_train).reshape(-1, 28, 28, 1)\nx_test = np.array(x_test).reshape(-1, 28, 28, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils.np_utils import to_categorical # one-hot-encoding'a çevirmek için \ny_train = to_categorical(y_train, num_classes = 10) # label encoding \ny_test = to_categorical(y_test, num_classes = 10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### CNN ile train etmek için np.array'e atıp reshape etmemiz gerekiyor. Yukarıda yaptığımız reshape işlemi 1 boyutlu olan pixellerimizi 3 boyut'a taşıyor. Array'imizde 60000/10000 olarak belirtilen kaç tane veri olduğunu tutuyor. Diğer kısım ise 3 boyutlu input'u gösteriyor. Bizim verimiz 28x28x1'lik 3 boyutlu 60000/10000 tane inputtan oluşuyor. \n* Kısaca (sample_size, 28x28x1)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"x_train shape after reshape:\", x_train.shape)\nprint(\"x_test shape after reshape:\", x_test.shape)\nprint(\"y_train shape after reshape:\", y_train.shape)\nprint(\"y_test shape after reshape:\", y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Normalization Data\n* Datamızı 0-1 arasına scale ediyoruz","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = x_train/255.0\nx_test = x_test/255.0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building Model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"###### Model oluşturmanın iki yolu var,\n    1.  Sequential Model ile,\n    2.  Function API kullanarak\n* Functional API daha komplike daha zorlu modellerde ve çok output var ise kullanılabilir. Basit düzeyde model kullanmak istiyoruz. \n* Sequential'da modelimize istediğimiz şekilde sırasıyla layer ekleyebiliyoruz.\n\n###### Modelimiz ,\n* 2 tane Conv. Blok'tan oluşacak.\n* Her blokt 2 tane Conv2D Layer'dan oluşacak ve aktivasyon fonksiyonu olarak LeakyRelu kullanacağız. Sonra MaxPool2D layerimiz ve son olarak Dropout yapacağız. \n* Sonrasında Flatten Layer'ımız bulunacak ardından outputmuzun olduğu Dense Layerlarımızı koyacağız\n\n* MaxPool2D layer'ı image'in boyutunu reduce etmemize yarıyoru. Pool size(2,2) default olarak uygulandığında (28,28) olan image'imiz (14,14)' düşüyor. Bir nevi feature reducing.\n\n* Dropout layer ise node'ları random şekilde sizin verdiğiniz oranda kapatıyor. Regularization layer'ı, over-fit engellemek için kullanıyoruz. \n\n* Output layer'ımız ise 10 node'dan oluşacak, sigmoid func kullanacağız output(y_train) 10 tane outputtan oluşuyor.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 30\nbatch_size = 250\nmodel = Sequential()\n\n# Block 1\nmodel.add(Conv2D(32,3, padding  =\"same\", input_shape=(28,28,1)))\nmodel.add(LeakyReLU())\nmodel.add(Conv2D(32,3, padding  =\"same\"))\nmodel.add(LeakyReLU())\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n#Block 2\nmodel.add(Conv2D(64,3, padding  =\"same\"))\nmodel.add(LeakyReLU())\nmodel.add(Conv2D(64,3, padding  =\"same\"))\nmodel.add(LeakyReLU())\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n#Flatten Block\nmodel.add(Flatten())\n\n#Output Block\nmodel.add(Dense(256,activation='relu'))\nmodel.add(Dropout(rate=0.25))\nmodel.add(Dense(32,activation='relu'))\nmodel.add(Dropout(rate=0.25))\nmodel.add(Dense(10,activation=\"softmax\"))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Compiling Model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"###### Optimizers: \n\n    1. SGD (Stochastic gradient descent optimizer)\n    2. RMSprop\n    3. Adam\n    4. Adamax","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"##### Learning Rate\n\n    1. Eğer learning rate çok yüksek ise loss'umuz azalırken bir anda yükselebilir. En az loss'a sahip olamayabiliriz.\n    2. Eğer learning rate çok az ise learning çok yavaş olur. Düzgün bir rate değeri seçmemiz gerekiyor.\n    3. lr değeri 0.001 yeterli bir değerdir. Eğer işe yaramazsa daha yüksek ya da düşük değer verilebilir.\n    4. Biz adam optimizer kullanacağız.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"##### Loss Functions: \n\n    1. binary_crossentropy: Bu loss fonksiyonu daha çok tek node'lu output layerlarda kullanılıyor. 0 ve 1 classificationlarında \n    2. categorical_crossentropy: Multi-class yani birden çok outputlarda kullanılyıor. \n    3. sparse_categorical_crossentropy: Yukarıdaki ile aynı aşağıda farkından bahsediliyor.\n  \n    \n    \n* Eğer target'im one-hot encoded ise categorical_crossentropy kullanabilirsin.\nÖrneğin:\n [1,0,0]\n [0,1,0]\n [0,0,1]\n\n* Eğer targetim integer ise sparse_categorical_crossentropy kullanabilirsin. \nÖrneğin:\n1\n2\n3\n\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"###### Improvement Learning Rate\n* ReduceLROnPlateau() keras'ta bulunan bir callback fonksiyon, bu fonksiyon aşamalı olarak accuracy'e bakarak, (eğer improvement durduysa)lr'yi düşürerek öğrenmenin daha iyi olmasını sağlıyor.\n\n\n    1. monitor: bir metric'i monitor ediyor, bu bizde val_accuracy\n    2. patience: ne kadar epochs süresince bir improvement olmadı, bunu belirliyoruz, örneğin 2 epochs sonrasında bir improvement olmadıysa lr düşürüyoruz. \n    3. factor: ne kadar değerde lr düşürülecek new_lr = lr * factor (0.5)\n    4. min_lr: en düşük lr band'ı (0.00001)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# kullanılabilir optimizer featureları\n\"\"\"\nsgd = keras.optimizers.SGD(lr=1e-4, momentum=0.9)\nrms_prop = keras.optimizers.RMSprop(lr=1e-4)\nadam = keras.optimizers.adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08) \nadamax = keras.optimizers.Adamax(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\nadadelta = keras.optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=1e-08, decay=0.0)\n\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.0001) \"\"\"\n\nadam = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n#rms_prop = RMSprop(lr=0.001)\nlearning_rate_reduce = ReduceLROnPlateau(monitor='val_accuracy', \n                                            patience=2, \n                                            verbose=1, \n                                            factor=0.4, \n                                            min_lr=0.00001)\nloss = \"categorical_crossentropy\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile( optimizer= adam, loss=loss ,metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Image Generate","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\ndatagen.fit(x_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training the model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit_generator(datagen.flow(x_train,y_train, batch_size = batch_size),\n                              epochs = epochs, validation_data = (x_test, y_test),\n                              steps_per_epoch = x_train.shape[0] // batch_size,\n                              callbacks=[learning_rate_reduce])\nresult = model.evaluate(x = x_train, y = y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Accuracy:', result[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Performance plotting","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.title(\"Loss Plot\", fontsize = 15)\nplt.xlabel(\"Epochs\", fontsize = 12)\nplt.ylabel(\"Loss\", fontsize = 12)\nplt.grid(alpha=0.3)\nplt.legend([\"Train\", \"Test\"])\nplt.show()\n\nplt.plot(history.history[\"accuracy\"])\nplt.title(\"Accuracy Plot\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\", fontsize = 12)\nplt.grid(alpha=0.3)\nplt.legend([\"Train\",\"Test\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Confusion Matrix","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nfrom sklearn.metrics import confusion_matrix\n\ny_pred = model.predict(x_test)\n\n# Convert predictions classes to one hot vectors \ny_pred_classes = np.argmax(y_pred,axis = 1) \n\n# Convert validation observations to one hot vectors\ny_true = np.argmax(y_test,axis = 1) \n\n# compute the confusion matrix\ncm = confusion_matrix(y_true, y_pred_classes) \n\n# plot the confusion matrix\nf,ax = plt.subplots(figsize=(8, 8))\n\nsns.heatmap(cm, annot = True, linewidths = 0.01, cmap = \"Greens\", linecolor = \"gray\", fmt = '.1f',ax = ax)\n\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_y = np.argmax(model.predict(x_test),axis =1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_submission = pd.DataFrame([test.index+1,test_y],[\"ImageId\",\"Label\"]).transpose()\ndf_submission.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}