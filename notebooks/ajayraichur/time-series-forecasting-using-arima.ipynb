{"cells":[{"metadata":{},"cell_type":"markdown","source":"https://medium.com/@stallonejacob/time-series-forecast-a-basic-introduction-using-python-414fcb963000"},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing required libraries\nimport pandas as pd\nimport numpy as np\n\n# Now, we will load the data set and look at some initial rows and data types of the columns:\ndata = pd.read_csv('../input/air-passengers/AirPassengers.csv')\nprint (data.head())\nprint ('\\n Data Types:')\nprint (data.dtypes)\n\n# The data contains a particular month and number of passengers travelling in that month. \n#In order to read the data as a time series, we have to pass special arguments to the read_csv command:\ndateparse = lambda dates: pd.datetime.strptime(dates, '%Y-%m')\ndata = pd.read_csv('../input/air-passengers/AirPassengers.csv', parse_dates=['Month'], index_col='Month',date_parser=dateparse)\nprint ('\\n Parsed Data:')\nprint (data.head())\n\n## NOTE: You can run remaining codes in this article as well, using this live coding window.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.getcwd()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\ndata=pd.read_csv('../input/air-passengers/AirPassengers.csv')\nprint('+++++data++++')\nprint(data.head())\nprint('\\n datatypes:')\nprint(data.dtypes)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\ndateparse=lambda dates:datetime.datetime.strptime(dates,'%Y-%m')\n\ndata=pd.read_csv('../input/air-passengers/AirPassengers.csv',index_col='Month',parse_dates=['Month'],date_parser=dateparse)\n\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts=data['#Passengers']\n\n#1. Specific the index as a string constant:\nts['1949-01-01']\n\n#2. Import the datetime library and use 'datetime' function:\nfrom datetime import datetime\nts[datetime(1949,1,1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.figure(figsize=(10,8))\nplt.plot(ts)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.stattools import adfuller\ndef test_stationarity(timeseries):\n    \n    #Determing rolling statistics\n    rolmean = timeseries.rolling(12).mean()\n    rolstd = timeseries.rolling(12).std()\n\n    #Plot rolling statistics:\n    orig = plt.plot(timeseries, color='blue',label='Original')\n    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n    plt.legend(loc='best')\n    plt.title('Rolling Mean & Standard Deviation')\n    plt.show(block=False)\n    \n    #Perform Dickey-Fuller test:\n    print('Results of Dickey-Fuller Test:')\n    dftest = adfuller(timeseries, autolag='AIC')\n    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n    for key,value in dftest[4].items():\n        dfoutput['Critical Value (%s)'%key] = value\n    print(dfoutput)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_stationarity(ts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts_log = np.log(ts)\nplt.plot(ts_log)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Moving average\n# In this approach, we take average of ‘k’ consecutive values depending on the frequency of time series.\n# Here we can take the average over the past 1 year, i.e. last 12 values. \n# Pandas has specific functions defined for determining rolling statistics.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"moving_avg = ts_log.rolling(12).mean()\nplt.plot(ts_log)\nplt.plot(moving_avg, color='red')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" ts_log.head(12)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"moving_avg.head(12)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The red line shows the rolling mean. Lets subtract this from the original series. Note that since we are taking average of last 12 values, \n# rolling mean is not defined for first 11 values. \n# This can be observed as:\n\nts_log_moving_avg_diff = ts_log - moving_avg\nts_log_moving_avg_diff.head(12)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts_log_moving_avg_diff.dropna(inplace=True)\ntest_stationarity(ts_log_moving_avg_diff)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"expwighted_avg = ts_log.ewm(halflife=12).mean()\nplt.plot(ts_log)\nplt.plot(expwighted_avg, color='red')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts_log_ewma_diff=ts_log-expwighted_avg\nts_log_ewma_diff.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_stationarity(ts_log_ewma_diff)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts_log_ewma_diff.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(ts_log_ewma_diff)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#to remove seasonality one is diffrenecing and other is decomposition\n#1.differencing\nts_log_diff = ts_log - ts_log.shift()\nprint(ts_log_diff.head())\nplt.plot(ts_log_diff)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts_log_diff.dropna(inplace=True)\ntest_stationarity(ts_log_diff)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#decomposition\nfrom statsmodels.tsa.seasonal import seasonal_decompose\ndecomposition = seasonal_decompose(ts_log)\n\ntrend = decomposition.trend\nseasonal = decomposition.seasonal\nresidual = decomposition.resid\n\nplt.subplot(411)\nplt.plot(ts_log, label='Original')\nplt.legend(loc='best')\nplt.subplot(412)\nplt.plot(trend, label='Trend')\nplt.legend(loc='best')\nplt.subplot(413)\nplt.plot(seasonal,label='Seasonality')\nplt.legend(loc='best')\nplt.subplot(414)\nplt.plot(residual, label='Residuals')\nplt.legend(loc='best')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts_log_decompose = residual\nts_log_decompose.dropna(inplace=True)\ntest_stationarity(ts_log_decompose)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ACF and PACF plots:\nfrom statsmodels.tsa.stattools import acf, pacf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lag_acf = acf(ts_log_diff, nlags=20)\nlag_pacf = pacf(ts_log_diff, nlags=20, method='ols')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plot ACF: \nplt.subplot(121) \nplt.plot(lag_acf)\nplt.axhline(y=0,linestyle='--',color='gray')\nplt.axhline(y=-1.96/np.sqrt(len(ts_log_diff)),linestyle='--',color='gray')\nplt.axhline(y=1.96/np.sqrt(len(ts_log_diff)),linestyle='--',color='gray')\nplt.title('Autocorrelation Function')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plot PACF:\nplt.subplot(122)\nplt.plot(lag_pacf)\nplt.axhline(y=0,linestyle='--',color='gray')\nplt.axhline(y=-1.96/np.sqrt(len(ts_log_diff)),linestyle='--',color='gray')\nplt.axhline(y=1.96/np.sqrt(len(ts_log_diff)),linestyle='--',color='gray')\nplt.title('Partial Autocorrelation Function')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.arima_model import ARIMA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = ARIMA(ts_log, order=(0, 1, 2))  \nresults_MA = model.fit(disp=-1)  \nplt.plot(ts_log_diff)\nplt.plot(results_MA.fittedvalues, color='red')\nplt.title('RSS: %.4f'% sum((results_MA.fittedvalues-ts_log_diff)**2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = ARIMA(ts_log, order=(2, 1, 0))  \nresults_AR = model.fit(disp=-1)  \nplt.plot(ts_log_diff)\nplt.plot(results_AR.fittedvalues, color='red')\nplt.title('RSS: %.4f'% sum((results_AR.fittedvalues-ts_log_diff)**2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = ARIMA(ts_log, order=(2, 1, 2))  \nresults_ARIMA = model.fit(disp=-1)  \nplt.plot(ts_log_diff)\nplt.plot(results_ARIMA.fittedvalues, color='red')\nplt.title('RSS: %.4f'% sum((results_ARIMA.fittedvalues-ts_log_diff)**2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_ARIMA_diff = pd.Series(results_ARIMA.fittedvalues, copy=True)\npredictions_ARIMA_diff.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_ARIMA_diff_cumsum = predictions_ARIMA_diff.cumsum()\npredictions_ARIMA_diff_cumsum.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_ARIMA_log = pd.Series(ts_log.iloc[0], index=ts_log.index)\nprint(predictions_ARIMA_log)\npredictions_ARIMA_log = predictions_ARIMA_log.add(predictions_ARIMA_diff_cumsum,fill_value=0)\npredictions_ARIMA_log.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts_log","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_ARIMA = np.exp(predictions_ARIMA_log)\nplt.plot(ts)\nplt.plot(predictions_ARIMA)\nplt.title('RMSE: %.4f'% np.sqrt(sum((predictions_ARIMA-ts)**2)/len(ts)))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":4}