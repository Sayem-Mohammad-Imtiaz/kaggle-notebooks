{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nfrom scipy.stats import zscore\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.svm import SVC \nfrom sklearn.impute import KNNImputer\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score\nimport matplotlib.pyplot as plt\nimport time\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import log_loss\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn import tree\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"all_data = \"/kaggle/input/pump-sensor-data/sensor.csv\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data =  pd.read_csv(all_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Data cleaning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# deleting column named as sensor 15.\ndata = data.drop('sensor_15', 1)\ndata = data.drop('Unnamed: 0', 1)\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating new columns named as data and time from timestamp and deleting the column timestamp.\ndata['date'] = data['timestamp'].apply(lambda x: x.split(' ')[0])\ndata['time'] = data['timestamp'].apply(lambda x: x.split(' ')[1])\ndata = data.drop(['timestamp'], 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# imputting missing values with median of each column\ndata_imputed = data.fillna(data.median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking out histogram for outlier data\ndata_imputed.hist(figsize=(15,15))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#removing outliers using zscore\nz_scores = zscore(data_imputed.iloc[:,:51])\nabs_z_scores = np.abs(z_scores)\nfiltered_entries = (abs_z_scores < 3).all(axis=1)\ndata_outlir = data_imputed[filtered_entries]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# how much data has been lost after removing outliers\n((220320 - 165201)/220320) * 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_outlir['machine_status'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# standarizing the dataset using minmax scalar\nscaler = MinMaxScaler()\ndata_std = scaler.fit_transform(data_outlir.iloc[:,:51])\ndata_std = pd.DataFrame(data_std)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking for variance of each feature\ndata_va = data_std.var(axis= 0)\ndata_vas = data_va.sort_values(ascending=False)\ny = data_vas.values \nx = range(len(y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (20,20))\nplt.plot(x, y)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As there is no flat line, every feature is has variance which is important for model input","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"corrmatrix = data_std.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# doing multicollinearity test\ndef correlation(dataset, threshold):\n    col_corr = set() # Set of all the names of deleted columns\n    corr_matrix = dataset.corr()\n    for i in range(len(corr_matrix.columns)):\n        for j in range(i):\n            if (abs(corr_matrix.iloc[i, j]) >= threshold) and (corr_matrix.columns[j] not in col_corr):\n                colname = corr_matrix.columns[i] # getting the name of column\n                col_corr.add(colname)\n                if colname in dataset.columns:\n                    del dataset[colname] # deleting the column from the dataset\n\n    return dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le = LabelEncoder()\nY = le.fit_transform(data_outlir['machine_status'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = correlation(data_std, 0.7)\nX","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After removing features with high correlation we are left with 36 columns","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#  2. Explodatory data analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in data_std.columns:\n    plt.scatter( data_outlir['machine_status'] , data_std[i] )\n    plt.xlabel('machine_status')\n    plt.ylabel(i)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. turns out most of the data pts(i.e days) belongs to normal class, while for class recovering it distributed to less days and very less days are with class broken","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter( data_outlir['time'] , data_outlir['machine_status'] )\nplt.xlabel('time')\nplt.ylabel('machine status')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Seems like most recovering happened at timings between 10 am to 12 o'clock.\n2. Most brokage happened as 12 o'clock and at around 8 am in morning.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import linear_model\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn import linear_model\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nfrom sklearn.cluster import KMeans\nfrom lightgbm import LGBMClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"KNN","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors=15)\nclf = knn.fit(X_train, y_train)\ny_pred = clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_knb_model=roc_auc_score(y_test, y_pred)*100\nacc_knb_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_proba = clf.predict_proba(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Logistic Regression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#applying logistic regression\nlr = LogisticRegression(C = 0.2)\nclf1 = lr.fit(X_train, y_train)\ny_pred1 = clf1.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_log_reg=roc_auc_score(y_test, y_pred1)*100\nacc_log_reg","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Naive Bayes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#applying naive bayes\nclf2 = GaussianNB().fit(X_train, y_train)\ny_pred2 = clf2.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_nb=roc_auc_score(y_test, y_pred2)*100\nacc_nb","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Decision Tree","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#applying decision tree\nclf3 = tree.DecisionTreeClassifier().fit(X_train, y_train)\ny_pred3 = clf3.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_dt=roc_auc_score(y_test, y_pred3)*100\nacc_dt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random Forest","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#applying random forest\nclf4 = RandomForestClassifier(max_depth=5, random_state=0).fit(X_train, y_train)\ny_pred4 = clf4.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_rmf_model=roc_auc_score(y_test, y_pred4)*100\nacc_rmf_model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"SVM","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#applying support vector machine\nclf5 = SVC(gamma='auto').fit(X_train, y_train)\ny_pred5 = clf5.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_svm_model=roc_auc_score(y_test, y_pred5)*100\nacc_svm_model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Stochastic Gradient descent","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sgd_model=SGDClassifier()\nsgd_model.fit(X_train,y_train)\nsgd_pred=sgd_model.predict(X_test)\nacc_sgd=round(sgd_model.score(X_train,y_train)*100,10)\nacc_sgd","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"X Boost","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_model=XGBClassifier()\nxgb_model.fit(X_train,y_train)\nxgb_pred=xgb_model.predict(X_test)\nacc_xgb=round(xgb_model.score(X_train,y_train)*100,10)\nacc_xgb","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Light GBM","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbm = LGBMClassifier()\nlgbm.fit(X_train,y_train)\nlgbm_pred=lgbm.predict(X_test)\nacc_lgbm=round(lgbm.score(X_train,y_train)*100,10)\nacc_lgbm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"regr = linear_model.LinearRegression()\nregr.fit(X_train,y_train)\nregr_pred=regr.predict(X_test)\nacc_regr=round(regr.score(X_train,y_train)*100,10)\nacc_regr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n              'Random Forest','Stochastic Gradient Decent','Linear Regression','Naive Bayes','XGBoost','LightGBM','Decision Tree'],\n    'Score': [acc_svm_model, acc_knb_model, acc_log_reg, \n              acc_rmf_model,acc_sgd,acc_regr,acc_nb,acc_xgb,acc_lgbm,acc_dt]})\nresult_df = results.sort_values(by='Score', ascending=False)\nresult_df = result_df.set_index('Score')\nresult_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}