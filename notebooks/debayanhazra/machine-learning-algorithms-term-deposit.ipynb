{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"conda install pydotplus","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/bank-marketing-dataset/bank.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nimport matplotlib.pyplot as plt \nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_c = data.select_dtypes(include=[object])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for c in data_c.columns:\n    print(\"----------------------\")\n    print(data_c[c].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(['poutcome', 'contact'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_vars = ['job','marital','education','default','housing','loan','month']\n\nfor var in cat_vars:\n    cat_list='var'+'_'+var\n    cat_list = pd.get_dummies(data[var], prefix=var)\n    data1=data.join(cat_list)\n    data=data1\n\ncat_vars=['job','marital','education','default','housing','loan','month']\n\ndata_vars=data.columns.values.tolist()\nto_keep=[i for i in data_vars if i not in cat_vars]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def binary_map(x):\n        return x.map({'yes': 1, \"no\": 0})\n    \ncols = ['deposit']\ndata[cols] = data[cols].apply(binary_map)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_final = data[to_keep]\ndata_final.columns.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list(data_final.select_dtypes(['object']).columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_final_v = data_final.columns.values.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data_final.loc[:, data_final.columns != 'deposit']\ny = data_final.loc[:, data_final.columns == 'deposit']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import RFE\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg = LogisticRegression()\nmodel = logreg.fit(X, y)\nrfe = RFE(logreg, 15)\nrfe = rfe.fit(X, y.values.ravel())\n\nprint(rfe.support_)\nprint(rfe.ranking_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\nlogit_model=sm.Logit(y, X)\nresult=logit_model.fit()\nprint(result.summary2())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def column_index(data, query_cols):\n    cols = data.columns.values\n    sidx = np.argsort(cols)\n    return sidx[np.searchsorted(cols, query_cols, sorter = sidx)]\n\nfeature_index = []\nfeatures = []\ncolumn_index(X, X.columns.values)\n\nfor num, i in enumerate(rfe.get_support(), start=0):\n    if i == True:\n        feature_index.append(str(num))\n\nfor num, i in enumerate(X.columns.values, start=0):\n    if str(num) in feature_index:\n        features.append(X.columns.values[num])\n\nprint(\"Top Features : {}\\n\".format(len(feature_index)))\nprint(\"Indexes: \\n{}\\n\".format(feature_index))\nprint(\"Feature Names: \\n{}\".format(features))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data[['job_retired', 'job_student', 'education_primary', 'housing_yes', 'loan_no', \n          'month_aug', 'month_dec', 'month_jan', 'month_jul', 'month_jun', 'month_mar', \n          'month_may', 'month_nov', 'month_oct', 'month_sep']] \n\ny = data['deposit']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logit_model=sm.Logit(y, X)\nresult = logit_model.fit()\nprint(result.summary2())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = pd.DataFrame()\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nclf = LogisticRegression()\ngrid_values = {'penalty': ['l1', 'l2'],'C':[0.001,.009,0.01,.09,1,5,10,25]}\ngrid_clf_acc = GridSearchCV(clf, param_grid = grid_values,scoring = 'recall')\ngrid_clf_acc.fit(X_train, y_train)\n\nprint(grid_clf_acc.best_estimator_)\n\ny_pred_acc = grid_clf_acc.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\nprint('Accuracy Score : ' + str(accuracy_score(y_test,y_pred_acc)))\nprint('Precision Score : ' + str(precision_score(y_test,y_pred_acc)))\nprint('Recall Score : ' + str(recall_score(y_test,y_pred_acc)))\nprint('F1 Score : ' + str(f1_score(y_test,y_pred_acc)))\n\n#Dummy Classifier Confusion matrix\nfrom sklearn.metrics import confusion_matrix\nprint('Confusion Matrix : \\n' + str(confusion_matrix(y_test,y_pred_acc)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42) \n\nlr_list = [0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1]\n\nfor learning_rate in lr_list:\n    gb_clf = GradientBoostingClassifier(n_estimators=20, learning_rate=learning_rate, \n                                        max_features=2, max_depth=2, random_state=0)\n    gb_clf.fit(X_train, y_train)\n\n    print(\"Learning rate: \", learning_rate)\n    print(\"Accuracy score (training): {0:.3f}\".format(gb_clf.score(X_train, y_train)))\n    print(\"Accuracy score (validation): {0:.3f}\".format(gb_clf.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gb_clf2 = GradientBoostingClassifier(n_estimators=20, learning_rate=0.5, max_features=2, \n                                     max_depth=2, random_state=0)\ngb_clf2.fit(X_train, y_train)\npredictions = gb_clf2.predict(X_test)\n\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(y_test, predictions))\n\nprint(\"Classification Report\")\nprint(classification_report(y_test, predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.externals.six import StringIO  \nfrom IPython.display import Image  \nfrom sklearn.tree import export_graphviz\nimport pydotplus","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\ngb = GradientBoostingClassifier(max_depth=3)\ngb.fit(X, y)\n\ndot_data = StringIO()\nexport_graphviz(gb.estimators_[0][0], out_file=dot_data, filled=True, rounded=True, \n                special_characters=True, feature_names = X.columns)\n\ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \nImage(graph.create_png())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\n\nxgb_clf = XGBClassifier()\nxgb_clf.fit(X_train, y_train)\n\nscore = xgb_clf.score(X_test, y_test)\nprint(score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(oob_score=True, n_estimators=100, random_state=42, n_jobs=-1, max_depth=2)\nrf.fit(X, y)\nrf.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"export_graphviz(rf.estimators_[1], out_file = 'tree.dot', feature_names = X.columns, rounded = True, precision = 1)\n\ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \nImage(graph.create_png())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import tree\ntreemodel = tree.DecisionTreeClassifier(max_depth = 3, random_state=42)\ntreemodel.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"treemodel.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = treemodel.predict(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dot_data = StringIO()\nexport_graphviz(treemodel, out_file=dot_data,  \n                filled=True, rounded=True,\n                special_characters=True, feature_names = X.columns)\ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \nImage(graph.create_png())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = gb.predict(X)\nconfusion_matrix(y, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score, cross_val_predict\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors=8)\nknn.fit(X_train, y_train)\ny_pred = knn.predict(X_test)\nmetrics.accuracy_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42) \n  \nneighbors = np.arange(1, 10) \ntrain_accuracy = np.empty(len(neighbors)) \ntest_accuracy = np.empty(len(neighbors)) \n  \n# Loop over K values \nfor i, k in enumerate(neighbors): \n    knn = KNeighborsClassifier(n_neighbors=k) \n    knn.fit(X_train, y_train) \n      \n    # Compute traning and test data accuracy \n    train_accuracy[i] = knn.score(X_train, y_train) \n    test_accuracy[i] = knn.score(X_test, y_test) \n  \n# Generate plot \nplt.plot(neighbors, test_accuracy, label = 'Testing Accuracy') \nplt.plot(neighbors, train_accuracy, label = 'Training Accuracy') \n  \nplt.legend() \nplt.xlabel('n_neighbors') \nplt.ylabel('Accuracy') \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = cross_val_score(logreg, X, y, cv=10)\nprint(scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nfrom math import sqrt\nfrom sklearn import model_selection\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import LeaveOneOut\nfrom sklearn.model_selection import LeavePOut\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.model_selection import StratifiedKFold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.30, random_state=100)\nmodel = LogisticRegression()\n\nmodel.fit(X_train, y_train)\nresult = model.score(X_test, y_test)\n\nprint(\"Accuracy: %.2f%%\" % (result*100.0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kfold = model_selection.KFold(n_splits=10, random_state=100)\nmodel_kfold = LogisticRegression()\n\nresults_kfold = model_selection.cross_val_score(model_kfold, X, y, cv=kfold)\n\nprint(\"Accuracy: %.2f%%\" % (results_kfold.mean()*100.0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skfold = StratifiedKFold(n_splits=6, random_state=100)\nmodel_skfold = LogisticRegression()\nresults_skfold = model_selection.cross_val_score(model_skfold, X, y, cv=skfold)\nprint(\"Accuracy: %.2f%%\" % (results_skfold.mean()*100.0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kfold2 = model_selection.ShuffleSplit(n_splits=10, test_size=0.30, random_state=100)\nmodel_shufflecv = LogisticRegression()\nresults_4 = model_selection.cross_val_score(model_shufflecv, X, y, cv=kfold2)\nprint(\"Accuracy: %.2f%% (%.2f%%)\" % (results_4.mean()*100.0, results_4.std()*100.0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg = LogisticRegression()\nlogreg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = logreg.predict(X_test)\nprint('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nlogit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\nfpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\nplt.figure()\nplt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.legend(loc=\"lower right\")\nplt.savefig('Log_ROC')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Do upvote if you found this to be of any help. "},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}