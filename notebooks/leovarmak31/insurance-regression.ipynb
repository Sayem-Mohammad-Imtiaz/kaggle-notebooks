{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!pip install jovian --upgrade\nimport jovian\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nfrom torchvision.datasets.utils import download_url\n\nfrom torch.utils.data import DataLoader, TensorDataset, random_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"project_name='02-insurance-linear-regression' ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATASET_URL = \"https://hub.jovian.ml/wp-content/uploads/2020/05/insurance.csv\"\nDATA_FILENAME = \"insurance.csv\"\ndownload_url(DATASET_URL, '.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataframe_raw = pd.read_csv(DATA_FILENAME)\ndataframe_raw.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(dataframe_raw)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataframe_raw.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataframe_raw.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The customize_dataset function will customize the dataset slightly using your name as a source of random numbers.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"your_name = 'Preeti'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def customize_dataset(dataframe_raw, rand_str):\n    dataframe = dataframe_raw.copy(deep=True)\n    # drop some rows\n    dataframe = dataframe.sample(int(0.95*len(dataframe)), random_state=int(ord(rand_str[0])))\n    # scale input\n    dataframe.bmi = dataframe.bmi * ord(rand_str[1])/100.\n    # scale target\n    dataframe.charges = dataframe.charges * ord(rand_str[2])/100.\n    # drop column\n    if ord(rand_str[3]) % 2 == 1:\n        dataframe = dataframe.drop(['region'], axis=1)\n    return dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataframe = customize_dataset(dataframe_raw, your_name)\ndataframe.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Let us answer some basic questions about the dataset.\n\nQ: How many rows does the dataset have?**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"num_rows = dataframe.shape[0]\nnum_rows","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Q: How many columns doe the dataset have**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"num_cols = dataframe.shape[1]\nnum_cols","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Q: What are the column titles of the input variables?****","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"input_cols = [\"age\",\"sex\",\"bmi\",\"children\",\"smoker\",\"charges\"]\ninput_cols","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Q: Which of the input columns are non-numeric or categorial variables ?**\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_cols = ['sex', 'smoker']\ndataframe.head()[categorical_cols]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"****Q: What are the column titles of output/target variable(s)?****","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"output_cols = ['charges']\nprint(dataframe[output_cols])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Q: (Optional) What is the minimum, maximum and average value of the charges column? Can you show the distribution of values in a graph? Use this data visualization cheatsheet for referece: https://jovian.ml/aakashns/dataviz-cheatsheet**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t = dataframe[output_cols]   #avg\navg = t/len(dataframe)\nsns.distplot(avg)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"e = t.max()\nsns.barplot(e )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f = t.min()\nsns.barplot(f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"jovian.commit(project=project_name, environment=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataframe[output_cols].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataframe[output_cols].min()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataframe[output_cols].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title('Distribution')\nsns.distplot(dataframe[output_cols], kde=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title('Distribution')\nsns.scatterplot(dataframe['charges'],dataframe_raw['bmi'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(dataframe['age'],dataframe_raw['bmi'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"avg_smokers_charges = dataframe[dataframe.smoker == 'yes'][output_cols].mean()\navg_non_smokers_charges = dataframe[dataframe.smoker == 'no'][output_cols].mean()\nprint('Average smokers', avg_smokers_charges)\nprint('Average non smokers', avg_non_smokers_charges)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"avg_smokers_charges/avg_non_smokers_charges","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x=\"sex\", y=\"charges\", hue=\"smoker\",\n            kind=\"violin\", data=dataframe, palette = 'magma')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(y=\"smoker\", x=\"charges\",data = dataframe[(dataframe.age == 18)],palette='pink')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,5))\nplt.title(\"Distribution of bmi\")\nax = sns.distplot(dataframe[\"bmi\"], color = 'm')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In non-smokers, the cost of treatment increases with age. That makes sense. So take care of your health, friends! In smoking people, we do not see such dependence. I think that it is not only in smoking but also in the peculiarities of the dataset. Such a strong effect of Smoking on the cost of treatment would be more logical to judge having a set of data with a large number of records and signs. But we work with what we have! Let's pay attention to bmi. I am surprised that this figure but affects the cost of treatment in patients. Or are we on a diet for nothing?","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Step 2: Prepare the dataset for training\nWe need to convert the data from the Pandas dataframe into a PyTorch tensors for training. To do this, the first step is to convert it numpy arrays. If you've filled out input_cols, categorial_cols and output_cols correctly, this following function will perform the conversion to numpy arrays.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def dataframe_to_arrays(dataframe):\n    # Make a copy of the original dataframe\n    dataframe1 = dataframe.copy(deep=True)\n    # Convert non-numeric categorical columns to numbers\n    for col in categorical_cols:\n        dataframe1[col] = dataframe1[col].astype('category').cat.codes\n    # Extract input & outupts as numpy arrays\n    inputs_array = dataframe1[input_cols].to_numpy()\n    targets_array = dataframe1[output_cols].to_numpy()\n    return inputs_array, targets_array","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs_array, targets_array = dataframe_to_arrays(dataframe)\ninputs_array.shape, inputs_array, targets_array","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Q: Convert the numpy arrays inputs_array and targets_array into PyTorch tensors. Make sure that the data type is torch.float32.\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs = torch.from_numpy(inputs_array).type(torch.float32)\ntargets = torch.from_numpy(targets_array).type(torch.float32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs.dtype, targets.dtype","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Next, we need to create PyTorch datasets & data loaders for training & validation. We'll start by creating a TensorDataset.*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = TensorDataset(inputs, targets)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":": Pick a number between 0.1 and 0.2 to determine the fraction of data that will be used for creating the validation set. Then use random_split to create training & validation datasets.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nval_percent = 0.1 # between 0.1 and 0.2\nval_size = int(num_rows * val_percent)\ntrain_size = num_rows - val_size\n\n\ntrain_ds, val_ds = random_split(dataset, [train_size, val_size])\n#refrence from https://jovian.ml/kir-prz/02-insurance-linear-regression","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally, we can create data loaders for training & validation.\n\nQ: Pick a batch size for the data loader.\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 32","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader = DataLoader(train_ds,  \n                          batch_size,\n                         shuffle=True)\nval_loader = DataLoader(val_ds, batch_size)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for xb, yb in train_loader:\n    print(\"inputs:\", xb)\n    print(\"targets:\", yb)\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"jovian.commit(project=project_name, environment=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_size = len(input_cols)\noutput_size = len(output_cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Q: Complete the class definition below by filling out the constructor (__init__), forward, training_step and validation_step methods.\n\nHint: Think carefully about picking a good loss fuction (it's not cross entropy). Maybe try 2-3 of them and see which one works best. See","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class InsuranceModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linear = nn.Linear(input_size, output_size)               # fill this (hint: use input_size & output_size defined above)\n        \n    def forward(self, xb):\n        out = self.linear(xb)                        # fill this\n        return out\n    \n    def training_step(self, batch):\n        inputs, targets = batch \n        # Generate predictions\n        out = self(inputs)          \n        # Calcuate loss\n        loss = F.l1_loss(out,targets)                       # fill this\n        return loss\n    \n    def validation_step(self, batch):\n        inputs, targets = batch\n        # Generate predictions\n        out = self(inputs)\n        # Calculate loss\n        loss = F.l1_loss(out,targets)               # fill this    \n        return {'val_loss': loss.detach()}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        return {'val_loss': epoch_loss.item()}\n    \n    def epoch_end(self, epoch, result, num_epochs):\n        # Print result every 20th epoch\n        if (epoch+1) % 20 == 0 or epoch == num_epochs-1:\n            print(\"Epoch [{}], val_loss: {:.4f}\".format(epoch+1, result['val_loss']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let us create a model using the InsuranceModel class. You may need to come back later and re-run the next cell to reinitialize the model, in case the loss becomes nan or infinity.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = InsuranceModel()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets check out the weight and bias of model using model.parameters() .","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"list(model.parameters())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"jovian.commit(project=project_name, environment=None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Step 4: Train the model to fit the data\nTo train our model, we'll use the same fit function explained in the lecture. That's the benefit of defining a generic training loop - you can use it for any problem.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(model, val_loader):\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        for batch in train_loader:\n            loss = model.training_step(batch)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        model.epoch_end(epoch, result, epochs)\n        history.append(result)\n    return history","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Use the evaluate function to calculate the loss on the validation set before training.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nresult = evaluate(model, val_loader)\nprint(result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 5000\nlr = 1.5e-1\nhistory2 = fit(epochs, lr, model, train_loader, val_loader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss = []\nfor values in history2:\n    loss.append(values['val_loss'])\nplt.plot(loss)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"jovian.commit(project=project_name, environment=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}