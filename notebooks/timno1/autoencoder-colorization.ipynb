{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Import libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import glob\nimport numpy as np\nimport pandas as pd\nimport sklearn \nimport seaborn as sns\nimport cv2\nimport random\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom skimage.io import imread\nfrom copy import deepcopy \n\nimport tensorflow.compat.v2 as tf \nimport tensorflow.keras as keras \nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization, UpSampling2D\nfrom tensorflow.keras.optimizers import Adam","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Set path to images"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"PATH_TO_IMG = \"../input/celeba-dataset/img_align_celeba/img_align_celeba/\"\n\npath_to_img_data = glob.glob(PATH_TO_IMG + \"*jpg\")\nlen(path_to_img_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Set size of dataset, batch size and shape of image"},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_SIZE = 25600\nTEST_SIZE = 640\n\nBATCH_SIZE = 128\n\nIMG_HEIGHT = 224\nIMG_WIDTH = 184","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plot original image"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nfor i,img_path in enumerate(path_to_img_data[:4]):\n    plt.subplot(1,4,i+1)\n    plt.axis('off')\n    img = plt.imread(img_path)\n    plt.imshow(img)   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"My generator, input image in grayscale, output colorated images."},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_input(image_path):\n    img = imread(image_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)      \n    img = img/255\n    img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n    img = np.reshape(img, (IMG_HEIGHT, IMG_WIDTH, 1))\n\n    return img \n\n\ndef get_output(image_path):\n    img = imread(image_path)\n    img = img/255.0\n    img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n    return img\n    \n    \ndef image_generator(files, batch_size = 64): \n    \n    tmp_x = deepcopy(files)\n    \n    while True:\n        len_array = len(tmp_x)\n        if len_array < batch_size:\n          tmp_x = deepcopy(files)\n          len_array = len(tmp_x)\n\n        batch_index = np.random.choice(len_array, size=batch_size, replace=False)\n        batch_paths = [tmp_x[index] for index in batch_index]\n        tmp_x = np.delete(tmp_x, batch_index)\n        batch_input  = []\n        batch_output = [] \n        for input_path in batch_paths:\n            input_img = get_input(input_path)\n            output = get_output(input_path)\n            batch_input.append(input_img)\n            batch_output.append(output)\n        batch_x = np.array( batch_input )\n        batch_y = np.array( batch_output )\n\n        yield( batch_x, batch_y )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Train and test generator with TRAIN/TEST size + BATCH size "},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gen = image_generator(path_to_img_data[:TRAIN_SIZE],BATCH_SIZE)\ntest_gen = image_generator(path_to_img_data[TRAIN_SIZE:TRAIN_SIZE+TEST_SIZE],BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First test generation of data"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_example_data = next(test_gen)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plotting input and output data"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(plot_example_data[0][1].reshape(IMG_HEIGHT,IMG_WIDTH),cmap='gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(plot_example_data[1][1])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model of convolutional autoencoder"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(64, (3, 3), activation='relu', padding='same', strides=2, input_shape=(IMG_HEIGHT, IMG_WIDTH, 1)))\nmodel.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\nmodel.add(Conv2D(128, (3,3), activation='relu', padding='same', strides=2))\nmodel.add(Conv2D(256, (3,3), activation='relu', padding='same'))\nmodel.add(Conv2D(256, (3,3), activation='relu', padding='same', strides=2))\nmodel.add(Conv2D(512, (3,3), activation='relu', padding='same'))\nmodel.add(Conv2D(256, (3,3), activation='relu', padding='same'))\n\nmodel.add(Conv2D(128, (3,3), activation='relu', padding='same'))\nmodel.add(UpSampling2D((2, 2)))\nmodel.add(Conv2D(64, (3,3), activation='relu', padding='same'))\nmodel.add(UpSampling2D((2, 2)))\nmodel.add(Conv2D(32, (3,3), activation='relu', padding='same'))\nmodel.add(Conv2D(16, (3,3), activation='relu', padding='same'))\nmodel.add(Conv2D(3, (3, 3), activation='tanh', padding='same'))\nmodel.add(UpSampling2D((2, 2)))\nmodel.compile(optimizer='adam', loss='mse' , metrics=['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Train model"},{"metadata":{"trusted":true},"cell_type":"code","source":"STEP = TRAIN_SIZE//BATCH_SIZE\nEPOCHS = 25\nmodel.fit_generator(generator=train_gen,steps_per_epoch=STEP,epochs=EPOCHS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_img = next(test_gen)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plot - original data, input data, output data"},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted = model.predict(test_img[0])\n\nn = 5\nplt.figure(figsize=(15, 10))\nfor i in range(n):\n    # display original\n    plt.subplot(3, n, i + 1 )\n    plt.imshow(test_img[1][i].reshape(IMG_HEIGHT, IMG_WIDTH, 3))\n    plt.axis('off')\n    \n    \n    # display grayscale\n    plt.subplot(3, n, i + 1 + n )\n    plt.imshow(test_img[0][i].reshape(IMG_HEIGHT, IMG_WIDTH), cmap='gray')\n    plt.axis('off')\n    \n    # display predict\n    plt.subplot(3, n, i + 1 + n * 2 )\n    plt.imshow(predicted[i].reshape(IMG_HEIGHT, IMG_WIDTH, 3))\n    plt.axis('off')\n        \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}