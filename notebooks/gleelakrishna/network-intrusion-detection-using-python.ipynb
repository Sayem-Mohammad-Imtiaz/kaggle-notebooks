{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"from time import time\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom scipy.stats import chi2_contingency\nfrom sklearn import preprocessing\nfrom sklearn import model_selection\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(r'/kaggle/input/network-intrusion-detection/Train_data.csv')\ntest_df = pd.read_csv(r'/kaggle/input/network-intrusion-detection/Test_data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train dataset shape - \",train_df.shape)\nprint(\"Test dataset shape - \",test_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_columns', None)\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Notice that we dont have class column in test dataset, because we need to predict for the test dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Notice that only protocol_type, service, flag and class are object type and the rest columns are numerical type","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Exploratory analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"t0 = time()\nprint(train_df.groupby('protocol_type')['protocol_type'].count())\ntime() - t0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t0 = time()\npd.set_option('display.max_row', None)\nprint(train_df.groupby('class')['class'].count())\ntime() - t0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t0 = time()\nprint(train_df.groupby('flag')['flag'].count())\ntime() - t0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Statistical based feature selection","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"col_names = train_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(col_names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_cols = col_names.drop(['protocol_type', 'flag', 'service'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_df = train_df[num_cols].corr()\nsns.heatmap(corr_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the heatmap, we can notice that correlation for num_outbounds_cmds with other features is constant","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['num_outbound_cmds'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"num_outbound_cmds coulmn has 0 values for all records, so we can drop this column","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.drop('num_outbound_cmds', axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Find the feature that are highly correlated and drop one feature from highly correlated feature","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"highly_correlated_df = (corr_df.abs() > 0.9) & (corr_df.abs() < 1.0) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_var_index = (highly_correlated_df == True).any()\ncorr_var_names = corr_var_index[corr_var_index == True].index\n\nde_duplicate = []\ncorr_pairs = []\n\nfor i in corr_var_index.index:\n    row = highly_correlated_df[i]\n    de_duplicate.append(i)\n    for j in corr_var_names:\n        if j not in de_duplicate and row[j] == True:\n            print(i,j,\": \", corr_df.loc[i,j])\n            corr_pairs.append((i,j))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.drop(['num_root', 'srv_serror_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate',\n              'dst_host_rerror_rate', 'dst_host_srv_rerror_rate'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Perform Chi-Square test to check whether categorical features depend on the output value or not. Before that we need to encode the categorical features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_columns = ['protocol_type', 'service', 'flag']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[categorical_columns].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_encoder = preprocessing.LabelEncoder()\ntrain_df['protocol_type'] = label_encoder.fit_transform(train_df['protocol_type'])\ntrain_df['service'] = label_encoder.fit_transform(train_df['service'])\ntrain_df['flag'] = label_encoder.fit_transform(train_df['flag'])\ntrain_df['class'] = label_encoder.fit_transform(train_df['class'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[categorical_columns].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To calculate chi square test we need to contigency table. At first we consider protocol_type and class. Let's take the significant value be 0.05","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#p value is 0.0 which is less than significant value. Hence service and class are not independent\nchi2_contingency(pd.crosstab(train_df['service'], train_df['class']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#P value is 0.0 which is less than significant value. Hence flag and class are not independent\nchi2_contingency(pd.crosstab(train_df['flag'], train_df['class']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#p value is 0.0 which is less than significant value. Hence service and class features are not independent.\nchi2_contingency(pd.crosstab(train_df['service'], train_df['class']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Split data for training and validation of model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Split the data into 70:30.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Y = train_df['class']\ntrain_df.drop('class', axis=1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nX_train, X_valid, Y_train, Y_valid = model_selection.train_test_split(train_df, Y, test_size = 0.3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training the model","execution_count":null},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"model = LogisticRegression()\nmodel = model.fit(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(X_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics.confusion_matrix(Y_valid, pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics.f1_score(Y_valid, pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predicting for test data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Test data should pass through the same preprocessing steps as training data before prediction","execution_count":null},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"test_df.drop('num_outbound_cmds', axis = 1, inplace = True)\ntest_df.drop(['num_root', 'srv_serror_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate',\n              'dst_host_rerror_rate', 'dst_host_srv_rerror_rate'], axis = 1, inplace = True)\ntest_df['protocol_type'] = label_encoder.fit_transform(test_df['protocol_type'])\ntest_df['service'] = label_encoder.fit_transform(test_df['service'])\ntest_df['flag'] = label_encoder.fit_transform(test_df['flag'])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.predict(test_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We reached to the end by predicting the network intrusion type for the test data","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}