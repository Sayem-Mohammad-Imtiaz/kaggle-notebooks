{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# A Direct Comparison of SVM Kernel Performance In a Tri-class Classification Problem\n\nAs part of one of my modules for my University Computer Science course, I was tasked with conducting an AI/ML project using a dataset. I decided to conduct an experiment to determine the best kernel to use in tri-class classification. You can find the project sourcecode and my paper going more in depth into the project on my GitHub: https://github.com/Spectrum2511/SVM-Kernel-performance-comparison\n\n\n\n\nI found the Palmer Archipelago (Antarctica) penguin dataset which looked fun to play with. It contained three subspecies of penguin with a variety of variables. You can download it at:\n- Kaggle:https://www.kaggle.com/parulpandey/palmer-archipelago-antarctica-penguin-data, \n- GitHub:https://github.com/allisonhorst/palmerpenguins) ","metadata":{"_uuid":"44bcd5ae-2267-4507-8e29-417f5248f2cb","_cell_guid":"df1961e8-fe7f-4b89-bf1b-337ee03e5762","trusted":true}},{"cell_type":"code","source":"import numpy as np\nimport sklearn\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import figure\nfigure(num=None, figsize=(16, 12), dpi=80, facecolor='w', edgecolor='k')\nimport pandas as pd\nfrom sklearn import datasets\nimport sklearn\n\ndata = \"../input/palmer-archipelago-antarctica-penguin-data/penguins_size.csv\"\n\n_df = pd.read_csv(data)\n_df.columns = [\"Species\", \"Island\", \"Culmen Length (mm)\", \"Culmen Depth (mm)\", \"Flipper Length (mm)\", \"Body Mass (g)\", \"Sex\"]\n_df\ndf = _df[[\"Species\", \"Culmen Length (mm)\", \"Culmen Depth (mm)\", \"Flipper Length (mm)\", \"Body Mass (g)\"]].copy()\npenguins = df.dropna()\npenguins","metadata":{"_uuid":"31286801-7dd9-4524-98c5-9bb48b3c5e77","_cell_guid":"906155db-0bc8-4d92-b1c4-0a37c4e9808e","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With the data in a DataFrame, we can now try to find some correlation to make classification easier. I took the dataset into an R environment and found clustering when the data was plotted on a scatterplot of culmen length by culmen depth.\nThis graph can be recreated using the following R code, note that `df` is the variable holding the data in a `data.frame`:\n\n`plot <- ggplot(data=df, mapping = aes(x=penguins$`Culmen Length (mm)`, y=penguins$`Culmen Depth (mm)`, color=penguins$Species)) + geom_point()`","metadata":{}},{"cell_type":"code","source":"plt.scatter(penguins[\"Culmen Length (mm)\"], penguins[\"Culmen Depth (mm)\"])","metadata":{"_uuid":"7b67ae6b-af81-4e3a-8b28-b77ccfa2efbb","_cell_guid":"9d775213-ffff-41d7-954b-6bb47745fa4c","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now that we have some features to use, we now need to label each observation with a numerical value, something a computer can understand:","metadata":{}},{"cell_type":"code","source":"l = []\nfor i in range(len(penguins)):\n  if penguins.iloc[i, 0] == \"Adelie\":\n    l.append(-1)\n  if penguins.iloc[i, 0] == \"Chinstrap\":\n    l.append(0)\n  if penguins.iloc[i, 0] == \"Gentoo\":\n    l.append(1)\nprint(l) \n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This gets added to the dataframe under the column name \"target\":","metadata":{}},{"cell_type":"code","source":"target = pd.DataFrame(l, columns = [\"target\"])\n_raw = pd.concat([penguins, target], axis =1)\nraw = _raw.drop([\"Species\"], axis=1)\nraw = raw.dropna()\nraw.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`raw_df` is now our raw set of data, which now includes the target labels for each subspecies. Lets give it a good ol' shuffle:","metadata":{}},{"cell_type":"code","source":"raw_df = raw\n# Shuffle dataset\nrng = np.random.default_rng(0)\nXy_df = raw_df.iloc[rng.permutation(len(raw_df))].reset_index(drop=True)\n\ndisplay(Xy_df)\ndisplay(raw_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now lets seperate the bits that we **REALLY** need, this includes culmen length, culmen depth and the target labels. Here, we create two seperate numpy arrays: one being a subsection of the `xy_df` only containing the culmen length and depth values and the other being just the target labels.","metadata":{}},{"cell_type":"code","source":"# prepare NumPy ndarrays\nX = np.array(Xy_df[[\"Culmen Length (mm)\", \"Culmen Depth (mm)\"]]) # we are using data from the first two columns\ny = np.array(Xy_df['target'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we need to split each of these subsets into test/train sets. You will notice we are using a 30:70 train/test split. This is because we are testing these kernels under a worst case scenario, a stress test of sorts. ","metadata":{}},{"cell_type":"code","source":"#train points and new points must add up to 340\n\n#We are using an 30:70 train/test split to vary the results and to act as a \"worst case scenario\" to properly test the kernels.\nn_train_points = 102\nn_new_points = 238\n\n# Split the data into training/new data\nX_train = X[:n_train_points]\nX_new = X[n_train_points:n_train_points+n_new_points]\n\n# Split the targets into training/new data\ny_train = y[:n_train_points]\ny_true = y[n_train_points:n_train_points+n_new_points]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now that the test/train sets are sorted, we can not train our models. We will be using four different instances of SVM each with a different kernel: \n\n- Sigmoid \n- Linear \n- RBF \n- polynomial \n\nNote that we are using a Linear SVC rather than a SVM with a linear kernel. We train the models and then create predictions. ","metadata":{}},{"cell_type":"code","source":"%%time\nfrom sklearn import svm\nC = 1.0  # SVM regularization parameter\nmodels = (svm.SVC(kernel=\"sigmoid\", C=C),\n          svm.LinearSVC(C=C, max_iter=10000),\n          svm.SVC(kernel='rbf', gamma=0.7, C=C),\n          svm.SVC(kernel='poly', degree=3, gamma='auto', C=C))\n\nmodels = (clf.fit(X_train, y_train) for clf in models)\n\n# Make predictions using the testing set, one set of predictions per classifer\ny_pred = []\nfor clf in models:\n  y_pred.append(clf.predict(X_new))\ngraph_labels = [\"SVC w/ sigmoid Kernel\", \"Linear SVC\", \"SVC w/ rbf kernel\", \"SVC w/ polynomial kernel\"]\nprint(y_pred)\nprint(X_new)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We want some graphical representation to show how each of the models behave. This method creates a scatterplot showing the training datapoints and the predicted datapoints. One graph is produced per kernel. Wityh each of these graphs, the predicted points are triangles and the training points are dits, its the color of the individual points we are looking at, not their positioning.","metadata":{}},{"cell_type":"code","source":"from mlxtend.plotting import plot_decision_regions\n\ndef plot_graphs(labels, lab):\n  \n  xrange = [30, np.max(X_new[:,0])+2]\n  yrange = [10, np.max(X_new[:,1])+2]\n  print(xrange)\n  print(yrange)\n  step = 0.1\n  x = np.arange(xrange[0], xrange[1], step)\n  y = np.arange(yrange[0], yrange[1], step)\n  xx, yy = np.meshgrid(x, y)\n\n\n  #plottingthe predicted results\n  X_pred_Adelie = X_new[labels==-1, :]\n  X_pred_Chinstrap = X_new[labels==0, :]\n  X_pred_Gentoo = X_new[labels==1, :]\n\n  plt.figure(num=1, figsize=(16, 12))\n\n  plt.scatter(X_pred_Adelie[:, 0], X_pred_Adelie[:, 1],  color='red', label='predicted species = Adelie ' + str(lab), marker='^')\n  plt.scatter(X_pred_Chinstrap[:, 0], X_pred_Chinstrap[:, 1],  color='green', label='predicted species = Chinstrap ' + str(lab), marker='^')\n  plt.scatter(X_pred_Gentoo[:, 0], X_pred_Gentoo[:, 1],  color='blue', label='predicted species = Gentoo ' + str(lab), marker='^')\n\n  #plotting the training data\n  X_true_Adelie = X_train[y_train==-1, :]\n  X_true_Chinstrap = X_train[y_train==0, :]\n  X_true_Gentoo = X_train[y_train==1, :]\n\n  plt.scatter(X_true_Adelie[:, 0], X_true_Adelie[:, 1],  color='red', label='species = Adelie')\n  plt.scatter(X_true_Chinstrap[:, 0], X_true_Chinstrap[:, 1],  color='green', label='species = Chinstrap')\n  plt.scatter(X_true_Gentoo[:, 0], X_true_Gentoo[:, 1],  color='blue', label='species = Gentoo')\n\n  plt.xlim(xrange)\n  plt.ylim(yrange)\n\n  plt.xlabel(\"Culmen Length (mm)\")\n  plt.ylabel(\"Culmen Depth (mm)\")\n\n  plt.legend()\n  plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We also want to confusion matricies for more numerical data:","metadata":{}},{"cell_type":"code","source":"def display_conf_mat(labels, l):\n  print(l)\n  # The accuracy score: If 1 for perfect prediction\n  print('Accuracy: {:.4f}'.format(sklearn.metrics.accuracy_score(y_true, labels)))\n  # Confusion matrix\n  #print('Confusion matrix: ', sklearn.metrics.confusion_matrix(y_true, labels, normalize='all'))\n  # Visualize the confusion matrix\n  sklearn.metrics.ConfusionMatrixDisplay(sklearn.metrics.confusion_matrix(y_true, labels, normalize='all'), [\"Adelie\", \"Chinstrap\", \"Gentoo\"]).plot(cmap=plt.cm.Blues)\n  plt.grid(False)\n  # The classification report, which contains accuracy, precision, recall, F1 score\n  print(sklearn.metrics.classification_report(y_true, labels))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we can view the performance of each kernel:","metadata":{}},{"cell_type":"code","source":"for array, l in zip(y_pred, graph_labels):\n  plot_graphs(array, l)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for array, lab in zip(y_pred, graph_labels):\n  display_conf_mat(array, lab)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Sigmoid seems to fall flat with learning the Chinstrap and Gentoo classes and seems to predict all the points as being Adeline penguins. As with the other three, they all seem to perform well.\nLooking at the metrics, RBF scores the highest accuracy compared to the other three.\n\nPlease feel free to use this code and adapt it for other problems, maybe even increasing  the number of classes...","metadata":{}}]}