{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Predicting & Visualising Customer Churning\nThis notebook aims to visualise different features in this data, and use them to predict whether a customer will leave the credit card company."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nfrom collections import Counter\nfrom xgboost import XGBClassifier\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.decomposition import PCA\nfrom sklearn.svm import LinearSVC, SVC\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler as ss, MinMaxScaler as mms\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score, train_test_split\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/credit-card-customers/BankChurners.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop(['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1'], axis=1)\ndf = df.drop(['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2'], axis=1)\ndf = df.drop('CLIENTNUM', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop('Attrition_Flag', axis=1)\ny = df['Attrition_Flag']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Categorical visualisation\nThe first step in this dataset is the visualisation of the different features."},{"metadata":{},"cell_type":"markdown","source":"The below plot is a pie chart which shows that roughly 84% of customers in our data are staying with the same firm, while 16% left."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(7, 7))\ncount = Counter(y)\nax.pie(count.values(), labels=count.keys(), autopct=lambda p:f'{p:.2f}%')\nax.set_title('Percentage of existing and attrited customers')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The next graph is a bar chart which tells us the education level of the customers. Most of the people using the bank have some form of education, with only around 1,500 not being educated."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15, 6))\ncount = Counter(X['Education_Level'])\ncount = pd.Series(count).sort_values(ascending=False)\nlabels = []\n\nfor i in count.keys():\n    labels.append(i + ' (' + str(count[i]/len(X['Education_Level'])*100)[:5] + '%)')\n\nplt.bar(labels, count, color='blue')\nplt.title('Education level of the customers')\nplt.xlabel('Education level')\nplt.ylabel('Number of customers')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The distribution of gender for this bank is relatively equal, with there being only around 3% more women than men."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(7, 7))\ncount = Counter(X['Gender'])\n\nax.pie(count.values(), labels=count.keys(), autopct=lambda p:f'{p:.2f}%')\nax.set_title('Gender of customers')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The marital status of the customers in our bank shows us that around half are married, roughly 40% are single, and 7% are unknown and 7% divorced."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(8, 7))\ncount = Counter(X['Marital_Status'])\nlabels = []\n\nfor i in count:\n    labels.append(i + ' (' + str(count[i]/len(X['Marital_Status'])*100)[:5] + '%)')\n    \nplt.bar(labels, count.values(), color='green')\nplt.title('Marital status for customers')\nplt.ylabel('Number of customers')\nplt.xlabel('Marital status')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The vast majority (93%) of customers use blue cards, followed by Silver (5%), Gold (1%) and Platinum (0.2%)."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(7, 7))\ncount = Counter(X['Card_Category'])\n\nax.pie(count.values(), labels=count.keys(), autopct=lambda p:f'{p:.2f}%')\nax.set_title('Card category of customers')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The most common number of relationships people have had is three (22%), followed by four, five and six, which have roughly 18% each. Followed by that is 2 relationships (12%) and 1 relationship (9%)."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(7, 6))\ncount = Counter(X['Total_Relationship_Count'])\ncount = pd.Series(count).sort_values(ascending=False)\nlabels = []\n\nfor i in count.keys():\n    labels.append(str(i) + ' (' + str(count[i]/len(X['Total_Relationship_Count'])*100)[:5] + '%)')\n    \nplt.bar(labels, count, color='purple')\nplt.title('Number of relationships for customers')\nplt.ylabel('Customers')\nplt.xlabel('Number of relationships')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"More than a third of the people make less than $40K, and the next most common category is $40-60K, which is almost half as frequent. After that is $80-120K (15%), $60-80K (14%), Unknown (11%) and then $120K+ (7%)."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(8, 6))\ncount = Counter(X['Income_Category'])\n\nax.pie(count.values(), labels=count.keys(), autopct=lambda p:f'{p:.2f}%')\nax.set_title('Income per customer')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Numerical visualisation"},{"metadata":{},"cell_type":"markdown","source":"The features in our dataset have some correlation, for example, Months_on_book and Customer_age, Avg_Utilization_Ratio and Total_Revolving_Bal."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10, 5))\nsns.heatmap(X.corr(), annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To visualise that correlation, we will use a scattergraph on the six most correlatable features: '**Total_Trans_Amt**' and '**Total_Trans_Ct**', '**Total_Revolving_Bal**' and '**Avg_Utilization_Ratio**', '**Months_on_book**' and '**Customer_Age**'."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 5))\n\nax1.scatter(X['Total_Trans_Amt'], df['Total_Trans_Ct'])\nax2.scatter(X['Total_Revolving_Bal'], df['Avg_Utilization_Ratio'])\nax3.scatter(X['Months_on_book'], df['Customer_Age'])\n\nax1.set_xlabel('Total_Trans_Amt', fontsize=20)\nax1.set_ylabel('Total_Trans_Ct', fontsize=20)\n\nax2.set_xlabel('Total_Revolving_Bal', fontsize=20)\nax2.set_ylabel('Avg_Utilization_Ratio', fontsize=20)\n\nax3.set_xlabel('Months_on_book', fontsize=20)\nax3.set_ylabel('Customer_Age', fontsize=20)\n\nax2.set_title('Correlation of features', fontsize=40, pad=40)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Afterwards, we check the distribution of the five least evenly-distributed features and see how they change with log transform, box cox, standard scaler and min max scaler."},{"metadata":{},"cell_type":"markdown","source":"The graphs below show us that 'Credit_Limit' and 'Avg_Utilization_Ratio' work best without a transformation, 'Avg_Open_To_Buy' and 'Total_Amt_Chng_Q4_Q1' are best with box cox and 'Total_Trans_amt' needs the log transform on it."},{"metadata":{"trusted":true},"cell_type":"code","source":"cols =['Credit_Limit','Avg_Open_To_Buy','Total_Amt_Chng_Q4_Q1','Total_Trans_Amt','Avg_Utilization_Ratio']\n\nfor col in cols:\n    i = 0\n    \n    fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n    \n    f1 = df[col]\n    f2 = (df[col]+1).transform(np.log)\n    f3 = pd.DataFrame(stats.boxcox(df[col]+1)[0])\n    f4 = pd.DataFrame(ss().fit_transform(np.array(df[col]).reshape(-1, 1)))\n    f5 = pd.DataFrame(mms().fit_transform(np.array(df[col]).reshape(-1, 1)))\n    \n    for column in [[f1, 'cyan', 'Normal'], [f2, 'pink', 'Log'], [f3, 'lightgreen', 'Box Cox'], \n                   [f4, 'skyblue', 'Standard'], [f5, 'yellow', 'MinMax']]:\n        feature = column[0]\n        colour = column[1]\n        name = column[2]\n        \n        feature.hist(ax=axes[i], color=colour)\n        deciles = feature.quantile([.1, .2, .3, .4, .5, .6, .7, .8, .9])\n        \n        for pos in np.array(deciles).reshape(1, -1)[0]:\n            handle = axes[i].axvline(pos, color='darkblue', linewidth=1)\n\n        axes[i].legend([handle], ['decile'])\n        axes[i].set_xlabel(name)\n        \n        i += 1 \n    \n    axes[2].set_title(col, fontsize=15, pad=15)\n    axes[3].set_title('')\n    axes[4].set_title('')\n                    \n    plt.show()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"These techniques are applied below:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X['Credit_Limit'] = X['Credit_Limit']\nX['Avg_Open_To_Buy'] = stats.boxcox(X['Avg_Open_To_Buy']+1)[0]\nX['Total_Amt_Chng_Q4_Q1'] = stats.boxcox(X['Total_Amt_Chng_Q4_Q1']+1)[0]\nX['Total_Trans_Amt'] = (X['Total_Trans_Amt']+1).transform(np.log)\nX['Avg_Utilization_Ratio'] = X['Avg_Utilization_Ratio']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we will do some binning on the five features which have the widest range of values. We will reduce the amount of unique categories per feature from thousands to one hundred."},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in ['Credit_Limit', 'Total_Revolving_Bal','Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1', \n            'Total_Trans_Amt']:\n    col = X[i]\n    diff = col.max() - col.min()\n    bins = np.digitize(col, np.arange(col.min(), col.max(), (diff/100)).tolist())\n    X[i+'_bin'] = bins","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The final piece of feature visualisation that we will do is displaying the distribution of the binned variables, where we can see that they are roughly centered, except from 'Credit_Limit_bin'."},{"metadata":{"trusted":true},"cell_type":"code","source":"i = 0\ncols = ['Credit_Limit_bin', 'Total_Revolving_Bal_bin', 'Avg_Open_To_Buy_bin', 'Total_Amt_Chng_Q4_Q1_bin',\n        'Total_Trans_Amt_bin']\ncolours = ['pink', 'lightblue', 'lightgreen', 'skyblue', 'yellow']\n\nfig1, axes1 = plt.subplots(1, 2, figsize=(8, 3))\nfig2, axes2 = plt.subplots(1, 3, figsize=(15, 3))\n\nfor ax in axes1:\n    col = X[cols[i]]\n    pd.DataFrame(col).hist(ax=ax, color=colours[i])\n    deciles = col.quantile([.1, .2, .3, .4, .5, .6, .7, .8, .9])\n    \n    for pos in deciles:\n        handle = ax.axvline(pos, color='darkblue', linewidth=1.15)\n    \n    ax.legend([handle], ['decile'])\n    i += 1\n    \nfor ax in axes2:\n    col = X[cols[i]]\n    pd.DataFrame(col).hist(ax=ax, color=colours[i])\n    deciles = col.quantile([.1, .2, .3, .4, .5, .6, .7, .8, .9])\n    \n    for pos in deciles:\n        handle = ax.axvline(pos, color='darkblue', linewidth=1.15)\n    \n    ax.legend([handle], ['decile'])\n    i += 1\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predicting Customer Churn\nNow is the time to use our dataset to predict whether a customer will end their use of the credit card company."},{"metadata":{},"cell_type":"markdown","source":"We will firstly use a LabelEncoder to convert the 'Gender', 'Education_Level', 'Marital_Status', 'Income_Category', and 'Card_Category' columns from categorical into numerical. Afterwards, we split the X and y into train and test datasets. The train will have 80% of X and the test will have 20%."},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_cols = ['Gender','Education_Level', 'Marital_Status', 'Income_Category', 'Card_Category']\nfor col in cat_cols:\n    le = LabelEncoder()\n    X[col] = le.fit_transform(X[col])\n    \nle = LabelEncoder()\ny = le.fit_transform(y)\nX = X.drop(['Credit_Limit', 'Total_Revolving_Bal_bin', 'Avg_Open_To_Buy_bin', 'Total_Amt_Chng_Q4_Q1_bin',\n            'Total_Trans_Amt_bin'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count = Counter(y_train)\nprint('Distribution of target 1 & 2:', count[1], '&', count[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"However, the '0' target has 5 times less samples than the '1' target. Therefore, we will need to use SMOTE to resample it so that both can be even."},{"metadata":{"trusted":true},"cell_type":"code","source":"smote = SMOTE()\nX_train, y_train = smote.fit_resample(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count = Counter(y_train)\nprint('Distribution of target 1 & 2:', count[1], '&', count[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, we will create a selection of classifiers and use the best one for our final output. The predictors that will be used are XGBoost, Random Forest, K Nearest Neighbours, SGD Classifier and SVC."},{"metadata":{"trusted":true},"cell_type":"code","source":"classifiers = [[XGBClassifier(),'XGB Classifier'], [RandomForestClassifier(),'Random Forest'], \n    [KNeighborsClassifier(), 'K-Nearest Neighbours'], [SGDClassifier(),'SGD Classifier'], [SVC(),'SVC']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To evaluate the results of our models, we will loop over them, fit them with the train sets and display the results with the score, cross_val and roc_auc metrics."},{"metadata":{"trusted":true},"cell_type":"code","source":"score_list = []\ncross_val_list = []\nroc_auc_list = []\n\nfor classifier in classifiers:\n    model = classifier[0]\n    model.fit(X_train, y_train)\n    model_name = classifier[1]\n    \n    pred = model.predict(X_test)\n\n    score = model.score(X_test, y_test)\n    cross_val = cross_val_score(model, X_test, y_test).mean()\n    roc_auc = roc_auc_score(y_test, pred)\n    \n    score_list.append(score)\n    cross_val_list.append(cross_val)\n    roc_auc_list.append(roc_auc)\n    \n    print(model_name, 'model score:     ' + str(round(score*100, 2)) + '%')\n    print(model_name, 'cross val score: ' +str(round(cross_val*100, 2)) + '%')\n    print(model_name, 'roc auc score:   ' + str(round(roc_auc*100, 2)) + '%')\n    \n    if model_name != classifiers[-1][1]:\n        print('')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As seen from the bar chart below, the XGBoost and the Random Forest consistently crush the rest of the competition. However, through a small margin, the winning model is the XGBoost Classifier. This predictor manages to achieve very high accuracies of **96%, 95%, and 94%**."},{"metadata":{},"cell_type":"markdown","source":"The Random Forest achieves slightly lower than this, with **95%, 93% and 92%**."},{"metadata":{},"cell_type":"markdown","source":"Next is the K-Nearest Neighbours achieving **81%, 88% and 79%**."},{"metadata":{},"cell_type":"markdown","source":"The SGD and SVC classifiers manage to get accuracies ranging from **40% to 84%**"},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = ['XGBoost', 'Random Forest', 'KNN', 'SGD Classifier', 'SVC']\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 5))\n\nax1.bar(labels, score_list, color='blue')\nax2.bar(labels, cross_val_list, color='red')\nax3.bar(labels, roc_auc_list, color='green')\n\nax1.set_title('Model score')\nax2.set_title('Cross validation score')\nax3.set_title('ROC AUC score')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have chosen the XGBoost Classifier as the one to make our final prediction with, and the results are shown below."},{"metadata":{"trusted":true},"cell_type":"code","source":"model = XGBClassifier()\nmodel.fit(X_train, y_train)\npred = model.predict(X_test)\n\nscore = model.score(X_test, y_test)\ncross_val = cross_val_score(model, X_test, y_test).mean()\nroc_auc = roc_auc_score(y_test, pred)\n\nprint('model score:     ' + str(round(score*100, 2)) + '%')\nprint('cross val score: ' +str(round(cross_val*100, 2)) + '%')\nprint('roc auc score:   ' + str(round(roc_auc*100, 2)) + '%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Thank you for reading my notebook."},{"metadata":{},"cell_type":"markdown","source":"### If you enjoyed this notebook and found it helpful, please upvote it so that I can make more of these."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}