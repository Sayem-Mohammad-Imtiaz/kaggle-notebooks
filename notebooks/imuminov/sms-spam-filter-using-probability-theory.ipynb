{"cells":[{"metadata":{},"cell_type":"markdown","source":"# SMS Spam Filter Using Probability theory\n\nThis project is about building an SMS Spam filter algorithm. The algorithm will be developed based on Naive Bayes theorem. What it essentially does is that it uses a dataset containing sms messages that are flagged as spam or non-spam and learns from that. Based on the knowledge built on the data, the algorithm will classify new messages whether they are spam or ham.\n\nThe dataset was put together by Tiago A. Almeida and José María Gómez Hidalgo, and it can be downloaded from the [The UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection). You can also download the dataset directly [from this link](https://dq-content.s3.amazonaws.com/433/SMSSpamCollection). The data collection process is described in more details on [this page](http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/#composition), where you can also find some of the authors' papers.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#loading the necessary modules and loading the data\nimport pandas as pd\nimport numpy as np\n\n# reading in the data with correct encoding, utf-8 throws and error.\nmessages = pd.read_csv('../input/sms-spam-collection-dataset/spam.csv',encoding='ISO-8859-1')\n\n# removing two unnecessary cols\nmessages = messages[['v1', 'v2']]\nmessages = messages.rename({'v1': 'Label',\n                           'v2': 'SMS'}, axis=1)\nmessages.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we have made cols easily distinguishable by renaming them to `label` and `sms`\n\nOur data set contains 2 columns and 5572 rows, and it has no NA values, which means no need for data cleaning.\n\n**Let's find out the proportion of spam vs ham messages**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"round(messages['Label'].value_counts(normalize=True)*100)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"We can see that **87%** of messages are non-spam, and **13%** is flagged as spam. These are prior probabilities that will be useful in our calculations.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Seperating the dataset into train and test\n\nIt is important to think of testing the algorithm before we go about creating it. A good idea is to split the data into *train and test* so that:\n- Train dataset will be used to train the model\n- test will be used to test how good our model actually is.\n\nFor Training we will use **80% ~4,458 messages** of the data, and the rest **20% ~1,114 messages** will be for testing.\n\n### Our final goal. \n\nOur goal is to achieve 80%+ accuracy with our model. \n\nWe will split the data into two parts, but before, we will randomize the dataset so that our spam and ham messages are spread across the dataset. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#randomizing the dataset before we split. \nmessages = messages.sample(frac=1, random_state=1)\n\n#importing display module for displaying several tables/graphs\nimport IPython.display\n\n#seperating train 80%, and test 20%\ntrain = messages.iloc[:4458, :]\ntest = messages.iloc[4458:, :]\n\ndisplay(round(test['Label'].value_counts(normalize=True)*100))\ndisplay(round(train['Label'].value_counts(normalize=True)*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We successfully split the datasets, and the resulting datasets have **exact proportion** of spam/ham messages. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Training the Algorithm on *train* dataset\n\n### Data cleaning.\n\nBefore we start building our algorithm we need to clean our data for easier calculation. \nHere are the things important for our model:\n- A vocabulary: consists all the unique words in our entire train data\n- number of unique words in each message\n\nIn order to get the # of unique words in each message, we will create columns that represent each unique word, and each row will show how many times each words was repeated in each message.\n\nFirst, we need to remove the punctutation from all messages, as we don't need them for analysis.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"'''removing punctuation from messages. \nre.sub('\\W', ' ', 'Message') This is our regex for replacing any upper/lowercase \ncharacter that is not a letter, digits.'''\npd.options.mode.chained_assignment = None\n\n\ntrain['SMS'] = train['SMS'].str.replace(r'\\W', ' ')\ntrain['SMS'] = train['SMS'].str.lower()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have removed the punctutation and made all letters lowercase. \n\nNow it is time to transform our dataset with cols each representing unique word in our vocabulary. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating a vocabulary containing all unique words from all messages.\nvocabulary = []\n\nfor sms in train['SMS'].str.split():\n    for word in sms:\n        vocabulary.append(word)\n\nvocabulary = list(set(vocabulary))\nlen(vocabulary)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A simple operation of converting messages to a list of words, and transforming a list into set to remove duplicates and back to list - gave us a list of unique words.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Transforming the train dataset into word count of each unique word for each sms/row\n\nThe below code will help create a frequency dictionary of each row in our train dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Function to create a dictionary of words with word count for each SMS.\nword_counts_per_sms = {unique_word: [0] * (len(train['SMS'])) for unique_word in vocabulary}\n\nfor index, sms in enumerate(train['SMS'].str.split()):\n    for word in sms:\n        word_counts_per_sms[word][index] += 1\n        \n# transforming dictionary to a dataframe.\nfinal_training = pd.DataFrame(word_counts_per_sms)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have created a frequency of each word for every message in our train dataset, In order to better see the data, we will combine this new dataframe with our existing train dataset. The resulting dataset will be called **final_training_set**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#concatenating the train and final_training datasets.\ndfs = [train, final_training]\nfinal_training_set = pd.concat(dfs, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Starting the algorithm\n\nNow that we have our training dataset ready, we can start building our model based on Multinomial Naive Bayes Theorem. \n\nThe formula for Multinomial Naive Bayes Algorithm is the following. \n\n![P(Spam|Words)](https://i.ibb.co/jhVKFb2/p-spam-given-words.png)\n![P(Ham|Words)](https://i.ibb.co/tssQ9Pm/p-ham-given-words.png)\n\nWe will be comparing the result of the first formula to the second, and \n- **if P(Spam|Words) > P(Ham|Words)**, the message will be marked **spam**\n- **if P(Spam|Words) < P(Ham|Words)**, the message will be marked **ham**\n- **if P(Spam|Words) < P(Ham|Words)**, we will need **human judgement** for these messages, as the algorithm could not classify","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# finding probabilities of spam and ham messages\np_ham_spam = round(final_training_set['Label'].value_counts(normalize=True),2)\np_ham = p_ham_spam['ham']\np_spam = p_ham_spam['spam']\n\n\n#seperating ham and spam messages\nham_messages = final_training_set.loc[final_training_set['Label']=='ham', 'SMS']\nspam_messages = final_training_set.loc[final_training_set['Label']=='spam', 'SMS']\n\n\n#counting number of words for ham and spam messages seperately\nn_ham = 0\nn_spam = 0\n\n\nfor message in ham_messages:\n    message = str(message)\n    message = message.split()\n    n_ham += len(message)\n\nfor message in spam_messages:\n    message = str(message)\n    message = message.split()\n    n_spam += len(message)\n    \n# Lapllace smoothing with a = 1\na = 1\n\n\n# number of words in vocabulary\nn_vocabulary = len(vocabulary)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Above, we calculated constants that will be used in our model. Now we will calculate two important probabilities.\n\n- **P of a word given spam message**\n- **P of a word given ham message**\n\nHere is the formula for calculating these values for each word.\n\n![p_words_given_ham_spam](https://i.ibb.co/yNgZ4QC/p-words-given-ham-spam.png)\n\n- **N(w|spam)** - total number that the word appears in spam messages\n- **N(w|ham)** - total number that the word appears in ham messages\n- **N(spam)** - total number of words in spam messages\n- **N(ham)** - total number of words in ham messages\n- **a** - is alpha for Laplace smoothing\n\n[Laplace/additive smoothing](https://en.wikipedia.org/wiki/Additive_smoothing) is a technique used to avoid having 0 probabilities, as some words might have appearances in either of the categories. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# we will create two dictionaries to store probabilities for each type of message\np_word_given_spam = {unique_word:0 for unique_word in vocabulary} \np_word_given_ham = {unique_word:0 for unique_word in vocabulary} \n\n\n# we will create a counter of each type of word using collections.Counter object\nimport collections\n\n\nspam_words = []\nham_words = []\nfor message in ham_messages.str.split():\n    for word in message:\n        ham_words.append(word)\nfor message in spam_messages.str.split():\n    for word in message:\n        spam_words.append(word)\n     \n    \n# Now that we have a list of all spam/ham words, we will create a dictionary of their count. \nham_word_count = collections.Counter(ham_words)\nspam_word_count = collections.Counter(spam_words)\n\nfor word in vocabulary:\n    n_ham_word = ham_word_count[word]\n    n_spam_word = spam_word_count[word]\n    \n    p_word_given_spam[word] = (n_spam_word + a) / (n_spam + a * n_vocabulary)\n    p_word_given_ham[word] = (n_ham_word + a) / (n_ham + a * n_vocabulary)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Classifying a new Message\n\nWe are ready to write our final algorithm and function that classifies a new message as spam or ham.\n\nThe function will take a string as an input and formats it as necessary. After having a message in a desired fashion, the function will calculate the probabilities for both spam and ham, after that classify the message depending on the probability results. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\n\ndef classify(message):\n\n    message = re.sub('\\W', ' ', message)\n    message = message.lower()\n    message = message.split()\n\n    \n    # calculation of probabilities for spam and ham\n    p_spam_given_message = p_spam\n    p_ham_given_message = p_ham\n    \n    \n    #iterate\n    for word in message:\n        if word in p_word_given_spam:\n            p_spam_given_message *= p_word_given_spam[word]\n        if word in p_word_given_ham:\n            p_ham_given_message *= p_word_given_ham[word]\n    \n\n    #classification based on comparison results\n    if p_ham_given_message > p_spam_given_message:\n        return 'ham'\n    elif p_ham_given_message < p_spam_given_message:\n        return 'spam'\n    else:\n        return 'needs human classification!'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have created the classify function, now we will apply this on two custom messages, Note that these messages are deliberately made easy as spam or ham only for testing.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"message_1 = 'WINNER!! This is the secret code to unlock the money: C3421.'\nmessage_2 = \"Sounds good, Tom, then see u there\"\nclassify(message_1), classify(message_2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Applying our function on test data.\n\nSo now we have the algorithm ready to go with our test dataset. Test dataset has never been applied to our algorithm, so it is a new message with respect to algorithm perspective. \n\nWe will create a new col in test dataset called **'predicted'** that will store results of our function output. After that we will be able to compare our predictions with our actual human classified labels.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# applying our function to our test dataset\ntest['predicted'] = test['SMS'].apply(classify)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Checking accuracy of our function","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# we will check the accuracy of our model. \ncorrect = 0\ntotal = len(test.SMS)\n\nfor row in test.iterrows():\n    label = row[1][0]\n    predicted = row[1][2]\n    if label == predicted:\n        correct += 1\naccuracy = round((correct / total) * 100, 2)\naccuracy","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Final Result\n\nOur model is predicting the message with 98.74% accuracy, which is much higher than I expected. This was a fun project to work with, thank you. ","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}