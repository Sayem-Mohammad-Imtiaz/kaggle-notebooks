{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"! pip install lazypredict","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport inspect # Debugging \n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ndata    = pd.read_csv(\"../input/heart-failure-clinical-data/heart_failure_clinical_records_dataset.csv\")\ncolumns = data.columns.values\n\n# No NaNs\n# data.isna().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlations\nfrom sklearn.decomposition import PCA \nimport matplotlib.pyplot as plt\n\ncorr = data.corr()\n\n# PCA\npca          = PCA(n_components=2)\nreduced_data = pca.fit_transform(data.values) \n\nfig, (corr_ax, pca_ax) = plt.subplots(1, 2, figsize=(16,8))\ncorr_ax.imshow(corr)\ncorr_ax.set_xticks(np.arange(len(columns)))\ncorr_ax.set_yticks(np.arange(len(columns)))\ncorr_ax.set_xticklabels(columns)\ncorr_ax.set_yticklabels(columns)\ncorr_ax.set_title(\"Correlations\")\nplt.setp(corr_ax.get_xticklabels(), rotation=45, ha=\"right\",\n         rotation_mode=\"anchor\")\n\nscatter = pca_ax.scatter(reduced_data[:, 0], reduced_data[:, 1], \n               c=data[\"DEATH_EVENT\"].values) \npca_ax.set_xticklabels([])\npca_ax.set_yticklabels([])\npca_ax.set_xticks([])\npca_ax.set_yticks([])\npca_ax.legend(*scatter.legend_elements(), title=\"Legend\")\npca_ax.set_title(\"PCA\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting \n\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.preprocessing   import StandardScaler\nfrom sklearn.neighbors       import LocalOutlierFactor\n\ntrain  = data.drop(columns=[\"DEATH_EVENT\"]).values\ntarget = data[\"DEATH_EVENT\"].values\n\nlof       = LocalOutlierFactor(n_neighbors=5)\noutliers  = lof.fit_predict(train)\nto_delete = np.where(outliers == -1)\nprint(f\"Initial num. of rows: {len(train)}, rows dropped: {len(to_delete[0])}\")\n\ntrain  = np.delete(train, to_delete, 0)\ntarget = np.delete(target, to_delete, 0)\n\nscaler = StandardScaler()\ntrain  = scaler.fit_transform(train)\n\nsss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=68)\nfor train_index, test_index in sss.split(train, target):\n    x_train, y_train = train[train_index, :], target[train_index]\n    x_test, y_test   = train[test_index, :], target[test_index]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Quick models evaluation\n\nfrom lazypredict.Supervised import LazyClassifier\nfrom sklearn.metrics        import recall_score\n\nclf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=recall_score)\nmodels, predictions = clf.fit(x_train, x_test, y_train, y_test)\n\nprint(models)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model(s) testing\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics         import make_scorer, accuracy_score, recall_score\n\nfrom sklearn.linear_model  import LogisticRegression\nfrom sklearn.svm           import SVC\nfrom sklearn.ensemble      import BaggingClassifier\nfrom sklearn.neighbors     import NearestCentroid\n\nfrom xgboost import XGBClassifier\n\nestimators = {\"LogisticRegression\": {\"func\"  : LogisticRegression(),\n                                     \"params\": {\"C\": [0.1, 0.5, 1, 1.5, 2]}},\n              \"SVC\"               : {\"func\"  : SVC(),\n                                     \"params\": {\"kernel\": [\"poly\",\n                                                           \"rbf\"],\n                                                \"C\"     : [0.1, 0.5, 1, 1.5, 2],\n                                                \"gamma\" : [\"scale\", \"auto\"],\n                                                \"shrinking\"  : [True, False],\n                                                \"probability\": [True, False]}},\n              \"BaggingClassifier\" : {\"func\"  : BaggingClassifier(),\n                                     \"params\": {\"n_estimators\": [10, 20, 30, 40, 50],\n                                                \"max_samples\" : [0.2, 0.4, 0.6, 0.8, 1.0],\n                                                \"max_features\": [0.2, 0.4, 0.6, 0.8, 1.0],\n                                                \"bootstrap\"   : [True, False],\n                                                \"bootstrap_features\": [True, False],\n                                                \"oob_score\"         : [True, False],\n                                                \"warm_start\"        : [True, False]}},\n             \"XGBClassifier\"      : {\"func\"  : XGBClassifier(),\n                                     \"params\": {\"n_estimators \"   : [20],\n                                                \"max_depth \"      : [6],\n                                                \"learning_rate\"   : [0.05],\n                                                \"booster\"         : [\"gbtree\", \"gblinear\", \"dart\"],\n                                                \"min_child_weight\": [0.1, 0.5, 0.8],\n                                                \"colsample_bytree\": [0.4, 0.6, 0.8, 1],\n                                                \"subsample\"       : [0.5, 0.75, 1],\n                                                \"n_jobs\":           [-1]}},\n             \"NearestCentroid\"    : {\"func\"  : NearestCentroid(),\n                                     \"params\": {\"metric\": [\"euclidean\", \"manhattan\"]}}}\n\n#models_to_test = estimators.keys()\nmodels_to_test = [\"NearestCentroid\"]\n\nfor estimator_name in models_to_test:\n    model = GridSearchCV(estimator=estimators[estimator_name][\"func\"],\n                        param_grid=estimators[estimator_name][\"params\"],\n                        scoring=make_scorer(recall_score),\n                        n_jobs=-1)\n    model.fit(x_train, y_train)\n    preds  = model.predict(x_test)\n    recall = recall_score(y_test, preds)\n    acc    = accuracy_score(y_test, preds)\n    print(f\"{estimator_name}: \\n REC: {recall}, \\n ACC: {acc}, \\n BEST PARAM: {model.best_params_} \\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import plot_confusion_matrix\n\nplot_confusion_matrix(model, x_test, y_test)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}