{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Importing the Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/company-bankruptcy-prediction/data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# splitting in X (features) and y (target)\nX_df = df[df.columns[1:]]\n\ny_df = pd.DataFrame(df['Bankrupt?'])\ny_df.columns = ['Bankrupt?']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Data Preprocessing\n\n## 2.1 Check missing Values and categorical values"},{"metadata":{"trusted":true},"cell_type":"code","source":"# check if there are missing values\n\nprint('Missing values in X_df: {}'.format(X_df.isnull().values.any()))\nprint('Missing values in y_df: {}'.format(y_df.isnull().values.any()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check if there are categorical features\n\nnumCols = X_df.select_dtypes('number').columns\ncatCols = X_df.select_dtypes('object').columns\n\nnumCols= list(set(numCols))\ncatCols= list(set(catCols))\n\nprint('Number of numerical features: {}'.format(len(numCols)))\nprint('Number of categorical features: {}'.format(len(catCols)))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.2 Feature Scaling"},{"metadata":{"trusted":true},"cell_type":"code","source":"# features scaling preserving the flag features\n\nfrom sklearn.preprocessing import StandardScaler\n\ndef get_scaling(X_df, flag_features):\n    \n    '''\n    The function takes in input the original dataframe X_df and\n    a list of index corresponding to the flag features \n    (i.e., features with values 0,1,2 etc., for example obtained \n    with One Hot Encoder if categorical in the original dataframe).\n\n    First, the function scales all the features.\n\n    The flag features should not be scaled: thus, the function\n    drops all the flag features in a for loop from the scaled dataframe.\n\n    Then, the flag features from the original dataframe are added to the\n    scaled dataframe with their original values.\n    '''\n    \n    sc = StandardScaler()\n\n    X_scaled = pd.DataFrame(sc.fit_transform(X_df))\n\n    X_scaled.columns = X_df.columns\n    \n    X_flag = []\n    flag_names = []\n    \n    for flg_ftrs in flag_features:\n        \n        X_scaled = X_scaled.drop([X_df.columns[flg_ftrs]],axis = 1)\n        \n        print('Flag feature with index {}: {}'.format(flg_ftrs,X_df.columns[flg_ftrs]))\n        \n        X_flag.append(pd.DataFrame(X_df.values[:,flg_ftrs]))\n        flag_names.append(X_df.columns[flg_ftrs])\n        \n    X_flag = pd.concat(X_flag, axis = 1)\n    X_flag.columns = flag_names\n    \n    X_scaled = pd.concat([X_scaled, X_flag],axis = 1)\n    \n    return X_scaled","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# flag features 84: Liability-Assets Flag\n# flag features 93: Net Income Flag\n\nX_scaled = get_scaling(X_df, flag_features = [84,93])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.3 Visualize data distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"# features distribution after scaling\n\nimport seaborn as sns\n\nfig = plt.figure(figsize = (20,5))\n\nax = fig.add_subplot(1,2,1)\nX_scaled.boxplot()\n\nax = fig.add_subplot(1,2,2)\nsns.histplot(y_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can notice two aspects:\n\n1) There are **many outliers** in the dataset\n\n2) The dataset is **clearly imbalanced** because the majority of the instances belong to the negative class 0 (Not Bankrupted). We can visualize the imbalance also in a scatter plot.\n\nLet's visualize the data in a scatterplot:"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (20,20))\n\nfor i in range(9):\n    \n    fig.add_subplot(3,3,i+1)\n    \n    ax_1 = 3*i\n    ax_2 = 2*i+1\n\n    plt.scatter(X_scaled.values[np.where(y_df == 0),ax_1],X_scaled.values[np.where(y_df == 0),ax_2], c = 'b')\n    plt.scatter(X_scaled.values[np.where(y_df == 1),ax_1],X_scaled.values[np.where(y_df == 1),ax_2], c = 'r')\n    plt.xlabel(X_scaled.columns[ax_1])\n    plt.ylabel(X_scaled.columns[ax_2])\n    plt.legend(['Not Bankrupted','Bankrupted'])\n\n\n    \n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.4 Dealing with Imbalanced Dataset\n\nThere are different techniques to deal with **imbalanced datasets** (https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/). In particular one can:\n\n**1) Resampling the dataset**: Adding copies of instances from the under-represented class called over-sampling (or more formally sampling with replacement), or deleting instances from the over-represented class, called under-sampling.**\n\n**2) Generating synthetic samples from the minority class.** The most popular of such algorithms is called **SMOTE or the Synthetic Minority Over-sampling Technique.** SMOTE is an oversampling method. It works by creating synthetic samples from the minor class instead of creating copies. The algorithm selects two or more similar instances (using a distance measure) and perturbing an instance one attribute at a time by a random amount within the difference to the neighboring instances.**\n\n\nIn this example, we use the **SMOTE algorithm (generation of synthetic samples from the minority class**."},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\nsmote = SMOTE()\n\nX_smote, y_smote = smote.fit_resample(X_scaled, y_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data distribution before and after SMOTE\n\nfig = plt.figure(figsize = (20,5))\n\nax = fig.add_subplot(1,2,1)\nsns.histplot(y_df)\nplt.title('Imbalanced Dataset',fontsize  = 20)\n\nax = fig.add_subplot(1,2,2)\nsns.histplot(y_smote)\nplt.title('SMOTE Dataset',fontsize  = 20)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.5 Removing Outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"# function to remove the outliers from the dataset (data which fall outside of the whiskers in the box plot)\n# the outliers are removed for each feature separately. It can happen that data that are outliers\n# for a certain feature are not outliers for another feature. \n# The threshold to consider data outliers or not is defined by q. \n\n# upper quartile or 75h percentile (Q3): value for which 75% of the data are less than this value (upper threshold of the box)\n# lower quartile or 25th percentile (Q1): value for which 25% of the data are less than this value (lower theshold of the box)\n# iqr: distance between the upper and lower quartile: Q3 - Q1\n\n# upper whisker: Q3 + q*iqr\n# lower whisler: Q1 - q*iqr\n\n# data > upper whisker or < lower whisker : outliers\n\n# q controls the amount of data to consider as outliers\n\ndef get_remove_outliers(X,y,q):\n    \n    data = np.column_stack((X.values,y.values))\n    \n    for j in range(data.shape[1]):\n    \n        median = np.median(data[:,j])\n        \n        upper_quartile = np.percentile(data[:,j], 75)\n        lower_quartile = np.percentile(data[:,j], 25)\n\n        iqr = upper_quartile - lower_quartile\n        upper_whisker = (data[:,j][data[:,j] <= upper_quartile + q * iqr]).max()\n        lower_whisker = (data[:,j][data[:,j] >= lower_quartile - q * iqr]).min()\n        \n        data_clean = data[data[:,j] <= upper_whisker]\n        data_clean = data_clean[data_clean[:,j] >= lower_whisker]\n        \n        data = data_clean\n        \n        \n    X_clean = pd.DataFrame(data_clean[:,:data_clean.shape[1] - 1])\n    X_clean.columns = X.columns\n    \n    y_clean = pd.DataFrame(data_clean[:,data_clean.shape[1] - 1])\n    y_clean.columns = y.columns\n    \n    return X_clean,y_clean","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q = 11\n\nX_clean, y_clean = get_remove_outliers(X_smote,y_smote, q)\n\nfraction_removed_outliers =  1 - X_clean.shape[0] / X_scaled.shape[0]\n\nprint('Removed {:.1f} % data'.format(fraction_removed_outliers * 100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data distribution after removing outliers\n\nfig = plt.figure(figsize = (20,10), dpi = 200)\n\nax = fig.add_subplot(2,2,1)\nX_smote.boxplot()\nplt.title('X before removing outliers', fontsize = 20)\n\nax = fig.add_subplot(2,2,2)\nsns.histplot(y_smote)\nplt.title('y before removing outliers', fontsize = 20)\n\nax = fig.add_subplot(2,2,3)\nX_clean.boxplot()\nplt.title('X after removing outliers', fontsize = 20)\n\nax = fig.add_subplot(2,2,4)\nsns.histplot(y_clean)\nplt.title('y after removing outliers', fontsize = 20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Removing 13.2% of the outliers we obtain features distributions which are closer to the mean. Before removing the outliers, we had huge variance, for example some features were from -80 to +80. After removing the outliers, the features range is concentrated between -9 and +6. Removing the outliers has resulted in having a low imbalance of the negative class, but compared to the original imbalance rate, this scenario is more than acceptable.\n\nLet's visualize the boxplots and the histogram of a smaller set of features for a more clear representation.\n\n**Boxplots**"},{"metadata":{"trusted":true},"cell_type":"code","source":"features = X_smote.columns[29: 32]\n\nfig = plt.figure(figsize = (10,5), dpi = 100)\n\nX_smote[features].boxplot()\nplt.title('X before removing outliers Boxplot', fontsize = 20)\n\nfig = plt.figure(figsize = (10,5), dpi = 100)\n\nX_clean[features].boxplot()\nplt.title('X after removing outliers Boxplot', fontsize = 20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Histograms**"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (10,10), dpi = 200)\n\nX_scaled[features].hist(bins = 100, figsize = (20,10), edgecolor='white')\nplt.title('X before removing outliers Boxplot', fontsize = 20)\n\n\nfig = plt.figure(figsize = (10,10), dpi = 200)\n\nX_clean[features].hist(bins = 50, figsize = (20,10), edgecolor='white')\nplt.title('X before removing outliers Boxplot', fontsize = 20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can visualize the stastical parameters (mean,std,min, lower whisker (25%), mean (50%), upper whisker (75%) and max:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_clean.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Visualizing the data into a scatter plot we can realize that we have sufficient balance between the two classes now."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (20,20))\n\nfor i in range(9):\n    \n    fig.add_subplot(3,3,i+1)\n    \n    ax_1 = 3*i\n    ax_2 = 2*i+1\n\n    plt.scatter(X_clean.values[np.where(y_clean == 0),ax_1],X_clean.values[np.where(y_clean == 0),ax_2], c = 'b')\n    plt.scatter(X_clean.values[np.where(y_clean == 1),ax_1],X_clean.values[np.where(y_clean == 1),ax_2], c = 'r')\n    plt.xlabel(X_clean.columns[ax_1])\n    plt.ylabel(X_clean.columns[ax_2])\n    plt.legend(['Not Bankrupted','Bankrupted'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's define X,y as the dataset with removed outliers\n\nX,y = X_clean, y_clean","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Features Selection using Random Forest Classifier with number of features chosen via Cross-Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\n\ndef get_RF_features_importances(X,y,n_features, plot):\n    \n    rf = RandomForestClassifier()\n    \n    rf.fit(X,y)\n    \n    features_names = X.columns\n    \n    data = {'feature_name' : features_names,'feature_importance' : rf.feature_importances_}\n    \n    fi_df = pd.DataFrame(data)\n    \n    #Sort the DataFrame in order decreasing feature importance\n    fi_df.sort_values(by = ['feature_importance'], ascending=False,inplace=True)\n    \n    selected_features = fi_df['feature_name'].values[:n_features]\n    \n    X_rf = X[selected_features]\n    \n    if plot:\n\n        #Define size of bar plot\n        plt.figure(figsize = (20,16))\n        #Plot Searborn bar chart\n        sns.barplot(x = fi_df['feature_importance'], y = fi_df['feature_name'])\n        #Add chart labels\n        plt.title('Random Forest Feature Importance')\n        plt.xlabel('Feature Importance')\n        plt.ylabel('Feature Name')\n    \n\n    return X_rf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_features = 20\n\nX_rf = get_RF_features_importances(X,y.values.ravel(),n_features, plot = True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_rf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n\ncv = 10\n\nn_features = [1, 5, 10, 15, 20, 25,30,35, 40]\n\ncv_score = []\n\n\nfor n_ftrs in n_features:\n    \n    X_rf = get_RF_features_importances(X,y.values.ravel(),n_ftrs, plot = False)\n\n    rf_clf = RandomForestClassifier()\n    \n    cross_val = cross_val_score(estimator = rf_clf, X = X_rf.values, y = y.values.ravel(), cv = cv)\n    \n    cv_score.append(np.average(cross_val))\n    \n    \nplt.plot(np.array(n_features),np.array(cv_score),'bo-')\nplt.xlabel('N. features')\nplt.ylabel('Cross-Val Accuracy')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With Random Forest, we have identified 35 features wich are important to predict the target. Using this smalles subset of features, it is possible to achieve a validation accuracy ~98%"},{"metadata":{},"cell_type":"markdown","source":"# 4. Data Analysis on the Preprocessed Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# first we get Random Forest dataset for the original dataset, not training/test separately\n\nn_features = 35\n\nX_rf = get_RF_features_importances(X,y.values.ravel(), n_features = 35, plot = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.1 Features Correlations"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(28,24))\n\nmask = np.zeros_like(pd.concat([y,X_rf],axis = 1).corr(), dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\nsns.heatmap(pd.concat([y,X_rf],axis = 1).corr(), \n            mask=mask,\n            vmin=-1, vmax=1, cmap=sns.diverging_palette(20, 220, as_cmap=True), annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As expected, all the features extracted by Random Forest are correlated to the target. With the heatmap, we can identify some patterns in the data and identify the features with the strongest positive and negative correlations with the target. The barplot below sorts the features by strongest positive/negative correlations."},{"metadata":{"trusted":true},"cell_type":"code","source":"features_names = X_rf.columns\n\ncorr = pd.concat([y,X_rf],axis = 1).corr().values[0,1:]\n    \ndata = {'feature_name' : features_names, 'corr' : corr}\n    \ncorr_df = pd.DataFrame(data)\n    \n#Sort the DataFrame in order decreasing feature importance\ncorr_df.sort_values(by = ['corr'], ascending = False,inplace=True)\n\nplt.figure(figsize = (20,16))\n#Plot Searborn bar chart\nsns.barplot(x = corr_df['corr'], y = corr_df['feature_name'])\n#Add chart labels\nplt.xlabel('Feature Correlation')\nplt.ylabel('Feature Name')\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Top 4 features with strongest positive correlation with the target:')\nprint('')\nfor i in range(4):\n    \n    print('{} : corr = {:.2f}'.format(corr_df.values[i,0], corr_df.values[i,1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Top 4 features with strongest negative correlation with the target:')\nprint('')\n\nfor i in range(4):\n    \n    print('{} : corr = {:.2f}'.format(corr_df.values[::-1][i,0], corr_df.values[::-1][i,1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Scatterplots of the top 4 features with strongest positive correlation with the target**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# scatterplot of features with strongest negative correlation with the target\n\nfig = plt.figure(figsize = (15,15))\n\n\nfor i in range(4):\n    \n    fig.add_subplot(2,2,i+1)\n    \n    ax_1 = corr_df.values[i,0]\n    ax_2 = corr_df.values[i + 1,0]\n\n    plt.scatter(X_rf[ax_1].values[np.where(y == 0)[0]],\n            X_rf[ax_2].values[np.where(y == 0)[0]],\n           c = 'b')\n\n    plt.scatter(X_rf[ax_1].values[np.where(y == 1)[0]],\n            X_rf[ax_2].values[np.where(y == 1)[0]],\n           c = 'r')\n    \n    plt.xlabel(ax_1)\n    plt.ylabel(ax_2)\n    plt.title('Corr = {:.3f}'.format(corr_df.values[i,1]))\n    plt.legend(['Not Bankrupted','Bankrupted'])\n    \n    plt.axhline(y = 0, c = 'r')\n    plt.axvline(x = 0, c = 'r')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The companies labeled as 'Bankrupted' are all in the top-right side of the scatterplots, given the positive correlations."},{"metadata":{},"cell_type":"markdown","source":"**Scatterplots of the top 4 features with strongest negative correlation with the target**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# scatterplot of features with strongest negative correlation with the target\n\nfig = plt.figure(figsize = (15,15))\n\n\nfor i in range(4):\n    \n    fig.add_subplot(2,2,i+1)\n    \n    ax_1 = corr_df.values[::-1][i,0]\n    ax_2 = corr_df.values[::-1][i + 1,0]\n\n    plt.scatter(X_rf[ax_1].values[np.where(y == 0)[0]],\n            X_rf[ax_2].values[np.where(y == 0)[0]],\n           c = 'b')\n\n    plt.scatter(X_rf[ax_1].values[np.where(y == 1)[0]],\n                X_rf[ax_2].values[np.where(y == 1)[0]],\n               c = 'r')\n    \n    \n    plt.xlabel(ax_1)\n    plt.ylabel(ax_2)\n    plt.title('Corr = {:.3f}'.format(corr_df.values[::-1][i,1]))\n    plt.legend(['Not Bankrupted','Bankrupted'])\n    \n    plt.axhline(y = 0, c = 'r')\n    plt.axvline(x = 0, c = 'r')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The companies labeled as 'Bankrupted' are all in the bottom-left side of the scatterplots, given the negative correlations."},{"metadata":{},"cell_type":"markdown","source":"We can also plot the boxplots of the features of interest, splitted in the two classes. For the features with strong negative correlation, we expect the boxplots to show that main distribution (inside the box, 50% of the data) of the 'Bankrupt' class (1), to have negative values, and lower than the values in the boxplots of the 'Not Bankrupt' class (0).\n\nOn the contrary, for the features with positive correlation, we expect the boxplots to show that main distribution  of the 'Bankrupt' class (1), to have positive values, and higher than the values in the boxplots of the 'Not Bankrupt' class (0).\n"},{"metadata":{},"cell_type":"markdown","source":"**Boxplots of the top 4 features with strongest positive correlation with the target**"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (15,15))\n\n\nfor i in range(4):\n    \n    fig.add_subplot(2,2,i+1)\n    \n    ax = corr_df.values[i,0]\n    \n\n    plt.title('Corr = {:.3f}'.format(corr_df.values[i,1]))\n\n    sns.boxplot(x = y_clean.columns[0],\n                y = X_rf[ax], \n              data = pd.concat([X_rf,y_clean],axis = 1))\n            ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Boxplots of the top 4 features with strongest nevative correlation with the target**"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (15,15))\n\n\nfor i in range(4):\n    \n    fig.add_subplot(2,2,i+1)\n    \n    ax = corr_df[::-1].values[i,0]\n    \n    plt.title('Corr = {:.3f}'.format(corr_df[::-1].values[i,1]))\n\n    sns.boxplot(x = y_clean.columns[0],\n                y = X_rf[ax], \n                data = pd.concat([X_rf,y_clean],axis = 1))\n            ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.2 PCA\n\nPerforming PCA, we can identify reduced dimension which explain most of the variance in the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\n\ndef get_pca(X, n_components):\n\n    pca = PCA(n_components = n_components)\n\n    pca.fit(X)\n\n    X_pca = pca.fit_transform(X)\n\n    X_pca = pd.DataFrame(X_pca)\n    \n    fn = []\n    \n    for i in range(n_components):\n        \n        fn.append('component ' + str(i + 1))\n        \n    X_pca.columns = fn\n    \n    pve = pca.explained_variance_ratio_\n    \n    #for i in range(n_components):\n    \n       # print('PVE component {}: {:.1f} %'.format(i + 1, pve[i] * 100))\n    print('Cumulative PVE with {} components: {:.1f}%'.format(n_components,sum(pve)*100))\n    \n    return X_pca, pca, pve\n\ndef get_scree_plot(X,n_components):\n    \n    cumulative_pve = np.zeros((len(n_components)))\n    \n    for i,n in enumerate(n_components):\n        \n        _, _, pve = get_pca(X,n)\n        \n        \n        cumulative_pve[i] += 100 * sum(pve)\n        \n    fig = plt.figure(figsize = (5,5))\n        \n    plt.plot(n_components, cumulative_pve,'bo-')\n    plt.xlabel('N. components')\n    plt.ylabel('Cumulative PVE')\n        \n        \n# the biplot illustrates the loading vectors of each features and \n# the data plotted in the principal component space\n\n# in an element phi_jm of the loading vector phi_m of the feature m associated with the feature j\n# has a high positive value, it means that the feature j has a high contribution to the component m\n\n\ndef get_biplot(X_pca,y,comp_ax_hor,comp_ax_ver,features_names):\n    \n    score = X_pca.values\n    coeff = np.transpose(pca.components_[[comp_ax_hor-1,comp_ax_ver-1], :])\n    \n    \n    ax_1 = score[:,0]\n    ax_2 = score[:,1]\n    n = coeff.shape[0]\n    scale_ax_1 = 1.0/(ax_1.max() - ax_1.min())\n    scale_ax_2 = 1.0/(ax_2.max() - ax_2.min())\n    \n    fig = plt.figure(figsize = (10,10))\n    plt.scatter(ax_1[np.where(y == 0)[0]] * scale_ax_1,\n                ax_2[np.where(y == 0)[0]] * scale_ax_2,\n                c = 'b',\n                s=5)\n    \n\n    plt.scatter(ax_1[np.where(y == 1)[0]] * scale_ax_1,\n                ax_2[np.where(y == 1)[0]] * scale_ax_2,\n                c = 'r',\n                s=5)\n    \n    plt.xlabel('Component {}'.format(comp_ax_hor))\n    plt.ylabel('Component {}'.format(comp_ax_ver))\n    plt.legend(['Not Bankrupted','Bankrupted'])\n    \n    for i in range(n):\n        plt.arrow(0, 0, coeff[i,0], coeff[i,1],color = 'r',alpha = 0.5)\n        if features_names is None:\n            plt.text(coeff[i,0]* 1.15, coeff[i,1] * 1.15, \"Var\"+str(i+1), color = 'green', ha = 'center', va = 'center')\n        else:\n            plt.text(coeff[i,0]* 1.15, coeff[i,1] * 1.15, features_names[i], color = 'g', ha = 'center', va = 'center')\n        \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_scree_plot(X_rf, n_components = [1,5,10,15,20])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The **elbow** of the **scree plot** corresponds to **10 principal components (cumulative PVE: ~97%)**."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_pca,pca,_ = get_pca(X_rf, n_components = 10)\n\ncomp_ax_hor = 1\n\ncomp_ax_ver = 2\n\nfeatures_names = X_rf.columns\n\nget_biplot(X_pca,y,comp_ax_hor, comp_ax_ver, features_names )\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The biplot illustrates that Bankrupted companies tend to have negative values of the first component, where Current Liability to Assets, Debt ratio % and Borrow dependency (in particular) have positive values: it means that these high values of these features tend to represent Bankrupted companies. \n\nOn the other hand, Not Bankrupted companies have positive values of the first components, which are representative (in particular) of Net Income to Total Assets, ROA(A), ROA(B) and ROA(C). Strong of these features tend to represent Not Bankrupted companies.\n\nThese analysis made for the Biplot is in line to the analysis made for the Heatmap about the positive/negative correlations between the features and the target.\n\n\nSince a dataset reduced to 10 components reprents the 97% of variance of the original dataset, we can use the reduced dataset to fit classifiers, being sure that the most significant statistical information is retained in this dataset.\n\nThe performed data analysis involving features scaling, balancing classes, outliers removal, features selection and dimensionality reduction has provided a suitable dataset to fit ML models."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_pca","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Training-Test Splitting"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X_pca,y, test_size = 0.33, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. Fitting Classifiers"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import roc_curve,auc,precision_recall_curve,plot_roc_curve,plot_precision_recall_curve\nfrom sklearn.metrics import confusion_matrix,plot_confusion_matrix\n\n\ndef plot_classification_performance(clf,X,y_true, step, binary):\n   \n    '''\n    performance of classification is evaluated with:\n    \n    1) accuracy: (TP + TN)/(TP + TN + FP + FN)\n    \n    2) precision: TP / (TP + FP)\n    \n    3) recall (sensitivity, true positive rate): TP / (TP + FN)\n    \n    4) f_score: 2 * precision * recall / (precision + recall)\n    \n    5) precsion_recall_curve: x-axis: precision, y-axis: recall\n    \n    6) roc_curve: x-axis: true positive rate, y-axis: false positive rate\n                \n                true positive rate (recall, sensitivity): TP / (TP + FN)\n                false positive rate (fall out, 1 - specificity): FP / (FP + TN) = 1 - specificity = 1 - TN / (TN + FP)\n                \n                specifity (or true negative rate): TN / (TN + FP) \n                \n    ROC Curves summarize the trade-off between the true positive rate and false positive rate for a predictive model using different probability thresholds.\n    \n    Precision-Recall curves summarize the trade-off between the true positive rate and the positive predictive value for a predictive model using different probability thresholds.\n    \n    ROC curves are appropriate when the observations are balanced between each class, whereas precision-recall curves are appropriate for imbalanced datasets.\n    \n    7) confusion_matrix = [TP  FP\n                           FN  TN]  \n    \n    '''\n    \n    accuracy = clf.score(X,y_true)\n    \n    if binary:\n    \n       \n    \n        y_pred = clf.predict(X)\n        \n        report = classification_report(y_true,y_pred)\n        print('{} Classification Report'.format(step))\n        print(report)\n    \n    \n        plot_roc_curve(clf, X, y_true)\n        plt.title('{} ROC curve'.format(step))\n    \n        plot_precision_recall_curve(clf, X, y_true)\n        plt.title('{} Precision Recall curve'.format(step))\n        \n        \n        plot_confusion_matrix(clf,X, y_true)\n        plt.title('{} Confusion Matrix'.format(step))\n        \n    else:\n        \n        \n        n_classes = len(clf.classes_)\n        #y_score = clf.predict_proba(X)\n        y_score = clf.decision_function(X)\n        y_pred = clf.predict(X)\n\n        fpr = dict()\n        tpr = dict()\n        roc_auc = dict()\n    \n        precision = dict()\n        recall = dict()\n        f_score = dict()\n    \n        y_true_dummies = pd.get_dummies(y_true, drop_first = False).values\n    \n        for i in range(n_classes):\n        \n            fpr[i], tpr[i], _ = roc_curve(y_true_dummies[:, i], y_score[:, i])\n            roc_auc[i] = auc(fpr[i], tpr[i])\n        \n            precision[i], recall[i],_ =  precision_recall_curve(y_true_dummies[:, i], y_score[:, i])\n            \n        report = classification_report(y_true,y_pred)\n        print('{} Classification Report'.format(step))\n        print(report)\n                                                                \n       \n    \n        figsize=(8, 5)\n        fig, ax = plt.subplots(figsize = figsize)\n        ax.plot([0, 1], [0, 1], 'k--')\n        ax.set_xlim([0.0, 1.0])\n        ax.set_ylim([0.0, 1.05])\n        ax.set_xlabel('False Positive Rate')\n        ax.set_ylabel('True Positive Rate')\n        ax.set_title('{} ROC curve'.format(step))\n        \n        for i in range(n_classes):\n            ax.plot(fpr[i], tpr[i], label = 'Class {} (area = {:.2f})'.format(i, roc_auc[i]))\n    \n        ax.legend(loc=\"best\")\n        ax.grid(alpha=.4)\n        sns.despine()\n        plt.show()\n    \n        figsize=(8, 5)\n        fig, ax = plt.subplots(figsize = figsize)\n\n        ax.set_xlabel('Precision')\n        ax.set_ylabel('Recall')\n        ax.set_title('{} Precision Recall curve'.format(step))\n        \n        for i in range(n_classes):\n            ax.plot(precision[i], recall[i], label = 'Class {}'.format(i))\n        \n        ax.legend(loc=\"best\")\n        ax.grid(alpha=.4)\n        sns.despine()\n        plt.show()\n    \n        figsize=(8, 5)\n        plot_confusion_matrix(clf,X,y_true)\n        \n        \n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6.1 Random Forest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier()\n\nrf.fit(X_train,y_train)\n\nplot_classification_performance(rf, X_train,y_train, step ='Train', binary = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_classification_performance(rf, X_test,y_test, step ='Test', binary = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6.2 Support Vector Classifier with C chosen via Cross-Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\ncv = 10\n\nC_values = [1e2,1e3, 1e4, 1e5]\n\ncv_score = []\n\n\nfor C in C_values:\n    \n\n\n    svc = SVC(C = C, kernel = 'rbf')\n    \n    cross_val = cross_val_score(estimator = svc, X = X_train.values, y = y_train.values.ravel(), cv = cv)\n    \n    cv_score.append(np.average(cross_val))\n    \n    \nplt.plot(np.array(C_values),np.array(cv_score),'bo-')\nplt.xscale('log')\nplt.xlabel('C')\nplt.ylabel('Cross-Val Accuracy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svc = SVC(C = 1e3)\n\nsvc.fit(X_train,y_train)\n\nplot_classification_performance(svc, X_train,y_train.values.ravel(), step ='Train', binary = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_classification_performance(svc, X_test,y_test, step ='Test', binary = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6.3 K-Nearest Neighbors with K chosen via Cross-Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\n\ncv = 10\n\nk_values = [1,10, 100, 1000]\n\ncv_score = []\n\n\nfor k in k_values:\n    \n\n\n    knn  = KNeighborsClassifier(n_neighbors = k)\n    \n    cross_val = cross_val_score(estimator = knn, X = X_train.values, y = y_train.values.ravel(), cv = cv)\n    \n    cv_score.append(np.average(cross_val))\n    \n    \nplt.plot(np.array(k_values),np.array(cv_score),'bo-')\n\nplt.xlabel('N. Neighbors')\nplt.ylabel('Cross-Val Accuracy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors = 1)\n\nknn.fit(X_train,y_train)\n\nplot_classification_performance(knn, X_train,y_train, step ='Train', binary = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_classification_performance(knn, X_test,y_test, step ='Test', binary = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6.4 Neural Network"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import InputLayer,Dense, Dropout","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Dense(units = 10))\n\nmodel.add(Dropout(0.1))\n\nmodel.add(Dense(units = 5))\n\nmodel.add(Dropout(0.1))\n\nmodel.add(Dense(units = 2))\n\nmodel.add(Dropout(0.1))\n\nmodel.add(Dense(units = 1, activation = 'sigmoid'))\n\nmodel.compile(optimizer = 'adam', loss = 'mse', metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(X_train,y_train, epochs = 200, validation_split = 0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (10,5), dpi = 200)\n\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.xlabel('Epochs',fontsize = 20)\nplt.ylabel('Accuracy',fontsize = 20)\nplt.legend(['Training','Validation'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7. Conclusion\n\n- **Most relevant features: 35 out of 95 from the initial dataset**\n\n- **Features (among relevant) which most characterize tendency of bankrupting:**\n\n1) Borrowing dependency (high)\n\n2) Debt ratio % (high)\n\n3) Liability to Equity (high)\n\n4) Current Liability to Equity (high)\n\n5) Persistent EPS in the Last Four Seasons (low)\n\n6) Net worth/Assets (low)\n\n7) ROA(C) before interest and depreciation before interest (low)\n\n8) Net profit before tax/Paid-in capital (low)\n\n\n- **A dataset reduced to 10 components retain ~97% of the variance**\n\n- **Most performant classifiers fitted on reduced dataset: Random Forest, SVC\n\n**Test results**\n\n- precision: 97%\n\n- recall: 98%\n\n- f1: 98% \n\n- accuracy: 98%\n\n\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}