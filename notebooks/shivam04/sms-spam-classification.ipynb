{"nbformat_minor":1,"nbformat":4,"cells":[{"outputs":[],"metadata":{"_execution_state":"idle","_uuid":"a5093388bb8717bd9ad61b37f33237abbf5c697c","_cell_guid":"9bd239e3-5a47-431c-8834-39676d0b4abe"},"cell_type":"markdown","source":"SMS Spam classification Comparision between different model (SVM, Gaussian Naive Bayes, Logistic Regression, Multi-layer Perceptron classifier and Decision Tree)","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","trusted":true,"_uuid":"5fa9f2866c19d8f3037abcb3274f880de962a239","_cell_guid":"576cf62f-5677-42f5-a3ef-99516ba6e0f6"},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","trusted":true,"_uuid":"f1e99e86ee9d3da6bbcc27ea7c94119b309bfb73","_cell_guid":"e7ce9751-7d92-4fed-a521-6339d314239e"},"cell_type":"code","source":"data = pd.read_csv('../input/spam.csv',encoding='latin1')\ndata.head()","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","collapsed":true,"trusted":true,"_uuid":"4e61c5235d7d4fc24ad4185fde427212415f2926","_cell_guid":"ec04966f-f9e7-4ecc-a06f-cb78e1203628"},"cell_type":"code","source":"del data['Unnamed: 2']\ndel data['Unnamed: 3']\ndel data['Unnamed: 4']","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","trusted":true,"_uuid":"adb4c6b657bbef4f85fbae8c216613a19b9927ac","_cell_guid":"d414f060-abaf-49f4-b05b-689396fd25ef"},"cell_type":"code","source":"data.head()","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","trusted":true,"_uuid":"bc35a33f7fdf312a8d7985654fa4b6aa048744de","_cell_guid":"39fb2933-142f-404d-af6f-5944bb2cc0e1"},"cell_type":"code","source":"data['v1'] = data['v1'].replace(['ham','spam'],[0,1])\ndata.head()","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","trusted":true,"_uuid":"e40f766c3bdda58726ea5e76e53bf244a1ceeedf","_cell_guid":"8eb816b4-c1cb-42e1-b227-e703378efffe"},"cell_type":"code","source":"y = data['v1'].as_matrix()\nX_text = data['v2'].as_matrix() \nprint(X_text.shape)\nprint(y.shape)","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","trusted":true,"_uuid":"fd573c7af2f0da68cfd3a2572d184fde9fc6248a","_cell_guid":"94f28013-abf4-4724-9e5a-31e3d8b5d81c"},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nfrom nltk.corpus import stopwords\nsw = stopwords.words(\"english\")\ncv = CountVectorizer(stop_words =sw)\ntcv = cv.fit_transform(X_text).toarray()\n#print(cv.vocabulary_)\nprint(len(tcv[0,:]))","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","trusted":true,"_uuid":"03ae67281becb10bf648e4779cda83a826f86e8c","_cell_guid":"bf7bd1ff-2f07-4f47-8c59-e09080983dad"},"cell_type":"code","source":"print(tcv.shape)\nprint(y.shape)","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","trusted":true,"_uuid":"a84b9c21b9838a3546ab03b12a772a5215cee362","_cell_guid":"6e73c47c-af03-4692-b8df-86d3bff89a32"},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nvectorizer = TfidfVectorizer(stop_words=sw,lowercase=True)\nX = vectorizer.fit_transform(X_text).toarray()\nprint(X.shape)\nprint(y.shape)","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","trusted":true,"_uuid":"06c6a7d2b448aa161ee4032ea7b82014d6b45531","_cell_guid":"0ae976db-4101-4c93-8524-498c1aaa25a9"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.202, random_state=42)\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\ny_test.shape","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","collapsed":true,"trusted":true,"_uuid":"6619b6d1de7f9504c0f5210f0b46f8ea6fd0442a","_cell_guid":"66b6051d-92d1-4d25-9827-d70ffe1e45b3"},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nclf = LogisticRegression()\nclf.fit(X_train,y_train)\npred = clf.predict(X_test)\naccuracy_score(y_test,pred)","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","collapsed":true,"trusted":true,"_uuid":"8c4beeb010eb6fe12118d3ef2f8a142ebca752f5","_cell_guid":"979f2da4-2e2b-44b4-a369-943109ad149b"},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nclf = GaussianNB()\nclf.fit(X_train,y_train)\npred = clf.predict(X_test)\naccuracy_score(y_test,pred)","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","collapsed":true,"trusted":true,"_uuid":"6b23a71b2e2501c94a5722eae4be559c779bc3bb","_cell_guid":"998e35b3-6561-487b-9da5-ae34215c13ed"},"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\nclf = MLPClassifier(hidden_layer_sizes=(500,500))\nclf.fit(X_train,y_train)\npred = clf.predict(X_test)\naccuracy_score(y_test,pred)","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","collapsed":true,"trusted":true,"_uuid":"9d4b70a5c3c61c2581ee708926e2da02f1038039","_cell_guid":"d479724f-71e3-4efc-b1d0-dc063d6f6f81"},"cell_type":"code","source":"from sklearn import tree\nclf = tree.DecisionTreeClassifier()\nclf.fit(X_train,y_train)\npred = clf.predict(X_test)\naccuracy_score(y_test,pred)","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","collapsed":true,"trusted":true,"_uuid":"8b3eafd5ec51e1fe9a1862255071f1837d67f99f","_cell_guid":"b4f97513-ce97-4f0e-abba-1a85a3caf2c7"},"cell_type":"code","source":"from sklearn.svm import SVC\nclf = SVC(gamma=0.1,C=1,kernel='rbf')\nclf.fit(X_train,y_train)\npred = clf.predict(X_test)\naccuracy_score(y_test,pred)","execution_count":null},{"outputs":[],"metadata":{"trusted":true,"_uuid":"675211a86c0f5a3d5e2a4dca35828ed0e34c2e84","_cell_guid":"13cf2ed4-bbe8-4a06-8ceb-1b7e5277a2b0"},"cell_type":"code","source":"n_classes = 2\ny_n_train = np.zeros((y_train.size,n_classes)).astype(int)\nprint(y_n_train.shape)\nk = 0\nfor i in y_train:\n    y_n_train[k,i] = 1\n    k+=1\nprint(y_n_train)","execution_count":null},{"outputs":[],"metadata":{"scrolled":true,"trusted":true,"_uuid":"86228ba2befd9a09d6a2512cd39a0cf840998884","_cell_guid":"17023034-60c8-4692-82f5-4a4da6b2a302"},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.contrib import rnn\nepochs = 25\nn_classes = 2\nbatch_size = 78\nchunk_size = 97\nn_chunks = 88\nrnn_size = 78\nx = tf.placeholder('float',[None,n_chunks,chunk_size])\ny = tf.placeholder('float')\n#from tensorflow.python.ops import rnn, rnn_cell\ndef recurrent_neural_network(x):\n    layer = {'weights':tf.Variable(tf.random_normal([rnn_size,n_classes])),\n             'biases':tf.Variable(tf.random_normal([n_classes]))}\n\n    x = tf.unstack(x, n_chunks, 1)\n    #print x.shape\n    lstm_cell = rnn.BasicLSTMCell(rnn_size, forget_bias=1.0)\n\n    # Get lstm cell output\n    outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n\n    output = tf.matmul(outputs[-1],layer['weights']) + layer['biases']\n\n    return output\ndef train_neural_network(x):\n    prediction = recurrent_neural_network(x)\n    cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=y) )\n    optimizer = tf.train.AdamOptimizer().minimize(cost)\n    \n    \n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n\n        for epoch in range(epochs):\n            epoch_loss = 0\n            i = 0\n            while i<len(X_train):\n                start = i\n                end = i + batch_size\n                #print(start,end)\n                epoch_x, epoch_y = X_train[start:end],y_n_train[start:end]\n                epoch_x = epoch_x.reshape((batch_size,n_chunks,chunk_size))\n                #print epoch_x.shape\n                _, c = sess.run([optimizer, cost], feed_dict={x: epoch_x, y: epoch_y})\n                epoch_loss += c\n                i += batch_size\n\n            print('Epoch', epoch, 'completed out of',epochs,'loss:',epoch_loss)\n\n        correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n\n        accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n        print('Accuracy:',accuracy.eval({x:X_train.reshape((-1, n_chunks, chunk_size)), y:y_n_train}))\n        #pred = sess.run(prediction,feed_dict={x:X_test.reshape((-1, n_chunks, chunk_size))})\n        #corr = tf.argmax(pred,1)\n        #corr = sess.run(corr)\n        #print(corr)\n        #k = [i+1 for i in range(len(corr))]\n        #yg = pd.DataFrame({'ImageId':pd.Series(k),'Label':pd.Series(corr)})\n        #yg.to_csv('ans.csv',index=False)\ntrain_neural_network(x)","execution_count":null}],"metadata":{"language_info":{"codemirror_mode":{"version":3,"name":"ipython"},"nbconvert_exporter":"python","version":"3.6.1","file_extension":".py","pygments_lexer":"ipython3","name":"python","mimetype":"text/x-python"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}}}