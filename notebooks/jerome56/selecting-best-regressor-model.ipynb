{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Importing Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Loading the data into data frame\ndf = pd.read_csv(\"/kaggle/input/housesalesprediction/kc_house_data.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Droping Id,Date column\ndf = df.drop(['id','date'],axis=1)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Descriptive Statistic\ndf.describe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking for missing values\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Independent Feature and Dependent Feature\nX = df.drop(\"price\",1)\ny = df['price']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Selection Methods"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation map \n#Using Pearson Correlation\nplt.figure(figsize=(12,10))\ncor = df.corr()\nsns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Correlation with output variable\ncor_target = abs(cor[\"price\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Selecting highly correlated features\nrelevant_features = cor_target[cor_target>0.5]\nrelevant_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df[[\"bathrooms\",\"sqft_living\"]].corr())\nprint(df[[\"sqft_living\",\"grade\"]].corr())\nprint(df[[\"grade\",\"sqft_above\"]].corr())\nprint(df[[\"sqft_above\",\"sqft_living15\"]].corr())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Backward Elimination\nimport statsmodels.api as sm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Adding constant column of ones, mandatory for sm.OLS model\nX_1 = sm.add_constant(X)\n#Fitting sm.OLS model\nmodel = sm.OLS(y,X_1).fit()\nmodel.pvalues","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Backward Elimination\ncols = list(X.columns)\npmax = 1\nwhile (len(cols)>0):\n    p= []\n    X_1 = X[cols]\n    X_1 = sm.add_constant(X_1)\n    model = sm.OLS(y,X_1).fit()\n    p = pd.Series(model.pvalues.values[1:],index = cols)      \n    pmax = max(p)\n    feature_with_p_max = p.idxmax()\n    if(pmax>0.05):\n        cols.remove(feature_with_p_max)\n    else:\n        break\nselected_features_BE = cols\nprint(selected_features_BE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Recursive Feature Elimination\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LinearRegression()\n#Initializing RFE model\nrfe = RFE(model, 7)\n#Transforming data using RFE\nX_rfe = rfe.fit_transform(X,y)  \n#Fitting the data to model\nmodel.fit(X_rfe,y)\nprint(rfe.support_)\nprint(rfe.ranking_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#no of features\nnof_list=np.arange(1,13)            \nhigh_score=0\n#Variable to store the optimum features\nnof=0           \nscore_list =[]\nfor n in range(len(nof_list)):\n    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 0)\n    model = LinearRegression()\n    rfe = RFE(model,nof_list[n])\n    X_train_rfe = rfe.fit_transform(X_train,y_train)\n    X_test_rfe = rfe.transform(X_test)\n    model.fit(X_train_rfe,y_train)\n    score = model.score(X_test_rfe,y_test)\n    score_list.append(score)\n    if(score>high_score):\n        high_score = score\n        nof = nof_list[n]\nprint(\"Optimum number of features: %d\" %nof)\nprint(\"Score with %d features: %f\" % (nof, high_score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = list(X.columns)\nmodel = LinearRegression()\n#Initializing RFE model\nrfe = RFE(model, 10)             \n#Transforming data using RFE\nX_rfe = rfe.fit_transform(X,y)  \n#Fitting the data to model\nmodel.fit(X_rfe,y)              \ntemp = pd.Series(rfe.support_,index = cols)\nselected_features_rfe = temp[temp==True].index\nprint(selected_features_rfe)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Search"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train_scale = scaler.fit_transform(X_train)\nX_test_scale = scaler.fit_transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## *Linear Models*"},{"metadata":{},"cell_type":"markdown","source":"## Linear Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import linear_model\nreg = linear_model.LinearRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg.fit(X_train_scale,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = reg.predict(X_test_scale)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\nprint(\"MAE: \",mean_absolute_error(y_test,y_pred))\nprint(\"MSE: \",mean_squared_error(y_test,y_pred))\nprint(\"R Squared: \",r2_score(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"errors = abs(y_pred - y_test)\n# Calculate mean absolute percentage error (MAPE)\nmape = 100 * (errors / y_test)\n# Calculate and display accuracy\naccuracy = 100 - np.mean(mape)\nprint('Accuracy:', round(accuracy, 2), '%.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Ridge Regressor "},{"metadata":{"trusted":true},"cell_type":"code","source":"ridge_reg = linear_model.Ridge(alpha=0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ridge_reg.fit(X_train_scale,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = ridge_reg.predict(X_test_scale)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"MAE: \",mean_absolute_error(y_test,y_pred))\nprint(\"MSE: \",mean_squared_error(y_test,y_pred))\nprint(\"R Squared: \",r2_score(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"errors = abs(y_pred - y_test)\n# Calculate mean absolute percentage error (MAPE)\nmape = 100 * (errors / y_test)\n# Calculate and display accuracy\naccuracy = 100 - np.mean(mape)\nprint('Accuracy:', round(accuracy, 2), '%.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Lasso Regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"lasso_reg = linear_model.Lasso(alpha=0.1,max_iter=2000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lasso_reg.fit(X_train_scale,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = lasso_reg.predict(X_test_scale)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"MAE: \",mean_absolute_error(y_test,y_pred))\nprint(\"MSE: \",mean_squared_error(y_test,y_pred))\nprint(\"R Squared: \",r2_score(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"errors = abs(y_pred - y_test)\n# Calculate mean absolute percentage error (MAPE)\nmape = 100 * (errors / y_test)\n# Calculate and display accuracy\naccuracy = 100 - np.mean(mape)\nprint('Accuracy:', round(accuracy, 2), '%.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Stochastic Gradient Decent Regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"sgdr = linear_model.SGDRegressor()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sgdr.fit(X_train_scale,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = sgdr.predict(X_test_scale)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"MAE: \",mean_absolute_error(y_test,y_pred))\nprint(\"MSE: \",mean_squared_error(y_test,y_pred))\nprint(\"R Squared: \",r2_score(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"errors = abs(y_pred - y_test)\n# Calculate mean absolute percentage error (MAPE)\nmape = 100 * (errors / y_test)\n# Calculate and display accuracy\naccuracy = 100 - np.mean(mape)\nprint('Accuracy:', round(accuracy, 2), '%.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## *Suppor Vector Machines*"},{"metadata":{},"cell_type":"markdown","source":"## Support Vector Regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import svm\nsvm_reg = svm.SVR()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svm_reg.fit(X_train_scale,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = svm_reg.predict(X_test_scale)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"MAE: \",mean_absolute_error(y_test,y_pred))\nprint(\"MSE: \",mean_squared_error(y_test,y_pred))\nprint(\"R Squared: \",r2_score(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"errors = abs(y_pred - y_test)\n# Calculate mean absolute percentage error (MAPE)\nmape = 100 * (errors / y_test)\n# Calculate and display accuracy\naccuracy = 100 - np.mean(mape)\nprint('Accuracy:', round(accuracy, 2), '%.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## *Ensemble Methods*"},{"metadata":{},"cell_type":"markdown","source":"## Decision Tree Regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import tree\ndtr = tree.DecisionTreeRegressor()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtr = dtr.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = dtr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"MAE: \",mean_absolute_error(y_test,y_pred))\nprint(\"MSE: \",mean_squared_error(y_test,y_pred))\nprint(\"R Squared: \",r2_score(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"errors = abs(y_pred - y_test)\n# Calculate mean absolute percentage error (MAPE)\nmape = 100 * (errors / y_test)\n# Calculate and display accuracy\naccuracy = 100 - np.mean(mape)\nprint('Accuracy:', round(accuracy, 2), '%.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest Regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nrfr = RandomForestRegressor(n_estimators=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfr = rfr.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = rfr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"MAE: \",mean_absolute_error(y_test,y_pred))\nprint(\"MSE: \",mean_squared_error(y_test,y_pred))\nprint(\"R Squared: \",r2_score(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"errors = abs(y_pred - y_test)\n# Calculate mean absolute percentage error (MAPE)\nmape = 100 * (errors / y_test)\n# Calculate and display accuracy\naccuracy = 100 - np.mean(mape)\nprint('Accuracy:', round(accuracy, 2), '%.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Gradient Boosting Regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\ngbr = GradientBoostingRegressor(n_estimators=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gbr = gbr.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = gbr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"MAE: \",mean_absolute_error(y_test,y_pred))\nprint(\"MSE: \",mean_squared_error(y_test,y_pred))\nprint(\"R Squared: \",r2_score(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"errors = abs(y_pred - y_test)\n# Calculate mean absolute percentage error (MAPE)\nmape = 100 * (errors / y_test)\n# Calculate and display accuracy\naccuracy = 100 - np.mean(mape)\nprint('Accuracy:', round(accuracy, 2), '%.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Voting Regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import VotingRegressor\nr1 = linear_model.LinearRegression()\nr2 = GradientBoostingRegressor(n_estimators=20)\nr3 = RandomForestRegressor(n_estimators=20)\nereg = VotingRegressor(estimators=[('gb', r1), ('rf', r2), ('lr', r3)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ereg = ereg.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = ereg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"MAE: \",mean_absolute_error(y_test,y_pred))\nprint(\"MSE: \",mean_squared_error(y_test,y_pred))\nprint(\"R Squared: \",r2_score(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"errors = abs(y_pred - y_test)\n# Calculate mean absolute percentage error (MAPE)\nmape = 100 * (errors / y_test)\n# Calculate and display accuracy\naccuracy = 100 - np.mean(mape)\nprint('Accuracy:', round(accuracy, 2), '%.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## K-Fold Cross Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"\"\" Creating Cross Validation score for best regressor random forest with 10 folds.\"\"\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nrfr = RandomForestRegressor(n_estimators=20)\nscores = cross_val_score(rfr,X,y,cv=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nrfr = RandomForestRegressor(n_estimators=20)\nscores = cross_val_score(rfr,X,y,cv=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores.mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Hyperparameter Tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"rfr = RandomForestRegressor(n_estimators=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pprint import pprint\n# Look at parameters used by our current forest\nprint('Parameters currently in use:\\n')\npprint(rfr.get_params())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Hyperparameter Grid"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 20, stop = 200, num = 10)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4]\n# Method of selecting samples for training each tree\nbootstrap = [True, False]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\npprint(random_grid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use the random grid to search for best hyperparameters\n# First create the base model to tune\nrfr = RandomForestRegressor()\n# Random search of parameters, using 5 fold cross validation, \n# search across 50 different combinations, and use all available cores\nrf_random = RandomizedSearchCV(estimator = rfr, param_distributions = random_grid, n_iter = 50, cv = 5, verbose=2, random_state=42, n_jobs = -1)\n# Fit the random search model\nrf_random.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_random.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(model, test_features, test_labels):\n    predictions = model.predict(test_features)\n    errors = abs(predictions - test_labels)\n    mape = 100 * np.mean(errors / test_labels)\n    accuracy = 100 - mape\n    print('Model Performance')\n    print('Accuracy = {:0.2f}%.'.format(accuracy))\n    \n    return accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model = RandomForestRegressor(n_estimators = 20, random_state = 42)\nbase_model.fit(X_train, y_train)\nbase_accuracy = evaluate(base_model, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_random = rf_random.best_estimator_\nrandom_accuracy = evaluate(best_random, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy - base_accuracy) / base_accuracy))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}