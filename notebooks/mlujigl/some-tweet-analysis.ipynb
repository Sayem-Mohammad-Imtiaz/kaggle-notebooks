{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"88eccfc0-e609-4810-959d-f47a0e8662dd","_uuid":"e0ae72da7e189e52690ed332a4db69b8173e5621","collapsed":true,"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/tweets.csv')","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data.head()","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"02b441fa-680b-48d3-9c3b-e30968596ed8","_uuid":"9174e99cf5c8b1ea5e148f0b82e0ba9edb8c454c"},"cell_type":"markdown","source":"So we have 28 columns. Let's check the names"},{"metadata":{"_cell_guid":"a4dcff28-e106-4f6b-8a1b-181cc93b756f","_uuid":"89a90b08d580207cd2d54626852219268b1afa0b","trusted":true},"cell_type":"code","source":"data.columns","execution_count":4,"outputs":[]},{"metadata":{"_cell_guid":"cbd48f4a-3cbb-441a-88b0-69587fc61bea","_uuid":"d51e06a0bfb798a86948845029e9e74b6c2f1ee1"},"cell_type":"markdown","source":"How many missing values do we have (NaN)?"},{"metadata":{"_cell_guid":"ab49a55d-b30b-4d4f-b91a-f26c8510ca3e","_uuid":"f34062f5c10cde991b67c1bb0b3ffe5a781d78fa","trusted":true},"cell_type":"code","source":"missing_values_count = data.isnull().sum()\n\n# Number of NaN in the first ten columns\nmissing_values_count[0:10]","execution_count":5,"outputs":[]},{"metadata":{"_cell_guid":"283f2714-8977-4773-8d40-ffa4b3916963","_uuid":"f325cbc2bdd94a37c9c79ac06d85e8ae19c45ccc","trusted":true},"cell_type":"code","source":"# how many total missing values do we have?\ntotal_cells = np.product(data.shape)\ntotal_missing = missing_values_count.sum()\n\n# percent of data that is missing\n(total_missing/total_cells) * 100","execution_count":6,"outputs":[]},{"metadata":{"_cell_guid":"c3f5969f-6fb5-453e-bd16-8f6cadc25a61","_uuid":"be10d0c6326d2fca8e9e78f05ac126d2e556b9c2"},"cell_type":"markdown","source":"That's a lot!!!"},{"metadata":{"_cell_guid":"16204073-1104-4d19-b0be-eae19526ee4e","_uuid":"3e21b3a89912b080d3e9bd8c50031a3d3f62aaaf"},"cell_type":"markdown","source":"Let's print some information of the first row"},{"metadata":{"_cell_guid":"de3abec0-38dc-4143-9ce2-11490096fe5b","_uuid":"e2be072fe1ce43f6cf557ded5d35bb661c062735","trusted":true},"cell_type":"code","source":"print('id: ',data['id'][0])\nprint('source: ',data['source_url'][0])\nprint('favourite count: ',data['favorite_count'][0])\nprint('retweet_count: ',data['retweet_count'][0])\nprint('entities: ',data['entities'][0])\nprint('lang: ',data['lang'][0])\nprint('text: ', data['text'][0])\nprint('place: ', data['place_name'][0])\n","execution_count":7,"outputs":[]},{"metadata":{"_cell_guid":"3e305271-5aee-4656-9fd7-3ce26bbf6371","_uuid":"a1c3ea43d2caefa7b91baff4a23369541814bc99","trusted":true},"cell_type":"code","source":"lang_list=[]\nfor t in data['lang']:\n    if t not in lang_list:\n        lang_list.append(t)\n        \nprint(\"Languages of the tweets:\")\nfor t in lang_list:\n    print(t)\n    ","execution_count":8,"outputs":[]},{"metadata":{"_cell_guid":"d8d62f6f-b395-4779-aa45-ab2401941348","_uuid":"21ed500c50e332dda3e9369d519d040c7476a343","trusted":true},"cell_type":"code","source":"percent = np.zeros(len(lang_list))\n\nfor t in data['lang']:\n    for index in range(len(lang_list)):\n        if t == lang_list[index]:\n            percent[index] += 1\n            pass\n\npercent /= 100\n\n\npie_chart = pd.Series(percent, index=lang_list, name='Languages')\npie_chart.plot.pie(fontsize=11, autopct='%.2f', figsize=(6, 6));\n","execution_count":9,"outputs":[]},{"metadata":{"_cell_guid":"80507e17-4d72-4b13-a9e3-882311341b15","_uuid":"b308317e08ab7fe32ffb20ffba759fbdbf44e1aa","trusted":true},"cell_type":"code","source":"pie_chart.plot.barh(fontsize=11, figsize=(6, 6))","execution_count":10,"outputs":[]},{"metadata":{"_cell_guid":"3e29a398-bc2a-428f-93da-d65fbc1a7cbb","_uuid":"feede409f931f89c413fdda5ac30f43c846ed726","trusted":true},"cell_type":"code","source":"data.text.str.split(expand=True).stack().value_counts()[:10]\n","execution_count":11,"outputs":[]},{"metadata":{"_cell_guid":"5a686a95-a586-4db9-a42e-0d6b8833d3a0","_uuid":"f38d079e31882a42ea8bb3b919db8494281b19ae","trusted":true},"cell_type":"code","source":"words = {}\ntotal = 0\n\nfor word in data.text.str.split(expand=True).stack():\n    if word in words:\n        words[word] += 1\n    else:\n        words[word] = 1\n    total += 1    \n\n#print the 20 most frequency words \nx=[];y=[]    \nsorted_words = sorted(words, key = words.get, reverse=True)\nprint(\"FREQUENCY OF WORDS\")\nprint(\" \")\ncount=0\nfor w in sorted_words:\n    count += 1 \n    print(w, ' ', words[w]/total)\n    x.append(w)\n    y.append(words[w])\n    if count == 20:\n        break","execution_count":24,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4cf0c2cd47dac3fd25225d7b4968702e99080c01"},"cell_type":"code","source":"import matplotlib.pyplot as plt \n\ny_pos = np.arange(len(x))\nplt.title('Most common words')\nplt.barh(y_pos,y,align = 'center')\nplt.yticks(y_pos, x)\nplt.show()","execution_count":50,"outputs":[]},{"metadata":{"_cell_guid":"c2c58bad-387b-45f8-943f-646748f7df0d","_uuid":"0b5b7601f657d3b267c4488036446714559d20f6","trusted":true},"cell_type":"code","source":"hashtags ={}\nfor word in words:\n    if word.startswith('#'):\n        if word in hashtags:\n            hashtags[word] += 1\n        else:\n            hashtags[word] = 1\n\nsorted_hashtags = sorted (hashtags,key = hashtags.get, reverse=True)             \nprint (sorted_hashtags[:10])","execution_count":21,"outputs":[]},{"metadata":{"_cell_guid":"eb51a93d-2f04-4795-85a7-5ecfffd58776","_uuid":"c747b74c7b6830d42b2680736b6c8b7d59c1538c","collapsed":true,"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":1}