{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \ndata=pd.read_csv('/kaggle/input/insurance/insurance.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"bmi\"]=data[\"bmi\"].astype(int)\ndata[\"charges\"]=data[\"charges\"].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=data.iloc[:, :-1].values\ny=data.iloc[:,-1].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Encode Categorical Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Gender\nfrom sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()\nx[:,1]=le.fit_transform(x[:,1])\nx[:,4]=le.fit_transform(x[:,4])\nx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#region\nnp.set_printoptions(threshold=np.sys.maxsize)\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [5])], remainder='passthrough')\nx = np.array(ct.fit_transform(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x[:3]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Test Train Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test=train_test_split(x,y,test_size=0.2, random_state=43)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training the Multiple Linear Regression model on the Training set"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nregressor=LinearRegression()\nregressor.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ## Predicting the Test set results using the class\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=regressor.predict(x_test) #### Vector of PREDICTED cost (x_Test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.set_printoptions(precision=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(np.concatenate((y_pred.reshape(len(y_pred), 1),y_test.reshape(len(y_test),1)),1))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1 column - predicted cost, 2 column - real cost\nIt seems that our model brought closer results to the real charges. Let me know if it makes sense"},{"metadata":{},"cell_type":"markdown","source":"## Backward Elimination - Manual Elimination"},{"metadata":{"trusted":true},"cell_type":"code","source":"x=x[:,1:] ## to avoid dummy trap \nlen(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.set_printoptions(threshold=np.sys.maxsize)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\n## Create the b0\nx=np.append(arr=np.ones((len(x),1)).astype(int),values=x,axis=1)\nx[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_opt=x[:,[0,1,2,3,4,5,6,7,8]]\nx_opt=x_opt.astype(np.float64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Step 2: Fit the full model  with all possible predictors\nregressor_OLS=sm.OLS(endog=y,exog=x_opt).fit()\n# endog is dependent variable, exog - regressor","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ordinary least-squares (OLS) models assume that the analysis is fitting a model of a relationship between one or more explanatory variables and a continuous or at least interval outcome variable that minimizes the sum of square errors, where an error is the difference between the actual and the predicted value of the"},{"metadata":{"trusted":true},"cell_type":"code","source":"regressor_OLS.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x[:3]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ### Now we need to get rid of the variables, with the highest p-values (everything that is higher 0.05)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#x5 has the highest p-value: 0.693 - this is the gender, so the gender has less  significant influence on the cost\nx_opt=x[:,[0,1,2,3,4,6,7,8]]\nx_opt=x_opt.astype(np.float64)\nregressor_OLS=sm.OLS(endog=y, exog=x_opt).fit()\nregressor_OLS.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x[:3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Again x1 has the highest p-values, 0.878\nx_opt=x[:,[0,2,3,4,6,7,8]]\nx_opt=x_opt.astype(np.float64)\nregressor_OLS=sm.OLS(endog=y,exog=x_opt).fit()\nregressor_OLS.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_opt=x[:,[0,2,4,6,7,8]]\nx_opt=x_opt.astype(np.float64)\nregressor_OLS=sm.OLS(endog=y, exog=x_opt).fit()\nregressor_OLS.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_opt=x[:,[0,4,6,7,8]]\nx_opt=x_opt.astype(np.float64)\nregressor_OLS=sm.OLS(endog=y, exog=x_opt).fit()\nregressor_OLS.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Now the model is ready, with the backward elimination we have left only those variables that matter ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n=x[:,[0,4,6,7,8]]\nn[:3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Variables that are statistically significant for our prediction:\n  - Constant\n  - Age\n  - BMI\n  - Children\n  - Smoker Status"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}