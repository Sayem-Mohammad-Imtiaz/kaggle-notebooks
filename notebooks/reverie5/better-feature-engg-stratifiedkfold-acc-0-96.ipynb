{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Drug Classification\n\n**Problem Type: MultiClass Classification**\n\nIn this begineer friendly notebook, I have done exploratory data analysis, Modelling using DecisionTreeClassifier and RandomForestClassifier with StratifiedKFold cross validation strategy. \n\nI have noted my observations at many places. Still if you have any queries or suggestions please ask. Kindly Upvote if you find it interesting :)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### PART 1: Exploratory data analysis","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Import libraries\nimport numpy as np \nimport pandas as pd \n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#reading data\ndata= pd.read_csv('/kaggle/input/drug-classification/drug200.csv')\nprint(\"Dataframe Shape: \",data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check data\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* 5 Features: ['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K']\n* 1 Target Variable: Drug","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Target variable analysis\ndata['Drug'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* We have imbalanced dataset with 5 classes in target. Need to use StratifiedKFold cross validation strategy.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Feature variables analysis\n#Check for missing values\ndata.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* No missing values in data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# col-Age\nsns.distplot(data['Age'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* We have age distribution from 15-74 years. Need to create Age bins for different age groups.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_columns', 100)\npd.set_option('display.max_rows', 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby(['Age', 'Drug']).size()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# col- Sex\ndata.Sex.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby(['Sex', 'Drug']).size()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Sex feature is low cardinality nominal variable. Need to use One hot encoding technique here or since we have only two labels, we can binarize it.\n* Almost equal distribution of drugs over both sexes.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# col- BP\ndata.BP.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x=\"Drug\", y=\"BP\", data=data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Its distinctive in case of drugC, drugA, drugB","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby(['BP', 'Drug']).size()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* BP (Blood Pressure) feature is ordinal categorical variable(having some kind of order between values, LOW, NORMAL, HIGH). Label encoding would be suitable for this.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# col- Cholesterol\ndata.Cholesterol.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby(['Cholesterol', 'Drug']).size()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Cholesterol is again ordinal categorical variable (NORMAL, HIGH). Need to use label encoder.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# col- Na_to_K\nprint(data.Na_to_K.nunique())\nsns.distplot(data['Na_to_K'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x=\"Drug\", y=\"Na_to_K\", data=data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Cool, when Na_to_K ratio > 15, only DrugY is used. Create new feature.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* Out of 200 dataset 198 rows have unique values for Na_to_K ratio, It is not distinctive and useful. We need to group it into different bins in order to make sense from this data.\n* We can observe deviation from normal distribution here. Data is skewed.\n* Positive skewness","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Positive skewness also tells, (mean and median) > mode\n#mean, median, mode: lets check\nprint(data.Na_to_K.mean())\nprint(data.Na_to_K.median())\nprint(data.Na_to_K.mode()[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#skewness and kurtosis\nprint(\"Skewness= \", data['Na_to_K'].skew())\nprint(\"Kurtosis= \", data['Na_to_K'].kurt())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Skewness > 1, suggests distribution is somewhat moderate to highly skewed (positive)\n* kurtosis < 3, suggests distribution is shorter, tails are thinner than the normal distribution. The peak is lower and broader, which means that data are light-tailed or lack of outliers.\n\n*NOTE: We can apply some kind of transformation technique to make distribution normal.*","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### PART 2: Data Preparation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Age.max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# feature engg\n# Binning Age into Age groups\nbins= [13,18,65,80]\nlabels = ['Teen','Adult','Elderly']\ndata['AgeGroup'] = pd.cut(data['Age'], bins=bins, labels=labels, right=False)\ndata.drop('Age', axis=1, inplace=True)\nprint (data.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.AgeGroup.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Now the next challenge is how do we group the Sodium to Potassium ratio data. We dont have any distinct groups as Age. \n#### So, I will group the data based on percentile distribution of data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['is_Na2K_greater15'] = [1 if x>15 else 0 for x in data['Na_to_K']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Na_to_K groups\ndata['Na_to_K_groups'] = pd.qcut(data['Na_to_K'],\n                            q=[0, .2, .4, .6, .8, 1],\n                            labels=False)\ndata.drop('Na_to_K', axis=1, inplace=True)\ndata.Na_to_K_groups.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Binarize Sex variable\ndata['Sex'].replace(['F','M'],[0,1],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Label encoding\nfrom sklearn import preprocessing \n  \nle = preprocessing.LabelEncoder() \ndata['BP']= le.fit_transform(data['BP']) \ndata['Cholesterol']= le.fit_transform(data['Cholesterol'])\ndata['AgeGroup']= le.fit_transform(data['AgeGroup']) \ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### PART 3: Modelling & Evaluation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#features\nfeatures = ['Sex', 'BP', 'Cholesterol', 'AgeGroup','is_Na2K_greater15', 'Na_to_K_groups']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model\nfrom sklearn import tree\nfrom sklearn import ensemble\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kf = StratifiedKFold(n_splits=5,shuffle=True,random_state=42)\nX = data[features]\ny = data.Drug\n\nscores= []\ni=1\nfor train_index,test_index in kf.split(X, y):\n    print('Fold no. = ', i)\n    \n    x_train, x_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n    \n    #model\n    model1 = tree.DecisionTreeClassifier(random_state=42)\n    model1.fit(x_train, y_train)\n     \n    test_pred= model1.predict(x_test)\n    test_acc = metrics.accuracy_score(y_test, test_pred)\n    print('Accuracy score over test set:',test_acc)\n    scores.append(test_acc)    \n    \n    i+=1\n    \n#mean score\nprint()\nprint('Mean Accuracy for Decision Tree: ', np.mean(scores))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### We got an Accuracy of 0.96 with Decision Tree (default parameters). But the good thing we avoided Overfitting using StratifiedKFold approach. Ofcourse this accuracy can be improved by hyperparameter tuning and feature selection/feature engg.\n\n#### Lets try another ML model, RandomForestClassifier.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#RandomForestClassifier\nkf = StratifiedKFold(n_splits=5,shuffle=True,random_state=42)\nX = data[features]\ny = data.Drug\n\nscores= []\ni=1\nfor train_index,test_index in kf.split(X, y):\n    print('Fold no. = ', i)\n    \n    x_train, x_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n    \n    #model\n    model2 = ensemble.RandomForestClassifier(random_state=42)\n    model2.fit(x_train, y_train)\n     \n    test_pred= model2.predict(x_test)\n    test_acc = metrics.accuracy_score(y_test, test_pred)\n    print('Accuracy score over test set:',test_acc)\n    scores.append(test_acc)    \n    \n    i+=1\n    \n#mean score\nprint()\nprint('Mean Accuracy for Random Forest Classifier: ', np.mean(scores))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Cool!!! we got better accuracy 0.96 with RandomForestClassifier.\n\n**Lets plot feature importance and visualize.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# model-random forest classifier feature importance\nfeat_importances = pd.Series(model2.feature_importances_, index=features)\nfeat_importances.plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Most Important feature is is_Na2K_greater15 (Sodium to Potassium ratio) that we created.\n* Second important feature is Blood pressure.\n* Agegroups and Cholesterol level have similar level of importance.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Thank you for making it till the end.  \n\n#### Kindly upvote and comment if you have any suggestions or queries. Happy learning :)","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}