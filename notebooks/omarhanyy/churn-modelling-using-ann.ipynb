{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Import Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# Import visualization libraries \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\ndef ignore_warn(*args, **kwargs):\n    pass\nwarnings.warn = ignore_warn #ignore annoying warning (from matplotlib and seaborn)\n\n%matplotlib inline\n\n# Model building libraries \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nimport keras \nfrom keras.models import Sequential\nfrom keras.layers import Dense\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loading The Data"},{"metadata":{},"cell_type":"markdown","source":"> Let's understand our data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reading the data into pandas data frame \ndf = pd.read_csv('../input/churn-modelling/Churn_Modelling.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA "},{"metadata":{},"cell_type":"markdown","source":"> Let's visualize our data for better understanding "},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# Finding Relation between Exited and Gender\n# Creating frequency table\nfreq_table = df.groupby(['Exited']).size().reset_index(name='Count')\nfreq_table['Male'] = freq_table['Exited'].apply(lambda x : df['Exited'][(df['Exited'] == x) & (df['Gender'] == 'Male')].count())\nfreq_table['Female'] = freq_table['Exited'].apply(lambda x : df['Exited'][(df['Exited'] == x) & (df['Gender'] == 'Female')].count())\n\nplt.figure(figsize=(12, 5))\nsns.countplot(x='Exited', data=df, hue='Gender')\nfreq_table","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating frequency table \nfreq_table = df.groupby(['Geography']).size().reset_index(name='Count')\nfreq_table['0'] = freq_table['Geography'].apply(lambda x : df['Geography'][(df['Geography'] == x) & (df['Exited'] == 0)].count())\nfreq_table['1'] = freq_table['Geography'].apply(lambda x : df['Geography'][(df['Geography'] == x) & (df['Exited'] == 1)].count())\n\n# Initializing lables and sizes for the pie chart \nlabels = ['France', 'Germany', 'Spain']  # names on pie chart \nsizes = [df['Geography'][df['Geography'] == 'France'].count(),df['Geography'][df['Geography'] == 'Germany'].count(), df['Geography'][df['Geography'] == 'Spain'].count()]  \n# only \"explode\" the 2nd and 3rd slice (i.e. 'France', 'Germany')\nexplode = (0, 0.1, 0.1)\n#add colors   \ncolors = ['#FFA32F','#378AFF', '#93F03B'] \n\nfig, ax =plt.subplots(nrows=1, ncols=2, figsize=(15, 7))\nsns.countplot(x='Geography', data=df, hue='Exited', ax=ax[0])\n# Equal aspect ratio ensures that pie is drawn as a circle\nax[1].pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=90, textprops={'fontsize': 15, 'fontWeight':'500'})\nax[1].axis('equal')\nplt.tight_layout()\nfreq_table ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Relation between Geography and Gender\nplt.figure(figsize=(15, 5))\nsns.countplot(x='Geography', data=df, hue='Gender')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 7))\ndf.CreditScore.plot.hist(grid=True, bins=20, rwidth=0.9)\nplt.xlabel('CreditScore')\nplt.grid(axis='y', alpha=0.75)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The majority of people taking loan are between 30 - 40 years old \nprint('The smallest age is {} and the largest is {}'.format(df.Age.min(), df.Age.max()))\nplt.figure(figsize=(10, 5))\nsns.distplot(df.Age)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Corr heatmap\nplt.figure(figsize=(15,7))\nsns.heatmap(df.corr(), vmin=-1, cmap='coolwarm', annot=True)\ndf.corr().Exited.sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Preprocessing "},{"metadata":{},"cell_type":"markdown","source":"> Now Let's preprocess our data to be ready for the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# One hot encoding Geography and Gender features \ngeo = pd.get_dummies(df.Geography, drop_first=True)\ngender = pd.get_dummies(df.Gender, drop_first=True)\ndf = pd.concat([geo, gender, df], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop unnecessary features \ndf.drop(['RowNumber', 'CustomerId', 'Surname', 'Geography', 'Gender'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.iloc[:, :-1].values\ny = df.iloc[:, -1].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Spiliting the data into training and testing \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Standardize our data\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.fit_transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Building Model"},{"metadata":{},"cell_type":"markdown","source":"> We will build an ANN using Keras "},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential() #initialize model object\n\nmodel.add(Dense(32, activation='relu', kernel_initializer='normal', input_dim=11))\nmodel.add(Dense(16, activation='relu', kernel_initializer='normal'))\nmodel.add(Dense(1, activation='sigmoid', kernel_initializer='normal')) \n\n# Compiling the ANN\nmodel.compile(optimizer='adam', loss= 'binary_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting the model\nmodel.fit(X_train, y_train, batch_size = 20, epochs = 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting the test set\nprediction = model.predict(X_test)\nprediction = (prediction > 0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#86.15%\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n\nprint('Accuracy: {}% \\n'.format(accuracy_score(y_test, prediction)* 100)) # Calculating accuracy \nprint('*'*100)\nprint(confusion_matrix(y_test, prediction))\nprint(classification_report(y_test, prediction)) ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}