{"cells":[{"metadata":{},"cell_type":"markdown","source":"### College of Computing and Informatics, Drexel University\n### INFO 213: Data Science Programming II\n---\n\n## Final Report\n\n## Project Title: Countrywide Car Accidents Analysis and Forecasting\n\n## Student(s): Khanh Tran, Amanjyot Singh\n\n#### Date: August 30, 2020\n---","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 1. Introduction\n---\n*(Introduce the project and describe the objectives.)* ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"With a good amount of data and thoroughly executed analytics, one can possibly unveil the many faces of a problem or phenomenon. Data science has been being considered the most direct and reliable way to attack a problem, tracing it to the root and predicting what and when next consequences will take place. This project will follow the same direction and try to solve a specific real-world problem: what can data analytics do to reduce the number of car accidents in the U.S. The analytics will be based on “A Countrywide Traffic Accident Dataset” by Moosavi, Sobhan, Mohammad Hossein Samavatian, Srinivasan Parthasarathy, and Rajiv Ramnath. In this project, we will strive for understanding the cause and effect rules of the accidents, and from that, we will try to build several machine learning models that can help with the future accidents forecasting.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 2. Problem Definition\n---\n*(Define the problem that will be solved in this data analytics project.)*","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"On average, there are 6 million car accidents in the U.S. every year. That's roughly 16,438 per day. Over 37,000 Americans die in automobile crashes per year, and there is an additional 3 million injured or disabled annually. Economically, traffic accidents cost the country $871 billion a year, and that was 6 years ago. These are only a few quick car crash statistics happening right now in the U.S. Even though the country is standing at 110th on the list of countries with the highest traffic-related death rate, the number can still be lowered tremendously if science-based solutions are carried out in a mission to improve the safety of the people on the roads. With a good dataset, data analysis can be an efficient method to extract useful information in order to figure out the cause and effect rules of the accidents, which will result in improved accident prevention.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 3. Data Sources\n---\n*(Describe the origin of the data sources. What is the format of the original data? How to access the data?)*","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"As the dataset was acquired on Kaggle and because of its size, downloading it to local computers will be quite time-consuming. Using Kaggle notebook will solve this problem as we don't have to manually download the dataset to use it. Kaggle allows their users to get access to the datasets available on their website. There are currently about 3.5 million accident records in this dataset. It covers 49 states of the USA, and the data were collected from February 2016 to June 2020, using two APIs that provide streaming traffic incident (or event) data. Along with the large number of records, this dataset also provide a wide range of attributes for each accident. With 49 columns, analysts can observe and discover many faces of the accidents such as starting-ending time, exact starting-ending location, address, weather conditions, existed crossings, junctions, or bumps, etc. Our goals are planned upon this variety of features. We will also make use of pandas, numpy, matplotlib.pyplot, math, and sklearn packages of Python to effectively analyze, visualize, and model our data.\n\nAcknowledgements\n\n- Moosavi, Sobhan, Mohammad Hossein Samavatian, Srinivasan Parthasarathy, and Rajiv Ramnath. “A Countrywide Traffic Accident Dataset.”, 2019.\n\n- Moosavi, Sobhan, Mohammad Hossein Samavatian, Srinivasan Parthasarathy, Radu Teodorescu, and Rajiv Ramnath. \"Accident Risk Prediction based on Heterogeneous Sparse Data: New Dataset and Insights.\" In proceedings of the 27th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems, ACM, 2019.\n\nhttps://www.kaggle.com/sobhanmoosavi/us-accidents","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 4. The Goal(s) of the predictions\n---\n*(What are the expected results of the project?)*","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The project's mission is to provide assitance for this battle against car accidents with statistics-based findings and data-based analysis. To be more specific, we strive for determining the importance of each attribute toward predicting severity levels of accidents. The process is to create two similar models that predict severity level of available accidents based on a set of attributes. One model will take in all attributes except for the target attribute, for example weather conditions, and the other one will take in every attribute including the target attribute. Two sets of metric scores will be calculated and compared to see if adding the target attribute to the model will improve its performance or hurt it. Additionally, the level of influence of each target attribute will also be evaluated to find out which one plays the most important role and which one plays the least in supporting the performance of the algorithms. The target attributes are:\n\n- Weather Conditions\n- Locations\n- Time of the day\n- Time of the year\n\nFor each attribute, we will create a separate set of models. We will try to implement as many machine learning algorithms as possible. Each of the attribute listed above will be carefully processed and feeded into the models, making sure they retain their full features and hopefully are influential enough to affect the performance of the algorithms for the better or worse. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 5. Experimental Models\n---","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"See the other notebook.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### 6. Final Models\n---","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import models \nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import r2_score, mean_squared_error\nimport matplotlib.pyplot as plt\nimport pandas as  pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\n\ndf = pd.read_csv(\"../input/us-accidents/US_Accidents_June20.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# With the Weather_Condition column\ndf2 = df[[\"Distance(mi)\", \n          \"Temperature(F)\", \n          \"Wind_Chill(F)\", \n          \"Humidity(%)\", \n          \"Pressure(in)\", \n          \"Visibility(mi)\", \n          \"Precipitation(in)\", \n          \"Weather_Condition\",\n          \"Severity\"]]\n\n# Without the Weather_Condition column\ndf1 = df[[\"Distance(mi)\",  \n          \"Temperature(F)\", \n          \"Wind_Chill(F)\", \n          \"Humidity(%)\", \n          \"Pressure(in)\", \n          \"Visibility(mi)\", \n          \"Precipitation(in)\",\n          \"Severity\"\n          ]]\n\ndf1.replace(-1, np.nan, inplace=True)  \ndf1 = df1.dropna()\n\ndf2.replace(-1, np.nan, inplace=True)  \ndf2 = df2.dropna()\n\nY1 = df1.Severity.values\nX1 = df1.loc[:, df1.columns != 'Severity']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After dropping NA values, we have nearly 1.3 million records left.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(Y1.shape)\nprint(X1.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Due to the enormous amount of time it takes to run SVC in scikit-learn (time complexity is O(n_samples^2*n_features)), we will opt that model out in the final run. In section 5, it took us an hour to run SVC with 100k input. Mathematically, it will take at least 100 times longer than that if we run the model with 1 million input. Even though we don't have SVC in our final run, we can still draw a conclusion on its performance with and without the target attributes. \n\nAccording to Section 5, the best set of parameters will be applied to each model below. We will find out how each target attribute affects the performance of the models after fine tuning. For the first target attribute \"Weather_Condition\", we are again running models on two dataframes, one with the attribute and one without. The one without \"Weather_Condition\" will be considered the benchmark of not just this attribute but also the other three. The rest of the models will be compared to the performance of this set of benchmarks. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train1, X_test1,Y_train1,Y_test1 = train_test_split(X1, Y1, test_size=0.33, random_state=99)\n#Without Weather\n\n# KNN\n\nknn = KNeighborsClassifier(n_neighbors = 10)\nknn.fit(X_train1, Y_train1)\nY_pred = knn.predict(X_test1)\nacc_knn1 = round(knn.score(X_test1, Y_test1) * 100, 2)\nprint(\"Accuracy KNN: \" , acc_knn1)\n\n\n# Logistic Regression\n\nlogreg = LogisticRegression(max_iter = 2000, C=0.1)\nlogreg.fit(X_train1, Y_train1)\nY_pred = logreg.predict(X_test1)\nacc_log1 = round(logreg.score(X_train1, Y_train1) * 100, 2)\nprint(\"Accuracy Log: \", acc_log1)\n\n\n# Gaussian Naive Bayes\n\ngaussian = GaussianNB()\ngaussian.fit(X_train1, Y_train1)\nY_pred = gaussian.predict(X_test1)\nacc_gaussian1 = round(gaussian.score(X_test1, Y_test1) * 100, 2)\nprint(\"Accuracy Gaussian (still no fine tuning): \", acc_gaussian1)\n\n# Perceptron\n\nperceptron = Perceptron(early_stopping=False, validation_fraction=0.2)\nperceptron.fit(X_train1, Y_train1)\nY_pred = perceptron.predict(X_test1)\nacc_perceptron1 = round(perceptron.score(X_test1, Y_test1) * 100, 2)\nprint(\"Accuracy Perceptron: \", acc_perceptron1)\n\n# Stochastic Gradient Descent\n\nsgd = SGDClassifier(early_stopping=True, validation_fraction=0.1)\nsgd.fit(X_train1, Y_train1)\nY_pred = sgd.predict(X_test1)\nacc_sgd1 = round(sgd.score(X_test1, Y_test1) * 100, 2)\nprint(\"Accuracy SGD: \", acc_sgd1)\n\n# Decision Tree\n\ndecision_tree = DecisionTreeClassifier(max_depth=5)\ndecision_tree.fit(X_train1, Y_train1)\nY_pred = decision_tree.predict(X_test1)\nacc_decision_tree1 = round(decision_tree.score(X_test1, Y_test1) * 100, 2)\nprint(\"Accuracy Decision Tree: \", acc_decision_tree1)\n\n# Random Forest\n\nrandom_forest = RandomForestClassifier(n_estimators=32)\nrandom_forest.fit(X_train1, Y_train1)\nY_pred = random_forest.predict(X_test1)\nrandom_forest.score(X_train1, Y_train1)\nacc_random_forest1 = round(random_forest.score(X_test1, Y_test1) * 100, 2)\nprint(\"Accuracy Random Forest: \", acc_random_forest1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Mapping\nencoded_cons = []\nfor con in df2[\"Weather_Condition\"].values:\n    if \"Rain\" in con.split(\" \"):\n        encoded_cons.append(1)\n    elif \"Snow\" in con.split(\" \"):\n        encoded_cons.append(2)\n    elif \"Fog\" in con.split(\" \"):\n        encoded_cons.append(3)\n    else:\n        encoded_cons.append(4)\n\n# New column and delete the original Weather_Condition column\ndf2['Encoded_Weather'] = encoded_cons\ndel df2[\"Weather_Condition\"]\n\nY = df2.Severity.values\nX = df2.loc[:, df2.columns != 'Severity']df2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train2, X_test2, Y_train2, Y_test2 = train_test_split(X, Y, test_size=0.33, random_state=99)\n#With weather\n\n# KNN\n\nknn = KNeighborsClassifier(n_neighbors = 10)\nknn.fit(X_train2, Y_train2)\nY_pred = knn.predict(X_test2)\nacc_knn2 = round(knn.score(X_test2, Y_test2) * 100, 2)\nprint(\"Accuracy KNN: \" , acc_knn2)\nprint(\"Improvement: \", acc_knn2 > acc_knn1)\n\n\n# Logistic Regression\n\nlogreg = LogisticRegression(max_iter = 2000, C=0.1)\nlogreg.fit(X_train2, Y_train2)\nY_pred = logreg.predict(X_test2)\nacc_log2 = round(logreg.score(X_test2, Y_test2) * 100, 2)\nprint(\"Accuracy Log: \", acc_log2)\nprint(\"Improvement: \", acc_log2 > acc_log1)\n\n\n# Gaussian Naive Bayes\n\ngaussian = GaussianNB()\ngaussian.fit(X_train2, Y_train2)\nY_pred = gaussian.predict(X_test2)\nacc_gaussian2 = round(gaussian.score(X_test2, Y_test2) * 100, 2)\nprint(\"Accuracy Gaussian (still no fine tuning): \", acc_gaussian2)\nprint(\"Improvement: \", acc_gaussian2 > acc_gaussian1)\n\n# Perceptron\n\nperceptron = Perceptron(early_stopping=True, validation_fraction=0.1)\nperceptron.fit(X_train2, Y_train2)\nY_pred = perceptron.predict(X_test2)\nacc_perceptron2 = round(perceptron.score(X_test2, Y_test2) * 100, 2)\nprint(\"Accuracy Perceptron: \", acc_perceptron2)\nprint(\"Improvement: \", acc_perceptron2 > acc_perceptron1)\n\n\n# Stochastic Gradient Descent\n\nsgd = SGDClassifier(early_stopping=False, validation_fraction=0.2)\nsgd.fit(X_train2, Y_train2)\nY_pred = sgd.predict(X_test2)\nacc_sgd2 = round(sgd.score(X_test2, Y_test2) * 100, 2)\nprint(\"Accuracy SGD: \", acc_sgd2)\nprint(\"Improvement: \", acc_sgd2 > acc_sgd1)\n\n\n# Decision Tree\n\ndecision_tree = DecisionTreeClassifier(max_depth=4)\ndecision_tree.fit(X_train2, Y_train2)\nY_pred = decision_tree.predict(X_test2)\nacc_decision_tree2 = round(decision_tree.score(X_test2, Y_test2) * 100, 2)\nprint(\"Accuracy Decision Tree: \", acc_decision_tree2)\nprint(\"Improvement: \", acc_decision_tree2 > acc_decision_tree1)\n\n\n# Random Forest\n\nrandom_forest = RandomForestClassifier(n_estimators=32)\nrandom_forest.fit(X_train2, Y_train2)\nY_pred = random_forest.predict(X_test2)\nrandom_forest.score(X_train2, Y_train2)\nacc_random_forest2 = round(random_forest.score(X_test2, Y_test2) * 100, 2)\nprint(\"Accuracy Random Forest: \", acc_random_forest2)\nprint(\"Improvement: \", acc_random_forest2 > acc_random_forest1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# With State column\ndfState = df[[\"Distance(mi)\", \n          \"Temperature(F)\", \n          \"Wind_Chill(F)\", \n          \"Humidity(%)\", \n          \"Pressure(in)\", \n          \"Visibility(mi)\", \n          \"Precipitation(in)\", \n          \"State\",\n          \"Severity\"]]\n\ndfState.replace(-1, np.nan, inplace=True)  \ndfState = dfState.dropna()\n\n# Mapping \nencoded_states = []\nfor states in dfState[\"State\"].values:\n    if \"PA\" in states.split(\" \"):\n        encoded_states.append(1)\n    elif \"CA\" in states.split(\" \"):\n        encoded_states.append(2)\n    elif \"NY\" in states.split(\" \"):\n        encoded_states.append(3)\n    else:\n        encoded_states.append(4)\n\n# New column and delete the original Weather_Condition column\ndfState['Encoded_States'] = encoded_states\ndel dfState[\"State\"]\n\n\nYState = dfState.Severity.values\nXState = dfState.loc[:, dfState.columns != 'Severity']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_trainState, X_testState, Y_trainState, Y_testState = train_test_split(XState, YState, test_size=0.33, random_state=99)\n#With state\n\n# KNN\n\nknn = KNeighborsClassifier(n_neighbors = 10)\nknn.fit(X_trainState, Y_trainState)\nY_pred = knn.predict(X_testState)\nacc_knnState = round(knn.score(X_testState, Y_testState) * 100, 2)\nprint(\"Accuracy KNN: \" , acc_knnState)\nprint(\"Improvement: \", acc_knnState > acc_knn1)\n\n\n# Logistic Regression\n\nlogreg = LogisticRegression(max_iter = 2000, C=0.1)\nlogreg.fit(X_trainState, Y_trainState)\nY_pred = logreg.predict(X_testState)\nacc_logState = round(logreg.score(X_testState, Y_testState) * 100, 2)\nprint(\"Accuracy Log: \", acc_logState)\nprint(\"Improvement: \", acc_logState > acc_log1)\n\n\n# Gaussian Naive Bayes\n\ngaussian = GaussianNB()\ngaussian.fit(X_trainState, Y_trainState)\nY_pred = gaussian.predict(X_testState)\nacc_gaussianState = round(gaussian.score(X_testState, Y_testState) * 100, 2)\nprint(\"Accuracy Gaussian (still no fine tuning): \", acc_gaussianState)\nprint(\"Improvement: \", acc_gaussianState > acc_gaussian1)\n\n\n# Perceptron\n\nperceptron = Perceptron(early_stopping=True, validation_fraction=0.1)\nperceptron.fit(X_trainState, Y_trainState)\nY_pred = perceptron.predict(X_testState)\nacc_perceptronState = round(perceptron.score(X_testState, Y_testState) * 100, 2)\nprint(\"Accuracy Perceptron: \", acc_perceptronState)\nprint(\"Improvement: \", acc_perceptronState > acc_perceptron1)\n\n\n# Stochastic Gradient Descent\n\nsgd = SGDClassifier(early_stopping=False, validation_fraction=0.2)\nsgd.fit(X_trainState, Y_trainState)\nY_pred = sgd.predict(X_testState)\nacc_sgdState = round(sgd.score(X_testState, Y_testState) * 100, 2)\nprint(\"Accuracy SGD: \", acc_sgdState)\nprint(\"Improvement: \", acc_sgdState > acc_sgd1)\n\n\n# Decision Tree\n\ndecision_tree = DecisionTreeClassifier(max_depth=7)\ndecision_tree.fit(X_trainState, Y_trainState)\nY_pred = decision_tree.predict(X_testState)\nacc_decision_treeState = round(decision_tree.score(X_testState, Y_testState) * 100, 2)\nprint(\"Accuracy Decision Tree: \", acc_decision_treeState)\nprint(\"Improvement: \", acc_decision_treeState > acc_decision_tree1)\n\n\n# Random Forest\n\nrandom_forest = RandomForestClassifier(n_estimators=32)\nrandom_forest.fit(X_trainState, Y_trainState)\nY_pred = random_forest.predict(X_testState)\nrandom_forest.score(X_trainState, Y_trainState)\nacc_random_forestState = round(random_forest.score(X_testState, Y_testState) * 100, 2)\nprint(\"Accuracy Random Forest: \", acc_random_forestState)\nprint(\"Improvement: \", acc_random_forestState > acc_random_forest1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\n\n\ndf[\"Year\"] = pd.DatetimeIndex(df[\"Start_Time\"]).year\n\n#With Year\ndfYear = df[[\"Distance(mi)\", \n          \"Temperature(F)\", \n          \"Wind_Chill(F)\", \n          \"Humidity(%)\", \n          \"Pressure(in)\", \n          \"Visibility(mi)\", \n          \"Precipitation(in)\", \n          \"Year\",\n          \"Severity\"]]\n\ndfState.replace(-1, np.nan, inplace=True)  \ndfState = dfState.dropna()\n\nYYear = dfYear.Severity.values\nXYear = dfYear.loc[:, dfYear.columns != 'Severity']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_trainYear, X_testYear, Y_trainYear, Y_testYear = train_test_split(XYear, YYear, test_size=0.33, random_state=99)\n#With year\n\n# KNN\n\nknn = KNeighborsClassifier(n_neighbors = 10)\nknn.fit(X_trainYear, Y_trainYear)\nY_pred = knn.predict(X_testYear)\nacc_knnYear = round(knn.score(X_testYear, Y_testYear) * 100, 2)\nprint(\"Accuracy KNN: \" , acc_knnYear)\nprint(\"Improvement: \", acc_knnYear > acc_knn1)\n\n\n# Logistic Regression\n\nlogreg = LogisticRegression(max_iter = 400, C=1)\nlogreg.fit(X_trainYear, Y_trainYear)\nY_pred = logreg.predict(X_testYear)\nacc_logYear = round(logreg.score(X_testYear, Y_testYear) * 100, 2)\nprint(\"Accuracy Log: \", acc_logYear)\nprint(\"Improvement: \", acc_logYear > acc_log1)\n\n\n# Gaussian Naive Bayes\n\ngaussian = GaussianNB()\ngaussian.fit(X_trainYear, Y_trainYear)\nY_pred = gaussian.predict(X_testYear)\nacc_gaussianYear = round(gaussian.score(X_testYear, Y_testYear) * 100, 2)\nprint(\"Accuracy Gaussian (still no fine tuning): \", acc_gaussianYear)\nprint(\"Improvement: \", acc_gaussianYear > acc_gaussian1)\n\n# Perceptron\n\nperceptron = Perceptron(early_stopping=True, validation_fraction=0.1)\nperceptron.fit(X_trainYear, Y_trainYear)\nY_pred = perceptron.predict(X_testYear)\nacc_perceptronYear = round(perceptron.score(X_testYear, Y_testYear) * 100, 2)\nprint(\"Accuracy Perceptron: \", acc_perceptronYear)\nprint(\"Improvement: \", acc_perceptronYear > acc_perceptron1)\n\n\n# Stochastic Gradient Descent\n\nsgd = SGDClassifier(early_stopping=True, validation_fraction=0.1)\nsgd.fit(X_trainYear, Y_trainYear)\nY_pred = sgd.predict(X_testYear)\nacc_sgdYear = round(sgd.score(X_testYear, Y_testYear) * 100, 2)\nprint(\"Accuracy SGD: \", acc_sgdYear)\nprint(\"Improvement: \", acc_sgdYear > acc_sgd1)\n\n\n# Decision Tree\n\ndecision_tree = DecisionTreeClassifier(max_depth=5)\ndecision_tree.fit(X_trainYear, Y_trainYear)\nY_pred = decision_tree.predict(X_testYear)\nacc_decision_treeYear = round(decision_tree.score(X_testYear, Y_testYear) * 100, 2)\nprint(\"Accuracy Decision Tree: \", acc_decision_treeYear)\nprint(\"Improvement: \", acc_decision_treeYear > acc_decision_tree1)\n\n\n# Random Forest\n\nrandom_forest = RandomForestClassifier(n_estimators=32)\nrandom_forest.fit(X_trainYear, Y_trainYear)\nY_pred = random_forest.predict(X_testYear)\nrandom_forest.score(X_trainYear, Y_trainYear)\nacc_random_forestYear = round(random_forest.score(X_testYear, Y_testYear) * 100, 2)\nprint(\"Accuracy Random Forest: \", acc_random_forestYear)\nprint(\"Improvement: \", acc_random_forestYear > acc_random_forest1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Hour\"] = pd.DatetimeIndex(df[\"Start_Time\"]).hour\n\n#With Year\ndfHour = df[[\"Distance(mi)\", \n          \"Temperature(F)\", \n          \"Wind_Chill(F)\", \n          \"Humidity(%)\", \n          \"Pressure(in)\", \n          \"Visibility(mi)\", \n          \"Precipitation(in)\", \n          \"Hour\",\n          \"Severity\"]]\n\ndfHour.replace(-1, np.nan, inplace=True)  \ndfHour = dfHour.dropna()\n\nYHour = dfHour.Severity.values\nXHour = dfHour.loc[:, dfHour.columns != 'Severity']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_trainHour, X_testHour, Y_trainHour, Y_testHour = train_test_split(XHour, YHour, test_size=0.33, random_state=99)\n#With Hour\n\n# KNN\n\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_trainHour, Y_trainHour)\nY_pred = knn.predict(X_testHour)\nacc_knnHour = round(knn.score(X_testHour, Y_testHour) * 100, 2)\nprint(\"Accuracy KNN: \" , acc_knnHour)\nprint(\"Improvement: \", acc_knnHour > acc_knnNoHour)\n\n\n# Logistic Regression\n\nlogreg = LogisticRegression(max_iter = 400)\nlogreg.fit(X_trainHour, Y_trainHour)\nY_pred = logreg.predict(X_testHour)\nacc_logHour = round(logreg.score(X_testHour, Y_testHour) * 100, 2)\nprint(\"Accuracy Log: \", acc_logYear)\nprint(\"Improvement: \", acc_logHour > acc_logNoHour)\n\n\n# Gaussian Naive Bayes\n\ngaussian = GaussianNB()\ngaussian.fit(X_trainHour, Y_trainHour)\nY_pred = gaussian.predict(X_testHour)\nacc_gaussianHour = round(gaussian.score(X_testHour, Y_testHour) * 100, 2)\nprint(\"Accuracy Gaussian: \", acc_gaussianHour)\nprint(\"Improvement: \", acc_gaussianHour > acc_gaussianNoHour)\n\n# Perceptron\n\nperceptron = Perceptron()\nperceptron.fit(X_trainHour, Y_trainHour)\nY_pred = perceptron.predict(X_testHour)\nacc_perceptronHour = round(perceptron.score(X_testHour, Y_testHour) * 100, 2)\nprint(\"Accuracy Perceptron: \", acc_perceptronHour)\nprint(\"Improvement: \", acc_perceptronHour > acc_perceptronNoHour)\n\n\n# Stochastic Gradient Descent\n\nsgd = SGDClassifier()\nsgd.fit(X_trainHour, Y_trainHour)\nY_pred = sgd.predict(X_testHour)\nacc_sgdHour = round(sgd.score(X_testHour, Y_testHour) * 100, 2)\nprint(\"Accuracy SGD: \", acc_sgdHour)\nprint(\"Improvement: \", acc_sgdHour > acc_sgdNoHour)\n\n\n# Decision Tree\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_trainHour, Y_trainHour)\nY_pred = decision_tree.predict(X_testHour)\nacc_decision_treeHour = round(decision_tree.score(X_testHour, Y_testHour) * 100, 2)\nprint(\"Accuracy Decision Tree: \", acc_decision_treeHour)\nprint(\"Improvement: \", acc_decision_treeHour > acc_decision_treeNoHour)\n\n\n# Random Forest\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_trainHour, Y_trainHour)\nY_pred = random_forest.predict(X_testHour)\nrandom_forest.score(X_trainHour, Y_trainHour)\nacc_random_forestHour = round(random_forest.score(X_testHour, Y_testHour) * 100, 2)\nprint(\"Accuracy Random Forest: \", acc_random_forestHour)\nprint(\"Improvement: \", acc_random_forestHour > acc_random_forestNoHour)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Project Requirements\n\nThis final project examines the level of knowledge the students have learned from the course. The following course outcomes will be checked against the content of the report:\n\nUpon successful completion of this course, a student will be able to:\n* Describe the key Python tools and libraries that related to a typical data analytics project. \n* Identify data science libraries, frameworks, modules, and toolkits in Python that efficiently implement the most common data science algorithms and techniques.\n* Apply latest Python techniques in data acquisition, transformation and predictive analytics for data science projects.\n* Discuss the underlying principles and main characteristics of the most common methods and techniques for data analytics. \n* Build data analytic and predictive models for real world data sets using existing Python libraries.\n\n** Marking will be foucsed on both presentation and content.** \n\n## Written Presentation Requirements\nThe report will be judged on the basis of visual appearance, grammatical correctness, and quality of writing, as well as its contents. Please make sure that the text of your report is well-structured, using paragraphs, full sentences, and other features of well-written presentation.\n\n## Technical Content:\n* Is the problem well defined and described thoroughly?\n* Is the size and complexity of the data set used in this project comparable to that of the example data sets used in the lectures and assignments?\n* Did the report describe the charactriatics of the data?\n* Did the report describe the goals of the data analysis?\n* Did the analysis conduct exploratory analyses on the data?\n* Did the analysis build models of the data and evaluated the performance of the models?\n* Overall, what is the rating of this project?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}