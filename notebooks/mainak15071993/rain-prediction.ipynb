{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load the dataset and explore"},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.read_csv('../input/weather-dataset-rattle-package/weatherAUS.csv',index_col=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.dtypes)\nprint(train.shape)\nprint(train.describe(include='all'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check if there are missing values in the target variable if true then drop them\nprint(train['RainTomorrow'].isna().sum()/len(train))\ntrain=train.dropna(axis=0,subset=['RainTomorrow'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprint(train.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Divide the dataset into X and y"},{"metadata":{"trusted":true},"cell_type":"code","source":"y=train[['RainTomorrow']]\nX=train.drop(['RainTomorrow'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Let us perform EDA on the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let us define few functions for visualization\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef boxplot(df):\n    plt.figure(figsize=(10,6))\n    plt.title('Boxplot')\n    sns.boxplot(df)\n    plt.show()\n\ndef histogram(df):\n    plt.figure(figsize=(10,6))\n    sns.displot(df,kde=True)\n    plt.title('Histogram')\n    sns.despine()\n    plt.show\n\ndef countplot(df):\n    plt.figure(figsize=(10,6))\n    sns.countplot(df,palette='spring')\n    plt.title('Countplot')\n    plt.show()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X.dtypes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualize the numeric variables (Boxplot)\n\nnum_col=X.select_dtypes(include=[np.number]).columns\nnum_cols=[n for n in num_col]\n \nfor n in num_cols:\n    boxplot(X[n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From boxplot we can see the only 4 columns have no outliers. Sunshine,WindSpeed3pm , Cloud9am and Cloud3am. In the next step we will visualize the distribution of the variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Distribution of the numeric variables\n\nfor n in num_cols:\n    histogram(X[n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(num_cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The columns ['Evaporation', 'Sunshine', 'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am','Cloud9am', 'Cloud3pm'] are not symmetric in nature. We'll apply preprocessing later. We'll not that much be oncerned about outlers as we'll implement Boosting learner."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Count plot of the categorical variables\ncat_col=X.select_dtypes(exclude=[np.number]).columns\ncat_cols=[ c for c in cat_col]\n\nfor c in cat_cols:\n    countplot(X[c])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see thet the RainToday column is imbalanced."},{"metadata":{},"cell_type":"markdown","source":"# Check for missing values\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X.select_dtypes(include=[np.number]).isna().sum()/len(X))\nprint('************************************************')\nprint(X.select_dtypes(exclude=[np.number]).isna().sum()/len(X))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Evaporation and Cloud3pm has 43 and 40 percent missing values. Sunshine also has 48 percent missing values and Cloud9am has 37 percent missing values. We'll impute these values later. What strategy to use for imputation depends on whether outliers exists ir not for that variable."},{"metadata":{},"cell_type":"markdown","source":"# Check whether the dependent variable is balanced or not"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y.value_counts())\ncountplot(y['RainTomorrow'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The dataset is highly imbalaced. Thus we'll split the data in a stratified manner."},{"metadata":{},"cell_type":"markdown","source":"# Perform Train Test split"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_valid,y_train,y_valid=train_test_split(X,y,test_size=.25,stratify=y,random_state=99)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape, X_valid.shape)\nprint(y_train.value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Clearly the stratification is maintained here also."},{"metadata":{},"cell_type":"markdown","source":"# Apply preprocessing "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Apply preprocessing to the numeric variables\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import QuantileTransformer\n\nfor c in num_cols:\n    im_n=SimpleImputer(strategy='median')\n    X_train[c]=im_n.fit_transform(X_train[[c]])\n    X_valid[c]=im_n.transform(X_valid[[c]])\n\nfor n in num_cols:\n    qt=QuantileTransformer(output_distribution='normal',random_state=99)\n    X_train[n]=qt.fit_transform(X_train[[n]])\n    X_valid[n]=qt.transform(X_valid[[n]])\n    \nprint(X_train.isna().sum())       ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Clearly the missing values are imputed with median strategy"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Preprocessing for categorical variables\nfrom sklearn.preprocessing import OrdinalEncoder\n\nfor c in cat_cols:\n    im_c=SimpleImputer(strategy='most_frequent')\n    X_train[c]=im_c.fit_transform(X_train[[c]])\n    X_valid[c]=im_c.transform(X_valid[[c]])\n\nfor c in cat_cols:\n    oe=OrdinalEncoder(dtype=int)\n    X_train[c]=oe.fit_transform(X_train[[c]])\n    X_valid[c]=oe.transform(X_valid[[c]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.head(n=6))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All the preprocessing is completed without any data leakage"},{"metadata":{},"cell_type":"markdown","source":"> # Modeling using catBoostClassifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost import CatBoostClassifier,Pool\n\ncat_features = [X_train.columns.get_loc(col) for col in cat_cols]\nprint(cat_features)\n\ntrain_x=Pool(data=X_train,label=y_train,cat_features=cat_features)\nvalid_x=Pool(data=X_valid,label=y_valid,cat_features=cat_features)\n\nparams = {'loss_function':'Logloss',\n          'learning_rate':0.03,\n          'depth':7,\n          'n_estimators':10000,\n          'eval_metric':'AUC',\n          'od_type': 'Iter',\n          'od_wait':1000,\n          'verbose':200,\n          'one_hot_max_size':0,\n          'class_weights':(1,3.4),\n          'random_state':99\n         }\n#Fit the random forest learner\ncb=CatBoostClassifier(**params)\ncb.fit(train_x,eval_set=valid_x,use_best_model=True,plot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Simple Catboost model performs very well on the validation data. "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}