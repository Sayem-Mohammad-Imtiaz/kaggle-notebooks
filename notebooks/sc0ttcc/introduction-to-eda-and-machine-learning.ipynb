{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Predicting the final grade of a student\n\nThe data used is from a Portuguese secondary school. The data includes academic and personal characteristics of the students as well as final grades. The task is to predict the final grade from the student information. (Regression)\n\n### [Link to dataset](https://archive.ics.uci.edu/ml/datasets/student+performance)\n\n### Citation:\n\nP. Cortez and A. Silva. Using Data Mining to Predict Secondary School Student Performance. In A. Brito and J. Teixeira Eds., Proceedings of 5th FUture BUsiness TEChnology Conference (FUBUTEC 2008) pp. 5-12, Porto, Portugal, April, 2008, EUROSIS, ISBN 978-9077381-39-7.\n[Web Link](http://www3.dsi.uminho.pt/pcortez/student.pdf)\n\n### Reference [article](/home/dipamvasani7/Desktop/Ubuntu/jupyter_notebooks/data)","metadata":{"_uuid":"4fd7d146d8bc4ccc9f2b77f5cfd28e7260129475"}},{"cell_type":"markdown","source":"**1.导入所需函数库**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport scipy\nimport matplotlib.pyplot as plt\nimport pylab as pl\nimport sys\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, median_absolute_error\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.svm import SVR\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.decomposition import PCA\nfrom sklearn import tree\nfrom sklearn.naive_bayes import GaussianNB","metadata":{"execution":{"iopub.status.busy":"2021-06-02T02:47:23.806151Z","iopub.execute_input":"2021-06-02T02:47:23.806491Z","iopub.status.idle":"2021-06-02T02:47:23.816071Z","shell.execute_reply.started":"2021-06-02T02:47:23.806447Z","shell.execute_reply":"2021-06-02T02:47:23.815054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**2.说明该数据集基本情况**","metadata":{}},{"cell_type":"code","source":"student = pd.read_csv('../input/waterpower/.csv',encoding='cp936')\nstudent.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T02:47:23.820914Z","iopub.execute_input":"2021-06-02T02:47:23.82115Z","iopub.status.idle":"2021-06-02T02:47:23.877952Z","shell.execute_reply.started":"2021-06-02T02:47:23.821108Z","shell.execute_reply":"2021-06-02T02:47:23.8769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Total number of students:',len(student))","metadata":{"execution":{"iopub.status.busy":"2021-06-02T02:47:23.879272Z","iopub.execute_input":"2021-06-02T02:47:23.879544Z","iopub.status.idle":"2021-06-02T02:47:23.884441Z","shell.execute_reply.started":"2021-06-02T02:47:23.879503Z","shell.execute_reply":"2021-06-02T02:47:23.883651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**3.成绩分布情况**","metadata":{}},{"cell_type":"code","source":"student['成绩'].describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T02:47:23.885538Z","iopub.execute_input":"2021-06-02T02:47:23.885747Z","iopub.status.idle":"2021-06-02T02:47:23.901558Z","shell.execute_reply.started":"2021-06-02T02:47:23.885714Z","shell.execute_reply":"2021-06-02T02:47:23.900633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(70.70)\nax = fig.add_subplot(1,1,1)\nax.hist(student['成绩'],bins = 100)\nplt.title('Final Score')\nplt.xlabel('score')\nplt.ylabel('Totle number')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T02:47:23.902668Z","iopub.execute_input":"2021-06-02T02:47:23.902904Z","iopub.status.idle":"2021-06-02T02:47:24.419036Z","shell.execute_reply.started":"2021-06-02T02:47:23.902866Z","shell.execute_reply":"2021-06-02T02:47:24.418347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**4.成绩相关性分析**","metadata":{}},{"cell_type":"code","source":"most_correlated = student.corr().abs()['成绩'].sort_values(ascending=False)\nmost_correlated = most_correlated[:12]\nprint(most_correlated)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T02:47:24.420555Z","iopub.execute_input":"2021-06-02T02:47:24.420799Z","iopub.status.idle":"2021-06-02T02:47:24.429775Z","shell.execute_reply.started":"2021-06-02T02:47:24.42075Z","shell.execute_reply":"2021-06-02T02:47:24.428881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**5.选择相关性最高的四个因素进行深度研究**","metadata":{}},{"cell_type":"code","source":"studentDataset = student[['卷面成绩', '作业成绩', '作业提交个数', '作业提交次数', '成绩']]\n\ndataset1 = studentDataset[studentDataset['成绩'] >= 70]\ndatasetc1 = dataset1.copy()\ndatasetc1['成绩'] = 1\n\ndataset2 = studentDataset[(studentDataset['成绩'] < 70)]\ndatasetc2 = dataset2.copy()\ndatasetc2['成绩'] = 0\n\ndatasetSum = pd.concat([datasetc1, datasetc2])\ndatasetSum.columns =['paperGrades','taskGrades','Number of Job Submissions','Count of Job Submissions','grade']\n\nX = datasetSum.iloc[:, 0:4].values\ny = datasetSum.iloc[:, 4].values","metadata":{"execution":{"iopub.status.busy":"2021-06-02T02:47:24.432554Z","iopub.execute_input":"2021-06-02T02:47:24.433224Z","iopub.status.idle":"2021-06-02T02:47:24.446688Z","shell.execute_reply.started":"2021-06-02T02:47:24.43291Z","shell.execute_reply":"2021-06-02T02:47:24.445746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**6.相关性因素热图**","metadata":{}},{"cell_type":"code","source":"corr = datasetSum.corr()\nplt.subplots(figsize=(15,10))\nsns.heatmap(corr, annot=True) ","metadata":{"execution":{"iopub.status.busy":"2021-06-02T02:47:24.448657Z","iopub.execute_input":"2021-06-02T02:47:24.449289Z","iopub.status.idle":"2021-06-02T02:47:25.41432Z","shell.execute_reply.started":"2021-06-02T02:47:24.448941Z","shell.execute_reply":"2021-06-02T02:47:25.413448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**7. 四个特征变量相关性分析**","metadata":{}},{"cell_type":"code","source":"regr = RandomForestRegressor()\n# regr = RandomForestRegressor(random_state=100,\n#                              bootstrap=True,\n#                              max_depth=2,\n#                              max_features=2,\n#                              min_samples_leaf=3,\n#                              min_samples_split=5,\n#                              n_estimators=3)\npipe = Pipeline([('scaler', StandardScaler()), ('reduce_dim', PCA()),\n                 ('regressor', regr)])\npipe.fit(X_train, y_train)\nypipe = pipe.predict(X_test)\n\nimportances = list(regr.feature_importances_)\n# List of tuples with variable and importance\nprint(importances)\n\n# Saving feature names for later use\ndatasetSum.columns =['paperGrades','taskGrades','Number of Job Submissions','Count of Job Submissions','grade']\nfeature_list = list(datasetSum.columns)[0:4]\n\nfeature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n# Sort the feature importances by most important first\nfeature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n\n\nplt.rcParams['font.sans-serif']=['SimHei'] #用来正常显示中文标签\nplt.rcParams['axes.unicode_minus'] = False #用来正常显示负号\nx_values = list(range(len(importances)))\n# Make a bar chart\nplt.bar(x_values, importances, orientation = 'vertical')\n# Tick labels for x axis\nplt.xticks(x_values, feature_list,rotation=6,)\n# Axis labels and title\nplt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances');\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T02:47:25.415835Z","iopub.execute_input":"2021-06-02T02:47:25.416363Z","iopub.status.idle":"2021-06-02T02:47:25.79097Z","shell.execute_reply.started":"2021-06-02T02:47:25.416299Z","shell.execute_reply":"2021-06-02T02:47:25.78999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**8. 选择多种机器学习模型做回归分析**","metadata":{}},{"cell_type":"code","source":"\n\n# 将数据分为训练集和测试集\nX_train, X_test, y_train, y_test = train_test_split(X,\n                                                    y,\n                                                    test_size=0.2,\n                                                    random_state=0)\n# 选择7种不同的回归模型对数据进行预测，对比7种模型的MAE和RMSE\n\ndef evaluate(X_train, X_test, y_train, y_test):\n    # Names of models\n    model_name_list = ['Linear Regression', 'ElasticNet Regression',\n                       'Random Forest', 'Extra Trees', 'SVM',\n                       'Gradient Boosted', 'Baseline']\n\n    model1 = LinearRegression()\n    model2 = ElasticNet(alpha=1.0, l1_ratio=0.5)\n    model3 = RandomForestRegressor(n_estimators=100)\n    model4 = ExtraTreesRegressor(n_estimators=100)\n    model5 = SVR(kernel='rbf', degree=3, C=1.0, gamma='auto')\n    model6 = GradientBoostingRegressor(n_estimators=50)\n\n    # Dataframe for results\n    results = pd.DataFrame(columns=['mae', 'rmse'], index=model_name_list)\n\n    # Train and predict with each model\n    for i, model in enumerate([model1, model2, model3, model4, model5, model6]):\n        model.fit(X_train, y_train)\n        predictions = model.predict(X_test)\n\n        # Metrics\n        mae = np.mean(abs(predictions - y_test))\n        rmse = np.sqrt(np.mean((predictions - y_test) ** 2))\n\n        # Insert results into the dataframe\n        model_name = model_name_list[i]\n        results.loc[model_name, :] = [mae, rmse]\n\n    # Median Value Baseline Metrics\n    baseline = np.median(y_train)\n    baseline_mae = np.mean(abs(baseline - y_test))\n    baseline_rmse = np.sqrt(np.mean((baseline - y_test) ** 2))\n\n    results.loc['Baseline', :] = [baseline_mae, baseline_rmse]\n\n    return results\n\nresults = evaluate(X_train, X_test, y_train, y_test)\nprint(results)\n\nplt.figure(figsize=(12, 8))\n\n# Root mean squared error\nax =  plt.subplot(1, 2, 1)\nresults.sort_values('mae', ascending = True).plot.bar(y = 'mae', color = 'b', ax = ax, fontsize=20)\nplt.title('Model Mean Absolute Error', fontsize=20)\nplt.ylabel('MAE', fontsize=20)\n\n# Median absolute percentage error\nax = plt.subplot(1, 2, 2)\nresults.sort_values('rmse', ascending = True).plot.bar(y = 'rmse', color = 'r', ax = ax, fontsize=20)\nplt.title('Model Root Mean Squared Error', fontsize=20)\nplt.ylabel('RMSE',fontsize=20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T02:47:25.792239Z","iopub.execute_input":"2021-06-02T02:47:25.792614Z","iopub.status.idle":"2021-06-02T02:47:27.490949Z","shell.execute_reply.started":"2021-06-02T02:47:25.79245Z","shell.execute_reply":"2021-06-02T02:47:27.489934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**9. 使用线性分类模型计算准确率**","metadata":{}},{"cell_type":"code","source":"\nlogreg = LogisticRegression(solver= 'lbfgs' ,max_iter=100)\nlogreg.fit(X, y)\ny_pred = logreg.predict(X)\nprint('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X, y)))\n\n\nc_m = confusion_matrix(y, y_pred)\nprint(c_m)\n\nsns.heatmap(pd.DataFrame(c_m), annot=True, cmap=\"YlGnBu\", fmt='g')\nplt.tight_layout()\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\n\nprint(classification_report(y, y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-06-02T02:47:27.492015Z","iopub.execute_input":"2021-06-02T02:47:27.492233Z","iopub.status.idle":"2021-06-02T02:47:28.100247Z","shell.execute_reply.started":"2021-06-02T02:47:27.492192Z","shell.execute_reply":"2021-06-02T02:47:28.099046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**10.使用多种模型预测准确率分析**","metadata":{"_uuid":"1777bb0314a93980c5577e9f6f48e2a0da156bdc"}},{"cell_type":"code","source":"# creating a model\nmodel = RandomForestClassifier()\n\n# feeding the training data to the model\nmodel.fit(X_train, y_train)\n\n# predicting the x-test results\ny_pred = model.predict(X_test)\n\n# roc_auc_score(y_test, y_pred, multi_class='raise')\n\nprint(\"Training Accuracy :\", model.score(X_train, y_train))\nprint(\"Testing Accuracy :\", model.score(X_test, y_test))","metadata":{"_uuid":"25d1c535a6287dc4ee9d957600296cf42dd0b4aa","execution":{"iopub.status.busy":"2021-06-02T02:47:28.101831Z","iopub.execute_input":"2021-06-02T02:47:28.102158Z","iopub.status.idle":"2021-06-02T02:47:28.163126Z","shell.execute_reply.started":"2021-06-02T02:47:28.102104Z","shell.execute_reply":"2021-06-02T02:47:28.162229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**10.1 随机森林模型计算准确率**","metadata":{"_uuid":"f09286dceb58152550ee9f3f53a5cb5e09eba2a2"}},{"cell_type":"code","source":"classifier = RandomForestClassifier(n_estimators = 50, random_state=0)\nclassifier.fit(X_train, y_train)\ny_pred1 = classifier.predict(X_test)\nroc_auc_score(y_test, y_pred1)\ncm = confusion_matrix(y_test, y_pred1)\nplt.figure(figsize=(6,6))\nsns.heatmap(cm, annot=True, fmt=\".0f\", linewidths=0.5, square = True, cmap = 'Pastel1')\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nRandmForestAccuracy =roc_auc_score(y_test, y_pred1)\n# RandmForestAccuracy = 'Accuracy Score: {0}'.format(roc_auc_score(y_test, y_pred1))\nprint(RandmForestAccuracy)\nplt.title(all_sample_title, size = 15)","metadata":{"_uuid":"a8d09942763d369af6cff00eeb77100d7961a84a","execution":{"iopub.status.busy":"2021-06-02T02:47:28.164621Z","iopub.execute_input":"2021-06-02T02:47:28.164955Z","iopub.status.idle":"2021-06-02T02:47:28.783551Z","shell.execute_reply.started":"2021-06-02T02:47:28.164889Z","shell.execute_reply":"2021-06-02T02:47:28.782568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**10.2 朴素贝叶斯模型计算准确率**","metadata":{}},{"cell_type":"code","source":"def NBAccuracy(features_train, labels_train, features_test, labels_test):\n    \n    clf = GaussianNB()#创建分类器\n    clf.fit(features_train, labels_train) #拟合训练分类器\n    pred = clf.predict(features_test) #用训练过的分类器预测测试特征对应的标签\n    \n    accuracy = clf.score(features_test, labels_test)\n    ###利用分类器调用score函数计算数据的精确度\n    return accuracy\n\ndef submitAccuracy():\n    accuracy = NBAccuracy(X_train, y_train,X_test, y_test)\n    return accuracy\nNaiveBayesAccuracy = submitAccuracy()\nprint(NaiveBayesAccuracy)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T02:47:28.784994Z","iopub.execute_input":"2021-06-02T02:47:28.785506Z","iopub.status.idle":"2021-06-02T02:47:28.797178Z","shell.execute_reply.started":"2021-06-02T02:47:28.785447Z","shell.execute_reply":"2021-06-02T02:47:28.79629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**10.3 SVM模型计算准确率**","metadata":{}},{"cell_type":"code","source":"clf = SVC(kernel=\"linear\") #创建分类器\nclf.fit(X_train, y_train)#拟合训练分类器\npred=clf.predict(X_test) #预测并将预测结果存放在名为pred的列表内\n\nfrom sklearn.metrics import accuracy_score\n###借用sklearn.metric模块中的accuracy_score函数计算精确度\nSVMAccuracy = accuracy_score(pred, y_test) #计算精确度\n\nprint(SVMAccuracy)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T02:47:28.798734Z","iopub.execute_input":"2021-06-02T02:47:28.79925Z","iopub.status.idle":"2021-06-02T02:47:29.222735Z","shell.execute_reply.started":"2021-06-02T02:47:28.799183Z","shell.execute_reply":"2021-06-02T02:47:29.222001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**10.4 二叉树模型计算准确率**","metadata":{}},{"cell_type":"code","source":"clf = tree.DecisionTreeClassifier() #创建一个分类器\n\nclf.fit(X_train,y_train) #拟合训练分类器\npredictions = clf.predict(X_test)\n\nDTAccuracy=accuracy_score(y_true = y_test, y_pred = predictions)\nprint(DTAccuracy)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T02:47:29.223647Z","iopub.execute_input":"2021-06-02T02:47:29.22399Z","iopub.status.idle":"2021-06-02T02:47:29.233578Z","shell.execute_reply.started":"2021-06-02T02:47:29.223952Z","shell.execute_reply":"2021-06-02T02:47:29.232732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**11.不同模型准确率对比**","metadata":{}},{"cell_type":"code","source":"sb=sns.barplot(x=['RandomForest','NaiveBayes','SVM','DecisionTree'], \n                y=[RandmForestAccuracy,NaiveBayesAccuracy,SVMAccuracy,DTAccuracy])\nsb.set_xlabel('Machine Learning Model')\nsb.set_ylabel('Accuracy')\nsb.axes.set_title(\"Different ML Model Accuracy Comparision\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T02:47:29.234812Z","iopub.execute_input":"2021-06-02T02:47:29.235069Z","iopub.status.idle":"2021-06-02T02:47:29.531314Z","shell.execute_reply.started":"2021-06-02T02:47:29.235027Z","shell.execute_reply":"2021-06-02T02:47:29.530733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Grades according to the number of students who scored them","metadata":{"_uuid":"4f23eb0de5a6f7ef79c3631dc52d3be32b523688"}},{"cell_type":"code","source":"plt.subplots(figsize=(8,12))\ngrade_counts = student['G3'].value_counts().sort_values().plot.barh(width=.9,color=sns.color_palette('inferno',40))\ngrade_counts.axes.set_title('Number of students who scored a particular grade',fontsize=30)\ngrade_counts.set_xlabel('Number of students', fontsize=30)\ngrade_counts.set_ylabel('Final Grade', fontsize=30)\nplt.show()","metadata":{"_uuid":"4858b087380366df9fbce93ae6b55be213cada7b","execution":{"iopub.status.busy":"2021-06-02T02:47:29.532401Z","iopub.execute_input":"2021-06-02T02:47:29.532796Z","iopub.status.idle":"2021-06-02T02:47:30.103902Z","shell.execute_reply.started":"2021-06-02T02:47:29.532753Z","shell.execute_reply":"2021-06-02T02:47:30.019894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\nThis plot does not tell us much. What we should really plot is the distribution of grade.\n\n","metadata":{"_uuid":"13ef5df1f876db680fb73fd23554dce920611cdf"}},{"cell_type":"markdown","source":"# Final grade distribution","metadata":{"_uuid":"a6ec94b998f63fb93eb6b0c9ec3735f0be7ce2f2"}},{"cell_type":"code","source":"b = sns.countplot(student['G3'])\nb.axes.set_title('Distribution of Final grade of students', fontsize = 30)\nb.set_xlabel('Final Grade', fontsize = 20)\nb.set_ylabel('Count', fontsize = 20)\nplt.show()","metadata":{"_uuid":"cd672f2c325598c7690d80e74e60a31ab9742ac6","execution":{"iopub.status.busy":"2021-06-02T02:47:30.020693Z","iopub.status.idle":"2021-06-02T02:47:30.021052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Hmmmmm!\n\nSomething seems off here. Apart from the high number of students scoring 0, the distribution is normal as expected.\nMaybe the value 0 is used in place of null. Or maybe the students who did not appear for the exam, or were not allowed to sit for the exam due to some reason are marked as 0. We cannot be sure. Let us check the table for null values","metadata":{"_uuid":"5fd9017e99d8ba1786d3bc09ce77d74367cacbef"}},{"cell_type":"code","source":"student.isnull().any()","metadata":{"_uuid":"b889a5fcf61e50dd5437a35800bd49492db99e1f","execution":{"iopub.status.busy":"2021-06-02T02:47:30.0218Z","iopub.status.idle":"2021-06-02T02:47:30.022367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### None of the variables has null values so maybe grade 0 does not mean null after all","metadata":{"_uuid":"53f116b60f2710bc266e1a9bdaeaa8da440e6359"}},{"cell_type":"markdown","source":"## Next let us take a look at the gender variable","metadata":{"_uuid":"c79114befc4c85069fd40f31863714404e1f9394"}},{"cell_type":"code","source":"male_studs = len(student[student['sex'] == 'M'])\nfemale_studs = len(student[student['sex'] == 'F'])\nprint('Number of male students:',male_studs)\nprint('Number of female students:',female_studs)","metadata":{"_uuid":"2e3f9e88643618a23ecb4cfe7528c344235305d9","execution":{"iopub.status.busy":"2021-06-02T02:47:30.023213Z","iopub.status.idle":"2021-06-02T02:47:30.023724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Checking the distribution of Age along with gender","metadata":{"_uuid":"125d4ef9cf539258318e42b358ced0dd2f281678"}},{"cell_type":"code","source":"b = sns.kdeplot(student['age'], shade=True)\nb.axes.set_title('Ages of students', fontsize = 30)\nb.set_xlabel('Age', fontsize = 20)\nb.set_ylabel('Count', fontsize = 20)\nplt.show()","metadata":{"_uuid":"bed2e9789ea7cf80f7fadc40568d7033aef0273b","execution":{"iopub.status.busy":"2021-06-02T02:47:30.024444Z","iopub.status.idle":"2021-06-02T02:47:30.024807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Histogram might be more useful to compare different ages","metadata":{"_uuid":"ba1fbba5b4717b3c2a3acba3746a242267b76418"}},{"cell_type":"code","source":"b = sns.countplot('age',hue='sex', data=student)\nb.axes.set_title('Number of students in different age groups',fontsize=30)\nb.set_xlabel(\"Age\",fontsize=30)\nb.set_ylabel(\"Count\",fontsize=20)\nplt.show()","metadata":{"_uuid":"dce2ddad930bf44c3cf059d336c643b36542a698","execution":{"iopub.status.busy":"2021-06-02T02:47:30.025507Z","iopub.status.idle":"2021-06-02T02:47:30.02597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The ages seem to be ranging from 15 - 19. The students above that age may not necessarily be outliers but students with year drops. Also the gender distribution is pretty even.","metadata":{"_uuid":"0b1bfdb9ccdfe8230512733ec183e82898650b5a"}},{"cell_type":"markdown","source":"## Does age have anything to do with the final grade?","metadata":{"_uuid":"72d85d5d9d3a02d95083bff490bb9c2a15bc8592"}},{"cell_type":"code","source":"b = sns.boxplot(x='age', y='G3', data=student)\nb.axes.set_title('Age vs Final', fontsize = 30)\nb.set_xlabel('Age', fontsize = 20)\nb.set_ylabel('Final Grade', fontsize = 20)\nplt.show()","metadata":{"_uuid":"7a3c141aeaf39695c5c7c844fd94c1081752eece","execution":{"iopub.status.busy":"2021-06-02T02:47:30.026693Z","iopub.status.idle":"2021-06-02T02:47:30.027107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plotting the distribution rather than statistics would help us better understand the data","metadata":{"_uuid":"47544667cbfa7bad22046db105164e85f13500c6"}},{"cell_type":"code","source":"b = sns.swarmplot(x='age', y='G3',hue='sex', data=student)\nb.axes.set_title('Does age affect final grade?', fontsize = 30)\nb.set_xlabel('Age', fontsize = 20)\nb.set_ylabel('Final Grade', fontsize = 20)\nplt.show()","metadata":{"_uuid":"b0112a1ef31a580bf1f47dbc1b15ce25e2580290","execution":{"iopub.status.busy":"2021-06-02T02:47:30.027697Z","iopub.status.idle":"2021-06-02T02:47:30.028091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We see that age 20 has only 3 data points hence the inconsistency in statistics. Otherwise there seems to be no clear relation of age or gender with final grade","metadata":{"_uuid":"4aea5a2b5bb61a123083766f75c0e0c40519674b"}},{"cell_type":"markdown","source":"## Count of students from urban and rural areas","metadata":{"_uuid":"6450d8f9870158fbfbcef90647ccb0510d2b4296"}},{"cell_type":"code","source":"b = sns.countplot(student['address'])\nb.axes.set_title('Urban and rural students', fontsize = 30)\nb.set_xlabel('Address', fontsize = 20)\nb.set_ylabel('Count', fontsize = 20)\nplt.show()","metadata":{"_uuid":"b38e084d3c80032601fa2e9c217883b61305fae4","execution":{"iopub.status.busy":"2021-06-02T02:47:30.028746Z","iopub.status.idle":"2021-06-02T02:47:30.029072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Most students are from urban ares, but do urban students perform better than rurual students?","metadata":{"_uuid":"e4c1037db0f630ffdf41c057d32527e1028d14eb"}},{"cell_type":"code","source":"# Grade distribution by address\nsns.kdeplot(student.loc[student['address'] == 'U', 'G3'], label='Urban', shade = True)\nsns.kdeplot(student.loc[student['address'] == 'R', 'G3'], label='Rural', shade = True)\nplt.title('Do urban students score higher than rural students?', fontsize = 20)\nplt.xlabel('Grade', fontsize = 20);\nplt.ylabel('Density', fontsize = 20)\nplt.show()","metadata":{"_uuid":"62db3437052a3a1e056860a34b42060594d6f10b","execution":{"iopub.status.busy":"2021-06-02T02:47:30.029703Z","iopub.status.idle":"2021-06-02T02:47:30.030147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The graph shows that on there is not much difference between the scores based on location.","metadata":{"_uuid":"1d56d2b88043127bf34ee0a7b811e26c01991527"}},{"cell_type":"markdown","source":"## Reason to choose this school","metadata":{"_uuid":"aa442bb915ae0d3a8bb4464e2dd6fe42ce85a6f3"}},{"cell_type":"code","source":"b = sns.swarmplot(x='reason', y='G3', data=student)\nb.axes.set_title('Reason vs Final grade', fontsize = 30)\nb.set_xlabel('Reason', fontsize = 20)\nb.set_ylabel('Final Grade', fontsize = 20)\nplt.show()","metadata":{"_uuid":"d5992f2ee3747d78c8ba6486a3fb9df42ec1aaa2","execution":{"iopub.status.busy":"2021-06-02T02:47:30.030705Z","iopub.status.idle":"2021-06-02T02:47:30.031074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Other features\n\nIt might not be wise to analyse every feature so I will find the features most correlated to the final grade and spend more time on them.","metadata":{"_uuid":"06071d021379de14a75b4dc28a38abb4c1dde0a2"}},{"cell_type":"markdown","source":"## Correlation\n\nNext we find the correlation between various features and the final grade.\n \n### Note: This correlation is only between numeric values","metadata":{"_uuid":"54546c92e78ff00bebbf15ba9a783b0cd83d8fa0"}},{"cell_type":"code","source":"student.corr()['G3'].sort_values()","metadata":{"_uuid":"7a0a25a0741993fbdef4872111f406c17671593b","execution":{"iopub.status.busy":"2021-06-02T02:47:30.031712Z","iopub.status.idle":"2021-06-02T02:47:30.03213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Encoding categorical variables\n\nA machine learning model cannot deal with categorical variables (except for some models). Therefore we need to find a way to encode them (represent as numbers) before handing them to the model.\n\n## Label encoding\n\nThis method involves assigning one label for each category\n\n| Occupation    | Label         |\n| ------------- |:-------------:|\n| programmer    | 0             |\n| data scientist| 1             |\n| Engineer      | 2             |\n\n\n\nThe problem with label encoding is that the assignment of integers is random and changes every time we run the function. Also the model might give higher priority to larger labels. Label encoding can be used when we have only 2 unique values.\n\n## One hot encoding\n\nThe problem with label encoding is solved by one hot encoding. It creates a new column for each category and uses only binary values. The downside of one hot encoding is that the number of features can explode if the categorical variables have many categories. To deal with this we can perform PCA (or other dimensionality reduction methods) followed by one hot encoding.\n\n| Occupation    | Occupation_prog| Occupation_ds | Occupation_eng |\n| ------------- |:-------------: |:-------------:|:-------------: |\n| programmer    | 1              | 0             | 0              |\n| data scientist| 0              | 1             | 0              |\n| Engineer      | 0              | 0             | 1              |","metadata":{"_uuid":"ef9f808b4f0659db5207b5c84166f8c804f5e5fc"}},{"cell_type":"markdown","source":"### Example of one hot encoding","metadata":{"_uuid":"5aa5de808a8293b01f9a92f91efe4da315290edc"}},{"cell_type":"code","source":"# Select only categorical variables\ncategory_df = student.select_dtypes(include=['object'])\n\n# One hot encode the variables\ndummy_df = pd.get_dummies(category_df)\n\n# Put the grade back in the dataframe\ndummy_df['G3'] = student['G3']\n\n# Find correlations with grade\ndummy_df.corr()['G3'].sort_values()","metadata":{"_uuid":"86de6cac09612ea9dbaaae6da33311ce076fc654","execution":{"iopub.status.busy":"2021-06-02T02:47:30.032672Z","iopub.status.idle":"2021-06-02T02:47:30.033006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Applying one hot encoding to our data and finding correlation again!\n\n\n### Note: \nAlthough G1 and G2 which are period grades of a student and are highly correlated to the final grade G3, we drop them. It is more difficult to predict G3 without G2 and G1, but such prediction is much more useful because we want to find other factors affect the grade.","metadata":{"_uuid":"59054b499e4dd4d5ada7225adce11c6426c2d2c6"}},{"cell_type":"code","source":"# selecting the most correlated values and dropping the others\nlabels = student['G3']\n\n# drop the school and grade columns\nstudent = student.drop(['school', 'G1', 'G2'], axis='columns')\n    \n# One-Hot Encoding of Categorical Variables\nstudent = pd.get_dummies(student)","metadata":{"_uuid":"bf95a7005cc64ef2ae47ecccabbe568e0f2f1ba0","execution":{"iopub.status.busy":"2021-06-02T02:47:30.033607Z","iopub.status.idle":"2021-06-02T02:47:30.034094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find correlations with the Grade\nmost_correlated = student.corr().abs()['G3'].sort_values(ascending=False)\n\n# Maintain the top 8 most correlation features with Grade\nmost_correlated = most_correlated[:9]\nmost_correlated","metadata":{"_uuid":"1bbb59828ab6c5cce9362843760107d9c15d4abb","execution":{"iopub.status.busy":"2021-06-02T02:47:30.034647Z","iopub.status.idle":"2021-06-02T02:47:30.035109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"student = student.loc[:, most_correlated.index]\nstudent.head()","metadata":{"_uuid":"cee9e309e6eaef71378fbde49c78f092dca94dc2","execution":{"iopub.status.busy":"2021-06-02T02:47:30.035721Z","iopub.status.idle":"2021-06-02T02:47:30.036078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Now we will analyse these variables and then train a model","metadata":{"_uuid":"8250683e083869f851fbcf52b8f44a1136caff4c"}},{"cell_type":"markdown","source":"### Student with less previous failures usually score higher","metadata":{"_uuid":"e8c4d899129ccec73f83f709f8d87356dfaf6c47"}},{"cell_type":"code","source":"b = sns.swarmplot(x=student['failures'],y=student['G3'])\nb.axes.set_title('Students with less failures score higher', fontsize = 30)\nb.set_xlabel('Number of failures', fontsize = 20)\nb.set_ylabel('Final Grade', fontsize = 20)\nplt.show()","metadata":{"_uuid":"bc6bcd1a2cd52385bd7357a7a39f818a0e8d288c","execution":{"iopub.status.busy":"2021-06-02T02:47:30.036673Z","iopub.status.idle":"2021-06-02T02:47:30.037045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"family_ed = student['Fedu'] + student['Medu'] \nb = sns.boxplot(x=family_ed,y=student['G3'])\nb.axes.set_title('Educated families result in higher grades', fontsize = 30)\nb.set_xlabel('Family education (Mother + Father)', fontsize = 20)\nb.set_ylabel('Final Grade', fontsize = 20)\nplt.show()","metadata":{"_uuid":"80e30a471ecb51a8b946bd47cfba394d177a5955","execution":{"iopub.status.busy":"2021-06-02T02:47:30.037665Z","iopub.status.idle":"2021-06-02T02:47:30.038045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There seems to be a slight trend that with the increase in family education the grade moves up (apart from the unusual high value at family_ed = 1 (maybe students whose parents did not get to study have more motivation)\n\n### Note:\n\nI prefer swarm plots over box plots because it is much more useful to see the distribution of data (and also to spot outliers)","metadata":{"_uuid":"e4375c3c0be84918f553e4a9b347de2fe86e6f82"}},{"cell_type":"code","source":"b = sns.swarmplot(x=family_ed,y=student['G3'])\nb.axes.set_title('Educated families result in higher grades', fontsize = 30)\nb.set_xlabel('Family education (Mother + Father)', fontsize = 20)\nb.set_ylabel('Final Grade', fontsize = 20)\nplt.show()","metadata":{"_uuid":"f46754011b590e147aa8afc427e64dd228cf97ea","execution":{"iopub.status.busy":"2021-06-02T02:47:30.038675Z","iopub.status.idle":"2021-06-02T02:47:30.039124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see there are only 2 points in family_ed = 1 hence our conclusion was faulty.","metadata":{"_uuid":"640ecd4f17defa76ff3404eb964c6f01a950d2ad"}},{"cell_type":"markdown","source":"## Higher education\n\nHigher education was a categorical variable with values yes and no. Since we used one hot encoding it has been converted to 2 variables. So we can safely eliminate one of them (since the values are compliments of each other). We will eliminate higher_no, since higher_yes is more intuitive.","metadata":{"_uuid":"b36bb14bbb50617d636c97594e07722e80ef8b23"}},{"cell_type":"code","source":"student = student.drop('higher_no', axis='columns')\nstudent.head()","metadata":{"_uuid":"7e48203c31faef51ff2eeb30192bf4d2761c64d4","execution":{"iopub.status.busy":"2021-06-02T02:47:30.039667Z","iopub.status.idle":"2021-06-02T02:47:30.039989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"b = sns.boxplot(x = student['higher_yes'], y=student['G3'])\nb.axes.set_title('Students who wish to go for higher studies score more', fontsize = 30)\nb.set_xlabel('Higher education (1 = Yes)', fontsize = 20)\nb.set_ylabel('Final Grade', fontsize = 20)\nplt.show()","metadata":{"_uuid":"9b48604bdf4a2719caba3cb00b67ce0a971c24c8","execution":{"iopub.status.busy":"2021-06-02T02:47:30.040703Z","iopub.status.idle":"2021-06-02T02:47:30.041037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Going out with friends","metadata":{"_uuid":"eb477a6dcbf210967b82de982aa53a4d70ff35fc"}},{"cell_type":"code","source":"b = sns.countplot(student['goout'])\nb.axes.set_title('How often do students go out with friends', fontsize = 30)\nb.set_xlabel('Go out', fontsize = 20)\nb.set_ylabel('Count', fontsize = 20)\nplt.show()","metadata":{"_uuid":"60cad7719a09619ac011f56988260ab6dddf0253","execution":{"iopub.status.busy":"2021-06-02T02:47:30.041729Z","iopub.status.idle":"2021-06-02T02:47:30.042067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Most students have an average score when it comes to going out with friends. (normal distribution)","metadata":{"_uuid":"e6061a596cee5d52b78f9c2e3d8366a4b667caf7"}},{"cell_type":"code","source":"b = sns.swarmplot(x=student['goout'],y=student['G3'])\nb.axes.set_title('Students who go out a lot score less', fontsize = 30)\nb.set_xlabel('Going out', fontsize = 20)\nb.set_ylabel('Final Grade', fontsize = 20)\nplt.show()","metadata":{"_uuid":"64f9fef6bdfab3d0a9ed888806d908604ebe976c","execution":{"iopub.status.busy":"2021-06-02T02:47:30.042639Z","iopub.status.idle":"2021-06-02T02:47:30.042964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The graph shows a slight downward trend","metadata":{"_uuid":"0de462441284c8418b04ac6fce8d19c7460c8bc2"}},{"cell_type":"markdown","source":"## Does having a romantic relationship affect grade?\n\nAgain because of one hot encoding we have our variable called romantic_no which is slightly less intuitive but I am going to stick with it. Keep in mind that:\n\n- romantic_no = 1 means NO romantic relationship\n- romantic_no = 0 means romantic relationship","metadata":{"_uuid":"658c85b12a9845131ffbaa36d48e83e44380f478"}},{"cell_type":"code","source":"b = sns.swarmplot(x=student['romantic_no'],y=student['G3'])\nb.axes.set_title('Students with no romantic relationship score higher', fontsize = 30)\nb.set_xlabel('Romantic relationship (1 = None)', fontsize = 20)\nb.set_ylabel('Final Grade', fontsize = 20)\nplt.show()","metadata":{"_uuid":"3a1c8bf596a269c25dbc123fe492c002cc0aee35","execution":{"iopub.status.busy":"2021-06-02T02:47:30.043554Z","iopub.status.idle":"2021-06-02T02:47:30.043942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling\n\n### We can create a model in 3 ways\n\n1. Binary classification\n    - G3 > 10: pass\n    - G3 < 10: fail\n2. 5-level classification based on Erasmus grade conversion system\n    - 16-20: very good\n    - 14-15: good\n    - 12-13: satisfactory\n    - 10-11: sufficient\n    -  0-9 : fail\n3. Regression (Predicting G3)\n\n### We will be using the 3rd type","metadata":{"_uuid":"9721a30e523bf6beb3b5918109608275882783bf"}},{"cell_type":"code","source":"# splitting the data into training and testing data (75% and 25%)\n# we mention the random state to achieve the same split everytime we run the code\nX_train, X_test, y_train, y_test = train_test_split(student, labels, test_size = 0.25, random_state=42)","metadata":{"_uuid":"acbfde56b4630ecc72230d0ba4310ab6e8f5cf80","execution":{"iopub.status.busy":"2021-06-02T02:47:30.044559Z","iopub.status.idle":"2021-06-02T02:47:30.04491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.head()","metadata":{"_uuid":"558d4f3dcd17041b8925d039b7a5d1f488f88131","execution":{"iopub.status.busy":"2021-06-02T02:47:30.045607Z","iopub.status.idle":"2021-06-02T02:47:30.046041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### MAE - Mean Absolute Error\n### RMSE - Root Mean Square Error","metadata":{"_uuid":"2241439a4251187108b804053dfc3479044a6256"}},{"cell_type":"code","source":"# Calculate mae and rmse\ndef evaluate_predictions(predictions, true):\n    mae = np.mean(abs(predictions - true))\n    rmse = np.sqrt(np.mean((predictions - true) ** 2))\n    \n    return mae, rmse","metadata":{"_uuid":"2da83f94954edf37387dca0603509e9a4378816d","execution":{"iopub.status.busy":"2021-06-02T02:47:30.046568Z","iopub.status.idle":"2021-06-02T02:47:30.046904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Naive baseline is the median prediction","metadata":{"_uuid":"9ffc2cd8a2c297b17395b38e5e0d553004df0d8b"}},{"cell_type":"code","source":"# find the median\nmedian_pred = X_train['G3'].median()\n\n# create a list with all values as median\nmedian_preds = [median_pred for _ in range(len(X_test))]\n\n# store the true G3 values for passing into the function\ntrue = X_test['G3']","metadata":{"_uuid":"9dffd7044f920be613583b0cdba983ca1652ddc6","execution":{"iopub.status.busy":"2021-06-02T02:47:30.047592Z","iopub.status.idle":"2021-06-02T02:47:30.047999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display the naive baseline metrics\nmb_mae, mb_rmse = evaluate_predictions(median_preds, true)\nprint('Median Baseline  MAE: {:.4f}'.format(mb_mae))\nprint('Median Baseline RMSE: {:.4f}'.format(mb_rmse))","metadata":{"_uuid":"9a46e89a4a27e4a0ee3a5d093f3aa7aebbaa2cb5","execution":{"iopub.status.busy":"2021-06-02T02:47:30.048589Z","iopub.status.idle":"2021-06-02T02:47:30.04893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate several ml models by training on training set and testing on testing set\ndef evaluate(X_train, X_test, y_train, y_test):\n    # Names of models\n    model_name_list = ['Linear Regression', 'ElasticNet Regression',\n                      'Random Forest', 'Extra Trees', 'SVM',\n                       'Gradient Boosted', 'Baseline']\n    X_train = X_train.drop('G3', axis='columns')\n    X_test = X_test.drop('G3', axis='columns')\n    \n    # Instantiate the models\n    model1 = LinearRegression()\n    model2 = ElasticNet(alpha=1.0, l1_ratio=0.5)\n    model3 = RandomForestRegressor(n_estimators=100)\n    model4 = ExtraTreesRegressor(n_estimators=100)\n    model5 = SVR(kernel='rbf', degree=3, C=1.0, gamma='auto')\n    model6 = GradientBoostingRegressor(n_estimators=50)\n    \n    # Dataframe for results\n    results = pd.DataFrame(columns=['mae', 'rmse'], index = model_name_list)\n    \n    # Train and predict with each model\n    for i, model in enumerate([model1, model2, model3, model4, model5, model6]):\n        model.fit(X_train, y_train)\n        predictions = model.predict(X_test)\n        \n        # Metrics\n        mae = np.mean(abs(predictions - y_test))\n        rmse = np.sqrt(np.mean((predictions - y_test) ** 2))\n        \n        # Insert results into the dataframe\n        model_name = model_name_list[i]\n        results.loc[model_name, :] = [mae, rmse]\n    \n    # Median Value Baseline Metrics\n    baseline = np.median(y_train)\n    baseline_mae = np.mean(abs(baseline - y_test))\n    baseline_rmse = np.sqrt(np.mean((baseline - y_test) ** 2))\n    \n    results.loc['Baseline', :] = [baseline_mae, baseline_rmse]\n    \n    return results","metadata":{"_uuid":"3cffd50d5d84bb2798f1ace645c7d828a6788c39","execution":{"iopub.status.busy":"2021-06-02T02:47:30.049596Z","iopub.status.idle":"2021-06-02T02:47:30.050038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = evaluate(X_train, X_test, y_train, y_test)\nresults","metadata":{"_uuid":"f4eb747781716f58bd10addd6471ae36f172cee8","execution":{"iopub.status.busy":"2021-06-02T02:47:30.050647Z","iopub.status.idle":"2021-06-02T02:47:30.051051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 8))\n\n# Root mean squared error\nax =  plt.subplot(1, 2, 1)\nresults.sort_values('mae', ascending = True).plot.bar(y = 'mae', color = 'b', ax = ax, fontsize=20)\nplt.title('Model Mean Absolute Error', fontsize=20) \nplt.ylabel('MAE', fontsize=20)\n\n# Median absolute percentage error\nax = plt.subplot(1, 2, 2)\nresults.sort_values('rmse', ascending = True).plot.bar(y = 'rmse', color = 'r', ax = ax, fontsize=20)\nplt.title('Model Root Mean Squared Error', fontsize=20) \nplt.ylabel('RMSE',fontsize=20)\n\nplt.show()","metadata":{"_uuid":"a5e1a176a08b7209eb680aeda99026a87b59351c","execution":{"iopub.status.busy":"2021-06-02T02:47:30.051615Z","iopub.status.idle":"2021-06-02T02:47:30.0521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### We see that linear regression is performing the best in both cases","metadata":{"_uuid":"9ed456d647875e439645146697fe2b2eb902deee"}},{"cell_type":"code","source":"","metadata":{"_uuid":"785a284423cbf3efc2b40d18c40e7dd43d96b94e","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":null,"outputs":[]}]}