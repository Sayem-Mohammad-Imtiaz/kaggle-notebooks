{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"# PYTHON DATA SCIENCE TOOLBOX\n\n## USER DEFINED FUNCTION\n\nWhat we need to know about functions:\n\n    docstrings: documentation for functions. Example:\n    for f():\n    \"\"\"This is docstring for documentation of function f\"\"\"\n    tuble: sequence of immutable python objects.\n    cant modify values\n    tuble uses paranthesis like tuble = (1,2,3)\n    unpack tuble into several variables like a,b,c = tuble\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tuplelar farklı değişkenlere aktarılabildiği gibi\n# Aktarılan değişkenlerdende sadece istenilen değişken print edilebilir.\ndef tuble_ex():\n    t=(1,2,3)\n    return t\na,b,c = tuble_ex()\nz,_,_ = tuble_ex()\nprint(a,b,c)\nprint(z)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Scope\n* Global ve Local variable'dan farklı olarak:\n* Python tarafından daha önceden sabit olarak bir göreve atanmış isimler build in scope olarak geçmektedir.\n* Bu isimler bir variable isim olarak tercih edilemez.\n* Python'da kayıtlı scope'ları görmek için:\n      import builtins\n      dir(builtins)    "},{"metadata":{},"cell_type":"markdown","source":"## Nested Function \nFonksiyon içinde fonksiyon olması ile oluşan fonksiyon tipleridir.\n\n*     function inside function.\n*     There is a LEGB rule that is search local scope, enclosing function, global and built in scopes, respectively.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def square():\n    \"\"\" return square of value \"\"\"\n    def add():\n        \"\"\" add two local variable \"\"\"\n        x = 2\n        y = 3\n        z = x + y\n        return z\n    return add()**2\nprint(square())  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## DEFAULT and FLEXIBLE ARGUMENTS\n\n\n    Default argument example:\n    def f(a, b=1):\n\n      \"\"\" b = 1 is default argument\"\"\"\n\n    Flexible argument example:\n    def f(*args):\n\n     \"\"\" *args can be one or more\"\"\"\n\n\n    def f(** kwargs)\n\n     \"\"\" **kwargs is a dictionary\"\"\"\n\nEğer bir fonksiyonda parametreler default olarak bir değere sahip ise\nörnekte görüldüğü gibi b=1, c=2 variableleri default değere sabittir. Bu durumda:\nBu fonksiyon çağrıldığında parametreler verilirken default değere sahip değişkenler için bir inputa gerek yoktur. input verilmediği taktirde default değerler ile işlem yapacaktır.\nprint(f(5)) de f fonksiyonu çağrılmış ve a parametresi 5 olarak verilmiştir. Verilmesi zorunludur çünkü bir default değeri yoktur fakat b ve c parametrelerine bir input verilmemiştir bu durumda python b ve c inputları olmadığı için işlemlere default değerler ile devam eder.\n\nikinci print ifadesine baktığımızda 3 parametre içinde 3 input bulunmaktadır. Bu durumda b ve c parametrelerinin default değerleri override(geçersiz) kılınarak input olarak verilen değerler kaide alınacaktır.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# default arguments\ndef f(a, b = 1, c = 2):\n    y = a + b + c\n    return y\nprint(f(5))\n# what if we want to change default arguments\nprint(f(5,4,3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**args felaxible arguments python tarafından oluşturulmuş bir argümendir.**\nOluşturulan fonksiyonda eğer kaç parametreye ihtiyaç duyulacağı belli değil ise parametre olarak *args verilir. Bu durumda fonksiyon istenilen parametre sayısınca çağrılır.\n\nAynı mantıkla **kwargs flexible Dictionary'de kullanılan bir yapıdır.**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# flexible arguments *args\ndef f(*args):\n    for i in args:\n        print(\"f: \",i)\nf(1)        \nprint(\"\")\nf(1,2,3,4)    #1\\n 2\\n 3\\n 4\\n\nprint(\"\")\n# flexible arguments **kwargs that is dictionary\ndef f(**kwargs):\n    \"\"\" print key and value of dictionary\"\"\"\n    for key, value in kwargs.items():               # If you do not understand this part turn for loop part and look at dictionary in for loop\n        print(key, \" \", value)\nf(country = 'spain', capital = 'madrid', population = 123456)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## LAMBDA FUNCTION \nFaster way of writing function"},{"metadata":{"trusted":true},"cell_type":"code","source":"# user defined function (long way)\ndef square(x):\n    return x**2\nprint(square(4))      #1. uzun yol\n\ndef tot(x,y,z):\n    return x+y+z\nprint(tot(1,2,3))     #2. uzun yol\n\ndef result(sayi1,sayi2,sayi3=3):\n    return sayi1**sayi2+sayi3\nprint(\"result: \",result(2,3)) ## 2**3+3 = 11\n\n\n#lambda function\n#1. ve 2. fonksiyonların lambda ile kısa yoldan yazılışları\n\nsquare = lambda x: x**2     # where x is name of argument\nprint(square(4))\n\ntot = lambda x,y,z: x+y+z   # where x,y,z are names of arguments\nprint(tot(1,2,3))\n\nresult = lambda sayi1,sayi2,sayi3=3: sayi1**sayi2+sayi3\nprint(\"Lambdaresult: \",result(2,3)) ## 2**3+3 = 11\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ANONYMOUS FUNCTİON\n\nLike lambda function but it can take more than one arguments.\n\n    map(func,seq) : applies a function to all the items in a list\n    \nBirinci parametresine fonksiyon ikinci parametresine liste alabilen hafızasında resultları tutup daha sonra bunları döndürebilen yapılardır."},{"metadata":{"trusted":true},"cell_type":"code","source":"number_list = [1,2,3]     \nnumber_list2 = [2,3,4]\ny = map(lambda x:x**2,number_list)      # result=[1,4,9]  list(map(lambda x:x**2,number_list))\nprint(list(y))\n\n## number_list ve numberlist2 listelerinin değerlerinin kareleri alındı\n## liste isimli variable'a list1(y) ve list2(z) art arda eklenerek tek liste elde edildi.\n## iki liste tek zip objesine (iki listenin i'nci indisleri birleştirilerek) dönüştürüldü.\n## zip objesi liste olarak yazdırıldı\ny,z = map(lambda x:x**2,number_list),map(lambda y:y**2,number_list2)    # [1,4,9] , [4,9,16]\ny=list(y)   # y=list\nz=list(z)   # z=list \nyz= zip(y,z)  # yz=((yi,zi),(yi+1,zi+1)...(yn,zn)) ==>object         \nprint(\"yz : \",list(yz))  ## zip object\nliste = y+z\nprint(\"liste: \",liste)  # list= [listy elemanları,listz elemanları]\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ITERATORS\n\n    iterable is an object that can return an iterator\n    iterable: an object with an associated iter() method\n    example: list, strings and dictionaries\n    iterator: produces next value with next() method\n    \n* İteratörler dizileri dictionaryleri ve string yapıdaki objeleri parçalara ayıran ve parçaların kısımlarını return edebilen yapılardır.\n- string dictionary ve diziler aslında birer iterable objedir.\n- örneğin string objesi her biri char(karakter,harf)lerden oluşan iterabledır.\n- diziler herbir stringlerden veya integerlerden oluşan bir iterabledir."},{"metadata":{"trusted":true},"cell_type":"code","source":"name = \"KARAGOZ\"\nindeks_character = iter(name)\nprint(type(indeks_character))  # return str_iterator object\n\nprint(next(indeks_character))   # 0. indeks   K\nprint(next(indeks_character))   # 1. indeks   A\nprint(next(indeks_character))   # 2. indeks   R\nprint(next(indeks_character))   # 3. indeks   A\n\n\nprint(*indeks_character)    # kalan indekslerin tamamı  G O Z\n\nprint(\"\\n\\n\")    # 2 boşluk\n\n# iteration example 2\nname = \"ronaldo\"\nit = iter(name)\nprint(next(it))    # print next iteration\nprint(*it)  \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Zipler dizileri birleştirmek için kullanılır.\n* Birleştirme işlemini yaparken iki diziyide indeksel olarak birleştirir yani 1. dizinin i (sayaç)'nci indeksi ile 2. dizinin i (sayaç)'nci indeksini birleştirir. \n* Birleşme sonucu oluşan varlık bir objedir. Bu obje de liste türüne dönüştürülerek birleştirme tamamlanır.\n \n* un_zip ise aksine birleşmiş olan dizileri ayırmak için kullanılır.\n* Birleştirilmiş dizinin önüne \"*\" karakteri getirelerek unzip yapılacağı söylenir ve bir değişkene aktarılır.\n* Aktarılan bu değişken artık 2 objeyi barındırmaktadır. İlgili obje list türüne dönüştürülerek iki farklı tuple elde edilir.\n* İstenildiği taktirde bu tuplelar list() methodu ile list türünede dönüştürülebilir."},{"metadata":{"trusted":true},"cell_type":"code","source":"# zip example\nlist1 = [1,2,3,4]\nlist2 = [\"a\",\"b\",\"c\",\"d\"]\nz = zip(list1,list2)\nprint(z)\nz_list = list(z)\nprint(z_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"zlist= \",*z_list)\nun_zip = zip(*z_list)\nun_list1,un_list2 = list(un_zip) # unzip returns tuble\nprint(un_list1)  # (1,2,3,4)  type=tupple\nprint(un_list2)  # ('a','b','c','d') type=tupple\nprint(type(un_list2))\nlist1 = list(un_list1)\nlist2 = list(un_list2)\nprint(\"tr: Liste 1'in tipi : {}, Liste 2'nin tipi: {}\"\n     .format(type(list1),type(list2)))\nprint(\"eng: list1's type : {}, list2's type: {}\"\n     .format(type(list1),type(list2)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## LIST COMPREHENSİON\n\n* One of the most important topic of this kernel\n* We use list comprehension for data analysis often.\n* list comprehension: collapse for loops for building lists into a single line\n* Ex: num1 = [1,2,3] and we want to make it num2 = [2,3,4]. This can be done with for loop. However it is unnecessarily long. We can make it one line code that is list comprehension.\n\n* Dizileri döngüler içinde kullanarak yeni diziler elde etmenin yoludur."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Example of list comprehension\n#  num2 kısmını incelersek:\n#  for kısmının sağ tarafı num1 dizisinin içindeki elemanı al ve i değişkenine aktar.\n#  for kısmının sol tarafı ise alınan bu i değişkenini 1 ile topla ve num2 \n#  isimli değişkene aktar.\n#  [i + 1 for i in num1 ]  ==> list comprehension\n#  i +1  ==> list comprehension syntax\n#  for i in num1  ==> for loop syntax\n#  i ==> iterator\n#  num1 => iterable object\nnum1 = [1,2,3]\nnum2 = [i + 1 for i in num1 ]\nprint(num2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Conditionals on iterable\n## 20 adet rastgele sayı oluşturularak num1 listesine atıldı\n## daha sonra tek mi çift mi kontrol edildi\n## tek mi çift mi sonuçları bir yeni listeye eklendi\n## son olarak sayıları tutan num1 ve yeni oluşturulan liste bir zip ile birleştirildi\n## resultlar indeksli olarak print edildi\n\nimport random\nnum1 = [random.randint(1,100) for i in range(0,20)]\n    \nnum2 = [\"Çift\" if i%2==0 else \"Tek\" for i in num1] ## conditionalson iterable\n\nnum12 = list(zip(num1,num2))   ## used zip num1 + num2\n\nfor index,value in enumerate (num12):  ## used enumerate    #ENUMERATE diziyi indekslendirmek için kullanılır.\n    print(index+1,\".random sayi: \",value)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Conditionals on iterable\nnum1 = [5,10,15]\nnum2 = [i**2 if i == 10 else i-5 if i < 7 else i+5 for i in num1]\nprint(num2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Conditionals on iterable  but dataset pokemon import for used\n### Bu resultı alabilmek için pokemon data setininin import edilmesi gerekir.\n\n*  lets return pokemon csv and make one more list comprehension example\n*  lets classify pokemons whether they have high or low speed. Our threshold is average speed.\n*   1THRESHOLUD TÜM pokemonların hızlarının ortalaması\n*  data[\"speed_level\"] (hız seviyesi) adında bir figure nitelik eklendi\n*  tüm pokemonların hızları tek tek kontrol edilerek ortalama hızdan:\n*    2 büyük ise \"high\", küçük ise \"low\" yazdırıldı.\n*  son adımda ilk 10 hız değeri  ve onlara karşılık gelen ortalama değerler gösteriliyor\n* \n* threshold = sum(data.Speed)/len(data.Speed) #  1 tüm hızlar / toplam hız sayısı \n* print(\"threshold\",threshold)  # ortalama hız\n* data[\"speed_level\"] = [\"high\" if i > threshold else \"low\" for i in data.Speed] #2\n* data.loc[:10,[\"speed_level\",\"Speed\"]] # we will learn loc more detailed later\n\n#### RESULT\n* \tspeed_level \tSpeed\n* 0 \tlow \t45\n* 1 \tlow \t60\n* 2 \thigh \t80\n* 3 \thigh \t80\n* 4 \tlow \t65\n* 5 \thigh \t80\n* 6 \thigh \t100\n* 7 \thigh \t100\n* 8 \thigh \t100\n* 9 \tlow \t43\n* 10 \tlow \t58"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# CLEANING DATA\n\n### Bir veri neden cleanıng edilmelidir ? \n-Datalar unclear olabilir: \n- upperlower: Bu tür veriler isimlendirme veya inputlarda yapılan yanlışlıkları temsil eder. Kolon isimleri veya veri isimleri \"aTTack\",\"DEFENSE\" gibi farklı türde formatlarda biçimlenmiş olabilirler.\n- space between words: Aynı şekilde veriler veya kolonların isimlendirilirken boşluk \"space\" ( ) karakteri kullanılması ile oluşan unclear türüdür. Datalar çağrılırken örneğin \"Type 1\" kolonunu çağırmak istediğimizde. Data.Type 1  bize hata verecektir. Bu isimlendirme \"type1\" olarak formatlanmalıdır.\n- Missing data (value): Veriler girilirken kayıp değer olarak \"None\", \" \", \"--\" anlamsız karakterler ile belirtilmiş olabilir. Bu durumda anlamsızlık oluşmaktadır. Bu durumun giderilmesi gerekmektedir. \n- Different language: Adından da anlaşılabileceği gibi dataların anlamsız ifadeler içermesidir. Anlaşılamayan veril bilgi haline dönüştürülemez.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\ndata = pd.read_csv(\"../input/world-happiness/2019.csv\")\ndata2 = pd.read_csv(\"../input/world-happiness/2016.csv\")\ndata.info()\n#  world-happiness isimli dataset import edildi.\n# # DATA:\n# Genel Sıralama\n# Ülke ya da bölge\n# puan\n# gdp\n# sosyal destek\n# sağlıklı yaşam beklentsi\n# yaşam seçimleri yapma özgürlüğü\n# kötü algılar","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()   # default first 5 data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.tail()  # default last 5 data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns   # (column in data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape    ## data count and column count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()   # data information (data hakkında bilgi verir)\n# 156 adet data, indekslemesi 0 ila 155 arası\n# 9 adet kolon\n# float, int ve object(string) 3 farklı object ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EXPLORATORY DATA ANALYSIS (EDA)\n\n    value_counts(): dataların hangi kategoriden kaç adet olduğunu gösterir.\n    outlier: Aykırı Değerler anlamına gelir. Yani bir veri setindeki değerlerden çok fazla veya çok az durumda olan bir değer var ise bu bir outlier'dır.\n    lower quartile - 1.5IQR = outlier\n    upper quartile + 1.5IQR = outlier\n    Örneğin Bir şirketteki 9 çalışanın aldıkları maaşa bakacak olursak:\n    CA = [150, 2000, 2500, 3000, 2600, 2900, 1900, 4000, 96000]\n    CA dizisindeki 150 ve 96000 değerleri outlier'dır. Diğer değerlere göre çok anormal değerler ifade etmektedir.\n    İstatistiksel ve matematiksel açıklanışı\n    upper quartile + 1.5IQR = 96000  => outlier\n    lower uqartile - 1.5IQR = 150    => outlier\n\n    describe() methodu bu durumları otomatik olarak hesaplar.\n----------------------------------------------------------------------------------------------------------------------------------------------------------\n\n    Lets say value at 75% is Q3 and value at 25% is Q1.\n    Outlier are smaller than Q1 - 1.5(Q3-Q1) and bigger than Q3 + 1.5(Q3-Q1). (Q3-Q1) = IQR\n    We will use describe() method. Describe method includes:\n    count: number of entries\n    mean: average of entries\n    std: standart deviation\n    min: minimum entry\n    25%: first quantile\n    50%: median or second quantile\n    75%: third quantile\n    max: maximum entry\n\n\n### what is quartile ?   ( quartile nedir)\n    1,3,5,7,9,22,33,44,55,77,130\n*     #### Bir dizinin Median(ortanca) değerini bulmak için ilk önce dizi sıralanmalıdır!\n   - Median: Ortanca değer diğer ismi ile quartile 50% dir.\n   - Yukarıdaki sayı dizisinin ortanca değeri yani sayı dizisinin tam -ortasında kalan değer: 22\n   - 1 ile median (22) arasındaki değer **lower quartile** Lower quartile -(25% quartile) = 5'dir.\n   - median (22) ile 130 arasındaki değer ise **upper quartile** olarak isimlendirilir. Upper quartile (75% quartile) = 55'dir.\n   \n   - ##### Bir Upper Quartile ile Lower Quartile arasındaki mesafe IQR olarak isimlendirilir.\n   - #### Lower Quartile değerinden daha az değere sahip veriler 1.5IQR olarak isimlendirilir.\n   - ## lower quartile - 1.5IQR = outlier\n   - ## upper quartile + 1.5IQR = outlier\n\n----------------------------------------------------------------------\n\n    1,4,5,6,8,9,11,12,13,14,15,16,17\n * ####   To find the median value of an array, the array must be sorted first!\n\n*     The median is the number that is in middle of the sequence. In this case it would be 11.\n\n*     The lower quartile is the median in between the smallest number and the median i.e. in between 1 and 11, which is 6.\n*     The upper quartile, you find the median between the median and the largest number i.e. between 11 and 17, which will be 14 according to the question above.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"data2.info() #(157 (157 veri 0-156 indeks) satır numaralandırması,13 kolon tuble'ı)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data2.shape    #  157 adet data,veri,sample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" data2.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data2['Region'].value_counts(dropna=False))\n# 157 region verisinde 38'i sub-saharan africa, 9 u southeastern asia vb...","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Mean (ortalama) varken Neden median (ortanca)\n*     Bir şiketin çalışanlarının aldıkları maaş örneğine bakacak olursak:\n*    (200,300,400,500,700, 2500, 4500, 9000, 10000)\n*     Şirkette bir zam söz konusu ise :\n*     patron tarafından personellere maaş yapılacak zam önerisi istiyorum dediğinde.\n*     ortalama değere bakarsak yaklaşık 3000'e denk gelmektedir.\n*     Bu durumda patron şu yargıya varacaktır. zaten personeller yeterince uygun maaş almaktadır. Ya hiç maaş yapılmalı ya da çok az miktarda bir maaş yapılmalı. Fakat alınan maaşları incelediğimizde çok sayıda personel 3000 den az maaş almaktadır. Bu durumda olumsuz etkilenen taraf çok fazladır.\n*     Ortanca değere bakarsak 700 değerini elde ederiz bu durumda zam anlayışı ve yargısı çok daha farklı olacaktır. (olumlu yönde)\n*     Yani bazı durumlarda mean median faktörleri önemli rol oynamaktadır.*\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"data2.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visual Exploratory Data Analysis (Datayı görsel analiz etme)\n\n* Box plots: visualize basic statistics like outliers, min/max or quantiles\n- outliers, min/max ve quantiles'ları plot etmek için kullanılır.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Happiness Score niteliğinin ortalama değerini bulduk\n# Yeni Bir kolon oluşturarak bu değerlerden küçük olanları false\n# Büyük olanları True yapacağız\n# Aşağıdaki iki yöntemlede bu sonuca ulaşabildik.\n#print(\"Mean: \",data2[\"Happiness Score\"].mean())\n#print (\"Mean: \",sum(data2[\"Happiness Score\"]) / len(data2[\"Happiness Rank\"]))\nmean= data2[\"Happiness Score\"].mean()\ndata2[\"isHappy\"] = [True if i>mean else False for i in  data2[\"Happiness Score\"]]\nsonuc1 = data2.loc[0:4,[\"Happiness Score\",\"isHappy\"]]   ## ilk 5 veri\nsonuc2 = data2.loc[len(data2[\"Happiness Score\"])-5:len(data2[\"Happiness Score\"]),[\"Happiness Score\",\"isHappy\"]] # son 5 veri\nprint(sonuc1)   ## İlk 5 veri için Happiness Score ve isHappy\nprint(sonuc2)   ## son 5 veri için Happiness Score ve isHappy\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data2.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\ndata2.boxplot(column='Health (Life Expectancy)',by = 'isHappy')\nplt.show()\n\n# yuvarlak daire ile gösterilen True kısmında bir tane outlier olduğu görülmekte.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Tidy Data\n- melt() methodu pandas kütüphanesinin bir methodudur."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Firstly I create new data from pokemons data to explain melt nore easily.\ndata_new = data2.head()    # I only take 5 rows into new data\ndata_new","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### melt etmek nedir ? \n- Datanın değerleri sabit kalacak şekilde farklı bir yapıya büründürülmesi işlemidir.\n- frame: Hangi datalar için işlem yapılacak.\n- id_vars: Sabit Kalacak kolon(nitelik).\n- value_vars: Yapılandırılacak kolonlar(nitelikler)."},{"metadata":{"trusted":true},"cell_type":"code","source":"data2.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ex1\n\n# lets melt\n# id_vars = what we do not wish to melt\n# value_vars = what we want to melt\n# Melt işleminden sonra \"Name\" niteliği yine sabit kalacak\n# Yeni oluşması istenilen variablelar ise value_vars içinde belirtilen nitelikler.\n# yeni oluşan variable ve value kolonları melt methodunun atadığı kolonlardır.\n# Aşağıda yaptığımız işlem Country kolonu sabit kalacak şekilde, Happiness Rank\n# ve isHappy kolonlarını bir arada gösterme (yapılandırma) işlemidir.\n# beklediğimiz sonuç Her bir data_new değişkeninde yani ilk 5 veri için:\n## data_new uzunluğu kadar:\n# Country kolonunun i'nci (i=sırası il 0,1... veri) , Happiness Rank kolon ismi, Happiness Rank i'nci değer\n## data_new uzunluğu kadar:\n# Country kolonunun i'nci (i=sırası il 0,1... veri) , isHappy kolon ismi , isHappy kolonundaki i'nci veri\n# end\n# Amaç yukarıdaki ikiliyi elde etmektir.\n\n\nmelted = pd.melt(frame=data_new,  id_vars = 'Country', value_vars= ['Happiness Rank','isHappy'])\nmelted\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ex 2\n\n#Amaç: Son 10 veri için:\n# Region kolonu sabit kalacak şekilde fredom,generosity,isHappy kolonlarını yapılandırmak\n\n#data_endten = data2.tail(10)  # Son 10 veriyi data_endten dataframe'sine aktardık.\n#melted_fgs = pd.melt(frame=data_endten,id_vars='Region',value_vars=['Freedom','Generosity','isHappy'])\n\n# yukarıda gerekli paramereleri verdik ve çıkacak sonucu melted_fgs frame'sine aktardık\n# ilk 10 veri için Region - Hangi variable olduğunu belirten kolon ismi (Freedom) - indise ait veri\n#ilk 10 veri için Region - Hangi variable olduğunu belirten kolon ismi (Generosity) - indise ait veri\n#ilk 10 veri için Region - Hangi variable olduğunu belirten kolon ismi (isHappy) - indise ait veri\n# Beklenen frame sonucu 30 sample'dan (0-29) oluşacak.\n#melted_fgs\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pivoting Data\n- Reverse of melting.\n- Yapılan melt işleminin geri alınması için kullanılır."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Index is country\n# I want to make that columns are variable\n# Finally values in columns are value\n# ilk yaptığımız (ex1) örnekteki melt işlemini geri almak için kullanacağımız,\n# sabit değer yani indeksimiz \"Country\"dir. Eski haline dönmesini istediğimiz kolonun\n# yani 'variable' isim kolon  ve eski haline dönmesini isteiğimiz değerlerin yer aldığı\n# kolon olon value'i de input olarak values parametresine verdiğimiz eski haline döner.\n\n# ex1 için geri dönüştürme\n# melted=melt'i atadığımız frame, index sabit kalan kolon, columns dönüşüm sonucu oluşan kolon\n# values= kolonların değerlerini barındıran kolon ismi\nmelted.pivot(index = 'Country', columns = 'variable',values='value')\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## CONCATENATING DATA\n- We can concatenate two dataframe\n- İki dataframe birleştirmek için kullanılır\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"data3 = pd.read_csv(\"../input/world-happiness/2015.csv\") # new data 2015 not 2018,2019\ndata3.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#Dikey Birleştirme\n\ndata1=data3.head() #ilk 5 data\ndata2=data3.tail() #son 5 data\n# ignore_index = yeni index formatı\nconc_data_row = pd.concat([data1,data2],axis=0,ignore_index=True)\nconc_data_row","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Yatay Birleştirme\ndf1 = data3['Country'].head() # Country kayıtlarındaki ilk 5 kayıt (first 5 sample)\ndf2 = data3['Region'].head()  # Region kayıtlarındaki ilk 5 kayıt  (last 5 sample)\ndf3 = data3['Family'].head() # isHappy kayıtlarının ilk 5'i\ndf4 =  data3['Happiness Rank'].head()\nconc_data_col = pd.concat([df1,df2,df2,df4],axis=1) #axis 1 = horizontal adds dataframes in column\nconc_data_col","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Types and type convert\n* There are 5 basic data types: object(string),boolean, integer, float and categorical.\n* We can make conversion data types like from str to categorical or from int to float\n* Why is category important:\n\n    - make dataframe smaller in memory\n    - can be utilized for anlysis especially for sklearn(we will learn later)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"data3.dtypes ## Datamızdaki kolonlarını türlerini görüntüledik","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets convert object(str) to categorical and int to float.\n# object(str) tipindeki dataları categorical,integer ve float tipine dönüştürme\n# astype() methodu tip değişimi için kullanılan methoddur.\n# Country stringden category tipine dönüştürüldü.\n# Happiness Rank int tipinden float tipine dönüştürüldü\ndata3['Country'] = data3['Country'].astype('category') # result Country is not string, is category\ndata3['Happiness Rank'] = data3['Happiness Rank'].astype('float')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data3.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Missing Data and Testing With Assert\n\n###### If we encounter with missing data, what we can do:\n\n*     leave as is\n*     drop them with dropna()\n*     fill missing value with fillna()\n*     fill missing values with test statistics like mean\n*     Assert statement: check that you can turn on or turn off when you are done with your testing of the program\n\n* Missing Data: Daha önceden tanımlanmamış, değeri olmayan kayıtlardır.\n- Veri setinde bu tür veriler \" NaN\" olarak \"boş\" anlamında bırakılmış olabilir.\n\n\n#### Bu durumlarda anlaşılması zor olan konu ilgili kolonun gerçekten bu datası yok mu, yoksa unutuldu veya es geçildi tarzında yapılan yanlışlıklardan dolayı mı NoN değerini aldı?\n\n#### Bu durumlarda başa çıkma yöntemleri:\n- Öylece bırakılabilir. Belkide gerçekten ilgili niteliğe sahip değildir.\n- Missing Value'ler yani bu tür veriler dataset içerisinden çıkarılabilir.\n- Boş bırakılan yerleri NoN ile doldurabiliriz bazı durumlarda değerin olmadığını göstermek için veya yanlış girişlerden kaynaklı olarak anlamsız ifadeler (\"-\",\"?,\"--\") yer alıyor olabilir. Tek tür NaN olmalıdır\n- Missing Valuenin ait olduğu kolon sayısal değerlere sahip ise ilgili kolonun \"mean\" ya da \"median\" değeri ile doldurulabilir.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"data3.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## FAKAT NULL değerleri nasıl değiştireceğimizi görmek amacıyla ben Null değere sahip kolon oluşturdum.\n## Ekonomi değerleri 0.1 den küçük olan sample'ları NaN yaptım diğerlerini ise iyi.\n## Bu değişiklikleri ise Deneme adında bir kolona kaydettim.\ndata3['Deneme'] = [\"empty\" if i<0.1 else \"iyi\" for i in data3[\"Economy (GDP per Capita)\"]]  # önce burayı calıstır\n#data3[\"Deneme\"].fillna('empty',inplace = True)\n\ndata3['Deneme'].value_counts(dropna=False)  \n# dropna=false ile eğer Country kolonunda NAN Value(Null,Nan..) değer var ise onu da göster dedik.\n# Çıkan sonuca göre null değer bulunmamaktadır.\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#data3['Deneme'].value_counts(dropna=False)\n## çıkan sonuçtata NaN, NULL türünda sample olduğu görülmektedir.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## NaN türünde samplelar datamızda nasıl düzeltiriz ?\nd1 = data3   ## data3, d1'e kopyalandı. \"gerçek projelerde önerilmeyen kopyalama olayıdır.\"\n## DROPNA yani Null(NaN) olan değerleri çıkar ve o şekilde kaydet\nd1[\"Deneme\"].dropna(inplace=True)\nd1[\"Deneme\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#assert 1==2  # Hata Vermesi gerekir Assert Kontrolü","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Assert özellği ile bir olayın doğruluğu tespit edilebilir.\n#  Lets check with assert statement\n# Assert statement:\nassert 1==1 # return nothing because it is true ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Yukarıda null değere ait sampleları datasetten çıkarmadan önce\n# d1'e aktarmıştık\n# Nan değerlerin gerçekten silinip silinmediğini kontrol etmek için:\n# assert kullanalım.\n# assert d1 == data3 # Eğer bu sonuç False yani Error veriyor ise silme işlemi\n# başarılıdır. Sonuç olarak d1 artık data3 e eşit değildir. Aksi yaşanıyorsa d3 ile d1 aynıdır yani null değerler haala mevcuttur.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Veya diğer bir assert kontrol yöntemi ise\nassert d1['Deneme'].notnull().all() # returns nothing because we drop nan values\n## bu işlemden programrama şunu sorduk d1[Deneme] samplelarının hepsi null değil değilmi\n## Diğer bir deyişle:\n## Deneme kolonundaki hiçbir kayıt null değerine sahip değil, kontrol et.\n## söylediğimiz komut True dönüşe sahip olduğu için herhangi bir error almıyoruz.\n## bu şekildede teyit etmiş oluyoruz.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d1[\"Deneme\"].fillna('empty',inplace = True)## burada yaptığımız işlem\n## Deneme kolonunu \"empty\" ile doldurmak","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert  d1['Deneme'].notnull().all() # returns nothing because we do not have nan values\n# tekrar aynı kullanımı sorgulama emrini verdiğimizde bu sefer bize hata döndürecektir.\n# Çünkü null değerler(empty) ile dolu bir d1 kolonu bulunmaktadır.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" ## ASSERT KULLANIM ÖRNEĞİ--ASSERT EXAMPLE\n \nd1.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#assert d1.columns[0] == \"COUNTRY\"  ## data kolonlarının 1.si(0.indis)\"COUNTRY\" dir. Dedik\n                                    ## Bu durumda bize dönecek cevap hatadır.\n# Çünküd datamızın 1. kolonu \"Country\" dir.\n\nassert d1.columns[0] == \"Country\"  # Hata dönmeyecektir doğru bir ifadedir.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np ## numpy import ettik. \n#assert d1.Freedom.dtypes == np.float64 ## freedom dataları float dedik. Doğru bir ifadedir hata almadk.\n#assert d1.Generosity.dtypes ==np.int # yanlış bir ifadedir hata aldık. FALSE ERROR\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  -Pandas Foundation\n\nAs you notice, I do not give all idea in a same time. Although, we learn some basics of pandas, we will go deeper in pandas.\n\n    single column = series\n    NaN = not a number\n    dataframe.values = numpy"},{"metadata":{},"cell_type":"markdown","source":"## BUILDING DATA FRAMES FROM SCRATCH\nAlso we can build dataframe from dictionaries\n\n    -zip() method: This function returns a list of tuples, where the i-th tuple contains the i-th element from each of the argument sequences or iterable\nAdding new column\nBroadcasting: Create new column and assign a value to entire column\n\n- DataFramelerin \"Dictionary\" lerden nasıl build edildiğini göreceğiz.\n- Broadcasitng = DataFrame yeni bir kolon ekleyip ona yeni değerler atama işlemidir."},{"metadata":{"trusted":true},"cell_type":"code","source":"# data frames from dictionary\ncountry = [\"Spain\",\"France\"]  #liste1\npopulation = [\"11\",\"12\"]      #liste2  \nlist_label = [\"country\",\"population\"] #iki listeye etiket verildi\nlist_col = [country,population]       #country ve population listeleri kolon oluşturmak üzere bir listeye aktarıldı.\nzipped = list(zip(list_label,list_col)) #etiketler ve kolonlar ziple birleştirildi\ndata_dict = dict(zipped)  #zip file dictionary'e çevrildi\ndf = pd.DataFrame(data_dict)  #dataframe kullanarak dictionary frame'de gösterildi\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add new columns\ndf[\"capital\"] = [\"madrid\",\"paris\"] #df içerisine \"capital\" adında bir kolon oluşturuldu ve değerleri verildi.\ndf\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Broadcasting Example\ndf[\"income\"] = 0 #Broadcasting entire column\n                 #Gelir adında bir kolon oluşturuldu ve bütün değerleri 0 yapıldı\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## VISUAL EXPLORATORY DATA ANALYSIS\n\n    Plot\n    Subplot\n    Histogram:\n        bins: number of bins\n        range(tuble): min and max values of bins\n        normed(boolean): normalize or not\n        cumulative(boolean): compute cumulative distribution\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bu bölümde çalışmak için yeni bir dataset(StudentsPerformance) import ettik.\nimport pandas as pd\ndata = pd.read_csv(\"../input/students-performance-in-exams/StudentsPerformance.csv\")\ndata.info()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1 = data.loc[:,[\"math score\",\"reading score\",\"writing score\"]] #kolonlar data1 e aktarıldı\ndata1.plot() #ilgili kolonlar tek bir plot üzerinde gösterildi. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1.plot(subplots=True) #data1 içerisindeki tüm kolonlarları ayrı subplotlarda gösterdik\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#math score ve writing score arasındaki ilişikiyi (corelation) \n#görmek için scatter plot kullandık\n\ndata1.plot(kind=\"scatter\",x=\"math score\",y=\"writing score\")\nplt.show()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# normed = datanın normalize (0-1) edilmiş halidir. \n# range = 0 ile 250 arasında \"y\" eksen değerleri verilmiştir. \ndata1.plot(kind=\"hist\", y=\"reading score\", bins=50, range =(0,250), normed=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#cumulative ile olasılıklar toplana toplana gider. Artan bir şekilde giden değerlerdir.\nfig, axes = plt.subplots(nrows=2,ncols=1)\ndata1.plot(kind = \"hist\",y = \"reading score\",bins = 50,range= (0,250),normed = True,ax = axes[0])\ndata1.plot(kind = \"hist\",y = \"reading score\",bins = 50,range= (0,250),normed = True,ax = axes[1],cumulative = True)\nplt\n#birinci grafikte normal değer karşılıkları yer alırken\n#iknci grafikte değerlerin kümülatif bir şekilde (artarak) gösterildiği görülmektedir.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## INDEXING PANDAS TIME SERIES (Zamana Bağlı İndeksleme)\n\n    datetime = object\n    parse_dates(boolean): Transform date to ISO 8601 (yyyy-mm-dd hh:mm:ss ) format\n\n- data içerisinde yer alan indeksler time series şeklinde oluşmaktadır.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":" #str formatını uygun olduğu taktirde datetime formatına çevirir.\n # pd.to_datetime() fonksiyonu ile bu işlem gerçekleştirilir\n # parametre olarak string tarih tipi verilmelidir\n\ntime_list = [\"1992-03-08\",\"1992-04-12\"]  # str type\nprint(type(time_list[1])) # As you can see date is string   \n# however we want it to be datetime object\ndatetime_object = pd.to_datetime(time_list) \nprint(type(datetime_object))   #datetimeindex type","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data2 = data.head()  # veri setindeki ilk 5 veri data2 e aktarıldı\ndata2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#--------------------Hata önlendi---------------------------\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n#-------------------ES GEÇ----------------------------------\n# Kullandığımız veri setinde (data object) time series bulunmamaktadır.\n# datetimeIndex örneklerini yapabilmek amacı ile veri setimize datetype ekleyeceğiz.\n# ilk 5 veri için datetime oluşturarak ekleyelim.\n\n\ndate_list = [\"1992-01-10\",\"1992-02-10\",\"1992-03-10\",\"1993-03-15\",\"1993-03-16\"] # 5 string listesi\ndatetime_object = pd.to_datetime(date_list) #datetime objesi oluştu\ndata2[\"date\"] = datetime_object #ilk 5 sample için date kolonu oluşturuldu ve datetime lar atandı.\ndata2 = data2.set_index(\"date\") #  indekslemesi 0,1,..  iken \"date\" biçiminde derleyerek indekslemenin date tipinde olmasını sağladık\ndata2   #indeksleme artık date göre yapılacak\n\n# Bu şekilde type series data (zamana bağlı data) elde etmiş olduk.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Zaman Bağlı Datalar ile neler yapabiliriz ?\n# Now we can select according to our date index\n# loc ile belirli indeksteki veri çekilebilir.\n\n#print(data2.loc[\"1993-03-16\"]) # ilgili datadaki bilgiler\nprint(data2.loc[\"1992-03-10\":\"1993-03-16\"]) # iki ay arasındaki data bilgileri\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## RESAMPLING PANDAS TIME SERIES\n\n    Resampling: statistical method over different time intervals\n        Needs string to specify frequency like \"M\" = month or \"A\" = year\n    Downsampling: reduce date time rows to slower frequency like from daily to weekly\n    Upsampling: increase date time rows to faster frequency like from daily to hourly\n    Interpolate: Interpolate values according to different methods like ‘linear’, ‘time’ or index’\n        https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.interpolate.html\n\n    - Bir data içerisinden elde ettiğimiz yeni sample lar \"Resampling\" olarak adlandırılır.\n    - 'M 'harfi kullanarak tüm aylar veya 'A' harfi kullanarak tüm yıllar resampling edilebilir\n    - ilgili ay veya yıllar arasında kalan tüm herhangi bir \"nitelik\"(kolon) filtre edilebilir.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"data2.resample(\"A\").mean()  #data2 (ilk 5 kayıt)  yıla göre resampling edildi\n# iki farklı tür resampling edildi ve mean() ile ilgili yıllar arasındaki \n# sampleların (kayıtların) ortalaması alındı\n# Beklenen sonuçlar : 1992 yılındaki kayıtların \"math score\",\"reading score\",\"writing score\"\n# kolonlarında yer alan değerlerin ortalamaları\n# Aynı şekilde 1993 yılında yer alan kayıtların iligili kolon ortalamaları\n# işlemler tipi sayısal olarak kolonlara yapılabilir. Diğer kolonlar,\n# object tipinde olduğu için resamplig edilmez.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets resample with month\n# Çalışma mantığı en erken yıl ile en geç yıl arasını aylara göre resample eder.\ndata2.resample(\"M\").mean()\n# As you can see there are a lot of nan because data2 does not include all months\n#Aylara göre resampling işlemi yapmaya kalktığında (toplam 12 ay) herhangi bir ayda\n#data bulunmuyor ise mean işlemide yapılamayacağın için Null değer (NaN) resampling edilir.\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## NAN Değerler Nasıl Doldurulabilir ???"},{"metadata":{"trusted":true},"cell_type":"code","source":"# In real life (data is real. Not created from us like data2) we can solve this problem with interpolate\n# We can interpolete from first value\n\n#first().interpolate(\"linear\") ile nümeric olan değerler linear bir şekilde interpolate edilir.\ndata2.resample(\"M\").first().interpolate(\"linear\")\n\n# sonuç olarak sayısal değer alan kolonlar linear(doğrusal artan) bir şekilde dolduruldu\n\n# 1992-04-30 ile 1993-02-28 arası sayısal kolonlar linear olarak interpolate edildi artık NaN değil.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data2.resample(\"M\").mean().interpolate(\"linear\")\n# burada meanlerden yararlanılarak artan(linear) bir şekilde interpolate edildi","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# - MANIPULATING DATA FRAMES WITH PANDAS"},{"metadata":{},"cell_type":"markdown","source":"## INDEXING DATA FRAMES\n\n    Indexing using square brackets\n    Using column attribute and row label\n    Using loc accessor\n    Selecting only some columns\n\n"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"# Bu bölümde kullanmak üzere pokemon dataset'ini import ettik.\nimport pandas as pd\ndata = pd.read_csv(\"../input/pokemon-challenge/pokemon.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# read data\ndata = pd.read_csv(\"../input/pokemon-challenge/pokemon.csv\")\ndata= data.set_index(\"#\") # feature (yeni bir indeks tanımlandık artık 0,1.. diye gitmiyor)\ndata.head()               # 1'den başlıyor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# indexing using square brackets\ndata[\"HP\"][1]  # indeksi 1 olan datanın \"HP\" (kolon)feature'sini göster\n# Eğer indeksleme türünü (\"#\") olarak set etmeseydik. \n# Aynı result'ı alabilmek için data[\"HP\"][0] yapmalı idik.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Farklı bir şekilde erişim olarak:\ndata.HP[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Selecting only some columns\n# Loc ile ayrıntılı aynı lokasyona erişim.\ndata.loc[1,[\"HP\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Hp ve Attack seçilerek indeksli olarak yazdırır.\ndata[[\"HP\",\"Attack\"]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### SLICING DATA FRAME\n    Aralık Seçme imkanı verir.\n    Difference between selecting columns\n        Series and data frames\n    Slicing and indexing series\n    Reverse slicing\n    From something to end\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Difference between selecting columns: series and dataframes\n# Series ve Data Frames arasındaki fark\nprint(type(data[\"HP\"]))     # series\nprint(type(data[[\"HP\"]]))   # data frames","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Slicing and indexing series\ndata.loc[1:10,\"HP\":\"Defense\"]   # 10 and \"Defense\" are inclusive\n# 1 ve 10 arası samplelarda HP ve Defense arası resultları göster","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reverse slicing \n# Aynı işlem 10'dan 1'e kadar \ndata.loc[10:1:-1,\"HP\":\"Defense\"] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# From something to end\n# 1 ile 10 arasındaki kayıtlar için \"Spped\" featuredan başlayıp sona kadar bütün featureleri getir\ndata.loc[1:10,\"Speed\":] \n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### FILTERING DATA FRAMES\n\nCreating boolean series Combining filters Filtering column based others"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating boolean series\nboolean = data.HP > 200   # canı 200'den büyükleri gösteren bir filtre oluşturduk\ndata[boolean]             # filtreyi data içerisine gömerek istenen resulta eriştik\n#diğer bir kullanım:\n\n#data[data.HP > 200]\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Combining filters,\n# Çoklu Filtre Kullanımı\nfirst_filter = data.HP > 150    # Canı 150'den büyük pokemonlar\nsecond_filter = data.Speed > 35 # Hızı 35'den büyük pokemonlar\n# Result = Canı 154'den büyük ve Hızı 35'den büyük pokemonlar \ndata[first_filter & second_filter]  #(İki filtrenin kesişimini verir)\n# data[data.HP>150 & data.Speed>35]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filtering column based others\n# İstenin Kolonu Filtreleme İşlemi\ndata.HP[data.Speed<15] # Hızın 15'den küçük olduğu pokemonları bul ama Canlarını göster","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### TRANSFORMING DATA \n- Fonksiyonların datalara uygulanışı\n\n    Plain python functions\n    Lambda function: to apply arbitrary python function to every element\n    Defining column using other columns\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plain python functions\ndef div(n):\n    return n/2\n# div fonksiyonuna n parametresi gelsin ve bu n 2'e bölünerek return etsin.\n# data.Hp e div fonksiyonu uygulanarak Can(HP) parametre olarak verilmiş olur\ndata.HP.apply(div)\n# RESULT  \n# 1 45/2 = 22.5\n# 2 60/2 = 30.0\n# 3 80/2 = 40.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Or we can use lambda function\n# Aynı işlemi lambda fonksiyonu ile yapılışı\ndata.HP.apply(lambda n : n/2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Yeni bir kolon eklemek istediğimizde\n# Defining column using other columns\n# total_power kolonunu,  \"attack\" ve \"defense\" featurelerının değerlerinin toplamı olarak tanımladık\ndata[\"total_power\"] = data.Attack + data.Defense\ndata.head()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### INDEX OBJECTS AND LABELED DATA\n- İndex ile neler yapabiliriz ?\n- index: sequence of label\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n# our index name is this:\nprint(data.index.name) # indeksimizin ismi nedir ? = \"#\"\n# lets change it\ndata.index.name = \"index_name\" # indeksimizin adını değiştirdik = \"index_name\"\ndata.head()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#datanın indeksini nasıl değiştiririz ? \n\n# Overwrite index\n# if we want to modify index we need to change all of them.\ndata.head()\n# first copy of our data to data3 then change index \ndata3 = data.copy() # datamızı data3 e aktardık\n# lets make index start from 100. It is not remarkable change but it is just example\ndata3.index = range(100,900,1) # datalarımız 100'den 900'e kadar 1 er 1 er artsın.\ndata3.head()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n# We can make one of the column as index. I actually did it at the beginning of manipulating data frames with pandas section\n# It was like this\n# data= data.set_index(\"#\") # datamızı \" #\" olarak değiştirdik\n# also you can use \n# data.index = data[\"#\"] #Datamızın indeksini Datamızın \"#\" isimli feature(kolon) sine eşit olsun\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\n\n### HIERARCHICAL INDEXING\n\n    - İndeksler arasında hiyerarşi kurma\n    Setting indexing\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets read data frame one more time to start from beginning\n# Datanın bozulma ihtimaline karşı tekrar import ettik\ndata = pd.read_csv(\"../input/pokemon-challenge/pokemon.csv\")\ndata.head()\n# As you can see there is index. However we want to set one or more column to be index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setting index : type 1 is outer type 2 is inner index\n# Hiyerarşik bir indeks tanımladık.\n# İlk yazdığımız \"TYPE1\" ilk indeks ikinci yazdığımız \"TYPE2\"  ikinci indekstir.\ndata1 = data.set_index([\"Type 1\",\"Type 2\"])  # hiyerarşik indeksleme\ndata1.head(100)\n# data1.loc[\"Fire\",\"Flying\"] # howw to use indexes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### PIVOTING DATA FRAMES\n\n    pivoting: reshape tool\n    \n    - value ile feature'ın yer değiştirmesi olayıdır.\n    - Pokemon Data Set'inden örnek verecek olursak:\n        - Name isimli featuresi ile onun valuesi olan \"Poison\" yer değişir.\n        - Aynı Şekil Legandary featuresi ile onun valuesi olan \"False\" yer değişir.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Yeni Bir DataFrame tanımladık.\n# Treatment:tedavi , Gender:Cinsiyet, Response:Tedaviye cevap verme oranı, Age:Yaş\ndic = {\"treatment\":[\"A\",\"A\",\"B\",\"B\"],\"gender\":[\"F\",\"M\",\"F\",\"M\"],\"response\":[10,45,5,9],\"age\":[15,4,72,65]}\ndf = pd.DataFrame(dic)\ndf\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pivoting\n# indeks treatment ve gender olacak şekilde sadece response değerlerini istiyoruz.\n# Feature olarak ise gender istiyoruz.\n# index=\"İndeksleme neyden oluşsun ?\"\n# columns= \"Hangi featureleri istiyoruz ?\"\n# values = \"Featurelere denk gelen valueler hangi kolon değerlerinden pivot edilsin ?\"\ndf.pivot(index=\"treatment\",columns = \"gender\",values=\"response\") #Pivot işlemi","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### STACKING and UNSTACKING DATAFRAME\n    unstacking : Birden fazla indeksli dataframelerin unstack (indekslerden birini devredışı bırakma işlemi) yapar\n    deal with multi label indexes\n    level: position of unstacked index\n    swaplevel: change inner and outer level index position\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = df.set_index([\"treatment\",\"gender\"]) #ilk önce tedaviye göre sonra cinsiyete göre indeksleme yaptırdık\ndf1\n# lets unstack it\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#yukarıdaki örnekte A ve F,M indeks olarak görülmektedir. Bunları teke düşürmek için unstack yapılır\n# level determines indexes\ndf1.unstack(level=0) #0'ı 0. yani 1. sıradaki kolonu unstack yapmasını sağladık\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bu sefer 1.indeksi yani 2. sıradaki indeksi unstack yapmasını sağladık\ndf1.unstack(level=1)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# change inner and outer level index position\n# indeksleme önceliğini swaplevel ile değiştirebiliriz\ndf2 = df1.swaplevel(0,1) # indekslerin yeri değişti\ndf2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### MELTING DATA FRAMES\n\n    Reverse of pivoting\n    Pivotun tam tersi işlem yapar\n    \n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# indeks olarak treatment sabit kalsın fakat valueler age ve response featurelerınden oluşsun\n# df.pivot(index=\"treatment\",columns = \"gender\",values=\"response\")\n# Yaptığımız pivotlama işleminin tam tersini melt ile yaptık\npd.melt(df,id_vars=\"treatment\",value_vars=[\"age\",\"response\"]) # age ve responseleri value olarak kullandık\n# age ve response featurelerinin değerlerini ise value kolonunda istedik\n# variable ve value kolonarını otomatik yapılır","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### CATEGORICALS AND GROUPBY"},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will use df\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#treatment feature'sine göre grupla ve kalan featurelerin ortalama (mean) değerlerini göster\n# according to treatment take means of other features\ndf.groupby(\"treatment\").mean()   # mean is aggregation / reduction method\n# there are other methods like sum, std,max or min\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we can only choose one of the feature\n# df.groupby(\"treatment\").age.max()    # type=series  \n# df.groupby(\"treatment\")[\"age\"].max() # type=series\n# Yukarıdaki iki kullanımda aynı sonucu verir result series tipindedir.\n\n# Aşağıdaki çevrim frame tipinde result verir.\ndf.groupby(\"treatment\")[[\"age\"]].max() # treatment'a göre grupla ve maksimum yaşlarını value olarak ver   type=dataframe\n\n# 3 kullanmdada aynı valuelere ulaşılır fakat tipleri farklıdır.\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# treatmen'a göre grupla daha sonra age ve response featurelerinin minimum valuelerini result et\n# Or we can choose multiple features\ndf.groupby(\"treatment\")[[\"age\",\"response\"]].min() \n# Result olarak:\n    # iki farklı treatment vardır A ve B\n    # ilk önce A featuresine ait age değerlerinden minimumu\n    # Daha sonra A feturesine ait response değerlerinden minimumu\n    # Daha sonra B featuresne ait age ve response kolonlarındaki minimum değerler result edilir.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info() # dataframe bilgilerini verir.\n# Featurelerin typeları, null içerip içermedikleri ve sample countları yer alır.\n# as you can see gender is object\n# However if we use groupby, we can convert it categorical data. \n# Because categorical data uses less memory, speed up operations like groupby\n# Data Frame ait featurelerin typelarını astype() ile değiştirilebilir.\n#df[\"gender\"] = df[\"gender\"].astype(\"category\")\n#df[\"treatment\"] = df[\"treatment\"].astype(\"category\")\n#df.info()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}