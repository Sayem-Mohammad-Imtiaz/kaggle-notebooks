{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Prediction of Customer Churn"},{"metadata":{},"cell_type":"markdown","source":"## Important:Instructions mentioned below.\n\n- The Sheet is structured in **4 steps**:\n    1. Understanding data and manipulation\n    2. Data visualization\n    3. Implementing Machine Learning models(Note: It should be more than 1 algorithm)\n    4. Model Evaluation and concluding with the best of the model.[](http://)"},{"metadata":{},"cell_type":"markdown","source":"### Importing the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# use these links to do so:\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom collections import defaultdict\nfrom sklearn import metrics\nfrom pylab import rcParams\n\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Understanding the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nprint(os.listdir('../input/telco-customer-churn'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Manipulation"},{"metadata":{"trusted":true},"cell_type":"code","source":"for item in data.columns:\n    print(item)\n    print (data[item].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(['customerID'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Convert all yes and no to 0's & 1's so our classifier can use this data."},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"gender\"].replace(['Female','Male'],[0,1],inplace=True)\ndata[\"Partner\"].replace(['No', 'Yes'], [0, 1], inplace=True)\ndata[\"Dependents\"].replace(['No', 'Yes'], [0, 1], inplace=True)\ndata[\"PhoneService\"].replace(['No', 'Yes'], [0, 1], inplace=True)\ndata[\"PaperlessBilling\"].replace(['No', 'Yes'], [0, 1], inplace=True)\ndata[\"Churn\"].replace(['No', 'Yes'], [0, 1], inplace=True)\ndata[\"StreamingMovies\"].replace(['No', 'Yes'], [0, 1], inplace=True)\n\ndata[\"InternetService\"].replace(['No','DSL', 'Fiber optic'],[0,1,2],inplace=True)\ndata[\"Contract\"].replace(['Month-to-month','One year', 'Two year'],[0,1,2],inplace=True)\n\ndata = pd.get_dummies(data=data, columns=['PaymentMethod'])\n\ndata[\"MultipleLines\"].replace(['No','Yes'],[0,1],inplace=True)\ndata[\"OnlineSecurity\"].replace(['No','Yes'],[0,1],inplace=True)\ndata[\"OnlineBackup\"].replace(['No','Yes'],[0,1],inplace=True)\ndata[\"DeviceProtection\"].replace(['No','Yes'],[0,1],inplace=True)\ndata[\"TechSupport\"].replace(['No', 'Yes'], [0, 1], inplace=True)\ndata[\"StreamingTV\"].replace(['No', 'Yes'], [0, 1], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns_to_convert = ['MultipleLines', \n                      'OnlineSecurity', \n                      'OnlineBackup', \n                      'DeviceProtection', \n                      'TechSupport',\n                      'StreamingTV',\n                     'StreamingMovies']\n\nfor item in columns_to_convert:\n    data[item].replace(to_replace='No internet service',  value=0, inplace=True)\n    data[item].replace(to_replace='No phone service',  value=0, inplace=True)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We can see TotalCharges is still an object. Fix TotalCharges as a float...\ndata['TotalCharges'] = data['TotalCharges'].replace(r'\\s+', np.nan, regex=True)\ndata['TotalCharges'] = pd.to_numeric(data['TotalCharges'])\n\ndata = data.fillna(value=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby('Churn').size()/len(data) # What is the percentage of churners","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.hist(bins=50, figsize=(20,15));","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"corr = data.corr()\ncorr","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"sns.countplot(data['Churn'],label = 'count')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data to plot\nlabels =data['Churn'].value_counts(sort = True).index\nsizes = data['Churn'].value_counts(sort = True)\n\n\ncolors = [\"whitesmoke\",\"red\"]\nexplode = (0.1,0)  # explode 1st slice\n \nrcParams['figure.figsize'] = 8,8\n# Plot\nplt.pie(sizes, explode=explode, labels=labels, colors=colors,\n        autopct='%1.1f%%', shadow=True, startangle=270,)\n\nplt.title('Percent of churn in customer')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='SeniorCitizen',data=data,hue='Churn')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(x='MonthlyCharges',y='TotalCharges',alpha=0.1, data=data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We plot the correlation matrix, the darker a box is, the more features are correlated\nplt.figure(figsize=(12,10))\ncorr = data.apply(lambda x: pd.factorize(x)[0]).corr()\nax = sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns, linewidths=.2, cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Churn rate is a health indicator for subscription-based companies. The ability to identify customers that aren’t happy with provided solutions allows businesses to learn about product or pricing plan weak points, operation issues, as well as customer preferences and expectations to proactively reduce reasons for churn.\n\nIt’s important to define data sources and observation period to have a full picture of the history of customer interaction. Selection of the most significant features for a model would influence its predictive performance: The more qualitative the dataset, the more precise forecasts are.\n\nCompanies with a large customer base and numerous offerings would benefit from customer segmentation. The number and choice of ML models may also depend on segmentation results. Data scientists also need to monitor deployed models, and revise and adapt features to maintain the desired level of prediction accuracy."},{"metadata":{},"cell_type":"markdown","source":"### Implement Machine Learning Models"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier \nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, accuracy_score, precision_score, recall_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"Churn\"] = data[\"Churn\"].astype(int)\nY = data[\"Churn\"].values\nX = data.drop(labels = [\"Churn\"],axis = 1)\n# Create Train & Test Data\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=101)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model Evaluation"},{"metadata":{},"cell_type":"markdown","source":"#### LogisticRegression"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Running logistic regression model\nfrom sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression()\nresult = model.fit(X_train, y_train)\nfrom sklearn import metrics\nprediction_test = model.predict(X_test)\n# Print the prediction accuracy\nprint (metrics.accuracy_score(y_test, prediction_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### RandomForestClassifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_rf = RandomForestClassifier(n_estimators=1000 , oob_score = True, n_jobs = -1,\n                                  random_state =50, max_features = \"auto\",\n                                  max_leaf_nodes = 30)\nmodel_rf.fit(X_train, y_train)\n\n# Make predictions\nprediction_test = model_rf.predict(X_test)\nprint (metrics.accuracy_score(y_test, prediction_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### SupportVectorClassifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.svm = SVC(kernel='linear') \nmodel.svm.fit(X_train,y_train)\npreds = model.svm.predict(X_test)\nmetrics.accuracy_score(y_test, preds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### XGBClassifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\nmodel = XGBClassifier()\nmodel.fit(X_train, y_train)\npreds = model.predict(X_test)\nmetrics.accuracy_score(y_test, preds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### AdaBoostClassifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"# AdaBoost Algorithm\nfrom sklearn.ensemble import AdaBoostClassifier\nmodel = AdaBoostClassifier()\n# n_estimators = 50 (default value) \n# base_estimator = DecisionTreeClassifier (default value)\nmodel.fit(X_train,y_train)\npreds = model.predict(X_test)\nmetrics.accuracy_score(y_test, preds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Confusion matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create the Confusion matrix\nfrom sklearn.metrics import classification_report, confusion_matrix  \nprint(confusion_matrix(y_test,preds))  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import itertools\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Compute confusion matrix\ncnf_matrix = confusion_matrix(y_test, preds)\nnp.set_printoptions(precision=2)\nclass_names = ['Not churned','churned']\n# Plot normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n                      title='Normalized confusion matrix')\n\nplt.show()\n\nfrom sklearn.metrics import classification_report\neval_metrics = classification_report(y_test, preds, target_names=class_names)\nprint(eval_metrics)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Final Conclusions"},{"metadata":{},"cell_type":"markdown","source":"##### Finally, this task allowed us to identify the parameters that influence the departure of a client. It also permitted to develop a predictive model that will help the company to target more easily and quickly people that are likely to leave.\n\nAs LR score of 0.80 which is quite correct, optimizing the parameters didn't led to a better score. We can try to use more complex models such as Random Forest, Gradient Boosting etc.\n\nChurn rate is a health indicator for subscription-based companies. The ability to identify customers that aren’t happy with provided solutions allows businesses to learn about product or pricing plan weak points, operation issues, as well as customer preferences and expectations to proactively reduce reasons for churn.\n\nIt’s important to define data sources and observation period to have a full picture of the history of customer interaction. Selection of the most significant features for a model would influence its predictive performance: The more qualitative the dataset, the more precise forecasts are.\n\nCompanies with a large customer base and numerous offerings would benefit from customer segmentation. The number and choice of ML models may also depend on segmentation results. Data scientists also need to monitor deployed models, and revise and adapt features to maintain the desired level of prediction accuracy."},{"metadata":{},"cell_type":"markdown","source":"> **Foot-notes:¶**\n> I'm not a stats major, so please do let me know in the comments if you feel that I've left out any important technique or if there was any mistake in the content.\n> \n> Do leave a comment/upvote :)"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}