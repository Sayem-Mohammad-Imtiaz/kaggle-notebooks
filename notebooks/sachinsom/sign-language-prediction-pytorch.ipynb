{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Image classification with sign langauage MNIST using pytorch**\nThis is a part of course project conducted by jovian.ml with freecodecamp. In this project,I have used sign langauage MNIST dataset to predict sign language images using diffrent modals like loginstic regression, feed forword nn, convolution nn.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"project_name = 'final-project-jovain.ml'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# sign language MNIST dataset\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Downloading and exploring the data ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"first, I will import some libraries that i will throughout this project","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"! pip install jovian --upgrade -q","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nfrom torch.utils.data import TensorDataset, DataLoader, random_split\n\nfrom PIL import Image\nimport pandas as pd\n\nfrom torchvision.transforms import ToTensor\nimport matplotlib.pyplot as plt\n\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torchvision.utils import make_grid\n\nimport jovian","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dir = \"../input/sign-language-mnist/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv(data_dir+'sign_mnist_test/sign_mnist_test.csv')\ntrain_df = pd.read_csv(data_dir+'sign_mnist_train/sign_mnist_train.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, I have created a helper function to convert all dataframes into numpy array","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def dataframe_to_nparray(train_df, test_df):\n    train_df1 = train_df.copy(deep = True)\n    test_df1 = test_df.copy(deep = True)\n    train_images = train_df1.iloc[:, 1:].to_numpy(dtype = 'float32')\n    test_images = test_df1.iloc[:, 1:].to_numpy(dtype = 'float32')\n    return train_images,test_images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_img, test_img = dataframe_to_nparray(train_df, test_df)\ntrain_labels = train_df['label'].values\ntest_labels = test_df['label'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_img.size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images_shaped = train_img.reshape(train_img.shape[0],1,28,28)\ntest_images_shaped = test_img.reshape(test_img.shape[0],1,28,28)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next step is to convert all numpy arrays into pytorch tensors","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images_tensors = torch.from_numpy(train_images_shaped)\ntrain_labels_tensors = torch.from_numpy(train_labels)\n\ntest_images_tensors = torch.from_numpy(test_images_shaped)\ntest_labels_tensors = torch.from_numpy(test_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pytorch dataset\ntrain_ds_full = TensorDataset(train_images_tensors, train_labels_tensors) #this dataset will further devided into validation dataset and training dataset\ntest_ds = TensorDataset(test_images_tensors, test_labels_tensors)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that we converted each image in a 3-dimensions tensor (1, 28, 28). The first dimension is for the number of channels. The second and third dimensions are for the size of the image, in this case, 28px by 28px.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"img, label = train_ds_full[0]\nprint(img.shape, label)\nimg","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we will define hyperparameters for our modal","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Hyperparmeters\nbatch_size = 64\nlearning_rate = 0.001\n\n# Other constants\nin_channels = 1\ninput_size = in_channels * 28 * 28\nnum_classes = 26\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training and validation dataset \nNow we are going to use three datasets-\n<ol>\n<li>Training set - used to train the model (compute the loss and adjust the weights of the model using gradient descent).</li>\n<li>Validation set - used to evaluate the model while training, adjust hyperparameters (learning rate etc.) and pick the best version of the model.</li>\n<li>Test set - used to compare different models, or different types of modeling approaches, and report the final accuracy of the model.</li>\n    </ol>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"random_seed = 11\ntorch.manual_seed(random_seed);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_size = 7455\ntrain_size = len(train_ds_full) - val_size\n\ntrain_ds, val_ds = random_split(train_ds_full, [train_size, val_size,])\nlen(train_ds), len(val_ds), len(test_ds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we will load the training,validation and test dataset in batches ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\nval_dl = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)\ntest_dl = DataLoader(test_ds, batch_size*2, num_workers=4, pin_memory=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for img, label in train_dl:\n    print(img.size())\n    break","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Models for image classification\nWe are going to create three different models for this project:\n\n1. Logistic Regression\n1. Deep Neural Network\n1. Convolutional Neural Network\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Logistic regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class ASLModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linear = nn.Linear(input_size, num_classes)\n        \n    def forward(self, xb):\n        xb = xb.reshape(-1, in_channels*28*28)\n        out = self.linear(xb)\n        return out\n    \n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc.detach()}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))\n    \nmodel = ASLModel()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for images, labels in test_dl:\n    outputs = model(images)\n    print(labels)\n    print(accuracy(outputs, labels))\n    \n    break\n\nprint('outputs.shape : ', outputs.shape)\nprint('Sample outputs :\\n', outputs[:2].data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n\ndef evaluate(model, val_loader):\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        for batch in train_loader:\n            loss = model.training_step(batch)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result0 = evaluate(model, val_dl)\nresult0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The initial accuracy is around 4%, which is what one might expect from a randomly intialized model (since it has a 1 in 10 chance of getting a label right by guessing randomly). Also note that we are using the .format method with the message string to print only the first four digits after the decimal point.\n\nWe are now ready to train the model. Let's train for 5 epochs and look at the results.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"history1 = fit(10, 0.001, model, train_dl, val_dl)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history2 = fit(10, 0.0001, model, train_dl, val_dl)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history3 = fit(10, 0.00001, model, train_dl, val_dl)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history4 = fit(10, 0.000001, model, train_dl, val_dl)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now with 40 iteration we went from 4% acc to 94% accuracy.It's quite amazing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"history = [result0] + history1 + history2 + history3 + history4\naccuracies = [result['val_acc'] for result in history]\nplt.plot(accuracies, '-x')\nplt.xlabel('epoch')\nplt.ylabel('accuracy')\nplt.title('Accuracy vs. No. of epochs');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = [result0] + history1 + history2 + history3 + history4\naccuracies = [result['val_loss'] for result in history]\nplt.plot(accuracies, '-x')\nplt.xlabel('epoch')\nplt.ylabel('accuracy')\nplt.title('Accuracy vs. No. of epochs');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluate on test dataset\nresult = evaluate(model, test_dl)\nresult","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_image(img, model):\n    xb = img.unsqueeze(0)\n    yb = model(xb)\n    _, preds  = torch.max(yb, dim=1)\n    return preds[0].item()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img, label = test_ds[10]\nplt.imshow(img.view(28,28), cmap='gray')\nprint('Label:', label.item(), ', Predicted:', predict_image(img, model))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img, label = test_ds[200]\nplt.imshow(img.view(28,28), cmap='gray')\nprint('Label:', label.item(), ', Predicted:', predict_image(img, model))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img, label = test_ds[1000]\nplt.imshow(img.view(28,28), cmap='gray')\nprint('Label:', label.item(), ', Predicted:', predict_image(img, model))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# saving the modal","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(model.state_dict(), 'ASL-logistic.pth')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Commit and upload the notebook\nAs a final step, we can save and commit our work using the jovian library. Along with the notebook, we can also attach the weights of our trained model, so that we can use it later.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"jovian.commit(project= project_name, enviornment= None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Deep Neural Network","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Definging the model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() / len(preds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ASLModel2(nn.Module):\n    \"\"\"Feedfoward neural network with 2 hidden layer\"\"\"\n    def __init__(self, in_size, out_size):\n        super().__init__()\n        # hidden layer 1\n        self.linear1 = nn.Linear(in_size, 512)\n        # hidden layer 2\n        self.linear2 = nn.Linear(512, 256)\n        # hidden layer 3\n        self.linear3 = nn.Linear(256, 128)\n        # output layer  \n        self.linear4 = nn.Linear(128, out_size)\n        \n    def forward(self, xb):\n        # Flatten the image tensors\n        out = xb.view(xb.size(0), -1)\n        # Get intermediate outputs using hidden layer 1\n        out = self.linear1(out)\n        # Apply activation function\n        out = F.relu(out)\n        # Get intermediate outputs using hidden layer 2\n        out = self.linear2(out)\n        # Apply activation function\n        out = F.relu(out)\n        # Get inermediate outputs using hidden layer 3\n        out = self.linear3(out)\n        # Apply a activation function\n        out = F.relu(out)\n        # Get predictions using output layer\n        out = self.linear4(out)\n        return out\n    \n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss, 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Using a GPU \nTo work with GPU's we have to take help of some utility functions, so let's define couple utility functions ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.cuda.is_available()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_default_device():\n    if torch.cuda.is_available() == True:\n        return torch.device('cuda')\n    else: \n        return torch.device('cpu')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = get_default_device()\ndevice","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dl = DeviceDataLoader(train_dl, device)\nval_dl = DeviceDataLoader(val_dl, device)\ntest_dl = DeviceDataLoader(test_dl, device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_dl.device)\nprint(test_dl.device)\nprint(val_dl.device)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training the Modal","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(model, val_loader):\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        for batch in train_loader:\n            loss = model.training_step(batch)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_size, num_classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = ASLModel2(input_size, out_size = num_classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for loading our model into GPU\nmodel = to_device(model, device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = [evaluate(model, val_dl)]\nhistory","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"so initially, this modal has very small accuracy of almost 3% that is vary low.\nso to improve this, we will iterate the process upto some epochs","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"history += fit(10, .001, model, train_dl, val_dl)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"losses = [x['val_loss'] for x in history]\nplt.plot(losses)\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.title('epoch vs loss')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = [x['val_acc'] for x in history]\nplt.plot(acc)\nplt.xlabel('epochs')\nplt.ylabel('accuracy')\nplt.title('epoch vs accuracy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = evaluate(model, test_dl)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# predictions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_image(img, model):\n    xb = to_device(img.unsqueeze(0), device)\n    yb = model(xb)\n    _, preds  = torch.max(yb, dim=1)\n    return preds[0].item()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img, label = test_ds[229]\nplt.imshow(img.view(28,28), cmap='gray')\nprint('Label:', label.item(), ', Predicted:', predict_image(img, model))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img, label = test_ds[6767]\nplt.imshow(img.view(28,28), cmap='gray')\nprint('Label:', label.item(), ', Predicted:', predict_image(img, model))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img, label = test_ds[7171]\nplt.imshow(img.view(28,28), cmap='gray')\nprint('Label:', label.item(), ', Predicted:', predict_image(img, model))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img, label = test_ds[6762]\nplt.imshow(img.view(28,28), cmap='gray')\nprint('Label:', label.item(), ', Predicted:', predict_image(img, model))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img, label = test_ds[55]\nplt.imshow(img.view(28,28), cmap='gray')\nprint('Label:', label.item(), ', Predicted:', predict_image(img, model))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img, label = test_ds[6766]\nplt.imshow(img.view(28,28), cmap='gray')\nprint('Label:', label.item(), ', Predicted:', predict_image(img, model))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# saving the Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(model.state_dict(), 'ASL-dnn.pth')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# commiting the notebook ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"jovian.commit(project=project_name, enviornment=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Convolution Neural Network","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n\nclass ASLBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['train_loss'], result['val_loss'], result['val_acc']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ASLCNNModel(ASLBase):\n    def __init__(self, in_channels, num_classes):\n        super().__init__()\n        self.network = nn.Sequential(\n            nn.Conv2d(in_channels, 28, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(28, 28, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),     #image size : 28*14*14 \n\n            nn.Conv2d(28, 56, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(56, 56, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),  # image size : 56*7*7\n\n            nn.Flatten(), \n            nn.Linear(56*7*7, 512),\n            nn.ReLU(),\n            nn.Linear(512, 128),\n            nn.ReLU(),\n            nn.Linear(128, num_classes))\n        \n    def forward(self, xb):\n        return self.network(xb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"in_channels, num_classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = ASLCNNModel(in_channels, num_classes)\nmodel","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = get_default_device()\ndevice","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dl = DeviceDataLoader(train_dl, device)\nval_dl = DeviceDataLoader(val_dl, device)\ntest_dl = DeviceDataLoader(test_dl, device)\nto_device(model, device);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        model.train()\n        train_losses = []\n        for batch in train_loader:\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = to_device(ASLCNNModel(in_channels, num_classes), device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluate(model, val_dl)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"so, initially this cnn model gives us 4% accuracy and a large validation loss of 3.26","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs = 10\nopt_func = torch.optim.Adam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = fit(num_epochs, 0.001 , model, train_dl, val_dl, opt_func)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_accuracies(history):\n    accuracies = [x['val_acc'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs. No. of epochs');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_accuracies(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs');\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_losses(history)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Testing With Test Images","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Testing with test dataloader\nresult = evaluate(model, test_dl)\nresult","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_image(img, model):\n    # Convert to a batch of 1\n    xb = to_device(img.unsqueeze(0), device)\n    # Get predictions from model\n    yb = model(xb)\n    # Pick index with highest probability\n    _, preds  = torch.max(yb, dim=1)\n    # Retrieve the class label\n    return preds[0].item()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img, label = test_ds[0]\nplt.imshow(img.view(28,28), cmap='gray')\nprint('Label:', label, ', Predicted:', predict_image(img, model))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img, label = test_ds[6762]\nplt.imshow(img.view(28,28), cmap='gray')\nprint('Label:', label, ', Predicted:', predict_image(img, model))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img, label = test_ds[3535]\nplt.imshow(img.view(28,28), cmap='gray')\nprint('Label:', label, ', Predicted:', predict_image(img, model))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img, label = test_ds[23]\nplt.imshow(img.view(28,28), cmap='gray')\nprint('Label:', label, ', Predicted:', predict_image(img, model))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Saving the model\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(model.state_dict(), '3-asl-cnn.pth')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Commiting the notebook in jovianML","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"jovian.commit(project= project_name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}