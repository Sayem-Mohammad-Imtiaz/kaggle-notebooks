{"cells":[{"metadata":{},"cell_type":"markdown","source":"## importing libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"import pandas as pd\ndataset = pd.read_csv(\"../input/housesalesprediction/kc_house_data.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\ndataset.hist(figsize=(20, 15), bins=50)\n#scatter_matrix(data)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## I found that the colomns [ id , data , sqft_lot ,  condition , yr_built , zipcode , long  , sqft_lot15 ] does not contribute in price ,so drop it"},{"metadata":{"trusted":true},"cell_type":"code","source":"new_dataset = dataset.drop(['id', 'date', 'sqft_lot', 'condition', 'yr_built', 'zipcode', 'long', 'sqft_lot15'],axis = 1)\nnew_dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## preprocessing"},{"metadata":{},"cell_type":"markdown","source":"## 1- splitting X and Y"},{"metadata":{"trusted":true},"cell_type":"code","source":"Y = new_dataset[['price']]\nY","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = new_dataset.drop('price',axis = 1)\nX","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Because there is no NaN values and categorical variables ,I'll go through `Scaling`"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)\nprint(Y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.preprocessing import StandardScaler\n# scalar = StandardScaler()\n# #print(np.max(X_train))\n# print('before scalling, max is %d and min is %d'%(np.max(np.max(X_train)), np.min(np.min(X_train))))\n# X_train2 = scalar.fit_transform(X_train)\n# X_test2  = scalar.transform(X_test)  # transform only because that's train\n# print('after scalling, max is %d and min is %d'%(np.max(np.max(X_train2)), np.min(np.min(X_train2))))\n# # Y_train2 = scalar.fit_transform(Y_train)\n# # Y_test2  = scalar.transform(Y_test)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# let's build our model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nmodel = LinearRegression()\nmodel.fit(X_train, Y_train)\nprint(X_train.shape,Y_train.shape)\nmodel.coef_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Now let's check our model "},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = model.predict(X_test)\nprint(X_test.shape, prediction.shape)\nfrom sklearn.metrics import explained_variance_score\nexplained_variance_score(Y_test,prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(Y_test[:10],' \\n ', prediction[:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(X_test, prediction,'.', X_test, prediction, '.')\nplt.title('our first simple model')\nplt.xlabel('Features')\nplt.ylabel('price')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## If I take the most efficient features only"},{"metadata":{"trusted":true},"cell_type":"code","source":"new_dataset2 =  dataset[['sqft_living']]\nnew_dataset2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nnew_X_train, new_X_test, new_Y_train, new_Y_test = train_test_split(new_dataset2, Y, test_size = 0.2, random_state = 0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.preprocessing import StandardScaler\n# scalar = StandardScaler()\n# #print(np.max(X_train))\n# print('before scalling, max is %d and min is %d'%(np.max(np.max(new_X_train)), np.min(np.min(new_X_train))))\n# X_train3 = scalar.fit_transform(new_X_train)\n# X_test3  = scalar.transform(new_X_test)  # transform only because that's train\n# print('after scalling, max is %d and min is %d'%(np.max(np.max(X_train3)), np.min(np.min(X_train3))))\n# Y_train2 = scalar.fit_transform(Y_train)\n# # Y_test2  = scalar.transform(Y_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nmodel = LinearRegression()\nmodel.fit(new_X_train, new_Y_train)\nmodel.coef_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"goal_predict = model.predict(new_X_test)\nprint(new_Y_test[:10],' \\n ', goal_predict[:10])\nfrom sklearn.metrics import r2_score\nr2_score(new_Y_test,goal_predict )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(new_X_test[:10], goal_predict[:10],'.', new_X_test[:10], goal_predict[:10], '-')\nplt.title('our first simple model')\nplt.xlabel('Features')\nplt.ylabel('price')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import explained_variance_score\nexplained_variance_score(Y_test,goal_predict)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## As we have shown ,when we reduce the nomber of feature, the accuracy reduce \n## In the 1st one the accuracy was 0.655 \n## In the 2nd one the accuracy reduced to 0.4825"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Now let's try PolynomialRegression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\n\n# Create The Polynomial Features\n\nfrom sklearn.preprocessing import PolynomialFeatures\npoly_reg = PolynomialFeatures(degree=3)\n\nx_poly_train = poly_reg.fit_transform(X_train)            \nx_poly_test  = poly_reg.fit_transform(X_test) \n\n# print(x_poly_train.shape,' ', x_poly_test.shape)\n# print(Y_train.shape)\n\nregressor.fit(x_poly_train,Y_train)\n\n# Test the model \ny_pred = regressor.predict(x_poly_test)\n\n# Calculate the Accuracy\nprint('Polynomial Linear Regression Accuracy:',explained_variance_score(Y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## It's obvious that the accuracy is increased to 0.75386 after using PolynomialRegression"},{"metadata":{},"cell_type":"markdown","source":"## تم بحمد الله"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":1}