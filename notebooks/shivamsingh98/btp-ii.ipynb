{"cells":[{"metadata":{"id":"mESj8ubpVedE","outputId":"c8afce3d-0b3c-4d51-f6a6-2bbc3e991b77","trusted":true},"cell_type":"code","source":"# Python libraries\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score, learning_curve, train_test_split\nfrom sklearn.metrics import precision_score, roc_auc_score, recall_score, confusion_matrix, roc_curve, precision_recall_curve, accuracy_score\nimport xgboost as xgb\nimport warnings\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.subplots as tls\nimport plotly.figure_factory as ff","execution_count":null,"outputs":[]},{"metadata":{"id":"WBYospOHWFXr","trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/abcdef/WA_Fn-UseC_-HR-Employee-Attrition.csv')","execution_count":null,"outputs":[]},{"metadata":{"id":"jwCAZwlUYg47","outputId":"aaf885d5-96e9-46e2-eea1-01d6521acc54","trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"OagD8xlVXxnr","trusted":true},"cell_type":"code","source":"# Reassign target\ndata.Attrition.replace(to_replace = dict(Yes = 1, No = 0), inplace = True)\n# Drop useless feat\ndata = data.drop(columns=['StandardHours', \n                          'EmployeeCount', \n                          'Over18',\n                        ])","execution_count":null,"outputs":[]},{"metadata":{"id":"XumKhqo9YAXp","outputId":"155be301-6809-4d20-ca24-3440e7bb77f8","trusted":true},"cell_type":"code","source":"# head\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"LWkuoz8MYEQE","outputId":"7da4b3f3-ca6b-49d3-8598-6e6626564577","trusted":true},"cell_type":"code","source":"# describe\ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{"id":"GwaP5ND7YJZf","outputId":"ab591eb8-7374-4534-f4a4-b5d526b46db0","trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"s0kTs8BcYq4w"},"cell_type":"markdown","source":"## Feature Selection","execution_count":null},{"metadata":{"id":"dl1UH5SXYxn9"},"cell_type":"markdown","source":"Adding 24 new features:","execution_count":null},{"metadata":{"id":"oAi99RN5YbOm","trusted":true},"cell_type":"code","source":"def SalesDpt(data) :\n    if data['Department'] == 'Sales':\n        return 1\n    else:\n        return 0\ndata['SalesDpt'] = data.apply(lambda data:SalesDpt(data) ,axis = 1)\n\ndef JobInvCut(data) :\n    if data['JobInvolvement'] < 2.5 :\n        return 1\n    else:\n        return 0\ndata['JobInvCut'] = data.apply(lambda data:JobInvCut(data) ,axis = 1)\n\ndef MiddleTraining(data) :\n    if data['TrainingTimesLastYear'] >= 3 and data['TrainingTimesLastYear'] <= 6:\n        return 1\n    else:\n        return 0\ndata['MiddleTraining'] = data.apply(lambda data:MiddleTraining(data) ,axis = 1)\n\ndef MoovingPeople(data) :\n    if data['NumCompaniesWorked'] > 4:\n        return 1\n    else:\n        return 0\ndata['MoovingPeople'] = data.apply(lambda data:MoovingPeople(data), axis = 1)\n\ndata['TotalSatisfaction_mean'] = (data['RelationshipSatisfaction']  + data['EnvironmentSatisfaction'] + data['JobSatisfaction'] + data['JobInvolvement'] + data['WorkLifeBalance'])/5\n\ndef NotSatif(data) : \n    if  data['TotalSatisfaction_mean'] < 2.35 :\n        return 1\n    else : \n        return 0\ndata['NotSatif'] = data.apply(lambda data:NotSatif(data) ,axis = 1)\n\ndef LongDisWL1(data) : \n    if  data['DistanceFromHome'] > 11 and data['WorkLifeBalance'] == 1 :\n        return 1\n    else : \n        return 0\ndata['LongDisWL1'] = data.apply(lambda data:LongDisWL1(data) ,axis = 1)\n\ndef LongDis(data) : \n    if  data['DistanceFromHome'] > 11:\n        return 1\n    else : \n        return 0\ndata['LongDis'] = data.apply(lambda data:LongDis(data) ,axis = 1)\n\ndef LongDisJobS1(data) : \n    if  data['DistanceFromHome'] > 11 and data['JobSatisfaction'] == 1 :\n        return 1\n    else : \n        return 0\ndata['LongDisJobS1'] = data.apply(lambda data:LongDisJobS1(data) ,axis = 1)\n\ndef LongDisJL1(data) : \n    if  data['DistanceFromHome'] > 11 and data['JobLevel'] == 1 :\n        return 1\n    else : \n        return 0\ndata['LongDisJL1'] = data.apply(lambda data:LongDisJL1(data) ,axis = 1)\n\ndef ShortDisNotSingle(data) : \n    if  data['MaritalStatus'] != 'Single' and data['DistanceFromHome'] < 5:\n        return 1\n    else : \n        return 0\ndata['ShortDisNotSingle'] = data.apply(lambda data:ShortDisNotSingle(data) ,axis = 1)\n\ndef LongDisSingle(data) : \n    if  data['MaritalStatus'] == 'Single' and data['DistanceFromHome'] > 11:\n        return 1\n    else : \n        return 0\ndata['LongDisSingle'] = data.apply(lambda data:LongDisSingle(data) ,axis = 1)\n\ndef Engaged(data) : \n    if data['Age'] > 35 and data['MaritalStatus'] != 'Single':\n        return 1\n    else : \n        return 0\ndata['Engaged'] = data.apply(lambda data:Engaged(data) ,axis = 1)\n\ndef YoungAndBadPaid(data) : \n    if data['Age'] < 35 and data['Age'] > 23 and (data['MonthlyIncome'] < 3500):\n        return 1\n    else : \n        return 0\ndata['YoungAndBadPaid'] = data.apply(lambda data:YoungAndBadPaid(data) ,axis = 1)\n\ndef YoungNeverEngaged(data) : \n    if data['Age'] < 24 and data['MaritalStatus'] == 'Single' :\n        return 1\n    else : \n        return 0\ndata['YoungNeverEngaged'] = data.apply(lambda data:YoungNeverEngaged(data) ,axis = 1)\n\ndata['Time_in_each_comp'] = (data['Age'] - 20) / ((data)['NumCompaniesWorked'] + 1)\ndata['RelSatisf_mean'] = (data['RelationshipSatisfaction']  + data['EnvironmentSatisfaction']) / 2\ndata['JobSatisf_mean'] = (data['JobSatisfaction'] + data['JobInvolvement']) / 2\ndata['Income_Distance'] = data['MonthlyIncome'] / data['DistanceFromHome']\ndata['Hrate_Mrate'] = data['HourlyRate'] / data['MonthlyRate']\ndata['Stability'] = data['YearsInCurrentRole'] / data['YearsAtCompany']\ndata['Stability'].fillna((data['Stability'].mean()), inplace=True)\ndata['Income_YearsComp'] = data['MonthlyIncome'] / data['YearsAtCompany']\ndata['Income_YearsComp'] = data['Income_YearsComp'].replace(np.Inf, 0)\ndata['Fidelity'] = (data['NumCompaniesWorked']) / data['TotalWorkingYears']\ndata['Fidelity'] = data['Fidelity'].replace(np.Inf, 0)","execution_count":null,"outputs":[]},{"metadata":{"id":"HitueTiXa_ny","trusted":true},"cell_type":"code","source":"def plot_distribution(var_select, bin_size) : \n# Calculate the correlation coefficient between the new variable and the target\n    corr = data['Attrition'].corr(data[var_select])\n    corr = np.round(corr,3)\n    tmp1 = attrition[var_select]\n    tmp2 = no_attrition[var_select]\n    hist_data = [tmp1, tmp2]\n    \n    group_labels = ['Yes_attrition', 'No_attrition']\n    colors = ['#FFD700', '#7EC0EE']\n\n    fig = ff.create_distplot(hist_data, group_labels, colors = colors, show_hist = True, curve_type='kde', bin_size = bin_size)\n    \n    fig['layout'].update(title = var_select+' '+'(corr target ='+ str(corr)+')')\n\n    py.iplot(fig, filename = 'Density plot')\ndef barplot(var_select, x_no_numeric) :\n    tmp1 = data[(data['Attrition'] != 0)]\n    tmp2 = data[(data['Attrition'] == 0)]\n    tmp3 = pd.DataFrame(pd.crosstab(data[var_select],data['Attrition']), )\n    tmp3['Attr%'] = tmp3[1] / (tmp3[1] + tmp3[0]) * 100\n    if x_no_numeric == True  : \n        tmp3 = tmp3.sort_values(1, ascending = False)\n\n    color=['lightskyblue','gold' ]\n    trace1 = go.Bar(\n        x=tmp1[var_select].value_counts().keys().tolist(),\n        y=tmp1[var_select].value_counts().values.tolist(),\n        name='Yes_Attrition',opacity = 0.8, marker=dict(\n        color='gold',\n        line=dict(color='#000000',width=1)))\n\n    \n    trace2 = go.Bar(\n        x=tmp2[var_select].value_counts().keys().tolist(),\n        y=tmp2[var_select].value_counts().values.tolist(),\n        name='No_Attrition', opacity = 0.8, marker=dict(\n        color='lightskyblue',\n        line=dict(color='#000000',width=1)))\n    \n    trace3 =  go.Scatter(   \n        x=tmp3.index,\n        y=tmp3['Attr%'],\n        yaxis = 'y2',\n        name='% Attrition', opacity = 0.6, marker=dict(\n        color='black',\n        line=dict(color='#000000',width=0.5\n        )))\n\n    layout = dict(title =  str(var_select),\n              xaxis=dict(), \n              yaxis=dict(title= 'Count'), \n              yaxis2=dict(range= [-0, 75], \n                          overlaying= 'y', \n                          anchor= 'x', \n                          side= 'right',\n                          zeroline=False,\n                          showgrid= False, \n                          title= '% Attrition'\n                         ))\n\n    fig = go.Figure(data=[trace1, trace2, trace3], layout=layout)\n    py.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"id":"JvwHn6WBbMyj","outputId":"982b0d4a-2650-4fcf-d2ec-3e276421204e","trusted":true},"cell_type":"code","source":"attrition = data[(data['Attrition'] != 0)]\nno_attrition = data[(data['Attrition'] == 0)]\n\nplot_distribution('Age', False)\nbarplot('Age', False)\nplot_distribution('DailyRate', 100)\nplot_distribution('DistanceFromHome', False)\nbarplot('DistanceFromHome', False)\nplot_distribution('HourlyRate', False)\nplot_distribution('MonthlyIncome', 100)\nplot_distribution('MonthlyRate', 100)\nplot_distribution('NumCompaniesWorked', False)\nbarplot('NumCompaniesWorked',False)\nplot_distribution('PercentSalaryHike', False)\nbarplot('PercentSalaryHike', False) \nplot_distribution('TotalWorkingYears', False)\nbarplot('TotalWorkingYears', False)\nplot_distribution('TrainingTimesLastYear', False)\nbarplot('TrainingTimesLastYear',False)\nplot_distribution('YearsAtCompany', False)\nbarplot('YearsAtCompany', False)\nplot_distribution('YearsInCurrentRole', False)\nbarplot('YearsInCurrentRole', False)\nplot_distribution('YearsSinceLastPromotion', False)\nbarplot('YearsSinceLastPromotion', False)\nplot_distribution('YearsWithCurrManager', False)\nbarplot('YearsWithCurrManager', False)","execution_count":null,"outputs":[]},{"metadata":{"id":"ZUNnnKUYaslJ","outputId":"97a5e815-4d09-4f00-d83a-7f9d5d4d7edb","trusted":true},"cell_type":"code","source":"barplot('Engaged', False)\nbarplot('YoungAndBadPaid', False)\nbarplot('YoungNeverEngaged', False)\nbarplot('LongDisSingle', False)\nbarplot('LongDisJL1', False)\nbarplot('ShortDisNotSingle', False)","execution_count":null,"outputs":[]},{"metadata":{"id":"4Gz8pjWkbq2J"},"cell_type":"markdown","source":"Dropping some features:","execution_count":null},{"metadata":{"id":"tMJ0JYYGavWL","outputId":"5950a9eb-724d-420a-e5c2-53690f59041a","trusted":true},"cell_type":"code","source":"data = data.drop(columns=[\n                        'Age',\n                        'MonthlyIncome',\n                        'YearsAtCompany',\n                        'DistanceFromHome',\n                        'PerformanceRating',\n                        'NumCompaniesWorked'\n                     ])\n\nprint (\"\\nMissing values :  \", data.isnull().sum().values.sum())","execution_count":null,"outputs":[]},{"metadata":{"id":"t82iQxuIby0X"},"cell_type":"markdown","source":"Feature Encoding and Scaling:","execution_count":null},{"metadata":{"id":"lJreAoSvbtVu","trusted":true},"cell_type":"code","source":"#customer id col\nId_col     = ['EmployeeNumber']\n#Target columns\ntarget_col = [\"Attrition\"]\n#categorical columns\ncat_cols   = data.nunique()[data.nunique() < 10].keys().tolist()\ncat_cols   = [x for x in cat_cols if x not in target_col]\n#numerical columns\nnum_cols   = [x for x in data.columns if x not in cat_cols + target_col + Id_col]\n#Binary columns with 2 values\nbin_cols   = data.nunique()[data.nunique() == 2].keys().tolist()\n#Columns more than 2 values\nmulti_cols = [i for i in cat_cols if i not in bin_cols]\n\n#Label encoding Binary columns\nle = LabelEncoder()\nfor i in bin_cols :\n    data[i] = le.fit_transform(data[i])\n    \n#Duplicating columns for multi value columns\ndata = pd.get_dummies(data = data,columns = multi_cols )\n\n#Scaling Numerical columns\nstd = StandardScaler()\nscaled = std.fit_transform(data[num_cols])\nscaled = pd.DataFrame(scaled,columns=num_cols)\n\n#dropping original values merging scaled values for numerical columns\ndf_data_og = data.copy()\ndata = data.drop(columns = num_cols,axis = 1)\ndata = data.merge(scaled,left_index=True,right_index=True,how = \"left\")\ndata = data.drop(['EmployeeNumber'],axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"id":"G1JCrnQ3b_da"},"cell_type":"markdown","source":"Correlation Matrix:","execution_count":null},{"metadata":{"id":"3I647q4Bb0me","outputId":"6f7338d6-c830-42b0-e510-5c8451e300a1","trusted":true},"cell_type":"code","source":"correlation = data.corr()\n#tick labels\nmatrix_cols = correlation.columns.tolist()\n#convert to array\ncorr_array  = np.array(correlation)\n\n#Plotting\ntrace = go.Heatmap(z = corr_array,\n                   x = matrix_cols,\n                   y = matrix_cols,\n                   colorscale='Viridis',\n                   colorbar   = dict() ,\n                  )\nlayout = go.Layout(dict(title = 'Correlation Matrix for variables',\n                        autosize = False,\n                        #height  = 1400,\n                        #width   = 1600,\n                        margin  = dict(r = 0 ,l = 210,\n                                       t = 25,b = 210,\n                                     ),\n                        yaxis   = dict(tickfont = dict(size = 9)),\n                        xaxis   = dict(tickfont = dict(size = 9)),\n                       )\n                  )\nfig = go.Figure(data = [trace],layout = layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"id":"ci_lV21DcKqy"},"cell_type":"markdown","source":"Remove Collinear features:","execution_count":null},{"metadata":{"id":"mvUWjx4dcA5q","outputId":"633f287c-edc2-4165-dd84-75a9f1580c57","trusted":true},"cell_type":"code","source":"# Threshold for removing correlated variables\nthreshold = 0.8\n\n# Absolute value correlation matrix\ncorr_matrix = data.corr().abs()\ncorr_matrix.head()\n\n# Upper triangle of correlations\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\nupper.head()\n\n# Select columns with correlations above threshold\nto_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n\nprint('There are %d columns to remove :' % (len(to_drop)))\n\ndata = data.drop(columns = to_drop)\n\nto_drop","execution_count":null,"outputs":[]},{"metadata":{"id":"S6hSn4rScTlG"},"cell_type":"markdown","source":"Applying Model:","execution_count":null},{"metadata":{"id":"E7DxOEchcJt-","trusted":true},"cell_type":"code","source":"def model_performance_plot(model) : \n    #conf matrix\n    conf_matrix = confusion_matrix(y_test, y_pred)\n    trace1 = go.Heatmap(z = conf_matrix  ,x = [\"0 (pred)\",\"1 (pred)\"],\n                        y = [\"0 (true)\",\"1 (true)\"],xgap = 2, ygap = 2, \n                        colorscale = 'Viridis', showscale  = False)\n\n    #show metrics\n    tp = conf_matrix[1,1]\n    fn = conf_matrix[1,0]\n    fp = conf_matrix[0,1]\n    tn = conf_matrix[0,0]\n    Accuracy  =  ((tp+tn)/(tp+tn+fp+fn))\n    Precision =  (tp/(tp+fp))\n    Recall    =  (tp/(tp+fn))\n    F1_score  =  (2*(((tp/(tp+fp))*(tp/(tp+fn)))/((tp/(tp+fp))+(tp/(tp+fn)))))\n\n    show_metrics = pd.DataFrame(data=[[Accuracy , Precision, Recall, F1_score]])\n    show_metrics = show_metrics.T\n\n    colors = ['gold', 'lightgreen', 'lightcoral', 'lightskyblue']\n    trace2 = go.Bar(x = (show_metrics[0].values), \n                   y = ['Accuracy', 'Precision', 'Recall', 'F1_score'], text = np.round_(show_metrics[0].values,4),\n                    textposition = 'auto',\n                   orientation = 'h', opacity = 0.8,marker=dict(\n            color=colors,\n            line=dict(color='#000000',width=1.5)))\n    \n    #plot roc curve\n    model_roc_auc = round(roc_auc_score(y_test, y_score) , 3)\n    fpr, tpr, t = roc_curve(y_test, y_score)\n    trace3 = go.Scatter(x = fpr,y = tpr,\n                        name = \"Roc : \",\n                        line = dict(color = ('rgb(22, 96, 167)'),width = 2), fill='tozeroy')\n    trace4 = go.Scatter(x = [0,1],y = [0,1],\n                        line = dict(color = ('black'),width = 1.5,\n                        dash = 'dot'))\n    \n    # Precision-recall curve\n    precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n    trace5 = go.Scatter(x = recall, y = precision,\n                        name = \"Precision\" + str(precision),\n                        line = dict(color = ('lightcoral'),width = 2), fill='tozeroy')\n    \n    #subplots\n    fig = tls.make_subplots(rows=2, cols=2, print_grid=False, \n                        subplot_titles=('Confusion Matrix',\n                                        'Metrics',\n                                        'ROC curve'+\" \"+ '('+ str(model_roc_auc)+')',\n                                        'Precision - Recall curve'))\n    \n    fig.append_trace(trace1,1,1)\n    fig.append_trace(trace2,1,2)\n    fig.append_trace(trace3,2,1)\n    fig.append_trace(trace4,2,1)\n    fig.append_trace(trace5,2,2)\n    \n    fig['layout'].update(showlegend = False, title = '<b>Model performance</b><br>'+str(model),\n                        autosize = False, height = 900,width = 830,\n                        plot_bgcolor = 'rgba(240,240,240, 0.95)',\n                        paper_bgcolor = 'rgba(240,240,240, 0.95)',\n                        margin = dict(b = 195))\n    fig[\"layout\"][\"xaxis2\"].update((dict(range=[0, 1])))\n    fig[\"layout\"][\"xaxis3\"].update(dict(title = \"false positive rate\"))\n    fig[\"layout\"][\"yaxis3\"].update(dict(title = \"true positive rate\"))\n    fig[\"layout\"][\"xaxis4\"].update(dict(title = \"recall\"), range = [0,1.05])\n    fig[\"layout\"][\"yaxis4\"].update(dict(title = \"precision\"), range = [0,1.05])\n    fig.layout.titlefont.size = 14\n    \n    py.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"id":"I74BPdeqcVPo","trusted":true},"cell_type":"code","source":"def features_imp(model, cf) : \n\n    coefficients  = pd.DataFrame(model.feature_importances_)\n    column_data     = pd.DataFrame(list(data))\n    coef_sumry    = (pd.merge(coefficients,column_data,left_index= True,\n                              right_index= True, how = \"left\"))\n    coef_sumry.columns = [\"coefficients\",\"features\"]\n    coef_sumry    = coef_sumry.sort_values(by = \"coefficients\",ascending = False)\n    coef_sumry = coef_sumry[coef_sumry[\"coefficients\"] !=0]\n    trace = go.Bar(x = coef_sumry[\"features\"],y = coef_sumry[\"coefficients\"],\n                    name = \"coefficients\",\n                    marker = dict(color = coef_sumry[\"coefficients\"],\n                                  colorscale = \"Viridis\",\n                                  line = dict(width = .6,color = \"black\")))\n    layout = dict(title =  'Feature Importances xgb_cfl')\n                    \n    fig = dict(data = [trace], layout=layout)\n    py.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"id":"flrPfQsXcY6W","trusted":true},"cell_type":"code","source":"def cum_gains_curve(model):\n    pos = pd.get_dummies(y_test).values\n    pos = pos[:,1] \n    npos = np.sum(pos)\n    index = np.argsort(y_score) \n    index = index[::-1] \n    sort_pos = pos[index]\n    #cumulative sum\n    cpos = np.cumsum(sort_pos) \n    #recall\n    recall = cpos/npos \n    #size obs test\n    n = y_test.shape[0] \n    size = np.arange(start=1,stop=369,step=1) \n    #proportion\n    size = size / n \n    #plots\n    model = 'xgb_cfl'\n    trace1 = go.Scatter(x = size,y = recall,\n                        name = \"Lift curve\",\n                        line = dict(color = ('rgb(22, 96, 167)'),width = 2))\n    trace2 = go.Scatter(x = size,y = size,\n                        name = \"Baseline\",\n                        showlegend=False,\n                        line = dict(color = ('black'),width = 1.5,\n                        dash = 'dot'))\n\n    layout = dict(title = 'Cumulative gains curve'+' '+str(model),\n                  yaxis = dict(title = 'Percentage positive targeted',zeroline = False),\n                  xaxis = dict(title = 'Percentage contacted', zeroline = False)\n                 )\n\n    fig  = go.Figure(data = [trace1,trace2], layout = layout)\n    py.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"id":"ecu1ERYFcdvs","trusted":true},"cell_type":"code","source":"def cross_val_metrics(model) :\n    scores = ['accuracy', 'precision', 'recall']\n    for sc in scores:\n        scores = cross_val_score(model, X, y, cv = 5, scoring = sc)\n        print('[%s] : %0.5f (+/- %0.5f)'%(sc, scores.mean(), scores.std()))","execution_count":null,"outputs":[]},{"metadata":{"id":"VQdlksNqch2I"},"cell_type":"markdown","source":"Prepare Dataset:","execution_count":null},{"metadata":{"id":"UEX7xwojcg0a","trusted":true},"cell_type":"code","source":"# Def X and Y\ny = np.array(data.Attrition.tolist())\ndata = data.drop('Attrition', 1)\nX = np.array(data.values)","execution_count":null,"outputs":[]},{"metadata":{"id":"w6GPHXMDclmY","trusted":true},"cell_type":"code","source":"# Train_test split\nrandom_state = 42\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = random_state)","execution_count":null,"outputs":[]},{"metadata":{"id":"OKPcEXeLdMYp","outputId":"142fb447-1e72-4fb5-e8d6-b4374a42144b","trusted":true},"cell_type":"code","source":"def timer(start_time=None):\n    if not start_time:\n        start_time = datetime.now()\n        return start_time\n    elif start_time:\n        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n        tmin, tsec = divmod(temp_sec, 60)\n        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))\n        \n        \nxgb_cfl = xgb.XGBClassifier(n_jobs = -1)\n\n\n# A parameter grid for XGBoost\nparams = {\n        'n_estimators' : [100, 200, 500, 750],\n        'learning_rate' : [0.01, 0.02, 0.05, 0.1, 0.25],\n        'min_child_weight': [1, 5, 7, 10],\n        'gamma': [0.1, 0.5, 1, 1.5, 5],\n        'subsample': [0.6, 0.8, 1.0],\n        'colsample_bytree': [0.6, 0.8, 1.0],\n        'max_depth': [3, 4, 5, 10, 12]\n        }\n\nfolds = 5\nparam_comb = 800\n\nrandom_search = RandomizedSearchCV(xgb_cfl, param_distributions=params, n_iter=param_comb, scoring='accuracy', n_jobs=-1, cv=5, verbose=3, random_state=42)\n\n# Here we go\nstart_time = timer(None) # timing starts from this point for \"start_time\" variable\n#----------------------------# random_search.fit(X, y)\ntimer(start_time) # timing ends here for \"start_time\" variable","execution_count":null,"outputs":[]},{"metadata":{"id":"esI36JFCdezz","trusted":true},"cell_type":"code","source":"# xgb \nxgb_clf = xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n                           colsample_bytree=0.8, gamma=1.5, learning_rate=0.05,\n                           max_delta_step=0, max_depth=3, min_child_weight=7, missing=None,\n                           n_estimators=200, n_jobs=-1, nthread=None,\n                           objective='binary:logistic', random_state=0, reg_alpha=0,\n                           reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n                           subsample=0.6)\n\nxgb_clf.fit(X_train, y_train)\ny_pred = xgb_clf.predict(X_test)\ny_score = xgb_clf.predict_proba(X_test)[:,1]\n\nmodel_performance_plot('xgb_clf')","execution_count":null,"outputs":[]},{"metadata":{"id":"JYjm11dzdlam","outputId":"4e0d6f94-7938-4458-faa0-d088ead592fd","trusted":true},"cell_type":"code","source":"features_imp(xgb_clf, 'features')","execution_count":null,"outputs":[]},{"metadata":{"id":"_4Ik3qsCd7Db","outputId":"69aed756-a03d-4223-8f0a-fad5df6d0f08","trusted":true},"cell_type":"code","source":"#feature importance plot TOP 40\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\ndef plot_feature_importance(model):\n    tmp = pd.DataFrame({'Feature': list(data), 'Feature importance': model.feature_importances_})\n    tmp = tmp.sort_values(by='Feature importance',ascending=False).head(30)\n    plt.figure(figsize = (10,12))\n    plt.title('Top 30 - Features importance - XGBoost',fontsize=14)\n    s = sns.barplot(y='Feature',x='Feature importance',data=tmp, orient='h')\n    s.set_xticklabels(s.get_xticklabels(),rotation=90)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"HDTnpjXyd9Jb","outputId":"6e813652-de43-49ff-dace-31c830e23325","trusted":true},"cell_type":"code","source":"plot_feature_importance(xgb_clf)","execution_count":null,"outputs":[]},{"metadata":{"id":"4t3bN3jCeHwX","outputId":"9f155817-a733-45c6-8cb4-4bc5f98bf0bf","trusted":true},"cell_type":"code","source":"cum_gains_curve(xgb_clf)","execution_count":null,"outputs":[]},{"metadata":{"id":"NcCQUGzDeW-O","outputId":"a9c797a2-a03f-4712-8341-622493df60f8","trusted":true},"cell_type":"code","source":"# Cross val score\ncross_val_metrics(xgb_clf)","execution_count":null,"outputs":[]},{"metadata":{"id":"Y3ydYUUMepVp","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}