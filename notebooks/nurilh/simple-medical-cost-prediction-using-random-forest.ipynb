{"cells":[{"metadata":{"_uuid":"4588f0304b527508b6f2f789707218a1161e2192"},"cell_type":"markdown","source":"**<h1>1. Introduction</h1>**\n\nThis kernel aims to exercising simple data pre-processing and regression model building for predicting medical cost based on medical dataset."},{"metadata":{"_uuid":"358ac66c7650a7714035accae8a8871a8c5e95c6"},"cell_type":"markdown","source":"**<h1>2. Dataset Overview</h1>**\n\nLet's take a glimpse at the dataset before we processed it furthermore. Then we can decide what pre-processing method suitable for making medical cost prediction."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\n\n# Load dataset\ndata_path = '../input/insurance.csv'\ndata = pd.read_csv(data_path)\n\n# See general information about the dataset & 5 sample data points\nprint(data.info())\ndata.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cc8aee3e3ea1fe63eab783fd094acb6b90005b63"},"cell_type":"markdown","source":"As seen above, the medical cost dataset consists of 1338 data, which each data has 7 columns, 3 of them are categorical (stated by object data type). Categorical value can be found in *sex*, *smoker*, and *region* column. Those categorical values need to be converted to numerical values in prior to building the prediction model. In addition, there is no missing values in the dataset, showed by number 1338 (the number of total data) on each column information."},{"metadata":{"trusted":true,"_uuid":"cc75bb096230eda518abd819fcd0a224cc40ef72"},"cell_type":"markdown","source":"**<h1>3. Data Pre-processing</h1>**\n\n**<h2>Label Encoding</h2>**\n\nLabel encoding is a process to transform categorical value to numerical value. *LabelEncoder* from scikit-learn library is used in this transformation process. Decimal number is assigned to each categorical value within the column. New columns containing encoded categorical values then added at the end of medical dataset column.\n"},{"metadata":{"trusted":true,"_uuid":"0cb7c76549ad3169f47ca465e8d21e7f36ffa6bf"},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# Label encoder initialization\nle_sex = LabelEncoder()\nle_smoker = LabelEncoder()\nle_region = LabelEncoder()\n\n# Label encoding\ndata['sex_encoded'] = le_sex.fit_transform(data.sex)\ndata['smoker_encoded'] = le_smoker.fit_transform(data.smoker)\ndata['region_encoded'] = le_region.fit_transform(data.region)\n\n# See the encoding mapping \n# (categorical value encoded by the index)\nprint('sex column encoding mapping : %s' % list(le_sex.classes_))\nprint('smoker column encoding mapping : %s' % list(le_smoker.classes_))\nprint('region column encoding mapping : %s' % list(le_region.classes_))\n\n# See label encoding result\ndata.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f05c9e8ae6a900a128bf8b5f6386e25c770a5fe5"},"cell_type":"markdown","source":"As seen above, numerical value assigned for *region* column is not binary (it has 4 categorical values).  It doesn't seem like a problem at first, but it does. Unless the categorical value has some order (i.e. cold, warm, hot) \"binarization\" of categorical value is necessary. Therefore One Hot Encoding is applied to transform decimal number assigned to *region* column to binary values. See this neat [article](https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f) for more explanation as to how label encoding is not enough to transform categorical values."},{"metadata":{"_uuid":"9e0629d51e808f477756d7a755c5e16ecf87ac3d"},"cell_type":"markdown","source":"**<h2>One Hot Encoding</h2>**\n\nOne Hot Encoding (OHE) utilized in this kernel is using module from scikit-learn. The OHE module takes decimal number assigned to categorical value as input. The OHE result then added to the end of the dataset column."},{"metadata":{"trusted":true,"_uuid":"f80c11305d3392cc8bd58f8cfbc4196f8694be83"},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\n# One hot encoder initialization\nohe_region = OneHotEncoder()\n\n# One hot encoding (OHE) to array\narr_ohe_region = ohe_region.fit_transform(data.region_encoded.values.reshape(-1,1)).toarray()\n\n# Convert array OHE to dataframe and append to existing dataframe\ndfOneHot = pd.DataFrame(arr_ohe_region, columns=['region_'+str(i) for i in range(arr_ohe_region.shape[1])])\ndata = pd.concat([data, dfOneHot], axis=1)\n\n# See the preprocessing result\ndata.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b68b652f25bb2e881d942e229b7f09842625b5df"},"cell_type":"markdown","source":"So far, we added the transformed categorical column to the end of the dataset column, but not all the column will be used for building the prediction model. So unnecessary column will be dropped, such as the categorical column and non-binary encoded column."},{"metadata":{"trusted":true,"_uuid":"df5a4e30ba1ea6e796b9e8b5e3d4f3f5bbb86b42"},"cell_type":"code","source":"# Drop categorical features\npreprocessed_data = data.drop(['sex','smoker','region',\n                               'region_encoded'], axis=1)\n\n# See the preprocessing final result\npreprocessed_data.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"**<h1>3. Data Preparation</h1>**\n\nThe pre-processed dataset then divided to training data and testing data. Training data is used for building the prediction model, while testing data is used for evaluating the prediction model."},{"metadata":{"trusted":true,"_uuid":"47f2221722ad9eb84e521843df8d8d4a1ea38f23"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Split the dataset to training and testing\ntrain, test = train_test_split(preprocessed_data, test_size=0.2)\n\n# Split the feature and the target\ntrain_y = train.charges.values\ntrain_x = train.drop(columns=['charges']).values\ntest_y = test.charges.values\ntest_x = test.drop(columns=['charges']).values\n\n# See the size of training and testing\nprint('Training features : ', train_x.shape)\nprint('Training target : ', train_y.shape)\nprint('Testing features : ', test_x.shape)\nprint('Testing target : ', test_y.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a5da71ea9e05a61fb2c7d054ffb45df8f834417e"},"cell_type":"markdown","source":"**<h1>4. Building Prediction Model (Training)</h1>**\n\nIn this kernel, 2 method are employed to building the prediction model : Linear Regression & Random Forest. The two method then evaluated and compared in term of performance."},{"metadata":{"trusted":true,"_uuid":"bd3fd136d8f40b11eac5ad580afff35652328c44"},"cell_type":"code","source":"from sklearn import linear_model\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Building linear regression model\nlr_model = linear_model.LinearRegression()\nlr_model.fit(train_x, train_y)\n\n# Building Random Forest model\nrf_model = RandomForestRegressor()\nrf_model.fit(train_x, train_y)\n\n# Make prediction\nlr_predict = lr_model.predict(test_x)\nrf_predict = rf_model.predict(test_x)\n\n# Sample the prediction\nsample_id = 7\nprint('Actual Charges : %.2f' % test_y[sample_id])\nprint('Linear Regression Prediction : %.2f' % lr_predict[sample_id])\nprint('Random Forest Prediction : %.2f' % rf_predict[sample_id])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dfc8c2b100ff702ec90da5c8db451931b093f394"},"cell_type":"markdown","source":"**<h1>5. Model Evaluation (Testing)</h1>**\n\nThe prediction made using testing data evaluated using *Mean Squared Error (MSE)* and R2-Score.  MSE is the average squared difference between predicted values and actual values. R2-Score (coefficient of determination) is regression score function. The result show that random forest model yield better prediction than linear regression indicated both by MSE and R2-Score."},{"metadata":{"trusted":true,"_uuid":"ab948743c46e5c29694e0314ffb318d42ae9cec0"},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, r2_score\nimport math\n\n# Evaluate prediction model using MSE\nlr_mse = mean_squared_error(test_y, lr_predict)\nprint('MSE-Linear Regression : %.2f (square-rooted)' % math.sqrt(lr_mse))\nrf_mse = mean_squared_error(test_y, rf_predict)\nprint('MSE-Random Forest : %.2f (square-rooted)' % math.sqrt(rf_mse))\n\n# Evaluate prediction model using R2-Score\nlr_r2 = r2_score(test_y, lr_predict)\nprint('R2-Linear Regression : %.2f' % lr_r2)\nrf_r2 = r2_score(test_y, rf_predict)\nprint('R2-Random Forest : %.2f' % rf_r2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"95dea341843d98f6474395dfc6731bc3b9b4e0ed"},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}