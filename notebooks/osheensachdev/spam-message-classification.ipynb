{"cells":[{"metadata":{"id":"Wqfz_rXXx8bx","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n\ndef get_data(train_file, test_file = None):\n    if test_file == None:\n        frame = pd.read_csv(train_file)\n        data = frame.values\n        np.random.shuffle(data)\n        return data\n    else:\n        train_frame = pd.read_csv(train_file)\n        test_frame = pd.read_csv(test_file)\n\n        train_data = train_frame.values\n        test_data = test_frame.values\n        np.random.shuffle(train_data)\n        np.random.shuffle(test_data)\n\n        return train_data, test_data\n\n\ndef get_training_testing_sets(train_file, test_file = None):\n    if test_file == None:\n        data = get_data(train_file)\n        train_data, test_data = train_test_split(data)\n    else:\n\n        train_data, test_data = get_data(train_file, test_file)\n\n    X_train = train_data[:, 1:]\n    Y_train = train_data[:, :1]\n    X_test = test_data[:, 1:]\n    Y_test = test_data[:, :1]\n\n    print(X_train.shape, X_test.shape)\n    \n    return X_train, Y_train, X_test, Y_test\n\n\n\n\ndata = get_data('../input/SPAM text message 20170820 - Data.csv')\nm = data.shape[0]\n\nprint(data[0])\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"id":"pl8UG6uG3pKR","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.preprocessing import LabelEncoder\nimport string\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\n\n\npunctuations = string.punctuation\nstopwords = stopwords.words('english')\nlemmatizer = WordNetLemmatizer()\n\nfor i in range(m):\n    data[i][1] = ''.join(j for j in data[i][1] if j not in punctuations)\n    data[i][1] = ' '.join(lemmatizer.lemmatize(j.lower()) for j in data[i][1].split() if j not in stopwords)\n\nprint(data[0])   \n\n\n","execution_count":null,"outputs":[]},{"metadata":{"id":"6PxLo--o3m2z","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"filtered_spam_data = ''\nfiltered_ham_data = ''\nfor i in range(data.shape[0]):\n    filtered_spam_data +=' '.join(j for j in data[i][1].split() if data[i][0] == 'spam')\n    filtered_ham_data +=' '.join(j for j in data[i][1].split() if data[i][0] == 'ham')\n\n \nfrom wordcloud import WordCloud\nfrom matplotlib import pyplot as plt\n%matplotlib inline\n\n\nx, y = np.ogrid[:300, :300]\nmask = (x - 150) ** 2 + (y - 150) ** 2 > 130 ** 2\nmask = 255 * mask.astype(int)\n\nwc = WordCloud(max_font_size=40, max_words=200, background_color='white', random_state=1337, mask=mask).generate(filtered_spam_data)\nplt.figure(figsize=(10,10))\nplt.imshow(wc, interpolation='bilinear')\nplt.axis(\"off\")\nplt.title(\"Spam Words\", fontsize=20)\nplt.show()\n\nwc = WordCloud(max_font_size=40, max_words=200, background_color='white', random_state=1337, mask=mask).generate(filtered_ham_data)\nplt.figure(figsize=(10,10))\nplt.imshow(wc, interpolation='bilinear')\nplt.axis(\"off\")\nplt.title(\"Ham Words\", fontsize=20)\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"id":"KVegRC0q3fy-","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"\n\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.preprocessing import LabelEncoder\n\n\n\n# cv = TfidfVectorizer(ngram_range=(1, 2))\ncv = TfidfVectorizer()\nX = cv.fit_transform(data[:, 1])\nprint(X[0])\n\nle = LabelEncoder()\nY = le.fit_transform(data[:, 0])\nprint(Y[0])\n\n\nX_test = X[:1500, :]\nX_train = X[1500:, :]\n\nY_test = Y[:1500]\nY_train = Y[1500:]\n\nprint('X_train', X_train.shape)\nprint('X_test', X_test.shape)\nprint('Y_train', Y_train.shape)\nprint('Y_test', Y_test.shape)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"id":"56UVOvvG1zlU","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import BernoulliNB\nfrom sklearn.svm import LinearSVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nimport warnings\n\nwith warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n    results = []\n    for clf, name in [(BernoulliNB(),'BernoulliNB'), (LinearSVC(C = 0.1), 'SVC'), (DecisionTreeClassifier(max_depth = 15), 'DecisionTreeClassifier', ), (LogisticRegression(C = 5), 'LogisticRegression') ]:\n    #     Y_train.reshape(Y_train.shape[0],)\n    #     Y_test.reshape(Y_test.shape[0])\n        clf.fit(X_train, Y_train)\n        \n        predictions = clf.predict(X_train)\n        training_accuracy = accuracy_score(predictions, Y_train)\n\n        m_test = X_test.shape[0]\n        predictions = clf.predict(X_test)\n        accuracy = accuracy_score(predictions, Y_test)\n        confusion = confusion_matrix(predictions, Y_test)\n\n        results.append([name, training_accuracy, accuracy, confusion])\n\nfor result in results:\n    print(result[0], result[1], result[2])\n    print(result[3])","execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"SpamClassification.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":1}