{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport spacy\nfrom sklearn.model_selection import train_test_split\nfrom nltk.tokenize import RegexpTokenizer\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\nimport string\nfrom string import punctuation\nimport collections\nfrom collections import Counter\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.model_selection import cross_val_score\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/amazon-music-reviews/Musical_instruments_reviews.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(['reviewerID', 'asin','reviewerName', 'unixReviewTime', 'helpful'], axis = 1)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['reviewText'].fillna('Null', inplace = True)\ndata.isna().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['overall'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rating(overall):\n    if (int(overall <= 3)):\n        return 0\n    else:\n        return 1\n        \ndata['rating'] = data['overall'].apply(rating)\ndata = data.drop(['overall'], axis = 1)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.rating.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Good and Bad reviews viz","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data.rating)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most of the reviews are good","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['reviewText'] = data['reviewText'] + data['summary']\ndata = data.drop(['summary'], axis = 1)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = pd.DataFrame(data['reviewText'])\ny = pd.DataFrame(data.rating)\ndata.reviewText = data.reviewText.astype('str')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* removing stop words\n* removing punctuations\n* tokenization\n* lemmatization\n* bow\n* tf-idf ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"nlp = spacy.load(\"en_core_web_sm\")\ntokenizer = RegexpTokenizer(r'\\w+')\nlemmatizer = WordNetLemmatizer()\nstop = set(stopwords.words('english'))\npunctuation = list(string.punctuation)\nstop.update(punctuation)\n\n            \ndef furnished(text):\n    final_text = []\n    for i in text.split():\n        if i.lower() not in stop:\n            word = lemmatizer.lemmatize(i)\n            final_text.append(word.lower())\n    return \" \".join(final_text)\n\n\n            \ndata.reviewText = data.reviewText.apply(furnished)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.reviewText.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Common words viz","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in data.reviewText:\n    global text\n    text = i.split()\n    \ncounter=Counter(text)\nmost=counter.most_common()\n\nx, y= [], []\nfor word,count in most[:20]:\n    if (word not in stop):\n        x.append(word)\n        y.append(count)\nplt.figure(figsize = (10,10))     \nsns.barplot(x=y,y=x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,x_test,y_train,y_test = train_test_split(data.reviewText,data.rating,test_size = 0.2 , random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#bow\ncv=CountVectorizer(min_df=0,max_df=1,binary=False,ngram_range=(1,3))\nbow_x_train = cv.fit_transform(x_train)\nbow_x_test = cv.transform(x_test)\n\nprint('bow_x_train:',bow_x_train.shape)\nprint('bow_x_test:',bow_x_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#tf-idf \ntv=TfidfVectorizer(min_df=0,max_df=1,use_idf=True,ngram_range=(1,3))\n\ntfidf_x_train =tv.fit_transform(x_train)\ntfidf_x_test =tv.transform(x_test)\n\nprint('tfidf_x_train:',tfidf_x_train.shape)\nprint('tfidf_x_test:',tfidf_x_test.shape)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model Fitting, Prediction and accuracy","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Naive Bayes\nnb = MultinomialNB()\n\n#fit\nbow = nb.fit(bow_x_train, y_train)\ntfidf = nb.fit(tfidf_x_train, y_train)\n\n#predict\nbow_predict = nb.predict(bow_x_test)\ntfidf_predict = nb.predict(tfidf_x_test)\n\n#accuracy\nnb_bow = accuracy_score(y_test, bow_predict)\nnb_tfidf = accuracy_score(y_test,tfidf_predict)\n\nprint('nb bow accuracy:', nb_bow)\nprint('tfidf accuracy:', nb_tfidf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#random forest\nrf = RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0)\n\n#fit\nbow = rf.fit(bow_x_train, y_train)\ntfidf = rf.fit(tfidf_x_train, y_train)\n\n#predict\nbow_predict = rf.predict(bow_x_test)\ntfidf_predict = rf.predict(tfidf_x_test)\n\n#accuracy\nrf_bow = accuracy_score(y_test, bow_predict)\nrf_tfidf = accuracy_score(y_test,tfidf_predict)\n\nprint('rf bow accuracy:', rf_bow)\nprint('rf tfidf accuracy:', rf_tfidf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Linear SVC\nls =  LinearSVC()\n\n#fit\nbow = ls.fit(bow_x_train, y_train)\ntfidf = ls.fit(tfidf_x_train, y_train)\n\n#predict\nbow_predict = ls.predict(bow_x_test)\ntfidf_predict = ls.predict(tfidf_x_test)\n\n#accuracy\nls_bow = accuracy_score(y_test, bow_predict)\nls_tfidf = accuracy_score(y_test,tfidf_predict)\n\nprint('ls bow accuracy:', ls_bow)\nprint('ls tfidf accuracy:', ls_tfidf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lr\nlr = LogisticRegression(random_state=0)\n\n#fit\nbow = lr.fit(bow_x_train, y_train)\ntfidf = lr.fit(tfidf_x_train, y_train)\n\n#predict\nbow_predict = lr.predict(bow_x_test)\ntfidf_predict = lr.predict(tfidf_x_test)\n\n#accuracy\nlr_bow = accuracy_score(y_test, bow_predict)\nlr_tfidf = accuracy_score(y_test,tfidf_predict)\n\nprint('lr bow accuracy:', lr_bow)\nprint('lr tfidf accuracy:', lr_tfidf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = {'accuracy': [nb_bow * 100, nb_tfidf * 100, rf_bow * 100, rf_tfidf * 100, lr_bow * 100, lr_tfidf * 100, ls_tfidf * 100, ls_bow * 100],\n                   'model': ['naive bayes bow', 'naive bayes tfidf', 'random forest bow', 'random forest tfidf', \n                                'logit bow', 'logit tfidf', 'SVM bow', 'SVM tfidf']}\ndf = pd.DataFrame(data, columns = ['accuracy', 'model'])\ndf.head(8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (17,7))\nsns.barplot(y = df.accuracy, x = df.model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"around the same accuracy of 89%","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}