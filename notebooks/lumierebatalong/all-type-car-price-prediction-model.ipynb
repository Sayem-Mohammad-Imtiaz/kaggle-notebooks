{"cells":[{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport statsmodels.api as sm\nfrom scipy.stats import normaltest\nimport holoviews as hv\nfrom holoviews import opts\nhv.extension('bokeh')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, cross_val_predict\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\nfrom sklearn.neighbors import KNeighborsRegressor \nfrom sklearn.preprocessing import StandardScaler, PolynomialFeatures, MinMaxScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LinearRegression\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create class\nclass car_price_model:\n    \"\"\"  **car_price_model** is the class for exploratory data \n        analysis and machine learning in each data car. \n        This class have 10 attributes that are given important:\n\n    - multi_categorical_plot\n\n    - distplot_multi\n\n    - boxplot_multi\n\n    - correlation_plot\n\n    - VIF\n\n    - learner_selection\n\n    - training_evaluate\n    \"\"\"\n    \n    def __init__(self, data=None, cols=None, name='price'):\n        \n        self.name = name # target\n        self.data = data # feature\n        self.cols = cols # feature columns name\n        self.listof_model = {'LinearRegression': LinearRegression(), \n                'KNeighborsRegression':KNeighborsRegressor(),\n                'RandomForestRegression': RandomForestRegressor(),\n               'GradientBoostingRegression': GradientBoostingRegressor(),\n                'XGBoostRegression': XGBRegressor(),\n                'adaboost':AdaBoostRegressor()} # list of different learner\n    \n    #Read csv file\n    def read(self, file):\n        return pd.read_csv(file)\n    \n    def multi_categorical_plot(self, data):\n    \n        \"\"\" plot a categorical feature\n        \n            data: float64 array  n_observationxn_feature\n        \n        \"\"\"\n        # Find a feature that type is object\n        string = []\n        for i in data.columns:\n            if data[i].dtypes == \"object\":\n                string.append(i)\n    \n        fig = plt.figure(figsize=(20,5))\n        fig.subplots_adjust(wspace=0.2, hspace = 0.3)\n        for i in range(1,len(string)+1):\n            ax = fig.add_subplot(2,3,i)\n            sns.countplot(x=string[i-1], data=data, ax=ax)\n            ax.set_title(f\" {string[i-1]} countplot\")\n            \n    def distplot_multi(self, data):\n        \"\"\" plot multi distplot\"\"\"\n    \n        \n        from scipy.stats import norm\n        cols = []\n        \n        #Feature that is int64 or float64 type \n        for i in data.columns:\n            if data[i].dtypes == \"float64\" or data[i].dtypes == 'int64':\n                cols.append(i)\n        \n        gp = plt.figure(figsize=(15,10))\n        gp.subplots_adjust(wspace=0.4, hspace=0.4)\n        for i in range(1, len(cols)+1):\n            ax = gp.add_subplot(2,3,i)\n            sns.distplot(data[cols[i-1]], fit=norm, kde=False)\n            ax.set_title('{} max. likelihood gaussian'.format(cols[i-1]))\n            \n    def boxplot_multi(self, data):\n        \n        \"\"\" plot multi box plot\n            hue for plotting categorical data\n        \"\"\"\n    \n        cols = []\n        for i in data.columns:\n            if data[i].dtypes == \"float64\" or data[i].dtypes == 'int64':\n                cols.append(i)\n    \n        gp = plt.figure(figsize=(15,10))\n        gp.subplots_adjust(wspace=0.4, hspace=0.4)\n        for i in range(1, len(cols)+1):\n            ax = gp.add_subplot(2,3,i)\n            sns.boxplot(x = cols[i-1], data=data)\n            ax.set_title('Boxplot for {}'.format(cols[i-1]))\n            \n    def correlation_plot(self, data, vrs= 'price'):\n    \n        \"\"\"\n        This function plot only a variable that are correlated with a target  \n        \n            data: array m_observation x n_feature\n            vrs:  target feature (n_observation, )\n            cols: interested features\n        \"\"\"\n        \n        cols = []\n        for i in data.columns:\n            if data[i].dtypes == \"float64\" or data[i].dtypes == 'int64':\n                cols.append(i)\n                \n        feat = list(set(cols) - set([vrs]))\n    \n        fig = plt.figure(figsize=(15,10))\n        fig.subplots_adjust(wspace = 0.3, hspace = 0.25)\n        for i in range(1,len(feat)+1):\n        \n            gp = data.groupby(feat[i-1]).agg('mean').reset_index()\n        \n            if len(feat) < 3:\n                ax = fig.add_subplot(1,3,i)\n            else:\n                n = len(feat)//2 + 1\n                ax = fig.add_subplot(2,n,i)\n            \n            ax.scatter(data[feat[i-1]], data[vrs], alpha=.25)\n            ax.plot(gp[feat[i-1]], gp[vrs], 'r-', label='mean',  linewidth=1.5)\n            ax.set_xlabel(feat[i-1])\n            ax.set_ylabel(vrs)\n            ax.set_title('Plotting data {0} vs {1}'.format(vrs, feat[i-1]))\n            ax.legend(loc='best')\n            \n    # Standardize data\n    def standardize(self, data):\n        data = (data - data.mean())/data.std()\n        return data\n            \n            \n    def VIF(self, data):\n        \"\"\" \n        This function compute variance inflation factor for data that all feature are multicolinear\n        \n        if the outcome is 1, it is okay\n        if it is between 1 and 5, it shows low to average colinearity, and above 5 generally means highly \n        redundant and variable should be dropped\n        \"\"\" \n        # Apply the standardize method to each feature and save it to a new data\n        std_data = data.apply(self.standardize, axis=0)\n    \n        from statsmodels.stats.outliers_influence import variance_inflation_factor\n    \n        vif = pd.DataFrame()\n        vif['VIF_FACTOR'] = [variance_inflation_factor(std_data.values, i) for i in range(std_data.shape[1])]\n    \n        vif['feature'] = std_data.columns\n    \n        return vif\n    \n    \n    def split_data(self):\n        \"\"\"\n        This function splits data to train set and target set\n        \n        data: matrix feature n_observation x n_feature dimension\n        name: target  (n_observation, )\n        cols: interested feature\n        \n        return xtrain, xtest, ytrain, ytest\n        \"\"\"\n    \n        train = self.data[self.cols]\n        target = self.data[self.name]\n    \n        return train_test_split(train, target, random_state=42, test_size=0.2, shuffle=True)\n    \n    def spearman_pearson_correlation(self, data):\n        \n        \n        gp = plt.figure(figsize=(15,5))\n        cols = ['pearson', 'spearman']\n        gp.subplots_adjust(wspace=0.4, hspace=0.4)\n        for i in range(1, len(cols)+1):\n            ax = gp.add_subplot(1,2,i)\n            sns.heatmap(data.corr(method=cols[i-1]), annot=True)\n            ax.set_title('{} correlation'.format(cols[i-1]))\n        \n        \n        plt.show()\n    \n    \n    def learner_selection(self):\n\n        \"\"\"\n            This function compute differents score measure like cross validation,\n            r2, root mean squared error and mean absolute error.\n            listof_model: dictionary type containing different model algorithm.     \n        \"\"\" \n    \n        result = {}\n        \n        x, _, y, _ = self.split_data() # take only xtrain and ytrain\n    \n        for cm in list(self.listof_model.items()):\n        \n            name = cm[0]\n            model = cm[1]\n        \n            cvs = cross_val_score(model, x, y, cv=10).mean()\n            ypred = cross_val_predict(model, x, y, cv=10)\n            r2 = r2_score(y, ypred)\n            mse = mean_squared_error(y, ypred)\n            mae = mean_absolute_error(y, ypred)\n            rmse = np.sqrt(mse)\n        \n            result[name] = {'cross_val_score': cvs, 'rmse': rmse, 'mae': mae, 'r2': r2}\n        \n            print('{} model done !!!'.format(name))\n        \n        \n        return pd.DataFrame(result)\n    \n    \n    def training_evaluate(self, algorithm):\n        \n        \"\"\"This function train and evaluate our model to find r2, rmse and mae\"\"\"\n        \n        result = {}\n        xtrain, xtest, ytrain, ytest = self.split_data()\n        \n        learner = self.listof_model[algorithm] # learner selected in model_selection function\n        \n        model = learner.fit(xtrain, ytrain)\n        ypred = model.predict(xtest)\n        \n        r2 = learner.score(xtest, ytest)\n        rmse =  np.sqrt(mean_squared_error(ytest, ypred))\n        mae = mean_absolute_error(ytest, ypred)\n        \n        result['car price measure'] = {'r2':round(r2, 3),  'rmse':round(rmse, 3), 'mae':round(mae, 3)}\n        \n        return  pd.DataFrame(result)\n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### car_price_model class explaination\n\n**car_price_model** is the class that I use to do exploratory data analysis and machine learning in each data car. This class have 10 attributes that are:\n\n- multi_categorical_plot\n\n- distplot_multi\n\n- boxplot_multi\n\n- spearman_pearson_correlation\n\n- correlation_plot\n\n- VIF\n\n- learner_selection\n\n- training_evaluate\n\nThese are the function that we are going to use in this notebook. \n\n**N.B: We are making prediction price for 5 cars (focus, audi, ford, toyota, skoda)** ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"car1 = '/kaggle/input/used-car-dataset-ford-and-mercedes/focus.csv'\ncar2 = '/kaggle/input/used-car-dataset-ford-and-mercedes/audi.csv'\ncar3 = '/kaggle/input/used-car-dataset-ford-and-mercedes/ford.csv'\ncar4 = '/kaggle/input/used-car-dataset-ford-and-mercedes/toyota.csv'\ncar5 = '/kaggle/input/used-car-dataset-ford-and-mercedes/skoda.csv'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = car_price_model()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Focus car price","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"focus = model.read(car1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"focus.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"focus.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualization, correlation, VIF, learner selection, training and evaluation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model.multi_categorical_plot(focus)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = 'model', hue='fuelType', data=focus)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"focus.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.distplot_multi(focus)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.boxplot_multi(focus) # we see well that our maximun likelihood gaussian go with our boxplot. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.spearman_pearson_correlation(focus)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.correlation_plot(focus)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"with this two correlations we can see that **price is most correlated with mileage and year**. also year well correlated with mileage. We use VIF to see how this correlation are.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"focus_cols = ['mileage', 'year', 'engineSize'] #take columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.VIF(focus[focus_cols])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"focus_model = car_price_model(data=focus, cols=focus_cols) #select best algorithm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"focus_model.learner_selection()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"focus_model.training_evaluate('GradientBoostingRegression')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We have** $R^2 = 92.1\\%$ **for Focus car**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Audi car price","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"audi = model.read(car2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"audi.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"audi.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualization, correlation, VIF, learner selection, training and evaluation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model.multi_categorical_plot(audi)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"audi.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.distplot_multi(audi)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.boxplot_multi(audi)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.spearman_pearson_correlation(audi)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.correlation_plot(audi)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"audi_cols = ['year', 'mileage', 'mpg', 'engineSize', 'tax'] #there is or not necessary to take tax feature","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.VIF(audi[audi_cols]) #all vif factor of feature are acceptable","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#select learner\naudi_model = car_price_model(data=audi, cols=audi_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"audi_model.learner_selection()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"audi_model.training_evaluate('XGBoostRegression')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We have** $R^2 = 94.5\\%$ **for Audi car**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Ford car price","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ford = model.read(car3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ford.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ford.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ford = ford.replace(to_replace=2060, value=2016) #some errors","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualization, correlation, VIF, learner selection, training and evaluate","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model.multi_categorical_plot(ford) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ford.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.distplot_multi(ford)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.boxplot_multi(ford)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.spearman_pearson_correlation(ford)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.correlation_plot(ford)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"ford_cols = ['mileage', 'year', 'tax', 'engineSize', 'mpg']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.VIF(ford[ford_cols])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ford_model = car_price_model(data=ford, cols=ford_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ford_model.learner_selection()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ford_model.training_evaluate('XGBoostRegression')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We get** $R^2 = 91.6\\%$ **for Ford car**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Toyota car price","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"toyota = model.read(car4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"toyota.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"toyota.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualization, correlation, VIF, learner selection, training and evaluate","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model.multi_categorical_plot(toyota)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"toyota.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.distplot_multi(toyota)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.boxplot_multi(toyota)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.spearman_pearson_correlation(toyota)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.correlation_plot(toyota)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"toyota_cols = ['engineSize','year','tax', 'mileage', 'mpg']","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"model.VIF(toyota[toyota_cols])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"toyota_model = car_price_model(data=toyota, cols=toyota_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"toyota_model.learner_selection()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"toyota_model.training_evaluate('XGBoostRegression')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We obtain** $R^2 = 96.2\\%$ **for Toyota car.**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Skoda car price","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"skoda = model.read(car5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skoda.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skoda.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualization, correlation, VIF, learner selection, training and evaluate","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model.multi_categorical_plot(skoda)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skoda.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.distplot_multi(skoda)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.boxplot_multi(skoda)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.spearman_pearson_correlation(skoda)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.correlation_plot(skoda)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skoda_cols = ['year', 'engineSize', 'mileage', 'tax', 'mpg']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.VIF(skoda[skoda_cols])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skoda_model = car_price_model(data=skoda, cols=skoda_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skoda_model.learner_selection()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skoda_model.training_evaluate('XGBoostRegression')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We obtain** $R^2 = 92.6\\%$ **for Skoda car.**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Summarize\n\nFor this five cars, we obtain de $R^2$ score:\n\n> Skoda car $92.6\\%$\n\n> Toyota car $96.2\\%$\n\n> Ford car $91.6\\%$\n\n> Audi car $94.5\\%$\n\n> Focus car $92.1\\%$\n\n**For the rest of car, you can continue to find a score. If you do not understand my model or method be free to ask your question.**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Update","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}