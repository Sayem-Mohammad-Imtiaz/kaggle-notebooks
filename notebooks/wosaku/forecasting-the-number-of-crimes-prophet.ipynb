{"metadata":{"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"},"language_info":{"version":"3.6.1","pygments_lexer":"ipython3","file_extension":".py","mimetype":"text/x-python","nbconvert_exporter":"python","codemirror_mode":{"version":3,"name":"ipython"},"name":"python"}},"nbformat":4,"cells":[{"metadata":{},"source":"# Introduction\n\nFollowing on my series __*Crime in Vancouver*__, the next step is to forecast the number of crimes. For this task, I'll be using the Facebook Prophet package.","cell_type":"markdown"},{"metadata":{"_uuid":"2aa253b15480e7430a54c3a0702e394e16d04920","_cell_guid":"c774bc77-edfd-4599-a832-c8676b2aa14a"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib auto\nfrom fbprophet import Prophet","cell_type":"code","execution_count":1},{"metadata":{},"outputs":[],"source":"# Importing the data\ndf = pd.read_csv('../input/crime.csv')\ndf.head()","cell_type":"code","execution_count":2},{"metadata":{},"outputs":[],"source":"# Using pandas function to_datetime to convert it to a datetime data type\ndf['DATE'] = pd.to_datetime({'year':df['YEAR'], 'month':df['MONTH'], 'day':df['DAY']})","cell_type":"code","execution_count":3},{"metadata":{},"outputs":[],"source":"# Group the data by date\ndf = df.groupby('DATE').count()['TYPE'].to_frame()","cell_type":"code","execution_count":4},{"metadata":{},"outputs":[],"source":"# The input must be a data frame with two columns 'ds' and 'y' \n# (ds is the date and y is the number of crimes). Let's adjust it.\ndf.reset_index(inplace=True)\ndf.columns = ['ds','y']\ndf.head()","cell_type":"code","execution_count":5},{"metadata":{},"source":"# Using Prophet\n\nOne interesting feature of Prophet is that it is *\"robust to outliers, missing data, and dramatic changes in your time series\"*.\n\nSo let's try 3 different models:\n\n* Model 1 - plain (without removing outliers).\n* Model 2 - removing outliers.\n* Model 3 - including holidays.\n\n<br>\n## Model 1 - Plain","cell_type":"markdown"},{"metadata":{"collapsed":true},"outputs":[],"source":"# Starting by making a copy of the data frame\ndf_m1 = df.copy()","cell_type":"code","execution_count":6},{"metadata":{"collapsed":true},"outputs":[],"source":"# The only transformation we'll do is a 'log transformation' of y\ndf_m1['y'] = np.log(df_m1['y'])","cell_type":"code","execution_count":7},{"metadata":{"collapsed":true},"outputs":[],"source":"# Prophet code are basically these lines\nm1_plain = Prophet()\nm1_plain.fit(df_m1)\n\n# Let's try a forecast for 365 days\nfuture = m1_plain.make_future_dataframe(periods=365)\nforecast_m1 = m1_plain.predict(future)","cell_type":"code","execution_count":8},{"metadata":{},"outputs":[],"source":"m1_plain.plot(forecast_m1)","cell_type":"code","execution_count":9},{"metadata":{},"outputs":[],"source":"m1_plain.plot_components(forecast_m1)","cell_type":"code","execution_count":10},{"metadata":{},"source":"This is interesting. Prophet displays the general, weekly and monthly trends.\n* In the first subplot, we can see that the number of crimes decreased until 2011 and then start increasing.\n* The weekly subplot shows that Friday and Saturday have more crimes.\n* The yearly subplot shows that summers months have higher number of crimes.\n\nNow let's measure the error for this model. For that, I'll be using the *Mean Absolute Percentage Error (MAPE)*.","cell_type":"markdown"},{"metadata":{"collapsed":true},"outputs":[],"source":"# First, let's get some useful variables: \"y\" for the actual value and \"n\" for the number of observations.\ny = df['y'].to_frame()\ny.index = df['ds']\nn = np.int(y.count())","cell_type":"code","execution_count":11},{"metadata":{"collapsed":true},"outputs":[],"source":"# The forecast is 'log transformed', so we need to 'inverse' it back by using the exp\nforecast_m1_exp = np.exp(forecast_m1[['yhat','yhat_lower','yhat_upper']])\nforecast_m1_exp.index = forecast_m1['ds']","cell_type":"code","execution_count":12},{"metadata":{},"outputs":[],"source":"# Now let's calculate the MAPE for m1\nerror = forecast_m1_exp['yhat'] - y['y']\nMAPE_m1 = (error/y['y']).abs().sum()/n *100\nround(MAPE_m1,2)","cell_type":"code","execution_count":13},{"metadata":{},"source":"## Model 2 - Removing outliers","cell_type":"markdown"},{"metadata":{"collapsed":true},"outputs":[],"source":"# Make another copy of the data frame as m2\ndf_m2 = df.copy()","cell_type":"code","execution_count":14},{"metadata":{"collapsed":true},"outputs":[],"source":"# Define the Upper Control Limit and Lower Control Limit as 3 standard deviations from the mean\nucl = df_m2.mean() + df_m2.std()*3\nlcl = df_m2.mean() - df_m2.std()*3","cell_type":"code","execution_count":15},{"metadata":{},"outputs":[],"source":"# Print the number of outliers found\nprint('Above 3 standard deviations: ', df_m2[df_m2['y'] > ucl['y']]['y'].count(), 'entries')\nprint('Below 3 standard deviations: ', df_m2[df_m2['y'] < lcl['y']]['y'].count(), 'entries')","cell_type":"code","execution_count":16},{"metadata":{"collapsed":true},"outputs":[],"source":"# Remove them by setting their value to None. Prophet says it can handle null values.\ndf_m2.loc[df_m2['y'] > ucl['y'], 'y'] = None\ndf_m2.loc[df_m2['y'] < lcl['y'], 'y'] = None","cell_type":"code","execution_count":17},{"metadata":{"collapsed":true},"outputs":[],"source":"# Log transformation\ndf_m2['y'] = np.log(df_m2['y'])","cell_type":"code","execution_count":18},{"metadata":{"collapsed":true},"outputs":[],"source":"# Run Prophet using model 2\nm2_no_outlier = Prophet()\nm2_no_outlier.fit(df_m2)\nfuture = m2_no_outlier.make_future_dataframe(periods=365)\nforecast_m2 = m2_no_outlier.predict(future)","cell_type":"code","execution_count":19},{"metadata":{"collapsed":true},"outputs":[],"source":"# Inverse the log\nforecast_m2_exp = np.exp(forecast_m2[['yhat','yhat_lower','yhat_upper']])\nforecast_m2_exp.index = forecast_m2['ds']","cell_type":"code","execution_count":20},{"metadata":{},"outputs":[],"source":"# Calculate the error\nerror = forecast_m2_exp['yhat'] - y['y']\nMAPE_m2 = (error/y['y']).abs().sum()/n *100\nround(MAPE_m2,2)","cell_type":"code","execution_count":21},{"metadata":{},"source":"With Model 2 by removing the outliers, the model performed only a little better than the plain model. This is probably because the outliers that were considered were only a few data points (18 of 5295). They were not a sequence of data points that compromised the trend, so in this case, they didn't make much difference. Prophet handled them well in the first plain model.\n\n<br>\n## Model 3 - Holidays\n\nProphet has a nice flexibility of including events (holidays) that impact the trend. To do that, we need to create a data frame with dates (past and future). Another cool thing is that we can add a 'lower' and 'upper' window. For example, if we have Christmas as a holiday and we want to add the Christmas' Eve, all we need to do is to add a 'lower window' of -1.\n\nI'll be using three sets of holidays. \n* One with no added window: Mother's day, Victoria Day, Canada Day, Labour Day, Remembrance Day, Christmas.\n* Another with a -1 lower and 1 upper window: Halloween, New Year's\n* And another with a -2 lower and a 1 upper window: BC Day and Thanksgiving (long weekends)","cell_type":"markdown"},{"metadata":{"collapsed":true},"outputs":[],"source":"holidays_0 = pd.DataFrame({\n        'holiday': '0 window',\n        'ds' :pd.to_datetime(\n            ['2003-05-11','2004-05-09','2005-05-08','2006-05-14','2007-05-13','2008-05-11','2009-05-10','2010-05-09','2011-05-08','2012-05-13','2013-05-12','2014-05-11','2015-05-10','2016-05-08','2017-05-14','2018-05-13','2019-05-12','2020-05-10','2003-05-19','2004-05-24','2005-05-23','2006-05-22','2007-05-21','2008-05-19','2009-05-18','2010-05-24','2011-05-23','2012-05-21','2013-05-20','2014-05-19','2015-05-18','2016-05-23','2017-05-22','2018-05-21','2019-05-20','2020-05-18','2003-07-01','2004-07-01','2005-07-01','2006-07-01','2007-07-01','2008-07-01','2009-07-01','2010-07-01','2011-07-01','2012-07-01','2013-07-01','2014-07-01','2015-07-01','2016-07-01','2017-07-01','2018-07-01','2019-07-01','2020-07-01','2003-09-01','2004-09-06','2005-09-05','2006-09-04','2007-09-03','2008-09-01','2009-09-07','2010-09-06','2011-09-05','2012-09-03','2013-09-02','2014-09-01','2015-09-07','2016-09-05','2017-09-04','2018-09-03','2019-09-02','2020-09-07','2003-11-11','2004-11-11','2005-11-11','2006-11-11','2007-11-11','2008-11-11','2009-11-11','2010-11-11','2011-11-11','2012-11-11','2013-11-11','2014-11-11','2015-11-11','2016-11-11','2017-11-11','2018-11-11','2019-11-11','2020-11-11','2003-12-25','2004-12-25','2005-12-25','2006-12-25','2007-12-25','2008-12-25','2009-12-25','2010-12-25','2011-12-25','2012-12-25','2013-12-25','2014-12-25','2015-12-25','2016-12-25','2017-12-25','2018-12-25','2019-12-25','2020-12-25']),\n        'lower_window' : 0,\n        'upper_window' : 0,       \n    })\n\nholidays_1 = pd.DataFrame({\n        'holiday': '1 window',\n        'ds' :pd.to_datetime(\n            ['2003-10-31','2004-10-31','2005-10-31','2006-10-31','2007-10-31','2008-10-31','2009-10-31','2010-10-31','2011-10-31','2012-10-31','2013-10-31','2014-10-31','2015-10-31','2016-10-31','2017-10-31','2018-10-31','2019-10-31','2020-10-31','2003-01-01','2004-01-01','2005-01-01','2006-01-01','2007-01-01','2008-01-01','2009-01-01','2010-01-01','2011-01-01','2012-01-01','2013-01-01','2014-01-01','2015-01-01','2016-01-01','2017-01-01','2018-01-01','2019-01-01','2020-01-01']),\n        'lower_window' : -1,\n        'upper_window' : 1,       \n    })\n\nholidays_2 = pd.DataFrame({\n        'holiday': '2 window',\n        'ds' :pd.to_datetime(\n            ['2003-08-04','2004-08-02','2005-08-01','2006-08-07','2007-08-06','2008-08-04','2009-08-03','2010-08-02','2011-08-01','2012-08-06','2013-08-05','2014-08-04','2015-08-03','2016-08-01','2017-08-07','2018-08-06','2019-08-05','2020-08-03','2003-10-13','2004-10-11','2005-10-10','2006-10-09','2007-10-08','2008-10-13','2009-10-12','2010-10-11','2011-10-10','2012-10-08','2013-10-14','2014-10-13','2015-10-12','2016-10-10','2017-10-09','2018-10-08','2019-10-14','2020-10-12']),\n        'lower_window' : -2,\n        'upper_window' : 1,       \n    })\n\n# Concatenate all 3 df into 1\nholidays_list = pd.concat((holidays_0, holidays_1, holidays_2))","cell_type":"code","execution_count":22},{"metadata":{"collapsed":true},"outputs":[],"source":"# Now we pass the holidays variable when we instantiate Prophet\nm3_holidays = Prophet(holidays=holidays_list)\nm3_holidays.fit(df_m1)\nfuture = m3_holidays.make_future_dataframe(periods=365)\nforecast_m3 = m3_holidays.predict(future)","cell_type":"code","execution_count":23},{"metadata":{"collapsed":true},"outputs":[],"source":"# Inverse the log\nforecast_m3_exp = np.exp(forecast_m3[['yhat','yhat_lower','yhat_upper']])\nforecast_m3_exp.index = forecast_m3['ds']","cell_type":"code","execution_count":24},{"metadata":{},"outputs":[],"source":"# Calculate error\nerror = forecast_m3_exp['yhat'] - y['y']\nMAPE_m3 = (error/y['y']).abs().sum()/n *100\nround(MAPE_m3,2)","cell_type":"code","execution_count":25},{"metadata":{},"source":"## Comparing the models","cell_type":"markdown"},{"metadata":{},"outputs":[],"source":"print('M1:', round(MAPE_m1,2), '--> Plain','\\n')\nprint('M2:', round(MAPE_m2,2), '--> Without outliers','\\n')\nprint('M3:', round(MAPE_m3,2),'--> Plain with holidays','\\n')","cell_type":"code","execution_count":26},{"metadata":{},"source":"Model 3, with the inclusion of holidays, had a better result. Let's check it.","cell_type":"markdown"},{"metadata":{},"outputs":[],"source":"m3_holidays.plot(forecast_m3)","cell_type":"code","execution_count":27},{"metadata":{},"source":"We can see that there is a peak every year that model 1 didn't have. This is the result of adding a holiday that had a relevant impact. This is going to be reflected in the forecast.\n\n<br>\n## Conclusion\n\nFinally, to see the forecasted numbers, we can check the forecast data frame:","cell_type":"markdown"},{"metadata":{},"outputs":[],"source":"start = '2017-09-01'\nend = '2017-09-05'\nforecast_m3_exp[(forecast_m3_exp.index >= start) & (forecast_m3_exp.index <= end)].astype(int)","cell_type":"code","execution_count":28}],"nbformat_minor":1}