{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<center>\n    <h1>   \n         Clinical Features Model to Predict Stroke \n    </h1>\n</center>\n \n<center><img src=\"https://image-cdn.medkomtek.com/_A7vRjeLyfZqshjKM71BAmEmmKU=/673x373/smart/klikdokter-media-buckets/medias/2309095/original/050687900_1572589916-Stroke-infarct-By-peterschreiber.media-Shutterstock_1423084877.jpg\" alt=\"Stroke\" width=\"600\" ></center>\n\n<center> <h3> Please Upvote if you like the work ðŸ˜Š </h3></center>\n\n<center>Don't hesitate to give your comment on this notebook. It gives me motivation to improve the analysis in the future</center>\n\n# Introduction\nThis program is used to find the right model for the Telecomunication dataset. \n\n# Contents\nContents:\n\n* [1. Load Packages](#1)\n* [2. Load Dataset](#2)\n* [3. Drop NaN and duplicates values](#3)\n* [4. Do Explanatory Data Analysis](#4)\n* [5. Mapping Sentiment](#5) \n* [6. Modelling](#6)","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"1\"></a>\n    \n# <font size=\"+2\" color=\"indigo\"><b>1. Load Packages</b></font><br>","metadata":{}},{"cell_type":"code","source":"# runtime\nimport timeit\n\n# Data manipulation\nimport pandas as pd\nimport numpy as np\n\n# Data visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\n\n# preprocessing\nfrom sklearn.feature_selection import RFE\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, Normalizer\n\n# Ml model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\n\nfrom collections import Counter\nfrom sklearn.datasets import make_classification\nfrom imblearn.over_sampling import SMOTE\nfrom matplotlib import pyplot\nfrom numpy import where\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import roc_auc_score\n\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\nfrom sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n\nnp.warnings.filterwarnings('ignore')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"2\"></a>\n    \n# <font size=\"+2\" color=\"indigo\"><b>2. Load Dataset</b></font><br>","metadata":{}},{"cell_type":"code","source":"data_df=pd.read_csv(\"/kaggle/input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv\")\ndata_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"3\"></a>\n    \n# <font size=\"+2\" color=\"indigo\"><b>3. Find Null and Duplicate Values</b></font><br>","metadata":{}},{"cell_type":"code","source":"display(data_df.isnull().sum())\nprint(\"====///====\")\ndisplay(data_df.duplicated().sum())\nprint(\"====///====\")\ndisplay(data_df.info())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Found null values in bmi columns --> needs to be treated","metadata":{}},{"cell_type":"code","source":"data_df=data_df.dropna(axis='rows')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"4\"></a>\n    \n# <font size=\"+2\" color=\"indigo\"><b>4. Exploratory Data Analysis</b></font><br>","metadata":{}},{"cell_type":"markdown","source":"## <font size=\"+1\" color=\"indigo\"><b>Affect of Gender on Stroke</b></font><br> ","metadata":{}},{"cell_type":"code","source":"# Data visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\n\nch = {1: 'Having Stroke', 0: 'Not Having Stroke'}\nanalyze_data=data_df.copy()\nanalyze_data['stroke'] = data_df['stroke'].map(ch)\n\ngender = analyze_data.groupby(['gender', 'stroke']).agg({'stroke': 'count'}).rename(columns = {'stroke': 'count'}).reset_index()\ngender","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.sunburst(gender, path = ['gender', 'stroke'], values = 'count', color = 'gender', title = 'Affect of Age on Stroke', width = 600, height = 600)\nfig.update_traces(textinfo = 'label + percent parent')\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font size=\"+1\" color=\"indigo\"><b>Distribution of Age of People Having Stroke</b></font><br> ","metadata":{}},{"cell_type":"code","source":"fig = plt.figure()\nax = fig.add_subplot(1, 1, 1)\n\nvalue = analyze_data[analyze_data['stroke']=='Having Stroke']['age']\n\nax.hist(value, bins=10)\nplt.title('Distribution of Age of People Having Stroke')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font size=\"+1\" color=\"indigo\"><b>Distribution of BMI of People Having Stroke</b></font><br> \n\nFor certain individuals, BMI is a reliable measure of body fatness. It is used to scan for weight ranges that could be associated with health issues.","metadata":{}},{"cell_type":"code","source":"fig = plt.figure()\nax = fig.add_subplot(1, 1, 1)\n\nvalue = analyze_data[analyze_data['stroke']=='Having Stroke']['bmi']\n\nax.hist(value, bins=10)\nplt.title('Distribution of BMI of People Having Stroke')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font size=\"+1\" color=\"indigo\"><b>Affect of Residence_type on Stroke</b></font><br> ","metadata":{}},{"cell_type":"code","source":"Residence_type = analyze_data.groupby(['Residence_type', 'stroke']).agg({'stroke': 'count'}).rename(columns = {'stroke': 'count'}).reset_index()\n\nfig = px.sunburst(Residence_type, path = ['Residence_type', 'stroke'], values = 'count', color = 'Residence_type', title = 'Affect of Residence_type on Stroke', width = 600, height = 600)\nfig.update_traces(textinfo = 'label + percent parent')\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font size=\"+1\" color=\"indigo\"><b>Affect of smoking on Stroke</b></font><br> ","metadata":{}},{"cell_type":"code","source":"smoking_status = analyze_data.groupby(['smoking_status', 'stroke']).agg({'stroke': 'count'}).rename(columns = {'stroke': 'count'}).reset_index()\n\nfig = px.sunburst(smoking_status, path = ['smoking_status', 'stroke'], values = 'count', color = 'smoking_status', title = 'Affect of smoking_status on Stroke', width = 600, height = 600)\nfig.update_traces(textinfo = 'label + percent parent')\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = sns.countplot(x=\"stroke\", data=data_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> We need to use SMOTE method in order to overcome the problem of unbalanced data","metadata":{}},{"cell_type":"markdown","source":"<a id=\"5\"></a>\n    \n# <font size=\"+2\" color=\"indigo\"><b>5. Label Encoding</b></font><br>","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = data_df.drop(['stroke','id'], axis = 1)\ny = data_df['stroke']\n\n# Split feature as categorical and continuous features\n\ncat_features=X.select_dtypes(exclude=np.number).columns\ncont_features=X.select_dtypes(include=[np.number,'float64','int64']).columns\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Label Encoder for Categorical Features\ndef label_encoder(df):\n    for i in cat_features:\n        le = LabelEncoder()\n        df[i] = le.fit_transform(df[i])\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Standard Scaler for Continuous Features\nsc = StandardScaler()\nX[cont_features] = sc.fit_transform(X[cont_features])\n\n# Label encoding for Categorical Features\nX = label_encoder(X)\n\nX.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"6\"></a>\n    \n# <font size=\"+2\" color=\"indigo\"><b>6. Exploratory Data Analysis (Part 2)</b></font><br>","metadata":{}},{"cell_type":"code","source":"data_df2=X.join(y)\ncorrmat = data_df2.corr(method='pearson')\nf, ax = plt.subplots(figsize=(24, 16))\nsns.heatmap(corrmat, ax=ax, cmap=\"YlGnBu\", linewidths=0.1, annot=True)\ndata_df2.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"7\"></a>\n    \n# <font size=\"+2\" color=\"indigo\"><b>7. Modelling</b></font><br>\n## <font size=\"+1\" color=\"indigo\"><b>Data Splitting</b></font><br>","metadata":{}},{"cell_type":"code","source":"oversample = SMOTE()\nX, y = oversample.fit_resample(X, y)\nX_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.15,random_state=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font size=\"+1\" color=\"indigo\"><b>XGBClassifier</b></font><br>","metadata":{}},{"cell_type":"code","source":"Model=XGBClassifier(eval_metric=\"logloss\")\n#pipeModel=Pipeline([('scaler', StandardScaler()), ('model', Model)])\n\n# the benefit of using K-Fold is that we could calculate the cross validation value using some of the methods of scoring \nkfold = KFold(n_splits=10, shuffle=True, random_state=0)\ncv_results = cross_val_score(Model, X_train, y_train, cv=kfold)\n\nModel.fit(X_train, y_train)\n# this is the scaled XGBClassifier\nprint('Score for XGBClassifier method:', Model.score(X_test, y_test))\n\n# the mean result (10 data) of negative mean squared error\nprint('Score for XGBClassifier method using cross_val_score:', cv_results.mean())\ny_pred = Model.predict(X_test)\ny_prob = Model.predict_proba(X_test)[:,1]\n\n#print(mean_squared_error(y_test, y_pred))\nprint(classification_report(y_test,y_pred))\nprint(\"roc_auc score:\", roc_auc_score(y_test,y_prob))\n\n# Roc curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nprint('\\n\\n-----------------------------------------------------\\n\\n')\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (8, 8))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()\n\nprint('\\n\\n-----------------------------------------------------\\n\\n')\nplt.figure(figsize = (8, 8))\nfrom matplotlib import pyplot\nfrom xgboost import plot_importance\nplot_importance(Model, max_num_features=10) # top 10 most important features\nplt.show()\n\nprint('\\n\\n-----------------------------------------------------\\n\\n')\narr=confusion_matrix(y_test, y_pred)\ndf_cm = pd.DataFrame(arr, range(2), range(2))\nplt.figure(figsize = (8, 8))\nsns.heatmap(arr, cmap = 'Blues', annot = True, fmt = 'd', annot_kws = {'fontsize': 15},\n           yticklabels = ['Stayed', 'Left'], xticklabels = ['Predicted stayed', 'Predicted left'])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font size=\"+1\" color=\"indigo\"><b>Logistic Regression</b></font><br>","metadata":{}},{"cell_type":"code","source":"Model=LogisticRegression(random_state = 22)\n#pipeModel=Pipeline([('scaler', StandardScaler()), ('model', Model)])\n\n# the benefit of using K-Fold is that we could calculate the cross validation value using some of the methods of scoring \nkfold = KFold(n_splits=10, shuffle=True, random_state=0)\ncv_results = cross_val_score(Model, X_train, y_train, cv=kfold)\n\nModel.fit(X_train, y_train)\n\nprint('Score for Logistic Regression method:', Model.score(X_test, y_test))\n\n# the mean result (10 data) of negative mean squared error\nprint('Score for Logistic Regression method using cross_val_score:', cv_results.mean())\ny_pred = Model.predict(X_test)\ny_prob = Model.predict_proba(X_test)[:,1]\n\n#print(mean_squared_error(y_test, y_pred))\nprint(classification_report(y_test,y_pred))\nprint(\"roc_auc score:\", roc_auc_score(y_test,y_prob))\n\n# Roc curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nprint('\\n\\n-----------------------------------------------------\\n\\n')\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (8, 8))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()\n\nprint('\\n\\n-----------------------------------------------------\\n\\n')\nplt.figure(figsize = (8, 8))\n\nfeature_importance = abs(Model.coef_[0])\nfeature_importance = 100.0 * (feature_importance / feature_importance.max())\nsorted_idx = np.argsort(feature_importance)\npos = np.arange(sorted_idx.shape[0]) + .5\n\nfeatfig = plt.figure()\nfeatax = featfig.add_subplot(1, 1, 1)\nfeatax.barh(pos, feature_importance[sorted_idx], align='center')\nfeatax.set_yticks(pos)\nfeatax.set_yticklabels(np.array(X.columns)[sorted_idx], fontsize=8)\nfeatax.set_xlabel('Relative Feature Importance')\n\nplt.tight_layout()   \nplt.show()\n\nprint('\\n\\n-----------------------------------------------------\\n\\n')\narr=confusion_matrix(y_test, y_pred)\ndf_cm = pd.DataFrame(arr, range(2), range(2))\nplt.figure(figsize = (8, 8))\nsns.heatmap(arr, cmap = 'Blues', annot = True, fmt = 'd', annot_kws = {'fontsize': 15},\n           yticklabels = ['Stayed', 'Left'], xticklabels = ['Predicted stayed', 'Predicted left'])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font size=\"+1\" color=\"indigo\"><b>Gradient Boosting Classifier</b></font><br>","metadata":{}},{"cell_type":"code","source":"Model=GradientBoostingClassifier()\n#pipeModel=Pipeline([('scaler', StandardScaler()), ('model', Model)])\n\n# the benefit of using K-Fold is that we could calculate the cross validation value using some of the methods of scoring \nkfold = KFold(n_splits=10, shuffle=True, random_state=0)\ncv_results = cross_val_score(Model, X_train, y_train, cv=kfold)\n\nModel.fit(X_train, y_train)\n\nprint('Score for GBC method:', Model.score(X_test, y_test))\n\n# the mean result (10 data) of negative mean squared error\nprint('Score for GBC method using cross_val_score:', cv_results.mean())\ny_pred = Model.predict(X_test)\ny_prob = Model.predict_proba(X_test)[:,1]\n\n#print(mean_squared_error(y_test, y_pred))\nprint(classification_report(y_test,y_pred))\nprint(\"roc_auc score:\", roc_auc_score(y_test,y_prob))\n\n# Roc curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nprint('\\n\\n-----------------------------------------------------\\n\\n')\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (8, 8))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()\n\nprint('\\n\\n-----------------------------------------------------\\n\\n')\nplt.figure(figsize = (8, 8))\n\nfeature_importance = abs(Model.feature_importances_)\nfeature_importance = 100.0 * (feature_importance / feature_importance.max())\nsorted_idx = np.argsort(feature_importance)\npos = np.arange(sorted_idx.shape[0]) + .5\n\nfeatfig = plt.figure()\nfeatax = featfig.add_subplot(1, 1, 1)\nfeatax.barh(pos, feature_importance[sorted_idx], align='center')\nfeatax.set_yticks(pos)\nfeatax.set_yticklabels(np.array(X.columns)[sorted_idx], fontsize=8)\nfeatax.set_xlabel('Relative Feature Importance')\n\nplt.tight_layout()   \nplt.show()\n\nprint('\\n\\n-----------------------------------------------------\\n\\n')\narr=confusion_matrix(y_test, y_pred)\ndf_cm = pd.DataFrame(arr, range(2), range(2))\nplt.figure(figsize = (8, 8))\nsns.heatmap(arr, cmap = 'Blues', annot = True, fmt = 'd', annot_kws = {'fontsize': 15},\n           yticklabels = ['Stayed', 'Left'], xticklabels = ['Predicted stayed', 'Predicted left'])\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> XGBoost gives best results based on accuracy. The hyperparameter need to be tuned.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"8\"></a>\n    \n# <font size=\"+2\" color=\"indigo\"><b>8. Tuning Hyperparameter</b></font><br>","metadata":{}},{"cell_type":"code","source":"#List Hyperparameters yang akan diuji\n#penalty = ['l1', 'l2']\n#C = np.logspace(-4,4,20)\n\n#Menjadikan ke dalam bentuk dictionary\n#hyperparameters = dict(penalty=penalty, C=C)\n\nparam_tuning = {\n    'learning_rate': [0.01, 0.1],\n    'max_depth': [3, 5, 7, 10],\n    'min_child_weight': [1, 3, 5],\n    'subsample': [0.5, 0.7],\n    'colsample_bytree': [0.5, 0.7],\n    'n_estimators' : [100, 200, 500],\n    'objective': ['reg:squarederror']\n}\n\n#Membuat Object Logistic Regression\nlogreg = XGBClassifier(eval_metric=\"logloss\")\n\n#Memasukan ke Grid Search\n#CV itu Cross Validation\n#Menggunakan 10-Fold CV\nclf = GridSearchCV(logreg, param_grid = param_tuning, cv=10)\n\n#Fitting Model\nbest_model = clf.fit(X,y)\n\n#Nilai hyperparameters terbaik\nprint('Best Params:', best_model.best_estimator_.get_params())\n\n#Prediksi menggunakan model baru\n#y_pred = best_model.predict(x_test)\n\n#Check performa dari model\n#print(classification_report(y_test, y_pred))\n#roc_auc_score(y_test, y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Model=XGBClassifier(eval_metric=\"logloss\", learning_rate=best_model.best_estimator_.get_params()['learning_rate'],\n                        max_depth=best_model.best_estimator_.get_params()['max_depth'],\n                        min_child_weight=best_model.best_estimator_.get_params()['min_child_weight'],\n                        subsample=best_model.best_estimator_.get_params()['subsample'],\n                        colsample_bytree=best_model.best_estimator_.get_params()['colsample_bytree'],\n                        n_estimators=best_model.best_estimator_.get_params()['n_estimators'],\n                        objective=best_model.best_estimator_.get_params()['objective'])\n#pipeModel=Pipeline([('scaler', StandardScaler()), ('model', Model)])\n\n# the benefit of using K-Fold is that we could calculate the cross validation value using some of the methods of scoring \nkfold = KFold(n_splits=10, shuffle=True, random_state=0)\ncv_results = cross_val_score(Model, X_train, y_train, cv=kfold)\n\nModel.fit(X_train, y_train)\n\nprint('Score for XGBoost method:', Model.score(X_test, y_test))\n\n# the mean result (10 data) of negative mean squared error\nprint('Score for XGBoost method using cross_val_score:', cv_results.mean())\ny_pred = Model.predict(X_test)\ny_prob = Model.predict_proba(X_test)[:,1]\n\n#print(mean_squared_error(y_test, y_pred))\nprint(classification_report(y_test,y_pred))\nprint(\"roc_auc score:\", roc_auc_score(y_test,y_prob))\n\n# Roc curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nprint('\\n\\n-----------------------------------------------------\\n\\n')\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (8, 8))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()\n\nprint('\\n\\n-----------------------------------------------------\\n\\n')\n\nplt.figure(figsize = (8, 8))\nfrom matplotlib import pyplot\nfrom xgboost import plot_importance\nplot_importance(Model, max_num_features=10) # top 10 most important features\nplt.show()\n\nprint('\\n\\n-----------------------------------------------------\\n\\n')\narr=confusion_matrix(y_test, y_pred)\ndf_cm = pd.DataFrame(arr, range(2), range(2))\nplt.figure(figsize = (8, 8))\nsns.heatmap(arr, cmap = 'Blues', annot = True, fmt = 'd', annot_kws = {'fontsize': 15},\n           yticklabels = ['Stayed', 'Left'], xticklabels = ['Predicted stayed', 'Predicted left'])\nplt.show()","metadata":{},"execution_count":null,"outputs":[]}]}