{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Importing libraries and dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(action=\"ignore\")\nplt.style.use([\"seaborn-bright\",\"dark_background\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Checking for missing value percentage."},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in data.columns:\n    perc = data[i].isnull().sum()\n    print(\"Missing data in column {} = {}%\".format(i,(perc/len(data))*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val = [\"bmi\"]\nfrom sklearn.impute import SimpleImputer\nimputer = SimpleImputer(missing_values= np.nan, strategy=\"mean\" )\ndata[val] = imputer.fit_transform(data[val])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_data = [x for x in data.columns if data[x].dtype == \"object\"]\nnum_data = [y for y in data.columns if data[y].dtype != \"object\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in cat_data:\n    print(i,\" = \",data[i].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Visualizing categorical values using countplot."},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in cat_data:\n    plt.figure(figsize=(8,5))\n    sns.countplot(data[i])\n    plt.title(i,fontsize=15,color=\"lime\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['gender'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Removing the row with \"Other\" as gender value as it is only 1 in count."},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data[data.gender!=\"Other\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Ploting histogram for numerical values."},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in num_data:\n    plt.figure(figsize=(8,5))\n    sns.histplot(data[i],kde=True)\n    plt.title(i,fontsize=15,color=\"lime\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Ploting boxplot to check outliers."},{"metadata":{"trusted":true},"cell_type":"code","source":"num_data = [\"age\",\"avg_glucose_level\",\"bmi\"]\nfor i in num_data:\n    plt.figure(figsize=(8,5))\n    sns.boxplot(data[\"work_type\"],data[i],hue=data[\"gender\"])\n    plt.title(i,fontsize=15,color=\"lime\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Removing outliers."},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_outliers(feature):\n    q1 = data[feature].quantile(0.25)\n    q3 = data[feature].quantile(0.75)\n    iqr = q3 - q1\n    upper = q3 + 1.5*iqr\n    lower = q1 - 1.5*iqr\n    return upper,lower","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def func(feature):\n    upper,lower = find_outliers(feature)\n    data[feature] = np.where(data[feature]>upper,upper,data[feature])\n    data[feature] = np.where(data[feature]<lower,lower,data[feature])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in num_data:\n    func(feature)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Creating dummies."},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.get_dummies(data,columns=[\"gender\",\"ever_married\",\"Residence_type\"],drop_first=True)\ndata = pd.get_dummies(data,columns=[\"work_type\",\"smoking_status\"],drop_first=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(columns=[\"id\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Ploting correleation heatmap."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,15))\nsns.heatmap(data.corr(),annot=True,cmap=\"rainbow\")\nplt.title(\"Correleation Heatmap\",fontsize=20,color=\"c\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data.drop(columns=[\"stroke\"])\nY = data[\"stroke\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx1_train,x1_test,y1_train,y1_test = train_test_split(X,Y,test_size=0.2,random_state=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nRFC = RandomForestClassifier(n_estimators=100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Train score."},{"metadata":{"trusted":true},"cell_type":"code","source":"RFC.fit(x1_train,y1_train)\nRFC.score(x1_train,y1_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y1_train = pd.DataFrame(y1_train,columns=[\"stroke\"])\ny1_train.stroke.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Test score."},{"metadata":{"trusted":true},"cell_type":"code","source":"RFC.score(x1_test,y1_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prob1 = RFC.predict_proba(x1_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Confusion matrix."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix,classification_report\nprint(\"For train data \\n\",confusion_matrix(y1_train,RFC.predict(x1_train)))\nprint(\"For test data \\n\",confusion_matrix(y1_test,RFC.predict(x1_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Classification Report."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"For train data \\n\",classification_report(y1_train,RFC.predict(x1_train)))\nprint(\"For test data \\n\",classification_report(y1_test,RFC.predict(x1_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### The precision , recall and f1-score for class 1 is very bad, as our dataset is imbalanced. So now we will balance the dataset using the library imblearn."},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nx_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state=100)\nsm = SMOTE(random_state=27)\nx_train, y_train = sm.fit_resample(x_train, y_train)\nx_train.shape, y_train.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = pd.DataFrame(y_train, columns = ['stroke'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.stroke.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sm = SMOTE(random_state=27)\nx_test, y_test = sm.fit_resample(x_test, y_test)\nx_test.shape, y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test = pd.DataFrame(y_test, columns = ['stroke'])\ny_test.stroke.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RFC.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RFC.score(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RFC.score(x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prob = RFC.predict_proba(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix,classification_report\nprint(\"For train data \\n\",confusion_matrix(y_train,RFC.predict(x_train)))\nprint(\"For test data \\n\",confusion_matrix(y_test,RFC.predict(x_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"For train data \\n\",classification_report(y_train,RFC.predict(x_train)))\nprint(\"For test data \\n\",classification_report(y_test,RFC.predict(x_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Precision-Recall curve for imbalanced dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_recall_curve\nprecision_points, recall_points, threshold_points = precision_recall_curve(y1_test,prob1[:,1])\nplt.figure(dpi =100, figsize=(6,6))\nplt.plot(threshold_points, precision_points[:-1], color = 'r', label = 'Precision')\nplt.plot(threshold_points, recall_points[:-1], color = 'b', label = 'Recall')\nplt.xlabel('Threshold')\nplt.ylabel('Frequency')\nplt.title('Precision-Recall Curve for X1_Test')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Precision-Recall curve for balanced dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_recall_curve\nprecision_points, recall_points, threshold_points = precision_recall_curve(y_test,prob[:,1])\nplt.figure(dpi =100, figsize=(6,6))\nplt.plot(threshold_points, precision_points[:-1], color = 'r', label = 'Precision')\nplt.plot(threshold_points, recall_points[:-1], color = 'b', label = 'Recall')\nplt.xlabel('Threshold')\nplt.ylabel('Frequency')\nplt.title('Precision-Recall Curve for X_Test')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### AUC-ROC curve for imbalanced dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve,roc_auc_score\nfpr, tpr, threshold = roc_curve(y1_test ,prob1[:,1])\nplt.figure(dpi = 100, figsize=(8,6))\nplt.plot(fpr,tpr, color = 'r', label='FPR-TPR')\nplt.plot([0,1],[0,1], color = 'g', label = 'Baseline')\nplt.title('AUC-ROC Curve for X1_Test')\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### AUC-ROC curve for balanced dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve,roc_auc_score\nfpr, tpr, threshold = roc_curve(y_test ,prob[:,1])\nplt.figure(dpi = 100, figsize=(8,6))\nplt.plot(fpr,tpr, color = 'r', label='FPR-TPR')\nplt.plot([0,1],[0,1], color = 'g', label = 'Baseline')\nplt.title('AUC-ROC Curve for X_Test')\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}