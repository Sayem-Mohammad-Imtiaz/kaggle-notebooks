{"cells":[{"metadata":{},"cell_type":"markdown","source":"## 1. Data Exploration\n### 1.1 Basic Information"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt \nfrom sklearn import manifold, datasets\nfrom sklearn.manifold import TSNE\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nimport seaborn as sns\nimport csv\nimport json\n\n\nsns.set_style('darkgrid') \n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n\n# Any results you write to the current directory are saved as output.\ncredits=pd.read_csv('/kaggle/input/tmdb-movie-metadata/tmdb_5000_credits.csv')\nmovies=pd.read_csv('/kaggle/input/tmdb-movie-metadata/tmdb_5000_movies.csv')\n# print(credits.shape) #(4803, 4)\n\ndel credits['title']\ndel movies['id']\nfull=pd.concat([credits,movies],axis=1)\nprint(full.shape) #the size of the dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full.info()  #show the information","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full.head() #get the first 5 lines of the dataframe (full)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.2 Matric Data"},{"metadata":{},"cell_type":"markdown","source":"In dataframe \"full\", there are some columns have matric data: movie_id, budget, released date,revenue,runtime,popularity,vote_average and vote_count.In this section, we will do some exploration about these data."},{"metadata":{},"cell_type":"markdown","source":"First, we can drop the movies with NaN value of release_date, then use Seaborn to visualize the distribution of the movies with release_time."},{"metadata":{"trusted":true},"cell_type":"code","source":"sub0=full[['popularity','vote_average','release_date']]\nsub0.release_date=pd.to_datetime(sub0.release_date)\nsub0.release_date=sub0.release_date.dt.year\n#dorp the movies with NaN value of release_date\nsub0 = sub0[~sub0.release_date.isnull()] \nsub0 = sub0[~sub0.popularity.isnull()] \nsub0 = sub0[~sub0.vote_average.isnull()] \n# sub0=sub0[~sub0.popularity.str.isnumeric()]\n\n#float to int \nsub0.release_date = sub0.release_date.apply(int)\n\n\nplt.figure(figsize=(20, 10))\nsns.distplot(sub0.release_date)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Then we use scatter diagram how the popularity and vote_average of movies changed according to the generation."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.relplot(x=\"release_date\", y=\"vote_average\", data= sub0, hue =\"popularity\",palette=\"ch:r=-.5,l=.75\",alpha=1,height=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(sub0.popularity.max())\ndelete=[875.581305,418.708552,434.278564,481.098624,514.569956,724.247784]\nsub0_1=sub0[~sub0['popularity'].isin(delete)]\nsns.relplot(x=\"release_date\", y=\"vote_average\", data= sub0_1, hue =\"popularity\",palette=\"ch:r=-.5,l=.75\",alpha=.4,height=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We narrow the scope to the movies after 2000 years."},{"metadata":{"trusted":true},"cell_type":"code","source":"sub0_2=sub0[sub0['release_date']>= 2000] #after 2000 years\nsub0_2.release_date = sub0_2.release_date.apply(int)\nsns.relplot(x=\"release_date\", y=\"vote_average\", data= sub0_2, hue =\"popularity\",palette='Set3',sizes=(40,1000),alpha=1,height=8)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thenï¼Œ we want to explore what is the revenue of the movies influence its popularity and vote_average."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"sub1=full[['budget','revenue','popularity','vote_average']]\nprint(sub1)\nplt.figure(figsize=(10, 10))\nprofit=sub1.revenue.values-sub1.budget.values\nvote_average=sub1.vote_average.values\npopularity=sub1.popularity.values\nprint(profit)\nprint(vote_average)\n# plt.scatter(profit, vote_average)\nplt.scatter(profit,popularity)\n#plt.scatter(sub1.revenue.values,sub1.popularity)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsub1=sub1[sub1['vote_average']>= 7] #vote>=7\nsns.relplot(x=\"revenue\", y=\"vote_average\", data= sub1,size =\"popularity\",sizes=(40,1000),palette=\"ch:r=-.5,l=.75\",alpha=.4,height=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.3 Json Data"},{"metadata":{},"cell_type":"markdown","source":"We explore the crew data and the keywords data, which may decide what type of the movies.\n"},{"metadata":{},"cell_type":"markdown","source":"**The crews' job of the movies: **"},{"metadata":{"trusted":true},"cell_type":"code","source":" def getcrew_job(x):\n    a=[]\n    for i in x:\n        a.append(i['job'])\n    return a\n\nsub2=full[['crew','vote_average']]\n#crew_dict=json.load(sub2.crew.values)\nprint(type(sub2.crew))\nsub2.crew=sub2.crew.apply(json.loads)\ncrew_job=sub2.crew.apply(getcrew_job)\nresult = crew_job.apply(pd.value_counts) #result is dataframe\nresult=result.fillna(0)  #substitute \"NaN\" to 0\nresult_top10=result.head(10) #just print the first 10 lines\nresult_top10['col_sum'] = result_top10.apply(lambda x: x.sum(), axis=1) #the sum of all crews and save it to col_sum\nprint(result_top10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(50, 30))\nsns.heatmap(result_top10, annot=False, fmt=\".1f\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"However, since the number of dimension is large, the heatmap had bad performance on showing the pattern of different types of movies. So we decide to deduce the dimensions."},{"metadata":{},"cell_type":"markdown","source":"**The keywords of the movies:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_keywords(x):\n    a=[]\n    for i in x:\n        a.append(i['name'])\n    return a\n\nsub3=full[['keywords']]\nsub3.keywords=sub3.keywords.apply(json.loads)\nkeywords=sub3.keywords.apply(get_keywords)\nresult2 = keywords.apply(pd.value_counts) \n# result2.loc['Row_sum'] = result2.apply(lambda x: x.sum())\nresult2=result2.fillna(0)  #substitute \"NaN\" to 0\nresult2['Col_sum'] = result2.apply(lambda x: x.sum(), axis=1)\nresult_top10_2=result2.head(10)\nprint(result_top10_2)\nprint(result_top10_2.keys()) # get the colomn name","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.Classify the type of movies\nJust combine the crews and the keywords as the features of the classifer."},{"metadata":{"trusted":true},"cell_type":"code","source":"sub4=full[['crew','keywords']]\nsub4.crew=sub4.crew.apply(json.loads)\nsub4.crew=sub4.crew.apply(getcrew_job)\nsub4.keywords=sub4.keywords.apply(json.loads)\nsub4.keywords=sub4.keywords.apply(get_keywords) # sub4.crew type: series\nresult4 = sub4.crew.apply(pd.value_counts) #result4 type: dataframe\n\nresult4=pd.concat([result4,sub4.keywords.apply(pd.value_counts)]) # combine two dataframes\nresult4=result4.fillna(0)  \nresult_top10_4=result4.head(10)\nprint(result_top10_4)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Then we use TSNE to reduce the dimension to two dimension."},{"metadata":{"trusted":true},"cell_type":"code","source":"tsne = manifold.TSNE(n_components=2, init='pca', random_state=501)\nresult4_tsne = tsne.fit_transform(result4)\nprint(\"Org data dimension is {}. Embedded data dimension is {}\".format(result4.shape[-1], result4_tsne.shape[-1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(type(result4_tsne))\nprint(result4_tsne)\nnp.save(\"./result4_tsne.npy\",result4_tsne) # save as npy file","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We use kmeans to cluster."},{"metadata":{"trusted":true},"cell_type":"code","source":"d=[]\nfor i in range(1,40):   #experiements on different value of k\n    km=KMeans(n_clusters=i,init='k-means++',n_init=10,max_iter=300,random_state=0)\n    km.fit(result4_tsne)\n    d.append(km.inertia_)  #inertia:Sum of squares of errors in clusters\n\nplt.plot(range(1,40),d,marker='o')\nplt.xlabel('number of clusters')\nplt.ylabel('distortions')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# kmeas clustering\n#from sklearn import metrics\nresult4_kmeans=KMeans(n_clusters=20,random_state=0)\nresult4_kmeans.fit(result4_tsne)\nresult4_pre=result4_kmeans.predict(result4_tsne)  #predict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualization of the clustering\ncenters=result4_kmeans.cluster_centers_ \nprint(centers)\ncolors=['#D0505D','#E1929A','#B4D1D9','#6194A7',\n        '#203643','#F6A945','#FEEB90','#Fd8732',\n        '#262F34','#6B3A7F',\"#006B89\",\"#978065\",\n        \"#3A281C\",\"#9b59b6\", \"#3498db\", \"#95a5a6\", \n        \"#e74c3c\", \"#34495e\", \"#2ecc71\",\"#9EC1E0\",'#131B1B']\nplt.figure(figsize=(10, 6))\nfor j in range(20):\n    index_set=np.where(result4_pre==j)\n    cluster=result4_tsne[index_set]\n    plt.scatter(cluster[:,0],cluster[:,1],c=colors[j],marker='.')  \n    plt.plot(centers[j][0],centers[j][1],'o',markerfacecolor=colors[j],markeredgecolor='k',markersize=8)  #ç”»ç±»åˆ«ä¸­å¿ƒ\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"file_npy='./result4_tsne.npy'\nnp.load(file_npy)\n#print(np)\n#plt.plot(re[:,0],re[:,1])\n#plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Some usage of Seaborn"},{"metadata":{},"cell_type":"markdown","source":"### 3.1 the color and the style"},{"metadata":{"trusted":true},"cell_type":"code","source":"current_palette=sns.color_palette() \n#the parameter is the name of the themes, and seaborn has six default themes(deep,muted,pastel,bright,dark,colorblind)\nsns.palplot(current_palette)\n\n#use your own color\nmycolor=['#D0505D','#E1929A','#B4D1D9','#6194A7',\n        '#203643','#F6A945','#FEEB90','#Fd8732']\nsns.palplot(sns.color_palette(mycolor))\n\nsns.palplot(sns.color_palette(\"Blues\"))\n# reverse:Blues_r \n\nsns.palplot(sns.cubehelix_palette(8))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}