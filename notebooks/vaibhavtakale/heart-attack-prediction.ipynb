{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import classification_report, mean_squared_error, accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n\nsns.set(style=\"white\")\nsns.set(style=\"whitegrid\", color_codes=True)\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-25T07:34:57.223575Z","iopub.execute_input":"2021-06-25T07:34:57.22408Z","iopub.status.idle":"2021-06-25T07:34:57.2369Z","shell.execute_reply.started":"2021-06-25T07:34:57.224046Z","shell.execute_reply":"2021-06-25T07:34:57.235808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/heart-attack-analysis-prediction-dataset/heart.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T07:33:20.248661Z","iopub.execute_input":"2021-06-25T07:33:20.249Z","iopub.status.idle":"2021-06-25T07:33:20.291471Z","shell.execute_reply.started":"2021-06-25T07:33:20.248973Z","shell.execute_reply":"2021-06-25T07:33:20.290373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Correlation Heatmap","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,15))\nsns.heatmap(df.corr(), annot=True, linewidths=1, cmap = 'coolwarm')\nplt.title('Correlation Heatmap')\nplt.xlabel('Column')\nplt.ylabel('Column')","metadata":{"execution":{"iopub.status.busy":"2021-06-25T07:33:21.008462Z","iopub.execute_input":"2021-06-25T07:33:21.008827Z","iopub.status.idle":"2021-06-25T07:33:22.160522Z","shell.execute_reply.started":"2021-06-25T07:33:21.008796Z","shell.execute_reply":"2021-06-25T07:33:22.159584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Visualization","metadata":{}},{"cell_type":"code","source":"fig, axs = plt.subplots(1,2,figsize=(14,4))\n\ntable=pd.crosstab(df.cp,df.output)\ntable.div(table.sum(1).astype(float), axis=0).plot(ax=axs[0],kind='bar', stacked=True)\npd.crosstab(df.cp,df.output).plot(ax=axs[1],kind='bar')\n\nfor ax in axs.flat:\n    ax.set(xlabel='Cp', ylabel='number of patients')\n    ax.title.set_text('Number of Patients for different Cp types')","metadata":{"execution":{"iopub.status.busy":"2021-06-25T07:33:22.162022Z","iopub.execute_input":"2021-06-25T07:33:22.162488Z","iopub.status.idle":"2021-06-25T07:33:22.54244Z","shell.execute_reply.started":"2021-06-25T07:33:22.162451Z","shell.execute_reply":"2021-06-25T07:33:22.541508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As from above figures, we can say that for type 1 and type 2 cp, the proability of y being 1 is high","metadata":{}},{"cell_type":"code","source":"table=pd.crosstab(df.caa,df.output)\ntable.div(table.sum(1).astype(float), axis=0).plot(kind='bar', stacked=True)\nplt.title('Proportion of number of patients for different number of major veseels')\nplt.xlabel('number of major vessels')\nplt.ylabel('Number of Patients')","metadata":{"execution":{"iopub.status.busy":"2021-06-25T07:33:22.544145Z","iopub.execute_input":"2021-06-25T07:33:22.544433Z","iopub.status.idle":"2021-06-25T07:33:22.734823Z","shell.execute_reply.started":"2021-06-25T07:33:22.544403Z","shell.execute_reply":"2021-06-25T07:33:22.733821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Similarly, for number of vessels 0 and 4, probability of y being 1 is high. Hence the correlation of caa with output is high","metadata":{}},{"cell_type":"code","source":"output = df.output.unique()\nplt.hist([df.loc[df.output == x, 'thalachh'] for x in output], label=output)\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T07:33:26.198461Z","iopub.execute_input":"2021-06-25T07:33:26.198828Z","iopub.status.idle":"2021-06-25T07:33:26.406488Z","shell.execute_reply.started":"2021-06-25T07:33:26.198797Z","shell.execute_reply":"2021-06-25T07:33:26.405631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can observe that when value of thalachh (maximum heart rate achieved) is around 160, the value of y is 1","metadata":{}},{"cell_type":"code","source":"pd.crosstab(df.exng,df.output).plot(kind='bar')\nplt.title('Patients with exercise induced angina & Possibility of heart attack')\nplt.xlabel('exng')\nplt.ylabel('Number of Patients')","metadata":{"execution":{"iopub.status.busy":"2021-06-25T07:33:28.763763Z","iopub.execute_input":"2021-06-25T07:33:28.764196Z","iopub.status.idle":"2021-06-25T07:33:28.929469Z","shell.execute_reply.started":"2021-06-25T07:33:28.764167Z","shell.execute_reply":"2021-06-25T07:33:28.928149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As expected, the patients with exercise induced angina are less likely to be suffered from heart attack","metadata":{}},{"cell_type":"code","source":"pd.crosstab(df.thall,df.output).plot(kind='bar')\nplt.title('Patients with different type of thall')\nplt.xlabel('thall')\nplt.ylabel('Number of Patients')","metadata":{"execution":{"iopub.status.busy":"2021-06-25T07:33:31.378379Z","iopub.execute_input":"2021-06-25T07:33:31.380004Z","iopub.status.idle":"2021-06-25T07:33:31.565809Z","shell.execute_reply.started":"2021-06-25T07:33:31.379954Z","shell.execute_reply":"2021-06-25T07:33:31.564753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"When thall type is 2, the chances of getting heart attack are much higher.","metadata":{}},{"cell_type":"code","source":"pd.crosstab(df.fbs,df.output).plot(kind='bar')\nplt.title('Patients with fasting blood sugar > 120')\nplt.xlabel('fbs')\nplt.ylabel('Number of Patients')","metadata":{"execution":{"iopub.status.busy":"2021-06-25T07:33:33.598512Z","iopub.execute_input":"2021-06-25T07:33:33.598848Z","iopub.status.idle":"2021-06-25T07:33:33.7824Z","shell.execute_reply.started":"2021-06-25T07:33:33.598817Z","shell.execute_reply":"2021-06-25T07:33:33.780882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see, the number of patients getting heart attack is almost same as number of patients who are less likely to get heart attack regardless of their blood sugar level. So this feature will less likely to be helpful in classification model","metadata":{}},{"cell_type":"markdown","source":"## Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"### Correlation Coefficient magnitute with target variable (output)\n1. Greater than 0.35 - cp, thalachh, exng, oldpeak, slp, caa\n2. Greater than 0.25 - thall, sex\n3. Less than 0.25 and greater than 0.1 - age, trtbps, restecg\n4. Almost equal to 0 - chol, fbs  \n\n**Note**: We can see that slp and oldpeak have negative correlation of 0.58 which is significant. So, only one of them is included in x_train. As the correaltion of oldpeak with output is greater than that of slp, we are dropping slp from x","metadata":{}},{"cell_type":"markdown","source":"## Importance of Feature Engineering  \nLet's see the accuracy of the logistic regression model without doing any feature engineering","metadata":{}},{"cell_type":"code","source":"x = df.drop(columns=['output'])\ny = df['output']\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n\nlogreg = LogisticRegression(solver='liblinear')\nlogreg.fit(x_train, y_train)\n\ny_test_pred = logreg.predict(x_test)\nprint(classification_report(y_test, y_test_pred))","metadata":{"execution":{"iopub.status.busy":"2021-06-25T07:33:59.088855Z","iopub.execute_input":"2021-06-25T07:33:59.089205Z","iopub.status.idle":"2021-06-25T07:33:59.110543Z","shell.execute_reply.started":"2021-06-25T07:33:59.089176Z","shell.execute_reply":"2021-06-25T07:33:59.109512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let's try the same thing with dropping the features with correlation less than 0.25","metadata":{}},{"cell_type":"code","source":"x = df.drop(columns=['output','slp','chol','fbs','trtbps', 'restecg','age'])\ny = df['output']\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n\nlogreg = LogisticRegression(solver='liblinear')\nlogreg.fit(x_train, y_train)\n\ny_test_pred = logreg.predict(x_test)\nprint(classification_report(y_test, y_test_pred))","metadata":{"execution":{"iopub.status.busy":"2021-06-25T07:37:07.672304Z","iopub.execute_input":"2021-06-25T07:37:07.672858Z","iopub.status.idle":"2021-06-25T07:37:07.692111Z","shell.execute_reply.started":"2021-06-25T07:37:07.672823Z","shell.execute_reply":"2021-06-25T07:37:07.691146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that accuracy increased from 0.87 to 0.89 when the columns are dropped. This shows us the importance of feature engineering. It's always importat to make sure that the features are independant of each other and have maximum correlation with target variable only.","metadata":{"execution":{"iopub.status.busy":"2021-06-24T15:39:47.013537Z","iopub.execute_input":"2021-06-24T15:39:47.01392Z","iopub.status.idle":"2021-06-24T15:39:47.024181Z","shell.execute_reply.started":"2021-06-24T15:39:47.013888Z","shell.execute_reply":"2021-06-24T15:39:47.022925Z"}}},{"cell_type":"markdown","source":"## Classification Models","metadata":{}},{"cell_type":"code","source":"logreg = LogisticRegression(solver=\"liblinear\")\ngnb = GaussianNB()\nknn = KNeighborsClassifier()\ndec_tree = DecisionTreeClassifier(random_state=42)\nrf = RandomForestClassifier(random_state=42,verbose=False)\ngb = GradientBoostingClassifier(verbose=False)\n\nmodels = [logreg,gnb,knn,dec_tree,rf,gb]","metadata":{"execution":{"iopub.status.busy":"2021-06-25T07:39:11.264162Z","iopub.execute_input":"2021-06-25T07:39:11.264575Z","iopub.status.idle":"2021-06-25T07:39:11.269636Z","shell.execute_reply.started":"2021-06-25T07:39:11.264546Z","shell.execute_reply":"2021-06-25T07:39:11.268631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for model in models:\n    model.fit(x_train,y_train)\n    name = model.__class__.__name__\n    y_pred = model.predict(x_test)\n    print(\"Model    -\", name)\n    print(\"Accuracy -\",accuracy_score(y_test,y_pred))\n    print(\"Loss     -\", mean_squared_error(y_test,y_pred))\n    print()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T07:43:10.474493Z","iopub.execute_input":"2021-06-25T07:43:10.476921Z","iopub.status.idle":"2021-06-25T07:43:10.760751Z","shell.execute_reply.started":"2021-06-25T07:43:10.476872Z","shell.execute_reply":"2021-06-25T07:43:10.759586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Maximum Accuracy is for Logistic Regression - 0.885","metadata":{}}]}