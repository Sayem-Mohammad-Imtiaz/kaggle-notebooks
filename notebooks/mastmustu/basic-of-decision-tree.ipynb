{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# read the data \ndf = pd.read_csv('/kaggle/input/iris-flower-dataset/IRIS.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#top 5 record of the data \ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# columns\ndf.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# describe  the data \n\ndf.describe()\n\n# only works on numerical cols\n# statistics about data \n# data distributions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Information about the data in a glance\n\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dimension  i.e. rows and columns\n\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Unique values is Species \ndf['species'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# count of the different species\n\ndf['species'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Features V/s Target \n\nfeatures  = list(df.columns)[:-1]\nprint(features)\ntarget = list(df.columns)[-1:][0]\nprint(target)\n\n# Features  --- > Predictor \n# Target  --> Predicted ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data Visualisation Step\n\n\nimport seaborn as sns\nsns.pairplot(df,hue ='species')\n\n# hue - color based on a column name  - in most case it will be Target Columns\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separates features and corresponding labels/target \n# by dropping Species - we get data frame with all features \n\nX = df.drop(['species'], axis=1)  #  X will hold all features\ny = df['species'] # y will hold target/labels\n\nprint(X.shape) #dimensions of input data\nprint(y.shape) #dimensions of output data\n\n\n# is this binary classification or not  ?","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.model_selection import train_test_split \nX_train, X_test, y_train, y_test = train_test_split( X, y, test_size = 0.5, random_state = 0) \nprint(X_train.shape)\nprint(X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training using Decision Tree Classifier \n\nfrom sklearn.tree import DecisionTreeClassifier  \nclassifier1 = DecisionTreeClassifier(criterion='gini')  \nclassifier1.fit(X_train, y_train) \n\n# Check Criteria  ?\nprint(classifier1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using information gain \n\nclassifier2 = DecisionTreeClassifier(criterion='entropy')  \nclassifier2.fit(X_train, y_train) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict using both the classifier \n\n\n\ny_pred_1 = classifier1.predict(X_test)  \nprint(y_pred_1)\n\ny_pred_2 = classifier2.predict(X_test)  \nprint(y_pred_2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# compute accuracy \n\nfrom sklearn.metrics import accuracy_score #importing accuracy_score function from sklearn.metrics package\nacc_1 = accuracy_score(y_test,y_pred_1)\nprint(\"Accuracy for Gini model {} %\".format(acc_1*100))\n\n\nacc_2 = accuracy_score(y_test,y_pred_2)\nprint(\"Accuracy for Entropy model {} %\".format(acc_2*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# confusion matrix for Gini Model \n\n\nfrom sklearn.metrics import classification_report, confusion_matrix  \nprint(confusion_matrix(y_test, y_pred_1))\nprint(classification_report(y_test, y_pred_1)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# important features \n\nprint(classifier1.feature_importances_)\n\n#SepalLenCm   SepalWidCm    PetalLenCm     PetalWidCm\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot a tree \n\n\nfrom sklearn import tree\nfrom sklearn.tree import export_graphviz\n\ntree.export_graphviz(classifier2,out_file='tree.dot',feature_names = ['SepalLenCm','SepalWidCm','PetalLenCm', 'PetalWidCm'],\nclass_names = 'Species',rounded = True, proportion = False, precision = 2, filled = True)  \n\n!dot -Tpng tree.dot -o tree.png\nfrom IPython.display import Image\nImage(filename = 'tree.png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Distance based model #","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\n\nclassifier3 = KNeighborsClassifier(n_neighbors= 7)  \nclassifier3.fit(X_train, y_train) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_3 = classifier3.predict(X_test)  \nprint(y_pred_3)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_3 = accuracy_score(y_test,y_pred_3)\nprint(\"Accuracy for Entropy model {} %\".format(acc_3*100))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# confusion matrix for Gini Model \n\n\nfrom sklearn.metrics import classification_report, confusion_matrix  \nprint(confusion_matrix(y_test, y_pred_3))\nprint(classification_report(y_test, y_pred_3)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}