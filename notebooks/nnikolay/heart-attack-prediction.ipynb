{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Heart Attack Prediction"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%matplotlib inline\n\nimport pandas as pd\npd.set_option('display.float_format', '{:.3f}'.format)\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix, precision_recall_curve, auc, roc_auc_score, roc_curve, recall_score, classification_report\nfrom pandas import Series\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport eli5 \nfrom eli5.sklearn import PermutationImportance\n\nimport itertools","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def plot_cf_matrix_and_roc(model, \n                           X_train, \n                           y_train,\n                           X_test, \n                           y_test,\n                           y_pred, \n                           classes=[0,1],\n                           normalize=False,\n                           cmap=plt.cm.Blues):\n    metrics_list = []\n    \n    # the main plot\n    plt.figure(figsize=(15,5))\n\n    # the confusion matrix\n    plt.subplot(1,2,1)\n    cm = confusion_matrix(y_test, y_pred)\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    \n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=0)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        plt.title(\"Normalized confusion matrix\")\n    else:\n        plt.title('Confusion matrix')\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, \"{:0.2f}\".format(cm[i, j]),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n        else:\n            plt.text(j, i, format(cm[i, j]),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    \n    # the ROC curve\n    plt.subplot(1,2,2)\n    tmp = model.fit(X_train, y_train.ravel())\n    y_pred_sample_score = tmp.decision_function(X_test)\n    fpr, tpr, thresholds = roc_curve(y_test, y_pred_sample_score)\n    roc_auc = auc(fpr,tpr)\n\n    # Plot ROC\n    plt.title('Receiver Operating Characteristic (ROC)')\n    plt.plot(fpr, tpr, 'b',label='AUC = %0.3f'% roc_auc)\n    plt.legend(loc='lower right')\n    plt.plot([0,1],[0,1],'r--')\n    plt.xlim([-0.01,1.0])\n    plt.ylim([-0.01,1.01])\n    plt.ylabel('True Positive Rate')\n    plt.xlabel('False Positive Rate')\n    plt.tight_layout()\n    \n    # the result metrix\n    summary_df = pd.DataFrame([[str(np.unique( y_pred )),\n                               str(round(metrics.precision_score(y_test, y_pred.round()),3)),\n                               str(round(metrics.accuracy_score(y_test, y_pred.round()),3)),\n                               str(round(metrics.recall_score(y_test, y_pred.round(), average='binary'),3)),\n                               str(round(metrics.roc_auc_score(y_test, y_pred.round()),3)),\n                               str(round(roc_auc,3)),\n                               str(round(metrics.f1_score(y_test, y_pred.round(), average='binary'),3))]], \n                              columns=['Class', 'Precision', 'Accuracy', 'Recall', 'ROC-AUC', 'AUC', 'F1-score'])\n    # print the metrics\n    print(\"\\n\");\n    print(summary_df);\n    print(\"\\n\");\n    \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=0)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:1\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def summary(df):\n    summary = pd.DataFrame(df.dtypes, columns=['dtypes'])\n    summary = summary.reset_index()\n    summary['Missing'] = df.isnull().sum().values    \n    summary['Uniques'] = df.nunique().values\n    return summary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import stats\nfrom scipy.stats import norm, skew\n\ndef numeric_transform(df, var, transform_type = 'log'):\n    \"\"\" possible values: 'log', 'log1p', 'log10', 'sqrt' \"\"\"\n    print('Transform with: '+ transform_type+\"\\n\");\n    \n    # Plot histogram and probability\n    fig = plt.figure(figsize=(15,5))\n    plt.subplot(1,2,1)\n    sns.distplot(df[var] , fit=norm);\n    (mu, sigma) = norm.fit(df[var])\n    print( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n    plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n                loc='best')\n    plt.ylabel('Frequency')\n    plt.title(var+' distribution')\n    plt.subplot(1,2,2)\n    res = stats.probplot(df[var], plot=plt)\n    plt.suptitle('Before transformation')\n    \n    # Apply transformation\n    if transform_type == 'log':\n        df[var] = np.log(df[var])\n    elif transform_type == 'log10':\n        df[var] = np.log10(df[var] )\n    elif transform_type == 'sqrt':\n        df[var] = np.sqrt(df[var] )\n        \n    # New prediction\n    y_train = df[var].values\n    y_train_orig = df[var]\n\n    # Plot histogram and probability after transformation\n    fig = plt.figure(figsize=(15,5))\n    plt.subplot(1,2,1)\n    sns.distplot(df[var] , fit=norm);\n    (mu, sigma) = norm.fit(df[var])\n    print( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n    plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n                loc='best')\n    plt.ylabel('Frequency')\n    plt.title(var+' distribution')\n    plt.subplot(1,2,2)\n    res = stats.probplot(df[var], plot=plt)\n    plt.suptitle('After transformation')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def to_numeric_mean(df, cols):\n    for col in cols:\n        data.loc[data[col].isnull(), col] = 0\n        data[col] = pd.to_numeric(data[col])\n        data[col].fillna((data[col].mean()), inplace=True)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def to_numeric_most_frequent(df, cols):\n    for col in cols:\n        data.loc[data[col].isnull(), col] = 0\n        data[col] = pd.to_numeric(data[col])\n        data[col].fillna((data[col].value_counts().index[0]), inplace=True)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/heart-attack-prediction/data.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"summary(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.replace('?', np.nan, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.rename({'num       ':'num'},axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"summary(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Drop the columns with more than 5% of NaN values"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(columns=['slope', 'ca', 'thal'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Replace the nan values and convert to numeric"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = to_numeric_mean(data, ['chol', 'trestbps', 'thalach'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = to_numeric_mean(data, ['restecg', 'exang', 'fbs'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"summary(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data['num'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_no_lead = len(data[data['num']==0])\ncount_lead = len(data[data['num']==1])\npct_of_no_sub = count_no_lead/(count_no_lead+count_lead)*100\npct_of_sub = count_lead/(count_no_lead + count_lead)*100\nprint('{} {} % Sales '.format(count_lead, pct_of_sub))\nprint('{} {} % No-Sales '.format(count_no_lead, pct_of_no_sub))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Correlation with the target variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.corrwith(data.num).plot.bar(figsize=(20,15), \n                                              title=\"Correlation with the response Variable\", \n                                              fontsize=15, rot=90, grid=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25, 15))\ncorr = data.corr()\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)] = True\nsns.heatmap(corr, mask=mask, square=True, cmap='RdBu_r', vmin=-1, vmax=1, annot=True, fmt='.2f');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Standardisation for all variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\ncol_names = data.columns\nfeatures = data[col_names]\nscaler = MinMaxScaler(feature_range = (0,1)).fit(features.values)\nfeatures = scaler.transform(features.values)\ndata[col_names] = features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Split the data to train (70%) and test (30%)"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data.drop(columns=['num'])\ny = data['num']\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)\n\nprint('Shape of X: {}'.format(X.shape))\nprint('Shape of y: {}'.format(y.shape))\nprint (\"\\n\")\nprint(\"Number transactions X_train dataset: \", X_train.shape)\nprint(\"Number transactions y_train dataset: \", y_train.shape)\nprint(\"Counts of label '0': {}\".format(sum(y_train==0)))\nprint(\"Counts of label '1': {}\".format(sum(y_train==1)))\nprint (\"\\n\")\nprint(\"Number transactions X_test dataset: \", X_test.shape)\nprint(\"Number transactions y_test dataset: \", y_test.shape)\nprint(\"Counts of label '0': {}\".format(sum(y_test==0)))\nprint(\"Counts of label '1': {}\".format(sum(y_test==1)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Classifier: Logistic Regression with class_weight 1:3"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\n# Logistic Regression with class weight 1:3 for the minority class\nclf = LogisticRegression(\n    class_weight={0:1,1:3},\n    n_jobs=-1 # Use all CPU\n)\n\n# train the classifier\nclf.fit(X_train, y_train)\n\n# predict on the test data\npred_y = clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_cf_matrix_and_roc(clf, X_train, y_train, X_test, y_test, pred_y , classes=['NO','YES'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Optimize the parameters for better classifier performance"},{"metadata":{"trusted":true},"cell_type":"code","source":"# set different parameters\nparams = [{\n    'solver': ['newton-cg', 'lbfgs', 'sag'],\n    'C': [0.3, 0.5, 0.7, 1, 1.3],\n    'penalty': ['l2']\n    },{\n    'solver': ['liblinear','saga'],\n    'C': [0.3, 0.5, 0.7, 1, 1.3],\n    'penalty': ['l1','l2']\n}]\n\n# Logistic Regression with class weight 1:3 for the minority class\nclf = LogisticRegression(\n    class_weight={0:1,1:3},\n    n_jobs=-1 # Use all CPU\n)\n\n# load GridSearchCV for the best parameter evaluation\nsearch = GridSearchCV(\n    estimator=clf,\n    param_grid=params,\n    n_jobs=-1,\n    scoring='recall'\n)\n\n# train search object\nsearch.fit(X_train, y_train)\n\n# predict the on the test data\npred_y_p = search.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_cf_matrix_and_roc(search, X_train, y_train, X_test, y_test, pred_y_p , classes=['NO','YES'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Crossvalidate the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cross-validate the recall score on the complete data with Kfold\nfrom sklearn.model_selection import StratifiedKFold\nkf = StratifiedKFold(shuffle=True, n_splits=5)\ncv_results = cross_val_score(X=X,y=y,estimator=search, cv=kf, scoring='recall')\nprint(\"KFold: Cross-validation recall scores:\",cv_results)\nprint(\"Mean recall score:\",cv_results.mean())","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}