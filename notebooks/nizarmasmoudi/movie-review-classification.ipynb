{"cells":[{"metadata":{},"cell_type":"markdown","source":"<center>\n    <h1>Movie Review Classification</h1>\n</center>"},{"metadata":{},"cell_type":"markdown","source":"## Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Data manipulation\nimport numpy as np\nimport pandas as pd\n# Data visualisation\nimport matplotlib.pyplot as plt\n# Text pre-processing\nfrom string import punctuation\nfrom nltk.corpus import stopwords\nimport spacy\n# Splitting data into train, evaluation and test\nfrom sklearn.model_selection import train_test_split\n# Naïve Bayes\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\n# Evaluation\nfrom sklearn.metrics import classification_report\n# Vectorization\nfrom sklearn.feature_extraction.text import TfidfVectorizer","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loading data"},{"metadata":{"trusted":true},"cell_type":"code","source":"reviews = pd.read_csv('/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')\n\nprint('Number of reviews :', len(reviews))\nreviews.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s = reviews['sentiment'].value_counts()\ns = (s/s.sum())*100\n\nplt.figure()\nbars = plt.bar(s.index, s.values, color = ['green', 'red'], alpha = .6)\nplt.xticks(s.index, ['Positive', 'Negative'], fontsize = 15)\nplt.tick_params(bottom = False, top = False, left = False, right = False, labelleft = False)\nfor spine in plt.gca().spines.values():\n    spine.set_visible(False)\nfor bar in bars:\n    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() - 5, s = str(bar.get_height())[:2] + '%', ha = 'center', fontsize = 15)\nplt.title('Reviews polarity', fontsize = 17)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Text pre-processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"nlp = spacy.load('en')\nstopwords_ = set(stopwords.words('english'))\nkeep_track = 1\n\ndef remove_stopwords(text, stopwords):\n    tokens = text.split(' ')\n    tokens = [token for token in tokens if token not in stopwords]\n    return ' '.join(tokens)\n\ndef lemmatize(text):\n    global keep_track\n    \n    doc = nlp(text)\n    lemms = []\n    for token in doc:\n        if token.lemma_.startswith('-'):\n            lemms.append(str(token).lower())\n        else:\n            lemms.append(token.lemma_)\n    lemms = [lemm for lemm in lemms if not lemm.startswith('-')]\n    if keep_track % 100 == 0:\n        print(str(np.round((keep_track/50000)*100, 2)) + '%', end = '\\r')\n    keep_track += 1\n    return ' '.join(lemms) ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"print('Pre-processing ...')\n# Removing line breakers ...\nreviews['review'] = reviews['review'].str.replace('<br />', ' ')\n# Removing digits ...\nreviews['review'] = reviews['review'].str.replace('\\d+', ' ')\n# Lower casing ...\nreviews['review'] = reviews['review'].str.lower()\nprint('Done! ')\n\nprint('Removing stopwords ...')\nreviews['review'] = reviews['review'].apply(lambda review: remove_stopwords(review, stopwords_))\nprint('Done! ')\n\nprint('Lemmatizing ...')\nreviews['review'] = reviews['review'].apply(lemmatize)\nprint('Done! ')\n\nprint('Removing punctuation ...')\nreviews['review'] = reviews['review'].str.replace('[' + punctuation +']', ' ', regex = True)\n# Squeezing white spaces ...\nreviews['review'] = reviews['review'].str.replace('\\s+', ' ')\nprint('Done! ')\nreviews['review'].head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Splitting data for training"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(reviews['review'], reviews['sentiment'], train_size = .9)\n\nprint('Training dataset : {} reviews'.format(X_train.shape[0]))\nprint('Testing dataset : {} reviews'.format(X_test.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Vectorizing reviews for training\n\nHaving a large vocabulary usually makes ML models overfit the training data. Thus, we will only be using terms that appear in more than 1% of our documents (reviews).\n\nNote : I did go through multiple values of `min_df` and 1% seems to be the optimal value to balance between overfitting and underfitting."},{"metadata":{"trusted":true},"cell_type":"code","source":"vect = TfidfVectorizer(ngram_range = (1, 2), min_df = .01)\nX_train_vect = vect.fit_transform(X_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training Machine learning model"},{"metadata":{},"cell_type":"markdown","source":"### Multinomial Naïve Bayes"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = MultinomialNB(alpha = 0.001).fit(X_train_vect, y_train)\ny_pred_test = model.predict(vect.transform(X_test))\ny_pred_train = model.predict(X_train_vect)\n\nprint('Training data')\nprint(classification_report(y_train, y_pred_train))\nprint('Test data')\nprint(classification_report(y_test, y_pred_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LogisticRegression().fit(X_train_vect, y_train)\ny_pred_test = model.predict(vect.transform(X_test))\ny_pred_train = model.predict(X_train_vect)\n\nprint('Training data')\nprint(classification_report(y_train, y_pred_train))\nprint('Test data')\nprint(classification_report(y_test, y_pred_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = RandomForestClassifier().fit(X_train_vect, y_train)\ny_pred_test = model.predict(vect.transform(X_test))\ny_pred_train = model.predict(X_train_vect)\n\nprint('Training data')\nprint(classification_report(y_train, y_pred_train))\nprint('Test data')\nprint(classification_report(y_test, y_pred_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random Forest seems to be overfitting.\n\nLogistic Regression is giving the best accuracy (89%) which is still low"},{"metadata":{},"cell_type":"markdown","source":"## Going through wrong predictions (Logistic Regression)"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LogisticRegression().fit(X_train_vect, y_train)\ny_pred_test = model.predict(vect.transform(X_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame()\ndf['reviews'] = X_test\ndf['predicted sentiment'] = y_pred_test\ndf['actual sentiment'] = y_test\ndf = df[df['actual sentiment'] != df['predicted sentiment']]\n\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looking at review 33066 which was labeled positive and predicted negative"},{"metadata":{"trusted":true},"cell_type":"code","source":"reviews['review'][33066]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"One of the most common issues encountered while making ML model or DL model is mis-labeled data and on the example above we can clearly notice an example. The review reflected negative feedback with term such as \"weak script\", \"slow pace\", \"exhaustingly long\", ...\n\nThis doesn't change the fact that some reviews are wrongly classified (example below)"},{"metadata":{"trusted":true},"cell_type":"code","source":"reviews['review'][7428]","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}