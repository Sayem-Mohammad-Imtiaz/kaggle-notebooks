{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_orig=pd.read_csv(\"/kaggle/input/twitter-sentiment-analysis-hatred-speech/train.csv\")\ntest_nolabel=pd.read_csv(\"/kaggle/input/twitter-sentiment-analysis-hatred-speech/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Let us do some pre-processing. Without preprocessing results are:  (Avoid looking at these metrics in the beginning, will be explained in the end of notebook)**\n<pre>\n               precision    recall  f1-score   support\n \n            0       0.95      1.00      0.97     14880\n            1       0.85      0.35      0.49      1101\n \n     accuracy                           0.95     15981\n    macro avg       0.90      0.67      0.73     15981\n weighted avg       0.95      0.95      0.94     15981\n \n [[14815    65]\n [  718   383]]\n</pre>"},{"metadata":{},"cell_type":"markdown","source":"**New metric:**\n<pre>\n              precision    recall  f1-score   support\n\n           0       0.96      1.00      0.98     14848\n           1       0.88      0.40      0.55      1133\n\n    accuracy                           0.95     15981\n   macro avg       0.92      0.70      0.76     15981\nweighted avg       0.95      0.95      0.95     15981\n\n[[14786    62]\n [  683   450]]\n</pre>"},{"metadata":{},"cell_type":"markdown","source":"**New report with stratification enabled. Shows further improvement in results\n**<pre>\n              precision    recall  f1-score   support\n\n           0       0.96      1.00      0.98     14860\n           1       0.89      0.42      0.57      1121\n\n    accuracy                           0.96     15981\n   macro avg       0.92      0.71      0.77     15981\nweighted avg       0.95      0.96      0.95     15981\n\n[[14800    60]\n [  650   471]]\n</pre>"},{"metadata":{},"cell_type":"markdown","source":"**Classification report after upsampling the minority classes. Look at updated values for label 1**\n<pre>\n              precision    recall  f1-score   support\n\n           0       0.98      0.91      0.94     14860\n           1       0.92      0.98      0.95     14860\n\n    accuracy                           0.94     29720\n   macro avg       0.95      0.94      0.94     29720\nweighted avg       0.95      0.94      0.94     29720\n\n[[13542  1318]\n [  345 14515]]\n</pre>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.corpus import stopwords\nfrom nltk import word_tokenize\nimport string\nimport re\nstop_words = set(stopwords.words('english'))\n\ntrain = train_orig\n\ndef remove_stopwords(line):\n    word_tokens = word_tokenize(line)\n    filtered_sentence = [w for w in word_tokens if not w in stop_words] \n    return \" \".join(filtered_sentence)\n\ndef preprocess(line):\n    line = line.lower()  #convert to lowercase\n    line = re.sub(r'\\d+', '', line)  #remove numbers\n    line = line.translate(line.maketrans(\"\",\"\", string.punctuation))  #remove punctuation\n#     line = line.translate(None, string.punctuation)  #remove punctuation\n    line = remove_stopwords(line)\n    return line\nfor i,line in enumerate(train.tweet):\n    train.tweet[i] = preprocess(line)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(train['tweet'], train['label'], test_size=0.5, stratify=train['label'])\n\ntrainp=train[train.label==1]\ntrainn=train[train.label==0]\nprint(trainp.info())\ntrainn.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let us balance the dataset\ntrain_imbalanced = train\nfrom sklearn.utils import resample\ndf_majority = train[train.label==0]\ndf_minority = train[train.label==1]\n \n# Upsample minority class\ndf_minority_upsampled = resample(df_minority, \n                                 replace=True,     # sample with replacement\n                                 n_samples=len(df_majority),    # to match majority class\n                                 random_state=123) # reproducible results\n \n# Combine majority class with upsampled minority class\ndf_upsampled = pd.concat([df_majority, df_minority_upsampled])\n \n# Display new class counts\nprint(\"Before\")\nprint(train.label.value_counts())\nprint(\"After\")\nprint(df_upsampled.label.value_counts())\n\nX_train, X_test, y_train, y_test = train_test_split(df_upsampled['tweet'], df_upsampled['label'], test_size=0.5, stratify=df_upsampled['label'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nmodel = MultinomialNB()\n# Xtext=train.tweet\n# Xtest=test.tweet\n# y=train.label\n# test\n# ytest=test.label","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Convert text data to numerical data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nvect = CountVectorizer()\ntf_train=vect.fit_transform(X_train)  #train the vectorizer, build the vocablury\ntf_test=vect.transform(X_test)  #get same encodings on test data as of vocabulary built","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf_test_nolabel=vect.transform(test_nolabel.tweet)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(tf_train)\n# vect.get_feature_names()[:10] #print few features only to avoid slowing down the notebook","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X=tf_train,y=y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"expected = y_test\npredicted=model.predict(tf_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\n\nprint(metrics.classification_report(expected, predicted))\nprint(metrics.confusion_matrix(expected, predicted))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from mlxtend.plotting import plot_confusion_matrix\n\nplot_confusion_matrix(metrics.confusion_matrix(expected, predicted))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(trainp.iloc[:10])\ntrainn.iloc[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gg=X_test.reset_index(drop=True)\n# print(gg)\nfor i, p in enumerate(predicted):\n#     print(i)\n    print (gg[i] + \" - \" + str(p))\n    if i>5:\n        break #to avoid a lot of printing and slowing down the notebook","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_nolabel=model.predict(tf_test_nolabel)\nfor i, p in enumerate(tf_test_nolabel):\n#     print(i)\n    print (test_nolabel.tweet[i] + \" - \" + str(predicted_nolabel[i]))\n    if i>5:\n        break #to avoid a lot of printing and slowing down the notebook","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_custom=pd.DataFrame([\"racist\", \"white judge trial\", \"it is a horrible incident\", \"@user #white #supremacists want everyone to see the new â  #birdsâ #movie â and hereâs why\", \" @user #white #supremacists want everyone to see the new â  #birdsâ #movie â and hereâs why\", \"@user  at work: attorneys for white officer who shot #philandocastile remove black judge from presiding over trial. htâ¦\"])\ntf_custom = vect.transform(test_custom[0])\nmodel.predict(tf_custom)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}