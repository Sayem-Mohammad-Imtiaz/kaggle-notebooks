{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"In this assignment, I will using the kNN (k-Nearest Neighbors) algorithm to solve a classification problem. The kNN is a simple and robust classifier, which is used in different applications.\n\nThe dataset was first introduced by statistician R. Fisher and consists of 50 observations from each of three species Iris (Iris setosa, Iris virginica and Iris versicolor). For each sample, 4 features are given: the sepal length and width, and the petal length and width.\n\nThe goal is to train kNN algorithm to distinguish the species from one another."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"  Given columns for the dataset\n    \n   1. sepal length in cm\n   2. sepal width in cm\n   3. petal length in cm\n   4. petal width in cm\n   5. class"},{"metadata":{},"cell_type":"markdown","source":"## Load the data from the file (`iris.data`) into the DataFrame. Set the names of columns according to the column definitions given in Data Description."},{"metadata":{"trusted":true},"cell_type":"code","source":"iris_data= pd.read_csv('/kaggle/input/iris-flower-dataset/IRIS.csv')\niris_data.dataframeName= 'Iris.csv'\niris_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"iris_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"iris_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"iris_data.groupby('species').size()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Statistical Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"iris_data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## * There are 150 observations with 4 different features such as sepal_length, sepal_width, petal_length, petal_width. And, there are three different species\n(Iris - setosa, virginica, versicolor)\n\n* No null values."},{"metadata":{},"cell_type":"markdown","source":"# Plot & visualize data"},{"metadata":{},"cell_type":"markdown","source":"## sepal length vs sepal width"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lmplot(x='sepal_length', y= 'sepal_width', hue ='species',data= iris_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## petal length vs petal width"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lmplot(x='petal_length', y= 'petal_width', hue ='species', data= iris_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(hue ='species', data= iris_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you could see in the above graphs, it is clear that the relationship between iris-setosa(blue) is distinctly different from other two species. Setosa has small petals, versicolor has medium sized petals and virginica have the largest petals and some overlap between those  two species (Iris-virginica , versicolor)."},{"metadata":{},"cell_type":"markdown","source":"## Standardize the variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(iris_data.drop(\"species\",axis =1))\nscaled_features = scaler.transform(iris_data.drop(\"species\",axis =1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_feat= pd.DataFrame(scaled_features, columns=iris_data.columns[: -1])\ndf_feat.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.array(df_feat.iloc[:, 0:4]) \ny = np.array(iris_data['species']) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ny = le.fit_transform(y)\ny","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Split the data into train and test using sklearn train_test_split function.\n\n## 80% train data and 20% test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,\n                                                    test_size=0.20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Run the fit using KNeighborsClassifier from sklearn.neighbors."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = knn.predict(X_test)\nprint(pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix\nprint(confusion_matrix(y_test,pred))\nprint(classification_report(y_test,pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = accuracy_score(y_test, pred)\nprint('accuracy:{}'.format(100*accuracy))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"error_rate = []\n\nfor i in range(1,50):\n    \n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train,y_train)\n    pred_i = knn.predict(X_test)\n    error_rate.append(np.mean(pred_i != y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nplt.plot(range(1,50),error_rate,color='blue', linestyle='dashed', marker='o',\n         markerfacecolor='red', markersize=10)\nplt.title('Error Rate vs. K Value')\nplt.xlabel('K')\nplt.ylabel('Error Rate')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The error rate is lower (0) with lower K value between K= 0 and 10 (0-0.04). As K value increases from  K =10 to 30, the error rate increased as well (0.04) and as K value went further the error value also increased to 0.10. Therefore, somewhere between K = 1 to 30 is a good number to choose for modelling."},{"metadata":{"trusted":true},"cell_type":"code","source":"#NOW WITH K=10\nknn = KNeighborsClassifier(n_neighbors=10)\n\nknn.fit(X_train,y_train)\npred = knn.predict(X_test)\n\nprint('WITH K=10')\nprint('\\n')\nprint(confusion_matrix(y_test,pred))\nprint('\\n')\nprint(classification_report(y_test,pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#NOW WITH K=40\nknn = KNeighborsClassifier(n_neighbors=40)\n\nknn.fit(X_train,y_train)\npred = knn.predict(X_test)\n\nprint('WITH K=40')\nprint('\\n')\nprint(confusion_matrix(y_test,pred))\nprint('\\n')\nprint(classification_report(y_test,pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#NOW WITH K=50\nknn = KNeighborsClassifier(n_neighbors=50)\n\nknn.fit(X_train,y_train)\npred = knn.predict(X_test)\n\nprint('WITH K=50')\nprint('\\n')\nprint(confusion_matrix(y_test,pred))\nprint('\\n')\nprint(classification_report(y_test,pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Thanks!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}