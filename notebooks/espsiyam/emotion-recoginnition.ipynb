{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/facial-expression-recognitionferchallenge/fer2013/fer2013/fer2013.csv')\nprint(df.shape)\nprint(type(df))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.emotion.unique()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emotion_label_to_text = {0:'anger', 1:'disgust',2:'fear', 3:'happiness',4:'sadness',5:'surprice',6:'neural'}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.emotion.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import scikitplot\nimport seaborn as sns\nfrom matplotlib import pyplot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df.emotion)\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.pixels[0].split(' ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df.pixels[0].split(' '))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\nmath.sqrt(len(df.pixels[0].split(' ')))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df.emotion==1].pixels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = pyplot.figure(1,(14,14))\nk=0\n\nfor label in sorted(df.emotion.unique()):\n    for j in range(7):\n        px = df[df.emotion==label].pixels.iloc[k]   #Image of a single photo of a specific emotion\n        px = np.array(px.split(' ')).reshape(48,48).astype('float32') #Converting into nupy array,spllition numbers by comma(,), Then converting it into float32 dtype which is required in cnn\n        \n        k = k+1\n        \n        ax = pyplot.subplot(7,7,k)\n        ax.imshow(px,cmap='gray')\n        ax.set_xticks([]) #Remove scale from x axis\n        ax.set_yticks([]) #Remove scale from y axis\n        ax.set_title(emotion_label_to_text[label]) #To give title of emotion in every photo","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"INTERESTED_LABELS = [3, 4, 6] #As they have the hightest number of phtos\n# 3 = happiness\n# 4 = sadness\n# 6 = neural","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[df.emotion.isin(INTERESTED_LABELS)]  #To take the data for interested labels\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's make tha data compatible for cnn"},{"metadata":{"trusted":true},"cell_type":"code","source":"img_array = df.pixels.apply(lambda x: np.array(x.split(' ')).reshape(48,48,1).astype('float32'))\nimg_array = np.stack(img_array, axis = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_array.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.emotion","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\nimg_labels = le.fit_transform(df.emotion)\nimg_labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import np_utils\nimg_labels = np_utils.to_categorical(img_labels)\nimg_labels.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le.classes_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" le.transform(le.classes_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" dict(zip(le.classes_, le.transform(le.classes_)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\nprint(le_name_mapping)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train,X_test,y_train,y_test = train_test_split(img_array,img_labels,test_size = 0.1, random_state = 42,shuffle = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_width = X_train.shape[1]\nimg_height = X_train.shape[2]\nimg_depth = X_train.shape[3]\nnum_classes = y_train.shape[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train / 255.\nX_test = X_test / 255.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Flatten, Dense, Conv2D, MaxPooling2D, Concatenate\nfrom tensorflow.keras.layers import Dropout, BatchNormalization\nfrom tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_net(optim):\n    net = Sequential(name='DCNN')\n\n    net.add(\n        Conv2D(\n            filters=64,\n            kernel_size=(5,5),\n            input_shape=(img_width, img_height, img_depth),\n            activation='elu',\n            padding='same',\n            kernel_initializer='he_normal',\n            name='conv2d_1'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_1'))\n    net.add(\n        Conv2D(\n            filters=64,\n            kernel_size=(5,5),\n            activation='elu',\n            padding='same',\n            kernel_initializer='he_normal',\n            name='conv2d_2'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_2'))\n    \n    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_1'))\n    net.add(Dropout(0.4, name='dropout_1'))\n\n    net.add(\n        Conv2D(\n            filters=128,\n            kernel_size=(3,3),\n            activation='elu',\n            padding='same',\n            kernel_initializer='he_normal',\n            name='conv2d_3'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_3'))\n    net.add(\n        Conv2D(\n            filters=128,\n            kernel_size=(3,3),\n            activation='elu',\n            padding='same',\n            kernel_initializer='he_normal',\n            name='conv2d_4'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_4'))\n    \n    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_2'))\n    net.add(Dropout(0.4, name='dropout_2'))\n\n    net.add(\n        Conv2D(\n            filters=256,\n            kernel_size=(3,3),\n            activation='elu',\n            padding='same',\n            kernel_initializer='he_normal',\n            name='conv2d_5'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_5'))\n    net.add(\n        Conv2D(\n            filters=256,\n            kernel_size=(3,3),\n            activation='elu',\n            padding='same',\n            kernel_initializer='he_normal',\n            name='conv2d_6'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_6'))\n    \n    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_3'))\n    net.add(Dropout(0.5, name='dropout_3'))\n\n    net.add(Flatten(name='flatten'))\n        \n    net.add(\n        Dense(\n            128,\n            activation='elu',\n            kernel_initializer='he_normal',\n            name='dense_1'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_7'))\n    \n    net.add(Dropout(0.6, name='dropout_4'))\n    \n    net.add(\n        Dense(\n            num_classes,\n            activation='softmax',\n            name='out_layer'\n        )\n    )\n    \n    net.compile(\n        loss='categorical_crossentropy',\n        optimizer=optim,\n        metrics=['accuracy']\n    )\n    \n    net.summary()\n    \n    return net\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nearly_stopping = EarlyStopping(\n    monitor='val_accuracy',\n    min_delta=0.00005,\n    patience=11,\n    verbose=1,\n    restore_best_weights=True,\n)\n\nlr_scheduler = ReduceLROnPlateau(\n    monitor='val_accuracy',\n    factor=0.5,\n    patience=7,\n    min_lr=1e-7,\n    verbose=1,\n)\n\ncallbacks = [\n    early_stopping,\n    lr_scheduler,\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rotation_range=15,\n    width_shift_range=0.15,\n    height_shift_range=0.15,\n    shear_range=0.15,\n    zoom_range=0.15,\n    horizontal_flip=True,\n)\ntrain_datagen.fit(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 32 \nepochs = 10\noptims = [\n    optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name='Nadam'),\n    optimizers.Adam(0.001),\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = build_net(optims[1]) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit_generator(\n    train_datagen.flow(X_train, y_train, batch_size=batch_size),\n    validation_data=(X_test, y_test),\n    steps_per_epoch=len(X_train) / batch_size,\n    epochs=epochs,\n    callbacks=callbacks,\n    use_multiprocessing=True\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_yaml = model.to_yaml()\nwith open(\"model.yaml\", \"w\") as yaml_file:\n    yaml_file.write(model_yaml)\n    \nmodel.save(\"model.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set()\nfig = pyplot.figure(0, (12, 4))\n\nax = pyplot.subplot(1, 2, 1)\nsns.lineplot(history.epoch, history.history['accuracy'], label='train')\nsns.lineplot(history.epoch, history.history['val_accuracy'], label='valid')\npyplot.title('Accuracy')\npyplot.tight_layout()\n\nax = pyplot.subplot(1, 2, 2)\nsns.lineplot(history.epoch, history.history['loss'], label='train')\nsns.lineplot(history.epoch, history.history['val_loss'], label='valid')\npyplot.title('Loss')\npyplot.tight_layout()\n\npyplot.savefig('epoch_history_dcnn.png')\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_accu = pd.DataFrame({'train': history.history['accuracy'], 'valid': history.history['val_accuracy']})\ndf_loss = pd.DataFrame({'train': history.history['loss'], 'valid': history.history['val_loss']})\n\nfig = pyplot.figure(0, (14, 4))\nax = pyplot.subplot(1, 2, 1)\nsns.violinplot(x=\"variable\", y=\"value\", data=pd.melt(df_accu), showfliers=False)\npyplot.title('Accuracy')\npyplot.tight_layout()\n\nax = pyplot.subplot(1, 2, 2)\nsns.violinplot(x=\"variable\", y=\"value\", data=pd.melt(df_loss), showfliers=False)\npyplot.title('Loss')\npyplot.tight_layout()\n\npyplot.savefig('performance_dist.png')\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nyhat_valid = model.predict_classes(X_test)\nscikitplot.metrics.plot_confusion_matrix(np.argmax(y_test, axis=1), yhat_valid, figsize=(7,7))\npyplot.savefig(\"confusion_matrix_dcnn.png\")\n\nprint(f'total wrong validation predictions: {np.sum(np.argmax(y_test, axis=1) != yhat_valid)}\\n\\n')\nprint(classification_report(np.argmax(y_test, axis=1), yhat_valid))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mapper = {\n    0: \"happy\",\n    1: \"sad\",\n    2: \"neutral\",\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(2)\nrandom_sad_imgs = np.random.choice(np.where(y_test[:, 1]==1)[0], size=9)\nrandom_neutral_imgs = np.random.choice(np.where(y_test[:, 2]==1)[0], size=9)\n\nfig = pyplot.figure(1, (18, 4))\n\nfor i, (sadidx, neuidx) in enumerate(zip(random_sad_imgs, random_neutral_imgs)):\n        ax = pyplot.subplot(2, 9, i+1)\n        sample_img = X_test[sadidx,:,:,0]\n        ax.imshow(sample_img, cmap='gray')\n        ax.set_xticks([])\n        ax.set_yticks([])\n        ax.set_title(f\"true:sad, pred:{mapper[model.predict_classes(sample_img.reshape(1,48,48,1))[0]]}\")\n\n        ax = pyplot.subplot(2, 9, i+10)\n        sample_img = X_test[neuidx,:,:,0]\n        ax.imshow(sample_img, cmap='gray')\n        ax.set_xticks([])\n        ax.set_yticks([])\n        ax.set_title(f\"t:neut, p:{mapper[model.predict_classes(sample_img.reshape(1,48,48,1))[0]]}\")\n\n        pyplot.tight_layout()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}