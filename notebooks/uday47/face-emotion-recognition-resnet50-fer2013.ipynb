{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this Notebook, We'll train a CNN model that is similar to ResNet50 in architecture."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Let us first import the needed packages.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import layers\nfrom keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\nfrom keras.models import Model, load_model\nfrom keras.preprocessing import image\nfrom keras.utils import layer_utils\nfrom keras.utils.data_utils import get_file\nfrom keras.applications.imagenet_utils import preprocess_input\nimport pydot\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.utils import plot_model\n\nfrom keras.initializers import glorot_uniform\nimport scipy.misc\nfrom matplotlib.pyplot import imshow\n%matplotlib inline\n\nimport keras.backend as K\nK.set_image_data_format('channels_last')\nK.set_learning_phase(1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Create a directory to save our generated models.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"os.mkdir(\"./model\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Define the identity block helper function.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def identity_block(X, f, filters, stage, block):\n    \"\"\"\n    Implementation of the identity block\n    \n    Arguments:\n    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n    f -- integer, specifying the shape of the middle CONV's window for the main path\n    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n    stage -- integer, used to name the layers, depending on their position in the network\n    block -- string/character, used to name the layers, depending on their position in the network\n    \n    Returns:\n    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n    \"\"\"\n    \n    # defining name basis\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n    \n    # Retrieve Filters\n    F1, F2, F3 = filters\n    \n    # Save the input value. You'll need this later to add back to the main path. \n    X_shortcut = X\n    \n    # First component of main path\n    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n    \n   \n    # Second component of main path\n    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n\n    # Third component of main path \n    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n\n    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n    X = Add()([X_shortcut,X])\n    X = Activation(\"relu\")(X)\n        \n    return X","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Define the covolutional block helper function.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def convolutional_block(X, f, filters, stage, block, s = 2):\n    \"\"\"\n    Implementation of the convolutional block4\n    \n    Arguments:\n    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n    f -- integer, specifying the shape of the middle CONV's window for the main path\n    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n    stage -- integer, used to name the layers, depending on their position in the network\n    block -- string/character, used to name the layers, depending on their position in the network\n    s -- Integer, specifying the stride to be used\n    \n    Returns:\n    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n    \"\"\"\n    \n    # defining name basis\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n    \n    # Retrieve Filters\n    F1, F2, F3 = filters\n    \n    # Save the input value\n    X_shortcut = X\n\n\n    ##### MAIN PATH #####\n    # First component of main path \n    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n    \n    # Second component of main path \n    X = Conv2D(F2, (f, f), strides = (1,1), name = conv_name_base + '2b',padding = 'same', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n\n    # Third component of main path \n    X = Conv2D(F3, (1, 1), strides = (1,1), name = conv_name_base + '2c',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n\n    ##### SHORTCUT PATH #### \n    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n\n    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n    X = Add()([X_shortcut,X])\n    X = Activation(\"relu\")(X)\n        \n    return X","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Merge them together into the model.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def Net50(input_shape = (48,48,1), classes = 7):\n    \"\"\"\n    Implementation of the popular ResNet50 the following architecture:\n    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n\n    Arguments:\n    input_shape -- shape of the images of the dataset\n    classes -- integer, number of classes\n\n    Returns:\n    model -- a Model() instance in Keras\n    \"\"\"\n    \n    # Define the input as a tensor with shape input_shape\n    X_input = Input(input_shape)\n\n    \n    # Zero-Padding\n    #X = ZeroPadding2D((1, 1))(X_input)\n    X = X_input\n    # Stage 1\n\n    X = Conv2D(8, (3, 3), strides = (1, 1), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n    X = Activation('relu')(X)\n    # removed maxpool\n    #X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n\n    # Stage 2\n    X = convolutional_block(X, f = 3, filters = [32, 32, 128], stage = 2, block='a', s = 1)\n    X = identity_block(X, 3, [32, 32, 128], stage=2, block='b')\n    X = identity_block(X, 3, [32, 32, 128], stage=2, block='c')\n\n\n    # Stage 3 \n    X = convolutional_block(X, f = 3, filters = [64,64,256], stage = 3, block='a', s = 2)\n    X = identity_block(X, 3, [64,64,256], stage=3, block='b')\n    X = identity_block(X, 3, [64,64,256], stage=3, block='c')\n    X = identity_block(X, 3, [64,64,256], stage=3, block='d')\n\n    # Stage 4 \n    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 4, block='a', s = 2)\n    X = identity_block(X, 3, [128, 128, 512], stage=4, block='b')\n    X = identity_block(X, 3, [128, 128, 512], stage=4, block='c')\n    X = identity_block(X, 3, [128, 128, 512], stage=4, block='d')\n    X = identity_block(X, 3, [128, 128, 512], stage=4, block='e')\n    X = identity_block(X, 3, [128, 128, 512], stage=4, block='f')\n\n    # Stage 5 \n    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 5, block='a', s = 2)\n    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='b')\n    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='c')\n\n    # AVGPOOL . \n    X = AveragePooling2D((2,2), name='avg_pool')(X)\n    \n    # output layer\n    X = Flatten()(X)\n    X = Dense(512, activation = 'relu', name='fc1024' , kernel_initializer = glorot_uniform(seed=0))(X)\n    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n    \n    \n    # Create model\n    model = Model(inputs = X_input, outputs = X, name='Net50')\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Load and preprocess the dataset.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\nfrom keras.callbacks import ReduceLROnPlateau\nimport tensorflow as tf\n \ndataset_path = '../input/fer2013/fer2013.csv'\nimage_size=(48,48)\nbatch_size = 32\n\ndef load_fer2013():\n    data = pd.read_csv(dataset_path)\n    data = (data[data['pixels'].notnull()])\n    pixels = data['pixels'].tolist()\n    width, height = 48, 48\n    faces = []\n    for pixel_sequence in pixels:\n        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n        face = np.asarray(face).reshape(width, height)\n        face = cv2.resize(face.astype('uint8'),image_size)\n        faces.append(face.astype('float32'))\n    faces = np.asarray(faces)\n    faces = np.expand_dims(faces, -1)\n    emotions = (data['emotion'])#.values\n    return faces, emotions\n \ndef preprocess_input(x, v2=True):\n    x = x.astype('float32')\n    x = x / 255.0\n    if v2:\n        x = x - 0.5\n        x = x * 2.0\n    return x\n \nfaces, emotions = load_fer2013()\nfaces = preprocess_input(faces)\nxtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True)\n#Data Augumentation\ndata_generator = ImageDataGenerator(\n                        featurewise_center=False,\n                        featurewise_std_normalization=False,\n                        rotation_range=10,\n                        shear_range = 10,\n                        width_shift_range=0.1,\n                        height_shift_range=0.1,\n                        zoom_range=.1,\n                        horizontal_flip=True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Declaring hyperparameters and callbacks.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 32\nnum_epochs = 150\ninput_shape = (48, 48, 1)\nverbose = 1\nnum_classes = 7\npatience = 25\nbase_path = './model/'\nl2_regularization=0.01\n\n# callbacks\nlog_file_path = base_path + '_emotion_training.log'\ncsv_logger = CSVLogger(log_file_path, append=False)\nearly_stop = EarlyStopping('val_loss', patience=patience)\nreduce_lr = ReduceLROnPlateau('val_loss', factor=0.1, patience=int(patience/2), verbose=1)\ntrained_models_path = base_path + '_mini_XCEPTION'\nmodel_names = trained_models_path + '.{epoch:02d}-{val_accuracy:.2f}.hdf5'\nmodel_checkpoint = ModelCheckpoint(model_names, 'val_loss', verbose=1,save_best_only=True)\ncallbacks = [model_checkpoint, csv_logger, early_stop, reduce_lr]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Compile the model.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.optimizers import Adam, SGD\nmodel = Net50(input_shape = (48, 48, 1), classes = 7)\noptimizer = Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, epsilon=1e-7)\nmodel.compile(optimizer= optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(data_generator.flow(xtrain, ytrain,),\n                        steps_per_epoch=len(xtrain) / batch_size,\n                        epochs=num_epochs, verbose=1, callbacks=callbacks,\n                        validation_data= (xtest,ytest))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plot performance metrics.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom matplotlib import pyplot as plt\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testloss = model.evaluate(xtest, ytest) \nprint(\"Test Loss \" + str(testloss[0]))\nprint(\"Test Acc: \" + str(testloss[1]))\ntrainloss = model.evaluate(xtrain, ytrain) \nprint(\"Train Loss \" + str(trainloss[0]))\nprint(\"Train Acc: \" + str(trainloss[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Visualizing model architecture.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(model, to_file='model.png')\nSVG(model_to_dot(model).create(prog='dot', format='svg'))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}