{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Objective (Problem Statement): To predict the area burned in the Forest Fire."},{"metadata":{},"cell_type":"markdown","source":"## Import Library"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import library\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import zscore\nimport xgboost as xgb\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import LabelEncoder \nfrom sklearn.model_selection import train_test_split\n\n\npd.set_option('display.float_format', lambda x: '{:.4f}'.format(x)) #Limiting 4 decimal\nplt.rcParams[\"figure.figsize\"] = [9,5]\nplt.style.use('ggplot')\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load & Describe Dataset"},{"metadata":{},"cell_type":"markdown","source":"### Load"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df = pd.read_csv(\"../input/forest-fires-data-set/forestfires.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### First Five Rows"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Set Target Variable\nWe need to find area burned so we set target equals to area "},{"metadata":{"trusted":true},"cell_type":"code","source":"target = 'area' ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Shape"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data types"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We need to convert month and day to either `int` or `float` from object data type"},{"metadata":{},"cell_type":"markdown","source":"### Feature Columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Describe Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p>As we can see count of every feature columns are same as shape of dataset. So we can say there is no missing data but we need to check to confirm. We will check later.</p>\n<p>Wen can see 50% (the middle of the data) also called median of feature columns('X', 'Y', 'DMC', 'ISI', 'RH', 'wind', 'rain', 'area') have higher mean value than median i.e data is right skewed. In all feature columns, column: 'area' is highly skewed.    \n</p>"},{"metadata":{},"cell_type":"markdown","source":"#### How to handle right skewed data?\n<p>Here data are right-skewed (clustered at lower values). We will perform operations like:- square root, cube root, logarithmic, etc. to transform the data. If the data are left-skewed (clustered at higher values). We will perform operations like:- cube, square, etc.</p>"},{"metadata":{},"cell_type":"markdown","source":"## EDA(Explotary Data Analysis)"},{"metadata":{},"cell_type":"markdown","source":"### Check missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculating missing data in feature columns\ndata_mis = (data_df.isnull().sum() / len(data_df)) * 100\ndata_mis = data_mis.drop(data_mis[data_mis == 0].index).sort_values(ascending=False)\ndata_mis = pd.DataFrame({'Percentage' :data_mis})\ndata_mis['Id'] = data_mis.index\ndata_mis.reset_index(drop=True,level=0, inplace=True)\ndata_mis.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No missing value is found in the dataset."},{"metadata":{},"cell_type":"markdown","source":"#### Numerical and & Categorical Columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"dft = data_df.drop(columns=target)\ncate_columns = dft.select_dtypes(include='object').columns.tolist()\nnume_columns = dft.select_dtypes(exclude='object').columns.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Categorical columns: ',cate_columns)\nprint('Numerical columns: ',nume_columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Univariate Check"},{"metadata":{},"cell_type":"markdown","source":"### Skewness & Kurtosis"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Skew: \\n{}\".format(data_df.skew()))\nprint(\"Kurtosis: \\n{}\".format(data_df.kurtosis()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p>Skew is the degree of distortion from a normal distribution. skewed, meaning there are a minority of very large values.</p>\n<p>Kurtosis is all about the tails of the distribution — not the peakedness or flatness. It is used to describe the extreme values in one versus the other tail. It is actually the measure of outliers present in the distribution . High kurtosis in a data set is an indicator that data has heavy tails or outliers.</p>"},{"metadata":{},"cell_type":"markdown","source":"<p>If skewness is positive, the data are positively skewed or skewed right, meaning that the right tail of the distribution is longer than the left. If skewness is negative, the data are negatively skewed or skewed left, meaning that the left tail is longer.</p>"},{"metadata":{},"cell_type":"markdown","source":"<ul>\n    <li>If skewness is less than −1 or greater than +1, the distribution is highly skewed.</li>\n    <li>If skewness is between −1 and −½ or between +½ and +1, the distribution is moderately skewed.</li>\n    <li>If skewness is between −½ and +½, the distribution is approximately symmetric.</li>\n</ul>"},{"metadata":{},"cell_type":"markdown","source":"<ul>\n<li>A normal distribution has kurtosis exactly 3 (excess kurtosis exactly 0). Any distribution with kurtosis ≈3 (excess ≈0) is called mesokurtic.</li>\n<li>A distribution with kurtosis &lt;3 (excess kurtosis &lt;0 ) is called platykurtic. Compared to a normal distribution, its tails are shorter and thinner, and often its central peak is lower and broader.</li>\n<li>A distribution with kurtosis &gt;3 (excess kurtosis >0) is called leptokurtic. Compared to a normal distribution, its tails are longer and fatter, and often its central peak is higher and sharper.</li>\n</ul>"},{"metadata":{},"cell_type":"markdown","source":"<p>\n<b> Feature columns:- 'ISI', & 'rain'  have +ve skewness, value more than +1 so, they are right skewed.</b>\n</p>    "},{"metadata":{},"cell_type":"markdown","source":"<p>\n<b> Feature columns:- 'FFMC', & 'temp'  have -ve skewness, value less than -1 so, they are left skewed.</b>\n</p>    "},{"metadata":{},"cell_type":"markdown","source":"<p>\n<b> Feature columns:- 'FFMC', 'ISI', & 'rain'  have higher kurtosis value. i,e have outliers.</b>\n</p>    "},{"metadata":{},"cell_type":"markdown","source":"Feature columns with (high, +ve, or -ve) outliers, skewness and kurtosis are: \n<ol>\n<li>FFMC</li>\n<li>ISI</li>\n<li>rain</li>\n</ol>"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,5))\nax = sns.kdeplot(data_df[target],shade=True,color='b')\nplt.xticks([i for i in range(0,1250,50)])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### target i.e area is right skewed."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,5))\nax = sns.kdeplot(data_df['FFMC'],shade=True,color='b')\nplt.xticks([i for i in range(0,100,5)])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### FFMC is left skewed."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,5))\nax = sns.kdeplot(data_df['ISI'],shade=True,color='b')\nplt.xticks([i for i in range(0,100,5)])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### ISI is right skewed."},{"metadata":{},"cell_type":"markdown","source":"### Outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"outl_dect = sns.boxplot(data_df[target])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outl_dect = sns.boxplot(data_df['FFMC'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outl_dect = sns.boxplot(data_df['ISI'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outl_dect = sns.boxplot(data_df['rain'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Outlier analysis"},{"metadata":{},"cell_type":"markdown","source":"Outliers are found in the following columns:\n<ol>\n<li>area</li>\n<li>FFMC</li>\n<li>ISI</li>\n<li>rain</li>\n</ol>\n"},{"metadata":{},"cell_type":"markdown","source":"<p>Instead of removing them we will transform the data to treat the outliers.</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"outlier_columns = ['area','FFMC','ISI','rain']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.log1p(data_df[outlier_columns]).skew()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.log1p(data_df[outlier_columns]).kurtosis()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Even after transformation we still have high skewness and kurtosis in `FFMC` & `rain`"},{"metadata":{},"cell_type":"markdown","source":"<p>Removing outliers by zscore method.</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"mask = data_df.loc[:,['FFMC']].apply(zscore).abs() < 3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df = data_df[mask.values]\ndata_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Since most of the values in rain are 0.0, we can convert it as a categorical column\ndata_df['rain'] = data_df['rain'].apply(lambda x: int(x > 0.0))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outlier_columns.remove('rain')\ndata_df[outlier_columns] = np.log1p(data_df[outlier_columns])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df[outlier_columns].skew()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df[outlier_columns].kurtosis() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dataset is ready for model preparation."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_sel = data_df.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Applying xgboost"},{"metadata":{},"cell_type":"markdown","source":"Encoding `day` & `month` column with label encoder"},{"metadata":{"trusted":true},"cell_type":"code","source":"le = LabelEncoder() \n  \ndata_sel['day']= le.fit_transform(data_sel['day']) \ndata_sel['month']= le.fit_transform(data_sel['month']) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X, y = data_sel.iloc[:,:-1],data_sel.iloc[:,-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=7)\n\n#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=123)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dividing dataset into 33% test sample and 67% training sample ."},{"metadata":{"trusted":true},"cell_type":"code","source":"#xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n#                max_depth = 5, alpha = 10, n_estimators = 10)\n\nxg_reg = xgb.XGBRegressor(base_score=0.3, booster='gbtree', colsample_bylevel=1,\n       colsample_bytree=0.24, gamma=0, learning_rate=0.01, max_delta_step=0,\n       max_depth=3, min_child_weight=1, missing=None, n_estimators=102,\n       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n       silent=True, subsample=1)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#eval_set = [(X_test, y_test)]\neval_set = [(X_train, y_train), (X_test, y_test)]\nxg_reg.fit(X_train, y_train, eval_metric=[\"rmse\"],eval_set=eval_set, verbose=False)\npreds = xg_reg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### verbose set to False so that we can hide results of model fit progress"},{"metadata":{"trusted":true},"cell_type":"code","source":"def calc_ISE(X_train, y_train, model):\n    '''returns the in-sample R^2 and RMSE; assumes model already fit.'''\n    predictions = model.predict(X_train)\n    mse = mean_squared_error(y_train, predictions)\n    rmse = np.sqrt(mse)\n    return model.score(X_train, y_train), rmse\n    \ndef calc_OSE(X_test, y_test, model):\n    '''returns the out-of-sample R^2 and RMSE; assumes model already fit.'''\n    predictions = model.predict(X_test)\n    mse = mean_squared_error(y_test, predictions)\n    rmse = np.sqrt(mse)\n    return model.score(X_test, y_test), rmse\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Calculate In-Sample and Out-of-Sample R^2 and Error**"},{"metadata":{"trusted":true},"cell_type":"code","source":"is_r2, ise = calc_ISE(X_train, y_train,xg_reg )\nos_r2, ose = calc_OSE(X_test, y_test, xg_reg)\n\n# show dataset sizes\ndata_list = (('R^2_in', is_r2), ('R^2_out', os_r2), \n             ('ISE', ise), ('OSE', ose))\nfor item in data_list:\n    print('{:10}: {}'.format(item[0], item[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Clearly test error(OSE) is near to the training error(ISE). i.e our model is ok.\n**"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('train/test: ',ose/ise)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rmse = np.sqrt(mean_squared_error(y_test, preds))\nprint(\"RMSE: %f\" % (rmse))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb.plot_tree(xg_reg,num_trees=0)\n\nplt.rcParams['figure.figsize'] = [15, 15]\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb.plot_importance(xg_reg)\nplt.rcParams['figure.figsize'] = [7, 7]\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# retrieve performance metrics\nresults = xg_reg.evals_result()\nepochs = len(results['validation_0']['rmse'])\nx_axis = range(0, epochs)\n# plot RMSE\nfig, ax = plt.subplots()\nax.plot(x_axis, results['validation_0']['rmse'], label='Train')\nax.plot(x_axis, results['validation_1']['rmse'], label='Test')\nax.legend()\nplt.ylabel('RMSE')\nplt.title('XGBoost RMSE')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xg_reg.save_model('0001.model_forest_fire')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":4}