{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I have always been curious of how tweets can affect a company's share price. If you have the same question in mind, I hope to address it in this notebook. \n\n*P.S I am still fairly new to this and I would welcome any form of feedback as to how to improve my skill or approach to this question*"},{"metadata":{},"cell_type":"markdown","source":"**Importing the essential libraries**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nfrom scipy import stats as stat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cpy = pd.read_csv('../input/tweets-about-the-top-companies-from-2015-to-2020/Company.csv')\ncpy_tweet = pd.read_csv('../input/tweets-about-the-top-companies-from-2015-to-2020/Company_Tweet.csv')\ntweet = pd.read_csv('../input/tweets-about-the-top-companies-from-2015-to-2020/Tweet.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Inspecting the dataframes**"},{"metadata":{"trusted":true},"cell_type":"code","source":"cpy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cpy_tweet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweet","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After inspecting the dataframes, I decided to merge the tweet dataframe with the cpy_tweet dataframe which will allow me to identify the company that is talked about in the tweet"},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets = pd.merge(tweet,cpy_tweet,on='tweet_id',how='inner')\ntweets.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets['post_date'] = pd.to_datetime(tweets['post_date'], unit='s')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets['date'] = pd.to_datetime(tweets['post_date'].apply(lambda date: date.date()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets['date'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets = tweets.drop(['tweet_id'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The \"writer\" column is the only column with missing data. Since we are not likely to use this column, I decided to ignore the missing value for now."},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets.ticker_symbol.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aapl = tweets[tweets['ticker_symbol'] == 'AAPL']\ntsla = tweets[tweets['ticker_symbol'] == 'TSLA']\namzn = tweets[tweets['ticker_symbol'] == 'AMZN']\nmsft = tweets[tweets['ticker_symbol'] == 'MSFT']\ngoog = tweets[tweets['ticker_symbol'] == 'GOOG']\ngoogl = tweets[tweets['ticker_symbol'] == 'GOOGL'] ## With stockholders voting rights","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install yfinance","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import yfinance as yf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tsla_stock = yf.Ticker('TSLA')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start = min(tsla['date'])\nend = max(tsla['date'])\n\ntsla_stock = tsla_stock.history(start=start.date(), end=end.date())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tsla_stock","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aapl_stock = yf.Ticker(\"AAPL\").history(start=min(aapl['date']).date(),end=max(aapl['date']).date())\namzn_stock = yf.Ticker(\"AMZN\").history(start=min(amzn['date']).date(),end=max(amzn['date']).date())\ngoogl_stock = yf.Ticker(\"GOOGL\").history(start=min(googl['date']).date(),end=max(googl['date']).date())\nmsft_stock = yf.Ticker(\"MSFT\").history(start=min(msft['date']).date(),end=max(msft['date']).date())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Firstly, I would like to find out if the amount of tweets affects the volume traded of the particular company. To do that,I made us of panda shift operator to shift the entire timeseries back by 1 period. By doing so, I will be able to compare the effects of the volume of tweets the day before on the particular company share price the following day. \n\nI decided to use the Spearman correlation statistic test instead of the Pearson correlation because Spearman correlation test does not assume that the dataset are normally distributed. \n\n* null hypothesis: There is no correlation between the volume of tweets with the volume of stock traded\n* alternate hypothesis: There is a correlation between the volume of tweets with the volume of stock traded\n\nIf the p-value of the spearman correlation, falls below the pre-determined threshold of 0.05, I will reject the null hypothesis and we will have enough evidence to conclude that there is a positive/negative correlation between the volume of stocks traded and the amount of tweets.\n\nBeside the statistic test, I have also decided to plot the volume traded and the volume of tweets in the same graph to visualise the data for a overview of the relationship between these 2 variables. To get a clearer picture of how these two variables correlates, I had to use the rolling operator to get the average of 30 days window to have a clearer senses of the overall trend. \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def tweet_vol_affect(tweets,stocks,title):\n    tweet_shift1 = tweets.groupby('date').size().shift(-1).dropna() \n    stock_data = stocks['Volume'].dropna()\n    corr, pval = stat.spearmanr(tweet_shift1.reindex(stock_data.index), stock_data,nan_policy='omit')\n    tweets_vol = tweets.groupby('date').size().rolling(30).mean().dropna()\n    stocks_data = stocks['Volume'].rolling(30).mean().dropna()\n    fig = plt.figure(figsize=(16,8))\n    ax1 = fig.add_subplot()\n    ax2 = fig.add_subplot()\n    ax2 = ax1.twinx()\n    ax1.plot(tweets_vol.index,tweets_vol,label='Tweet Volume')\n    ax2.plot(stocks_data.index,stocks_data,color='orange',label='Trade Volume')\n    ax2.set_title(title+\" \\n Spearman correlation: corr={0:.5f} pval={1:.5f}\".format(corr,pval))\n    \n    lines, labels = ax1.get_legend_handles_labels()\n    lines2, labels2 = ax2.get_legend_handles_labels()\n    ax2.legend(lines + lines2, labels + labels2, loc=0)\n    plt.show()\n    \n  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweet_vol_affect(tsla,tsla_stock,\"Tesla\")    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweet_vol_affect(aapl,aapl_stock,\"Apple\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweet_vol_affect(amzn,amzn_stock,\"Amazon\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweet_vol_affect(googl,googl_stock,\"Google\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweet_vol_affect(msft,msft_stock,\"Microsoft\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looking at it, it appears that the shear volume of tweets does seems to have a positive correlation with the trade volume. However, the strength of the correlation is questionable. Additionally, it is not certain that volume of tweets is always correlated with the share price as demostrated in Mircosoft's case where the p-value exceeded the predetermined threshold of 0.05"},{"metadata":{},"cell_type":"markdown","source":"# **Classifying positive and negative tweets**"},{"metadata":{},"cell_type":"markdown","source":"The next hypothesis that I will be testing are as follows:\n* Null Hypothesis: The sentiment of the tweet has no correlation with the shareprice of the company \n* Alternate Hypothesis: The sentiment of the tweet has a correlation with the shareprice of the company\n\nIn order to identify the sentiment of the tweets, I will be using the Afinn library. \n\nMore information can be found [here.](http://pypi.org/project/afinn/)\n\nIn general, the afinn library will be able to provide a score where 0 is neutral, negative value would mean that the tweet is negative while postive would be otherwise."},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install afinn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from afinn import Afinn\nafinn = Afinn()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tsla['score'] =  tsla['body'].apply(lambda tweet: afinn.score(tweet))\naapl['score'] =  aapl['body'].apply(lambda tweet: afinn.score(tweet))\namzn['score'] =  amzn['body'].apply(lambda tweet: afinn.score(tweet))\nmsft['score'] =  msft['body'].apply(lambda tweet: afinn.score(tweet))\ngoogl['score'] =  googl['body'].apply(lambda tweet: afinn.score(tweet))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tsla.score.plot(kind='hist',range=(-5,5),bins=40,edgecolor='black');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"amzn.score.plot(kind='hist',range=(-5,5),bins=40,edgecolor='black');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"googl.score.plot(kind='hist',range=(-5,5),bins=40,edgecolor='black');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"msft.score.plot(kind='hist',range=(-5,5),bins=40,edgecolor='black');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, I will be adopting the same method as aforementioned to test my hypothesis"},{"metadata":{"trusted":true},"cell_type":"code","source":"def sentiment_overtime(tweets,stock,title):\n    visual= tweets.groupby('date')['score'].mean().shift(-1).rolling(30).mean().dropna()\n    corr_test = tweets.groupby('date')['score'].mean().shift(-1).dropna()\n    corr, pval = stat.spearmanr(corr_test.reindex(stock.index), stock['Open'],nan_policy='omit')\n\n    fig = plt.figure(figsize=(16,8))\n    ax1 = fig.add_subplot()\n    ax2 = fig.add_subplot()\n    ax2 = ax1.twinx()\n    \n    ax1.plot(visual.index,visual,label='Tweets Sentiment')\n    ax2.plot(stock.index,stock['Close'],color='orange',label='share price')\n    ax2.set_title(\"Effects of \"+title+\" tweets to shareprice\" +\"\\n Spearman correlation: corr={0:.5f} pval={1:.5f}\".format(corr,pval))\n    lines, labels = ax1.get_legend_handles_labels()\n    lines2, labels2 = ax2.get_legend_handles_labels()\n    ax2.legend(lines + lines2, labels + labels2, loc=0)\n    plt.show()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentiment_overtime(tsla,tsla_stock,\"Tesla\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentiment_overtime(amzn,amzn_stock,\"Amazon\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentiment_overtime(msft,msft_stock,\"Mircosoft\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentiment_overtime(googl,googl_stock,\"Google\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentiment_overtime(aapl,aapl_stock,\"Apple\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There seems to be a stronger correlation between the sentiment of the tweets to the share price of the company as compared to the previous hypothesis. However, the result shown on Tesla dataset appears to show a different result from the rest much like how Microsoft result was different in the previous hypothesis.\n\nIn conclusion, although 4/5 of the companies in this notebook have shown positive result but the strength of the correlation differs across the different company. On top of that, these companies may not be a good representative of the other stocks out there in the market. Further research needs to be done, to prove the viability of using tweet to determine the stock movement of the company."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}