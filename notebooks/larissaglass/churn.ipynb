{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC, LinearSVC\n\n\nclass NumericalTransformer(BaseEstimator, TransformerMixin):\n    #Class Constructor\n    def __init__( self):\n        self.is_fitted = False\n        \n    #Return self, nothing else to do here\n    def fit( self, X, y = None ):\n        self.is_fitted = True\n        self.feature_names = X.columns\n        return self \n    \n    #Custom transform method we wrote that creates aformentioned features and drops redundant ones \n    def transform(self, X, y = None):\n        #Converting any infinity values in the dataset to Nan\n        X = X.replace( [ np.inf, -np.inf ], np.nan )\n        #returns a numpy array\n        return X.values\n    \n    def get_feature_names(self):\n        if self.is_fitted:\n            return self.feature_names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# total charges has a few \" \" values, which hinders conversion\ndf[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors='coerce')\n\n# imputation\ndf[\"TotalCharges\"] = df[\"TotalCharges\"].fillna(value=df[\"TotalCharges\"].mean())\n\n# map Yes/No to True/False\ndf[\"Churn\"] = df[\"Churn\"].str.strip().map({\"Yes\":True, \"No\":False})\n\n# Senior citizen is a boolean variable formatted as int (0/1)\ndf[\"SeniorCitizen\"] = df[\"SeniorCitizen\"].astype(bool)\n\n# map Yes/No to True/False\nfor col in [\"Partner\",\"Dependents\",\"PhoneService\",\"PaperlessBilling\"]:\n    df[col] = df[col].str.strip().map({\"Yes\":True, \"No\":False})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prepare data for model training\n\nfeature_cols = ['gender', 'SeniorCitizen', 'Partner', 'Dependents',\n                'tenure', 'PhoneService', 'MultipleLines', 'InternetService',\n                'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',\n                'StreamingTV', 'StreamingMovies', 'PaperlessBilling',\n                'PaymentMethod', 'MonthlyCharges', 'TotalCharges']\n# Takin contract out because it is misleading. Of course people with month-to-month contract are more free to leave than 2-year contract holders. \n# The contract type is not what is making them leave though. The reason is maybe a bad product or bad support, contract type is just the enabler of churn.\n#'Contract', \n\ntarget_col = 'Churn'\n\nX = df[feature_cols]\ny = df[target_col].values\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Analysis pipeline definition\n\n# treatment of categorical and numerical features\ncategorical_features = df.dtypes[(df.dtypes == object) | (df.dtypes == bool)].index.to_list()\ncategorical_features = list(set(categorical_features).intersection(set(feature_cols)))\n\ncategorical_transformer = OneHotEncoder()\n\n\nnumeric_features = df.dtypes[(df.dtypes == int) | (df.dtypes == float)].index.to_list()\nnumeric_features = list(set(numeric_features).intersection(set(feature_cols)))\n\nnumeric_transformer = NumericalTransformer()\n\n# pull feature preprocessing together\npreprocessor = ColumnTransformer(\n    transformers=[('cat', categorical_transformer, categorical_features),\n                  ('num', numeric_transformer, numeric_features)]\n)\n\n# model\nmodel = LogisticRegression(solver='liblinear')\n\n# define pipeline\nclf = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('classifier', model)])\n\n# fit pipeline\nclf.fit(X_train, y_train)\n\n# score pipeline\nprint(\"Train score: {:.2f}\".format(clf.score(X_train, y_train)))\nprint(\"Test score: {:.2f}\".format(clf.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Prediction accuracy is ~80%, both for training and test set. Not overfitting, maybe slightly underfitting."},{"metadata":{"trusted":true},"cell_type":"code","source":"names = np.concatenate([clf.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names(categorical_features),\n                        clf.named_steps['preprocessor'].named_transformers_['num'].get_feature_names()])\n#names = clf.named_steps['preprocessor'].get_feature_names()\nvalues = np.exp(clf['classifier'].coef_).flatten().round(2)\n\ncoefficients = dict(zip(names, values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"big_coefficients = {k:v for k,v in coefficients.items() if abs(v-1)>0.15}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted(big_coefficients.items(), key=lambda kv: kv[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This means that electronic check payment method and fiber optic internet service are the highest predictors of churn, each increasing probability of churn by 33%. It indicates, that there are problems with these services, that should be addressed. This is supported by the fact that tech support given goes with a lower probability of churn. People are having problems with the services and if they don't receive tech support, they leave. Also, online security seems to be popular and may be advertised more."},{"metadata":{},"cell_type":"markdown","source":"## Training multiple models"},{"metadata":{"trusted":true},"cell_type":"code","source":"configs = []\ntrain_scores = []\ntest_scores = []\n\nfor model in [LogisticRegression(solver='liblinear'), \n              DecisionTreeClassifier(random_state=0, min_samples_leaf=100), \n              KNeighborsClassifier(),\n              GaussianNB(),\n              SVC(random_state=0, gamma='scale')\n              # any other models to test\n              ]:\n    clf = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('classifier', model)])\n    clf.fit(X_train, y_train)\n\n    # score pipeline\n    configs.append(str(model))\n    train_scores.append(round(clf.score(X_train, y_train),2))\n    test_scores.append(round(clf.score(X_test, y_test),2))\n    \nresults = pd.DataFrame(list(zip(configs, train_scores, test_scores)), columns=[\"model\",\"train_score\",\"test_score\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":1}