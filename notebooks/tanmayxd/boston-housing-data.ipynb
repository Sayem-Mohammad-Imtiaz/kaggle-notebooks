{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Importing Sklearn \nimport sklearn \n\n#Common imports\nimport numpy as np\nimport pandas as pd\n\n#To plot data \n%matplotlib inline\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt \nmpl.rc('axes', labelsize=14)\nmpl.rc('xtick', labelsize=12)\nmpl.rc('ytick', labelsize=12)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Defining data path \nDATA_PATH = '../input/boston-house-prices/housing.csv'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Defining a function to load data from the given path\ndef loading_data(data_path=DATA_PATH):\n    return pd.read_csv(data_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating a Dataframe which contains data from housing.csv\nhousing = loading_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Previewing our dataframe \nhousing.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see there are no columns into our data/dataframe thus er first need to add column names into our dataset using the given information"},{"metadata":{"trusted":true},"cell_type":"code","source":"#defining column names \ncolumn_names = ['CRIM','ZN','INDUS','CHAS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIO','B','LSTAT','MEDV']\n\n#Creating a dataframe which contains data form housing.csv and includes column_names \nhousing_with_columns = pd.read_csv(DATA_PATH,delim_whitespace=True,names = column_names)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Column names represents \n\n* CRIM: This is the per capita crime rate by town\n* ZN: This is the proportion of residential land zoned for lots larger than 25,000 sq.ft.\n* INDUS: This is the proportion of non-retail business acres per town.\n* CHAS: This is the Charles River dummy variable (this is equal to 1 if tract bounds river; 0 otherwise)\n* NOX: This is the nitric oxides concentration (parts per 10 million)\n* RM: This is the average number of rooms per dwelling\n* AGE: This is the proportion of owner-occupied units built prior to 1940\n* DIS: This is the weighted distances to five Boston employment centers\n* RAD: This is the index of accessibility to radial highways\n* TAX: This is the full-value property-tax rate per 10,000\n* PTRATIO: This is the pupil-teacher ratio by town\n* B: This is calculated as 1000(Bk — 0.63)², where Bk is the proportion of people of African American descent by town\n* LSTAT: This is the percentage lower status of the population\n* MEDV: This is the median value of owner-occupied homes in 1000s"},{"metadata":{"trusted":true},"cell_type":"code","source":"#We copy housing dataframe with columns into housing dataframe\nhousing_df = housing_with_columns.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Taking a look at our dataframe \nhousing_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Getting info about our dataset \nhousing_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see all the column are integer and float type.\n\nThus we don't need to use any encoders."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Describing dataframe \nhousing_df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**.describe()** gives us some basic statistical details like percentile, mean, std etc. of a data frame or a series of numeric values."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting the data \nhousing_df.hist(bins = 50, figsize=(20,15))\nplt.savefig('attribute_histogram_plots')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Setting a random seed \nnp.random.seed(42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We set a random seed so that notebook's output is identical on every run"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using train_test_spilt to spilt data into train and test set \nfrom sklearn.model_selection import train_test_split\n\ntrain_set, test_set = train_test_split(housing_df, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Discover and visualize the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Finding correlation in data \ncorr_matrix = housing_df.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix['MEDV'].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"raw","source":"#Using scatter plot to plot correlation matrix\nfrom pandas.plotting import scatter_matrix \n\nscatter_matrix(housing_df, figsize=(42,28))\nplt.savefig(\"scatter_matrix_plot\")"},{"metadata":{},"cell_type":"markdown","source":"## Preparing the data \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"housing = train_set.drop(\"MEDV\",axis = 1) # drop label for training set \nhousing_labels = train_set['MEDV'].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Finding incomplete or null rows \nincomplete_rows = housing[housing.isnull().any(axis=1)]\nincomplete_rows.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This we can see that there are no rows with NaN values"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using standard scaler using pipeline \nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline \n\nnum_pipeline = Pipeline([\n    ('std_scaler',StandardScaler()),\n])\n\nhousing = num_pipeline.fit_transform(housing)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Select and train model "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using linear regression \nfrom sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\nlin_reg.fit(housing, housing_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using mean squared error\nfrom sklearn.metrics import mean_squared_error \n\nhousing_predictions = lin_reg.predict(housing)\nlin_mse = mean_squared_error(housing_labels,housing_predictions)\nlin_rmse = np.sqrt(lin_mse)\nlin_rmse ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using mean absolute error\nfrom sklearn.metrics import mean_absolute_error \n\nlin_mae = mean_absolute_error(housing_labels,housing_predictions)\nlin_mae ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using Decision Tree Regressor \nfrom sklearn.tree import DecisionTreeRegressor \n\ntree_reg = DecisionTreeRegressor(random_state=42)\ntree_reg.fit(housing,housing_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing_predictions = tree_reg.predict(housing)\ntree_mse = mean_squared_error(housing_labels, housing_predictions)\ntree_rmse = np.sqrt(tree_mse)\ntree_rmse","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fine-tuning your model"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Finding Cross validation score\nfrom sklearn.model_selection import cross_val_score \n\n#Finding cross validation score for tree regression \nscores = cross_val_score(tree_reg, housing, housing_labels, scoring='neg_mean_squared_error',cv = 10)\ntree_scores = np.sqrt(-scores)\n\n#Finding cross validation score for linear regression\nscores = cross_val_score(lin_reg,housing,housing_labels,scoring=\"neg_mean_squared_error\",cv=10)\nlin_scores = np.sqrt(-scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Display scores\ndef display_scores(scores):\n    print(\"Scores: \",scores)\n    print(\"Mean: \", scores.mean())\n    print(\"Standard deviation: \", scores.std())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Displaying scores \nprint(\"Score for decision tree regression\")\nprint(display_scores(tree_scores))\nprint(\"Score for linear regression\")\nprint(display_scores(lin_scores))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using Random forest regression \nfrom sklearn.ensemble import RandomForestRegressor\n\nforest_reg = RandomForestRegressor(n_estimators=100,random_state=42)\nforest_reg.fit(housing,housing_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = cross_val_score(forest_reg, housing, housing_labels,\n                                scoring=\"neg_mean_squared_error\", cv=10)\nforest_scores = np.sqrt(-scores)\ndisplay_scores(forest_scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using support vector regression \nfrom sklearn.svm import SVR\n\nsvm_reg = SVR(kernel=\"linear\")\nsvm_reg.fit(housing,housing_labels)\nhousing_predictions = svm_reg.predict(housing)\nsvm_mse = mean_squared_error(housing_labels,housing_predictions)\nsvm_rmse = np.sqrt(svm_mse)\nsvm_rmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using Grid Search CV\nfrom sklearn.model_selection import GridSearchCV\n\nparam_grid = [\n    {'n_estimators':[3,10,30], 'max_features': [2,4,6,8]},\n    {'bootstrap':[False],'n_estimators':[3,10],'max_features':[2,3,4]},\n]\n\nforest_reg = RandomForestRegressor(random_state = 42)\n\n# train across 5 folds, that's a total of (12+6)*5=90 rounds of training \ngrid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n                           scoring='neg_mean_squared_error',\n                           return_train_score=True)\ngrid_search.fit(housing, housing_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Best Hyperparameter combination found:\ngrid_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search.best_estimator_\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's look at the score of each hyperparameter combination tested during the grid search:\n\ncvres = grid_search.cv_results_\nfor mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n    print(np.sqrt(-mean_score), params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(grid_search.cv_results_)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using randomized search cv\n\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import randint\n\nparam_distribs = {\n        'n_estimators': randint(low=1, high=200),\n        'max_features': randint(low=1, high=8),\n    }\n\nforest_reg = RandomForestRegressor(random_state=42)\nrnd_search = RandomizedSearchCV(forest_reg, param_distributions=param_distribs,\n                                n_iter=10, cv=5, scoring='neg_mean_squared_error', random_state=42)\nrnd_search.fit(housing, housing_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cvres = rnd_search.cv_results_\nfor mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n    print(np.sqrt(-mean_score), params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_importances = grid_search.best_estimator_.feature_importances_\nfeature_importances","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using final model\nfinal_model = grid_search.best_estimator_\n\n#Preparing test set \nX_test = test_set.drop(\"MEDV\",axis = 1)\ny_test = test_set[\"MEDV\"].copy()\n\nX_test = num_pipeline.transform(X_test)\nfinal_predictions = final_model.predict(X_test)\n\n#Finding rsme erroer for our final prediction \nfinal_mse = mean_squared_error(y_test, final_predictions)\nfinal_rmse = np.sqrt(final_mse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_rmse","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}