{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # работа с датасетом\nimport pandas as pd # математическая библиотека\nfrom pandas import read_csv, DataFrame, Series # чтение данных\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score # подготовка дынных и анализ результатов\nimport matplotlib.pyplot as plt # построение графика\nfrom sklearn.preprocessing import LabelEncoder # манипуляции с данными\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Для начала считаем данные из файла в переменную data, чтобы в дальнейшем мы смогли свободно с ними работать"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data = read_csv('../input/german-credit-data-with-risk/german_credit_data_with_risk.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Узнаем размеры таблицы:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Итак, таблица содержит 1000 строк (объектов) и 11 столбцов (признаков), включая выходной (целевой) признак.\n\nМы можем посмотреть на несколько первых и несколько последних строк этой таблицы, чтобы получить представление об имеющихся данных:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.tail(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Похоже, что первый столбец - это просто индекс, который мы можем удалить."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(data.columns[0], inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.tail(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Получим некоторую сводную информацию по всей таблице. По умолчанию будет выдана информация только для количественных признаков. Это общее их количество (count), среднее значение (mean), стандартное отклонение (std), минимальное (min), макcимальное (max) значения, медиана (50%) и значения нижнего (25%) и верхнего (75%) квартилей:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Видим,что нет пропущенных значений у количественных признаков\n\nВыделим числовые и категориальные признаки:"},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_columns = [c for c in data.columns if data[c].dtype.name == 'object']\nnumerical_columns   = [c for c in data.columns if data[c].dtype.name != 'object']\nprint(categorical_columns)\nprint(numerical_columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Теперь мы можем получить некоторую общую информацию по категориальным признакам:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[categorical_columns].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Определим полный перечень значений категориальных признаков:"},{"metadata":{"trusted":true},"cell_type":"code","source":"for c in categorical_columns:\n    print(data[c].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas.tools.plotting import scatter_matrix\nscatter_matrix(data, alpha=0.05, figsize=(20, 20));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Посмотрим корреляцию количественных признаков:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Видим, что практиччески все признаки не сильно коррелируют, т.к. по модулю значения не превышают 0,3. Но есть признак Credit amount, где корреляция уже достаточно ощутимая\n\nУзнаем количество заполненных элементов. Параметр axis = 0 указывает, что мы двигаемся по размерности 0 (сверху вниз), а не размерности 1 (слева направо), т.е. нас интересует количество заполненных элементов в каждом столбце, а не строке:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.count(axis=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Если данные имеют пропущенные значения, существует несколько альтернатив. Удаление строк с пропущенными, удаление столбцов с пропущенными значениями. Но тогда данных станет горазо меньше. К примеру, если мы удалим строки со всеми пропущенными значениями стобца Checking account, то количество данных сократится 396 строк. А это уже весомая потеря наших данных. \n\nПоэтому мы рассмотрим два альтернативных способа. \n1. Замена пропущенных значений на самое популярное в столбце.\n2. Замена пропущенных значений новым признаком. Например, no_inf\n\nДанные для первого способа мы сохраним в переменную data_top, а для второго способа в переменную data_new. И в итоге посмотрим, какой способ лучше."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_top = read_csv('../input/german-credit-data-with-risk/german_credit_data_with_risk.csv')\ndata_new = read_csv('../input/german-credit-data-with-risk/german_credit_data_with_risk.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Для варианта с самыми популярными значениями заполним неопределенные признаки самым популярным значением:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_describe = data_top.describe(include=[object])\nfor c in categorical_columns:\n    data_top[c] = data_top[c].fillna(data_describe[c]['top'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_top.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Для варианта с новым значением введем значение no_inf и заполним им все пропущенные:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_describe = data_new.describe(include=[object])\nfor c in categorical_columns:\n    data_new[c] = data_new[c].fillna('no_inf')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Библиотека scikit-learn не умеет напрямую обрабатывать категориальные признаки. Поэтому прежде чем подавать данные на вход алгоритмов машинного обучения преобразуем категориальные признаки в количественные.\n\nКатегориальные признаки, принимающие два значения (т.е. бинарные признаки) и принимающие большее количество значений будем обрабатывать по-разному.\n\nВначале выделим бинарные и небинарные признаки:"},{"metadata":{"trusted":true},"cell_type":"code","source":"binary_columns    = [c for c in categorical_columns if data_describe[c]['unique'] == 2]\nnonbinary_columns = [c for c in categorical_columns if data_describe[c]['unique'] > 2]\nprint('Binary:', binary_columns)\nprint('Non binary:', nonbinary_columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Значения бинарных признаков просто заменим на 0 и 1. Чтобы избежать дублирования кода, напишем простую функцию для кодирования столбцов."},{"metadata":{"trusted":true},"cell_type":"code","source":"def SetBinary(data):\n    label = LabelEncoder()\n    dicts = {}\n\n    label.fit(data.Sex.drop_duplicates())\n    dicts['Sex'] = list(label.classes_)\n    data.Sex = label.transform(data.Sex)\n\n    label.fit(data.Risk.drop_duplicates())\n    dicts['Risk'] = list(label.classes_)\n    data.Risk = label.transform(data.Risk)\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new = SetBinary(data_new)\ndara_top = SetBinary(data_top)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Просмотрим, все ли у нас успешно получилось:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_top.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Далее у нас остались небинарные признаки. К небинарными признакам применим метод векторизации."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_nonbinary_top = pd.get_dummies(data_top[nonbinary_columns])\nprint(data_nonbinary_top.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_nonbinary_new = pd.get_dummies(data_new[nonbinary_columns])\nprint(data_nonbinary_new.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Многие алгоритмы машинного обучения чувствительны к масштабированию данных. К таким алгоритмам, например, относится метод ближайших соседей, машина опорных векторов и др.\n\nВ этом случае количественные признаки полезно нормализовать. Это можно делать разными способами. Например, каждый количественный признак приведем к нулевому среднему и единичному среднеквадратичному отклонению:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_numerical_top = data_top[numerical_columns]\ndata_numerical_top = (data_numerical_top - data_numerical_top.mean()) / data_numerical_top.std()\ndata_numerical_top.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_numerical_new = data_new[numerical_columns]\ndata_numerical_new = (data_numerical_new - data_numerical_new.mean()) / data_numerical_new.std()\ndata_numerical_new.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Соединим все столбцы в одну таблицу:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_top = pd.concat((data_numerical_top, data_top[binary_columns], data_nonbinary_top), axis=1)\ndata_top = pd.DataFrame(data_top, dtype=float)\ndata_top.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new = pd.concat((data_numerical_new, data_new[binary_columns], data_nonbinary_new), axis=1)\ndata_new = pd.DataFrame(data_new, dtype=float)\ndata_new.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Посмотрим размеры получившихся таблиц"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_top.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Разделим входные признаки и выделенные призак:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_top = data_top.drop(('Risk'), axis=1)\ny_top = data_top['Risk']\n\nX_new = data_new.drop(('Risk'), axis=1)\ny_new = data_new['Risk']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Обучаться, или, как говорят, строить модель, мы будем на обучающей выборке, а проверять качество построенной модели – на тестовой. В соревнованиях и конкурсах по анализу данных и машинному обучению участнику доступна только обучающая выборка, а тестовая неизвестна.\n\nВ рассматриваемой задаче мы сами разобьем имеющиеся у нас данные на обучающую и тестовую выборки (на самом деле, это больше соответствует реальной ситуации, с которой сталкиваются исследователи).\n\nРазбиение на тестовую и обучающую выборку должно быть случайным. Обычно используют разбиения в пропорции 50%:50%, 60%:40%, 75%:25% и т.д.\n\nМы воспользуемся функцией train_test_split из модуля sklearn.cross_validation. и разобьем данные на обучающую/тестовую выборки в отношении 70%:30%:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_top, X_test_top, y_train_top, y_test_top = train_test_split(X_top, y_top, test_size = 0.3, random_state = 11)\nX_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X_new, y_new, test_size = 0.3, random_state = 11)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Заранее заведем список, где будут храниться результаты \"предсказаний\" по тестовой выбрке методов, которые мы будем использовать"},{"metadata":{"trusted":true},"cell_type":"code","source":"itog_val = {} #список для записи результатов работы методов","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Начнем с одного из самых простых алгоритмов машинного обучения – метода k ближайших соседей (kNN).\n\nДля нового объекта алгоритм ищет в обучающей выборке k наиболее близких объекта и относит новый объект к тому классу, которому принадлежит большинство из них.\n\nКоличество соседей k соответствует параметру n_neighbors. По умолчанию, n_neighbors = 5.\n\nВначале обучим модель:"},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier()\nknn.fit(X_train_top, y_train_top)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"После того, как модель обучена, мы можем предсказывать значение целевого признака по входным признакам для новых объектов. Делается это с помощью метода predict.\n\nНас интересует качество построенной модели, поэтому будем предсказывать значение выходного признака на тех данных, для которых оно известно: на обучающей и (что более важно) тестовой выборках:"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_predict_top = knn.predict(X_train_top)\ny_test_predict_top = knn.predict(X_test_top)\n\nerr_train = np.mean(y_train_top != y_train_predict_top)\nerr_test  = np.mean(y_test_top  != y_test_predict_top)\nprint('Train top error:', err_train)\nprint('Test top error', err_test)\nitog_val['KNeighborsClassifierTop'] = np.mean(y_test_top == y_test_predict_top)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"err_train и err_test – это ошибки на обучающей и тестовой выборках. Как мы видим, они составили 23.3% и 34.7%.\n\nДля нас более важным является ошибка на тестовой выборке, так как мы должны уметь предсказывать правильное (по возможности) значение на новых объектах, которые при обучении были недоступны.\n\nМы обучили модель и предсказали на данных, в которых пропущенные значения мы заполнили популярными значениями. Теперь давате проделаем тоже самое уже на других данных - с новым значениями."},{"metadata":{"trusted":true},"cell_type":"code","source":"knn.fit(X_train_new, y_train_new)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_predict_new = knn.predict(X_train_new)\ny_test_predict_new = knn.predict(X_test_new)\n\nerr_train = np.mean(y_train_new != y_train_predict_new)\nerr_test  = np.mean(y_test_new  != y_test_predict_new)\nprint('Train new error:', err_train)\nprint('Test new error', err_test)\n\nitog_val['KNeighborsClassifierNew'] = np.mean(y_test_new == y_test_predict_new)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Хм, заполнение пустых значений новыми признаками в методе k соседей дает небольшое, но уменьшение ошибки. Ошибка в тестовой выборке при замене на наиболее популярное дало 34,7% ошибки, в то время как при добавлении нового признака дает ошибку в 32,3%. Преимущество конечно не существенное, но все же чем меньше - тем лучше :)\n\nДавайте проверим данную тенденцию еще на двух алгоритмах и уже окончательно определимся с итоговыми данными.\n\nСледующий метод, который мы попробуем – машина опорных векторов (SVM – support vector machine или SVC – support vector classifier) – сразу приводит к более оптимистичным результатам.\n\nУже со значением параметров по умолчанию (в частности, ядро – радиальное rbf) получаем более низкую ошибку на обучающей выборке:"},{"metadata":{"trusted":true},"cell_type":"code","source":"svc = SVC()\nsvc.fit(X_train_top, y_train_top)\n\nerr_train = np.mean(y_train_top != svc.predict(X_train_top))\nerr_test  = np.mean(y_test_top  != svc.predict(X_test_top))\nprint('Train top error:', err_train)\nprint('Test top error', err_test)\n\nitog_val['SVC_Top'] = np.mean(y_test_top == y_test_predict_top)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Итак, на тестовой выборке, где пропущенные значения были заполнены популярными, получили ошибку в 32%. Теперь проверим данный алгоритм на других данных, где мы заполнили новыми значениями пропущеннные"},{"metadata":{"trusted":true},"cell_type":"code","source":"svc.fit(X_train_new, y_train_new)\ny_train_predict_new = svc.predict(X_train_new)\ny_test_predict_new = svc.predict(X_test_new)\n\nerr_train = np.mean(y_train_new != y_train_predict_new)\nerr_test  = np.mean(y_test_new  != y_test_predict_new)\nprint('Train new error:', err_train)\nprint('Test new error', err_test)\n\nitog_val['SVC_New'] = np.mean(y_test_new == y_test_predict_new)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier()\n\nrf.fit(X_train_top, y_train_top)\n\nerr_train = np.mean(y_train_top != rf.predict(X_train_top))\nerr_test  = np.mean(y_test_top  != rf.predict(X_test_top))\nprint('Train top error:', err_train)\nprint('Test top error', err_test)\n\nitog_val['RandomForest_Top'] = np.mean(y_test_top == y_test_predict_top)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf.fit(X_train_new, y_train_new)\ny_train_predict_new = rf.predict(X_train_new)\ny_test_predict_new = rf.predict(X_test_new)\n\nerr_train = np.mean(y_train_new != y_train_predict_new)\nerr_test  = np.mean(y_test_new  != y_test_predict_new)\nprint('Train new error:', err_train)\nprint('Test new error', err_test)\n\nitog_val['RandomForest_New'] = np.mean(y_test_new == y_test_predict_new)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DataFrame.from_dict(data = itog_val, orient='index').plot(kind='bar', legend=False, figsize=(10,6))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}