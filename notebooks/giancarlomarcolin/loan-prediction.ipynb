{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Loan Prediction\n\nThis is my first kernel, (completely) copied for learning purposes from:\n\nhttps://www.kaggle.com/yaheaal/loan-status-with-different-models\n\nOther kernels I got inspiration from:\n\nhttps://www.kaggle.com/aarti19/loan-predictionproblem\nhttps://www.kaggle.com/yonatanrabinovich/loan-prediction-dataset-ml-project\n\nThanks @Yaheaal, @aarti19, @yonatanrabinovich\n\nLibraries: **sklearn, matplotlib, numpy, pandas, seaborn, scipy**\n\n\nMissing values filled in using **backward 'bfill' method** for numerical columns , and **most frequent value** for categorical columns (simple techniques)\n\n\n* Train models\n\n    **a) Logistic regression**\n    \n    **b) KNeighborsClassifier**\n    \n    **C) SVC**\n    \n    **d) DecisionTreeClassifier**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os #paths to file\nimport numpy as np # linear algebra\nimport pandas as pd # data processing\nimport warnings# warning filter\n\n\n#ploting libraries\nimport matplotlib.pyplot as plt \nimport seaborn as sns\n\n#relevant ML libraries\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\n\n#ML models\nfrom xgboost import XGBClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\n\n#default theme\nsns.set(context='notebook', style='darkgrid', palette='deep', font='sans-serif', font_scale=1, color_codes=False, rc=None)\n\n#warning hadle\nwarnings.filterwarnings(\"ignore\")\n\nprint(\"Libraries imported\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/loan-prediction-problem-dataset/train_u6lujuX_CVtuZ9i.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* # **1. Exploratory Analysis**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()\n# We have missing data , we will handle them as we go","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Describe the numerical data\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will change the type of Credit_History to object becaues we can see that it is 1 or 0\ndf['Credit_History'] = df['Credit_History'].astype('O')\n\n# describe categorical data (\"object\")\ndf.describe(include='O')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will drop ID because it's not important for our model and it will just mislead the mode\n\ndf.drop('Loan_ID', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.duplicated().any()\n\n# We got no duplicated rows","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's look at the target percentage\n\nplt.figure(figsize=(8,6))\nsns.countplot(df['Loan_Status']);\n\nprint('The percentage of Y class : %.2f' % (df['Loan_Status'].value_counts()[0] / len(df)))\nprint('The percentage of N class : %.2f' % (df['Loan_Status'].value_counts()[1] / len(df)))\n\n# We can consider it as imbalanced data, but for now i will not","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Credit_History\n\ngrid = sns.FacetGrid(df,col='Loan_Status', size=3.2, aspect=1.6)\ngrid.map(sns.countplot, 'Credit_History');\n\n# We didn't give a loan for most people who got Credit History = 0\n# but we did give a loan for most of people who got Credit History = 1\n# so we can say if you got Credit History = 1 , you will have better chance to get a loan","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(pd.crosstab(df['Credit_History'],df['Loan_Status']))\n\ndf_history_Y = df[df['Credit_History'] == 1]\ndf_history_N = df[df['Credit_History'] == 0]\n\nperc_df_self_Y = df_history_Y['Loan_Status'].value_counts()['Y']/len(df_history_Y)\nperc_df_self_N = df_history_N['Loan_Status'].value_counts()['Y']/len(df_history_N)\n\nprint('\\n')\n\nprint('Percentage loans with Credit_History Y: %.3f' %perc_df_self_Y)\nprint('Percentage loans with Credit_History N: %.3f' %perc_df_self_N)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gender\n\ngrid = sns.FacetGrid(df,col='Loan_Status', size=3.2, aspect=1.6)\ngrid.map(sns.countplot, 'Gender');\n\n# Most males got loan and most females got one too so (No pattern)\n\n# I think it's not so important feature, we will see later","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Married\nplt.figure(figsize=(15,5))\nsns.countplot(x='Married', hue='Loan_Status', data=df);\n\n# Most people who get married did get a loan.\n# If you'r married then you have better chance to get a loan.\n# Good feature","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dependents\n\nplt.figure(figsize=(15,5))\nsns.countplot(x='Dependents', hue='Loan_Status', data=df);\n\n# First if Dependents = 0 , we got higher chance to get a loan ((very hight chance))\n# Good feature","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Education\n\ngrid = sns.FacetGrid(df,col='Loan_Status', size=3.2, aspect=1.6)\ngrid.map(sns.countplot, 'Education');\n\n# If you are graduated or not, you will get almost the same chance to get a loan (No pattern)\n# Here you can see that most people did graduated, and most of them got a loan.\n# On the other hand, most of people who did't graduate also got a loan, but with less \n# percentage from people who graduated.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_graduated = df[df['Education'] == 'Graduate']\ndf_not_graduated = df[df['Education'] != 'Graduate']\n\nprint('Graduate')\ndf_graduated.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Not graduate')\ndf_not_graduated.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_loans_gr = len(df_graduated[df_graduated['Loan_Status'] == 'Y'])\n#n_loans_gr = df_graduated['Loan_Status'].value_counts()[0]\nlength_gr =len(df_graduated)\nperc_df_graduated_Y = n_loans_gr/length_gr\n\nn_loans_not_gr = len(df_not_graduated[df_not_graduated['Loan_Status'] == 'Y'])\n#n_loans_gr = df_graduated['Loan_Status'].value_counts()[0]\nlength_not_gr =len(df_not_graduated)\nperc_df_not_graduated_Y = n_loans_not_gr/length_not_gr\n\nprint('Percentage loans for NOT graduated: %.2f' % perc_df_not_graduated_Y)\n\nprint('Percentage loans for graduated: %.2f' % perc_df_graduated_Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Self_Employed\n\ngrid = sns.FacetGrid(df,col='Self_Employed', size=3.2, aspect=1.6)\ngrid.map(sns.countplot, 'Loan_Status');\n\n# No pattern (same as Education)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_self_employed_Y = df[df['Self_Employed'] == 'Yes']\ndf_self_employed_N = df[df['Self_Employed'] == 'No']\n\nn_loans_self_y = df_self_employed_Y['Loan_Status'].value_counts()[0]\nlength_self_y =len(df_self_employed_Y)\nperc_df_self_Y = n_loans_self_y/length_self_y\n\nn_loans_self_n = df_self_employed_N['Loan_Status'].value_counts()[0]\nlength_self_n =len(df_self_employed_N)\nperc_df_self_N = n_loans_self_n/length_self_n\n\nprint('Percentage loans for self employed: %.2f' % perc_df_self_Y)\n\nprint('Percentage loans for not self employed: %.2f' % perc_df_self_N)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Property_Area\n\nplt.figure(figsize=(15,5))\nsns.countplot(x='Property_Area', hue='Loan_Status', data=df);\n\n# We can say, Semiurban Property_Area got more than 50% chance to get a loan\n# Good feature","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ApplicantIncome\n\nplt.scatter(df['ApplicantIncome'], df['Loan_Status']);\n\n# No pattern","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The numerical data\n\ndf.groupby('Loan_Status').median() # median because Not affected with outliers\n\n# We can see that when we got low median in CoapplicantInocme we got Loan_Status = N\n\n# CoapplicantInocme is a good feature","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **2. Data Cleaning**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will separate the numerical columns from the categorical\n\ncat_data = []\nnum_data = []\n\nfor i,c in enumerate(df.dtypes):\n    if c == object:\n        cat_data.append(df.iloc[:, i])\n    else :\n        num_data.append(df.iloc[:, i])\n        \n\ncat_data = pd.DataFrame(cat_data).transpose()\nnum_data = pd.DataFrame(num_data).transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_data.isnull().sum().any() #cat_data missing values?","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Categorical data\n# If you want to fill every column with its own most frequent value you can use.\n\ncat_data = cat_data.apply(lambda x:x.fillna(x.value_counts().index[0]))\ncat_data.isnull().sum().any() # No more missing data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_data.isnull().sum().any() # num_data missing data?","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Numerical data\n# Fill every missing value with their previous value in the same column.\n\nnum_data.fillna(method='bfill', inplace=True)\nnum_data.isnull().sum().any() # no more missing data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder  \nle = LabelEncoder()\ncat_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transform the target column\n\ntarget_values = {'Y': 0 , 'N' : 1}\n\n# Save 'Loan_Status' column in 'target'\ntarget = cat_data['Loan_Status']\n\n#Remove 'Loan_Status' column from cat_data\ncat_data.drop('Loan_Status', axis=1, inplace=True)\n\n# Map 'target' according to 'target_values' \ntarget = target.map(target_values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transform the remaining columns of cat_data\n\nfor i in cat_data:\n    cat_data[i] = le.fit_transform(cat_data[i])\ntarget.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create new Pandas object \ndf = pd.concat([cat_data, num_data, target], axis=1)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **3. Train Data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create (X, y) Pandas objects for data training \nX = pd.concat([cat_data, num_data], axis=1)\ny = target","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will use StratifiedShuffleSplit to split the data Taking into consideration that we will get the same ratio on the target column\n\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\nsss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n\nfor train, test in sss.split(X, y):\n    X_train, X_test = X.iloc[train], X.iloc[test]\n    y_train, y_test = y.iloc[train], y.iloc[test]\n    \nprint('X_train shape', X_train.shape)\nprint('y_train shape', y_train.shape)\nprint('X_test shape', X_test.shape)\nprint('y_test shape', y_test.shape)\n\n# Almost same ratio\nprint('\\nratio of target in y_train :',y_train.value_counts().values/ len(y_train))\nprint('ratio of target in y_test :',y_test.value_counts().values/ len(y_test))\nprint('ratio of target in original_data :',df['Loan_Status'].value_counts().values/ len(df))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will use 4 different models for training\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\n\nmodels = {\n    'LogisticRegression': LogisticRegression(random_state=42),\n    'KNeighborsClassifier': KNeighborsClassifier(),\n    'SVC': SVC(random_state=42),\n    'DecisionTreeClassifier': DecisionTreeClassifier(max_depth=1, random_state=42)\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loss\n\nfrom sklearn.metrics import precision_score, recall_score, f1_score, log_loss, accuracy_score\n\ndef loss(y_true, y_pred, retu=False):\n    pre = precision_score(y_true, y_pred)\n    rec = recall_score(y_true, y_pred)\n    f1 = f1_score(y_true, y_pred)\n    loss = log_loss(y_true, y_pred)\n    acc = accuracy_score(y_true, y_pred)\n    \n    if retu:\n        return pre, rec, f1, loss, acc\n    else:\n        print('  pre: %.3f\\n  rec: %.3f\\n  f1: %.3f\\n  loss: %.3f\\n  acc: %.3f' \n              % (pre, rec, f1, loss, acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train data\n\ndef train_eval_train(models, X, y):\n    for name, model in models.items():\n        print(name,':')\n        model.fit(X, y)\n        loss(y, model.predict(X))\n        print('-'*30)\n\ntrain_eval_train(models, X_train, y_train)\n\n# We can see that best model is LogisticRegression at least for now, SVC is just \n# memorizing the data so it is overfitting.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cross validation\n\nfrom sklearn.model_selection import StratifiedKFold\n\nskf = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n\ndef train_eval_cross(models, X, y, folds):\n    # We will change X & y to dataframe because we will use iloc (iloc don't work on numpy array)\n    X = pd.DataFrame(X) \n    y = pd.DataFrame(y)\n    idx = [' pre', ' rec', ' f1', ' loss', ' acc']\n    for name, model in models.items():\n        ls = []\n        print(name,':')\n\n        for train, test in folds.split(X, y):\n            model.fit(X.iloc[train], y.iloc[train]) \n            y_pred = model.predict(X.iloc[test]) \n            ls.append(loss(y.iloc[test], y_pred, retu=True))\n        print(pd.DataFrame(np.array(ls).mean(axis=0), index=idx)[0])  #[0] because we don't want to show the name of the column\n        print('-'*30)\n        \ntrain_eval_cross(models, X_train, y_train, skf)\n\n# SVC is just memorizing the data, and you can see \n# that here DecisionTreeClassifier is better than LogisticRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Some explanation about Logistic Regression\n\nx = []\nidx = [' pre', ' rec', ' f1', ' loss', ' acc']\n\n# We will use one model\nlog = LogisticRegression()\n\nfor train, test in skf.split(X_train, y_train):\n    log.fit(X_train.iloc[train], y_train.iloc[train])\n    ls = loss(y_train.iloc[test], log.predict(X_train.iloc[test]), retu=True)\n    x.append(ls)\n    \n# Thats what we get\npd.DataFrame(x, columns=idx)\n\n# (column 0 represent the precision_score of the 10 folds)\n# (row 0 represent the (pre, rec, f1, loss, acc) for the first fold)\n# then we should find the mean of every column\n# pd.DataFrame(x, columns=idx).mean(axis=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **4. Features Engineering**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# We got it right for most of the features, as you can see we've say at the first of \n# the kernel, that Credit_History and Married etc, are good features, actually \n# Credit_History is the best.\n\ndata_corr = pd.concat([X_train, y_train], axis=1)\ncorr = data_corr.corr()\nplt.figure(figsize=(10,7))\nsns.heatmap(corr, annot=True);\n\n# Here we got 58% similarity between LoanAmount & ApplicantIncome \n# and that may be bad for our model so we will see what we can do","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# I will try to make some operations on some features, here I just tried diffrent operations on different features,\n# having experience in the field, and having knowledge about the data will also help\n\nX_train['new_col'] = X_train['CoapplicantIncome'] / X_train['ApplicantIncome']  \nX_train['new_col_2'] = X_train['LoanAmount'] * X_train['Loan_Amount_Term']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_corr = pd.concat([X_train, y_train], axis=1)\ncorr = data_corr.corr()\nplt.figure(figsize=(10,7))\nsns.heatmap(corr, annot=True);\n\n# new_col 0.03 , new_col_2, 0.047\n# Not that much , but that will help us reduce the number of features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.drop(['CoapplicantIncome', 'ApplicantIncome', 'Loan_Amount_Term', 'LoanAmount'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_eval_cross(models, X_train, y_train, skf)\n\n# SVC is improving, but LogisticRegression is overfitting\n# We do not change anything so we can see what will happen as we go","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's take a look at the value counts of every label\n\n#print(X_train.shape)\n#print(X_train.shape[0]) # Rows\n#print(X_train.shape[1]) # Columns\n\nprint('************************\\n')\n\nfor i in range(X_train.shape[1]):\n    print(X_train.iloc[:,i].value_counts(), end='\\n----------\\\n--------------------------------------\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# new_col_2\n\n# We can see we got right_skewed\n# We can solve this problem with very simple statistical technique , by taking the logarithm of all the values\n# because when data is normally distributed that will help improving our model\n\nfrom scipy.stats import norm\n\nfig, ax = plt.subplots(1,2,figsize=(20,5))\n\nsns.distplot(X_train['new_col_2'], ax=ax[0], fit=norm)\nax[0].set_title('new_col_2 before log')\n\nX_train['new_col_2'] = np.log(X_train['new_col_2'])  # logarithm of all the values\n\nsns.distplot(X_train['new_col_2'], ax=ax[1], fit=norm)\nax[1].set_title('new_col_2 after log');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now we will evaluate our models, and i will do that continuously ,so i don't need to \n# mention that every time\n\ntrain_eval_cross(models, X_train, y_train, skf)\n\n# Our models improved really good by just doing the previous step.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# new_col\n\n# Most of our data is 0 , so we will try to change other values to 1\n\nprint('before:')\nprint(X_train['new_col'].value_counts())\n\nX_train['new_col'] = [x if x==0 else 1 for x in X_train['new_col']]\nprint('-'*50)\nprint('\\nafter:')\nprint(X_train['new_col'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_eval_cross(models, X_train, y_train, skf)\n\n# We are improving our models as we go","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(X_train.shape[1]):\n    print(X_train.iloc[:,i].value_counts(), end='\\n------------------------------------------------\\n')\n    \n# Looks better","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Outliers: we will use boxplot to detect them \n\nsns.boxplot(X_train['new_col_2']);\nplt.title('new_col_2 outliers', fontsize=15);\nplt.xlabel('');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"threshold = 0.1  # This number is a hyper parameter, by reducing it, more points are removed.\n                 # You can just try different values, the deafult value is (1.5) it works good for most cases.\n                 # Be careful, you don't want to try a small number because you may loss some important information from data.\n                 # That's why I was surprised when 0.1 gived me the best result\n            \nnew_col_2_out = X_train['new_col_2']\n\nq25, q75 = np.percentile(new_col_2_out, 25), np.percentile(new_col_2_out, 75) # Q25, Q75\n\nprint('Quartile 25: {} , Quartile 75: {}'.format(q25, q75))\n\niqr = q75 - q25\nprint('iqr: {}'.format(iqr))\n\ncut = iqr * threshold\nlower, upper = q25 - cut, q75 + cut\nprint('Cut Off: {}'.format(cut))\nprint('Lower: {}'.format(lower))\nprint('Upper: {}'.format(upper))\n\noutliers = [x for x in new_col_2_out if x < lower or x > upper]\nprint('Nubers of Outliers: {}'.format(len(outliers)))\nprint('outliers:{}'.format(outliers))\n\ndata_outliers = pd.concat([X_train, y_train], axis=1)\nprint('\\nlen X_train before dropping the outliers', len(data_outliers))\ndata_outliers = data_outliers.drop(data_outliers[(data_outliers['new_col_2'] > upper) | (data_outliers['new_col_2'] < lower)].index)\n\nprint('len X_train before dropping the outliers', len(data_outliers))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = data_outliers.drop('Loan_Status', axis=1)\ny_train = data_outliers['Loan_Status']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(X_train['new_col_2']);\nplt.title('new_col_2 without outliers', fontsize=15);\nplt.xlabel('');\n\n# good :)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_eval_cross(models, X_train, y_train, skf)\n\n# Now we get 94.1 ??? for precision & 53.5 for recall","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Features selection**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Self_Employed got really bad corr (-0.00061) , let's try to remove it and see what will happen\n\ndata_corr = pd.concat([X_train, y_train], axis=1)\ncorr = data_corr.corr()\nplt.figure(figsize=(10,7))\nsns.heatmap(corr, annot=True);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X_train.drop(['Self_Employed'], axis=1, inplace=True)\n\ntrain_eval_cross(models, X_train, y_train, skf)\n\n# looks like Self_Employed is not important\n# KNeighborsClassifier improved\n\n# droping all the features Except for Credit_History actually improved KNeighborsClassifier and didn't change anything in other models\n# so you can try it by you self\n# but don't forget to do that on testing data too\n\n#X_train.drop(['Self_Employed','Dependents', 'new_col_2', 'Education', 'Gender', 'Property_Area','Married', 'new_col'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_corr = pd.concat([X_train, y_train], axis=1)\ncorr = data_corr.corr()\nplt.figure(figsize=(10,7))\nsns.heatmap(corr, annot=True);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# evaluate the models on Test_data"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_new = X_test.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = []\n\nX_test_new['new_col'] = X_test_new['CoapplicantIncome'] / X_test_new['ApplicantIncome']  \nX_test_new['new_col_2'] = X_test_new['LoanAmount'] * X_test_new['Loan_Amount_Term']\nX_test_new.drop(['CoapplicantIncome', 'ApplicantIncome', 'Loan_Amount_Term', 'LoanAmount'], axis=1, inplace=True)\n\nX_test_new['new_col_2'] = np.log(X_test_new['new_col_2'])\n\nX_test_new['new_col'] = [x if x==0 else 1 for x in X_test_new['new_col']]\n\n#X_test_new.drop(['Self_Employed'], axis=1, inplace=True)\n\n# drop all the features Except for Credit_History\n#X_test_new.drop(['Self_Employed','Dependents', 'new_col_2', 'Education', 'Gender', 'Property_Area','Married', 'new_col'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_new.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for name,model in models.items():\n    print(name, end=':\\n')\n    loss(y_test, model.predict(X_test_new))\n    print('-'*40)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}