{"cells":[{"metadata":{},"cell_type":"markdown","source":"Hey there fellow Kaggler :)\n\nNCOVID-19 has done a tremendous amount of damage to the flow of work we had this year, but guess what? We have more time than ever these days and what can you do?\n\nTrain a model on thousands of movie reviews to see if they are positive or negative! Definitely. That is exactly what we will be seeing here today, learning to differentiate between the positive and negative reviews from about 2,000 reviews."},{"metadata":{},"cell_type":"markdown","source":"Given to us, is a CSV file which has about 50,000 reviews which are categorized as negative or positive. You would ask me why train on just 2,000 reviews when you have 50,000? My answer to that being that:\n\n1. It would be <font color = 'red'>computationally expensive.</font>\n2. Since I am new to this, I want to get my results out <font color  ='green'>as quickly as possible</font>.\n\nTalking about NLP or Natural Language Processing what does it mean?\nThis sect of the field of Artificial Intelligence deals with sequential data. Sequential data refers to all data that comes in a sequence. The words you say, the words you type and the words you read it is refered to as Sequential Data. Not just this, it also includes audio recognition."},{"metadata":{},"cell_type":"markdown","source":"Answering some questions\n\n### Why are we using FastAI Library not PyTorch?\nWell, firstly it is built in top of the PyTorch library. It is is easier to use and often gives state of the art results even if you are a beginner. It is has all the hyperparameters set to exactly where they should be and generalize perfectly over all sorts of NLP problems.\n\n### Why do we do such mundane tasks in Natural Language Processing?\nEveryone starts somewhere, these are baby steps that are required towards something bigger. Check out this blog for [application of NLP](https://monkeylearn.com/blog/natural-language-processing-applications/).\n\n### Are there a different kind of neural networks that would work for these problems?\nYes we will be using LSTMS:\n![](https://missinglink.ai/wp-content/uploads/2019/08/A.png)"},{"metadata":{},"cell_type":"markdown","source":"# Table of Content\n\n## 1. Libraries\n## 2. Introducing the Data\n## 3. Creating the Classifier\n## 4. Training the Classifier"},{"metadata":{},"cell_type":"markdown","source":"# Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Importing from FastAI and Pandas:\nfrom fastai.text.all import *\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Defining the path where our data is stored:\npath = \"../input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Introducing the Data\nIntroducing the data, more like defining the paths and reading the csv file where our data exists."},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(path)\n\n# Lets scale down this a little bit since my GPU won't be able to handle data this big:\nnewdata = data[:2000]\nnewdata.to_csv(\"./newdata.csv\")\n\n# Taking a look at it:\nnewdata.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining the DataBlock:\nimdb_clas = DataBlock(\n    blocks=(TextBlock.from_df('review', seq_len=72), CategoryBlock),\n    get_x=ColReader('text'), get_y=ColReader('sentiment'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Further processing it:\nimdb = imdb_clas.dataloaders(newdata, bs = 64, is_lm=True)\n\n# Taking a look at it:\nimdb.show_batch(max_n=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's take the first review:\ntxt = data['review'].iloc[0]\ntxt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets tokenize this till 30 words:"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nspacy = WordTokenizer()\ntoks = first(spacy([txt]))\nprint(coll_repr(toks, 30))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Further processing:\n\ntkn = Tokenizer(spacy)\nprint(coll_repr(tkn(txt), 31))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating the Classifier\nWe will be classifying whether the review was positive or negative."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Time to fin-tune the model:\nlearn = text_classifier_learner(imdb,\n                               AWD_LSTM,\n                               metrics = [accuracy, Perplexity()]).to_fp16()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training the Classifier\nFinally training it."},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(5, 1e-3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And we have 80% accuracy in a matter of about 30 seconds!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}