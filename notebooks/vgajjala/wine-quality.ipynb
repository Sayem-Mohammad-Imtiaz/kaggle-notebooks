{"cells":[{"metadata":{"trusted":false},"cell_type":"code","source":"# Data manipulation\nimport numpy as np\nimport pandas as pd\n\n# Data pre-processing\nfrom sklearn.preprocessing import StandardScaler as ss\n\n# Dimensionality reduction\nfrom sklearn.decomposition import PCA\n\n#  Data splitting and model parameter search\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\n\n# Modeling modules\nfrom xgboost.sklearn import XGBClassifier\n\n# Model pipelining\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.pipeline import make_pipeline\n\n# Model evaluation metrics\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import auc, roc_curve\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score, recall_score, f1_score\n\n# Plotting\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom xgboost import plot_importance\n\n# For Bayes optimization\nfrom sklearn.model_selection import cross_val_score\nfrom bayes_opt import BayesianOptimization\n\n# Finding feature importance of ANY BLACK BOX estimator\nimport eli5\nfrom eli5.sklearn import PermutationImportance\n\n# Misc\nimport time\nimport os\nimport gc\nimport random\nfrom scipy.stats import uniform","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Set option to dislay many rows\npd.set_option('display.max_columns', 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data = pd.read_csv(\"../input/winequalityN.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data.columns.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data.dtypes.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data.type.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data = data.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(10, 10))\nsns.heatmap(data.corr(),annot = True, linewidths = 0.8, cmap = 'PuOr')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Plotting acidic factors\nsns.pairplot(data, vars = ['fixed acidity', 'volatile acidity', 'citric acid', 'pH',], hue='type', height = 5, palette=\"prism\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Plotting chemical factors\nsns.pairplot(data, vars = ['chlorides', 'sulphates', 'free sulfur dioxide', 'total sulfur dioxide',], hue='type', height = 5, palette=\"prism\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Checking relation between quality, alcohol and type\nplt.figure(figsize=(10, 10))\nsns.boxplot(x='quality', y = 'alcohol', hue = 'type' , data = data)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"data.type.value_counts()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(10, 10))\nsns.countplot(x = 'quality', data=data, hue='type')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X = data.iloc[ :, 1:13]                       ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X.head(2) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y = data.iloc[ : , 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y = y.map({'white':1, 'red' : 0})","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y.dtype","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"colnames = X.columns.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Split dataset into train and validation parts\nX_train, X_test, y_train, y_test = train_test_split(X,\n                                                    y,\n                                                    test_size=0.35,\n                                                    shuffle = True\n                                                    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_test.shape ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#  Making Pipeline using xgboost\nsteps_xg = [('sts', ss() ),\n            ('pca', PCA()),\n            ('xg',  XGBClassifier(silent = False,\n                                  n_jobs=2)       \n            )\n            ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Instantiate Pipeline object\npipe_xg = Pipeline(steps_xg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#  Specify xgboost parameter-range                        \nparameters = {'xg__learning_rate':  [0, 1], \n              'xg__n_estimators':   [50,  100],  \n              'xg__max_depth':      [3,5],\n              'pca__n_components' : [5,7]\n              } ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"##################### Grid Search #################\nclf = GridSearchCV(pipe_xg,            \n                   parameters,       \n                   n_jobs = 2,        \n                   cv =2 ,           \n                   verbose =2,         \n                   scoring = ['accuracy', 'roc_auc'], \n                   refit = 'roc_auc' \n                   )","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Start fitting data to pipeline\nstart = time.time()\nclf.fit(X_train, y_train)\nend = time.time()\n(end - start)/60 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Evaluate\nf\"Best score: {clf.best_score_} \"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"f\"Best parameter set {clf.best_params_}\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#  Find feature importance of any BLACK Box model\n# Instantiate the importance object\nperm_gs = PermutationImportance(\n                            clf,\n                            random_state=1\n                            )","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# fit data & learn\nstart = time.time()\nperm_gs.fit(X_test, y_test)\nend = time.time()\n(end - start)/60","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Get feature weights\neli5.show_weights(\n                  perm_gs,\n                  feature_names = colnames\n                  )","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fw_gs = eli5.explain_weights_df(\n                  perm_gs,\n                  feature_names = colnames    \n                  )","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Print importance\nfw_gs","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"##################### Randomized Search #################\n\n# Tune parameters using randomized search\n#  Hyperparameters to tune and their ranges\nparameters = {'xg__learning_rate':  uniform(0, 1),\n              'xg__n_estimators':   range(50,100),\n              'xg__max_depth':      range(3,5),\n              'pca__n_components' : range(5,7)}","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#  Tune parameters using random search\n#     Create the object first\nrs = RandomizedSearchCV(pipe_xg,\n                        param_distributions=parameters,\n                        scoring= ['roc_auc', 'accuracy'],\n                        n_iter=10,          \n                        verbose = 3,\n                        refit = 'roc_auc',\n                        n_jobs = 2,          \n                        cv = 2               \n                        )","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Fitting data\nstart = time.time()\nrs.fit(X_train, y_train)\nend = time.time()\n(end - start)/60","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Evaluate\nf\"Best score: {rs.best_score_} \"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"f\"Best parameter set: {rs.best_params_} \"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#  Instantiate the importance object\nperm_rs = PermutationImportance(\n                            rs,\n                            random_state=1\n                            )","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# fit data & learn\nstart = time.time()\nperm_rs.fit(X_test, y_test)\nend = time.time()\n(end - start)/60","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Get feature weights\neli5.show_weights(\n                  perm_rs,\n                  feature_names = colnames      \n                  )","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fw_rs = eli5.explain_weights_df(\n                  perm_rs,\n                  feature_names = colnames     \n                  )","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Print importance\nfw_rs ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"##################### Bayesian Optimization #################\n\n# Which parameters to consider and what is each one's range\npara_set = {\n           'learning_rate':  (0, 1),                 \n           'n_estimators':   (50,100),               \n           'max_depth':      (3,5),                 \n           'n_components' :  (5,7)                 \n            }","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#  Create a function that when passed some parameters\n#    evaluates results using cross-validation\n#    This function is used by BayesianOptimization() object\ndef xg_eval(learning_rate,n_estimators, max_depth,n_components):\n\n    pipe_xg1 = make_pipeline (ss(),                        \n                              PCA(n_components=int(round(n_components))),\n                              XGBClassifier(\n                                           silent = False,\n                                           n_jobs=2,\n                                           learning_rate=learning_rate,\n                                           max_depth=int(round(max_depth)),\n                                           n_estimators=int(round(n_estimators))\n                                           )\n                             )\n\n    # fit the pipeline and evaluate\n    cv_result = cross_val_score(estimator = pipe_xg1,\n                                X= X_train,\n                                y = y_train,\n                                cv = 5,\n                                n_jobs = 2,\n                                scoring = 'f1'\n                                ).mean()             \n\n\n    #  return maximum/average value of result\n    return cv_result","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#      Instantiate BayesianOptimization() object\n#      This object  can be considered as performing an internal-loop\n#      i)  Given parameters, xg_eval() evaluates performance\n#      ii) Based on the performance, set of parameters are selected\n#          from para_set and fed back to xg_eval()\n#      (i) and (ii) are repeated for given number of iterations\n#\nxgBO = BayesianOptimization(\n                             xg_eval,     \n                             para_set\n                             )","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#  Gaussian process parameters\n#     Modulate intelligence of Bayesian Optimization process\n#     This parameters controls how much noise the GP can handle,\n#     so increase it whenever you think that extra flexibility is needed.\ngp_params = {\"alpha\": 1e-5}      # Initialization parameter for gaussian Process","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#  Fit/train (so-to-say) the BayesianOptimization() object\n#     Start optimization. 25minutes\n#     Our objective is to maximize performance (results)\nstart = time.time()\nxgBO.maximize(init_points=5,    # Number of randomly chosen points to\n                                 # sample the target function before\n                                 #  fitting the gaussian Process (gp)\n                                 #  or gaussian graph\n               n_iter=20,        # Total number of times the\n               #acq=\"ucb\",       # ucb: upper confidence bound\n                                 #   process is to be repeated\n                                 # ei: Expected improvement\n               # kappa = 1.0     # kappa=1 : prefer exploitation; kappa=10, prefer exploration\n              **gp_params\n               )\nend = time.time()\n(end-start)/60","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"###############  Fitting Best parameters in our model ##############\n###############    Model Importance   #################\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#  Model with parameters of grid search\nmodel_gs = XGBClassifier(\n                    learning_rate = clf.best_params_['xg__learning_rate'],\n                    max_depth = clf.best_params_['xg__max_depth'],\n                    n_estimators=clf.best_params_['xg__max_depth']\n                    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Model with parameters of random search\nmodel_rs = XGBClassifier(\n                    learning_rate = rs.best_params_['xg__learning_rate'],\n                    max_depth = rs.best_params_['xg__max_depth'],\n                    n_estimators=rs.best_params_['xg__max_depth']\n                    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model_bo = XGBClassifier(\n                    learning_rate = xgBO.max['params']['learning_rate'],\n                    max_depth = int(xgBO.max['params']['max_depth']),\n                    n_estimators= int(xgBO.max['params']['n_estimators'])\n                    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#  Modeling with all parameters\nstart = time.time()\nmodel_gs.fit(X_train, y_train)\nmodel_rs.fit(X_train, y_train)\nmodel_bo.fit(X_train, y_train)\nend = time.time()\n(end - start)/60","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#  Predictions with all models\ny_pred_gs = model_gs.predict(X_test)\ny_pred_rs = model_rs.predict(X_test)\ny_pred_bo = model_bo.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Confusion Matrix for all models\nprint(\"Confusion Matrix for GS is \\n\",confusion_matrix(y_test,y_pred_gs))\nprint(\"Confusion Matrix for RS is \\n\",confusion_matrix(y_test,y_pred_rs))\nprint(\"Confusion Matrix for BO is \\n\",confusion_matrix(y_test,y_pred_bo))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Accuracy from all models\naccuracy_gs = accuracy_score(y_test, y_pred_gs)\naccuracy_rs = accuracy_score(y_test, y_pred_rs)\naccuracy_bo = accuracy_score(y_test, y_pred_bo)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Calculating Precision/Recall/F-score\nprecision_gs, precision_rs, precision_bo = precision_score(y_test,y_pred_gs), precision_score(y_test,y_pred_rs), precision_score(y_test,y_pred_bo)\nrecall_gs, recall_rs, recall_bo = recall_score(y_test,y_pred_gs), recall_score(y_test,y_pred_rs), recall_score(y_test,y_pred_bo)\nf1_score_gs, f1_score_rs, f1_score_bo = f1_score(y_test,y_pred_gs), f1_score(y_test,y_pred_rs), f1_score(y_test,y_pred_bo)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#  Get feature importances from all 3 models\nmodel_gs.feature_importances_\nmodel_rs.feature_importances_\nmodel_bo.feature_importances_\nplot_importance(model_gs)\nplot_importance(model_rs)\nplot_importance(model_bo)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Get probability of occurrence of each class\ny_pred_prob_gs = model_gs.predict_proba(X_test)\ny_pred_prob_rs = model_rs.predict_proba(X_test)\ny_pred_prob_bo = model_bo.predict_proba(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Draw ROC curve\nfpr_gs, tpr_gs, thresholds = roc_curve(y_test,\n                                 y_pred_prob_gs[: , 0],\n                                 pos_label= 0\n                                 )\n\nfpr_rs, tpr_rs, thresholds = roc_curve(y_test,\n                                 y_pred_prob_rs[: , 0],\n                                 pos_label= 0\n                                 )\n\nfpr_bo, tpr_bo, thresholds = roc_curve(y_test,\n                                 y_pred_prob_bo[: , 0],\n                                 pos_label= 0\n                                 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# AUC\nauc_gs = auc(fpr_gs,tpr_gs)\nauc_rs = auc(fpr_rs,tpr_rs)\nauc_bo = auc(fpr_bo,tpr_bo)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Plot ROC Curve\nfig = plt.figure()  \nax = fig.add_subplot(111)  \n\n#Connect diagonals\nax.plot([0, 1], [0, 1], ls=\"--\")\n\n# Labels \nax.set_xlabel('False Positive Rate') \nax.set_ylabel('True Positive Rate')\nax.set_title('ROC curve for models')\n\n# Set graph limits\nax.set_xlim([0.0, 1.0])\nax.set_ylim([0.0, 1.0])\n\n# Plot each graph now\nax.plot(fpr_gs, tpr_gs, label = \"Grid Search\")\nax.plot(fpr_rs, tpr_rs, label = \"Random Search\")\nax.plot(fpr_bo, tpr_bo, label = \"Bayesian Optimization\")\n\n# Set legend and show plot\nax.legend(loc=\"lower right\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"f\"For GS, Accuracy = {round(accuracy_gs,5)}, Precison = {round(precision_gs,5)}, Recall = {round(recall_gs,5)}, f1_score = {round(f1_score_gs,5)}, AUC = {round(auc_gs,5)}\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"f\"For RS, Accuracy = {round(accuracy_rs,5)}, Precison = {round(precision_rs,5)}, Recall = {round(recall_rs,5)}, f1_score = {round(f1_score_rs,5)}, AUC = {round(auc_rs,5)}\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f\"For BO, Accuracy = {round(accuracy_bo,5)}, Precison = {round(precision_bo,5)}, Recall = {round(recall_bo,5)}, f1_score = {round(f1_score_bo,5)}, AUC = {round(auc_bo,5)}\"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":1}