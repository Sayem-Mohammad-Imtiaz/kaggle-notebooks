{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -q efficientnet","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# IMPORTING LIBRARIES","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nimport cv2\nimport sys\nimport seaborn as sns\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nimport scikitplot as skplt\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score,precision_recall_curve\nimport efficientnet.tfkeras as efn","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# IMPORTING DATA","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**IMPORTING APTOS-2019 BLINDNESS DETECTION DATA CSV FILE**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.read_csv('../input/resized-2015-2019-blindness-detection-images/labels/trainLabels19.csv')\n\ndataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**VISUALIZING DATASET**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"names = ['Normal', 'Mild', 'Moderate', 'Severe', 'Proliferate DR']\nprint(dataset['diagnosis'].value_counts())\nsns.barplot(x=names,y=dataset.diagnosis.value_counts().sort_index())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**IMPORTING DIABETIC RETINOPATHY RESIZED DATA FROM THE KAGGLE COMPETITION 2015 CSV FILE**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset1 = pd.read_csv('../input/resized-2015-2019-blindness-detection-images/labels/trainLabels15.csv')\ndataset1.columns = ['id_code','diagnosis']\ndataset1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**VISUALIZING DATASET1**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(dataset1['diagnosis'].value_counts())\nsns.barplot(x=names,y=dataset1.diagnosis.value_counts().sort_index())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# BALANCING THE DATASET","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**FORMING THE FINAL DATASET**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now we will take 900 images in total for each class. So to complete the 900 images we will take majority of images from 'dataset' \n#and if necessary take the rest of the required images from 'dataset1'\n\n#index  Final_Img_count   Image taken from dataset 1\n# 0          900                   (0)\n# 1          900                 (530)\n# 2          900                   (0)\n# 3          900                 (707)\n# 4          900                 (605)\n\n\nlevel_1 = dataset1[dataset1.diagnosis == 1].sample(n=530)\n\nlevel_3 = dataset1[dataset1.diagnosis == 3].sample(n=707)\n\nlevel_4 = dataset1[dataset1.diagnosis == 4].sample(n=605)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"level_1.shape , level_3.shape, level_4.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"level_0 = dataset[dataset.diagnosis == 0].sample(n=900)\nlevel_0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"level_2 = dataset[dataset.diagnosis == 2].sample(n=900)\nlevel_2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset= dataset[dataset['diagnosis']>0]\ndataset= dataset[dataset['diagnosis'] != 2]\nprint(dataset['diagnosis'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.concat([level_0,level_2,dataset])\ndataset=dataset.sample(frac=1)\nprint(dataset['diagnosis'].value_counts())\ndataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset1 = pd.concat([level_1,level_3, level_4])\ndataset1=dataset1.sample(frac=1)\n\nprint(dataset1['diagnosis'].value_counts())\ndataset1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# IMPORTING SELECTED IMAGES FROM THE DATASET","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**RESIZING THE IMPORTING DATA**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"images = []\nfor i, image_id in enumerate(tqdm(dataset.id_code)):\n    im = cv2.imread(f'../input/resized-2015-2019-blindness-detection-images/resized train 19/{image_id}.jpg')\n    #im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n    im = cv2.resize(im, (128, 128))\n    images.append(im)\n\nimages","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, image_id in enumerate(tqdm(dataset1.id_code)):\n    im = cv2.imread(f'../input/resized-2015-2019-blindness-detection-images/resized train 15/{image_id}.jpg')\n    #im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n    im = cv2.resize(im, (128, 128))\n    images.append(im)\n\nimages","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# PREPROCESSING OF IMAGE DATA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# random image from imported data\nplt.imshow(images[-30])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**APPLYING GAUSSIAN BLUR NOISE FILTER**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# This function will act as a filter for the image data\n\ndef load_colorfilter(image, sigmaX=10):\n    #image = cv2.imread(path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    #image = crop_image_from_gray(image)\n    #image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n    image=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , sigmaX),-4 ,128)\n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(images)):\n    output = load_colorfilter(images[i])\n    images[i] = output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# image after filtering\nplt.imshow(images[-30])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images = np.array(images)\nimages.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**VISUALIZING BALANCED DATASET**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.concat([dataset,dataset1])\nprint(dataset['diagnosis'].value_counts())\n\nsns.barplot(x=names,y=dataset.diagnosis.value_counts().sort_index())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**SCALING/NORMALISING IMAGE DATASET**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = images/255.0\ny = dataset.diagnosis.values\nX, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cleaning some RAM memory space\ndel images,level_1,level_3, level_4, level_0, dataset1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# IMAGE AUGMENTATION","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Applying image augmentation\nsys.stdout.flush()\naug = ImageDataGenerator(rotation_range=0.2, width_shift_range=0.2, \\\n    height_shift_range=0.2, shear_range=0.2, zoom_range=0.2,\\\n    horizontal_flip=True, fill_mode=\"nearest\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SPLITTING OF DATASET IN TRAIN AND TEST DATA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#from sklearn.model_selection import train_test_split\n#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n#X_train.shape, X_test.shape, y_train.shape, y_test.shape\n\n#X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.1)#\n#X_train.shape, X_valid.shape, y_train.shape, y_valid.shape\n#######################################################################################\n\nX, X_test, y, y_test = train_test_split(X,y,test_size=0.1, stratify = y)\nX.shape, X_test.shape, y.shape, y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function defined to plot the curves during training\n\ndef display_training_curves(training, validation, title, subplot):\n    \n    if subplot%10==1: # set up the subplots on the first call\n        plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n        plt.tight_layout()\n    ax = plt.subplot(subplot)\n    ax.set_facecolor('#F8F8F8')\n    ax.plot(training)\n    ax.plot(validation)\n    ax.set_title('model '+ title)\n    ax.set_ylabel(title)\n    #ax.set_ylim(0.28,1.05)\n    ax.set_xlabel('epoch')\n    ax.legend(['train', 'valid.'])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# TRAINING OF MODEL","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"1. **DESIGNING THE CONVOLUTIONAL NEURAL NETWORK MODEL**\n2. **USING STRATIFIED K-FOLD CROSS VALIDATION TECHNIQUE TO SPLIT THE TRAINING DATA INTO TRAINING AND VALIDATION SETS**\n3. **COMPILE AND TRAIN THE MODEL FOR EACH SPLIT**\n4. **PLOT THE TRAINING CURVES FOR EACH SPLIT**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"BS = 32       #Batch size\naccuracy = []\n\n############ USING STRATIFIED K-FOLD CROSS VALIDATION TECHNIQUE ##########\n\nskf = StratifiedKFold(n_splits=5)\nskf.get_n_splits(X,y)\n\nfor train, test in skf.split(X,y):\n    model2 = tf.keras.Sequential([\n        efn.EfficientNetB5(\n            input_shape=(128,128, 3),\n            weights='imagenet',\n            include_top=False\n        ),\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dropout(0.4),\n        tf.keras.layers.Dense(5, activation='softmax')\n    ])\n    \n    # Compiling the model\n    model2.compile(optimizer=tf.keras.optimizers.Adam(lr=0.00001),loss='sparse_categorical_crossentropy',metrics=['acc'])\n    \n    # Training\n    history = model2.fit_generator(aug.flow(X[train], y[train], batch_size=BS),\n    validation_data=(X[test], y[test]),\n    epochs=80, verbose = 1)\n\n    # Evaluate score\n    acc=model2.evaluate(X[test], y[test])\n    accuracy.append(acc[1])\n    \n    # Plotting traning curves\n    display_training_curves(\n    history.history['loss'], \n    history.history['val_loss'], \n    'loss', 211)\n    \n    display_training_curves(\n    history.history['acc'], \n    history.history['val_acc'], \n    'accuracy', 212)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we can see the minimum and maximum validation accuracy received after training on the training dataset\naccuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# thus we can assume the mean accuracy of the model on the training set to be:\na=sum(accuracy)/len(accuracy)\nprint(f'Mean evaluated accuracy of model : {a}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**MODEL LAYER DIAGRAM**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\nSVG(model_to_dot(model2).create(prog='dot', format='svg'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ANALYSIS OF TRAINING MODEL","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#predicting training labels\ny_train_pred = model2.predict_classes(X)\n\n#Accuracy of train prediction\nprint('\\nAccuracy of training data prediction : {:.2f}\\n'.format(accuracy_score(y, y_train_pred)))\n\n#confusion matrix for training set\nconfusion = confusion_matrix(y, y_train_pred)\nprint('Confusion Matrix of training data prediction \\n')\nprint(confusion)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizing confusion matrix for train data\nskplt.metrics.plot_confusion_matrix(y, y_train_pred, figsize=(8, 8))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Classification report \nprint('\\nClassification Report of training set : \\n')\nprint(classification_report(y, y_train_pred, target_names=['No DR', 'Mild', 'Moderate', 'Severe', 'Proliferate DR']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# PREDICTING TEST RESULTS","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model2.predict_classes(X_test)\ny_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**ANALYSIS OF TEST RESULTS**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Accuracy of test prediction\nprint('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confusion matrix of the test data\nconfusion = confusion_matrix(y_test, y_pred)\nprint('Confusion Matrix\\n')\nprint(confusion)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizing confusion matrix for test data\nskplt.metrics.plot_confusion_matrix(y_test, y_pred, figsize=(8, 8))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Classification report\nprint('\\nClassification Report\\n')\nprint(classification_report(y_test, y_pred, target_names=['No DR', 'Mild', 'Moderate', 'Severe', 'Proliferate DR']))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}