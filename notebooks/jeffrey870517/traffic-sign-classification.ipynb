{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import gc\nimport os\nimport sys\nimport time\nimport random\nimport logging\nimport datetime as dt\nimport cv2\nimport pickle\n\nimport numpy as np\nimport pandas as pd\nimport datetime\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.utils.data as data\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as fun\nimport torchvision as vision\nfrom torch.autograd import Variable\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nfrom torchvision import datasets, models, transforms\nfrom pathlib import Path\nfrom PIL import Image\nfrom contextlib import contextmanager\n\nfrom joblib import Parallel, delayed\nfrom tqdm import tqdm\nfrom fastprogress import master_bar, progress_bar\n\nfrom sklearn.metrics import fbeta_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dir = '../input/traffic-signs-preprocessed/'\nnum_epochs = 32\nbatch_size = 50\nlearning_rate = 0.0001","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pickle.load(open(data_dir+'train.pickle','rb'))\ntest = pickle.load(open(data_dir+'test.pickle','rb'))\nvalid = pickle.load(open(data_dir+'valid.pickle','rb'))\nlabels = pickle.load(open(data_dir+'labels.pickle','rb'))\n#print(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labs = train['labels']\nvalid_labs = valid['labels']\ntest_labs = test['labels']\n\ntrain_imgs = train['features']\nvalid_imgs = valid['features']\ntest_imgs = test['features']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(train_labs),len(valid_labs),len(test_labs))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"means = np.mean(train_imgs, axis=(0, 1, 2)) / 255.\nstds = np.std(train_imgs, axis=(0, 1, 2)) / 255.\nprint(means)\nprint(stds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class dataprocessor(Dataset):\n    def __init__(self,image,labels,transform):\n        self.image = image\n        self.labels = labels\n        self.transform = transform\n    def __len__(self):\n        return self.labels.shape[0]\n    def __getitem__(self,idx):\n        image = self.image[idx] \n        image= Image.fromarray(image)\n        image = self.transform(image)\n        image= image.tolist()\n        label = np.zeros((43),dtype=int)\n        label= label.tolist()\n        label_idx = self.labels[idx]\n        label[label_idx] = 1\n        label= torch.FloatTensor(label)\n        image=torch.FloatTensor(image)\n        \n        return [image,label]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_transforms = {\n    'train': vision.transforms.Compose([\n    vision.transforms.Resize((64,64)),\n    transforms.RandomResizedCrop(250),\n    transforms.RandomHorizontalFlip(),\n    vision.transforms.ToTensor(),\n    vision.transforms.Normalize(mean=means, std=stds)\n    ]),\n    'val': vision.transforms.Compose([\n        vision.transforms.Resize(256),\n        vision.transforms.CenterCrop(224),\n        vision.transforms.ToTensor(),\n        vision.transforms.Normalize(mean=means, std=stds)\n    ]),\n}\n\ndata_transforms[\"test\"] = data_transforms[\"train\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = dataprocessor(train_imgs,train_labs,data_transforms[\"train\"])\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True , num_workers=2, pin_memory=True)\n\ntest_dataset = dataprocessor(test_imgs,test_labs,data_transforms[\"test\"])\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True , num_workers=2, pin_memory=True)\n\nvalid_dataset = dataprocessor(valid_imgs,valid_labs,data_transforms[\"test\"])\nvalid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False , num_workers=2, pin_memory=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def training(epoch,loss_func,optimizer,model,dataloader):\n    training_loss = 0\n    training_acc = 0\n    for step,( x,y ) in enumerate(dataloader):\n        data = Variable(x).cuda()   # batch x\n        target = Variable(y).cuda()   #batch x\n        model.cuda()\n        output = model(data)\n        target = Variable(y).cuda()\n        loss = loss_func(output, target.float())   # cross entropy loss\n        optimizer.zero_grad()           # clear gradients for this training step\n        loss.backward()                 # backpropagation, compute gradients\n        optimizer.step()                # apply gradients\n        training_loss += loss.item()\n        training_acc += (torch.max(output, 1)[1] == torch.max(target, 1)[1]).type(torch.FloatTensor).mean().item()\n        if step==0:\n            start = time.time()\n            ti = 0\n        elif step==100:\n            ti = time.time()-start #total time = ti*(length/100)\n            #print(ti)\n            ti = ti*(len(dataloader)/100)\n        if step % 100 == 0:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.10f}\\tTime Remain : {} '.\n                     format(epoch+1, \n                            step * len(data), \n                            len(dataloader.dataset),\n                            100.*step/len(dataloader), \n                            loss.data.item(),\n                            datetime.timedelta(seconds=(ti*((int(len(dataloader)-step)/len(dataloader)))))))\n        data.detach()   # batch x\n        target.detach()   # batch y\n    epoch_loss = training_loss / len(dataloader)\n    epoch_acc = training_acc / len(dataloader) #caculating the whole epoch accuracy\n    print(\"Train MSELoss/Accuracy: \\t{:.4f}\\t{:.4f}\".format(epoch_loss,epoch_acc))\n    print(\"Epoch: {} finish!\".format(epoch+1))\n    return model\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"densenet201 = models.densenet201(pretrained='imagenet')#\nresnet50 = models.resnet50(pretrained='imagenet')#\n#in_features = 1920,\ndensenet201.classifier = nn.Linear(in_features=1920,out_features=43, bias = True)#in_features=2048\nresnet50.fc = nn.Linear(in_features=2048, out_features=43, bias=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def training_process(net_name,model,parameters):\n    print(\"Taining Model :{}.\\n Numbers of epoch: {}\".format(net_name,num_epochs))\n    for epoch  in range(num_epochs) :\n        loss_func=torch.nn.MSELoss()\n        optimizer = torch.optim.Adam(model.parameters(), lr=0.00002/(2**epoch))\n        model=training(epoch,loss_func,optimizer,model,train_loader)\n        valid_loss = 0\n        valid_acc = 0\n        with torch.no_grad():\n            for step,( x,y ) in enumerate(valid_loader):\n                data = Variable(x).cuda()   # batch x\n                target = Variable(y).cuda()   #batch x\n                model.cuda()\n                output = model(data)\n                target = Variable(y).cuda()\n                loss = loss_func(output, target.float())   # cross entropy loss\n    \n                valid_loss += loss.item()\n                valid_acc += (torch.max(output, 1)[1] == torch.max(target, 1)[1]).type(torch.FloatTensor).mean().item()\n        epoch_valid_loss = valid_loss / len(valid_loader)\n        epoch_valid_acc = valid_acc / len(valid_loader)\n        print(\"{}\\tValid MSELoss/Accuracy: \\t{:.4f}\\t{:.4f}\".format(net_name,epoch_valid_loss,epoch_valid_acc))\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trained_densenet201 = training_process('Densenet201',densenet201,densenet201.parameters())\ntorch.save(trained_densenet201, 'trained_densenet201.pkl')\ntorch.cuda.empty_cache()\n!nvidia-smi","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trained_resnet50 = training_process('Resnet50',resnet50,resnet50.parameters())\ntorch.save(trained_resnet50, 'trained_resnet50.pkl')\ntorch.cuda.empty_cache()\n!nvidia-smi","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test(net_name,errors,model):\n    test_acc = 0\n    test_loss = 0\n    loss_func=torch.nn.MSELoss()\n    for step, (x,y) in enumerate(test_loader):\n        data = Variable(x).cuda()   # batch x\n        target = Variable(y).cuda()   #batch y\n        \n        model.cuda()\n        output = model(data)\n        target = Variable(y).cuda()\n        loss = loss_func(output, target.float())\n        test_loss += loss.item()\n        test_acc += (torch.max(output, 1)[1] == torch.max(target, 1)[1]).type(torch.FloatTensor).mean().item()\n        \n        true_labels = torch.max(target, 1)[1]\n        pred_labels = torch.max(output, 1)[1]\n        for idx in range(len(true_labels)):\n            if true_labels[idx] != pred_labels[idx]:\n                errors.append((np.transpose(data[idx].cpu().numpy(), (1,2,0)), true_labels[idx], pred_labels[idx]))\n    epoch_loss = test_loss / len(test_loader)\n    epoch_acc = test_acc / len(test_loader)\n    print('{} \\t Test Loss: {:.4f}'.format(net_name,epoch_loss))\n    print('{}\\t Test Accuracy: {:.4f}'.format(net_name,epoch_acc))\n    return errors","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net_densenet = torch.load('trained_densenet201.pkl')\ndensenet201_errors = test('densenet201',[],net_densenet)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net_resnet = torch.load('trained_resnet50.pkl')\nresnet50_errors = test('resnet50',[],net_resnet)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}