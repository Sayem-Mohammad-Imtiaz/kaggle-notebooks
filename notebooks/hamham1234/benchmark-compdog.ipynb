{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/input/timm-pytorch-image-models/pytorch-image-models-master')\n\nimport os\nimport random\nfrom tqdm import tqdm\n\nimport timm\nimport torch\nfrom torch import nn\nfrom torch.cuda.amp import autocast, GradScaler\nimport numpy as np\nimport pandas as pd\nimport cv2\n\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold\n\nfrom torch.utils.data import Dataset","metadata":{"execution":{"iopub.status.busy":"2021-08-31T09:00:42.34282Z","iopub.execute_input":"2021-08-31T09:00:42.343318Z","iopub.status.idle":"2021-08-31T09:00:43.931803Z","shell.execute_reply.started":"2021-08-31T09:00:42.343214Z","shell.execute_reply":"2021-08-31T09:00:43.93087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = {\n    \"fold_num\": 5,\n    \"seed\": 6,\n    \"model_arch\": \"tf_efficientnet_b3\",\n    \"model_shape\" : \"eff\",\n    \"debug\": 1,\n    \"pretrained\" : 1,\n    \"img_size\": 256,\n    \"epochs\": 1,\n    \"train_bs\": 16,\n    \"valid_bs\": 16,\n    \"T_0\": 10,\n    \"lr\": 3e-4,\n    \"min_lr\": 3e-6,\n    \"weight_decay\": 1e-4,\n    \"num_workers\": 4,\n    \"verbose_step\": 1,\n    \"device\": \"cuda:0\",\n    \"tta\": 2,\n    \"monitor\" : \"val_accuracy\",\n    \"patience\" : 2,\n    \"mode\" : \"max\"\n}","metadata":{"execution":{"iopub.status.busy":"2021-08-31T09:00:43.934309Z","iopub.execute_input":"2021-08-31T09:00:43.934865Z","iopub.status.idle":"2021-08-31T09:00:43.94153Z","shell.execute_reply.started":"2021-08-31T09:00:43.934817Z","shell.execute_reply":"2021-08-31T09:00:43.94074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed):\n    \"seed値を一括指定\"\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\ndef get_img(path):\n    \"\"\"\n    pathからimageの配列を得る\n    \"\"\"\n    im_bgr = cv2.imread(path)\n    if im_bgr is None:\n        print(path)\n    im_rgb = im_bgr[:, :, ::-1]\n    \n    return im_rgb","metadata":{"execution":{"iopub.status.busy":"2021-08-31T09:00:43.943293Z","iopub.execute_input":"2021-08-31T09:00:43.94364Z","iopub.status.idle":"2021-08-31T09:00:43.957213Z","shell.execute_reply.started":"2021-08-31T09:00:43.9436Z","shell.execute_reply":"2021-08-31T09:00:43.956146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed_everything(config['seed'])\ndevice = torch.device(config['device'])","metadata":{"execution":{"iopub.status.busy":"2021-08-31T09:00:43.958855Z","iopub.execute_input":"2021-08-31T09:00:43.959242Z","iopub.status.idle":"2021-08-31T09:00:43.968118Z","shell.execute_reply.started":"2021-08-31T09:00:43.959204Z","shell.execute_reply":"2021-08-31T09:00:43.967338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data読み込み\ndf_train = pd.read_csv(\"/kaggle/input/comp-dog/train.csv\")\ndf_test = pd.read_csv(\"/kaggle/input/comp-dog/submission.csv\")\nsubmission = pd.read_csv(\"/kaggle/input/comp-dog/submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-08-31T09:00:43.970727Z","iopub.execute_input":"2021-08-31T09:00:43.971026Z","iopub.status.idle":"2021-08-31T09:00:44.006362Z","shell.execute_reply.started":"2021-08-31T09:00:43.970992Z","shell.execute_reply":"2021-08-31T09:00:44.005478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ラベルエンコーディング、130個\nle = preprocessing.LabelEncoder()\ndf_train[\"label\"] = le.fit_transform(df_train[\"class\"])\ndf_train[\"path\"] = \"/kaggle/input/comp-dog/train/train/\" + df_train[\"img_name\"] + \".jpg\"\ndf_test[\"label\"] = -1\ndf_test[\"path\"] = \"/kaggle/input/comp-dog/test/test/\" + df_test[\"img_name\"] + \".jpg\"\nprint(\"training_class : \", len(le.classes_))","metadata":{"execution":{"iopub.status.busy":"2021-08-31T09:00:44.007659Z","iopub.execute_input":"2021-08-31T09:00:44.008024Z","iopub.status.idle":"2021-08-31T09:00:44.036586Z","shell.execute_reply.started":"2021-08-31T09:00:44.00798Z","shell.execute_reply":"2021-08-31T09:00:44.035757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data augmentation\nfrom albumentations import (\n    PadIfNeeded, HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize,ToGray\n)\n\nfrom albumentations.pytorch import ToTensorV2\n\ndef get_train_transforms(input_shape):\n    return Compose([\n            Resize(input_shape, input_shape),\n            HorizontalFlip(p=0.5),\n            VerticalFlip(p=0.5),\n            ShiftScaleRotate(p=0.5),\n            Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(p=1.0),\n        ], p=1.)\n\ndef get_valid_transforms(input_shape):\n    return Compose([\n                Resize(input_shape, input_shape),\n                Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n                ToTensorV2(p=1.0),\n            ], p=1.)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T09:00:44.037759Z","iopub.execute_input":"2021-08-31T09:00:44.038098Z","iopub.status.idle":"2021-08-31T09:00:44.348478Z","shell.execute_reply.started":"2021-08-31T09:00:44.038061Z","shell.execute_reply":"2021-08-31T09:00:44.347624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dataset\nclass DogDataset(Dataset):\n    def __init__(self, df, transforms=None):\n        super().__init__()\n        self.df = df.reset_index(drop=True).copy()\n        self.transforms = transforms\n\n    def __len__(self):\n        return self.df.shape[0]\n\n    def __getitem__(self, index: int):\n        target = self.df.loc[index][\"label\"]\n\n        img  = get_img(self.df.loc[index][\"path\"])\n\n        if self.transforms:\n            img = self.transforms(image=img)['image']\n\n        return img, target","metadata":{"execution":{"iopub.status.busy":"2021-08-31T09:00:44.351042Z","iopub.execute_input":"2021-08-31T09:00:44.35144Z","iopub.status.idle":"2021-08-31T09:00:44.357987Z","shell.execute_reply.started":"2021-08-31T09:00:44.351401Z","shell.execute_reply":"2021-08-31T09:00:44.357162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model\nclass DogClassifier(nn.Module):\n    def __init__(self, model_arch, n_class, model_shape, pretrained=True):\n        super().__init__()\n        self.model = timm.create_model(model_arch, pretrained=pretrained)\n\n        if model_shape == \"eff\":\n            n_features = self.model.classifier.in_features\n            self.model.classifier = nn.Linear(n_features, n_class)\n        elif model_shape == \"vit\":\n            n_features = self.model.head.in_features\n            self.model.head = nn.Linear(n_features, n_class)\n        elif model_shape == \"res\":\n            n_features = self.model.fc.in_features\n            self.model.fc = nn.Linear(n_features, n_class)\n\n    def forward(self, x):\n        x = self.model(x)\n        return x\n\ndef train_one_epoch(epoch, model, loss_fn, optimizer, train_loader, device, verbose_step, scheduler=None, schd_batch_update=False, arcface=False):\n    model.train()\n    scaler = GradScaler()\n\n    running_loss = None\n\n    pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n    for step, (imgs, image_labels) in pbar:\n        imgs = imgs.to(device).float()\n        image_labels = image_labels.to(device).long()\n\n        with autocast():\n            image_preds = model(imgs)\n            loss = loss_fn(image_preds, image_labels)\n\n            scaler.scale(loss).backward()\n\n            if running_loss is None:\n                running_loss = loss.item()\n            else:\n                running_loss = running_loss * .99 + loss.item() * .01\n\n            scaler.step(optimizer)\n            scaler.update()\n            optimizer.zero_grad()\n            if scheduler is not None and schd_batch_update:\n                scheduler.step()\n\n            if ((step + 1) % verbose_step == 0) or ((step + 1) == len(train_loader)):\n                description = f'epoch {epoch} loss: {running_loss:.4f}'\n                pbar.set_description(description)\n\n    print(\"train: \"+ description)\n    if scheduler is not None and not schd_batch_update:\n        scheduler.step()\n\ndef valid_one_epoch(epoch, model, loss_fn, val_loader, device, verbose_step, scheduler=None, schd_loss_update=False):\n    model.eval()\n\n    loss_sum = 0\n    sample_num = 0\n    image_preds_all = []\n    image_targets_all = []\n\n    pbar = tqdm(enumerate(val_loader), total=len(val_loader))\n    for step, (imgs, image_labels) in pbar:\n        imgs = imgs.to(device).float()\n        image_labels = image_labels.to(device).long()\n\n        image_preds = model(imgs)\n\n        image_preds_all += [torch.argmax(image_preds, 1).detach().cpu().numpy()]\n        image_targets_all += [image_labels.detach().cpu().numpy()]\n\n        loss = loss_fn(image_preds, image_labels)\n\n        loss_sum += loss.item()*image_labels.shape[0]\n        sample_num += image_labels.shape[0]\n\n        if ((step + 1) % verbose_step== 0) or ((step + 1) == len(val_loader)):\n            description = f'epoch {epoch} loss: {loss_sum/sample_num:.4f}'\n            pbar.set_description(description)\n\n    print(\"valid \"+ description)\n    image_preds_all = np.concatenate(image_preds_all)\n    image_targets_all = np.concatenate(image_targets_all)\n    print('validation multi-class accuracy = {:.4f}'.format((image_preds_all==image_targets_all).mean()))\n\n    if scheduler is not None:\n        if schd_loss_update:\n            scheduler.step(loss_sum/sample_num)\n        else:\n            scheduler.step()\n\n    monitor = {}\n    monitor[\"val_loss\"] = loss_sum/sample_num\n    monitor[\"val_accuracy\"] = (image_preds_all==image_targets_all).mean()\n    return monitor\n\ndef inference_one_epoch(model, data_loader, device):\n    model.eval()\n\n    image_preds_all = []\n    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n    for step, (imgs, _) in pbar:\n        imgs = imgs.to(device).float()\n\n        image_preds = model(imgs)   #output = model(input)\n        image_preds_all += [torch.softmax(image_preds, 1).detach().cpu().numpy()]\n\n    image_preds_all = np.concatenate(image_preds_all, axis=0)\n    return image_preds_all\n\nclass EarlyStopping:\n    def __init__(self, patience):\n        self.max_val_monitor = 1000\n        self.min_val_monitor = -1000\n        self.val_epoch = -1\n        self.stop_count = 0\n        self.patience = patience\n        self.min_delta = 0\n\n    # mode = \"min\" or \"max\"(val_loss, val_accuracy)\n    def update(self, monitor, epoch, mode):\n        if mode == \"max\":\n            if monitor > self.min_val_monitor:\n                self.min_val_monitor = monitor\n                self.val_epoch = epoch\n                self.stop_count = 0\n            else:\n                self.stop_count+=1\n        else:\n            if monitor < self.max_val_monitor:\n                self.max_val_monitor = monitor\n                self.val_epoch = epoch\n                self.stop_count = 0\n            else:\n                self.stop_count+=1\n\n        if self.stop_count >= self.patience:\n            return -1\n        else:\n            return 0","metadata":{"execution":{"iopub.status.busy":"2021-08-31T09:00:44.359574Z","iopub.execute_input":"2021-08-31T09:00:44.36016Z","iopub.status.idle":"2021-08-31T09:00:44.514094Z","shell.execute_reply.started":"2021-08-31T09:00:44.360122Z","shell.execute_reply":"2021-08-31T09:00:44.512918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ds = DogDataset(df_test, transforms=get_valid_transforms(config[\"img_size\"]))\ntest_loader = torch.utils.data.DataLoader(\n    test_ds,\n    batch_size=config[\"valid_bs\"],\n    num_workers=config[\"num_workers\"],\n    shuffle=False,\n    pin_memory=True,\n)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T09:00:44.516225Z","iopub.execute_input":"2021-08-31T09:00:44.516861Z","iopub.status.idle":"2021-08-31T09:00:44.529335Z","shell.execute_reply.started":"2021-08-31T09:00:44.516817Z","shell.execute_reply":"2021-08-31T09:00:44.528409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_epochs = []\nfolds = StratifiedKFold(\n            n_splits=config['fold_num'],\n            shuffle=True,\n            random_state=config['seed']).split(np.arange(df_train.shape[0]),\n            df_train.label.values\n        )\n\nfor fold, (trn_idx, val_idx) in enumerate(folds):\n    if fold > 0: # 時間がかかるので最初のモデルのみ\n        break\n\n    # Dataset作成\n    train_ = df_train.loc[trn_idx,:].reset_index(drop=True)\n    valid_ = df_train.loc[val_idx,:].reset_index(drop=True)\n\n    train_ds = DogDataset(train_, transforms=get_train_transforms(config[\"img_size\"]))\n    valid_ds = DogDataset(valid_, transforms=get_valid_transforms(config[\"img_size\"]))\n\n    train_loader = torch.utils.data.DataLoader(\n            train_ds,\n            batch_size=config[\"train_bs\"],\n            pin_memory=True,\n            drop_last=False,\n            num_workers=config[\"num_workers\"],\n        )\n\n    valid_loader = torch.utils.data.DataLoader(\n        valid_ds,\n        batch_size=config[\"valid_bs\"],\n        num_workers=config[\"num_workers\"],\n        shuffle=False,\n        pin_memory=True,\n    )\n    \n    #modelと最適化関数作成\n    model = DogClassifier(config['model_arch'],\n                              len(le.classes_),\n                              config[\"model_shape\"],\n                              pretrained=config[\"pretrained\"])\n\n    model.eval()\n    model = model.to(device)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'], weight_decay=config['weight_decay'])\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=config['T_0'], T_mult=1, eta_min=config['min_lr'], last_epoch=-1)\n    er = EarlyStopping(config['patience'])\n\n    loss_tr = nn.CrossEntropyLoss().to(device)\n    loss_vl = nn.CrossEntropyLoss().to(device)\n    \n    print(f'Training with fold {fold} started (train:{len(trn_idx)}, val:{len(val_idx)})')\n    # train phase\n    for epoch in range(config['epochs']):\n        train_one_epoch(epoch, model, loss_tr, optimizer, train_loader, device, config['verbose_step'],scheduler=scheduler, schd_batch_update=False)\n        with torch.no_grad():\n            monitor = valid_one_epoch(epoch, model, loss_vl, valid_loader, device, config['verbose_step'], scheduler=None, schd_loss_update=False)\n\n        # Early Stopiing\n        if er.update(monitor[config[\"monitor\"]], epoch, config[\"mode\"]) < 0:\n            break\n\n        if epoch == er.val_epoch:\n            torch.save(model.state_dict(),f'/kaggle/working/{config[\"model_arch\"]}_fold_{fold}_{epoch}')\n\n    val_epochs.append(er.val_epoch)\n    \n    del model, train_loader, valid_loader, optimizer, scheduler\n    \n    #inference phase\n    model = DogClassifier(config['model_arch'],\n                              len(le.classes_),\n                              config[\"model_shape\"]).to(device)\n\n    model.load_state_dict(torch.load(f'/kaggle/working/{config[\"model_arch\"]}_fold_{fold}_{er.val_epoch}'))\n    tst_preds = []\n    with torch.no_grad():\n        tst_preds += [inference_one_epoch(model, test_loader, device)]\n    tst_preds = np.mean(tst_preds, axis=0)\n    tst_pred = le.inverse_transform(np.argmax(tst_preds, axis=1))\n    submission[\"class\"] = tst_pred\n    submission.to_csv(f\"/kaggle/working/benchmark.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T09:00:44.532163Z","iopub.execute_input":"2021-08-31T09:00:44.532486Z","iopub.status.idle":"2021-08-31T09:05:46.67222Z","shell.execute_reply.started":"2021-08-31T09:00:44.532458Z","shell.execute_reply":"2021-08-31T09:05:46.671204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}