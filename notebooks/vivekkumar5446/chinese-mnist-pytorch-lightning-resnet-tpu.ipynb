{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Install dependencies","metadata":{}},{"cell_type":"code","source":"!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n!python pytorch-xla-env-setup.py --version \"nightly\"","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-09T09:16:22.311835Z","iopub.execute_input":"2021-06-09T09:16:22.312188Z","iopub.status.idle":"2021-06-09T09:16:43.939485Z","shell.execute_reply.started":"2021-06-09T09:16:22.312158Z","shell.execute_reply":"2021-06-09T09:16:43.93833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -U pytorch_lightning","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-09T09:16:43.941686Z","iopub.execute_input":"2021-06-09T09:16:43.942118Z","iopub.status.idle":"2021-06-09T09:19:14.586201Z","shell.execute_reply.started":"2021-06-09T09:16:43.94207Z","shell.execute_reply":"2021-06-09T09:19:14.585227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#https://drive.google.com/file/d/1KBtB-kk3O6YTHqQOAz4weDVsSkWbXvlt/view?usp=sharing","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define dataset and dataloader via pytorch-lightning datamodule","metadata":{}},{"cell_type":"code","source":"import os\nfrom pathlib import Path\n\nimport albumentations as A\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport pytorch_lightning as pl\nimport torch\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations.augmentations.transforms import Blur, RandomBrightness\nfrom torch.utils.data import DataLoader, Dataset\n\n\nclass ChineseMNISTDataset(Dataset):\n    def __init__(\n        self,\n        df: pd.DataFrame,\n        image_root: Path,\n        transform: A.BasicTransform = None,\n    ) -> None:\n        super().__init__()\n        self.df = df\n        self.image_root = image_root\n        self.transform = transform\n\n    def __getitem__(self, idx: int):\n        row = self.df.loc[idx, :]\n        suite_id, code, sample_id = row.suite_id, row.code, row.sample_id\n        filename = self.image_root / f\"input_{suite_id}_{sample_id}_{code}.jpg\"\n        assert os.path.isfile(filename), f\"{filename} is not a file\"\n        image = cv2.imread(str(filename))\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        image = image[:, np.newaxis]\n        if self.transform is not None:\n            image = self.transform(image=image)[\"image\"]\n        return image, code - 1\n\n    def __len__(self):\n        return len(self.df)\n\n\nclass ChineseMNISTDataModule(pl.LightningDataModule):\n    def __init__(\n        self,\n        data_root: Path,\n        all_df: pd.DataFrame,\n        train_indices: pd.Index,\n        val_indices: pd.Index,\n        batch_size: int = 64\n    ) -> None:\n        super().__init__()\n        self.data_root = data_root\n        self.df = all_df\n        self.image_root = self.data_root / \"data\" / \"data\"\n        self.train_df = self.df.loc[train_indices, :].copy().reset_index()\n        self.train_transform = A.Compose(\n            [\n                Blur(),\n                RandomBrightness(),\n                ToTensorV2(),\n            ]\n        )\n        self.val_df = self.df.loc[val_indices, :].copy().reset_index()\n        self.val_transform = A.Compose(\n            [\n                ToTensorV2(),\n            ]\n        )\n        self.batch_size = batch_size\n\n    def train_dataloader(self):\n        ds = ChineseMNISTDataset(self.train_df, self.image_root, self.train_transform)\n        return DataLoader(\n            ds,\n            batch_size=self.batch_size,\n            shuffle=True,\n            num_workers=4,\n            pin_memory=True,\n        )\n\n    def val_dataloader(self):\n        ds = ChineseMNISTDataset(self.val_df, self.image_root, self.val_transform)\n        return DataLoader(\n            ds,\n            batch_size=self.batch_size,\n            shuffle=False,\n            num_workers=4,\n            pin_memory=True,\n        )\n\n    def test_dataloader(self):\n        return self.val_dataloader()\n    \n# sanity check\nis_kaggle = os.path.isdir(\"/kaggle\")\ndata_root = Path(\"/kaggle/input/chinese-mnist\" if is_kaggle else \"archive\")\nassert os.path.isdir(data_root), f\"{data_root} is not a dir\"\ndf = pd.read_csv(data_root / \"chinese_mnist.csv\")\n\ndata_module = ChineseMNISTDataModule(data_root, df, df.index[:20], df.index[20:30])","metadata":{"execution":{"iopub.status.busy":"2021-06-09T09:19:14.587772Z","iopub.execute_input":"2021-06-09T09:19:14.588049Z","iopub.status.idle":"2021-06-09T09:19:16.767652Z","shell.execute_reply.started":"2021-06-09T09:19:14.588019Z","shell.execute_reply":"2021-06-09T09:19:16.76517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model definition","metadata":{}},{"cell_type":"code","source":"import os\nfrom pathlib import Path\n\nimport pandas as pd\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\nfrom pytorch_lightning.metrics import Accuracy\nfrom sklearn.model_selection import StratifiedKFold\nfrom torch import nn, optim\nfrom torchvision.models import resnet18\n\n\nclass ChineseMNISTResnetModel(pl.LightningModule):\n    def __init__(self, learning_rate=1e-3):\n        super().__init__()\n        self.learning_rate = learning_rate\n        self.num_classes = 15\n        resnet = resnet18(pretrained=True, progress=True)\n        resnet.conv1 = nn.Conv2d(\n            in_channels=1,\n            out_channels=resnet.conv1.out_channels,\n            kernel_size=resnet.conv1.kernel_size,\n            stride=resnet.conv1.stride,\n            dilation=resnet.conv1.dilation,\n            bias=resnet.conv1.bias,\n        )\n        resnet.fc = nn.Linear(512, self.num_classes)\n        self.resnet = resnet\n        self.accuracy = Accuracy()\n        self.criterion = nn.CrossEntropyLoss()\n\n    def forward(self, image):\n        image = image.permute(0, 3, 1, 2).contiguous().float()\n        return self.resnet(image)\n\n    def training_step(self, batch, batch_idx: int):\n        image, y = batch\n        yhat = self(image)\n        loss = self.criterion(yhat, y)\n        acc = self.accuracy(yhat, y)\n        return loss\n\n    def validation_step(self, batch, batch_idx: int, log: bool = True):\n        image, y = batch\n        yhat = self(image)\n        loss = self.criterion(yhat, y)\n        acc = self.accuracy(yhat, y)\n        if log:\n            self.log('val_loss', loss, prog_bar=True, on_epoch=True, on_step=False)\n            self.log('val_acc', acc, prog_bar=True, on_epoch=True, on_step=False)        \n        return {'val_loss': loss, 'val_acc': acc}\n\n    def test_step(self, batch, batch_idx):\n        metrics = self.validation_step(batch, batch_idx, log = False)\n        self.log('test_loss', metrics[\"val_loss\"], on_epoch=True, on_step=False)\n        self.log('test_acc', metrics[\"val_acc\"], on_epoch=True, on_step=False)    \n        return {\"test_acc\": metrics[\"val_acc\"], \"test_loss\": metrics[\"val_loss\"]}\n\n    def configure_optimizers(self):\n        optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)\n        return optimizer\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"is_kaggle = os.path.isdir(\"/kaggle\")\ndata_root = Path(\"/kaggle/input/chinese-mnist\" if is_kaggle else \"archive\")\nall_df = pd.read_csv(data_root / \"chinese_mnist.csv\")\n\nskf = StratifiedKFold(n_splits=5, shuffle=True)\n\ncheckpoint_callback = ModelCheckpoint(\n    filepath=os.getcwd(),\n    save_top_k=1,\n    verbose=True,\n    monitor=\"val_loss\",\n    mode=\"min\",\n)\ntrainer = pl.Trainer(\n    # gpus=1,\n    tpu_cores=8,\n    max_epochs=20,\n    precision=16,\n    val_check_interval=1.,\n    callbacks=[checkpoint_callback]\n)\n\nfor train_indices, val_indices in skf.split(all_df, all_df.code):\n    data_module = ChineseMNISTDataModule(\n        data_root=data_root,\n        all_df=all_df,\n        train_indices=train_indices,\n        val_indices=val_indices,\n        batch_size=32\n    )\n    model = ChineseMNISTResnetModel()\n    trainer.fit(model, datamodule=data_module)\n    break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(torch.load(checkpoint_callback.best_model_path)[\"state_dict\"])\ntrainer.test(test_dataloaders=data_module.train_dataloader(),ckpt_path=None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.test(test_dataloaders=data_module.val_dataloader(),ckpt_path=None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}