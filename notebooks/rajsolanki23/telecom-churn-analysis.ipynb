{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Predicting Telco Customer Churn using Random Forest Classifier","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"In this notebook I will build the prediction model using the SparkML library.\n\nThis notebook walks you through these steps:\n\n- Load and Visualize data set.\n- Build a predictive model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 1.0 Install required packages\n\nThere are a couple of Python packages I will use in this notebook. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install --user pyspark==2.3.3 --upgrade|tail -n 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport json\nimport os\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.0 Load and Clean data\n\nThe data will be loaded as a pandas data frame.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nprint(os.listdir(\"../input/telco-customer-churn\"))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.1 Drop CustomerID feature (column)\nAs it contains PII","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop('customerID', axis=1)\ndf.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.2 Examine the data types of the features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Statistics for the columns (features). Set it to all, since default is to describe just the numeric features.\ndf.describe(include = 'all')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It can be observed that Tenure ranges from 0 (new customer) to 6 years, Monthly charges range from $18 to $118, etc","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 2.3 Check for need to Convert TotalCharges column to numeric if it is detected as object\n\nSince above `df.info` shows the \"TotalCharges\" columnn as an object, it needs to converted to numeric.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"totalCharges = df.columns.get_loc(\"TotalCharges\")\nnew_col = pd.to_numeric(df.iloc[:, totalCharges], errors='coerce')\ndf.iloc[:, totalCharges] = pd.Series(new_col)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\n### 2.4 Any NaN values should be removed to create a more accurate model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check if we have any NaN values and see which features have missing values that should be addressed\nprint(df.isnull().values.any())\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`TotalCharges` column has missing values. There are various ways to address this issue:\n\n- Drop records with missing values \n- Fill in the missing value with one of the following strategies: Zero, Mean of the values for the column, Random value, etc).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Handle missing values for nan_column (TotalCharges)\nfrom sklearn.impute import SimpleImputer\n\n# Find the column number for TotalCharges (starting at 0).\ntotal_charges_idx = df.columns.get_loc(\"TotalCharges\")\nimputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\") #SimpleImputer(strategy=\"most_frequent\")\n\ndf.iloc[:, total_charges_idx] = imputer.fit_transform(df.iloc[:, total_charges_idx].values.reshape(-1, 1))\ndf.iloc[:, total_charges_idx] = pd.Series(df.iloc[:, total_charges_idx])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Validate that we have addressed any NaN values\nprint(df.isnull().values.any())\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n### 2.5 Categorize Features\n\nSome of the columns / features are categorized based on wether they are categorical values or continuous (i.e numerical) values which will be used later to build visualizations.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"columns_idx = np.s_[0:] # Slice of first row(header) with all columns.\nfirst_record_idx = np.s_[0] # Index of first record\n\nstring_fields = [type(fld) is str for fld in df.iloc[first_record_idx, columns_idx]] # All string fields\nall_features = [x for x in df.columns if x != 'Churn']\ncategorical_columns = list(np.array(df.columns)[columns_idx][string_fields])\ncategorical_features = [x for x in categorical_columns if x != 'Churn']\ncontinuous_features = [x for x in all_features if x not in categorical_features]\n\n#print('All Features: ', all_features)\n#print('\\nCategorical Features: ', categorical_features)\n#print('\\nContinuous Features: ', continuous_features)\n#print('\\nAll Categorical Columns: ', categorical_columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.6 Visualize data\n\nData visualization can be used to find patterns, detect outliers, understand distribution and more. Following graphs can be used such as:\n\n- Histograms, boxplots, etc: To find distribution / spread of our continuous variables.\n- Bar charts: To show frequency in categorical values.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import LabelEncoder\n\n%matplotlib inline\nsns.set(style=\"darkgrid\")\nsns.set_palette(\"hls\", 3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To get a high level view of the distribution of `Churn`. What percentage of customer in our dataset are churning vs not churning. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.groupby(['Churn']).size())\nchurn_plot = sns.countplot(data=df, x='Churn', order=df.Churn.value_counts().index)\nplt.ylabel('Count')\nfor p in churn_plot.patches:\n    height = p.get_height()\n    churn_plot.text(p.get_x()+p.get_width()/2., height + 1,'{0:.0%}'.format(height/float(len(df))),ha=\"center\") \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Frequency counts charts can be used to get an understanding of the categorical features relative to `Churn`  \n\n- It can be observed that for the `gender` feature, We have relatively equal rates of churn by `gender`\n- It can be observed that for the `InternetService` feature, We have higher churn for those that have \"Fiber optic\" service versus those with \"DSL\"\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Categorical feature count plots\nf, ((ax1, ax2, ax3), (ax4, ax5, ax6), (ax7, ax8, ax9), (ax10, ax11, ax12), (ax13, ax14, ax15)) = plt.subplots(5, 3, figsize=(20, 20))\nax = [ax1, ax2, ax3, ax4, ax5, ax6, ax7, ax8, ax9, ax10, ax11, ax12, ax13, ax14, ax15 ]\n\nfor i in range(len(categorical_features)):\n    sns.countplot(x = categorical_features[i], hue=\"Churn\", data=df, ax=ax[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Histrogram charts can be used to get an understanding of the distribution of our continuous / numerical features relative to Churn.\n\n- It can be observed that for the `MonthlyCharges` feature, customers that churn tend to pay higher monthly fees than those that stay.\n- It can be observed that for the `tenure` feature, customers that churn tend to be relatively new customers.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Continuous feature histograms.\nfig, ax = plt.subplots(2, 2, figsize=(28, 8))\ndf[df.Churn == 'No'][continuous_features].hist(bins=20, color=\"blue\", alpha=0.5, ax=ax)\ndf[df.Churn == 'Yes'][continuous_features].hist(bins=20, color=\"orange\", alpha=0.5, ax=ax)\n\n# Or use displots\n#sns.set_palette(\"hls\", 3)\n#f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(25, 25))\n#ax = [ax1, ax2, ax3, ax4]\n#for i in range(len(continuous_features)):\n#    sns.distplot(df[continuous_features[i]], bins=20, hist=True, ax=ax[i])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Create Grid for pairwise relationships\ngr = sns.PairGrid(df, height=5, hue=\"Churn\")\ngr = gr.map_diag(plt.hist)\ngr = gr.map_offdiag(plt.scatter)\ngr = gr.add_legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot boxplots of numerical columns. More variation in the boxplot implies higher significance. \nf, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(25, 25))\nax = [ax1, ax2, ax3, ax4]\n\nfor i in range(len(continuous_features)):\n    sns.boxplot(x = 'Churn', y = continuous_features[i], data=df, ax=ax[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.0 Create a model\n\nNow machine learning model can be created. You could use the insights / intuition gained from the data visualization steps above to what kind of model to create or which features to use. For now, I am creating a simple classification model by removing some of the uninformative features such as gender, StreamingTV and StreamingMovies","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.1 Split the data into training and test sets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.model_selection import train_test_split\nX = df[['SeniorCitizen', 'Partner', 'Dependents', 'tenure',\n       'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity',\n       'OnlineBackup', 'DeviceProtection', 'TechSupport',\n       'Contract', 'PaperlessBilling', 'PaymentMethod',\n       'MonthlyCharges', 'TotalCharges']]\ny = df['Churn']\nX_train, X_test, y_train, y_test = train_test_split(\n                X, y, test_size=0.33, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"one_hot_encoded_training_predictors = pd.get_dummies(X_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(random_state=42)\nrfc.fit(one_hot_encoded_training_predictors, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = rfc.fit(one_hot_encoded_training_predictors, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = pd.get_dummies(X_test)\nmodel.score(test_data, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The simple random forest classifier gives an accuracy of 79%. The best metric for evaluating a binary classifier is ROC AUC(Area Under the curve)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\ny_scores = model.predict(test_data)\ny_scores = pd.get_dummies(y_scores)\ny_test = pd.get_dummies(y_test)\nroc_auc_score(y_test, y_scores)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}