{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#!/usr/bin/env python\n# coding: utf-8\n\n# Author: Daniele Berto\n# \n# SID: 1163243\n#\n# In questo lavoro, provo ad utilizzare la classe DecisionTreeClassifier su due set di dati abbastanza noti:\n# MNIST e il TITANIC dataset\n#\n# Con MNIST, l'albero di decisione che viene creato da sklearn con impostazioni di default, dà risultati interessanti.\n# Infatti, nel test set riesce ad avere una precisione superiore all'80% (a fronte del 10% che darebbe una selezione casuale).\n# \n# Tuttavia, penso che il MNIST dataset non sia un bel campo di applicazione per un dt.\n#\n# Un punto di forza di questo metodo è quello di creare una struttura intelleggibile. Non ha molto senso, secondo me,\n# utilizzare un dt valutando ad ogni nodo il \"grigiore\" dei pixel. Funziona in modo apprezzabile, certo, ma, probabilmente,\n# ci sono campi di applicazione migliori.\n#\n# Secondo me il TITANIC dataset è un campo migliore in cui usare un decision tree. Quello che ho creato si può sicuramente\n# migliorare molto.\n#\n# E' stato interessante perché mi sono dovuto subito confrontare con il concetto di bias: quali sono, infatti, gli attributi\n# rilevanti dei passeggeri per valutare se sono sopravvissuti o no?\n#\n# Alcuni attributi possono nascondere informazioni rilevanti, come la collacazione nella nave mediante il numero del\n# biglietto.\n#\n# La conoscenza settoriale e quella del Machine Learning si devono per forza incontrare per ottenere una buona soluzione\n#\n# Quella che propongo non è secondo me una buona soluzione: nel test set ha una precisione di solo il 75% circa.\n# Considerando che la maggior parte dei passeggeri sono morti, è probabile che la funzione costante \"predict(idPassenger)\n# = dead for each idPassenger\" abbia una precisione paragonabile.\n#\n# Tuttavia, sono convinto che, con un dt sul TITANIC dataset, si possa far molto meglio e sono convinto che un decision\n# tree possa essere un valido strumento per problemi come questo.\n#\n# Date: 2020/10/28\n\nimport numpy as np\nimport math\nimport random\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn import tree","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#loading MNIST dataset\nmnist_train = pd.read_csv(\"../input/mnist-in-csv/mnist_train.csv\")\nmnist_test = pd.read_csv(\"../input/mnist-in-csv/mnist_test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"array_train = mnist_train.values\ny_train = array_train[:,0]\nX_train = array_train[:,1:]\n\nclf = tree.DecisionTreeClassifier()\nclf = clf.fit(X_train, y_train)\n\narray_test = mnist_test.values\n\ny_test = array_test[:,0]\n\nX_test = array_test[:,1:]\n\nmnist_prediction = clf.predict(X_test)\n\nmismatching_count = 0\n\nfor i in range(len(y_test)):\n    if y_test[i] != mnist_prediction[i]:\n       mismatching_count+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matching = len(y_test) - mismatching_count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"precision = matching/len(y_test)\n\nprint(precision)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"titanic_train = pd.read_csv(\"../input/titanic-cleaned-data/train_clean.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"titanic_train.loc[titanic_train['Sex'] == 'male', 'Sex'] = 0\ntitanic_train.loc[titanic_train['Sex'] == 'female', 'Sex'] = 1\n\ntitanic_array = titanic_train.values\n\n#Splitting the array between training set and test set\n#I underline that, during the official competition, there was a specific test set\n#with the survived column left blank.\n\ntitanic_train_array = titanic_array[0:500,:]\ntitanic_test_array = titanic_array[500:,:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"titanic_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#I've decided to use these features:\n#Age (0), Fare(3), Parch(5), Pclass(7), Sex(8), SibSp(9) and family_size(13)\n\ntitanic_train_X = titanic_train_array[:,[0,3,5,7,8,9,13]]\ntitanic_train_X= titanic_train_X.astype('float')\ntitanic_train_y = titanic_train_array[:,[10]]\ntitanic_train_y= titanic_train_y.astype('float')\n\ntitanic_test_X = titanic_test_array[:,[0,3,5,7,8,9,13]]\ntitanic_test_X = titanic_test_X.astype('float')\ntitanic_test_y = titanic_test_array[:,[10]]\ntitanic_test_y = titanic_test_y.astype('float')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"titanic_test_y = titanic_test_y[:,0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"titanicf = tree.DecisionTreeClassifier()\ntitanicf = titanicf.fit(titanic_train_X, titanic_train_y)\n\ntitanic_prediction = titanicf.predict(titanic_test_X)\n\nmismatching_count = 0\n\n#mismatching_count\nfor i in range(len(titanic_test_y)):\n    if titanic_test_y[i] != titanic_prediction[i]:\n       mismatching_count+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matching = len(titanic_test_y) - mismatching_count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"precision = matching/len(titanic_test_y)\n\nprint(precision)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}