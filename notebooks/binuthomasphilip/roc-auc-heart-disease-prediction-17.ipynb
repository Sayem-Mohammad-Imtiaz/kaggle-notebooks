{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Recently I published a self help book titled Inspiration: Thoughts on Spirituality, Technology, Wealth, Leadership and Motivation. The preview of the book can be read from the Amazon link https://lnkd.in/gj7bMQA\n\n### You can refer to my other notebooks from https://www.kaggle.com/binuthomasphilip/code"},{"metadata":{},"cell_type":"markdown","source":"In this Kerne we will try to Predict who will have Heart Disease.But our main focus will be on how to compare two models using ROC and AUC Curves.In this notebook we will be covering following topic\n\n1.Data import and preprocessing\n\n2.Exploratory Data Analysis \n\n3.Feature Engineering\n\n4.Model Built\n\n5.Model Comparsion using ROC curve\n\n6.Conclusion"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1.Data Import And Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"### Importing Modules"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom dateutil import parser\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler \nfrom sklearn.svm import SVC \nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,classification_report,accuracy_score\nfrom sklearn.model_selection import GridSearchCV\nimport pickle\nfrom lightgbm import LGBMClassifier\nimport warnings\nplt.style.use('fivethirtyeight')\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Importing Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data=pd.read_csv('../input/heart-disease-uci/heart.csv')\ndata.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Terminology"},{"metadata":{},"cell_type":"markdown","source":"- age: The person's age in years\n- sex: The person's sex (1 = male, 0 = female)\n- cp: The chest pain experienced (Value 1: typical angina, Value 2: atypical angina, Value 3: non-anginal pain, Value 4: asymptomatic)\n- trestbps: The person's resting blood pressure (mm Hg on admission to the hospital)\n- chol: The person's cholesterol measurement in mg/dl\n- fbs: The person's fasting blood sugar (> 120 mg/dl, 1 = true; 0 = false)\n- restecg: Resting electrocardiographic measurement (0 = normal, 1 = having ST-T wave abnormality, 2 = showing probable or definite left ventricular hypertrophy by Estes' criteria)\n- thalach: The person's maximum heart rate achieved\n- exang: Exercise induced angina (1 = yes; 0 = no)\n- oldpeak: ST depression induced by exercise relative to rest ('ST' relates to positions on the ECG plot. See more here)\n- slope: the slope of the peak exercise ST segment (Value 1: upsloping, Value 2: flat, Value 3: downsloping)\n- ca: The number of major vessels (0-3)\n- thal: A blood disorder called thalassemia (3 = normal; 6 = fixed defect; 7 = reversable defect)\n- target: Heart disease (0 = no, 1 = yes)"},{"metadata":{},"cell_type":"markdown","source":"### Missing Values"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are very lucky here there are no Null Values in the dataset.But in this data the missing values are present in the form of value ZERO. Our next task would be to find out numbers of ZEROS in each column."},{"metadata":{},"cell_type":"markdown","source":"### Findout Zero Values in DataSet"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"cols = data.columns\nprint(\"# Rows in the dataset {0}\".format(len(data)))\nprint(\"---------------------------------------------------\")\nfor col in cols:\n    print(\"# Rows in {1} with ZERO value: {0}\".format(len(data.loc[data[col] ==0]),col))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The columns which have categorical values can have ZERO values.But columns like cp,trestbps,chol,fbs,exang,oldpean and Slope should not have value ZERO.The presence of ZERO in this columns indicate the presence of null values."},{"metadata":{},"cell_type":"markdown","source":"# 2.Exploraory Data Analysis "},{"metadata":{},"cell_type":"markdown","source":"### Heat Map "},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"\ncorrmat = data.corr()\nfig = plt.figure(figsize = (12,12))\nsns.heatmap(corrmat,vmax = 1,square = True,annot = True,vmin = -1)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that there is not much correlation between the features in the dataset.If corelation was high we can face issue of multicollinearity.In that case we would need to use feature engineering to avoid multi colinearity."},{"metadata":{},"cell_type":"markdown","source":"## 3.Feature Engineering "},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"final_cols = cols\nfinal_cols = list(final_cols)\nfinal_cols.remove('ca')\nfinal_cols.remove('cp')\nfinal_cols.remove('exang')\nfinal_cols.remove('fbs')\nfinal_cols.remove('restecg')\nfinal_cols.remove('sex')\nfinal_cols.remove('slope')\nfinal_cols.remove('target')\nfinal_cols.remove('thal')\nfinal_cols","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have dropped the columns with categorical columns.This is because when we do feature engineering we will be repacing the numerical column Zero values with the mean values.This is not needed for the columns with categorical variables."},{"metadata":{},"cell_type":"markdown","source":"### Creating Feature of Matrix"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"X = data.drop('target',axis=1) #predictor feature columns\ny = data.target\ny.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that the dataset is unbalanced.First we will balance the dataset.Balancing data set is a good approach to improve the accuracy of the machine learning model."},{"metadata":{},"cell_type":"markdown","source":"### Balancing Dataset"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nsm = SMOTE(random_state=42)\nX_res_OS , Y_res_OS = sm.fit_resample(X,y)\npd.Series(Y_res_OS).value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Converting Numpy Arrays into Dataframe"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"X_res_OS = pd.DataFrame(X_res_OS,columns=['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n       'exang', 'oldpeak', 'slope', 'ca', 'thal'])\nY_res_OS = pd.DataFrame(Y_res_OS,columns=['target'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Test Train Split"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"X_train,X_test,y_train,y_test = train_test_split(X_res_OS,Y_res_OS,test_size = 0.1,random_state=10)\nprint('Training Set :',len(X_train))\nprint('Test Set :',len(X_test))\nprint('Training labels :',len(y_train))\nprint('Test labels :',len(y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The number of rows of data is very low in the dataset.This may not be sufficient to build a good model.Let us see how our model works out."},{"metadata":{},"cell_type":"markdown","source":"### Replacing all the ZEROS with Mean of the Column"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from sklearn.impute import SimpleImputer \nfill = SimpleImputer(missing_values=np.nan, strategy='mean')\n\nX_train = fill.fit_transform(X_train[final_cols])\nX_test = fill.fit_transform(X_test[final_cols])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.Machine Learning Model Built"},{"metadata":{},"cell_type":"markdown","source":"### Importing Modules"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from sklearn.datasets import make_classification\nimport numpy as np\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(max_features=5, n_estimators=500)\nrf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Naive Bayes"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"nb = GaussianNB()\nnb.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predicting Probabilities"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"r_probs = [0 for _ in range(len(y_test))]\nrf_probs = rf.predict_proba(X_test)\nnb_probs = nb.predict_proba(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have kept Probabilities for the Positive Outcome."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"rf_probs = rf_probs[:, 1]\nnb_probs = nb_probs[:, 1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5.Model Comparsion with ROC Curve"},{"metadata":{},"cell_type":"markdown","source":"### What is ROC Curve?\n\nROC curve is a plot of False Positive Rate with the True Positive Rate \n\n$TPR(Sensitivity) = \\frac{TP}{TP + FN}$\n\n$FPR (1 - Specificity) = \\frac{FP}{TN + FP}$  "},{"metadata":{},"cell_type":"markdown","source":"### Computing AUROC and ROC curve values"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve, roc_auc_score\nr_auc = roc_auc_score(y_test, r_probs)\nrf_auc = roc_auc_score(y_test, rf_probs)\nnb_auc = roc_auc_score(y_test, nb_probs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Printing AUC Scores"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('Random (chance) Prediction: AUROC = %.3f' % (r_auc))\nprint('Random Forest: AUROC = %.3f' % (rf_auc))\nprint('Naive Bayes: AUROC = %.3f' % (nb_auc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Calculate ROC curve"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"r_fpr, r_tpr, _ = roc_curve(y_test, r_probs)\nrf_fpr, rf_tpr, _ = roc_curve(y_test, rf_probs)\nnb_fpr, nb_tpr, _ = roc_curve(y_test, nb_probs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plotting ROC Curve"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(r_fpr, r_tpr, linestyle='--', label='Random prediction (AUROC = %0.3f)' % r_auc)\nplt.plot(rf_fpr, rf_tpr, marker='.', label='Random Forest (AUROC = %0.3f)' % rf_auc)\nplt.plot(nb_fpr, nb_tpr, marker='.', label='Naive Bayes (AUROC = %0.3f)' % nb_auc)\n\n# Title\nplt.title('ROC Plot')\n# Axis labels\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\n# Show legend\nplt.legend() # \n# Show plot\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We ca see that the Random Forest Model Has Shightly Higher Value of AUC.So we can ay Random Fores Model Would perform better than the Naive Bayes Model for this particular Data Set."},{"metadata":{},"cell_type":"markdown","source":"# 6.Conclusion\n\n1.We have imported and preprocessed the data set.We have handled the missing values which were in the form of Zeros.\n\n2.We have dropped some of the features as they wont have much influence on our model prediction.\n\n3.As the dataset was unbalanced we balanced the dataset by doing oversampling.This helps to improve the model accuracy. mode 4.We have done the Heart Disease prediction using Random Forest and Naive Bayes algorithm.\n\n5.We plotted a ROC curve for our models and used the AUC value to arrive at he best model"},{"metadata":{},"cell_type":"markdown","source":"### You can refer to my other notebooks from https://www.kaggle.com/binuthomasphilip/code"},{"metadata":{},"cell_type":"markdown","source":"# TO BE CONTINUED "},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}