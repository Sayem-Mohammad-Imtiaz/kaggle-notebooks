{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Predicting Rain in Australia","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div id='back'></div>\n\nIn this notebook, I will be using the 'Rain in Australia' dataset to predict if it will rain in Australia tomorrow. Here is the link to the dataset: https://www.kaggle.com/jsphyg/weather-dataset-rattle-package\n\nThe outcome is binary (will it rain or not tomorrow in Australia), and I will train a Logistic Regression model on the dataset to predict the outcome. \n\nHere is a summary of my workflow:\n\n\n1.  [DATA PREPARATION](#DataPrep)  \n   **a)** [Preliminary work](#pw) on the dataset - extract columns into list of features, drop 'Risk_MM' and 'RainTomorrow from list, and binarise target column.  \n   **b)** [Selecting features](#sf) -  missing values, pairwise correlation, feature engineering (new features, one-hot encoding, cyclical features)    \n   \n2. [MODEL TRAINING](#mt)  \n   **c)** [Split dataset into train and test sets](#split)       \n   **d)** [Scale features](#scale)      \n   **e)** [Train Logistic Regression model](#train)     \n   **f)** [Evaluate](#eval)    ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#reading in csv file and changing dtype of 'Date' column to datetime\nweather = pd.read_csv('/kaggle/input/weather-dataset-rattle-package/weatherAUS.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **About the Rain in Australia dataset**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#dataset info\nweather.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#timespan of data\nprint(\"The weather data was collected over the time period {0} to {1}.\".format(weather.loc[0, 'Date'], weather.loc[142192, 'Date']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 142193 entries, and 24 variables. The columns of the *weather* dataset are:\n\n**Date** - The date of observation  \n**Location** - The common name of the location of the weather station  \n**MinTemp** - The minimum temperature in degrees celsius  \n**MaxTemp** - The maximum temperature in degrees celsius    \n**Rainfall** - The amount of rainfall recorded for the day in mm  \n**Evaporation** - The so-called Class A pan evaporation (mm) in the 24 hours to 9am (Class A pan evaporation is measured as the depth of water which evaporates from a pan of a certain size in 24 hours)  \n**Sunshine** - The number of hours of bright sunshine in the day  \n**WindGustDir** - The direction of the strongest wind gust in the 24 hours to midnight  \n**WindGustSpeed** - The speed (km/h) of the strongest wind gust in the 24 hours to midnight  \n**WindDir9am** - Direction of the wind at 9am  \n**WindDir3pm** - Direction of the wind at 3pm  \n**WindSpeed9am** - Wind speed (km/hr) averaged over 10 minutes prior to 9am  \n**WindSpeed3pm** - Wind speed (km/hr) averaged over 10 minutes prior to 3pm  \n**Humidity9am** - Humidity (percent) at 9am  \n**Humidity3pm** - Humidity (percent) at 3pm  \n**Pressure9am** - Atmospheric pressure (hpa) reduced to mean sea level at 9am  \n**Pressure3pm** - Atmospheric pressure (hpa) reduced to mean sea level at 3pm  \n**Cloud9am** - Fraction of sky obscured by cloud at 9am. This is measured in \"oktas\", which are a unit of eigths. It records how many eigths of the sky are obscured by cloud. A 0 measure indicates completely clear sky whilst an 8 indicates that it is completely overcast    \n**Cloud3pm** - Fraction of sky obscured by cloud (in \"oktas\": eighths) at 3pm. See Cload9am for a description of the values  \n**Temp9am** - Temperature (degrees C) at 9am  \n**Temp3pm** - Temperature (degrees C) at 3pm  \n**RainToday** -  Yes if precipitation (mm) in the 24 hours to 9am exceeds 1mm, otherwise No  \n**RISK_MM** - The amount of next day rain in mm. Used to create response variable RainTomorrow. A kind of measure of the \"risk\"  \n**RainTomorrow** - The target variable. Did it rain tomorrow, Yes or No?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#number of missing values in each variable\nweather.isnull().sum().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Theare is a sizeable amount of missing values to handle. The variables 'Sunshine' and 'Evaporation' have roughly half of their values missing. The target variable, 'Rain Tomorrow',  has no missing values.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<div id=\"DataPrep\"></div><font size = 5>**1. Data Preparation **</font>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### a)<div id ='pw'>Preliminary work</div>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"First, we will extract all the columns of the dataset into a list. As we go and prepare the data and pick the features,we will drop the columns we do not need. In this way, if we need to change features or check something, we can easily go back to the orginal dataset. We can index into the dataset with the final list of columns when we are ready to train and test the model.\n\nWe will drop rows in place in the original dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#list of columns\nfeatures = weather.columns.tolist()\n#check\nfeatures","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, we will drop 'RainTomorrow' from our list of features as this is our target variable.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop target variable from list of features\nfeatures.remove('RainTomorrow')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Drop the column 'RISK_MM' from the weather dataset as it leaks information about the future. Please see [here](http://www.kaggle.com/jsphyg/weather-dataset-rattle-package/discussion/78316) for an explanation.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop RISK_MM from list of features\nfeatures.remove('RISK_MM')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" Binarise the column 'Rain Today' and the target column, 'Rain Tomorrow'.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#how many missing values in 'RainToday'\nprint('There are {} missing values in \"Rain Today\", and they make up {:.2f}% of the number of entries.'\n      .format(weather['RainToday'].isnull().sum(),(weather['RainToday'].isnull().sum())/(weather.shape[0])*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will drop the rows with missing values in 'RainToday' as they make up just about 1% of the total number of entries, and I cannot think of a way to impute for the missing values of this particular variable.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop rows with missing values in 'RainToday'\nweather = weather[weather['RainToday'].notnull()]\n#check\nweather['RainToday'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#any missing values in the target variable?\nweather['RainTomorrow'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#for checking purposes\nRToday_values_before = weather['RainToday'].value_counts()\nRTomorrow_values_before = weather['RainTomorrow'].value_counts()\nprint('Value count in \"Rain Today\":\\n {}'.format(RToday_values_before))\nprint('Value count in \"Rain Tomorrow\":\\n {}'.format(RTomorrow_values_before))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#binarise 'RainToday' and 'RainTomorrow'\nweather['RainToday'] = (weather['RainToday'] == 'Yes')*1\nweather['RainTomorrow'] = (weather['RainTomorrow'] == 'Yes')*1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check\nprint('Value count in \"Rain Today\":\\n {}'.format(weather['RainToday'].value_counts()))\nprint('\\nValue count in \"Rain Tomorrow\":\\n {}'.format(weather['RainTomorrow'].value_counts()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have now binarised the 'RainToday' and the target variable 'RainTomorrow' so that 1 indicates rain and 0 indicates no rain.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"[Back to contents](#back)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### b)<div id='sf'></div>** Feature Selection**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let's see how many entries we are left with if we drop all the missing values in this dataset. \n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"before_rows = weather.shape[0]\ncopy_data = weather.copy()\nmod_data = copy_data.dropna()\nafter_rows = mod_data.shape[0]\nprint('{} rows are dropped.'.format(before_rows - after_rows))\nprint('\\nDropping rows with at least one missing value will reduce our dataset by {:.2f} %.'.format((before_rows - after_rows)/before_rows*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Instead of dropping all the rows with a missing value (and risk losing valuable information), we will examine each of the columns individually, and their relationship to each other. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"weather[features].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Are any of the features with contiunous data type strongly correlated (linearly) with one another?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,10))\ncont_features = ['MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation','Sunshine',\n                 'WindGustSpeed','WindSpeed9am','WindSpeed3pm', 'Humidity9am',\n                'Humidity3pm', 'Pressure9am', 'Pressure3pm','Cloud9am', 'Cloud3pm',\n                'Temp9am','Temp3pm']\ncorr_weather = weather[cont_features].corr()\nmask = np.triu(np.ones_like(corr_weather, dtype=bool))\nsns.heatmap(corr_weather, mask=mask,annot=True, cmap='YlOrRd')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the correlation matrix, we can see that there is very strong correlation (corr $\\geq$ 80) between:\n* 'Temp3pm' and 'MaxTemp' (corr = 0.98) (near perfect correlation)\n* 'Pressure9am' and 'Pressure3pm' (corr = 0.96) (near perfect correlation)\n* 'Temp9am' and 'MinTemp' (corr = 0.9)\n* 'Temp9am' and 'MaxTemp' (corr = 0.89)\n* 'Temp9am and 'Temp3pm' (corr = 0.86)\n\nThere is moderate to strong correlation (0.65 $\\leq$ corr $<$ 0.8) between:\n* 'MaxTemp' and 'MinTemp' (corr = 0.74)\n* 'WindSpeed3pm' and 'WindGustSpeed' (corr = 0.69)\n* 'Cloud9am' and 'Sunshine' (corr = -0.68)\n* 'Cloud3pm' and 'Sunshine' (corr = -0.7)\n* 'Humidity9am' and 'Humidity3pm' (corr =  0.67)\n\nIn order to avoid problesm in the model from high collinearity between variables, we will drop the feature in the above pairs which has the weakest relationship with the target variable. SInce 'RainTomorrow' is binary, we will create scatter plots to see what kind of relationship, if any, exists.\n\nIn the examining the following scatterplots, it is important to keep in mind that 'RainTomorrow' indicates no rain 3.5 times more than it indicates rain.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#'RainTomorrow' value counts\nweather['RainTomorrow'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First, we will consider the temperature variables.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#pairwise scatter plots of temperature variables\nplt.figure(figsize=(15,15))\nsns.pairplot(weather[['MinTemp','MaxTemp','Temp9am','Temp3pm','RainTomorrow']], hue = 'RainTomorrow' )\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We know from the correlation matrix that there are strong positive relationships between the temperature variables. \n\nThere is not much of a difference in the shape and position of the 'RainTomorrow' distributions for 'MinTemp' and 'Temp9am'. For 'MaxTemp' and 'Temp3pm',  'RainTomorrow' is 'Yes' more often at lower temperatures, and 'Temp3pm' shows a greater difference between the 'Yes' and 'No' distributions of 'RainTomorrow' than 'MaxTemp'. \n\nBased on this, we will drop 'Temp9am', 'MaxTemp', and 'MinTemp' from our list of features for the model, and keep 'Temp3pm'.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"'Sunshine', 'Cloud9am', 'Cloud3pm', and 'Evaporation' are grouped together next as it is obvious from a practical point of view that they may have a relationship. In a basic sense, we know that if it is very cloudy, there will be little sunshine. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#pairwise scatter plots of 'Sunshine','Cloud9am,'Cloud3pm', and 'Evaporation'\nplt.figure(figsize=(15,15))\nsns.pairplot(weather[['Sunshine','Evaporation','Cloud9am','Cloud3pm','RainTomorrow']], hue = 'RainTomorrow' )\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The correlation matrix indicated a moderately strong negative relationship between 'Sunshine' and both 'Cloud9am' and'Cloud3pm'. The pairwise plots do not seem to indicate that relationship. \n\nOn the first diagonal plot, we can see that the distribution of 'Yes' values for 'RainTomorrow' skews left (lower values for 'Sunshine') and the distribution of 'No' values for 'RainTomorrow' skews right (higher values for 'Sunshine'. From this, the number of hours of 'Sunshine' is a good determinant of 'RainTomorrow'.\n\nOn the second diagonal plot, there in't much of a difference between the distributions of the binary values of 'RainTomorrow' on 'Evaporation'.\n\nOn the third and fourth diagonal plts, the distribution of 'Yes' values for 'RainTomorrow' skews right and the distribution of 'No' values for 'RainTomorrow' skews left. This indicates that 'Cloud9am' and 'Cloud3pm' are  good determinants of 'RainTomorrow'.\n\nBased on these observations, we will drop 'Evaporation', and deal with 'Sunshine', Cloud9am', and 'Cloud3pm' later.\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#pairwise scatter plots of wind variables\nplt.figure(figsize=(15,15))\nsns.pairplot(weather[['WindGustSpeed','WindSpeed9am','WindSpeed3pm','RainTomorrow']], hue = 'RainTomorrow' )\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We know from the correlation matrix that 'WindGustSpeed'has a strong positive correlation with 'WindSpeed3pm' and a moderate positive relationshipe with 'Windspeed9am'. This is reflected in the scatter plots.\n\nThe plots on the diagonal show that the distribution of the 'Yes' and 'No' values of 'RainTomorrow' are similar for 'WindSpeed9am' and 'WindSpeed3pm'. For, 'WindGustSpeed', the 'No' values skew to the left and the 'Yes' values to the right which indicates that a higher wind gust speed may indicate rain the next day. \n\nBased on these observations, we will drop 'WindSpeed9am' and 'WindSpeed3pm' from our model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#pairwise scatter plots of rainfall, pressure and humidity variables\nplt.figure(figsize=(15,15))\nsns.pairplot(weather[['Rainfall','Humidity9am','Humidity3pm','Pressure9am', 'Pressure3pm','RainTomorrow']], hue = 'RainTomorrow' )\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The near perfect positive linear relationship between 'Pressure9am' and 'Pressure3pm' is reflected in this scatter point. There is no obvious difference in the distributions in the 'Yes' and 'No' values of 'RainTomorrow' with regards to both the pressure variables. \n\nThe 'Yes' values of 'RainTomorrow' skew to the left of the 'No' values for both 'Humidity9am' and 'Humidity3pm', and to a greater degree for 'Humidity3pm'.\n\n\nBased on these observations, we will drop 'Humidity9am' and 'Pressure9am' from the model.\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"'RainToday' is described  as 'Yes' if precipitation (mm) in the 24 hours to 9am exceeds 1mm, otherwise No. 'Rainfall' is described as the amount of rainfall recorded for the day in mm. Given the description, I assume that 'RainToday' indicates whether there was any rain in the 24hr period before 9am today (so would cover the previous day as well), and 'Rainfall' indicates how much rain fell today before and after 9am. Is there any relationship between the two?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#scatter plot of'RainToday' and 'Rainfall'\nplt.figure(figsize=(10,5))\nsns.scatterplot(weather['Rainfall'],weather['RainToday'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The scatter plot indicates strongly that if there was any precipitation greater than 1mm in the 24 hours up to 9am today, then there will be rainfall today. We will therefore drop 'RainToday' from our model.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"So far, we have decided to drop 'MinTemp', 'MaxTemp', 'Temp9am', 'Evaporation', 'RainToday','WindSpeed9am' 'WindSpeed3pm', 'Humidity9am' and 'Pressure9am' from our model. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#dropping listed features\nto_drop = ['MinTemp', 'MaxTemp', 'Temp9am', 'Evaporation', 'RainToday','WindSpeed9am',\n           'WindSpeed3pm','Humidity9am','Pressure9am']\nfor col in to_drop:\n    features.remove(col)\n#check\nfeatures","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We noted above that we will deal with 'Sunshine', 'Cloud9am', 'Cloud3pm'. These feature have nearly half their values missing. It would be easier to drop these features from our model. However, is it possible to capture their information in another way? Would grouping the weather data by seasons utilising the 'Date' column be useful?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\nweather['Year'] = pd.DatetimeIndex(weather['Date']).year\nweather['Season'] = pd.DatetimeIndex(weather['Date']).month\nweather['Season'].replace({1: 'Summer', 2:'Summer', 3:'Spring', 4:'Spring', 5:'Spring', 6:'Winter',\n                          7:'Winter', 8:'Winter', 9:'Autumn', 10:'Autumn', 11:'Autumn', 12:'Summer'}, inplace=True)\n#check\nweather['Season'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#graphs\nweather.pivot_table('Cloud3pm', index='Season', columns='Year', aggfunc='mean').plot(figsize=(10,7), title = 'Cloud3pm')\nweather.pivot_table('Cloud9am', index='Season', columns='Year', aggfunc='mean').plot(figsize=(10,7), title = 'Cloud9am')\nweather.pivot_table('Sunshine', index='Season', columns='Year', aggfunc='mean').plot(figsize=(10,7), title = 'Season')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"'Sunshine' shows a strong seasonal pattern, and 'Cloud3pm' and 'Cloud9am'  do not.  We also know that 'Sunshine' has strong correlations with the cloud variables. We will therefore drop the cloud variables. We can also drop 'Sunshine' as the newly created 'Season' variable will capture some of the information of the 'Sunshine' variable and we no longer have to worry about the chunk of missing values in 'Sunshine'. We will also drop 'Date' and 'Location' as we have no need for those variables. We will add 'Season'.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#dropping listed features\nto_drop2 = ['Sunshine','Cloud9am','Cloud3pm', 'Date','Location']\nfor col in to_drop2:\n    features.remove(col)\nfeatures.append('Season')\n#check\nfeatures","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's check the missing values in the features we have not dropped so far.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"weather[features].isnull().sum().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"How many entries will we lose if we drop the rows with missing data?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"copy_weather = weather[features].copy()\nbefore = copy_weather.shape[0]\ncopy_weather = copy_weather.dropna()\nafter = copy_weather.shape[0]\nprint('The number of rows dropped will be {} which is {:.2f} % of the remaining dataset.'.format(before - after, ((before-after)/before)*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is a considerable portion of the dataset. An exploration of the dataset shows that the missing values for each feature tends to come in orderly chuncks, that is to say, they are missing for consecutive days at a time. This indicates that certain variables were not recorded for particular locations at different periods of time. As a result, we cannot take any kind of average from data points on either side of the missing values without compromising the information in the dataset in a significant way.\n\nTherefore, we will drop the rows with the remaining missing values in the features we have selected so far.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"weather = weather.dropna(how='any', subset=features)\nweather[features].info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weather[features].info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have three categorical features relating to wind - 'WindDir9am','WindDir3pm','WindGustDir' - plus a categorical feature which we created called 'Season'. As the Logistic Regression model cannot handle categorical values, we will have to transform them into numerical feat We will one-hot encode 'Season' which means that we will have 4 features - one for each season - which takes 1 if the entry is that season and 0 otherwise. Once that is done, we will add the dummy features to our list of features and remove 'Season' from it.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#create dummy variables for 'Season'\ndummies_season = pd.get_dummies(weather['Season'], prefix = 'Season')\nweather = pd.concat([weather, dummies_season], axis=1)\nfeatures.extend(dummies_season.columns.tolist())\nfeatures.remove('Season')\n#check\nweather[features].info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have the wind direction variables left to deal with.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#unique values in 'WindGustDir', 'WindDir9am', WindDir3pm'\nwindgust_unique = weather['WindGustDir'].unique().tolist()\nwinddir9am_unique = weather['WindDir9am'].unique().tolist()\nwinddir3pm_unique = weather['WindDir3pm'].unique().tolist()\nprint('{} unique values in \"WindGustDir\": {}'.format(len(windgust_unique), windgust_unique))\nprint('{} unique values in \"WindDir9am\": {}'.format(len(winddir9am_unique), winddir9am_unique))\nprint('{} unique values in \"WindDir3pm\": {}'.format(len(winddir3pm_unique), winddir3pm_unique))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 16 unique values for each of the wind direction features.  \n\nIf we one-hot encode the wind direction variables, we will end up with 48 dummy features. Instead, we will note that wind direction can be represented in degrees (of a circle). After we convert the wind direction to degrees, we will then use a technique to engineer cyclical variables which will represent their cyclical nature properly. Please see this [link](http://http://blog.davidkaleko.com/feature-engineering-cyclical-features.html) which explains the method for transforming cyclical variables. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#mapping wind direction labels to degrees \ndict_dir = {'N': 0, 'NNE': 22.5, 'NE': 45, 'ENE': 67.5, 'E': 90, 'ESE': 112.5, 'SE': 135, 'SSE': 157.5, 'S': 180, 'SSW': 202.5, 'SW': 225, 'WSW': 247.5, 'W': 270, 'WNW': 292.5, 'NW': 315, 'NNW': 337.5}\nfor col in ['WindDir9am', 'WindDir3pm', 'WindGustDir']:\n    weather[col].replace(dict_dir, inplace=True)\n#check\nweather[['WindDir9am', 'WindDir3pm','WindGustDir']].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weather[['WindDir9am', 'WindDir3pm','WindGustDir']].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#converting wind direction in degrees to values on unit circle, adding to list of features, removing original feature\nfor col in ['WindDir9am', 'WindDir3pm', 'WindGustDir']:\n    weather[col + '_sin'] = np.sin(weather[col]*(2*np.pi/360))\n    weather[col + '_cos'] = np.cos(weather[col]*(2*np.pi/360))\n    features.append(col + '_sin')\n    features.append(col + '_cos')\n    features.remove(col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking\nfig, ax = plt.subplots(1,3,figsize = (20,5))\ni = 0\nfor col in ['WindDir9am', 'WindDir3pm', 'WindGustDir']:\n    ax[i].scatter(weather[col + '_sin'], weather[col + '_cos'])\n    ax[i].set_title(col)\n    i+=1\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can now see if there is any linear relationship between the engineered wind variables such that we can drop one or two of them.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"wind_sin_corr = weather[['WindDir9am_sin', 'WindDir3pm_sin','WindGustDir_sin']].corr()\nsns.heatmap(wind_sin_corr, annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wind_sin_corr = weather[['WindDir9am_cos', 'WindDir3pm_cos','WindGustDir_cos']].corr()\nsns.heatmap(wind_sin_corr, annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above correlation matrices show that 'WindDir3pm' and 'WindGustDir' are strongly correlated. We will drop 'WindGustDir'.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"features.remove('WindGustDir_sin')\nfeatures.remove('WindGustDir_cos')\nfeatures","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('The selected features for the Logistic Regression model are: \\n {}'.format(features))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[Back to contents](#back)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# <div id='mt'></div> Model training","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**<div id='split'></div>Split the data set into training and testing datasets**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_X, test_X, train_y, test_y = train_test_split(weather[features], weather['RainTomorrow'], test_size = 0.2, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**<div id='scale'></div>Scale features**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"columns_to_scale = ['Rainfall', 'WindGustSpeed','Humidity3pm','Pressure3pm','Temp3pm']\ntrain_X[columns_to_scale].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The features above have different ranges. We will scale them so that they are in the range [0,1]. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import minmax_scale\n\nfor col in columns_to_scale:\n    train_X[col + \"_scaled\"] = minmax_scale(train_X[col])\n    test_X[col + \"_scaled\"] = minmax_scale(test_X[col])\n    weather[col + \"_scaled\"] = minmax_scale(weather[col])\n    features.append(col + '_scaled')\n    features.remove(col)\nfeatures","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_X.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**<div id= 'train'></div>Train the model and predict**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We will use sklearn's Logistic Regression Classifier to train and predict the model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\n\nlr = LogisticRegression(max_iter=1000)\nlr.fit(train_X, train_y)\npredictions = lr.predict(test_X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**<div id='eval'></div>Evaluate**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport scikitplot as skplt\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\nplt.hist(weather['RainTomorrow'])\nplt.title('Histogram of RainTomorrow')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The histogram above shows that the **RainTomorrow** data is highly skewed. There are nearly 4 times more occurences of no rain than rain. Therefore, to evaluate our data, we will need to calculate precision and recall, as the  accuracy score will not give a good picture of the model's performance.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The function below will calculate accuracy score, null accuracy, precision, recall, specificity, and the F_score of the model using a confusion matrix.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#evaluation function\ndef evaluation(test_y, predictions):\n    \n    #accuracy score\n    accuracy = accuracy_score(test_y, predictions)\n    print(\"The classification accuracy is {:.2f} %.\" .format(accuracy*100))\n    \n  \n    y_test_mean = test_y.mean()\n    #null accuracy\n    null_accuracy = max(y_test_mean, 1-y_test_mean)\n    print('The null accuracy is {:.2f} %.'.format(null_accuracy*100))\n    \n    #confusion matrix\n    skplt.metrics.plot_confusion_matrix(test_y, predictions)\n    \n    conf_matrix = confusion_matrix(test_y, predictions)\n    \n    TN = conf_matrix[0,0] #true negatives\n    FP = conf_matrix[0,1] #false positives\n    FN = conf_matrix[1,0] #false negatives\n    TP = conf_matrix[1,1] #true positives\n    \n    #precision\n    precision = TP/(TP+FP)*100\n    print('The precision is {:.2f} %.'.format(precision))\n    #sensitivity/ recall\n    recall = TP/(FN+TP)*100\n    print('The sensitivity/recall is {:.2f} %.'.format(recall))\n    #specificity\n    specificity = TN/(FP+TN)*100\n    print('The specificity is {:.2f} %.'.format(specificity))\n    #F_score\n    F_score = (2*precision*recall)/(precision + recall)\n    print('The F score is {:.2f} %.'.format(F_score))\n    \n    return None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluation(test_y, predictions)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Evaluation scores:\n\n* The model predicts the correct label 84.58% of the time. This is not much higher than the null accuracy score of 77.91% which is the score a model will get if it predicted the dominant class all the time.\n* Both precision and recall are not high. Of all the true instances of rain, the model correctly predicts rain only 53.01% of the time. This is not good for a rain prediction model as that is its entire purpose. To increase recall, we can lower the prediction threshold from 0.5 (the default in the sklearn model). This will however lead to lower precision.\n\nIs the model suffering from high bias or high variance?\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Diagnostics","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#splitting data into train, validation, and test set in proportions of 60%, 20%, and 20% respectively\nX_set, X_test, y_set, y_test = train_test_split(weather[features], weather['RainTomorrow'], test_size = 0.2, random_state = 0)\nX_train, X_cv, y_train, y_cv = train_test_split(X_set, y_set, test_size = 0.25, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.preprocessing import normalize","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create polynomial variables of specified degree and scale them\n\ndef PolyAndScale(X, degree):\n    \n    #initialise polynomial transformer \n    poly = PolynomialFeatures(degree = degree, include_bias = True)\n    #fit and return polynomial features\n    X_poly = poly.fit_transform(X)\n    #normalise X_poly\n    X_poly = normalize(X_poly, axis=0)\n    \n    return X_poly\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlr_poly = LogisticRegression(max_iter=2000, fit_intercept=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def PredictAndError(X, y):\n    \n    #predict and  calculate error\n    prediction = lr_poly.predict(X)\n    #misclassification error\n    error = 1 - accuracy_score(y_true = y, y_pred = prediction)\n    \n    return error\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def LearningCurvesPoly(X_train, X_cv, y_train, y_cv):\n\n    poly_degrees = [1,2,3,4,5]\n\n    train_costs = []\n    cv_costs = []\n\n    for p in poly_degrees:\n        X_tr = PolyAndScale(X_train, degree=p)\n        lr_poly.fit(X_tr, y_train)\n        train_error = PredictAndError(X_tr, y_train)\n        train_costs.append(train_error)\n        X_crossval = PolyAndScale(X_cv, degree=p)\n        cv_error = PredictAndError(X_crossval, y_cv)\n        cv_costs.append(cv_error)\n        \n    \n    #plot learning curves\n    plt.figure(figsize=(10,10))\n    plt.plot(train_costs, label = 'Train')\n    plt.plot(cv_costs, label = 'CV')\n    plt.legend(loc=\"upper right\")\n    plt.xlabel('Polynomial degree')\n    plt.xticks(ticks = [0,1,2,3,4], labels = [1,2,3,4,5])\n    plt.ylabel('Misclassification Error')\n    plt.title('Learning Curves')\n    plt.show()\n    \n    return None\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will plot the errors of both the training and cross-validation set for polynomial degrees from 1 to 5 to see if the model is suffering from either high bias or high variance.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"LearningCurvesPoly(X_train, X_cv, y_train, y_cv)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Both the training error and the cross-validation error decrease with increasing degrees of the polynomial function. As the model increases in complexity, the misclassification errors of both sets fall. The model is underfitting and will benefit from additional features and/or polynomial features. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"[Back to contents](#back)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"In conclusion, this has been an interesting dataset to practice on, especially with regards to feature selection and missing values, which is what I spent the bulk of my time on. If anyone happens to see this notebook, I would really appreciate any criticism or suggestions to learn from.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}