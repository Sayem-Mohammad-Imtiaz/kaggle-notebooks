{"cells":[{"metadata":{},"cell_type":"markdown","source":"# MALL SEGMENTATION","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"In this kernel, I used k-Means clustering to find structure in data on mall customers based on their age, annual income, and spending score.\n\nInstead of using sklearn's built in methods. I have implemented the k-Means algorithm to understand  how this simple algorithm works. \n\nI have also defined functions for the Average Silhouette method. \n\nUsing Plotly, I visualised the data and clusters in 3D interactive plots.\n\nThis is a great dataset to begin understanding unsupervised learning.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<div id='back'></div>\n**Contents**\n\n1. [Data Exploration and Preparation](#prep) - visualise data in interactive 3D plots, examine descriptive statistics, and scale data\n2. [Running K-Means](#train) - define functions for [k-Means algorithm](#kmeans), define functions for calculating the [average silhouette score](#avg), find optimal number of clusters using average silhouette method, and run kMeans algorithm \n3. [Evaluation](#eval) - visualise clusters and evaluate result\n","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#load dataset\ncustomers = pd.read_csv('/kaggle/input/customer-segmentation-tutorial-in-python/Mall_Customers.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div id='prep'></div>**Data Exploration and Preparation**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#first few entries of dataset\ncustomers.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dataset info\ncustomers.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 200 training examples, and 5 features. There are no missing values.\n\nFeatures:\n1. Customer ID - Nominal data used to identify customers. This feature is unnecessary for our model as it has no information beyond identifying a customer.\n2. Gender - Dichotomous categorical variable to label gender of customer. Will map Male/Female labels to 0/1.\n3. Age - Ratio scale denoting age of customer.\n4. Annual Income (in 000's dollars) - Ratio scale denoting average income of customer.\n5. Spending Score (1-100) - Score assigned by the mall based on customer behavior and spending nature. The highe the score, the more the customer is likely to purchase something, or spend highly.\n\nWe will first explore the data to see if we can spot patterns/relationships.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"What is the distribution of the Gender feature?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\nplt.hist(customers['Gender'])\nplt.title('Distribution of Gender')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are more female than male customers in the data set.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Are there any patterns in male/ female spending such that Gender will be an important factor in clustering? For example, are males or females of a particular age group and income group likely to spend/purchase more? Will we see a cluster of males in the 40-60 age group and with income between 80,000  - 100,000 dollars show  the same high spending behavioiur? Or perhaps women under 21 or over 60 and with income over 80,000 dollars share the same high spending behaviour?\n\nWe will plot a 3D scatter plot with Age, Annual Income, and Spending Score measured on the x, y, and z axis, respectively? Gender will be the fourth feature denoted by colour.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.io as pio\npio.renderers.default='notebook'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\n\nfig = px.scatter_3d(customers, x='Age', y='Annual Income (k$)', z='Spending Score (1-100)',\n              color='Gender')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Keeping in mind that females outnumber males in this dataset, there does not seem to be a striking pattern of behaviour in which gender is a feature. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We will map Male/Female in Gender to 0/1 (0 indicating Male, 1 indicating Female).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#check unique values in Gender\nprint(customers['Gender'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#replace  Male/Female with 0/1\ncustomers['Gender'].replace({'Male':0, 'Female':1}, inplace=True)\n#check\nprint(customers['Gender'].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nLets's look at the distributions of Age, Annual Income, and  Spending Score (1-100).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#descriptive statistics\ncustomers[['Age', 'Annual Income (k$)', 'Spending Score (1-100)']].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Things to note:\n* All three of the features have very similar values for each of their mean and median. This suggests that their respective distributions are fairly symmetrical.\n* According to the [US Bureau of Labour Statistics](https://www.thestreet.com/personal-finance/average-income-in-us-14852178), the median annual income for full-time workers is 48,672 dollars. The median annual income in our dataset  61,500 dollars. Since the mean and median annual income of our dataset is very similar, the sample distribution of this dataset does not represent very well the population distribution (population here literally meaning the country's population). If this dataset is a sample of frequent mall customers, then it may very well be a representative sample.\n* The [median age](https://www.statista.com/statistics/241494/median-age-of-the-us-population/) of the US population as of 2018 was 38.2. The median age of this dataset is 36, so the dataset population, in terms of age, is a good representation of the general population.\n* The features have different ranges, so they will need to be scaled before training the model.\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Are any of the continuous variables linearly correlated with each other?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#linear correlation coefficients between Age, Annual Income, and Spending Score\ncorr_customers = customers[['Age', 'Annual Income (k$)', 'Spending Score (1-100)']].corr()\nmask = np.triu(np.ones_like(corr_customers, dtype=bool))\nsns.heatmap(corr_customers, mask=mask,annot=True, cmap='BuPu')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The features Age, Annual Income, and Spending Score are not strongly correlated with each other. The strongest correlation between these features is between Age and Spendng Score which has a negative correlation coefficient of -0.33.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We will be clustering the data using a k-means algorithm that calculates clusters using Euclidean distance. This type of algorithm only works with continuous variables,, we will use Age, Annual Income, and Spending Score to cluster the data. The binary feature, Gender, can safely be left out, as we saw above that there are no distinct behaviour in which Gender is a prominent factor.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**3D scatter plot of Customers**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.io as pio\npio.renderers.default='notebook'\n\nimport plotly.graph_objs as go\n\ndata = go.Scatter3d(x = customers['Age'], y = customers['Annual Income (k$)'], z = customers['Spending Score (1-100)'], \n                    mode ='markers', marker = dict(size = 4, color = 'crimson',  line=dict(width=2, color='DarkSlateGrey')))\n\nlayout =  dict(title = 'Customers',\n              scene = dict(xaxis= dict(title= 'Age',ticklen= 5,zeroline= False),\n              yaxis= dict(title= 'Annual Income',ticklen= 5,zeroline= False),\n              zaxis= dict(title= 'Spending Score',ticklen= 5,zeroline= False))\n             )\n\nfig = go.Figure(dict(data = data, layout = layout))\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Points to note from 3D plot:\n\n* People who earn roughly the median income are much more likely to have a spending score around 50, and much less llikely yo have a high or low spending score, when compared to low income and high income earners.\n\n* Median earners across the age group spend in moderation.\n\n* Of the low income earners, people under 30 are more likely to have a high spending score.\n\n* High income earners tend to either have a very high spending score or a low spending score. Moderation in spending is not a feature in their behaviour.\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Scale data to be between 0 and 1.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#scaling the features\nfrom sklearn.preprocessing import minmax_scale\n\nfor col in ['Age', 'Annual Income (k$)', 'Spending Score (1-100)']:\n    customers[col + '_scaled'] = minmax_scale(customers[col])\n    \n#check\ncustomers.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[back to Contents](#back)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<div id='train'></div>**K-Means Clustering**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<div id = 'kmeans'></div>\nThe k-means clustering algorithm:\n\n**1.** Initialise cluster centroids (randomly pick training examples to be initial cluster centers)  \n**2.** Iterate over a) and b) for specified number of iterations or until some precision is reached:   \n         a)Assign each point to nearest centroid as measured by Euclidean distance  \n         b) Assign new cluster centroids which are the average points of each of the clusters","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We will first define some functions.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def findClosestCentroids(X, centroids):\n    \n    '''\n    Calculates the closest centroid in centroids for each training example in X.\n    Returns vector of centroid assignments for each training example.\n    '''\n    \n    #set K\n    K = centroids.shape[0]\n    \n    #vector of cluster assignments\n    idx = np.zeros(X.shape[0])\n    \n    dist = np.zeros(K)\n    for i in range(X.shape[0]):\n        for k in range(K):\n            dist[k] = np.sum((X[i,:] - centroids[k,:])**2)**0.5\n        idx[i] = np.argmin(dist)\n        \n    return idx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def computeCentroids(X, idx, K):\n    \n    '''\n    Calculates new centroids by computing the mean of the \n    data points assigned to each centroid. Returns matrix\n    where each row is a new centroid's point.\n    '''\n    \n    #no. of data points\n    m = X.shape[0]\n    #dimension of points\n    n = X.shape[1]\n    \n    centroids = np.zeros((K,n))\n    \n    for k in range(K):\n        count = 0\n        s = np.zeros((1,n))\n        for i in range(m):\n            if idx[i] == k:\n                s = s + X[i,:]\n                count += 1\n        centroids[k,:] = s/count\n        \n    return centroids","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def RandInitialCentroids(X, K):\n    \n    '''\n    Initializes K centroids by randomly selecting K points in X.\n    '''\n    \n    centroids = np.zeros((K, X.shape[1]))\n    \n    #Randomly reorder the indicies of examples\n    randidx = np.random.permutation(range(X.shape[0]))\n    #Take the first K examples\n    centroids = X[randidx[0:K],:]\n    \n    return centroids","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Distortion is the average distance between all training examples and the centroid of the cluster to which it has been assigned. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def kMeansDistortion(X, idx, centroids):\n    \n    '''\n    Calculates the average distance between the examples and the \n    centroid of the cluster to which each example has been assigned.\n    '''\n    \n    #no. of data points\n    m = X.shape[0]\n    \n    distortion = 0\n    \n    for i in range(X.shape[0]):\n        closest = int(idx[i])\n        distance = np.sum((X[i,:] - centroids[closest])**2)\n        distortion = distortion + distance\n        \n    distortion = distortion/m\n    \n    return distortion","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The k-Means algorithm function:**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def kMeans(X, K, max_iters):\n           \n    '''\n    Run the kmeans algorithm for specified number of iterations \n    and returns final centroids, index of closest centroids for \n    each example (idx), final distortion, and distortion history.\n    '''\n    distortion_history = []\n    distortion = 0\n    centroids = RandInitialCentroids(X, K)       \n\n    for i in range(max_iters):\n        idx = findClosestCentroids(X, centroids)\n        distortion = kMeansDistortion(X, idx, centroids)\n        distortion_history.append(distortion)\n        centroids = computeCentroids(X, idx, K)\n        \n    return centroids, idx, distortion, distortion_history           \n           ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's test the algorithm and plot the graph of distortion_history to make sure everything is working properly. Distortion should decrease with the number of iterations and eventuslly converge to some value. We will run a test with 5 clusters and 30 iterations.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"centroids, idx, distortion, distortion_history = kMeans(np.array(customers[['Age_scaled', 'Annual Income (k$)_scaled', 'Spending Score (1-100)_scaled']]), 5, 30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\nplt.plot(distortion_history)\nplt.title('Distortion History')\nplt.xlabel('Iteration')\nplt.ylabel('Distortion')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(distortion_history)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this model, k-Means converges before 10 iterations have completed. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**K-Means with multiple random initialisations**:\n\nThe centroids at which the algorithm converges depends on the starting centroids. In order to avoid ending up at a local optima, the following function runs the k-Means algorithm a specified number of times, and picks the result with the lowest distortion.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#run kmeans with specified different random initialisations and pick one with lowest distortion\ndef kMeansRuns(X, K, max_iters, init_runs):\n    '''\n    Run the kMeans algorithm for specified number of random initialisations, init_runs, \n    and return result with lowets distortion.\n    '''\n    for r in range(init_runs):\n        if r == 0:\n            centroids, index, distortion, distortion_hist = kMeans(X, K, max_iters)\n            distortion_lowest = distortion\n        else:\n            current_centroids, current_index, distortion, current_distortion_hist = kMeans(X, K, max_iters)\n            if distortion_lowest > distortion:\n                centroids= current_centroids\n                index = current_index\n                distortion_lowest = distortion\n                \n    return centroids, index, distortion_lowest\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Number of Clusters**:\n\nSince there are not any absolute answers to choosing the number of clusters, we can manually pick the number of clusters or we can utilise methods like the Elbow method to help guide our selection. I have chosen to use the average silhouette method, and have defined the functions for it below.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<div id='avg'></div>\n**Average silhouette** measures the quality of clustering. We calculate the average silhouette for a range of number of clusters, and pick the the number of clusters which has the highest average silhouette score.\n\n\n\nFirst, we calculate the silhouette score for each training example, i. \n\nThe silhouette score is     <font size = '4'> $s(i) = \\frac{b(i) - a(i)}{max\\{a(i), b(i)\\}}$ </font>   where a(i) is the average euclidean distance bwetween training example, i, and all other points in its cluster, and b(i) is the average distance between the training example, i, and its closest cluster by average distance.\n\nA silhouette score of close to 1 indicates that the training example is much closer to its own cluster than to its nearest cluster, a score of 0 indicates that the training example is halfway between the cluster it is assigned to and the its nearest other cluster, and a score of -1 indicates that the training example is nowhere near its own cluster in comparison with the nearest other cluster. \n\n\nAfter we have calculated the silhouette score for each training example, we average it. \n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.spatial import distance\n\ndef SilhouetteScore(x_i, X, idx, K):\n    '''\n    For given training example (with index x_i), calculates  and returns its silhouette score.\n    \n    First, the function calculates the average distance, a_i, between the given training example\n    and all other points in the cluster it belongs to. Then, the function calculates the average distance\n    between the training example and all other points not in its own cluster, and picks the cluster with \n    the smallest average distance. Using a_i and b_i, it calculates the silhouette score of the given \n    training example.\n    '''\n    #calculate average distance between x_i and all points in its cluster\n    \n    #training example \n    point = X[x_i]\n    #cluster index of training example\n    idx_point = idx[x_i]\n    \n    #list of distances between point and other points in own cluster\n    own_cluster_distances = np.empty(0)\n    #loop over training examples' assigned cluster index, find points in \n    #own cluster and calculate euclidean distance\n    for i in range(idx.shape[0]):\n        if idx[i] == idx_point:\n            own_cluster_distances = np.append(own_cluster_distances, distance.euclidean(point, X[i]))\n    \n    #average distance between point and all other points in own cluster\n    a_i = np.sum(own_cluster_distances)/(own_cluster_distances.shape[0])\n    \n    #for each k in range K, calculate average distance between point and all other points in cluster k\n    avg_cluster_distances = np.empty(0)\n    #range of K without given trainig example's own cluster\n    other_clusters = [r for r in range(K) if r != idx_point]\n    \n    for k in other_clusters:\n        #distances between point and all points in cluster k\n        k_distances = np.empty(0)\n        #all points in cluster k\n        k_cluster = X[idx==k]\n        #number of points in cluster k\n        k_len = k_cluster.shape[0]\n        for n in range(k_len):\n            k_distances = np.append(k_distances, distance.euclidean(point, k_cluster[n]))\n        #average distance between point and all points in cluster k appended to\n        #avg_cluster_distances array\n        if k_len != 0:\n            avg_cluster_distances = np.append(avg_cluster_distances, np.sum(k_distances)/k_len)\n        else:\n            avg_cluster_distances = np.append(avg_cluster_distances, 0)\n        \n        \n    #find closest cluster in avg_cluster_distances\n    b_i = np.min(avg_cluster_distances)\n    \n    silhouette_score = (b_i - a_i)/np.max([a_i, b_i])\n    \n    \n    return silhouette_score ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def AverageSilhouette(X, idx,  K):\n    '''\n    Calculates and returns the average silhoutte for given number of clusters, K.\n    \n    Average silhouette is the average of the silhouette scores of all the training examples.\n    '''\n    silhouette_scores = np.empty(0)\n    #loop over all training examples and calculate their silhouette score\n    for i in range(X.shape[0]):\n        silhouette_i = SilhouetteScore(i, X, idx, K)\n        silhouette_scores = np.append(silhouette_scores, silhouette_i)\n    \n    #calculate average of all scores\n    avg_silhouette = np.sum(silhouette_scores)/len(silhouette_scores)\n    \n    return avg_silhouette\n        \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The following function runs k-Means for each K in the range 2 - K_range, calculates the average silhouette, and plots a graph of the average silhouette score for each K.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def PlotAvgSilhouettes(X, K_range, max_iters, init_runs):\n    \n    '''\n    Runs kMeans and plots the average silhouette scores for \n    each number of clusters in K_range.\n    \n    '''\n    clusters_avg_sil = np.empty(0)\n    #minimum of K_range must be 2\n    for K in range(2, K_range+1):\n        centroids, idx, distortion_lowest = kMeansRuns(X, K, max_iters, init_runs)\n        k_avg_sil = AverageSilhouette(X, idx,  K)\n        clusters_avg_sil = np.append(clusters_avg_sil, k_avg_sil)\n        \n    \n    plt.figure(figsize = (12.8, 9.6))\n    plt.plot(np.arange(2,K_range+1,1), clusters_avg_sil)\n    plt.title('Average Silhouette for number of clusters K')\n    plt.xlabel('K')\n    plt.ylabel('Average Silhouette')\n    plt.show()\n    \n    \n    return None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#features as an array, X\nX = np.array(customers[['Age_scaled', 'Annual Income (k$)_scaled', 'Spending Score (1-100)_scaled']])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will calculate and plot the average silhouette score for each K number of clusters in the range 2-15 (inclusive). We will run K-Means with 50 random initialisations, and for 20 iterations per random initialisation (we saw above that, for this model, the function converges before 10 iterations).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.simplefilter('error')\n\n#calculate and plot graph of average silhouettes for 2-15 clusters\nPlotAvgSilhouettes(X, 15, 20, 50)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the plot above, the maximum average silhouette score is for the model with nine clusters. \n\nWe will now run k-Means with nine clusters with 100 random initialisations, and 20 iterations for each random initiliation.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"centroids, ind, distortion = kMeansRuns(X, 9, 20, 50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#extract unscaled features into variable C so we can plot and understand the results\nC = np.array(customers[['Age', 'Annual Income (k$)', 'Spending Score (1-100)']])\n\n#get clusters\ncluster0 = C[ind==0]\ncluster1 = C[ind==1]\ncluster2 = C[ind==2]\ncluster3 = C[ind==3]\ncluster4 = C[ind==4]\ncluster5 = C[ind==5]\ncluster6 = C[ind==6]\ncluster7 = C[ind==7]\ncluster8 = C[ind==8]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(cluster0.shape)\nprint(cluster1.shape)\nprint(cluster2.shape)\nprint(cluster3.shape)\nprint(cluster4.shape)\nprint(cluster5.shape)\nprint(cluster6.shape)\nprint(cluster7.shape)\nprint(cluster8.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div id='eval'></div>**Evaluation**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We will now plot the clusters in a 3D scatter plot.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#cluster 3d scatter plot\n\nimport plotly.graph_objs as go\n\n\ntrace0 = go.Scatter3d(x = cluster0[:,0], y = cluster0[:,1], z = cluster0[:,2], \n                      mode = 'markers', name='Cluster0', marker = dict(size = 4, color = 'black'))\n\ntrace1 = go.Scatter3d(x = cluster1[:,0], y = cluster1[:,1], z = cluster1[:,2], \n                      mode = 'markers', name='Cluster1', marker = dict(size = 4, color = 'green'))\n\ntrace2 = go.Scatter3d(x = cluster2[:,0], y = cluster2[:,1], z = cluster2[:,2], \n                      mode = 'markers', name='Cluster2', marker = dict(size = 4, color =  'chartreuse'))\n\ntrace3 = go.Scatter3d(x = cluster3[:,0], y = cluster3[:,1], z = cluster3[:,2], \n                      mode = 'markers', name='Cluster3', marker = dict(size = 4, color =  'maroon'))\n\ntrace4 = go.Scatter3d(x = cluster4[:,0], y = cluster4[:,1], z = cluster4[:,2], \n                      mode = 'markers', name='Cluster4', marker = dict(size = 4, color =  'hotpink'))\n\ntrace5 = go.Scatter3d(x = cluster5[:,0], y = cluster5[:,1], z = cluster5[:,2], \n                      mode = 'markers', name='Cluster5', marker = dict(size = 4, color =  'crimson'))\n\ntrace6 = go.Scatter3d(x = cluster6[:,0], y = cluster6[:,1], z = cluster6[:,2], \n                      mode = 'markers', name='Cluster6', marker = dict(size = 4, color =  'cyan'))\n\n\ntrace7 = go.Scatter3d(x = cluster7[:,0], y = cluster7[:,1], z = cluster7[:,2], \n                      mode = 'markers', name='Cluster7', marker = dict(size = 4, color =  'darkblue'))\n\n\ntrace8 = go.Scatter3d(x = cluster8[:,0], y = cluster8[:,1], z = cluster8[:,2], \n                      mode = 'markers', name='Cluster8', marker = dict(size = 4, color =  'chocolate'))\n\ndata = [trace0, trace1, trace2, trace3, trace4, trace5, trace6, trace7, trace8]\n\n\nlayout = dict(title = 'Mall Segmentation Clusters',\n              scene = dict(xaxis= dict(title= 'Age',ticklen= 5,zeroline= False),\n              yaxis= dict(title= 'Annual Income',ticklen= 5,zeroline= False),\n              zaxis= dict(title= 'Spending Score',ticklen= 5,zeroline= False))\n             )\n\nfig = go.Figure(dict(data = data, layout = layout))\n\nfig.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Things to note from above plot:\n\n* We can broadly see the clusters we identified in the model before training, eg the high spending young people with a low income. \n* The moderate spenders with around median are split into three age groups.\n* There is a cluster of high income earners with a higher than median spending score.\n* There are two clusters of high income earners with a lower than median spending score.\n* There is a cluster of low income, young to middle age people with low spending scores.\n* There is a cluster of older, low income earners with low spending scores.\n\n\n\n\n\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#average silhouette score\nprint('The average silhouette score of this model with 9 clusters is {:0.2f}.'.format(AverageSilhouette(X, ind,  9)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The average silhouette score shows that this model is reasonably well clustered. As this is an average score, it doesn't reflect the fact that some clusters have a better clustering quality that others. For example, the three clusters in the middle of the plot are 'tighter', with all their points relatively closer to each other, than the other clusters. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We can use the descriptive statistics of each cluster, and procure additional information, to identify the demographics and spending patterns of each group. We can then target products and services accordingly.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"[back to Contents](#back)","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}