{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-13T21:01:10.474456Z","iopub.execute_input":"2021-09-13T21:01:10.474899Z","iopub.status.idle":"2021-09-13T21:01:10.4989Z","shell.execute_reply.started":"2021-09-13T21:01:10.474869Z","shell.execute_reply":"2021-09-13T21:01:10.49785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport seaborn as sns\nfrom sklearn.cluster import KMeans","metadata":{"execution":{"iopub.status.busy":"2021-09-13T21:01:10.500929Z","iopub.execute_input":"2021-09-13T21:01:10.501487Z","iopub.status.idle":"2021-09-13T21:01:10.507193Z","shell.execute_reply.started":"2021-09-13T21:01:10.501442Z","shell.execute_reply":"2021-09-13T21:01:10.506403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Collection & Analysis","metadata":{}},{"cell_type":"code","source":"customer_data = pd.read_csv('../input/customer-segmentation-tutorial-in-python/Mall_Customers.csv')","metadata":{"execution":{"iopub.status.busy":"2021-09-13T21:01:10.508238Z","iopub.execute_input":"2021-09-13T21:01:10.508475Z","iopub.status.idle":"2021-09-13T21:01:10.529766Z","shell.execute_reply.started":"2021-09-13T21:01:10.508448Z","shell.execute_reply":"2021-09-13T21:01:10.528922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# first 5 rows in the dataframe\ncustomer_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-13T21:01:22.414328Z","iopub.execute_input":"2021-09-13T21:01:22.414611Z","iopub.status.idle":"2021-09-13T21:01:22.436902Z","shell.execute_reply.started":"2021-09-13T21:01:22.414582Z","shell.execute_reply":"2021-09-13T21:01:22.436065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# finding the number of rows and columns\ncustomer_data.shape\n\n# data available for 200 customers","metadata":{"execution":{"iopub.status.busy":"2021-09-13T21:01:34.411173Z","iopub.execute_input":"2021-09-13T21:01:34.411467Z","iopub.status.idle":"2021-09-13T21:01:34.421309Z","shell.execute_reply.started":"2021-09-13T21:01:34.411437Z","shell.execute_reply":"2021-09-13T21:01:34.420339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# getting some informations about the dataset\ncustomer_data.info()","metadata":{"execution":{"iopub.status.busy":"2021-09-13T21:01:43.249833Z","iopub.execute_input":"2021-09-13T21:01:43.250153Z","iopub.status.idle":"2021-09-13T21:01:43.273821Z","shell.execute_reply.started":"2021-09-13T21:01:43.250122Z","shell.execute_reply":"2021-09-13T21:01:43.272799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Missing Values","metadata":{}},{"cell_type":"code","source":"# checking for missing values\ncustomer_data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-09-13T21:01:50.741131Z","iopub.execute_input":"2021-09-13T21:01:50.741454Z","iopub.status.idle":"2021-09-13T21:01:50.750649Z","shell.execute_reply.started":"2021-09-13T21:01:50.74142Z","shell.execute_reply":"2021-09-13T21:01:50.749754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature Selection\n#### Choosing the Annual Income Column & Spending Score column","metadata":{}},{"cell_type":"code","source":"X = customer_data.iloc[:,[3,4]].values\n# x-axis : annual income \n# y-axis : spending score","metadata":{"execution":{"iopub.status.busy":"2021-09-13T21:02:49.348894Z","iopub.execute_input":"2021-09-13T21:02:49.349232Z","iopub.status.idle":"2021-09-13T21:02:49.355877Z","shell.execute_reply.started":"2021-09-13T21:02:49.349204Z","shell.execute_reply":"2021-09-13T21:02:49.35523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Choosing the number of clusters\n### WCSS  ->  Within Clusters Sum of Squares","metadata":{}},{"cell_type":"code","source":"# finding wcss value for different number of clusters\n# cost function --> within cluster the sum of square distances of each data point from the centroid of that cluster\n\nwcss = []\n\nfor i in range(1,11):\n  kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42)\n  # ‘k-means++’ : selects initial cluster centers for k-mean clustering in a smart way to speed up convergence\n\n  kmeans.fit(X)\n\n  wcss.append(kmeans.inertia_)\n  # inertia_float : Sum of squared distances of samples to their closest cluster center.","metadata":{"execution":{"iopub.status.busy":"2021-09-13T21:03:26.89974Z","iopub.execute_input":"2021-09-13T21:03:26.90031Z","iopub.status.idle":"2021-09-13T21:03:27.488072Z","shell.execute_reply.started":"2021-09-13T21:03:26.900271Z","shell.execute_reply":"2021-09-13T21:03:27.487097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot an elbow graph\n\nsns.set()\nplt.plot(range(1,11), wcss)\nplt.title('The Elbow Point Graph')\nplt.xlabel('Number of Clusters')\nplt.ylabel('WCSS')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-13T21:03:46.604338Z","iopub.execute_input":"2021-09-13T21:03:46.604632Z","iopub.status.idle":"2021-09-13T21:03:46.852589Z","shell.execute_reply.started":"2021-09-13T21:03:46.604598Z","shell.execute_reply":"2021-09-13T21:03:46.851751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training the k-Means Clustering Model using k=5","metadata":{}},{"cell_type":"code","source":"kmeans = KMeans(n_clusters=5, init='k-means++', random_state=0) #best-fit model\n\n# return a label for each data point based on their cluster\nY = kmeans.fit_predict(X)\n\nprint(Y)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T21:04:15.233772Z","iopub.execute_input":"2021-09-13T21:04:15.234083Z","iopub.status.idle":"2021-09-13T21:04:15.282823Z","shell.execute_reply.started":"2021-09-13T21:04:15.234044Z","shell.execute_reply":"2021-09-13T21:04:15.282149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualizing all the Clusters","metadata":{}},{"cell_type":"code","source":"# Cluster Centers\nkmeans.cluster_centers_","metadata":{"execution":{"iopub.status.busy":"2021-09-13T21:04:47.359553Z","iopub.execute_input":"2021-09-13T21:04:47.35985Z","iopub.status.idle":"2021-09-13T21:04:47.367037Z","shell.execute_reply.started":"2021-09-13T21:04:47.359822Z","shell.execute_reply":"2021-09-13T21:04:47.3661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotting all the clusters and their Centroids\n# x-axis : annual income \n# y-axis : spending score\n\nplt.figure(figsize=(8,8))\nplt.scatter(X[Y==0,0], X[Y==0,1], s=50, c='green', label='Cluster 1')\nplt.scatter(X[Y==1,0], X[Y==1,1], s=50, c='red', label='Cluster 2')\nplt.scatter(X[Y==2,0], X[Y==2,1], s=50, c='yellow', label='Cluster 3')\nplt.scatter(X[Y==3,0], X[Y==3,1], s=50, c='violet', label='Cluster 4')\nplt.scatter(X[Y==4,0], X[Y==4,1], s=50, c='blue', label='Cluster 5')\n\n# plot the centroids\n  # cluster_centers_ndarray of shape (n_clusters, n_features) : Coordinates of cluster centers. \nplt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], s=100, c='cyan', label='Centroids')\n\nplt.title('Customer Groups')\nplt.xlabel('Annual Income')\nplt.ylabel('Spending Score')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-13T21:04:55.181531Z","iopub.execute_input":"2021-09-13T21:04:55.182042Z","iopub.status.idle":"2021-09-13T21:04:55.518592Z","shell.execute_reply.started":"2021-09-13T21:04:55.182011Z","shell.execute_reply":"2021-09-13T21:04:55.517699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Measuring performance of clusteres - silhouette_score","metadata":{}},{"cell_type":"code","source":"# Metrics for clustering algorithms\nfrom sklearn.metrics import silhouette_samples, silhouette_score\n\n# Based on the elbow plot we choose various candidates for number of clusters\nclusters = [4,5,6,7,8,9]\n\n\n\n\nfor cluster in clusters:\n  # creating a sub-plot with 2 columns\n  fig, (ax1, ax2) = plt.subplots(1,2) # 1 row, 2 columns\n  fig.set_size_inches(18, 7)\n\n  # silhouette coefficient can range from -1 to 1\n  # -1 being worst, 1 being the best\n  ax1.set_xlim([-0.2,1])\n\n  # we need to insert blank space between silhouette plots, \n  ax1.set_ylim([0, len(X) + (cluster + 1) * 10])\n\n  km_cluster = KMeans(n_clusters=cluster, random_state= 1)\n  cluster_labels = km_cluster.fit_predict(X)\n\n\n  # \"silhoutte_score\" gives the average value for all the samples, a perspective into density and separation of clusters formed\n\n  silhoutte_avg = silhouette_score(X, cluster_labels)\n  print(\"For n_clusters = \", cluster, \" The average silhouette_score is :\", silhoutte_avg)\n\n\n  # Compute the silhouette scores for each sample\n  sample_silhouette_values = silhouette_samples(X, cluster_labels)\n\n\n\n  # plotting silhoutte graph\n  y_lower = 10\n  for i in range(cluster):\n      # Aggregate the silhouette scores for samples belonging to\n      # cluster i, and sort them\n      ith_cluster_silhouette_values = \\\n          sample_silhouette_values[cluster_labels == i]\n\n      ith_cluster_silhouette_values.sort()\n\n      size_cluster_i = ith_cluster_silhouette_values.shape[0]\n      y_upper = y_lower + size_cluster_i\n\n      color = cm.nipy_spectral(float(i) / cluster)\n      ax1.fill_betweenx(np.arange(y_lower, y_upper),\n                        0, ith_cluster_silhouette_values,\n                        facecolor=color, edgecolor=color, alpha=0.7)\n\n      # Label the silhouette plots with their cluster numbers at the middle\n      ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n\n      # Compute the new y_lower for next plot\n      y_lower = y_upper + 10  # 10 for the 0 samples\n\n  ax1.set_title(\"The silhouette plot for the various clusters.\")\n  ax1.set_xlabel(\"The silhouette coefficient values\")\n  ax1.set_ylabel(\"Cluster label\")\n\n  # The vertical line for average silhouette score of all the values\n  ax1.axvline(x=silhoutte_avg, color=\"red\", linestyle=\"--\")\n\n  ax1.set_yticks([])  # Clear the yaxis labels / ticks\n  ax1.set_xticks([-0.2, 0, 0.2, 0.4, 0.6, 0.8, 1])\n\n  # 2nd Plot showing the actual clusters formed\n  colors = cm.nipy_spectral(cluster_labels.astype(float) / cluster)\n  ax2.scatter(X[:, 0], X[:, 1], marker='.', s=30, lw=0, alpha=0.7,\n              c=colors, edgecolor='k')\n\n  # Labeling the clusters\n  centers = km_cluster.cluster_centers_\n\n\n  # Draw white circles at cluster centers\n  ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n              c=\"white\", alpha=1, s=200, edgecolor='k')\n\n  for i, c in enumerate(centers):\n      ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n                  s=50, edgecolor='k')\n\n  ax2.set_title(\"The visualization of the clustered data.\")\n  ax2.set_xlabel(\"Feature space for the 1st feature\")\n  ax2.set_ylabel(\"Feature space for the 2nd feature\")\n\n  plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n                \"with n_clusters = %d\" % cluster),\n                fontsize=14, fontweight='bold')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-13T21:05:39.682839Z","iopub.execute_input":"2021-09-13T21:05:39.683423Z","iopub.status.idle":"2021-09-13T21:05:44.230534Z","shell.execute_reply.started":"2021-09-13T21:05:39.683383Z","shell.execute_reply":"2021-09-13T21:05:44.229532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Note: a high value indicates that the object is well matched to its own cluster and poorly matched to neighboring clusters.\n# Observations: clusters = 5 has got the highest silhoutte score","metadata":{"execution":{"iopub.status.busy":"2021-09-13T21:08:15.67166Z","iopub.execute_input":"2021-09-13T21:08:15.672507Z","iopub.status.idle":"2021-09-13T21:08:15.676387Z","shell.execute_reply.started":"2021-09-13T21:08:15.672467Z","shell.execute_reply":"2021-09-13T21:08:15.67534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}