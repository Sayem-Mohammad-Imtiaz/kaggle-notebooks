{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-14T15:26:12.785232Z","iopub.execute_input":"2021-09-14T15:26:12.785558Z","iopub.status.idle":"2021-09-14T15:26:12.899165Z","shell.execute_reply.started":"2021-09-14T15:26:12.785479Z","shell.execute_reply":"2021-09-14T15:26:12.898283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Steps I followed:\n1. Importing data\n2. Cleaning data and data exploration\n3. Feature engineering (choosing required features)\n4. Data visualization\n5. Finding if there exists corr among variables\n6. train test split\n7. Model building and Hyper-parameter tuning\n8. using various sklearn.metrics : mean_absolute_error, mean_squared_error, np.sqrt(mean_squared_error)\n9. converting the model to pickle file for future use","metadata":{}},{"cell_type":"code","source":"# Importing Dependencies\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Lasso\nfrom sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_selection import SelectFromModel\nimport xgboost as xgb\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn import metrics","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:26:12.901026Z","iopub.execute_input":"2021-09-14T15:26:12.901318Z","iopub.status.idle":"2021-09-14T15:26:14.358386Z","shell.execute_reply.started":"2021-09-14T15:26:12.901281Z","shell.execute_reply":"2021-09-14T15:26:14.357665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing data\ndataset = pd.read_csv(\"../input/vehicle-dataset-from-cardekho/car data.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:26:14.359564Z","iopub.execute_input":"2021-09-14T15:26:14.359807Z","iopub.status.idle":"2021-09-14T15:26:14.378219Z","shell.execute_reply.started":"2021-09-14T15:26:14.359775Z","shell.execute_reply":"2021-09-14T15:26:14.377587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# About features\n1. **name** - Name of the cars\n2. **year** - Year of the car when it was bought\n3. **selling_price** - Price at which the car is being sold\n4. **km_driven** - Number of Kilometres the car is driven\n5. **fuel** - Fuel type of car\n6. **seller_type** - tells if a seller is individual or a dealer\n7. **transmission** - Gear transmission fo the car\n8. **owner** - Number of previous owners of the car","metadata":{}},{"cell_type":"code","source":"# top 5-rows of dataset\ndataset.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:26:14.3802Z","iopub.execute_input":"2021-09-14T15:26:14.380455Z","iopub.status.idle":"2021-09-14T15:26:14.40945Z","shell.execute_reply.started":"2021-09-14T15:26:14.380423Z","shell.execute_reply":"2021-09-14T15:26:14.408634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# getting more familier with the dataset\ndataset.info()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:26:14.410875Z","iopub.execute_input":"2021-09-14T15:26:14.411169Z","iopub.status.idle":"2021-09-14T15:26:14.429884Z","shell.execute_reply.started":"2021-09-14T15:26:14.411134Z","shell.execute_reply":"2021-09-14T15:26:14.429068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Selling_Price is the target feature","metadata":{}},{"cell_type":"markdown","source":"# Missing Values","metadata":{}},{"cell_type":"code","source":"# Checking if there is any missing value\ndataset.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:26:14.431525Z","iopub.execute_input":"2021-09-14T15:26:14.432135Z","iopub.status.idle":"2021-09-14T15:26:14.44382Z","shell.execute_reply.started":"2021-09-14T15:26:14.432083Z","shell.execute_reply":"2021-09-14T15:26:14.442713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Categorical Variable Encoding","metadata":{}},{"cell_type":"code","source":"cat_features = [feature for feature in dataset.columns if dataset[feature].dtypes in ['object']]\ncat_features","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:26:14.445331Z","iopub.execute_input":"2021-09-14T15:26:14.445736Z","iopub.status.idle":"2021-09-14T15:26:14.456714Z","shell.execute_reply.started":"2021-09-14T15:26:14.445699Z","shell.execute_reply":"2021-09-14T15:26:14.455975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Categorical feature distribution with 'Selling_Price'","metadata":{}},{"cell_type":"code","source":"dataset.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:26:14.458001Z","iopub.execute_input":"2021-09-14T15:26:14.45835Z","iopub.status.idle":"2021-09-14T15:26:14.467417Z","shell.execute_reply.started":"2021-09-14T15:26:14.458312Z","shell.execute_reply":"2021-09-14T15:26:14.466519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.Car_Name.nunique()\n# There are 98 different features","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:26:14.469095Z","iopub.execute_input":"2021-09-14T15:26:14.469443Z","iopub.status.idle":"2021-09-14T15:26:14.47967Z","shell.execute_reply.started":"2021-09-14T15:26:14.469409Z","shell.execute_reply":"2021-09-14T15:26:14.478861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Mean prices per category of categorical variables\nplt.figure(figsize=(15,8))\nfor feature in cat_features:\n    dataset.groupby(feature)['Selling_Price'].mean().plot.bar()\n    plt.title(feature)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:26:14.483969Z","iopub.execute_input":"2021-09-14T15:26:14.484248Z","iopub.status.idle":"2021-09-14T15:26:16.565275Z","shell.execute_reply.started":"2021-09-14T15:26:14.484221Z","shell.execute_reply":"2021-09-14T15:26:16.564407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Observation of categorical features\n1. Few car names have higher prices, like 'fortuner', 'innova', 'land cruiser', etc.\n2. In Fuel_Type, 'Diesel' type cars have higher prices as compared to CNG or Petrol driven cars\n3. In seller_type, 'Dealer' are selling cars with higher prices than 'Individual'\n4. And finally, 'Automatic' cars are being sold for higher prices than 'Manual' cars","metadata":{}},{"cell_type":"code","source":"# count of prices per category of categorical variables\nplt.figure(figsize=(15,8))\nfor feature in cat_features:\n    dataset.groupby(feature)['Selling_Price'].count().plot.bar()\n    plt.title(feature)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:26:16.567958Z","iopub.execute_input":"2021-09-14T15:26:16.568491Z","iopub.status.idle":"2021-09-14T15:26:18.542721Z","shell.execute_reply.started":"2021-09-14T15:26:16.568459Z","shell.execute_reply":"2021-09-14T15:26:18.541916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Temporal Feature: Features releted to time, date or year","metadata":{}},{"cell_type":"code","source":"temporal_feature = [feature for feature in dataset.columns if 'year' in feature.lower() or 'yr' in feature.lower()]\ntemporal_feature","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:26:18.544059Z","iopub.execute_input":"2021-09-14T15:26:18.544319Z","iopub.status.idle":"2021-09-14T15:26:18.552063Z","shell.execute_reply.started":"2021-09-14T15:26:18.544283Z","shell.execute_reply":"2021-09-14T15:26:18.551138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Updating the temporal feature with number years since the car was bought","metadata":{}},{"cell_type":"code","source":"for feature in temporal_feature:\n    dataset[feature] = 2021 - dataset[feature]","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:26:18.553695Z","iopub.execute_input":"2021-09-14T15:26:18.554018Z","iopub.status.idle":"2021-09-14T15:26:18.576524Z","shell.execute_reply.started":"2021-09-14T15:26:18.55398Z","shell.execute_reply":"2021-09-14T15:26:18.575815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:26:18.577774Z","iopub.execute_input":"2021-09-14T15:26:18.578204Z","iopub.status.idle":"2021-09-14T15:26:18.5933Z","shell.execute_reply.started":"2021-09-14T15:26:18.578171Z","shell.execute_reply":"2021-09-14T15:26:18.59261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Now 'year' variable represents the number of years passed since the car was bought","metadata":{}},{"cell_type":"markdown","source":"# Numerical Variables","metadata":{}},{"cell_type":"markdown","source":"##### finding correlation between all the numerical values with target variable Selling_Price","metadata":{}},{"cell_type":"code","source":"dataset.corr()['Selling_Price'].drop('Selling_Price', axis=0) # pandas.core.frame.DataFrame","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:26:18.594525Z","iopub.execute_input":"2021-09-14T15:26:18.594962Z","iopub.status.idle":"2021-09-14T15:26:18.608928Z","shell.execute_reply.started":"2021-09-14T15:26:18.594927Z","shell.execute_reply":"2021-09-14T15:26:18.607435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Observation: The Selling_Price is linearly directly correlated with Present_Price","metadata":{}},{"cell_type":"code","source":"dataset[['Year', 'Present_Price',  'Kms_Driven', 'Owner']].head()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:26:18.610228Z","iopub.execute_input":"2021-09-14T15:26:18.610991Z","iopub.status.idle":"2021-09-14T15:26:18.625857Z","shell.execute_reply.started":"2021-09-14T15:26:18.610954Z","shell.execute_reply":"2021-09-14T15:26:18.62517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the number of unique values present per numerical variable\ndataset[['Year', 'Present_Price',  'Kms_Driven', 'Owner']].nunique()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:26:18.62848Z","iopub.execute_input":"2021-09-14T15:26:18.628704Z","iopub.status.idle":"2021-09-14T15:26:18.639775Z","shell.execute_reply.started":"2021-09-14T15:26:18.628682Z","shell.execute_reply":"2021-09-14T15:26:18.638912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset[['Year', 'Present_Price',  'Kms_Driven', 'Owner']].info()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:26:18.64112Z","iopub.execute_input":"2021-09-14T15:26:18.64201Z","iopub.status.idle":"2021-09-14T15:26:18.659339Z","shell.execute_reply.started":"2021-09-14T15:26:18.641972Z","shell.execute_reply":"2021-09-14T15:26:18.658611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Although 'Kms_Driven' is of type int64, but it should be continuous numerical variable","metadata":{}},{"cell_type":"code","source":"# Changing the datatype of Kms_driven\ndataset.Kms_Driven = dataset.Kms_Driven.astype('float64')","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:26:18.660414Z","iopub.execute_input":"2021-09-14T15:26:18.661202Z","iopub.status.idle":"2021-09-14T15:26:18.666298Z","shell.execute_reply.started":"2021-09-14T15:26:18.661166Z","shell.execute_reply":"2021-09-14T15:26:18.665241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset[['Year', 'Present_Price',  'Kms_Driven', 'Owner']].info()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:26:18.667617Z","iopub.execute_input":"2021-09-14T15:26:18.668513Z","iopub.status.idle":"2021-09-14T15:26:18.687303Z","shell.execute_reply.started":"2021-09-14T15:26:18.668473Z","shell.execute_reply":"2021-09-14T15:26:18.686593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Discrete Numerical Variables","metadata":{}},{"cell_type":"code","source":"discrete_num_features = [feature for feature in dataset.columns if dataset[feature].dtypes in ['int64']]\ndiscrete_num_features","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:26:18.688487Z","iopub.execute_input":"2021-09-14T15:26:18.688765Z","iopub.status.idle":"2021-09-14T15:26:18.696831Z","shell.execute_reply.started":"2021-09-14T15:26:18.68873Z","shell.execute_reply":"2021-09-14T15:26:18.695877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's see the relationship of discrete numerical variables with target variable ('SalePrice')\nfor feature in discrete_num_features:\n    dataset.groupby(feature)['Selling_Price'].mean().plot.bar()\n\n    plt.xlabel(feature)\n    plt.ylabel('Selling_Price')\n    plt.title(feature)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:26:18.698728Z","iopub.execute_input":"2021-09-14T15:26:18.699292Z","iopub.status.idle":"2021-09-14T15:26:19.087195Z","shell.execute_reply.started":"2021-09-14T15:26:18.699251Z","shell.execute_reply":"2021-09-14T15:26:19.086324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Observations: \n1. With the increase in the number of years, we can see a clear decline in Selling Price\n2. In case of Owner, if there was no previous (0 owner) the selling price is highest, but the 3 owner mean > 1 onwer; we need to check the median value here","metadata":{}},{"cell_type":"code","source":"# Let's see the relationship of discrete numerical variables with target variable ('SalePrice')\nfor feature in discrete_num_features:\n    dataset.groupby(feature)['Selling_Price'].median().plot.bar()\n\n    plt.xlabel(feature)\n    plt.ylabel('Selling_Price')\n    plt.title(feature)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:26:19.088804Z","iopub.execute_input":"2021-09-14T15:26:19.089087Z","iopub.status.idle":"2021-09-14T15:26:19.488604Z","shell.execute_reply.started":"2021-09-14T15:26:19.089052Z","shell.execute_reply":"2021-09-14T15:26:19.487952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Observations: \n1. With the increase in the number of years, we can see a clear decline in Selling Price\n2. In case of Owner, if there was no previous (0 owner) the selling price is highest, but the 3 owner meadian > 1 onwer median.","metadata":{}},{"cell_type":"markdown","source":"### Continuous Numerical Variables","metadata":{}},{"cell_type":"code","source":"continuous_num_features = [feature for feature in dataset.columns if dataset[feature].dtypes == 'float64']\ncontinuous_num_features","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:26:19.489877Z","iopub.execute_input":"2021-09-14T15:26:19.490253Z","iopub.status.idle":"2021-09-14T15:26:19.497018Z","shell.execute_reply.started":"2021-09-14T15:26:19.490217Z","shell.execute_reply":"2021-09-14T15:26:19.496223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dropping target variable from continuous_num_features list\ncontinuous_num_features.remove('Selling_Price')\ncontinuous_num_features","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:26:19.498718Z","iopub.execute_input":"2021-09-14T15:26:19.499056Z","iopub.status.idle":"2021-09-14T15:26:19.512663Z","shell.execute_reply.started":"2021-09-14T15:26:19.499016Z","shell.execute_reply":"2021-09-14T15:26:19.511912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's analyse the continuous values by creating histograms to understand the distribution\nfor feature in continuous_num_features:\n    dataset[feature].hist(bins=30)\n    plt.xlabel(feature)\n    plt.ylabel('count')\n    plt.title(feature)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:26:19.51415Z","iopub.execute_input":"2021-09-14T15:26:19.514464Z","iopub.status.idle":"2021-09-14T15:26:19.96624Z","shell.execute_reply.started":"2021-09-14T15:26:19.514429Z","shell.execute_reply":"2021-09-14T15:26:19.965566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's analyse the continuous values by creating histograms to understand the distribution\nfor feature in continuous_num_features:\n    sns.histplot(data=dataset, x=feature, kde=True)\n    plt.xlabel(feature)\n    plt.ylabel('count')\n    plt.title(feature)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:26:19.967623Z","iopub.execute_input":"2021-09-14T15:26:19.967862Z","iopub.status.idle":"2021-09-14T15:26:20.646259Z","shell.execute_reply.started":"2021-09-14T15:26:19.96783Z","shell.execute_reply":"2021-09-14T15:26:20.645554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Obseravation: Continuous variables are right skewed (mode < median < mean)","metadata":{}},{"cell_type":"markdown","source":"### Outliers : Checking outliers in numerical variables","metadata":{}},{"cell_type":"code","source":"# boxplot to visualize outliers\n\nfor feature in discrete_num_features + continuous_num_features:\n    dataset.boxplot(column = feature)\n    plt.ylabel(feature)\n    plt.title(feature)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:26:20.650408Z","iopub.execute_input":"2021-09-14T15:26:20.65079Z","iopub.status.idle":"2021-09-14T15:26:21.290502Z","shell.execute_reply.started":"2021-09-14T15:26:20.650745Z","shell.execute_reply":"2021-09-14T15:26:21.28973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Observations: All the numerical variables have outliers. Had there been any missing values, we would have replaced with median() instead of mean()","metadata":{}},{"cell_type":"markdown","source":"# Splitting Data","metadata":{}},{"cell_type":"code","source":"X = dataset.drop('Selling_Price', axis=1)\ny = dataset.Selling_Price\nX.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:26:21.294642Z","iopub.execute_input":"2021-09-14T15:26:21.294932Z","iopub.status.idle":"2021-09-14T15:26:21.312811Z","shell.execute_reply.started":"2021-09-14T15:26:21.294871Z","shell.execute_reply":"2021-09-14T15:26:21.312139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Categorical variable Encoding\n### Label encoding and One-hot encoding","metadata":{}},{"cell_type":"markdown","source":"#### Label Encoding for Fuel_Type, Seller_Type, Transmission","metadata":{}},{"cell_type":"code","source":"# label encoding\ncar_dataset = X.copy()\ncar_dataset.replace({'Fuel_Type':{'Petrol':3, 'Diesel':1, 'CNG':2}}, inplace=True)\ncar_dataset.replace({'Seller_Type':{'Dealer':1, 'Individual':2}}, inplace=True)\ncar_dataset.replace({'Transmission':{'Manual':2, 'Automatic':1}}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:26:21.313972Z","iopub.execute_input":"2021-09-14T15:26:21.314753Z","iopub.status.idle":"2021-09-14T15:26:21.329634Z","shell.execute_reply.started":"2021-09-14T15:26:21.314709Z","shell.execute_reply":"2021-09-14T15:26:21.328747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train - Test Split","metadata":{}},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(car_dataset, y, random_state=1, test_size=0.1)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:26:21.331038Z","iopub.execute_input":"2021-09-14T15:26:21.331799Z","iopub.status.idle":"2021-09-14T15:26:21.340541Z","shell.execute_reply.started":"2021-09-14T15:26:21.331745Z","shell.execute_reply":"2021-09-14T15:26:21.339752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### One-hot encoding for Car-Name","metadata":{}},{"cell_type":"code","source":"x_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:26:21.34223Z","iopub.execute_input":"2021-09-14T15:26:21.342509Z","iopub.status.idle":"2021-09-14T15:26:21.357984Z","shell.execute_reply.started":"2021-09-14T15:26:21.342472Z","shell.execute_reply":"2021-09-14T15:26:21.357069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 'handle_unknown' helps to discard categories not seen during fit\nencoder_OH = OneHotEncoder(handle_unknown = 'ignore', sparse=False)\n\ntrain_encoded = pd.DataFrame(encoder_OH.fit_transform(x_train[['Car_Name']]), index = x_train.index)\ntest_encoded = pd.DataFrame(encoder_OH.transform(x_test[['Car_Name']]), index = x_test.index)\n\ntrain_OH = pd.concat([x_train.select_dtypes(include = ['int64', 'float64']), train_encoded], axis = 1)\ntest_OH = pd.concat([x_test.select_dtypes(include = ['int64', 'float64']), test_encoded], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:26:21.359442Z","iopub.execute_input":"2021-09-14T15:26:21.359718Z","iopub.status.idle":"2021-09-14T15:26:21.376221Z","shell.execute_reply.started":"2021-09-14T15:26:21.359685Z","shell.execute_reply":"2021-09-14T15:26:21.375368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_OH.shape)\nprint(test_OH.shape)\n# total number of features = 101","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:26:21.377406Z","iopub.execute_input":"2021-09-14T15:26:21.377954Z","iopub.status.idle":"2021-09-14T15:26:21.389429Z","shell.execute_reply.started":"2021-09-14T15:26:21.377883Z","shell.execute_reply":"2021-09-14T15:26:21.388593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature Selection","metadata":{}},{"cell_type":"code","source":"# Next setps:\n#     1. feature scaling \n#     2. feature selection using lasso and select from model\n#     3. model building using treebase ensemble models randomforest, extra tree, xgboost\n#     4. use of randomized search cv for hyperparameter tuning\n#     5. selecting the best model out of them\n#     6. printing the test score","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:26:21.390822Z","iopub.execute_input":"2021-09-14T15:26:21.391115Z","iopub.status.idle":"2021-09-14T15:26:21.39841Z","shell.execute_reply.started":"2021-09-14T15:26:21.391083Z","shell.execute_reply":"2021-09-14T15:26:21.39758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_cols = train_OH.columns\n\n# MinMax scaler object\nscaler = MinMaxScaler()\n\n# transforming train data\nx_train_encoded_scaled = pd.DataFrame(scaler.fit_transform(train_OH), columns = train_cols)\n\n# transforming test data\nx_test_encoded_scaled = pd.DataFrame(scaler.transform(test_OH), columns = train_cols)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:26:21.399916Z","iopub.execute_input":"2021-09-14T15:26:21.400201Z","iopub.status.idle":"2021-09-14T15:26:21.417951Z","shell.execute_reply.started":"2021-09-14T15:26:21.400169Z","shell.execute_reply":"2021-09-14T15:26:21.417252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Selection using Lasso regression to select important features\n#### This is the reason why I performed feature scaling","metadata":{}},{"cell_type":"code","source":"# The bigger the alpha for Lasso, less features gets selected\n# SelectFromModel selects features whose coefficients are non-zero\n# feature selection using training data\nfeature_sel = SelectFromModel(Lasso(alpha = 0.01, random_state=1, max_iter=10000))\nfeature_sel.fit(x_train_encoded_scaled, y_train)\n\nselected_features = x_train_encoded_scaled.columns[feature_sel.get_support()]\nlen(selected_features)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:26:21.42065Z","iopub.execute_input":"2021-09-14T15:26:21.420842Z","iopub.status.idle":"2021-09-14T15:26:21.43791Z","shell.execute_reply.started":"2021-09-14T15:26:21.420822Z","shell.execute_reply":"2021-09-14T15:26:21.43679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Out of 101 features, only 24 got selected","metadata":{}},{"cell_type":"code","source":"np.array(selected_features)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:26:21.43926Z","iopub.execute_input":"2021-09-14T15:26:21.439748Z","iopub.status.idle":"2021-09-14T15:26:21.445876Z","shell.execute_reply.started":"2021-09-14T15:26:21.439713Z","shell.execute_reply":"2021-09-14T15:26:21.444922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model building","metadata":{}},{"cell_type":"markdown","source":"### Refer below articles to know more about Tree based algorithms\n### [Decision trees and ensemble methods do not require feature scaling to be performed as they are not sensitive to the the variance in the data](https://towardsdatascience.com/do-decision-trees-need-feature-scaling-97809eaa60c6)\n\n### [ExtraTreesRegressor vs RandomForestRegressor](https://quantdare.com/what-is-the-difference-between-extra-trees-and-random-forest/)","metadata":{}},{"cell_type":"code","source":"# # ExtraTreesRegressor and RandomForestRegressor have exactly same set of parameters,\n\n# Important differences among them exists as below:\n    # 1. Random forest uses bootstrap replicas (bootstrap == True), i.e., it subsamples the input data with replacement. \n    # But Extra Trees uses the whole original samples (bootstrap == False).\n\n    # 2. Random forest chooses optimum split for splitting nodes (computationally costly), but ExtraTrees chooses splits randomly","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:26:21.447455Z","iopub.execute_input":"2021-09-14T15:26:21.448072Z","iopub.status.idle":"2021-09-14T15:26:21.454652Z","shell.execute_reply.started":"2021-09-14T15:26:21.44803Z","shell.execute_reply":"2021-09-14T15:26:21.453779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Considering features selected using lasso regression\nx_train_final = train_OH[selected_features]\nx_test_final = test_OH[selected_features]","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:26:21.456364Z","iopub.execute_input":"2021-09-14T15:26:21.456976Z","iopub.status.idle":"2021-09-14T15:26:21.469752Z","shell.execute_reply.started":"2021-09-14T15:26:21.456941Z","shell.execute_reply":"2021-09-14T15:26:21.468741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train_final.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:26:21.471429Z","iopub.execute_input":"2021-09-14T15:26:21.472576Z","iopub.status.idle":"2021-09-14T15:26:21.529326Z","shell.execute_reply.started":"2021-09-14T15:26:21.472533Z","shell.execute_reply":"2021-09-14T15:26:21.528624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Hyper-parameter Tuning","metadata":{}},{"cell_type":"code","source":"params_ET_RF = {\n'n_jobs' : [-1],\n'n_estimators' : [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200],\n'criterion' : ['mse', 'mae'],\n'max_depth' : [5, 10, 15, 20, 25, 30],\n'max_features' : ['auto', 'sqrt'],\n'min_samples_split' : [2, 5, 10, 15, 100],\n'min_samples_leaf' : [1, 2, 5, 10]\n}\n\nparams_XGBRegressor = {\n'n_jobs' : [-1],\n'learning_rate' : [0.05, 0.1, 0.15, 0.2, 0.25, 0.3],\n'max_depth' : [3,4,5,6,8,10,12,15],\n'n_estimators' : [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200],\n\"min_child_weight\" : [1,3,5,7],\n\"gamma\" : [0.0, 0.1, 0.2, 0.3, 0.4],\n\"colsample_bytree\" : [0.3, 0.4, 0.5, 0.6]\n}\n","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:26:21.533235Z","iopub.execute_input":"2021-09-14T15:26:21.535437Z","iopub.status.idle":"2021-09-14T15:26:21.54791Z","shell.execute_reply.started":"2021-09-14T15:26:21.535397Z","shell.execute_reply":"2021-09-14T15:26:21.546731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"regressors = [ExtraTreesRegressor(), RandomForestRegressor(), xgb.XGBRegressor()]\nparams = [params_ET_RF, params_ET_RF, params_XGBRegressor]\nnames = ['ExtraTreesRegressor', 'RandomForestRegressor', 'XGBRegressor']\n# looping through each regressor\nfor i in range(3):\n    cv_regressor = RandomizedSearchCV(regressors[i], param_distributions = params[i], n_iter = 5, scoring = 'neg_mean_squared_error', n_jobs=-1, cv = 5)\n    # scorings='roc_auc' for classification problems\n    # scorings='neg_mean_squared_error' for regression problems\n\n    cv_regressor.fit(x_train_final,y_train)\n\n    print(\"************\",names[i],\"************\")\n    print(\"Best estimators: \\n {}\".format(cv_regressor.best_estimator_))\n    print()\n    print(\"Best score: \\n {}\".format(cv_regressor.best_score_))\n    print()\n    print(\"Best parameters: \\n {}\".format(cv_regressor.best_params_))\n    print()\n    print()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:26:53.890752Z","iopub.execute_input":"2021-09-14T15:26:53.8915Z","iopub.status.idle":"2021-09-14T15:29:45.429621Z","shell.execute_reply.started":"2021-09-14T15:26:53.891463Z","shell.execute_reply":"2021-09-14T15:29:45.428778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### XGBRegressor performed best","metadata":{}},{"cell_type":"markdown","source":"### Final Prediction","metadata":{}},{"cell_type":"code","source":"# defination of final model\nfinal_model = xgb.XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n             colsample_bynode=1, colsample_bytree=0.3, gamma=0.3, gpu_id=-1,\n             importance_type='gain', interaction_constraints='',\n             learning_rate=0.05, max_delta_step=0, max_depth=3,\n             min_child_weight=5,  monotone_constraints='()',\n             n_estimators=1100, n_jobs=-1, num_parallel_tree=1, random_state=0,\n             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n             tree_method='exact', validate_parameters=1, verbosity=None)\n\n# fitting and prediction\nfinal_model.fit(x_train_final, y_train)\npredictions = final_model.predict(x_test_final)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:32:46.277825Z","iopub.execute_input":"2021-09-14T15:32:46.278404Z","iopub.status.idle":"2021-09-14T15:32:47.090876Z","shell.execute_reply.started":"2021-09-14T15:32:46.278368Z","shell.execute_reply":"2021-09-14T15:32:47.090095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Performance Metrics","metadata":{}},{"cell_type":"code","source":"from sklearn import metrics\n\n# performance metrices\nprint('MAE:', metrics.mean_absolute_error(y_test, predictions))\nprint('MSE:', metrics.mean_squared_error(y_test, predictions))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n\n\nimport pickle\n# open a file, where you ant to store the data\nfile = open('final_model.pkl', 'wb')\n\n# dump information to that file\npickle.dump(final_model, file)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T15:33:15.978303Z","iopub.execute_input":"2021-09-14T15:33:15.97899Z","iopub.status.idle":"2021-09-14T15:33:16.038311Z","shell.execute_reply.started":"2021-09-14T15:33:15.97896Z","shell.execute_reply":"2021-09-14T15:33:16.037387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}