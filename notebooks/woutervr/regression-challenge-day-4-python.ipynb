{"nbformat_minor":1,"cells":[{"source":"Welcome to day 4 of the regression challenge! So far we've been focusing on examples where we are looking at the effect of **one** input variable on a specific output variable. Today, we're going to be looking at predicting a single output variable using multiple input variables. This is known as \"multiple regression\".\n\nWe're going to be using all the skills we've learned so far, so feel free to head back to the previous day's challenges if you need a quick refresher:\n\n* [Day 1: Learned about different types of regression (Poisson, linear and logistic) and when to use them](https://www.kaggle.com/rtatman/regression-challenge-day-1)\n* [Day 2: Learned how to fit & evaluate a model with diagnostic plots](https://www.kaggle.com/rtatman/regression-challenge-day-2)\n* [Day 3: Learned how to read and understand models](https://www.kaggle.com/rtatman/regression-challenge-day-3)\n\nIf you're already caught up, we can get right to down to fitting and examining a model using multiple regression! \n___\n\n<center>\n[**You can check out a video that goes with this notebook by clicking here.**](https://www.youtube.com/embed/iN8Rl8sIzVg)","cell_type":"markdown","metadata":{"_cell_guid":"845c5e6c-417f-45fb-bd30-924b32a17e7b","_uuid":"72c16084810825369926caf530810ab39e84fbbf"}},{"source":"## Example: Predicting BMI\n___\n\nFor my multiple regression example, I'm going to be using a dataset of health and eating habits of Americans collected by the US Bureau of Labor Statistics. I'm going to see if we can predict BMI (body mass index, intended to be a rough measure of body fat) using height, weight, how much time each person spends exercising and how much time each person spends eating. \n\nI'm also reading a dataset of New York City census data for you to use in your exercises.","cell_type":"markdown","metadata":{"_cell_guid":"bdb03078-ec0d-4631-b54a-7d37d8cdf4bf","_uuid":"a559ec0d901929b8f226eb2fc1f881f291f7b853"}},{"outputs":[],"execution_count":null,"source":"import pandas as pd\n\n# read in our data \nbmi_data = pd.read_csv(\"../input/eating-health-module-dataset//ehresp_2014.csv\")\nnyc_census = pd.read_csv(\"../input/new-york-city-census-data/nyc_census_tracts.csv\")","cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"51e1cdbf-9e5a-4652-8a20-95849c398425","_uuid":"eaa2c9667225279c0d6565c93cc57f375b094bfd"}},{"outputs":[],"execution_count":null,"source":"# remove rows where the reported BMI is less than 0 (impossible)\nbmi_data = bmi_data[bmi_data['erbmi']>0]","cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"b2056e2d-df7e-4c55-9220-cef0ecedfc4d","_uuid":"bf195dfefe68d3402ec9ba7c00ca2977c8025ba3"}},{"source":"The columns names in the bmi_data dataset aren't very helpful, so I've checked [the documentation](https://www.bls.gov/tus/ehmintcodebk1416.pdf) to figure out which columns have the information I want. After looking through the documentation, I picked out these five variables:\n\n* erbmi = body mass index (this is what I'm going to try to predict!)\n* euexfreq = how many times in the past week the person exercised (outside of their job)\n* euwgt = weight, in pounds\n* euhgt = height, in inches\n* ertpreat = amount of time spent eating and drinking (in minutes) over the past week \n\nWith this in mind, I'm going to use the same formula notation we've been using the past few days. I'm just adding four terms instead of one:","cell_type":"markdown","metadata":{"_cell_guid":"67af99b1-1d13-4ab1-99a1-8b67b72dfe18","_uuid":"7407d221a85caf5e1e3144f82fd1b94169b14fef"}},{"outputs":[],"execution_count":null,"source":"X = bmi_data[['euexfreq', 'euwgt', 'euhgt', 'ertpreat']]\ny = bmi_data['erbmi']\n# fit a glm model\nfrom sklearn.linear_model import LinearRegression\nreg = LinearRegression()\nreg.fit(X,y)","cell_type":"code","metadata":{"_cell_guid":"12c72664-4331-497d-94b9-6c261bcb2574","_uuid":"89a2a2ffec1ff63966e11f7832a511e91c0cc088"}},{"source":"Now that we've fit our model, let's check out some diagnostic plots. I'm using the plot() function, so we're going to get very slightly different plots than with would with the glm.diag.plots() function from the boot package. ","cell_type":"markdown","metadata":{"_cell_guid":"8a804129-fe12-4ed8-b464-725b9666d25a","_uuid":"9a28ed9b81c1863fb88e4dbebf6c85edc173bdd5"}},{"outputs":[],"execution_count":null,"source":"import matplotlib.pyplot as plt\ny_pred = reg.predict(X)\nresidual = y - y_pred\nplt.scatter(y_pred,residual)","cell_type":"code","metadata":{"_cell_guid":"826bc0e1-21f1-42f2-b4fd-d34bcac0e895","_uuid":"c635de7649aa531b6d4138b59a934eb4d3d5b03e"}},{"source":"The top two plots are pretty much the same as the ones we saw on day 2, but the bottom two are slightly different.\n\n* **Residuals vs. predicted values**: We don't want to see a pattern here, it should just sort of look like a cloud & the red line in the middle should be more-or-less flat. The pattern we see here, with bigger residuals towards the sides and smaller ones in the center, means that our model is much more accurate for values in the middle range than extreme values (either very high or very low).\n* **Normal Q-Q**: We want all our points to be on that dotted line and the line to go across the center diagonal of the plot. The fact that a lot of our residuals are above or below the line suggests that there's a strong skew in our data.\n* **Scale-Location**:  This helps you see if your data points are spread out evenly along your predictors (for example, making sure that 20 out of 25 cantaloupes all weigh exactly 1 pound, which might suggest something is up with your dataset). You want points to be scattered randomly and the red line in the middle to be flat(ish). This plot suggests that we have a strong skew in our data. (Which is the same thing the other plots have been telling us).\n* **Residuals vs. Leverage**:  This plot will help you look for outliers. If you can see a dotted red line between the bulk of the points and one or two off on their own, those outliers are strongly affecting your analysis. Here we don't have any strong outliers to worry about.\n\nThese plots are telling us that we have a pretty strong skew in our data. We can probably trust the predictions we make towards the center of our range (since residuals are very low around 30), but the further away we move from the mean the less we can trust our model. If we want accurate predictions across the range of possible BMI's we probably don't want to use this model. **We can still continue investigating our model, but we should be very cautious in interpreting our results!**\n\nNow that we're aware of some of the pitfalls with this model, we can examine it more closely.","cell_type":"markdown","metadata":{"_cell_guid":"79daa66a-a7b6-4a8d-bb57-e665f19d927d","_uuid":"8a5bfe4fe37f2e59dd51e86bae566c591316c7ce"}},{"outputs":[],"execution_count":null,"source":"# examine our model\nprint('coefficient = ' + str(reg.coef_))\nprint('intercept = ' + str(reg.intercept_))","cell_type":"code","metadata":{"_cell_guid":"8a1bbf6b-1622-44cb-8248-3446d27dd25b","_uuid":"e85ae7484aed019e538447bc7069988228824837"}},{"source":"Looking at our model, we can tell that we're pretty sure that the average BMI isn't 0, since the intercept is pretty far from 0 and the standard error for it is relatively small (less than 10% of the estimate). Using that same metric, we can also tell that both weight (euwgt) and height (euhgt) are probably important, but that neither how often someone exercises (euexfreq) nor how much time they spend eating (ertpreat) seem to be particularly informative.\n\nWe can also see that all our inputs together are very helpful because there's a large difference between the residual deviance and the null deviance.\n\nSo, while we do want to be careful with interpreting this model given that we know it doesn't handle extreme values well, it looks like both weight and height are important for predicting BMI. (Which is good, since BMI is calculated using both weight and height!)\n\nWe can double check this using Added-Variable Plots, also known as partial-regression plots. AV Plots are a set of plots, one for each of your input variables, where it shows you what happens to your output variables if you hold all but one input variable stable and just change that one input variable. Each observation is represented by a single point on the plot, and the coefficient is shown using a red line.\n\nYou can read these a bit like correlation plots: if an input variable is important, there will be a strong linear pattern in the points and the line will have a slope that's very different from 0. If an input variable isn't important, you won't see a strong pattern in the dots and the red line will just be a flat line at 0.","cell_type":"markdown","metadata":{"_cell_guid":"c538c76c-bcd7-4092-9b99-48b50fce0111","_uuid":"e70503466d23cdbce96bdf169f0e75e005404bdd"}},{"outputs":[],"execution_count":null,"source":"# added-variable plots for our model","cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"d98d4970-b6fc-429d-a7af-332760f6335f","_uuid":"261476a1bf439aa8dec9312b31e333e469b67656"}},{"source":"Looking at these plots, we can see by looking in the top right corner that as euwgt (weight) increases, so does erbmi (BMI, the variable we're trying to predict). Looking at the bottom left corner we can see that as euhgt (height) increases, erbmi actually **decreases**. So both height and weight are important, but they have the opposite effect! We can also tell this from our model summary because euwgt had a *positive* estimate, while euhgt had a *negative* estimate.\n\nThe other two plots show that there's not a strong relationship between those variables and the one we're trying to predict, which we already figured out from our model.\n\nAnd that's it for multiple regression! Now it's time for you to try it yourself. :)\n\n> If you're really dying to know how to fit a model that's a better representation of this particular dataset, you can check out [this notebook](https://www.kaggle.com/rtatman/regression-challenge-day-4-gamma-distribution/), but you don't need it to work on your assignment for today.","cell_type":"markdown","metadata":{"_cell_guid":"b98273af-3800-4757-836b-a050eba41626","_uuid":"34a031308f3b20345c103d11adbf089b6bb8a884"}},{"source":"## Your turn!\n___\n\nNow it's your turn to come up with a model and interpret it!\n\n1. Pick a question to answer to using the NYC Census dataset. Pick a variable to predict and at least three variables to use to predict it.\n2. Fit a GLM model of the appropriate family. (Check out [Monday's challenge](https://www.kaggle.com/rtatman/regression-challenge-day-1) if you need a refresher).\n3. Plot diagnostic plots for your model. Does it seem like your model is a good fit for your data? If you're fitting a linear or Poisson model, are the residuals normally distributed (no patterns in the first plot and the points in the second plot are all in a line)? Are there any influential outliers?\n4. Check out your model using the summary() function. Which, if any, input variables have a strong relationship to the output variable you're predicting?\n5. Plot your output variables using the avPlot() function. Do the plots agree with your interpretation of the model summary? \n6. *Optional:* If you want to share your analysis with friends or to ask for help, you’ll need to make it public so that other people can see it.\n    * Publish your kernel by hitting the big blue “publish” button. (This may take a second.)\n    * Change the visibility to “public” by clicking on the blue “Make Public” text (right above the “Fork Notebook” button).\n    * Tag your notebook with 5daychallenge","cell_type":"markdown","metadata":{"_cell_guid":"3efed215-8f19-41a9-ae8d-9a19ec8a4b8f","_uuid":"d451068d6ff4c5e0f07d18866bfe1ad9d07eb51a"}},{"outputs":[],"execution_count":null,"source":"nyc_census.head()","cell_type":"code","metadata":{"_cell_guid":"dd9976aa-bc3d-4c57-a5e6-8a90efea4ffd","_uuid":"4da1b3004a8f89ba4bf7d351466569076cc0ef72"}},{"outputs":[],"execution_count":null,"source":"nyc_census.columns","cell_type":"code","metadata":{"_cell_guid":"3e6251bb-f97d-42d2-9793-c44b5a67f43a","_uuid":"403ba5650cac4517790604388739d19231972c14"}},{"outputs":[],"execution_count":null,"source":"selected_nyc_census = nyc_census[['Unemployment', 'Hispanic', 'White', 'Black', 'Native']]\nselected_nyc_census = selected_nyc_census.dropna()\nX = selected_nyc_census[['Hispanic', 'White', 'Black', 'Native']]\ny = selected_nyc_census['Unemployment']","cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"3a51924f-3951-4b5f-9826-afbca2fce3fe","_uuid":"7b65009a68b975f5b36eb485e6138f09a72fc2a8"}},{"outputs":[],"execution_count":null,"source":"# fit a glm model\nfrom sklearn.linear_model import LinearRegression\nreg = LinearRegression()\nreg.fit(X,y)","cell_type":"code","metadata":{"_cell_guid":"8e7c5cae-1082-4fb0-a73d-e8f1fae9000c","_uuid":"b45773761f9eba2cb8980ac2278b0ed846253a0c"}},{"outputs":[],"execution_count":null,"source":"y_pred = reg.predict(X)\nresidual = y - y_pred\nplt.scatter(y_pred,residual)","cell_type":"code","metadata":{"_cell_guid":"ab1568ba-1eab-4f14-bb4e-a25150213874","_uuid":"60d7dbf33a998054c8c0158bcfa50dc2a8b0995b"}},{"outputs":[],"execution_count":null,"source":"# examine our model\nprint('coefficient = ' + str(reg.coef_))\nprint('intercept = ' + str(reg.intercept_))","cell_type":"code","metadata":{"_cell_guid":"cd5d83e6-b0f8-465e-9f07-c8dba37b730b","_uuid":"248000ad5fe1790611e3c1edace5ea22eeab1537"}},{"source":"Want more? Ready for a different dataset? [This notebook](https://www.kaggle.com/rtatman/datasets-for-regression-analysis/) has additional dataset suggestions for you to practice regression with. ","cell_type":"markdown","metadata":{"_cell_guid":"0ec5af26-fb2a-4cf7-a9f5-39297eb5572a","_uuid":"35f0962be93a57fb6047c1a5e0581232cd91dc76"}}],"nbformat":4,"metadata":{"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3","name":"python","mimetype":"text/x-python"}}}