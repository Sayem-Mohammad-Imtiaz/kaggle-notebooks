{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 7 Models to Predict Death Causes by Heart Failure","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Index \n\n1. Data Preparation     \n2. Exploratory Data Analysis    \n   * Heatmap to Invertigate Correlation in Data\n   * Countplot for Binary Features\n   * Bivariate Analysis for Continous Variables    \n3. Prediction Algorithms    \n   * Logistic Regression\n   * Support Vector Machine (SVM)\n   * Decision Tree\n   * Random Forest\n   * Gradient Boosting Classifier\n   * LGBM\n   * XgBoost           \n4. Conclusion \n    ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 1. Data Preparation","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport plotly.express as px \nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read csv file into dataframe\ndf = pd.read_csv('../input/heart-failure-clinical-data/heart_failure_clinical_records_dataset.csv')\n\n# Show dataframe\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Understand data\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for missing data\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2 Exploratory Data Analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Heatmap to Invertigate Correlation in Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set()\n\nfig, ax = plt.subplots(figsize=(9, 6))\nsns.heatmap(df.corr(), linewidths=.5, ax=ax, cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Countplot for Binary Features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_style('white') \nfig, ax = plt.subplots(3,2,figsize=(13,15))\nsns.countplot(df['anaemia'], palette='Pastel1', ax=ax[0][0])\nsns.countplot(df['diabetes'], palette='Set3', ax=ax[0][1])\nsns.countplot(df['high_blood_pressure'], palette='Set2', ax=ax[1][0])\nsns.countplot(df['sex'], palette='Set1', ax=ax[1][1])\nsns.countplot(df['smoking'], palette='Pastel2', ax=ax[2][0])\nsns.countplot(df['DEATH_EVENT'], palette='Accent', ax=ax[2][1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Bivariate Analysis for Continous Variables","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(6,1,figsize=(13,20))\nplt.suptitle('Bivariate Analysis (Hue=Sex)', fontsize=20)\nplt.tight_layout(4)\n\nsns.lineplot(data=df, x='age', y='creatinine_phosphokinase', hue='sex', lw=2, ax=ax[0])\nsns.lineplot(data=df, x='age', y='ejection_fraction', hue='sex', lw=2, ax=ax[1])\nsns.lineplot(data=df, x='age', y='platelets', hue='sex', lw=2, ax=ax[2])\nsns.lineplot(data=df, x='age', y='serum_creatinine', hue='sex', lw=2, ax=ax[3])\nsns.lineplot(data=df, x='age', y='serum_sodium', hue='sex', lw=2, ax=ax[4])\nsns.lineplot(data=df, x='age', y='time', hue='sex', lw=2, ax=ax[5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(6,1,figsize=(13,20))\nplt.suptitle('Bivariate Analysis (Hue=Death)', fontsize=20)\nplt.tight_layout(4)\n\nsns.lineplot(data=df, x='age', y='creatinine_phosphokinase', hue='DEATH_EVENT', lw=2, ax=ax[0])\nsns.lineplot(data=df, x='age', y='ejection_fraction', hue='DEATH_EVENT', lw=2, ax=ax[1])\nsns.lineplot(data=df, x='age', y='platelets', hue='DEATH_EVENT', lw=2, ax=ax[2])\nsns.lineplot(data=df, x='age', y='serum_creatinine', hue='DEATH_EVENT', lw=2, ax=ax[3])\nsns.lineplot(data=df, x='age', y='serum_sodium', hue='DEATH_EVENT', lw=2, ax=ax[4])\nsns.lineplot(data=df, x='age', y='time', hue='DEATH_EVENT', lw=2, ax=ax[5])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Prediction Algorithms","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom imblearn.over_sampling import SMOTE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y = df['DEATH_EVENT']\nX = df[['age', 'anaemia', 'creatinine_phosphokinase', 'diabetes',\n       'ejection_fraction', 'high_blood_pressure', 'platelets',\n       'serum_creatinine', 'serum_sodium', 'sex', 'smoking', 'time']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# SMOTE: Synthetic Minority Over-sampling Technique\nX_smote,Y_smote = SMOTE().fit_sample(X,Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(X_smote, Y_smote, stratify = Y_smote, test_size=0.2, random_state=52)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Shape of X_train:', X_train.shape)\nprint('Shape of X_test:', X_test.shape)\nprint('Shape of Y_train:', Y_train.shape)\nprint('Shape of Y_test:', Y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report \nfrom sklearn.linear_model import LogisticRegression\nimport scikitplot as skplt\n\nlogis = LogisticRegression(random_state=0, solver='lbfgs')\nmodel = logis.fit(X_train, Y_train)\nY_predict = model.predict(X_test)\n\nskplt.metrics.plot_confusion_matrix(Y_test, Y_predict, figsize=(8,8), \n                                    title='Confusion Matrix: Logistic Regression',\n                                    normalize=True,\n                                    cmap='Blues')\n\nprint(classification_report(Y_test, Y_predict))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Support Vector Machine (SVM)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import svm\n\nsvm = svm.SVC(kernel='linear', C = 1)\nmodel = svm.fit(X_train, Y_train)\nY_predict = model.predict(X_test)\n\nskplt.metrics.plot_confusion_matrix(Y_test, Y_predict, figsize=(8,8), \n                                    title='Confusion Matrix: SVM',\n                                    normalize=True,\n                                    cmap='Blues')\n\nprint(classification_report(Y_test, Y_predict))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Decision Tree","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\ndt = DecisionTreeClassifier()\nmodel = dt.fit(X_train, Y_train)\nY_predict = model.predict(X_test)\n\nskplt.metrics.plot_confusion_matrix(Y_test, Y_predict, figsize=(8,8), \n                                    title='Confusion Matrix: Decision Tree',\n                                    normalize=True,\n                                    cmap='Blues')\n\nprint(classification_report(Y_test, Y_predict))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(n_estimators=50)\nmodel = rf.fit(X_train, Y_train)\nY_predict = model.predict(X_test)\n\nskplt.metrics.plot_confusion_matrix(Y_test, Y_predict, figsize=(8,8), \n                                    title='Confusion Matrix: Random Forest',\n                                    normalize=True,\n                                    cmap='Blues')\n\nprint(classification_report(Y_test, Y_predict))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Gradient Boosting Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\n\ngb = GradientBoostingClassifier()\nmodel = gb.fit(X_train, Y_train)\nY_predict = model.predict(X_test)\n\nskplt.metrics.plot_confusion_matrix(Y_test, Y_predict, figsize=(8,8), \n                                    title='Confusion Matrix: Gradient Boosting Classifier',\n                                    normalize=True,\n                                    cmap='Blues')\n\nprint(classification_report(Y_test, Y_predict))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### LGBM","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\nfrom lightgbm import LGBMClassifier\n\nlgbm = LGBMClassifier()\nmodel = lgbm.fit(X_train, Y_train)\nY_predict = model.predict(X_test)\n\nskplt.metrics.plot_confusion_matrix(Y_test, Y_predict, figsize=(8,8), \n                                    title='Confusion Matrix: LGBM',\n                                    normalize=True,\n                                    cmap='Blues')\n\nprint(classification_report(Y_test, Y_predict))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show importance features\nplt.figure()\nlgb.plot_importance(model)\nplt.title(\"Feature Importances\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### XgBoost","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost\nfrom xgboost import XGBClassifier\n\nxgb = XGBClassifier()\nmodel = xgb.fit(X_train, Y_train)\nY_predict = model.predict(X_test)\n\nskplt.metrics.plot_confusion_matrix(Y_test, Y_predict, figsize=(8,8), \n                                    title='Confusion Matrix: XgBoost',\n                                    normalize=True,\n                                    cmap='Blues')\n\nprint(classification_report(Y_test, Y_predict))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\nxgboost.plot_importance(model)\nplt.title(\"Feature Importances\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Results","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Below is the accuracy of each model in descending order:\n* Ramdom Forest : 0.93\n* Gradient Boosting Classifier : 0.90\n* XgBoost : 0.89\n* Decision Tree : 0.88\n* Logistic Regression : 0.87\n* LGBM : 0.87\n* Support Vector Machine (SVM) : 0.76\n","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}