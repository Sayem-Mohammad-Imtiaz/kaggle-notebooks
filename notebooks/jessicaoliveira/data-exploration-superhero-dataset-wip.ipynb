{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input/superhero-set\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":3,"outputs":[{"output_type":"stream","text":"['heroes_information.csv', 'super_hero_powers.csv']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_information = pd.read_csv(\"../input/superhero-set/heroes_information.csv\")\ndf_information.head()\ndf = df_information.copy()","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Know your data\nExtract some information to help you deal with missing data"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.shape)\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From info method, you can check columns names, type of data for each column, and non-null values count, from which it can be count all null values. But for a more clean information on that, we can use the isnull method:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To calculate the percentage of missing data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum().sum()/df.shape[1]","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"1.5454545454545454"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"What about other values that can be considered as empty values, like string columns with empty strings or values with \"-\"?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# this way even empty strings are counted as null \ndf.replace('', np.nan).isnull().sum()\ndf.replace('[-|]', np.nan, regex=True).isnull().sum()","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"Unnamed: 0      0\nname           54\nGender         29\nEye color     172\nRace          312\nHair color    172\nHeight          0\nPublisher      35\nSkin color    663\nAlignment       7\nWeight          2\ndtype: int64"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Or negative values for height and weight, what wouldn't make sense"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df[df['Height'] < 0].shape)\ndf[df['Weight'] < 0].shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Those values are better being treated as NaN"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[df['Height'] < 0] = np.nan\ndf.loc[df['Weight'] < 0] = np.nan","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Is important to look for duplicate rows! The method duplicated can do the trick."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"But sometimes is more important to look for duplicated values in specific columns, like Heros name, in that case. You can check how many duplicated values, see a list of them, or see the entire rows they appear, to have a better look at wha is going on."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df['name'].duplicated().sum())\nprint(df[df['name'].duplicated(keep=False)]['name'].unique())\nprint(df[df[['name']].duplicated(keep=False)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df[['name', 'Gender', 'Publisher']].duplicated().sum())\ndf[df[['name', 'Gender', 'Publisher']].duplicated(keep=False)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For numeric values, descirbe method is quite handy!"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data frame can be separeted in two subdatasets, with numerical an non-numerical values:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_num = df.select_dtypes(include=['float64', 'int64'])\ndf_obj = df.select_dtypes(include=['object'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For categorical data, we can list categories and count the number of entries in each categorie:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df['Gender'].unique())\ndf['Gender'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plotting data can be helpfull, and we are doing that with Seaborn"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.countplot(df['Gender'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Its a good thing to check data distribution by a histogram, for numeric values"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['Height'], bins=10, kde=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['Weight'], bins=10, kde=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Correlation (WIP)"},{"metadata":{},"cell_type":"markdown","source":"### References: \nhttps://towardsdatascience.com/be-a-more-efficient-data-scientist-today-master-pandas-with-this-guide-ea362d27386\nhttps://towardsdatascience.com/10-python-pandas-tricks-that-make-your-work-more-efficient-2e8e483808ba"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}