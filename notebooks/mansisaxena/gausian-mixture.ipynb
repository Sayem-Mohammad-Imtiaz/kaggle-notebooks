{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Using Gaussian Clustering and PCA Techniques to make clusters of the Credit Car data**","metadata":{}},{"cell_type":"markdown","source":"This notebook explains in detail the implementation of the gaussian mixture model using the expectation maximization for an appropriate data set and validating the clusters properly with the help of various external validation measures.","metadata":{}},{"cell_type":"markdown","source":"## Importing the data and necessary libraries ","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt \nfrom pandas import DataFrame \nfrom sklearn.preprocessing import StandardScaler, normalize\nfrom sklearn.decomposition import PCA\nfrom sklearn.mixture import GaussianMixture \nfrom sklearn.metrics import silhouette_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-07-19T11:30:14.383795Z","iopub.execute_input":"2021-07-19T11:30:14.384326Z","iopub.status.idle":"2021-07-19T11:30:15.785267Z","shell.execute_reply.started":"2021-07-19T11:30:14.384228Z","shell.execute_reply":"2021-07-19T11:30:15.784429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/ccdata/CC GENERAL.csv')","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-07-19T11:30:15.786602Z","iopub.execute_input":"2021-07-19T11:30:15.787045Z","iopub.status.idle":"2021-07-19T11:30:15.863502Z","shell.execute_reply.started":"2021-07-19T11:30:15.786996Z","shell.execute_reply":"2021-07-19T11:30:15.862622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-19T11:30:15.865104Z","iopub.execute_input":"2021-07-19T11:30:15.865576Z","iopub.status.idle":"2021-07-19T11:30:15.90469Z","shell.execute_reply.started":"2021-07-19T11:30:15.865526Z","shell.execute_reply":"2021-07-19T11:30:15.903993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing the data and applying PCA\n\n1. Dropping Customer ID as it does not provide useful information for clustering\n2. Standardising and Normalising the data. This prevents one attribute from having a greater influence on clustering than another as the data is now uniform. \n3. Creating DataFrame of the uniform  data.\n4. Applying PCA to reduce the data to 2 dimensions. This data is plotted. ","metadata":{}},{"cell_type":"code","source":"df1 = df.drop('CUST_ID', axis = 1) \ndf1.fillna(method ='bfill', inplace = True) ","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-07-19T11:30:15.90604Z","iopub.execute_input":"2021-07-19T11:30:15.906472Z","iopub.status.idle":"2021-07-19T11:30:15.918896Z","shell.execute_reply.started":"2021-07-19T11:30:15.906424Z","shell.execute_reply":"2021-07-19T11:30:15.917979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Standardize data\nscaler = StandardScaler() \nscaled_df = scaler.fit_transform(df1) ","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-07-19T11:30:15.920211Z","iopub.execute_input":"2021-07-19T11:30:15.920571Z","iopub.status.idle":"2021-07-19T11:30:15.94295Z","shell.execute_reply.started":"2021-07-19T11:30:15.920541Z","shell.execute_reply":"2021-07-19T11:30:15.941882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Normalizing the Data \nnormalized_df = normalize(df1) ","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-07-19T11:30:15.944653Z","iopub.execute_input":"2021-07-19T11:30:15.944971Z","iopub.status.idle":"2021-07-19T11:30:15.952833Z","shell.execute_reply.started":"2021-07-19T11:30:15.944922Z","shell.execute_reply":"2021-07-19T11:30:15.951801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Converting the numpy array into a pandas DataFrame \nnormalized_df = pd.DataFrame(normalized_df) ","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-07-19T11:30:15.954837Z","iopub.execute_input":"2021-07-19T11:30:15.955154Z","iopub.status.idle":"2021-07-19T11:30:15.965887Z","shell.execute_reply.started":"2021-07-19T11:30:15.955127Z","shell.execute_reply":"2021-07-19T11:30:15.964585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reducing the dimensions of the data \npca = PCA(n_components = 3) \npcadf = pca.fit_transform(normalized_df) \npcadf = pd.DataFrame(pcadf) \npcadf.columns = ['Principal Component 1', 'Principal Component 2', 'Principal Component 3'] \n  \npcadf.head(10)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-07-19T11:30:15.967089Z","iopub.execute_input":"2021-07-19T11:30:15.967393Z","iopub.status.idle":"2021-07-19T11:30:16.28075Z","shell.execute_reply.started":"2021-07-19T11:30:15.967362Z","shell.execute_reply":"2021-07-19T11:30:16.279555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(12, 8))\nscatter = ax.scatter(pcadf['Principal Component 1'],\n                     pcadf['Principal Component 2'], \n                     c = pcadf['Principal Component 3'],\n                     alpha=0.6)\nplt.title('Plotting the 3-Dimensional data after PCA is applied', fontsize = 20)\nplt.xlabel('Principal Component 1', fontsize = 15)\nplt.ylabel('Principal Component 2', fontsize = 15)\nplt.legend(*scatter.legend_elements(), loc=\"best\", title=\"Principal\\nComponent 3\")\nax.plot([])\nax.grid()\nplt.show()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-07-19T11:30:16.284287Z","iopub.execute_input":"2021-07-19T11:30:16.284799Z","iopub.status.idle":"2021-07-19T11:30:17.24436Z","shell.execute_reply.started":"2021-07-19T11:30:16.284746Z","shell.execute_reply":"2021-07-19T11:30:17.24332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca.explained_variance_ratio_","metadata":{"execution":{"iopub.status.busy":"2021-07-19T11:30:17.245939Z","iopub.execute_input":"2021-07-19T11:30:17.246223Z","iopub.status.idle":"2021-07-19T11:30:17.252145Z","shell.execute_reply.started":"2021-07-19T11:30:17.246195Z","shell.execute_reply":"2021-07-19T11:30:17.251236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Elbow Method ","metadata":{}},{"cell_type":"code","source":"import seaborn as sns; sns.set()\nfrom sklearn.cluster import KMeans\n\nsse = []\nK = range(1,10)\nfor k in K:\n    kmeanModel = KMeans(n_clusters=k)\n    kmeanModel.fit(df1)\n    sse.append(kmeanModel.inertia_)\nplt.figure(figsize=(15,6))\nplt.plot(K, sse, 'bx-')\nplt.xlabel('Number of Clusters (k)', fontsize = 15)\nplt.ylabel('Sum of Squared Error', fontsize = 15)\nplt.title('The Elbow Method showing the optimal k \\n(For data without PCA applied)', fontsize = 20)\nplt.show()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-07-19T11:30:17.253641Z","iopub.execute_input":"2021-07-19T11:30:17.253919Z","iopub.status.idle":"2021-07-19T11:30:41.580585Z","shell.execute_reply.started":"2021-07-19T11:30:17.253889Z","shell.execute_reply":"2021-07-19T11:30:41.579641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will choose 3 as k value here","metadata":{}},{"cell_type":"code","source":"import seaborn as sns; sns.set()\nfrom sklearn.cluster import KMeans\n\nsse = []\nK = range(1,10)\nfor k in K:\n    kmeanModel = KMeans(n_clusters=k)\n    kmeanModel.fit(pcadf)\n    sse.append(kmeanModel.inertia_)\nplt.figure(figsize=(15,6))\nplt.plot(K, sse, 'bx-')\nplt.xlabel('Number of Clusters (k)', fontsize = 15)\nplt.ylabel('Sum of Squared Error', fontsize = 15)\nplt.title('The Elbow Method showing the optimal k \\n(For data with PCA applied)', fontsize = 20)\nplt.show()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-07-19T11:30:41.584284Z","iopub.execute_input":"2021-07-19T11:30:41.586097Z","iopub.status.idle":"2021-07-19T11:30:59.018011Z","shell.execute_reply.started":"2021-07-19T11:30:41.586048Z","shell.execute_reply":"2021-07-19T11:30:59.016958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will choose k as 3 here ","metadata":{}},{"cell_type":"code","source":"import matplotlib\nmatplotlib.rc_file_defaults()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-07-19T11:30:59.01943Z","iopub.execute_input":"2021-07-19T11:30:59.019793Z","iopub.status.idle":"2021-07-19T11:30:59.027567Z","shell.execute_reply.started":"2021-07-19T11:30:59.01976Z","shell.execute_reply":"2021-07-19T11:30:59.025278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Applying the Gaussian Mixture Model to cluster our data (PCA-applied) into 3 clusters","metadata":{}},{"cell_type":"code","source":"gmm = GaussianMixture(n_components = 3) \ngmm.fit(pcadf)","metadata":{"execution":{"iopub.status.busy":"2021-07-19T11:30:59.029203Z","iopub.execute_input":"2021-07-19T11:30:59.029866Z","iopub.status.idle":"2021-07-19T11:30:59.29634Z","shell.execute_reply.started":"2021-07-19T11:30:59.029817Z","shell.execute_reply":"2021-07-19T11:30:59.295572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize = (7, 7))\nplt.suptitle(\"Plotting the 3 component with colors representing clusters\", fontsize = 15)\n             \nx, s1 = pcadf['Principal Component 1'], \"Principal Component 1\"\ny, s2 = pcadf['Principal Component 2'], \"Principal Component 2\"\nz, s3 = pcadf['Principal Component 3'], \"Principal Component 3\"\n\nc = gmm.fit_predict(pcadf) \n\nax = fig.add_subplot(111, projection = '3d')\nax.scatter(x, y, z, c = c, s=0.5, alpha = 1)\nplt.title('x axis : P1 | y axis : P2 | z axis : P3')\nax.set_xlabel(s1, fontsize = 13)\nax.set_ylabel(s2, fontsize = 13)\nax.set_zlabel(s3, fontsize = 13)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-19T11:30:59.297598Z","iopub.execute_input":"2021-07-19T11:30:59.300686Z","iopub.status.idle":"2021-07-19T11:31:00.123683Z","shell.execute_reply.started":"2021-07-19T11:30:59.300637Z","shell.execute_reply":"2021-07-19T11:31:00.122843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Applying the Gaussian Mixture Model to cluster our data (without PCA) into 3 clusters","metadata":{}},{"cell_type":"code","source":"gmm1 = GaussianMixture(n_components = 3) \ngmm1.fit(df1)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-07-19T11:31:00.127294Z","iopub.execute_input":"2021-07-19T11:31:00.129275Z","iopub.status.idle":"2021-07-19T11:31:02.667651Z","shell.execute_reply.started":"2021-07-19T11:31:00.129226Z","shell.execute_reply":"2021-07-19T11:31:02.666576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## External Evaluation Metric","metadata":{}},{"cell_type":"markdown","source":"#### A. For data with PCA applied","metadata":{}},{"cell_type":"code","source":"y_pred = gmm.predict(pcadf)\npred = pd.DataFrame(y_pred)\npred.columns = ['Type']\n\nprediction = pd.concat([pcadf, pred], axis = 1)\n\nclus0 = prediction.loc[prediction.Type == 0]\nclus1 = prediction.loc[prediction.Type == 1]\nclus2 = prediction.loc[prediction.Type == 2]\n\ncluster_list = [clus0.values, clus1.values, clus2.values]","metadata":{"execution":{"iopub.status.busy":"2021-07-19T11:31:02.669287Z","iopub.execute_input":"2021-07-19T11:31:02.669917Z","iopub.status.idle":"2021-07-19T11:31:02.711503Z","shell.execute_reply.started":"2021-07-19T11:31:02.669866Z","shell.execute_reply":"2021-07-19T11:31:02.710386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### B. For data without PCA applied","metadata":{}},{"cell_type":"code","source":"y_pred1 = gmm1.predict(df1)\npred1 = pd.DataFrame(y_pred1)\npred1.columns = ['Type']\n\nprediction1 = pd.concat([df1, pred1], axis = 1)\n\nclus10 = prediction1.loc[prediction1.Type == 0]\nclus11 = prediction1.loc[prediction1.Type == 1]\nclus12 = prediction1.loc[prediction1.Type == 2]\n\ncluster_list1 = [clus10.values, clus11.values, clus12.values]","metadata":{"execution":{"iopub.status.busy":"2021-07-19T11:31:02.713062Z","iopub.execute_input":"2021-07-19T11:31:02.713695Z","iopub.status.idle":"2021-07-19T11:31:02.745594Z","shell.execute_reply.started":"2021-07-19T11:31:02.713644Z","shell.execute_reply":"2021-07-19T11:31:02.7444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1. Silhoutte Score","metadata":{}},{"cell_type":"markdown","source":"#### A. For data with PCA applied","metadata":{}},{"cell_type":"code","source":"from sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\nX = pcadf\ny = gmm.fit_predict(pcadf)\nprint(\"Clusters\\tSilhoutte Score\\n\")\nfor n_components in range(2, 11):\n    gmm = GaussianMixture(n_components=n_components).fit(X)\n    sil_coeff = silhouette_score(X, c, metric='euclidean')\n    print(\"k = {} \\t--> \\t{}\".format(n_components, sil_coeff))","metadata":{"execution":{"iopub.status.busy":"2021-07-19T11:31:02.747159Z","iopub.execute_input":"2021-07-19T11:31:02.747767Z","iopub.status.idle":"2021-07-19T11:31:23.988208Z","shell.execute_reply.started":"2021-07-19T11:31:02.747719Z","shell.execute_reply":"2021-07-19T11:31:23.987154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### B. For data without PCA applied","metadata":{}},{"cell_type":"code","source":"from sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\nX = df1\ny = gmm1.fit_predict(pcadf)\nprint(\"Clusters\\tSilhoutte Score\\n\")\nfor n_components in range(2, 11):\n    gmm = GaussianMixture(n_components=n_components).fit(X)\n    sil_coeff = silhouette_score(X, c, metric='euclidean')\n    print(\"k = {} \\t--> \\t{}\".format(n_components, sil_coeff))","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-07-19T11:31:23.989431Z","iopub.execute_input":"2021-07-19T11:31:23.989726Z","iopub.status.idle":"2021-07-19T11:32:01.244427Z","shell.execute_reply.started":"2021-07-19T11:31:23.989699Z","shell.execute_reply":"2021-07-19T11:32:01.243289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Thus, data with PCA applied gives better clustering results","metadata":{}},{"cell_type":"markdown","source":"### 2. DB Index","metadata":{}},{"cell_type":"markdown","source":"#### A. For data with PCA applied","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import davies_bouldin_score\ndavies_bouldin_score(pcadf, y_pred)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-07-19T11:32:01.245619Z","iopub.execute_input":"2021-07-19T11:32:01.245915Z","iopub.status.idle":"2021-07-19T11:32:01.269271Z","shell.execute_reply.started":"2021-07-19T11:32:01.245886Z","shell.execute_reply":"2021-07-19T11:32:01.268012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### B. For data without PCA applied","metadata":{}},{"cell_type":"code","source":"davies_bouldin_score(df1, y_pred1) ","metadata":{"execution":{"iopub.status.busy":"2021-07-19T11:32:01.271061Z","iopub.execute_input":"2021-07-19T11:32:01.27154Z","iopub.status.idle":"2021-07-19T11:32:01.296017Z","shell.execute_reply.started":"2021-07-19T11:32:01.271494Z","shell.execute_reply":"2021-07-19T11:32:01.29452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The lower the DB index, the better. Thus, data applied with PCA gives better results","metadata":{}}]}