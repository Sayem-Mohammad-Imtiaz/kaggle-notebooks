{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Linear Regression","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Problem Statement\n\nA Chinese automobile company **Geely Auto** aspires to enter the US market by setting up their manufacturing unit there and producing cars locally to give competition to their US and European counterparts. \n\nThey have contracted an automobile consulting company to understand the factors on which the pricing of cars depends. Specifically, they want to understand the factors affecting the pricing of cars in the American market, since those may be very different from the Chinese market. The company wants to know:\n\n- Which variables are significant in predicting the price of a car\n- How well those variables describe the price of a car\n\nBased on various market surveys, the consulting firm has gathered a large dataset of different types of cars across the American market. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Supress Warnings\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display all columns and rows\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load data from CarPrice_Assignment.csv dataset\n\ncar_df = pd.read_csv(\"/kaggle/input/car-price-prediction/CarPrice_Assignment.csv\", engine='python')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the head of the dataset\n\ncar_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for null values\n\ncar_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dataset dimensions\n\ncar_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dataset information\n\ncar_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# More understanding about the dataset\n\ncar_df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Custom Functions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to get VIF (Variation Inflation Factor)\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\ndef get_VIF(X_train):\n    # A dataframe that will contain the names of all the feature variables and their respective VIFs\n    vif = pd.DataFrame()\n    vif['Features'] = X_train.columns\n    vif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\n    vif['VIF'] = round(vif['VIF'], 2)\n    vif = vif.sort_values(by = \"VIF\", ascending = False)\n    print(vif)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data cleaning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a derived column for company name of cars from the column CarName\n\ncar_df.loc[:,'company'] = car_df.CarName.str.split(' ').str[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"car_df.company = car_df.company.apply(lambda x: str(x).lower())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"car_df.company.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are a few company names which are evidently mis-spelled in the dataset like toyota has been written as toyouta. \nWe will go ahead and repair these. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"car_df['company'].replace('maxda','mazda',inplace=True)\ncar_df['company'].replace('porcshce','porsche',inplace=True)\ncar_df['company'].replace('toyouta','toyota',inplace=True)\ncar_df['company'].replace(['vokswagen','vw'],'volkswagen',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping the CarName column\n\ncar_df.drop(columns = 'CarName', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"car_df.fuelsystem.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From business understanding of the automobile domain we can understand the following:\n\n- mpfi stands for Multi Point Fuel Injection. There is no such thing as mfi in automobile","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"car_df['fuelsystem'].replace('mfi','mpfi',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"car_df.enginetype.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here also we can see that the following data are incorrect.\n\n- ohc hasbeen mis-spelled at places with ohcv\n- dohc has been mis-spelled as dohcv","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"car_df['enginetype'].replace('dohcv','dohc',inplace = True)\ncar_df['enginetype'].replace('ohcv','ohc',inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"car_df.drivewheel.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here fwd has been mis-spelled as 4wd","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"car_df['drivewheel'].replace('4wd', 'fwd', inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Understanding and Preparation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Data Visualization - Continuous Variable","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting a paiplot for the continuous variables\n\nsns.pairplot(car_df, diag_kind=\"kde\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,12))\nsns.heatmap(car_df.corr(), linewidths=.5, annot=True, cmap=\"YlGnBu\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above plots we can understand the following:\n\n1. The dependent variable **price** has a high positive co-relation with:\n    * horsepower\n    * enginesize\n    * curbweight\n    * carwidth\n    * carlength\n\n2. The dependent variable **price** has a high negative co-relation with:\n    * highwaympg\n    * citympg\n    \nAmong the variables which have a high relation with the dependent variable price, there are a few variables which have a very high co-relation with some other variables such are:\n\n- enginesize with horsepower and curbwidth\n- curbweigth with enginesize, carwidth and carlength\n- highwaympg with citympg\n\nThese multi-collinearity need to be considered while building the model as non-multicollinearity is one of the assumptions of linear regression","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Derived variable creation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# curbweight/enginesize\n\ncar_df.loc[:,'curbweight/enginesize'] = car_df.curbweight/car_df.enginesize","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# enginesize/horsepower\n\ncar_df.loc[:,'enginesize/horsepower'] = car_df.enginesize/car_df.horsepower","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# carwidth/carlength\n\ncar_df.loc[:,'carwidth/carlength'] = car_df.carwidth/car_df.carlength","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# highwaympg/citympg\n\ncar_df.loc[:,'highway/city'] = car_df.highwaympg/car_df.citympg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We can now drop the corresponding columns as we have taken a ratio.\n\ncar_df.drop(columns = ['enginesize','carwidth', 'carlength', 'highwaympg', 'citympg'], inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the dataset once more\n\ncar_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping car_ID column as it is not useful\n\ncar_df.drop(columns = 'car_ID', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Data Visualization - Categorical Variable","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The description of symboling given in the data dictionary states, it's assigned insurance risk rating, A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe.\n\nWe divide as follows: \n\n- -3,-2,-1 --> **Safe**\n- 0,1      --> **Moderate**\n- 2,3      --> **Risky**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"car_df.symboling = car_df.symboling.map({-3: 'safe', -2: 'safe',-1: 'safe',0: 'moderate',1: 'moderate',2: 'risky',3:'risky'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizing categorical data via boxplots\n\nplt.figure(figsize=(20, 16))\nplt.subplot(3,3,1)\nsns.boxplot(x = 'symboling', y = 'price', data = car_df)\nplt.subplot(3,3,2)\nsns.boxplot(x = 'fueltype', y = 'price', data = car_df)\nplt.subplot(3,3,3)\nsns.boxplot(x = 'aspiration', y = 'price', data = car_df)\nplt.subplot(3,3,4)\nsns.boxplot(x = 'doornumber', y = 'price', data = car_df)\nplt.subplot(3,3,5)\nsns.boxplot(x = 'carbody', y = 'price', data = car_df)\nplt.subplot(3,3,6)\nsns.boxplot(x = 'drivewheel', y = 'price', data = car_df)\nplt.subplot(3,3,7)\nsns.boxplot(x = 'enginelocation', y = 'price', data = car_df)\nplt.subplot(3,3,8)\nsns.boxplot(x = 'cylindernumber', y = 'price', data = car_df)\nplt.subplot(3,3,9)\nsns.boxplot(x = 'fuelsystem', y = 'price', data = car_df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Cars with rear engines are clearly more priced than others.\n2. Similiarly, there is a significant relationship among price and cylinder number and whether it has a risky or safe symbol. \n3. However, fuel-type and number of doors does not seem to have that much effect on the price of a car.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting company vs price\n\nplt.figure(figsize=(20, 16))\nsns.boxplot(x = 'company', y = 'price', data = car_df, palette=\"Reds\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Company name definitely seems to have a significant effect on the price as companies such as BMW, Jaguar, Buick and Porsche seem to manufacture some serious high end expensive cars. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We can divide the companies into buckets of low, med and high mased on the **median** price of that company. We choose the mediam price instead of mean as there were some outliers in the data for the feature \"company\"","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"median_dict = car_df.groupby(['company'])[['price']].median().to_dict()\nmedian_dict = median_dict['price']\nmedian_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dict_keys = list(median_dict.keys())\n\n# Median price of category below 10000 is low, between 10000 and 20000 is med and above 20000 is high\nfor i in dict_keys:\n    if median_dict[i] < 10000:\n        median_dict[i] = 'low'\n    elif median_dict[i] >= 10000 and median_dict[i] <= 20000:\n        median_dict[i] = 'med'\n    else:\n        median_dict[i] = 'high'\n\nmedian_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"car_df.company = car_df.company.map(median_dict)\ncar_df.company.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### One Hot Encoding for the categorical variables","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"car_df = pd.get_dummies(car_df, drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking dataframe after dummy variable creation\n\ncar_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Splitting the entire dataset into test and train data\n\nHere we are splitting the data in a 75 and 25 ratio for train and test respectively.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndf_train, df_test = train_test_split(car_df, train_size = 0.7, test_size = 0.3, random_state = 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train data shape: \", df_train.shape)\nprint(\"Test data shape: \", df_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Feature scaling\n\nFeature scaling is necessary for all continuous variables to help the gradient decent algorithm converge quickly.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"conti_vars = ['wheelbase', 'carheight', 'boreratio', 'stroke', 'compressionratio', 'peakrpm', 'horsepower', 'curbweight', 'price', 'curbweight/enginesize', 'carwidth/carlength', 'highway/city', 'enginesize/horsepower']\ndf_train[conti_vars] = scaler.fit_transform(df_train[conti_vars])\n\ndf_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X and y division\n\ny_train = df_train.pop('price')\nX_train = df_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Modeling\n\nWe first use sklearn's RFE(Recursive Feature Elimination) technique to reduce down the model to 10 values.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lm = LinearRegression()\nlm.fit(X_train, y_train)\n\nrfe = RFE(lm, 10)             # running RFE to select 10 best features\nrfe = rfe.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Model 1 - 10 features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the statistics of the model using statsmodel library\n\ncol_rfe = X_train.columns[rfe.support_]\nX_train = X_train[col_rfe]\n\nX_train_sm = sm.add_constant(X_train)\nlm_1 = sm.OLS(y_train, X_train_sm).fit()\nprint(lm_1.summary()) #stats\nget_VIF(X_train_sm) #VIF","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This seems a decent point to start removing features one by one. All the features except *carbody_hardtop* have acceptable p-values. Hence we will start removing feature *carbody_hardtop* and rebuild the model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.drop(columns='carbody_hardtop', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Model 2 - 9 features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_sm = sm.add_constant(X_train)\nlm_2 = sm.OLS(y_train, X_train_sm).fit()\nprint(lm_2.summary()) #stats\nget_VIF(X_train_sm) #VIF","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*wheelbase* came out to have a high p-value. Removing and rebuilding model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.drop(columns='wheelbase', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Model 3 - 8 features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_sm = sm.add_constant(X_train)\nlm_3 = sm.OLS(y_train, X_train_sm).fit()\nprint(lm_3.summary()) #stats\nget_VIF(X_train_sm) #VIF","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*carbody_sedan* has a high p-value and a VIF above 5. So it becomes a very good candidate to be dropped. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.drop(columns='carbody_sedan', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Model 4 - 7 features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_sm = sm.add_constant(X_train)\nlm_4 = sm.OLS(y_train, X_train_sm).fit()\nprint(lm_4.summary()) #stats\nget_VIF(X_train_sm) #VIF","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"At this point we see that all the p values are below 0.05 and the VIFs are also below 5. \nSo we can be pretty confident that this is a good model.\n\nWe also see that lm_4 model has an **R-squared value of 0.926** and an **adjusted R-squared value of 0.922**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Residual Analysis\n\n##### On training data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_price = lm_4.predict(X_train_sm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure()\nsns.distplot((y_train - y_train_price), bins = 20)\nfig.suptitle('Residual Error Distribution', fontsize = 20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The residual errors are distributed in a bell shaped curve with the mean centered at 0.0. It is showing a good Normal Distribution curve ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"##### On testing data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# We are scaling the testing set with the already existing scaler object which has been fitted on the train dataset\n\ndf_test[conti_vars] = scaler.transform(df_test[conti_vars])\n\ndf_test.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X and y division\n\ny_test = df_test.pop('price')\nX_test = df_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = X_test[col_rfe]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.drop(columns=['carbody_sedan', 'wheelbase', 'carbody_hardtop'], inplace=True) # Dropping columns which we dropped while building the model after RFE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_sm = sm.add_constant(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = lm_4.predict(X_test_sm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting y_test and y_pred to understand the spread.\nfig = plt.figure()\nplt.scatter(y_test,y_pred)\nplt.xlabel('y_test_price', fontsize=18)\nplt.ylabel('y_pred', fontsize=16)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model Evaluation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nfrom math import sqrt\nfrom sklearn.metrics import r2_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rmse = sqrt(mean_squared_error(y_test, y_pred))\nprint('Model RMSE:',rmse)\n\nr2=r2_score(y_test, y_pred)\nprint('Model r2_score:',r2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**R2_score on training data**: 0.926\n\n**R2_score on testing data**: 0.914\n\nThis proves that our model is able to explain the variance of the test set, almost as much as it is explaining the variance of the training set.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"c = [i for i in range(1,63)]\n\nfig = plt.figure()\nplt.plot(c,y_test,color=\"blue\",linewidth=3,linestyle='-')\nplt.plot(c,y_pred,color=\"red\",linewidth=3,linestyle='-')\nplt.ylabel('Car Price')\nplt.xlabel('Index')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The test vs predicted results almost overlap each other which shows good prediction.\n\nThe final model has the following features and coefficients:\n\n| Feature Name | Co-efficient |\n| -: | -: |\n| curbweight | 0.4328 |\n| horsepower | 0.2874 |\n| carbody_hatchback | -0.0232 |\n| carbody_wagon | -0.0454 |\n| enginelocation_rear | 0.1697 |\n| company_low | -0.2831 |\n| company_med | -0.2307 |","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Final Analysis and Recommendations","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Geely Auto can use the above features to determine the price of a car which they are about to distribute in the US market. \n\nAlong with that, our initial analysis brought out some valient features which has a huge impact on the price of a car. These are summarized again below:- \n\n1. **Company Name** - Brand value is a big factor. Companies such as Porsche, BMW, Jaguar produce some expensive cars. So price depends a lot on the company of the car.\n2. **Symboling** - Cars symboled safe have a higher price range than others.\n3. **Fueltype** - Diesel powered cars tend to be very slightly expensive than their petrol counterparts. This could be because diesel is less expensive than petrol and thus a diesel car willcost less over time.\n4. **Engine Location** - Cars with engines on the rear are significantly more expensive than the cars with engine on the front. This is mainly because the expensive sports cars have engine towards the back for better balance at high speeds and aerodynamic enhancement.\n5. **Cylinder Number** - With the increase in the number of cylinders, the prices increase as well","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}