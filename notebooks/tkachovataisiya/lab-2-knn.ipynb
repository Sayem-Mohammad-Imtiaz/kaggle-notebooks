{"cells":[{"metadata":{},"cell_type":"markdown","source":"Метрические методы классификации\n1. Методы ближайших соседей\n2. Настройка оптимального числа ближайших соседей в методе kNN\n3. Выбор метрики в методе kNN\n4. Другие метрические методы"},{"metadata":{},"cell_type":"markdown","source":"# Методы ближайших соседей"},{"metadata":{},"cell_type":"markdown","source":"*1. Подключитесь к одному из наборов данных на Kaggle: Вариант 3: Bank marketing.*"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Загрузка данных\ndf = pd.read_csv('/kaggle/input/bank-marketing-dataset/bank.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*2. Извлеките целевой признак (target). Какая из задач обучения с учителем рассматривается –– классификация или регрессия?*\n\nЦелевым признаком (target) является 'deposit', принимающий значения \"yes\" и \"no\", что означает положит клиент срочный депозит или нет. Рассматривается категория - обучение с учителем и тип задачи - классификация (предсказание категории объекта).\n"},{"metadata":{},"cell_type":"markdown","source":"*3. Каково распределение значений target-переменной? Постройте подходящую визуализацию. Прокомментируйте результат.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.catplot(x = \"deposit\", kind = \"count\", palette = \"ch:.25\", data = df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Выведем процентное соотношение\ndf['deposit'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(df['deposit'].shape) # Всего 11162 строк\ndf['deposit']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Имеем ~52,6% клиентов без депозитов и ~47,4% клиентов c депозитом.\n\nМожно заметить, что классы 'no' и 'yes' почти сбалансированы."},{"metadata":{},"cell_type":"markdown","source":"*4. Проведите необходимую предобработку данных (preprocessing). Для построения моделей с помощью метрических методов все признаки должны быть закодированы числами. Полезными будут следующие методы библиотеки Pandas:*\n1. map() – для перекодировки категориальной переменной числовыми метками; \n2. get_dummies() – для создания нескольких бинарных признаков на основе категориального. \n\n*Также может потребоваться масштабирование данных (scaling). Воспользуйтесь классом StandardScaler библиотеки Scikit-learn.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn. preprocessing import LabelEncoder\n\nle = LabelEncoder()\nle.fit(df.default)\ndf['default_le'] = le.transform(df.default)\n\n# ручная альтернатива\n#dct = {'no': 0, 'yes': 1} # словарь для кодировки \n#df['default_le'] = df['default'].map(dct)\n\nle_1 = LabelEncoder()\nle_1.fit(df.housing)\ndf['housing_le'] = le_1.transform(df.housing)\n\nle_2 = LabelEncoder()\nle_2.fit(df.housing)\ndf['loan_le'] = le_2.transform(df.loan)\n\nle_3 = LabelEncoder()\nle_3.fit(df.housing)\ndf['deposit_le'] = le_3.transform(df.deposit)\n\ndct_1 = {'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4, 'may': 5, 'jun': 6, 'jul': 7, 'aug': 8, 'sep': 9, 'oct': 10, 'nov': 11, 'dec':12}\ndf['month_le'] = df['month'].map(dct_1)\n\n#dct_2 = {'married': 1, 'single': 2, 'divorced': 3}\n#df['marital_le'] = df['marital'].map(dct_2)\n\n#dct_3 = {'secondary': 1, 'tertiary': 2, 'primary': 3, 'unknown': 4}\n#df['education_le'] = df['education'].map(dct_3)\n\n#dct_4 = {'unknown': 0, 'cellular': 1, 'telephone': 2}\n#df['contact_le'] = df['contact'].map(dct_4)\n\n#dct_5 = {'unknown': 0, 'other': 1, 'failure': 2, 'success': 3}\n#df['poutcome_le'] = df['poutcome'].map(dct_5)\n\ndf.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_1 = pd.read_csv('/kaggle/input/bank-marketing-dataset/bank.csv')\ndf_1['default'] = df['default_le']\ndf_1['housing'] = df['housing_le']\ndf_1['loan'] = df['loan_le']\ndf_1['deposit'] = df['deposit_le']\ndf_1['month'] = df['month_le']\n\n#df_1['marital'] = df['marital_le']\n#df_1['education'] = df['education_le']\n#df_1['contact'] = df['contact_le']\n#df_1['poutcome'] = df['poutcome_le']\n\n# get_dummies\ndf_1 = pd.get_dummies(df_1, columns=['marital', 'education', 'contact', 'poutcome'])\n\ndf_1.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_1.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_2 = df_1.drop(['job'], axis = 1)\ndf_2 = pd.get_dummies(df_1, columns=['job']) \n\ndf_2.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_2.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n\n# Создание X - вся таблица без target (deposit), а y - target (deposit).\n\ny = df_2['deposit']\ndf_3 = df_2.drop('deposit', axis = 1)\n\nX = df_3\n\nX_new = scaler.fit_transform(X)\nX_new","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*5. Разбейте набор данных на обучающую и валидационную (тестовую) выборки с помощью метода train_test_split.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Разбиение\nfrom sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split(X, \n                                                      y, \n                                                      test_size=0.25, \n                                                      random_state=20) \n\n#random_state. Controls the shuffling applied to the data before applying the split. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape, y_train.shape)\nprint( X_valid.shape, y_valid.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*6. Обучите алгоритм классификации kNeighborsClassifier или регрессии KNeighborsRegressor . Оцените качество каждой модели на валидационной выборке с помощью*\n1. accuracy_score для классификации;\n2. mean_squared_error для регрессии.\n\n*Сравните результаты и сделайте выводы.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Обучение классификатора\n# Создаём представителя класса модели, задаём необходимые гиперпараметры\n\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Обучаем модель на обучающей выборке\nknn.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Строим предсказания на основе обученной модели\ny_pred = knn.predict(X_valid)\ny_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Функция mean_squared_error вычисляет среднеквадратичную ошибку, метрику риска, \n#соответствующую ожидаемому значению квадратичной ошибки или убытка.\n\nfrom sklearn.metrics import mean_squared_error\nmean_squared_error(y_valid, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Вычисляем метрику\nknn.score(X_valid, y_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ещё один способ для вычисления метрики\nfrom sklearn.metrics import accuracy_score\nprint(accuracy_score(y_valid, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nprint(confusion_matrix(y_valid, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cреднеквадратическая ошибка мала, а score достаточно большое, откуда следует, что  модель можно считать качественной.\n\nТакже можно сделать вывод, что модель предсказывает случаи 'no' немного лучше чем 'yes', что очевидно, ведь ноборов 'no' в данном датасете больше. "},{"metadata":{},"cell_type":"markdown","source":"# Настройка оптимального числа ближайших соседей в методе kNN"},{"metadata":{},"cell_type":"markdown","source":"*1. Создайте генератор разбиений, который перемешивает выборку перед созданием блоков ( shuffle=True ). Число блоков n_splits равно 5. Задайте также параметр random_state для воспроизводимости результатов. Например: kf = KFold(n_splits=5, shuffle=True, random_state=42).*\n\n*Найдите показатель качества модели kNN на кросс-валидации. Подумайте, приемлемо ли использование вашей меры (метрики) качества в данной задаче? При необходимости пересчитайте качество с помощью другой метрики из списка.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold, cross_val_score\nkf = KFold(n_splits = 5, shuffle = True, random_state = 42)\n\nscores = cross_val_score(knn, X, y, cv = kf, scoring = 'accuracy')\nscores.mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"В лучщем случае метод должен вернуть положительное значение с плавающей запятой (лучшее - 1). Имеется число наближенное к 1-е, следовательное использованиие этой метрики для данной задачи \nприемлимо. "},{"metadata":{},"cell_type":"markdown","source":"Для примера,рассмотрим ещё F1 score. The F1 score is the harmonic mean of the precision and recall. The highest possible value of F1 is 1, indicating perfect precision and recall, and the lowest possible value is 0, if either the precision or the recall is zero."},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = cross_val_score(knn, X, y, cv = kf, scoring = 'f1')\nscores.mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Полученное значение наближенно к единице,но хуже предыдущего случая."},{"metadata":{},"cell_type":"markdown","source":"*2. Осуществите кросс-валидацию модели при числе соседей k ∈ [1;50]. Используйте GridSearchCV . При каком k качество получилось наилучшим? Чему равна эта оценка качества? Постройте график значений метрики в зависимости от k (matplotlib.pyplot.plot()).*"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nknn_params = {'n_neighbors': np.arange(1, 51)}\nknn_grid = GridSearchCV(knn, \n                        knn_params, \n                        scoring='f1',\n                        cv = kf)\nknn_grid.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Best_estimator: \", knn_grid.best_estimator_)\nprint(\"Cross-validated score of the best_estimator: \", knn_grid.best_score_)\nprint( \"Best_index_ while the best_score_ attribute will not be available: \", knn_grid.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_results = pd.DataFrame(knn_grid.cv_results_)\ncv_results.T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Предсказания на тестовой выборке для оптимального числа соседей\ny_pred = knn_grid.predict(X_valid)\naccuracy_score(y_valid, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_knn = KNeighborsClassifier(n_neighbors=13)\ny_pred = best_knn.fit(X_train, y_train).predict(X_valid)\naccuracy_score(y_valid, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(cv_results[\"param_n_neighbors\"],cv_results[\"mean_test_score\"])\n\nplt.xlabel('Number of neighbors')\nplt.ylabel('Test accuracy')\nplt.title('F1 score')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" При k = 13 качество получилось наилучшим."},{"metadata":{},"cell_type":"markdown","source":"\n# Выбор метрики в методе kNN"},{"metadata":{},"cell_type":"markdown","source":"*1. Переберите разные варианты значений параметра p по сетке от 1 до 10 с таким шагом, чтобы всего было протестировано 200 вариантов (удобно использовать функцию numpy.linspace ). Используйте KNeighborsClassifier или KNeighborsRegressor с оптимальным значением n_neighbors , найденным ранее. Задайте опцию weights='distance' – данный параметр добавляет в алгоритм веса, зависящие от расстояния до ближайших соседей. В качестве метрики качества снова используйте accuracy . Качество оценивайте с помощью кросс-валидации по 5 блокам.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_params = {\"p\": np.linspace(1,10, 200)}\n\nknn = KNeighborsClassifier(n_neighbors = 13, weights = \"distance\", n_jobs = -1)\nknn.fit(X_train, y_train)\n\ncv = GridSearchCV(knn, knn_params, cv = kf, scoring=\"f1\")\ncv.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*2. Определите, при каком p качество на кросс-валидации оказалось оптимальным. Обратите внимание, что cross_val_score возвращает массив показателей качества по блокам; необходимо максимизировать среднее этих показателей.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprint(\"Лучшее значение:\", cv.best_score_)\nprint(cv.best_estimator_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_result = pd.DataFrame(cv.cv_results_)\ncv_result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(cv_result[\"param_p\"],cv_result[\"mean_test_score\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Другие метрические методы"},{"metadata":{},"cell_type":"markdown","source":"*Поэкспериментируйте с другими метрическими методами для задач регрессии и классификации, представленными в библиотеке Scikit-learn:*\n1. RadiusNeighborsClassifier;\n2. RadiusNeighborsRegressor;\n3. NearestCentroid"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import NearestCentroid\nclf = NearestCentroid()\nclf.fit(X_train, y_train)\nNearestCentroid()\n\ny_pred_nc = clf.predict(X_valid)\ny_pred_nc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_squared_error(y_valid, y_pred_nc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(accuracy_score(y_valid, y_pred_nc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_valid, y_pred_nc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Метод NearestCentroid в сравнении с kNN даёт хуже результат, так как среднеквадратическая ошибка по значению близка к score."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}