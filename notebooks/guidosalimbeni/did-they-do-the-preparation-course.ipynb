{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"cell_type":"markdown","source":"# Predict Using Random Forest Classifier\n\n\nWe are using scikit-learn Random Forest Classifier to predict, if a particular student has already completed **test preparation course** .\n\n* so given how well they did in the course, we predict if they did the preparation course before doing the course."},{"metadata":{"_uuid":"4cb4e35d3c8ac8f2cd4d342d4c764a2c361902a8","trusted":true},"cell_type":"code","source":"import pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt\nimport seaborn as snb","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"56bc7667fe6ad8b44c740681dc5a8b21e0a3ae99","trusted":true},"cell_type":"code","source":"# read csv\ndf = pd.read_csv(\"/kaggle/input/students-performance-in-exams/StudentsPerformance.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"88a553ad8c8f99f420f6d8be40adb2206a986f29"},"cell_type":"markdown","source":"* Read top few rows from the file using the head() method of Pandas."},{"metadata":{"_uuid":"eec5bbc63179ea989692cafc5411fc04581b017d","trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"042cd2808f4ffc6dfc3df7a8eebe8a8103859049"},"cell_type":"markdown","source":"* Check missing values\n* .<code>isnull()</code> and <code>sum()</code> is used to find whether there are any missing values in the CSV file."},{"metadata":{"_uuid":"8a46d412112d51ed0edcc62d50c22984df867666","trusted":true},"cell_type":"code","source":"df.isnull().sum() # checking missing values","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"892f93375f27b48fa2c4893038bfba5e14a37fa3"},"cell_type":"markdown","source":"* explore the target"},{"metadata":{"_uuid":"2ec43d37f8227993e9777763966957a54dbd0294","trusted":true},"cell_type":"code","source":"# get test preparation course values count\ndf['test preparation course'].value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Turn categorical values of the target into number"},{"metadata":{"trusted":true},"cell_type":"code","source":"mapping = {\"none\" : 0, \"completed\" : 1}\ndf['test preparation course'] = df['test preparation course'].map(mapping)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* plot the pairplot graph of the original dataset using the target 'test preparation course' as the hue of the graph\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.pairplot(df,hue='test preparation course',palette='Set1')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Categorical data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.get_dummies(df, columns = ['gender', 'race/ethnicity', 'parental level of education', 'lunch'],drop_first = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"892099d296254f112cc76e642cbc30765dcfea3d"},"cell_type":"markdown","source":"# create X and y\n    "},{"metadata":{"trusted":true},"cell_type":"code","source":"X= df.drop(\"test preparation course\", axis = 1)\ny = df[\"test preparation course\"]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bbde31b31342534ccb31c0ea3bc56fe8da933a46"},"cell_type":"markdown","source":"# Split train and test "},{"metadata":{"_uuid":"c429f1702af2456a165f7c33423fa52900baa9f6","trusted":true},"cell_type":"code","source":"# split train test data set\nfrom sklearn.model_selection import train_test_split\nX_Train, X_Test, y_Train, y_Test = train_test_split(X, y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d8301ac736487454b8dddeb952bbe362de7346ae"},"cell_type":"markdown","source":"## Random Forest Classifier"},{"metadata":{"_uuid":"6dbe85ca5be2512bf983f8821380a631dc3f06f7"},"cell_type":"markdown","source":"<p>A random forest is* a meta estimator* that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting.</p>\n\n<code>n_estimators</code> <i>integer, optional (default=10)</i>  The number of trees in the forest.<br/>\n\n"},{"metadata":{"_uuid":"bd9c293925c960079330f0e9d5220b21e49109a9","trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nRandomForest = RandomForestClassifier(n_estimators = 100, max_features= 10) ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"01b1c5b309e2ec59acbdb22925cd2f6d4618c9e8"},"cell_type":"markdown","source":"**Fit X_Train and y_Train**"},{"metadata":{"_uuid":"337d83613f4d8497ed52ddce97a8642cad8ce374","trusted":true},"cell_type":"code","source":"RandomForest.fit(X_Train, y_Train) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* score of the training data "},{"metadata":{"_uuid":"aebeb0f592c2589d982a08e22e149a59e4757dd0","trusted":true},"cell_type":"code","source":"RandomForest.score(X_Train, y_Train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* score of the testing data \n"},{"metadata":{"_uuid":"cc07d29e68de6dff6c278c71af285cceee3b1d9d","trusted":true},"cell_type":"code","source":"RandomForest.score(X_Test, y_Test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looks like the model is not able to generalise very well on unseen data. Let's investigate more evaluation metrics"},{"metadata":{"_uuid":"7fd400f68e94901d612d450954bd5d0cb118e4dc","trusted":true},"cell_type":"code","source":"predictions = RandomForest.predict(X_Test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* classification report of your true labels y_test compared to the predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_Test,predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(y_Test,predictions)\nfig, ax = plt.subplots(figsize=(5, 5))\nsns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \nax.set_title('Confusion Matrix'); ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_features = X.shape[1]\nplt.barh(range(n_features),RandomForest.feature_importances_)\nplt.yticks(np.arange(n_features),df.columns[1:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"1. # Another approach - Logistic Regression and polynomial features"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"mean_grade\"] = (df[\"math score\"] + df[\"reading score\"] + df[\"writing score\"]) / 3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"math score_squared\"] = df[\"math score\"] * df[\"math score\"]\ndf[\"reading score_squared\"] = df[\"reading score\"] * df[\"reading score\"]\ndf[\"writing score_squared\"] = df[\"writing score\"] * df[\"writing score\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X= df[['math score', 'reading score','writing score', 'gender_male','mean_grade', 'math score_squared', 'reading score_squared','writing score_squared']]\nX = df.drop(\"test preparation course\", 1)\ny = df[\"test preparation course\"]\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\n# split train test data set\nfrom sklearn.model_selection import train_test_split\nX_Train, X_Test, y_Train, y_Test = train_test_split(X, y)\nfrom sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression() \nmodel.fit(X_Train, y_Train) \nprint (model.score(X_Train, y_Train))\nprint (model.score(X_Test, y_Test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"widgets":{"state":{},"version":"1.1.2"}},"nbformat":4,"nbformat_minor":1}