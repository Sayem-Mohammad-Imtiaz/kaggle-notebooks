{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-07-31T17:37:30.564959Z","iopub.execute_input":"2021-07-31T17:37:30.565298Z","iopub.status.idle":"2021-07-31T17:37:30.576409Z","shell.execute_reply.started":"2021-07-31T17:37:30.56527Z","shell.execute_reply":"2021-07-31T17:37:30.575413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"font-family: 'Poppins', sans-serif; font-size: 32px; text-align: center; color: #31393C; background-color: #FDCA40; padding: 20px; border-radius: 10px\">Spam Messages Filtering using NLP<h1>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px; text-align: left;\">So I recently started Natural Language Processing and I thought I would just keep a record of what I am learning and understanding. This notebook can also be helpful to anyone who is just starting NLP.<p>","metadata":{}},{"cell_type":"markdown","source":"<h1 style=\"font-family: 'Poppins', sans-serif; font-size: 22px; text-align: left; color: #2176FF;\">1. Natural Language Processing</h1>\n\n<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px; text-align: left; color: #000;\">Natural language processing (NLP) is a collective term referring to automatic computational processing of human languages. Basically, we are converting human language such that computer understands it, analyzes it and gives us back the result we need.<br><br> For eg. Chatbots are the best example of this. Chatbots are software applications that use natural language processing to understand what a human wants, and guides them to their desired outcome with as little work for the end user as possible.<br><br>Other examples are Speech Recognition, Filtering Spams, etc.</p>","metadata":{}},{"cell_type":"markdown","source":"<h1 style=\"font-family: 'Poppins', sans-serif; font-size: 22px; text-align: left; color: #2176FF;\">3. Basic Analysis of the data</h1>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px; text-align: left; color: #000;\">I will be working on this sms spam collection dataset to build a model to predict spam and ham messages.</p><br>","metadata":{}},{"cell_type":"code","source":"# importing important libraries\nimport numpy as np\nimport pandas as pd\nimport nltk\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-07-31T17:37:30.578209Z","iopub.execute_input":"2021-07-31T17:37:30.578651Z","iopub.status.idle":"2021-07-31T17:37:30.590616Z","shell.execute_reply.started":"2021-07-31T17:37:30.578606Z","shell.execute_reply":"2021-07-31T17:37:30.589719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#reading the csv file\nmessages = pd.read_csv(\"/kaggle/input/sms-spam-collection-dataset/spam.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-07-31T17:37:30.593137Z","iopub.execute_input":"2021-07-31T17:37:30.59355Z","iopub.status.idle":"2021-07-31T17:37:30.621222Z","shell.execute_reply.started":"2021-07-31T17:37:30.593508Z","shell.execute_reply":"2021-07-31T17:37:30.620306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"messages.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-31T17:37:30.622703Z","iopub.execute_input":"2021-07-31T17:37:30.623289Z","iopub.status.idle":"2021-07-31T17:37:30.636657Z","shell.execute_reply.started":"2021-07-31T17:37:30.623247Z","shell.execute_reply":"2021-07-31T17:37:30.635723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"messages.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-31T17:37:30.637999Z","iopub.execute_input":"2021-07-31T17:37:30.638401Z","iopub.status.idle":"2021-07-31T17:37:30.659242Z","shell.execute_reply.started":"2021-07-31T17:37:30.638361Z","shell.execute_reply":"2021-07-31T17:37:30.658146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px; text-align: left; color: #000;\">The number of missing values is too much to take into consideration. I will just drop these columns with NaN values. We will only take the Text message and its type ie ham or spam into consideration for our model</p><br>","metadata":{}},{"cell_type":"code","source":"messages = messages.drop('Unnamed: 2', axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-07-31T17:37:30.661981Z","iopub.execute_input":"2021-07-31T17:37:30.662269Z","iopub.status.idle":"2021-07-31T17:37:30.673339Z","shell.execute_reply.started":"2021-07-31T17:37:30.662242Z","shell.execute_reply":"2021-07-31T17:37:30.672643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"messages = messages.drop('Unnamed: 3', axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-07-31T17:37:30.674569Z","iopub.execute_input":"2021-07-31T17:37:30.674999Z","iopub.status.idle":"2021-07-31T17:37:30.687871Z","shell.execute_reply.started":"2021-07-31T17:37:30.674967Z","shell.execute_reply":"2021-07-31T17:37:30.686826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"messages = messages.drop('Unnamed: 4', axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-07-31T17:37:30.689132Z","iopub.execute_input":"2021-07-31T17:37:30.689418Z","iopub.status.idle":"2021-07-31T17:37:30.701675Z","shell.execute_reply.started":"2021-07-31T17:37:30.689391Z","shell.execute_reply":"2021-07-31T17:37:30.700899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"messages.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-31T17:37:30.703106Z","iopub.execute_input":"2021-07-31T17:37:30.703781Z","iopub.status.idle":"2021-07-31T17:37:30.721206Z","shell.execute_reply.started":"2021-07-31T17:37:30.70374Z","shell.execute_reply":"2021-07-31T17:37:30.720005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"messages.describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-31T17:37:30.72246Z","iopub.execute_input":"2021-07-31T17:37:30.722902Z","iopub.status.idle":"2021-07-31T17:37:30.751972Z","shell.execute_reply.started":"2021-07-31T17:37:30.722862Z","shell.execute_reply":"2021-07-31T17:37:30.750801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"messages.groupby('v1').describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-31T17:37:30.753317Z","iopub.execute_input":"2021-07-31T17:37:30.753632Z","iopub.status.idle":"2021-07-31T17:37:30.785676Z","shell.execute_reply.started":"2021-07-31T17:37:30.753602Z","shell.execute_reply":"2021-07-31T17:37:30.784791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px; text-align: left; color: #000;\">As you can see the top Ham message is \"Sorry, I'll call later\" and the top spam message is \"Please call our customer service.....\"</p>\n<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px; text-align: left; color: #000;\">Now this might help in the future as we make the model to differentiate between the Ham and Spam message.\"</p>","metadata":{}},{"cell_type":"code","source":"messages['length'] = messages['v2'].apply(len)","metadata":{"execution":{"iopub.status.busy":"2021-07-31T17:37:30.786837Z","iopub.execute_input":"2021-07-31T17:37:30.787142Z","iopub.status.idle":"2021-07-31T17:37:30.794863Z","shell.execute_reply.started":"2021-07-31T17:37:30.787113Z","shell.execute_reply":"2021-07-31T17:37:30.794183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"messages.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-31T17:37:30.795769Z","iopub.execute_input":"2021-07-31T17:37:30.796062Z","iopub.status.idle":"2021-07-31T17:37:30.812193Z","shell.execute_reply.started":"2021-07-31T17:37:30.796034Z","shell.execute_reply":"2021-07-31T17:37:30.811264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px; text-align: left; color: #000;\">The length of the messages can be another identifier to check whether the message is spam or ham. Spam messages might have similar lengths and it may help to filter these out.</p>","metadata":{}},{"cell_type":"code","source":"sns.histplot(messages['length'], bins=100)","metadata":{"execution":{"iopub.status.busy":"2021-07-31T17:37:30.814724Z","iopub.execute_input":"2021-07-31T17:37:30.815025Z","iopub.status.idle":"2021-07-31T17:37:31.195273Z","shell.execute_reply.started":"2021-07-31T17:37:30.814997Z","shell.execute_reply":"2021-07-31T17:37:31.194453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"messages.hist(column='length', by='v1', bins=60, figsize=(12,4))","metadata":{"execution":{"iopub.status.busy":"2021-07-31T17:37:31.196805Z","iopub.execute_input":"2021-07-31T17:37:31.197088Z","iopub.status.idle":"2021-07-31T17:37:31.712502Z","shell.execute_reply.started":"2021-07-31T17:37:31.19706Z","shell.execute_reply":"2021-07-31T17:37:31.711759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px; text-align: left; color: #000;\">This clearly proves the fact that most Ham messages are short and concise with only average length of around 30-50.</p>\n<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px; text-align: left; color: #000;\">Spam messages are relatively big with average length being around 150. Thus we can use this a differentiating factor to find out if the message is spam or ham.</p>\n<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px; text-align: left; color: #000;\">Let's look at some other factors that can be used to distinguish.</p>","metadata":{}},{"cell_type":"markdown","source":"<h1 style=\"font-family: 'Poppins', sans-serif; font-size: 22px; text-align: left; color: #2176FF;\">4. Text Preprocessing</h1>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px; text-align: left; color: #000;\">Since all of our data is mostly String, we have to convert it into some form i.e. make list of tokens or in simple words make a list with the sentence converted to a list of all the words it includes. Classification models only take in numeric values so accordingly we have to vectorize our data later.</p>","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2021-07-31T17:37:31.713682Z","iopub.execute_input":"2021-07-31T17:37:31.713999Z","iopub.status.idle":"2021-07-31T17:37:31.718828Z","shell.execute_reply.started":"2021-07-31T17:37:31.71397Z","shell.execute_reply":"2021-07-31T17:37:31.717838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"msg_train, msg_test, label_train, label_test = train_test_split(messages['v2'], messages['v1'], test_size=0.3)","metadata":{"execution":{"iopub.status.busy":"2021-07-31T17:37:31.720225Z","iopub.execute_input":"2021-07-31T17:37:31.72062Z","iopub.status.idle":"2021-07-31T17:37:31.730909Z","shell.execute_reply.started":"2021-07-31T17:37:31.72058Z","shell.execute_reply":"2021-07-31T17:37:31.729791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import string\nfrom nltk.corpus import stopwords","metadata":{"execution":{"iopub.status.busy":"2021-07-31T17:37:31.732462Z","iopub.execute_input":"2021-07-31T17:37:31.732958Z","iopub.status.idle":"2021-07-31T17:37:31.740783Z","shell.execute_reply.started":"2021-07-31T17:37:31.732913Z","shell.execute_reply":"2021-07-31T17:37:31.739971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px; text-align: left; color: #000;\">Now let's create a function to do our processing. Things we are going to do:<ul style=\"font-family: 'Poppins', sans-serif; font-size: 16px; text-align: left; color: #000;\"><li>Remove Punctuations </li><li>Remove stop words(is, an, the, etc.)</li><li>Return list of clean words.</li></ul></p>","metadata":{}},{"cell_type":"code","source":"def text_process(mess):\n    no_punc = [char for char in mess if char not in string.punctuation]\n    no_punc = \"\".join(no_punc)\n    return [word for word in no_punc.split() if word.lower() not in stopwords.words('english')]","metadata":{"execution":{"iopub.status.busy":"2021-07-31T17:37:31.742275Z","iopub.execute_input":"2021-07-31T17:37:31.742843Z","iopub.status.idle":"2021-07-31T17:37:31.7521Z","shell.execute_reply.started":"2021-07-31T17:37:31.742782Z","shell.execute_reply":"2021-07-31T17:37:31.751127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"messages.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-31T17:37:31.753377Z","iopub.execute_input":"2021-07-31T17:37:31.753762Z","iopub.status.idle":"2021-07-31T17:37:31.774308Z","shell.execute_reply.started":"2021-07-31T17:37:31.753689Z","shell.execute_reply":"2021-07-31T17:37:31.773373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#applying function\nmsg_train.head(5).apply(text_process)","metadata":{"execution":{"iopub.status.busy":"2021-07-31T17:37:31.775574Z","iopub.execute_input":"2021-07-31T17:37:31.775879Z","iopub.status.idle":"2021-07-31T17:37:31.804483Z","shell.execute_reply.started":"2021-07-31T17:37:31.775848Z","shell.execute_reply":"2021-07-31T17:37:31.803784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"font-family: 'Poppins', sans-serif; font-size: 22px; text-align: left; color: #2176FF;\">4. Building the Classification Models</h1>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px; text-align: left; color: #000;\">Now that we have created our list of tokens we need to convert it into vectors such that the our model understands and differentiates it properly. We are basically making a bag of words. We'll use Count Vectorizer from Sklearn library to do this.</p>","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB","metadata":{"execution":{"iopub.status.busy":"2021-07-31T17:47:42.576546Z","iopub.execute_input":"2021-07-31T17:47:42.576956Z","iopub.status.idle":"2021-07-31T17:47:42.58129Z","shell.execute_reply.started":"2021-07-31T17:47:42.576923Z","shell.execute_reply":"2021-07-31T17:47:42.580301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\n\npipeline = Pipeline([\n    ('bow', CountVectorizer(analyzer=text_process)),  # strings to token integer counts\n    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n])","metadata":{"execution":{"iopub.status.busy":"2021-07-31T17:47:44.633636Z","iopub.execute_input":"2021-07-31T17:47:44.634111Z","iopub.status.idle":"2021-07-31T17:47:44.641303Z","shell.execute_reply.started":"2021-07-31T17:47:44.634078Z","shell.execute_reply":"2021-07-31T17:47:44.640372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipeline.fit(msg_train,label_train)","metadata":{"execution":{"iopub.status.busy":"2021-07-31T17:48:03.834231Z","iopub.execute_input":"2021-07-31T17:48:03.834589Z","iopub.status.idle":"2021-07-31T17:48:11.405421Z","shell.execute_reply.started":"2021-07-31T17:48:03.834552Z","shell.execute_reply":"2021-07-31T17:48:11.404404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = pipeline.predict(msg_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-31T17:48:34.217292Z","iopub.execute_input":"2021-07-31T17:48:34.217778Z","iopub.status.idle":"2021-07-31T17:48:37.418138Z","shell.execute_reply.started":"2021-07-31T17:48:34.217747Z","shell.execute_reply":"2021-07-31T17:48:37.417167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(predictions,label_test))","metadata":{"execution":{"iopub.status.busy":"2021-07-31T17:49:08.786953Z","iopub.execute_input":"2021-07-31T17:49:08.787333Z","iopub.status.idle":"2021-07-31T17:49:08.86029Z","shell.execute_reply.started":"2021-07-31T17:49:08.787297Z","shell.execute_reply":"2021-07-31T17:49:08.8591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"font-family: 'Poppins', sans-serif; font-size: 22px; text-align: left; color: #FA8334;\">The Model performed well with an overall accuracy of 96% but the f1-score of Spam was not up to the mark. I will try doing more feature engineering on this to get a better score for Spam.</h1>","metadata":{}}]}