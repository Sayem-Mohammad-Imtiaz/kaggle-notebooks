{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport spacy\nnlp = spacy.load(\"en_core_web_sm\")\nimport gensim\nimport matplotlib.pyplot as plt\nimport plotly\nimport datetime\nimport plotly.graph_objects as go\nfrom wordcloud import WordCloud, STOPWORDS\nfrom textblob import TextBlob \nimport re\nfrom collections import Counter\n# from allennlp.predictors.predictor import Predictor\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"tweets = pd.read_csv(\"../input/trump-tweets/trumptweets.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets['year'] = tweets.date.apply(lambda x: int(x[0:4]))\ntweets_filter = tweets[tweets['year'] >= 2016]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"tweets_filter['formatted_date'] = pd.to_datetime(tweets_filter['date'])\ntweets_filter['day_of_year'] = tweets_filter['formatted_date'].apply(lambda x: x.dayofyear)\ntweets_filter['week_of_year'] = tweets_filter['formatted_date'].apply(lambda x: x.weekofyear)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"start_date = datetime.datetime(2016,1,1).date()\ndates = []\ncounts = []\nreweets = []\ncount = 0\nfor el in tweets_filter.formatted_date.dt.date:\n    if (el-start_date).days <= 7:\n#         print(\"entered here\")\n        count += 1\n    else:\n        counts.append(count)\n        dates.append(start_date.strftime(\"%Y %b-%d\"))\n        start_date = (start_date+datetime.timedelta(days = 7))\n        count = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = go.Figure(data=go.Scatter(x=dates, y=counts,line=dict(color='firebrick', width=4)))\nfig.update_layout(title='No of Tweets by POTUS',\n                   xaxis_title='No of Tweets',\n                   yaxis_title='Week',\n                  xaxis = go.layout.XAxis(\n        tickangle = 270))\nfig.update_xaxes(nticks=10)\nfig.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There was a slight increase in no of tweets per week that peaked in the week of october 4th 2019"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":" def clean_tweet(tweet): \n        ''' \n        Utility function to clean tweet text by removing links, special characters \n        using simple regex statements. \n        '''\n        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n  \n  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"tweets_filter['content'] = tweets_filter.content.apply(clean_tweet)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def get_tweet_sentiment(tweet): \n        ''' \n        Utility function to classify sentiment of passed tweet \n        using textblob's sentiment method \n        '''\n        # create TextBlob object of passed tweet text \n        analysis = TextBlob(tweet.lower()) \n        # set sentiment \n        if analysis.sentiment.polarity > 0: \n            return 'positive'\n        elif analysis.sentiment.polarity == 0: \n            return 'neutral'\n        else: \n            return 'negative'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"%%time\ntweets_filter['sentiment'] = tweets_filter.content.apply(get_tweet_sentiment)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"%%time\nword_cloud_data = {}\nNER_data = {}\nfor sentiment in tweets_filter.sentiment.unique():\n    data_filter = tweets_filter[(tweets_filter.formatted_date.dt.date >= \\\n                                 datetime.datetime(2017,1,1).date())&\\\n                               (tweets_filter.sentiment == sentiment)]\n    tweetText = data_filter.content.tolist()\n    words = []\n    NER = []\n    for t in tweetText:\n        doc = nlp(t)\n        ner = []\n        for ent in doc.ents:\n            NER.append(ent.label_)\n        for w in t.split():\n            if w.strip().lower() not in STOPWORDS:\n                words.append(w.strip().lower())\n    word_cloud_data[sentiment] = words\n    NER_data[sentiment] = NER","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(12,6))\ntweets_filter.sentiment.value_counts().plot(kind = \"bar\", title = \"# Tweets\")\nplt.xlabel('Sentiment')\nplt.ylabel('Tweets')\n# plt.title.set_text(\"No of tweets\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The POTUS Tweets positively**"},{"metadata":{},"cell_type":"markdown","source":"**A word cloud of tweets by the POTUS**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"%%time\nfig = plt.figure(figsize=(24,24))\naxes = fig.subplots(nrows=3, ncols=1)\ncounter = 0\nfor row in axes:\n    unique_string = (\" \").join(list(word_cloud_data.values())[counter])\n    wordcloud = WordCloud(width = 1500, height = 750, background_color = \"white\").generate(unique_string)\n    row.title.set_text(list(word_cloud_data.keys())[counter])\n    row.imshow(wordcloud)\n    row.axis(\"off\")\n    counter+=1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**A breakdown of Entities the POTUS talks about in the tweets**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"%%time\nfor sentiment in tweets_filter.sentiment.unique():\n    counter = Counter(NER_data[sentiment])\n    labels = list(counter.keys())\n    values = list(counter.values())\n    fig = go.Figure(data=[go.Pie(labels=labels, values=values)])\n    fig.update_layout(title = sentiment)\n    fig.show()\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}