{"cells":[{"metadata":{"_cell_guid":"869a833b-f230-4de5-0e29-832c941ebe63","_uuid":"2a0131b9d50cdc999db1b6e307cf6523a9b3cd96"},"cell_type":"markdown","source":"### Classification modeling of breast cancer data "},{"metadata":{"_cell_guid":"68b5ba03-c522-fdc1-b7a7-3cfb8111d27f","_uuid":"5570ff5a18eb782cd19c473fae1175c2ba166f0f"},"cell_type":"markdown","source":"In the previous blog, collinearity issues were addressed by removing some of the variables from the data  and PCA was applied to reduce the dimensionality. The reduced data is used here in this blog for modeling breast cancer. Since, we do not know the best model for this problem, first selected classification models will be compared and later the best will be fitted to the data for prediction purposes. \n\nThe classification models compared are K-nearest Neighbors, Support Vector Classifier, and Logistic Regression.  "},{"metadata":{"_cell_guid":"43f8b352-ff59-db53-a7f3-1b6e462e43ef","trusted":true,"_uuid":"38eb2a538c2116a1fbeaa28a94cc3050422563ae"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom matplotlib import pyplot as plt\nfrom sklearn.decomposition import PCA\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"96c40b55-e0f6-bf5d-8de0-43e339a40d9a","trusted":true,"_uuid":"f896ae2ebbeba10e38a8e5472aecf0423f46e3e1"},"cell_type":"code","source":"# loading the raw data\nbc=pd.read_csv(\"../input/data.csv\")\nbc.head()  \nP=bc.iloc[:,2:32]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"69c08fa1-c0fd-507d-23d5-8843c8809785","trusted":true,"_uuid":"89dee4a0fe2095830da1b72cfa2a09402af93556"},"cell_type":"code","source":"# summary stat of the raw data\nbc.iloc[:,2:32].describe() ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7839a07a-13e3-5023-59d8-b6360af77d40","trusted":true,"_uuid":"7e5e5c27f47f032dd04b7c3d76415ecb21f3d55d"},"cell_type":"code","source":"yd=pd.get_dummies(bc.diagnosis)\ny=yd.M\ny.head() # response variable","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"09ff7360-d799-1427-1a04-0228e11d31a5","trusted":true,"_uuid":"6bf7d890a20770f85ad9baba68598a81e7ad0b32"},"cell_type":"code","source":"# standardizing and PCA\nscaler = StandardScaler()\nP_scaled=scaler.fit_transform(P)\nP_scaled=pd.DataFrame(P_scaled)\nPP=P_scaled.drop(P_scaled.columns[[2, 3, 22, 23, 12, 13]], axis=1) \npca=PCA(n_components=0.95)\nP_pca=pca.fit_transform(PP)\nprint (P_pca.shape)\nprint(pca.explained_variance_ratio_) \nprint (pca.explained_variance_ratio_.sum())","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e2ebdb3e-1e0f-d034-2954-f1868de9d8a1","trusted":true,"_uuid":"8d14671033a4b38df8f5b84733399c3eb2521ac4"},"cell_type":"code","source":"n=['PC1','PC2','PC3','PC4','PC5','PC6','PC7','PC8','PC9','PC10','PC11','diagnosis']\nd=bc.iloc[:,1:2]  # diagnosis column\n#merging the reduced data with diagnosis column\nXy=pd.DataFrame(np.hstack([P_pca,d.as_matrix()]),columns=n)\n# plotting the the first 2 pca components against diagnosis\nsns.lmplot(\"PC1\", \"PC2\", hue=\"diagnosis\", data=Xy, fit_reg=False,markers=[\"o\", \"x\"],palette=\"Set1\")\nsns.plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"fbb9cfa2-f463-bab1-59a0-ab7bbe6fb1eb","_uuid":"0e20d106154311a28f7c63e97bfdc5deeff9ab39"},"cell_type":"markdown","source":"## Modeling \nFrom the above plot, we can see that the positive and negative cases (i.e. B and M) have fairly distinctive regions, this makes it easier to fit linear or non-linear classifiers to model the problem. Below, **k-neighbors,Support Vector MAchine(SVM), and Linear Discriminant Analysis (LDA)** classifiers are fit to the data and later results are compared."},{"metadata":{"_cell_guid":"58b4aa6d-560d-ab8a-96f6-bc8f3324b77e","_uuid":"de50b5327b7670d518de50f42b3b5ae2bf7c987f"},"cell_type":"markdown","source":"#### Splitting the data: training and test "},{"metadata":{"_cell_guid":"561e3c28-2218-a654-47f2-8b69659ad0d6","trusted":true,"_uuid":"c32c4198f42b8629718454b38a7e818e52760a17"},"cell_type":"code","source":"from sklearn.cross_validation import train_test_split\n#predictor X\nX=(Xy.iloc[:,0:11]).as_matrix()\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"87cc8390-8f88-e43e-2a8c-2a68142e25d6","_uuid":"879a6033a5a87d6603527e810f269457b730647b"},"cell_type":"markdown","source":"### 1. K-nearest Neighbors classifier"},{"metadata":{"_cell_guid":"8cc3dbf0-f270-d42d-6278-6a1c655fe96d","trusted":true,"_uuid":"ef2e172cc77d964e391ae75215fa950c9949a0a5"},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.cross_validation import cross_val_score\nknn=KNeighborsClassifier()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d34fc31f-a675-ca25-0967-aedd2636a84d","_uuid":"eb93815c9ad1c721126ca8098660bf9c3a3aa471"},"cell_type":"markdown","source":"**Parameter tuning: optimizing the number of neighbors (k)**\n* For optimization purposes it is suggested using the training data; and\n* for performance estimation or to figure out the best model, the test data will be used."},{"metadata":{"_cell_guid":"ce61922d-f62b-8160-ff98-3ffebdc675ae","trusted":true,"_uuid":"591f83c6bca86cd82f4362d89ebdab15132e0f61"},"cell_type":"code","source":"k_range=list(range(1,50))\nk_scores=[]\nfor k in k_range:\n    knn=KNeighborsClassifier(n_neighbors=k)\n    scores=cross_val_score(knn, X_train,y_train,cv=10,scoring='recall')\n    k_scores.append(scores.mean())\nprint(np.round(k_scores,3)) # to display scores to 3 decimal places\nfrom matplotlib import pyplot as plt\nplt.plot(k_range,k_scores,color=\"red\")\nplt.xlabel('k values')\nplt.ylabel('Recall')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"450da1ef-17ce-24c9-90f8-6b8e265cfd82","_uuid":"87e58003e1015470cc106a4bdf8a5713fd5128e6"},"cell_type":"markdown","source":"* From the above plot the optimal k value is somewhere between 1 and 10. Looking at the scores, at k=5 we have the highest recall/sensitivity.\n* We can use a more efficient parameter tuning approach called **GridSearchCV** as shown below which basically automates the search process and it also fits the optimal parameter to the training data."},{"metadata":{"_cell_guid":"e1500c75-0589-44fd-c082-3babec1ac82b","trusted":true,"_uuid":"732a9d0e5051c1c521596fd286964bc68d0eeb23"},"cell_type":"code","source":"from sklearn.grid_search import GridSearchCV\nk_range=list(range(1,50))\nparam_grid=dict(n_neighbors=k_range)\nscores = ['accuracy', 'recall'] # evaluation scores for selecting best parameter\nfor sc in scores:\n    grid_knn=GridSearchCV(knn,param_grid,cv=10,scoring=sc,n_jobs=-1)\n    print(\"# Tuning hyper-parameters for %s\" % sc)\n    grid_knn.fit(X_train,y_train)\n    print(grid_knn.best_params_)\n    print(np.round(grid_knn.best_score_,3))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4573a985-5def-6d6e-e8dd-c5dac3eb5d3b","_uuid":"14c792378bb852f9f8b6665574608be8c0b10483"},"cell_type":"markdown","source":"* Here, the optimal n_neighbors according to recall score (sensitivity) is **selected i.e.k=5** instead of k=6. As we are more concerned in predicting cancer cases (M) accurately rather than no-cancer cases (B), we go with results found using recall or sensitivity score."},{"metadata":{"_cell_guid":"8bee09c2-fead-439e-ec7f-4a77fd77d8fa","trusted":true,"_uuid":"16af57113c94b9d027181a5ab7b60c252907a0bd"},"cell_type":"code","source":"# fitting the optimal model (i.e. knn with k=5 based upon recall score) onto the training data\nknn=KNeighborsClassifier(n_neighbors=5)\nknn.fit(X_train, y_train)\n\n# for display purposes, we fit the model on the first two components i.e. PC1, and PC2\nknn.fit(X_train[:,0:2], y_train)\n# Plotting the decision boundary for all data (both train and test)\n# Create color maps\nfrom matplotlib.colors import ListedColormap\ncmap_light = ListedColormap(['#AAFFAA','#FFAAAA'])\ncmap_bold = ListedColormap(['#0000FF','#FF0000'])\n# creating a meshgrid\nx_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\ny_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\nh=0.05\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h),np.arange(y_min, y_max, h))\nxy_mesh=np.c_[xx.ravel(), yy.ravel()]\nZ = knn.predict(xy_mesh)\n%matplotlib inline\nZ = Z.reshape(xx.shape)\n#print(Z)\nplt.figure()\nplt.pcolormesh(xx, yy, Z, cmap=cmap_light)\nax=plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold)\nplt.xlim(xx.min(), xx.max());plt.ylim(yy.min(), yy.max())\nplt.xlabel('PC1');plt.ylabel('PC2')\nplt.title('KNN')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"cda00849-bf4e-4ab9-570c-85a2e81de990","_uuid":"662a78c031b64e0c33c3b442502950d13c8a44a8"},"cell_type":"markdown","source":"#### 2. Support Vector Machine (SVM)"},{"metadata":{"_cell_guid":"0ba22d0a-020a-f7aa-71f6-09c34617a72b","trusted":true,"_uuid":"6924ad77be6718a1bfbeb1470f7c1df7c07a1a96"},"cell_type":"code","source":"from sklearn.cross_validation import cross_val_score\nfrom sklearn.svm import SVC\nsvc=SVC()\nparam_grid = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4, 1e-5],'C': [1, 10, 100, 1000]},\n              {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\nscores = ['accuracy', 'recall']\nfor sc in scores:\n    grid=GridSearchCV(svc,param_grid,cv=10,scoring=sc,n_jobs=-1)\n    print(\"# Tuning hyper-parameters for %s\" % sc)\n    grid.fit(X_train,y_train)\n    print(grid.best_params_)\n    print(np.round(grid.best_score_,3))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"61e2c735-961d-7b21-f051-8e71cb2c752d","_uuid":"36c5a4719de97713a1fb6b864da1ad9d15577c85"},"cell_type":"markdown","source":"* Using accuracy and recall as scoring metrics, both give the same model as optimal i.e. {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}. Here below, we fit this model to the data and do visualization of the results."},{"metadata":{"_cell_guid":"f6624a12-012a-9013-53f0-f40904888b37","trusted":true,"_uuid":"5b02b540cb8e4b758194adcbf95c70c04f92bca5"},"cell_type":"code","source":"from sklearn import metrics\nfrom sklearn import cross_validation as cv\n\n# fitting the optimal model onto the training data\nsvc=SVC(C=100,gamma=0.001,kernel='rbf')\nsvc.fit(X_train, y_train)\n\n# for display purposes, we fit the model on the first two components i.e. PC1, and PC2\nsvc.fit(X_train[:,0:2], y_train)\n\n# Plotting the decision boundary for all data (both train and test)\n# Create color maps\nfrom matplotlib.colors import ListedColormap\ncmap_light = ListedColormap(['#AAFFAA','#FFAAAA'])\ncmap_bold = ListedColormap(['#0000FF','#FF0000'])\n\n# creating a meshgrid\nx_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\ny_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\nh=0.05\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h),np.arange(y_min, y_max, h))\nxy_mesh=np.c_[xx.ravel(), yy.ravel()]\nZ = svc.predict(xy_mesh)\nZ = Z.reshape(xx.shape)\n\n#plotting data on decision boundary\n%matplotlib inline\nplt.figure()\nplt.pcolormesh(xx, yy, Z, cmap=cmap_light)\nplt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold)\nplt.xlim(xx.min(), xx.max())\nplt.ylim(yy.min(), yy.max())\nplt.xlabel('PC1');plt.ylabel('PC2')\nplt.title('SVC')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6788c9b9-81bb-0bd6-77ca-e26578c0da58","_uuid":"2041d8f5434ba4b8536d0673ae407fbcc882868f"},"cell_type":"markdown","source":"#### 3. Logistic Regression"},{"metadata":{"_cell_guid":"85ae1da9-6c79-baaf-e60f-941dc2c0fc21","trusted":true,"_uuid":"dfeb249761dc0090a61f6865e195e7d07e7df1e5"},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.cross_validation import cross_val_score\nfrom sklearn.grid_search import GridSearchCV\n\nlgr = LogisticRegression()\n\n#parameter tuning\nparam_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] }\nscores = ['accuracy', 'recall']\nfor sc in scores:\n    grid_lgr=GridSearchCV(lgr,param_grid,cv=10,scoring=sc,n_jobs=-1)\n    print(\"# Tuning hyper-parameters for %s\" % sc)\n    grid_lgr.fit(X_train,y_train)\n    print(grid_lgr.best_params_)\n    print(np.round(grid_lgr.best_score_,3))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b9244ef2-f82e-b945-ff56-175b4e4cf640","trusted":true,"_uuid":"ba5db182e588bc06684918dc3810f52015ee4c2a"},"cell_type":"code","source":"# fitting the optimal model onto the training data\nfrom sklearn import metrics\nfrom sklearn import cross_validation as cv\n\n# fitting the optimal model onto the training data\nlgr=LogisticRegression(C=1)\nlgr.fit(X_train, y_train)\n\n# for display purposes, we fit the model on the first two components i.e. PC1, and PC2\nlgr.fit(X_train[:,0:2], y_train)\n\n# Plotting the decision boundary for all data (both train and test)\n# Create color maps\nfrom matplotlib.colors import ListedColormap\ncmap_light = ListedColormap(['#AAFFAA','#FFAAAA'])\ncmap_bold = ListedColormap(['#0000FF','#FF0000'])\n\n# creating a meshgrid\nx_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\ny_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\nh=0.05\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h),np.arange(y_min, y_max, h))\nxy_mesh=np.c_[xx.ravel(), yy.ravel()]\nZ = lgr.predict(xy_mesh)\nZ = Z.reshape(xx.shape)\n\n%matplotlib inline\n#print(Z)\nplt.figure()\nplt.pcolormesh(xx, yy, Z, cmap=cmap_light)\nplt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold)\nplt.xlim(xx.min(), xx.max())\nplt.ylim(yy.min(), yy.max())\nplt.xlabel('PC1');plt.ylabel('PC2')\nplt.title('Logistc Regression')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_execution_state":"idle","_cell_guid":"f482d941-5529-850b-fd53-f034b36cc0a1","_uuid":"481c0d49ca1d779ddc1bc5aec52bef5d8bae53ed"},"cell_type":"markdown","source":"SVC and Logistic regression scored similar performance, but we should be careful since the model has not yet tested on test data or on data independent of the one used for training the models. Below, we fit the three models onto the test data (X_test) and compare the predictions (y_predict) with observations (y_test). For this purpose, various evaluation metrics are implemented. "},{"metadata":{"_cell_guid":"1652d458-3f8c-639a-a8e0-c49657887f5b","_uuid":"ab0ecf67436c2eef920893e1c784bbdcee4e2550"},"cell_type":"markdown","source":"#### Model Selection"},{"metadata":{"_cell_guid":"024e608e-e17d-0898-4789-de7b14238f61","trusted":true,"_uuid":"b438ac29f4f912f17810be256f1e33cc6ea79772"},"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\n\n# KNN\n# fitting the knn model on the training data\nknn=KNeighborsClassifier(n_neighbors=5)\nknn.fit(X_train, y_train)\ny_pred_knn =knn.predict(X_test)\n# computing and plotting confusion matrix\nc_m = confusion_matrix(y_test, y_pred_knn)\nprint('KNN:\\n confusion matrix\\n', c_m,'\\n\\n')\nax=plt.matshow(c_m,cmap=plt.cm.Reds)\nprint('Confusion matrix plot of KNN classifier')\nplt.colorbar(ax)\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.show()\n# classification report\nprint('\\n Classification report \\n',classification_report(y_test, y_pred_knn))\nprint ('#############################################################################')\n\n# SVC\n# fitting the SVC model on the training data and predicting for test data\nsvc=SVC(C=100,gamma=0.001,kernel='rbf',probability=True)\nsvc.fit(X_train, y_train)\ny_pred_svc =svc.predict(X_test)\n# computing and plotting confusion matrix\nc_m = confusion_matrix(y_test, y_pred_svc)\nprint('SVC:\\n confusion matrix\\n', c_m,'\\n\\n')\nax=plt.matshow(c_m,cmap=plt.cm.Reds)\nprint('Confusion matrix plot of SVC')\nplt.colorbar(ax)\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.show()\n# classification report\nprint('\\n Classification report \\n',classification_report(y_test, y_pred_svc))\nprint ('#############################################################################')\n\n# Logistic Regression\n# fitting the lgr model on the training data\nlgr=LogisticRegression(C=1)\nlgr.fit(X_train, y_train)\ny_pred_lgr =lgr.predict(X_test)\n# computing and plotting confusion matrix\nc_m = confusion_matrix(y_test, y_pred_lgr)\nprint('Logistic Regression:\\nconfusion matrix\\n', c_m,'\\n\\n')\nax=plt.matshow(c_m,cmap=plt.cm.Reds)\nprint('Confusion matrix plot of Logistic regression')\nplt.colorbar(ax)\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.show()\n# classification report\nprint('\\n Classification report \\n',classification_report(y_test, y_pred_lgr))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d373d9e1-8524-d781-1d3e-0cfa862a9b00","_uuid":"6a1cb117ca912dc82eb6f424c58f4f3c383fc3f3"},"cell_type":"markdown","source":"* Scores on Malignant cases from each model are summarized as below:\n\n\n\n| Model         | Precision  | Recall | f1-score |\n| ------------- |:----------:| -----: | --------:|\n| KNN           | 0.98       |   0.91 | 0.94     |\n| SVC           | 0.98       |   0.94 | 0.96     |\n| Logistic      | 0.98       |   0.94 | 0.96     |\n\n"},{"metadata":{"_cell_guid":"60deb5c0-94ac-5ce7-5ad5-060419c6c9cd","_uuid":"d95cb4b5d4da5acb1fefdba0dc966641f12fb87f"},"cell_type":"markdown","source":"** Conclusion:**\n\n* As results show, both SVC and logistic regression are performing equally good. One may choose either of the models on the basis of other factors such as simplicity in parameter tuning and ease of interpritation and so on.\n* Threshold of 0.5 is used by default (for binary problems) to convert predicted probabilities into class predictions\n* Threshold can be adjusted to increase sensitivity or specificity. Specificity explains how often is the prediction correct when the actual value is negative (0). Sensitivity and specificity have an inverse relationship.\n* For this sepcific case, sensitivity is more important so we focus finding the threshold level which can give us the highest sensitivity. \n* We can manually change the threshold level and evaluate results. But instead we can plot ROC curve and see the effect of threshold on sensitivity and specificity. "},{"metadata":{"_cell_guid":"51533fbb-1972-9ba4-1ea9-d23b3ee0281c","_uuid":"a0a0efc45c33b3d4e732f7db8fb64969059c00ce"},"cell_type":"markdown","source":"#### Effect of classification threshold on model performance\n* Threshold of 0.5 is used by default to convert predicted probabilities to class predictions. Threshold can be adjusted to increase sensitivity/recall "},{"metadata":{"_cell_guid":"508c5da0-7d58-e7ea-c45b-deeed14016d4","trusted":true,"_uuid":"8c8246e4e3aaca298f8a1ed1bae5fec7c81cb7b9"},"cell_type":"code","source":"# false positive rate,fpr= FP/(TN+FP) OR fpr=1-specificty, tpr=sensitivity \ny_pred_knn_p =knn.predict_proba(X_test)[:,1]\ny_pred_svc_p =svc.predict_proba(X_test)[:,1]\ny_pred_lgr_p =lgr.predict_proba(X_test)[:,1]\n\nmodels=[y_pred_knn_p,y_pred_svc_p,y_pred_lgr_p]\nlabel=['KNN','SVC','Logistic']\n\n# plotting ROC curves\nplt.figure(figsize=(10, 8))\nm=np.arange(3)\nfor m in m:\n    fpr, tpr,thresholds= metrics.roc_curve(y_test,models[m])\n    print('model:',label[m])\n    print('thresholds:',np.round(thresholds,3))\n    print('tpr:       ',np.round(tpr,3))\n    print('fpr:       ',np.round(fpr,3))\n    plt.plot(fpr,tpr,label=label[m])\nplt.xlim([0.0,1.0])\nplt.ylim([0.0,1.0])\nplt.title('ROC curve for Cancer classifer')\nplt.xlabel('False positive rate (1-specificity)')\nplt.ylabel('True positive rate (sensitivity)')\nplt.legend(loc=4,)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bd2bac32-5dcd-2d77-d985-f2a2107d6d20","_uuid":"66724a0c20167e883bf52d837f8b8ce6cd599ae3"},"cell_type":"markdown","source":"* From the ROC curve, KNN has resulted the least peformance among the three models. SVC and Logistic seem to have the same performance for thresholds ~0.25 and above but for threshold below 0.25 svc performs better than logistic. \n* From these, we can lean to scv as its overall performace is better under various threshold levels. Therefore, \n  * **Optimal model: svc with C=100, gamma=0.001, kernel=rbf, and threshold value of 0.44**\n      * by changing the treshold from its default value of 0.5 to 0.44, the sensitivity increases from 0.94 to 0.962. \n  "}],"metadata":{"_change_revision":0,"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"},"_is_fork":false,"language_info":{"pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","name":"python","nbconvert_exporter":"python","version":"3.6.1","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}