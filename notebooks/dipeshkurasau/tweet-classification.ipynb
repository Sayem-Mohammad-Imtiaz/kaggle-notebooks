{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nfrom nltk.corpus import stopwords \nfrom nltk.tokenize import word_tokenize \nfrom nltk.corpus import words\n\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import roc_auc_score, accuracy_score, classification_report\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression, RidgeClassifier, Lasso\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import preprocessing\n\nfrom nltk.stem import WordNetLemmatizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/covid-19-nlp-text-classification/Corona_NLP_train.csv', encoding=\"ISO-8859-1\", low_memory=False)\ntest = pd.read_csv('/kaggle/input/covid-19-nlp-text-classification/Corona_NLP_test.csv', encoding=\"ISO-8859-1\", low_memory=False) \ndf = train.append(test, sort = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Sentiment'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mapping = {'Neutral' : 0, 'Positive' : 1, 'Extremely Negative' : -1, 'Negative' : -1,'Extremely Positive' : 1}\ndf['label'] = df['Sentiment'].map(mapping)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns_to_keep = ['OriginalTweet','label']\ndf = df[columns_to_keep]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Removing Urls"},{"metadata":{"trusted":true},"cell_type":"code","source":"def url_cleaning(tweet):\n    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n    return url_pattern.sub(r'link', tweet)\n\ndf['OriginalTweet'] = df['OriginalTweet'].apply(url_cleaning)\ndisplay(df['OriginalTweet'].head(5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef text_cleaning_1(tweet):\n    tweet = re.sub(r\" usa \", \" America \", tweet)\n    tweet = re.sub(r\" USA \", \" America \", tweet)\n    tweet = re.sub(r\" u s \", \" America \", tweet)\n    tweet = re.sub(r\" uk \", \" England \", tweet)\n    tweet = re.sub(r\" UK \", \" England \", tweet)\n    tweet = re.sub(r\"USAgov\", \"USA government\", tweet)\n    tweet = re.sub(r\"the US\", \"America\", tweet)\n    tweet = re.sub(r\"Coronavirus\", \" covid \", tweet)\n    tweet = re.sub(r\"Covid19\", \" covid \", tweet)\n    tweet = re.sub(r\"\\W\", \" \", tweet)\n    tweet = re.sub(r\"_\", \" \", tweet)\n    return str(tweet)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['OriginalTweet'] = df['OriginalTweet'].apply(text_cleaning_1)\ndisplay(df['OriginalTweet'].head(5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Lower Case"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['OriginalTweet'] = df['OriginalTweet'].str.lower()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Removing Stop words"},{"metadata":{"trusted":true},"cell_type":"code","source":"def stop_word(tweet): \n    stop_words = set(stopwords.words('english')) \n\n    word_tokens = word_tokenize(tweet) \n    filtered_sentence = [w for w in word_tokens if not w in stop_words] \n    filtered_sentence = [] \n\n    for w in word_tokens: \n        if w not in stop_words: \n            filtered_sentence.append(w) \n    return ' '.join(filtered_sentence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['OriginalTweet'] = df['OriginalTweet'].apply(stop_word)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['OriginalTweet'].head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#spell = SpellChecker()\ndef correct_spellings(text):\n    corrected_text = []\n    misspelled_words = spell.unknown(text.split())\n    words = text.split()\n    for word in words:\n        if word in misspelled_words:\n            corrected_text.append(spell.correction(word))\n        elif word not in misspelled_words:\n            corrected_text.append(word)\n    return \" \".join(corrected_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df['OriginalTweet'] = df['OriginalTweet'].apply(correct_spellings)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tokenize and Lemmatizer"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['OriginalTweet'] = df['OriginalTweet'].apply(word_tokenize)\nlem = WordNetLemmatizer()\ndef lemma_wordnet(input):\n    return [lem.lemmatize(w) for w in input]\ndf['OriginalTweet'] = df['OriginalTweet'].apply(lemma_wordnet)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def combine_word(tweet):\n    return \" \".join(tweet)\ndf['OriginalTweet'] = df['OriginalTweet'].apply(combine_word)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Split data into Train and Test data sets "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n\nX_train, X_test, y_train, y_test = train_test_split(df['OriginalTweet'], \n                                                    df['label'], \n                                                    random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Vectorization with CountVectorizer"},{"metadata":{"trusted":true},"cell_type":"code","source":"vect = CountVectorizer(min_df=5, ngram_range=[1,4], analyzer='char_wb').fit(X_train)\nX_train_vect = vect.transform(X_train)\nX_test_vect = vect.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Vectorization with TFID vectorizer"},{"metadata":{"trusted":true},"cell_type":"code","source":"vect = TfidfVectorizer(min_df=3, ngram_range=[1,4]).fit(X_train)\nX_train_vect_TFID = vect.transform(X_train)\nX_test_vect_TFID = vect.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Applying ML"},{"metadata":{"trusted":true},"cell_type":"code","source":"def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n    lb = preprocessing.LabelBinarizer()\n    lb.fit(y_test)\n    y_test = lb.transform(y_test)\n    y_pred = lb.transform(y_pred)\n    return roc_auc_score(y_test, y_pred, average=average)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### MultinomialNB"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"MultinomialNB with CountVectorizer\\n\")\nalpha = [0.01, 0.1, 1.0, 5.0, 10.0, 20.0, 100.0]\nfor value in alpha:\n    model = MultinomialNB(alpha = value).fit(X_train_vect, y_train)\n    y_predicted = model.predict(X_test_vect)\n    score = multiclass_roc_auc_score(y_test, y_predicted)\n    acc_score = accuracy_score(y_test, y_predicted)\n    print(f\"With alpha set to {value}, AUC score of model is {score} and Accuracy Score is {acc_score}\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"MultinomialNB with Tfid Vectorizer\\n\")\nalpha = [0.01, 0.1, 1.0, 5.0, 10.0, 20.0, 100.0]\nfor value in alpha:\n    model = MultinomialNB(alpha = value).fit(X_train_vect_TFID, y_train)\n    y_predicted = model.predict(X_test_vect_TFID)\n    score = multiclass_roc_auc_score(y_test, y_predicted)\n    acc_score = accuracy_score(y_test, y_predicted)\n    print(f\"With alpha set to {value}, AUC score of model is {score} and Accuracy Score is {acc_score}\\n\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"####  Decision Tree Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"DecisionTreeClassifier with CountVectorizer\\n\")\ndepth = [3,6,9,12,15]\nfor value in depth:\n    model = DecisionTreeClassifier(max_depth = value).fit(X_train_vect, y_train)\n    y_predicted = model.predict(X_test_vect)\n    score = multiclass_roc_auc_score(y_test, y_predicted)\n    acc_score = accuracy_score(y_test, y_predicted)\n    print(f\"With max_depth set to {value}, AUC score of model is {score} and Accuracy Score is {acc_score}\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"DecisionTreeClassifier with CountVectorizer\\n\")\ndepth = [3,6,9,12,15]\nfor value in depth:\n    model = DecisionTreeClassifier(max_depth = value).fit(X_train_vect_TFID, y_train)\n    y_predicted = model.predict(X_test_vect_TFID)\n    score = multiclass_roc_auc_score(y_test, y_predicted)\n    acc_score = accuracy_score(y_test, y_predicted)\n    print(f\"With max_depth set to {value}, AUC score of model is {score} and Accuracy Score is {acc_score}\\n\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Logistic Regression with CountVectorizer\\n\")\nC = [ 1, 5, 10, 20, 100, 1000]\nfor value in C:\n    model = LogisticRegression(C = value,solver='lbfgs').fit(X_train_vect, y_train)\n    y_predicted = model.predict(X_test_vect)\n    score = multiclass_roc_auc_score(y_test, y_predicted)\n    acc_score = accuracy_score(y_test, y_predicted)\n    print(f\"With C set to {value}, AUC score of model is {score} and Accuracy Score is {acc_score}\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Logistic Regression with Tfid Vectorizer\\n\")\nC = [ 1, 5, 10, 20, 100, 1000]\nfor value in C:\n    model = LogisticRegression(C = value,solver='lbfgs').fit(X_train_vect_TFID, y_train);\n    y_predicted = model.predict(X_test_vect_TFID); \n    score = multiclass_roc_auc_score(y_test, y_predicted);\n    acc_score = accuracy_score(y_test, y_predicted)\n    print(f\"With C set to {value}, AUC score of model is {score} and Accuracy Score is {acc_score}\\n\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Rigid"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Rigid with Tfid Vectorizer\\n\")\nC = [ 1, 5, 10, 20, 100, 1000]\nfor value in C:\n    model = RidgeClassifier(alpha = value).fit(X_train_vect_TFID, y_train)\n    y_predicted = model.predict(X_test_vect_TFID)\n    score = accuracy_score(y_test, y_predicted)\n    acc_score = multiclass_roc_auc_score(y_test, y_predicted)\n    print(f\"With C set to {value}, AUC score of model is {score} and Accuracy Score is {acc_score}\\n\");","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}