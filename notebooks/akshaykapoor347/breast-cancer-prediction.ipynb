{"cells":[{"metadata":{"_uuid":"00f70dbac0e459236d65da760d86c0829851b993"},"cell_type":"markdown","source":"# Breast cancer detection\ndataset source: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)\n"},{"metadata":{"_uuid":"c2bb9af2345d606cb31bdf86ee8c316ec7317a62"},"cell_type":"markdown","source":"We have 30 different attributes from images extracted, Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. <br>\nWe predict the Stage of Breast Cancer B (Bengin) or M (malignant)."},{"metadata":{"_uuid":"66a3ef535510a356b68aa4b188dda7edf1f3148c"},"cell_type":"markdown","source":"**Attribute Information:**\n<br>\n1) ID number <br>\n2) Diagnosis (M = malignant, B = benign) <br>\n3-32) <br>\n\nTen real-valued features are computed for each cell nucleus: <br>\n\na) radius (mean of distances from center to points on the perimeter) <br>\nb) texture (standard deviation of gray-scale values) <br>\nc) perimeter <br>\nd) area <br>\ne) smoothness (local variation in radius lengths) <br>\nf) compactness (perimeter^2 / area - 1.0) <br>\ng) concavity (severity of concave portions of the contour) <br>\nh) concave points (number of concave portions of the contour) <br>\ni) symmetry <br>\nj) fractal dimension (\"coastline approximation\" - 1) <br>"},{"metadata":{"trusted":true,"_uuid":"9648314e801c7f497e1794dc4ddc85e8ded2731e"},"cell_type":"code","source":"#Importing the libraries\n\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport seaborn as sns \n%matplotlib inline\n\n#scikit learn libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.cross_validation import KFold\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import metrics\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"76e54a7180d40635e626b64e43b2f322a00808e3"},"cell_type":"markdown","source":"## Let us learn more about the data "},{"metadata":{"trusted":true,"_uuid":"3526d45ab8647e341a43596310b1273e0d00fdbe"},"cell_type":"code","source":"df = pd.read_csv(\"../input/data.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71d68148197aef240fb916d6d7936df1fadabddf"},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bef9cc071d3df5b96c390bc436935eb01382d3f3"},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"da3d2f6ee4e7374ac868eea43bbad23230125788"},"cell_type":"code","source":"#We can see Unnamed:32 has all null values hence we cannot use this column for our analysis and id will also be of no use for analysis\ndf.drop('Unnamed: 32', axis  = 1, inplace=True)\ndf.drop('id', axis = 1, inplace= True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c62ea2c9444f826bfd97836528f01a4198e2a822"},"cell_type":"code","source":"#Let us convert 'Malign' and 'Benign' to 1 and 0 respectively so it will be easier for analysis\n\ndf['diagnosis'] = df['diagnosis'].map({'M':1,'B':0})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"29978d4ed2ef16ad117863e9884b0b57afe3e3d0"},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5bd0a3ad983ac1c85c189144b533edf21125cf4c"},"cell_type":"markdown","source":"## Performing Exploratory Data Analysis\n"},{"metadata":{"trusted":true,"_uuid":"8848870f5266e37f34e8c39ac7f270b918b252a5"},"cell_type":"code","source":"sns.countplot(df['diagnosis'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9d756e16be921352f99236edc4ca2b5698bffd6e"},"cell_type":"markdown","source":"We can see there are almost double number patients with benign cancer"},{"metadata":{"trusted":true,"_uuid":"25e0c2e9934b9a263493c7ef5b99c37a52294087"},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9603ebf506bd59e7261fb9a62f96643e728e936a"},"cell_type":"code","source":"#The mean, standard error, and \"worst\" or largest (mean of the three largest values) of these features were computed for each image,resulting in 30 features.\n#For instance, field 3 is Mean Radius, field 13 is Radius SE, field 23 is Worst Radius.\n#more info at https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.names\n\nfirst = list(df.columns[1:10])\nsecond = list(df.columns[11:21])\nthird =  list(df.columns[21:30])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1d36ba60bb1b18fec1f131ae87fb03cc5df9d6f7"},"cell_type":"code","source":"#Let us find the correlation between different attributes\ncorr1 = df[first].corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0dd446dc8dc92f801ddbc78e786fb5cdf0abd20e"},"cell_type":"code","source":"#Let us visualize with a heatmap\nplt.figure(figsize=(14,10))\nsns.heatmap(corr1, cmap='coolwarm', xticklabels = first,  yticklabels = first, annot=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d3415f339beb7a94106a54426066bf714377b334"},"cell_type":"markdown","source":"**We can see that radius, perimeter and area are highly correlated as seen from the heatmap.** <br>\n**Also compactness_mean, concavepoint_mean and concavity_mean are highly correlated**\n"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"be34524b54e4fc656234ec98eb689b3a86e5cfd4"},"cell_type":"code","source":"#Let us perform analysis on the mean features\n\nmelign = df[df['diagnosis'] == 1][first]\nbening = df[df['diagnosis'] == 0][first]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"39f8f356d7ebf7bfad268044779af4960034a7de"},"cell_type":"code","source":"melign.columns","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true,"_uuid":"8fa3af16a8376e3c5552f6891f44db0d086d617d"},"cell_type":"code","source":"for columns in melign.columns:\n    plt.figure()\n    sns.distplot(melign[columns], kde=False, rug= True)\n    sns.distplot(bening[columns], kde=False, rug= True)\n    sns.distplot\nplt.tight_layout()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f0d4b6c7485e2cb8bcb98fa977561432e6054261"},"cell_type":"markdown","source":"We can see that the mean values of perimeter, area, concavity, compactness, radius and concave points can be used for classification as these parameters show a correlation. <br>\nWhile parameters such as smoothness, symmetry, fractual dimension and texture don't show much seperation and is of not much use for classification.\n"},{"metadata":{"scrolled":false,"trusted":true,"_uuid":"d22e2f1246377610ab579a893029fac3dfd8e999"},"cell_type":"code","source":"color_function = {0: \"green\", 1: \"red\"}\ncolors = df[\"diagnosis\"].map(lambda x: color_function.get(x))\n\npd.plotting.scatter_matrix(df[first], c=colors, alpha = 0.4, figsize = (15, 15));\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"46f19575292aeb9c9402721dba366d04da2451e0"},"cell_type":"markdown","source":"**Using a scatter matrix we can see a well seperation of malign and benign cancer with green points indication benign cancer cells and red points indicating malign cancer cells.**\n"},{"metadata":{"_uuid":"c269631c3a3352019a5fed8d41d63d61cc28a4ae"},"cell_type":"markdown","source":"## Machine learning\n"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"42ccec3e5ca4d330e0832877ee8658865612d111"},"cell_type":"code","source":"#We divide the data into Training and test set \ntrain, test = train_test_split(df, test_size = 0.25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"55049a20a392882b3702b60916a2170b5efa89a5"},"cell_type":"code","source":"# I have created a function to perform k folds cross validation which helps in obtaining a better insight to test the accuracy of the model\n# More info at https://www.analyticsvidhya.com/blog/2018/05/improve-model-performance-cross-validation-in-python-r/\n\ndef classification_model(model, data, predictors, outcome):\n  #Fit the model:\n  model.fit(data[predictors],data[outcome])\n  \n  predictions = model.predict(data[predictors])\n  \n  accuracy = metrics.accuracy_score(predictions,data[outcome])\n  print(\"Accuracy : %s\" % \"{0:.3%}\".format(accuracy))\n\n  #Perform k-fold cross-validation with 5 folds\n  kf = KFold(data.shape[0],n_folds= 5)\n  error = []\n  for train, test in kf:\n    # Filter the training data\n    train_predictors = (data[predictors].iloc[train,:])\n    train_target = data[outcome].iloc[train]\n    model.fit(train_predictors, train_target)\n    \n    error.append(model.score(data[predictors].iloc[test,:], data[outcome].iloc[test]))\n    \n    print(\"Cross-Validation Score : %s\" % \"{0:.3%}\".format(np.mean(error)))\n    \n  model.fit(data[predictors],data[outcome]) ","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true,"_uuid":"6d534fbd1617eed4dea006c06574706735088fe7"},"cell_type":"code","source":"#Using Logistic regression on the top five features\n#more info at https://en.wikipedia.org/wiki/Logistic_regression\n\npredictor_var = ['radius_mean','perimeter_mean','area_mean','compactness_mean','concave points_mean']\noutcome_var='diagnosis'\nmodel=LogisticRegression()\nclassification_model(model,train,predictor_var,outcome_var)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b0f9eea61b52be88a0a2fdb5d5269f4db154c8c2"},"cell_type":"code","source":"#Let us check the accuracy on test data\nclassification_model(model, test,predictor_var,outcome_var)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"50c2db4ac00538fe7b50c046c60dbddf873e413c"},"cell_type":"code","source":"#Let us try to classify using a decision tree classifier \npredictor_var = ['radius_mean','perimeter_mean','area_mean','compactness_mean','concave points_mean']\nmodel = DecisionTreeClassifier()\nclassification_model(model,train,predictor_var,outcome_var)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"efa07d5536a6412e010ccb100a03b93de45d43a4"},"cell_type":"markdown","source":"We are getting 100% accuracy! Is it overfitting let us try it on test data\n"},{"metadata":{"trusted":true,"_uuid":"4ee40ea61886c4a032940c968a709cdadede3c81"},"cell_type":"code","source":"classification_model(model, test,predictor_var,outcome_var)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"da6a76cef7d0f04e947370101f882992f253c0de"},"cell_type":"markdown","source":"Let us try using random forest"},{"metadata":{"trusted":true,"_uuid":"0fba306797fed847a6e8f1d2e12940e7bdc495c5"},"cell_type":"code","source":"predictor_var = first\nmodel = RandomForestClassifier()\nclassification_model(model, train,predictor_var,outcome_var)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"172ca60b4f645d46995887e723238fcafd4b63d5"},"cell_type":"code","source":"#Let us find the most important features used for classification model\n\nfeatimp = pd.Series(model.feature_importances_, index=predictor_var).sort_values(ascending=False)\nprint(featimp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce5a3a29cafd5901b126f0ab451df2201b797bee"},"cell_type":"code","source":"predictor_var = ['concave points_mean','area_mean','radius_mean','perimeter_mean','concavity_mean']\nmodel = RandomForestClassifier()\nclassification_model(model,train,predictor_var,outcome_var)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"be0c29da834bcfea3fe3e1bed656ea7577c23764"},"cell_type":"code","source":"# I think we get a better prediction with all the features now let us try it on test data!\npredictor_var = first\nmodel = RandomForestClassifier()\nclassification_model(model, test,predictor_var,outcome_var)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cb07757634116f79de0376bc1d6c2cae5f630eba"},"cell_type":"markdown","source":"## Conclusion\n\nHence we can see detailed exploratory data analysis of breast cancer data and implementation of classification algorithms to train a model in detecting whether the cancer is benign or malign.\n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}