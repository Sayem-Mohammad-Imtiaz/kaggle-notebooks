{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import keras\nfrom keras import optimizers\nfrom keras.preprocessing import image\nfrom keras.engine import Layer\nfrom keras.layers import Conv2D, Conv3D, UpSampling2D, InputLayer, Conv2DTranspose, Input, Reshape, merge, concatenate\nfrom keras.layers import Activation, Dense, Dropout, Flatten\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.callbacks import TensorBoard\nfrom keras.models import Sequential, Model\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\nfrom skimage.transform import resize, rescale\nfrom skimage.io import imsave, imread\nfrom time import time\nimport numpy as np\nimport os\nimport random\nimport tensorflow as tf\nfrom PIL import Image, ImageFile\nimport matplotlib.pyplot as plt\nimport glob","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dir = '/kaggle/input/celeba-dataset/img_align_celeba/img_align_celeba'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_rand_filename(samplesize, a, b):\n  filenames = []\n  for _ in range(samplesize):\n    randint = str(random.randint(a,b))\n    filestring = '/'+'0'*(6-len(randint))+randint+'.jpg'\n    filenames.append(filestring)\n  return filenames","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Visualize raw data\nfiles = []\nfilepaths = []\nnum_examples = 4\ncount = 1\n\n# for filename in glob.iglob(train_dir+'/*.jpg'):\nfilenames = generate_rand_filename(4, 104246, 104746)\nfor filename in filenames:\n  files.append(filename)\n  filepaths.append(train_dir+filename)\n  if count > num_examples:\n    break\n  count += 1\n\nfiles.sort()\nfilepaths.sort()\n\nfig = plt.figure(figsize=(20,10))\nfor i in range(num_examples):\n  fig.add_subplot(1, num_examples, i+1)\n  plt.imshow(plt.imread(filepaths[i]))\n  plt.title(files[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## constants\nnum_train_samples = 9000\nnum_val_samples = 1000\nimg_height = 224\nimg_width = 224\nbatch_size = 128\nepochs = 30","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class colorizationGenerator():\n  \n  def __init__(self, path, batch_size, filerange):\n    self.path = path\n    self.batch_size = batch_size\n    self.filerange = filerange\n\n  def get_input(self, path, filename):\n    img = imread(path+filename)\n    img = resize(img,(224,224,3))\n    labImage = rgb2lab(img)\n    return(labImage)\n\n  def get_output(self, labImage):\n    abch = labImage[:,:,1:]/128.0\n    return np.array(abch)\n\n  def preprocess_input(self, labImage):\n    lch = labImage[:,:,0]/100.0\n    l3ch = gray2rgb(lch)\n    return np.array(l3ch)\n\n  def random_flip(self, currinput, curroutput):\n    if random.uniform(0, 1) > 0.5:\n      currinput = currinput[:,::-1,:]\n      curroutput = curroutput[:,::-1,:]\n    return currinput, curroutput\n\n  def image_generator(self):\n      while True:\n            # Select files (paths/indices) for the batch\n            files = generate_rand_filename(self.batch_size, self.filerange[0], self.filerange[1])\n            batch_paths  = np.random.choice(a    = files, \n                                            size = self.batch_size)\n            batch_input  = []\n            batch_output = [] \n            \n            # Read in each input, perform preprocessing and get labels\n            for input_path in batch_paths:\n                currinput = self.get_input(self.path, input_path)\n                curroutput = self.get_output(currinput)\n                currinput = self.preprocess_input(currinput)\n\n                currinput, curroutput = self.random_flip(currinput, curroutput)\n                batch_input += [currinput]\n                batch_output += [curroutput]\n                \n            # Return a tuple of (input, output) to feed the network\n            batch_x = np.array(batch_input)\n            batch_y = np.array(batch_output)\n          \n            yield(batch_x, batch_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## The model\nmodelInput = Input(shape=(img_height, img_width, 3))\nvggModel = keras.applications.vgg16.VGG16(include_top=False, weights='imagenet', input_tensor=modelInput)\n\noutput = vggModel.layers[-1].output\nvgg16TruncModel = Model(vggModel.input, output)\nfor layer in vgg16TruncModel.layers:\n  layer.trainable=False\n\ndecoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(vgg16TruncModel.output)\n# decoder_output = BatchNormalization()(decoder_output)\ndecoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(decoder_output)\n# decoder_output = BatchNormalization()(decoder_output)\ndecoder_output = UpSampling2D((2, 2))(decoder_output)\ndecoder_output = Conv2D(64, (3,3), activation='relu', padding='same')(decoder_output)\n# decoder_output = BatchNormalization()(decoder_output)\ndecoder_output = UpSampling2D((2, 2))(decoder_output)\ndecoder_output = Conv2D(32, (3,3), activation='relu', padding='same')(decoder_output)\n# decoder_output = BatchNormalization()(decoder_output)\ndecoder_output = UpSampling2D((2, 2))(decoder_output)\ndecoder_output = Conv2D(16, (3,3), activation='relu', padding='same')(decoder_output)\n# decoder_output = BatchNormalization()(decoder_output)\ndecoder_output = UpSampling2D((2, 2))(decoder_output)\ndecoder_output = Conv2D(2, (3, 3), activation='tanh', padding='same')(decoder_output)\ndecoder_output = UpSampling2D((2, 2))(decoder_output)\nmodel = Model(inputs=modelInput, outputs=decoder_output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam', loss='mse' , metrics=['accuracy'])\n\n# model.compile(loss='mse',\n#               optimizer=optimizers.RMSprop(lr=1e-4),\n#               metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dataGenerator = colorizationGenerator(train_dir, os.listdir(train_dir), batch_size)\n# valGenerator = colorizationGenerator(val_dir, os.listdir(val_dir), num_val_samples)\ndataGenerator = colorizationGenerator(train_dir, batch_size, [1, 1 + num_train_samples])\nvalGenerator = colorizationGenerator(train_dir, batch_size, [200000, 200000 + num_val_samples])\n\nfrom keras.callbacks import ModelCheckpoint\n\ncheckpoint_callback = ModelCheckpoint('best_model_wval.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_img = imread(train_dir+'/104247.jpg')\ntest_img = resize(test_img,(224,224,3))\nlab = rgb2lab(test_img)\nprint(lab.shape)\nl = lab[:,:,0]\na = lab[:,:,1]\nb = lab[:,:,2]\nprint(np.max(l))\nprint(np.max(a))\nprint(np.max(b))\nplt.imshow(test_img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images = next(dataGenerator.image_generator())\nprint(len(images))\nprint(images[1][0].shape)\nprint(np.max(images[0][0][0]))\nprint(np.max(images[1][0][:,:,0]))\nprint(np.max(images[1][0][:,:,1]))\ncur = np.zeros((224, 224, 3))\ncur[:,:,0] = images[0][0][:,:,0]*100.0\ncur[:,:,1:] = images[1][0]*128.0\noutput = lab2rgb(cur)\nplt.imshow(output)\nprint(np.max(cur[:,:,0]))\nprint(np.max(cur[:,:,1]))\nprint(np.max(cur[:,:,2]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit_generator(\n    dataGenerator.image_generator(),\n    steps_per_epoch=num_train_samples // batch_size,\n    validation_data=valGenerator.image_generator(),\n    validation_steps=num_val_samples // batch_size,\n    epochs=epochs,\n    callbacks=[checkpoint_callback]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('last_model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history['accuracy']\nmse = history.history['loss']\n\nepochs_range = range(len(acc))\n\nplt.figure(figsize=(16, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, mse, label='Training MSE')\nplt.plot(history.history['val_loss'], label='Validation MSE')\nplt.legend(loc='upper right')\nplt.title('Training MSE')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testfiles = []\ntestfilepaths = []\nval_index = 200000\nnum_examples = 10\nfig = plt.figure(figsize=(20,10))\nfor i in range(val_index, val_index + num_examples):\n  fig.add_subplot(1, num_examples, i+1-val_index)\n  filename = str(i) + '.jpg' \n  testfiles.append(filename)\n  testfilepaths.append(os.path.join(train_dir,filename))\n  plt.imshow(plt.imread(os.path.join(train_dir,filename)))\n  plt.title(str(i) + '.jpg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import load_model\nbestModel = load_model('last_model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs = []\noutputs = []\nfor idx, file in enumerate(testfilepaths):\n    test = imread(file)\n    test = resize(test, (224,224,3), anti_aliasing=True)\n    lab = rgb2lab(test)\n    l = lab[:,:,0]\n    L = gray2rgb(l/100.0)\n    inputs.append(L)\n    L = L.reshape((1,224,224,3))\n    ab = bestModel.predict(L)\n    ab = ab*128\n    cur = np.zeros((224, 224, 3))\n    cur[:,:,0] = l\n    cur[:,:,1:] = ab\n    outputs.append(cur)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_examples = 10\nfig = plt.figure(figsize=(20,10))\nfor i in range(num_examples):\n  fig.add_subplot(1, num_examples, i+1)\n  plt.imshow(inputs[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_examples = 10\nfig = plt.figure(figsize=(20,10))\nfor i in range(num_examples):\n  fig.add_subplot(1, num_examples, i+1)\n  plt.imshow(lab2rgb(outputs[i]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(outputs[0][:,:,1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(outputs[0][:,:,2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bestModel = load_model('best_model_wval.h5')\ninputs = []\noutputs = []\nfor idx, file in enumerate(testfilepaths):\n    test = imread(file)\n    test = resize(test, (224,224,3), anti_aliasing=True)\n    lab = rgb2lab(test)\n    l = lab[:,:,0]\n    L = gray2rgb(l/100.0)\n    inputs.append(L)\n    L = L.reshape((1,224,224,3))\n    ab = bestModel.predict(L)\n    ab = ab*128\n    cur = np.zeros((224, 224, 3))\n    cur[:,:,0] = l\n    cur[:,:,1:] = ab\n    outputs.append(cur)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_examples = 10\nfig = plt.figure(figsize=(20,10))\nfor i in range(num_examples):\n  fig.add_subplot(1, num_examples, i+1)\n  plt.imshow(inputs[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_examples = 10\nfig = plt.figure(figsize=(20,10))\nfor i in range(num_examples):\n  fig.add_subplot(1, num_examples, i+1)\n  plt.imshow(lab2rgb(outputs[i]))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}