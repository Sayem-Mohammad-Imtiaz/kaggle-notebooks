{"cells":[{"metadata":{},"cell_type":"markdown","source":"## MALL Customer Segmentation\n\nThe goal is to identify types of Customers visiting the mall. Who are described as \"good mall spenders:\" Males or Females?\nTo identify different customers based on income and their spending which will help to create strategies in terms products and services to cater to their needs.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We start by importing the dependencies.\n1. Numpy and Pandas for basic calculations and datatables\n2. Matplotlib and its support libraries along with seaborn to plot different kinds of plots for visualisation\n3. Sklearn packages for Kmeans calculation, Standardization of data.\n4. OS to control flow from directory","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom matplotlib import style\nfrom matplotlib.ticker import MaxNLocator\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score, silhouette_samples\nfrom mpl_toolkits.mplot3d import Axes3D","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Import","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        path=os.path.join(dirname, filename)\n        print(path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_data=pd.read_csv(path)\nraw_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We read the data from the csv file and display it in the console.\nOn the first glace we notice we have 3 continuous variable and 1 categorical variable\nBased on Income, Spending and gender we can create our cluster or groupings","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Understanding the DATA and its distribution","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_data.drop([\"CustomerID\"], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thus based on the above output we understand the data type of each category and we can assume that there is no null values bases on the fact that all 4 variables have equal non null counts","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The max and min above and below the 75% and 25% gives us the sense of the data distributions although the presence of outliers cannot be ruled out as of now","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### NULL value check","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This confirms that there isn't presence of any null values.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Gender and its demographics\n\nGrouping data by Gender to indentify the spending habits of each gender and their respective incomes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"gender_group_mean=raw_data.groupby([\"Gender\"]).mean().reset_index()\ngender_group_mean","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(6,6))\nplt.bar(gender_group_mean[\"Gender\"], gender_group_mean[\"Annual Income (k$)\"], color=[\"orange\",\"indigo\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Males on average earns slightly more than females","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\nplt.bar(gender_group_mean[\"Gender\"], gender_group_mean[\"Spending Score (1-100)\"], color=[\"b\",\"g\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Average spendings of females are larger than males\n\nThus we can conclude two aspects of the demographics:-\n1. Saving of Females are lower than their male counterparts\n2. Male population is larger than females still less count and spending of males suggest they are non users who can be converted to users in future\n3. More male oriented products or themes or attractions can be placed/ utilized in the malls to draw the male crowds.\n4. Female spends generally more on cloths, jewellary, kids store while males spends more on games, consumer electronics, foods and movies with no clear demarkation between gender roles are quite often noted.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(6,6))\nsns.boxenplot(raw_data[\"Gender\"], raw_data[\"Annual Income (k$)\"], palette =\"rainbow\")\nplt.grid(color=\"silver\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above graph we can see the women salary is more distributed with large concentration of women earling betwwen $40k to $80k while the men's income ranged from $45k to $79k. The norrowing of graph indicates presence of outliers. The are generally have similar pay scales where as men have multiple pay scales.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14,6))\n\nplt.subplot(1,2,1) #subplot rows, columns and Index\nsns.boxenplot(raw_data[\"Gender\"], raw_data[\"Spending Score (1-100)\"], palette =\"rocket\")\nplt.grid(color=\"silver\")\n\nplt.subplot(1,2,2)\nsns.boxplot(raw_data[\"Gender\"], raw_data[\"Spending Score (1-100)\"], palette =\"seismic\")\nplt.grid(color=\"silver\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above graph we can see that most male spendings range from $45k ~ $79k aprrox while female spendings range from $40k ~ ~ $78k approx. So there is an overall $4000 less spendings on male counterpart","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,8))\n\nplt.subplot(1,2,1)\nax=sns.distplot(raw_data[\"Spending Score (1-100)\"], color=\"mediumspringgreen\")\n\nplt.subplot(1,2,2)\nax=sns.distplot(raw_data[\"Annual Income (k$)\"], color=\"blue\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Spending scores histogram is quite well balanced with its peak in the center (0 shewness) suggest the absense of noticeable outliers. Where as for Annual income it is very slightly skewed to the right indicate presence of minute outliers.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_data.groupby([\"Gender\"]).count().reset_index()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the data we have more Female representatives than males\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Converting Categorical variable to Continuous\n\nThis is required specially when we will be going to fit_transform the whole dataset to standardscaler","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_data[\"Gender\"]=raw_data[\"Gender\"].replace([\"Male\", \"Female\"], [0,1])\nraw_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Standard Scaling of data.\n\n#### Using Skleanr's StandardScaler()\n\nThe reason who standardize the data becore KMeans() creates clusters based on distances (Euclidean Distances). So all the values of each variable needs to be on the same scale so as to have equal distances.\n\nA varibale whose value ranges like 500g will be perceived more dominant by the algorithm than 5kg despite the fact 5kg is bigger than 500g.\n\nThus we standardize the data by substracting the mean and dividing it with its is standard deviation, thus each data sample will have unit variance.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"std_slr=StandardScaler()\nraw_data_std=std_slr.fit_transform(raw_data)\nraw_data_std[0:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_data_std=pd.DataFrame(raw_data_std, columns=raw_data.columns)\nraw_data_std","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Taking the standardized values of two main variable for clustering","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data=raw_data_std.iloc[:,2:].values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Finding the optimum Clustering\n\n####  using KMeans via the Elbow Method and Silhouette scores\n\nKmeans is used to do the clusters and to find their centroids.\n\nBasically we run the KMeans() from sklearn with most of its parameters as default except the number of clusters which we fun via a for loop to find out the optimum cluster size and its Silhouette score.\n\n#### Kmeans:-\n\nThe KMeans algorithm clusters data by trying to separate samples in n groups of equal variance, minimizing a criterion known as the inertia or within-cluster sum-of-squares\n\nThis algorithm requires the number of clusters to be specified. Inertia makes the assumption that clusters are convex and isotropic, which is not always the case. It responds poorly to elongated clusters, or manifolds with irregular shapes, another reason for required standardization.\n\nhttps://scikit-learn.org/stable/modules/clustering.html#k-means\n\nParameters: https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n\n\n#### Silhoutte Scores\n\nThe Silhouette Coefficient is calculated using the mean intra-cluster distance (a) and the mean nearest-cluster distance (b) for each sample. The Silhouette Coefficient for a sample is (b - a) / max(a, b). \n\nThe best value is 1 and the worst value is -1. Values near 0 indicate overlapping clusters. Negative values generally indicate that a sample has been assigned to the wrong cluster, as a different cluster is more similar.\n\nParameters: Mostly at defaults with Labels set via KMeans.Labels_.\n\nhttps://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"wss=[]\nsil=[]\nfor k in range(2,20):\n    kmeans=KMeans(n_clusters=k, random_state=1).fit(data)\n    wss.append(kmeans.inertia_)\n    labels=kmeans.labels_\n    sil.append(silhouette_score(raw_data_std, labels, metric = 'euclidean'))\nprint(wss)\nprint(sil)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k=range(2,20)\nfig,ax=plt.subplots(figsize=(20,8))\nax.set_facecolor('white')\nax.plot(k,wss, color=\"green\")\nax.xaxis.set_major_locator(MaxNLocator(nbins=20,integer=True)) #forces the scales to be in integer, nbins as scales size.\nax.set_xlabel(\"No of clusters\",color=\"black\", fontsize=20)\nax.set_ylabel(\"WSS (With in sum of squares)\", color=\"green\", fontsize=20)\nax2=ax.twinx() #creates the second axis on the first plot (ax)\nax2.plot(k,sil, color=\"blue\")\nax2.set_ylabel(\"Silhouette scores\", color=\"Blue\", fontsize=20)\nax.grid(True, color=\"silver\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we see as the no of cluster increases the **WSS**(with-in sum of squares) decrease *sharply* upto 5 then the curve begin to flat out.\nThis is the elbow method where there is an initial steep decent and then the rate of decrease of WSS slows decreases suggesting that with the increase in new clusters there is **not much significant improvement to the model**\n\nThe silhoutte scores on the other hand tell us the max coefficent value of intercluster distance. We see it peaks out at 5 exactly where the elbow method's WSS steep decent begins to flat-out suggesting that *\"5\"* is the optimal choice for this dataset.\n\n**Thus choosen no of clusters = 5**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"n=5\nkmeans=KMeans(n_clusters=n, random_state=1).fit(data)\nclusters=kmeans.labels_\ncentroids=kmeans.cluster_centers_\nclusters","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_data_std2=pd.DataFrame(pd.concat([raw_data_std, pd.Series(kmeans.labels_)], axis=1).rename(columns={0:\"Clusters\"})).copy()\nraw_data2=pd.DataFrame(pd.concat([raw_data, pd.Series(kmeans.labels_)], axis=1).rename(columns={0:\"Clusters\"})).copy()\nraw_data2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_data2_copy=raw_data2.copy()\nraw_data2_copy.sort_values([\"Clusters\"], inplace=True)\nraw_data_std2.sort_values([\"Clusters\"], inplace=True)\nfor i in range(0,n+1):\n    raw_data2_copy[\"Clusters\"]=raw_data2_copy[\"Clusters\"].replace(i, chr(i+65))\n    raw_data_std2[\"Clusters\"]=raw_data_std2[\"Clusters\"].replace(i, chr(i+65))\nraw_data2_copy[\"Clusters\"].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_data2_copy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig=plt.figure(figsize=(14,8))\nax=Axes3D(fig) #used to create 3D plots, part of matplotlib\nx=np.array(raw_data[\"Age\"])\ny=np.array(raw_data[\"Annual Income (k$)\"])\nz=np.array(raw_data[\"Spending Score (1-100)\"])\ncentroids=np.array(centroids)\nax.scatter(x, y,z, c=y)\nplt.title('SPENDING SCORE VS ANNUAL INCOME VS AGE')\nax.set_xlabel('Age')\nax.set_ylabel('ANNUAL Income')\nax.set_zlabel('Spending Score')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A 3d plot showing the cluster compared with Age, Spending Score and Annual income.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x=raw_data.iloc[:,2:].values\ny_means=kmeans.fit_predict(data)\nprint(y_means)\nprint(\"X shape:\",x.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cluster plot and its interpretation\n\nCode snippet: x[y_means==0,0] mean plot x whos cluster center is 0 (x[y_means==0]) and the second \"0\" is a postional argument of array X, X shape is (n, 2) so [0,1] are positional arguments. This arguements are used to set Annual income (pos=0) as X and Spending Score (pos=1) as Y","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14,8))\n\nplt.scatter(x[y_means==0,0], x[y_means==0,1], color=\"cyan\", label=\"Normal\") #pos argument 0 for X and 1 for Y\nplt.scatter(x[y_means==1,0], x[y_means==1,1], color=\"indigo\", label=\"High Spenders\") #y_means==1 for cluster center 1\nplt.scatter(x[y_means==2,0], x[y_means==2,1], color=\"red\", label=\"Value buyers\")\nplt.scatter(x[y_means==3,0], x[y_means==3,1], color=\"green\", label=\"Savers\")\nplt.scatter(x[y_means==4,0], x[y_means==4,1], color=\"blue\", label=\"Impulse buyers\")\n\nplt.xlabel(\"Annual Income (Thousand $)\")\nplt.ylabel(\"Spending Score (1-100)\")\nplt.legend(loc=\"right\")\nplt.grid(True, color=\"silver\")\nplt.title(\"Customers Demographics\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Interpretation\n\n***Above and Below*** are the two cluster outputs based on Income and Spending Habits.\n\nHere we can see *5* total distinctive groups with minimum overlaps which suggest our clustering model did a pretty good job.\n\n\n**Explainations and Suggestions**\n\nOf the 5 total clusters we observe the following:-\n1. The **Red** group lies in the bottom left of the plots have both least Income and Spending Capability. They are rational with their spending habits and thus will choose **Value** products which offer maximum benefit for least price. A **mass** marketing strategy will work in this type of consumer segment. **Offers, discounts** are quite attractive to this group. A all in one departmental stores like Walmarts, Big bazar (India) are preferred retailers.\n\n2. The **Blue** group are mostly **Impulse buyers** who dont believe in saving. A good array of display with relevant digital marketing techniques like location based advertisement to offers can be used to attact this group. Display plays a key role in selling to these customers. Can be seen flocking around Exclusive branded stores as well as departmental all in one retails.\n\n3. The **Skyblue** group behaves like an ideal group who likes to maintain a optimised life of earning and spendings. They are generally value buyers who like to buy products of low cost but gives the premium feel. Such customers will opt for EMI based shopping of high value CGs or like to upgrade an old item with a new. Can be seen flocking around Exclusive branded stores as well as departmental all in one retails.\n\n4. The **Green** group are groups who are savers and don't believe in unnecessary expenditure. They generally buy a movie tickets sans the pop corn. Prefer to buy a lot from all in one departmental retails.\n\n5. The **Indigo** group are high earners and high spenders thus a lucrative target for all types of goods. They are thrill, luxury seakers who don't bugde to spend the extra bug for good experience. Exclusive branded outlets are the most preferred choices here.\n\n\n\nNB: Group colour are based on the above Graph only.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14,8))\nsns.scatterplot(\"Annual Income (k$)\", \"Spending Score (1-100)\", hue=\"Clusters\", data=raw_data_std2)\nplt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:, 1], s = 100,c=\"Blue\", label = 'centeroid')\nplt.legend()\nplt.grid()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Centroids (centre of mass of a geometric object of uniform density.) of each groups highlighted in blue","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Compute the Silhouette Coefficient for each sample.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_silhouette_values=silhouette_samples(raw_data_std, clusters)\nraw_data_std2[\"silhouette_values\"]=sample_silhouette_values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_data_std2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_data_std2.groupby([\"Clusters\"])[\"silhouette_values\"].mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Silhoutte scores for each sample. Ranges from **-1 < score < +1**. Where samples in the same cluster are similar to each other, and well separated, where samples in different clusters are not very similar to each other.\n\n**+1** suggest ***strong similarity*** with-in the group and ***dissimilarity*** with other groups (good clustering)\n\n**0** suggest **no** similarity with-in the group and **no** dissimilarity with other group (no clustering)\n\n**-1** suggest **strong dissimilarity** with-in the group and **similarity** with other groups (poor clustering)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"silhouette_score(raw_data_std, clusters) #all data points","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}