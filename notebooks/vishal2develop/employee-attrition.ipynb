{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Employee Attrition Prediction","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Loading Libraries","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Basic Libs\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import statements required for Plotly \nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import the necessary modelling algos.\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\n\n#model selection\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,roc_curve,roc_auc_score\nfrom sklearn.model_selection import GridSearchCV\n\nfrom imblearn.over_sampling import SMOTE\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import ExtraTreeClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#preprocess.\nfrom sklearn.preprocessing import MinMaxScaler,StandardScaler,LabelEncoder,OneHotEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils import resample\nfrom sklearn.metrics import (accuracy_score,\n                             f1_score,\n                             roc_auc_score,\n                             roc_curve,\n                             confusion_matrix)\nfrom sklearn.model_selection import (cross_val_score,\n                                     GridSearchCV,\n                                     RandomizedSearchCV,\n                                     learning_curve,\n                                     validation_curve,\n                                     train_test_split)\n\nfrom sklearn.pipeline import make_pipeline # For performing a series of operations\n\nfrom sklearn.metrics import plot_confusion_matrix\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/ibm-hr-analytics-attrition-dataset/WA_Fn-UseC_-HR-Employee-Attrition.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Getting a Feel of the data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes.unique() # There are the only available datatypes in our dataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5 number summary","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Attrition.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Attrition.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.BusinessTravel.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df.Age) # Age is unimodal","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Age.describe() # Age is Normally Distributed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.skew()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_cat = df.select_dtypes(exclude='O')\nnum_cat_cols = num_cat.columns\nnum_cat_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(6,2,figsize=(9,9))\nsns.distplot(df['TotalWorkingYears'],ax=ax[0,0])\nsns.distplot(df['MonthlyIncome'],ax=ax[0,1])\nsns.distplot(df['YearsAtCompany'], ax = ax[1,0]) \nsns.distplot(df['DistanceFromHome'], ax = ax[1,1]) \nsns.distplot(df['YearsInCurrentRole'], ax = ax[2,0]) \nsns.distplot(df['YearsWithCurrManager'], ax = ax[2,1]) \nsns.distplot(df['YearsSinceLastPromotion'], ax = ax[3,0]) \nsns.distplot(df['PercentSalaryHike'], ax = ax[3,1]) \nsns.distplot(df['YearsSinceLastPromotion'], ax = ax[4,0]) \nsns.distplot(df['TrainingTimesLastYear'], ax = ax[4,1]) \nsns.distplot(df['DailyRate'], ax = ax[5,0]) \nsns.distplot(df['HourlyRate'], ax = ax[5,1]) \nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_df = df.select_dtypes(include='O')\ncat_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# function to plot all categorical variables\ndef plot_cat(attr):\n    #sns.factorplot(data=df,kind='count',size=5,aspect=1.5,x=attr)\n    data = [go.Bar(\n            x=df[attr].value_counts().index.values,\n            y= df[attr].value_counts().values\n    )]\n    py.iplot(data, filename='basic-bar')\n\n\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_cat('Attrition')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The data is imbalanced**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_cat(df.BusinessTravel.name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_cat(df.EducationField.name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_cat(df.Department.name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_cat(df.Gender.name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_cat(df.MaritalStatus.name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_cat(df.JobRole.name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_cat(df.Over18.name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Over18.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Over18.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_cat(df.OverTime.name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def plot_num(attr):\n#     sns.factorplot(data=df,kind='count',size=5,aspect=1.5,x=attr)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for i in num_cat_cols:\n#     plot_num(i)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Checking Correlation\n    1.Using heatmap","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cor_mat = df.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.amin(cor_mat) # No serious -ve correlation can be seen","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmask = np.array(cor_mat)\nmask[np.tril_indices_from(mask)] = False\nfig=plt.gcf()\nfig.set_size_inches(30,15)\nsns.heatmap(data=cor_mat,mask=mask,fmt='.2f',linewidths=0.1,square=True,annot=True,cbar=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observations**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"    1. Job level has a positive correlation with Age (0.51) - Aged employees are seniors\n    2. Monthly Income has a positive correlation with Age (0.50) and Job Level (0.95) - Aged Employees are seniors and have higher salary\n    3. Performance Rating has a strong +ve correlation with percent salary hike (0.77) - Hike is based on performance\n    4. Total working years has a strong +ve correlation with Age (0.68),Job level(0.78) and Monthly Income (0.77) which is  obvious\n    5. Years in current core is highly correlated with years at company (0.76)\n    6. Years since last promotion is well correlated with years at company (0.62) - More the no of years at company more the chances pf promotion\n    7. Years with current manager is highly correlated with years at company(0.77) and years in current role (0.71)\n    8. Years with current manager is also correlated with years since last promotion (0.51)\n    9. Years at con=mpany has a +ve correlation with age (0.31) and Job level (0.53), Monthly income (0.51) and Total       working years (0.63)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Till Now, we have plotted individual features and visualzed the correlation. Now, Lets plot against target variable","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a function to plot against target variable\ndef plot_target(attr):\n    if attr == df.Age.name:\n        sns.factorplot(data=df,y='Age',x='Attrition',size=5,aspect=1,kind='box')\n        return\n    sns.factorplot(data=df,kind='count',x=df.Attrition.name,col = attr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_target(df.Department.name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pd.crosstab(columns=df.Attrition,index=df.Department,values=df.Attrition,aggfunc='mean')\npd.crosstab(columns=df.Attrition,index=df.Department,normalize='index') # normailze = index gives row wise mean","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[Cross Table Reference](https://pbpython.com/pandas-crosstab.html)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"    1. 19 % HR Employees Leave\n    2. 13% R&D Employyes Leave\n    3. 20% Sales Employees Leave","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_target('Age')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**People who have higher age - Seniors have less tendency to leave the organization as compared to Young employees.**\n\n**This is true as young employees look to explore oppurtunites and experiment with their careers, whereas aged employees have already been there and done that. Now they have settled for good.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.factorplot(data=df,kind='bar',x='Attrition',y='MonthlyIncome')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Employees with High income dont quit**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_target(df.JobSatisfaction.name)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Job Satisfaction level 1 and level 3 employees quit the most. Why Level 3 Though?**\n\n**Maybe because the no of employees with job satisfaction level 3 are more. Hence the trend** ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"age_cross_tab = pd.crosstab(columns=df.Attrition,index=df.Age,margins_name='Total',margins=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"age_cross_tab['Attrition_Ratio'] = age_cross_tab.Yes/age_cross_tab.Total","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"age_cross_tab","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    . Attrition Ratio is the Highest for Age 19","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(columns=[df.Attrition],index=[df.Gender],margins=True,normalize='index')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    1. 14.7% females left\n    2. 17% males left\n    3. Overall 16.1% employees left","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(columns=df.Attrition,index=df.JobLevel,margins=True,normalize='index')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**People from job level 1 leave the most followed by job level 3**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(columns=df.Attrition,index=[df.JobLevel,df.JobSatisfaction],margins=True,normalize='index')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**People with Job Satisfaction 1 - Poor leave the most**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(columns=[df.Attrition],index=[df.EnvironmentSatisfaction],margins=True,normalize='index')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Poor (1) Environment Satisfaction also results in employee leaving the company**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(columns=[df.Attrition],index=df.YearsWithCurrManager,margins=True,normalize='index')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**It can be seen that employees with new managers leave the most. Could it be an Unhealthy relationship between the both**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(columns=[df.Attrition],index=df.YearsSinceLastPromotion,margins=True,normalize='index')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Promotion can also be a reason for the employee leaving**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(columns=[df.Attrition],index=[df.WorkLifeBalance],margins=True,normalize='index')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**More Employees with Poor work life balance leave**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(columns=[df.Attrition],index=[df.BusinessTravel],margins=True,normalize='index')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Selection","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using RFE\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LogisticRegression\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Encoding","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Encoding Salary to low medium high","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ecoding to low medium high based on ranges \ndef encode_salary(salary):\n    if salary>=1009 and salary < 7339:\n        return 'Low'\n    elif salary>=7339 and salary < 13669:\n        return 'Medium'\n    elif salary >=13669 and salary <= 19999:\n        return 'High'\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Income_Cat'] = df['MonthlyIncome'].apply(encode_salary)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Income_Cat.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Income_Cat.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum(axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Income_Cat.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dic = {'Low':0,'Medium':1, 'High':2}\ndf.Income_Cat = df.Income_Cat.map(dic)\ndf.Income_Cat.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Income_Cat.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dropping column which we think arent important","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['BusinessTravel','DailyRate','EmployeeCount','EmployeeNumber','HourlyRate','MonthlyRate'\n          ,'NumCompaniesWorked','Over18','StandardHours', 'StockOptionLevel','TrainingTimesLastYear','MonthlyIncome'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def feature_encode(feature):\n    le = LabelEncoder()\n    df[feature] = le.fit_transform(df[feature])\n    print(le.classes_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_df = df.select_dtypes(include='object')\ncat_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in cat_df.columns:\n    feature_encode(col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Income_Cat.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We have encoded categorical data. Everything is now numerical, but are of varying magnitudes and range.\n#### It is important we perform feature scaling in such cases","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Feature Scaling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# scaler = StandardScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# scaled_df = scaler.fit_transform(df.drop('Attrition',axis=1))\n# X= scaled_df\n# Y = df['Attrition'].to_numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X = df.loc[:,df.columns!='Attrition']\n# X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Y = df['Attrition']\n# Y.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Splitting into Train & Test data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_2 = df.loc[:, df.columns != \"Attrition\"].values # All columns except Attrition\ny_2 = df.loc[:, df.columns == \"Attrition\"].values.flatten() # Attrition column and flatten to bring it to row format","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(\n    X_2, y_2, test_size=0.2, stratify=y_2, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_2[y_train_2 == 1].shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We know that the dataset is imbalanced and hence we perfeorm upsampling of the minority class below","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Upsampling minority class","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"[Upsampling Reference](https://elitedatascience.com/imbalanced-classes)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_u, y_train_u  = resample(X_train_2[y_train_2 == 1],\n                                y_train_2[y_train_2==1],\n                                 replace = True,\n                                 n_samples=X_train_2[y_train_2 == 0].shape[0],\n                                random_state=1\n                                )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Combine majority class with upsampled minority class\nX_train_u = np.concatenate((X_train_2[y_train_2 == 0], X_train_u))\ny_train_u = np.concatenate((y_train_2[y_train_2 == 0], y_train_u))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Original shape:\", X_train_2.shape, y_train_2.shape)\nprint(\"Upsampled shape:\", X_train_u.shape, y_train_u.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building Models","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build random forest classifier\nmethods_data = {\"Original\": (X_train_2, y_train_2),\n                \"Upsampled\": (X_train_u, y_train_u)}\n\nfor method in methods_data.keys():\n    pip_rf = make_pipeline(StandardScaler(),\n                           RandomForestClassifier(n_estimators=500,\n                                                  class_weight=\"balanced\",\n                                                  random_state=123))\n    hyperparam_grid = {\n        \"randomforestclassifier__n_estimators\": [10, 50, 100, 500],\n        \"randomforestclassifier__max_features\": [\"sqrt\", \"log2\", 0.4, 0.5],\n        \"randomforestclassifier__min_samples_leaf\": [1, 3, 5],\n        \"randomforestclassifier__criterion\": [\"gini\", \"entropy\"]}\n    \n    gs_rf = GridSearchCV(pip_rf,\n                         hyperparam_grid,\n                         scoring=\"f1\",\n                         cv=10,\n                         n_jobs=-1)\n    \n    gs_rf.fit(methods_data[method][0], methods_data[method][1])\n    \n    print(\"\\033[1m\" + \"\\033[0m\" + \"The best hyperparameters for {} data:\".format(method))\n    for hyperparam in gs_rf.best_params_.keys():\n        print(hyperparam[hyperparam.find(\"__\") + 2:], \": \", gs_rf.best_params_[hyperparam])\n    \n    print(\"\\033[1m\" + \"\\033[94m\" + \"Best 10-folds CV f1-score: {:.2f}%.\".format((gs_rf.best_score_) * 100))\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Upsampling has the highest CV f1-score with 98.55%.\n#### we will use upsampled data on other models too","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_u[y_train_u == 0].shape, X_train_u[y_train_u == 1].shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### After upsampling Our data is divided into 50% Attrition =1 and 50 % Attrition = 0","execution_count":null},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Refitting Random Forest with Upsampled Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Refit RF classifier using best params\nclf_rf = make_pipeline(StandardScaler(),\n                       RandomForestClassifier(n_estimators=500,\n                                              criterion=\"gini\",\n                                              max_features='sqrt',\n                                              min_samples_leaf=1,\n                                              class_weight=\"balanced\",\n                                              n_jobs=-1,\n                                              random_state=123))\n\n\nclf_rf.fit(X_train_u, y_train_u)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot confusion matrix and ROC curve\nnp.set_printoptions(precision=2)\ndisp = plot_confusion_matrix(clf_rf,X_test_2,y_test_2,display_labels=df.Attrition.name,cmap=plt.cm.Blues)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build Gradient Boosting classifier\npip_gb = make_pipeline(StandardScaler(),\n                       GradientBoostingClassifier(loss=\"deviance\",\n                                                  random_state=123))\n\nhyperparam_grid = {\"gradientboostingclassifier__max_features\": [\"log2\", 0.5],\n                   \"gradientboostingclassifier__n_estimators\": [100, 300, 500],\n                   \"gradientboostingclassifier__learning_rate\": [0.001, 0.01, 0.1],\n                   \"gradientboostingclassifier__max_depth\": [1, 2, 3]}\n\ngs_gb = GridSearchCV(pip_gb,\n                      param_grid=hyperparam_grid,\n                      scoring=\"f1\",\n                      cv=10,\n                      n_jobs=-1)\n\ngs_gb.fit(X_train_u, y_train_u)\n\nprint(\"\\033[1m\" + \"\\033[0m\" + \"The best hyperparameters:\")\nprint(\"-\" * 25)\nfor hyperparam in gs_gb.best_params_.keys():\n    print(hyperparam[hyperparam.find(\"__\") + 2:], \": \", gs_gb.best_params_[hyperparam])\n\nprint(\"\\033[1m\" + \"\\033[94m\" + \"Best 10-folds CV f1-score: {:.2f}%.\".format((gs_gb.best_score_) * 100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### GBT have a F1-Score of 95.5%","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build logistic model classifier\npip_logmod = make_pipeline(StandardScaler(),\n                           LogisticRegression(class_weight=\"balanced\"))\n\nhyperparam_range = np.arange(0.5, 20.1, 0.5)\n\nhyperparam_grid = {\"logisticregression__penalty\": [\"l1\", \"l2\"],\n                   \"logisticregression__C\":  hyperparam_range,\n                   \"logisticregression__fit_intercept\": [True, False]\n                  }\n\ngs_logmodel = GridSearchCV(pip_logmod,\n                           hyperparam_grid,\n                           scoring=\"accuracy\",\n                           cv=2,\n                           n_jobs=-1)\n\ngs_logmodel.fit(X_train_u, y_train_u)\n\nprint(\"\\033[1m\" + \"\\033[0m\" + \"The best hyperparameters:\")\nprint(\"-\" * 25)\nfor hyperparam in gs_logmodel.best_params_.keys():\n    print(hyperparam[hyperparam.find(\"__\") + 2:], \": \", gs_logmodel.best_params_[hyperparam])\n\nprint(\"\\033[1m\" + \"\\033[94m\" + \"Best 10-folds CV f1-score: {:.2f}%.\".format((gs_logmodel.best_score_) * 100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression have a F1-Score of 75.10%","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Printing out the Accuracy and f1-score of each model ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"estimators = {\"RF\": clf_rf,\n              \"LR\": gs_logmodel,\n              \"GBT\": gs_gb\n             }\n\n# Print out accuracy score on test data\nprint(\"The accuracy rate and f1-score on test data are:\")\nfor estimator in estimators.keys():\n    print(\"{}: {:.2f}%, {:.2f}%.\".format(estimator,\n        accuracy_score(y_test_2, estimators[estimator].predict(X_test_2)) * 100,\n         f1_score(y_test_2, estimators[estimator].predict(X_test_2)) * 100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Printing out other important metrics","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model_names=['RandomForestClassifier','Logistic Regression','GradientBoostingClassifier']\nmodels = [clf_rf,gs_logmodel,gs_gb]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def compare_models(model):\n    clf=model\n    clf.fit(X_train_u,y_train_u)\n    pred=clf.predict(X_test_2)\n    \n    # Calculating various metrics\n    \n    acc.append(accuracy_score(pred,y_test_2))\n    prec.append(precision_score(pred,y_test_2))\n    rec.append(recall_score(pred,y_test_2))\n    auroc.append(roc_auc_score(pred,y_test_2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc=[]\nprec=[]\nrec=[]\nauroc=[]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for model in models:\n    compare_models(model)\nd={'Modelling Algo':model_names,'Accuracy':acc,'Precision':prec,'Recall':rec,'Area Under ROC Curve':auroc}\nmet_df=pd.DataFrame(d)\nmet_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Finding the Important features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_rf = RandomForestClassifier(n_estimators=500,\n                                criterion=\"gini\",\n                                max_features='sqrt',\n                                min_samples_leaf=1,\n                                class_weight=\"balanced\",\n                                n_jobs=-1,\n                                random_state=123)\n\n\nclf_rf.fit(StandardScaler().fit_transform(X_train_u), y_train_u)\n\n# Plot features importance\nimportances = clf_rf.feature_importances_\nindices = np.argsort(clf_rf.feature_importances_)[::-1]\nplt.figure(figsize=(12, 6))\nplt.bar(range(1, 24), importances[indices], align=\"center\")\nplt.xticks(range(1, 24), df.columns[df.columns != \"Attrition\"][indices], rotation=90)\nplt.title(\"Feature Importance\", {\"fontsize\": 16});","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusion:** Age plays a vital role in attrition according to our analysis and model. This can be true as it is normally seen that younger empoloyees tend to switch organizations in order to explore fields and find what best suits them.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}