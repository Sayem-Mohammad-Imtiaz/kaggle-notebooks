{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Bank Customer Churn Analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Churner is generally defined as a customer who stops using a product or service for a given period of time.\n\nThis notebook is to do the data analysis and predictions on the churn.csv file.\n\nThe first step in the Data Preprocessing is to import the libraries, load the data and do some Exploratory Data Analysis (EDA).\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install sankey","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install dash","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pySankey","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### STEP1 - Import all important Libraries and dataset","execution_count":null},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"import pandas as pd    #for EDA\nimport numpy as np     #for numerical operation if required\nimport sankey   #for sankey plot\nimport matplotlib.pyplot as plt      #for visualization\n\nimport seaborn as sns\n%matplotlib inline\n#dataset=pd.read_csv(r'/home/ajaygoswami/Documents/Bobby/DATA SET/churn.csv')\ndataset= pd.read_csv(r'../input/predicting-churn-for-bank-customers/Churn_Modelling.csv')\ndataset.shape\n#importing dataset and put it in a variable called dataset\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Accuracy_Report = pd.DataFrame(columns=[\"Models\",\"Accuracy\"])\nmodels_lis, acc_lis = [], []\ndef Submit_Score(lis1,lis2):\n    models_lis.append(lis1)\n    acc_lis.append(lis2)\n    return\n    \ndef Show_Model_Score():\n    temp_df = pd.DataFrame({'Models': models_lis, 'Accuracy': acc_lis})\n    return temp_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function for plotting the confusion matrix\n\ndef plot_Confusion_matrix(cm, target_names, cmap, title, accuracy):\n    \n    Submit_Score(title,accuracy)\n    \n    if cmap is None:\n            cmap = plt.get_cmap('Blues')\n\n    plt.figure(figsize=(8, 6))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    \n    for i in range(2):\n        for j in range(2):\n            text = plt.text(j, i, cm[i, j],\n                           ha=\"center\", va=\"center\", color=\"black\")\n\n\n    if target_names is not None:\n        tick_marks = np.arange(len(target_names))\n        plt.xticks(tick_marks, target_names, rotation=45)\n        plt.yticks(tick_marks, target_names)\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label\\naccuracy={:0.4f}'.format(accuracy))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. Exploratory Data Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.info()  #for dataset information\n\n#dataset.head()\ndataset.shape  #understanding the shape of our dataset ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.isna().sum()  #finding all the null values as per each column","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.describe() #for descriptive information(statical)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"round(dataset.describe(),2)  \n#'''rounding off all the decimal values up-to 2 place'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"exit=dataset[dataset[\"Exited\"]==1]\nexit\n\n#'''exit = ONLY ROWS WHERE Exited == 1'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"notexit=dataset[dataset[\"Exited\"] ==0]\nnotexit\n#'''notexit = ONLY ROWS WHERE Exited == 0'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#notexit[\"Surname\"]\n\n#return all the Surname values of notexit","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"notexit[[\"Surname\",\"CreditScore\",\"Balance\"]]\n#Return given columns of notexit","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### calculating Exited and not_exited client ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"exited=len(dataset[dataset[\"Exited\"] ==0])\nnotexited=len(dataset[dataset[\"Exited\"] ==1])\nprint(\"length of exited persons :- {}\".format(exited))\n#return length of exited persons\nprint(\"length of exited persons :- {}\".format(notexited))\n#return length of notexited persons","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"exited_perc=round(exited/len(dataset)*100,2)\nnotexited_perc=round(notexited/len(dataset)*100,2)\n\n#finding the percentage of exited and notexited persons from the length of whole dataset \n#and rounded of its decimal value up to 2 place\n\nprint(\"Exited :- {} %\".format(exited_perc))\nprint(\"Not-exited :- {} %\".format(notexited_perc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plotting Exited and not_exited persons as per ratio\nlabels=[\"Exited\",\"Not_exited\"]\ndata = [exited_perc,notexited_perc]\ncolors=[\"#95f542\",\"#02f2ee\"]\nplt.pie(data, \n        labels = labels,\n        colors=colors,\n        autopct=\"%0.2f%%\")            # after point. numbers\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### So, around of 20% of the clients exited the bank, while around 80% stayed. As the goal here is to identify which of the customers are at higher risk to discontinue their services with the bank, we are dealing with a classification problem.\n\nimportant point to take into consideration here is that we are dealing with an imbalanced dataset.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"country = list(dataset[\"Geography\"].unique()) \ngender = list(dataset[\"Gender\"].unique())\n\n#finding the unique values of country and gender wih \".unique()/.nunique()\" methods\n\nprint(country)\nprint(gender)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset[\"Exited_str\"]=dataset[\"Exited\"]\ndataset[\"Exited_str\"]=dataset[\"Exited_str\"].map({1:'Exited',0:\"Stayed\"})\n#creating a new column with the help of \"Exited\" column where numeric values(0,1) converted as-\n#..................string values(stayed,exited))repectively\n\ndataset[\"Exited_str\"]","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"sns.catplot(\"Exited_str\",data=dataset,kind=\"count\",hue=\"NumOfProducts\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we can see that those clients who consist one product exited the most and other side who has2 product has mazority in stayed clients.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"'''We can also convert other modified column with the help of given columns'''\n#exampole:-\n#dataset[\"Geography_str\"]=dataset[\"Geography\"]\n#dataset[\"Geography_str\"]=dataset[\"Geography_str\"].map({'Spain':'Spa','France':\"Fra\",'Germany':'Ger'})\n#dataset[\"Geography_str\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gender_count=dataset[\"Gender\"].value_counts() \n#return different categorical values of gender column\ngender_count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gender_pct=gender_count/len(dataset.index) *100    #(ratio/percentage)\ngender_pct","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#gender=pd.concat([gender_count,round(gender_pct,2)],axis=1)   #to bring it in rows\ngender=pd.concat([gender_count,gender_pct],axis=1)\n#concate the count and percentage different gender wise\ngender","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"gender=pd.concat([gender_count,round(gender_pct,2)],axis=1).set_axis(['count','pct'],axis=1,inplace=False)\n#changing the axis name as per our understanding\ngender","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"geography_count=dataset[\"Geography\"].value_counts() #return different categorical values\ngeography_count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"geography_pct=geography_count/len(dataset.index) *100    #(ratio)\ngeography_pct","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"geography=pd.concat([geography_count,round(geography_pct,2)],axis=1).set_axis(['G_count','G_pct'],axis=1,inplace=False)\ngeography","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##plotting MALE and FEMALE  ratio\nlabels=[\"Males\",\"Females\"]\ncolors=[\"#16915c\",\"#f25ae6\"]\nplt.pie(gender_pct,\n        colors=colors,\n        labels = labels,\n         autopct=\"%0.2f%%\"\n       )            # after point. numbers\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting GEOGRAPHICAL RATIO\n\nlabels=[\"France\",\"Germany\",\"Spain\"]\ncolors=[\"#51f5ae\",\"#ebf060\",\"#ee78f0\"]\nplt.pie(geography_pct,\n        colors=colors,\n        labels = labels,\n        autopct=\"%0.2f%%\"\n       )            # after point. numbers\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the dataset, there are more men (55%) than women (45%), and it has only 3 different countries: France, Spain, and Germany. Where 50% of the customers are from France and 25% are from Germany, and the other group are from Spain.\n\nNow, let's just check the relationship between the features and the outcome ('Exited').\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"salary_min=dataset[dataset[\"EstimatedSalary\"]<30000]\nsalary_min","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"salary_min_count=len(dataset[dataset[\"EstimatedSalary\"]<30000])\nsalary_max_count=len(dataset[dataset[\"EstimatedSalary\"]>30000])\nprint(\"persons sallery below 30,000 :- {}\".format(salary_min_count))\nprint(\"persons sallery above 30,000 :- {}\".format(salary_max_count))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"salary_min_pct=salary_min_count/len(dataset.index)*100\nsalary_max_pct=salary_max_count/len(dataset.index)*100\nprint(\"(salary < 30,000) % :- {}\".format(salary_min_pct))\nprint(\"(salary > 30,000) % :- {}\".format(salary_max_pct))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"labels=[\"salary under 30000\",\"salary above 30000\"]\ndata=[salary_min_pct,salary_max_pct]\ncolors=[\"skyblue\",'lightgreen']\nplt.pie(data,labels=labels,colors=colors,autopct=\"%0.2f%%\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Here we can see the salary Percentage of clients with salary more than 30,000 are 85% and below 30,000 are 15%","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nHasCrCard_count=dataset[\"HasCrCard\"].value_counts() \n#return different categorical values of Hascreditcard/Dont_havecreditcards\nHasCrCard_count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"HasCrCard_pct=HasCrCard_count/len(dataset.index) *100    #(ratio)\nHasCrCard_pct","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"HasCrCard=pd.concat([HasCrCard_count,round(HasCrCard_pct,2)],axis=1).set_axis(['H_count','H_pct'],axis=1,inplace=False)\nHasCrCard","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Ratio of who has credit cards and who dont have credit cards\nlabels=[\"Has_Cedit_Card\",\"Dont_Has_Cedit_Card\"]\ncolors=[\"#db0494\",\"#12147a\"]\nplt.pie(HasCrCard_pct,\n        colors=colors,\n        labels = labels,\n        autopct=\"%0.2f%%\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- As we can see from this Pie chart From all the clients 71% clients has credit cards  and approx 29% dont has credit cards","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"###### Features and outcome(exited)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.groupby(['Gender']).agg([\"count\"])\n#count the values of all Numeric columns as per \"gender\" group.\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.groupby(['Gender']).agg([\"max\"])\n\n#MAX values of all Numeric columns as per \"gender\" group.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = dataset.groupby(['Gender','Exited']).agg([\"count\"])\n#count all the vales as per gender and exited croup separately\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = dataset.groupby(['Gender','Exited'])['Exited'].agg([\"count\"])\n#count the vlue of column \"Exited\" as per Gender and Exited group\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot('Exited',data=dataset,kind=\"count\",hue=\"Gender\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- From this catplot we can understand that from Exitd Clients the number of female are little bit more than males ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"temp=dataset.groupby(['Gender'])['Exited'].agg([\"count\"])\ntemp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def count_by_group(data, feature, target):\n    df = data.groupby([feature, target])[target].agg(['count'])\n    temp = data.groupby([feature])[target].agg(['count'])\n    df['pct'] = 100 * df.div(temp, level = feature).reset_index()['count'].values\n    return df.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_by_group(dataset, feature=\"Gender\", target='Exited')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_by_group(dataset, feature=\"Geography\", target='Exited')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#!pip install pySankey","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pySankey.sankey import sankey","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colorDict = {\n    'Exited':'#f71b1b',\n    'Stayed':'grey',\n    'France':'#f3f71b',\n    'Spain':'#12e23f',\n    'Germany':'#f78c1b'\n}\nsankey(dataset['Geography'], dataset['Exited_str'],\n       aspect=20, colorDict=colorDict,\n       fontsize=12,figure_name=\"Geography\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"HasCrCard_count=dataset[\"HasCrCard\"].value_counts() \nHasCrCard_count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"HasCrCard_pct=HasCrCard_count/len(dataset.index) *100   \nHasCrCard_pct","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"HasCrCard=pd.concat([HasCrCard_count,HasCrCard_pct],axis=1).set_axis(['H_count','H_pct'],axis=1,inplace=False)\nHasCrCard","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_by_group(dataset, feature = \"HasCrCard\",target = \"Exited\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset[\"HasCrCard_str\"]=dataset['HasCrCard'].map({1:\"Has Credit Card\", 0:\"dont Has Credit Card\"})\ncolorDict = {\n    'Exited':'#f71b1b',\n    'Stayed':'grey',\n    \"Has Credit Card\":'#f3f71b',\n    \"dont Has Credit Card\":'#71f5ec'}\n  \nsankey(dataset['HasCrCard_str'], dataset['Exited_str'],\n       aspect=20, colorDict=colorDict,\n       fontsize=12,figure_name=\"HasCrCard_str\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IsActiveMember_count=dataset[\"IsActiveMember\"].value_counts() \nIsActiveMember_count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IsActiveMember_pct=IsActiveMember_count/len(dataset.index) *100   \nIsActiveMember_pct","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IsActiveMember=pd.concat([IsActiveMember_count,IsActiveMember_pct],axis=1).set_axis(['I_count','I_pct'],axis=1,inplace=False)\nIsActiveMember","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_by_group(dataset, feature = \"IsActiveMember\",target = \"Exited\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset[\"IsActiveMember_str\"]=dataset['IsActiveMember'].map({1:\"IsActiveMember\", 0:\"Is_not_ActiveMember\"})\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colorDict = {\n    'Exited':'#f71b1b',\n    'Stayed':'grey',\n    \"IsActiveMember\":'#4ddbc4',\n    \"Is_not_ActiveMember\":'#75b84b',\n    \n}\nsankey(dataset['IsActiveMember_str'], dataset['Exited_str'],\n       aspect=20, colorDict=colorDict,\n       fontsize=12,figure_name=\"IsActiveMember_str\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nNumOfProducts_count = dataset['NumOfProducts'].value_counts()\nNumOfProducts_pct= NumOfProducts_count / len(dataset.index)\n\nNumOfProducts = pd.concat([NumOfProducts_count, round(NumOfProducts_pct,2)], axis=1)\\\n        .set_axis(['count', 'pct'], axis=1, inplace=False)\nNumOfProducts\n\n\n# STEP 2\ncount_by_group(dataset, feature = 'NumOfProducts', target = 'Exited')\n\n\n\n# STEP 3\ndataset['NumOfProducts_str'] = dataset['NumOfProducts'].map({1: '1', 2: '2', 3: '3', 4: '4'})\n\n# STEP 4\n\ncolorDict = {\n    'Exited':'#f71b1b',\n    'Stayed':'grey',\n    '1':'#f3f71b',\n    '2':'#12e23f',\n    '3':'#f78c1b',\n    '4':'#8E388E'\n}\nsankey(\n    dataset['NumOfProducts_str'], dataset['Exited_str'], aspect=20, colorDict=colorDict,\n    fontsize=12, figure_name=\"NumOfProducts\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset[(dataset[\"Exited\"]==0)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"figure = plt.figure(figsize=(15,8))\nplt.hist([\n        dataset[(dataset.Exited==0)]['Age'],\n        dataset[(dataset.Exited==1)]['Age']\n        ], \n         stacked=True, color = ['grey','r'],\n         bins = 'auto',label = ['Stayed','Exited'],\n         edgecolor='black', linewidth=1.2)\nplt.xlabel('Age (years)')\nplt.ylabel('Number of customers')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=2, ncols=2, figsize = (15,15))\nfig.subplots_adjust(left=0.2, wspace=0.6)\nax0, ax1, ax2, ax3 = axes.flatten()\n\nax0.hist([\n        dataset[(dataset.Exited==0)]['CreditScore'],\n        dataset[(dataset.Exited==1)]['CreditScore']\n        ], \n         stacked=True, color = ['grey','r'],\n         bins = 'auto',label = ['Stayed','Exited'],\n         edgecolor='black', linewidth=1.2)\nax0.legend()\nax0.set_title('Credit Score')\n\nax1.hist([\n        dataset[(dataset.Exited==0)]['Tenure'],\n        dataset[(dataset.Exited==1)]['Tenure']\n        ], \n         stacked=True, color = ['grey','r'],\n         bins = 'auto',label = ['Stayed','Exited'],\n         edgecolor='black', linewidth=1.2)\nax1.legend()\nax1.set_title('Tenure')\n\nax2.hist([\n        dataset[(dataset.Exited==0)]['Balance'],\n        dataset[(dataset.Exited==1)]['Balance']\n        ], \n         stacked=True, color = ['grey','r'],\n         bins = 'auto',label = ['Stayed','Exited'],\n         edgecolor='black', linewidth=1.2)\nax2.legend()\nax2.set_title('Balance')\n\nax3.hist([\n        dataset[(dataset.Exited==0)]['EstimatedSalary'],\n        dataset[(dataset.Exited==1)]['EstimatedSalary']\n        ], \n         stacked=True, color = ['grey','r'],\n         bins = 'auto',label = ['Stayed','Exited'],\n         edgecolor='black', linewidth=1.2)\nax3.legend()\nax3.set_title('Estimated Salary')\n\nfig.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the tables and plots above, we can have some insights:\n\n1. As for gender, `women are lower in number` than the men, but have a `higher rate to close` the account.\n2. There is a `higher rate of exited clients in Germany `(32%, which is about 2x higher), and `lower in Spain` and France (around 16% each).\n3. On age, `customer below 40 and above 65` years old have a `tendency to keep their account`.\n4. Has or not `credit card does not impact on the decision` to stay in the bank (both groups has 20% of exited customers)\n5. Non active members tend to discontinue their services with a bank compared with the active clients (27% vs 14%). \n6. The dataset has 96% of clients  with 1 or 2 product, and `customers with 1 product only have a higher rate to close the account` than those with 2 products (around 3x higher).\n7. Estimated `Salary does not seem to affect` the churn rate","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 2. Predictive Models","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Separating Dataset into X and y subsets","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### 2.1 One-Hot encoding Categorical Attributes","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"- One-Hot encoding Categorical Attributes::::::::::::::::::It refers to splitting the column which contains numerical categorical data to many columns depending on the number of categories present in that column. Each column contains “0” or “1” corresponding to which column it has been placed.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"- One-Hot encoding -- process by which categorical variables are converted into a form that could be provided to ML algorithms.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"list_cat=['Geography','Gender']\ndataset=pd.get_dummies(dataset,columns=list_cat,prefix=list_cat)\n#we have converted the both categorical columns into dummy variables for processing\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dropping the unnecessory columns \ndataset = dataset.drop(['RowNumber', 'CustomerId', 'Surname', 'Exited_str','HasCrCard_str', 'IsActiveMember_str','NumOfProducts_str'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating input variables (dropping output column)\nfeatures = list(dataset.drop('Exited', axis = 1))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#this is our output columns\ntarget = 'Exited'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.2 Splitting the dataset into the Training set and Test set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test = train_test_split(dataset, test_size = 0.2, random_state = 1)\n\n#here we are deviding the dataset into 80-20 ratio for training and testing\n\nprint('Number of clients in the dataset: {}'.format(len(dataset)))\nprint('Number of clients in the train set: {}'.format(len(train)))\nprint('Number of clients in the test set: {}'.format(len(test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"exited_train = len(train[train['Exited'] == 1]['Exited'])\nexited_train_perc = round(exited_train/len(train)*100,1)\n\nexited_test = len(test[test['Exited'] == 1]['Exited'])\nexited_test_perc = round(exited_test/len(test)*100,1)\n\nprint('Complete Train set - Number of clients that have exited the program: {} ({}%)'.format(exited_train, exited_train_perc))\nprint('Test set - Number of clients that haven\\'t exited the program: {} ({}%)'.format(exited_test, exited_test_perc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2.3 Feature Scaling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n#Standardize features by removing the mean and scaling to unit variance","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Feature scaling is a method used to normalize the range of independent variables or features of data. In data processing, it is also known as data normalization and is generally performed during the data preprocessing step.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sc = StandardScaler()\n\n# fit on training set\ntrain[features] = sc.fit_transform(train[features])\n\n# only transform on test set\ntest[features] = sc.transform(test[features])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.4 Complete Trainning Set","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### 2.4.1 Logistic Regression (Sklearn)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LR_Classifier = LogisticRegression(penalty = 'l2').fit(train[features], train[target])\nLR_Classifier = LR_Classifier.fit(train[features], train[target])\nLR_pred = LR_Classifier.predict(test[features])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import balanced_accuracy_score, roc_auc_score, accuracy_score, classification_report, confusion_matrix\nLR_acc = accuracy_score(test[target], LR_pred)\nprint(\"Logistic Regression accuracy is\",LR_acc)\ncm = confusion_matrix(test[target], LR_pred)\n\nplot_Confusion_matrix(cm,['Exited','Not Exited'],'Blues',\"Logistic Regression\", LR_acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LR_Cla_Rep = classification_report(test[target], LR_pred)\nprint(LR_Cla_Rep)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- 1- Accuracy of our Machine Learning model is 81% ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"- 2- precision of exited - notexited predictive result is respectively 83% and 64%\n\n#(also called positive predictive value) is the fraction of relevant instances among the retrieved instances","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"- recall of exited - notexited predictive result is respectively 97% and 33%\n\n#(also known as sensitivity) is the fraction of the total amount of relevant instances that were actually retrieved. Both precision and recall are therefore based on an understanding and measure of relevance. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"- 3- F1 score  of exited - notexited predictive result is respectively 89% and 33%\n\n#F1 Score is the weighted average of Precision and Recall. Therefore, this score takes both false positives and false negatives into account. Intuitively it is not as easy to understand as accuracy, but F1 is usually more useful than accuracy, especially if you have an uneven class distribution.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"- 4- macro avg of precision ,recall , f1-score is respectively 73%,59%,61%\n\n#Macro-average recall = (R1+R2)/2 = (80+84.75)/2 = 82.25. The Macro-average F-Score will be simply the harmonic mean of these two figures. Suitability. Macro-average method can be used when you want to know how the system performs overall across the sets of data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}