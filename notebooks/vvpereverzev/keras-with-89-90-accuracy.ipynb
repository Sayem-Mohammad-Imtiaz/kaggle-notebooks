{"cells":[{"metadata":{},"cell_type":"markdown","source":"According to the conditions of the problem at the university, I had to solve this task using only neural networks. I chose Keras for its simplicity.\n\nUnfortunately, the majority of the owners of the kernels flopped neural networks without any data preparation, and as a result they receive 80-85% score. I tried to make it just a bit smarter and got an accuracy of 89-90%.\n\nIn principle, just a little has been done: data is standardized, classes are balanced, and a pair of hidden layers in a neural network was added. You can also replace the output activation function to softmax, and make cross-validate. I tried it, but my accuracy was low. If you beat my record, please send a link to your work on email: vvpereverzev@edu.hse.ru"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import *\nsns.set_style('whitegrid')\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\nnp.random.seed(42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/heart.csv', delimiter=',')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's look at the distribution of people by sex\nmale = len(data[data.sex == 1])\nfemale = len(data[data.sex == 0])\nsns.countplot('sex', hue='target', data=data)\nplt.title('Heart Disease: Sex')\nplt.xlabel('Sex (0 = Female, 1 = Male)')\nplt.xticks(rotation=0)\nplt.legend([\"Haven't Disease\", \"Have Disease\"])\nplt.ylabel('Frequency')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now, let's look at the distribution of people by age.\nplt.figure(figsize=(9, 9))\nplt.title('Heart Disease: Age')\nplt.xlabel('Age')\nplt.ylabel('Qantity')\ndata['age'].hist(bins=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_v = data.iloc[:, 0:13].values\nprint('Feature vector:', data_v[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's look at the overall distribution. Maybe we will find out something"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Reducing the dimension to 2 for visualization.\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=2).fit(data_v)\ndata_2d = pca.transform(data_v)\n\n#Building a graph on a two-dimensional matrix\ncolormap = np.array(['red', 'lime'])\nplt.figure(figsize=(10, 10))\n\nfor i in range(0, data_2d.shape[0]):\n    if data['target'][i] == 1:\n        c1 = plt.scatter(data_2d[i, 0], data_2d[i, 1], c='red')\n    elif data['target'][i] == 0:\n        c2 = plt.scatter(data_2d[i, 0], data_2d[i, 1], c='lime')\n\nplt.title('People distribution')\nplt.legend([c1, c2], ['Sick', 'Healthy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see, they are not that different."},{"metadata":{},"cell_type":"markdown","source":"At the end, we look at the correlation of signs"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 12))\nsns.heatmap(data.corr(), annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It's simple! Less thalach, more oldpeak, and everything will be fine"},{"metadata":{},"cell_type":"markdown","source":"## Let's look at the distribution of target"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data['target'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(7, 7))\ndata['target'].value_counts().plot(kind='bar', label='Target')\nplt.legend()\nplt.title('Distribution of target')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Rebalancing target values"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils import resample\n\ndf_majority = data[data.target==1]\ndf_minority = data[data.target==0]\n \n\ndf_minority_upsampled = resample(df_minority, \n                                 replace=True,     \n                                 n_samples=165,    \n                                 random_state=123)\n \n\ndata = pd.concat([df_majority, df_minority_upsampled])\n \n\ndata['target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras import metrics\nfrom keras.layers.core import Dense, Activation ,Dropout\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Standardize data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_pop = data.drop(\"target\", axis=1)\ntarget = data[\"target\"]\nX_train, X_test, Y_train, Y_test = train_test_split(data_pop, target, test_size=0.3, random_state=0)\n\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Keras time"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Keras neural network\n\nmodel = Sequential()\nmodel.add(Dense(15, init = 'uniform', activation='relu', input_dim=13))\nmodel.add(Dense(10, init = 'uniform', activation='relu'))\nmodel.add(Dense(6, init = 'uniform', activation='relu'))\nmodel.add(Dense(1, init = 'uniform', activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n#Fitting\nmodel.fit(X_train, Y_train, epochs=130)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Testing on a test sample\nY_pred_nn = model.predict(X_test)\nrounded = [round(x[0]) for x in Y_pred_nn]\nY_pred_nn = rounded","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_nn = round(accuracy_score(Y_pred_nn, Y_test)*100,2)\nscore_f1 = round(f1_score(Y_pred_nn, Y_test)*100, 2)\nprint(\"Accuracy score: \" + str(score_nn) + \" %\")\nprint(\"F1 score: \" + str(score_f1) + \"%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If at start you got less accuracy, then try restarting the cells with the neural network several times: until the scales are initialized with greater accuracy"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}