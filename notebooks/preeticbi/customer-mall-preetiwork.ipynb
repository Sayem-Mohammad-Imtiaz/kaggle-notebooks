{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Exercise\n### Beginners: Mall Customer Segmentation using Gaussian Mixture Model\n\n##### Proceed to cluster customers as follows:\n\ni)    Read dataset and rename columns appropriately. \n\nii)   Drop customerid column and also transform Gender column to [0,1].  \n\niii)  Use seaborn to understand each feature and relationships among features. \n\niv)  Use sklearn's StandardScaler() to scale dataset. \n\nv)   Perform clustering using Gaussian Mixture Modeling. \n\nvi)  Use aic and bic measures to draw a scree plot and discover ideal number of clusters. \n\nviii) Lookup anomalous customers and try to understand their behavior. \n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Call Libraries\n# For Handling of Warnings\nimport warnings\n# Handling of \"Deprecation Warnings\"\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n\n# For data manipulations\nimport numpy as np\nimport pandas as pd\nimport re\n\n# For plotting\nimport seaborn as sns; sns.set(style=\"white\", color_codes=True)\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport matplotlib.pyplot as plt\nfrom pandas.plotting import andrews_curves\n\n# Modeling Library\n# For data processing\nfrom sklearn.preprocessing import StandardScaler\n\n# Split dataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.manifold import TSNE\n\n# How good is clustering?\nfrom sklearn.metrics import silhouette_score\nfrom yellowbrick.cluster import SilhouetteVisualizer\n\n\n# Class to develop kmeans model\nfrom sklearn.cluster import KMeans\n\n# OS related\nimport os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display multiple outputs from a jupyter cell\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### i) Read dataset and rename columns appropriately.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Go to folder containing data file\nos.chdir(\"/kaggle/input/customer-segmentation-tutorial-in-python\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read csv file\ncust_df = pd.read_csv(\"Mall_Customers.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set Maximum Columns Option\npd.options.display.max_columns = 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Some DataSet related information\ncust_df.shape\ncust_df.columns\ncust_df.head","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Rename Columns 'Annual Income (k$)' & 'Spending Score (1-100)'\ncust_df.rename(columns={'Annual Income (k$)':'Annual_Income_k',\n                       'Spending Score (1-100)':'Spending_Score_1to100'},inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ii) Drop customerid column and also transform Gender column to [0,1].","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop 'CustomerID' column\ncust_df.drop(columns={'CustomerID'},inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#have a Look of Modified Column_names & their dtypes\ncust_df.columns\ncust_df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transform 'Gender' column\n# Replace Male with 0\n# Replace Female with 1\ncust_df.Gender[cust_df['Gender']=='Male']=0\ncust_df.Gender[cust_df['Gender']=='Female']=1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### iii) Use seaborn to understand each feature and relationships among features.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add two categorical columns for analysis purpose\n# 'Age_Cat': will categorise age in 'Young','Adult','Elder'\n# 'Income_Cat' : will categorise Annual_income in 'Low','Medium' ,'High'\ncust_df['Age_Cat']= pd.cut(cust_df['Age'],\n                         bins=3,\n                         labels=['Young','Adult','Elder'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cust_df['Income_Cat']= pd.cut(cust_df['Annual_Income_k'],\n                         bins=3,\n                         labels = ['L','M','H'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Explore modified data\ncust_df.head","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Relate 'Spending_Score' with 'Age'\n# Young category customers' maximum spending score is upto 100.\n# Adult category customers have avg spending score range between 0 to 90.\n# Elder customers spending score is between 0 to 60 only\nsns.relplot(x='Age',y='Spending_Score_1to100',col='Age_Cat',data=cust_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"group1= cust_df.groupby('Age_Cat').mean","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(cust_df['Age'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Relate Gender with Spending_Score\n# Male spending score is between 22 to 70 whereass Female customers' spending score is 30 to 75.\n\nsns.catplot('Gender','Spending_Score_1to100', data = cust_df, kind = 'box') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Strong correlation between Age & Annual_Income_k\nsns.jointplot(cust_df.Age, cust_df.Annual_Income_k,        kind = 'hex') \n# Strong correlation between Age & Annual_Income_k\nsns.jointplot(cust_df.Age, cust_df.Spending_Score_1to100,        kind = 'kde') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x='Income_Cat', y='Spending_Score_1to100', kind='bar',hue='Gender',    data = cust_df) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using for loop to plot all at once\ncolumns = ['Age', 'Annual_Income_k', 'Spending_Score_1to100', 'Gender']\nfig = plt.figure(figsize = (10,10))\nfor i in range(len(columns)):\n    plt.subplot(2,2,i+1)\n    sns.distplot(cust_df[columns[i]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# More such relationships through for-loop\ncolumns = ['Age', 'Annual_Income_k', 'Spending_Score_1to100', 'Gender']\ncatVar = ['Age_Cat', 'Income_Cat' ]\n\n# Now for loop. First create pairs of cont and cat variables\nmylist = [(cont,cat)  for cont in columns  for cat in catVar]\nmylist\n\n# 6.4 Now run-through for-loop\nfig = plt.figure(figsize = (10,10))\nfor i, k in enumerate(mylist):\n    #print(i, k[0], k[1])\n    plt.subplot(4,2,i+1)\n    sns.boxplot(x = k[1], y = k[0], data = cust_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Relationship of a categorical to numeric variable\nsns.barplot(x = 'Age_Cat',\n            y = 'Annual_Income_k',\n            estimator = np.sum,      # As there are multiple occurrences of Gender, sum up 'Clicked_on_ad'\n            ci = 95,                 # Estimate default confidence interval using bootstrapping\n            hue = 'Gender',\n            data = cust_df,\n            #capsize = 1\n            )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Relationship of a categorical to another numeric variable\nsns.barplot(x = 'Gender',\n            y = 'Annual_Income_k',\n            estimator = np.sum,      # As there are multiple occurrences of Gender, sum up 'Clicked_on_ad'\n            ci = 95,                 # Estimate default confidence interval using bootstrapping\n            hue = 'Age_Cat',\n            data = cust_df,\n            #capsize = 1\n            )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Relationship of a categorical to another categorical variable\nfig = plt.figure(figsize = (10,8))\nsns.barplot(x = 'Income_Cat',\n            y = 'Gender',\n            estimator = np.sum,      # As there are multiple occurrences of Gender, sum up 'Clicked_on_ad'\n            ci = 68,                 # Estimate default confidence interval using bootstrapping\n            hue = 'Age_Cat',\n            data = cust_df,\n            #capsize = 1\n            )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### iv) Use sklearn's StandardScaler() to scale dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop Categorical Columns\ncust_df.drop(columns=['Age_Cat','Income_Cat'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scale data using StandardScaler\nss = StandardScaler()     # Create an instance of class\nss.fit(cust_df)                # Train object on the data\nX = ss.transform(cust_df)      # Transform data\nX[:5, :]                  # See first 5 rows","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### v) Perform clustering using Gaussian Mixture Modeling.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Perform clsutering\ngm = GaussianMixture(\n                     n_components = 2,\n                     n_init = 10,\n                     max_iter = 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train the algorithm\ngm.fit(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Where are the clsuter centers\ngm.means_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Did algorithm converge?\ngm.converged_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# How many iterations did it perform?\ngm.n_iter_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Clusters labels\ngm.predict(cust_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Weights of respective gaussians.\ngm.weights_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# What is the frequency of data-points\nnp.unique(gm.predict(X), return_counts = True)[1]/len(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot cluster and cluster centers\nfig = plt.figure()\nplt.scatter(X[:,0],X[:,1],\n            c=gm.predict(X),\n            s=2)\nplt.scatter(gm.means_[:,0], gm.means_[:,1],\n            marker='v',\n            s=5,               # marker size\n            linewidths=5,      # linewidth of marker edges\n            color='red'\n            )\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## vi) Use aic and bic measures to draw a scree plot and discover ideal number of clusters.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Discover How many clusters are there?\nbic = []\naic = []\nfor i in range(8):\n    gm = GaussianMixture(\n                     n_components = i+1,\n                     n_init = 10,\n                     max_iter = 100)\n    gm.fit(X)\n    bic.append(gm.bic(X))\n    aic.append(gm.aic(X))\n# Look at the plots\n\nfig = plt.figure()\nplt.plot([1,2,3,4,5,6,7,8], aic)\nplt.plot([1,2,3,4,5,6,7,8], bic)\nplt.show()\n\n# Plot has minimum value at 2-clusters","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tsne = TSNE(n_components = 2,perplexity=30.0)\ntsne_out = tsne.fit_transform(X)\nplt.scatter(tsne_out[:, 0], tsne_out[:, 1],\n            marker='v',\n            s=10,              # marker size\n            linewidths=5,      # linewidth of marker edges\n            c=gm.predict(X)   # Colour as per gmm\n            )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## viii) Lookup anomalous customers and try to understand their behavior.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Anomaly detection\ndensities = gm.score_samples(X)\ndensities\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"density_threshold = np.percentile(densities,4)\ndensity_threshold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"anomalies = X[densities < density_threshold]\nanomalies\nanomalies.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show anomalous points\nfig = plt.figure()\nplt.scatter(X[:, 0], X[:, 1], c = gm.predict(X))\nplt.scatter(anomalies[:, 0], anomalies[:, 1],\n            marker='v',\n            s=20,               # marker size\n            linewidths=5,      # linewidth of marker edges\n            color='blue'\n            )\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets analyse the differences in anomalous & unanomalous (ie normal)data.\n# Get first unanomalous data\nunanomalies = X[densities >= density_threshold]\nunanomalies.shape    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transform both anomalous and unanomalous data to pandas DataFrame\ndf_anomalies = pd.DataFrame(anomalies, columns = cust_df.columns.values)\ndf_anomalies['type_unA_An'] = 'anomalous'   # Create a IIIrd constant column\ndf_normal = pd.DataFrame(unanomalies, columns = cust_df.columns.values)\ndf_normal['type_unA_An'] = 'unanomalous'    # Create a IIIrd constant column\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Explore df_anomalies & df_normal\ndf_anomalies","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_normal","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let us see density plots\n# Dispersion of Normal points is lesser than anomalous points\nsns.distplot(df_anomalies['Annual_Income_k'])\nsns.distplot(df_normal['Annual_Income_k'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Draw side-by-side boxplots\n# Ist stack two dataframes\ndf = pd.concat([df_anomalies,df_normal])\n# Draw featurewise boxplots\nsns.boxplot(x = df['type_unA_An'], y = df['Annual_Income_k'])\n# Again less dispersion for normal points comparetively .","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Here less dispersion for anomalous points comparetively .\nsns.boxplot(x = df['type_unA_An'], y = df['Spending_Score_1to100'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}