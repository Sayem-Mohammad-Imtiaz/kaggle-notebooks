{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Stroke Prediction"},{"metadata":{},"cell_type":"markdown","source":"Predicting whether or not a person would have a stroke. The dataset is acquired from kaggle (https://www.kaggle.com/fedesoriano/stroke-prediction-dataset)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv('../input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(df.isna(), cmap='magma')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see from the .info() command, the bmi columns are missing about 100 data. But in the heatmap we see that the missing values are actually not too significant, so we're just gonna drop the entire missing values."},{"metadata":{"trusted":true},"cell_type":"code","source":"df2=df.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Some EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='gender', data=df2)\nprint(df['gender'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='stroke', data=df2, palette='rocket', hue='gender')\nplt.xlabel('Stroke')\nplt.ylabel('Count')\nprint(df['stroke'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see, the data is heavily imbalanced. We're going to have to deal with this later on."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='Residence_type', data=df2, palette='magma', hue='gender')\nplt.xlabel('Residence Type')\nplt.ylabel('Count')\nplt.title('Classification Based on Residence Type', fontsize=14)\nprint(df['Residence_type'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='smoking_status', data=df2, palette='viridis', hue='gender')\nplt.xlabel('Smoking Status')\nplt.ylabel('Count')\nplt.title('Classification Based on Smoking Status', fontsize=14)\nprint(df['smoking_status'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='ever_married', data=df2, palette='mako', hue='gender')\nplt.xlabel('Ever Married')\nplt.ylabel('Count')\nplt.title('Classification Based on Marriage', fontsize=14)\nprint(df['ever_married'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='work_type', data=df2, palette='viridis', hue='gender')\nplt.xlabel('Work Type')\nplt.ylabel('Count')\nplt.title('Classification Based on Work', fontsize=14)\nprint(df['work_type'].value_counts())\nplt.legend(loc='upper right')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Turn Categorical Columns into Numerical Values"},{"metadata":{},"cell_type":"markdown","source":"Using One Hot encoding, we should transform categorical columns such as gender, ever_married, work_type, Residence_type and smoking_status into numerical columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"gender=pd.get_dummies(df2['gender'], drop_first=True)\nmarried=pd.get_dummies(df2['ever_married'], drop_first=True)\nwork=pd.get_dummies(df2['work_type'], drop_first=True)\nreside=pd.get_dummies(df2['Residence_type'], drop_first=True)\nsmoke=pd.get_dummies(df2['smoking_status'], drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Concat to the dataframe (df2) and make it into a new dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"ndf=pd.concat([df2,gender,married,work,reside,smoke], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Drop 'id' column and also the original categorical columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"ndf.drop(['id','gender','ever_married','work_type','Residence_type','smoking_status'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Deal with the imbalanced data"},{"metadata":{},"cell_type":"markdown","source":"What we're gonna do is that we're gonna oversample the minority data (stroke=1) and undersample the majority data (stroke=0). <br>\n<br>\nWe are going to use SMOTE for the oversampling process and RandomUnderSampler for the undersampling process"},{"metadata":{},"cell_type":"markdown","source":"First we separate the target and the features"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=ndf.drop('stroke', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=ndf['stroke']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Import SMOTE and RandomUnderSampler"},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.pipeline import Pipeline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oversample = SMOTE()\nundersample = RandomUnderSampler()\nsteps = [(\"o\", oversample), (\"u\", undersample)]\npipeline = Pipeline(steps=steps)\n# transform the dataset\nX, y = pipeline.fit_resample(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we do train test split with test size = 30%"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test= train_test_split(X,y, test_size=0.3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that the y dataframe is now evenly distributed. Now we build the model."},{"metadata":{},"cell_type":"markdown","source":"## Building model"},{"metadata":{},"cell_type":"markdown","source":"For this project we're gonna use Logistic Regression, Random Forest, KNN, and Gaussian Naive Bayes and then we're gonna compare the scores of each model."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Elbow method for optimal number of n_neighbors in KNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"err_rate=[]\n\nfor i in range (1,50):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train, y_train)\n    pred_i = knn.predict(X_test)\n    err_rate.append(np.mean(pred_i != y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,5))\nsns.set_style('whitegrid')\nplt.plot(range(1,50),err_rate, color='green', marker='d', ls='--')\nplt.xticks(np.arange(1,50,1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So the optimal number of n_neighbors is 2"},{"metadata":{"trusted":true},"cell_type":"code","source":"lm=LogisticRegression()\nrfc=RandomForestClassifier()\ngnb=GaussianNB()\nknn=KNeighborsClassifier(n_neighbors=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lm.fit(X_train,y_train)\nrfc.fit(X_train,y_train)\ngnb.fit(X_train,y_train)\nknn.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lmpredict=lm.predict(X_test)\nrfcpredict=rfc.predict(X_test)\ngnbpredict=gnb.predict(X_test)\nknnpredict=knn.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Comparison"},{"metadata":{},"cell_type":"markdown","source":"Use classification report to determine which model fits this project best."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Classification report for Logistic Regression')\nprint(classification_report(lmpredict,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Classification report for Random Forest Classifier')\nprint(classification_report(rfcpredict,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Classification report for KNN')\nprint(classification_report(knnpredict,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Classification report for GNB')\nprint(classification_report(gnbpredict,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Thank You"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}