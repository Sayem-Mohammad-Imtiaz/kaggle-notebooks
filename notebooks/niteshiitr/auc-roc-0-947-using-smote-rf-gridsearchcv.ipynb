{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Load necessary libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pandas.plotting import scatter_matrix\nfrom statsmodels.formula.api import ols\npd.set_option('precision', 3)\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loading the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"wine = pd.read_csv(\"../input/winequality-red.csv\")\nwine.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"wine[pd.isnull(wine).any(axis=1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping the null rows\nwine.dropna(axis=0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wine.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wine.quality.value_counts()\n#plt.hist(wine.quality)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### COMMENT : Highly imbalance classes with majority being 5 & 6"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\n\ncor = wine.corr()\nmask = np.zeros_like(cor, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\nsns.heatmap(cor,mask=mask,annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### COMMENT : A few variables like fixed acidity, pH, total & fixed sulphur dioxide are correlated as expected but correlation coefficient ain't really high so as to drop them from the dataset. So we will consider all the variables to be the part of our training data"},{"metadata":{"trusted":true},"cell_type":"code","source":"wine.groupby('quality').mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25,35))\ni=1\nfor col in wine.columns[:-1] :\n    plt.subplot(4,3,i)\n    sns.boxplot(x='quality',y=col,data=wine)\n    i = i+1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### COMMENT : Except for all 3 kinds of acidities & alcohol, there ain't much trend between quality of wine and the variables. There are, though, huge number of outliers in a few variables."},{"metadata":{},"cell_type":"markdown","source":"### Splitting data into train and test"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx = wine.drop('quality',axis=1)\ny = wine.quality","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Standardise the training and testing data and oversampling using SMOTE"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=0)\n\nfrom sklearn.preprocessing import StandardScaler\nscale = StandardScaler().fit(x_train)\nx_train_std = scale.transform(x_train)\nx_test_std = scale.transform(x_test)\n\nfrom imblearn.over_sampling import SMOTE\nsm = SMOTE(random_state=0)\nx_train_std_os,y_train_os = sm.fit_sample(x_train_std,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Using ordinal logit to predict the wine quality"},{"metadata":{"trusted":true},"cell_type":"code","source":"import mord\nquality = np.array([3,4,5,6,7,8])\n\nord_model_IT = mord.LogisticIT(alpha=0).fit(x_train_std,y_train.astype('int'))\ny_pred_IT = ord_model_IT.predict_proba(x_test_std)\nord_model_AT = mord.LogisticAT(alpha=0).fit(x_train_std,y_train.astype('int'))\ny_pred_AT = ord_model_AT.predict_proba(x_test_std)\n\norder_IT = np.argmax(y_pred_IT,axis=1)\npredicted_IT = np.zeros((order_IT.size))\nfor i in range(len(predicted_IT)):\n    predicted_IT[i] = order_IT[i]+3\n    \norder_AT = np.argmax(y_pred_AT,axis=1)\npredicted_AT = np.zeros((order_AT.size))\nfor i in range(len(predicted_AT)):\n    predicted_AT[i] = order_AT[i]+3","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Evalutating the performance of ordinal logit"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error,mean_squared_error,precision_score,f1_score\n\ndf1 = pd.DataFrame(y_test)\ndf2 = pd.DataFrame(predicted_IT,columns=['predicted'])\n\nres_ord = pd.concat([df1.reset_index(),df2.reset_index()],axis=1).drop(['index'],axis=1)\nprint ('Macro precision = ',precision_score(res_ord.quality,res_ord.predicted,average='macro'))\nprint ('Micro precision = ',precision_score(res_ord.quality,res_ord.predicted,average='micro'))\n\nprint ('Macro f1 score = ',f1_score(res_ord.quality,res_ord.predicted,average='macro'))\nprint ('Micro f1_score = ',f1_score(res_ord.quality,res_ord.predicted,average='micro'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Using an RF model for the predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf_model = RandomForestClassifier(random_state=0).fit(x_train_std_os,y_train_os)\ny_pred_RF = rf_model.predict(x_test_std)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = pd.DataFrame(y_test)\ndf2 = pd.DataFrame(y_pred_RF,columns=['predicted'])\n\nres_rf = pd.concat([df1.reset_index(),df2.reset_index()],axis=1).drop(['index'],axis=1)\nprint ('Macro precision = ',precision_score(res_rf.quality,res_rf.predicted,average='macro'))\nprint ('Micro precision = ',precision_score(res_rf.quality,res_rf.predicted,average='micro'))\n\nprint ('Macro f1 score = ',f1_score(res_rf.quality,res_rf.predicted,average='macro'))\nprint ('Micro f1_score = ',f1_score(res_rf.quality,res_rf.predicted,average='micro'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### OBSERVATION : We get very low values of precision and f1 score if we try to predict the exact quality bucket of wine. So a better approach, as per the guidelines, would be to split the wine quality in 2 buckets, i.e. good(above 6) and bad(below or equal to 6)"},{"metadata":{},"cell_type":"markdown","source":"### Create a binary quality variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"good = y.apply(lambda x: int(x/7))\ngood.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Split the data, standardise and oversample using SMOTE"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,good,test_size=0.2,random_state=0)\n\nfrom sklearn.preprocessing import StandardScaler\nscale = StandardScaler().fit(x_train)\nx_train_std = scale.transform(x_train)\nx_test_std = scale.transform(x_test)\n\nfrom imblearn.over_sampling import SMOTE\nsm = SMOTE(random_state=0)\nx_train_std_os,y_train_os = sm.fit_sample(x_train_std,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### EVALUATION METRIC : Since it's a highly class imbalance data, looking at accuracy will be misguiding. So we are gonna look at area under precision recall curve as our evaluation metric for different models."},{"metadata":{},"cell_type":"markdown","source":"### Training multiple models on train data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Logistic regression\nfrom sklearn.linear_model import LogisticRegression\nlr = LogisticRegression(random_state=0).fit(x_train_std_os,y_train_os)\nlr_pred = lr.predict_proba(x_test_std)\n\n# Decision tree\nfrom sklearn.tree import DecisionTreeClassifier\ntree = DecisionTreeClassifier(random_state=0).fit(x_train_std_os,y_train_os)\ntree_pred = tree.predict_proba(x_test_std)\n\n# Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(random_state=0).fit(x_train_std_os,y_train_os)\nrf_pred = rf.predict_proba(x_test_std)\n\n# KNN classifier\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier().fit(x_train_std_os,y_train_os)\nknn_pred = knn.predict_proba(x_test_std)\n\n# SVC : Linear kernel\nfrom sklearn.svm import SVC\nsv_lin = SVC(kernel='linear',random_state=0,probability=True).fit(x_train_std_os,y_train_os)\nsv_lin_pred = sv_lin.predict_proba(x_test_std)\n\n# SVC : RBF kernel\nfrom sklearn.svm import SVC\nsv_rbf = SVC(kernel='rbf',random_state=0,probability=True).fit(x_train_std_os,y_train_os)\nsv_rbf_pred = sv_rbf.predict_proba(x_test_std)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Evaluating the models using AUPRC"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_recall_curve,average_precision_score,auc,roc_auc_score\n\nmodels = ['LR','Decision Tree','Random Forest','KNN','Linear kernel SVM','RBF kernel SVM']\npreds = [lr_pred,tree_pred,rf_pred,knn_pred,sv_lin_pred,sv_rbf_pred]\nfor pred,model in zip(preds,models):\n    precision,recall,thresholds = precision_recall_curve(y_test,pred[:,1])\n    print ('Area under precision recall curve for %s model = '%(model),round(auc(recall,precision),3))\n    print ('Area under ROC curve for %s model = '%(model),round(roc_auc_score(y_test,pred[:,1]),3),'\\n') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nprint ('Train set AUC for Random Forest model : ',roc_auc_score(y_train,rf.predict_proba(x_train_std)[:,1]))\nprint ('Cross validation AUC for Random Forest model : ',np.mean(cross_val_score(rf,x_train_std,y_train,scoring='roc_auc',cv=10)))\nprint ('Test set AUC for Random Forest model : ',roc_auc_score(y_test,rf.predict_proba(x_test_std)[:,1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### COMMENT : Random forest model does the best among all. We will tune it's hyperparameters now using GridSearchCV"},{"metadata":{},"cell_type":"markdown","source":"### Tuning RF model's hyperparameters using GridSearchCV"},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will first use RandomizedSearchCV to narrow down the sample space for GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\nn_estimators = [i for i in range(100,1100,100)]\nmax_depth = [i for i in range(10,110,10)]\nmax_depth.append(None)\nmax_features = ['auto','sqrt']\n\nrandom_grid = {'n_estimators' : n_estimators,\n               'max_depth' : max_depth,\n               'max_features' : max_features}\n\nrf_new = RandomForestClassifier(random_state=0)\nrf_rand = RandomizedSearchCV(rf_new,random_grid,n_iter=100,cv=10,verbose=0,random_state=0,n_jobs=-1)\nrf_rand.fit(x_train_std_os,y_train_os)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print ('Best params obtained via random search : ',rf_rand.best_params_)\nprint ('AUC achieved using the base model : ',round(roc_auc_score(y_test,rf.predict_proba(x_test_std)[:,1]),3))\nbest_rand = rf_rand.best_estimator_\nprint ('AUC achieved using the best params achieved in Randomized search : ',round(roc_auc_score(y_test,best_rand.predict_proba(x_test_std)[:,1]),3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### COMMENT : Since now we have the best parameters obtained via random search and that shows an improvement over base model, we will fine tune our search using GridSearchCV "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = {'n_estimators' : [100,200,300,400,500,600,1000],\n              'max_depth' : [10,20,30,40,50,60,None],\n              'max_features' : ['auto','sqrt']}\n\nrf_new = RandomForestClassifier(random_state = 0)\nrf_grid = GridSearchCV(rf_new,param_grid,verbose=0,n_jobs=-1,cv=10)\nrf_grid.fit(x_train_std_os,y_train_os)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print ('Best params achieved via GridSearch : ',rf_grid.best_params_)\nrf_best = rf_grid.best_estimator_\nprint ('Best AUC achieved using best params : ',round(roc_auc_score(y_test,rf_best.predict_proba(x_test_std)[:,1]),3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plot the feature importances"},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_importances = pd.DataFrame(rf.feature_importances_,index = x_train.columns,\n                                   columns=['importance']).sort_values('importance',ascending=True)  \n\nplt.figure(figsize=(15,5))\nplt.barh(feature_importances.index,feature_importances.importance)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}