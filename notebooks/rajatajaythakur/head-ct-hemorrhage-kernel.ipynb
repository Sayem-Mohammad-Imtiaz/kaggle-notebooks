{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#Thanks to Luciano Prevedello and Barbaros Selner Erdal.\n\n##First of all, we are going to load the images and labels\nfrom glob import glob\nimport os\nimport pandas as pd \nimport cv2\nimport numpy as np\n\n# Now we define the dimensions of our images.\n\nimg_width, img_height = 128, 128\n\nfiles = sorted(glob('../input/head_ct/head_ct/*.png'))\n\nlabels = pd.read_csv('../input/labels.csv')[' hemorrhage'].tolist()\n\nimages = np.empty((len(files), img_width, img_height))\n\nfor i, _file in enumerate(files):\n    images[i, :, :] = cv2.resize(cv2.imread(_file, 0), (img_width, img_height))\n    \nprint ('\\033[1m' + 'Ready for next step!')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"766ca7389634efbbf0cde556b5c8ad6abf241779"},"cell_type":"code","source":"#Let's take a look at the images\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 10))\nfor i in range(0, 9):\n    plt.subplot(330 + 1 + i)\n    plt.imshow(images[i], cmap=plt.get_cmap('gray'))\n    plt.title(\"\\nLabel:{}\".format(labels[i]))\n# show the plot\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9bf9208c2293b5569e6dd2bd5af4c50a5159ebe8"},"cell_type":"code","source":"#Let's take a look at the proportion of normal and hemorrhage labels\ndum = plt.bar(labels, 110)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8102cc5f4436464a0fe5e19db7c450242d071ea8"},"cell_type":"code","source":"#Now we split the dataset into train (80%), validation (10%) and test (10%) sets.\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n\ntrain_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=0.2, random_state=1)\nval_images, test_images, val_labels, test_labels = train_test_split(test_images, test_labels, test_size=0.5, random_state=1)\n\nprint((len(train_images), len(val_images), len(test_images)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b4d56ccfa8539e20686eabd200d7eb780d5313ca"},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense, GlobalAveragePooling2D\nfrom keras import backend as K\n\ninput_shape = (img_width, img_height, 1)\n\nSIIM_custom_model = None\n\nSIIM_custom_model = Sequential()\n\n#Below we have the first Convolutional Layer\n\nSIIM_custom_model.add(Conv2D(32, (3, 3), input_shape=input_shape))\nSIIM_custom_model.add(Activation('relu'))\n\n#We then add a MaxPool layer, which will reduce the size of the output of the first conv layer in 75%.\n#This is performed to avoid an exagerated increase in the number of parameters of the network.\n#Don't worry if you do not understand in detail each one of these operations right now. Try to focus on the big picture.\n\nSIIM_custom_model.add(MaxPooling2D(pool_size=(2, 2)))\n\n#We will add more convolutional layers, followed by MaxPool layers\n\nSIIM_custom_model.add(Conv2D(32, (3, 3)))\nSIIM_custom_model.add(Activation('relu'))\nSIIM_custom_model.add(MaxPooling2D(pool_size=(2, 2)))\n\nSIIM_custom_model.add(Conv2D(64, (3, 3)))\nSIIM_custom_model.add(Activation('relu'))\nSIIM_custom_model.add(MaxPooling2D(pool_size=(2, 2)))\n\n#Finally, we will add two dense layers, or 'Fully Connected Layers'.\n#These layers are classical neural nets, without convolutions.\n\nSIIM_custom_model.add(Flatten())\nSIIM_custom_model.add(Dense(64))\nSIIM_custom_model.add(Activation('relu'))\n\n#Dropout is an overfitting reduction technique.\n\nSIIM_custom_model.add(Dropout(0.5))\n\n#Now, we will set the output o the network.\n#The Dense function has the argument \"1\" because the net output is the hematoma x non-hematoma classification\n\nSIIM_custom_model.add(Dense(1))\n\n#The output is either 0 or 1 and this can be obtained with a sigmoid function.\n\nSIIM_custom_model.add(Activation('sigmoid'))\n\n#Let's compile the network.\n\nSIIM_custom_model.compile(loss='binary_crossentropy',\n              optimizer='rmsprop',\n              metrics=['accuracy'])\n\nprint ('\\033[1m' + 'Ready for next step!')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6a4f24bc2440044ca1bbc8d1a19ad6cb83ad7587"},"cell_type":"code","source":"\nfrom numpy.random import seed\nseed(1337)\nfrom tensorflow import set_random_seed\nset_random_seed(1337)\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nnb_train_samples = len(train_images)\nnb_validation_samples = len(val_images)\nepochs = 100\nbatch_size = 10\n\n\n# this is the augmentation configuration we will use for training\ntrain_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n    shear_range=0.0,\n    zoom_range=0.1,\n    rotation_range=10,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    horizontal_flip=True)\n\n# this is the augmentation configuration we will use for validation:\nval_datagen = ImageDataGenerator(rescale=1. / 255)\n\ntrain_generator = train_datagen.flow(\n    train_images[..., np.newaxis],\n    train_labels,\n    batch_size=batch_size)\n\nvalidation_generator = val_datagen.flow(\n    val_images[..., np.newaxis],\n    val_labels,\n    batch_size=batch_size)\n\nprint ('\\033[1m' + 'Ready for next step!')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"76ac82b2082362ed5f984988a7b3fb0aa4ade718","_kg_hide-output":false,"_kg_hide-input":false,"scrolled":true},"cell_type":"code","source":"history = SIIM_custom_model.fit_generator(\n    train_generator,\n    steps_per_epoch=nb_train_samples // batch_size,\n    epochs=epochs,\n    validation_data=validation_generator,\n    validation_steps=nb_validation_samples // batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a9764408f533094419b0820b4efca374d25843da"},"cell_type":"code","source":"# Plot training & validation accuracy values\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot training & validation loss values\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"783aab9fce6e3bfb47b099e636a7bde5d13441b0"},"cell_type":"code","source":"#Now we evaluate on the test set. Remember to make pixels between [0, 1] by dividing by 255.\n\nprint(\"Accuracy: \" + str(SIIM_custom_model.evaluate(test_images[..., np.newaxis] / 255., test_labels)[1] * 100) + \"%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e9c1afac1b41c677f41644dac640f3887dab2fe2"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}