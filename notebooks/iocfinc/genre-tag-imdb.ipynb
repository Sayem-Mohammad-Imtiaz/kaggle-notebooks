{"cells":[{"metadata":{"_uuid":"ced6afafff58d6893734ea432f17710cdb5f0fae"},"cell_type":"markdown","source":"# Genre Labeler of IMDB descriptions\n\nHere I have created a model for labeling the genre of an input description based on the IMDB dataset. The current version of the model only has an accuracy of 48%.  When tested with data that it has not yet seen (2018 movies) the results are pretty convincing. For now, it is able to retrieve a sample description from the user as the input and will output the likeliest Genre tag for that description. Right now this is using the pipeline `model = Pipeline([('vectorizer',CountVectorizer()),('tfidf',TfidfTransformer()),('clf',OneVsRestClassifier(LinearSVC(class_weight='balanced')))])` for its prediction. What it basically does it look for frequency of the words from the description and create its mapping from there. From that mapping, the new descriptions can then be classified based on the frequency of words as well.\n\nThis could still be improved with the use of Deep Learning, with the use of LSTM or Conv1D (in wavenet configuration) we could possibly make the model think of the context of the description based on the arrangement of the words instead of just the frequency."},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nimport string\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"834e5fa73c26d5d1c7d840e99a9c5ee528e0bb60","trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Read the dataset\ndata = pd.read_csv('../input/IMDB-Movie-Data.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"afadc636a7a6588cafe1e3d150dce3de69b5f85f","scrolled":false,"trusted":true},"cell_type":"code","source":"# Basic check of the data\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b7572fa906bea7b42b223b6705dd1d906ebcac87","trusted":true,"scrolled":false},"cell_type":"code","source":"# Checking the data\ndata.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e93c06d18949c8e35cfb8657093ee94e8d5969f6"},"cell_type":"markdown","source":"## Some Preprocessing\n\nHere I did some preprocessing of the data. We will remove the punctuation marks for the description and make them all lower case. We also make the Genre lower case for uniformity as well. If we do not do this then we could end up with multiple labels as the code will see the different cased genre as unique even though they point to the same genre."},{"metadata":{"_uuid":"21d683c52dfd46a2196def163e4f1ec98cafb2c2","scrolled":false,"trusted":true},"cell_type":"code","source":"# Pre-processing: We want to at do a lower case of Genre and Description columns.\n# Also added removal of punctuation.\ntranslator = str.maketrans('','',string.punctuation)\n\ndata['Description']= data['Description'].str.lower().str.translate(translator)\ndata['Genre']= data['Genre'].str.lower()\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ef907f53347e12a9db910ded5cde64f3296a9a4d"},"cell_type":"markdown","source":"## Splitting up the Genre into the individual components\n\nIf we look at the `Genre` column we can see that there are movies that have more than one genre. Since we want to come up with a genre tag/labeler we must consider the each of the items listed under the `Genre` entry of a data set to be unique. Otherwise we would be labeling them based on the grouping (ex. Action,Sci-fi) instead of (Action __AND__ Sci-fi).<br><br>\n__To Do:__ Come up with a way that we would be able to spilt the genre into each individual components but still retain the same description. For example __[`genre`: `Sci-fi, Action` , `description`:`This is a good movie, lots of action and adventure...`]__ would become two entries, one for Action and one for Sci-fi.<br>\n __[`genre`: `Action` , `description`:`This is a good movie, lots of action and adventure...`]__ <br>\n  __[`genre`: `Sci-fi` , `description`:`This is a good movie, lots of action and adventure...`]__ \n"},{"metadata":{"_uuid":"d7654e3e0131dd24b5c56516d13b2e3a3710135d","trusted":true,"scrolled":true},"cell_type":"code","source":"# This is for splitting the individual grouped genre into individual genre\nnew_data = pd.DataFrame(columns = ['Title','Genre','Description'])\nfor i in range(len(data['Genre'])):  # GO over the Genre\n    for word in data['Genre'][i].split(\",\"): # We will split the Genre\n        new_data = new_data.append({'Title':data['Title'][i],'Genre':word,'Description':data['Description'][i]}, ignore_index = 1)\n# Checking the new data created\nnew_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f7e5cdad0e079122321dcaf4bc7cf15755c5f890","scrolled":true},"cell_type":"code","source":"new_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2b49d152ba6907bb3f8c0a8ffa61cc6ee81a86ee"},"cell_type":"code","source":"# This is for splitting the individual grouped genre into individual genre\nnew_data = pd.DataFrame(columns = ['Title','Genre','Description'])\nfor i in range(len(data['Genre'])):  # GO over the Genre\n    for word in data['Genre'][i].split(\",\"): # We will split the Genre\n        new_data = new_data.append({'Title':data['Title'][i],'Genre':word,'Description':data['Description'][i]}, ignore_index = 1)\n# Checking the new data created\nnew_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"2dc91466f889e33268b1778f9438074c77c11d6b"},"cell_type":"code","source":"new_data.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"82c08f04efc323fe16e269f452b5acb15c6ac7d6","scrolled":true},"cell_type":"code","source":"Genre_count = Counter(new_data['Genre'])\nGenre_count","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3ce5bf27ebbc0e7a069b2233740ba467f6b41966"},"cell_type":"markdown","source":"## Trimming up less frequent genre\n\nReviewing the dataset, we can see that there are genre that appear less frequent than others. For example we have `musical` which only appears 5 times or `western` which only has 7 entries. To avoid under-representation I trimmed up the genre and made one new genre `others` to cover all the genres that have less than 100 entries."},{"metadata":{"trusted":true,"_uuid":"0793ee9763d3c7af824f7ca62bc77a6ebf6a6412"},"cell_type":"code","source":"# Aggregate all Genres with less that 100 items as 'others'\nothers = ['animation','family','music','history','western','war','musical','sport','biography']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b39ab8151db9d77e270389aa66667a7f8f354cf6"},"cell_type":"code","source":"for i in range(len(new_data['Genre'])):\n    if new_data['Genre'][i] in others:\n        new_data.iloc[i]['Genre'] = 'others'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"cde2f92606385788d38c81f111ce63406a82eabd"},"cell_type":"code","source":"new_data[new_data['Genre']=='others']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"007088112e467321e4401bf6e6589f04a8c8a622"},"cell_type":"markdown","source":"## Cleaning up the description (Again)\n\nThis time we are going after the spaces, new lines, and digits (0-9) in the data."},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"63284ea65f041b3d699be43187e1f5536f141c1e"},"cell_type":"code","source":"import re\n\ndef cleanup(string):\n    '''\n    Helper Function:\n    Will clean up the input string (for description) in this case.\n    '''\n    string = re.sub(r\"\\n\",'',string)\n    string = re.sub(r\"\\n\",'',string)\n    string = re.sub(r\"[0-9]\",'digit',string) # We do not care for the specific number\n    string = re.sub(r\"\\''\",'',string)\n    string = re.sub(r'\\\"','',string)\n    return string.strip().lower()\nX = []\n\nfor item in range(new_data.shape[0]):\n    X.append(cleanup(new_data.iloc[item][2]))\ny = np.array(new_data['Genre'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cce4aca3240f480ab038a7a1a3ad65886b8af7be"},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"191920b74237fb7a6a8b0b7f21cf5cfe9996c448"},"cell_type":"markdown","source":"## Splitting the data\n\nHere we split up the data into training data and testing data with a 70-30 split."},{"metadata":{"trusted":true,"_uuid":"3cb3057397cf233c9452b02d2f05266e5ec8a0e6"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0b590678e00dca713468467114355dab1816050f"},"cell_type":"markdown","source":"## Creating the pipeline\n\nI am thinking this is similar to the way we define models in keras/tensorflow (?). We are having the countvectorizer for this model then we use that for the tfidf transformer and finally the classifier."},{"metadata":{"trusted":true,"_uuid":"f1ccce4bb1eb37d4cbc41c6141a69eeebb9a67ec"},"cell_type":"code","source":"# Pipeline\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.svm import LinearSVC\nmodel = Pipeline([('vectorizer',CountVectorizer()),('tfidf',TfidfTransformer()),('clf',OneVsRestClassifier(LinearSVC(class_weight='balanced')))])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"93f748e64ed1ede48a46cf0ad4679d368d4ffbea"},"cell_type":"markdown","source":"## Using Gridsearch to look for optimal parameters\n\nHere we are simply going over some parameters for our model to see which one has the best score overall."},{"metadata":{"trusted":true,"_uuid":"58bee5b3b89887b1433c7d9feb9ff6500f8253e0"},"cell_type":"code","source":"#Selecting the best parameter via gridsearch\nfrom sklearn.grid_search import GridSearchCV\nparameters = {'vectorizer__ngram_range':[(1,1), (1,2),(2,2)],\n              'vectorizer__min_df':[0,0.001],\n              'tfidf__use_idf':('True','False')}\ngs_clf_svm = GridSearchCV(model, parameters, n_jobs= -1)\ngs_clf_svm = gs_clf_svm.fit(X,y)\nprint(gs_clf_svm.best_score_)\nprint(gs_clf_svm.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"39c940376729c86770f6879acf68c12097663f80"},"cell_type":"code","source":"model = Pipeline([('vectorizer',CountVectorizer(ngram_range = (1,2),min_df=0)),\n                  ('tfidf',TfidfTransformer(use_idf=True)),('clf',OneVsRestClassifier(LinearSVC(class_weight='balanced')))])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"86701d1a10d7efa6139343698eaa2f3ca253d8df"},"cell_type":"code","source":"model.fit(X,y)\npred = model.predict(X_test)\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nconfusion_matrix(pred,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"cbf49061c49fd0a3bb485503ec6a53fbe156b3a3"},"cell_type":"code","source":"model.score(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cc0be54736838f2ac1d35d93a5b299222b9a74f6","scrolled":true},"cell_type":"code","source":"model.predict(['Robert McCall serves an unflinching justice for the exploited and oppressed, but how far will he go when that is someone he loves?'])[0]\n\n## Description is from 'The Equalizer' Genre: Action, Crime, Thriller ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2b8f5530d64bd16a23a75dd0236f6adae4505c18"},"cell_type":"markdown","source":"## Balancing the dataset"},{"metadata":{"trusted":true,"_uuid":"34840dcac81a580b40ff1deb3f36f7a4bccceb9d"},"cell_type":"code","source":"a = Counter(new_data['Genre'])\ns = set(a)\ns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d29143ac9a0efc5e4b1fb734d2233cc3fd755087"},"cell_type":"code","source":"trimmed = pd.DataFrame(columns=new_data.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6d4a879d54b8670514b0e58df10aa768d1171b04"},"cell_type":"code","source":"for genre in s:\n    trimmed=trimmed.append(new_data[new_data['Genre'] == genre][:100])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6880ef15eb5b867c313f67ceabd8e9eb24e0783d"},"cell_type":"code","source":"trimmed.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9fac0f45671773636a20caabeaca279693a53872"},"cell_type":"code","source":"trimmed[trimmed['Genre']=='action'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"da296b5ef35cd0d876ece46434c0a0dbc1b3fc8d"},"cell_type":"code","source":"import re\n\ndef cleanup(string):\n    '''\n    Helper Function:\n    Will clean up the input string (for description) in this case.\n    '''\n    string = re.sub(r\"\\n\",'',string)\n    string = re.sub(r\"\\n\",'',string)\n    string = re.sub(r\"[0-9]\",'digit',string) # We do not care for the specific number\n    string = re.sub(r\"\\''\",'',string)\n    string = re.sub(r'\\\"','',string)\n    return string.strip().lower()\nX = []\n\nfor item in range(trimmed.shape[0]):\n    X.append(cleanup(trimmed.iloc[item][2]))\ny = np.array(trimmed['Genre'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d401552ddd0bf9d3b3336f550051bb64d3892ce8"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"de6c45d4b17c25ea40b0f6f92fa68f803a8ac599"},"cell_type":"code","source":"# Pipeline\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.svm import LinearSVC\nmodel = Pipeline([('vectorizer',CountVectorizer()),('tfidf',TfidfTransformer()),('clf',OneVsRestClassifier(LinearSVC(class_weight='balanced')))])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"53693826cd08296f61f7bb9a3e6c7d9622f5d53c"},"cell_type":"code","source":"#Selecting the best parameter via gridsearch\nfrom sklearn.grid_search import GridSearchCV\nparameters = {'vectorizer__ngram_range':[(1,1), (1,2),(2,2)],\n              'vectorizer__min_df':[0,0.001],\n              'tfidf__use_idf':('True','False')}\ngs_clf_svm = GridSearchCV(model, parameters, n_jobs= -1)\ngs_clf_svm = gs_clf_svm.fit(X,y)\nprint(gs_clf_svm.best_score_)\nprint(gs_clf_svm.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2dac32a4729d4166b69be0cdef2940f531c8881b"},"cell_type":"code","source":"model = Pipeline([('vectorizer',CountVectorizer(ngram_range = (1,2),min_df=0)),\n                  ('tfidf',TfidfTransformer(use_idf=True)),('clf',OneVsRestClassifier(LinearSVC(class_weight='balanced')))])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5e343f7c90d69a83d9f0410405cc7680bafcb68d"},"cell_type":"code","source":"model.fit(X_train,y_train)\npred = model.predict(X_test)\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nconfusion_matrix(pred,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b78d7db52642327faf5a70c01f0662b24bc9bf5"},"cell_type":"code","source":"model.score(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"60fed8a9ea9beae23bd661d6347d639f9a5ee9a8"},"cell_type":"code","source":"Description_=input()\nmodel.predict([Description_])[0]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"86fef8cb55ac443d2d8087b1361f285170599cdc"},"cell_type":"markdown","source":"## Saving the model\n\nsource: https://machinelearningmastery.com/save-load-machine-learning-models-python-scikit-learn/"},{"metadata":{"trusted":true,"_uuid":"64152150c0bb35004e5fb2e83c6bd9198bd8b438"},"cell_type":"code","source":"import pickle\nfilename = \"model-genre-classifier.sav\"\npickle.dump(model, open(filename,'wb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ff0d69d7df862a71d03ece1420fc78dd961b811f"},"cell_type":"code","source":"loaded_model = pickle.load(open(filename,'rb'))\nloaded_model.score(X,y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"167f009b30db6f2ac15c8c5b8e9473492c4d4783"},"cell_type":"markdown","source":"## Summary\n\nFor now we have created a model that can classify an input description to a genre. We can still improve on the accuracy of the model, so far we only have a score of 0.495 although it can convincingly ouput a genre that is within the actual genre classification of the target.\n\nSome improvements for this would be:\n\n* The use of an ANN (for improved classification but still frequency based) or the use of RNN-LSTM or Conv1D (WaveNet configuration) for analysis on the arrangement of the words and not just the frequency.\n\n* A possible feature for this would be to output the top 3 Genre for the given description. One possbile way to do this would be the use of cosine similarity although I have to figure out first how to add it to the pipeline."},{"metadata":{"trusted":true,"_uuid":"c5aafeca53ca9e0977fa79aa0a5acde5aec27da5","scrolled":true},"cell_type":"code","source":"### STOP HERE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2f138c426571012f3a58f7725eab047e1bd64a3a"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}