{"cells":[{"metadata":{"id":"dpXBFpvET_eT"},"cell_type":"markdown","source":"## Pima Indians Diabetes Prediction (Using KNN)"},{"metadata":{},"cell_type":"markdown","source":"This is a classification predictive analytics project. Here I will be using k-Nearest Neighbour algorithm to predict the occurance of diabetes. "},{"metadata":{},"cell_type":"markdown","source":"### Importing Libraries, Dataset, and EDA"},{"metadata":{"id":"IFawbG_GTu7b","trusted":true},"cell_type":"code","source":"#importing libraries\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import roc_auc_score\n\nfrom sklearn.preprocessing import MinMaxScaler\n\n","execution_count":null,"outputs":[]},{"metadata":{"id":"ZTZLjAhGKFIx","outputId":"aa601d25-cac0-4695-ed30-0c2f2ef8543f","trusted":true},"cell_type":"code","source":"#importing dataset\n\ndiabetes_df = pd.read_csv('../input/pima-indians-diabetes-database/diabetes.csv')","execution_count":null,"outputs":[]},{"metadata":{"id":"ck-9Yl_zKFLm","outputId":"bd1b3ed2-395b-4344-cdbf-bd99af8309f0","trusted":true},"cell_type":"code","source":"diabetes_df.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"1zKfzaxoKFO0","outputId":"bacde52a-ffd6-4abc-f3a7-481ab9255128","trusted":true},"cell_type":"code","source":"#accessing target variable distribution\ndiabetes_df['Outcome'].hist()","execution_count":null,"outputs":[]},{"metadata":{"id":"LUlyJLQeKono","outputId":"139f9ecc-8505-445e-e84a-30fda76f45da","trusted":true},"cell_type":"code","source":"#exploring distribution and individual values\nsns.pairplot(diabetes_df,hue=\"Outcome\")","execution_count":null,"outputs":[]},{"metadata":{"id":"lxAEC9VpSO64","outputId":"8ce2e20b-549b-416b-e177-820e5787d1a4","trusted":true},"cell_type":"code","source":"diabetes_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"id":"Mg1psEe4WV8X","trusted":true},"cell_type":"code","source":"#assigning input and target variables\nX=diabetes_df.drop('Outcome',axis=1)\ny=diabetes_df['Outcome']","execution_count":null,"outputs":[]},{"metadata":{"id":"CD0qL8-GKoqR","outputId":"65da8568-c597-42e8-bef8-4def2f68c483","trusted":true},"cell_type":"code","source":"#rescaling data for analysis\nscaler = MinMaxScaler()\n\nX_ = scaler.fit_transform(X)\n\nX_rescaled = pd.DataFrame(X_, columns= X.columns)\n\nX_rescaled.describe()\n\n","execution_count":null,"outputs":[]},{"metadata":{"id":"aVlbciNdUzjD"},"cell_type":"markdown","source":"### K-Nearest Nighbour\n\nTo begin with, I will split data into 70% training and 30% testing dataset. After that, I wil build a knn model and test the model using the 30% dataset.\n\nI will be using Sci-kit learn ML library to split the dataset, build the model, and test the model.\n\n- from sklearn.model_selection import train_test_split: to split our data into 70% training & 30% testing datasets\n- from sklearn.neighbors import KNeighborsClassifier: to build knn model using the training dataset\n- from sklearn.model_selection import cross_val_score: to find the optimal value of k\n- from sklearn.metrics import classification_report: to get the classsification report (f1, accuracy, precision)"},{"metadata":{"id":"dXkcNKfnVoJL","trusted":true},"cell_type":"code","source":"#splitting data 70/30 into training and test datasets\nX_train, X_test, y_train, y_test = train_test_split(X_rescaled,y,test_size=0.3,random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"id":"5afzBVnlZ2CS","outputId":"1ed2daba-b785-4d6e-c672-cd3e5891f5c2","trusted":true},"cell_type":"code","source":"#building KNN  model\nknn = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\nknn.fit(X_train,y_train)\n\ny_pred = knn.predict(X_test)\n\nprint(\"ROC AUC : \", roc_auc_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"id":"KpLhWN0ykZmL","trusted":true},"cell_type":"code","source":"#Determining optimal value of k based on ROC AUC using \"cross_val_score\" package\nfrom sklearn.model_selection import cross_val_score\nmax_k = 100\ncv_score = []\n\nfor k in range(1,max_k):\n  knn = KNeighborsClassifier(n_neighbors= k)\n  scores = cross_val_score(knn,X_train,y_train.values.ravel(),cv = 5, scoring = \"roc_auc\")\n  cv_score.append(scores.mean())","execution_count":null,"outputs":[]},{"metadata":{"id":"rFuXdYazl753","outputId":"f6c72488-c575-41ef-d5bc-fe9a86bf29a7","trusted":true},"cell_type":"code","source":"sns.lineplot(x=range(1,max_k),y=cv_score)","execution_count":null,"outputs":[]},{"metadata":{"id":"u4bo4lakjaC6"},"cell_type":"markdown","source":"Here, we can see that the optimal value of k lies in the range (40, 60). To find the exact optimal value of k, we will use following function:"},{"metadata":{"id":"t7jZ5A5MrB0u","outputId":"970c0fd1-517c-40fb-ea14-b828084a1e5c","trusted":true},"cell_type":"code","source":"cv_score.index(max(cv_score))+1","execution_count":null,"outputs":[]},{"metadata":{"id":"XBDw6wditXds"},"cell_type":"markdown","source":"Therefore, the optimal value of k is 43."},{"metadata":{"id":"VJgVkhP3VzkB","outputId":"f15586ba-ca47-4281-b088-df57afd3214c","trusted":true},"cell_type":"code","source":"#optimized KNN model\nknn = KNeighborsClassifier(n_neighbors=43, metric='euclidean')\nknn.fit(X_train,y_train)\n\ny_pred = knn.predict(X_test)\n\nprint(\"KNN Model\\n\")\n\nprint(\"ROC AUC : \", roc_auc_score(y_test, y_pred))\n\n#classification report for KNN model\nprint(classification_report(y_test,y_pred))\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}