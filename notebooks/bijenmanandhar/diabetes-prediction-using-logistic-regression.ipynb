{"cells":[{"metadata":{"id":"dpXBFpvET_eT"},"cell_type":"markdown","source":"## Pima Indians Diabetes Prediction (Using Logistic Regression)"},{"metadata":{},"cell_type":"markdown","source":"This is a classification predictive analytics project. Here I will be using logistic regression model to predict the occurance of diabetes. "},{"metadata":{},"cell_type":"markdown","source":"### Importing Libraries, Dataset, and EDA"},{"metadata":{"id":"P5DXuiIX_7qi","trusted":true},"cell_type":"code","source":"#importing libraries\nimport pandas as pd### Importing Libraries, Dataset, and EDA\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression","execution_count":null,"outputs":[]},{"metadata":{"id":"f-OAfQHPU1Ip","outputId":"77ceb441-b288-46cd-bbd9-7e428f9db3ba","trusted":true},"cell_type":"code","source":"#importing dataset\ndiabetes_df=pd.read_csv(\"../input/pima-indians-diabetes-database/diabetes.csv\")","execution_count":null,"outputs":[]},{"metadata":{"id":"5bQmrWjtU1Np","outputId":"39b2692f-de0b-46bb-b5ce-3ac2608425ea","trusted":true},"cell_type":"code","source":"diabetes_df.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"j89-YoWlU1Qm","outputId":"40a4c62e-9435-4dd6-dcc1-304e93f69e49","trusted":true},"cell_type":"code","source":"#Evaluating target variable distribution\ndiabetes_df['Outcome'].hist()","execution_count":null,"outputs":[]},{"metadata":{"id":"SvAc3IlwVduV","outputId":"9bb164b5-ccf9-412d-d4e9-b0c62c038a40","trusted":true},"cell_type":"code","source":"#examining missing values\nsns.heatmap(diabetes_df.isnull(),cbar=False)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"tOzOLtzRVdxD","outputId":"bf389b50-3de0-4b4a-9ebf-a8cf020acea2","trusted":true},"cell_type":"code","source":"#examining data types\ndiabetes_df.info()\n","execution_count":null,"outputs":[]},{"metadata":{"id":"PKjfvfxaVdz-","outputId":"02908427-8600-4d8b-b613-895a7947c711","trusted":true},"cell_type":"code","source":"#examining data distribution\ndiabetes_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"id":"zlVZgAFyheeO","outputId":"5ff1a492-aba0-426d-c229-a220a32c6167","trusted":true},"cell_type":"code","source":"#examining data intercorrelations\nsns.pairplot(diabetes_df,hue='Outcome')","execution_count":null,"outputs":[]},{"metadata":{"id":"aVlbciNdUzjD"},"cell_type":"markdown","source":"### Logistic Regression\n\nTo begin with, I will split data into 70% training and 30% testing dataset. After that, I wil build a logistic regression model and test the model using the 30% dataset.\n\nI will be using Sci-kit learn ML library to split the dataset, build the model, and test the model.\n\n- from sklearn.model_selection import train_test_split: to split our data into 70% training & 30% testing datasets\n- from sklearn.linear_model import LogisticRegression: to build a logistic regression model using the training dataset\n- from sklearn.metrics import roc_auc_score,roc_curve: to construct a roc curve adn roc auc score\n- from sklearn.metrics import classification_report: to get the classsification report (f1, accuracy, precision)\n- import statsmodels.api as sm: to determine features having no effect in the outcome"},{"metadata":{"id":"KSBAHElxN7IQ","trusted":true},"cell_type":"code","source":"#assigning input and target variables\nX=diabetes_df.drop('Outcome',axis=1)\ny=diabetes_df['Outcome']","execution_count":null,"outputs":[]},{"metadata":{"id":"skBD64orkRdQ","outputId":"c0fd801a-83fe-4d92-f971-6cfa61ee3a56","trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"w1jRJVRFkRgK","outputId":"c130663e-63a8-49db-b2bd-e0bd918e6dda","trusted":true},"cell_type":"code","source":"y.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"ViuupIOokRjd","trusted":true},"cell_type":"code","source":"#splitting data 70/30 into training and test datasets\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"id":"fwv2AtWRkRlv","outputId":"f287b15d-f39e-46ce-af67-f2d6f9ccc357","trusted":true},"cell_type":"code","source":"#building logistic model\nlogmodel=LogisticRegression(solver='liblinear')\nlogmodel.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"id":"HU5q6-3_N9O2","trusted":true},"cell_type":"code","source":"#evaluating model performance\ny_pred=logmodel.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"id":"mABoesNbopP_","outputId":"ff57f256-5ea1-47fd-bad6-7c4b5eb99c77","trusted":true},"cell_type":"code","source":"y_pred[:20]","execution_count":null,"outputs":[]},{"metadata":{"id":"WlQAyV_mopS4","outputId":"e5a47842-4638-4c56-b5dc-c6d9d9fdb581","trusted":true},"cell_type":"code","source":"#displaying confusion matrix\nfrom sklearn.metrics import confusion_matrix, classification_report\nconfusion_matrix(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"id":"KXCGRROkopWq","outputId":"75eb595b-9773-4a34-e39b-de2afce3dfcf","trusted":true},"cell_type":"code","source":"#displaying classification report (accuracy, recall, precision)\nprint(classification_report(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"id":"idTGA4ojopZN","outputId":"0a46923f-0162-41bb-d8d2-c348d647d03b","trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score,roc_curve\nimport matplotlib.pyplot as plt\n\n#ROC AUC score calculation\nlogit_roc_auc =roc_auc_score(y_test,logmodel.predict(X_test))\nprint(\"The ROC AUC score is \"+str(logit_roc_auc))\n","execution_count":null,"outputs":[]},{"metadata":{"id":"0pqE00forQTf","outputId":"387dd735-9cfe-4985-9498-3210ef5ffc98","trusted":true},"cell_type":"code","source":"#displaying ROC curve\nfpr,tpr,thresholds = roc_curve(y_test,logmodel.predict_proba(X_test)[:,1])\nplt.figure()\nplt.plot(fpr,tpr,label=\"Logistic Regression (area = %0.2f)\"%logit_roc_auc)\nplt.xlim([0.0,1.0])\nplt.ylim([0.0,1.05])\nplt.plot([0,1],[0,1],'r--')\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"Receiver Operating Characteristics\")\nplt.legend(loc=\"lower right\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"9FYESlfpODdA","outputId":"6492635b-a0a5-4d85-fa46-f5c32c01e51b","trusted":true},"cell_type":"code","source":"#determining features having no effect on the outcome using statsmodels package\nimport statsmodels.api as sm\nlogit_model=sm.Logit(y_train,X_train)\nlogmodel_2 = logit_model.fit()\nprint(logmodel_2.summary2())","execution_count":null,"outputs":[]},{"metadata":{"id":"6rM1lBWQ2eCj"},"cell_type":"markdown","source":"In the above table, P>|z| shows statistical significance in predicting the outcome of diabetes. If the P>|z| is greater than 0.05, that parameter does not have statistically significant effect on the outcome.\n\nIn above table, we can see that SkinThickness, Insulin, BMI,DiabetesPedigreeFunction, and Age have probability greater than 0.05. These parameters are not stastistically significant in predicting the outcome"},{"metadata":{"id":"GZCpQT-I1eFO","outputId":"f95217bd-b56c-4854-a47b-79ef380473dd","trusted":true},"cell_type":"code","source":"#rebuilding the model excluding non-statistically significant features\nX1 = diabetes_df.drop([\"Outcome\",\"SkinThickness\",\"Insulin\",\"BMI\",\"DiabetesPedigreeFunction\",\"Age\"],axis=1)\nX1.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"WfiHwhmP4jEr","outputId":"c875e74d-24b8-46ea-e389-ff9018941164","trusted":true},"cell_type":"code","source":"y.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"wXrPVAV44xEm","trusted":true},"cell_type":"code","source":"#assigning training and testing data for new model\nX1_train, X1_test, y1_train, y1_test = train_test_split(X1,y,test_size=0.3,random_state=1)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"8mtqJjaJAJqW","outputId":"1a51dd19-7dca-471d-d542-c2e3e6fba803","trusted":true},"cell_type":"code","source":"#building new logistic model\nlogmodel_re=LogisticRegression(solver='liblinear')\nlogmodel_re.fit(X1_train,y1_train)","execution_count":null,"outputs":[]},{"metadata":{"id":"FHXzm4-4AVLR","outputId":"d6912760-17c8-4580-d058-11e6bb718fcc","trusted":true},"cell_type":"code","source":"#drawing roc. curve to see new model\nlogit_roc_auc_re =roc_auc_score(y1_test,logmodel_re.predict(X1_test))\nprint(\"The ROC AUC score is \"+str(logit_roc_auc_re))\nfpr1,tpr1,thresholds1 = roc_curve(y1_test,logmodel_re.predict_proba(X1_test)[:,1])\nplt.figure()\nplt.plot(fpr1,tpr1,label=\"Logistic Regression (area = %0.2f)\"%logit_roc_auc_re)\nplt.xlim([0.0,1.0])\nplt.ylim([0.0,1.05])\nplt.plot([0,1],[0,1],'r--')\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"Receiver Operating Characteristics\")\nplt.legend(loc=\"lower right\")\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"id":"kS62K86WDppL"},"cell_type":"markdown","source":"Here, we can see that the ROC AUC score for both model are same. In this context, our model did not change significantly while excluding the statistically non-significant parameters. \n\nTherefore, our analysis on defining statistically non-significant parameters is correct. "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}