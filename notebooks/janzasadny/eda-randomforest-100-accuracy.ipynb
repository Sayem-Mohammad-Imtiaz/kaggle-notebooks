{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 style=\"color:black; background-color:#7cdff3; font-family:Helvetica;font-size:400%;text-align:center\">Star Type Dataset - EDA and Classification </h1>","metadata":{}},{"cell_type":"code","source":"from IPython.display import Image\nImage(\"../input/space-bar/space_bar.png\")","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Imports-and-function-definitions\" data-toc-modified-id=\"Imports-and-function-definitions-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Imports and function definitions</a></span></li><li><span><a href=\"#Data-loading-and-exploration\" data-toc-modified-id=\"Data-loading-and-exploration-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Data loading and exploration</a></span><ul class=\"toc-item\"><li><span><a href=\"#Reading-data-into-a-DataFrame\" data-toc-modified-id=\"Reading-data-into-a-DataFrame-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Reading data into a DataFrame</a></span></li><li><span><a href=\"#Basic-information\" data-toc-modified-id=\"Basic-information-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Basic information</a></span></li><li><span><a href=\"#Null-value-and-type-checking\" data-toc-modified-id=\"Null-value-and-type-checking-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Null-value and type checking</a></span></li></ul></li><li><span><a href=\"#Variable-exploration\" data-toc-modified-id=\"Variable-exploration-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Variable exploration</a></span><ul class=\"toc-item\"><li><span><a href=\"#Target-variable-exploration\" data-toc-modified-id=\"Target-variable-exploration-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Target variable exploration</a></span><ul class=\"toc-item\"><li><span><a href=\"#Target-variable-distribution\" data-toc-modified-id=\"Target-variable-distribution-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>Target variable distribution</a></span></li></ul></li><li><span><a href=\"#Numerical-variable-exploration-and-preliminary-feature-engineering\" data-toc-modified-id=\"Numerical-variable-exploration-and-preliminary-feature-engineering-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Numerical variable exploration and preliminary feature engineering</a></span><ul class=\"toc-item\"><li><span><a href=\"#Basic-information\" data-toc-modified-id=\"Basic-information-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>Basic information</a></span></li><li><span><a href=\"#Boxplots\" data-toc-modified-id=\"Boxplots-4.2.2\"><span class=\"toc-item-num\">4.2.2&nbsp;&nbsp;</span>Boxplots</a></span></li><li><span><a href=\"#Histograms\" data-toc-modified-id=\"Histograms-4.2.3\"><span class=\"toc-item-num\">4.2.3&nbsp;&nbsp;</span>Histograms</a></span></li><li><span><a href=\"#Boxplots-per-target-variable-values\" data-toc-modified-id=\"Boxplots-per-target-variable-values-4.2.4\"><span class=\"toc-item-num\">4.2.4&nbsp;&nbsp;</span>Boxplots per target variable values</a></span></li></ul></li><li><span><a href=\"#Categorical-variable-exploration\" data-toc-modified-id=\"Categorical-variable-exploration-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Categorical variable exploration</a></span><ul class=\"toc-item\"><li><span><a href=\"#Basic-information\" data-toc-modified-id=\"Basic-information-4.3.1\"><span class=\"toc-item-num\">4.3.1&nbsp;&nbsp;</span>Basic information</a></span></li><li><span><a href=\"#Unique-values-of-Color\" data-toc-modified-id=\"Unique-values-of-Color-4.3.2\"><span class=\"toc-item-num\">4.3.2&nbsp;&nbsp;</span>Unique values of Color</a></span></li><li><span><a href=\"#Color-value-remapping\" data-toc-modified-id=\"Color-value-remapping-4.3.3\"><span class=\"toc-item-num\">4.3.3&nbsp;&nbsp;</span>Color value remapping</a></span></li><li><span><a href=\"#Countplot-of-Color-variable\" data-toc-modified-id=\"Countplot-of-Color-variable-4.3.4\"><span class=\"toc-item-num\">4.3.4&nbsp;&nbsp;</span>Countplot of Color variable</a></span></li><li><span><a href=\"#Color-variable-encoding\" data-toc-modified-id=\"Color-variable-encoding-4.3.5\"><span class=\"toc-item-num\">4.3.5&nbsp;&nbsp;</span>Color variable encoding</a></span></li><li><span><a href=\"#Unique-values-of-Spectral_Class\" data-toc-modified-id=\"Unique-values-of-Spectral_Class-4.3.6\"><span class=\"toc-item-num\">4.3.6&nbsp;&nbsp;</span>Unique values of Spectral_Class</a></span></li><li><span><a href=\"#Countplot-of-Spectral_Class-variable\" data-toc-modified-id=\"Countplot-of-Spectral_Class-variable-4.3.7\"><span class=\"toc-item-num\">4.3.7&nbsp;&nbsp;</span>Countplot of Spectral_Class variable</a></span></li><li><span><a href=\"#Spectral_Class-variable-encoding\" data-toc-modified-id=\"Spectral_Class-variable-encoding-4.3.8\"><span class=\"toc-item-num\">4.3.8&nbsp;&nbsp;</span>Spectral_Class variable encoding</a></span></li></ul></li><li><span><a href=\"#Countplots-per-target-variable-values\" data-toc-modified-id=\"Countplots-per-target-variable-values-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Countplots per target variable values</a></span></li><li><span><a href=\"#Variable-correlations\" data-toc-modified-id=\"Variable-correlations-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Variable correlations</a></span><ul class=\"toc-item\"><li><span><a href=\"#Pearson-heatmap\" data-toc-modified-id=\"Pearson-heatmap-4.5.1\"><span class=\"toc-item-num\">4.5.1&nbsp;&nbsp;</span>Pearson heatmap</a></span></li><li><span><a href=\"#Correlation-pairplot\" data-toc-modified-id=\"Correlation-pairplot-4.5.2\"><span class=\"toc-item-num\">4.5.2&nbsp;&nbsp;</span>Correlation pairplot</a></span></li></ul></li></ul></li><li><span><a href=\"#Final-feature-engineering\" data-toc-modified-id=\"Final-feature-engineering-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Final feature engineering</a></span><ul class=\"toc-item\"><li><span><a href=\"#Removal-of-non-encoded-versions-of-categorical-variables\" data-toc-modified-id=\"Removal-of-non-encoded-versions-of-categorical-variables-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Removal of non-encoded versions of categorical variables</a></span></li><li><span><a href=\"#Target-and-feature-separation\" data-toc-modified-id=\"Target-and-feature-separation-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Target and feature separation</a></span></li><li><span><a href=\"#Data-split-into-train-and-test-sets\" data-toc-modified-id=\"Data-split-into-train-and-test-sets-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Data split into train and test sets</a></span></li></ul></li><li><span><a href=\"#Model-training\" data-toc-modified-id=\"Model-training-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Model training</a></span><ul class=\"toc-item\"><li><span><a href=\"#Default-RandomForestClassifier\" data-toc-modified-id=\"Default-RandomForestClassifier-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Default RandomForestClassifier</a></span></li><li><span><a href=\"#Feature-importance\" data-toc-modified-id=\"Feature-importance-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Feature importance</a></span></li></ul></li><li><span><a href=\"#Summary\" data-toc-modified-id=\"Summary-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Summary</a></span></li></ul></div>","metadata":{"toc":true}},{"cell_type":"markdown","source":"## 1 Introduction","metadata":{}},{"cell_type":"markdown","source":"This notebook contains an **Exploratory Data Analysis** of the [Star Type Classification / NASA Dataset](https://www.kaggle.com/brsdincer/star-type-classification) and a **RandomForestClassifier** model for prediction of star types.\n\n**The dataset**\n\nThe [Star Type Classification / NASA Dataset](https://www.kaggle.com/brsdincer/star-type-classification) contains various information about stars, such as their tempearture, colour or radius. This data can be used for training classification and regression models.\n\n**Objectives**\n\nThe main objective of this notebook is to explore all of the variables contained in the dataset and present relevant observations.\nAfterwards, I will perform feature engineering in order to transform the data into a form suitable for the RandomForestClassifier. Lastly, I will train the classifier to **predict Star Types** and analyse the results.","metadata":{}},{"cell_type":"markdown","source":"## 2 Imports and function definitions","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sqlite3\nimport plotly.express as px\nimport plotly\nimport math\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Function used to add value labels to vertical barplots \n\ndef add_val_labels(plot, spacing=float(0.5)):\n    for p in plot.patches:\n        if not math.isnan(p.get_height()):\n            x = p.get_x() + p.get_width()- float(0.45)\n            y = p.get_height() - spacing\n            value = round(p.get_height(), 1)\n            plot.text(x, y, value, ha=\"left\", color=\"black\", size='large')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3 Data loading and exploration","metadata":{}},{"cell_type":"markdown","source":"### 3.1 Reading data into a DataFrame","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"../input/star-type-classification/Stars.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.2 Basic information","metadata":{}},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations:**\n\n- This dataset is small, containing only 240 rows\n\n- It contains 7 columns","metadata":{}},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(-10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Column definitions:**\n- Temperature - Temperature of the star, expressed in degrees of Kelvin: (K)\n- L - Relative luminosity, expressed in terms of nominal solar luminosity: (L/L⊙)\n- R - Relative radius, expressed in terms of nominal solar radius: (R/R⊙)\n- A_M - Absolute magnitude, expressed in: (Mv)\n- Color - Observable color of the star\n- Spectral_Class - Spectral class of the star, classified under the Morgan–Keenan (MK) system\n- Type - Type of the star:\n    - Red Dwarf - 0\n    - Brown Dwarf - 1\n    - White Dwarf - 2\n    - Main Sequence - 3\n    - Super Giant - 4\n    - Hyper Giant - 5\n","metadata":{}},{"cell_type":"markdown","source":"### 3.3 Null-value and type checking","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations:**\n\n- There is no null values\n\n- 4 columns contain numerical values: \n    - Temperature (int64)\n    - L (float64)\n    - R (float64)\n    - A_M (float64)\n\n- 3 columns contain categorical values: \n    - Color (object)\n    - Spectral_Class (object)\n    - Type (int64)\n\n- Target variable is Type ","metadata":{}},{"cell_type":"markdown","source":"## 4 Variable exploration","metadata":{}},{"cell_type":"markdown","source":"### 4.1 Target variable exploration","metadata":{}},{"cell_type":"markdown","source":"#### 4.1.1 Target variable distribution","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nsns.countplot(x=\"Type\", data=df)\nplt.title(\"Type distribution\", fontsize=20)\nplt.xlabel(\"Type\", fontsize=16)\nplt.ylabel(\"Count\", fontsize=16)\nplt.xticks(fontsize=10)\nplt.yticks(fontsize=10)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations:**\n\n- There is an equal number of rows corresponding to each star Type - Classes are completely balanced\n\n- Each of the 6 types has 40 corresponding observations","metadata":{}},{"cell_type":"markdown","source":"### 4.2 Numerical variable exploration and preliminary feature engineering","metadata":{}},{"cell_type":"markdown","source":"#### 4.2.1 Basic information","metadata":{}},{"cell_type":"code","source":"df_vars_num = df.loc[:, [\"Temperature\", \"L\", \"R\", \"A_M\"]]\ndf_vars_num.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations:**\n\n- Variables Temperature, L, R appear to be skewed and may contain outliers. It can be confirmed by observing boxplots and histograms.","metadata":{}},{"cell_type":"markdown","source":"#### 4.2.2 Boxplots","metadata":{}},{"cell_type":"code","source":"for col_name in df_vars_num:\n    plt.figure(figsize=(16, 4))\n    sns.boxplot(x=df_vars_num[col_name])\n    plt.title(col_name+ \" boxplot\", fontsize=20)\n    plt.xlabel(col_name, fontsize=16)\n    plt.xticks(fontsize=10)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations:**\n\n- Temperature, L and R variables contain outliers","metadata":{}},{"cell_type":"markdown","source":"#### 4.2.3 Histograms","metadata":{}},{"cell_type":"code","source":"for col_name in df_vars_num:\n    \n    plt.figure(figsize=(16, 6))\n    sns.histplot(x=col_name, kde=True, bins=30, data=df_vars_num)\n    plt.title(col_name+ \" distribution\", fontsize=20)\n    plt.xlabel(col_name, fontsize=16)\n    plt.ylabel(\"Count\", fontsize=16)\n    plt.xticks(fontsize=10)\n    plt.yticks(fontsize=10)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Obesrvations:**\n\n- None of the numerical variables follow the Gaussian distribution\n\n- For Temperature, L and R variables - Great majority of the values is contained on the far left edge of the distribution\n\n- For A_M variables - Majority of the values is contained on the left and right sides of the distribtuion","metadata":{}},{"cell_type":"markdown","source":"#### 4.2.4 Boxplots per target variable values","metadata":{}},{"cell_type":"code","source":"for col_name in df_vars_num:\n    plt.figure(figsize=(16, 8))\n    sns.boxplot(y=\"Type\", x=col_name, data=df, orient=\"h\")\n    plt.title(col_name+ \" distribution per value of Type\", fontsize=20)\n    plt.xlabel(col_name, fontsize=16)\n    plt.ylabel(\"Type\", fontsize=16)\n    plt.xticks(fontsize=10)\n    plt.yticks(fontsize=10)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations:**\n\n- All stars of Type 0 and 1 have temperature below 5000\n\n- Stars of types 0-2 have much lower luminosity than those of types 4-5. Majority of type 3 stars also has much lower luminosity, excluding a few outliers.\n\n- Stars of type 5 have much larger radius than other types\n\n- Absolute magnintude (A_M) seems to gradually get lower for stars of higher type","metadata":{}},{"cell_type":"markdown","source":"### 4.3 Categorical variable exploration","metadata":{}},{"cell_type":"markdown","source":"#### 4.3.1 Basic information","metadata":{}},{"cell_type":"code","source":"df_vars_cat = df.loc[:, [\"Color\", \"Spectral_Class\"]]\ndf_vars_cat.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations:**\n\n- There is 17 unique values of Color and 7 unique values of Spectral_Class\n\n- Red is the most common color and it appears 112 times\n\n- M is the most common spectral class and it appears 111 times","metadata":{}},{"cell_type":"markdown","source":"#### 4.3.2 Unique values of Color","metadata":{}},{"cell_type":"code","source":"df[\"Color\"].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"![Star Colours](https://i.stack.imgur.com/XyJyp.jpg)\n\n**Observations**\n\n- It can be noticed that there's several values that are almost exactly the same, namely:\n\n    - \"yellowish\", \"Yellowish\", \"Yellow\"\n    \n    - \"Blue White\", \"Blue white\", \"Blue-white\", \"Blue-White\"\n    \n    - \"yellow-white\" and \"White-Yellow\"\n    \n    - \"white\", \"White\", \"Whitish\"\n    \n- Similar values mentioned above can be remapped to eliminate redundancy\n\n- As can be observed on the above image, star colours are strongly correlated with temperatures. Because of this, we can transform this categorical variable using a technique of label encoding, so that stars with \"colder\" colours get lower values and stars with \"hotter\" colours get higher values. This will allow us to treat \"Color\" as if it was an ordinal variable\n\n- We will change the name of \"Color\" column to \"Color_name\" and use the name \"Color\" for the newly created label-encoded column instead\n","metadata":{}},{"cell_type":"markdown","source":"#### 4.3.3 Color value remapping","metadata":{}},{"cell_type":"code","source":"remap_dict = {\n    'Red': 'Red',\n    'Blue White': 'Blue-White',\n    'White': 'White',\n    'Yellowish White': 'White-Yellow',\n    'Blue white': 'Blue-White',\n    'Pale yellow orange': 'Yellow-Orange',\n    'Blue': 'Blue',\n    'Blue-white': 'Blue-White',\n    'Whitish': 'White',\n    'yellow-white': 'White-Yellow',\n    'Orange': 'Orange',\n    'White-Yellow': 'White-Yellow',\n    'white': 'White',\n    'yellowish': 'Yellow',\n    'Yellowish': 'Yellow',\n    'Orange-Red': 'Orange-Red',\n    'Blue-White': 'Blue-White'\n}\n\ndf[\"Color_name\"] = df[\"Color\"].map(remap_dict)\ndf[\"Color_name\"].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations:**\n- By remapping Color values, total number of unique values has been reduced from 17 to 9","metadata":{}},{"cell_type":"markdown","source":"#### 4.3.4 Countplot of Color variable","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20, 10))\npalette = {\"Red\": \"#fa0000\", \"Blue\": \"#001dfa\", \"Blue-White\": \"#8bb7f0\", \"White\": \"#e3e1d8\",\n           \"White-Yellow\": \"#fff6a1\", \"Yellow\": \"#fffc36\", \"Orange\": \"#ff9d00\", \"Orange-Red\": \"#ff6f00\",\n           \"Yellow-Orange\": \"#ffc800\"}\nplot = sns.countplot(x=\"Color_name\", data=df,\n              order=df[\"Color_name\"].value_counts().index, palette=palette)\nplt.title(\"Color distribution\", fontsize=20)\nplt.xlabel(\"Color\", fontsize=16)\nplt.ylabel(\"count\", fontsize=16)\nplt.xticks(fontsize=10)\nplt.yticks(fontsize=10)\nadd_val_labels(plot, spacing=float(-0.2))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations:**\n\n- Red is the most common colour, Orange-Red and Yellow-Orange are the least common (each have only 1 occurence).\n","metadata":{}},{"cell_type":"markdown","source":"#### 4.3.5 Color variable encoding","metadata":{}},{"cell_type":"code","source":"remap_dict_2 = {\n    \"Red\": 0,\n    \"Orange-Red\": 1,\n    \"Orange\": 2,\n    \"Yellow-Orange\": 3,\n    \"Yellow\": 4,\n    \"White-Yellow\": 5,\n    \"White\": 6,\n    \"Blue-White\": 7,\n    \"Blue\": 8\n}\n\ndf[\"Color\"] = df[\"Color_name\"].map(remap_dict_2)\ndf[\"Color\"].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations:**\n\n- After encoding, Color is an ordinal variable with values ranging from 0 to 8","metadata":{}},{"cell_type":"markdown","source":"#### 4.3.6 Unique values of Spectral_Class","metadata":{}},{"cell_type":"code","source":"df[\"Spectral_Class\"].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations:**\n- Spectral_Class has 7 unique values\n\n- According to the Wikipedia article on Stellar classification (https://en.wikipedia.org/wiki/Stellar_classification):\n\n        \"Most stars are currently classified under the Morgan–Keenan (MK) system using the letters O, B, A, F, G, K, and M, a sequence from the hottest (O type) to the coolest (M type).\"\n        \n    With that knowledge in mind, we can encode this variable in a similar way to how we encoded the Color variable.","metadata":{}},{"cell_type":"markdown","source":"#### 4.3.7 Countplot of Spectral_Class variable","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20, 10))\nplot = sns.countplot(x=\"Spectral_Class\", data=df,\n              order=df['Spectral_Class'].value_counts().index, palette=\"Accent\")\nplt.title(\"Spectral_Class distribution\", fontsize=20)\nplt.xlabel(\"Spectral_Class\", fontsize=16)\nplt.ylabel(\"count\", fontsize=16)\nplt.xticks(fontsize=10)\nplt.yticks(fontsize=10)\nadd_val_labels(plot, spacing=float(-0.2))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations:**\n\n- M is the most common spectral class and G is the least common (only a single occurence)\n","metadata":{}},{"cell_type":"markdown","source":"#### 4.3.8 Spectral_Class variable encoding","metadata":{}},{"cell_type":"code","source":"df[\"Spectral_Class_name\"] = df[\"Spectral_Class\"]\n\nremap_dict_3 = {\n    \"M\": 0,\n    \"K\": 1,\n    \"G\": 2,\n    \"F\": 3,\n    \"A\": 4,\n    \"B\": 5,\n    \"O\": 6\n}\n\ndf[\"Spectral_Class\"] = df[\"Spectral_Class_name\"].map(remap_dict_3)\ndf[\"Spectral_Class\"].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations:**\n\n- After encoding, Spectral_Class is an ordinal variable with values ranging from 0 to 6","metadata":{}},{"cell_type":"markdown","source":"### 4.4 Countplots per target variable values","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20, 10))\nsns.countplot(x=\"Color_name\", hue=\"Type\", data=df)\nplt.title(\"Color distribution per value of Type\", fontsize=20)\nplt.xlabel(\"Color\", fontsize=16)\nplt.ylabel(\"Type\", fontsize=16)\nplt.xticks(fontsize=10)\nplt.yticks(fontsize=10)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations**:\n\n- Type 0 and 1 stars are exclusively Red\n\n- No type 3 stars are Red\n\n- All Yellow and Orange-Red stars are type 3\n\n- All Yellow-Orange stars are type 2\n\n- All Orange stars are type 5","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20, 10))\nsns.countplot(x=\"Spectral_Class_name\", hue=\"Type\", data=df)\nplt.title(\"Spectral_Class distribution per value of Type\", fontsize=20)\nplt.xlabel(\"Spectral_Class\", fontsize=16)\nplt.ylabel(\"Type\", fontsize=16)\nplt.xticks(fontsize=10)\nplt.yticks(fontsize=10)\nplt.legend(loc=\"upper right\", title=\"Type\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations**:\n\n- Type 0 and 1 stars are exclusively Class M\n\n- All Class G stars are Type 5\n\n- Majority of Type 4 stars belong to class O\n\n- Majority of Type 2 stars belong to class B","metadata":{}},{"cell_type":"markdown","source":"### 4.5 Variable correlations","metadata":{}},{"cell_type":"markdown","source":"#### 4.5.1 Pearson heatmap","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correlations = df.corr()\nplt.figure(figsize=(16, 12))\nax = sns.heatmap(correlations, square=True, annot=True,\n                 fmt='.2f', linecolor='white', cmap=\"vlag\")\nax.set_xticklabels(ax.get_xticklabels(), rotation=30, fontsize=10)\nax.set_yticklabels(ax.get_yticklabels(), rotation=30, fontsize=10)\nplt.title(\"Pearson's correlation heatmap\", fontsize=20)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations:**\n\n- A_M and Type are very heavily negatively correlated\n\n- A_M and L, R are also negatively correlated\n\n- Type and L, R are positively correlated\n\n- L and R are positively correlated\n\n- Color and Temperature are heavily positively correlated\n\n- Spectral_Class and Temperature are heavily positively correlated\n\n- Spectral_Class and Color are very heavily positively correlated","metadata":{}},{"cell_type":"markdown","source":"#### 4.5.2 Correlation pairplot","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(16, 16))\nsns.pairplot(df, kind='reg', diag_kind='hist', palette='Rainbow')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Thanks to the pairplot we can observe and confirm previously identified correlations. \n\nHeavy correlations between the target variable and features of the data (The first 3 observed) are desirable, while heavy correlations between different features (The last 3 observed) are not, because they may end up not providing any meaningful data, while increasing model's degrees of freedom, which may cause overfitting.","metadata":{}},{"cell_type":"markdown","source":"## 5 Final feature engineering","metadata":{}},{"cell_type":"markdown","source":"### 5.1 Removal of non-encoded versions of categorical variables","metadata":{}},{"cell_type":"code","source":"df = df.drop([\"Color_name\", \"Spectral_Class_name\"], axis=1)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we have previously encoded Color and Spectral_Class variables, transforming them into ordinal variables, we should drop their non-encoded versions.","metadata":{}},{"cell_type":"markdown","source":"### 5.2 Target and feature separation","metadata":{}},{"cell_type":"code","source":"y = df[\"Type\"]\ny.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df.drop([\"Type\"], axis=1)\nX.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5.3 Data split into train and test sets ","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.4, random_state=1)\n\nprint(X_train.shape, X_test.shape, y_train.shape, y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations:**\n\n- Data has been split into a train and test dataset according to a 60/40 ratio\n\n- Training set contains 144 observations and testing set contains 96","metadata":{}},{"cell_type":"markdown","source":"## 6 Model training","metadata":{}},{"cell_type":"markdown","source":"### 6.1 Default RandomForestClassifier","metadata":{}},{"cell_type":"code","source":"rfc_model = RandomForestClassifier(random_state=1)\n\nrfc_model.fit(X_train, y_train)\n\ny_pred_1 = rfc_model.predict(X_test)\n\nscore_1 = accuracy_score(y_test, y_pred_1)\n\nprint(\"Accuracy of default RandomForestClassifier = \"+str(score_1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Using just the default RandomForestClassifier model we're able to achieve perfect accuracy. This is most likely caused by following:\n\n- High correlation values of all features with the target variable\n\n- Relatively large ratio of observations to possible target classes \n\nIt is very important to note, however that our trained model is not perfect and will not always have perfect accuracy on new data, because:\n\n- The amount of training observations was quite low (only 144)\n\n- Several categorical feature values only appeared a few times (Such as Colors: Orange-Red, Yellow-Orange)\n\nThis flaw can be easily observed by changing the random_state variable of our train_test_split:","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.4, random_state=47)\n\nprint(X_train.shape, X_test.shape, y_train.shape, y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfc_model2 = RandomForestClassifier(random_state=1)\n\nrfc_model2.fit(X_train, y_train)\n\ny_pred_2 = rfc_model2.predict(X_test)\n\nscore_2 = accuracy_score(y_test, y_pred_2)\n\nprint(\"Accuracy of default RandomForestClassifier with random_state of train_test_split changed = \"+str(score_2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations:**\n\n- After changing a usually insignificant parameter (random_state of train_test_split), accuracy goes down by around 1%\n\n- Despite that, this model makes the best possible use of the available data and can be used for making predictions on new data\n\n- Further optimization is therefore unnecessary","metadata":{}},{"cell_type":"markdown","source":"### 6.2 Feature importance","metadata":{}},{"cell_type":"code","source":"feature_importance = pd.Series(\n    rfc_model.feature_importances_, index=X.columns).sort_values(ascending=False)\n\nplt.figure(figsize=(16, 10))\nsns.barplot(x=feature_importance, y=feature_importance.index, palette=\"CMRmap\")\nplt.title(\"Feature importance\", fontsize=20)\nplt.xlabel(\"Mean decrease in impurity\", fontsize=16)\nplt.ylabel(\"Feature\", fontsize=16)\nplt.xticks(fontsize=10)\nplt.yticks(fontsize=10)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations:**\n\n- Features A_M and R together contribute to over 60% of the mean decrease in impurity\n\n- Feature Spectral_Class is not very significant compared to all the others, providing only a 5% decrease in impurity","metadata":{}},{"cell_type":"markdown","source":"## 7 Summary","metadata":{}},{"cell_type":"markdown","source":"- **Analysed dataset contains information about 240 different stars divided into 7 features: 'Temperature', 'L', 'R', 'A_M', 'Color', 'Spectral_Class', 'Type'**\n\n\n- **'Type' is the target variable**\n\n\n- **Target variable's distribution is perfectly balanced**\n\n\n- **All of the numerical features are heavily skewed and most contain outliers, though they ended up not affecting the predictive model negatively**\n\n\n- **Both categorical features may be expressed as ordinal features, potentially increasing model's accuracy**\n\n\n- **All of the features have at least a slight degree of correlation with the target variable**\n\n\n- **A default RandomForestClassifier model trained on entirety of the data after feature engineering was able to achieve accuracy of** <span style=\"color:green; font-weight:bold\">100%</span>","metadata":{}},{"cell_type":"markdown","source":"<h1 style=\"color:black; background-color:#7cdff3; font-family:Helvetica;font-size:200%;text-align:center\">Thank you for your attention! </h1>","metadata":{}},{"cell_type":"code","source":"Image(\"../input/space-bar/space_bar.png\")","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]}]}