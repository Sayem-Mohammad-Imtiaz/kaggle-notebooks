{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Reading"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import cross_val_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/diamonds/diamonds.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['x']==0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data[(data[['x','y','z']] != 0).all(axis=1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in data.columns:\n    print(i,sum(data[i].isna()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# z / mean(x, y)\ndata['volume'] = data['x']*data['y']*data['z']\ndata['area'] = data['x']*data['y']\ndata['priceunvol'] = data['price']/data['volume']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(['Unnamed: 0','x','y','z'],axis = 1)\n# data = data.drop(['Unnamed: 0'],axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['table'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nnp.where(data['volume'].values )\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## One Hot"},{"metadata":{"trusted":true},"cell_type":"code","source":"data =  pd.get_dummies(data)\ndata.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Standardization"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\n\n# data_fitter =  pd.DataFrame(sc.fit_transform(data[['carat','depth','volume','table']]),columns=['carat','depth','volume','table'],index=data.index)\n\n# data_fitter =  pd.DataFrame(sc.fit_transform(data[['carat','depth','volume','table','area']]),columns=['carat','depth','volume','table','area'],index=data.index)\n\ndata_fitter =  pd.DataFrame(sc.fit_transform(data[['carat','depth','volume','table','area','priceunvol']]),columns=['carat','depth','volume','table','area','priceunvol'],index=data.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data2 = data.copy(deep=True)\n# data2[['carat','depth','volume','table']] = data_fitter[['carat','depth','volume','table']]\n# data2[['carat','depth','volume','table','area']] = data_fitter[['carat','depth','volume','table','area']]\ndata2[['carat','depth','volume','table','area','priceunvol']] = data_fitter[['carat','depth','volume','table','area','priceunvol']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.model_selection import train_test_split\nx = data2.drop([\"price\"],axis=1)\ny = data2.price\ntrain_x, test_x, train_y, test_y = train_test_split(x, y,random_state = 2,test_size=0.3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Models"},{"metadata":{},"cell_type":"markdown","source":"## Reg"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import r2_score\nfrom sklearn import linear_model\n\nregr = linear_model.LinearRegression()\nregr.fit(train_x,train_y)\ny_pred = regr.predict(test_x)\nprint(\"accuracy: \"+ str(regr.score(test_x,test_y)*100) + \"%\")\nprint(\"Mean absolute error: {}\".format(mean_absolute_error(test_y,y_pred)))\nprint(\"Mean squared error: {}\".format(mean_squared_error(test_y,y_pred)))\nR2 = r2_score(test_y,y_pred)\nprint('R Squared: {}'.format(R2))\nn=test_x.shape[0]\np=test_x.shape[1] - 1\nadj_rsquared = 1 - (1 - R2) * ((n - 1)/(n-p-1))\nprint('Adjusted R Squared: {}'.format(adj_rsquared))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Adaboost"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostRegressor \n\nclf_rf = AdaBoostRegressor()\nclf_rf.fit(train_x , train_y)\naccuracies = cross_val_score(estimator = clf_rf, X = train_x, y = train_y, cv = 5,verbose = 1)\ny_pred2 = clf_rf.predict(test_x)\nprint('Score : %.4f' % clf_rf.score(test_x, test_y))\nmse = mean_squared_error(test_y, y_pred2)\nmae = mean_absolute_error(test_y, y_pred2)\nrmse = mean_squared_error(test_y, y_pred2)**0.5\nr2 = r2_score(test_y, y_pred2)\nprint('MSE    : %0.2f ' % mse)\nprint('MAE    : %0.2f ' % mae)\nprint('RMSE   : %0.2f ' % rmse)\nprint('R2     : %0.2f ' % r2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nclf_rf = RandomForestRegressor()\nclf_rf.fit(train_x , train_y)\naccuracies = cross_val_score(estimator = clf_rf, X = train_x, y = train_y, cv = 5,verbose = 1)\ny_pred2 = clf_rf.predict(test_x)\nprint('Score : %.4f' % clf_rf.score(test_x, test_y))\nmse = mean_squared_error(test_y, y_pred2)\nmae = mean_absolute_error(test_y, y_pred2)\nrmse = mean_squared_error(test_y, y_pred2)**0.5\nr2 = r2_score(test_y, y_pred2)\nprint('MSE    : %0.2f ' % mse)\nprint('MAE    : %0.2f ' % mae)\nprint('RMSE   : %0.2f ' % rmse)\nprint('R2     : %0.2f ' % r2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tabulate import tabulate\nheaders = [\"name\", \"score\"]\nvalues = sorted(zip(train_x.columns, clf_rf.feature_importances_), key=lambda x: x[1] * -1)\nprint(tabulate(values, headers, tablefmt=\"plain\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Gradient Boost"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\n\nclf_gbr = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1,max_depth=1, random_state=0, loss='ls',verbose = 1)\nclf_gbr.fit(train_x , train_y)\naccuracies = cross_val_score(estimator = clf_gbr, X = train_x, y = train_y, cv = 5,verbose = 1)\ny_pred2 = clf_gbr.predict(test_x)\nprint('Score : %.4f' % clf_gbr.score(test_x, test_y))\nmse = mean_squared_error(test_y, y_pred2)\nmae = mean_absolute_error(test_y, y_pred2)\nrmse = mean_squared_error(test_y, y_pred2)**0.5\nr2 = r2_score(test_y, y_pred2)\nprint('MSE    : %0.2f ' % mse)\nprint('MAE    : %0.2f ' % mae)\nprint('RMSE   : %0.2f ' % rmse)\nprint('R2     : %0.2f ' % r2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.5"},"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"nbformat":4,"nbformat_minor":1}