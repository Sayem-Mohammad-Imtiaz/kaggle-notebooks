{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '/kaggle/input/ecommerce-data/data.csv'\ndf = pd.read_csv(path)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Country'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## There are some <= 0 quantities, we will remove them\n\ndf['Quantity'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df[df['Quantity']>0]\ndf.head()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.dropna(subset = ['CustomerID'],how='all')\ndf.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Df is cleaned\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Preprocessing for RFM analysis\ndf['InvoiceDate'].max()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['InvoiceDate'].min()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Restrict to data to one full year for good RFM analysis\n\ndf = df[df['InvoiceDate']>= '2010-12-09']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['InvoiceDate'].min()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['InvoiceDate'].max()\n\n\n\n\n## as you see our difference of min and max date is 1 year","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['InvoiceDate'] = pd.DatetimeIndex(df['InvoiceDate']).date\nsnapshot_day = df['InvoiceDate'].max()\ndf.head(3)\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['TotalSum'] = df['Quantity'] * df['UnitPrice']\n\ndf.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Recency\ndf_recency = df.groupby('CustomerID', as_index = False)['InvoiceDate'].max()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_recency['Recency'] = df_recency['InvoiceDate'].apply(lambda x : (snapshot_day - x).days)\n\ndf_recency = df_recency.drop('InvoiceDate',axis = 1)\ndf_recency.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_process = df.groupby(['CustomerID']).agg({\n        'InvoiceDate': lambda x: (snapshot_day - x.max()).days,\n        'InvoiceNo': 'count',\n        'TotalSum': 'sum'})\n# Rename the columns \ndata_process.rename(columns={'InvoiceDate': 'Recency',\n                         'InvoiceNo': 'Frequency',\n                         'TotalSum': 'MonetaryValue'}, inplace=True)\ndata_process","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_process = data_process.reset_index()\n\ndata_process['CustomerID'] = data_process['CustomerID'].astype('int64')\n\ndata_process.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r_label = range(4,0,-1)\n\nr_groups = pd.qcut(data_process['Recency'], q = 4 , labels = r_label)\n\nf_label = range(1,5)\nf_groups = pd.qcut(data_process['Frequency'] , q = 4 , labels = f_label)\n\nm_label = range(1,5)\n\nm_groups = pd.qcut(data_process['MonetaryValue'],  q = 4 , labels = m_label)\n\n\ndata_process = data_process.assign(R = r_groups.values, F = f_groups.values, M = m_groups)\ndata_process.head()\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Concat RFM quartile values to create RFM Segments\ndef join_rfm(x): return str(int(x['R'])) + str(int(x['F'])) + str(int(x['M']))\ndata_process['RFM_Segment_Concat'] = data_process.apply(join_rfm, axis=1)\nrfm = data_process\nrfm.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def score(x): return int(x['R']) + int(x['F']) + int(x['M'])\n\ndata_process['score'] = rfm.apply(score,axis = 1)\ndata_process","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rfm_level(score):\n    if  ((score >1) and (score < 4)):\n        return 'bottom'\n    elif ((score >3) and (score < 7)):\n        return 'lower'\n    elif ((score > 6) and (score <10)):\n        return 'medium'\n    else:\n        return 'Top'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_process['Level'] = data_process['score'].apply(lambda score : rfm_level(score))\ndata_process","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_process.groupby('Level').agg({\n    'Recency' : 'mean',\n    'Frequency' : 'mean',\n    'MonetaryValue' : ['mean','count']\n})","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}