{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Dataset is taken from Kaggle(https://www.kaggle.com/rajyellow46/wine-quality). The two datasets are related to red and white variants of the Portuguese \"Vinho Verde\" wine. The reference [Cortez et al., 2009]. Due to privacy and logistic issues, only physicochemical (inputs) and sensory (the output) variables are available (e.g. there is no data about grape types, wine brand, wine selling price, etc.).\n\nThese datasets can be viewed as classification or regression tasks. Following dataset having different variables, Some of them are correlated to each other. lets perform some analysis and check how data will predict quality of wine.\n\nFirst we have to import libraries, these are libraries help us to import data also help us to do analysis.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-02T03:17:37.884444Z","iopub.execute_input":"2021-08-02T03:17:37.884931Z","iopub.status.idle":"2021-08-02T03:17:37.909823Z","shell.execute_reply.started":"2021-08-02T03:17:37.884842Z","shell.execute_reply":"2021-08-02T03:17:37.908069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1.Import Libraries","metadata":{}},{"cell_type":"code","source":"import matplotlib \nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nsns.set(color_codes = True)\n%matplotlib inline\n\n\nfrom sklearn.linear_model import LinearRegression,SGDClassifier, RidgeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import LabelEncoder,MinMaxScaler , StandardScaler\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:17:46.681386Z","iopub.execute_input":"2021-08-02T03:17:46.681771Z","iopub.status.idle":"2021-08-02T03:17:48.044693Z","shell.execute_reply.started":"2021-08-02T03:17:46.681741Z","shell.execute_reply":"2021-08-02T03:17:48.043566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2.Import Data","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/wine-quality/winequalityN.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:18:20.681369Z","iopub.execute_input":"2021-08-02T03:18:20.68176Z","iopub.status.idle":"2021-08-02T03:18:20.754526Z","shell.execute_reply.started":"2021-08-02T03:18:20.681729Z","shell.execute_reply":"2021-08-02T03:18:20.753167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## check Nan value\nfor i in df.columns:\n    print (i+\": \"+str(df[i].isna().sum()))","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:18:21.919637Z","iopub.execute_input":"2021-08-02T03:18:21.920128Z","iopub.status.idle":"2021-08-02T03:18:21.937829Z","shell.execute_reply.started":"2021-08-02T03:18:21.920081Z","shell.execute_reply":"2021-08-02T03:18:21.936465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Visualize Data","metadata":{}},{"cell_type":"code","source":"# correlation gives us relation between each varibale. how much each variable is contributing.\n#correlation shows how each feature is dependent on other. from this will find out colinearity between each function, if colinearity is more than 0.5 that leads to problem however we can avoid that problem by dropping feature which highly correlated to each feature.","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:19:21.247659Z","iopub.execute_input":"2021-08-02T03:19:21.248098Z","iopub.status.idle":"2021-08-02T03:19:21.252971Z","shell.execute_reply.started":"2021-08-02T03:19:21.248049Z","shell.execute_reply":"2021-08-02T03:19:21.251392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correlation = df.corr()","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:19:22.638168Z","iopub.execute_input":"2021-08-02T03:19:22.638569Z","iopub.status.idle":"2021-08-02T03:19:22.651131Z","shell.execute_reply.started":"2021-08-02T03:19:22.638514Z","shell.execute_reply":"2021-08-02T03:19:22.649811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (15,8))\nsns.heatmap(correlation,annot = True, cmap = 'Blues')","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:19:23.974814Z","iopub.execute_input":"2021-08-02T03:19:23.975231Z","iopub.status.idle":"2021-08-02T03:19:25.747613Z","shell.execute_reply.started":"2021-08-02T03:19:23.9752Z","shell.execute_reply":"2021-08-02T03:19:25.746374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:19:25.749358Z","iopub.execute_input":"2021-08-02T03:19:25.749791Z","iopub.status.idle":"2021-08-02T03:19:25.782071Z","shell.execute_reply.started":"2021-08-02T03:19:25.749748Z","shell.execute_reply":"2021-08-02T03:19:25.781032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# with the help of correaltion check weather na values columns affects low in that case if you drop values thah will be fine but will go with replacement with median value of particular feture\ndf['pH'] = df['pH'].fillna(df['pH'].median())\ndf['sulphates'] = df['sulphates'].fillna(df['sulphates'].median())\ndf['chlorides'] = df['chlorides'].fillna(df['chlorides'].median())\ndf['residual sugar'] = df['residual sugar'].fillna(df['residual sugar'].median())\ndf['citric acid'] = df['citric acid'].fillna(df['citric acid'].median())\ndf['volatile acidity'] = df['volatile acidity'].fillna(df['volatile acidity'].median())\ndf['fixed acidity'] = df['fixed acidity'].fillna(df['fixed acidity'].median())","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:19:27.817437Z","iopub.execute_input":"2021-08-02T03:19:27.817888Z","iopub.status.idle":"2021-08-02T03:19:27.834159Z","shell.execute_reply.started":"2021-08-02T03:19:27.817836Z","shell.execute_reply":"2021-08-02T03:19:27.832927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nx = np.unique(df[\"quality\"])\nx","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:19:29.920215Z","iopub.execute_input":"2021-08-02T03:19:29.92064Z","iopub.status.idle":"2021-08-02T03:19:29.929248Z","shell.execute_reply.started":"2021-08-02T03:19:29.920608Z","shell.execute_reply":"2021-08-02T03:19:29.927716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now as we can see quality score is vaires in between 3 to 8, as we know low quality wine having low score and high quality wine having high score accordingly we will going to assign class to score and try to predict classes.","metadata":{}},{"cell_type":"markdown","source":"# 4.Preprocessing Data","metadata":{}},{"cell_type":"code","source":"def values(x):\n    if x <= 5:\n        x = 'low'\n    elif x >5 and x <7:\n        x = 'medium'\n    else:\n        x = 'high'\n    \n    return(x)\ndf['level'] = df['quality'].apply(lambda x: values(x))","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:20:37.536638Z","iopub.execute_input":"2021-08-02T03:20:37.536992Z","iopub.status.idle":"2021-08-02T03:20:37.546395Z","shell.execute_reply.started":"2021-08-02T03:20:37.536959Z","shell.execute_reply":"2021-08-02T03:20:37.545271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"using preprocessing method convert quality classes into numerical variable and apply ordinal encoding method.","metadata":{}},{"cell_type":"code","source":"label = LabelEncoder()\n\nquality_score  = label.fit_transform(df['level'])\n\nprint(quality_score)\nprint((label.classes_))","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:20:39.400171Z","iopub.execute_input":"2021-08-02T03:20:39.400624Z","iopub.status.idle":"2021-08-02T03:20:39.411177Z","shell.execute_reply.started":"2021-08-02T03:20:39.400589Z","shell.execute_reply":"2021-08-02T03:20:39.409616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# seaborn packages gives us nice visualitons where in barplot helps us to predict how much each classes having alcohol.\nplt.figure(figsize = (15,8))\nax = sns.barplot(x=\"level\", y=\"alcohol\", data=df)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:20:40.23896Z","iopub.execute_input":"2021-08-02T03:20:40.239436Z","iopub.status.idle":"2021-08-02T03:20:40.65264Z","shell.execute_reply.started":"2021-08-02T03:20:40.239398Z","shell.execute_reply":"2021-08-02T03:20:40.651195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Again will check how much sulphates is used in each classes and which class had used more sulphate.\nplt.figure(figsize = (15,8))\nax = sns.barplot(x=\"level\", y=\"sulphates\", data=df)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:20:41.479209Z","iopub.execute_input":"2021-08-02T03:20:41.479682Z","iopub.status.idle":"2021-08-02T03:20:41.889906Z","shell.execute_reply.started":"2021-08-02T03:20:41.479647Z","shell.execute_reply":"2021-08-02T03:20:41.88827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = sns.countplot(x=\"level\", data=df, palette=\"Set3\")","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:20:44.612194Z","iopub.execute_input":"2021-08-02T03:20:44.61267Z","iopub.status.idle":"2021-08-02T03:20:44.803624Z","shell.execute_reply.started":"2021-08-02T03:20:44.612599Z","shell.execute_reply":"2021-08-02T03:20:44.802168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"outliers lead to error in data, to avoid that firstly check weather outliers are present in data,if outliers are there then try to remove and avoid error.\noutliers find out using histogram using matplotlib function and also will check how each variable is spread and based on that will decide which algorithm is best suitable for predicting accurate values.","metadata":{}},{"cell_type":"code","source":"df.hist(bins=10,figsize=(15,12))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:20:48.600889Z","iopub.execute_input":"2021-08-02T03:20:48.60126Z","iopub.status.idle":"2021-08-02T03:20:51.17018Z","shell.execute_reply.started":"2021-08-02T03:20:48.601228Z","shell.execute_reply":"2021-08-02T03:20:51.169062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#In introduction part we already discussed about type of wine is present in data, so will use dummuy encoding method for converting categorical feature into numerical.\ndf['type'] = pd.get_dummies(df['type'],drop_first = True)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:20:52.838974Z","iopub.execute_input":"2021-08-02T03:20:52.839333Z","iopub.status.idle":"2021-08-02T03:20:52.851974Z","shell.execute_reply.started":"2021-08-02T03:20:52.839301Z","shell.execute_reply":"2021-08-02T03:20:52.850781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = df.iloc[:,:-2]\nx.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:20:56.240945Z","iopub.execute_input":"2021-08-02T03:20:56.241353Z","iopub.status.idle":"2021-08-02T03:20:56.273064Z","shell.execute_reply.started":"2021-08-02T03:20:56.241307Z","shell.execute_reply":"2021-08-02T03:20:56.271613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = sns.countplot(x=\"type\", data=df, palette=\"Set3\")","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:21:00.639774Z","iopub.execute_input":"2021-08-02T03:21:00.640114Z","iopub.status.idle":"2021-08-02T03:21:00.806403Z","shell.execute_reply.started":"2021-08-02T03:21:00.640085Z","shell.execute_reply":"2021-08-02T03:21:00.805019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"from above count plot you can see most of the data is from white wine.","metadata":{}},{"cell_type":"markdown","source":"to achieve minimum global minima we have to reduce cost function as in dataset some of values having high values to avoid errors, will perform feature scaling","metadata":{}},{"cell_type":"code","source":"standard = StandardScaler()\n\nstd_x = standard.fit_transform(x)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:21:45.082929Z","iopub.execute_input":"2021-08-02T03:21:45.08332Z","iopub.status.idle":"2021-08-02T03:21:45.09851Z","shell.execute_reply.started":"2021-08-02T03:21:45.083261Z","shell.execute_reply":"2021-08-02T03:21:45.097344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Split Data","metadata":{}},{"cell_type":"code","source":"x_train,x_test,y_train,y_test = train_test_split(std_x,quality_score,test_size = 0.20,random_state = 40)\n\n\nprint(\"Training data:{}\".format(x_train.shape))\nprint(\"Test data:{}\".format(x_test.shape))","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:22:04.120945Z","iopub.execute_input":"2021-08-02T03:22:04.121287Z","iopub.status.idle":"2021-08-02T03:22:04.133112Z","shell.execute_reply.started":"2021-08-02T03:22:04.121258Z","shell.execute_reply":"2021-08-02T03:22:04.131548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = []","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:22:05.278713Z","iopub.execute_input":"2021-08-02T03:22:05.279129Z","iopub.status.idle":"2021-08-02T03:22:05.284118Z","shell.execute_reply.started":"2021-08-02T03:22:05.279095Z","shell.execute_reply":"2021-08-02T03:22:05.282617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. Build Model and Check Accuracy for Each Model","metadata":{}},{"cell_type":"code","source":"clf = SGDClassifier(max_iter = 10000,random_state = 0)\n\n\n\nclf.fit(x_train,y_train)\ny_predicted = clf.predict(x_test)\nscore = clf.score(x_test,y_test)\n\n\nprint(score)\nresults.append(score)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:23:01.160217Z","iopub.execute_input":"2021-08-02T03:23:01.160634Z","iopub.status.idle":"2021-08-02T03:23:01.445527Z","shell.execute_reply.started":"2021-08-02T03:23:01.1606Z","shell.execute_reply":"2021-08-02T03:23:01.444385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf_1 = RidgeClassifier(alpha = 2,max_iter = 10000)\n\n\n\nclf_1.fit(x_train,y_train)\ny_predicted = clf_1.predict(x_test)\nscore = clf_1.score(x_test,y_test)\n\n\nprint(score)\nresults.append(score)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:23:01.920848Z","iopub.execute_input":"2021-08-02T03:23:01.921266Z","iopub.status.idle":"2021-08-02T03:23:01.981323Z","shell.execute_reply.started":"2021-08-02T03:23:01.921233Z","shell.execute_reply":"2021-08-02T03:23:01.98015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf = LogisticRegression(max_iter= 10000,solver ='newton-cg',random_state = 0,n_jobs = 2 )\n\nclf.fit(x_train,y_train)\ny_predicted = clf.predict(x_test)\nscore = clf.score(x_test,y_test)\n\n\nprint(score)\nresults.append(score)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:23:03.321088Z","iopub.execute_input":"2021-08-02T03:23:03.321454Z","iopub.status.idle":"2021-08-02T03:23:05.270256Z","shell.execute_reply.started":"2021-08-02T03:23:03.321421Z","shell.execute_reply":"2021-08-02T03:23:05.268904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7. Use Confusion Matrix","metadata":{}},{"cell_type":"code","source":"cnf_matrix = confusion_matrix(y_test, y_predicted)\nnp.set_printoptions(precision=2)\ncnf_matrix","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:23:05.272739Z","iopub.execute_input":"2021-08-02T03:23:05.273543Z","iopub.status.idle":"2021-08-02T03:23:05.288745Z","shell.execute_reply.started":"2021-08-02T03:23:05.27349Z","shell.execute_reply":"2021-08-02T03:23:05.286969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import itertools\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:23:48.851564Z","iopub.execute_input":"2021-08-02T03:23:48.85198Z","iopub.status.idle":"2021-08-02T03:23:48.864429Z","shell.execute_reply.started":"2021-08-02T03:23:48.851947Z","shell.execute_reply":"2021-08-02T03:23:48.862505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = df['level'].value_counts()\n\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=classes.index,\n                      title='Confusion matrix, without normalization')\n# With normalization\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes= classes.index, normalize=True,\n                      title='Normalized confusion matrix')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:23:50.319344Z","iopub.execute_input":"2021-08-02T03:23:50.319856Z","iopub.status.idle":"2021-08-02T03:23:51.072874Z","shell.execute_reply.started":"2021-08-02T03:23:50.319809Z","shell.execute_reply":"2021-08-02T03:23:51.071834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf_1 = DecisionTreeClassifier(criterion = 'entropy',min_samples_split=7,max_depth = 8,)\n\n\n\nclf_1.fit(x_train,y_train)\ny_predicted = clf_1.predict(x_test)\nscore = clf_1.score(x_test,y_test)\n\n\nprint(score)\nresults.append(score)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:23:51.678511Z","iopub.execute_input":"2021-08-02T03:23:51.678967Z","iopub.status.idle":"2021-08-02T03:23:51.728957Z","shell.execute_reply.started":"2021-08-02T03:23:51.678933Z","shell.execute_reply":"2021-08-02T03:23:51.727579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnf_matrix = confusion_matrix(y_test, y_predicted)\nnp.set_printoptions(precision=2)\ncnf_matrix","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:23:52.679201Z","iopub.execute_input":"2021-08-02T03:23:52.679686Z","iopub.status.idle":"2021-08-02T03:23:52.693705Z","shell.execute_reply.started":"2021-08-02T03:23:52.679652Z","shell.execute_reply":"2021-08-02T03:23:52.692379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build Model\nclf = RandomForestClassifier(criterion= \"entropy\",bootstrap = False,n_estimators = 1000,n_jobs = 2,verbose = 1,max_features =3)\nclf.fit(x_train, y_train)\ny_predicted = clf.predict(x_test)\nscore=clf.score(x_test,y_test)\nresults.append(score)\n\nprint(score)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:23:53.728632Z","iopub.execute_input":"2021-08-02T03:23:53.729066Z","iopub.status.idle":"2021-08-02T03:24:12.991978Z","shell.execute_reply.started":"2021-08-02T03:23:53.729032Z","shell.execute_reply":"2021-08-02T03:24:12.99085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnf_matrix = confusion_matrix(y_test, y_predicted)\nnp.set_printoptions(precision=2)\ncnf_matrix","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:24:12.993947Z","iopub.execute_input":"2021-08-02T03:24:12.994244Z","iopub.status.idle":"2021-08-02T03:24:13.010682Z","shell.execute_reply.started":"2021-08-02T03:24:12.994214Z","shell.execute_reply":"2021-08-02T03:24:13.008965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import itertools\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:24:13.013122Z","iopub.execute_input":"2021-08-02T03:24:13.013642Z","iopub.status.idle":"2021-08-02T03:24:13.024984Z","shell.execute_reply.started":"2021-08-02T03:24:13.013578Z","shell.execute_reply":"2021-08-02T03:24:13.023474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure()\nplot_confusion_matrix(cnf_matrix, classes=classes.index,\n                      title='Confusion matrix, without normalization')\n# With normalization\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes= classes.index, normalize=True,\n                      title='Normalized confusion matrix')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:24:13.027299Z","iopub.execute_input":"2021-08-02T03:24:13.027885Z","iopub.status.idle":"2021-08-02T03:24:13.860013Z","shell.execute_reply.started":"2021-08-02T03:24:13.027838Z","shell.execute_reply":"2021-08-02T03:24:13.859008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_df = pd.DataFrame({\"ML Models\":[\"SGDClassifier\",\"Ridge classifier\",\"Logistic Regression\",\n                                       \"Decision Tree\",\"Random Forest\"],\"Score\":results})","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:24:13.863522Z","iopub.execute_input":"2021-08-02T03:24:13.863908Z","iopub.status.idle":"2021-08-02T03:24:13.871028Z","shell.execute_reply.started":"2021-08-02T03:24:13.863876Z","shell.execute_reply":"2021-08-02T03:24:13.869438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_df","metadata":{"execution":{"iopub.status.busy":"2021-08-02T03:24:13.873206Z","iopub.execute_input":"2021-08-02T03:24:13.873789Z","iopub.status.idle":"2021-08-02T03:24:13.893327Z","shell.execute_reply.started":"2021-08-02T03:24:13.873748Z","shell.execute_reply":"2021-08-02T03:24:13.892086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}