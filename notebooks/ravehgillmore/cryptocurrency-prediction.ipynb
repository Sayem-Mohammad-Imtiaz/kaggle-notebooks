{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"As always, let's start with a few imports:","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-18T09:14:00.127114Z","iopub.execute_input":"2021-07-18T09:14:00.127831Z","iopub.status.idle":"2021-07-18T09:14:00.15578Z","shell.execute_reply.started":"2021-07-18T09:14:00.127735Z","shell.execute_reply":"2021-07-18T09:14:00.154356Z"}}},{"cell_type":"code","source":"import os\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, LSTM\nfrom tensorflow.keras.metrics import MeanSquaredError\n\nimport os\n","metadata":{"execution":{"iopub.status.busy":"2021-07-18T09:28:30.297913Z","iopub.execute_input":"2021-07-18T09:28:30.298259Z","iopub.status.idle":"2021-07-18T09:28:30.305383Z","shell.execute_reply.started":"2021-07-18T09:28:30.298223Z","shell.execute_reply":"2021-07-18T09:28:30.304596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next, let's see what kind if data we have:","metadata":{}},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2021-07-18T09:28:38.350545Z","iopub.execute_input":"2021-07-18T09:28:38.350916Z","iopub.status.idle":"2021-07-18T09:28:38.37475Z","shell.execute_reply.started":"2021-07-18T09:28:38.350881Z","shell.execute_reply":"2021-07-18T09:28:38.373994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read the data\nWe set some parameters and write a function to read the data","metadata":{}},{"cell_type":"code","source":"pd.options.mode.chained_assignment = None\npd.options.display.max_columns = 999\n\nRootDir = \"/kaggle/input/cryptocurrencypricehistory\"\nHistory = 60\n\ndef read_data ():\n    coin_no = 0\n    for name in os.listdir(RootDir):\n        coin_no += 1\n    \n    max_length, min_length = 0, 1000000\n    for name in os.listdir(RootDir):\n        df = pd.read_csv(RootDir + \"/\" + name, parse_dates=['Date'])\n        length = df.shape[0]\n        if max_length < length:\n            max_length = length\n        if min_length > length:\n            min_length = length\n    \n    data = np.zeros ((coin_no, max_length))\n    lengths = np.zeros(coin_no, dtype = int)\n    i = 0\n    for name in os.listdir(RootDir):\n        short_name = name[5:-4]\n        df = pd.read_csv(RootDir + \"/\" + name, parse_dates=['Date'])\n        length = df.shape[0]\n        lengths[i] = length\n        print (i, short_name, length)\n        data[i, 0:length] = df['Close'].values  # We only keep the closing price as a sequence!\n        i += 1\n    \n    return coin_no, lengths, data\n\ncoin_no, lengths, data = read_data ()\nprint (\"Got\", coin_no, \"coins.\")","metadata":{"execution":{"iopub.status.busy":"2021-07-18T09:28:44.405929Z","iopub.execute_input":"2021-07-18T09:28:44.406264Z","iopub.status.idle":"2021-07-18T09:28:44.915787Z","shell.execute_reply.started":"2021-07-18T09:28:44.406233Z","shell.execute_reply":"2021-07-18T09:28:44.914903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Scaling and splitting:\nWe need to scale the data:","metadata":{}},{"cell_type":"code","source":"def scale_data (data, lengths):\n    coin_no = data.shape[0]\n    shift = np.zeros (coin_no)\n    factor = np.zeros (coin_no)\n    for i in range (coin_no):\n        max_val = data[i,:lengths[i]].max()\n        min_val = data[i, :lengths[i]].min()\n        shift[i] = min_val\n        factor[i] = max_val - min_val\n        data[i,0:lengths[i]] = (data[i,0:lengths[i]]-shift[i])/factor[i]\n    return (shift, factor)\n    \nshift, factor = scale_data (data, lengths)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T09:29:14.085408Z","iopub.execute_input":"2021-07-18T09:29:14.085721Z","iopub.status.idle":"2021-07-18T09:29:14.093095Z","shell.execute_reply.started":"2021-07-18T09:29:14.085692Z","shell.execute_reply":"2021-07-18T09:29:14.092224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Coins 0-18 will be our training set. We'll use the next 4 coins for validation, and we'll use the last coin (XRP) for testing ","metadata":{}},{"cell_type":"code","source":"def create_sequences (data, lengths, start, end):\n    x = []\n    y = []\n    for i in range (start, end):   # Go only over the specified coins\n        for j in range(History, lengths[i]):\n            x.append(data[i, j-History:j])\n            y.append(data[i, j])\n    return np.array(x)[:, :, np.newaxis], np.array(y)\n\nx_train, y_train = create_sequences(data, lengths, 0, 18)\nprint (\"Got\", y_train.shape[0], \"training sequenes.\")\nx_val, y_val = create_sequences(data, lengths, 18, 22)\nprint (\"Got\", y_val.shape[0], \"validation sequenes.\")\nx_test, y_test = create_sequences(data, lengths, 22, 23)\nprint (\"Got\", y_test.shape[0], \"test sequenes.\")","metadata":{"execution":{"iopub.status.busy":"2021-07-18T09:29:21.894054Z","iopub.execute_input":"2021-07-18T09:29:21.89439Z","iopub.status.idle":"2021-07-18T09:29:21.967997Z","shell.execute_reply.started":"2021-07-18T09:29:21.894359Z","shell.execute_reply":"2021-07-18T09:29:21.967039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LSTM model\nWe build a model based on the LSTM architecture to model the data","metadata":{}},{"cell_type":"code","source":"def build_lstm ():\n    # Build an LSTM model\n    model = Sequential()\n    model.add(LSTM(128, return_sequences=True, input_shape= (History, 1)))\n    model.add(LSTM(64, return_sequences=False))\n    model.add(Dense(25))\n    model.add(Dense(1))\n    \n    # Compile the model\n    model.compile(optimizer='adam', loss='mean_squared_error', metrics=[MeanSquaredError()])\n    model.summary()\n    \n    return model\n\nmodel = build_lstm()","metadata":{"execution":{"iopub.status.busy":"2021-07-18T09:29:30.527225Z","iopub.execute_input":"2021-07-18T09:29:30.527539Z","iopub.status.idle":"2021-07-18T09:29:32.83501Z","shell.execute_reply.started":"2021-07-18T09:29:30.527509Z","shell.execute_reply":"2021-07-18T09:29:32.834245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, let's train the model we just built using the training set:","metadata":{}},{"cell_type":"code","source":"hist = model.fit(x_train, y_train, validation_data = (x_val, y_val), \n              batch_size=32, epochs=5) ","metadata":{"execution":{"iopub.status.busy":"2021-07-18T09:29:38.980733Z","iopub.execute_input":"2021-07-18T09:29:38.981138Z","iopub.status.idle":"2021-07-18T09:30:23.665701Z","shell.execute_reply.started":"2021-07-18T09:29:38.981103Z","shell.execute_reply":"2021-07-18T09:30:23.664805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's write a function to show the training stats:","metadata":{}},{"cell_type":"code","source":"def show_stats (hist):\n    plt.plot(hist.history['loss'])\n    plt.plot(hist.history['val_loss'])\n    plt.title(\"Model loss\")\n    plt.ylabel(\"Loss\")\n    plt.xlabel(\"Epoch\")\n    plt.legend([\"Training loss\",\"Validation loss\"])\n    plt.show()\n\nshow_stats (hist)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T09:30:30.309905Z","iopub.execute_input":"2021-07-18T09:30:30.310231Z","iopub.status.idle":"2021-07-18T09:30:30.487359Z","shell.execute_reply.started":"2021-07-18T09:30:30.310201Z","shell.execute_reply":"2021-07-18T09:30:30.486365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A bit of overfitting at the end, but it doesn't seem to be too bad. In retrospect, one or two epochs should be enough.\n\nNow that the model is trained, we can use it to predict the test data:","metadata":{}},{"cell_type":"code","source":"predictions = model.predict(x_test)\nrmse = np.sqrt(np.mean(((predictions - y_test) ** 2)))\nprint (\"Root mean square error on test data:\", rmse)    \nplt.plot(predictions*factor[22] + shift[22])\nplt.plot(y_test*factor[22] + shift[22])    \nplt.legend([\"Predictions\",\"Real data\"])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-18T09:32:24.793604Z","iopub.execute_input":"2021-07-18T09:32:24.793999Z","iopub.status.idle":"2021-07-18T09:32:25.817185Z","shell.execute_reply.started":"2021-07-18T09:32:24.793951Z","shell.execute_reply":"2021-07-18T09:32:25.816255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Seems like the predictions are pretty accurate!","metadata":{}}]}