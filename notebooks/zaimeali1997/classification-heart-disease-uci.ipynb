{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Import Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Import Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/heart-disease-uci/heart.csv')\ndata.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis"},{"metadata":{},"cell_type":"markdown","source":"* age [29-77]\n* sex [1=male, 0=female]\n* chest pain type (4 values) [0, 1, 2, 3]\n* resting blood pressure\n* serum cholestoral in mg/dl\n* fasting blood sugar > 120 mg/dl [1=true, 0=false]\n* resting electrocardiographic results (values 0,1,2)\n* maximum heart rate achieved => thalach\n* exercise induced angina [1=yes, 0=no]\n* oldpeak = ST depression induced by exercise relative to rest\n* the slope of the peak exercise ST segment [0, 1, 2]\n* number of major vessels (0-3) colored by flourosopy [0, 1, 2, 3, 4]\n* thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\n* target [1=Have Heart Disease, 0=Don't have Heart Disease]"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Total Rows in a Data: \", data.shape[0])\nprint(\"Total Columns in a Data: \", data.shape[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"\\t****************\")\nprint(\"\\tData Information:\")\nprint(\"\\t****************\\n\")\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All the values in a dataset are numerical."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"\\t****************\")\nprint(\"\\tData Describe:\")\nprint(\"\\t****************\\n\")\ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Null Values in each column:\")\nprint(data.isna().any())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Has from the above output there's no missing values in any column so we don't have to do data cleaning and data filling."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Unique Values in each column:\")\nprint(\"----------------------------\\n\")\ncols = list(data.columns)\nfor c in cols:\n    print(c.upper(), \":\", data[c].unique(), \"\\n\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Exploring Age Column"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The most younger person in a data:\")\nprint(data.iloc[data.age.idxmin()])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"the most youngest person is a male and has a heart disease."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The most older person in a data:\")\nprint(data.iloc[data.age.idxmax()])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"the most older person is a male and not has a heart disease."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(14, 8))\nsns.countplot(y=data.age)\n# sns.countplot(y=data['age'], order=data['age'].value_counts().index)\nplt.title(\"Age Count\")\nplt.xlabel(\"Count\")\nplt.ylabel(\"Age\")\nax.set(xticks=range(0, 21))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see from the above plot, mostly people age are between 50-60"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(data.age)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is no outlier in a dataset as we can see from the above plot. The average person age is between 50-60."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(14, 5))\nax = plt.plot(data.groupby('age')['target'].mean())\nplt.xticks(range(min(data.age)-1, max(data.age)+1))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"People from the age between 29 to 32 and 70 to 76 has the highest chance of having a heart disease."},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data.age == 61]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data.age > 70]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As from the above chart people above 70 has highest chance of having a heart disease."},{"metadata":{},"cell_type":"markdown","source":"### Exploring Gender Column"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of Unique Values in Gender Column: \", data.sex.nunique(), \"\\n\")\nprint(\"Unique Values count are:\")\nprint(data.sex.value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this dataset mostly people are Males and some are Females"},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.countplot(data.sex, palette='Set3')\nplt.xlabel(\"Sex\")\nplt.title(\"Gender Occuring in a Dataset\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see from the above plot Males are the most in a data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby('sex')['target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Male has a high heart disease rate than female and they are occuring 93 times while female has 72 times occuring"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(8, 6))\nax = sns.countplot(x='sex', hue='target', data=data, palette='Set2')\nplt.xlabel(\"Gender (0=Female, 1=Male)\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see from the above plot, that Male has a higher rate of heart disease."},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.catplot(x='target', col='sex', data=data, kind='count')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Exploring Chest Pain Column"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of Unique Values in Chest Pain Type Column: \", data.cp.nunique(), \"\\n\")\nprint(\"Unique Values count are:\")\nprint(data.cp.value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here 0 means no pain and 3 means extreme pain"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data.cp)\nplt.title(\"Chest Pain Count\")\nplt.xlabel(\"Chest Pain Type\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Mostly people have no Chest Pain"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby('cp')['target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Person who has a Chest Pain Type 1 and 2 has the highest chance to have Heart Disease."},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.countplot(x='cp', data=data, hue='target')\nplt.xlabel(\"Chest Pain Type (lowest to highest)\")\nplt.ylabel(\"Count\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this plot, as we can see a Person who has a chest pain type 2 has mostly chances to have heart disease."},{"metadata":{},"cell_type":"markdown","source":"### Exploring Blood Sugar Column"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of Unique Values in Fasting Blood Sugar Column: \", data.fbs.nunique(), \"\\n\")\nprint(\"Unique Values count are:\")\nprint(data.fbs.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby('fbs')['target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A person who don't have a Blood Sugar has the highest chance of having Heart Disease."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='fbs', hue='target', data=data, palette='Set2')\nplt.xlabel(\"Fasting Blood Sugar (0=False, 1=True)\")\nplt.ylabel(\"Count\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Exploring Electrographic Column"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of Unique Values in Resting Electrocardiographic Column: \", data.restecg.nunique(), \"\\n\")\nprint(\"Unique Values count are:\")\nprint(data.restecg.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby('restecg')['target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=data['restecg'])\nplt.xlabel(\"Resting Electrocardiographic Results\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Exploring Thalach Column"},{"metadata":{},"cell_type":"markdown","source":"Thalach = maximum heart rate achieved"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of Unique Values in Thalach Column: \", data.thalach.nunique(), \"\\n\")\nprint(\"Unique Values count are:\")\nprint(data.thalach.value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thalach is a continous column so we have to draw distribute plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(data.thalach)\nplt.xlabel(\"Heart Rate\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is left skewed means negative skewed. [For Further Know](https://www.statisticshowto.datasciencecentral.com/probability-and-statistics/skewed-distribution/)"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x='age', y='thalach', data=data)\nplt.xlabel('Age')\nplt.ylabel('Heart Rate')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Exploring Exercise Induced Angina Column"},{"metadata":{},"cell_type":"markdown","source":"[Open this link for further knowing of Exercise Induced Angina](https://www.mayoclinic.org/diseases-conditions/angina/symptoms-causes/syc-20369373)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of Unique Values in Exercise Induced Angina Column: \", data.exang.nunique(), \"\\n\")\nprint(\"Unique Values count are:\")\nprint(data.exang.value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This result shows us that 204 people have no Exercise Induced Angina and 99 people have it."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby('exang')['target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see from the above output people who don't have Induced Angina have a higher chance of having Heart Disease."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(y=data.exang)\nplt.xlabel(\"Count\")\nplt.ylabel(\"Exercised Induced Angina\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let visualize the above graph with respect to Target variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.countplot(x='exang', data=data, hue='target')\nplt.xlabel(\"Exercised Induced Angina (0=No, 1=Yes)\")\nplt.ylabel(\"Count\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Above graph is illustrating that person who don't have Induced Angina has Heart Disease."},{"metadata":{},"cell_type":"markdown","source":"### Exploring Slope Column"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title(\"The Slope of the Peak Exercise \")\nsns.countplot(x=data['slope'])\nplt.xlabel(\"Slope\")\nplt.ylabel(\"Count\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see 1 and 2 are the highest occuring slopes in a dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title(\"The Slope of the Peak Exercise \")\nsns.countplot(x=data['slope'], hue=data['target'], data=data)\nplt.xlabel(\"Slope\")\nplt.ylabel(\"Count\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The person who has a type 2 slope has a higher chance of having Heart Disease"},{"metadata":{},"cell_type":"markdown","source":"### Exploring Further Columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=data['ca'])\nplt.title(\"Number of Major Vessels\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In ca column there are 5 categories."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=data['thal'])\nplt.title(\"Blood Disorder called Thalassemia\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Exploring Target Column"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=data['target'])\nplt.title(\"Target Count\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are more people who have a heart disease in this data."},{"metadata":{},"cell_type":"markdown","source":"## Data Correlation"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.corr()['target'].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Column: cp, thalach, slope are +ve correlated to a target while other columns are -ve correlated."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15, 15))\nsns.heatmap(data.corr(), annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data[['cp', 'restecg', 'thalach', 'slope', 'target']])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"X1 = data.iloc[:, :-1]\ny1 = data.iloc[:, -1]\n\ndf = data[['cp', 'restecg', 'thalach', 'slope', 'target']]\nX2 = df.iloc[:, :-1]\ny2 = df.iloc[:, -1]\n\nprint(\"Columns in Data1: \", list(data.columns))\nprint(\"Data1 Shape: \", data.shape)\nprint(\"X1 Shape: \", X1.shape)\nprint(\"y1 Shape: \", y1.shape)\nprint()\n\nprint(\"Columns in Data2: \", list(df.columns))\nprint(\"Data2 Shape: \", df.shape)\nprint(\"X2 Shape: \", X2.shape)\nprint(\"y2 Shape: \", y2.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Splitting Data"},{"metadata":{},"cell_type":"markdown","source":"### Train Test Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_X1, test_X1, train_y1, test_y1 = train_test_split(X1, y1, test_size=0.2, random_state=42)\ntrain_X2, test_X2, train_y2, test_y2 = train_test_split(X2, y2, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For prediction, i'm going to use \n* Decision Tree Classifier\n* Random Forest Classifier \n* Logistic Regression\n* Support Vector Machine \n* Stochastic Gradient Descent\n* K-Nearest Neighbor Classifier\n* Adaboost Classifier"},{"metadata":{},"cell_type":"markdown","source":"### Decision Tree Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nDTC = DecisionTreeClassifier()\nDTC.fit(train_X1, train_y1)\npred_dtc1 = DTC.predict(test_X1)\nscore_dtc1 = round(DTC.score(test_X1, test_y1)*100, 2)\nprint(\"Accuracy of Data 1 with Decision Tree Classifier is: \", score_dtc1, \"%\")\nprint()\nDTC.fit(train_X2, train_y2)\npred_dtc2 = DTC.predict(test_X2)\nscore_dtc2 = round(DTC.score(test_X2, test_y2)*100, 2)\nprint(\"Accuracy of Data 2 with Decision Tree Classifier is: \", score_dtc2, \"%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nRFC = RandomForestClassifier() # n_estimators = 100\nRFC.fit(train_X1, train_y1)\npred_rfc1 = RFC.predict(test_X1)\nscore_rfc1 = round(RFC.score(test_X1, test_y1)*100, 2)\nprint(\"Accuracy of Data 1 with Random Forest Classifier is: \", score_rfc1, \"%\")\nprint()\nRFC.fit(train_X2, train_y2)\npred_rfc2 = RFC.predict(test_X2)\nscore_rfc2 = round(RFC.score(test_X2, test_y2)*100, 2)\nprint(\"Accuracy of Data 2 with Random Forest Classifier is: \", score_rfc2, \"%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nLR = LogisticRegression()\nLR.fit(train_X1, train_y1)\npred_lr1 = LR.predict(test_X1)\nscore_lr1 = round(LR.score(test_X1, test_y1)*100, 2)\nprint(\"Accuracy of Data 1 with Logistic Regression is: \", score_lr1, \"%\")\nprint()\nLR.fit(train_X2, train_y2)\npred_lr2 = LR.predict(test_X2)\nscore_lr2 = round(LR.score(test_X2, test_y2)*100, 2)\nprint(\"Accuracy of Data 2 with Logistic Regression is: \", score_lr2, \"%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Support Vector Machine"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nSC = SVC()\nSC.fit(train_X1, train_y1)\npred_sc1 = SC.predict(test_X1)\nscore_sc1 = round(SC.score(test_X1, test_y1)*100, 2)\nprint(\"Accuracy of Data 1 with Support Vector Classifier is: \", score_sc1, \"%\")\nprint()\nSC.fit(train_X2, train_y2)\npred_sc2 = SC.predict(test_X2)\nscore_sc2 = round(SC.score(test_X2, test_y2)*100, 2)\nprint(\"Accuracy of Data 2 with Support Vector Classifier is: \", score_sc2, \"%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Stochastic Gradient Descent"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\nSGD = SGDClassifier()\nSGD.fit(train_X1, train_y1)\npred_sgd1 = SGD.predict(test_X1)\nscore_sgd1 = round(SGD.score(test_X1, test_y1)*100, 2)\nprint(\"Accuracy of Data 1 with Stochastic Gradient Descent Classifier is: \", score_sgd1, \"%\")\nprint()\nSGD.fit(train_X2, train_y2)\npred_sgd2 = SGD.predict(test_X2)\nscore_sgd2 = round(SGD.score(test_X2, test_y2)*100, 2)\nprint(\"Accuracy of Data 2 with Stochastic Gradient Descent Classifier is: \", score_sgd2, \"%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### K-Nearest Neighbor Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nKNN = KNeighborsClassifier(n_neighbors=10) # default n_neighbors = 5\nKNN.fit(train_X1, train_y1)\npred_knn1 = KNN.predict(test_X1)\nscore_knn1 = round(KNN.score(test_X1, test_y1)*100, 2)\nprint(\"Accuracy of Data 1 with K-Nearest Neighbor Classifier is: \", score_knn1, \"%\")\nprint()\nKNN.fit(train_X2, train_y2)\npred_knn2 = KNN.predict(test_X2)\nscore_knn2 = round(KNN.score(test_X2, test_y2)*100, 2)\nprint(\"Accuracy of Data 2 with K-Nearest Neighbor Classifier is: \", score_knn2, \"%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### AdaBoost Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nABC = AdaBoostClassifier() # n_estimators = 50 default\nABC.fit(train_X1, train_y1)\npred_abc1 = ABC.predict(test_X1)\nscore_abc1 = round(ABC.score(test_X1, test_y1)*100, 2)\nprint(\"Accuracy of Data 1 with AdaBoost Classifier is: \", score_abc1, \"%\")\nprint()\nABC.fit(train_X2, train_y2)\npred_abc2 = ABC.predict(test_X2)\nscore_abc2 = round(ABC.score(test_X2, test_y2)*100, 2)\nprint(\"Accuracy of Data 2 with AdaBoost Classifier is: \", score_abc2, \"%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## RESULT:"},{"metadata":{"trusted":true},"cell_type":"code","source":"model1 = pd.DataFrame(\n    {\n        'Models': [\n            'Decision Tree Classifier',\n            'Random Forest Classifier',\n            'Logistic Regression',\n            'Support Vector Machine',\n            'Stochastic Gradient Descent',\n            'K-Nearest Neighbors',\n            'AdaBoost Classifier'\n        ],\n        'Scores': [\n            score_dtc1,\n            score_rfc1,\n            score_lr1,\n            score_sc1,\n            score_sgd1,\n            score_knn1,\n            score_abc1\n        ],\n    }\n)\nmodel2 = pd.DataFrame(\n    {\n        'Models': [\n            'Decision Tree Classifier',\n            'Random Forest Classifier',\n            'Logistic Regression',\n            'Support Vector Machine',\n            'Stochastic Gradient Descent',\n            'K-Nearest Neighbors',\n            'AdaBoost Classifier'\n        ],\n        'Scores': [\n            score_dtc2,\n            score_rfc2,\n            score_lr2,\n            score_sc2,\n            score_sgd2,\n            score_knn2,\n            score_abc2\n        ],\n    }\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Models who are Train on Data 1:\")\nmodel1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this result, Decision Tree, Random Forest, Logistic Regression, AdaBoost are the best choice for Data 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Models who are Train on Data 2:\")\nmodel2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this result, Stochastic Gradient Descent, Logistic Regression are the best choice for Data 2"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}