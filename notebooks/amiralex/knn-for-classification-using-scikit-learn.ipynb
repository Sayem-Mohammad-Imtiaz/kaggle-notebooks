{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.datasets import make_moons\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score\nfrom numpy import linalg\nfrom scipy.spatial import distance\n","metadata":{"_uuid":"333dc72902f9a7b163226cb187cf989768665c43","_cell_guid":"059208d1-5542-4d80-9ee2-cee9a4391e78","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Load the dataset\ndf = pd.read_csv('../input/diabetes.csv')\n\n#Print the first 5 rows of the dataframe.\ndf.head()","metadata":{"_uuid":"d15b5491570a8ec6188b77240ab334f9b68f2655","_cell_guid":"0d788097-f6b8-4fca-99b4-f5102d1bbade","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's observe the shape of the dataframe.\ndf.shape","metadata":{"_uuid":"25e59b9710940c6b4d86dc6e1487ce41dbf284e3","_cell_guid":"766ae7f8-b08c-4ca7-bc1e-7e0401ac7fce","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's create numpy arrays for features and target\nX = df.drop('Outcome',axis=1).values\ny = df['Outcome'].values","metadata":{"_uuid":"5b6e02cc6d372bd5c3b646959fdf3db8c0e0a881","_cell_guid":"a405c050-6a75-4c4a-803f-86db6152d796","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's split the data randomly into training and test set. \n\nWe will fit/train a classifier on the training set and make predictions on the test set. Then we will compare the predictions with the known labels.\n\nScikit-learn provides facility to split data into train and test set using train_test_split method.","metadata":{"_uuid":"ce8256ba90e53d72f32d075e9beca80a32b4f14c","_cell_guid":"18477358-3b6a-46e2-8b32-67dfc3150e53"}},{"cell_type":"code","source":"#importing train_test_split\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"892a7dac3f31c5d7ef1506933102ebdec2605ce0","_cell_guid":"c674227c-f930-4ae0-a58a-c3f94c06c7d7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It is a best practice to perform our split in such a way that out split reflects the labels in the data. In other words, we want labels to be split in train and test set as they are in the original dataset. So we use the stratify argument.\n\nAlso we create a test set of size of about 40% of the dataset.","metadata":{"_uuid":"a4965dba9f73aa19400a4b767be4ce9bdb0426b2","_cell_guid":"92e7ad71-2384-4f93-93ef-e70476fbbe9f"}},{"cell_type":"code","source":"X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.33,random_state=42, stratify=y)","metadata":{"_uuid":"d90e61834caa0b28f7585e4322b49c1c2780d607","_cell_guid":"380309a4-ecaa-43e6-be63-f0e657e5838b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MyKNeighborsClassifier:\n\n    def __init__(self, k,  metric = 'euclidean'):\n        self.k = k\n        self.metric = metric\n\n    def euclidean_dist(self, array1, array2):\n        array1 = np.array(array1)\n\n        array2 = np.array(array2)\n        \n        return linalg.norm(array1 - array2)\n    \n    def manhattan_dist(self, array1, array2):\n    \n        array1 = np.array(array1)\n\n        array2 = np.array(array2)\n        return distance.cityblock(array1, array2)\n\n\n    def k_neighbors(self, test_row):\n        distances = []\n        for i in range(len(self.X_train)):\n            if self.metric == 'euclidean':\n                distance = self.euclidean_dist(test_row, self.X_train[i])\n            else:\n                distance = self.manhattan_dist(test_row, self.X_train[i])\n            distances.append((distance, self.y_train[i]))\n        distances.sort()\n        return distances[:self.k]\n\n\n    def get_nn(self):\n\n        self.X_train = np.array(self.X_train)\n\n        self.X_test = np.array(self.X_test)\n\n        self.y_train = np.array(self.y_train)\n\n        neighbors = []\n\n        for j in range(len(self.X_test)):\n\n            neighbors.append(self.k_neighbors(self.X_test[j]))\n\n        return neighbors\n\n\n    def vote_count(self, lst):\n\n        lst_count = dict()\n\n        for element in lst:\n\n            if element in lst_count:\n\n                lst_count[element] += 1\n\n            else:\n\n                lst_count[element] = 1\n\n        return lst_count\n\n\n    def fit(self, X_train, y_train):\n\n        self.X_train = X_train\n\n        self.y_train = y_train\n\n\n    def predict(self, X_test):\n\n        self.X_test = X_test\n\n        nbrs = self.get_nn()\n\n        predictions = []\n\n        for row in nbrs:\n\n            dist, labels = zip(*row)\n\n            label_dict = self.vote_count(labels)\n\n            predictions.append(max(label_dict, key = label_dict.get))\n        \n        return predictions\n\n    def evaluate(self, y_pred, y_test):\n\n        count = 0\n\n        for act, pred in zip(y_pred, y_test):\n            if act == pred:\n                count += 1\n\n        return count / len(y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Проверьте решение на датасете и сравните с kNeighborsClassifier из sklearn (4 балла)\n1. (1 балл) Выведите accuracy_score для вашего решения и для решения из sklearn, посчитайте в 4 вариациях (Должно получиться 8 чисел)\n  1. Параметры по умолчанию\n  2. `weights='distance'`\n  3. `metric='manhattan'`\n  4. `weights='distance'`, `metric='manhattan'`\n2. (2 балла) Переберите параметр k от 1 до 10 для каждой модели из пункта выше (получится 4 графика по две линии на каждом)\n  1. Переберите параметр, каждый раз обучайте модель\n  2. Выведите график зависимости `accuracy` от `k`\n  3. На этом же графике выведите пунктирной линией такую же зависимость для модели из sklearn\n3. (3 балла) Напишите вывод, сравнение всего, что получилось – получилось ли у вас достичь таких же результатов, как в sklearn, как на результат влияют параметры, какая модель и с какими параметрами оказалась лучшей.","metadata":{}},{"cell_type":"code","source":"k = 4\n\nknn = MyKNeighborsClassifier(k)\n\nknn.fit(X_train, y_train)\ny_pred = knn.predict(X_test)\nknn.evaluate(y_pred, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors=k)\nknn.fit(X_train, y_train)\nknn.score(X_test, y_test) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knn = MyKNeighborsClassifier(k, 'manhattan')\n\nknn.fit(X_train, y_train)\ny_pred = knn.predict(X_test)\nknn.evaluate(y_pred, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors=k, metric = 'manhattan')\nknn.fit(X_train, y_train)\nknn.score(X_test, y_test) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n#Setup arrays to store training and test accuracies\nneighbors = np.arange(1,11)\ntest_accuracy = np.empty(len(neighbors))\n\nfor i,k in enumerate(neighbors):\n    #Setup a knn classifier with k neighbors\n    knn = MyKNeighborsClassifier(k)\n    \n    #Fit the model\n    knn.fit(X_train, y_train)\n    y_pred = knn.predict(X_test)\n\n    #Compute accuracy on the training set\n    \n    #Compute accuracy on the test set\n    test_accuracy[i] = knn.evaluate(y_pred, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import KNeighborsClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\n#Setup arrays to store training and test accuracies\nneighbors = np.arange(1,11)\ntest_accuracy_sklearn = np.empty(len(neighbors))\n\nfor i,k in enumerate(neighbors):\n    #Setup a knn classifier with k neighbors\n    knn = KNeighborsClassifier(n_neighbors=k)\n    \n    #Fit the model\n    knn.fit(X_train, y_train)\n    \n    #Compute accuracy on the training set\n    \n    #Compute accuracy on the test set\n    test_accuracy_sklearn[i] = knn.score(X_test, y_test) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Generate plot\nplt.title('euclidean k-NN  Varying number of neighbors')\nplt.plot(neighbors, test_accuracy, label='My Accuracy')\nplt.plot(neighbors, test_accuracy_sklearn, label='Sklearn accuracy')\n\nplt.legend()\nplt.xlabel('Number of neighbors')\nplt.ylabel('Accuracy')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n#Setup arrays to store training and test accuracies\nneighbors = np.arange(1,11)\ntest_accuracy = np.empty(len(neighbors))\n\nfor i,k in enumerate(neighbors):\n    #Setup a knn classifier with k neighbors\n    knn = MyKNeighborsClassifier(k, 'manhattan')\n    \n    #Fit the model\n    knn.fit(X_train, y_train)\n    y_pred = knn.predict(X_test)\n\n    #Compute accuracy on the training set\n    \n    #Compute accuracy on the test set\n    test_accuracy[i] = knn.evaluate(y_pred, y_test)","metadata":{"_uuid":"745e27e18bf047cd2c71e014aebd324b306de5b5","_cell_guid":"ca8346d5-a9a4-4728-8b24-253de0d9a31c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import KNeighborsClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\n#Setup arrays to store training and test accuracies\nneighbors = np.arange(1,11)\ntest_accuracy_sklearn = np.empty(len(neighbors))\n\nfor i,k in enumerate(neighbors):\n    #Setup a knn classifier with k neighbors\n    knn = KNeighborsClassifier(n_neighbors=k, metric = 'manhattan')\n    \n    #Fit the model\n    knn.fit(X_train, y_train)\n    \n    #Compute accuracy on the training set\n    \n    #Compute accuracy on the test set\n    test_accuracy_sklearn[i] = knn.score(X_test, y_test) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Generate plot\nplt.title('manhattan k-NN  Varying number of neighbors')\nplt.plot(neighbors, test_accuracy, label='My Accuracy')\nplt.plot(neighbors, test_accuracy_sklearn, label='Sklearn accuracy')\n\nplt.legend()\nplt.xlabel('Number of neighbors')\nplt.ylabel('Accuracy')\nplt.show()","metadata":{"_uuid":"6e40ab5bc997d0f450215f65344bb79b4cf3896d","_cell_guid":"354c71d7-25f6-4862-9e5a-c390341c858b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Вывод \nSklearn работает явно лучше, хотя в при metric = 'manhattan' и при k = 4, 6 и 8 моя модель оказалась лучше и я не понимаю, почему.\nЕвклидово расстояние выводит результат лучше - 0.758, чем второе - 0.74.","metadata":{}}]}