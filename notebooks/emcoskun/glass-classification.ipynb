{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import cross_val_score, train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"45e4ab6e34c14eaf681a4cbe86d33510e03c5bd3"},"cell_type":"markdown","source":"**Data Exploration**"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/glass.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4911942034d5ff05a8a3479e23c63bed5480374b"},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c4c64803b095214c49eede60000bea296f83093b"},"cell_type":"markdown","source":"The dataset consists of ten columns. Nine of them are numerical features, the last one is the type of glass. In this notebook, we are going to build a classifier for the type of glass."},{"metadata":{"trusted":true,"_uuid":"a3f721ec1ba87ca9fcc470038e461f78f6501214"},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3c0da3ece5202b3a485ccda156d620dd646111ed"},"cell_type":"markdown","source":"There is great variation in the distribution of the numerical features, which necessitates the use of a scaler later on."},{"metadata":{"trusted":true,"_uuid":"c1f4c5cbdeecdf25d9478599fee7049784d372c5"},"cell_type":"code","source":"data[\"Type\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"68cb0060f37e86a510a9263dd58393cea9d5dcac"},"cell_type":"markdown","source":"There are six types of glass, labeled with numbers 1-7 (excluding 4)."},{"metadata":{"trusted":true,"_uuid":"96537a3c58987abb99d051d2f5475df98f8698ff"},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4bc11f8556103a577160142fffc334bf5829ef18"},"cell_type":"code","source":"sns.relplot(x=\"RI\", y=\"Type\", data=data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f1b90ccaf1e4c95284cc4f4f1966dd509b9dcc50"},"cell_type":"code","source":"sns.relplot(x=\"Na\", y=\"Type\", data=data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"09e3899108558f54b12345a32bfec0e2301c4265"},"cell_type":"code","source":"sns.relplot(x=\"Mg\", y=\"Type\", data=data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"92510ac8372605ae0ce1463a585621411f295a10"},"cell_type":"code","source":"sns.relplot(x=\"Al\", y=\"Type\", data=data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2b6314cf3f5248071f7c80636ff25c5068e76ef5"},"cell_type":"code","source":"sns.relplot(x=\"Si\", y=\"Type\", data=data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"93d6d611cdabf10941c022d9ded934818735ca06"},"cell_type":"code","source":"sns.relplot(x=\"K\", y=\"Type\", data=data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2a775f5b12891a86c1da0431601a55201ec0bab0"},"cell_type":"code","source":"sns.relplot(x=\"Ca\", y=\"Type\", data=data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f1b1feb91ab6862e85c180b5761f57251493632"},"cell_type":"code","source":"sns.relplot(x=\"Ba\", y=\"Type\", data=data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"20b38b1154e81ee8cb366c47cf631e54d5a616ae"},"cell_type":"code","source":"sns.relplot(x=\"Fe\", y=\"Type\", data=data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8da6c4457f40ae55d39b2dc182a854284e67e9d"},"cell_type":"code","source":"g = sns.PairGrid(data)\ng.map(plt.scatter)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"94357bf802565f220de508ee49982dee63da549b"},"cell_type":"markdown","source":"As we can see from the plots above, there does not seem to be any correlation between the numerical features."},{"metadata":{"_uuid":"6e81fecb5ab33e90fa14c2801f033b1148ff898a"},"cell_type":"markdown","source":"**Preparation of the Training and the Test Data**"},{"metadata":{"trusted":true,"_uuid":"a89f7c7fa7c2e25174c41b8ad63e425f1f47c5eb"},"cell_type":"code","source":"y = data[\"Type\"]\nX = data.drop([\"Type\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b634bbc770040a0e05ee4b69fe1223d473831e47"},"cell_type":"code","source":"numerical_features = [\"RI\", \"Na\", \"Mg\", \"Al\", \"Si\", \"K\", \"Ca\", \"Ba\", \"Fe\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b91191d1536a32a8a7bb4a33efe39ada2da0418"},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y,\n                                                    test_size=0.2,\n                                                    random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"49b7cb1e0bb7b3928344191c88614b9510456e48"},"cell_type":"markdown","source":"**Model Construction and Evaluation**"},{"metadata":{"trusted":true,"_uuid":"09771e2af230ea7d0c5e6cf4bc50375e30b058c6"},"cell_type":"code","source":"numerical_transformer = Pipeline(steps=[\n    (\"std_scaler\", StandardScaler())\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"834015029a7bb120a2a34e498370aa6e3b8b7138"},"cell_type":"code","source":"preprocessor = ColumnTransformer(transformers=[\n    (\"num\", numerical_transformer, numerical_features)\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e4bf9ba3946036a5526707071a36a3cc1984df2a"},"cell_type":"code","source":"def evaluate_classifier(label, classifier):\n    pipeline = Pipeline(steps=[\n        (\"preprocessor\", preprocessor),\n        (\"classifier\", classifier)\n    ])\n    pipeline.fit(X_train, y_train)\n    print(label, \":\", pipeline.score(X_test, y_test))\n    y_pred = pipeline.predict(X_test)\n    print(confusion_matrix(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f140b1acd714dc957c1e2f722d7ba533a8561d05"},"cell_type":"markdown","source":"Let us evaluate a bunch of classifiers, with their default settings."},{"metadata":{"trusted":true,"_uuid":"124adba269c6268497ea332dd53bebcccd62c137","scrolled":true},"cell_type":"code","source":"evaluate_classifier(\"Decision Tree\",\n                    DecisionTreeClassifier(random_state=42))\nevaluate_classifier(\"K Neighbors\",\n                    KNeighborsClassifier())\nevaluate_classifier(\"Support Vector Machine\",\n                    SVC(random_state=42))\nevaluate_classifier(\"Random Forest\",\n                    RandomForestClassifier(random_state=42))\nevaluate_classifier(\"Multi-Layer Perceptron\",\n                    MLPClassifier(random_state=42))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e45e7824d03499f5c598a4fc7f3d45c476f2cee7"},"cell_type":"markdown","source":"The random forest and multi-layer perceptron classifiers seem to be the most promising. Let us try a bunch of values for the n_estimators parameter for the random forest classifier."},{"metadata":{"trusted":true,"_uuid":"999f78467eada1fa8132f329325b5486c0b44c32"},"cell_type":"code","source":"evaluate_classifier(\"Random Forest, n=5\",\n                    RandomForestClassifier(random_state=42, n_estimators=5))\nevaluate_classifier(\"Random Forest, n=10\",\n                    RandomForestClassifier(random_state=42, n_estimators=10))\nevaluate_classifier(\"Random Forest, n=20\",\n                    RandomForestClassifier(random_state=42, n_estimators=20))\nevaluate_classifier(\"Random Forest, n=50\",\n                    RandomForestClassifier(random_state=42, n_estimators=50))\nevaluate_classifier(\"Random Forest, n=100\",\n                    RandomForestClassifier(random_state=42, n_estimators=100))\nevaluate_classifier(\"Random Forest, n=200\",\n                    RandomForestClassifier(random_state=42, n_estimators=200))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f3425b61eca3de9735e52ee76acc0d170ebf2c34"},"cell_type":"markdown","source":"Random forest classifiers with n=50 give the best score of 0.86."},{"metadata":{"_uuid":"8934864157f842da7ff1c467fa714f22b045f6fa"},"cell_type":"markdown","source":"Let us now try out a bunch of multi-layer perceptron classifiers with different parameters."},{"metadata":{"trusted":true,"_uuid":"c0b264c390da4618ae8645331e96cc9d407526fa"},"cell_type":"code","source":"evaluate_classifier(\"MLP Classifier, hidden_layer_size=20\",\n                   MLPClassifier(random_state=42, hidden_layer_sizes=(20,)))\nevaluate_classifier(\"MLP Classifier, hidden_layer_size=50\",\n                   MLPClassifier(random_state=42, hidden_layer_sizes=(50,)))\nevaluate_classifier(\"MLP Classifier, hidden_layer_size=100\",\n                   MLPClassifier(random_state=42, hidden_layer_sizes=(100,)))\nevaluate_classifier(\"MLP Classifier, hidden_layer_size=200\",\n                   MLPClassifier(random_state=42, hidden_layer_sizes=(200,)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"af5580781902ad7ecf6c55ad0fef7f66d0d09815"},"cell_type":"markdown","source":"The default size for the hidden layer, 100, works out well."},{"metadata":{"_uuid":"9c1d7249339a4efd04b0a14e606a59299ca05779"},"cell_type":"markdown","source":"After some fiddling, I found the following parameters for a MLP Classifier that give a score of 0.86: three hidden layers with 80 neurons each, and alpha=1. The number of neurons seems too high for this job. It seems that the random forest model is more suitable."},{"metadata":{"trusted":true,"_uuid":"19e1ac0d24dc3461aadb1df1e98387036b3cd4ef"},"cell_type":"code","source":"evaluate_classifier(\"MLP Classifier\",\n                   MLPClassifier(random_state=42,\n                                 hidden_layer_sizes=(80,80,80),\n                                alpha=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1bdbacbd1efc6f84d9a36d53f688f5cd5f89be2d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}