{"cells":[{"metadata":{"id":"Au7Y1ZaGwdOJ","colab_type":"text","_uuid":"c31c4729d35dabb474a989530af3445a93ceb964"},"cell_type":"markdown","source":"# Dataset - Women's E-Commerce Clothing Reviews"},{"metadata":{"id":"jb7Q2yPlp16Z","colab_type":"text","_uuid":"e4573f23b2cd2abe6d0c25987d25830ed0aee499"},"cell_type":"markdown","source":"## References \n\n* https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews\n*  http://math.mit.edu/~gs/linearalgebra/ila0601.pdf\n*   http://web.mit.edu/be.400/www/SVD/Singular_Value_Decomposition.htm\n* https://machinelearningmastery.com/singular-value-decomposition-for-machine-learning/\n* https://www.analyticsvidhya.com/blog/2018/08/dimensionality-reduction-techniques-python/\n* https://medium.com/analytics-vidhya/text-mining-101-a-stepwise-introduction-to-topic-modeling-using-latent-semantic-analysis-using-add9c905efd9\n\n"},{"metadata":{"id":"3U9Bp1h1yg6H","colab_type":"text","_uuid":"43b5dfe0f77fa57ba294355e8f2643a33db6afa0"},"cell_type":"markdown","source":"## Setting up environment"},{"metadata":{"id":"NSSfitlPw9-M","colab_type":"code","colab":{},"trusted":true,"_uuid":"bb14f5cf614ebc70e534a5cfeac7f1dfb8d72bf0"},"cell_type":"code","source":"# Global variables \ndataset_filename = \"../input/Womens Clothing E-Commerce Reviews.csv\"","execution_count":null,"outputs":[]},{"metadata":{"id":"is-ZcycqzAap","colab_type":"code","colab":{},"trusted":true,"_uuid":"1b0eaec5393815b08bc27da70d81a20b78bdbf39"},"cell_type":"code","source":"# Import libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport string\nimport re\nimport numpy as np \nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom scipy.spatial.distance import cosine\nfrom numpy import array\nfrom sklearn.decomposition import TruncatedSVD\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"id":"PP6UvEsvzW7R","colab_type":"code","colab":{},"trusted":true,"_uuid":"8e1c4bdb8ab3068ce3e0f33755f417d465685d0e"},"cell_type":"code","source":"# Loading dataset\ndata = pd.read_csv(dataset_filename, index_col=0)","execution_count":null,"outputs":[]},{"metadata":{"id":"nc0awZvxFPZh","colab_type":"text","_uuid":"de7732276d74fb19d8b8345ebf1924d477230388"},"cell_type":"markdown","source":"# Question 1: Preprocess the corpus of customer reviews dataset"},{"metadata":{"id":"Siy0qO2sBk3A","colab_type":"text","_uuid":"9e269ae86a76cd795fb8b57856150497140cd67f"},"cell_type":"markdown","source":"## Performing Some Basic EDA"},{"metadata":{"id":"v5Z1eGMKzkBH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"0f2a35e5-1c93-4ad5-fe6b-0e017356f17d","trusted":true,"_uuid":"83099c86573257c4b5900cb7fecea1321ae2a323"},"cell_type":"code","source":"# Looking at some of the top rows of dataset\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"ya3ohZQc0crb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"dcbc659c-b5fd-4d56-8958-0e6c61c803aa","trusted":true,"_uuid":"df4e8cca301b5e4a91227d6229b7d890ee33fe3b"},"cell_type":"code","source":"# Description\ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{"id":"13qBvFBT0gTE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"7e7fad02-f885-45e7-e087-dc8b7df535b9","trusted":true,"_uuid":"a53da258d639d8ee5f0ae4e3e0f634e7321248d1"},"cell_type":"code","source":"# Info\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"id":"AcmwI7ycBu36","colab_type":"text","_uuid":"aea644f22c3a2c2e1bdc69c1b33034c1791b6573"},"cell_type":"markdown","source":"## Selecting Clothing ID"},{"metadata":{"id":"j4Tzwf5ZB6oU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"756ca637-cd0a-4000-895b-e1f74e927225","trusted":true,"_uuid":"81da4fd09029389b61389b51d8890745ba07a37a"},"cell_type":"code","source":"# Printing the unique Clothing IDs along with their frequencies\ndata['Clothing ID'].value_counts()[:5]","execution_count":null,"outputs":[]},{"metadata":{"id":"apo_S1SOCd_3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"b7c7f8ab-3ba7-44e4-ffaf-3468617f3478","trusted":true,"_uuid":"5846458eacfd1f8e07983b52da64c0232f27f159"},"cell_type":"code","source":"# From here, we can conclude Clothing ID 1078 as most common. So, we will be using this for the rest of our project\ndatax = data.loc[data['Clothing ID'] == 1078 , :] # We will be calling this data as datax\ndatax.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"ryyWwezQDk2J","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"e0f4947b-b25f-462a-a00a-c44ed0f5a563","trusted":true,"_uuid":"d6ffa8ec3845cf34b6a9ea51f4aca37682faa259"},"cell_type":"code","source":"datax.info()","execution_count":null,"outputs":[]},{"metadata":{"id":"dj7I14CZT6gY","colab_type":"text","_uuid":"173a843fa777566b97c974af017c1c24eb3cf6ea"},"cell_type":"markdown","source":"## Extracting our Text Corpus"},{"metadata":{"id":"3GnMozR1UBv5","colab_type":"code","colab":{},"trusted":true,"_uuid":"093c0251922083c0144830c756cc6d0c49943b00"},"cell_type":"code","source":"corpus = [review for (id,review) in datax['Review Text'].iteritems() if isinstance(review,str)]","execution_count":null,"outputs":[]},{"metadata":{"id":"F9ulboWcyoDF","colab_type":"text","_uuid":"da863e2b27498d8c808e36fd3ef9eea6efd87156"},"cell_type":"markdown","source":"## Creating Review to ID Dictionary"},{"metadata":{"id":"O3nQrW8cy0oK","colab_type":"code","colab":{},"trusted":true,"_uuid":"b995cf831e6e87584164cb99068e7af7ca17a756"},"cell_type":"code","source":"# Creating dictionary of review to id\nreview_to_id_dict = {review : id for (id,review) in enumerate(corpus)}","execution_count":null,"outputs":[]},{"metadata":{"id":"-4WUf-bvF52M","colab_type":"text","_uuid":"6cd82af5a4a7ff68f4e46e983a319c9a22322cbb"},"cell_type":"markdown","source":"## Tokenize"},{"metadata":{"id":"kYHtGQLjGQjx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"6664879e-4a4c-4cb4-8669-f61e0de65f6f","trusted":true,"_uuid":"7d7670d8758003667959717fab6e83d8e3267a6e"},"cell_type":"code","source":"corpus_tokenized = np.array([review.split() for review in corpus])\n\nprint(corpus_tokenized[:5])","execution_count":null,"outputs":[]},{"metadata":{"id":"WAAD_hlyE_nQ","colab_type":"text","_uuid":"75e998b867b982a2ebce479710b4f70460375dbd"},"cell_type":"markdown","source":"# Question 2: Remove stopwords, standardize tokens"},{"metadata":{"id":"Cz0b5MhlUmJu","colab_type":"text","_uuid":"c44329bd699817858cf90065e604d404d08868eb"},"cell_type":"markdown","source":"### Removing All Symbols other than Alphabets and Converting all Letters to Lowercase"},{"metadata":{"id":"xAdiWvwXVYc1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"8db8fb35-4ec0-49f4-98af-a72099d5203f","trusted":true,"_uuid":"a6216770165741c42b0792e48f0db6223698efce"},"cell_type":"code","source":"for i in range(5):\n  print(i, corpus[i])","execution_count":null,"outputs":[]},{"metadata":{"id":"rLKLUIdiUjST","colab_type":"code","colab":{},"trusted":true,"_uuid":"741e46e6d793141c0802649bd96ace9a66a3e60d"},"cell_type":"code","source":"corpus1 = []\n\nfor review in corpus:\n  if isinstance(review,str):\n    review = review.split()\n    review = [re.sub('[^A-Za-z]+', '', x) for x in review]\n    review = [x.lower() for x in review if len(x) > 0]\n    corpus1.append(' '.join(review))","execution_count":null,"outputs":[]},{"metadata":{"id":"JKfAiRKTMwSg","colab_type":"text","_uuid":"b8ddc26aa500a528c45f8db7b0b72bd8c7208226"},"cell_type":"markdown","source":"### Getting Set of Stopwords"},{"metadata":{"id":"QeJl421EFDE9","colab_type":"code","colab":{},"trusted":true,"_uuid":"d649b0c2031db33e286cd4daac24c0a23fef3be3"},"cell_type":"code","source":"# We are using nltk list of stopwords\nstopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you',\n             \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself',\n             'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her',\n             'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them',\n             'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom',\n             'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are',\n             'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had',\n             'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and',\n             'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at',\n             'by', 'for', 'with', 'about', 'against', 'between', 'into',\n             'through', 'during', 'before', 'after', 'above', 'below', 'to',\n             'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under',\n             'again', 'further', 'then', 'once', 'here', 'there', 'when',\n             'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n             'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own',\n             'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will',\n             'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll',\n             'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn',\n             \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\",\n             'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma',\n             'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\",\n             'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\",\n             'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n\n# Extending stopwords with space\nstopwords.append('')\n\n# Converting it to a set\nstopwords = set(stopwords)","execution_count":null,"outputs":[]},{"metadata":{"id":"48_GtYynN-rn","colab_type":"text","_uuid":"7924b08ecd99b8b11834b3da4c54ab4bdef3014b"},"cell_type":"markdown","source":"### Removing Stopwords from Reviews"},{"metadata":{"id":"SICGg-TgOEDB","colab_type":"code","colab":{},"trusted":true,"_uuid":"82cdc52c784a617abaa343fef86c87c8fbbd5a39"},"cell_type":"code","source":"# Removing stopwords and storing it into a new dict\n\ncorpus_sr = [] # Corpus after removing stopwords\n\nfor review in corpus1 :\n  if isinstance(review, str):\n    review = review.split()\n    new_review = []\n    for x in review:\n      if x not in stopwords:\n        new_review.append(x)\n    corpus_sr.append(\" \".join(new_review))","execution_count":null,"outputs":[]},{"metadata":{"id":"D9SJcwIKRors","colab_type":"text","_uuid":"1a3849f9fde684d3494a61fc0b96e061d26e75d4"},"cell_type":"markdown","source":"### Stemming and Lemmatization"},{"metadata":{"id":"cN70P5UcRzHf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"4b0e511f-3a07-4df8-f065-9117c421a3f8","trusted":true,"_uuid":"713a8b30a33eb2dad42e7c508c8addf569779af3"},"cell_type":"code","source":"# Creating a list of all words present in review\nword_list = []\n\nfor review in corpus_sr:\n  word_list.extend(review.split())\n\nword_list = list(set(word_list))\n\nprint(word_list[:10])","execution_count":null,"outputs":[]},{"metadata":{"id":"vN_ORyKpWNp4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"1472a50e-63f1-4bec-be65-870ed5f009da","trusted":true,"_uuid":"13cd8a28ded1507b080daa9597116345a8b812b8"},"cell_type":"code","source":"# Stemming\nimport nltk\nfrom nltk.stem.porter import PorterStemmer\nporter_stemmer = PorterStemmer()\n\ncorpus_stemmed = []\n\nfor review in corpus_sr:\n  review = [porter_stemmer.stem(x) for x in review.split()]\n  corpus_stemmed.append(' '.join(review))\n\nfor i in range(5):\n  print(corpus_sr[i])\n  print(corpus_stemmed[i])","execution_count":null,"outputs":[]},{"metadata":{"id":"YJwXXT6GYYZr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"ed263924-123e-4079-802b-3a4416e38cb6","trusted":true,"_uuid":"4230eb0ebe35e372292ab48c08da817462a7cdd0"},"cell_type":"code","source":"# Lemmatization\nimport nltk\nnltk.download('wordnet')\nfrom nltk.stem import WordNetLemmatizer\nwordnet_lemmatizer = WordNetLemmatizer()\n\ncorpus_lemmatized = []\n\nfor review in corpus_sr:\n  review = [wordnet_lemmatizer.lemmatize(x) for x in review.split()]\n  corpus_lemmatized.append(' '.join(review))\n\nfor i in range(5):\n  print(corpus_sr[i])\n  print(corpus_lemmatized[i])","execution_count":null,"outputs":[]},{"metadata":{"id":"1sO69JV-INOG","colab_type":"text","_uuid":"a2c521db30b2d4b442972db6594035904d4e7a87"},"cell_type":"markdown","source":"## Standardize Tokens"},{"metadata":{"id":"ST3MdLBoIMOB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"c504b9b0-aadf-4481-e984-a7e92ec44c89","trusted":true,"_uuid":"6340d13ad3d772b8f6440f88119a7e488d06091b"},"cell_type":"code","source":"corpus_tokenized = np.array([review.split() for review in corpus_lemmatized])\n\nprint(corpus_tokenized[:5])","execution_count":null,"outputs":[]},{"metadata":{"id":"vPtnvheXZazS","colab_type":"text","_uuid":"4be45033440b7c3a8dc3efbfc4f7ef2b248e2c61"},"cell_type":"markdown","source":"# Question 3: Build the Term-Frequency Inverse-Document-Frequency (TF-IDF) matrix and apply the Latent Semantic Analysis (LSA) method"},{"metadata":{"id":"aeYMp5Lch2hq","colab_type":"text","_uuid":"058539130897bf32cbcb1067bd48f0bc82f8b3c2"},"cell_type":"markdown","source":"### Creating Word List"},{"metadata":{"id":"Lwbt8wQliAlz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"41d31f6a-f260-4282-c42f-c78cbff2eeef","trusted":true,"_uuid":"19bc41ddb99542002bfb830dd6942bdbaf0156ae"},"cell_type":"code","source":"vocabulary = []\nfor review in corpus_lemmatized:\n  vocabulary.extend(review.split())\nvocabulary = list(set(vocabulary))\n\n# Printing some of the first elements of word_list and number of words present in it\nprint(vocabulary[:5])\nprint(len(vocabulary))\n\n# Tokenizing\nword_to_id = {word:id for id,word in enumerate(vocabulary)}\nid_to_word = {id:word for id,word in enumerate(vocabulary)}","execution_count":null,"outputs":[]},{"metadata":{"id":"Z1GfGn6DZhcp","colab_type":"text","_uuid":"a1907f6e41c9365490c891d7cd89b18bd0731ae2"},"cell_type":"markdown","source":"### Document-term matrix"},{"metadata":{"id":"lP7wq7SKhwM8","colab_type":"code","colab":{},"trusted":true,"_uuid":"253656aa9889aa15ad008bc0b430314e87531d51"},"cell_type":"code","source":"m = len(corpus_lemmatized) # m = number of reviews \nn = len(vocabulary) # n = number of unique words\n\ntfm = np.zeros((m, n),dtype=int) # Term frequency matrix\nfor i in range(m):\n  words = corpus_lemmatized[i].split()\n  for j in range(len(words)):\n    word = words[j]\n    tfm[i][word_to_id[word]] += 1 ","execution_count":null,"outputs":[]},{"metadata":{"id":"J68QTlqAoWU_","colab_type":"text","_uuid":"5894cf83d3e5b4d4cb8e2fb37e585afc11d1bef2"},"cell_type":"markdown","source":"### Term frequency inverse document frequency matrix"},{"metadata":{"id":"uUPybZsllkRP","colab_type":"code","colab":{},"trusted":true,"_uuid":"3828b8aa054dfe2bd04891305ee01b53e2c0a598"},"cell_type":"code","source":"tmpm = tfm != 0 # Temporary matrix\ndft = tmpm.sum(axis = 0) #the number of documents where term t appears\ntfidfm = np.multiply(tfm, np.log(m/dft))","execution_count":null,"outputs":[]},{"metadata":{"id":"bfg_V2ZjEB6K","colab_type":"text","_uuid":"995d84a0396c6a385180f9ab44e5eac373ba1531"},"cell_type":"markdown","source":"### Perform ​LSA​ using Singular Value Decomposition (​SVD​). Consider the TF matrix for SVD. You can also perform SVD on the TF-IDF matrix."},{"metadata":{"id":"-JFY6I_XEAvQ","colab_type":"code","colab":{},"trusted":true,"_uuid":"3415bb08433f1b801edb93e8acaa16d9f1c6c923"},"cell_type":"code","source":"U, s, VT = np.linalg.svd(tfm)\n\nK = 2 # number of components\n\ntfm_reduced = np.dot(U[:,:K], np.dot(np.diag(s[:K]), VT[:K, :]))\ndocs_rep = np.dot(tfm, VT[:K, :].T)\nterm_rep = np.dot(tfm.T, U[:,:K])","execution_count":null,"outputs":[]},{"metadata":{"id":"FseHPcSsGRTG","colab_type":"text","_uuid":"e2dfc63325fbd4ccec389e5bdecd6453e1ccd0eb"},"cell_type":"markdown","source":"### Plot documents in the LSA/TF-IDF space"},{"metadata":{"id":"g-oPbgCeFfws","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"5d0e997e-4cac-4780-f9ea-7940bd34adf1","trusted":true,"_uuid":"bd9f19a7bc124f0d7a9f6780f566fde7bf716622"},"cell_type":"code","source":"plt.scatter(docs_rep[:,0], docs_rep[:,1])\nplt.title(\"Document Representation\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"yT-NgwjaA6nG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"ff01cfc6-2a6c-4f2d-e73d-b0a2fa08a1d2","trusted":true,"_uuid":"f7f86d0720ea6257c7cfda1e35d9cf0dcc04f33e"},"cell_type":"code","source":"plt.scatter(term_rep[:,0], term_rep[:,1])\nplt.title(\"Term Representation\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"erlg5cOSGWt-","colab_type":"text","_uuid":"f8ae6fedba335c3b3af659e5088200622953c49f"},"cell_type":"markdown","source":"# Question 4: Compare the performance of Information Retrieval (IR) using both TF-IDF and LSA methods"},{"metadata":{"id":"pdAgoAggJQOg","colab_type":"code","colab":{},"trusted":true,"_uuid":"921f3a9271b0c5af89831d6355d04be588ebcc46"},"cell_type":"code","source":"query = 'nice good'\n\n\nkey_word_indices = []\n\nfor x in query.split():\n  if x in word_to_id.keys():\n    key_word_indices.append(word_to_id[x])","execution_count":null,"outputs":[]},{"metadata":{"id":"uPO3KDalJJOn","colab_type":"text","_uuid":"c46c2e2e11c2c6b137f19fa8405456a1421121b7"},"cell_type":"markdown","source":"## IR using LSA with TF matrix"},{"metadata":{"id":"kx1yoVLoGbeo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"bbf8a355-1f0e-40d0-a8d0-a28573ee4f48","trusted":true,"_uuid":"e57ea0ea17ebdb4131905b9b3edeb3acde5a8865"},"cell_type":"code","source":"key_words_rep = term_rep[key_word_indices,:]     \nquery_rep = np.sum(key_words_rep, axis = 0)\n\nprint (query_rep)","execution_count":null,"outputs":[]},{"metadata":{"id":"KxcIfj_RCQRR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"97056558-d75e-4e52-8c91-fcd3c9d83977","trusted":true,"_uuid":"a6a2dcbcc33130f61010e2ae740c2c56570f3530"},"cell_type":"code","source":"query_doc_cos_dist = [cosine(query_rep, doc_rep) for doc_rep in docs_rep]\nquery_doc_sort_index = np.argsort(np.array(query_doc_cos_dist))\n\nfor rank, sort_index in enumerate(query_doc_sort_index):\n    print (rank, query_doc_cos_dist[sort_index], corpus[sort_index])\n    if rank == 4 : \n      break","execution_count":null,"outputs":[]},{"metadata":{"id":"-58ejZy9J55t","colab_type":"text","_uuid":"d8a8bb79a9b64ddc0e1cb241230acc231ce90b88"},"cell_type":"markdown","source":"## IR using TF-IDF matrix"},{"metadata":{"id":"iTxzai2UKkGb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"962cc708-34ce-4745-c35f-7750ababc38c","trusted":true,"_uuid":"4711ad622de531b1d6f41ed7146080bc3d0d0b55"},"cell_type":"code","source":"query_vector = np.zeros((1,n))\nfor x in key_word_indices:\n  query_vector[0,x] += 1\n  \nquery_vector = np.multiply(query_vector, np.log(m/dft))\n\nquery_doc_cos_dist = [cosine(query_vector, tfidfm[i]) for i in range(m)]\nquery_doc_sort_index = np.argsort(np.array(query_doc_cos_dist))\n\nx = []\n\nfor rank, sort_index in enumerate(query_doc_sort_index):\n    print (rank, query_doc_cos_dist[sort_index], corpus[sort_index])\n    x.append(corpus[sort_index])\n    if rank == 4 : \n      break","execution_count":null,"outputs":[]},{"metadata":{"id":"OTe8INhKNb_K","colab_type":"text","_uuid":"664b1579446e787cab2837e5a93a4f68fe68651a"},"cell_type":"markdown","source":"## Comparision Between LSA and TF-IDF"},{"metadata":{"id":"6VeblC28N-Gv","colab_type":"text","_uuid":"bd3127c293b6d1973063ef421f0b29dbdeee4753"},"cell_type":"markdown","source":"Query : nice good\n\n### Result by LSA with TF matrix\n\n\n*   0 3.906716264934218e-07 I really like this dress. i tried it on in the store and i had to take it home with me. the print is fun and bright and interesting, without being over the top. the grommets give it a little bit of edgy balance to the sweet, flowy shape. a note on the the fit: i am a 12/14 and the 12 fit well. it is a bit loose in some places, like the waist, but it certainly doesn't look like a maternity dress. i think the looseness is a good part of the overall look. i am high-waisted, and the waistline hit\n*   4.924336040046384e-07 I really like the soft, flowy satin fabric and vibrant color of this dress! i am 5'5'' 125lbs, the s was too large, so i ordered the xs instead. things to note: pockets, elastic waistband with nice detailing on the sides, slip underneath, and large flutter sleeves. i think that women with smaller torsos should consider petite sizing.\n*  2.0761380433720333e-06 I didn't hate it, but i don't love it. i purchased it in 2 colors b/c i thought i'd fall in love. it is just ok. maybe it's b/c i have a larger chest, but i felt like it was too small in the chest area and too loose elsewhere. not the maxi fit i normally go for. however, the material is great and it's a simple sunday dress to lounge around in and run errands comfortably.\n* 2.6978156143497856e-06 This is the most flattering dress i have bought in years. the fact that it's machine washable was a huge plus. fabric is so comfortable and the length is perfect! i wear either m or l and went with the large for a little extra room, but either would have fit well.\n* 4.388323377790826e-06 I was lucky enough to get a hold of this intarsia sweater dress after the sale and i wish i had purchased this the first time round. it is absolutely stunning, flattering, comfortable and unique! i am 5'3\" and the regular hem fit me just fine at the ankles. i think this dress runs both tts to a bit large so i would size down if your small framed and stay your usual if your busty or broad shouldered. perfectly complements my taupe booties that i already owned and a my taupe maxi sweater that has\n\n\n### Result by TF-IDF\n* 0.5753370983500936 I love this dress . perfect fit and very good quality.\n* 0.6377201772710546 I bought this dress because i thought it would look good on her, and it does.\n* 0.6633070868863611 This dress really was huge, and not at all flattering. i don't know how they got it to look good on the model in the picture. material was nice and soft, but i really don't see how anyone could look good in this, no matter what your body shape is.\n* 0.7419458491496504 The pattern and fabric on this dress are very nice. there is just too much fabric. it's much too baggy but could make a nice maternity dress. i'll be returning it.\n* 0.7570324564069156 Really cute fun print. nice summer dress..\n\n\n\nFor this example, TF-IDF is giving comparatively better result."}],"metadata":{"colab":{"name":"AI - Project - 3","version":"0.3.2","provenance":[],"collapsed_sections":["3U9Bp1h1yg6H","Siy0qO2sBk3A","AcmwI7ycBu36","F9ulboWcyoDF","WAAD_hlyE_nQ","JKfAiRKTMwSg","D9SJcwIKRors","aeYMp5Lch2hq","Z1GfGn6DZhcp","J68QTlqAoWU_","bfg_V2ZjEB6K","FseHPcSsGRTG","erlg5cOSGWt-"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU","language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}