{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# About this Notebook\n## Author: Seyedsaman Emami\n\n<hr>","metadata":{}},{"cell_type":"markdown","source":"\n<h3> Dataset </h3>\nIn the following notebook, I tried to analyze the attached dataset.\n\n<h3> Classification problem </h3>\nClassification problem\nTo classify the class labels I used the gradient Boosting model from Friedman's work and applied different metrics and evaluation methods to check the model performance.\n\n<h4> Metrics </h4>\nThe metric I used to measure the model performance is the accuracy of the classifier.\nThe followings are the evaluation methods;\n<ol>\n    <li> Accuracy </li>\n    <li> Staged Predict </li>\n    <li> Confusion matrix </li>\n</ol>\n\n<h3>splitting method</h3>\nK-Fold cross validation\n\n</br>\n\n<img src=\"https://cdn.mdedge.com/files/s3fs-public/Image/August-2018/pills_520225198_web.jpg\" alt=\"Travel\" width=\"500\" height=\"600\">\n\n<hr>\nI tried to explain each cell in a markdown cell above.\n\n\n<h5>If you are interested in this problem and detailed analysis, you can copy this Notebook as follows</h5>\n\n<img src=\"https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F1101107%2F8187a9b84c9dde4921900f794c6c6ff9%2FScreenshot%202020-06-28%20at%201.51.53%20AM.png?generation=1593289404499991&alt=media\" alt=\"Copyandedit\" width=\"300\" height=\"300\" class=\"center\">","metadata":{}},{"cell_type":"markdown","source":"# Table of Contents\n* [Importing Libs](#lib)\n* [Exploring dataset](#dataset)\n* [Feature engineering](#Feature_engineering)\n* [Modeling](#modeling)\n","metadata":{}},{"cell_type":"markdown","source":"<a id=’lib’></a>\n# Import Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nwarnings.simplefilter(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2021-09-06T17:01:23.079759Z","iopub.execute_input":"2021-09-06T17:01:23.080112Z","iopub.status.idle":"2021-09-06T17:01:23.085131Z","shell.execute_reply.started":"2021-09-06T17:01:23.080077Z","shell.execute_reply":"2021-09-06T17:01:23.084374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='dataset'> </a>\n# 1. Dataset","metadata":{}},{"cell_type":"markdown","source":"## 1.1. Importing the dataset","metadata":{}},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        data = pd.read_csv(os.path.join(dirname, filename))\ndata.head()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-06T16:19:01.563442Z","iopub.execute_input":"2021-09-06T16:19:01.563958Z","iopub.status.idle":"2021-09-06T16:19:01.588819Z","shell.execute_reply.started":"2021-09-06T16:19:01.56392Z","shell.execute_reply":"2021-09-06T16:19:01.587785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.2. Data info","metadata":{}},{"cell_type":"code","source":"df = data.copy()\ndata.describe().T.style.bar()","metadata":{"execution":{"iopub.status.busy":"2021-09-06T16:19:23.484828Z","iopub.execute_input":"2021-09-06T16:19:23.485182Z","iopub.status.idle":"2021-09-06T16:19:23.515952Z","shell.execute_reply.started":"2021-09-06T16:19:23.485146Z","shell.execute_reply":"2021-09-06T16:19:23.515031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2021-09-06T16:19:25.206662Z","iopub.execute_input":"2021-09-06T16:19:25.207141Z","iopub.status.idle":"2021-09-06T16:19:25.220546Z","shell.execute_reply.started":"2021-09-06T16:19:25.207107Z","shell.execute_reply":"2021-09-06T16:19:25.219538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('We have', data.shape[0], 'Rows and', data.shape[1], 'features')","metadata":{"execution":{"iopub.status.busy":"2021-09-06T16:19:25.494682Z","iopub.execute_input":"2021-09-06T16:19:25.49519Z","iopub.status.idle":"2021-09-06T16:19:25.500511Z","shell.execute_reply.started":"2021-09-06T16:19:25.495159Z","shell.execute_reply":"2021-09-06T16:19:25.499667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.columns","metadata":{"execution":{"iopub.status.busy":"2021-09-06T16:19:25.728724Z","iopub.execute_input":"2021-09-06T16:19:25.729079Z","iopub.status.idle":"2021-09-06T16:19:25.734382Z","shell.execute_reply.started":"2021-09-06T16:19:25.729039Z","shell.execute_reply":"2021-09-06T16:19:25.733706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.3. Check the missing values","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(23, 3))\nsns.heatmap(data.isnull(), yticklabels=False, cbar=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-06T16:19:26.072629Z","iopub.execute_input":"2021-09-06T16:19:26.072968Z","iopub.status.idle":"2021-09-06T16:19:26.293566Z","shell.execute_reply.started":"2021-09-06T16:19:26.072936Z","shell.execute_reply":"2021-09-06T16:19:26.292509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Hopefully, there is no Null value in the mentioned dataset.","metadata":{}},{"cell_type":"markdown","source":"<a id='Feature_engineering' > </a>\n# 2. Feature engineering ","metadata":{}},{"cell_type":"markdown","source":"## 2.1. Identifying datatype","metadata":{}},{"cell_type":"markdown","source":"<h4> Returning the numeric features </h4>","metadata":{}},{"cell_type":"code","source":"num_col = data._get_numeric_data().columns.tolist()\nprint('numeric features:', num_col)","metadata":{"execution":{"iopub.status.busy":"2021-09-06T16:19:27.077657Z","iopub.execute_input":"2021-09-06T16:19:27.078005Z","iopub.status.idle":"2021-09-06T16:19:27.083973Z","shell.execute_reply.started":"2021-09-06T16:19:27.077973Z","shell.execute_reply":"2021-09-06T16:19:27.082833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h4> Returning the categorical features </h4>","metadata":{}},{"cell_type":"code","source":"cat_col = set(data.columns) - set(num_col)\nprint('categorical features:',cat_col)","metadata":{"execution":{"iopub.status.busy":"2021-09-06T16:19:27.807732Z","iopub.execute_input":"2021-09-06T16:19:27.808052Z","iopub.status.idle":"2021-09-06T16:19:27.81308Z","shell.execute_reply.started":"2021-09-06T16:19:27.808027Z","shell.execute_reply":"2021-09-06T16:19:27.812241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.2. One hot encoding\n<h4>Converting categorical features and class labels</h4>","metadata":{}},{"cell_type":"code","source":"for i in cat_col:\n    le = LabelEncoder()\n    n = str(i) + '_n'\n    df[n] = le.fit_transform(df[i])\n    del df[i]\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-06T16:19:41.279794Z","iopub.execute_input":"2021-09-06T16:19:41.280135Z","iopub.status.idle":"2021-09-06T16:19:41.296927Z","shell.execute_reply.started":"2021-09-06T16:19:41.280106Z","shell.execute_reply":"2021-09-06T16:19:41.295759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 5))\nfor i, j in enumerate(df.keys()):\n    plt.subplot(2, 2+1, i+1)\n    plt.boxplot(df[j], 0,'o',showbox=True,\n            showfliers=True, showcaps=True, showmeans=True)\n    plt.title(j + ' - box plot')","metadata":{"execution":{"iopub.status.busy":"2021-09-06T16:45:07.105083Z","iopub.execute_input":"2021-09-06T16:45:07.105613Z","iopub.status.idle":"2021-09-06T16:45:07.649406Z","shell.execute_reply.started":"2021-09-06T16:45:07.105567Z","shell.execute_reply":"2021-09-06T16:45:07.648681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h4> As we can see, the Na_to_K might has outliers, but I will skip the outlier treatment in this notebook </h4>","metadata":{}},{"cell_type":"markdown","source":"<a id='modeling'></a>\n# 3. Modeling","metadata":{}},{"cell_type":"markdown","source":"## 3.1. Introducing the dependant and independent variables","metadata":{}},{"cell_type":"code","source":"X = (df.drop(['Drug_n'], axis=1)).values\ny = (df.Drug_n).values\nclass_n = np.unique(y)\nprint('X shape:', X.shape, 'y shape:', y.shape, 'class labels:', class_n)","metadata":{"execution":{"iopub.status.busy":"2021-09-06T16:36:07.40131Z","iopub.execute_input":"2021-09-06T16:36:07.401676Z","iopub.status.idle":"2021-09-06T16:36:07.409814Z","shell.execute_reply.started":"2021-09-06T16:36:07.401642Z","shell.execute_reply":"2021-09-06T16:36:07.408764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.2. Label histogram","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(20, 3))\nax = plt.axes()\nplt.title('class Distribution')\nsns.histplot(y, kde=True, color='gray')\nplt.xlabel('Drug Type')\nplt.ylabel('Numbers')\nplt.xticks(class_n)\nplt.savefig('hist.jpg', dpi=300)","metadata":{"execution":{"iopub.status.busy":"2021-09-06T16:57:54.861427Z","iopub.execute_input":"2021-09-06T16:57:54.861815Z","iopub.status.idle":"2021-09-06T16:57:55.311358Z","shell.execute_reply.started":"2021-09-06T16:57:54.861777Z","shell.execute_reply":"2021-09-06T16:57:55.310641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.3. Training the model","metadata":{}},{"cell_type":"markdown","source":"<h4>For sampling and splitting the dataset, I used the stratified method to produce the test/train indices to guarantee the same distribution of samples and built ten-folds for training the model.\nMoreover, the random seed is constant for re-producing the same result.\n</h4>","metadata":{}},{"cell_type":"code","source":"y.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-06T17:06:18.543472Z","iopub.execute_input":"2021-09-06T17:06:18.543833Z","iopub.status.idle":"2021-09-06T17:06:18.551905Z","shell.execute_reply.started":"2021-09-06T17:06:18.543802Z","shell.execute_reply":"2021-09-06T17:06:18.550951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"K = 10\nN = 100\n\nerr_mart = np.zeros((K, N))\npred_mart = np.zeros((y.shape[0], 100))\npred_t = np.zeros_like(y)\nacc = []\n\nkfold = StratifiedKFold(n_splits=K, shuffle=True, random_state=1)\n\nfor k, (train_index, test_index) in enumerate(kfold.split(X, y)):\n    x_train, x_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n\n    mart = GradientBoostingClassifier(max_depth=2,\n                                      subsample=0.75,\n                                      max_features=\"sqrt\",\n                                      learning_rate=0.025,\n                                      random_state=1,\n                                      n_estimators=100)\n    pipe = Pipeline([(\"scaler\", StandardScaler()), (\"clf\", mart)])\n    pipe.fit(x_train, y_train)\n    pred_t[test_index] = pipe.predict(x_test)\n    acc.append(accuracy_score(y_test, pipe.predict(x_test)))\n    \n    mart.fit(x_train, y_train)\n    \n\n    for i, pred in enumerate(mart.staged_predict(x_test)):\n        pred_mart[test_index, i] = pred","metadata":{"execution":{"iopub.status.busy":"2021-09-06T17:20:11.730685Z","iopub.execute_input":"2021-09-06T17:20:11.731043Z","iopub.status.idle":"2021-09-06T17:20:18.563444Z","shell.execute_reply.started":"2021-09-06T17:20:11.731015Z","shell.execute_reply":"2021-09-06T17:20:18.56261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.4. Evaluation","metadata":{}},{"cell_type":"markdown","source":"### 3.4.1. Model Accuracy","metadata":{}},{"cell_type":"code","source":"print('Model average accuracy is:', '{0:.2f}%'.format(np.mean(acc, axis=0)))","metadata":{"execution":{"iopub.status.busy":"2021-09-06T17:21:39.841947Z","iopub.execute_input":"2021-09-06T17:21:39.84229Z","iopub.status.idle":"2021-09-06T17:21:39.847727Z","shell.execute_reply.started":"2021-09-06T17:21:39.842261Z","shell.execute_reply":"2021-09-06T17:21:39.846616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.4.2. Base learner accuracy\n<h4> Check the performance of each base learner in the ensemble model.\n </h4>","metadata":{}},{"cell_type":"code","source":"test_score_mart = np.empty((100))\nfor i in range(mart.n_estimators_):\n    test_score_mart[i] = accuracy_score(y, pred_mart[:, i])\n\n    \nplt.plot(test_score_mart, '-', label='Accuracy', linewidth=3, color='black')\nplt.xlabel('Boosting Iteration')\nplt.ylabel('accuracy')\nplt.legend(loc=0)\nplt.title('Base learners performance')\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-06T16:57:42.727838Z","iopub.execute_input":"2021-09-06T16:57:42.728333Z","iopub.status.idle":"2021-09-06T16:57:43.098063Z","shell.execute_reply.started":"2021-09-06T16:57:42.728301Z","shell.execute_reply":"2021-09-06T16:57:43.09712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.4.3 loss curve\n<h4> in train loss for each boosting iteration on the in-bag sample. </h4>","metadata":{}},{"cell_type":"code","source":"plt.plot(mart.train_score_, '-', label='Loss', linewidth=3, color='black')\nplt.xlabel('Boosting Iteration')\nplt.ylabel('loss')\nplt.legend(loc=0)\nplt.title('loss curve')\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-06T17:30:50.343156Z","iopub.execute_input":"2021-09-06T17:30:50.343505Z","iopub.status.idle":"2021-09-06T17:30:50.488461Z","shell.execute_reply.started":"2021-09-06T17:30:50.343475Z","shell.execute_reply":"2021-09-06T17:30:50.48756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model performance","metadata":{}},{"cell_type":"code","source":"plt.plot(mart.train_score_, '-', label='Loss', linewidth=3, color='blue')\nplt.plot(test_score_mart, '-', label='Accuracy', linewidth=3, color='red')\nplt.xlabel('Boosting Iteration')\nplt.legend(loc=0)\nplt.title('Model performance')\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-06T17:31:37.191974Z","iopub.execute_input":"2021-09-06T17:31:37.192334Z","iopub.status.idle":"2021-09-06T17:31:37.346637Z","shell.execute_reply.started":"2021-09-06T17:31:37.192298Z","shell.execute_reply":"2021-09-06T17:31:37.345529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.4.4. Confusion Matrix","metadata":{}},{"cell_type":"code","source":"cf = confusion_matrix(y, pred_t)\nsns.heatmap(cf, cmap='PuBu', annot=True, fmt='0.1f')\nplt.xlabel('Predicted values')\nplt.ylabel('True labels')\nplt.title('MART')","metadata":{"execution":{"iopub.status.busy":"2021-09-06T17:24:27.180484Z","iopub.execute_input":"2021-09-06T17:24:27.180849Z","iopub.status.idle":"2021-09-06T17:24:27.486803Z","shell.execute_reply.started":"2021-09-06T17:24:27.180817Z","shell.execute_reply":"2021-09-06T17:24:27.48571Z"},"trusted":true},"execution_count":null,"outputs":[]}]}