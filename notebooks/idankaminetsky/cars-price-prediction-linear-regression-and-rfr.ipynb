{"cells":[{"metadata":{},"cell_type":"markdown","source":"# _Regression notebook_"},{"metadata":{},"cell_type":"markdown","source":"# <ins> A. Task definition and general information </ins> "},{"metadata":{},"cell_type":"markdown","source":"## Regression task - Predict Car Selling Price"},{"metadata":{},"cell_type":"markdown","source":"### general knowledge about the dataset:\nThis dataset contains information about used cars listed on www.cardekho.com and published on Kaggle.\n\nThe columns in the given dataset is as follows:\n\n- Car_Name\n- Year (of manufacture)\n- Selling_Price\n- Present_Price\n- Kms_Driven\n- Fuel_Type\n- Seller_Type\n- Transmission\n- Owner"},{"metadata":{},"cell_type":"markdown","source":"# <ins> B. Basic familiarity with the Dataset </ins>"},{"metadata":{},"cell_type":"markdown","source":"### imports"},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import metrics\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error as MAE\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.dummy import DummyRegressor\n\nplt.style.use('seaborn')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/vehicle-dataset-from-cardekho/car data.csv\")\ndf.rename(columns = {'Owner':'Past_Owners'},inplace = True)\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## attributes information"},{"metadata":{},"cell_type":"markdown","source":"<br>\nlet's take a look at the attributes categories:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Basic information about the data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### let's take a look at the numeric attributes histograma:"},{"metadata":{"trusted":true},"cell_type":"code","source":"atttibutes_hist = df[[\"Kms_Driven\", \"Present_Price\", \"Selling_Price\", \"Year\"]].hist(bins=50, figsize=(20,15))\natttibutes_hist","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### let's look at the categorial attributes histograma (as pies):\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(2,2, figsize = (12,12))\n((ax1, ax2), (ax3, ax4)) = ax\n\nlabels = df['Fuel_Type'].value_counts().index.tolist()\nvalues = df['Fuel_Type'].value_counts().tolist()\nax1.pie(x=values, labels=labels, autopct=\"%1.2f%%\", shadow=True, explode=[0, 0.2, 0.2])\nax1.set_title(\"Fuel Type:\", fontdict={'fontsize': 14})\n\nlabels = df['Seller_Type'].value_counts().index.tolist()[:2]\nvalues = df['Seller_Type'].value_counts().tolist()[:2]\nax2.pie(x=values, labels=labels, autopct=\"%1.2f%%\", shadow=True, explode=[0, 0.2])\nax2.set_title(\"Seller Type:\", fontdict={'fontsize': 14})\n\nlabels = df['Transmission'].value_counts().index.tolist()[:2]\nvalues = df['Transmission'].value_counts().tolist()\nax3.pie(x=values, labels=labels, autopct=\"%1.2f%%\", shadow=True, explode=[0, 0.2])\nax3.set_title(\"Transmission:\", fontdict={'fontsize': 14})\n\nlabels = df['Past_Owners'].value_counts().index.tolist()\nvalues = df['Past_Owners'].value_counts().tolist()\nax4.pie(x=values, labels=labels, autopct=\"%1.2f%%\", shadow=True, explode=[0, 0.2, 0.2])\nax4.set_title(\"number of Past Owners:\", fontdict={'fontsize': 20})\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <ins> C. Clean and prepare the data </ins>  "},{"metadata":{},"cell_type":"markdown","source":"### - Unique values\n#### as we can see, in the 'Fuel type' attribute, there is only 2 observation that is uniqe. because it's just one I will remove this observation."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df['Fuel_Type'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[df['Fuel_Type'] != \"CNG\"]\nprint(df['Fuel_Type'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## - Handeling text and categorial attributes\n\n#### first of all, I will use \"get_dummies\" function to \"convert\" every categorial attribute."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_copy = df.copy() # save for later use\ndf = pd.get_dummies(df, columns=['Fuel_Type', 'Seller_Type', 'Transmission'])\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### The year coulmn is not generalize, so I will generate it to Age. this is a better information."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Car_Age']= 2019-df['Year'] # the dataset is from 2019","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### I will drop the names and year columns.\nIt is true that in theory the names can give us a good information, but we have only 300 rows and 98 uniqe names, so, not in this case."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(columns=['Car_Name'], inplace=True)\ndf.drop(columns=['Year'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(data={'features': df.columns})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<br>\n\n# <ins>D. Dig into the DATA - correlations and patterns</ins>"},{"metadata":{},"cell_type":"markdown","source":"## Let's try so uncover some patterns.\n\n#### although linear correlations are not the only correlations we can find, it can gives us a good start. I will use Pearsonâ€™s correlation coefficient in the next matrixes.\n\n### Correlation Matrix:"},{"metadata":{"trusted":true},"cell_type":"code","source":"cmap = sns.diverging_palette(30, 230, 90, 20, as_cmap=True)\nfig, ax = plt.subplots(figsize=(12,12))\nsns.heatmap(df.corr(),annot=True, cmap=cmap)\nsns.set(font_scale=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### high correlations with selling price:"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix = df.corr()\ncorralations = corr_matrix['Selling_Price'].sort_values(ascending = False) \nhigh_corr = (corralations > 0.2)|(corralations < -0.2)\npd.DataFrame(corralations[high_corr])\ncorralations[high_corr].index","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- here we can see the features wich have a significant linear correlation with Selling Price:"},{"metadata":{},"cell_type":"markdown","source":"### heatmap correlations which is greater then -+0.2:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"heatmap of the high correlations with Selling Price:\")\nfig, ax = plt.subplots(figsize=(12,12))\nsns.heatmap(df[corralations[high_corr].index].corr(),annot=True, cmap=cmap)\nsns.set(font_scale=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### categorial features correlations:"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(2, 2, figsize=(15, 15))\nfig.suptitle('categorial features:')\n\nsns.swarmplot(ax=axes[0,0], x=\"Fuel_Type\", y=\"Selling_Price\", data=df_copy)\nsns.swarmplot(ax=axes[0,1], x=\"Seller_Type\", y=\"Selling_Price\", data=df_copy)\nsns.swarmplot(ax=axes[1,0], x=\"Transmission\", y=\"Selling_Price\", data=df_copy)\nsns.swarmplot(ax=axes[1,1], x=\"Past_Owners\", y=\"Selling_Price\", data=df_copy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### numerical features correlations:"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df[['Selling_Price', 'Present_Price', 'Kms_Driven', 'Car_Age']], kind='reg')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### to get a better understanding of the Age affect I will plot it another way:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('This bar plot represents an estimate of central tendency for a Selling-Price with the height of each rectangle and provides some indication of the uncertainty around that estimate price using error bars.')\nfig = plt.figure(figsize=(10,5))\nsns.barplot('Car_Age','Selling_Price',data=df).set_title('Selling Price range by Car Age')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <ins> E. Select a Performance Measure </ins>"},{"metadata":{},"cell_type":"markdown","source":"I will use 2 performance measurements: R2 and MAE.\n\n<br>R2:\nThe coefficient of determination, R2 (\"R squared\"), is the proportion of the variance in the dependent variable that is predictable from the independent variable(s).\n\nIt is a statistic used in the context of statistical models whose main purpose is either the prediction of future outcomes or the testing of hypotheses, on the basis of other related information. It provides a measure of how well observed outcomes are replicated by the model, based on the proportion of total variation of outcomes explained by the model.\n\n( source - https://en.wikipedia.org/wiki/Coefficient_of_determination )\n\nin simple words, R2 is the percentage of the explained variance from the general variance.\n<br>The percentage of explained variance allows us to know how much of the variance of the dependent variable is explained by the independent variables.<br>\nThe higher the percentage of explained variance, the more it means that X helps us predict Y."},{"metadata":{},"cell_type":"markdown","source":"MAE:\n\nfrom these 3 metrics:\n- MAE is the easiest to understand, because it's the average error.\n- MSE is more popular than MAE, because MSE \"punishes\" larger errors, which tends to be useful in the real world.\n- RMSE is even more popular than MSE, because RMSE is interpretable in the \"y\" units.\nAll of these are loss functions, because we want to minimize them.\n\nI chose MAE because it gives a basic, simple-to-understand assessment of the error that the model has."},{"metadata":{},"cell_type":"markdown","source":"# <ins> F. Test Set and Train Test + Scaling</ins>"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop(columns=['Selling_Price'])\nY = df['Selling_Price']\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- I will scale the data in 2 ways To see if there are significant differences×¥\n### scaling the numerical features with StandardScaler and MinMax functions:"},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler_standard = StandardScaler()\nscaler_MinMax = MinMaxScaler()\n\nX_train_standardized = X_train.copy()\nX_test_standardized = X_test.copy()\nX_train_normalized = X_train.copy()\nX_test_normalized = X_test.copy()\n\nnumerical_features = ['Present_Price', 'Kms_Driven', 'Past_Owners', 'Car_Age']\n\n# Standardization:\nscaler_standard.fit(X_train[numerical_features])\nX_train_standardized[numerical_features] = scaler_standard.transform(X_train_standardized[numerical_features])\n\n# the scaling is with the the same fitted scaler (by the train data)\nX_test_standardized[numerical_features] = scaler_standard.transform(X_test_standardized[numerical_features])\n\n# Normalization:\nscaler_MinMax.fit(X_train[numerical_features])\nX_train_normalized[numerical_features] = scaler_MinMax.transform(X_train_normalized[numerical_features])\n\n# the scaling is with the the same fitted scaler (by the train data)\nX_test_normalized[numerical_features] = scaler_MinMax.transform(X_test_normalized[numerical_features])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('note: the mean is 0 and std is 1')\nX_train_standardized.describe()[numerical_features].iloc[[1, 2]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('note: the min is 0 and max is 1')\nindexes = [False, False, False, True, False, False, False, True]\nX_train_normalized.describe()[numerical_features].iloc[indexes]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Now we have scaled test set and train set, we can continue to find a good model!\n<br> <br>"},{"metadata":{},"cell_type":"markdown","source":"### but first, let's see the dummy model:"},{"metadata":{"trusted":true},"cell_type":"code","source":"dummy_regr = DummyRegressor(strategy=\"mean\")\ndummy_regr.fit(X_train, y_train)\nR2_score = dummy_regr.score(X_test, y_test)\ny_predict = dummy_regr.predict(X_test)\nmae = MAE(y_test, y_predict)\nprint('The dummy model have a R2 score of ' + str(R2_score)[:6] + \" as expected (around 0), and mean absolute error of \" + str(mae)[:4])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <ins> G. Linear-Regression Model </ins>"},{"metadata":{"trusted":true},"cell_type":"code","source":"LR = LinearRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kf = KFold(n_splits=10, random_state=42, shuffle=True)\n\nR2_scores_standardized = cross_val_score(LR, X_train_standardized, y_train, cv=kf)\ny_predict_standardized = cross_val_predict(LR, X_train_standardized, y_train, cv=kf)\nmae_standarsized = MAE(y_train, y_predict_standardized)\n\nR2_scores_normalized = cross_val_score(LR, X_train_normalized, y_train, cv=kf)\ny_predict_normalized = cross_val_predict(LR, X_train_normalized, y_train, cv=kf)\nmae_normalized = MAE(y_train, y_predict_normalized)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1,2)\n((ax1, ax2)) = axes\n\ny_predicted = cross_val_predict(LR, X_train_standardized, y_train, cv=kf)\nax1.scatter(y_train, y_predicted, alpha=0.3, color='orange')\nax1.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'k--', lw=4)\nax1.set_xlabel('Actual')\nax1.set_ylabel('Predicted')\nax1.set_title('standardized:')\n\ny_predicted = cross_val_predict(LR, X_train_normalized, y_train, cv=kf)\nax2.scatter(y_train, y_predicted, alpha=0.3, color='red')\nax2.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'k--', lw=4)\nax2.set_xlabel('Actual')\nax2.set_ylabel('Predicted')\nax2.set_title('normalized:')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### standadized train set cross validation:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"the scores of cross validation are:\")\nprint(R2_scores_standardized)\nprint()\nprint(\"mean R2 is: \" + str(R2_scores_standardized.mean())[:5] + \" with std of  \" + str(R2_scores_standardized.std())[:5] + \" and MAE of \" + str(mae_standarsized)[:6])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### normalized train set cross validation:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"the scores of cross validation are:\")\nprint(R2_scores_normalized)\nprint()\nprint(\"mean R2 is: \" + str(R2_scores_normalized.mean())[:5] + \" with std of  \" + str(R2_scores_normalized.std())[:5] + \" and MAE of \" + str(mae_normalized)[:6])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- this is preaty good, but I think that I can improve that with a creating new features!\n- note: it looks like the scaling method isn't matter, I will check that later also. but you can see below that the values of the features are different."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_normalized","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_standardized","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### I will make new featurs to use the data more efficiently:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# create 3 more features:\ndf['KMs_Per_year'] = df['Kms_Driven']/df['Car_Age']\ndf['Present_Price_Age_ratio'] = df['Present_Price']/df['Car_Age']\ndf['Present_Price_KMs_ratio'] = df['Present_Price']/df['Kms_Driven']\ndf.describe()[['KMs_Per_year', 'Present_Price_Age_ratio', 'Present_Price_KMs_ratio']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix = df.corr()\ncorr_matrix['Selling_Price'].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Present_Price_Age_ratio is very significant.\n- Present_Price_KMs_ratio more significant than KMS alone.\n- KMs_Per_year is more significant than KMS ang Car Age separately."},{"metadata":{},"cell_type":"markdown","source":"##### Let's see those correlations:"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df[['Selling_Price', 'Present_Price_Age_ratio', 'Present_Price_KMs_ratio', 'KMs_Per_year']], kind='reg')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I will repeat the previous steps to include the new features in the train and test sets. \n<br>note: the test and train sets rows will not change because Im using the same random_state. so, the rows will remain the same in each set."},{"metadata":{},"cell_type":"markdown","source":"### Scaling the numerical features (including the new ones) with StandardScaler and MinMax functions:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# test train split\nX = df.drop(columns=['Selling_Price'])\nY = df['Selling_Price']\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 42)\n\n# scaling the numerical features\nscaler_standard = StandardScaler()\nscaler_MinMax = MinMaxScaler()\n\nX_train_standardized = X_train.copy()\nX_test_standardized = X_test.copy()\nX_train_normalized = X_train.copy()\nX_test_normalized = X_test.copy()\n\nnumerical_features = ['Present_Price', 'Kms_Driven', 'Past_Owners', 'Car_Age', 'KMs_Per_year', 'Present_Price_Age_ratio', 'Present_Price_KMs_ratio']\n\n# Standardization:\nscaler_standard.fit(X_train[numerical_features])\nX_train_standardized[numerical_features] = scaler_standard.transform(X_train_standardized[numerical_features])\n\n# the scaling is with the the same fitted scaler (by the train data)\nX_test_standardized[numerical_features] = scaler_standard.transform(X_test_standardized[numerical_features])\n\n# Normalization:\nscaler_MinMax.fit(X_train[numerical_features])\nX_train_normalized[numerical_features] = scaler_MinMax.transform(X_train_normalized[numerical_features])\n\n# the scaling is with the the same fitted scaler (by the train data)\nX_test_normalized[numerical_features] = scaler_MinMax.transform(X_test_normalized[numerical_features])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kf = KFold(n_splits=10, random_state=42, shuffle=True)\n\nR2_standardized = cross_val_score(LR, X_train_standardized, y_train, cv=kf)\ny_predict_standardized = cross_val_predict(LR, X_train_standardized, y_train, cv=kf)\nmae_standarsized = MAE(y_train, y_predict_standardized)\n\nprint('standartize:')\nprint('R2 score: ' + str(R2_standardized.mean())[:6])\nprint('R2 std: ' + str(R2_standardized.std())[:6])\nprint('MAE: ' + str(mae_standarsized)[:6])\n\nprint()\n\nR2_normalized = cross_val_score(LR, X_train_normalized, y_train, cv=kf)\ny_predict_normalized = cross_val_predict(LR, X_train_standardized, y_train, cv=kf)\nmae_normalized = MAE(y_train, y_predict_normalized)\n\nprint('normalize: ')\nprint('R2 score: ' + str(R2_normalized.mean())[:6])\nprint('R2 std: ' + str(R2_normalized.std())[:6])\nprint('MAE: ' + str(mae_normalized)[:6])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### This is a big improvment!\nnote that the results are still the same, it seems that normalization and standatization have the same affect on linear regression models.\n<br>I will use only one of them the next step.\n\n<br> I will try to increase the R2 with feature selection. \n\n\n"},{"metadata":{},"cell_type":"markdown","source":"## feature selection:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# I will use this function for make a copy of\n# train set by specific correlation limit.\n\n# copy X with columns which grater than specific limit:\ndef copy_by_corr_limit(X, lim, limits):\n    X_copy = X.copy()\n    s = (limits < lim)\n    X_copy = X_copy[X_copy.columns[~s]]\n    return X_copy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('I will use the next list to select features by correlations')\nprint('correlations (without the sign+-):')\ncorrelations = abs(corr_matrix['Selling_Price']).sort_values(ascending=False)\ncorrelations.drop('Selling_Price', inplace=True)\ncorrelations","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_limits = [0, 0.03, 0.09, 0.25, 0.35, 0.40, 0.55, 0.552, 0.555, 0.9]\n\nmean_scores = []\nstd_scores = []\nmae_scores = []\n\nfor limit in corr_limits:\n    X_train_copy = copy_by_corr_limit(X_train_standardized, limit, correlations)\n    R2_scores = cross_val_score(LR, X_train_copy, y_train, cv=kf)\n    y_predict = cross_val_predict(LR, X_train_copy, y_train, cv=kf)\n    mae_score = MAE(y_train, y_predict)\n\n    \n    mean_scores.append(R2_scores.mean())\n    std_scores.append(R2_scores.std())\n    mae_scores.append(mae_score)\n    \npd.DataFrame(data={'lim correlation:':corr_limits, 'R2_score': mean_scores, 'R2_std': std_scores, 'MAE score': mae_scores}) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"this is a minority improvment, so it is not significant. that is why I will go with 0.00 correlation limit.\n## Testing our best linear regression model:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_copy = copy_by_corr_limit(X_train_standardized, 0.00, correlations)\nX_test_copy = copy_by_corr_limit(X_test_standardized, 0.00, correlations)\n\nLR.fit(X_train_copy, y_train)\nR2_score = LR.score(X_test_copy, y_test)\ny_predict = LR.predict(X_test_copy)\nmae_score = MAE(y_test, y_predict)\n\nindexes = list(range(1, len(y_predict)+1))\nfig, axs = plt.subplots(1, 1, figsize=(9, 3), sharey=True)\naxs.plot(indexes, y_predict, label='target_predicted', color='orange')\naxs.plot(indexes, y_test, label='target_value', color='purple')\naxs.legend()\naxs.set_xlabel('targes indexes')\naxs.set_ylabel('Selling Price')\nfig.suptitle('Predicted values VS True Values:')\nplt.show()\n\npd.DataFrame(index=['test LR model'], data={'R2_score': R2_score, 'MAE score': mae_score})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<br>\n<br>\n<br>"},{"metadata":{},"cell_type":"markdown","source":"# H. Random Forest Regressor model "},{"metadata":{"trusted":true},"cell_type":"code","source":"RFR = RandomForestRegressor()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kf = KFold(n_splits=10, random_state=42, shuffle=True)\n\nR2_scores_standardized = cross_val_score(RFR, X_train_standardized, y_train, cv=kf)\ny_predict_standardized = cross_val_predict(RFR, X_train_standardized, y_train, cv=kf)\nmae_standarsized = MAE(y_train, y_predict_standardized)\n\nR2_scores_normalized = cross_val_score(RFR, X_train_normalized, y_train, cv=kf)\ny_predict_normalized = cross_val_predict(RFR, X_train_normalized, y_train, cv=kf)\nmae_normalized = MAE(y_train, y_predict_normalized)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1,2)\n((ax1, ax2)) = axes\n\ny_predicted = cross_val_predict(RFR, X_train_standardized, y_train, cv=kf)\nax1.scatter(y_train, y_predicted, alpha=0.3, color='orange')\nax1.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'k--', lw=4)\nax1.set_xlabel('Actual')\nax1.set_ylabel('Predicted')\nax1.set_title('standardized:')\n\ny_predicted = cross_val_predict(RFR, X_train_normalized, y_train, cv=kf)\nax2.scatter(y_train, y_predicted, alpha=0.3, color='red')\nax2.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'k--', lw=4)\nax2.set_xlabel('Actual')\nax2.set_ylabel('Predicted')\nax2.set_title('normalized:')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### standadized train set cross validation:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"the scores of cross validation are:\")\nprint(R2_scores_standardized)\nprint()\nprint(\"mean R2 is: \" + str(R2_scores_standardized.mean())[:5] + \" with std of  \" + str(R2_scores_standardized.std())[:5] + \" and MAE of \" + str(mae_standarsized)[:6])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### normalized train set cross validation:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"the scores of cross validation are:\")\nprint(R2_scores_normalized)\nprint()\nprint(\"mean R2 is: \" + str(R2_scores_normalized.mean())[:5] + \" with std of  \" + str(R2_scores_normalized.std())[:5] + \" and MAE of \" + str(mae_normalized)[:6])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Those are great scores! let's see the score with the test set:"},{"metadata":{},"cell_type":"markdown","source":"### Random Forest Regressor standardized data Test:"},{"metadata":{"trusted":true},"cell_type":"code","source":"RFR = RandomForestRegressor()\n\nRFR.fit(X_train_standardized, y_train)\nR2_score = RFR.score(X_test_standardized, y_test)\ny_predict = RFR.predict(X_test_standardized)\nmae_score = MAE(y_test, y_predict)\n\nindexes = list(range(1, len(y_predict)+1))\nfig, axs = plt.subplots(1, 1, figsize=(9, 3), sharey=True)\naxs.plot(indexes, y_predict, label='target_predicted', color='orange')\naxs.plot(indexes, y_test, label='target_value', color='purple')\naxs.legend()\naxs.set_xlabel('targes indexes')\naxs.set_ylabel('Selling Price')\nfig.suptitle('Predicted values VS True Values:')\nplt.show()\n\npd.DataFrame(index=['test LR model'], data={'R2_score': R2_score, 'MAE score': mae_score}) \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest Regressor normalized data"},{"metadata":{"trusted":true},"cell_type":"code","source":"RFR = RandomForestRegressor()\n\nRFR.fit(X_train_normalized, y_train)\nR2_score = RFR.score(X_test_normalized, y_test)\ny_predict = RFR.predict(X_test_normalized)\nmae_score = MAE(y_test, y_predict)\n\nindexes = list(range(1, len(y_predict)+1))\nfig, axs = plt.subplots(1, 1, figsize=(9, 3), sharey=True)\naxs.plot(indexes, y_predict, label='target_predicted', color='orange')\naxs.plot(indexes, y_test, label='target_value', color='purple')\naxs.legend()\naxs.set_xlabel('targes indexes')\naxs.set_ylabel('Selling Price')\nfig.suptitle('Predicted values VS True Values:')\nplt.show()\n\npd.DataFrame(index=['test LR model'], data={'R2_score': R2_score, 'MAE score': mae_score}) \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### this score is pretty good!\n\n- I will try to increase the R2 and the MAE of the Random Forest Regressor model by choosing the best hyperparams.\n- I will use only the normalized data because it has a better scores.\n\n## Randomized Search:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\n\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4]\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# search across 100 different combinations\nrf_random = RandomizedSearchCV(estimator = RFR, param_distributions = random_grid, n_iter = 100, cv = kf, verbose=2, random_state=42, n_jobs = -1, scoring='r2')\n# Fit the random search model\nrf_random.fit(X_train_normalized, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Massive improvement:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"best R2 score is:\")\nprint(rf_random.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_random.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Testing best Random forest Regressor model:"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = rf_random.best_estimator_\nrf.fit(X_train_normalized, y_train)\n\nR2_score = rf.score(X_test_normalized, y_test)\ny_predict = rf.predict(X_test_normalized)\nmae_score = MAE(y_test, y_predict)\n\nindexes = list(range(1, len(y_predict)+1))\nfig, axs = plt.subplots(1, 1, figsize=(9, 3), sharey=True)\naxs.plot(indexes, y_predict, label='target_predicted', color='orange')\naxs.plot(indexes, y_test, label='target_value', color='purple')\naxs.legend()\naxs.set_xlabel('targes indexes')\naxs.set_ylabel('Selling Price')\nfig.suptitle('Predicted values VS True Values:')\nplt.show()\n\npd.DataFrame(index=['test RFR model'], data={'R2_score': R2_score, 'MAE score': mae_score}) \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Although the high score with the cross validation, the test is not so good.\n#### I will check the feature importances list, and if I can use feature selection to improve the model.\n## feature selection:"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf.feature_importances_\nfeature_imp = pd.Series(rf.feature_importances_,index=X_train_normalized.columns).sort_values(ascending=False)\nprint(\"feature importances list:\")\nfeature_imp","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### check the limits scores:"},{"metadata":{"trusted":true},"cell_type":"code","source":"imp_limits = [0, 0.0001, 0.017, 0.02, 0.03, 0.035, 0.036, 0.037, 0.04, 0.07, 0.08, 0.1, 0.3]\n\nmean_scores = []\nstd_scores = []\nmae_scores = []\n\nfor limit in imp_limits:\n    X_train_copy = copy_by_corr_limit(X_train_normalized, limit, feature_imp)\n    R2_scores = cross_val_score(rf, X_train_copy, y_train, cv=kf)\n    y_predict = cross_val_predict(rf, X_train_copy, y_train, cv=kf)\n    mae_score = MAE(y_train, y_predict)\n\n    mean_scores.append(R2_scores.mean())\n    std_scores.append(R2_scores.std())\n    mae_scores.append(mae_score)\n    \npd.DataFrame(data={'lim importance:':imp_limits, 'R2_score': mean_scores, 'R2_std': std_scores, 'MAE score': mae_scores}) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The best score is without any limit. this is what we did earlier, so it didn't help us as I hoped."},{"metadata":{},"cell_type":"markdown","source":"<br>\n<br>\n\n#### In conclusion:"},{"metadata":{},"cell_type":"markdown","source":"\n# <ins>I. My best model:</ins>"},{"metadata":{},"cell_type":"markdown","source":"### Linear Regression with the params below:"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_random.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The scores are:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_copy = copy_by_corr_limit(X_train_standardized, 0.00, correlations)\nX_test_copy = copy_by_corr_limit(X_test_standardized, 0.00, correlations)\n\nLR.fit(X_train_copy, y_train)\nR2_score = LR.score(X_test_copy, y_test)\ny_predict = LR.predict(X_test_copy)\nmae_score = MAE(y_test, y_predict)\n\nindexes = list(range(1, len(y_predict)+1))\nfig, axs = plt.subplots(1, 1, figsize=(9, 3), sharey=True)\naxs.plot(indexes, y_predict, label='target_predicted', color='orange')\naxs.plot(indexes, y_test, label='target_value', color='purple')\naxs.legend()\naxs.set_xlabel('targes indexes')\naxs.set_ylabel('Selling Price')\nfig.suptitle('Predicted values VS True Values:')\nplt.show()\n\npd.DataFrame(index=['test LR model'], data={'R2_score': R2_score, 'MAE score': mae_score}) \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# This _linear regression_ model has R2 score which is a 10% improvement compared to  top-5 most voted notebooks at kaggle for this DATASET. The main reason is because I added 3 new features.\nyou can check here the most voted notebooks: https://www.kaggle.com/nehalbirla/vehicle-dataset-from-cardekho/code?datasetId=33080&sortBy=voteCount"},{"metadata":{},"cell_type":"markdown","source":"### what can I do better?\n\n- handle outliers.\n- grid search for the RFR model.\n- check more algoritems (more models types)."},{"metadata":{},"cell_type":"markdown","source":"### I would love to get comments, reviews and suggestions for improvement!\nI would especially love to get ideas why there are significant differences between the training (including cross-validation) and the testing with the Random Forest Regressor model."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}