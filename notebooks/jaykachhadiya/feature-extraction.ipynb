{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Why Feature extraction ?**","metadata":{}},{"cell_type":"markdown","source":"* Accuracy improvement\n* overfitting risk reduction\n* speed up training\n* improved data visualization\n* to increase explainability of model","metadata":{}},{"cell_type":"markdown","source":"# **Importing the required libraries**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport time\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Importing the data**","metadata":{}},{"cell_type":"code","source":"data= pd.read_csv(\"../input/mushroom-classification/mushrooms.csv\")\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Missing values**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.heatmap(data.isnull(), yticklabels=False) # no null values in the dataset\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Seperating features (x) and Labels (y)**","metadata":{}},{"cell_type":"code","source":"x= data.drop(columns='class')\ny= data['class']\nx= pd.get_dummies(x, prefix_sep=\"_\")\nx.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Scaling and Encoding**","metadata":{}},{"cell_type":"code","source":"x= StandardScaler().fit_transform(x)\ny= LabelEncoder().fit_transform(y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We will make function to split the data, train model and caluclate the score**","metadata":{}},{"cell_type":"code","source":"def forest_test(x,y):\n    x_train, x_test, y_train, y_test= train_test_split(x,y,test_size=0.3, random_state=101)\n    start= time.process_time()\n    clf= RandomForestClassifier(n_estimators=700).fit(x_train, y_train)\n    print(time.process_time()-start)\n    pred= clf.predict(x_test)\n    print(confusion_matrix(y_test, pred))\n    print(classification_report(y_test, pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"forest_test(x,y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **model gives 100% accuracy if we use all the features**","metadata":{}},{"cell_type":"markdown","source":"# **Feature extraction**","metadata":{}},{"cell_type":"markdown","source":"# Principal Component Analysis (PCA)","metadata":{}},{"cell_type":"markdown","source":"# it is a most widely used linear dimensionality reduction technique. \n# In PCA we will input the oroiginal features and try to find the combination of features best summarise the original featuresa\n","metadata":{}},{"cell_type":"markdown","source":"# **1. we will reduce the dataset into only two features**","metadata":{}},{"cell_type":"code","source":"from sklearn.decomposition import PCA\n\npca= PCA(n_components=2)\nx_pca_2= pca.fit_transform(x)\npca_df= pd.DataFrame(data=x_pca_2, columns=[\"PC1\", 'PC2'])\npca_df= pd.concat([pca_df, data['class']], axis=1)\npca_df['class']= LabelEncoder().fit_transform(pca_df['class'])\npca_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8,8), dpi=80, facecolor='w', edgecolor='k')\n\nclasses= [1,0]\ncolors= ['r', 'b']\nfor clas, color in zip(classes, colors):\n    plt.scatter(pca_df.loc[pca_df['class'] == clas, 'PC1'],\n               pca_df.loc[pca_df['class'] == clas, 'PC2'],\n               c= color)\n\nplt.xlabel('principal component 1', fontsize= 12)\nplt.ylabel('principal component 2', fontsize= 12)\nplt.title('2D PCA', fontsize= 15)\nplt.legend(['Poisonous', 'Edible'])\nplt.grid()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"forest_test(x_pca_2, y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **we got 95% score by using just 2 features**","metadata":{}},{"cell_type":"markdown","source":"# **3 Features PCA**","metadata":{}},{"cell_type":"code","source":"pca= PCA(n_components=3, svd_solver='full')\nx_pca= pca.fit_transform(x)\nprint(pca.explained_variance_)\n\nforest_test(x_pca, y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\npca_df= pd.DataFrame(data=x_pca, columns=[\"PC1\", 'PC2', 'PC3'])\ndf = pd.concat([pca_df, data['class']], axis=1)\nfig = px.scatter_3d(df, x='PC1', y='PC2', z='PC3',\n              color='class',labels= ['Poisonous', 'edible'])\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **We got 98% by using 3 features**","metadata":{}},{"cell_type":"code","source":"from itertools import product\n\nX_Reduced, X_Test_Reduced, Y_Reduced, Y_Test_Reduced = train_test_split(x_pca_2, y, \n                                                                        test_size = 0.30, \n                                                                        random_state = 101)\ntrainedforest = RandomForestClassifier(n_estimators=700).fit(X_Reduced,Y_Reduced)\n\nx_min, x_max = X_Reduced[:, 0].min() - 1, X_Reduced[:, 0].max() + 1\ny_min, y_max = X_Reduced[:, 1].min() - 1, X_Reduced[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1), np.arange(y_min, y_max, 0.1))\nZ = trainedforest.predict(np.c_[xx.ravel(), yy.ravel()])\nZ = Z.reshape(xx.shape)\nplt.contourf(xx, yy, Z,cmap=plt.cm.coolwarm, alpha=0.4)\nplt.scatter(X_Reduced[:, 0], X_Reduced[:, 1], c=Y_Reduced, s=20, edgecolor='k')\nplt.xlabel('Principal Component 1', fontsize = 12)\nplt.ylabel('Principal Component 2', fontsize = 12)\nplt.title('Random Forest', fontsize = 15)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Independent Component Analyasis (ICA)**","metadata":{}},{"cell_type":"markdown","source":"**ICA is linear dimensionality reduction method which takes as input data a mixture of independent components and it try to correctly identify each of them.**","metadata":{}},{"cell_type":"code","source":"from sklearn.decomposition import FastICA\n\nica= FastICA(n_components=3)\nx_ica= ica.fit_transform(x)\nforest_test(x_ica, y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Linear Discriminant Analysis (LDA)**","metadata":{}},{"cell_type":"markdown","source":"**LDA is supervised learning dimensionality reduction technique and machine learning classifier**\n1. It maximize the distance between the mean of each class\n2. minimize the spread within the class ","metadata":{}},{"cell_type":"code","source":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n\nlda = LinearDiscriminantAnalysis(n_components=1)\n\n# run an LDA and use it to transform the features\nX_lda = lda.fit(x,y).transform(x)\nprint('Original number of features:', x.shape[1])\nprint('Reduced number of features:', X_lda.shape[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"forest_test(X_lda, y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_Reduced, X_Test_Reduced, Y_Reduced, Y_Test_Reduced = train_test_split(X_lda, y, \n                                                                        test_size = 0.30, \n                                                                        random_state = 101)\n\nstart = time.process_time()\nlda = LinearDiscriminantAnalysis().fit(X_Reduced,Y_Reduced)\nprint(time.process_time() - start)\npredictionlda = lda.predict(X_Test_Reduced)\nprint(confusion_matrix(Y_Test_Reduced,predictionlda))\nprint(classification_report(Y_Test_Reduced,predictionlda))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Locally Linear Embedding**","metadata":{}},{"cell_type":"markdown","source":"it is the dimensionalty reduction method based on manifold learning which is used in case of non lineaer features\n\n","metadata":{}},{"cell_type":"code","source":"from sklearn.manifold import LocallyLinearEmbedding\n\nembedding = LocallyLinearEmbedding(n_components=3, eigen_solver='dense')\nx_lle= embedding.fit_transform(x)\n\nforest_test(x_lle,y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **t-Distributed Stochastic Neighbor Embedding (t-SNE)**","metadata":{}},{"cell_type":"markdown","source":"It is non-linear dimenaionality reduction technique whic is typically used to visualize high dimensional datasets","metadata":{}},{"cell_type":"code","source":"from sklearn.manifold import TSNE\nstart= time.process_time()\ntsne= TSNE(n_components=3, verbose= 1, perplexity=40, n_iter=300)\nx_tsne= tsne.fit_transform(x)\n\nprint(time.process_time()-start)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"forest_test(x_tsne, y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Autoencoders**","metadata":{}},{"cell_type":"markdown","source":"# Autoencoders are family of machine learning algorithms which can be used to reduce the dimensionality of the higher dimensional dataset  ","metadata":{}},{"cell_type":"code","source":"from keras.layers import Input, Dense\nfrom keras.models import Model\n\ninput_layer= Input(shape=(x.shape[1],))\nencoded= Dense(3, activation='relu')(input_layer)\ndecoded= Dense(x.shape[1], activation='softmax')(encoded)\nautoencoder= Model(input_layer, decoded)\nautoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n\nx1, x2, y1, y2= train_test_split(x,x,test_size=0.3, random_state=101)\n\nautoencoder.fit(x1, y1, \n               epochs= 100, \n               batch_size=300, \n               shuffle= True, \n               verbose= 30, \n               validation_data=(x2, y2))\nencoder= Model(input_layer, encoded)\nx_ae= encoder.predict(x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"forest_test(x_ae, y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}