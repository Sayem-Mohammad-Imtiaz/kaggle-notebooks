{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Table of Contents\n\n* [Introduction and objectives](#introduction)\n* [Get familiar with the data](#familiar)\n* [Data preprocessing](#preprocessing) \n    - [Deal with null values](#preprocessing-one)\n    - [Deal with feature dropping](#preprocessing-two)\n    - [Deal with standardization](#preprocessing-three)\n* [Build a machine learning for clustering (KMeans)](#classifier)\n* [Analyzing the models' result](#analyze)\n* [Conclusion](#conclusion)\n\n***Written by:*** *Fakhrul Hasbi*"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"introduction\"></a>\n## Introduction\n\nAs a brief context, the dataset is a collection of customer-level credit card behaviours data recorded in 17 different attributes. The segmentation of customer with similar behaviour might help to create targeted marketing strategy for each clusters necessity and avoid the *one size fits all* strategy.\n\n## Objectives\n\n1. Identify the features as factors of grouping the customers into different clusters.\n2. Predict the appropriate number of classes of clusters that group customers with similar behaviours."},{"metadata":{},"cell_type":"markdown","source":"<a id=\"familiar\"></a>\n## Get familiar with the data "},{"metadata":{},"cell_type":"markdown","source":"*-> **Import necessary** libraries*"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_context('notebook')\nplt.style.use('fivethirtyeight')\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*-> **Read** the csv file*"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/ccdata/CC GENERAL.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*-> **Quick** checking the dataframe*"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"preprocessing\"></a>\n## Data preprocessing "},{"metadata":{},"cell_type":"markdown","source":"<a id=\"preprocessing-one\"></a>\n### Deal with null values "},{"metadata":{},"cell_type":"markdown","source":"*-> **Checking null values.** If exists, then need to be removed.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"# make a heatmap to visualize the missing values\nsns.heatmap(df.isnull(), cbar=False, yticklabels=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop the NaN rows\ndf.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# last checking to make sure that there are no more missing values in features\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"preprocessing-three\"></a>\n### Deal with feature dropping"},{"metadata":{},"cell_type":"markdown","source":"*-> **Drop the CUST_ID** column since it is merely an identification for rows*"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(\"CUST_ID\", axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"preprocessing-five\"></a> \n### Deal with standardization"},{"metadata":{},"cell_type":"markdown","source":"*-> **Rescaling the data** to normalize all of the features unit*"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sc = StandardScaler()\ndf_scaled = pd.DataFrame(data=sc.fit_transform(df), columns=df.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"classifier\"></a>\n## Build a machine learning for clustering (KMeans)"},{"metadata":{},"cell_type":"markdown","source":"*-> We may proceed to **build the model** using machine learning classifier*"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# initialize random number of clusters. Lets' say k=3\nmodel = KMeans(n_clusters=3)\nmodel.fit(df_scaled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check the inertia score\nprint(model.inertia_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# basically, inertia score tells us how far away points within a cluster.Thus intuitively speaking, we aim to minimize the inertia score. Yet, we want for small inertia and small number of clusters.\ninertia_score = []\nfor k in range(1,15):\n    model = KMeans(n_clusters=k)\n    model.fit(df_scaled)\n    inertia_score.append(model.inertia_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot the inertia scores with k=1 to k=10\n# it seems that the elbow position (when its stop decrese significantly, either k=6, k=7 or k=8)\nplt.plot([*range(1,15)], inertia_score, marker='o', markersize=12)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# initialize KMeans model again with k=\nmodel = KMeans(n_clusters=7)\npredicted_labels = model.fit_predict(df_scaled)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"analyze\"></a>\n## Analyzing the models' result "},{"metadata":{},"cell_type":"markdown","source":"*-> **Analyze** the model result. Refer to the comment for further detail.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"# check all of the graphs all at once\nsns.pairplot(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make a new column for data frame: predicted_class\ndf['predicted_class'] = predicted_labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# filter out the features by selecting the best correlated features\ndf_corr = df.drop(\"predicted_class\", axis=1).corr().abs()\nbest_correlated_features = []\nfor col in df_corr.columns:\n    feature = df_corr[col].drop(labels=[col])\n    best = feature[feature == feature.max()].index[0]\n    best_correlated_features.append((col, best))\nbest_correlated_features = set(tuple(sorted(combination)) for combination in best_correlated_features) # filtering duplicate compbination regardless the order","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print all of the best correlated features\nbest_correlated_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# graph all of the best correlated features\nfor (x, y) in best_correlated_features:\n    plt.figure()\n    sns.scatterplot(data=df, x=x, y=y, hue='predicted_class', palette='coolwarm')\n    plt.title(\"{} against {}\".format(x, y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# graph the payment and purchase because more easier to interpret intuitively\nplt.figure()\nsns.scatterplot(data=df, x=\"PAYMENTS\", y=\"PURCHASES\", hue='predicted_class', palette=\"coolwarm\")\nplt.title(\"Payments against Purchases\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print cluster center for classes k=7: df_scaled\ndf_centroids = pd.DataFrame(data=model.cluster_centers_, columns=df.drop(\"predicted_class\", axis=1).columns)\ndf_centroids","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"conclusion\"></a>\n## Conclusion"},{"metadata":{},"cell_type":"markdown","source":"*-> **End of the notebook assignment:** from one of the graph above (payment and purchase) with k=6, shows a group of customers that spend higher in purchase as well as payment, yet still there are only small group of customers within this cluster. The marketing stratgy might be applied to this cluster.*"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}