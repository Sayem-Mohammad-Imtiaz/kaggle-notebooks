{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Lung CT Segmentation","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        #print(os.path.join(dirname, filename))\n        pass\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from nibabel.testing import data_path\nimport os","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load Sample Files","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"example_filename = os.path.join(data_path, '/kaggle/input/covid19-ct-scans/ct_scans/coronacases_org_001.nii')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"example_filename ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef multi_slice_viewer(volume):\n    #remove_keymap_conflicts({'j', 'k'})\n    fig, ax = plt.subplots()\n    ax.volume = volume\n    ax.index = volume.shape[0] // 2\n    ax.imshow(volume[ax.index])\n    fig.canvas.mpl_connect('key_press_event', process_key)\n\ndef process_key(event):\n    fig = event.canvas.figure\n    ax = fig.axes[0]\n    if event.key == 'j':\n        previous_slice(ax)\n    elif event.key == 'k':\n        next_slice(ax)\n    fig.canvas.draw()\n\ndef previous_slice(ax):\n    volume = ax.volume\n    ax.index = (ax.index - 1) % volume.shape[0]  # wrap around using %\n    ax.images[0].set_array(volume[ax.index])\n\ndef next_slice(ax):\n    volume = ax.volume\n    ax.index = (ax.index + 1) % volume.shape[0]\n    ax.images[0].set_array(volume[ax.index])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nibabel as nib","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = nib.load(example_filename)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(20):\n    plt.subplot(5, 5, i + 1)\n\n    plt.imshow(im_fdata[:,:,i])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(20):\n    plt.subplot(5, 5, i + 1)\n\n    plt.imshow(im_fdata[i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_images(images):\n\n    n_ = min(images.shape[0], 20) \n    rows = 4\n    cols = (n_ // 4) + (1 if (n_ % 4) != 0 else 0)\n    figure = plt.figure(figsize=(2*rows, 2*cols))\n    plt.subplots_adjust(0, 0, 1, 1, 0.001, 0.001)\n    for i in range(n_):\n        plt.subplot(cols, rows, i + 1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n        if images.shape[1] == 3:\n           \n            vol = images[i].detach().numpy()\n            img = [[[(1-vol[0,x,y])*vol[1,x,y], (1-vol[0,x,y])*vol[2,x,y], 0] \\\n                            for y in range(vol.shape[2])] \\\n                            for x in range(vol.shape[1])]\n            plt.imshow(img)\n        else: \n            plt.imshow((images[i, 0]*255).int(), cmap= \"gray\")\n\n    return figure","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install medpy\nimport os\nfrom os import listdir\nfrom os.path import isfile, join\nfrom medpy.io import load\nimport cv2\nimport numpy as np\n\ndef LoadLungData(x_shape, y_shape,limit):\n\n\n    image_dir = '/kaggle/input/covid19-ct-scans/ct_scans/'\n    label_dir = '/kaggle/input/covid19-ct-scans/lung_and_infection_mask/'\n\n    images = [f for f in listdir(image_dir) if (\n        isfile(join(image_dir, f)) and f[0] != \".\")]\n\n    out = []\n    count=0\n    for f in images:\n        \n        count+=1\n        if count<limit:\n            #print('Count ',count)\n            #print('Limit ',limit)\n\n            image, _ = load(os.path.join(image_dir, f))\n            label, _ = load(os.path.join(label_dir, f.replace('org_','')\n                                         .replace('org_covid-19-pneumonia-','')\n                                         .replace('covid-19-pneumonia-','')\n                                        .replace('-dcm','')))\n\n            if image.shape[0]!=label.shape[0]:\n               print('File and label with different shapes ',f)\n\n\n            #image=image/255\n\n            try:\n\n                image = reshape(image, new_shape=( x_shape, y_shape,576))\n                #print('Image shape ',image.shape)\n                label = reshape(label, new_shape=( x_shape, y_shape,576)).astype(int)\n            except:\n                print('Error in file ',f)\n                raise\n\n            out.append({\"image\": image, \"seg\": label, \"filename\": f})\n        else:\n            break\n\n \n    print(f\"Processed {len(out)} files, total {sum([x['image'].shape[0] for x in out])} slices\")\n    return np.array(out)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def reshape(image, new_shape):\n  \n    reshaped_image = np.zeros(new_shape)\n\n    print(reshaped_image.shape)\n    print(image.shape)\n    range_0=reshaped_image.shape[0]-image.shape[0]\n    range_1=reshaped_image.shape[1]-image.shape[1]\n    range_2=reshaped_image.shape[2]-image.shape[2]\n    \n    # if ((range_0>=0) and (range_1>=0)) and  (range_2>=0):\n    #reshaped_image[0:image.shape[0],0:image.shape[1],0:image.shape[2]]+=image\n    for i in range(image.shape[2]):\n        \n        reshaped_image[:,:,i]=cv2.resize(image[:,:,i], ( 64, 64))\n    reshaped_image=reshaped_image.transpose(2,1,0)\n    print('Image reshaped ',reshaped_image.shape)\n    # else:\n    #   raise Exception(\"Invalid file shape\")\n       \n        \n    return reshaped_image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# out=LoadLungData(64, 64,100)\n# print(out.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# out.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# import matplotlib.pyplot as plt\n# im_fdata=img.get_fdata()\n\n\n\n\n# plt.figure(figsize=(10,8))\n\n# # Iterate and plot random images\n# for i in range(20):\n#     plt.subplot(5, 5, i + 1)\n\n#     plt.imshow(out[0]['image'][i,:,:])\n#     plt.axis('off')\n    \n# # Adjust subplot parameters to give specified padding\n# plt.tight_layout()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# import matplotlib.pyplot as plt\n# im_fdata=img.get_fdata()\n\n\n\n\n# plt.figure(figsize=(10,8))\n\n# # Iterate and plot random images\n# for i in range(20):\n#     plt.subplot(5, 5, i + 1)\n\n#     plt.imshow(out[0]['seg'][i,:,:])\n#     value=out[0]['seg'][i,:,:]>0\n#     print(value)\n#     plt.axis('off')\n    \n# # Adjust subplot parameters to give specified padding\n# plt.tight_layout()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# import matplotlib.pyplot as plt\n# im_fdata=img.get_fdata()\n\n\n\n\n# plt.figure(figsize=(10,8))\n\n# # Iterate and plot random images\n# for i in range(20):\n#     plt.subplot(5, 5, i + 1)\n\n#     plt.imshow(out[0]['image'][:,:,i])\n#     plt.axis('off')\n    \n# # Adjust subplot parameters to give specified padding\n# plt.tight_layout()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# import matplotlib.pyplot as plt\n# im_fdata=img.get_fdata()\n\n\n\n\n# plt.figure(figsize=(10,8))\n\n# # Iterate and plot random images\n# for i in range(10,35):\n#     plt.subplot(5, 5, i + 1-10)\n\n#     plt.imshow(out[0]['seg'][:,:,i])\n#     plt.axis('off')\n    \n# # Adjust subplot parameters to give specified padding\n# plt.tight_layout()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# keys = range(len(out))\n# split = dict()\n# size=len(out)\n# split_1=int(size*0.7)\n# split_2=int(size*0.7)+int(size*0.2)\n# split['train']=range(0,split_1)\n# split['test']=range(split_1,split_2)\n# split['val']=range(split_2,size)\n# print('len val',len(split['val']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport time\n\nimport numpy as np\nimport torch\nimport torch.optim as optim\nimport torch.nn.functional as F\n\nfrom torch.utils.data import DataLoader\nfrom torch.utils.tensorboard import SummaryWriter","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_epochs =10\ntime_start = \"\"\ntime_end = \"\"\nepoch = 0\n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import torch\n# from torch.utils.data import Dataset\n\n\n# class SlicesDataset(Dataset):\n\n#     def __init__(self, data):\n#         self.data = data\n\n#         self.slices = []\n\n#         for i, d in enumerate(data):\n#             print(d[\"image\"].shape[0])\n#             for j in range(d[\"image\"].shape[0]):\n#                 self.slices.append((i, j))\n#         print('Len slices ',len(self.slices))\n\n#     def __getitem__(self, idx):\n\n#         slc = self.slices[idx]\n#         sample = dict()\n#         sample[\"id\"] = idx\n\n\n#         i,j=slc\n        \n#         #print('i ',i)\n#         #print('j ',j)\n    \n#         import numpy as np\n\n#         image_=self.data[i]['image']\n#         label_=self.data[i]['seg']\n#         image=image_[j,:,:]\n#         #print('Slice shape ',image.shape)\n#         print('1',image.shape)\n#         image=image.reshape(1,image.shape[0],image.shape[1])\n#         print('2',image.shape)\n#         label=label_[j,:,:]\n#         label=label.reshape(1,label.shape[0],label.shape[1])\n   \n#         sample['image']=torch.tensor(image)#\n#         sample['seg']=torch.tensor(label)#\n\n#         return sample\n\n#     def __len__(self):\n   \n#         return len(self.slices)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\nimport matplotlib\nfrom matplotlib import pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\nfrom nilearn.surface import surface\nfrom nilearn.plotting import show","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_loader = DataLoader(SlicesDataset(out[split[\"train\"]]),\n#                 batch_size=20, shuffle=True, num_workers=0)\n# val_loader = DataLoader(SlicesDataset(out[split[\"val\"]]),\n#                 batch_size=20, shuffle=True, num_workers=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_data = out[split[\"test\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model(inp_shape, k_size=3):\n    merge_axis = -1 # Feature maps are concatenated along last axis (for tf backend)\n    data = Input(shape=inp_shape)\n    conv1 = Convolution3D(padding='same', filters=32, kernel_size=k_size)(data)\n    conv1 = BatchNormalization()(conv1)\n    conv1 = Activation('relu')(conv1)\n    conv2 = Convolution3D(padding='same', filters=32, kernel_size=k_size)(conv1)\n    conv2 = BatchNormalization()(conv2)\n    conv2 = Activation('relu')(conv2)\n    pool1 = MaxPooling3D(pool_size=(2, 2, 2))(conv2)\n\n    conv3 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(pool1)\n    conv3 = BatchNormalization()(conv3)\n    conv3 = Activation('relu')(conv3)\n    conv4 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(conv3)\n    conv4 = BatchNormalization()(conv4)\n    conv4 = Activation('relu')(conv4)\n    pool2 = MaxPooling3D(pool_size=(2, 2, 2))(conv4)\n\n    conv5 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(pool2)\n    conv5 = BatchNormalization()(conv5)\n    conv5 = Activation('relu')(conv5)\n    conv6 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(conv5)\n    conv6 = BatchNormalization()(conv6)\n    conv6 = Activation('relu')(conv6)\n    pool3 = MaxPooling3D(pool_size=(2, 2, 2))(conv6)\n\n    conv7 = Convolution3D(padding='same', filters=128, kernel_size=k_size)(pool3)\n    conv7 = BatchNormalization()(conv7)\n    conv7 = Activation('relu')(conv7)\n    conv8 = Convolution3D(padding='same', filters=128, kernel_size=k_size)(conv7)\n    conv8 = BatchNormalization()(conv8)\n    conv8 = Activation('relu')(conv8)\n    pool4 = MaxPooling3D(pool_size=(2, 2, 2))(conv8)\n\n    conv9 = Convolution3D(padding='same', filters=128, kernel_size=k_size)(pool4)\n    conv9 = BatchNormalization()(conv9)\n    conv9 = Activation('relu')(conv9)\n\n    up1 = UpSampling3D(size=(2, 2, 2))(conv9)\n    conv10 = Convolution3D(padding='same', filters=128, kernel_size=k_size)(up1)\n    conv10 = BatchNormalization()(conv10)\n    conv10 = Activation('relu')(conv10)\n    conv11 = Convolution3D(padding='same', filters=128, kernel_size=k_size)(conv10)\n    conv11 = BatchNormalization()(conv11)\n    conv11 = Activation('relu')(conv11)\n    merged1 = concatenate([conv11, conv8], axis=merge_axis)\n    conv12 = Convolution3D(padding='same', filters=128, kernel_size=k_size)(merged1)\n    conv12 = BatchNormalization()(conv12)\n    conv12 = Activation('relu')(conv12)\n\n    up2 = UpSampling3D(size=(2, 2, 2))(conv12)\n    conv13 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(up2)\n    conv13 = BatchNormalization()(conv13)\n    conv13 = Activation('relu')(conv13)\n    conv14 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(conv13)\n    conv14 = BatchNormalization()(conv14)\n    conv14 = Activation('relu')(conv14)\n    merged2 = concatenate([conv14, conv6], axis=merge_axis)\n    conv15 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(merged2)\n    conv15 = BatchNormalization()(conv15)\n    conv15 = Activation('relu')(conv15)\n\n    up3 = UpSampling3D(size=(2, 2, 2))(conv15)\n    conv16 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(up3)\n    conv16 = BatchNormalization()(conv16)\n    conv16 = Activation('relu')(conv16)\n    conv17 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(conv16)\n    conv17 = BatchNormalization()(conv17)\n    conv17 = Activation('relu')(conv17)\n    merged3 = concatenate([conv17, conv4], axis=merge_axis)\n    conv18 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(merged3)\n    conv18 = BatchNormalization()(conv18)\n    conv18 = Activation('relu')(conv18)\n\n    up4 = UpSampling3D(size=(2, 2, 2))(conv18)\n    conv19 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(up4)\n    conv19 = BatchNormalization()(conv19)\n    conv19 = Activation('relu')(conv19)\n    conv20 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(conv19)\n    conv20 = BatchNormalization()(conv20)\n    conv20 = Activation('relu')(conv20)\n    merged4 = concatenate([conv20, conv2], axis=merge_axis)\n    conv21 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(merged4)\n    conv21 = BatchNormalization()(conv21)\n    conv21 = Activation('relu')(conv21)\n\n    conv22 = Convolution3D(padding='same', filters=2, kernel_size=k_size)(conv21)\n    output = Reshape([-1, 2])(conv22)\n    output = Activation('softmax')(output)\n    output = Reshape(inp_shape[:-1] + (2,))(output)\n\n    model = Model(data, output)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# out[0]['image'].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# len(out)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # X=[out[i]['image'] for i in range(len(out))]\n# y=[out[i]['seg'] for i in range(len(out))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X=np.array(X)\n# # y=np.array(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X.shape[1:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import Conv3D, Input, MaxPooling3D, Dropout, concatenate, UpSampling3D\nimport tensorflow as tf\n\ndef Unet3D(inputs,num_classes):\n    x=inputs\n    conv1 = Conv3D(8, 3, activation = 'relu', padding = 'same',data_format=\"channels_last\")(x)\n    conv1 = Conv3D(8, 3, activation = 'relu', padding = 'same')(conv1)\n    pool1 = MaxPooling3D(pool_size=(2, 2, 2))(conv1)\n    conv2 = Conv3D(16, 3, activation = 'relu', padding = 'same')(pool1)\n    conv2 = Conv3D(16, 3, activation = 'relu', padding = 'same')(conv2)\n    pool2 = MaxPooling3D(pool_size=(2, 2, 2))(conv2)\n    conv3 = Conv3D(32, 3, activation = 'relu', padding = 'same')(pool2)\n    conv3 = Conv3D(32, 3, activation = 'relu', padding = 'same')(conv3)\n    pool3 = MaxPooling3D(pool_size=(2, 2, 2))(conv3)\n    conv4 = Conv3D(64, 3, activation = 'relu', padding = 'same')(pool3)\n    conv4 = Conv3D(64, 3, activation = 'relu', padding = 'same')(conv4)\n    drop4 = Dropout(0.5)(conv4)\n    pool4 = MaxPooling3D(pool_size=(2, 2, 2))(drop4)\n\n    conv5 = Conv3D(128, 3, activation = 'relu', padding = 'same')(pool4)\n    conv5 = Conv3D(128, 3, activation = 'relu', padding = 'same')(conv5)\n    drop5 = Dropout(0.5)(conv5)\n\n    up6 = Conv3D(64, 2, activation = 'relu', padding = 'same')(UpSampling3D(size = (2,2,2))(drop5))\n    merge6 = concatenate([drop4,up6],axis=-1)\n    conv6 = Conv3D(64, 3, activation = 'relu', padding = 'same')(merge6)\n    conv6 = Conv3D(64, 3, activation = 'relu', padding = 'same')(conv6)\n\n    up7 = Conv3D(32, 2, activation = 'relu', padding = 'same')(UpSampling3D(size = (2,2,2))(conv6))\n    merge7 = concatenate([conv3,up7],axis=-1)\n    conv7 = Conv3D(32, 3, activation = 'relu', padding = 'same')(merge7)\n    conv7 = Conv3D(32, 3, activation = 'relu', padding = 'same')(conv7)\n\n    up8 = Conv3D(16, 2, activation = 'relu', padding = 'same')(UpSampling3D(size = (2,2,2))(conv7))\n    merge8 = concatenate([conv2,up8],axis=-1)\n    conv8 = Conv3D(16, 3, activation = 'relu', padding = 'same')(merge8)\n    conv8 = Conv3D(16, 3, activation = 'relu', padding = 'same')(conv8)\n\n    up9 = Conv3D(8, 2, activation = 'relu', padding = 'same')(UpSampling3D(size = (2,2,2))(conv8))\n    merge9 = concatenate([conv1,up9],axis=-1)\n    conv9 = Conv3D(8, 3, activation = 'relu', padding = 'same')(merge9)\n    conv9 = Conv3D(8, 3, activation = 'relu', padding = 'same')(conv9)\n    conv10 = Conv3D(1,1, activation = 'sigmoid')(conv9)\n    model = Model(inputs=inputs, outputs = conv10)\n    #model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_loss(y_true,y_pred, loss_type='jaccard', smooth=1.):\n\n    y_true_f = tf.cast(tf.reshape(y_true,[-1]),tf.float32)\n    y_pred_f =tf.cast(tf.reshape(y_pred,[-1]),tf.float32)\n\n    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n\n    if loss_type == 'jaccard':\n        union = tf.reduce_sum(tf.square(y_pred_f)) + tf.reduce_sum(tf.square(y_true_f))\n\n    elif loss_type == 'sorensen':\n        union = tf.reduce_sum(y_pred_f) + tf.reduce_sum(y_true_f)\n\n    else:\n        raise ValueError(\"Unknown `loss_type`: %s\" % loss_type)\n\n    return (1-(2. * intersection + smooth) / (union + smooth))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_coe(y_true,y_pred, loss_type='jaccard', smooth=1.):\n\n    y_true_f = tf.reshape(y_true,[-1])\n    y_pred_f = tf.reshape(y_pred,[-1])\n\n    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n\n    if loss_type == 'jaccard':\n        union = tf.reduce_sum(tf.square(y_pred_f)) + tf.reduce_sum(tf.square(y_true_f))\n\n    elif loss_type == 'sorensen':\n        union = tf.reduce_sum(y_pred_f) + tf.reduce_sum(y_true_f)\n\n    else:\n        raise ValueError(\"Unknown `loss_type`: %s\" % loss_type)\n\n    return (2. * intersection + smooth) / (union + smooth)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\n\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# initial_epoch_of_training=0\n# TRAIN_CLASSIFY_LEARNING_RATE =1e-4\n# OPTIMIZER=tf.keras.optimizers.Adam(lr=TRAIN_CLASSIFY_LEARNING_RATE,epsilon=1e-5)\n\n# INPUT_PATCH_SIZE=(576,64,64, 1)\n# #with tpu_strategy.scope():\n# inputs = tf.keras.Input(shape=(INPUT_PATCH_SIZE), name='CT')\n# Model_3D=Unet3D(inputs,num_classes=3)\n# Model_3D.compile(optimizer=OPTIMIZER, loss=[dice_loss], metrics=['accuracy',dice_coe])\n# Model_3D.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def my_generator(x_train, y_train, batch_size):\n    data_generator = ImageDataGenerator(\n            width_shift_range=0.1,\n            height_shift_range=0.1,\n            rotation_range=10,\n            zoom_range=0.1).flow(x_train, x_train, batch_size)\n    mask_generator = ImageDataGenerator(\n            width_shift_range=0.1,\n            height_shift_range=0.1,\n            rotation_range=10,\n            zoom_range=0.1).flow(y_train, y_train, batch_size)\n    while True:\n        x_batch, _ = data_generator.next()\n        y_batch, _ = mask_generator.next()\n        yield x_batch, y_batch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install nilearn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nilearn.plotting import view_img, glass_brain, plot_anat, plot_epi","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# image_batch, mask_batch = next(my_generator(X, y, 8))\n# fix, ax = plt.subplots(8,2, figsize=(8,20))\n# for i in range(8):\n    \n    \n#     ax[i,0].imshow(image_batch[i,:,:,0])\n#     ax[i,1].imshow(mask_batch[i,:,:,0])\n# plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + K.epsilon()) / (K.sum(y_true_f) + K.sum(y_pred_f) + K.epsilon())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n\nweight_saver = ModelCheckpoint('lung.h5', monitor='val_dice_coef', \n                                              save_best_only=True, save_weights_only=True)\nannealer = LearningRateScheduler(lambda x: 1e-3 * 0.8 ** x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# hist = Model_3D.fit(X, y,\n#                            steps_per_epoch = 20,\n                           \n#                            epochs=10, verbose=2,\n#                            )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# np.array([X[0]]).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# segmented=Model_3D.predict(np.array([X[0]]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# segmented_=segmented[0,:,:,:,0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# segmented_.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import SimpleITK as sitk\n# filtered_image = sitk.GetImageFromArray(segmented_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# filtered_image ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import nibabel as nib\n# import numpy as np\n\n# data = np.arange(4*4*3).reshape(4,4,3)\n\n# new_image = nib.Nifti1Image(segmented_, affine=np.eye(4))\n\n# new_image_ = nib.Nifti1Image(np.array(X[0]), affine=np.eye(4))\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot_anat(new_image)\n  \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# view_img(new_image , new_image_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# nib.save(new_image , '/kaggle/working/segmented.nii')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# nib.save(new_image_ , '/kaggle/working/original.nii')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install medpy\nimport os\nfrom os import listdir\nfrom os.path import isfile, join\nfrom medpy.io import load\nimport cv2\nimport numpy as np\n\ndef LoadLungData(x_shape, y_shape,limit):\n\n\n    image_dir = '/kaggle/input/covid19-ct-scans/ct_scans/'\n    label_dir = '/kaggle/input/covid19-ct-scans/infection_mask/'\n\n    images = [f for f in listdir(image_dir) if (\n        isfile(join(image_dir, f)) and f[0] != \".\")]\n\n    out = []\n    count=0\n    for f in images:\n        \n        count+=1\n        if count<limit:\n            #print('Count ',count)\n            #print('Limit ',limit)\n\n            image, _ = load(os.path.join(image_dir, f))\n            label, _ = load(os.path.join(label_dir, f.replace('org_','')\n                                         .replace('org_covid-19-pneumonia-','')\n                                         .replace('covid-19-pneumonia-','')\n                                        .replace('-dcm','')))\n\n            if image.shape[0]!=label.shape[0]:\n               print('File and label with different shapes ',f)\n\n\n            #image=image/255\n\n            try:\n\n                image = reshape(image, new_shape=( x_shape, y_shape,576))\n                #print('Image shape ',image.shape)\n                label = reshape(label, new_shape=( x_shape, y_shape,576))\n            except:\n                print('Error in file ',f)\n                raise\n\n            out.append({\"image\": image, \"seg\": label, \"filename\": f})\n        else:\n            break\n\n \n    print(f\"Processed {len(out)} files, total {sum([x['image'].shape[0] for x in out])} slices\")\n    return np.array(out)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# out=LoadLungData(64, 64,200)\n# print(out.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# import matplotlib.pyplot as plt\n# im_fdata=img.get_fdata()\n\n\n\n\n# plt.figure(figsize=(10,8))\n\n# # Iterate and plot random images\n# for i in range(30):\n#     plt.subplot(5, 6, i + 1)\n\n#     plt.imshow(out[0]['seg'][i,:,:])\n#     plt.axis('off')\n    \n# # Adjust subplot parameters to give specified padding\n# plt.tight_layout()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X=[out[i]['image'] for i in range(len(out))]\n# y=[out[i]['seg'] for i in range(len(out))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X=np.array(X)\n# y=np.array(y)\n\n# from sklearn.model_selection import train_test_split\n# X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# len(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# len(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# initial_epoch_of_training=0\n# TRAIN_CLASSIFY_LEARNING_RATE =1e-4\n# OPTIMIZER=tf.keras.optimizers.Adam(lr=TRAIN_CLASSIFY_LEARNING_RATE,epsilon=1e-5)\n\n# INPUT_PATCH_SIZE=(576,64,64, 1)\n# with tpu_strategy.scope():\n#     inputs = tf.keras.Input(shape=(INPUT_PATCH_SIZE), name='CT')\n#     Model_3D=Unet3D(inputs,num_classes=3)\n#     Model_3D.compile(optimizer=OPTIMIZER, loss=[dice_loss], metrics=['accuracy',dice_coe])\n#     Model_3D.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# history = Model_3D.fit(X_train, y_train,\n#                            batch_size=2,\n#                            validation_data=(X_test,y_test),\n#                            epochs=50, verbose=2,\n#                            )\n# auc=max(history.history['dice_coe'])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n# df_history=pd.DataFrame.from_dict(history.history)\n# df_history.to_csv('/kaggle/working/singleinput'+'.csv')\n\n# from matplotlib.pyplot import figure\n# figure(num=None, figsize=(10, 10), dpi=80, facecolor='w', edgecolor='k')\n\n# plt.plot(history.history['dice_coe'])\n# plt.plot(history.history['val_dice_coe'])\n# plt.title('Dice score single input')\n# plt.ylabel('loss')\n# plt.xlabel('epoch')\n# plt.legend(['dice', 'val_dice'], loc='upper left')\n# plt.savefig('/kaggle/working/singleinput.png')\n# plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cluster(img):\n            vectorized = img.reshape((-1,4))\n            vectorized = np.float32(vectorized)\n            criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n            K = 4\n            attempts=10\n            ret,label,center=cv2.kmeans(vectorized,K,None,criteria,attempts,cv2.KMEANS_PP_CENTERS)\n            center = np.uint8(center)\n            res = center[label.flatten()]\n            result_image = res.reshape((img.shape))\n            return result_image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import ndimage\nfrom skimage import filters","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from skimage.morphology import disk\n\ndef reshape_cluster2(image, new_shape):\n  \n    reshaped_image = np.zeros(new_shape)\n\n    print(reshaped_image.shape)\n    print(image.shape)\n    range_0=reshaped_image.shape[0]-image.shape[0]\n    range_1=reshaped_image.shape[1]-image.shape[1]\n    range_2=reshaped_image.shape[2]-image.shape[2]\n    \n    # if ((range_0>=0) and (range_1>=0)) and  (range_2>=0):\n    #reshaped_image[0:image.shape[0],0:image.shape[1],0:image.shape[2]]+=image\n    for i in range(image.shape[2]):\n        \n        reshaped_image[:,:,i]=filters.median(cv2.resize(image[:,:,i], ( 64, 64)),disk(1))\n\n    for i in range(reshaped_image.shape[1]):\n        \n        reshaped_image[:,i,:]=filters.median(reshaped_image[:,i,:],disk(1))\n        \n        \n    for i in range(reshaped_image.shape[0]):\n        \n        reshaped_image[i,:,:]=filters.median(reshaped_image[i,:,:],disk(1))\n    reshaped_image=reshaped_image.transpose(2,1,0)\n    print('Image reshaped ',reshaped_image.shape)\n    # else:\n    #   raise Exception(\"Invalid file shape\")\n       \n        \n    return reshaped_image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from skimage.morphology import disk\n\ndef reshape_cluster(image, new_shape):\n  \n    reshaped_image = np.zeros(new_shape)\n\n    print(reshaped_image.shape)\n    print(image.shape)\n    range_0=reshaped_image.shape[0]-image.shape[0]\n    range_1=reshaped_image.shape[1]-image.shape[1]\n    range_2=reshaped_image.shape[2]-image.shape[2]\n    \n    # if ((range_0>=0) and (range_1>=0)) and  (range_2>=0):\n    #reshaped_image[0:image.shape[0],0:image.shape[1],0:image.shape[2]]+=image\n    for i in range(image.shape[2]):\n        \n        reshaped_image[:,:,i]=cluster(cv2.resize(image[:,:,i], ( 64, 64)))\n\n    for i in range(reshaped_image.shape[1]):\n        \n        reshaped_image[:,i,:]=cluster(reshaped_image[:,i,:])\n        \n        \n    for i in range(reshaped_image.shape[0]):\n        \n        reshaped_image[i,:,:]=cluster(reshaped_image[i,:,:])\n    reshaped_image=reshaped_image.transpose(2,1,0)\n    print('Image reshaped ',reshaped_image.shape)\n    # else:\n    #   raise Exception(\"Invalid file shape\")\n       \n        \n    return reshaped_image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from skimage.morphology import disk\n\ndef reshape_cluster_spectral(image, new_shape):\n    \n    \n    import skimage.segmentation as seg\n\n\n\n    reshaped_image = np.zeros(new_shape)\n\n    print(reshaped_image.shape)\n    print(image.shape)\n    range_0=reshaped_image.shape[0]-image.shape[0]\n    range_1=reshaped_image.shape[1]-image.shape[1]\n    range_2=reshaped_image.shape[2]-image.shape[2]\n    \n    # if ((range_0>=0) and (range_1>=0)) and  (range_2>=0):\n    #reshaped_image[0:image.shape[0],0:image.shape[1],0:image.shape[2]]+=image\n    for i in range(image.shape[2]):\n        0\n        reshaped_image[:,:,i]= seg.slic(cv2.resize(image[:,:,i], ( 64, 64)),n_segments=30)\n\n    for i in range(reshaped_image.shape[1]):\n        \n        reshaped_image[:,i,:]= seg.slic(reshaped_image[:,i,:],n_segments=30)\n        \n        \n    for i in range(reshaped_image.shape[0]):\n        \n        reshaped_image[i,:,:]= seg.slic(reshaped_image[i,:,:],n_segments=30)\n    reshaped_image=reshaped_image.transpose(2,1,0)\n    print('Image reshaped ',reshaped_image.shape)\n    # else:\n    #   raise Exception(\"Invalid file shape\")\n       \n        \n    return reshaped_image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install medpy\nimport os\nfrom os import listdir\nfrom os.path import isfile, join\nfrom medpy.io import load\nimport cv2\nimport numpy as np\n\ndef LoadLungMaskData(x_shape, y_shape,limit):\n    \n\n\n\n    image_dir = '/kaggle/input/covid19-ct-scans/lung_and_infection_mask'\n    label_dir = '/kaggle/input/covid19-ct-scans/infection_mask/'\n\n    images = [f for f in listdir(image_dir) if (\n        isfile(join(image_dir, f)) and f[0] != \".\")]\n\n    out = []\n    count=0\n    for f in images:\n        \n        count+=1\n        if count<limit:\n            #print('Count ',count)\n            #print('Limit ',limit)\n\n            image, _ = load(os.path.join(image_dir, f))\n            label, _ = load(os.path.join(label_dir, f.replace('org_','')\n                                         .replace('org_covid-19-pneumonia-','')\n                                         .replace('covid-19-pneumonia-','')\n                                        .replace('-dcm','')))\n\n            if image.shape[0]!=label.shape[0]:\n               print('File and label with different shapes ',f)\n\n\n            #image=image/255\n\n            try:\n\n                image = reshape(image, new_shape=( x_shape, y_shape,576))\n                #print('Image shape ',image.shape)\n                label = reshape(label, new_shape=( x_shape, y_shape,576))\n            except:\n                print('Error in file ',f)\n                raise\n\n            out.append({\"image\": image, \"seg\": label, \"filename\": f})\n        else:\n            break\n\n \n    print(f\"Processed {len(out)} files, total {sum([x['image'].shape[0] for x in out])} slices\")\n    return np.array(out)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install medpy\nimport os\nfrom os import listdir\nfrom os.path import isfile, join\nfrom medpy.io import load\nimport cv2\nimport numpy as np\n\ndef LoadLungDataClusterData(x_shape, y_shape,limit):\n\n\n    image_dir = '/kaggle/input/covid19-ct-scans/lung_and_infection_mask'\n    label_dir = '/kaggle/input/covid19-ct-scans/infection_mask/'\n\n    images = [f for f in listdir(image_dir) if (\n        isfile(join(image_dir, f)) and f[0] != \".\")]\n\n    out = []\n    count=0\n    for f in images:\n        \n        count+=1\n        if count<limit:\n            #print('Count ',count)\n            #print('Limit ',limit)\n\n            image, _ = load(os.path.join(image_dir, f))\n            label, _ = load(os.path.join(label_dir, f.replace('org_','')\n                                         .replace('org_covid-19-pneumonia-','')\n                                         .replace('covid-19-pneumonia-','')\n                                        .replace('-dcm','')))\n\n            if image.shape[0]!=label.shape[0]:\n               print('File and label with different shapes ',f)\n\n\n            #image=image/255\n\n            try:\n\n                image = reshape_cluster(image, new_shape=( x_shape, y_shape,576))\n                #print('Image shape ',image.shape)\n                label = reshape_cluster(label, new_shape=( x_shape, y_shape,576)).astype(int)\n            except:\n                print('Error in file ',f)\n                raise\n\n            out.append({\"image\": image, \"seg\": label, \"filename\": f})\n        else:\n            break\n\n \n    print(f\"Processed {len(out)} files, total {sum([x['image'].shape[0] for x in out])} slices\")\n    return np.array(out)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out=LoadLungData(64, 64,100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out_=LoadLungDataClusterData(64, 64,100)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out__=LoadLungMaskData(64, 64,100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(30):\n    plt.subplot(5, 6, i + 1)\n\n    plt.imshow(out[0]['seg'][i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(40,70,1):\n    plt.subplot(5, 6, i + 1-40)\n\n    plt.imshow(out_[0]['image'][i,:,:]+out[0]['image'][i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(30):\n    plt.subplot(5, 6, i + 1)\n\n    plt.imshow(out__[0]['image'][i,:,:]+out[0]['image'][i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(30):\n    plt.subplot(5, 6, i + 1)\n\n    plt.imshow(out[1]['image'][i,:,:]-out_[1]['image'][i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nX=np.array([out[i]['image'] for i in range(len(out))])\ny=np.array([out[i]['seg'] for i in range(len(out))])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(30):\n    plt.subplot(5, 6, i + 1)\n\n    plt.imshow(y[0][i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(30):\n    plt.subplot(5, 6, i + 1)\n\n    plt.imshow(X[0][i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\ninitial_epoch_of_training=0\nTRAIN_CLASSIFY_LEARNING_RATE =1e-4\nOPTIMIZER=tf.keras.optimizers.Adam(lr=TRAIN_CLASSIFY_LEARNING_RATE,epsilon=1e-5)\n\nINPUT_PATCH_SIZE=(576,64,64, 1)\nwith tpu_strategy.scope():\n    inputs = tf.keras.Input(shape=(INPUT_PATCH_SIZE), name='CT')\n    \n    Model_3D=Unet3D(inputs,num_classes=3)\n    Model_3D.compile(optimizer=OPTIMIZER, loss=[dice_loss], metrics=['accuracy',dice_coe])\n    Model_3D.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# history = Model_3D.fit(X_train, y_train,\n#                            batch_size=2,\n#                            validation_data=(np.array(X_test),np.array(y_test)),\n#                            epochs=50, verbose=2,\n#                            )\n# df_history=pd.DataFrame.from_dict(history.history)\n# df_history.to_csv('/kaggle/working/withoutsoby.csv')\n# from matplotlib.pyplot import figure\n# figure(num=None, figsize=(10, 10), dpi=80, facecolor='w', edgecolor='k')\n\n# plt.plot(history.history['dice_coe'])\n# plt.plot(history.history['val_dice_coe'])\n# plt.title('Dice score multi input')\n# plt.ylabel('loss')\n# plt.xlabel('epoch')\n# plt.legend(['dice', 'val_dice'], loc='upper left')\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Model_3D.load_weights('/kaggle/input/segmentationlung/single.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfor j in range(20):\n\n    segmented=Model_3D.predict(np.array([X[j]]))\n    segmented_=segmented[0,:,:,:,0]\n    print(len(segmented_[segmented_>0]))\n\n    import matplotlib.pyplot as plt\n    im_fdata=img.get_fdata()\n\n\n\n\n    plt.figure(figsize=(10,8))\n\n    # Iterate and plot random images\n    for i in range(0,30):\n        plt.subplot(6, 6, i + 1)\n\n        plt.imshow(segmented_[i,:,:])\n        plt.axis('off')\n\n    # Adjust subplot parameters to give specified padding\n    plt.tight_layout()  \n    plt.show()\n    \n    import nibabel as nib\n    import numpy as np\n\n    data = np.arange(4*4*3).reshape(4,4,3)\n\n    new_image = nib.Nifti1Image(X[1], affine=np.eye(4))\n    nib.save(new_image , '/kaggle/working/infection'+str(j)+'.nii')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}