{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom nltk.tokenize import RegexpTokenizer\nimport nltk\nregex=nltk.RegexpTokenizer(r'\\w+')\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv('../input/train.csv',encoding = \"ISO-8859-1\",low_memory=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['word_count'] = df['tweet'].apply(lambda x: len(str(x).split(\" \"))) ## no of words\ndf[['tweet','word_count']].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['char_count'] = df['tweet'].str.len() ## no of characters\ndf[['tweet','char_count']].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def avg_word(sentence):  \n  words = sentence.split()\n  return (sum(len(word) for word in words)/len(words))  ##avg word length\n\ndf['avg_word'] = df['tweet'].apply(lambda x: avg_word(x))\ndf[['tweet','avg_word']].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.corpus import stopwords    \nstop = stopwords.words('english')\n\ndf['stopwords'] = df['tweet'].apply(lambda x: len([x for x in x.split() if x in stop])) ##counting stopwords\ndf[['tweet','stopwords']].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['hastags'] = df['tweet'].apply(lambda x: len([x for x in x.split() if x.startswith('#')])) ##counting special characters\ndf[['tweet','hastags']].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['numerics'] = df['tweet'].apply(lambda x: len([x for x in x.split() if x.isdigit()])) ##counting numerics\ndf[['tweet','numerics']].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## converting to lower case\ndf['tweet'] = df['tweet'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\ndf['tweet'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## removing punctuations\ndf['tweet'] = df['tweet'].str.replace('[^\\w\\s]','')\ndf['tweet'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.corpus import stopwords ##removing stopwords\nstop = stopwords.words('english')\ndf['tweet'] = df['tweet'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\ndf['tweet'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"freq = pd.Series(' '.join(df['tweet']).split()).value_counts()[:10]  ##couting common word\nfreq","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"freq = list(freq.index)\ndf['tweet'] = df['tweet'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq)) ##common word removal\ndf['tweet'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"freq = pd.Series(' '.join(df['tweet']).split()).value_counts()[-10:] ##finding rare words\nfreq ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"freq = list(freq.index)\ndf['tweet'] = df['tweet'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))  ## rare words removal\ndf['tweet'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from textblob import TextBlob\ndf['tweet'][:5].apply(lambda x: str(TextBlob(x).correct())) ## spelling correction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TextBlob(df['tweet'][1]).words  ## Tokenization","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Lemmatization\nfrom textblob import Word\ndf['tweet'] = df['tweet'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))  \ndf['tweet'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Lemmatization\nfrom textblob import Word\ndf['tweet'] = df['tweet'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))  \ndf['tweet'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## bage of Words\nfrom sklearn.feature_extraction.text import CountVectorizer\nbow = CountVectorizer(max_features=1000, lowercase=True, ngram_range=(1,1),analyzer = \"word\")\ndf_bow = bow.fit_transform(df['tweet'])\ndf_bow","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Sentiment Analysis\ndf['tweet'][:5].apply(lambda x: TextBlob(x).sentiment)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['sentiment'] = df['tweet'].apply(lambda x: TextBlob(x).sentiment[0] )\ndf[['tweet','sentiment']].head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}