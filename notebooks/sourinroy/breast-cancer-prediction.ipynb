{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Breast Cancer Prediction using the Wisconsin Cancer Dataset","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The dataset used is the very popular Wisconsin Cancer dataset. The link to the data is - https://www.kaggle.com/uciml/breast-cancer-wisconsin-data.\nThe data has been licensed under CC BY-NC-SA 4.0. Details about the license can be found at - https://creativecommons.org/licenses/by-nc-sa/4.0/.\n\nThe author of the dataset, in no way endorses this project of mine.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Reading the data","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/breast-cancer-wisconsin-data/data.csv')\n#The data has a column called  'Unnamed: 32' with nothing but NaN values.\ndf.drop(['Unnamed: 32'], axis = 1, inplace = True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Performing preliminary EDA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.isnull().sum().sum())\nprint(df.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The data has 569 rows of patient data with 32 features. The data also has no missing values.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Identifying target variable and encoding it to support Classification.\nThe target variable is the 'diagnosis' column which classifies the cancerous tumour as Malignant(M) or Benign(B). Malignant tumours are cancerous whereas Benign aren't. \n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['diagnosis'].replace({'B' : 0, 'M' : 1}, inplace = True)\ndf['diagnosis'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Splitting the data into train and test set.\n\nThe test set is for final check of the accuracy metric used. Validation of the data will be done on the test data itself using cross validation.  ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Allocating 69 rows to the test data and rest to the train data. \ndf_train = df.iloc[:500]\ndf_test = df.iloc[500:]\n\n# Re-indexing of the test data\ndf_test.reset_index(inplace = True)\ndf_test.drop('index', axis = 1,inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Using co-relation matrix to identify important features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_corr = df_train.corr()\ndf_corr = df_corr.where(abs(df_corr['diagnosis']) > 0.5)\ndf_corr.dropna(inplace=True)\ncols_to_drop = df_corr.columns.drop(df_corr.index.drop('diagnosis'))\ndf_corr.drop(columns = cols_to_drop, inplace = True)\nprint(\"Important features  are - \", df_corr.columns.values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Note - It is important to note that in Regression and Classification models, the features should be independent of each other. This ensures better fitting and less chances of errors.** \n\nHence only one feature is selcted from each set of mean,se and worst values.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#defining the features\nfeatures = ['radius_mean', 'concave points_mean', 'radius_se', 'radius_worst', 'concave points_worst']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Normalizing the data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nX = df_train[features]\ny = df_train.diagnosis\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = df_test[features]\ny_test = df_test.diagnosis\nscale = StandardScaler()\nX_test_scaled = scale.fit_transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Classification model(s)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* Random Forest Classification and hyperparameter tuning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import f1_score\n\n#developing baseline model\nRF_model = RandomForestClassifier(n_estimators = 1000, max_depth = 10, random_state = 7, n_jobs = -1)\nscores = cross_val_score(RF_model, X_scaled, y, cv = 5, scoring = 'f1')\nscores.mean()*100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This code snippet tunes 20 values. Hence it might take a few mins to run.... The optimized hyper-paramters will be displayed on the next cell... ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#hyperparamter tuning\nfor n_est in [200,400,600,800]:\n    for m_d in [5,6,7,8,12]:\n        RF_model = RandomForestClassifier(n_estimators = n_est, max_depth = m_d, random_state = 7, n_jobs = -1)\n        scores = cross_val_score(RF_model, X_scaled, y, cv = 5, scoring = 'f1')\n        print('estimators = ',n_est,\" max depth = \",m_d,\" score = \",scores.mean()*100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Optimized Hyperparamters are - 600 and 10 respectively.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#developing the optimized model\nRF_model = RandomForestClassifier(n_estimators = 600, max_depth = 10, random_state = 7, n_jobs = -1)\nRF_model.fit(X,y)\nscores = cross_val_score(RF_model, X_scaled, y, cv = 5, scoring = 'f1')\nscores.mean()*100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With a tuned RandomForest ensemble model, we get a f1 score of 92.26%","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* K-Nearest Neighbour Classification and hyperparameter tuning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.neighbors import KNeighborsClassifier\n\n#developing baseline model\nknn_model = KNeighborsClassifier(n_neighbors = 5, leaf_size = 20, n_jobs = -1)\nscores = cross_val_score(knn_model, X_scaled, y, cv = 5, scoring = 'f1')\nscores.mean()*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#hyperparameter tuning\nfor ne in [4,5,6,7,8,9,10]:\n    for ls in [10,20,30,40,50,60,80]:\n        knn_model = KNeighborsClassifier(n_neighbors = ne, leaf_size = ls, n_jobs = -1)\n        scores = cross_val_score(knn_model, X_scaled, y, cv = 5, scoring = 'f1')\n        print('n_neighbors = ', ne, ' leaf_size = ', ls, 'score = ', scores.mean()*100)            ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tuned hyperparameters are - 5 and 20 respectively, which is the baseline model itself.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#developing the optimized model\nknn_model = KNeighborsClassifier(n_neighbors = 5, leaf_size = 20, n_jobs = -1)\nscores = cross_val_score(knn_model, X_scaled, y, cv = 5, scoring = 'f1')\nscores.mean()*100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With a tuned KNN model we get an f1 score of 92.25%.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* Logistic Regression and hyperparamter tuning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\n\n#developing the baseline model and tuning it\nfor c in [0.1,0.2,0.3,0.4,0.5,1]:\n    LoReg_model = LogisticRegression(C = c, random_state = 3, n_jobs = -1)\n    scores = cross_val_score(LoReg_model, X_scaled ,y , cv=5, scoring='f1')\n    print(scores.mean()*100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The tuned hyperparameter is C = 0.5","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#developing the optimized model\nLoReg_model = LogisticRegression(C = 0.5, random_state = 3, n_jobs = -1)\nscores = cross_val_score(LoReg_model, X_scaled ,y , cv=5, scoring='f1')\nscores.mean()*100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With a slightly tuned Logistic Regression Classifier, we get a f1_score of 92.45%","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"From the above tuned models, it can be seen that, all of the models have a similar f1 score around 92. The f1_score is higher because of the earlier feature selection we performed. To finalize the model, I will be using the Random Forest Classifer. This is because, Random Forest is an ensemble classifier and it generally works better with un-seen data i.e. test data.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Analysis on Test Data (with yellowbrick)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fit the final model on the train data\nfinal_model = RandomForestClassifier(n_estimators = 600, max_depth = 10, random_state = 7, n_jobs = -1)\nfinal_model.fit(X_scaled, y);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Scoring on test data\ny_true = y_test\ny_pred = final_model.predict(X_test_scaled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#defining labels for prognosis\nlabels = ['Benign', 'Malignant']\n\n#using yellowbricks Classification Report\nfrom yellowbrick.classifier import ClassificationReport\n\nreport = ClassificationReport(final_model, size=(480,240), classes = labels, cmap = 'PuBu')\nreport.score(X_test_scaled, y_test)\nreport.show()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#using yellowbrick class prediction error\nfrom yellowbrick.classifier import ClassPredictionError\n\nerror = ClassPredictionError(final_model, size=(540,360), classes = labels)\nerror.score(X_test_scaled, y_test)\nerror.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Inferences and Report on the Test data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The model has been trained on a data of 500 rows and tested on a smaller data of 69 rows. From the yellowbrick analysis of test data, it can be ascertained that the model has performed well with the previously unseen test data. Owing to the small size of the test data, the following results can't be generalized.\n\nFor the class label Benign, i.e. non cancerous tumours, the model always predicts correctly and hence has a precision of 100%. However, for the class label Malignant, i.e. actual cancerous tumours, the model most of the time predicts correctly. It has a precision of 0.8%. \n\n------------------","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}