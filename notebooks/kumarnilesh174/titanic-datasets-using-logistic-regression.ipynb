{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Import Libraries\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n# Input data files are available in the \"../input/\" directory.\n\nimport os\nprint(os.listdir(\"../input\"))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Collection**"},{"metadata":{},"cell_type":"markdown","source":"Let's start by reading in the titanic_train.csv file into a pandas dataframe."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/train_data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Explorer Dataset**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# shape\nprint(df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#columns*rows\ndf.size","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"How many NA elements in every column"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**For getting some information about the dataset you can use info() command**"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.info())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**To check the first 5 rows of the data set, we can use head(5).**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**To check out last 5 row of the data set, we use tail() function**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.tail() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**To pop up 5 random rows from the data set, we can use sample(5) function**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.sample(5) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**To give a statistical summary about the dataset, we can use **describe()**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**To check out how many null info are on the dataset, we can use **isnull().sum().**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**To print dataset columns, we can use columns atribute**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Visualization**"},{"metadata":{},"cell_type":"markdown","source":"**Histogram**"},{"metadata":{},"cell_type":"markdown","source":"We can also create a histogram of each input variable to get an idea of the distribution."},{"metadata":{"trusted":true},"cell_type":"code","source":"# histograms\ndf.hist(figsize=(16,47))\nplt.figure()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Pairplot**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using seaborn pairplot to see the bivariate relation between each pair of features\nsns.pairplot(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Exploratory Data Analysis**"},{"metadata":{},"cell_type":"markdown","source":"Let's begin some exploratory data analysis! We'll start by checking out missing data!\n\n**Missing Data**\n\nWe can use seaborn to create a simple heatmap to see where we are missing data!"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_style('whitegrid')\nsns.countplot(x='Survived',data=df,palette='RdBu_r')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_style('whitegrid')\nsns.countplot(x='Survived',hue='Sex',data=df,palette='RdBu_r')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_style('whitegrid')\nsns.countplot(x='Survived',hue='Pclass_1',data=df,palette='rainbow')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['Age'].dropna(),kde=False,color='darkred',bins=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Age'].hist(bins=30,color='darkred',alpha=0.7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='Title_1',data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Building a Logistic Regression model**\n\nLet's start by splitting our data into a training set and test set (there is another test.csv file that you can play around with in case you want to use all this data for training)\n\n**Train Test Split**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(df.drop('Survived',axis=1), \n                                                    df['Survived'], test_size=0.22, \n                                                    random_state=51)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Training and Predicting**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logmodel = LogisticRegression()\nlogmodel.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = logmodel.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's move on to evaluate our model!"},{"metadata":{},"cell_type":"markdown","source":"**Evaluation**\n\nWe can check precision,recall,f1-score using classification report!"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report,classification_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test,predictions))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}