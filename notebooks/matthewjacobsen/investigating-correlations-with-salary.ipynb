{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this notebook, my objective is to see if we can develop a linear predictor for data scientist salary, using the dataset provided by @stephenofarrell for Cost of Living in various cities around the world.  One of the features I took on was including salary information for data scientists, based on data available via Glassdoor.  As can be seen in the dataset, there were several cities where salaries were missing (and others were Glassdoor rates the information as low confidence).  \n\nI wanted to see if I could use the cost of living information, along with the salaries already included to develop a linear regressor for predicting data scientist salaries to \"fill in the gaps\" and for other cities not included in the data set.\n\nTo start, I imported the data and set the index to the cities, to make eliminate the numerical index and replace with categorical indices."},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"import pandas as pd\ncost_of_living_rev1_df = pd.read_csv(r\"../input/revised-cost-of-living-v1/cost-of-living_rev1(25JAN2020).csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cost_of_living_rev1_df.set_index('Unnamed: 0', inplace=True)\ncost_of_living_rev1_df.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, the dataset is column oriented by city, which is the field we are trying to backfill.  So, let's transpose the dataframe and inspect."},{"metadata":{"trusted":true},"cell_type":"code","source":"trans_col_df = cost_of_living_rev1_df.T\ntrans_col_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Alright, now we've got a dataset ready for investigation.  We'll start by plotting the data correlations in sets of five."},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib\nimport matplotlib.pyplot as plt \n%matplotlib inline\nmatplotlib.style.use('fivethirtyeight')\nimport seaborn as sns\n\nrow_labels = list(trans_col_df.index)\ncols = list(trans_col_df.columns)[:-1]\nsal_data = list(trans_col_df['Avg Data Scientist Salary (USD/annum)'])\ni=0\nwhile i < len(cols)-5:\n    corr_data_1 = list(trans_col_df[cols[i]])\n    corr_data_2 = list(trans_col_df[cols[i+1]])\n    corr_data_3 = list(trans_col_df[cols[i+2]])\n    corr_data_4 = list(trans_col_df[cols[i+3]])\n    corr_data_5 = list(trans_col_df[cols[i+4]])\n    corr_df = pd.DataFrame(zip(corr_data_1,corr_data_2,corr_data_3,corr_data_4,corr_data_5,sal_data), columns = [str(cols[i]),str(cols[i+1]),str(cols[i+2]),str(cols[i+3]),str(cols[i+4]),str('annual salary')])\n    sns.pairplot(corr_df)\n    plt.show()\n    \n    i+=5","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, for ease of building the model, let's print the column titles."},{"metadata":{"trusted":true},"cell_type":"code","source":"cols","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Last, we'll build our regressor and data model.  For this, I used Bread, Rice, and 1 Bedroom Apartment as features, against the salary.  Note that we could have selected any of the apartment prices, but should only choose one, as they are all highly correlated.  As an interesting history aside, this approach is used by militaries around the world to monitor the stability of the local economy when they are conducting operations. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfit_df = pd.DataFrame(zip(trans_col_df['Loaf of Fresh White Bread (500g)'],\\\n                          trans_col_df['Rice (white), (1kg)'],\\\n                          trans_col_df['Apartment (1 bedroom) in City Centre'],\\\n                          sal_data),\\\n                      columns = ['bread_price','rice_price','apartment_price','salary'])\nfit_df.dropna(inplace=True)\nX = fit_df[['bread_price','rice_price','apartment_price']]\ny = fit_df['salary']\nreg = LinearRegression(fit_intercept=False).fit(X,y)\nprint(reg.score(X,y), reg.coef_, reg.intercept_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, we have a model with a score around 0.695, which isn't too bad for using bread, rice, and single bed apartment prices.  Can you make it better?"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}