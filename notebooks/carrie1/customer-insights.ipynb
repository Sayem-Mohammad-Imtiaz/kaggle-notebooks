{"metadata":{"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"},"language_info":{"mimetype":"text/x-python","nbconvert_exporter":"python","codemirror_mode":{"name":"ipython","version":3},"name":"python","version":"3.6.1","pygments_lexer":"ipython3","file_extension":".py"}},"nbformat":4,"cells":[{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_uuid":"f58e77c39ece19a822fbb1726c910db314c58d46","_cell_guid":"c778ce35-9d2d-4b21-ac09-d0fc4b8ec032"},"source":"#import the data, specify data types\nimport pandas as pd\ndf = pd.read_csv('../input/data.csv',encoding=\"ISO-8859-1\",dtype={'CustomerID': str,'InvoiceID': str})\ndf.InvoiceDate = pd.to_datetime(df.InvoiceDate, format=\"%m/%d/%Y %H:%M\")\ndf.info() "},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_uuid":"3e6e926585b3e043f355fd983ec7dce3aff12f86","_cell_guid":"2cc9f25d-2d36-42b9-89ee-513f3bfd7df2"},"source":"df.head()"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_uuid":"b2ab3783fb999a33f9e8d660dda2985359a6f09c","_cell_guid":"52bb267b-0dc1-4069-831f-d8e90eb203a4"},"source":"df.describe()"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_uuid":"a3133747a52a272f36faff528caaff04964cf6ab","_cell_guid":"3e4c2f44-e87a-4229-a191-71077ae87ed7"},"source":"#remove the negative values and replace with nan\nimport numpy as np\ndf[df['Quantity'] < 0] = np.nan\ndf[df['UnitPrice'] < 0] = np.nan\ndf.describe()"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_uuid":"fb456b574998deb414d1cbf75153be1be2d09fd8","_cell_guid":"f3c1426e-507c-477d-9245-21c9f953c62b"},"source":"#get the total spent for each line item\ndf['total_dollars'] = df['Quantity']*df['UnitPrice']\ndf.describe()"},{"cell_type":"markdown","metadata":{"_uuid":"fc7da896a53cefef85b70f72d2c2d69902bd7c1b","_cell_guid":"8c122f42-b763-4fdc-bd72-ccb7dfeeb3aa"},"source":"## Building a customer table"},{"cell_type":"markdown","metadata":{"_uuid":"5ec8784eb28066de70984415deda7405f156aeb3","_cell_guid":"bd43b072-c22c-49ca-a073-575b426ad57b"},"source":"Let's aggregrate transaction data to learn more about our customers."},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_uuid":"864d3c8b8ef5616b59222d42e9aea29601eb8d9e","_cell_guid":"82b1eda4-ee2c-4b81-a501-694be9535328"},"source":"#how many orders have they made\ninvoice_ct = df.groupby(by='CustomerID', as_index=False)['InvoiceNo'].count()\ninvoice_ct.columns = ['CustomerID', 'NumberOrders']\ninvoice_ct.describe()"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_uuid":"7bbff9bcc1af9c7b3e79733e0aca5d7bbfa3c27e","_cell_guid":"59eb7ef7-fc99-41da-82ae-6b470cdd6c2f"},"source":"#how much money have they spent\ntotal_spend = df.groupby(by='CustomerID', as_index=False)['total_dollars'].sum()\ntotal_spend.columns = ['CustomerID', 'total_spent']\ntotal_spend.describe()"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_uuid":"5c65156b29f049acb0443237c3374d3fe723ebfe","_cell_guid":"9ba8c50f-d984-4971-94ea-db72a9e3bca6"},"source":"#how many items they bought\ntotal_items = df.groupby(by='CustomerID', as_index=False)['Quantity'].sum()\ntotal_items.columns = ['CustomerID', 'NumberItems']\ntotal_items.describe()"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_uuid":"798b1279b63b68986b4758f17dec7b02fca5f0aa","_cell_guid":"81450b73-1cfc-46c7-8749-f7ea5b9f155c"},"source":"#when was their first order and how long ago was that from the last date in file (presumably\n#when the data were pulled)\nearliest_order = df.groupby(by='CustomerID', as_index=False)['InvoiceDate'].min()\nearliest_order.columns = ['CustomerID', 'EarliestInvoice']\nearliest_order['now'] = pd.to_datetime((df['InvoiceDate']).max())\nearliest_order['days_as_customer'] = 1 + (earliest_order.now-earliest_order.EarliestInvoice).astype('timedelta64[D]')\nearliest_order.drop('now', axis=1, inplace=True)\nearliest_order"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_uuid":"6239ff019a4b450bfb762346a9c003224d1df58f","_cell_guid":"e98bec1c-3d8d-4c1d-ac40-0d8c17662675"},"source":"#when was their last order and how long ago was that from the last date in file (presumably\n#when the data were pulled)\nlast_order = df.groupby(by='CustomerID', as_index=False)['InvoiceDate'].max()\nlast_order.columns = ['CustomerID', 'last_purchase']\nlast_order['now'] = pd.to_datetime((df['InvoiceDate']).max())\nlast_order['days_since_purchase'] = 1 + (last_order.now-last_order.last_purchase).astype('timedelta64[D]')\nlast_order.drop('now', axis=1, inplace=True)\nlast_order.head"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_uuid":"936f3e71c505cb83938458576b86e8b9cf58f718","_cell_guid":"054555c4-687b-44af-b1c9-409c08ffc88d"},"source":"#combine all the dataframes into one\nimport functools\ndfs = [total_spend,invoice_ct,earliest_order,last_order,total_items]\nCustomerTable = functools.reduce(lambda left,right: pd.merge(left,right,on='CustomerID', how='outer'), dfs)\nCustomerTable.head()"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_uuid":"f7390ee86edb782d1e1436cd0e3040c34c2f6c87","_cell_guid":"d5e9a07b-f8d8-4457-8db4-d27946a28b9d"},"source":"#how many customers?\nlen(CustomerTable)"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_uuid":"c2972e08c969b7e71bd77ab1a4508101304a9ee7","_cell_guid":"a95d231f-ea6f-48ae-97f1-6145cb9dab7a"},"source":"CustomerTable.describe()"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_uuid":"49b2bb3ebf427f5caa07d851d0553ca75cc5fca9","_cell_guid":"247b454c-e552-489b-9a03-77a33a023bc1"},"source":"#identify and separate big spenders, lots of orders, long-time customers, dormant customers for\n#sales and marketing campaign use; need to be separate flags because they aren't all mutually\n#exclusive\n\ndef big_spender(row):\n    if row['total_spent'] >= 1661.64:\n        return 'Yes'\n    else:\n        return 'No'\n\ndef many_orders(row):\n    if row['NumberOrders'] >= 100:\n        return 'Yes'\n    else:\n        return 'No'\n\ndef loyal_customer(row):\n    if row['days_as_customer'] >= 326:\n        return 'Yes' \n    else:\n        return 'No'\n\ndef dormant_customer(row):\n    if row['days_since_purchase'] >= 141:\n        return 'Yes' \n    else:\n        return 'No'\n\nCustomerTable['BigSpender'] = CustomerTable.apply(big_spender, axis=1)\nCustomerTable['ManyOrders'] = CustomerTable.apply(many_orders, axis=1)\nCustomerTable['LoyalCustomer'] = CustomerTable.apply(loyal_customer, axis=1)\nCustomerTable['DormantCustomer'] = CustomerTable.apply(dormant_customer, axis=1)\n\nCustomerTable['OrderFrequency'] = CustomerTable['NumberOrders']/CustomerTable['days_as_customer']\n\nCustomerTable.head(10)"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_uuid":"0202acfc14845f97107429c27f9decb5fcf058c3","_cell_guid":"ffe1f38d-5e1c-40f3-b911-a6bea739522c"},"source":"#look at the distributions and relationships with other continuous variables\nimport seaborn as sns\nsns.pairplot(CustomerTable, vars=[\"total_spent\", \"NumberOrders\",'days_as_customer',\n                                  'days_since_purchase','NumberItems','OrderFrequency'])"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{},"source":"RF = CustomerTable[[\"NumberOrders\",'days_as_customer','NumberItems','BigSpender','CustomerID']]\nfeatures = RF.columns[:3]\nfeatures"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{},"source":"RF['is_train'] = np.random.uniform(0, 1, len(RF)) <= .8\ntrain, test = RF[RF['is_train']==True], RF[RF['is_train']==False]\nprint('Number of observations in the training data:', len(train))\nprint('Number of observations in the test data:',len(test))"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{},"source":"y = pd.factorize(train['BigSpender'])[0]\ny[0:10] #show the first ten; 'No' = 0"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{},"source":"from sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier(n_jobs=2)\nclf.fit(train[features], y)\nlist(zip(train[features], clf.feature_importances_))"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{},"source":"clf.predict_proba(test[features])[0:10]"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{},"source":"test['Prediction'] = clf.predict(test[features])\ntest.head()"}],"nbformat_minor":1}