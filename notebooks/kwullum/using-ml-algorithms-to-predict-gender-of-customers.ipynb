{"cells":[{"metadata":{},"cell_type":"markdown","source":"This dataset is probably best suited for unsupervised ML techniques, but I was curious to see whether there are attributes that can help predict whether a customer is male or female. The attributes in question are Age, Income and Score. It's a small dataset (both in terms of features and number of customers), however I think this notebook gives a useful introduction to applying ML algorithms such as Random Forest, SVM and KNN."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.set_style('darkgrid')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Data Preprocessing**"},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = ['CustomerID', 'Gender', 'Age', 'Income', 'Score']\ndf = pd.read_csv('../input/Mall_Customers.csv', index_col='CustomerID', names=columns, header=0)\ndf = df[['Age', 'Income', 'Score', 'Gender']] # Putting Gender (target variable) at the end\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have data on 200 customers. This is not very much. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Age ranges between 18-70, income ranges between 15K-137K, and score ranges between 1-99."},{"metadata":{"trusted":true},"cell_type":"code","source":"# % share of gender in dataset\ndf.Gender.value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Exploratory Data Analysis**\n\nLet's look into the data. We start off by isolating the attributes and look at differences between the genders."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1,2, figsize=(9,4))\n\nfemale = df[df.Gender == 'Female']\nmale = df[df.Gender == 'Male']\n\nsns.distplot(female.Age, bins=12 ,ax=ax1)\nsns.distplot(male.Age, bins=12, ax=ax2)\n\nax1.set_title('Age distr among females')\nax2.set_title('Age distr among males')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1,2, figsize=(9,4))\n\nfemale = df[df.Gender == 'Female']\nmale = df[df.Gender == 'Male']\n\nsns.distplot(female.Income, bins=12 ,ax=ax1)\nsns.distplot(male.Income, bins=12, ax=ax2)\n\nax1.set_title('Income distr among females')\nax2.set_title('Income distr among males')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1,2, figsize=(9,4))\n\nfemale = df[df.Gender == 'Female']\nmale = df[df.Gender == 'Male']\n\nsns.distplot(female.Score, bins=12 ,ax=ax1)\nsns.distplot(male.Score, bins=12, ax=ax2)\n\nax1.set_title('Score distr among females')\nax2.set_title('Score distr among males')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Interestingly, females' scores are clustered relatively symetrically around the midpoint. Males, however, peak at the very bottom, very top, and the middle."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Map Gender to 1 for female and 0 for male\n\nmapping = {'Female': 1, 'Male': 0}\ndf.Gender.replace(mapping, inplace=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Comparing pairwise correlations between variables\nsns.pairplot(df[['Age', 'Income', 'Score']])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No significant correlations between the variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lmplot('Score', 'Income', hue='Gender', data=df, fit_reg=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see a pattern, although this is not a linear one. Interestingly there seems to be a cluster where most people who have income in the 40k-60k range have a score between 40-60. Anyone with income above or below this range seems to be at the extremes of the Score range - either very high or very low."},{"metadata":{},"cell_type":"markdown","source":"## **Machine Learning**\n\nCan we predict the gender of a customer (target variable) based on attributes such as age, income and score? We try training 3 different algorithms for this task - KNN, Random Forest, and SVM."},{"metadata":{},"cell_type":"markdown","source":"### **Feature scaling - standardizing the data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Standardize the data to all be the same unit\n\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nscaler.fit(df.drop('Gender', axis=1))\n\n# Transforming the data\nscaled_features = scaler.transform(df.drop('Gender', axis=1))\nscaled_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use the scaler to create scaler dataframe\n# This gives us a standardized version of our data\n\ndf_feat = pd.DataFrame(scaled_features, columns=df.columns[:-1])\ndf_feat.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Train test split**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, GridSearchCV\n\nX = df_feat\ny = df['Gender']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **KNN**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training and Predictions\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors=5) # k=5\nknn.fit(X_train, y_train)\npred = knn.predict(X_test)\npred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluating the algorithm\n\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\nprint (confusion_matrix(y_test, pred))\nprint (classification_report(y_test, pred))\nprint ('Accuracy Score: ' + str(accuracy_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The algorithm doesn't do a better prediction than a random draw would. Let's find the k with the lowest error rate through iterations."},{"metadata":{"trusted":true},"cell_type":"code","source":"error_rate = []\n\nfor i in range(1,40): # Checking every possible k value between 1-40\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train, y_train)\n    pred_i = knn.predict(X_test)\n    error_rate.append(np.mean(pred_i != y_test))\n    \nerror_rate","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The error rate is what we want to minimize, so we want to know the k that gives the smallest error rate. Let's create a visual representation to make life easier. "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nplt.plot(range(1,40), error_rate, color='grey', marker='o', markerfacecolor='red')\nplt.title('Error rate vs K value')\nplt.xlabel('K value')\nplt.ylabel('Mean error rate')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"0.35 is a very high error rate, but it is the best we're able to find. Let's now run the model again with k=17 again instead of k=1."},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors=17)\nknn.fit(X_train, y_train)\ny_pred = knn.predict(X_test)\n\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\nprint ('Accuracy Score: ' + str(accuracy_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We were able to classify a couple of more points correctly, but in general, an accuracy score of 0.65 is not good. It looks like we'd need more data (more features or larger dataset) to build a more robust model."},{"metadata":{},"cell_type":"markdown","source":"### **Random Forest**\n\nLet's try the Random Forest algorithm instead. We have already scaled data and split into train and test sets."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training the algorithm\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nforest = RandomForestClassifier(n_estimators=100, random_state=101)\nforest.fit(X_train, y_train)\ny_pred = forest.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluating the algorithm\n\nprint (confusion_matrix(y_test, y_pred))\nprint (classification_report(y_test, y_pred))\nprint ('Accuracy Score: ' + str(accuracy_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ouch, this ain't good. Nothing better than a random draw. Let's instead use grid search to find the best parameter values. Parameter tuning is the process to selecting the values for a modelâ€™s parameters that maximize the accuracy of the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Grid search\n\ngrid_param = {  \n    'n_estimators': [50, 80, 100, 120],\n    'criterion': ['gini', 'entropy'],\n    'bootstrap': [True, False],\n    'max_depth': [10,30,50],\n    'max_features': ['auto', 'sqrt'],\n    'min_samples_split': [3,9,20],\n    'min_samples_leaf': [1, 2, 4]\n    }\n\ngs = GridSearchCV(estimator=forest,  \n                     param_grid=grid_param,\n                     scoring='accuracy',\n                     cv=5,\n                     n_jobs=-1)\n\ngs.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(gs.best_params_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's train the algorithm again, using the information from the grid search."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training the tuned algorithm\n\nforest_tuned = RandomForestClassifier(n_estimators=100,\n                                      criterion= 'gini',\n                                      bootstrap= False,\n                                      max_depth= 10,\n                                      max_features= 'auto',\n                                      min_samples_split= 20,\n                                      min_samples_leaf= 1,\n                                      random_state=101)\nforest_tuned.fit(X_train, y_train)\ny_pred = forest_tuned.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluating the tuned algorithm\n\nprint (confusion_matrix(y_test, y_pred))\nprint (classification_report(y_test, y_pred))\nprint ('Accuracy Score: ' + str(accuracy_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Slightly better than previously, but still not noticably different from a random draw."},{"metadata":{},"cell_type":"markdown","source":"### **SVM**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training the algorithm\n\nfrom sklearn.svm import SVC\n\nsvm = SVC()\nsvm.fit(X_train, y_train)\ny_pred = svm.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluating the algorithm\n\nprint (confusion_matrix(y_test, y_pred))\nprint (classification_report(y_test, y_pred))\nprint ('Accuracy Score: ' + str(accuracy_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Not great, let's search for the best parameters using grid search."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Grid search\n\n# \"C\" controls the cost of misclassification on the training data. \n# A large C-value gives you low bias and high variance. Low bias causes you penalize the cost of misclassification a lot.\n\n# Small \"gamma\" means a Gaussian of a large variance. Large gamma leads to high bias and low variance in the model. \n\nparam_grid = {\n    'C': [0.1, 1, 10, 100, 1000],\n    'gamma': [1, 0.1, 0.01, 0.001, 0.0001]\n}\n\ngs = GridSearchCV(SVC(), param_grid, verbose=3)\ngs.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(gs.best_params_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's train the algorithm again, using the information from the grid search."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training the tuned algorithm\n\nsvm_tuned = SVC(C = 10, gamma = 0.1)\nsvm_tuned.fit(X_train, y_train)\ny_pred = svm_tuned.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluating the algorithm\n\nprint (confusion_matrix(y_test, y_pred))\nprint (classification_report(y_test, y_pred))\nprint ('Accuracy Score: ' + str(accuracy_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Slightly better than previously, but the model still has poor predictive ability."},{"metadata":{},"cell_type":"markdown","source":"## **Conclusion**\n\nNeither KNN, Random Forest nor the SVM algorithm are very useful in terms of predicting the gender of the customer based on the features Age, Income and Score. This indicates that the data does not have prediction capability. This doesn't come as a huge surprise, as we could already see in the EDA that there was little that suggested any major differences between the two genders when it came to these variables. However, the sample used is very small (n=200), and having more data might have given us higher accuracy scores.\n\nA high error rate indicates that the model is underfitting and has high bias. The model is not sufficiently complex, so it's simply not capable of representing the relationship between y and the input features. To combat this we could try increasing the number of input features."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}