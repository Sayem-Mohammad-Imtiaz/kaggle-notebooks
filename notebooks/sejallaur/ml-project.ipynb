{"cells":[{"metadata":{},"cell_type":"markdown","source":"So let's just have make sure that we have a well written and well documented code. So please explain everything you do and have the pevious (working version) of the program stored somewhere incase of something does not work after you alter it's implementation. Also, for reference, feel free to add resources when needed."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# state all imports over here\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport copy\nimport sklearn\nfrom sklearn.metrics import *\nfrom sklearn.decomposition import *","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# importing our dataset\nclient_info = pd.read_csv('../input/credit-card-approval-prediction/application_record.csv')\nclient_record = pd.read_csv('../input/credit-card-approval-prediction/credit_record.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Data Pre-processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing our dataset\nclient_info = pd.read_csv('../input/credit-card-approval-prediction/application_record.csv')\n\nclient_record = pd.read_csv('../input/credit-card-approval-prediction/credit_record.csv')\n'''\nSince the data we are using has alot of users than the number of transactions, \nwe will only consider users who have made a transaction recently\nfirst we will read the datasets into pandas dataframes\n'''\n\n\n''' dropping occupation type as it has a lot of missing values'''\n# print(client_info['OCCUPATION_TYPE'].unique())\nclient_info = client_info.drop(['OCCUPATION_TYPE'],axis=1)\n# print(client_info.columns)\n\n\n'''for mapping gender values\nwe have 1 for Male and 0 for Female'''\nclient_info['CODE_GENDER'].replace({\"M\": 1, \"F\": 0}, inplace=True)\n    \n\n'''for mapping whether the client has a car\nit will be 1 for yes and 0 for no'''\nclient_info[\"FLAG_OWN_CAR\"].replace({\"Y\": 1, \"N\": 0}, inplace=True)\n\n\n'''for mappping whether the client owns any real esate assents\nagain it will be 1 for 1 for yes and 0 for nonlocal'''\nclient_info[\"FLAG_OWN_REALTY\"].replace({\"Y\": 1, \"N\": 0}, inplace=True)    \n\n\n'''for mapping educational qualifications\nwe have not made dummy varaibles for this because we feel\nhigher educatonal qualifications should be given higher weight'''\nclient_info[\"NAME_EDUCATION_TYPE\"].replace({\"Higher education\": 3, \"Lower secondary\": 0, \"Secondary / secondary special\": 1, \"Incomplete higher\": 2, \"Academic degree\":4}, inplace=True)\n\n\n'''for mapping housing type\nthe value 0 would indicate a rented/municipal/office apartment \nor that the client lives with his parents whereas 1 would indicate a House/co-op apartment\nthe reason being that 1 would indicate that the person lives on a property that they own \nwhereas 0 would indicate that it is not a permanent place'''\nclient_info[\"NAME_HOUSING_TYPE\"].replace({\"House / apartment\":5, 'Co-op apartment':4, 'Municipal apartment':3, 'With parents':2, 'Office apartment':1, 'Rented apartment':0}, inplace=True)\n\n\n'''for mapping income type\nthe value 0 would indicate a student/person living on pension \nwhereas the value 1 would indicate a commercial associate or a person who \nis working or is a state servent. We have done so because a pensioner and \na student are people who are not actively working and hence should be considered\ninto a different category from the people who are actively working'''\nclient_info['NAME_INCOME_TYPE'].replace({'Working':3, 'Commercial associate':4, 'Pensioner':1, 'State servant':2, 'Student':0}, inplace=True)\n\n\n'''for mapping family status\nwe will classify marriage and civil marriage as 1 since they both indicate\nthat the person currently has a spouse and we will classify separated, single\nand widow as 0 since in all of them the client has no spouse'''\nclient_info['NAME_FAMILY_STATUS'].replace({'Single / not married':2, 'Separated':1, 'Widow':0, 'Married':4, 'Civil marriage':3}, inplace=True)\n\n\n''' for handling our response variable\nNOTE THIS IS SUBJECT TO CHANGE\nso the variable STATUS will be our response variable\nfor loans that were paid as safe credit approvals whereas all\ndues (all integer values) as unsafe credit approvals. The values assigned would be\n1 and 0 respectively. We might have to change this depending on accuracy'''\nclient_record['STATUS'].replace({'C':1, 'X':1,'1':0,'0':0,'2':0,'3':0,'4':0,'5':0},inplace=True)\n\n\n# '''for handling occupation type'''\n# client_info['OCCUPATION_TYPE'].replace({'Security staff':4, 'Sales staff':7, 'Accountants':16, 'Laborers':2, 'Managers':17, 'Drivers':6, 'Core staff':9, 'High skill tech staff':18, 'Cleaning staff':3, 'Private service staff':10, 'Cooking staff':5, 'Low-skill Laborers':1, 'Medicine staff':15, 'Secretaries':12, 'Waiters/barmen staff':8, 'HR staff':11, 'Realty agents':14, 'IT staff':13},inplace=True)\n\n\n'''One hot encoding'''\n#this was previously client_info1\nclient_info = pd.get_dummies(client_info, columns = [\"NAME_EDUCATION_TYPE\", \"NAME_HOUSING_TYPE\", \"NAME_INCOME_TYPE\", \"NAME_FAMILY_STATUS\"], drop_first=True)\n# print(client_info1.head())\n\n''' Merging the 2 datasets'''\ndata = client_record.merge(client_info, how = 'left', on = 'ID')\ndata = data.dropna()\ndata = data.reset_index()\ndata = data.drop(columns=['index'])\ndata = data.set_index('ID')\ndata = data.astype('float64')\n# data = abs(data)\ntempo = data['STATUS']\n# print(tempo)\n# print(len(data))\n# print(data[\"NAME_INCOME_TYPE\"].dtype)\n# print(client_record.dtypes)\n\n\n'''To normalize the dataset we used 2 differenet approaches\n1. Mean normalization\n2. Min-Max normalization '''\ndata_mean_norm = (data-data.mean())/data.std()\ndata_min_max_norm = (data-data.min())/(data.max()-data.min())\n\n\n'''since flag_mobil has all column entries as 1, it gives NaN value\nupon normalization. To ensure no loss of data we are reassigning \nit its original value'''\n# data['FLAG_MOBIL'].unique(); proof for the above statement\ndata_mean_norm['FLAG_MOBIL'] = 1.0\ndata_min_max_norm['FLAG_MOBIL'] = 1.0\ndata_mean_norm['STATUS'] = tempo\ndata_min_max_norm['STATUS'] = tempo\n# print(data_mean_norm.head())\n# print(data_min_max_norm.head())\n# client_info1.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y1=data_min_max_norm['STATUS']\ny1k = copy.deepcopy(y1)\ny1=y1.to_numpy()\nX1=copy.deepcopy(data_min_max_norm)\nX1=X1.drop(['STATUS','CNT_CHILDREN','DAYS_BIRTH'],axis=1)\n# X1=X1.drop(['STATUS'],axis=1)\nX1k = copy.deepcopy(X1)\nX1=X1.to_numpy()\nones=np.ones((X1.shape[0],1))\nX1 = np.concatenate((ones, X1), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y2=data_mean_norm['STATUS']\ny2k = copy.deepcopy(y2)\ny2=y2.to_numpy()\nX2=copy.deepcopy(data_mean_norm)\nX2=X2.drop(['STATUS','CNT_CHILDREN','DAYS_BIRTH'],axis=1)\n# X1=X1.drop(['STATUS'],axis=1)\nX2k = copy.deepcopy(X2)\nX2=X2.to_numpy()\nones=np.ones((X2.shape[0],1))\nX2 = np.concatenate((ones, X2), axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Implimenting K folds; to divide data into trainning and testing data\nThe function \"split\" take 3 inputs X:Input nummpy array\ny:nummy array (i.e our status)\nratio: the splitting ratio"},{"metadata":{"trusted":true},"cell_type":"code","source":"''' BOX PLOT FOR ALL FEATURES'''\nprint(data.columns)\n# print(data_mean_norm.boxplot())\nprint(data_min_max_norm.plot(kind='box', rot=75))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(n_components=1)\nxn = copy.deepcopy(data_min_max_norm)\nxxn = data_min_max_norm['STATUS']\nxxn = xxn.reset_index()\n# print(xxn)\nxn = xn.drop(['STATUS'],axis=1)\ntdata = pca.fit_transform(xn)\ntt = pd.DataFrame(tdata)\n# print(tt)\ntt['STATUS'] = xxn['STATUS']\nprint(tt.columns)\nprint(tt.boxplot()) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# removing outliers\nQ1 = tt[0].quantile(0.25)\nQ3 = tt[0].quantile(0.75)\nIQR = Q3 - Q1  #IQR is interquartile range. \nnorm_pts = ( tt[0] >= Q1 - 1.5 * IQR) & ( tt[0] <= Q3 + 1.5 *IQR)\nnorm_pts.value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# heat map for correlation\nimport seaborn as sns\nprint(data.columns)\ncorr = data.corr()\nplt.figure(figsize=(15,7.5))\nax = sns.heatmap(corr, square=True)\nprint(ax)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.metrics import log_loss\nfrom sklearn.datasets import load_iris\nfrom sklearn.linear_model import LogisticRegression\n\n\ndef Mylogestic(X_train,X_test,y_train,y_test):\n    \n    clf = LogisticRegression(random_state=10, max_iter=10000).fit(X_train, y_train)\n    return(clf.predict(X_test))\n\n\ndef train_test(X,y,ratio):\n    kf = KFold(n_splits=ratio)\n    for train_index, test_index in kf.split(X):\n        X_train, X_test = X[train_index], X[test_index]\n        y_train, y_test = y[train_index], y[test_index]\n        fin=Mylogestic(X_train,X_test,y_train,y_test)\n        print(accuracy_score(y_test, fin))\n        print(confusion_matrix(y_test, fin))\n    return ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Simple Logestic Regression function (input should be nummy array).Returns our predicted value\n\nTHE CONFUSION MATRIX\n\nTN,FP\n\nFN,TP"},{"metadata":{"trusted":true},"cell_type":"code","source":"#for min max\ntrain_test(X1,y1,10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#for mean\ntrain_test(X2,y2,10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns\n# data.corr()   ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}