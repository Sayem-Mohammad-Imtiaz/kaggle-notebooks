{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Import Packages, Functions & libraries "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n#import libraries for visualization, processing and modeling\n# %clear\n# %reset\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\n\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" # Import Datasets"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#load customer data\nbk_customers = pd.read_csv(r\"../input/predicting-churn-for-bank-customers/Churn_Modelling.csv\",index_col=0)\n\n#Get overview of the data\nbk_customers.head()\n\nbk_orginal = bk_customers.copy()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# Simple details about the data\n\nprint ( \"Size of dataset: \", bk_customers.shape) #number of rows and columns of the dataset\nprint (\"Features of the dataset: \", bk_customers.columns.tolist()) #features of the dataset\n\nprint (\"Variables with missing values: \", bk_customers.isnull().sum()) #No missing values, this is good for our task!\nprint (\"Unique values for each variable: \",bk_customers.nunique())\nprint (\"Check data type of the variables: \", bk_customers.dtypes)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Manipulation"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Carry out some data manipulation\n\n#Create categorical variables out of tenure, credit score and age variables\n\nsorted(bk_customers.CreditScore.unique())\nsorted(bk_customers.Tenure.unique())\nsorted(bk_customers.Age.unique())\n\ndef cust_tenure(bk_customers):\n    if bk_customers[\"Tenure\"] <= 2:\n        return \"Tenure_0-2\" # New customers\n    elif (bk_customers[\"Tenure\"] > 2) & (bk_customers[\"Tenure\"] <= 4) :\n        return \"Tenure_2-4\" #medium tenure with the bank \n    elif (bk_customers[\"Tenure\"] > 4) & (bk_customers[\"Tenure\"] <= 6) :\n        return \"Tenure_4-6\" # long tenure with the bank\n    elif bk_customers[\"Tenure\"] > 6 :\n        return \"Tenure_gt_6\" # very long tenure with the bank\n    \n#Age categories\n\ndef cust_age(bk_customers):\n    if bk_customers[\"Age\"] <= 30:\n        return \"Age_18-30\" #Youthful customers\n    elif ((bk_customers[\"Age\"]) > 30) & ((bk_customers[\"Age\"]) <= 40):\n        return \"Age_30-40\" #Mid-age customters\n    elif ((bk_customers[\"Age\"]) > 40) & ((bk_customers[\"Age\"]) <= 60):\n        return \"Age_40-60\" # Older customers\n    elif (bk_customers[\"Age\"]) > 60 :\n        return \"Age_gt_60\" # Pensioners\n    \n# Credit Score categories (Reference made to a types of credit score called FICO Scores (300 -850))\n\ndef cred_score(bk_customers):\n    if (bk_customers[\"CreditScore\"] > 300) & (bk_customers[\"CreditScore\"] <= 579):\n        return \"Very Poor\"\n    elif (bk_customers[\"CreditScore\"] > 579) & (bk_customers[\"CreditScore\"] <= 669):\n        return \"Fair\" \n    elif (bk_customers[\"CreditScore\"] > 669) & (bk_customers[\"CreditScore\"] <= 739):\n        return \"Good\"\n    elif (bk_customers[\"CreditScore\"] > 739) & (bk_customers[\"CreditScore\"] <= 799):\n        return \"Very Good\" \n    elif (bk_customers[\"CreditScore\"] > 799) & (bk_customers[\"CreditScore\"] <= 850):\n        return \"Exceptional\" \n\n# call/apply the functions above\nbk_customers[\"tenure_cat\"] = bk_customers.apply(lambda bk_customers:cust_tenure(bk_customers), axis = 1)\nbk_customers[\"age_cat\"] = bk_customers.apply(lambda bk_customers:cust_age(bk_customers), axis = 1)\nbk_customers[\"credit_cat\"] = bk_customers.apply(lambda bk_customers:cred_score(bk_customers), axis = 1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check the new values created \nsorted(bk_customers.credit_cat.unique())\nsorted(bk_customers.tenure_cat.unique())\nsorted(bk_customers.age_cat.unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Explanatory Data Analysis\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Explanatory Data Analysis\n\n#1. Explore data types\n\n# split catagorical and numerical variables\nId_var     = ['CustomerId']\ntarget_var = [\"Exited\"]\ncat_vars   = bk_customers.nunique()[bk_customers.nunique() < 6].keys().tolist()\ncat_vars   = [x for x in cat_vars if x not in target_var]\nnum_vars   = [x for x in bk_customers.columns if x not in cat_vars + target_var + Id_var]\nnum_vars.remove('Surname')\n\n# Create 2 datasets of churned and non churn customers\nchurn = bk_customers[bk_customers[\"Exited\"] == 1]\nnot_churn = bk_customers[bk_customers[\"Exited\"] == 0]\n\n#2. Descriptive statistics (Illustrations)\n\n#Create labels for our graphs\nlabels = \"Churned\",\"Retained\"\n\n# Graph to display percentages\nsize = [bk_customers.Exited[bk_customers['Exited']==1].count(), bk_customers.Exited[bk_customers['Exited']==0].count()]\nfig, ax = plt.subplots(figsize=(10, 8)) \nax.pie(size, labels=labels,colors = ['#098be8','#06c739'], autopct='%1.0f%%',startangle=90)\nax.axis('equal')\nplt.title(\"Churned Vs Non-churned Customers\", size = 20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Take a look at the distribution of variables on churn status\n\n#Illustrations of distribution of categorical\n\n#Bar graph function\n\ndef plot_bars(column,df):\n    fig, axs = plt.subplots(1, 1, figsize=(10, 8))\n    plot = sns.countplot(x=column,hue = 'Exited',data = df)\n    return plot\n\n#plot\nfor i in cat_vars :\n    plot_bars(i,bk_customers).set_title(i + \" distribution in customer attrition\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Illustrations of distribution of categorical\n\n#Boxplot function\n\ndef plot_box(column,df):\n    fig, axs = plt.subplots(1, 1, figsize=(10, 8))\n    plot = sns.boxplot(y=column,x = 'Exited', hue = 'Exited',data = df)\n    return plot\n\n#plot\nfor i in num_vars :\n    plot_box(i,bk_customers).set_title(i + \" distribution in customer attrition\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Average number of products by tenure category \n\navg_num_pdts = bk_customers.groupby([\"tenure_cat\",\"Exited\"])[[\"NumOfProducts\"]].mean().reset_index()\n\nplot = sns.barplot(x=\"tenure_cat\",y = \"NumOfProducts\",hue = 'Exited',data = avg_num_pdts)\n\n# Active members by credit group\n\nplot = sns.catplot(x=\"credit_cat\",hue = 'Exited',col=\"IsActiveMember\",data = bk_customers,kind=\"count\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Generate new variables to be used a proxy variables\n\n#Estimated salary and bank balance ratio\n\nbk_customers['salary_bal_ratio'] = bk_customers.Balance/bk_customers.EstimatedSalary\nsns.boxplot(y='salary_bal_ratio',x = 'Exited', hue = 'Exited',data = bk_customers)\nplt.ylim(0, 5)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Tenure and age of customer - normalize\n\nbk_customers['age_tenure'] = bk_customers.Tenure/(bk_customers.Age)\nsns.boxplot(y='age_tenure',x = 'Exited', hue = 'Exited',data = bk_customers)\nplt.ylim(0, 1)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#New variable to capture credit habits vs age of customer\n\nbk_customers['age_credit_score'] = bk_customers.CreditScore/(bk_customers.Age)\nsns.boxplot(y='age_credit_score',x = 'Exited', hue = 'Exited',data = bk_customers)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Insights from explanatory data analysis:\n\n#1.The customers churned had a median balance that is slightly higher than that of the customers that the bank retained.\n#2. Customers with very low credit scores churned.\n# The median age of customers that churned is around 45 yrs compared to 35 of those that the bank retained - interesting trend.\n# Tenure and estimated salary have no significant differences for customers that churned and those that didn't.\n# Germany has a higher customer attrition ratio compared to France and Spain.\n#No significant difference between retained and churned customers in regards to gender\n# Customers using 3 or more products churned\n#customers with credit cards more likely to churn\n#Inactive members more likely to churn\n# Average number of products almost similar across all tenure groups. \n#customers with higher balance estimated salary ratio more likely to churn\n\n#Questions/Assumptions\n#1. isActiveMember (No) - we assume this implies mere inactivity but still a customer of the bank that could resume activity at a later point in time.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Pre-processing\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Data preprocessing\n\n#Dropping variables that we wont use in predication\n\nlist_vars = ['CustomerId','Surname','tenure_cat', 'age_cat', 'credit_cat']\n\nbk_customers = bk_customers.drop(columns = list_vars,axis = 1)\n\n#Update the vars\n\ncat_vars   = bk_customers.nunique()[bk_customers.nunique() < 6].keys().tolist()\ncat_vars   = [x for x in cat_vars if x not in target_var]\nnum_vars   = [x for x in bk_customers.columns if x not in cat_vars + target_var + Id_var]\n\n#Binary columns with 2 values\nbin_vars = bk_customers.nunique()[bk_customers.nunique() == 2].keys().tolist()\n\n#Columns more than 2 values\n# multi_vars = [i for i in cat_vars if i not in bin_vars]\n\n#encode binary vars - numeric values\nle = LabelEncoder()\nfor i in bin_vars:\n    bk_customers[i] = le.fit_transform(bk_customers[i])\n\n#Create dummy vars\n\nbk_customers = pd.get_dummies(data = bk_customers,columns = ['Geography'] )\n\n#Scaling Numerical vars\n\nstd = StandardScaler()\nscaled = std.fit_transform(bk_customers[num_vars])\nscaled = pd.DataFrame(scaled,columns=num_vars)\n\nbk_customers = bk_customers.drop(columns = num_vars,axis = 1)\nbk_customers = bk_customers.merge(scaled,left_index=True,right_index=True,how = \"left\")\n\n# Use mean for NaNs\nbk_customers = bk_customers.fillna(bk_customers.mean())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Variable summary\nsummary = (bk_customers[[i for i in bk_customers.columns if i not in Id_var]].\n           describe().transpose().reset_index())\n\nsummary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"#looking correlation\ncorr = bk_customers.corr()\n\n# Heatmap\nheatmap = sns.heatmap(corr, \n        xticklabels=corr.columns,\n        yticklabels=corr.columns)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Review Dataset for prediction"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"#visualize dataset on a few variables\n\ndf0 = bk_orginal[bk_customers.Exited == 0]\ndf1 = bk_orginal[bk_customers.Exited == 1]\n\n##Observations\n#1. The dataset is imbalanced ~ 4:1, not good for prediction work.\n#Solution, use bootstrap method: 1) Include all datapoints of 'churned' and randomly sample an equal amount in 'Not churned'\n#2) Use ROC/AUC to evaluate perfomance\n#3) cross validation\n\n#visualize dataset on a few variables to select suitable algorithms to use.\nplt.xlabel('Age')\nplt.ylabel('EstimatedSalary')\nplt.scatter(df0['Age'],df0['EstimatedSalary'],color = 'green', marker= '+')\nplt.scatter(df1['Age'],df1['EstimatedSalary'],color = 'red', marker= '.')\n\n#No clear boundary between churned/Not churned, so SVM may not be a good candidate.\n#It's a fairly small dataset so Logistic regression is a good candiate\n#KNN/Decision \n#Random Forest Classifier","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Build model\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Build models\n\n#import libraries required/needed\n\nimport plotly.graph_objs as go#visualization\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,accuracy_score,classification_report\nfrom sklearn.metrics import roc_auc_score,roc_curve,scorer\nfrom sklearn.metrics import f1_score \nfrom sklearn.metrics import mean_squared_error\nimport statsmodels.api as sm\nfrom sklearn.metrics import precision_score,recall_score\n#from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.tree import export_graphviz\nfrom sklearn import tree\nfrom graphviz import Source\nfrom IPython.display import SVG,display\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import svm\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import svm, tree\n\n\n#Split training and test data\n\ntrain,test = train_test_split(bk_customers,test_size = .25 ,random_state = 142)\n\n#Dependent and independent variables\n\ntgr_var = ['Exited']\nind_var = [x for x in bk_customers.columns if x not in tgr_var]\n\ntrain_X = train[ind_var]\ntrain_Y = train[tgr_var]\ntest_X  = test[ind_var]\ntest_Y  = test[tgr_var]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create an array of all the classifiers\nclassifiers = []\n\n#logistic regression model\n\nlogit = LogisticRegression(solver='liblinear', random_state = 12)\nclassifiers.append(logit)\n\n#K-Nearest Neighbor\nknn = KNeighborsClassifier()\nclassifiers.append(knn)\n\n#support vector machine\nsvm = svm.SVC()\nclassifiers.append(svm)\n\n#Decision tree classifier\ndc_tree = tree.DecisionTreeClassifier()\nclassifiers.append(dc_tree)\n\n#Random forest classifier\nrfrorest = RandomForestClassifier()\nclassifiers.append(rfrorest)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"#Fit, evaluate and check accuracy and confusion matrix\n\nfor clf in classifiers:\n    clf.fit(train_X, train_Y.values.ravel())\n    y_pred= clf.predict(test_X)\n    accuracy = accuracy_score(test_Y, y_pred)\n    print(\"Accuracy of %s is %s\"%(clf, accuracy))\n    precision = precision_score(test_Y, y_pred)\n    print(\"Precision of %s is %s\"%(clf, precision))\n    recall = recall_score(test_Y, y_pred)\n    print(\"Recall of %s is %s\"%(clf, recall)) \n    cm = confusion_matrix(test_Y, y_pred)\n    print(\"Confusion Matrix of %s is %s\"%(clf, cm))\n\n#TODO:Add a visualization plot of the scores.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Baseline logistic regression model\n\n#create an instance of the estimator\nlogit = LogisticRegression(solver='liblinear', random_state = 12)\n\n#Train the estimator\nlogit.fit(train_X,train_Y.values.ravel())\n\n# Check out the attributes of the model\n\nlogit.classes_ #look at the values y takes on. Confirmation is a binary classification\n#array([0, 1])\n\nlogit.intercept_ #look at the value of the slope\n#array([-0.17604356])\n\nlogit.coef_ #Look at the intercept values\n#array([[-0.57983499, -0.24361904, -0.04307553, -0.79347376, -0.37318144,\n#         0.52263995, -0.32550208,  0.0569691 ,  0.01272032,  0.01889203,\n#         0.02319488,  0.02325823]])\n\n#Evaluate the model\ny_pred_logit = logit.predict(test_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Model Performance\n\n#confusion matrix\nconf_matrix = confusion_matrix(test_Y,y_pred_logit)\n\nax = plt.subplot()\nsns.heatmap(conf_matrix, annot=True, ax = ax)\n\n# labels, title and ticks\nax.set_xlabel('Predicted labels')\nax.set_ylabel('Actual labels')\nax.set_title('Confusion Matrix')\nax.xaxis.set_ticklabels([\"Predicted Not churn\",\"Predicted Churn\"])\nax.yaxis.set_ticklabels([\"Actual Not churn\",\"Actual Churn\"]) \n\n\n#2000 customers that didn't churn that were correctly identified by the algorithm #TP\n#36 customers that churned that were correctly identified by the algorithm #TN\n#420 customers that churned but algorithm said they didn't. #FN\n#39 customers that didn't churn but algorithm said they did. #FP","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#A comprehensive report on the classification model using classification_report\n\nprint (\"\\n Classification report :\\n\",classification_report(test_Y,y_pred_logit))\n\n#Weighted avg Precision is 0.76/ recall is 0.82 and f1 score 0.76\n\n#F1 Score: 0.1348314606741573 - not super impressive\n\nprint (\"Accuracy   Score : \",accuracy_score(test_Y,y_pred_logit))\n\n#Accuracy   Score :  0.8152","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### KNN classifier\n\nknn = KNeighborsClassifier()\nknn.fit(train_X,train_Y.values.ravel())\n\n#Predict the response for test dataset\n\ny_pred_knn   = knn.predict(test_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"## Model Performance\n\n#confusion matrix\nconf_matrix_knn = confusion_matrix(test_Y,y_pred_knn)\n\nax = plt.subplot()\nsns.heatmap(conf_matrix_knn, annot=True, ax = ax)\n\n# labels, title and ticks\nax.set_xlabel('Predicted labels')\nax.set_ylabel('Actual labels')\nax.set_title('Confusion Matrix')\nax.xaxis.set_ticklabels([\"Predicted Not churn\",\"Predicted Churn\"])\nax.yaxis.set_ticklabels([\"Actual Not churn\",\"Actual Churn\"]) \n\n\n#1900 customers that didn't churn that were correctly identified by the algorithm #TP\n#110 customers that churned that were correctly identified by the algorithm #TN\n#340 customers that churned but algorithm said they didn't. #FN\n#150 customers that didn't churn but algorithm said they did. #FP","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#A comprehensive report on the classification model using classification_report\n\nprint (\"\\n Classification report :\\n\",classification_report(test_Y,y_pred_knn))\n\n#Weighted avg Precision is 0.77/ recall is 0.80 and f1 score 0.78\n\nprint (\"Accuracy   Score : \",accuracy_score(test_Y,y_pred_knn))\n\n#Accuracy   Score :  0.8024\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Advanced Model performance comparisions"},{"metadata":{"trusted":true},"cell_type":"code","source":"#roc_auc_score\nmodel_roc_auc = roc_auc_score(test_Y,y_pred_logit) \nprint (\"Area under curve : \",model_roc_auc,\"\\n\")\n\n#Area under curve :  0.5317859671333294 \n#TODO: Visualize","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#roc_auc_score - KNN\nmodel_roc_auc_knn = roc_auc_score(test_Y,y_pred_knn) \nprint (\"Area under curve : \",model_roc_auc_knn,\"\\n\")\n\n#Area under curve :  0.6447216358146673 \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot roc curve\n#fig2 = go.Figure(data = go.Scatter(x = fpr,y = tpr,\n #                       name = \"Roc : \" + str(model_roc_auc),\n #                       line = dict(color = ('rgb(22, 96, 167)'),width = 2)))\n# \n#fig2.add_trace(go.Scatter(x = [0,1],y=[0,1],\n                        line = dict(color = ('rgb(205, 12, 24)'),width = 2,\n                        dash = 'dot')))\n#fig2[\"layout\"][\"xaxis\"].update(dict(title = \"false positive rate\"))\n#fig2[\"layout\"][\"yaxis\"].update(dict(title = \"true positive rate\"))\n#fig2[\"layout\"][\"title\"].update(dict(text = \"Confusion Matrix\"))\n\n\n#fig2.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Evaluate model on precision and recall\n\n#print (\"\\n Classification report :\\n\",classification_report(test_Y,y_pred_dt))\n\n#Precision on 1's is 0.44 and recall is 0.51\n\n#print (\"Accuracy   Score : \",accuracy_score(test_Y,y_pred_dt))\n\n#Accuracy   Score :  0.7916\n\n#confusion matrix\n#conf_matrix1 = confusion_matrix(test_Y,y_pred_dt)\n\n#visualize confusion matrix\n\n#fig4 = go.Figure(data = go.Heatmap(z = conf_matrix1 ,\n    #                    x = [\"Not churn\",\"Churn\"],\n   #                     y = [\"Not churn\",\"Churn\"],\n  #                      showscale  = False,\n #                       name = \"matrix1\"))\n                \n#fig4.show()\n#roc_auc_score\n#model_roc_auc1 = roc_auc_score(test_Y,predictions) \n#print (\"Area under curve : \",model_roc_auc1,\"\\n\")\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Comparing all models on accuray roc/auc\n\n#plt.barh(y_pos, performance, align='center', alpha=0.5)\n#plt.yticks(y_pos, objects)\n#plt.xlabel('Usage')\n#plt.title('Model Performance')\n\n#plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Get coefficients to understand feature importance\n\ncoefficients  = pd.DataFrame(logit.coef_.ravel())\n\ncolumn_df     = pd.DataFrame(ind_var)\ncoef_sumry    = (pd.merge(coefficients,column_df,left_index= True,\n                          right_index= True, how = \"left\"))\ncoef_sumry.columns = [\"coefficients\",\"features\"]\n\ncoef_sumry    = coef_sumry.sort_values(by = \"coefficients\",ascending = False)\n\n#plot coeffs\nfig3 = go.Figure([go.Bar(x = coef_sumry[\"features\"],y = coef_sumry[\"coefficients\"],\n                name = \"coefficients\",\n                marker = dict(color = coef_sumry[\"coefficients\"],\n                              colorscale = \"Picnic\",\n                              line = dict(width = .6,color = \"black\")))])\nfig3[\"layout\"][\"title\"].update(dict(text = \"Feature Importance\"))\n\nfig3.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n##The precision is not very impressive, however, this could be improved by retraining the model with additional data.\n#Note: I only used baseline models, different variations of the models could have be used for better results. \n##Note: I used alot online resource while attempting this exercise.\n\n\n#Additional steps that could have been done\n#Cross validation\n#Using a validate set to fine tune","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}