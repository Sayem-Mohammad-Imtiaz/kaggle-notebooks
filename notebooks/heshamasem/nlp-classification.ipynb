{"cells":[{"metadata":{},"cell_type":"markdown","source":"# NLP Classification\nBy : Hesham Asem\n\n_____\n\nwe have 2 files sheet 1 & sheet 2\n\nsheet 1 contain 80 replies from users to chatbot , & it either classied as offensive (flagged) or non-offensive (not flagged)\n\nand sheet 2 contain 125 resumes , some of them looks unreal so it flagged & some are real : not flagged\n\nwe need to use NLP techniques to train our model , so he can be able to diffrentiate between them \n\n\nData File : https://www.kaggle.com/samdeeplearning/deepnlp\n\nlet's first import needed libraries\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set(style=\"whitegrid\")\nfrom nltk.corpus import stopwords\nfrom wordcloud import WordCloud\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nimport collections\nimport spacy\nnlp = spacy.load('en_core_web_sm')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"and read both files"},{"metadata":{"trusted":true},"cell_type":"code","source":"ResponseData = pd.read_csv(\"../input/deepnlp/Sheet_1.csv\",encoding='latin-1')\nResumeData = pd.read_csv(\"../input/deepnlp/Sheet_2.csv\",encoding='latin-1')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"so we'll start witjh responses file \n\n_____\n\n\n# Response File\n\nlet's have a look to the file"},{"metadata":{"trusted":true},"cell_type":"code","source":"ResponseData.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we'll just need 2 columns , which is response_text as X & class as y , let's drop the rest "},{"metadata":{"trusted":true},"cell_type":"code","source":"ResponseData.drop(['response_id','Unnamed: 3', 'Unnamed: 4','Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7'],axis=1, inplace=True)\nResponseData.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"what is the shape ? "},{"metadata":{"trusted":true},"cell_type":"code","source":"ResponseData.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"does it contain any nulls ? "},{"metadata":{"trusted":true},"cell_type":"code","source":"ResponseData.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"great , now how many flagged & non-flagged we have here ? "},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='class', data=ResponseData ,facecolor=(0, 0, 0, 0),linewidth=5,edgecolor=sns.color_palette(\"dark\", 3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"suitable ratios , now let's define the cloud function , to show most repeated words in each sector"},{"metadata":{"trusted":true},"cell_type":"code","source":"def cloud(text):\n    plt.figure(figsize=(15,15))\n    plt.imshow(WordCloud(background_color=\"white\",stopwords=set(stopwords.words('english')))\n               .generate(\" \".join([i for i in text.str.lower()])))\n    plt.axis(\"off\")\n    plt.title(\"Response could words\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"now we can show most repeated words in flagged reponses"},{"metadata":{"trusted":true},"cell_type":"code","source":"cloud(ResponseData[ResponseData['class']=='flagged']['response_text'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"many related words appear like : suicide , anxiety , addiction \n\nnow how not-flagged looks like"},{"metadata":{"trusted":true},"cell_type":"code","source":"cloud(ResponseData[ResponseData['class']=='not_flagged']['response_text'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"many normal words appear . \n\nbut since several words appeared here , so it might mislead the training , so we have to know most common words , then remove them since they are like stop words\n\nso we we'll define a function to know most common words"},{"metadata":{"trusted":true},"cell_type":"code","source":"def CommonWords(text , kk=10) : \n\n    all_words = []\n\n    for i in range(text.shape[0]) : \n        this_phrase = list(text)[i]\n        for word in this_phrase.split() : \n            all_words.append(word)\n\n    print(f'Total words are {len(all_words)} words')   \n    print('')\n\n    common_words = collections.Counter(all_words).most_common()\n    k=0\n    word_list =[]\n    for word, i in common_words : \n        if not word.lower() in  nlp.Defaults.stop_words :\n            print(f'The word is   {word}   repeated   {i}  times')\n            word_list.append(word)\n            k+=1\n        if k==kk : \n            break\n            \n    return word_list","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"then here . we'll get most common 5 words in not flagged responses"},{"metadata":{"trusted":true},"cell_type":"code","source":"words1 = CommonWords(ResponseData[ResponseData['class']=='not_flagged']['response_text'],5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"and here most common 5 words in flagged"},{"metadata":{"trusted":true},"cell_type":"code","source":"words2 = CommonWords(ResponseData[ResponseData['class']=='flagged']['response_text'],5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"now we camn add the two lists "},{"metadata":{"trusted":true},"cell_type":"code","source":"filtered_words = words1+words2\nfiltered_words","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"then define the removal function "},{"metadata":{"trusted":true},"cell_type":"code","source":"def RemoveWords(data , feature , new_feature, words_list ) : \n    new_column = []\n    for i in range(data.shape[0]) : \n        this_phrase = data[feature][i]\n        new_phrase = []\n        for word in this_phrase.split() : \n            if not word.lower() in words_list : \n                new_phrase.append(word)\n        new_column.append(' '.join(new_phrase))\n    \n    data.insert(data.shape[1],new_feature,new_column)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"now to remove these words & make a new column call filtered_text"},{"metadata":{"trusted":true},"cell_type":"code","source":"RemoveWords(ResponseData , 'response_text' , 'filtered_text' , filtered_words)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"now how data looks like"},{"metadata":{"trusted":true},"cell_type":"code","source":"ResponseData.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"& even we can make cloud again for flagged responses"},{"metadata":{"trusted":true},"cell_type":"code","source":"cloud(ResponseData[ResponseData['class']=='flagged']['filtered_text'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"now words are more representative \n\n& cloud for nonflagged responses"},{"metadata":{"trusted":true},"cell_type":"code","source":"cloud(ResponseData[ResponseData['class']=='not_flagged']['filtered_text'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"great , now we need to label encode the output"},{"metadata":{"trusted":true},"cell_type":"code","source":"enc  = LabelEncoder()\nenc.fit(ResponseData['class'])\nResponseData['class'] = enc.transform(ResponseData['class'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"how data looks like ? "},{"metadata":{"trusted":true},"cell_type":"code","source":"ResponseData.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"then we define X & y"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = ResponseData['filtered_text']\ny = ResponseData['class']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"how is X & y shapes ? "},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"then apply count vectorizer to make the sparse matrix to X"},{"metadata":{"trusted":true},"cell_type":"code","source":"VecModel = TfidfVectorizer()\nX = VecModel.fit_transform(X)\n\nprint(f'The new shape for X is {X.shape}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"and split the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=402)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('X_train shape is ' , X_train.shape)\nprint('X_test shape is ' , X_test.shape)\nprint('y_train shape is ' , y_train.shape)\nprint('y_test shape is ' , y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"let's use Decision Tree Classifier , with gini criterion& depth 10"},{"metadata":{"trusted":true},"cell_type":"code","source":"DecisionTreeClassifierModel = DecisionTreeClassifier(criterion='gini',max_depth=10,random_state=33) \nDecisionTreeClassifierModel.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"how is scores ? "},{"metadata":{"trusted":true},"cell_type":"code","source":"print('DecisionTreeClassifierModel Train Score is : ' , DecisionTreeClassifierModel.score(X_train, y_train))\nprint('DecisionTreeClassifierModel Test Score is : ' , DecisionTreeClassifierModel.score(X_test, y_test))\nprint('DecisionTreeClassifierModel Classes are : ' , DecisionTreeClassifierModel.classes_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ok 90% is fine enough , let's predict some result"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = DecisionTreeClassifierModel.predict(X_test)\ny_pred_prob = DecisionTreeClassifierModel.predict_proba(X_test)\nprint('Predicted Value for DecisionTreeClassifierModel is : ' , y_pred[:10])\nprint('Prediction Probabilities Value for DecisionTreeClassifierModel is : ' , y_pred_prob[:10])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"also we can use the model to predict new phrases we just invent now\n\nlet's form a normal phrase , it should classified as not-flagged"},{"metadata":{"trusted":true},"cell_type":"code","source":"phrase = ['I went to my friend to talk about normal issues']\nenc.inverse_transform(DecisionTreeClassifierModel.predict(VecModel.transform(phrase)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"great , now to form a weired phrase which looks like offensive"},{"metadata":{"trusted":true},"cell_type":"code","source":"phrase = ['I know a Friend was thinking about suicide']\nenc.inverse_transform(DecisionTreeClassifierModel.predict(VecModel.transform(phrase)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"good job , not let's move to Resume Data , to apply same steps\n\n______\n\n# Resume Data\n\nwe'll apply almost same steps here , as we did in responses "},{"metadata":{"trusted":true},"cell_type":"code","source":"ResumeData.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ResumeData.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ResumeData.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='class', data=ResumeData ,facecolor=(0, 0, 0, 0),linewidth=5,edgecolor=sns.color_palette(\"dark\", 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cloud(ResumeData[ResumeData['class']=='flagged']['resume_text'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cloud(ResumeData[ResumeData['class']=='not_flagged']['resume_text'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"words1 = CommonWords(ResumeData[ResumeData['class']=='flagged']['resume_text'],10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"words2 = CommonWords(ResumeData[ResumeData['class']=='not_flagged']['resume_text'],10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filtered_words = words1+words2\nfiltered_words","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RemoveWords(ResumeData , 'resume_text' , 'filtered_text' , filtered_words)\nResumeData.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cloud(ResumeData[ResumeData['class']=='flagged']['filtered_text'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cloud(ResumeData[ResumeData['class']=='not_flagged']['filtered_text'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"enc.fit(ResumeData['class'])\nResumeData['class'] = enc.transform(ResumeData['class'])\nResumeData.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = ResumeData['filtered_text']\ny = ResumeData['class']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = VecModel.fit_transform(X)\n\nprint(f'The new shape for X is {X.shape}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=102)\nprint('X_train shape is ' , X_train.shape)\nprint('X_test shape is ' , X_test.shape)\nprint('y_train shape is ' , y_train.shape)\nprint('y_test shape is ' , y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"here we'll use SVC since it will make better accuracy "},{"metadata":{"trusted":true},"cell_type":"code","source":"SVCModel = SVC(kernel= 'linear',# it can be also linear,poly,sigmoid,precomputed\n               max_iter=10000,C=10,gamma='auto')\nSVCModel.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('SVCModel Train Score is : ' , SVCModel.score(X_train, y_train))\nprint('SVCModel Test Score is : ' , SVCModel.score(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = SVCModel.predict(X_test)\nprint('Predicted Value for SVCModel is : ' , y_pred[:10])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}