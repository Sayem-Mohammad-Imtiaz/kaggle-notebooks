{"cells":[{"metadata":{},"cell_type":"markdown","source":"To enable autocomplete in kaggel just run this in consol\n\n%config Completer.use_jedi = False"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Read and see the first five rows of the train dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"df= pd.read_csv('/kaggle/input/health-insurance-cross-sell-prediction/train.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"check shape of the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# For EDA I have used Dtale but soon update the notebook with EDA and visulizations\n\n"},{"metadata":{},"cell_type":"markdown","source":"let's undrstand the data.\n\nId :column is unique identifier hence it has no role in prediction\n\nGender: Male 206089, female 175020\n\nAge: understand the distribution\n\nDriving_license: represent weather the owner posses the lincence or not. My undestanding of the domain says for insurance driving license is required. only 812 observations do not posses  driving license else do.\n\nRegion_code: Although looks like integer but it is a categorical data consisting of 53 unique values.\n\nVehicle age: categorical data 1-2 Year 200316, < 1 Year 164786,> 2 Years 16007 \n\nvehicle damage: categorical data Yes 192413, No 188696\n\n\n\n\n\n\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Gender.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.displot(df.Age)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Driving_License.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Region_Code.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Previously_Insured.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Vehicle_Age.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Vehicle_Damage.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Annual_Premium.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Policy_Sales_Channel.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Response.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n# It is an imbalanced problem.Will use oversampling/undersampling for balancing the data.\n> Data Preprocessing.\n"},{"metadata":{},"cell_type":"markdown","source":"Drop id, policy sales channel and vintage,Region code\n\nOne hot encode gender,vehical damage,driving license,previously insured.\n\nordinal encode vehical_age.\n\nbin and encode Annual premium and Age.\n\nresponse is a target."},{"metadata":{"trusted":true},"cell_type":"code","source":"df1= df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def data_prep(df):\n    df= df.drop(columns=['id','Policy_Sales_Channel','Vintage'])\n    df=pd.get_dummies(df,columns=['Gender'] ,prefix='Gender')\n    df=pd.get_dummies(df,columns=['Vehicle_Damage'] ,prefix='Damage')\n    df=pd.get_dummies(df,columns=['Driving_License'] ,prefix='License')\n    df=pd.get_dummies(df,columns=['Previously_Insured'] ,prefix='prev_insured')\n    df[\"Age\"] = pd.cut(df['Age'], bins=[0, 29, 35, 50, 100])\n    df['Age']= df['Age'].cat.codes\n    df['Annual_Premium'] = pd.cut(df['Annual_Premium'], bins=[0, 30000, 35000,40000, 45000, 50000, np.inf])\n    df['Annual_Premium']= df['Annual_Premium'].cat.codes\n    df['Vehicle_Age'] =df['Vehicle_Age'].map({'< 1 Year': 0, '1-2 Year': 1, '> 2 Years': 2})\n    df.drop(columns=['Region_Code'],inplace= True)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1=data_prep(df1)\ndf1.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Features to be used in modelling"},{"metadata":{"trusted":true},"cell_type":"code","source":"Features= ['Age','Vehicle_Age','Annual_Premium',\"Gender_Female\",\"Gender_Male\",\"Damage_No\",\"Damage_Yes\",\"License_0\",\"License_1\" ,\"prev_insured_0\", \"prev_insured_1\"]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# use train_test split when not using pycaret"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(df1[Features],df1['Response'], test_size = 0.3, random_state = 101)\nX_train.shape,X_test.shape\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Handle Imbalance using imblearn undersampling"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install imblearn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.under_sampling import RandomUnderSampler\nRUS = RandomUnderSampler(sampling_strategy=.5,random_state=3,)\nX_train,Y_train  = RUS.fit_resample(df1[Features],df1['Response'])\nX_train.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_train.value_counts()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Accuracy metrices"},{"metadata":{"trusted":true},"cell_type":"code","source":"def performance_met(model,X_train,Y_train,X_test,Y_test):\n    acc_train=accuracy_score(Y_train, model.predict(X_train))\n    f1_train=f1_score(Y_train, model.predict(X_train))\n    acc_test=accuracy_score(Y_test, model.predict(X_test))\n    f1_test=f1_score(Y_test, model.predict(X_test))\n    print(\"train score: accuracy:{} f1:{}\".format(acc_train,f1_train))\n    print(\"test score: accuracy:{} f1:{}\".format(acc_test,f1_test))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score,auc\nfrom sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression()\nmodel.fit(X_train,Y_train) \nperformance_met(model,X_train,Y_train,X_test,Y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nmodel_DT=DecisionTreeClassifier(random_state=1)\nmodel_DT.fit(X_train,Y_train)\nperformance_met(model_DT,X_train,Y_train,X_test,Y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nForest= RandomForestClassifier(random_state=1)\nForest.fit(X_train,Y_train)\nperformance_met(Forest,X_train,Y_train,X_test,Y_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nrf= RandomForestClassifier(random_state=1)\nparameters = {\n    'bootstrap': [True],\n'max_depth': [10, 20],\n'min_samples_leaf': [3, 4],\n'min_samples_split': [4, 6],\n'n_estimators': [100, 200],\n\n}\ngrid_search_1 = GridSearchCV(rf, parameters, cv=3, verbose=2, n_jobs=-1)\ngrid_search_1.fit(X_train, Y_train)\nperformance_met(grid_search_1,X_train,Y_train,X_test,Y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train['Response']=Y_train\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Let's use pycaret"},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install pycaret\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pycaret.classification import *\nclf1= setup(data=X_train,target='Response',data_split_stratify=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"compare_models(exclude=['xgboost'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Gradient Boosting classifier is the best performer, let's further work with it."},{"metadata":{"trusted":true},"cell_type":"code","source":"gbm= create_model('gbc')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_model(gbm,probability_threshold=.65)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(gbm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(gbm,'confusion_matrix')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(gbm,'feature')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Instead of plotting everything. Just evaluate the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluate_model(gbm)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Now let's have the test data and do the preprocessing to make it a fit for our model."},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df= pd.read_csv('../input/health-insurance-cross-sell-prediction/test.csv')\ntest_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df2=data_prep(test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction=predict_model(gbm,data=test_df2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission=pd.read_csv('../input/health-insurance-cross-sell-prediction/sample_submission.csv')\nsubmission['Response']=prediction['Label']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.Response.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('final_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# work in progress..."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}