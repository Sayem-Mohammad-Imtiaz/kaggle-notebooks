{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport pandas as pd\nimport numpy as np\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reading the input csv file with pandas\ndata = pd.read_csv('../input/ibm-hr-analytics-attrition-dataset/WA_Fn-UseC_-HR-Employee-Attrition.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We need to check if there are some indepandent variables which are highly correlated. For creating better model we need to \nreduce collinearity between indepandent variables.<br/>\n<b>Why to remove collinearity between the indepandent variables?</b><br>\nwhen variables are highly correlated change in one variable would cause change in another variable so the model results \nfluctuate. Even a small change in the data can results a varied change in the model results.<br><br>\n<b>How to check if the there is collinearity between the indepandent variables?</b><br>\n1) By Correlation Matrix <br>\n2) By Variance inflation factor <br><br>\n\nI am using the correlation matrix to identify the collinearity<br>"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = data.drop(['Attrition'], axis=1).corr()\nplt.figure(figsize=(10,10))\nsns.heatmap(corr, cmap='YlGnBu')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the upcoming code we will get rid of the idependent variables with multi collinearity.<br>\nColumn Age is highly correlated with columns Job Level, MonthlyIncome, NumCompaniesWorked etc."},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Attrition'] = data['Attrition'].apply(lambda row: 1 if row=='Yes' else 0)\ndata['Attrition'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"there is imbalanced data since the employees which are not retained are very few"},{"metadata":{},"cell_type":"markdown","source":"<b>Checking if any column contains null values</b>"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Checking if any column data type is not correct</b>"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Getting the descriptive stats of the dataframe</b>"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are some numerical columns from which we can create categorical variables <br>\n1) <b>DistanceFromHome</b><br>\n   distance from office can be convrted to nearby, middistance and far<br>\n2) <b>YearsInCurrentRole</b><br>\n   Years in current role can be converted to short, medium and long<br>\nsimilarly there are other columns <b>YearsWithCurrManager</b>, <b>YearsSinceLastPromotion</b>, <b>YearsAtCompany</b> etc<br>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def groupDistanceFromHome(data):\n    if int(data) >=1 and int(data) <= 5:\n        return 'NearBy'\n    elif int(data) >=6 and int(data) <= 15:\n        return 'MidDistance'\n    else:\n        return 'Far'\n\ndef groupYearsInCurrentRole(data):\n    if int(data) >=0 and int(data) <= 3:\n        return 'short'\n    elif int(data) >3 and int(data) <= 8:\n        return 'medium'\n    else:\n        return 'long'\n    \ndef groupYearsWithCurrManager(data):\n    if int(data) >=0 and int(data) <= 3:\n        return 'short'\n    elif int(data) >3 and int(data) <= 8:\n        return 'medium'\n    else:\n        return 'long'\n\ndef groupYearsSinceLastPromotion(data):\n    if int(data) >=0 and int(data) <= 3:\n        return 'short'\n    elif int(data) >3 and int(data) <= 8:\n        return 'medium'\n    else:\n        return 'long'\n\ndef groupYearsAtCompany(data):\n    if int(data) >=0 and int(data) <= 3:\n        return 'short'\n    elif int(data) >3 and int(data) <= 8:\n        return 'medium'\n    else:\n        return 'long'\n    \ndef groupTotalWorkingYears(data):\n    if int(data) >=0 and int(data) <= 8:\n        return 'short'\n    elif int(data) >8 and int(data) <= 15:\n        return 'medium'\n    else:\n        return 'long'\n\ndef groupPercentSalaryHike_by_rating(data):\n    if int(data) == 3:\n        return 'good'\n    elif int(data) == 4:\n        return 'better'\n    else:\n        return 'best'\n\ndef groupAverageWorkingYearInEachComp(data):\n    if int(data) >= 0 and int(data) <= 3:\n        return 'short'\n    elif int(data) >3 and int(data) <= 8:\n        return 'medium'\n    else:\n        return 'long'\n\ndef getAvgWorkingYearInEachComp(TotalWorkingYears, NumCompaniesWorked):\n    if NumCompaniesWorked == 0:\n        return TotalWorkingYears\n    else:\n        return TotalWorkingYears / NumCompaniesWorked","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['AverageWorkingYearInEachComp'] = data[['TotalWorkingYears', 'NumCompaniesWorked']].apply(lambda row: \n                                        getAvgWorkingYearInEachComp(row.TotalWorkingYears, row.NumCompaniesWorked), axis=1)\ndata['AverageWorkingYearInEachComp'] = data['AverageWorkingYearInEachComp'].astype(int)\ndata['AverageWorkingYearInEachComp'] = data['AverageWorkingYearInEachComp'].apply(lambda row:\n                                        groupAverageWorkingYearInEachComp(row))\ndata['DistanceFromHome'] = data['DistanceFromHome'].apply(lambda row: groupDistanceFromHome(row))\ndata['YearsInCurrentRole'] = data['YearsInCurrentRole'].apply(lambda row: groupYearsInCurrentRole(row))\ndata['YearsWithCurrManager'] = data['YearsWithCurrManager'].apply(lambda row: groupYearsWithCurrManager(row))\ndata['YearsSinceLastPromotion'] = data['YearsSinceLastPromotion'].apply(lambda row: groupYearsSinceLastPromotion(row))\ndata['YearsAtCompany'] = data['YearsAtCompany'].apply(lambda row: groupYearsAtCompany(row))\ndata['TotalWorkingYears'] = data['TotalWorkingYears'].apply(lambda row: groupTotalWorkingYears(row))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['MontlyIncomeByAge'] = data['MonthlyIncome'] / data['Age']\ndata['MontlyIncomeByAge'] = data['MontlyIncomeByAge'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(['EmployeeNumber', 'EmployeeCount','StandardHours', 'Over18'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"corr = data.corr()\nplt.figure(figsize=(10,10))\nsns.heatmap(corr, cmap='YlGnBu')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Getting the categorical columns and numerical columns</b>"},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_columns =[]\nfor col, value in data.drop(['Attrition'], axis=1).iteritems():\n    if value.dtype == 'object':\n        cat_columns.append(col)\nnum_columns = data.drop(['Attrition'], axis=1).columns.difference(cat_columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"categorical columns - %s\" %(cat_columns))\nprint(\"\")\nprint(\"numerical columns - %s\" %(num_columns))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"attrition_data = data['Attrition']\ncat_data = data[cat_columns]\nnum_data = data[num_columns]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Creating dummy variables for the categorical variables</b>"},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_data = pd.get_dummies(cat_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"now concatenating the dummyvariables columns with numerical data and depandent variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"final_data = pd.concat([cat_data, num_data, attrition_data], axis=1)\nfinal_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>converting the data to train and test</b><br>\nusing the train_size as 0.7 and test_size as 0.3"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data, test_data = train_test_split(final_data, train_size=0.7, test_size=0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = train_data['Attrition']\nX_train = train_data.drop(['Attrition'], axis=1)\ny_test = test_data['Attrition']\nX_test = test_data.drop(['Attrition'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Normalizing the numerical values.<br>\n<b>Why normalizing of data is required?</b><br>\nIt may happen some of the numerical columns contains outliers. To make our model robut and doesn't get impacted from the outliers we need to normalize the data.<br>\n\nI am using the MinMaxScaler to normalize the numerical columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler()\nX_train_transformed = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"using the below code snippet i am getting the corr matrix and removing the one of columns for which the absolute value \nof corr is greater than 0.8 "},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix = X_train_transformed.corr()\ncorr_features = set()\nfor i in range(len(corr_matrix.columns)):\n    for j in range(i):\n        if abs(corr_matrix.iloc[i,j]) > 0.8:\n            corr_features.add(corr_matrix.columns[i])\ncorr_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# removing the columns for from the transformed data for which the value is greater than 0.8\nX_train_transformed = X_train_transformed.drop(columns=list(corr_features), axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Applying the LogisticRegression with rfecv to get the 10 top most features that lead to employee attrition</b><br>\nLogistic Regression is used for <b>Binary Classification</b> and classify the data points to one of the two categories.<br><br>\n\n<b><u>RFECV</u></b> - Recursive Feature Selection and Cross Validation Selection\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"log_reg = LogisticRegression()\nrfe = RFECV(log_reg, cv=StratifiedKFold(5), scoring='neg_mean_squared_error', min_features_to_select=5)\nrfe.fit(X_train_transformed, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_transformed = X_train_transformed.drop(X_train_transformed.columns[np.where(rfe.support_ == False)], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"important_cols = pd.DataFrame()\nimportant_cols['Cols'] = X_train_transformed.columns\nimportant_cols['Percent'] = rfe.estimator_.coef_[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"important_cols = important_cols.sort_values(by='Percent', ascending=False)\nimportant_cols","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"selecting the first 12 features and creating a Logistic Regression model using the same"},{"metadata":{"trusted":true},"cell_type":"code","source":"### getting only the first 12 featues\nX_train_10_imp_feature = X_train_transformed[important_cols['Cols'].values[0:12]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_reg.fit(X_train_10_imp_feature, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_transform = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_transform_required_cols = X_test_transform[X_train_10_imp_feature.columns]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_pred = log_reg.predict(X_test_transform_required_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics.accuracy_score(y_test_pred, y_test)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}