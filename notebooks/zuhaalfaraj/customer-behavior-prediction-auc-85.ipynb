{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.core.display import HTML\nHTML(\"\"\"\n<style>\n.output_png {\n    display: table-cell;\n    text-align: center;\n    vertical-align: middle;\n}\n</style>\n\"\"\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"![](https://www.harvestassure.com/wp-content/uploads/2018/11/Vehicle-Insurance-Banner-1400x411.jpg)\n"},{"metadata":{},"cell_type":"markdown","source":"# Content:\n\n1. Data Exploration\n2. Data Analysis\n    * Categorical Data\n    * Numerical Data\n2. Preprocessing\n    * Data Cleaning\n    * Split to Training and Validation\n    * Balancing The Training Set (Oversampling)\n4. Ensemble Learning Models\n    * Descision Tree (The Base Estimator)\n    * Reinforcement Learning\n    * Adaboost \n    * Gradient Boosting\n    * XGBoost"},{"metadata":{},"cell_type":"markdown","source":"# Data Exploration"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/health-insurance-cross-sell-prediction/train.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\ndata.hist(bins=50,figsize=(12,9))\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix= data.corr()\ncorr_matrix['Response'].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nf, ax = plt.subplots(figsize=(12,12))\nsns.heatmap(data.corr(),annot=True, linewidths=.5, ax=ax)\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nlabels ='Not-responed', 'Responed'\nsizes = [len(data[data['Response']==0]),len(data[data['Response']==1])]\nexplode = (0, 0.04) \n\nfig1, ax1 = plt.subplots(figsize=(8,8))\nax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n        shadow=True, colors=('r','yellow'), startangle=90)\nax1.set_title(\"Response Events\")\nax1.axis('equal') \n\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Analysis"},{"metadata":{},"cell_type":"markdown","source":"## Categorical Data"},{"metadata":{},"cell_type":"markdown","source":"### Two-Categories Data (Gender, Previously_Insured, Vehicle_Damage)"},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_2=['Gender','Previously_Insured','Vehicle_Damage']\n\ntypes=[['Women','Men'],['No','Yes'],['No','Yes']]\nfor i,c in enumerate(cat_2):\n    alive = data[data['Response']==0]\n    died= data[data['Response']==1]\n    plt.figure(figsize=(8,5))\n    bar1=plt.bar(np.arange(len(data[c].unique())), alive.groupby(c).count()['Age'], width=0.1, color='orange', align='center', label=\"Not responed\")\n    bar2= plt.bar(np.arange(len(data[c].unique()))+0.1, died.groupby(c).count()['Age'], width=0.1, color='green', align='center', label=\"responed\")\n    plt.title(c)\n    #plt.ylim(0,160)\n    plt.xticks([0,1], types[i])\n    plt.grid()\n    plt.legend()\n\n    hights_odd=[]\n    hights_even=[]\n    for i,rect in enumerate (bar1 + bar2):\n        height = rect.get_height()\n        if (i+1)%2==0:\n            hights_even.append(height)\n        if (i+1)%2!=0:\n            hights_odd.append(height)\n\n    for i,rect in enumerate (bar1 + bar2):\n        height = rect.get_height()\n        if (i+1)%2==0:\n            plt.text(rect.get_x() + rect.get_width()/2.0, height, '%s' % str(round((height/sum(hights_even)*100),2))+\"%\", ha='center', va='bottom')\n        if (i+1)%2!=0:\n            plt.text(rect.get_x() + rect.get_width()/2.0, height, '%s' % str(round((height/sum(hights_odd))*100,2))+\"%\", ha='center', va='bottom')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Region Code"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,7))\nplt.title('Region Code')\nplt.grid()\nmaxx=0\nhigh=[]\nxs=[]\nfor i in sorted(data['Region_Code'].unique()):\n    bar= plt.bar(i,len(data[data['Region_Code']==i]))    \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Seems like a huge percentage of people are in region 28:"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nlabels ='region 28', 'all but not 28'\nsizes = [len(data[data['Region_Code']==28]),len(data[data['Region_Code']!=28])]\nexplode = (0, 0.04) \n\nfig1, ax1 = plt.subplots(figsize=(8,8))\nax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n        shadow=True, colors=('b','c'), startangle=90)\nax1.set_title(\"Response Events\")\nax1.axis('equal') \n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Vehicle Age"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Vehicle_Age'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"time_1= data[data['Vehicle_Age']=='< 1 Year']\ntime_2= data[data['Vehicle_Age']=='1-2 Year']\ntime_3= data[data['Vehicle_Age']=='> 2 Years']\n\nexplode = (0, 0.05)\nlabels = 'Not responsive', 'Responsive'\n\ntypes= [time_1,time_2,time_3,]\nfig, (ax1, ax2,ax3) = plt.subplots(1, 3,figsize=(13,7))\nax= (ax1, ax2,ax3)\nfig.suptitle('Vehicle Age virsus Reponses',fontsize=20)\ntitles= ['Less than a year', '1-2 years', 'More than two years']\n\n\n\nfor ax, typ,title in zip(ax,types,titles ):\n    \n    sizes = [len(typ[typ['Response']==0]),len(typ[typ['Response']==1])]\n    wedges, texts,autopct = ax.pie(sizes, autopct='%1.1f%%', explode=explode,colors=['r','y'], labels=labels)\n    ax.set_title(title)\n    \n    ax.axis('equal') \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Policy Sales Channel"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,7))\nplt.title('Policy Sales Channel')\nplt.grid()\nmaxx=0\nfor i in sorted(data['Policy_Sales_Channel'].unique()):\n    bar= plt.bar(i,len(data[data['Policy_Sales_Channel']==i]))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Numerical Data"},{"metadata":{},"cell_type":"markdown","source":"### Age"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom scipy.stats import norm\nimport matplotlib.pyplot as plt\n\ntypes= [data[data['Response']==0]['Age'], data[data['Response']==1]['Age']]\ntitles= [ 'Age Distribution for People Who Doesnt Responded with ', 'Age Distribution for People Who Responded with ']\ncolors=['r','blue']\n#age= data['Age']\n\nfor age, tit,color in zip(types, titles,colors):\n    mu, std = norm.fit(age)\n    plt.figure(figsize=(12,7))\n    plt.hist(age, bins=25, density=True, alpha=0.6, color=color)\n\n    xmin, xmax = plt.xlim()\n    x = np.linspace(xmin, xmax, 100)\n    p = norm.pdf(x, mu, std)\n    plt.plot(x, p, 'k', linewidth=2)\n    tit +=\"mu = %.2f,  std = %.2f\" % (mu, std)\n    plt.title(tit)\n    plt.grid()\n    plt.show()                \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,8))\nplt.xticks([1,2], ['Responeded', 'Not'])\nplt.boxplot(types)\nplt.title('Boxplot for Age cat')\nplt.grid()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Vintage"},{"metadata":{"trusted":true},"cell_type":"code","source":"v_1= data[data['Vintage']<100]\nv_2= data[data['Vintage']>100][data['Vintage']<200]\nv_3= data[data['Vintage']>200]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nexplode = (0, 0.05)\nlabels = 'Not responsive', 'Responsive'\n\ntypes= [v_1,v_2,v_3]\nfig, (ax1, ax2,ax3) = plt.subplots(1, 3,figsize=(13,7))\nax= (ax1, ax2,ax3)\nfig.suptitle('Vehicle Age vs Reponses',fontsize=20)\ntitles= ['Less than a year', '1-2 years', 'More than two years']\n\n\n\nfor ax, typ,title in zip(ax,types,titles ):\n    \n    sizes = [len(typ[typ['Response']==0]),len(typ[typ['Response']==1])]\n    wedges, texts,autopct = ax.pie(sizes, autopct='%1.1f%%', explode=explode,colors=['r','y'], labels=labels)\n    ax.set_title(title)\n    \n    ax.axis('equal') \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\nplt.bar([0,1,2], [len(v_1),len(v_2),len(v_3)], color='g')\nplt.xticks([0,1,2], ['Group1','Group2', 'Group3'])\nplt.title(\"Vintage Groups Data Distribution\")\nplt.grid()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Annual Premium"},{"metadata":{"trusted":true},"cell_type":"code","source":"min(data['Annual_Premium'])\nmax(data['Annual_Premium'])\n#Convert to US Dollar\ndata['Annual_Premium_$']= data['Annual_Premium']*0.014","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(min(data['Annual_Premium_$']))\nprint(max(data['Annual_Premium_$']))\nprint(np.median(data['Annual_Premium_$']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom scipy.stats import norm\nimport matplotlib.pyplot as plt\n\nap= data['Annual_Premium_$']\n#age= data['Age']\n\nmu, std = norm.fit(age)\nplt.figure(figsize=(10,7))\nplt.hist(ap, bins=25, density=True, alpha=0.6, color='r')\n\nxmin, xmax = plt.xlim()\nx = np.linspace(xmin, xmax, 100)\np = norm.pdf(x, mu, std)\ntit =\"mu = %.2f,  std = %.2f\" % (mu, std)\nplt.title(\"Annual Premium--\"+ tit)\nplt.grid()\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a_1= data[data['Annual_Premium_$']<=442]\na_2= data[data['Annual_Premium_$']>442]\n\nexplode = (0, 0.05)\nlabels = 'Not responsive', 'Responsive'\n\ntypes= [a_1,a_2]\nfig, (ax1, ax2) = plt.subplots(1, 2,figsize=(12,7))\nax= (ax1, ax2)\nfig.suptitle('Annual Premium ',fontsize=20)\ntitles= ['Less than mean value', 'More than mean value']\n\n\n\nfor ax, typ,title in zip(ax,types,titles ):\n    \n    sizes = [len(typ[typ['Response']==0]),len(typ[typ['Response']==1])]\n    wedges, texts,autopct = ax.pie(sizes, autopct='%1.1f%%', explode=explode,colors=['r','y'], labels=labels)\n    ax.set_title(title)\n    \n    ax.axis('equal') \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\nplt.bar([0,1], [len(a_1),len(a_2)], color='g')\nplt.xticks([0,1], ['Group1','Group2'])\nplt.title(\"Vintage Groups Data Distribution\")\nplt.grid()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"## Data Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Gender']=data['Gender'].astype('category').cat.codes\ndata['Vehicle_Age']= [0 if data['Vehicle_Age'][i]=='< 1 Year' else 1 if data['Vehicle_Age'][i]=='1-2 Year' else 2 for i in range(len(data['Vehicle_Age']))]\n#data['Vehicle_Age'] = data['Gender'].astype('category')\ndata['Vehicle_Damage']=data['Vehicle_Damage'].astype('category').cat.codes\ndata['Region_Code']= data['Region_Code'].astype(int)\n#data['Policy_Sales_Channel']= data['Policy_Sales_Channel'].astype('category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features=[ 'Gender', 'Age','Region_Code',\n       'Previously_Insured', 'Vehicle_Age','Vehicle_Damage', 'Annual_Premium',\n       'Policy_Sales_Channel', 'Vintage', 'Response']\n\nnum=[ 'Age','Annual_Premium','Vintage']\n\ntrain_prep=data[features]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"from category_encoders import TargetEncoder\n\nencoder = TargetEncoder()\ntrain_prep['Region_Code'] = encoder.fit_transform(train_prep['Region_Code'], train_prep['Response'])\ntrain_prep['Policy_Sales_Channel'] = encoder.fit_transform(train_prep['Policy_Sales_Channel'], train_prep['Response'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"#train_prep['Region_Code'] = train_prep['Region_Code'].astype('category',copy=False)\n#train_prep= pd.get_dummies(train_prep)\n\nfrom sklearn.preprocessing import StandardScaler\nstd=StandardScaler()\ntrain_prep[num]= std.fit_transform(train_prep[num])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_prep","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Split to Traing and Validation Sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit \nsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\nfor train_index, valid_index in split.split(train_prep, train_prep[\"Response\"]):\n    train = train_prep.loc[train_index]\n    valid = train_prep.loc[valid_index]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Balancing The Trainig Set (Oversampling)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\n# Resample the minority class. You can change the strategy to 'auto' if you are not sure.\nsm = SMOTE(sampling_strategy='minority', random_state=7)\n\n# Fit the model to generate the data.\noversampled_trainX, oversampled_trainY = sm.fit_sample(train.drop('Response', axis=1), train['Response'])\noversampled_train = pd.concat([oversampled_trainX, oversampled_trainY], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oversampled_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train= oversampled_train['Response']\ny_valid= valid['Response']\n\nX_train= oversampled_train.drop('Response', axis=1)\nX_valid= valid.drop('Response', axis=1)\n\nX_train.index = np.arange(len(X_train))\nX_valid.index = np.arange(len(X_valid))\n\ny_train.index = np.arange(len(y_train))\ny_valid.index = np.arange(len(y_valid))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeling"},{"metadata":{},"cell_type":"markdown","source":"## The Base Estimator: Decision Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ntree_clf = DecisionTreeClassifier(max_depth=3, random_state=42)\ntree_clf.fit(X_train, y_train)\n\ntree_preds = tree_clf.predict(X_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score\nfrom sklearn.metrics import precision_score, recall_score\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.metrics import roc_auc_score\nprint(\"Acc:\",accuracy_score(y_valid, tree_preds))\n\nprint(\"Precision:\",precision_score(y_valid, tree_preds))\n\nprint(\"Recall:\",recall_score(y_valid, tree_preds))\n\nprint('f1-score', f1_score(y_valid, tree_preds))\n\nprint('ROC score', roc_auc_score(y_valid, tree_preds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import os\nPROJECT_ROOT_DIR = \".\"\nCHAPTER_ID = \"decision_trees\"\nIMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\nos.makedirs(IMAGES_PATH, exist_ok=True)\n\ndef save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n    print(\"Saving figure\", fig_id)\n    if tight_layout:\n        plt.tight_layout()\n    plt.savefig(path, format=fig_extension, dpi=resolution)\n    \nfrom graphviz import Source\nfrom sklearn.tree import export_graphviz\n\nexport_graphviz(\n        tree_clf,\n        out_file=os.path.join(IMAGES_PATH, \"iris_tree.dot\"),\n        feature_names=X_train.columns,\n        class_names=['not resp', 'resp'],\n        rounded=True,\n        filled=True\n    )\n\nSource.from_file(os.path.join(IMAGES_PATH, \"iris_tree.dot\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest"},{"metadata":{},"cell_type":"markdown","source":"![](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/02/rfc_vs_dt1.png)"},{"metadata":{},"cell_type":"markdown","source":"### Hyperparameter Tuning: max_features"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\n\n\nkf = KFold(n_splits=2)\n\nmax_features = ['auto', 'sqrt','log2', None]\n\nrf_Model = RandomForestClassifier()\n\nrf_Grid = GridSearchCV(estimator = rf_Model, param_grid = {'max_features':max_features}, cv = kf,  scoring='accuracy',n_jobs=-1, verbose=4)\n\nrf_Grid.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_results = pd.concat([pd.DataFrame(rf_Grid.cv_results_[\"params\"]),pd.DataFrame(rf_Grid.cv_results_[\"mean_test_score\"], columns=[\"Accuracy\"])],axis=1)\ngrid_results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_Grid.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores_test = rf_Grid.cv_results_['mean_test_score']\n#scores = np.array(scores).reshape(len(Cs), len(n_estimators))\nplt.figure(figsize=(10,6))\nplt.plot([0,1,2,3], scores_test, label=\"Testing Error\")\nplt.xticks([0,1,2,3], ['auto', 'sqrt', 'log2', 'None'])\nplt.legend()\nplt.xlabel('n_estimators')\nplt.ylabel('Mean score')\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Hyperparameter Tuning: min_samples_leaf"},{"metadata":{"trusted":true},"cell_type":"code","source":"min_samples_leaf=[1,2,4, 6]\n    \nrf_leaf_Model = RandomForestClassifier()\n\nrf_leaf_Grid = GridSearchCV(estimator = rf_leaf_Model, param_grid = {'min_samples_leaf':min_samples_leaf}, cv = kf, verbose=5, n_jobs = -1)\n\nrf_leaf_Grid.fit(X_train, y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_leaf_results = pd.concat([pd.DataFrame(rf_leaf_Grid.cv_results_[\"params\"]),pd.DataFrame(rf_leaf_Grid.cv_results_[\"mean_test_score\"], columns=[\"Accuracy\"])],axis=1)\ngrid_leaf_results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_leaf_Grid.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Hyperparameter Tuning: max_depth"},{"metadata":{"trusted":true},"cell_type":"code","source":"max_depth = [None,2,4,6]\n\nrf_depth_Model = RandomForestClassifier()\n\nrf_dep_Grid = GridSearchCV(estimator = rf_depth_Model, param_grid = {'max_depth':max_depth}, cv = kf, verbose=2, n_jobs = -1)\n\nrf_dep_Grid.fit(X_train, y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_results = pd.concat([pd.DataFrame(rf_dep_Grid.cv_results_[\"params\"]),pd.DataFrame(rf_dep_Grid.cv_results_[\"mean_test_score\"], columns=[\"Accuracy\"])],axis=1)\ngrid_results.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_dep_Grid.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Hyperparameter Tuning: min_samples_split"},{"metadata":{"trusted":true},"cell_type":"code","source":"min_samples_split = [2,5,7]\n\nrf_mss_Model = RandomForestClassifier()\n\nrf_mss_Grid = GridSearchCV(estimator = rf_mss_Model, param_grid = {'min_samples_split':min_samples_split}, cv = kf, verbose=2, n_jobs = -1)\n\nrf_mss_Grid.fit(X_train, y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_results = pd.concat([pd.DataFrame(rf_mss_Grid.cv_results_[\"params\"]),pd.DataFrame(rf_mss_Grid.cv_results_[\"mean_test_score\"], columns=[\"Accuracy\"])],axis=1)\ngrid_results.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_mss_Grid.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train Using The Best Hyperparameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"rnd_clf = RandomForestClassifier( max_features=None,max_depth= None,\n                                 min_samples_leaf=1,min_samples_split=2, random_state=42)\n\nrnd_clf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rnf_preds= rnd_clf.predict(X_valid)\nprint(\"Acc:\",accuracy_score(y_valid, rnf_preds))\n\nprint(\"Precision:\",precision_score(y_valid, rnf_preds))\n\nprint(\"Recall:\",recall_score(y_valid, rnf_preds))\n\nprint('f1-score', f1_score(y_valid, rnf_preds))\n\nprint('ROC score', roc_auc_score(y_valid, rnf_preds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve,auc\ny_score = rnd_clf.predict_proba(X_valid)[:,1]\nfpr, tpr, _ = roc_curve(y_valid,y_score)\nimport matplotlib.pyplot as plt\n\nplt.title('Random Forest ROC curve')\nplt.xlabel('FPR (Precision)')\nplt.ylabel('TPR (Recall)')\n\nplt.plot(fpr,tpr)\nplt.plot((0,1), ls='dashed',color='black')\nplt.show()\nprint ('Area under curve (AUC): ', auc(fpr,tpr))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\nfilename = 'rf_clf.sav'\npickle.dump(rnd_clf, open(filename, 'wb'))\n\nfilename = 'rf_clf.sav'\nrf_load = pickle.load(open(filename, 'rb'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## AdaBoost"},{"metadata":{},"cell_type":"markdown","source":"![](https://www.researchgate.net/profile/Zhuo_Wang8/publication/288699540/figure/fig9/AS:668373486686246@1536364065786/Illustration-of-AdaBoost-algorithm-for-creating-a-strong-classifier-based-on-multiple.png)"},{"metadata":{},"cell_type":"markdown","source":"### Hyperparameters Tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nada=AdaBoostClassifier()\nlr= [0.01, 0.1,0.5, 1.0]\nsearch_grid={'learning_rate':lr}\nsearch=GridSearchCV(estimator=ada,param_grid=search_grid,scoring='accuracy',n_jobs=1,cv=kf,verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"search.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_results = pd.concat([pd.DataFrame(search.cv_results_[\"params\"]),\n                          pd.DataFrame(search.cv_results_[\"mean_test_score\"], columns=[\"Accuracy\"])],axis=1)\ngrid_contour = grid_results.groupby(['learning_rate']).mean()\ngrid_contour","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(search.best_score_)\nprint(search.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"search.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training Using Best Hyperparameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\n\nada_clf = AdaBoostClassifier(\n    DecisionTreeClassifier(max_depth=1), n_estimators=300, learning_rate=1, random_state=42)\nada_clf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ada_pred= ada_clf.predict(X_valid)\nprint(\"Acc:\",accuracy_score(y_valid, ada_pred))\n\nprint(\"Precision:\",precision_score(y_valid, ada_pred))\n\nprint(\"Recall:\",recall_score(y_valid, ada_pred))\n\nprint('f1-score', f1_score(y_valid, ada_pred))\n\nprint('ROC score', roc_auc_score(y_valid, ada_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve,auc\ny_score = ada_clf.predict_proba(X_valid)[:,1]\nfpr, tpr, _ = roc_curve(y_valid,y_score)\nimport matplotlib.pyplot as plt\n\nplt.title('AdaBoost ROC curve')\nplt.xlabel('FPR (Precision)')\nplt.ylabel('TPR (Recall)')\n\nplt.plot(fpr,tpr)\nplt.plot((0,1), ls='dashed',color='black')\nplt.show()\nprint ('Area under curve (AUC): ', auc(fpr,tpr))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filename = 'ada_clf.sav'\npickle.dump(ada_clf, open(filename, 'wb'))\n\nfilename = 'ada_clf.sav'\nrf_load = pickle.load(open(filename, 'rb'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Gradient Boosting"},{"metadata":{},"cell_type":"markdown","source":"![](https://s3.amazonaws.com/assets.datacamp.com/production/course_7714/datasets/Gradient_Boosting3.png)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\ngb = GradientBoostingClassifier(random_state = 42)\ngb.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gbrt_pred= gb.predict(X_valid)\nprint(\"Acc:\",accuracy_score(y_valid, gbrt_pred))\n\nprint(\"Precision:\",precision_score(y_valid, gbrt_pred))\n\nprint(\"Recall:\",recall_score(y_valid, gbrt_pred))\n\nprint('f1-score', f1_score(y_valid, gbrt_pred))\n\nprint('ROC score', roc_auc_score(y_valid, gbrt_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_score = gb.predict_proba(X_valid)[:,1]\nfpr, tpr, _ = roc_curve(y_valid,y_score)\n\nplt.title('Gadient Boosting ROC curve')\nplt.xlabel('FPR (Precision)')\nplt.ylabel('TPR (Recall)')\n\nplt.plot(fpr,tpr)\nplt.plot((0,1), ls='dashed',color='black')\nplt.show()\nprint ('Area under curve (AUC): ', auc(fpr,tpr))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filename = 'gb_clf.sav'\npickle.dump(gb, open(filename, 'wb'))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## XGBoost"},{"metadata":{},"cell_type":"markdown","source":"### Hyperparameter Tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\n\nparam_grid = {\n        'min_child_weight': [1, 5, 10],\n        'gamma': [0.5, 1, 1.5, 2, 5],\n        }\nxgboost_model = XGBClassifier()\n\nxgboost_search= GridSearchCV(estimator = xgboost_model, param_grid = param_grid, cv = 2, verbose=10, n_jobs = -1)\n\nxgboost_search.fit(X_train, y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_results = pd.concat([pd.DataFrame(xgboost_search.cv_results_[\"params\"]),\n                          pd.DataFrame(xgboost_search.cv_results_[\"mean_test_score\"], columns=[\"Accuracy\"])],axis=1)\ngrid_contour = grid_results.groupby(['gamma','min_child_weight']).mean()\ngrid_contour","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgboost_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train Using The Best Hyperparameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"xgboost_clf = XGBClassifier(gamma= 2, min_child_weight=1)\nxgboost_clf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_pred= xgboost_clf.predict(X_valid)\nprint(\"Acc:\",accuracy_score(y_valid, xgb_pred))\n\nprint(\"Precision:\",precision_score(y_valid, xgb_pred))\n\nprint(\"Recall:\",recall_score(y_valid, xgb_pred))\n\nprint('f1-score', f1_score(y_valid, xgb_pred))\n\nprint('ROC score', roc_auc_score(y_valid, xgb_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_score = xgboost_clf.predict_proba(X_valid)[:,1]\nfpr, tpr, _ = roc_curve(y_valid,y_score)\n\nplt.title('XGBoost ROC curve')\nplt.xlabel('FPR (Precision)')\nplt.ylabel('TPR (Recall)')\n\nplt.plot(fpr,tpr)\nplt.plot((0,1), ls='dashed',color='black')\nplt.show()\nprint ('Area under curve (AUC): ', auc(fpr,tpr))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filename = 'xgb_clf.sav'\npickle.dump(xgb_pred, open(filename, 'wb'))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Compare Models\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nproba_tree,proba_rnd, proba_ada, proba_gb, proba_xg = tree_clf.predict_proba(X_valid)[:,1], rnd_clf.predict_proba(X_valid)[:,1],ada_clf.predict_proba(X_valid)[:,1],gb.predict_proba(X_valid)[:,1],xgboost_clf.predict_proba(X_valid)[:,1]\n\npreds= [proba_tree,proba_rnd, proba_ada, proba_gb, proba_xg]\n\nlabels= ['DT','Random Forest', 'AdaBoost',\"Gradient Boosting\",'XGBoost']\nplt.figure(figsize=(10,8))\n\nfor pred, label in zip(preds,labels):\n    fpr, tpr, thresholds = roc_curve(y_valid, pred)\n    plt.plot(fpr, tpr, linewidth=2, label=label)\nplt.plot([0, 1], [0, 1], 'k--') # dashed diagonal\nplt.axis([0, 1, 0, 1])                                    \nplt.xlabel('False Positive Rate (Fall-Out)', fontsize=16) \nplt.ylabel('True Positive Rate (Recall)', fontsize=16)    \nplt.grid(True)  \nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = []\n\nresults = pd.DataFrame(columns= [\"Models\",\"Accuracy\"])\n\nfor model in [tree_clf, rnd_clf, ada_clf, gb, xgboost_clf]:\n    names = model.__class__.__name__\n    y_pred = model.predict(X_valid)\n    accuracy = accuracy_score(y_valid, y_pred)    \n    result = pd.DataFrame([[names, accuracy*100]], columns= [\"Models\",\"Accuracy\"])\n    results = results.append(result)\n    \n    \nsns.barplot(x= 'Accuracy', y = 'Models', data=results, color=\"r\")\nplt.xlabel('Accuracy %')\nplt.title('Accuracy Ratios of Models'); \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Get The Test Data Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/health-insurance-cross-sell-prediction/test.csv')\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Gender']=test['Gender'].astype('category').cat.codes\ntest['Vehicle_Age']= [0 if test['Vehicle_Age'][i]=='< 1 Year' else 1 if test['Vehicle_Age'][i]=='1-2 Year' else 2 for i in range(len(test['Vehicle_Age']))]\n#data['Vehicle_Age'] = data['Gender'].astype('category')\ntest['Vehicle_Damage']=test['Vehicle_Damage'].astype('category').cat.codes\ntest['Region_Code']= test['Region_Code'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features=[ 'Gender', 'Age','Region_Code',\n       'Previously_Insured', 'Vehicle_Age','Vehicle_Damage', 'Annual_Premium',\n       'Policy_Sales_Channel', 'Vintage']\n\nnum=[ 'Age','Annual_Premium','Vintage']\n\ntest_prep=test[features]\n\nstd=StandardScaler()\ntest_prep[num]= std.fit_transform(test_prep[num])\ntest_prep.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models_preds={}\n\nmodels= [tree_clf, rnd_clf, ada_clf, gb, xgboost_clf]\n\nfor model in models:\n    name = model.__class__.__name__\n    \n    models_preds[name]= model.predict(test_prep)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models_preds.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_rnd= pd.concat([pd.DataFrame(test['id']), pd.DataFrame(models_preds['RandomForestClassifier'])] ,axis=1)\nsub_rnd.columns=['id', 'Response']\nsub_rnd.to_csv(r'sub_rnd.csv')\n\nsub_ada= pd.concat([pd.DataFrame(test['id']), pd.DataFrame(models_preds['AdaBoostClassifier'])] ,axis=1)\nsub_ada.columns=['id', 'Response']\nsub_ada.to_csv(r'sub_ada.csv')\n\nsub_gb= pd.concat([pd.DataFrame(test['id']), pd.DataFrame(models_preds['GradientBoostingClassifier'])] ,axis=1)\nsub_gb.columns=['id', 'Response']\nsub_gb.to_csv(r'sub_gb.csv')\n\nsub_xgb= pd.concat([pd.DataFrame(test['id']), pd.DataFrame(models_preds['XGBClassifier'])] ,axis=1)\nsub_xgb.columns=['id', 'Response']\nsub_xgb.to_csv(r'sub_xgb.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}