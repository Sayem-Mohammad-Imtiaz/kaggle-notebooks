{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression Using Python"},{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\nIn this project, We use Logistic Regression to diagnose CKD.\n\nLogistic Regression is deemed a better model for this case, because in addition to being 100% accurate, it also allows us to quantify the impact of unit increases in specific variables on likelihood of having CKD.\n\nThere are three links you may find important:\n\nA set of chronic kidney disease (CKD) data and other biological factors. The CKD data dictionary. An article comparing the use of k-nearest neighbors and support vector machines on predicting CKD. Real-world problem: Develop a medical diagnosis test that is better than our current diagnosis system for CKD.\n\nData science problem: Develop a medical diagnosis test that reduces both the number of false positives and the number of false negatives.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Importing the necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport warnings\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler\n%matplotlib inline\n\nwarnings.filterwarnings(\"ignore\")\npd.set_option('display.max_columns',500)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1 Import the CKDISEASE DataSet [1 Mark]"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.read_csv(\"../input/ckdisease/kidney_disease.csv\")\ndataset.head","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check No of records and columns\ndataset.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Columns in the Dataset\ndataset.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dataset Info\ndataset.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.select_dtypes(include = 'object').head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2.\tIdentify the columns with missing values (1 point)."},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# unique value analysis\nfor col in dataset:\n    print (f\"{col}: has {dataset[col].nunique()} total unique value\")\n    print(f\"Unique Values: {dataset[col].unique()}\")\n    print(\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check Value Count for Final Feature\ndataset.classification.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Prerequiste to use RegEx with string, We need to replace the Null Value in String\ndataset['pcv'].fillna('0', inplace=True)\ndataset['wc'].fillna('0', inplace=True)\ndataset['rc'].fillna('0.0', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check the bar graph of categorical Data using factorplot\nsns.set_style(\"whitegrid\")\nsns.factorplot(data=dataset, x='rbc', kind= 'count',size=4,aspect=2)\nsns.factorplot(data=dataset, x='pc', kind= 'count',size=4,aspect=2)\nsns.factorplot(data=dataset, x='pcc', kind= 'count',size=4,aspect=2)\nsns.factorplot(data=dataset, x='ba', kind= 'count',size=4,aspect=2)\nsns.factorplot(data=dataset, x='pcv', kind= 'count',size=6,aspect=2)\nsns.factorplot(data=dataset, x='wc', kind= 'count',size=10,aspect=2)\nsns.factorplot(data=dataset, x='rc', kind= 'count',size=6,aspect=2)\nsns.factorplot(data=dataset, x='htn', kind= 'count',size=4,aspect=2)\nsns.factorplot(data=dataset, x='dm', kind= 'count',size=4,aspect=2)\nsns.factorplot(data=dataset, x='cad', kind= 'count',size=4,aspect=2)\nsns.factorplot(data=dataset, x='appet', kind= 'count',size=4,aspect=2)\nsns.factorplot(data=dataset, x='pe', kind= 'count',size=4,aspect=2)\nsns.factorplot(data=dataset, x='ane', kind= 'count',size=4,aspect=2)\nsns.factorplot(data=dataset, x='classification', kind= 'count',size=4,aspect=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Created Function to convert the Data into Correct Format","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\ndef get_number(val):\n    if val.strip():\n        val = val.strip()\n        txt= re.findall(\"\\d+\", val)\n        if len(txt) > 0:\n            return txt[0]\n        else:\n            return '0'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\ndef get_dec_number(val):\n    if val.strip():\n        val = val.strip()\n        txt= re.findall(\"\\d+\\.\\d+\", val)\n        if len(txt) > 0:\n            return txt[0]\n        else:\n            return '0'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Loop on the Dataset and convert the Non-Numeric Field to Numeric\nfor ind in dataset.index: \n    if dataset['rbc'] [ind] == 'normal':\n        dataset['rbc'] [ind] = '1'\n    elif dataset['rbc'] [ind] == 'abnormal':\n        dataset['rbc'] [ind] = '0'\n        \n    if dataset['pc'] [ind] == 'normal':\n        dataset['pc'] [ind] = '1'\n    elif dataset['pc'] [ind] == 'abnormal':\n        dataset['pc'] [ind] = '0' \n        \n    if dataset['pcc'] [ind] == 'present':\n        dataset['pcc'] [ind] = '1'\n    elif dataset['pcc'] [ind] == 'notpresent':\n        dataset['pcc'] [ind] = '0'  \n\n    if dataset['ba'] [ind] == 'present':\n        dataset['ba'] [ind] = '1'\n    elif dataset['ba'] [ind] == 'notpresent':\n        dataset['ba'] [ind] = '0'  \n    \n    if dataset['htn'] [ind] == 'yes':\n        dataset['htn'] [ind] = '1'\n    elif dataset['htn'] [ind] == 'no':\n        dataset['htn'] [ind] = '0'\n    \n    if dataset['appet'] [ind] == 'good':\n        dataset['appet'] [ind] = '1'\n    elif dataset['appet'] [ind] == 'poor':\n        dataset['appet'] [ind] = '0'\n        \n    if dataset['pe'] [ind] == 'yes':\n        dataset['pe'] [ind] = '1'\n    elif dataset['pe'] [ind] == 'no':\n        dataset['pe'] [ind] = '0'   \n\n    if dataset['ane'] [ind] == 'yes':\n        dataset['ane'] [ind] = '1'\n    elif dataset['ane'] [ind] == 'no':\n        dataset['ane'] [ind] = '0'  \n        \n    if dataset['dm'] [ind] == 'yes' or dataset['dm'] [ind] == ' yes':\n        dataset['dm'] [ind] = '1'\n    elif dataset['dm'] [ind] == 'no':\n        dataset['dm'] [ind] = '0'  \n    elif dataset['dm'] [ind] == '\\tyes':\n        dataset['dm'] [ind] = '1'\n    elif dataset['dm'] [ind] == '\\tno':\n        dataset['dm'] [ind] = '0' \n        \n    if dataset['cad'] [ind] == 'yes':\n        dataset['cad'] [ind] = '1'\n    elif dataset['cad'] [ind] == 'no':\n        dataset['cad'] [ind] = '0'  \n    elif dataset['cad'] [ind] == '\\tno':\n        dataset['cad'] [ind] = '0'   \n        \n    if dataset['classification'] [ind] == 'ckd':\n        dataset['classification'] [ind] = '1'\n    elif dataset['classification'] [ind] == 'notckd':\n        dataset['classification'] [ind] = '0'  \n    elif dataset['classification'] [ind] == 'ckd\\t':\n        dataset['classification'] [ind] = '1'\n    \n    dataset['pcv'] [ind] = get_number(dataset['pcv'] [ind])\n    dataset['wc'] [ind] = get_number(dataset['wc'] [ind])\n    dataset['rc'] [ind] = get_dec_number(dataset['rc'] [ind])\n\n#Check the bar graph of categorical Data using factorplot\nsns.set_style(\"whitegrid\")\nsns.factorplot(data=dataset, x='rbc', kind= 'count',size=4,aspect=2)\nsns.factorplot(data=dataset, x='pc', kind= 'count',size=4,aspect=2)\nsns.factorplot(data=dataset, x='pcc', kind= 'count',size=4,aspect=2)\nsns.factorplot(data=dataset, x='ba', kind= 'count',size=4,aspect=2)\nsns.factorplot(data=dataset, x='pcv', kind= 'count',size=6,aspect=2)\nsns.factorplot(data=dataset, x='wc', kind= 'count',size=10,aspect=2)\nsns.factorplot(data=dataset, x='rc', kind= 'count',size=6,aspect=2)\nsns.factorplot(data=dataset, x='htn', kind= 'count',size=4,aspect=2)\nsns.factorplot(data=dataset, x='dm', kind= 'count',size=4,aspect=2)\nsns.factorplot(data=dataset, x='cad', kind= 'count',size=4,aspect=2)\nsns.factorplot(data=dataset, x='appet', kind= 'count',size=4,aspect=2)\nsns.factorplot(data=dataset, x='pe', kind= 'count',size=4,aspect=2)\nsns.factorplot(data=dataset, x='ane', kind= 'count',size=4,aspect=2)\nsns.factorplot(data=dataset, x='classification', kind= 'count',size=4,aspect=2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Identify the Percentage of Null Value in Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"100*(dataset.isnull().sum()/dataset.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Change the Datatype to Int and Float from Object\ndataset[['pcv','wc','classification']].astype(dtype = 'int64')\ndataset[['rbc','pc','rc','pcc']].astype(dtype = 'float64')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check before Imputing Null Values\ndataset.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Imputing Null Values in Numeric Fields using Mean and in Categorical using Mode\ndataset['age'].fillna(dataset['age'].mean(), inplace=True)\ndataset['bp'].fillna(dataset['bp'].mean(), inplace=True)\ndataset['sg'].fillna(dataset['sg'].mean(), inplace=True)\ndataset['al'].fillna(dataset['al'].mean(), inplace=True)\ndataset['su'].fillna(dataset['su'].mean(), inplace=True)\ndataset['bgr'].fillna(dataset['bgr'].mean(), inplace=True)\ndataset['bu'].fillna(dataset['bu'].mean(), inplace=True)\ndataset['sc'].fillna(dataset['sc'].mean(), inplace=True)\ndataset['sod'].fillna(dataset['sod'].mean(), inplace=True)\ndataset['pot'].fillna(dataset['pot'].mean(), inplace=True)\ndataset['hemo'].fillna(dataset['hemo'].mean(), inplace=True)\ndataset['rbc'].fillna('1', inplace=True)\ndataset['pc'].fillna('1', inplace=True)\ndataset['pcc'].fillna('0', inplace=True)\ndataset['ba'].fillna('0', inplace=True)\ndataset['htn'].fillna('0', inplace=True)\ndataset['dm'].fillna('0', inplace=True)\ndataset['cad'].fillna('0', inplace=True)\ndataset['appet'].fillna('1', inplace=True)\ndataset['pe'].fillna('0', inplace=True)\ndataset['ane'].fillna('0', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check After Imputing Null Values\ndataset.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Transform non-numeric columns into numerical columns\n#Pre-requiste no null Values should be there in column\nfor column in dataset.columns:\n        if dataset[column].dtype == np.number:\n            continue\n        print(column)\n        dataset[column] = LabelEncoder().fit_transform(dataset[column])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# descriptive statistics\ndataset.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Identify Columns with Missing Values\ndataset.isna().sum(axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def draw_histograms(dataframe, features, rows, cols):\n    fig=plt.figure(figsize=(20,20))\n    for i, feature in enumerate(features):\n        ax=fig.add_subplot(rows,cols,i+1)\n        dataframe[feature].hist(bins=20,ax=ax,facecolor='midnightblue')\n        ax.set_title(feature+\" Distribution\",color='DarkRed')\n        \n    fig.tight_layout()  \n    plt.show()\ndraw_histograms(dataset,dataset.columns,10,10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f,ax=plt.subplots(figsize=(30,25))\nsns.heatmap(dataset.corr(),annot=True,fmt=\".2f\",ax=ax,linewidths=0.5,linecolor=\"orange\")\nplt.xticks(rotation=45)\nplt.yticks(rotation=45)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Drop Id and RC Column\n#Id is not related to Classification\n#PCV and RC are highly corelated\n#Also Drop High Negatively Corelated Features with Classification i.e sg,rbc,pc,sod,hemo,pcv,wc,rc,appet\ndataset.drop(['id','sg','rbc','pc','sod','hemo','pcv','wc','rc','appet'],axis = 1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#New Shape of Dataset\ndataset.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create Box Plot to Identify Outliers\ndataset.boxplot(return_type='dict')\nplt.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plot Separate BoxPlot for Features where max Outliers Identified\ndataset.boxplot(column=['bgr'],return_type='dict')\nplt.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Replace Outlier Values with Mean and again Plot the BoxPlot\ndataset['bgr'] = dataset['bgr'].apply(lambda x: dataset['bgr'].mean() if x>220 else x)\ndataset.boxplot(column=['bgr'],return_type='dict')\nplt.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4.Visualize the dataset using two appropriate plots. (2 points)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#RBC against Classification\nplt.figure(figsize = (30,15))\nsns.barplot(x='age', y ='classification', data=dataset,estimator=sum,orient=\"v\")\nplt.title('Age against Classification')\nplt.xlabel(\"Age\")\nplt.ylabel(\"Classification\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#From Above BarPlot we can see that the majority of the test are conducted for the Age Group 45 to 75"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check the distribution of Age and BP against Classification using scatter plot\nfig, axs = plt.subplots(1,2, figsize=(15, 5), sharey=True)\naxs[0].scatter(data=dataset, x='al', y='classification')\nplt.xlabel(\"AL\")\nplt.ylabel(\"Classification\")\naxs[1].scatter(data=dataset, x='bp', y='classification', color = 'red')\nfig.suptitle('Scatter plot for Al and BP against Classification')\nplt.xlabel(\"Bp\")\nplt.ylabel(\"Classification\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#From Above Scatter Plot we can see that for Al amore than 1 clearly end with CKD\n#Similarly for BP more than 80 also results in CKD","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3.Extract X as all columns except the last column and Y as last column. (1 point). "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Determining the predictors/features(X) and response/Class Label (Y)\nX = dataset.iloc[:,0:14].values\nX","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y = dataset.iloc[:,[15]].values\nY","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Min Max Scaling\nscaler = MinMaxScaler(feature_range=(0, 1))\nX = scaler.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n#Making Confusion Matrix\nfrom sklearn.metrics import confusion_matrix,classification_report\n\ndef get_score(model, X_train, X_test, Y_train, Y_test):\n    model.fit(X_train, Y_train)\n    Y_pred = model.predict(X_test)\n    cm = confusion_matrix(Y_test,Y_pred)\n    print(\"Confusion Matrix /n\", cm)\n    print(classification_report(Y_test,Y_pred))\n    return model.score(X_test, Y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Perform 10 fold cross validation. (1 point)\n5.\tSplit the data into training set and testing set. (1 points)\n6.\tTrain a Logistic regression model for the dataset. (1 points)\n7.\tDisplay the coefficients and form the logistic regression equation. (2 point)\n8.\tCompute the accuracy and confusion matrix. (2 points)"},{"metadata":{"trusted":true},"cell_type":"code","source":"scores_l = []\n#Perform 10 fold cross validation\nfrom sklearn.model_selection import StratifiedKFold \nkf = StratifiedKFold(n_splits=10, random_state=None) \n\nfor train_index, test_index in kf.split(X,Y):\n      print(\"\\n\\nTrain:\", train_index, \"\\nValidation:\",test_index)\n      X_train, X_test = X[train_index], X[test_index] \n      Y_train, Y_test = Y[train_index], Y[test_index]\n      scores_l.append(get_score(LogisticRegression(), X_train, X_test, Y_train, Y_test))\n      print(get_score(LogisticRegression(), X_train, X_test, Y_train, Y_test))                ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores_l","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 9.\tPlot the decision boundary and test results. (1 point)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualising the Test set results,\nfrom sklearn.decomposition import PCA \nfrom matplotlib.colors import ListedColormap\npca = PCA(n_components = 2) \n  \nX_train = pca.fit_transform(X_train) \nX_test = pca.transform(X_test) \n  \nexplained_variance = pca.explained_variance_ratio_ \n\nX_set, y_set = X_test, Y_test,\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\nmodel = LogisticRegression() \nmodel.fit(X_train, Y_train)\nplt.contourf(X1, X2, model.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n             alpha = 0.75, cmap = ListedColormap(('red', 'green'))),\nplt.xlim(X1.min(), X1.max()),\nplt.ylim(X2.min(), X2.max()),\nfor i, j in enumerate(np.unique(y_set)):\n    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n                c = ListedColormap(('red', 'green'))(i), label = j)  \nplt.scatter(X_test.iloc[:, 0], X_test.iloc[:, 1], c=Y, edgecolors='k', cmap=plt.cm.Paired)\nplt.title('Logistic Regression (Test set)')\nplt.xlabel('Features PC1')\nplt.ylabel('Predicted Values PC2')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":1}