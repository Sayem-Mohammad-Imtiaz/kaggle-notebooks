{"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"},"language_info":{"nbconvert_exporter":"python","version":"3.6.4","pygments_lexer":"ipython3","mimetype":"text/x-python","name":"python","file_extension":".py","codemirror_mode":{"name":"ipython","version":3}}},"nbformat_minor":1,"nbformat":4,"cells":[{"metadata":{"_cell_guid":"2811a6e0-ef20-473e-92ae-653a54e002ef","_uuid":"9ae7e93aca9e988f5429235e1a7ce96776462039"},"outputs":[],"execution_count":null,"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"#Load the dataset\ndata = pd.read_csv(\"../input/mushrooms.csv\")"},{"metadata":{},"outputs":[],"execution_count":null,"cell_type":"code","source":"#Check the data\ndata.head()"},{"metadata":{},"outputs":[],"execution_count":null,"cell_type":"code","source":"#Shape of the data\ndata.shape"},{"metadata":{},"outputs":[],"execution_count":null,"cell_type":"code","source":"data.info()"},{"metadata":{},"cell_type":"markdown","source":"All variables are **categorical**. There are no missing values."},{"metadata":{},"outputs":[],"execution_count":null,"cell_type":"code","source":"data.describe(include='all').transpose()"},{"metadata":{},"cell_type":"markdown","source":"class has only 2 categories. e and p. The proportion of e in dataset is 4208/8124 = 51.8%. **It is a balanced dataset**\n\nveil_type has only one category, so it will not add any value. We sill drop this variable.\nSome variables (gill_attachment, veil_color, ring_number) have higher percentage on one category. We will explore more to understand.****"},{"metadata":{},"outputs":[],"execution_count":null,"cell_type":"code","source":"#dropping variable veil_type\ndata = data.drop([\"veil-type\"], axis = 1)"},{"metadata":{},"outputs":[],"execution_count":null,"cell_type":"code","source":"#seperating the dependant and independant variables.\nfeatures = data.columns\ntarget = 'class'\nfeatures = list(features.drop(target))\nfeatures"},{"metadata":{"scrolled":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"# There are 21 variables, so a plot is divided into 11 rows and 2 columns.\nfig, axs = plt.subplots(nrows=11, ncols=2, figsize=(11, 66))\n\nfor f, ax in zip(features, axs.ravel()):\n    sns.countplot(x=f, hue='class', data=data, ax = ax)"},{"metadata":{},"cell_type":"markdown","source":"Let us understand the graphs one by one. \n1. cap-shape: Categories 'x' and 'f' have approximately equal number of poisonous(p) and edible(e) mushrooms. They don't differentiate between 'p' and 'e'. Category 'b' has mostly edible mushrooms. Category 's' and 'c' have very small presence. (This might not be a good feature)\n2. cap-surface: Category 's' and 'y' have equal 'p' and 'e' mushrooms. Category 'f' have 50% more 'e' mushrooms. Very little presence of category 'g'. (This might not be a good feature)\n3. cap-color: Each category has both the types of mushrooms. (This might not be a good feature)\n4. bruises: Category 't' are majorly edible musrooms and category 'f' are poisonous.\n5. odor: Each category is either a poisonous or edible mushroom.\n6. gill-attachment: (This might not be a good feature)\n7. gill-spacing: It does not distinguish very clearly but can be a helpful feature.\n8. gill-size: Each category is either a poisonous or edible mushroom.\n9. gill-color: Here we can see, few colors distinguish very clearly between 'p' and 'e'/\n10. stalk-shape: (This might not be a good feature)\n11. stalk-root: Can be used as a feature.\n12. stalk-surface-above-ring: Can be used as a feature.\n13. stalk-surface-below-ring: Can be used as a feature.\n14. stalk-color-above-ring: Can be used as a feature.\n15. stalk-color-below-ring: Can be used as a feature.\n16. veil-color: (This might not be a good feature)\n17. ring-number: (This might not be a good feature)\n18. ring-type: Can be used as a feature.\n19. spore-print-color: Can be used as a feature.\n20. population: Can be used as a feature.\n21. habitat: Can be used as a feature."},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"#Converting categories to numbers (Label encoding)\nfrom sklearn import preprocessing\nlabelEncoder = preprocessing.LabelEncoder()\nfor col in data.columns:\n    data[col] = labelEncoder.fit_transform(data[col])"},{"metadata":{},"outputs":[],"execution_count":null,"cell_type":"code","source":"data.describe().transpose()"},{"metadata":{},"outputs":[],"execution_count":null,"cell_type":"code","source":"plt.figure(figsize=(14,12))\nsns.heatmap(data.corr(),linewidths=.1,cmap=\"GnBu\", annot=True)"},{"metadata":{},"cell_type":"markdown","source":"### Splitting the dataset"},{"metadata":{},"outputs":[],"execution_count":null,"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(data.loc[:,features],data.loc[:,target],test_size=0.3,random_state=0)\nprint ('Train data set', X_train.shape)\nprint ('Test data set', X_test.shape)"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n\nLR = LogisticRegression(random_state = 0)"},{"metadata":{},"outputs":[],"execution_count":null,"cell_type":"code","source":"# Using all features\nLR.fit(X_train,y_train)"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"y_pred = LR.predict(X_test)"},{"metadata":{},"outputs":[],"execution_count":null,"cell_type":"code","source":"#Let's see how our model performed\nprint(classification_report(y_test, y_pred))"},{"metadata":{},"cell_type":"markdown","source":"**Logistic Regression gives an accuracy of 95%**"},{"metadata":{},"outputs":[],"execution_count":null,"cell_type":"code","source":"#Confusion matrix for the LR classification\nprint(confusion_matrix(y_test, y_pred))"},{"metadata":{},"cell_type":"markdown","source":"False Positive: 80 \nFalse Negative: 49"},{"metadata":{},"outputs":[],"execution_count":null,"cell_type":"code","source":"#AUC for the LR classification\nauc_roc=roc_auc_score(y_test,y_pred)\nprint ('AUC using LR %0.3f' % (auc_roc))"},{"metadata":{},"cell_type":"markdown","source":"Now, using cross validation evaluation technique to optimize the model performance."},{"metadata":{},"outputs":[],"execution_count":null,"cell_type":"code","source":"#Now lets try to do some evaluation for random forest model using cross validation.\nLR_eval = cross_val_score(estimator = LR, X = X_train, y = y_train, cv = 10)\nLR_eval.mean()"},{"metadata":{},"cell_type":"markdown","source":"The Score does not improve. Accuracy is still 95%\n\n\n### Next I will use less features and check if there is any improvement.\n### After that I will use other classifications algorithm and see the difference."},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":""}]}