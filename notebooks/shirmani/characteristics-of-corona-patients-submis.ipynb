{"cells":[{"metadata":{},"cell_type":"markdown","source":"**The purpose of this notebook is to create a DATASET that includes**\n\n** Characteristics of patients like - **\n\n*age\n\n*sex\n\n*Country\n\nand so\n\n\n\n\n**The condition of the patients and their characteristics - **\n\n* Disease time (from diagnosis date)\n\n* Have been cured\n \n* Deaths\n\n\nThe database is designed to allow easy exploration of the data\n\nAnyone interested can use and donate"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import nltk\nimport pandas as pd \nimport  numpy as np\nfrom collections import Counter\nfrom ds_exam import *\nfrom update_time import *\nfrom bag_words import *","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"france = pd.read_csv(\"/kaggle/input/coronavirus-france-dataset/patient.csv\")\ntunisia = pd.read_csv(\"../input/coronavirus-tunisia/Coronavirus_Tunisia.csv\")\njapan = pd.read_csv(\"/kaggle/input/close-contact-status-of-corona-in-japan/COVID-19_Japan_Mar_07th_2020.csv\")\nindonesia = pd.read_csv(\"/kaggle/input/indonesia-coronavirus-cases/patient.csv\")\nkorea = pd.read_csv(\"/kaggle/input/coronavirusdataset/PatientInfo.csv\")\nHubei = pd.read_csv(\"/kaggle/input/covid19official/Hubei.csv\")\noutside_Hubei = pd.read_csv(\"/kaggle/input/covid19official/outside_Hubei.csv\")\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datasets = [france, tunisia, japan, indonesia, korea, Hubei, outside_Hubei]\ndatasets_name = [\"france\", \"tunisia\", \"japan\", \"indonesia\", \"korea\", \"Hubei\", \"outside_Hubei\"]\n\ngarbge = [print(\"\\n\"+datasets_name[i], [i for i in datasets[i].columns]) for i in range(len(datasets_name))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# datasets.shape"},{"metadata":{"trusted":true},"cell_type":"code","source":"o = []\nfor i in range(len(datasets)):\n    print(datasets_name[i],datasets[i].shape)\n    o.append(datasets[i].shape[0])\nprint(\"\\nnum of i \" + str(sum(o)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# change name of col"},{"metadata":{"trusted":true},"cell_type":"code","source":"france.rename(columns={\"health\":\"severity_illness\",\"status\":\"treatment\",\"infection_reason\":\"infection_place\"}\n              , inplace = True)\n\ntunisia.rename(columns={\"date\":\"confirmed_date\", \"gender\":\"sex\", \"situation\":\"severity_illness\", \n                        \"return_from\":\"infection_place\", \"health\":\"background_diseases\", \"hospital_name\":\"treatment\"}, inplace = True)\n\njapan.rename(columns={\"No.\":\"id\", \"Fixed date\":\"confirmed_date\",\"Age\":\"age\", \"residence\":\"region\",\n                      \"Surrounding patients *\":\"infected_by\"}, inplace = True)\n\nindonesia.rename(columns={\"patient_id\":\"id\",\"gender\": \"sex\", \"province\":\"region\", \"hospital\":\"treatment\",\n                          \"contacted_with\":\"infected_by\", \"current_state\":\"severity_illness\"}, inplace = True)\n\nkorea.rename(columns={\"patient_id\":\"id\", \"disease\":\"background_diseases_binary\", \"state\":\"severity_illness\",\n                      \"province\":\"region\", \"infection_case\" :\"infection_place\",\n                      \"symptom_onset_date\":\"date_onset_symptoms\"}, inplace = True)\n\nHubei = Hubei.rename(columns={ \"province\":\"region\",\"date_confirmation\": \"confirmed_date\",\n                              \"chronic_disease_binary\":\"background_diseases_binary\", \n                              \"chronic_disease\":\"background_diseases\", \"outcome\":\"severity_illness\",\n                               \"travel_history_location\":\"infection_place\"})\n\noutside_Hubei = outside_Hubei.rename(columns={ \"province\":\"region\", \"date_confirmation\": \"confirmed_date\",\n                              \"chronic_disease_binary\":\"background_diseases_binary\", \n                              \"chronic_disease\":\"background_diseases\", \"outcome\":\"severity_illness\", \n                              \"travel_history_location\":\"infection_place\",'travel_history_dates': \"return_date\", \n                              \"travel_history_location\":\"infection_place\" })\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# exam_df = columns vs dfs"},{"metadata":{"trusted":true},"cell_type":"code","source":"datasets = [france, tunisia, japan, indonesia, korea, Hubei, outside_Hubei]\ncolumns_name = Exam.build_columns_name_ls(datasets)\nexam_df = Exam.df_exam_columns_dfs(datasets,datasets_name,columns_name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def full_common(exam_df):\n    \"\"\"\n    Returns columns that all DATASETS have\n    \"\"\"\n    full_common = []\n    for j in exam_df.columns:\n        boolyan = exam_df[j].all()\n        if boolyan == True:\n            full_common.append(j)\n    return full_common","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"common = []\nunique = []\nblank = []\nfor i in exam_df.columns:\n    if exam_df[i].value_counts()[True]>1:\n        common.append(i)\n    elif exam_df[i].value_counts()[True]==1:\n        unique.append(i)\n    else:\n        blank.append(i)\n        \n        \nprint(common)\nprint(unique)\nprint(blank)   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# drop feature"},{"metadata":{},"cell_type":"markdown","source":"Tests for columns' usefulness before drop"},{"metadata":{},"cell_type":"markdown","source":"country_new"},{"metadata":{"trusted":true},"cell_type":"code","source":"for x in [outside_Hubei, Hubei]:\n    l = x.index[x.country_new.notnull() == True]\n    p = []\n    for i in l:\n        if x.country_new[i] == x.country[i]:\n            p.append(i)\n\n    print(\"country_new == country\",len(p))\n    print(\"country_new.notnull\",len(l),\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The column has no new information to give"},{"metadata":{},"cell_type":"markdown","source":"ID"},{"metadata":{"trusted":true},"cell_type":"code","source":"for x in [outside_Hubei, Hubei]:\n    m =[]\n    for i in range(len(x)):\n        if x.ID[i] != str(i+1):\n            m.append(i)\n    print(m[0],x.ID[m[0]])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see the ID is not arranged in any numerical order.\nand because there is no column that needs another row identifier\nI drop ID"},{"metadata":{},"cell_type":"markdown","source":"# drop"},{"metadata":{"trusted":true},"cell_type":"code","source":"france = france.drop(['id', \"departement\",\"source\",\"comments\",\"contact_number\"],axis=1)\n\n\nindonesia = indonesia.drop([\"id\", 'nationality'],axis=1)\njapan = japan.drop([\"id\"],axis=1)\n\nkorea = korea.drop([\"id\", \"age\",\"contact_number\"],axis=1)\n\nHubei = Hubei.drop([\"ID\",'location', 'admin3', 'admin2', \"admin1\" ,'latitude', 'longitude',\n                    'geo_resolution','admin_id', \"country_new\",\"source\",\"additional_information\",\"geo_resolution\"\n                    ,\"notes_for_discussion\"],axis=1)\n\noutside_Hubei = outside_Hubei.drop([\"ID\",'location', 'admin3', 'admin2', \"admin1\" ,'latitude', 'longitude',\n                                    'geo_resolution', 'admin_id', \"country_new\", \"data_moderator_initials\",\n                                    \"source\",\"additional_information\",\"geo_resolution\",\n                                    \"notes_for_discussion\"],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Examining values - v1 "},{"metadata":{"trusted":true},"cell_type":"code","source":"def examining_values_by_col (datasets, datasets_name, col):\n    \"\"\"\n    Prints values of each DF per column\n    \"\"\"\n    counter = 0\n    \n    for i in datasets:\n        if col in i.columns:\n            print(\"\\n\" + datasets_name[counter])\n            print(i[col].value_counts())\n        counter =counter + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datasets = [france, tunisia, japan, indonesia, korea, Hubei, outside_Hubei]\ncolumns_name = Exam.build_columns_name_ls(datasets)\nexam_df = Exam.df_exam_columns_dfs(datasets,datasets_name,columns_name)\n\nfor j in exam_df.columns[1:len(exam_df.columns)]:\n    print(j)\n    examining_values_by_col (datasets , datasets_name , j) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# format col"},{"metadata":{},"cell_type":"markdown","source":">datetime"},{"metadata":{"trusted":true},"cell_type":"code","source":"l1= tunisia.index[tunisia[\"return_date\"] == \"Local\"]\nl2 = tunisia.index[ tunisia[\"return_date\"].notnull()]\n\nindex = l2.drop(l1)\n\nfor indx in index:\n    tunisia.loc[indx,\"return_date\"] = pd.to_datetime(tunisia.loc[indx,\"return_date\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### CPU\ncols = [\"confirmed_date\",\"released_date\", \"deceased_date\"]\n\nfrance[cols] = france[cols].apply(pd.to_datetime)\nindonesia[cols] = france[cols].apply(pd.to_datetime)\njapan[cols] = france[cols].apply(pd.to_datetime)\nkorea[cols] = korea[cols].apply(pd.to_datetime)\n\n#### different#####\n\n# korea\nkorea_col = [\"date_onset_symptoms\"]\nkorea[korea_col] = korea[korea_col].apply(pd.to_datetime)\n\n#  tunisia\ntunisia_col = [\"confirmed_date\"]\ntunisia[tunisia_col] = tunisia[tunisia_col].apply(pd.to_datetime)\n\n# Hubei\nHubei_col = [\"confirmed_date\", \"date_death_or_discharge\", \"date_onset_symptoms\"]\nHubei[Hubei_col] = Hubei[Hubei_col].apply(pd.to_datetime)\n\n# outside_Hubei\noutside_Hubei_col = [\"date_death_or_discharge\"]\noutside_Hubei[outside_Hubei_col] = outside_Hubei[outside_Hubei_col].apply(pd.to_datetime)\n\n# 'travel_history_dates'\nfor j in [\"confirmed_date\", \"date_onset_symptoms\"]:\n    indexs = outside_Hubei.index[outside_Hubei[j].notnull()]\n    indexs_ , error = UpdateTime.updte_time(outside_Hubei, j, j, indexs,\".\",[ \"-\", ','])\n    print(j , error)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"indexs =  outside_Hubei.index[outside_Hubei[\"return_date\"].notnull()]\n\nfor indx in indexs:\n    i = outside_Hubei.loc[indx, \"return_date\"]\n    i = i.split(\"-\")\n\n    for x in range(len(i)):\n        i[x] = pd.to_datetime(i[x], errors='ignore')\n\n\n        if len(i) == 1:\n            pass\n            outside_Hubei.loc[indx , \"return_date\"] = i[0]\n\n        elif len(i)>1 and type(i[0]) == type(i[1]):\n            outside_Hubei.loc[indx , \"return_date\"] =  pd.DataFrame({\"t\":i}).max()[0]\n        \n        \noutside_Hubei[\"return_date\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# error\noutside_Hubei.index[outside_Hubei[\"date_onset_symptoms\"] == \"- 25.02.2020\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"examining_values_by_col (datasets , datasets_name , \"date_onset_symptoms\") ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"sex"},{"metadata":{"trusted":true},"cell_type":"code","source":"tunisia_sex = {\"F\":\"female\", \"M\":\"male\",np.nan:np.nan}\ntunisia.sex = [tunisia_sex[item] for item in  tunisia.sex] \n\njapan_sex = {\"Woman\":\"female\", \"Man\":\"male\",np.nan:np.nan, \"Checking\":np.nan, \"investigating\":np.nan}\njapan.sex = [japan_sex[item] for item in  japan.sex] \n\nfrance_sex = {\"female\":\"female\", \"male\":\"male\",\"Female\":\"female\", \"Male\":\"male\", \"male\\xa0?\":\"male\", \n              np.nan:np.nan }\nfrance.sex = [france_sex[item] for item in  france.sex] \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"examining_values_by_col(datasets, datasets_name, \"sex\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def update_index(dataset, col, indexs, data):\n    \"\"\"\n    Value change according index\n    \n    dataset: df\n    \n    col : str\n        name of col you want to change\n        \n    indexs: pd.index\n    \n    data: int/ str/ float\n        data you want to into\n    \n    \"\"\"\n    for indx in indexs:\n        dataset.loc[indx,col] = data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"background_diseases_binary"},{"metadata":{"trusted":true},"cell_type":"code","source":"indexs = korea.index[korea.background_diseases_binary == True]\nupdate_index(korea, \"background_diseases_binary\", indexs, 1.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tunisia[\"background_diseases_binary\"] = np.nan\n\nfor dataset in [tunisia, Hubei, outside_Hubei]:\n    indexs = dataset.index[dataset.background_diseases.notnull()]\n    update_index(dataset,\"background_diseases_binary\",indexs,1.0) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"examining_values_by_col (datasets, datasets_name, \"background_diseases_binary\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"background_diseases"},{"metadata":{"trusted":true},"cell_type":"code","source":"def getKeysByValue(dictOfElements, valueToFind):\n    listOfKeys = list()\n    listOfItems = dictOfElements.items()\n    for item  in listOfItems:\n        if item[1] == valueToFind:\n            listOfKeys.append(item[0])\n    return  listOfKeys\n\ndef remove(dict_a, keys_remove ):\n    for key in keys_remove:\n        if key in dict_a.keys():\n            dict_a.pop(key)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ps = nltk.stem.SnowballStemmer('english')\nr = []\no = []\nfor ind in outside_Hubei.index[outside_Hubei.background_diseases.notnull()]:\n    i = outside_Hubei.loc[ind, \"background_diseases\"]\n\n    i = BagWords.clean_str(i)\n    l = [ps.stem(x) for x in i]\n\n    for x in l:\n        if x.isalpha():\n            r.append(x)\n            \nkeys_remove = ['to', 'a','like',  'no', 'and',  'yes', 'then','complaint',\"great\", \"even\", \n         \"for\", \"the\", \"non\",  'of' , \"this\",  'on' ,'with', \"was\", 'c',\n         \"cannot\", \"recommend\", \"as\", \"a\", \"i\", \"did\", \"not\", \"want\", \"to\", \"have\", \"to\", \"do\", \"this\"]\n\n\n            \ntest_dict = dict(Counter(r))\nremove(test_dict, keys_remove )\nprint(test_dict)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#                                                     Complete features"},{"metadata":{},"cell_type":"markdown","source":"severity_illness"},{"metadata":{"trusted":true},"cell_type":"code","source":"bag_words= {\"good\":[\"good\",\"stabl\", \"follow\"],\n            \"critical\":[\"critic\", \"intens\", \"sever\"], \n            \"deceased\": [\"death\",\"dead\", \"die\", \"deceas\" ],\n            \"cured\":[\"discharg\", \"releas\", \"cure\", \"recov\", 'health'],\n            np.nan: [\"isol\"]}\n\nsentences_bag = {\"good\":[['not', 'hospit'],['in', 'progress']],\n                \"critical\":[], \n                \"deceased\": [ ],\n                \"cured\":[]}\n\n\n\ndatasets2 = [france, tunisia, indonesia, korea, Hubei, outside_Hubei]\ndatasets_name1 = [\"france\", \"tunisia\", \"indonesia\", \"korea\", \"Hubei\", \"outside_Hubei\"]\n\nfor ind in range(len(datasets_name1)):\n    dataset = datasets2[ind]\n    indexs = dataset.index[dataset.severity_illness.notnull()]\n    no_guess,multi_guess = BagWords.guess_category(dataset, \"severity_illness\", \"severity_illness\",indexs, ps, bag_words, sentences_bag)\n    \n    print(datasets_name1[ind])\n    print(no_guess)\n    print(multi_guess)\n\nfor x in [indonesia, france]:  \n    indexs = x.index[x.deceased_date.notnull()]\n    update_index(x,\"severity_illness\",indexs,\"deceased\") \n\n    indexs = x.index[x.released_date.notnull()]\n    update_index(x,\"severity_illness\",indexs,\"cured\") ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datasets2 = [france, tunisia, indonesia, korea, Hubei, outside_Hubei]\ndatasets_name1 = [\"france\", \"tunisia\", \"indonesia\", \"korea\", \"Hubei\", \"outside_Hubei\"]\nexamining_values_by_col(datasets2, datasets_name1,  \"severity_illness\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"released_date / deceased_date"},{"metadata":{"trusted":true},"cell_type":"code","source":"categories = [\"deceased\", \"cured\"]\ncols = [\"deceased_date\",\"released_date\"]\nfor indx_j in range(len(cols)) :\n    j  = cols[indx_j]\n    category = categories[indx_j]\n    \n    for x in [outside_Hubei, Hubei]:\n        x[j] = np.nan \n        indexs = x.index[x[\"severity_illness\"] == category]\n\n        for i in indexs:\n            x.loc[i, j]= pd.to_datetime(x.loc[ i, \"date_death_or_discharge\"])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"released_date exam"},{"metadata":{"trusted":true},"cell_type":"code","source":"datasets2 = [france, tunisia, japan, indonesia, korea, Hubei, outside_Hubei]\nexamining_values_by_col(datasets2, datasets_name, \"released_date\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"deceased_date exam"},{"metadata":{"trusted":true},"cell_type":"code","source":"datasets2 = [france, tunisia, japan, indonesia, korea, Hubei, outside_Hubei]\nexamining_values_by_col(datasets2, datasets_name, \"deceased_date\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"test"},{"metadata":{"trusted":true},"cell_type":"code","source":"for x in [outside_Hubei, Hubei]:\n    l = x.date_death_or_discharge.notnull().sum()\n    y = x.severity_illness.notnull().sum()\n    p = x.released_date.notnull().sum() +x.deceased_date.notnull().sum()\n    print(l,y,p)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for x in [outside_Hubei]:\n    complete_features =list(x.index[x.released_date.notnull()]) + list(x.index[x.deceased_date.notnull()])\n    date_death_or_discharge = list(x.index[x.date_death_or_discharge.notnull()])\n    severity_illness = list(x.index[x.severity_illness.notnull()])\n\n    if complete_features == date_death_or_discharge:\n        print(\"==\")\n    else:\n        print(\"not ==\")\n    \n    for i in severity_illness:\n        if i not in complete_features:\n            print(i)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"age"},{"metadata":{},"cell_type":"markdown","source":"exam "},{"metadata":{"trusted":true},"cell_type":"code","source":"indexs =  outside_Hubei.index[outside_Hubei.age.notnull()]\n\ndef int_num(dataset, col, indexs):\n    to_float = []\n\n    for i in indexs:\n        if dataset.loc[i, col].isdigit() == True:\n            to_float.append(i)\n\n    for indx in  to_float:\n        dataset.loc[indx, col] = float(dataset.loc[indx, col])\n    \n    return to_float\n        \n\nto_float= int_num(outside_Hubei, \"age\",indexs)\nindexs = indexs.drop(to_float)\n\nprint(indexs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### NEED AGE CPU \n\ndef birth_year_to_age(data):\n    age_ls = []\n\n    for i in range(len(data)):\n        age_ls.append(data.confirmed_date[i].year - data.birth_year[i])\n    return age_ls\n\nkorea[\"age\"] = birth_year_to_age(korea)\nfrance[\"age\"] = birth_year_to_age(france)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"country"},{"metadata":{"trusted":true},"cell_type":"code","source":"tunisia[\"country\"] = [\"tunisia\" for i in range(len(tunisia))]\njapan[\"country\"] = [\"japan\" for i in range(len(japan))]\nindonesia[\"country\"] = [\"indonesia\" for i in range(len(indonesia))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dataset in [outside_Hubei,Hubei]:\n\n    indexs = dataset.index[dataset[\"country\"].notnull()]\n    for indx in indexs:\n\n        dataset.loc[indx, \"country\"] = dataset.loc[indx, \"country\"].lower()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outside_Hubei[\"country\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"outside_Hubei data VS country data"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(korea))\nprint(outside_Hubei.country.value_counts()[\"south korea\"])\nprint()\n\nprint(len(france))\nprint(outside_Hubei.country.value_counts()[\"france\"])\nprint()\n\nprint(len(Hubei))\nprint(outside_Hubei.country.value_counts()[\"china\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**infection_place"},{"metadata":{"trusted":true},"cell_type":"code","source":"datasets2 = [france, tunisia, japan, indonesia, korea, Hubei, outside_Hubei]\nexamining_values_by_col(datasets2, datasets_name, \"infection_place\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(Hubei[\"wuhan(0)_not_wuhan(1)\"].value_counts())\nprint(outside_Hubei[\"infection_place\"].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"infection_case\n\n= Community \\abroad \\ Nan"},{"metadata":{},"cell_type":"markdown","source":"duplicate"},{"metadata":{"trusted":true},"cell_type":"code","source":"index_chack =  outside_Hubei.index[outside_Hubei[\"country\"] == \"France\" ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l = ['sex',  'city', 'confirmed_date',  'age']\ndf1 = france.loc[:, l]\n \ndf2 = outside_Hubei.loc[index_chack, l]\n\nx = pd.concat([df2,df1])\n\nprint(x.shape)\n\ndf_diff = x.index[x.duplicated(keep=\"last\") == True]\n\nlen(df_diff)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p = pd.DataFrame({\"r\": [0,9,0,88,7,6,0,0,0],\n                 \"o\": [0,9,0,88,7,6,6,7,4]})\n\nn = pd.DataFrame({\"r\": [0,9,4,886,77,6,607,0,0],\n                 \"o\": [0,9,0,88,7,65,6,7,4]})\n\nt = pd.concat([n,p])\nk = t.index[t.duplicated(keep=\"last\") == False]\nk","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"treatment"},{"metadata":{"trusted":true},"cell_type":"code","source":"index = tunisia.index[tunisia[\"hospital_place\"].notnull()]\n\ny = tunisia.index[tunisia[\"treatment\"] == \"Self-insulation\"]\nindex = index.drop(y)\nprint(index)\n\nupdate_index(tunisia, \"treatment\", y,\"home isolation\")\nupdate_index(tunisia, \"treatment\", index ,\"hospital\")\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"index = indonesia.index[indonesia[\"treatment\"].notnull()]\nupdate_index(tunisia, \"treatment\", index ,\"hospital\")\n\nindonesia[\"treatment\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = france.index[france[\"treatment\"] == \"deceased\"] \nx = france.index[france[\"treatment\"] == \"released\"]\n\nupdate_index(france, \"treatment\", y ,np.nan)\nupdate_index(france, \"treatment\", x ,np.nan)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outside_Hubei[\"treatment\"] = np.nan\nindex = outside_Hubei.index[outside_Hubei['date_admission_hospital'].notnull()]\nupdate_index(outside_Hubei, \"treatment\",  index,\"hospital\")\n\nHubei[\"treatment\"] = np.nan\nindex = Hubei.index[Hubei['date_admission_hospital'].notnull()]\nupdate_index(Hubei, \"treatment\", index ,\"hospital\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"del country"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in ['china',\"japan\",\"france\",\"south korea\"]:\n    ind = outside_Hubei.index[outside_Hubei[\"country\"] == i]\n    outside_Hubei = outside_Hubei.drop(ind, axis=0)\n\noutside_Hubei[\"country\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  Garbage drop \n- Features that have only one dataset or  built with Engineered another feature with them"},{"metadata":{"trusted":true},"cell_type":"code","source":"france = france.drop([\"birth_year\", \"group\"],axis=1)\ntunisia = tunisia.drop([\"hospital_place\"],axis=1)\njapan = japan.drop([\"Close contact situation\"],axis=1)\nkorea = korea.drop([\"birth_year\",\"global_num\"],axis=1)\nHubei = Hubei.drop([\"date_death_or_discharge\"],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# drop Non-baked features"},{"metadata":{"trusted":true},"cell_type":"code","source":"Hubei.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Hubei = Hubei.drop(['date_admission_hospital',\"wuhan(0)_not_wuhan(1)\",'travel_history_dates',\n                    'lives_in_Wuhan', \"reported_market_exposure\",\"sequence_available\"],axis=1)\noutside_Hubei = outside_Hubei.drop( ['wuhan(0)_not_wuhan(1)', 'date_admission_hospital', \"date_death_or_discharge\", 'lives_in_Wuhan',\n 'reported_market_exposure','sequence_available'],axis=1)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**> Feature sum**"},{"metadata":{"trusted":true},"cell_type":"code","source":"datasets2 = [france, tunisia, japan, indonesia, korea, Hubei, outside_Hubei]\ncolumns_name = Exam.build_columns_name_ls(datasets2)\nexam_df = Exam.df_exam_columns_dfs(datasets2, datasets_name, columns_name)\nprint(columns_name)\nexam_df.infection_place","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"unipue"},{"metadata":{},"cell_type":"markdown","source":"common feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"datasets3 = [france, tunisia, japan, indonesia, korea, Hubei, outside_Hubei]\ncolumns_name = Exam.build_columns_name_ls(datasets3)\nexam_df2 = Exam.df_exam_columns_dfs(datasets3,datasets_name,columns_name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in exam_df2.columns:\n    print(\"\\n\"+i)\n    examining_values_by_col (datasets, datasets_name, i)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# build final DS"},{"metadata":{"trusted":true},"cell_type":"code","source":"exam_df.sex","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datasets_final = [france, tunisia, japan, indonesia, korea,outside_Hubei, Hubei ]\nfinal_DS = pd.concat(datasets_final, axis=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# orgnaze DS"},{"metadata":{},"cell_type":"markdown","source":"index"},{"metadata":{"trusted":true},"cell_type":"code","source":"final_DS.index = range(len(final_DS))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_DS.to_csv(r'/kaggle/working/Characteristics_Corona_patients2.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_DS.to_csv()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}