{"cells":[{"metadata":{"_cell_guid":"e4be3fdf-7043-4f14-af08-663c15782767","_uuid":"545f3e88be29bc79e9a6ec8ae1aa334b46660158"},"cell_type":"markdown","source":"# Medical Dataの取り扱い例"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport pandas as pd\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\ndata = pd.read_csv(\"../input/insurance.csv\")\ndata.head()","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"c68ced2d-06ba-41f8-abe5-6186f375e0e6","_uuid":"cd20981c7dccd5d9da029434ff51664139c7bfe8"},"cell_type":"markdown","source":"## 質的データを数値化する\n各質的変数に対するカテゴリの種類を特定する。\n各カテゴリに対して数値をマッピングする。"},{"metadata":{"_cell_guid":"585985d8-0377-49b9-a64b-905c94cd8e00","_uuid":"bb274a72bb2abf53e304b2ea6587065e47576628","trusted":true},"cell_type":"code","source":"print(data['sex'].unique())\nprint(data['region'].unique())\nprint(data['smoker'].unique())\nsex_cat = data['sex'].unique()\nsex_dict = {sex_cat[idx]: idx for idx in range(len(sex_cat))}\nprint(sex_dict)\nreg_cat = data['region'].unique()\nreg_dict = {reg_cat[idx]: idx for idx in range(len(reg_cat))}\nprint(reg_dict)\nsmk_cat = data['smoker'].unique()\nsmk_dict = {smk_cat[idx]: idx for idx in range(len(smk_cat))}\nprint(smk_dict)","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"6ca82aec-0062-40c8-9313-ee01eacaf4a9","_uuid":"8478d2d661bf9efba5852b57ba85106516214cc3"},"cell_type":"markdown","source":"マッピングをデータに適用する。  \n（ここで、取り扱う質的変数には順序関係がないので名義尺度データである。）\n変数sex、smokerは2値データであるが、regionはそうでない。  \nそのため、regionだけはダミー展開する。"},{"metadata":{"_cell_guid":"1890f925-bf5e-42b3-916f-b6a0a084c930","_uuid":"d8dfdcc27e2adde9b6243057cb661db9c5f75179","trusted":true},"cell_type":"code","source":"for key in sex_dict.keys():\n    data.loc[data.sex == key, 'sex'] = sex_dict[key]\nfor key in reg_dict.keys():\n    data.loc[data.region == key, 'region'] = reg_dict[key]\nfor key in smk_dict.keys():\n    data.loc[data.smoker == key, 'smoker'] = smk_dict[key]\ndata.head()","execution_count":4,"outputs":[]},{"metadata":{"_cell_guid":"c84338bf-e21c-4a8a-9da6-31a0b2709fec","_uuid":"6a55fb871a7ff0be992cfaf8cb92bad1e3912f76"},"cell_type":"markdown","source":"## 各変数の相関を見る\n1. 相関係数行列を表示\n1. 相関可視化するために散布図を表示"},{"metadata":{"_cell_guid":"3845030a-5f50-411e-913b-b9755f225377","_uuid":"bca5c542293e74012afd89b7209a7375600043ee","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\ncorr = data.corr()\nprint(corr)\nsns.pairplot(data, size=2.5)\nplt.show()","execution_count":5,"outputs":[]},{"metadata":{"_cell_guid":"b3f162b4-bcfa-49ba-be82-b7a3ae9568f0","_uuid":"c5b6e0e29519938faa68dbc18ce0f9d6ed0c5d86","trusted":false,"collapsed":true},"cell_type":"code","source":"import numpy as np\n\n# ages = [idx*10 for idx in range(1, 7)]\n# means = {val: np.mean(data.loc[(data.age >= val) & (data.age < val+10), 'charges']) for val in ages}\n# stds = {val: np.std(data.loc[(data.age >= val) & (data.age < val+10), 'charges']) for val in ages}\n# for val in ages:\n#     data.loc[(data.age >= val) & (data.age < val+10), 'charges'] = (data.loc[(data.age >= val) & (data.age < val+10), 'charges'] - means[val]) / stds[val]\ndum = pd.get_dummies(data['region'])\ndata = data.drop('region', 1)\ndata = pd.concat((data, dum), axis=1)\nprint(data.head(10))\n\n# corr = data.corr()\n# print(corr)\n# sns.pairplot(data, size=2.5)\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a9180a69-00d7-4a5e-83f0-7038dbc2939b","_uuid":"e86c0b0d2991dd718cf75acad2ad6a7833925786"},"cell_type":"markdown","source":"## 回帰分析を行う\nchargesと強い相関持つ変数や変数同士に強い相関を持つ変数があるかどうかを  \n確認したので、回帰分析を行ってみる。    \n\nここまでで、smoker変数はcharges変数と相関が強いことがわかっている。\n1.  chargesを従属変数とし、smoker変数を除く残りの変数を独立変数として回帰\n2.  chargesを従属変数とし、その他の変数すべてを独立変数として回帰"},{"metadata":{"_cell_guid":"a8055157-1c43-4a6c-ae1f-6d9941d15a3a","_uuid":"5fedad2bde9bab38de728703f99d414771e51b49","trusted":true},"cell_type":"code","source":"import numpy as np\nimport sklearn\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\n# 従属変数と独立変数を分離\ndata_X = data.drop('charges', 1).drop('smoker', 1)\ndata_y = data.charges\n\n# 学習データと検証データに分ける(クロスバリデーション)\nX_train, X_test, y_train, y_test = train_test_split(data_X, data_y)\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# 学習精度\npred_train = model.predict(X_train)\ntrain_error = np.sqrt(np.mean((y_train-pred_train) ** 2))\n# 予測精度\npred_test = model.predict(X_test)\ntest_error = np.sqrt(np.mean((y_test-pred_test) ** 2))\n# 結果の表示\nprint('smokerを外した場合')\nprint('学習誤差：%f'%train_error)\nprint('予測誤差：%f'%test_error)\n\n# 従属変数と独立変数を分離\ndata_X = data.drop('charges', 1)\ndata_y = data.charges\n\n# 学習データと検証データに分ける(クロスバリデーション)\nX_train, X_test, y_train, y_test = train_test_split(data_X, data_y)\nprint(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# 学習誤差\npred_train = model.predict(X_train)\ntrain_error = np.sqrt(np.mean((y_train-pred_train) ** 2))\n# 予測誤差\npred_test = model.predict(X_test)\ntest_error = np.sqrt(np.mean((y_test-pred_test) ** 2))\n# 結果の表示\nprint('smokerを外さなかった場合')\nprint('学習誤差：%f'%train_error)\nprint('予測誤差：%f'%test_error)","execution_count":6,"outputs":[]},{"metadata":{"_cell_guid":"6a71a009-a54d-4936-922f-5a47e76a15ce","_uuid":"7712e6d2d895d52ebbe4f216a6ba22a0dec7d86f"},"cell_type":"markdown","source":"smoker変数はchargesを予測する上で相関の強すぎる変数というわけではない。\n\n## 予測精度を検討する\nsmoker変数はモデルに必要な変数として、以下を検討する。  \n誤差データから分布を確認し、誤差の平均値と標準偏差からその精度を数値化する。"},{"metadata":{"_cell_guid":"7fd854ec-ec01-4a0b-8627-e5cc845a8227","_uuid":"8c67cb562cf048b16854b4f21559460a366f1541","trusted":true},"cell_type":"code","source":"# 可視化\ntrain = plt.scatter(pred_train, (pred_train - y_train), c= 'b', alpha=0.5) \ntest = plt.scatter(pred_test, (pred_test - y_test), c ='r', alpha=0.5)\nplt.hlines(y = 0, xmin = -1.0, xmax = 2)\n# 凡例\nplt.legend((train, test), ('Training', 'Test'), loc = 'lower left') # 凡例\n# タイトル(残差プロット)\nplt.title('Residual Plots')\nplt.show()\n\nplt.hist((pred_train - y_train))\nplt.hist((pred_test - y_test))\nprint('誤差の平均値：%f'%np.mean((pred_test - y_test)))\nprint('誤差の標準誤差：%f'%np.std((pred_test - y_test)))","execution_count":7,"outputs":[]},{"metadata":{"_cell_guid":"7c46b8df-79b4-457e-8043-f648c805607d","_uuid":"64e9e5f349087b1c934de69691e9998a8f825d97","trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\n\ndecomposer = PCA(n_components=2)\n#decomposer.fit(X_train.drop('age', 1))\ndecomposer.fit(data)\n\n#平均ベクトル(D次元ベクトル)\nM = decomposer.mean_\n#print(M)\nprint(\"主成分の分散説明率\")\nprint(decomposer.explained_variance_ratio_)\n\n#主成分ベクトル（主成分数xDの行列）\nV = decomposer.components_\nprint(V)\n\n#固有値（各主成分におけるデータの分散）\nE = decomposer.explained_variance_\nprint(E)\n\n# 分析結果を元にデータセットを主成分に変換する\n#transformed = decomposer.fit_transform(X_train.drop('age', 1))\ntransformed = decomposer.fit_transform(data)\nprint(transformed)\n\n# 主成分をプロットする\nplt.figure(figsize=(10,10))\nplt.subplot(2, 1, 1)\nlabels=[idx for idx in range(4)]\nplt.scatter(transformed[:,0], transformed[:,1], c=pd.cut(data.charges, 4, labels=labels))\nplt.title('principal component')\nplt.xlabel('pc1')\nplt.ylabel('pc2')","execution_count":40,"outputs":[]},{"metadata":{"_cell_guid":"3e7d3541-645f-43e4-a080-7b45f6b37388","_uuid":"bb368265479c55537e24c9074785e7d94c4612b5","trusted":true,"scrolled":true},"cell_type":"code","source":"from sklearn.decomposition import FastICA\n\n#独立成分の数＝2\ndecomposer = FastICA(n_components = 2)\n\n#データの平均を計算\nM = np.mean(data.T, axis = 1)[:,np.newaxis]\nprint(M)\nprint(data.head(2))\n\n#各データから平均を引く\ndata2 = data.copy()\nfor idx in range(len(M)):\n    data2.iloc[:, idx] = data.iloc[:, idx] - M[idx]\n#print(data2.head(2))\n\n#平均0としたデータに対して、独立成分分析を実施\ndecomposer.fit(data2)\n\n#独立成分ベクトルを取得(D次元 x 独立成分数)\ntransformd = decomposer.transform(data2)\nprint(transformed)\n\n# 独立成分をプロットする\nplt.figure(figsize=(10,10))\nplt.subplot(2, 1, 1)\nlabels=[idx for idx in range(4)]\nplt.scatter(transformed[:,0], transformed[:,1], c=pd.cut(data2.charges, 4, labels=labels))\nplt.title('independence component')\nplt.xlabel('ic1')\nplt.ylabel('ic2')","execution_count":42,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}