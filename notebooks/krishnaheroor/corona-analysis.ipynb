{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Investigatng the data and exploratory data analysis"},{"metadata":{},"cell_type":"markdown","source":"First installing all the libraries that will use in our application. Installing the libraries in the first part because the algorithm we use later and the analysis we make more clearly will be done. Furthermore, investigating the data, presented some visualization and analyzed some features. Lets write it. Importing necessary packages and libraries."},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom datetime import datetime","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we are uploading our data set using the variable \"corona\" in the pandas library."},{"metadata":{"trusted":true},"cell_type":"code","source":"corona= pd.read_csv(\"../input/novel-corona-virus-2019-dataset/covid_19_data.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#after the loading the data. Next step is to view/see the top 10 rows of the loaded data set\n\ncorona.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#last 10 rows of loaded data set\n\ncorona.tail(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corona.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"describe function is a function that allos analysis between the numeric values contained in the the dataset. Using this function count, mean,std, min,max,25%,50%,75%.\n\nAs seen in this section, most values are generally numeric."},{"metadata":{"trusted":true},"cell_type":"code","source":"#information about each var\n\ncorona.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#we will be listing the columns of all the data.\n#we will check all columns\n\ncorona.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corona.sample(frac=0.01)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sample: random rows in the dataset\n#useful for future analysis\ncorona.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#next, how many rows an columns are there in the loaded data set\n\ncorona.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# and, will check null on all the data and if there is any null, getting the sum of all the null data's\n\ncorona.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we can see from the above analysis, there are 462 NaN values from Province/state variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"df= corona.groupby('ObservationDate')['Confirmed','Deaths','Recovered'].sum()\ndf=df.reset_index()\ndf=df.sort_values('ObservationDate', ascending= True)\ndf.head(60)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df= corona.groupby('Province/State')['Confirmed','Deaths','Recovered'].sum()\ndf=df.reset_index()\ndf=df.sort_values('Province/State', ascending= True)\ndf.head(60)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df=corona[corona['Confirmed'] == corona['Deaths']+['Recovered']]\n#df=df[['Province','Confirmed','Deaths','Recovered']]#\n#df=df.reset_index()\n#df=df.sort_values('Confirmed',ascending= True)\n#df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df= corona.groupby('ObservationDate')['Confirmed','Deaths','Recovered'].sum()\ndf.sort_values('ObservationDate',ascending=True)\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(min(corona.Confirmed))\nprint(max(corona.Confirmed))\nprint(corona.Confirmed.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(min(corona.Deaths))\nprint(max(corona.Deaths))\nprint(corona.Deaths.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(min(corona.Recovered))\nprint(max(corona.Recovered))\nprint(corona.Recovered.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Working on with the different data i,e confirmed data, deaths data and recovered data"},{"metadata":{"trusted":true},"cell_type":"code","source":"#loading the raw data of confirmed, deaths and confirmed\n\nconf=pd.read_csv(\"../input/novel-corona-virus-2019-dataset/time_series_covid_19_confirmed.csv\")\ndeath=pd.read_csv(\"../input/novel-corona-virus-2019-dataset/time_series_covid_19_deaths.csv\")\nrecov=pd.read_csv(\"../input/novel-corona-virus-2019-dataset/time_series_covid_19_recovered.csv\")\n\nprint(conf.shape)\nprint(death.shape)\nprint(recov.shape)\n\nconf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"conf2 = pd.melt(conf, id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], var_name=['Date'])\ndeath2 = pd.melt(death, id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], var_name=['Date'])\nrecov2 = pd.melt(recov, id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], var_name=['Date'])\n\nprint(conf2.shape)\nprint(death2.shape)\nprint(recov2.shape)\n\nconf2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting the new column to dates\n\nconf2['Date'] = pd.to_datetime(conf2['Date'])\ndeath2['Date'] = pd.to_datetime(death2['Date'])\nrecov2['Date'] = pd.to_datetime(recov2['Date'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#renaming the values to confirmed,death and recivered with respected datasets\n\nconf2.columns=conf2.columns.str.replace('value','Confirmed')\ndeath2.columns=death2.columns.str.replace('value','Deaths')\nrecov2.columns=recov2.columns.str.replace('value','Recovered')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Finding the sum of NaN values in the columns of respective loaded data set\n\nprint(conf2.isna().sum())\n#print(death2.isna().sum())\n#print(recov2.isna().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dealing with the Nan values\n\nconf2['Province/State'].fillna(conf2['Country/Region'], inplace=True)\ndeath2['Province/State'].fillna(death2['Country/Region'], inplace=True)\nrecov2['Province/State'].fillna(recov2['Country/Region'], inplace=True)\n\nconf2.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the next step we are going to join/ combine the three data sets, first we will once again printing the shape of the each loaded data set\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(conf2.shape)\nprint(death2.shape)\nprint(recov2.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And, in this step we are going to join the three datas i,e full joins\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"join= conf2.merge(death2[['Province/State','Country/Region','Date','Deaths']], \n                                      how = 'outer', \n                                      left_on = ['Province/State','Country/Region','Date'], \n                                      right_on = ['Province/State', 'Country/Region','Date'])\n\njoin2= join.merge(recov2[['Province/State','Country/Region','Date','Recovered']], \n                                      how = 'outer', \n                                      left_on = ['Province/State','Country/Region','Date'], \n                                      right_on = ['Province/State', 'Country/Region','Date'])\n\njoin2.head()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df= join2.groupby('Country/Region')['Confirmed','Deaths','Recovered'].sum()\ndf=df.reset_index()\ndf=df.sort_values('Country/Region', ascending= True)\ndf.head(60)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Verifying is there any null values from the above data\n\njoin2.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, there is no NaN values from the above dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Adding month and year as a new column\n\njoin2['Month-Year'] = join2['Date'].dt.strftime('%b-%Y')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"join2.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Total confirmed cases, death cases and recovered cases "},{"metadata":{"trusted":true},"cell_type":"code","source":"df= join2.groupby('Month-Year')['Confirmed','Deaths','Recovered'].sum()\ndf.sort_values('Month-Year',ascending=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":4}