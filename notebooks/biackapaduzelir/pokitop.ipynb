{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns #visualization tool\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/pokemon-challenge/pokemon.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#correlation map\nf,ax = plt.subplots(figsize=(18, 18))\nsns.heatmap(data.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Line Plot\n# color = color, label = label, linewidth = width of line, alpha = opacity, grid = grid, linestyle = sytle of line\ndata.Speed.plot(kind = 'line', color = 'g',label = 'Speed',linewidth=1,alpha = 0.5,grid = True,linestyle = ':')\ndata.Defense.plot(color = 'r',label = 'Defense',linewidth=1, alpha = 0.5,grid = True,linestyle = '-.')\nplt.legend(loc='upper right')     # legend = puts label into plot\nplt.xlabel('x axis')              # label = name of label\nplt.ylabel('y axis')\nplt.title('Line Plot')            # title = title of plot\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#scatter plot\n# x = attack, y = defense\ndata.plot(kind='scatter', x='Attack', y='Defense',alpha = 0.5,color = 'red')\nplt.xlabel('Attack')              # label = name of label\nplt.ylabel('Defence')\nplt.title('Attack Defense Scatter Plot')            # title = title of plot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Histogram\n# bins = number of bar in figure\ndata.Speed.plot(kind = 'hist',bins = 50,figsize = (12,12))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# clf() = cleans it up again you can start a fresh\ndata.Speed.plot(kind = 'hist',bins = 50)\nplt.clf()\n# We cannot see plot due to clf()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **DICTIONARY**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#create dictionary and look its keys and values\ndictionary = {'spain' : 'madrid','usa' : 'vegas'}\nprint(dictionary.keys())\nprint(dictionary.values())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Keys have to be immutable objects like string, boolean, float, integer or tubles\n# List is not immutable\n# Keys are unique\ndictionary['spain'] = \"barcelona\"    # update existing entry\nprint(dictionary)\ndictionary['france'] = \"paris\"       # Add new entry\nprint(dictionary)\ndel dictionary['spain']              # remove entry with key 'spain'\nprint(dictionary)\nprint('france' in dictionary)        # check include or not\ndictionary.clear()                   # remove all entries in dict\nprint(dictionary)\n#del dictionary delete entire dictionary","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **PANDAS**"},{"metadata":{"trusted":true},"cell_type":"code","source":" data= pd.read_csv(\"../input/pokemon-challenge/pokemon.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"series= data['Defense']\nprint(type(series))\ndata_frame=data[['Defense']]\nprint(type(data_frame))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Logic, Control flow, filtering**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#compresion operators\nprint(3>2)\nprint(3!=2)\n#boolean operator\nprint(True and False)\nprint(True or False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1- Filtering pandas data frame\nx = data['Defense']>200   #There are only 3 pokemons who have higher defense value than 200\ndata[x]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2 - Filtering pandas with logical_and\n# There are only 2 pokemons who have higher defence value than 2oo and higher attack value than 100\ndata[np.logical_and(data['Defense']>200,data['Attack']>100)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This is also same with previous code line. Therefore we can also use '&' for filtering.\ndata[(data['Defense']>200) & (data['Attack']>100)]   #yukarıdaki ile aynı","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Loop Data structures**\n*WHILE and FOR LOOPS*"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Stay in loop if condition( i is not equal 5) is true\n\ni = 0\nwhile i != 5:\n    print('i is:',i)\n    i +=1\nprint(i,'is equal to 5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Stay in loop if condition( i is not equal 5) is true\nlist =[1,2,3,4,5]\nfor i in list:\n     print('i is',i)\nprint('')\n\n# Enumerate index and value of list\n# index : value = 0:1, 1:2, 2:3, 3:4, 4:5\nfor index, value in enumerate(list):\n    print(index,\" \",value)\nprint('')\n\n# For dictionaries\n# We can use for loop to achive key and value of dictionary. We learnt key and value at dictionary part.\ndictionary = {'spain':'madrid','france':'paris'}\nfor key, value in dictionary.items():\n    print(key, ':' , value)\nprint('')\n\n# For pandas we can achieve index and value\nfor index, value in data[['Attack']][0:1 ].iterrows():\n    print(index, \":\" ,value)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Cleaning Data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data['Type 1'].value_counts(dropna = False))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**VISUAL EXPLORATORY DATA ANALYSIS**\n* Box plots: visualize basic statistics like outliers, min/max or quantiles"},{"metadata":{"trusted":true},"cell_type":"code","source":"# For example: compare attack of pokemons that are legendary  or not\n# Black line at top is max\n# Blue line at top is 75%\n# Green line is median (50%)\n# Blue line at bottom is 25%\n# Black line at bottom is min\n# There are no outliers\ndata.boxplot(column= 'Attack',by='Legendary')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n**TIDY DATA**\n\nWe tidy data with melt(). Describing melt is confusing. Therefore lets make example to understand it."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new = data.head()\ndata_new","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets melt\n# id_vars = what we do not wish to melt\n# value_vars = what we want to melt\nmelted=pd.melt(frame=data_new,id_vars='Name',value_vars=['Attack','Defense'])\nmelted","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n**PIVOTING DATA**\n\nReverse of melting"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Index is name\n# I want to make that columns are variable\n# Finally values in columns are value\nmelted.pivot(index = 'Name', columns = 'variable',values='value')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n **CONCATENATING DATA**\n\nWe can concatenate two dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"data1=data.head()\ndata2=data.tail()\nconc_data_row = pd.concat([data1,data2],axis=0,ignore_index=True)\nconc_data_row","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1= data['Attack'].head()\ndata2= data['Defense'].head()\nconc_data_col = pd.concat([data1,data2], axis=1)\nconc_data_col","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n**DATA TYPES**\nThere are 5 basic data types: object(string),boolean, integer, float and categorical.\nWe can make conversion data types like from str to categorical or from int to float\nWhy is category important:\n\n* make dataframe smaller in memory\n* can be utilized for anlaysis especially for sklearn(we will learn later)"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Type 1']= data['Type 1'].astype('category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n**MISSING DATA and TESTING WITH ASSERT**\n\nIf we encounter with missing data, what we can do:\n\n* leave as is _ Öylece bırakabiliriz\n* drop them with dropna() - datasetten çıkarabiliriz\n* fill missing value with fillna() -NaN ile doldurabiliriz\n* fill missing values with test statistics like mean  \n Assert statement: check that you can turn on or turn off when you are done with your testing of the program"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()\ndata1 = data.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets chech Type 2\ndata1[\"Type 2\"].value_counts(dropna =False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets drop nan values\n#data1=data   # also we will use data to fill missing value so I assign it to data1 variable\n#data1[\"Type 2\"].dropna(inplace = True)  # inplace = True means we do not assign it to new variable. Changes automatically assigned to data\n# So does it work ? Çalışmadı\ndata1 = data1.dropna()\nprint(data1.isnull().sum().sort_values(ascending=False))\n#Calıstı","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert 1==1 #return nothing because it is true","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#assert 1==2 #return error because it is false","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert data1['Type 2'].notnull().all() # returns nothing because we drop nan values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1['Type 2'].fillna('empty',inplace=True) #Nan olanları empty ile dolduruyoruz","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert data1['Type 2'].notnull().all() # returns nothing because we drop nan values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1['Type 2']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # With assert statement we can check a lot of thing. For example\n# assert data.columns[1] == 'Name'\n# assert data.Speed.dtypes == np.int","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# PANDAS FOUNDATION\n"},{"metadata":{},"cell_type":"markdown","source":"\n**REVİEW of PANDAS**\nAs you notice, I do not give all idea in a same time. Although, we learn some basics of pandas, we will go deeper in pandas.\n\n* single column = series\n* NaN = not a number\n* dataframe.values = numpy"},{"metadata":{},"cell_type":"markdown","source":"**BUILDING DATA FRAMES FROM SCRATCH**\n\nWe can build data frames from csv as we did earlier.\n* Also we can build dataframe from dictionaries\n* * zip() method: This function returns a list of tuples, where the i-th tuple contains the i-th element from each of the argument sequences or iterables.\n* Adding new column\n* Broadcasting: Create new column and assign a value to entire column"},{"metadata":{"trusted":true},"cell_type":"code","source":"country = [\"Spain\",\"France\"]\npopulation = [\"11\",\"12\"]\nlist_label = [\"country\",\"population\"]\nlist_col = [country,population]\nzipped = zip(list_label,list_col)\ndata_dict = dict(zipped)\ndf = pd.DataFrame(data_dict)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#add new columns\ndf['capital'] = ['madrid','paris']\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#brodcasting\ndf['income'] =0\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **VISUAL EXPLORATORY DATA ANALYSIS**\n\n* Plot\n* Subplot\n* Histogram:\n * bins: number of bins\n * range(tuble): min and max values of bins\n * normed(boolean): normalize or not\n * cumulative(boolean): compute cumulative distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting all data\ndata1=data.loc[:,['Attack','Defense','Speed']]\ndata1.plot()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1.plot(subplots=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#scatter plot\ndata1.plot(kind='scatter',x='Attack',y='Defense')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# hist plot  \ndata1.plot(kind = \"hist\",y = \"Defense\",bins = 50,range= (0,250))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# histogram subplot with non cumulative and cumulative\nfig, axes = plt.subplots(nrows=2,ncols=1)\ndata1.plot(kind='hist',y='Defense',bins=50,range=(0,250),ax=axes[0])\ndata1.plot(kind='hist',y='Defense',bins=50,range=(0,250),ax=axes[1],cumulative=True)\nplt.savefig('graph.png')\nplt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n**STATISTICAL EXPLORATORY DATA ANALYSIS**\nI already explained it at previous parts. However lets look at one more time.\n\n* count: number of entries\n* mean: average of entries\n* std: standart deviation\n* min: minimum entry\n* 25%: first quantile\n* 50%: median or second quantile\n* 75%: third quantile\n* max: maximum entry"},{"metadata":{"trusted":true},"cell_type":"code","source":"data1.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**INDEXING PANDAS TIME SERIES**\n\n* datetime = object\n* parse_dates(boolean): Transform date to ISO 8601 (yyyy-mm-dd hh:mm:ss ) format"},{"metadata":{"trusted":true},"cell_type":"code","source":"time_list =[\"1992-03-08\",\"1992-04-12\"]\nprint(type(time_list[1])) \ndatatime_object = pd.to_datetime(time_list)\nprint(type(datatime_object))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# close warning\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# In order to practice lets take head of pokemon data and add it a time list\ndata2=data.head()\ndate_list = [\"1992-01-10\",\"1992-02-10\",\"1992-03-10\",\"1993-03-15\",\"1993-03-16\"]\ndatetime_object = pd.to_datetime(date_list)\ndata2[\"date\"] = datetime_object\n# lets make date as index\ndata2= data2.set_index(\"date\")\ndata2 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data2.loc[\"1993-03-16\"])\nprint(data2.loc[\"1992-03-10\":\"1993-03-16\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**RESAMPLING PANDAS TIME SERIES**\n\n* Resampling: statistical method over different time intervals\n * Needs string to specify frequency like \"M\" = month or \"A\" = year\n* Downsampling: reduce date time rows to slower frequency like from daily to weekly\n* Upsampling: increase date time rows to faster frequency like from daily to hourly\n* Interpolate: Interpolate values according to different methods like ‘linear’, ‘time’ or index’\nhttps://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.interpolate.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"data2.resample('A').mean() #Yıla göre resample et ve ortalamasını al","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data2.resample('M').mean() #Aylara göre resample et ve ortalama al","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"NaN olan yerlerde o tarihte veri olmadığı için NaN diyor "},{"metadata":{"trusted":true},"cell_type":"code","source":"#data2.resample(\"M\").first().interpolate('linear')#","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**İndexing data frames**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# read data\ndata = pd.read_csv('/kaggle/input/pokemon-challenge/pokemon.csv')\ndata= data.set_index(\"#\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['HP'][1] #can kolonunu al 1. satırını seç\n#data.HP[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.loc[1,['HP']] #datanın locationu 1.satır can sutunu","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[[\"HP\",\"Attack\"]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**SLICING DATA FRAME** \n* Bize bir, iki şey seçme yerine aralık seçme şansı veriyor\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(type(data[\"HP\"])) #tek koseli parantez var ise seri\nprint(type(data[[\"HP\"]])) #iki koseli parantez var ise dataframe\n#Seriler ile dataframeler arasında ki fark budur","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.loc[1:10,\"HP\":\"Defense\"] #1den 10a kadar ayrıca canla defensea kadar al\n# can attack ve defense alınır","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#10dan 1e kadar yapmak için -1 koymak yeterli\ndata.loc[10:1:-1,\"HP\":\"Defense\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.loc[1:10,\"Speed\":] #1 den 10a kadar al aynı zamanda speed ve en sonuncusuna kadar al","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**FILTERING DATA FRAMES**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"boolean = data.HP >200 #bu bir filtre ve true,falselardan oluşuyor\ndata[boolean]\n#bunu (boolean) datamın içine koyduğumda falseları yazdırmayıp trueların hepsini yazdırır","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"first_filter = data.HP> 150\nsecond_filter = data.Speed > 35\ndata[first_filter & second_filter] #iki filtremin kesisimi olan pokemonları verir","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data.Speed<15]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.HP[data.Speed<15] #Hızımın 15ten küçük olduğu pokemonları bul ve bunların canını ekrana getir","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**TRANSFORMING DATA**\n* apply()\n* lambda func"},{"metadata":{"trusted":true},"cell_type":"code","source":"def div(n):\n    return n/2\ndata.HP.apply(div)  \n#apply methodu datadan canlar içindeki tüm satırları tek tek alıyor ikiye div methodu ile bölüyor bana sonucu tek tek yazdırıyor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.HP.apply(lambda n: n/2) #methodu kısaltıyor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#yeni bir colu mn tanımlamak istersek \ndata['total_power'] = data.Attack + data.Defense\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **INDEX OBJECTS AND LABELED DATA**\n# \nDatanın indexini kullanarak neler yapabiliriz ona bakalım"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#indeximizin ismine bakalım\nprint(data.index.name) \n# bunu değiştirelim\ndata.index.name = \"index_name\"\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()\ndata3= data.copy() #datamız bozulmasın diye başka bir dataya kopyaladık\ndata3.index = range(100,900,1)\n#100den 900e kadar 1er artarak indeximi tanımla\ndata3.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Sutunlardan birinide index olarak verebilirim \n# data= data.set_index(\"#\")\n# ayrıca datamın indexsi eşit olsun datamın featuruna\n# data.index = data[\"#\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **HIERARCHICAL INDEXİNG**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/pokemon-challenge/pokemon.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1 = data.set_index([\"Type 1\",\"Type 2\"]) #type1 ve type 2 benim yeni indexim olsun ilk yazdığım outer(ilk indexim) ikinci yazdığım inner(2.indexim oluyor)\ndata1.head(100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Type1 ve Type 2 feature'dı artık indexim oldu. Type 1'i grass olupta type 2si poison olmayan yokı bu ne demek böcekler genellikle zehirlidir.  su pokemonlarının type 2si yoktur. Dövüş pokemonlarının da type2 si yok"},{"metadata":{},"cell_type":"markdown","source":"**PIVOTING DATA FRAMES**"},{"metadata":{"trusted":true},"cell_type":"code","source":"dic = {\"treatment\":[\"A\",\"A\",\"B\",\"B\"],\"gender\":[\"F\",\"M\",\"F\",\"M\"],\"response\":[10,45,5,9],\"age\":[15,4,72,65]}\ndf = pd.DataFrame(dic)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.pivot(index=\"treatment\",columns=\"gender\", values=\"response\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Bir dataframe farklı bir bakış açısı getirir"},{"metadata":{},"cell_type":"markdown","source":"**STACKING and UNSTACKING DATAFRAME¶**\n\nBirden fazla index'e sahip dataframelerin indexlerinden bir tanesinden kurtuluyor gibi birşey"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = df.set_index([\"treatment\",\"gender\"])\ndf1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.unstack(level=0) #index sıfırı yani treatment'i indexlikten çıkarır","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.unstack(level=1) #index 1'i genderi çıkarır","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2= df1.swaplevel(0,1)\ndf2\n#indexlerin yerini değiştirir. sıfırıncı indexle birinci indexin yerini değiştirdi","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**MELTING DATA FRAMES**\n\nmelt etmek pivot etmenin tam tersi"},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.melt(df,id_vars=\"treatment\",value_vars=[\"age\",\"response\"])\n#treatment'in sabit kalsın geri kalan featurelarımın yerine variable ve value diye iki tane feature ekler. Bir şey belirtmezsek variable ve value defaulttur.\n#value_vars = [\"age\",\"response\"] bu ne demek benim yaşımı al bir değer olarak yaz (variable sutununda age yazar) onun valuesı da valueya yazılır","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**CATEGORICALS AND GROUPBY**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df bir şeye göre gruplayacaz\ndf.groupby(\"treatment\").mean()\n#treatmente göre grupla ve ortalamasını al\n#iki grubum var A ve B buna göre ort alır","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(\"treatment\").age.mean()\n#treatmente göre grupla (iki grup A ve B) bunların yaşlarının ort al","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(\"treatment\")[[\"age\",\"response\"]].min()\n#treatmente göre grupla içinden yas ve response min bul","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}