{"cells":[{"execution_count":null,"source":"#Auxílio do Tutorial: https://matheusfacure.github.io/2017/05/12/tensorflow-essencial/\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport tensorflow as tf\nimport gzip\nimport pickle\nimport numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nimport os # para criar pastas\nfrom sklearn.metrics import r2_score, accuracy_score\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","cell_type":"code","outputs":[],"metadata":{"_cell_guid":"8f6f5449-9d2b-4f13-b112-b5730f22ce66","_uuid":"ba316cf9fbcd289d0d2a1635414f48d64f3a49ed"}},{"execution_count":null,"source":"df = pd.read_csv('../input/mushrooms.csv')\ndf.head()","cell_type":"code","outputs":[],"metadata":{}},{"execution_count":null,"source":"le = preprocessing.LabelEncoder()\ndf_encoded = df.apply(le.fit_transform)\nlist(le.classes_)\n#list(le.inverse_transform([2, 2, 1]))\n\ndf_encoded.astype(float)\nscaler = MinMaxScaler()\ndf_encoded[df_encoded.columns] = scaler.fit_transform(df_encoded[df_encoded.columns])\ndf_encoded.head()\n\nX = df_encoded.drop(['class'], axis=1)\ny = df_encoded['class']","cell_type":"code","outputs":[],"metadata":{}},{"execution_count":null,"source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\nprint('Formato dos dados:', X_train.shape, y_train.shape)\n","cell_type":"code","outputs":[],"metadata":{}},{"execution_count":null,"source":"# definindo constantes\nlr = 1e-2 # taxa de aprendizado\nn_iter = 2501 # número de iterações de treino\nn_inputs = X_train.shape[1] # número de variáveis independentes\nn_outputs = 1 # número de variáveis dependentes\n\ngraph = tf.Graph() # isso cria um grafo\nwith graph.as_default(): # isso abre o grafo para que possamos colocar operações e variáveis dentro dele.\n    tf.set_random_seed(1)\n    \n    # adiciona as variáveis ao grafo\n    W = tf.Variable(tf.truncated_normal([n_inputs, n_outputs], stddev=.1), name='Weight')\n    b = tf.Variable(tf.zeros([n_outputs]), name='bias')\n\n\n    ######################################\n    # Monta o modelo de regressão linear #\n    ######################################\n\n    # Camadas de Inputs\n    x_input = tf.placeholder(tf.float32, [None, n_inputs], name='X_input')\n    y_input = tf.placeholder(tf.float32, [None, n_outputs], name='y_input')\n\n    # Camada Linear\n    y_pred = tf.add(tf.matmul(x_input, W), b, name='y_pred')\n\n    # Camada de custo ou função objetivo\n    EQM = tf.reduce_mean(tf.square(y_pred - y_input), name=\"EQM\")\n\n    # otimizador\n    optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(EQM)\n\n    # inicializador\n    init = tf.global_variables_initializer()\n\n    # para salvar o modelo treinado\n    saver = tf.train.Saver()\n","cell_type":"code","outputs":[],"metadata":{"collapsed":true}},{"execution_count":null,"source":"# criamos uma pasta para salvar o modelo\nif not os.path.exists('tmp'):\n    os.makedirs('tmp')\n\n# abrimos a sessão tf\nwith tf.Session(graph=graph) as sess:\n    sess.run(init) # iniciamos as variáveis\n    \n    # cria um feed_dict\n    feed_dict = {x_input: X_train, y_input: y_train.values.reshape(-1,1)}\n    \n    # realizamos as iterações de treino\n    for step in range(n_iter + 1):\n        \n        # executa algumas operações do grafo\n        _, l = sess.run([optimizer, EQM], feed_dict=feed_dict)\n        \n        if (step % 500) == 0:\n            print('Custo na iteração %d: %.2f \\r' % (step, l), end='')\n            saver.save(sess, \"./tmp/my_model.ckpt\")\n","cell_type":"code","outputs":[],"metadata":{}},{"execution_count":null,"source":"# novamente, abrimos a sessão tf\nwith tf.Session(graph=graph) as sess:\n    \n    # restauramos o valor das variáveis \n    saver.restore(sess, \"./tmp/my_model.ckpt\", )\n    \n    # rodamos o nó de previsão no grafo\n    y_hat = sess.run(y_pred, feed_dict={x_input: X_test})\n    \n    print('\\nR2: %.3f' % r2_score(y_pred=y_hat, y_true=y_test))\n    print('\\nAccuracy %.3f' % accuracy_score(y_test, y_hat.round(), normalize=True))\n","cell_type":"code","outputs":[],"metadata":{}},{"execution_count":null,"source":"","cell_type":"code","outputs":[],"metadata":{"collapsed":true}}],"nbformat":4,"nbformat_minor":1,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","nbconvert_exporter":"python","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","version":"3.6.3","file_extension":".py"}}}