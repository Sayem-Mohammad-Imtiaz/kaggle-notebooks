{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas_profiling\nimport sys\nimport math\nimport numpy.random as nr\nimport scipy.stats as ss\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport sklearn.preprocessing as skpe\nimport sklearn.model_selection as ms\nimport sklearn.metrics as sklm\nimport sklearn.linear_model as lm\nfrom sklearn import tree\nfrom sklearn import neighbors\nfrom sklearn import ensemble\nimport statsmodels.api as sm\nfrom statsmodels.sandbox.regression.predstd import wls_prediction_std","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path=\"../input/red-wine-quality-cortez-et-al-2009/winequality-red.csv\"\ndf=pd.read_csv(path)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# A brief overview and detailed EDA of this dataset\npandas_profiling.ProfileReport(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Univariate Analysis**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Histogram for univariate analysis\nfig, axs = plt.subplots(ncols=3, nrows=4, figsize=(20, 10))\nindex = 0\naxs = axs.flatten()\nfor k,v in df.items():\n    sns.distplot(v,kde=False,rug=True,ax=axs[index]) # rug is used to see the frequency density on the x-scale\n    index += 1\nplt.tight_layout(pad=0.4, w_pad=0.5, h_pad=5.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Box Plots to detect outliers\nfig, axs = plt.subplots(ncols=6, nrows=2, figsize=(20, 10))\nindex = 0\naxs = axs.flatten()\nfor k,v in df.items():\n    sns.boxplot(y=k, data=df, ax=axs[index])\n    index += 1\nplt.tight_layout(pad=0.4, w_pad=0.5, h_pad=5.0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Bivariate Analysis**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking correlation bw different variables\nplt.figure(figsize=(18,18))\nsns.heatmap(df.corr(),vmax=.7,cbar=True,annot=True)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (axis1,axis2) = plt.subplots(2,1,figsize=(10,8))\n\nsns.barplot(x='quality', y='fixed acidity', data=df, ax=axis1)\nsns.barplot(x='quality', y='volatile acidity', data=df, ax=axis2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (axis1,axis2) = plt.subplots(2,1,figsize=(10,8))\n\nsns.barplot(x='quality', y='citric acid', data=df, ax=axis1)\nsns.barplot(x='quality', y='residual sugar', data=df, ax=axis2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (axis1,axis2) = plt.subplots(2,1,figsize=(10,8))\n\nsns.barplot(x='quality', y='chlorides', data=df, ax=axis1)\nsns.barplot(x='quality', y='total sulfur dioxide', data=df, ax=axis2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (axis1,axis2) = plt.subplots(2,1,figsize=(10,8))\n\nsns.barplot(x='quality', y='free sulfur dioxide', data=df, ax=axis1)\nsns.barplot(x='quality', y='total sulfur dioxide' , data=df, ax=axis2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(axis1,axis2) = plt.subplots(2,1,figsize=(10,8))\n\nsns.barplot(x='quality', y='pH', data=df, ax=axis1)\nsns.barplot(x='quality', y='sulphates', data=df, ax=axis2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='quality', y='alcohol' , data=df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making bins in order to classify these bins as good or bad (binary classificaion)\nbins = (2, 6, 8)\ngroups = ['Bad', 'Good']\ndf['quality'] = pd.cut(df['quality'], bins = bins, labels = groups)\n\n\n# Encoding these binary gruoups into 0, 1, 2, etc.(categorical to numerical, because most of the machine learning models are not able to interpret categorical varaibles)\n# For this purpose we use label encoder\nle = skpe.LabelEncoder()\n\n\n# Fitting and transforming these features\ndf['quality'] = le.fit_transform(df['quality'])\n\nsns.countplot(df['quality'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Seperating dependent and independent variables \nX = df.drop('quality', axis = 1)\ny = df['quality']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting the data into train and test set\nX_train, X_test, y_train, y_test = ms.train_test_split(X, y, test_size = 0.25, random_state = 111,stratify=y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature scaling\nscaler=skpe.StandardScaler()\n\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.fit_transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_rfc = ensemble.RandomForestClassifier(n_estimators=300)\nclf_rfc.fit(X_train, y_train)\npred_rfc = clf_rfc.predict(X_test)\n\n# Model performance\nprint(sklm.classification_report(y_test, pred_rfc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Random Forest gives the accuracy of 89% **","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_metrics(labels, scores):\n    metrics = sklm.precision_recall_fscore_support(labels, scores)\n    conf = sklm.confusion_matrix(labels, scores)\n    print('                 Confusion matrix')\n    print('                 Score positive    Score negative')\n    print('Actual positive    %6d' % conf[0,0] + '             %5d' % conf[0,1])\n    print('Actual negative    %6d' % conf[1,0] + '             %5d' % conf[1,1])\n    print('')\n    print('Accuracy  %0.2f' % sklm.accuracy_score(labels, scores))\n    print(' ')\n    print('           Positive      Negative')\n    print('Num case   %6d' % metrics[3][0] + '        %6d' % metrics[3][1])\n    print('Precision  %6.2f' % metrics[0][0] + '        %6.2f' % metrics[0][1])\n    print('Recall     %6.2f' % metrics[1][0] + '        %6.2f' % metrics[1][1])\n    print('F1         %6.2f' % metrics[2][0] + '        %6.2f' % metrics[2][1])\n\n\n    \nprint_metrics(y_test, pred_rfc) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"log_reg=lm.LogisticRegression(penalty='l2')\nlog_reg.fit(X_train,y_train)\nprobabilities = log_reg.predict_proba(X_test)  # Predicting probablities of the quality of wine","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to classify the wine as good or bad based on the probability (if it is less than 0.5, then it is bad otherwise it is good)\ndef score_model(probs, threshold):\n    return np.array([1 if x > threshold else 0 for x in probs[:,1]])\nscores = score_model(probabilities, 0.5)\nprint(np.array(scores[:15]))\nprint(np.array(y_test[:15]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_metrics(labels, scores):\n    metrics = sklm.precision_recall_fscore_support(labels, scores)\n    conf = sklm.confusion_matrix(labels, scores)\n    print('                 Confusion matrix')\n    print('                 Score positive    Score negative')\n    print('Actual positive    %6d' % conf[0,0] + '             %5d' % conf[0,1])\n    print('Actual negative    %6d' % conf[1,0] + '             %5d' % conf[1,1])\n    print('')\n    print('Accuracy  %0.2f' % sklm.accuracy_score(labels, scores))\n    print(' ')\n    print('           Positive      Negative')\n    print('Num case   %6d' % metrics[3][0] + '        %6d' % metrics[3][1])\n    print('Precision  %6.2f' % metrics[0][0] + '        %6.2f' % metrics[0][1])\n    print('Recall     %6.2f' % metrics[1][0] + '        %6.2f' % metrics[1][1])\n    print('F1         %6.2f' % metrics[2][0] + '        %6.2f' % metrics[2][1])\n\n\n    \nprint_metrics(y_test, scores)   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Logistic regression gives an accuracy of 86%**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting ROC-AUC curve\n# This curve is used measure the performance of the model by area under the curve.\ndef plot_auc(labels, probs):\n    ## Compute the false positive rate, true positive rate\n    ## and threshold along with the AUC\n    fpr, tpr, threshold = sklm.roc_curve(labels, probs[:,1])\n    auc = sklm.auc(fpr, tpr)\n    \n    ## Plot the result\n    plt.title('Receiver Operating Characteristic')\n    plt.plot(fpr, tpr, color = 'orange', label = 'AUC = %0.2f' % auc)\n    plt.legend(loc = 'lower right')\n    plt.plot([0, 1], [0, 1],'r--')\n    plt.xlim([0, 1])\n    plt.ylim([0, 1])\n    plt.ylabel('True Positive Rate')\n    plt.xlabel('False Positive Rate')\n    plt.show()\n    \nplot_auc(y_test, probabilities) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Hyperparamter Tuning **","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# We can also use GridSearchCV but it takes a lot of time and searches through all hyperparameters even though they are not necessarily required.\n# Hence, RandomizedSearchCV is possibly the best method you could use\nparam_dist={'n_estimators':[100,200,300,400,500,600],'criterion':['gini','entropy'],'max_depth':ss.randint(1,15),'max_features':ss.randint(1,9),'min_samples_leaf':ss.randint(1,9)}\nclf=ensemble.RandomForestClassifier()\nclf_cv=ms.RandomizedSearchCV(clf,param_distributions=param_dist,cv=5)\nclf_cv.fit(X_train,y_train)\nprint(\"Tuned Random Forest Parameters: {}\".format(clf_cv.best_params_)) \nprint(\"Best score is {}\".format(clf_cv.best_score_)) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Accuracy improved from 89% to 91% using Random Forest**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Putting these hyperparameters into our model\nclf=ensemble.RandomForestClassifier(criterion='entropy',max_depth=12,max_features=2,min_samples_leaf=5,n_estimators=300)\nclf.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cross-Validation using Random Forest as estimator","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now let's see how this model works on an unseen data.For this we are using K-Fold CrossValidation\nrfc_cv = ms.cross_val_score(estimator = clf , X = X_train, y = y_train, cv = 10)\nrfc_cv.mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Hence, our model is generalizing well on unseen data**","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}