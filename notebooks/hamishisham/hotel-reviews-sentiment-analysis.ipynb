{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Sentiment Analysis of Hotel reviews\n","metadata":{}},{"cell_type":"markdown","source":"## Importing the packages for data analysis\n\n","metadata":{}},{"cell_type":"code","source":"! pip install nltk\n! pip install wordcloud\n\n","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# General packages\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\n\n# NLP packages\nimport nltk\nfrom nltk import word_tokenize\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom collections import Counter\nfrom wordcloud import WordCloud\n\n# Modeling packages\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\n\nimport re\n\nfrom pylab import rcParams\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nrcParams['figure.figsize'] = 14, 6\nplt.style.use('ggplot')\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Reading the data\n\n","metadata":{}},{"cell_type":"code","source":"hotel_reviews = pd.read_csv('../input/trip-advisor-hotel-reviews/tripadvisor_hotel_reviews.csv')\nhotel_reviews.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Getting the number of words by splitting them by a space\nwords_per_review = hotel_reviews.Review.apply(lambda x: len(x.split(\" \")))\nwords_per_review.hist(bins = 100)\nplt.xlabel('Review Length (words)')\nplt.ylabel('Frequency')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Average words:', words_per_review.mean())\nprint('Skewness:', words_per_review.skew())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"percent_val = 100 * hotel_reviews['Rating'].value_counts()/len(hotel_reviews)\npercent_val","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"percent_val.plot.bar()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Mapping the ratings\nhotel_reviews['Sentiment_rating'] = np.where(hotel_reviews.Rating > 3,1,0)\n\n## Removing neutral reviews \nhotel_reviews = hotel_reviews[hotel_reviews.Rating != 3]\n\n# Printing the counts of each class\nhotel_reviews['Sentiment_rating'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hotel_reviews.Sentiment_rating.value_counts().plot.bar()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pre-processing","metadata":{}},{"cell_type":"markdown","source":"\n\n1. Converting words to lower/upper case\n2. Removing special characters\n3. Removing stopwords and high/low-frequency words\n4. Stemming/lemmatization\n\n### 1. Converting words to lower/upper case\n\n","metadata":{}},{"cell_type":"code","source":"hotel_reviews['reviews_text_new'] = hotel_reviews['Review'].str.lower()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# # word tokenization","metadata":{}},{"cell_type":"code","source":"from nltk import word_tokenize\n\n# Word tokenization example:\nword_tokenize(\"DPhi Bootcamp rules. It is awesome :D\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For reviews not converted to lower case\ntoken_lists = [word_tokenize(each) for each in hotel_reviews['Review']]\ntokens = [item for sublist in token_lists for item in sublist]\nprint(\"Number of unique tokens then: \",len(set(tokens)))\n\n# For reviews converted to lower case\ntoken_lists_lower = [word_tokenize(each) for each in hotel_reviews['reviews_text_new']]\ntokens_lower = [item for sublist in token_lists_lower for item in sublist]\nprint(\"Number of unique tokens now: \",len(set(tokens_lower)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. Removing special characters","metadata":{}},{"cell_type":"code","source":"### Selecting non alpha numeric charactes that are not spaces\nspl_chars = hotel_reviews['reviews_text_new'].apply(lambda review: \n                                                     [char for char in list(review) if not char.isalnum() and char != ' '])\n\n## Getting list of list into a single list\nflat_list = [item for sublist in spl_chars for item in sublist]\n\n## Unique special characters\nset(flat_list)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"review_backup = hotel_reviews['reviews_text_new'].copy()\nhotel_reviews['reviews_text_new'] = hotel_reviews['reviews_text_new'].str.replace(r'[^A-Za-z0-9]+', ' ')\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"- Old Review -\")\nprint(review_backup.values[7])\nprint(\"\\n- New Review -\")\nprint(hotel_reviews['reviews_text_new'][8])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hotel_reviews.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3. Removing stop words","metadata":{}},{"cell_type":"code","source":"from nltk.corpus import stopwords\n\nprint('Available languages for NLTK v.3.4.5: ')\nprint(stopwords.fileids())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"noise_words = []\neng_stop_words = stopwords.words('english')\neng_stop_words","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stop_words = set(eng_stop_words)\nwithout_stop_words = []\nstopword = []\nsentence = hotel_reviews['reviews_text_new'][0]\nwords = nltk.word_tokenize(sentence)\n\nfor word in words:\n    if word in stop_words:\n        stopword.append(word)\n    else:\n        without_stop_words.append(word)\n\nprint('-- Original Sentence --\\n', sentence)\nprint('\\n-- Stopwords in the sentence --\\n', stopword)\nprint('\\n-- Non-stopwords in the sentence --\\n', without_stop_words)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def stopwords_removal(stop_words, sentence):\n    return [word for word in nltk.word_tokenize(sentence) if word not in stop_words]\n\nhotel_reviews['reviews_text_nonstop'] = hotel_reviews['reviews_text_new'].apply(lambda row: stopwords_removal(stop_words, row))\nhotel_reviews[['reviews_text_new','reviews_text_nonstop']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"- Old Review -\")\nprint(hotel_reviews['reviews_text_nonstop'][6])\nprint(\"\\n- New Review -\")\nprint(hotel_reviews['reviews_text_new'][6])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4. Stemming & lemmatization","metadata":{}},{"cell_type":"code","source":"from nltk.stem.porter import PorterStemmer\nporter_stemmer = PorterStemmer()\n\nword_data = \"It originated from the idea that there are readers who prefer learning new skills from the comforts of their drawing rooms\"\n# First Word tokenization\nnltk_tokens = word_tokenize(word_data)\n#Next find the roots of the word\nfor w in nltk_tokens:\n       print (\"Actual: %s  Stem: %s\"  % (w,porter_stemmer.stem(w)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.stem import WordNetLemmatizer\nwordnet_lemmatizer = WordNetLemmatizer()\n\nword_data = \"It originated from the idea that there are readers who prefer learning new skills from the comforts of their drawing rooms\"\nnltk_tokens = nltk.word_tokenize(word_data)\nfor w in nltk_tokens:\n       print (\"Actual: %s  Lemma: %s\"  % (w,wordnet_lemmatizer.lemmatize(w)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Building a machine learning model","metadata":{}},{"cell_type":"code","source":"hotel_reviews[['Review','Rating','Sentiment_rating']].head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## n-grams\n\n","metadata":{}},{"cell_type":"code","source":"from nltk import ngrams\n\nsentence = 'A bird in the hand worths two in the bush'\n\nfor n in range(1, 6):\n    print(str(n) + '-grams:\\n', list(ngrams(sentence.split(), n)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Bag-of-words","metadata":{}},{"cell_type":"code","source":"# The following code creates a word-document matrix.\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nvec = CountVectorizer()\nX = vec.fit_transform(hotel_reviews['reviews_text_new'])\ndf = pd.DataFrame(X.toarray(), columns = vec.get_feature_names())\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Creating a python object of the class CountVectorizer\n\nbow_counts = CountVectorizer(tokenizer= word_tokenize, # type of tokenization\n                             stop_words=noise_words, # List of stopwords\n                             ngram_range=(1,1)) # number of n-grams\n\nbow_data = bow_counts.fit_transform(hotel_reviews['reviews_text_new'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bow_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Divide into training and test sets:","metadata":{}},{"cell_type":"code","source":"X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(bow_data, # Features\n                                                                    hotel_reviews['Sentiment_rating'], # Target variable\n                                                                    test_size = 0.2, # 20% test size\n                                                                    random_state = 0) # random state for replication purposes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_bow.value_counts()/y_test_bow.shape[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Applying logistic regression","metadata":{}},{"cell_type":"code","source":"### Training the model \nlr_model_all = LogisticRegression() # Logistic regression\nlr_model_all.fit(X_train_bow, y_train_bow) # Fitting a logistic regression model\n\n## Predicting the output\ntest_pred_lr_all = lr_model_all.predict(X_test_bow) # Class prediction\n\n## Calculate key performance metrics\nprint(\"F1 score: \", f1_score(y_test_bow, test_pred_lr_all))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Changes with respect to the previous code\n### 1. Increasing the n-grams from just having 1-gram to (1-gram, 2-gram, 3-gram, and 4-gram)\n### 2. Including the stopwords in the bag of words features\n\nbow_counts = CountVectorizer(tokenizer= word_tokenize,\n                             ngram_range=(1,4))\n\nbow_data = bow_counts.fit_transform(hotel_reviews.reviews_text_new)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Notice the increase in features with inclusion of n-grams\nbow_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(bow_data,\n                                                                    hotel_reviews['Sentiment_rating'],\n                                                                    test_size = 0.2,\n                                                                    random_state = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining and training the model\nlr_model_all_new = LogisticRegression(max_iter = 200)\nlr_model_all_new.fit(X_train_bow, y_train_bow)\n\n# Predicting the results\ntest_pred_lr_all = lr_model_all_new.predict(X_test_bow)\n\nprint(\"F1 score: \", f1_score(y_test_bow,test_pred_lr_all))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## TF-IDF model","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n### Creating a python object of the class CountVectorizer\ntfidf_counts = TfidfVectorizer(tokenizer= word_tokenize, # type of tokenization\n                               stop_words=noise_words, # List of stopwords\n                               ngram_range=(1,1)) # number of n-grams\n\ntfidf_data = tfidf_counts.fit_transform(hotel_reviews['reviews_text_new'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tfidf_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(tfidf_data,\n                                                                            hotel_reviews['Sentiment_rating'],\n                                                                            test_size = 0.2,\n                                                                            random_state = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Setting up the model class\nlr_model_tf_idf = LogisticRegression()\n\n## Training the model \nlr_model_tf_idf.fit(X_train_tfidf,y_train_tfidf)\n\n## Prediciting the results\ntest_pred_lr_all = lr_model_tf_idf.predict(X_test_tfidf)\n\n## Evaluating the model\nprint(\"F1 score: \",f1_score(y_test_bow, test_pred_lr_all))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from joblib import load \nimport string\nfrom nltk import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nloaded_joblib_model = load(filename=\"utils/Sentiment_Analysis_unigram.joblib\")\nfeats = loaded_joblib_model.feature_names\nfeats_len = len(feats)\n\ndef sentiment_analyzer(sent):\n    lemmatizer = WordNetLemmatizer()\n    sent =sent.lower()\n    sent = sent.translate(str.maketrans('', '', string.punctuation))\n    filtered_sentence = [] \n    stop_words = set(stopwords.words('english'))\n    word_tokens = word_tokenize(sent) \n    filtered_sentence = [w for w in word_tokens if not w in stop_words] \n    lemmatized_output =[]\n    lemmatized_output = [lemmatizer.lemmatize(w) for w in filtered_sentence ]\n\n    sent_features=[]\n    sent_dict = {}\n    for word in lemmatized_output:\n        if not word in sent_dict:\n            sent_dict[word] = 0\n        sent_dict[word] = sent_dict[word] + 1\n    for i in range(feats_len):\n        if not feats[i] in sent_dict:\n            sent_features.append(0)\n        else:\n            sent_features.append(sent_dict[feats[i]])\n    joblib_y_preds = loaded_joblib_model.predict([sent_features])\n    return joblib_y_preds[0]\n","metadata":{},"execution_count":null,"outputs":[]}]}