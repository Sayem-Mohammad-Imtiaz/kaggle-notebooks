{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Functions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport scipy.stats as stats\nimport matplotlib.pyplot as plt\nfrom random import sample\nfrom sklearn.utils import resample\nfrom imblearn import under_sampling,over_sampling\nfrom sklearn.preprocessing import StandardScaler,LabelEncoder\nfrom sklearn.model_selection import train_test_split,learning_curve,StratifiedKFold\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LogisticRegression,SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import LinearSVC, SVC\nfrom sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\nfrom sklearn.dummy import DummyClassifier\nfrom statsmodels.stats import stattools\nimport statsmodels.graphics.tsaplots as smgt\nfrom sklearn.metrics import roc_curve, auc, accuracy_score, confusion_matrix, classification_report, precision_recall_curve, average_precision_score, roc_auc_score\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_categoric_feature(feature_name):\n    dftemp = dfdata.groupby([feature_name,'churn'],as_index = False).agg({'customerid':'count','monthlycharges':'mean'})\n    dftemp['feature_rate'] = dftemp.apply(lambda row: row['customerid'] / dftemp[dftemp[feature_name] == row[feature_name]]['customerid'].sum() ,axis = 1)\n    dftemp['rate'] = dftemp['customerid'] / dftemp['customerid'].sum()\n    fig,ax = plt.subplots(1,3,figsize=(20,3))\n    sns.barplot(y=feature_name, x = 'feature_rate', color = 'darkorange',data = dftemp[dftemp['churn'] == 'Yes'],ax = ax[0])\n    ax[0].set(title = 'churn rate in feature ' + feature_name, xlabel = '')\n    sns.barplot(y=feature_name, x = 'rate', hue='churn',data = dftemp,ax = ax[1])\n    ax[1].set(title = feature_name + ' rate in whole dataset',xlabel = '')\n    sns.barplot(y=feature_name, x = 'monthlycharges', hue='churn',data = dftemp,ax = ax[2])\n    ax[2].set(title = feature_name + ' monthlycharges',xlabel = '')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_learning_curve(estimator, X_train, y_train):\n    kfold = StratifiedKFold(n_splits = 5)\n    train_size,train_scores,test_scores = learning_curve(estimator,X_train,y_train,train_sizes = np.linspace(0.05,1,20),cv = kfold)\n    train_scores_mean = np.mean(train_scores,axis=1)\n    train_scores_std = np.std(train_scores,axis=1)\n    test_scores_mean = np.mean(test_scores,axis=1)\n    test_scores_std = np.std(test_scores,axis=1)\n\n    sns.lineplot(x=train_size, y=train_scores_mean, c='r', label='train')\n    plt.fill_between(x=train_size, y1=train_scores_mean+train_scores_std, y2=train_scores_mean-train_scores_std, alpha=0.1, color='r')\n    sns.lineplot(x=train_size,y=test_scores_mean,c='b',label='test')\n    plt.fill_between(x=train_size, y1=test_scores_mean+test_scores_std, y2=test_scores_mean-test_scores_std, alpha=0.1, color='b')\n    plt.legend(loc='best')\n    plt.title(\"Learning Curve\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_confusion_matrix(estimator,y,y_pred):\n    cm = confusion_matrix(y, y_pred, labels = [0,1] )\n    sns.heatmap(cm, annot=True,  fmt='.0f', xticklabels = [\"No\", \"Yes\"] , yticklabels = [\"No\", \"Yes\"],cbar = False)\n    plt.title(\"Confusion Matrix\")\n    plt.ylabel('Actual')\n    plt.xlabel('Prediction')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_empty_confusion_matrix():\n    plt.text(0.45, .6, \"TN\", size=100, horizontalalignment='right')\n    plt.text(0.45, .1, \"FN\", size=100, horizontalalignment='right')\n    plt.text(.95, .6, \"FP\", size=100, horizontalalignment='right')\n    plt.text(.95, 0.1, \"TP\", size=100, horizontalalignment='right')\n    plt.xticks([.25, .75], [\"predicted negative\", \"predicted positive\"], size=15)\n    plt.yticks([.25, .75], [\"positive class\", \"negative class\"], size=15)\n    plt.plot([.5, .5], [0, 1], '--', c='k')\n    plt.plot([0, 1], [.5, .5], '--', c='k')\n    plt.xlim(0, 1)\n    plt.ylim(0, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_clf_result(estimator,X_train,y_train,X_test = None, y_test = None):\n    y_pred = estimator.predict(X_train)\n    acc = round(accuracy_score(y_train, y_pred),2)\n    print(\"Train Accuracy : \", acc)\n    if X_test is None:\n        y_pred_test = estimator.predict(X_train)\n        plt.figure(figsize=(18,5))\n        plt.subplot(121)\n        plot_learning_curve(estimator,X_train,y_train)\n        plt.subplot(122)\n        plot_confusion_matrix(estimator,y_train,y_pred)   \n    else:\n        test_acc = round(estimator.score(X_test,y_test),2)\n        print(\"Classification Accuracy :\", test_acc)\n        y_pred_test = estimator.predict(X_test)\n        plt.figure(figsize=(18,5))\n        plt.subplot(121)\n        plot_learning_curve(estimator,X_train,y_train)\n        plt.subplot(122)\n        plot_confusion_matrix(estimator,y_test,y_pred_test)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_clf_data(n_points, n_centers = 2, random_state = 42):\n    n_features=2\n    rnd_gen = np.random.RandomState(random_state)\n    feature_names = ['feature' + str(x+1) for x in range(n_features)]\n    X = pd.DataFrame(columns = feature_names)\n    for center in range(n_centers):\n        X = X.append(pd.DataFrame(rnd_gen.normal(loc=5*center, size=(n_points, n_features)), columns=feature_names),ignore_index=True)\n    X['target'] = (X['feature1'] > 2)\n    n_changes = int(n_points * 0.2)\n    list_true = sample(X[X['target'] == True].index.to_list(), n_changes)\n    X.loc[list_true,'target'] = False\n    n_changes = int(n_points * 0.1)\n    list_false = sample(X[X['target'] == False].index.to_list(),n_changes)\n    X.loc[list_false,'target'] = True\n    X = X.sample(frac=1).reset_index(drop=True)\n    return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_decision_boundary(estimator,X,title = None):\n    xx = np.linspace(-3, 9, 100)\n    yy = np.linspace(-3, 9, 100)\n    X1, X2 = np.meshgrid(xx, yy)\n    X_grid = np.c_[X1.ravel(), X2.ravel()]\n    decision_values = estimator.decision_function(X_grid)\n    sns.scatterplot(x='feature1', y='feature2', hue='target', data = X)\n    plt.contour(X1, X2, decision_values.reshape(X1.shape), colors=\"black\",levels = 0)\n    if title is not None:\n        plt.title(title)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Get Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dfdata = pd.read_csv(\"../input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\ndfdata.columns = dfdata.columns.str.lower()\ndfdata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfdata.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Missing Values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dfdata.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfdata.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfdata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfdata.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfdata['seniorcitizen'] = dfdata['seniorcitizen'].map({0:'No',1:'Yes'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfdata['totalcharges_new'] = pd.to_numeric(dfdata['totalcharges'],errors = 'coerce')\ndfdata[dfdata['totalcharges_new'].isnull() == True][['totalcharges','totalcharges_new']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfdata['totalcharges_new'].fillna(0,inplace = True)\ndfdata['totalcharges'] = dfdata['totalcharges_new']\ndfdata.drop('totalcharges_new',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dfdata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Target Variable","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(round(100 * dfdata['churn'].value_counts() / dfdata.shape[0],0))\nplt.figure(figsize=(10,2))\nsns.countplot(y='churn',data = dfdata)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Numerical Features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"numeric_features = dfdata.columns[dfdata.dtypes != 'object'].values.tolist()\ncategoric_features = dfdata.columns[dfdata.dtypes == 'object'].values.tolist()\ncategoric_features.remove('customerid')\ncategoric_features.remove('churn')\nprint(\"Categoric features : \",categoric_features)\nprint(\"Numeric features : \",numeric_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(1,3,figsize=(18,5))\n\nsns.distplot(dfdata[dfdata['churn'] == 'No']['tenure'],label = 'No',ax=ax[0])\nsns.distplot(dfdata[dfdata['churn'] == 'Yes']['tenure'],label = 'Yes',ax=ax[0])\nax[0].set_title('Tenure')\nax[0].legend()\n\nsns.distplot(dfdata[dfdata['churn'] == 'No']['monthlycharges'],label = 'No',ax=ax[1])\nsns.distplot(dfdata[dfdata['churn'] == 'Yes']['monthlycharges'],label = 'Yes',ax=ax[1])\nax[1].set_title('Monthly Charges')\nax[1].legend()\n\nsns.distplot(dfdata[dfdata['churn'] == 'No']['totalcharges'],label = 'No',ax=ax[2])\nsns.distplot(dfdata[dfdata['churn'] == 'Yes']['totalcharges'],label = 'Yes',ax=ax[2])\nax[2].set_title('Total Charges')\nax[2].legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- New customers until 20 months tend to churn more\n- Customers monthly charges higher than 70 tend to churn more\n- Total charges dont depend on churn. Seems to be non important","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(dfdata[numeric_features + ['churn']],hue = 'churn', diag_kind = 'kde')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bins = range(12,75,12)\ndfdata['tenure_bin'] = np.digitize(dfdata['tenure'],bins,right = True)\ndfdata['tenure_bin'] = dfdata['tenure_bin'].astype('category')\ncategoric_features.append('tenure_bin')\nplot_categoric_feature('tenure_bin')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfdata['meancharges'] = dfdata['totalcharges'] / dfdata['tenure']\nnumeric_features.append('meancharges')\nfig,ax = plt.subplots(1,2,figsize=(18,4))\nsns.scatterplot(x='monthlycharges',y='meancharges',data = dfdata,ax = ax[0])\nsns.boxplot(x = 'tenure_bin',y = 'monthlycharges',data= dfdata,ax = ax[1])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfdata['comparemean'] = dfdata['meancharges'] > dfdata['monthlycharges']\ndfdata['comparemean'] = np.where(dfdata['meancharges'] == dfdata['monthlycharges'],'Equal',dfdata['comparemean'])\ndfdata['comparemean'] = dfdata['comparemean'].astype('category')\nplot_categoric_feature('comparemean')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- As tenure reaches to 3 years, customer gets extra discounts and average monthly charges decrease.\n- At first two years, average monthly charges increase with tenure.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Categorical Features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dfdata[categoric_features].nunique()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"plot_categoric_feature('gender')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Gender seems to have no effect on churn rate and monthly charges","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_categoric_feature('seniorcitizen')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Customers are generally young, old customers tend to churn and paying higher monthly charges","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_categoric_feature('partner')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Customers working without partner tend to churn. Nearly half of the customers work with partner","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_categoric_feature('dependents')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Customers who have no dependents tend to churn. Nearly 30% of customers have dependents.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_categoric_feature('phoneservice')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- 90% of customers use phone services but churn rate seems to be same among customers.\n- Using phone services means higher monthly charges but it doesnt change churn rate so much.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(dfdata['phoneservice'],dfdata['multiplelines'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_categoric_feature('multiplelines')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Phone services info is given in multiple lines feature. Churn rate seems to be same among customers using multiplelines","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_categoric_feature('internetservice')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Most of the customers use fiberoptic and they tend to churn more.\n- Fiberoptic internet service is more expensive than DSL as expected.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_categoric_feature('onlinesecurity')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- 50% of customers dont use online security and they tend to churn more.\n- Online security service seems to be free or so cheap for customers using internet service.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_categoric_feature('onlinebackup')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- 50% of customers dont use online backup and they tend to churn more.\n- Online backup service seems to be free or so cheap for customers using internet service.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_categoric_feature('deviceprotection')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- 45% of customers dont use device protection and they tend to churn more.\n- Device protection service seems to be so cheap for customers using internet service.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_categoric_feature('techsupport')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- 50% of customers dont use device protection and they tend to churn more","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_categoric_feature('streamingtv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_categoric_feature('streamingmovies')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Using streamingmovies or streamingtv has little effect on churn rate.\n- Prices seem to be nearly same for both services.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_categoric_feature('contract')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Monthly contracts pay less and tend to churn more.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_categoric_feature('paperlessbilling')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- 60% of customers use paperlessbilling, they tend to pay more charges and tend to churn more.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_categoric_feature('paymentmethod')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- 20% of customers use mailed check, paying less and their churn rate is lower.\n- Monthly charges dont change much with other payment methods.\n- 30% of customers use electronic check and they tend to churn more.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"- Gender, PhoneService, MultipleLines dont have a clear difference in distribution of churn rates.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dfdata['internet_fiber'] = np.where(dfdata['internetservice'] == 'Fiber optic','Yes','No')\ndfdata['monthly_contract'] = np.where(dfdata['contract'] == 'Month-to-month','Yes','No')\ndfdata['electronic_payment'] = np.where(dfdata['paymentmethod'] == 'Electronic check','Yes','No')\ncategoric_features.extend(['internet_fiber','monthly_contract','electronic_payment'])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"dfdata['internet'] = np.where(dfdata['internetservice'] == 'No','No','Yes')\ndfdata['num_services'] = (dfdata[['internet','onlinesecurity','onlinebackup','deviceprotection','techsupport','streamingtv','streamingmovies']] == 'Yes').sum(axis=1)\ndfdata['num_services'] = dfdata['num_services'].astype('category')\nplot_categoric_feature('num_services')\ncategoric_features.append('internet')\ndfdata['num_services'] = dfdata['num_services'].astype('int')\nnumeric_features.append('num_services')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfdata['monthly_mean_diff'] = (dfdata['monthlycharges'] - dfdata['monthlycharges'].mean()) / dfdata['monthlycharges'].mean()\nnumeric_features.append('monthly_mean_diff')\nservices_list = ['internetservice','onlinesecurity', 'onlinebackup', 'deviceprotection', 'techsupport','streamingtv', 'streamingmovies']\nfor service in services_list:\n    colname = service + '_mean_diff'\n    dfdata[colname] = dfdata['monthlycharges'] / dfdata.groupby(service)['monthlycharges'].transform('mean')\n    numeric_features.append(colname)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Selection","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"le = LabelEncoder()\nencoded_features = []\nfor feature in categoric_features:\n    colname = 'le_' + feature\n    dfdata[colname] = le.fit_transform(dfdata[feature])\n    encoded_features.append(colname)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.heatmap(dfdata[numeric_features].corr(),annot = True,fmt  ='.1g')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_list = ['meancharges','totalcharges','monthly_mean_diff','onlinebackup_mean_diff','deviceprotection_mean_diff','techsupport_mean_diff','streamingmovies_mean_diff']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.heatmap(dfdata[numeric_features].drop(drop_list,axis=1).corr(),annot = True,fmt  ='.1g')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numeric_features = [x for x in numeric_features if x not in drop_list]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfdata.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(18,12))\nsns.heatmap(dfdata[encoded_features].corr(),annot = True,fmt  ='.1g')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_list = ['le_phoneservice','le_contract','le_internet','le_tenure_bin']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(18,12))\nsns.heatmap(dfdata[encoded_features].drop(drop_list, axis=1).corr(),annot = True,fmt  ='.1g')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categoric_features = [x for x in encoded_features if x not in drop_list and categoric_features]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"[categoric_features + numeric_features]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression\n- Normal regression formula into sigmoid function\n- Result is the probability of true, 1 if positive, 0 if negative\n- Linear split of data space\n- Selection of decision boundary is important\n- Regression Assumptions\n    - Handling of outlier data points\n    - No perfect multicollinearity between the predictors (via VIF Factor or correlation)\n- Regularization type and magnitude are important parameters.\n- Uses logarithmic loss function to determine classes","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<img src='https://ai-master.gitbooks.io/logistic-regression/assets/sigmoid_function.png' width='50%' height = '50%'>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dftemp = make_clf_data(100)\nX = dftemp.drop('target',axis=1)\ny = dftemp['target']\nlog_reg = LogisticRegression()\nlog_reg.fit(X, y)\nprint(np.round(log_reg.intercept_, 2), np.round(log_reg.coef_, 2))\nprint_clf_result(log_reg, X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_decision_boundary(log_reg,dftemp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c_list = [0.01,0.1,1,10]\nplt.figure(figsize=(18,5))\nfor index, c_value in enumerate(c_list):\n    title = 'C : ' + str(c_value)\n    log_reg = LogisticRegression(C = c_value).fit(X,y)\n    plt.subplot(1,len(c_list),index+1)\n    plot_decision_boundary(log_reg, dftemp, title)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- low C parameter means, high regularization and high bias.\n- high C parameter means, high risk of overfitting.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = dfdata[numeric_features + categoric_features]\ny = dfdata['churn'].map({'No':0,'Yes':1})\nX_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler().fit(X_train)\nX_train_scaled = pd.DataFrame(scaler.transform(X_train), columns = X_train.columns)\nX_test_scaled = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_reg = LogisticRegression()\nlog_reg.fit(X_train_scaled, y_train)\nprint(np.round(log_reg.intercept_, 2), np.round(log_reg.coef_, 2))\nprint_clf_result(log_reg, X_train_scaled, y_train, X_test_scaled, y_test)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"c_list = [0.001,0.01,0.1,1,10,100,1000]\naccuracy_list = []\ncoef_list = []\nfig,ax = plt.subplots(1,2,figsize=(18,5))\nfor index, c_value in enumerate(c_list):\n    log_reg = LogisticRegression(C = c_value).fit(X_train_scaled,y_train)\n    y_pred = log_reg.predict(X_train_scaled)\n    accuracy_list.append(log_reg.score(X_train_scaled,y_train))\n    ax[0].plot(np.array(log_reg.coef_).ravel(),label = 'c:'+str(c_value))\n    ax[0].legend()\n    ax[0].set_title('Coefficients')\nax[1].plot(accuracy_list)\nax[1].set_title('Accuracy')\nplt.xticks(range(len(c_list)),c_list)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c_list = [0.001,0.01,0.05,0.1,1,10]\nscore = []\nn_zero_coefs = []\nfor c_value in c_list:\n    log_reg = LogisticRegression(C=c_value, penalty='l1', solver='liblinear').fit(X_train,y_train)\n    coef = np.round(log_reg.coef_,4)\n    n_zero_coefs.append(len(coef[coef == 0]))\n    score.append(round(log_reg.score(X_train, y_train),2))\n    \ndftemp = pd.DataFrame(zip(c_list, n_zero_coefs, score), columns = ['alpha','zero_coef','score'])\ndftemp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"estimator = LogisticRegression(C=0.05, penalty='l1', solver='liblinear')\nlog_reg = estimator.fit(X_train_scaled, y_train)\nrfe = RFE(estimator,n_features_to_select=3).fit(X_train_scaled, y_train)\ndftemp = pd.DataFrame(zip(X_train_scaled.columns.values,rfe.ranking_,log_reg.coef_.ravel()),columns = ['feature','rank','coef'])\ndftemp.sort_values('rank', ascending=True, inplace=True)\ndftemp.reset_index(inplace=True,drop=True)\ndftemp.tail(10)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"X_temp = X_train_scaled.drop(dftemp.iloc[-8:,0].values,axis = 1)\nlog_reg = LogisticRegression()\nlog_reg.fit(X_temp, y_train)\nprint(np.round(log_reg.intercept_, 2), np.round(log_reg.coef_, 2))\nprint_clf_result(log_reg, X_temp, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SVM\n- Linear and non linear support vector machines\n- Split data via linear vectors\n- Kernel trick : transformation of data to split data via linear vectors\n- Uses hinge loss function to determine classes\n- Hinge loss : Higher accuracy, worse probability analysis\n- High performance on low feature, low volume data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X.drop(dftemp.iloc[-8:,0].values,axis = 1,inplace=True)\nX_train, X_test, y_train, y_test = train_test_split(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler().fit(X_train)\nX_train_scaled = pd.DataFrame(scaler.transform(X_train), columns = X_train.columns)\nX_test_scaled = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svc = LinearSVC(C=0.05)\nsvc.fit(X_train_scaled,y_train)\nprint(np.round(svc.intercept_, 2), np.round(svc.coef_, 2))\nprint_clf_result(svc, X_train_scaled, y_train,X_test_scaled,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SVC","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"svc = SVC(C=1, gamma=0.1, kernel = 'rbf')\nsvc.fit(X_train_scaled,y_train)\nprint_clf_result(svc, X_train_scaled, y_train,X_test_scaled,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SGD Classifier\n- Gradient Descent Method\n- User defined loss functions can be used in addition to Hinge and Log loss functions\n- Efficient on high volume data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sgd = SGDClassifier(loss='hinge', alpha=0.05, eta0=0.01)\nsgd.fit(X_train_scaled, y_train)\nprint_clf_result(sgd, X_train_scaled, y_train, X_test_scaled, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Naive Bayes Classifier\n- Based on Bayes probability theorem\n- Can be used for determination of baseline accuracy\n- Fast training but worse generalization performance\n- Best in low volume data\n    - GaussianNB is used for continuos features\n    - BernoulliNB is used for binary features\n    - MultinomialNB is used for multi class features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"gnb = GaussianNB()\ngnb.fit(X_train, y_train)\nprint_clf_result(gnb, X_train, y_train, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mnb = MultinomialNB(alpha=0.05)\nmnb.fit(X_train, y_train)\nprint_clf_result(gnb, X_train, y_train, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bnb = BernoulliNB(alpha=0.05)\nbnb.fit(X_train, y_train)\nprint_clf_result(bnb, X_train, y_train, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decision Tree Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dt = DecisionTreeClassifier(max_depth=5, random_state=12)\ndt.fit(X_train_scaled, y_train)\nprint_clf_result(dt, X_train_scaled, y_train, X_test_scaled, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dftemp = pd.DataFrame(zip(X.columns.values,dt.feature_importances_), columns = ['feature','importance'])\nplt.figure(figsize=(18,5))\nsns.barplot(x='importance', y='feature', data=dftemp)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Uncertainty Estimates\n- Decision function\n- Probability Predictions\n- Not supported all models\n- Can be used via changing thresholds","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dftemp = pd.DataFrame(np.round(100 * log_reg.predict_proba(X_test_scaled),0),columns = ['prob0','prob1'])\ndftemp['y'] = y_test.values\ndftemp['y_pred'] = log_reg.predict(X_test_scaled)\ndftemp['decision'] = np.round(log_reg.decision_function(X_test_scaled), 2)\ndftemp['error'] = np.abs(dftemp['y'] - dftemp['y_pred'])\nprint(\"Min and max decision function values : \",round(np.min(log_reg.decision_function(X_test_scaled)),2),round(np.max(log_reg.decision_function(X_test_scaled)),2))\ndftemp.head()\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"bins = range(0,100,5)\ndftemp['prob1bin'] = np.digitize(dftemp['prob1'],bins,right=True)\nsns.barplot(x='prob1bin',y='error',data=dftemp)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Imbalanced Data\n- Balance data via data preparation methods, use of suitable classification algorithms or performance metrics\n- Random Under Sampling\n    - Discard majority class data\n    - Information loss\n- Random Over Sampling\n    - Random generation of minority class data\n    - Risk of overfit\n- Cluster Based Over Sampling\n    - Cluster minority and majority class data independently.\n    - Random generation of data for each cluster.\n    - Risk of overfit\n- SMOTE (Synthetic Minority OverSampling Technique)\n    - Random sub sample of minority class data\n    - Generate synthetic data from random selected data via KNN\n    - Not good performance on high volume data\n- Imbalanced Data Classifiers\n   - Ensemble Classifiers\n   - Cost Censitive Classifiers\n- Imbalanced Data Performance Metrics\n    - F1 score\n    - F2 score\n    - ROC AUC - PR AUC\n    - Precision and Recall\n    - Accuracy and G-Mean","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dummy_majority = DummyClassifier(strategy='most_frequent').fit(X_train_scaled, y_train)\npred_most_frequent = dummy_majority.predict(X_test_scaled)\nprint(\"Test score: {:.2f}\".format(dummy_majority.score(X_test_scaled, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"round(100 * dfdata['churn'].value_counts() / dfdata.shape[0], 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Preparation Methods","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rus = under_sampling.RandomUnderSampler()\nX_rus, y_rus = rus.fit_sample(X_train_scaled,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_reg = LogisticRegression()\nlog_reg.fit(X_rus, y_rus)\nprint(np.round(log_reg.intercept_, 2), np.round(log_reg.coef_, 2))\nprint_clf_result(log_reg, X_rus, y_rus,X_test_scaled,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"smote = over_sampling.SMOTE(sampling_strategy='minority')\nX_sm, y_sm = smote.fit_sample(X_train_scaled, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_reg = LogisticRegression()\nlog_reg.fit(X_sm, y_sm)\nprint(np.round(log_reg.intercept_, 2), np.round(log_reg.coef_, 2))\nprint_clf_result(log_reg, X_sm, y_sm,X_test_scaled,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Balancing via Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"svc = SVC(C=1, gamma=0.1, kernel = 'rbf', class_weight='balanced', probability=True)\nsvc.fit(X_train_scaled, y_train)\nprint_clf_result(svc, X_train_scaled, y_train, X_test_scaled, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Performance Metrics","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Confusion Matrix","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"plot_empty_confusion_matrix()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Positive Class : Geri Dönen Müşteri\n- Dönmeyecek müşteriyi döner olarak tahmin etmenin (FP) maliyeti =\n- Geri dönen müşteriyi dönmez olarak tahmin etmenin (FN) maliyeti = ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Common Metrics\n\\begin{equation}\n\\text{Accuracy} = \\frac{\\text{TP} + \\text{TN}}{\\text{TP} + \\text{TN} + \\text{FP} + \\text{FN}}\n\\end{equation}\n\n\\begin{equation}\n\\text{Precision (Positive Prediction Value)} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}\n\\end{equation}\n\n\\begin{equation}\n\\text{Recall (Sensitivity, TPR)} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}\n\\end{equation}\n\n\\begin{equation}\n\\text{FPR} = \\frac{\\text{FP}}{\\text{FP} + \\text{TN}}\n\\end{equation}\n\n\\begin{equation}\n\\text{Specificity} = \\frac{\\text{TN}}{\\text{FP} + \\text{TN}}\n\\end{equation}\n\n\\begin{equation}\n\\text{G-Mean} = (\\text{Sensitivity} * \\text{Specificity})\n\\end{equation}\n\n\\begin{equation}\n\\text{F1-Score} = 2 \\cdot \\frac{\\text{precision} \\cdot \\text{recall}}{\\text{precision} + \\text{recall}}\n\\end{equation}","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = log_reg.predict(X_test_scaled)\nplt.figure(figsize=(2,2))\nplot_confusion_matrix(log_reg, y_test, y_pred)\nplt.show()\nprint(classification_report(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_threshold = log_reg.decision_function(X_test_scaled) > -0.2\nplt.figure(figsize=(2,2))\nplot_confusion_matrix(log_reg, y_test, y_pred_threshold)\nplt.show()\nprint(classification_report(y_test,y_pred_threshold))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_threshold = log_reg.predict_proba(X_test_scaled)[:,1] > 0.35\nplt.figure(figsize=(2,2))\nplot_confusion_matrix(log_reg, y_test, y_pred_threshold)\nplt.show()\nprint(classification_report(y_test,y_pred_threshold))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ROC Curve\n- Tradeoff between recall and precision\n- Find best threshold to optimize both\n- Use in GridSearchCV, model, cross_val_score scoring parameter or test via different model hyperparameters","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"aps_logreg = round(average_precision_score(y_test, log_reg.predict_proba(X_test_scaled)[:, 1]),2)\naps_svc = round(average_precision_score(y_test, svc.decision_function(X_test_scaled)),2)\nprint(\"Average Precision Scores (log reg and svc) : \", aps_logreg, aps_svc)\nprecision_lr, recall_lr, thresholds_lr = precision_recall_curve(y_test, log_reg.decision_function(X_test_scaled))\nclose_zero_lr = np.argmin(np.abs(thresholds_lr))\nplt.plot(precision_lr[close_zero_lr], recall_lr[close_zero_lr], 'o', markersize=10, label=\"threshold zero logreg\", fillstyle=\"none\", c='k', mew=2)\nplt.plot(precision_lr, recall_lr, label=\"log reg\")\n\nprecision_svc, recall_svc, thresholds_svc = precision_recall_curve(y_test, svc.decision_function(X_test_scaled))\nclose_zero_svc = np.argmin(np.abs(thresholds_svc))\nplt.plot(precision_svc[close_zero_svc], recall_svc[close_zero_svc], 'v', markersize=10, label=\"threshold zero svc\", fillstyle=\"none\", c='k', mew=2)\nplt.plot(precision_svc, recall_svc, label=\"svc\")\nplt.legend()\nplt.title('Precision Recall Curve')\nplt.xlabel(\"Precision\")\nplt.ylabel(\"Recall\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_empty_confusion_matrix()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\\begin{equation}\n\\text{TPR} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}\n\\end{equation}\n\n\\begin{equation}\n\\text{FPR} = \\frac{\\text{FP}}{\\text{FP} + \\text{TN}}\n\\end{equation}\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"auc_logreg = roc_auc_score(y_test, log_reg.predict_proba(X_test_scaled)[:, 1])\nauc_svc = roc_auc_score(y_test, svc.decision_function(X_test_scaled))\nprint(\"AUC scores (logreg and svc) : \", round(auc_logreg,2), round(auc_svc,2))\n\nfpr_lr, tpr_lr, thresholds_lr = roc_curve(y_test, log_reg.decision_function(X_test_scaled))\nplt.plot(fpr_lr, tpr_lr, label=\"ROC LogReg\")\nclose_zero_lr = np.argmin(np.abs(thresholds_lr))\nplt.plot(fpr_lr[close_zero_lr], tpr_lr[close_zero_lr], 'o', markersize=10,label=\"threshold zero\", fillstyle=\"none\", c='k', mew=2)\n\nfpr_svc, tpr_svc, thresholds_svc = roc_curve(y_test, svc.decision_function(X_test_scaled))\nplt.plot(fpr_svc, tpr_svc, label=\"ROC SVC\")\nclose_zero_svc = np.argmin(np.abs(thresholds_svc))\nplt.plot(fpr_svc[close_zero_svc], tpr_svc[close_zero_svc], 'v', markersize=10, label=\"threshold zero\", fillstyle=\"none\", c='k', mew=2)\n\nplt.title('ROC Curve')\nplt.xlabel(\"FPR\")\nplt.ylabel(\"TPR (recall)\")\nplt.legend(loc=4)\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}