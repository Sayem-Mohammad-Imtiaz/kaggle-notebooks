{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Mobile Phone Price Prediction","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### About Dataset :","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"- In this Project,On the basis of the mobile Specification like Battery power, 3G enabled , wifi ,Bluetooth, Ram etc we are predicting Price range of the mobile. To know more about data https://www.kaggle.com/iabhishekofficial/mobile-price-classification","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"##### In this data:\n- id:ID\n- battery_power:Total energy a battery can store in one time measured in mAh\n- blue:Has bluetooth or not\n- clock_speed:speed at which microprocessor executes instructions\n- dual_sim:Has dual sim support or not\n- fc:Front Camera mega pixels\n- four_g:Has 4G or not\n- int_memory:Internal Memory in Gigabytes\n- m_dep:Mobile Depth in cm\n- mobile_wt:Weight of mobile phone\n- n_cores:Number of cores of processor\n- pc:Primary Camera mega pixels\n- px_height:Pixel Resolution Height\n- px_width:Pixel Resolution Width\n- ram:Random Access Memory in Megabytes\n- sc_h:Screen Height of mobile in cm\n- sc_w:Screen Width of mobile in cm\n- talk_time:longest time that a single battery charge will last when you are\n- three_g:Has 3G or not\n- touch_screen:Has touch screen or not\n- wifi:Has wifi or not\n- __price_range__: This is the target variable with value of __0 (low cost)__, __1 (medium cost)__, __2 (high cost)__ and __3 (very high cost)__","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 1. importing libraries & loading dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.read_csv('../input/mobile-price-classification/train.csv')\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- in this dataset there are 4 o/p varible.\n- its multiclass classification problem.\n\n- 0 - Low\n- 1 - Medium\n- 2 - High\n- 3 - Very High","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 2. EDA","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Checking the missing values.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- There are no null values. So now We can check the datatype\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### 2.1 Checking the datatype","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Seems Like there are no Categorical Feature. All value are numeric dataset. So We can do further process.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- We have 2000 samples and 21 Features.\n- The last Feature is Target Feature which means we have label dataset.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### 2.2 Descriptive Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.3 Data Visulization & Analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"####  2.3.1 checking balanced or imbalanced dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"value_counts = pd.value_counts(dataset['price_range'])\nvalue_counts.values # converting into numpy array cause other wise we can't plot pie\nlabel  = ['very high', 'high', 'medium', 'low']\ncolors = ['yellow','turquoise','lightblue', 'pink']\nfig1, axarr = plt.subplots()\n\nplt.pie(value_counts.values, autopct = '%0.01f', explode = [0.1,0.1,0.1,0.1], shadow = True, labels = label, colors = colors)\n\naxarr.set_title('balanced or imbalaced?')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- In above the pie chart all class have same number of dataset.\n- 0 - 500 (low price)\n- 1 - 500 (medium price)\n- 2 - 500 (high price)\n- 3 - 500 (very high price)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### 2.3.2  Ram affect on price","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot(x = 'ram', y = 'price_range', data = dataset, kind = 'kde', color = 'green')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"####  2.3.4 internal_memoery vs price","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pointplot(y = 'int_memory', x = 'price_range', data = dataset)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2.3.5 Battery Power vs Price range","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x = 'price_range', y = 'battery_power',data = dataset)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2.3.6 4g supported or not","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"values = dataset['four_g'].value_counts()\nlabel = ['4G-supported', 'Not supported']\ncolor = ['lightgreen', 'lightpink']\nfig, ax1 = plt.subplots()\nplt.pie(values, autopct = '%0.01f', labels = label, startangle = 90, colors  =color, shadow = True)\nax1.set_title('4G supported or not supported?')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2.3.7 3G support or not","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"values = dataset['three_g'].value_counts()\nlabel = ['3G supported', 'Not supported']\nfig, ax1 = plt.subplots()\nplt.pie(values, startangle = 70, labels = label, autopct = '%0.01f%%', explode = [0,0.1], shadow  = True)\nax1.set_title('3G supported or not supported?') \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2.3.8 No. of Phones vs Camera megapixels of front and primary camera","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\ndataset['fc'].hist(alpha=0.5,color='blue',label='Front camera')\ndataset['pc'].hist(alpha=0.5,color='red',label='Primary camera')\nplt.legend()\nplt.xlabel('MegaPixels')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"####  2.3.9 Mobile Weight vs price","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot(x = 'mobile_wt',y = 'price_range', data = dataset,kind = 'kde', color = 'green')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2.3.10 time talk vs price_range","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pointplot(y = 'talk_time',x = 'price_range', data = dataset,kind = 'kde', color = 'gold')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2.3.11 Finding the realation b/w the features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#sns.pairplot(data = dataset, hue = 'price_range')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2.3.12 Finding the correlation b/w the features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (20,20))\nsns.heatmap(dataset.corr(), annot = True, cmap = 'RdYlGn')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Data preparing","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#####  3.1 Dependent and indepedent dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X  = dataset.iloc[:,:-1]\ny = dataset.iloc[:,-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3.2 Splitting data into train and test set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.20, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3.3 Feature Scaling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Modeling","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 4.1 Logistic Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression(multi_class='multinomial',solver = 'sag') # (sag = Stochastic Average Gradient)\nlr.fit(X_train, y_train)\n\n# Predict the test set\ny_pred = lr.predict(X_test)\n\n# evauate the preformance\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\nprint(accuracy_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\ncvs = cross_val_score(estimator = lr,X = X_train, y = y_train)\nprint('accuracy of validation set :', cvs.mean())\nprint('accuracy of the training set :', lr.score(X_train,y_train))\nprint('accuracy of the testset :', lr.score(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.2 DecisonTreeClassifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier(criterion = 'entropy')\ndt.fit(X_train,y_train)\n\n# Predict the test set\ny_pred = dt.predict(X_test)\n\n# evauate the preformance\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\nprint(accuracy_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\ncvs = cross_val_score(estimator = dt,X = X_train, y = y_train)\nprint('accuracy of validation set :', cvs.mean())\nprint('accuracy of the training set :', dt.score(X_train,y_train))\nprint('accuracy of the testset :', dt.score(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###  4.3 RandomForest Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 0)\nrf.fit(X_train, y_train)\n\n# Predict the test set\ny_pred = rf.predict(X_test)\n\n# evauate the preformance\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\nprint(accuracy_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\ncvs = cross_val_score(estimator = rf,X = X_train, y = y_train)\nprint('accuracy of validation set :', cvs.mean())\nprint('accuracy of the training set :', rf.score(X_train,y_train))\nprint('accuracy of the testset :', rf.score(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.4  Gaussian  Naive Bayes Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb.fit(X_train, y_train)\n\n# Predict the test set\ny_pred = nb.predict(X_test)\n\n# evauate the preformance\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\nprint(accuracy_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\ncvs = cross_val_score(estimator = nb,X = X_train, y = y_train)\nprint('accuracy of validation set :', cvs.mean())\nprint('accuracy of the training set :', nb.score(X_train,y_train))\nprint('accuracy of the testset :', nb.score(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.5 SVM","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#####  using gridsearch find  the best parameter","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters ={\n'C' : [1,0.1,0.25,0.5,2,0.75],\n'kernel' : [\"linear\",\"rbf\"],\n'gamma' : [\"auto\",0.01,0.001,0.0001,1],\n'decision_function_shape' : [\"ovo\" ,\"ovr\"]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVC\n\ngrid_search = GridSearchCV(estimator = SVC(),\n                           param_grid = parameters,\n                           scoring = 'accuracy',\n                           cv = 10,\n                           )\ngrid_search = grid_search.fit(X_train, y_train)\nbest_accuracy = grid_search.best_score_\nbest_parameters = grid_search.best_params_\nprint(\"Best Accuracy: {:.2f} %\".format(best_accuracy*100))\nprint(\"Best Parameters:\", best_parameters)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Applying SVM with best Parameters","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\nsvc=SVC(C=2,gamma=\"auto\",decision_function_shape=\"ovo\",kernel=\"linear\",random_state=0)\nsvc.fit(X_train, y_train)\n\n\n# Predict the test set\ny_pred = svc.predict(X_test)\n\n# evaluate the preformance\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\nprint(accuracy_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\ncvs = cross_val_score(estimator = svc,X = X_train, y = y_train)\nprint('accuracy of validation set :', cvs.mean())\nprint('accuracy of the training set :', svc.score(X_train,y_train))\nprint('accuracy of the testset :', svc.score(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. Conclusion:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12,6))\nlabel = ['Logistic Regression', 'Decision Tree', 'Random Forest', 'GaussainNB', 'Support Vector Machine',]\nacc_score = [0.95, 0.85, 0.87, 0.83, 0.95]\n\nplt.bar(label,acc_score, color=['lightblue', 'pink', 'lightgrey','gold', 'cyan'])\nplt.title('Which model is the most accurate?')\nplt.xlabel('')\nplt.ylabel('Accuracy Scores')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- After training our dataset with five different model, we conclude that __SVM__ & __Logistic Regression__ is best model for our dataset. (via the highest accuracy score = 0.95)\n- But here i'm selecting __SVM__ to predict the test dataset. but we can also use Logsitic Regression.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 6. Applying the SVM to Test dataset","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### 6.1 Loading test data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = pd.read_csv('../input/mobile-price-classification/test.csv')\ntest_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Note : We don't have id column in 'train.csv' data so can  drop this columns from our test_dataset.To make the dimension of input dataset same.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### 6.2 dropping the 'id' Column","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df  = test_data.drop('id', axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Successfully removed id column from test_data.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"##### 6.3 Applying Feature scaling to test set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsc = StandardScaler()\ntest_df1 = sc.fit_transform(test_df)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 6.4 Applying SVM to test_df","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_price_range = svc.predict(test_df1) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_price_range","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- here above,we have predicted price by SVM Model for this __test_df__ dataset. Now we are going to add __predicted_price_range__ to the __test_df__ dataset.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### 6.5 Adding the predicted price to test_df","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df['price_range'] = predicted_price_range","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- __We have achieved our goal and predicted price ranges for mobile phones in our new dataset__.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}