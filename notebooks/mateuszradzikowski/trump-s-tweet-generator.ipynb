{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Importing string and regular expression library"},{"metadata":{"trusted":true},"cell_type":"code","source":"import string\nimport re","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Read data and put it to dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/all-trumps-twitter-insults-20152021/trump_insult_tweets_2014_to_2021.csv')\ntweets = df.tweet.tolist()\ndf.head(200)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Remove duplicate tweets"},{"metadata":{},"cell_type":"markdown","source":"Removing duplicates using set operation in pyhton."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Number of tweets before removing dupplicates: {len(tweets)}\")\ntweets = list(set(tweets)) \nprint(f\"Number of tweets after removing dupplicates: {len(tweets)}\")\ntweets[0:10]\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing of data"},{"metadata":{},"cell_type":"markdown","source":"For the preprocessing, i have used regular expression to remove puntuations and url tags. I have also changed tweets to lowercase. Taken about just last tweets to speeden up computations."},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets = tweets[4000:]\n\nfor i in range(len(tweets)):\n    tweets[i] = tweets[i].lower()\n    tweets[i] = re.sub(r'http\\S+', '', tweets[i])\n    tweets[i] = re.sub(r'[^\\w\\s]', '', tweets[i]) \ntweets[0:20]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Tokenization"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\n\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(tweets)\ntotal_no_words = len(tokenizer.word_index) + 1\ntotal_no_words","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Input Sequence"},{"metadata":{},"cell_type":"markdown","source":"Arranging the words to be represented by numbers instead of string representations."},{"metadata":{"trusted":true},"cell_type":"code","source":"input_tweet_sequences = []\nfor tweet in tweets:\n    tokenlist = tokenizer.texts_to_sequences([tweet])[0]\n    for i in range(1, len(tokenlist)):\n        ngram_sequence = tokenlist[:i+1]\n        input_tweet_sequences.append(ngram_sequence)\n        \nprint(input_tweet_sequences)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Add padding"},{"metadata":{},"cell_type":"markdown","source":"Providing all the sequence the same length."},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.sequence import pad_sequences\n\nmax_input_sequence_len = max([len(x) for x in input_tweet_sequences])\ninput_tweet_sequences = np.array(pad_sequences(input_tweet_sequences, maxlen=max_input_sequence_len, padding='pre'))\n\nprint(max_input_sequence_len)\nprint(input_tweet_sequences[0:10])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nes = EarlyStopping(\n    monitor='val_loss', min_delta=0, patience=0, verbose=0,\n    mode='auto', baseline=None, restore_best_weights=False\n)\n\nmodel = Sequential()\nmodel.add(Embedding(total_no_words, 160, input_length=max_input_sequence_len-1))\nmodel.add(Bidirectional(LSTM(200, return_sequences=True)))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(100))\nmodel.add(Dense(total_no_words/2, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\nmodel.add(Dense(total_no_words, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow.keras.utils as ku \n\nmodel_predictors, output_label = input_tweet_sequences[:,:-1],input_tweet_sequences[:,-1]\noutput_label = ku.to_categorical(output_label, num_classes=total_no_words)\n\nhistory = model.fit(model_predictors, output_label, epochs=100, verbose=1, callbacks=[es])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Song_Generate(text, next_words):\n    for _ in range(next_words):\n        tokenlist = tokenizer.texts_to_sequences([text])[0]\n        tokenlist = pad_sequences([tokenlist],\n                     maxlen=max_input_sequence_len-1,padding='pre')\n        predicted = model.predict_classes(tokenlist, verbose=0)\n        output= \"\"\n        for word, index in tokenizer.word_index.items():\n            if index == predicted:\n                output = word\n                break\n        text += \" \" + output\n    print(text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"next_words = 30 \ntext = \"Democrats and Obama have developed\"\nSong_Generate(text, next_words)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualizing history of epochs"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\ndef plot_graph(history, string):\n    plt.plot(history.history[string])\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(string)\n    plt.show()\nplot_graph(history, 'accuracy')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It's one of my first notebooks. Feel free to comment and leave some suggestion how could i improve it :D"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}