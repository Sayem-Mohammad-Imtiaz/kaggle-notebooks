{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"../input/brent-oil-prices\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Input Data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/brent-oil-prices/BrentOilPrices.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"1) Need to convert Date column to standard format"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nfrom matplotlib import pyplot as plt\n\ndf['Date'] = pd.to_datetime(df['Date'], format=\"%b %d, %Y\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Exploration"},{"metadata":{},"cell_type":"markdown","source":"**Visualizing Full Data as a line plot**"},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.lineplot(x='Date',y='Price',data = df)\nplt.title(\"Brent Oil Price Trend\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Function to plot Oil Price Trend between specific period**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_price_trend(df, start_date, end_date):\n    \"\"\"\n    This function filters the dataframe for the specified date range and \n    plots the line plot of the data using seaborn.\n    \n    The dataframe may not be indexed on any Datetime column.\n    In this case, we use mask to filter out the date.\n    \n    PS - There is another function provided later in the notebook \n    which used indexed column to filter data\n    \"\"\"\n    mask = (df['Date'] > start_date) & (df['Date'] <= end_date)\n    sdf = df.loc[mask]\n    plt.figure(figsize = (10,5))\n    chart = sns.lineplot(x='Date',y='Price',data = sdf)\n#     chart.set_xticklabels(chart.get_xticklabels(), rotation=45)\n    plt.title(\"Brent Oil Price Trend\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_price_trend(df,'2017-01-01','2019-01-01')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Forecast Model"},{"metadata":{},"cell_type":"markdown","source":"# 1) Using Prophet"},{"metadata":{},"cell_type":"markdown","source":"Step 1) - First we import the Prophet class from fbprophet module and then create an instance of this."},{"metadata":{"trusted":true},"cell_type":"code","source":"from fbprophet import Prophet\nm = Prophet()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Step 2) - Note that Prophet requires the date column as 'ds' and outcome varible as 'y'.\nSo we change this in our dataframe and check its data."},{"metadata":{"trusted":true},"cell_type":"code","source":"pro_df = df\npro_df.columns = ['ds','y']\npro_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Step 3) - Next we fit this dataframe into the model object created and then create a forecast for the Oil Price for the next 90 days. \n\nThis might take ~1mins"},{"metadata":{"trusted":true},"cell_type":"code","source":"m.fit(pro_df)\nfuture = m.make_future_dataframe(periods = 90)\nforecast = m.predict(future)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Step 4) - We check the forecast data has several components - trend, weakly and yearly seasonality - and for each of these components, we have the lower and upper confidence intervals data."},{"metadata":{"trusted":true},"cell_type":"code","source":"forecast.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Step 5) - We plot these components of the forecast fit model."},{"metadata":{"trusted":true},"cell_type":"code","source":"m.plot_components(forecast)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m.plot(forecast)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Step 6)- Next we want to visualize side by side the original data and the forecast data. So for this, we join the original and forecast data on the column 'ds'"},{"metadata":{"trusted":true},"cell_type":"code","source":"cmp_df = forecast.set_index('ds')[['yhat','yhat_lower','yhat_upper']].join(pro_df.set_index('ds'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cmp_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cmp_df.tail(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note that the original y data is NaN towards the end because, these are the predicted dates."},{"metadata":{},"cell_type":"markdown","source":"Step 7 - Then, we visualize the original and forecast data alongside each other"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(17,8))\n#plt.plot(cmp_df['yhat_lower'])\n#plt.plot(cmp_df['yhat_upper'])\nplt.plot(cmp_df['yhat'])\nplt.plot(cmp_df['y'])\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Step 8) - From above graph, we are not able to readily see how many months data was forecast. \n\nSo, We need a function which will show us the original and forecast data between a specified date range."},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_price_forecast(df,start_date, end_date):\n    \"\"\"\n    This function filters the dataframe for the specified date range and \n    plots the actual and forecast data.\n    \n    Assumption: \n    - The dataframe has to be indexed on a Datetime column\n    This makes the filtering very easy in pandas using df.loc\n    \"\"\"\n    cmp_df = df.loc[start_date:end_date]\n    plt.figure(figsize=(17,8))\n    plt.plot(cmp_df['yhat'])\n    plt.plot(cmp_df['y'])\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Stpe 9) - Using this function, we can see that, the original graph (orange) does not have data towards the end. This data can be taken from the forecasted graph (blue). "},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_price_forecast(cmp_df,'2017-01-01','2020-01-01')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2) Using ARIMA"},{"metadata":{},"cell_type":"markdown","source":"Step 1) - First we import the required libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.arima_model import ARIMA    # ARIMA Modeling\nfrom statsmodels.tsa.stattools import adfuller   # Augmented Dickey-Fuller Test for Checking Stationary\nfrom statsmodels.tsa.stattools import acf, pacf  # Finding ARIMA parameters using Autocorrelation\nfrom statsmodels.tsa.seasonal import seasonal_decompose # Decompose the ARIMA Forecast model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Step 2) - Arima requires the date column to be set as index"},{"metadata":{"trusted":true},"cell_type":"code","source":"arima_df = df.set_index('ds')\narima_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Step 3) - Next we write a function that plots the Rolling mean and standard deviation and then checks the stationarity of the time series using Augmented Dickey - Fuller Test\n\nCredit - https://www.kaggle.com/freespirit08/time-series-for-beginners-with-arima"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Perform Augmented Dickeyâ€“Fuller test to check if the given Time series is stationary:\ndef test_stationarity(ts):\n    \n    #Determing rolling statistics\n    rolmean = ts.rolling(window=12).mean()\n    rolstd = ts.rolling(window=12).std()\n\n    #Plot rolling statistics:\n    orig = plt.plot(ts, color='blue',label='Original')\n    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n    plt.legend(loc='best')\n    plt.title('Rolling Mean & Standard Deviation')\n    plt.show(block=False)\n    \n    #Perform Dickey-Fuller test:\n    print('Results of Dickey-Fuller Test:')\n    dftest = adfuller(ts['y'], autolag='AIC')\n    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n    for key,value in dftest[4].items():\n        dfoutput['Critical Value (%s)'%key] = value\n    print(dfoutput)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Step 4) - Next, we use this function to check if our given timeseries data is stationary or not"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_stationarity(arima_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observation - The null hypothesis of ADF test is the Time series is NOT stationary. We see that the Test Statistic (-1.95) is higher than 10% Critical Value (-2.56). This means this result is statistically significant at 90% confidence interval and so, we fail to reject the null hypothesis. \n\nThis means that our time series data is NOT stationary."},{"metadata":{},"cell_type":"markdown","source":"Step 5) - Some definitions - \n\nCorrelation - Describes how much two variables depend on each other. \n\nPartial Correlation - When multiple variables are involved, two variables may have direct relation as well as indirect relation (i.e x1 and x3 are related and x2 and x3 are related. Due to this indirect relation, x1 and x2 might be related). This is called partial correlation.\n\nAuto Correlation - In a time series data, variable at a time step is dependent upon its lag values. This is called auto-correlation (i.e. variable depending upon its own values)\n\nPartial Autocorrelation - describes correlation of a variable with its lag values after removing the effect of indirect correlation.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\nplot_acf(arima_df)\nplot_pacf(arima_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Implementing own function to create ACF plot\ndef get_acf_plot(ts):\n    #calling acf function from stattools\n    y = ts['y']\n    lag_acf = acf(y, nlags=500)\n    plt.figure(figsize=(16, 7))\n    plt.plot(lag_acf, marker=\"o\")\n    plt.axhline(y=0,linestyle='--',color='gray')\n    plt.axhline(y=-1.96/np.sqrt(len(y)),linestyle='--',color='gray')\n    plt.axhline(y=1.96/np.sqrt(len(y)),linestyle='--',color='gray')\n    plt.title('Autocorrelation Function')\n    plt.xlabel('number of lags')\n    plt.ylabel('correlation')\n    \ndef get_pacf_plot(ts):\n    #calling pacf function from stattools\n    y = arima_df['y']\n    lag_pacf = pacf(y, nlags=50)\n    plt.figure(figsize=(16, 7))\n    plt.plot(lag_pacf, marker=\"o\")\n    plt.axhline(y=0,linestyle='--',color='gray')\n    plt.axhline(y=-1.96/np.sqrt(len(y)),linestyle='--',color='gray')\n    plt.axhline(y=1.96/np.sqrt(len(y)),linestyle='--',color='gray')\n    plt.title('Partial Autocorrelation Function')\n    plt.xlabel('number of lags')\n    plt.ylabel('correlation')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_acf_plot(arima_df)\nget_pacf_plot(arima_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Step 6) - Next we see some methods to make the data stationary"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Log Transformation\nts_log = np.log(arima_df)\nplt.plot(ts_log)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Moving Average of last 12 values\nmoving_avg = ts_log.rolling(12).mean()\nplt.plot(ts_log)\nplt.plot(moving_avg, color='red')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Differencing\nts_log_ma_diff = ts_log - moving_avg\nts_log_ma_diff.head(12)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts_log_ma_diff.dropna(inplace=True)\ntest_stationarity(ts_log_ma_diff)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exponentially weighted moving average \nexpwighted_avg = ts_log.ewm(halflife=12).mean()\n\nplt.plot(ts_log)\nplt.plot(expwighted_avg, color='red')\nts_log_ewma_diff = ts_log - expwighted_avg\ntest_stationarity(ts_log_ewma_diff)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Step 8) - ARIMA models"},{"metadata":{"trusted":true},"cell_type":"code","source":"ts_log_diff = ts_log - ts_log.shift()\nplt.plot(ts_log_diff)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts_log_diff.dropna(inplace=True)\ntest_stationarity(ts_log_diff)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.seasonal import seasonal_decompose\ndecomposition = seasonal_decompose(ts_log, freq = 30)\n\ntrend = decomposition.trend\nseasonal = decomposition.seasonal\nresidual = decomposition.resid\n\nplt.subplot(411)\nplt.plot(ts_log, label='Original')\nplt.legend(loc='best')\nplt.subplot(412)\nplt.plot(trend, label='Trend')\nplt.legend(loc='best')\nplt.subplot(413)\nplt.plot(seasonal,label='Seasonality')\nplt.legend(loc='best')\nplt.subplot(414)\nplt.plot(residual, label='Residuals')\nplt.legend(loc='best')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts_log_decompose = residual\nts_log_decompose.dropna(inplace=True)\ntest_stationarity(ts_log_decompose)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = ARIMA(ts_log, order=(2, 1, 2))  \nresults_ARIMA = model.fit(disp=-1)  \nplt.plot(ts_log_diff)\nplt.plot(results_ARIMA.fittedvalues, color='red')\n# plt.title('RSS: %.4f'% sum((results_ARIMA.fittedvalues-ts_log_diff)**2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3) Using LSTM"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}