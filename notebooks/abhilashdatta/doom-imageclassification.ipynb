{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Importing Libraries\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory","metadata":{"execution":{"iopub.status.busy":"2021-08-13T07:39:28.063994Z","iopub.execute_input":"2021-08-13T07:39:28.064353Z","iopub.status.idle":"2021-08-13T07:39:28.071522Z","shell.execute_reply.started":"2021-08-13T07:39:28.064323Z","shell.execute_reply":"2021-08-13T07:39:28.070647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reading csvs\n\nanimal_df = pd.read_csv('../input/doom-crossing/animal_crossing_dataset.csv')\ndoom_df = pd.read_csv('../input/doom-crossing/doom_crossing_dataset.csv')","metadata":{"execution":{"iopub.status.busy":"2021-08-13T07:39:38.573465Z","iopub.execute_input":"2021-08-13T07:39:38.57379Z","iopub.status.idle":"2021-08-13T07:39:38.593591Z","shell.execute_reply.started":"2021-08-13T07:39:38.573761Z","shell.execute_reply":"2021-08-13T07:39:38.592803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"animal_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-13T07:38:56.383626Z","iopub.execute_input":"2021-08-13T07:38:56.383973Z","iopub.status.idle":"2021-08-13T07:38:56.413772Z","shell.execute_reply.started":"2021-08-13T07:38:56.383943Z","shell.execute_reply":"2021-08-13T07:38:56.41271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"doom_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-13T07:38:56.592898Z","iopub.execute_input":"2021-08-13T07:38:56.593151Z","iopub.status.idle":"2021-08-13T07:38:56.608432Z","shell.execute_reply.started":"2021-08-13T07:38:56.593127Z","shell.execute_reply":"2021-08-13T07:38:56.607427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = '../input/doom-crossing/'\n\nbatch_size = 16\nimg_height = 224\nimg_width = 224","metadata":{"execution":{"iopub.status.busy":"2021-08-13T07:38:56.863608Z","iopub.execute_input":"2021-08-13T07:38:56.863924Z","iopub.status.idle":"2021-08-13T07:38:56.868267Z","shell.execute_reply.started":"2021-08-13T07:38:56.86389Z","shell.execute_reply":"2021-08-13T07:38:56.867111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loading training dataset\n\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  data_dir,\n  validation_split=0.3,\n  subset=\"training\",\n  seed=100,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2021-08-13T07:38:58.065648Z","iopub.execute_input":"2021-08-13T07:38:58.065962Z","iopub.status.idle":"2021-08-13T07:39:00.331755Z","shell.execute_reply.started":"2021-08-13T07:38:58.065935Z","shell.execute_reply":"2021-08-13T07:39:00.330879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loading validation dataset\n\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  data_dir,\n  validation_split=0.2,\n  subset=\"validation\",\n  seed=100,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2021-08-13T07:40:18.723799Z","iopub.execute_input":"2021-08-13T07:40:18.724132Z","iopub.status.idle":"2021-08-13T07:40:18.849487Z","shell.execute_reply.started":"2021-08-13T07:40:18.724103Z","shell.execute_reply":"2021-08-13T07:40:18.848612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = train_ds.class_names\nprint(class_names)","metadata":{"execution":{"iopub.status.busy":"2021-08-13T07:40:42.104131Z","iopub.execute_input":"2021-08-13T07:40:42.104479Z","iopub.status.idle":"2021-08-13T07:40:42.109395Z","shell.execute_reply.started":"2021-08-13T07:40:42.104445Z","shell.execute_reply":"2021-08-13T07:40:42.10815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Augmentation\n\ntrain_dataset = train_ds\nvalidation_dataset = val_ds\n\ndata_augmentation = tf.keras.Sequential([\n  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n])","metadata":{"execution":{"iopub.status.busy":"2021-08-13T07:40:58.774081Z","iopub.execute_input":"2021-08-13T07:40:58.774564Z","iopub.status.idle":"2021-08-13T07:40:58.806275Z","shell.execute_reply.started":"2021-08-13T07:40:58.774521Z","shell.execute_reply":"2021-08-13T07:40:58.805487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualization\n\nfor image, _ in train_dataset.take(1):\n    plt.figure(figsize=(10, 10))\n    first_image = image[0]\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n        plt.imshow(augmented_image[0] / 255)\n        plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2021-08-13T07:41:10.293798Z","iopub.execute_input":"2021-08-13T07:41:10.294135Z","iopub.status.idle":"2021-08-13T07:41:17.013715Z","shell.execute_reply.started":"2021-08-13T07:41:10.294107Z","shell.execute_reply":"2021-08-13T07:41:17.012924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Mobilenet Preprocessing\n\npreprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\nrescale = tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset= -1)","metadata":{"execution":{"iopub.status.busy":"2021-08-13T07:42:30.09363Z","iopub.execute_input":"2021-08-13T07:42:30.093962Z","iopub.status.idle":"2021-08-13T07:42:30.10368Z","shell.execute_reply.started":"2021-08-13T07:42:30.093924Z","shell.execute_reply":"2021-08-13T07:42:30.102755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loading pretrained weights\n\nweights = '../input/keras-pretrain-model-weights/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5'\nIMG_SHAPE = (img_height, img_width) + (3,)\nbase_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n                                               include_top=False,\n                                               weights=weights)","metadata":{"execution":{"iopub.status.busy":"2021-08-13T07:42:48.873758Z","iopub.execute_input":"2021-08-13T07:42:48.874081Z","iopub.status.idle":"2021-08-13T07:42:50.388564Z","shell.execute_reply.started":"2021-08-13T07:42:48.874051Z","shell.execute_reply":"2021-08-13T07:42:50.3877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_batch, label_batch = next(iter(train_dataset))\nfeature_batch = base_model(image_batch)\nprint(feature_batch.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-13T07:43:32.795062Z","iopub.execute_input":"2021-08-13T07:43:32.795397Z","iopub.status.idle":"2021-08-13T07:43:41.31351Z","shell.execute_reply.started":"2021-08-13T07:43:32.795353Z","shell.execute_reply":"2021-08-13T07:43:41.31259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Implementing layers on top of base model\n\nbase_model.trainable = False\nglobal_average_layer = tf.keras.layers.GlobalAveragePooling2D()\nfeature_batch_average = global_average_layer(feature_batch)\nprint(feature_batch_average.shape)\nprediction_layer = tf.keras.layers.Dense(1)\nprediction_batch = prediction_layer(feature_batch_average)\nprint(prediction_batch.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-13T07:44:15.669623Z","iopub.execute_input":"2021-08-13T07:44:15.669983Z","iopub.status.idle":"2021-08-13T07:44:15.686304Z","shell.execute_reply.started":"2021-08-13T07:44:15.669951Z","shell.execute_reply":"2021-08-13T07:44:15.685186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Full Model\n\ninputs = tf.keras.Input(shape=(224, 224, 3))\nx = data_augmentation(inputs)\nx = preprocess_input(x)\nx = base_model(x, training=False)\nx = global_average_layer(x)\nx = tf.keras.layers.Dropout(0.3)(x)\noutputs = prediction_layer(x)\nmodel = tf.keras.Model(inputs, outputs)","metadata":{"execution":{"iopub.status.busy":"2021-08-13T07:44:28.794803Z","iopub.execute_input":"2021-08-13T07:44:28.795131Z","iopub.status.idle":"2021-08-13T07:44:29.219228Z","shell.execute_reply.started":"2021-08-13T07:44:28.795101Z","shell.execute_reply":"2021-08-13T07:44:29.218423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compilation\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0001),\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-08-13T07:44:48.493988Z","iopub.execute_input":"2021-08-13T07:44:48.494304Z","iopub.status.idle":"2021-08-13T07:44:48.513791Z","shell.execute_reply.started":"2021-08-13T07:44:48.494274Z","shell.execute_reply":"2021-08-13T07:44:48.512977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training model\n\nhistory = model.fit(train_dataset,\n                    epochs=20,\n                    validation_data=validation_dataset)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-13T07:45:13.669343Z","iopub.execute_input":"2021-08-13T07:45:13.66973Z","iopub.status.idle":"2021-08-13T07:56:51.663826Z","shell.execute_reply.started":"2021-08-13T07:45:13.669677Z","shell.execute_reply":"2021-08-13T07:56:51.662964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting Accuracy Curves\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy')\nplt.ylim([min(plt.ylim()),1])\nplt.title('Training and Validation Accuracy')","metadata":{"execution":{"iopub.status.busy":"2021-08-13T08:00:50.654144Z","iopub.execute_input":"2021-08-13T08:00:50.654506Z","iopub.status.idle":"2021-08-13T08:00:50.846028Z","shell.execute_reply.started":"2021-08-13T08:00:50.654471Z","shell.execute_reply":"2021-08-13T08:00:50.844996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploration tasks\n\n<b>Q-1 Which are the misclassified photos? How do you explain why they are misclassified? How can you help your model classify those photos correctly?</b>\n \nAns. The misclassified photos are mostly the ones which have text in them but don’t have appropriate features for Doom or Animal Crossing. They are misclassified because the model picks up on features and not the text, thus not appropriately classifying the pictures. We can run an additional OCR on the images to scan the text and can add a parallel pipeline to classify according to the text along with image features, giving text classification the greater priority.\n \n \n<b>Q-2 How do you know if your model has actually learned to classify the images? Or is it simply very lucky at guessing?</b>\n \nAns. I have divided the whole dataset into training and validation. If the model is guessing then it should give a higher training accuracy but a lower validation accuracy, but since it's giving good accuracies at both seen and well as unseen data we can infer that it's actually learning.\n \n \n<b>Q-3 What happens if you ask your model to classify a new image which is neither a Doom nor an Animal Crossing meme? You can try to upload a random photo and generate prediction on it to see the results. How would you modify your model to handle this situation?</b>\n \nAns. The model will classify the random photo into one of the categories regardless. The confidence score will surely be low. To handle this, we can create a third category ‘Not Doom or Animal Crossing’ and train the model again to handle the exceptions.\n \n \n<b>Q-4 After having successfully trained a model to classify Doom and Animal Cross memes, you want your model to classify other memes as well, such as those from Genshin Impact. How would you avoid retraining the model from scratch?</b>\n \nAns.We can use the current as a base model and can train extra layers over it to classify other memes categories, ie again using the concept of Transfer Learning.\n\n","metadata":{}}]}