{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_rsID(INFO):\n    return [x.split('=')[1] for x in INFO.split(';') if x.startswith('avsnp150')][0]\n\ndef get_maxMAF(INFO):\n    freq_columns = ['ExAC_nontcga_ALL', 'esp6500siv2_all']\n    freqs = []\n    for info in INFO.split(';'):\n        if info.startswith('ExAC_nontcga_ALL') or info.startswith('esp6500siv2_all'):\n            freq = info.split('=')[1]\n            freqs.append(float('0'+freq))\n    return max(freqs)\n\ndef is_exonic(INFO):\n    functions = [x.split('=')[1] for x in INFO.split(';') if x.startswith('Func.ensGene') or x.startswith('Func.refGene') or x.startswith('Func.knownGene')]\n    return 'exonic' in functions\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## VCF file cleanup\n\nIn this notebook, we will prepare a VCF ([variant call format](https://en.wikipedia.org/wiki/Variant_Call_Format)) file to apply ML models. These files contain information about the changes in the genome (e.g. A>C, T>G, etc.). The whole human genome has about 3 billion positions, but we usually have between 4 and 7 million variants, as more than 99% of our genomes are the same.\n\n### VCF file parts\nThe **VCF** file has a long header (all lines starting with ##) with information about the chromosomes present in the file, the programs/parameters used to generate the file and the meaning of some fields we see in the file.\n\nAfter the long header, we have the column labels, which is a single line starting with #. This line has the following columns:\n1. CHROM: variant chromosome \n2. POS: variant position in the chromosome\n3. ID: variant ID (usually rsID, from [dbSNP](https://www.ncbi.nlm.nih.gov/snp/))\n4. REF: reference allele (A, T, C, G, ...)\n5. ALT: alternate allele (A, T, C, G, ...)\n6. QUAL: variant quality\n7. FILTER: variant quality filter (usually generated by the [GATK VQSR](https://gatk.broadinstitute.org/hc/en-us/articles/360035531612-Variant-Quality-Score-Recalibration-VQSR-) tool)\n8. INFO: variant annotation (information like the gene name, variant location in the gene, functional impact, frequency in the population, etc.)\n9. FORMAT: order of additional fields about the genotypes\n10. ... From column 10 on, we have the information about the samples. The main information we want is how many copies each sample has of the reference (always represented by 0) and alternate alleles (represented by 1, 2, 3, ...). Let's say a specific variant is a change from A to G. Then A is the reference allele and G is the alternate allele. If a patient has two copies of the reference allele, we will see the genotype as \"0/0\". If the patient has one copy of the reference and one copy of the alternate allele, we will see the genotype as \"0/1\", and if the patient has two copies of the alternate allele, we will see \"1/1\". In some cases, more than one alternate alleles will be found (let's say most individuals have a T, but some can have a C and some can have a G). In these cases, we will see other combinations like \"0/2\" (the patient has one copy of the reference and one copy of the second most frequent alternate allele).\n\nTo simplify the analysis, we coded the variants as binary data, meaning that patients with at least one copy of the alternate allele will have 1 for that variant and if the patient has only the reference allele, the value will be 0.\n\nTo filter the variants for this competition, we selected variants that passed the GATK VQSR quality control, we removed variants that are outside genes (intergenic regions of the genome), and selected only variants with frequency of 10% or less.","metadata":{}},{"cell_type":"code","source":"data_dir = '/kaggle/input/end-als/end-als/genomics-data'\n\nfilename = data_dir + '/AnswerALS_subset_annovar.hg38_anno_and_geno.no_intergenic.vcf'\n\nchunksize = 2 * 10 ** 4\nnrows = 10945503\n\nchunks = pd.read_csv(filename, sep = '\\t', skiprows=3518, chunksize=chunksize)\n\ndf = pd.DataFrame()\n\nfor i,chunk in enumerate(chunks):\n    if i % 100 == 0:\n        print(f\"{i+1} out of {int(nrows/chunksize)} chunks.\")\n    # Selecting PASSing variants (according to GATK VQSR)\n    data = chunk[chunk.FILTER == 'PASS']\n    # Selecting exonic variants only\n    data = data[data.INFO.apply(is_exonic)]\n    # Selecting variants with frequency 10% or less\n    data = data[data.INFO.apply(lambda x: get_maxMAF(x) <= 0.1)]\n    # Defining index with SNP ID\n    data.index = data[['#CHROM', 'POS', 'INFO']].apply(lambda x: get_rsID(x[2]) if get_rsID(x[2]) != '.' else x[0]+':'+str(x[1]), axis=1)\n    # Selecting genotype columns only\n    geno = data.iloc[:,9:]\n    # Replacing genotype codes with 0s and 1s\n    for col in geno.columns:\n        geno[col] = geno[col].apply(lambda x: 0 if x.split(':')[0] == '0/0' else (np.nan if x.split(':')[0] == './.' else 1))\n    \n    \n    #print(geno.shape)\n    #geno.to_csv(f'{data_dir}/geno{i+1}.csv')\n    \n    # Concatenating to the dataframe\n    df = pd.concat([df, geno])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"meta_dir = '/kaggle/input/end-als/end-als/clinical-data/filtered-metadata/metadata/'\n\nmetadata = pd.read_csv(meta_dir + 'aals_released_files.csv')\n\nmetadata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metadata = metadata[['Participant_ID', 'CGND_ID']].drop_duplicates()\nmetadata = metadata[-metadata.CGND_ID.isnull()]\nmetadata = metadata[-metadata.Participant_ID.isnull()]\n\nfor i,row in metadata.iterrows():\n    if row['CGND_ID'] in df.columns:\n        df = df.rename(columns = {row['CGND_ID'] : row['Participant_ID']})\n    if row['CGND_ID']+'-b38' in df.columns:\n        df = df.rename(columns = {row['CGND_ID']+'-b38' : row['Participant_ID']})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df.to_csv(data_dir + 'geno.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}