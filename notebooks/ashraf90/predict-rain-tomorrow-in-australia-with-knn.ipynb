{"cells":[{"metadata":{},"cell_type":"markdown","source":"### importing our libraries "},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import metrics\nfrom sklearn import preprocessing\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report,confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reading Data .. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df= pd.read_csv('../input/weather-dataset-rattle-package/weatherAUS.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's explore our data"},{"metadata":{"trusted":false},"cell_type":"code","source":"# this to show the data type , columns names ,sum of data that not a nans and memory usage . \ndf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### it's  time to dealing with  missing values ..."},{"metadata":{"trusted":false},"cell_type":"code","source":"# show the number of missing values in each column.\ndf.isna().sum().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Removing some columns that have > 28% nan values\nmax_nans=len(df)*0.28\ndf=df.loc[:, (df.isnull().sum(axis=0) <= max_nans)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# show the number of the missing values \ndf.isna().sum().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#filling the missing values by the next value ('bfill') because the temperatures are nearly the same for the next day\ndf.fillna(method='bfill',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### let's working on the important features and drop some ..."},{"metadata":{"trusted":false},"cell_type":"code","source":"df.drop(columns=['RISK_MM','Date','Location'],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# here we change the data type for these two column\ndf['RainTomorrow']=df['RainTomorrow'].astype('category')\ndf['RainToday']=df['RainToday'].astype('category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# here we transform them to numeric values.\ndf['RainTomorrow']=df['RainTomorrow'].cat.codes\ndf['RainToday']=df['RainToday'].cat.codes","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":" # to know the number of row and columns .\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### let's make some visualisation..."},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.countplot(df['RainToday'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.countplot(df['RainTomorrow'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"g = sns.FacetGrid(df,hue='RainTomorrow',aspect=4)\ng.map(plt.hist,'MinTemp',alpha=0.6,bins=5)\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"g = sns.FacetGrid(df,hue='RainTomorrow',height=6,aspect=2)\ng.map(plt.hist,'Humidity3pm',alpha=0.6,bins=5)\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"g = sns.FacetGrid(df,hue='RainTomorrow',height=6,aspect=2)\ng.map(plt.hist,'WindGustSpeed',alpha=0.6,bins=5)\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### it's ML working time ..."},{"metadata":{"trusted":false},"cell_type":"code","source":"#select the columns for the model.\nX=df.iloc[:,:16]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# select our target .\ny=df['RainTomorrow']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# here we transform the non_numeric features to make the model dealing with it . \nX=pd.get_dummies(X,columns=['WindDir9am','WindDir3pm','WindGustDir'],drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Next, we split 75% of the data to the training set while 25% of the data to test set using below code.\nX_train, X_test, y_train, y_test =  train_test_split(X,y,test_size = 0.25, random_state= 0,stratify=y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#we need to bring all features to the same level of magnitudes. This can be achieved by a method called feature scaling.\nscaler = preprocessing.MinMaxScaler()\nscaler.fit(X)\nX = pd.DataFrame(scaler.transform(X), index=X.index, columns=X.columns)\nX.iloc[4:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### For k = 5 : "},{"metadata":{"trusted":false},"cell_type":"code","source":"#Our next step is to K-NN model and train it with the training data. Here n_neighbors is the value of factor K.\nclassifier = KNeighborsClassifier(n_neighbors = 5)\nclassifier.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Let's train our test data and check its accuracy.\ny_pred = classifier.predict(X_test)\nscore = accuracy_score(y_test,y_pred)\nprint('Accuracy :',score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# let's see the classification report .\ny_test_pred = classifier.predict(X_test)\nprint(classification_report(y_test,y_test_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#let's show the confusion matrix.\nconfusion_matrix(y_test,y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### for K = 8 :"},{"metadata":{"trusted":false},"cell_type":"code","source":"classifier = KNeighborsClassifier(n_neighbors = 8, p = 2)\nclassifier.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\ny_pred = classifier.predict(X_test)\nscore = accuracy_score(y_test,y_pred)\nprint('Accuracy :',score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\ny_test_pred = classifier.predict(X_test)\nprint(classification_report(y_test,y_test_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n### So we tried more than 3 values on K and  as we can see that Accuracy is maximum that is 83.7 when k = 8  ss\n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":4}