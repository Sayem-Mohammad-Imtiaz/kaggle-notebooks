{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# Data Analysis\nimport pandas as pd\nimport numpy as np\n\n# Data Viz\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfgame = pd.read_csv('../input/videogamesales/vgsales.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfgame.head(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfgame.tail(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## At this point I have loaded the dataset in and have a pretty highlevel understanding of what the dataset consists of\n## At this point I'll move on to cleaning the data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfgame.isnull().any()\n\n## identify any data that is missing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def missing_value_table(dfgame):\n    missing_value = dfgame.isna().sum().sort_values(ascending=False)\n    missing_value_table = pd.concat([missing_value], axis=1)\n    missing_value_table_return = missing_value_table.rename(columns = {0 : 'Missing Values' })\n    cm = sns.light_palette(\"red\", as_cmap=True)\n    missing_value_table_return = missing_value_table_return.style.background_gradient(cmap=cm)\n    return missing_value_table_return\n  \nmissing_value_table(dfgame)\n\n##see how many rows in total need to be addressed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfgame1 = dfgame.dropna()\n## I chose to drop the rows since there was only around 320 in total out of over 15000\n### What would be a better way to replace these value?\n### What other datacleaning function do oyu typically use?","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing3 = dfgame1[\"Year\"].isnull().sum()\nmissing4 = dfgame1[\"Publisher\"].isnull().sum()\n\n\nmissing3 + missing4 \n\n##updated dataframe to remove any rows with missing values. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# with sns.plotting_context(\"notebook\",font_scale=1):\n#     sns.set_style(\"whitegrid\")\n#     sns.distplot(dfgame[\"Year\"],\n#                  bins=80,\n#                  kde=False,\n#                  color=\"tomato\")\n#     title(\"Count by Year\")\n#     plt.ylabel(\"Count\")\nplt.hist(np.clip(dfgame['Year'],1995, 2015), bins = np.arange(1980, 2020))\nplt.xlim(1995, 2015)\n# addinng dat prior to 1995 --> segmenting to the meat of data set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with sns.plotting_context(\"notebook\",font_scale=1):\n    sns.set_style(\"whitegrid\")\n    sns.distplot(dfgame[\"Year\"],\n                 bins=80,\n                 kde=False,\n                 color=\"tomato\")\n    title(\"Count by Year\")\n    plt.ylabel(\"Count\")\n    \n    \n## Start diving into the data a little bit more, first thing I was interested in was how releases trended over time.\n#### Looks like the majority of titles were released over 2005 - 2011","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_style(style = 'whitegrid')\nplt.figure(figsize = (10,3))\nax = sns.countplot(x ='Platform', data = dfgame1,palette = 'Set3')\nplt.title('Count of different platforms',fontsize = 15)\nplt.xticks(rotation =90)\nplt.xlabel('Platform',fontsize = 15)\nplt.ylabel('Total Count',fontsize = 15)\n\n## Next thing that I wanted to look at was the distribution of titles across platforms\n#### Usual suspects (ps3, xbox, switch). Looks like the dataset ended just around the time when ps4 started to come out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfgame1['count']=1\n\ntop_5_genres=dfgame1['Platform'].value_counts(ascending=False).index[:5]\npd.pivot_table(index='Year',columns='Platform',values='count',aggfunc=sum,data=dfgame1[dfgame1['Platform'].apply(lambda x: x in top_5_genres)]).plot(figsize=(15,5))\nplt.legend(bbox_to_anchor=[1.1,1])\n\n\n## Looking at the distribution of titles released by platform\n###Is there a better way to filter the data to just show the reflected date range?","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_filtered = dfgame1[dfgame1['Year'] >= 2000] \ndf_filtered2 = df_filtered[df_filtered['Year'] <= 2017] \n\n##Adjusted to remove the unecasary years","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_filtered2['count']=1\n\ntop_5_Platforms=df_filtered2['Platform'].value_counts(ascending=False).index[:5]\npd.pivot_table(index='Year',columns='Platform',values='count',aggfunc=sum,data=df_filtered2[df_filtered2['Platform'].apply(lambda x: x in top_5_genres)]).plot(figsize=(15,5))\nplt.legend(bbox_to_anchor=[1.1,1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_filtered2['count']=1\n\ntop_5_Publisher =df_filtered2['Publisher'].value_counts(ascending=False).index[:3]\npd.pivot_table(index='Year',columns='Publisher',values='count',aggfunc=sum,data=df_filtered2[df_filtered2['Publisher'].apply(lambda x: x in top_5_Publisher)]).plot(figsize=(15,5))\nplt.legend(bbox_to_anchor=[1.1,1])\n\n\n##similar view to above, but looking at the top 3 publishers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize= (12,6))\nsns.barplot(x = dfgame1['Genre'], y = dfgame['Global_Sales'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_1 = dfgame1.groupby(['Genre'])['Global_Sales'].sum().reset_index()\ndf_2 = dfgame1.groupby(['Platform'])['Global_Sales'].sum().reset_index()\n##previously was just looking at count of titles, now want to look at sales breakdowns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize= (12,6))\n\n\nsns.barplot(x='Genre', y='Global_Sales', data=df_1)\n\n##Total sales breakdown by genre","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize= (12,6))\n\n\nsns.barplot(x='Platform', y='Global_Sales', data=df_2)\n\n##Total breakdown by platform\n#### How could you filter this to just show the top 10-15?","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NATotal = dfgame1['NA_Sales'].sum().round(1)\nEUTotal = dfgame1['EU_Sales'].sum().round(1)\nJPTotal = dfgame1['JP_Sales'].sum().round(1)\n\nprint(\"NATotal = \",  NATotal)\nprint(\"EUTotal = \",  EUTotal)\nprint(\"JPTotal = \",  JPTotal)\n\n\n##Finally want to look at the sales totals across all three regions\n#### How would I get this into a chart? Not sure how quite to do that\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Some other things that I think would be interesting to look at:\n## What is the fastest growing genre (overall, NA, EU, & JP?\n## Are there certain platforms that are losing pace vs others, what is the reason? fewer titles released? Releasing games in the wrong genres?","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}