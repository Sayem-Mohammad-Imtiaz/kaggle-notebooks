{"metadata":{"language_info":{"codemirror_mode":{"version":3,"name":"ipython"},"pygments_lexer":"ipython3","version":"3.6.4","nbconvert_exporter":"python","mimetype":"text/x-python","name":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"cells":[{"cell_type":"markdown","metadata":{},"source":"**1. Call libraries**"},{"cell_type":"code","metadata":{"_cell_guid":"96eb992d-9cbf-4e3a-9899-39bdfd06ed36","_uuid":"4e185846047fc91848a6fd52d16c4bb7c994556a"},"source":"## 1 Call libraries\nimport numpy as np                   # Data manipulation\nimport pandas as pd                  # DataFrame manipulation\nimport time                          # To time processes \nimport warnings                      # To suppress warnings\nimport matplotlib.pyplot as plt      # For Graphics\nimport seaborn as sns\nfrom sklearn import cluster, mixture # For clustering \nfrom sklearn.preprocessing import StandardScaler\n\nimport plotly.graph_objs as go\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\n%matplotlib inline\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{},"source":"**2. Read data**"},{"cell_type":"code","metadata":{},"source":"# 2. Read data\nWHR_Data= pd.read_csv(\"../input/2017.csv\", header = 0)\nWHR_Data.head(2)","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{},"source":"**3. Explore and scale data **"},{"cell_type":"code","metadata":{},"source":"# 2. Explore and scale data\nX = WHR_Data.iloc[:, 2: ]      # Ignore Country and Happiness_Rank columns\nX.dtypes","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{},"source":"**4. Normalize the data**\n* Normalize dataset for easier parameter selection. \n* Standardize features by removing the mean and scaling to unit variance"},{"cell_type":"code","metadata":{},"source":"# 4 Normalize the data\n\n# 4.1 Instantiate scaler object\nss = StandardScaler()\n# 4.2 Use ot now to 'fit' &  'transform'\nss.fit_transform(X)","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{},"source":"**5. Clustering Algorithems**\n\nFollowing clustering methods going to explore\n\n* K-Means\n* Mean Shift\n* Mini Batch K-Means\n* Spectral Clustering\n* DBSCAN\n* Affinity Propagation\n* Birch\n* Gaussian Mixture Modeling"},{"cell_type":"markdown","metadata":{},"source":"***5 . 1  Define class for clustering***"},{"cell_type":"code","metadata":{"collapsed":true},"source":"# Thisclass contains functions for all clustering methods\nclass ClustringAlgorithms(object) :\n    n_clusters = 2      # No of clusters. To use with techniques which needs this as input\n    bandwidth = 0.1     # To use with Mean Shift technique\n    eps = 0.3           # To use with DbScan technique for incremental area density\n    damping = 0.9       # To use with Affinity Propogation technique\n    preference = -200   # To use with Affinity Propogation technique \n      \n    # KMeans algorithm clusters data by trying to separate samples in n groups\n    # of equal variance, minimizing a criterion known as the within-cluster sum-of-squares.\n    # Parameter: Dataset, No of clusters.\n    def kmeans(self, X, n_clusters = n_clusters):\n        km = cluster.KMeans(n_clusters)\n        return km.fit_predict(X)\n    \n    # This clustering aims to discover blobs in a smooth density of samples.\n    # It is a centroid based algorithm, which works by updating candidates\n    # for centroids to be the mean of the points within a given region.\n    # These candidates are then filtered in a post-processing stage to\n    # eliminate near-duplicates to form the final set of centroids.\n    # Parameter: Dataset, bandwidth dictates size of the region to search through.\n    def meanshift(self, X, bandwidth=bandwidth):\n        ms = cluster.MeanShift(bandwidth)\n        return  ms.fit_predict(X)\n    \n    # Similar to kmeans but clustering is done in batches to reduce computation time\n    # Parameter: Dataset,No of clusters.\n    def minibatchkmeans(self, X, n_clusters = n_clusters):\n        two_means = cluster.MiniBatchKMeans(n_clusters)\n        return two_means.fit_predict(X)\n   \n    def spectral(self, X, n_clusters = n_clusters):\n        sp = cluster.SpectralClustering(n_clusters)\n        return sp.fit_predict(X)\n\n    def dbscan(self, X, eps=eps):\n        db = cluster.DBSCAN(eps)\n        return db.fit_predict(X)\n    \n    def affinitypropagation(self, X, preference=preference, damping=damping):\n        affinity_propagation =  cluster.AffinityPropagation(damping, preference)\n        affinity_propagation.fit(X)\n        return affinity_propagation.predict(X)\n       \n    def birch(self, X, n_clusters = n_clusters):\n        birch = cluster.Birch(n_clusters)\n        return birch.fit_predict(X)\n   \n    def gaussian_mixture(self, X, n_clusters = n_clusters):\n        gmm = mixture.GaussianMixture(n_clusters, covariance_type='full')\n        gmm.fit(X)\n        return  gmm.predict(X)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true},"source":"def clusteringAlgoProcessing(dataSet):\n    fig,ax = plt.subplots(4, 2, figsize=(10,10)) \n    clusterAlgo = ClustringAlgorithms()\n    i = 0\n    j=0\n    listofClusterMethod = ['KMeans',\"MeanShift\",\"MiniBatchKmeans\",\"DBScan\",\"Spectral\",\"Birch\",\"Gaussian_Mixture\"]\n    for cm in listofClusterMethod :\n        methodName = str(cm).lower()\n        method = getattr(clusterAlgo, methodName)\n        result = method(dataSet)\n        dataSet[cm] = pd.DataFrame(result)\n        ax[i,j].scatter(dataSet.iloc[:, 4], dataSet.iloc[:, 5],  c=result)\n        ax[i,j].set_title(cm)\n        j=j+1\n        if( j % 2 == 0) :\n            j= 0\n            i=i+1\n    plt.subplots_adjust(bottom=-0.5, top=1.5)\n    plt.show()","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{},"source":"***5 . 2  Process all algorithms and plot the scatter plot for each***"},{"cell_type":"code","metadata":{"scrolled":true},"source":"clusteringAlgoProcessing(X)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{},"source":"X.insert(0,'Country',WHR_Data.iloc[:,0])\nX.iloc[:,[0,11,12,13,14,15,16,17]]","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{},"source":"***5 . 3 Clustering data visulaization on world map***"},{"cell_type":"code","metadata":{},"source":"### 5.1 Kmeans Algorithm  \ndata = dict(type = 'choropleth', \n           locations = X['Country'],\n           locationmode = 'country names',\n           z = X['KMeans'], \n           text = X['Country'],\n           colorbar = {'title':'Cluster Group'})\nlayout = dict(title = 'K-Means Clustering Visualization', \n             geo = dict(showframe = False, \n                       projection = {'type': 'Mercator'}))\nchoromap3 = go.Figure(data = [data], layout=layout)\niplot(choromap3)","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{},"source":"***5.Gaussian Mixture Clustering Visualization***"},{"cell_type":"code","metadata":{},"source":"data = dict(type = 'choropleth', \n           locations = X['Country'],\n           locationmode = 'country names',\n           z = X['Gaussian_Mixture'], \n           text = X['Country'],\n           colorbar = {'title':'Cluster Group'})\nlayout = dict(title = 'Gaussian Mixture Clustering Visualization', \n             geo = dict(showframe = False, \n                       projection = {'type': 'Mercator'}))\nchoromap3 = go.Figure(data = [data], layout=layout)\niplot(choromap3)","execution_count":null,"outputs":[]}],"nbformat_minor":1}