{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5b9d96f4-9c81-46e9-9f12-1acbae333d9b","_cell_guid":"f3f26791-d184-40e9-b67b-786957240998","trusted":true},"cell_type":"code","source":"\n# -*- encoding: utf-8 -*-\n'''\n\n@Author  :   Yukai Song \n\n'''\n\n# here put the import lib\nfrom datetime import datetime\nfrom logging import log\nfrom os import listdir\nfrom os.path import isfile, join\nimport librosa\nimport librosa.display\nimport numpy as np\nimport pandas as pd\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom keras.utils import to_categorical\n\nfrom sklearn.preprocessing import LabelEncoder\n\n\nimport logging\n\ndef extract_features(file_name):\n    \"\"\"\n    This function takes in the path for an audio file as a string, loads it, and returns the MFCC\n    of the audio\"\"\"\n   \n    try:\n        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast', duration=20) \n        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n        pad_width = max_pad_len - mfccs.shape[1]\n        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n        \n    except Exception as e:\n        print(\"Error encountered while parsing file: \", file_name)\n        return None \n     \n    return mfccs\n\ndef construct_model(oh_labels_shape):\n    num_rows = 40\n    num_columns = 862\n    num_channels = 1\n\n    num_labels = oh_labels_shape\n    filter_size = 2\n    # Construct model \n    model = Sequential()\n    model.add(Conv2D(filters=16, kernel_size=filter_size,\n                    input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n    model.add(MaxPooling2D(pool_size=2))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(filters=32, kernel_size=filter_size, activation='relu'))\n    model.add(MaxPooling2D(pool_size=2))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(filters=64, kernel_size=filter_size, activation='relu'))\n    model.add(MaxPooling2D(pool_size=2))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(filters=128, kernel_size=filter_size, activation='relu'))\n    model.add(MaxPooling2D(pool_size=2))\n    model.add(Dropout(0.2))\n\n    model.add(GlobalAveragePooling2D())\n\n    model.add(Dense(num_labels, activation='softmax')) \n\n    # Compile the model\n    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam') \n\n    # Display model architecture summary \n    model.summary()\n\n    model.load_weights('../input/model-for-using/mymodel2_173.h5')\n\n    return model\n\n#config logging\nlogging.basicConfig(level=logging.DEBUG,#控制台打印的日志级别\n                    filename='result.log',\n                    filemode='a',##模式，有w和a，w就是写模式，每次都会重新写日志，覆盖之前的日志\n                    #a是追加模式，默认如果不写的话，就是追加模式\n                    format=\n                    '%(asctime)s - %(pathname)s[line:%(lineno)d] - %(levelname)s: %(message)s'\n                    #日志格式\n                    )\n\nmypath = '../input/respiratory-sound-database/Respiratory_Sound_Database/Respiratory_Sound_Database/audio_and_txt_files'\nfilenames_total = [f for f in listdir(mypath) if (isfile(join(mypath, f)) and f.endswith('.wav'))] \n\n# read file list from 2.txt\nfile_list = []\nwith open('../input/voice-config/Voice_config.txt','r') as f:\n    for i in f.readlines():\n        if str(i[:-1]).isdigit():\n            file_list.append(i[:-1])\nf.close()\n\nfilenames = []\nfor sfile in filenames_total:\n    if sfile[:3] in file_list:\n        filenames.append(sfile)\n        \n\n# filenames = filenames[:10]\n\n\np_id_in_file = [] # patient IDs corresponding to each file\nfor name in filenames:\n    p_id_in_file.append(int(name[:3]))\n\np_id_in_file = np.array(p_id_in_file) \n\n\nmax_pad_len = 862 # to make the length of all MFCC equal\n\n\nfilepaths = [join(mypath, f) for f in filenames] # full paths of files\n\np_diag = pd.read_csv(\"../input/respiratory-sound-database/Respiratory_Sound_Database/Respiratory_Sound_Database/patient_diagnosis.csv\",header=None) # patient diagnosis file\n\nlabels = np.array([p_diag[p_diag[0] == x][1].values[0] for x in p_id_in_file]) # labels for audio files\n# labels = labels[:40]\nfeatures = [] \n\n\n# Iterate through each sound file and extract the features\nfor file_name in filepaths:\n    data = extract_features(file_name)\n    features.append(data)\nprint('Finished feature extraction from ', len(features), ' files')\n\nfeatures = np.array(features) # convert to numpy array\n\n# delete the very rare diseases\nfeatures1 = np.delete(features, np.where((labels == 'Asthma') | (labels == 'LRTI'))[0], axis=0) \n\nlabels1 = np.delete(labels, np.where((labels == 'Asthma') | (labels == 'LRTI'))[0], axis=0)\n\n# print class counts\nunique_elements, counts_elements = np.unique(labels1, return_counts=True)\nprint(np.asarray((unique_elements, counts_elements)))\n\n# One-hot encode labels\nle = LabelEncoder()\n# i_labels = le.fit_transform(labels1)\nc_label = {'Bronchiectasis':0, 'Bronchiolitis':1, 'COPD':2, 'Healthy':3, 'Pneumonia':4, 'URTI':5}\n\ni_labels = np.array(list(map(lambda x :c_label[x], labels1)))\noh_labels = to_categorical(i_labels,6) \n# add channel dimension for CNN\nfeatures1 = np.reshape(features1, (*features1.shape,1)) \n\nx_test, y_test = features1, oh_labels\n\nmodel = construct_model(oh_labels.shape[1])\n\n# Calculate pre-training accuracy \nscore = model.evaluate(x_test, y_test, verbose=1)\naccuracy = 100*score[1]\n\nprint(\"test accuracy: %.4f%%\" % accuracy)\n\npreds = model.predict(x_test)\nclasspreds = np.argmax(preds, axis=1)\ny_testclass = np.argmax(y_test, axis=1) # true classes\n\n\nc_names = ['Bronchiectasis', 'Bronchiolitis', 'COPD', 'Healthy', 'Pneumonia', 'URTI']\nfor i in range(len(y_testclass)):\n    print(\"语音文件：{2},真实语音来源：{0},预测语音来源：{1}\".format(c_names[y_testclass[i]],c_names[classpreds[i]],filenames[i]))\n    logging.debug(\"语音文件：{2},真实语音来源：{0},预测语音来源：{1}\".format(c_names[y_testclass[i]],c_names[classpreds[i]],filenames[i]))\n\nprint('done')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}