{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# importing modules\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# importing data\ndf = pd.read_csv(\"../input/heart-disease-uci/heart.csv\")\ndf.describe()\nplt.scatter(df.age[df.target == 1], df.thalach[df.target ==1], c =\"salmon\");\n\nplt.scatter(df.age[df.target == 0], df.thalach[df.target == 0], c= \"lightblue\");\n\nplt.title( \"Heart disease age and max heart rate co-relation\")\nplt.xlabel(\"Age\")\nplt.ylabel(\"Max Heart rate\");\nplt.legend([1,0]);\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## checking coorelation with features and labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr =df.corr()\nfig, ax =plt.subplots(figsize =(16,8))\nax  = sns.heatmap(corr,annot =True,fmt = \".2f\", cmap = 'gray_r');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# splitting data\nX = df.drop(\"target\", axis =1)\nY = df[\"target\"]\nX.corrwith(df.target).plot(kind='bar',\n                           grid=True, \n                           figsize=(12, 8),\n                           title=\"Correlation with target\");\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, RandomizedSearchCV\n\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2)\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\n\nmodels = {\"log\": LogisticRegression(max_iter = 1001), \n          \"knn\": KNeighborsClassifier(), \n          \"rfc\": RandomForestClassifier()}\n\ndef fit_and_score(models, x_train, x_test, y_train, y_test):\n    \n    np.random.seed(17)\n    model_scores = {}\n    \n    for name, model in models.items():\n        model.fit(x_train, y_train)\n        \n        model_scores[name] = model.score(x_test, y_test)\n\n    return model_scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_scores = fit_and_score(models, x_train, x_test, y_train, y_test)\n\nmodel_scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_comp = pd.DataFrame(model_scores, index = [\"accuracy\"])\nmodel_comp.T.plot.bar();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"train_scores = []\ntest_scores = []\nneighbors = range(1,21)\n\n\nknn = KNeighborsClassifier()\n\nfor i in neighbors:\n    knn.set_params(n_neighbors = i)\n    knn.fit(x_train, y_train)\n    train_scores.append(knn.score(x_train, y_train))\n        \n    test_scores.append(knn.score(x_test, y_test))\n\nplt.plot(neighbors, train_scores, label = \"train scores\")\nplt.plot(neighbors, test_scores, label=\"test scores\")\nplt.xlabel(\"no. of neighbors\")\nplt.ylabel(\"model_score\")\nplt.legend();\n\nprint(f\"maximum accuracy: {max(test_scores)*100:.2f}%\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **using RandmoizedCV to find better parameters**"},{"metadata":{"trusted":true},"cell_type":"code","source":"LR_grid = {\"C\": np.logspace(-4, 4, 20),\n           \"solver\": [\"liblinear\"]}\n\nRF_grid = {\"n_estimators\" : [1, 200,500,1000],\n          \"max_depth\": [None, 3, 5, 10],\n          \"min_samples_split\": np.arange(2, 20, 2),\n          \"min_samples_leaf\": np.arange(1, 20, 2)}\n\nnp.random.seed(17)\nLR = RandomizedSearchCV(LogisticRegression(),\n                           param_distributions = LR_grid,\n                           cv =5,\n                           n_iter = 10,\n                           verbose =True)\n\nRF = RandomizedSearchCV(RandomForestClassifier(),\n                           param_distributions = RF_grid,\n                           cv =5,\n                           n_iter = 10,\n                           verbose = True)\n\nLR.fit(x_train, y_train).best_params_, RF.fit(x_train, y_train).best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LR.score(x_test, y_test), RF.score(x_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## GridsearchCV"},{"metadata":{"trusted":true},"cell_type":"code","source":"LGCV = {\"C\": np.logspace(-4, 4, 30),\n           \"solver\": [\"liblinear\"]}\n\nRFGCV = {\"n_estimators\" : [1000,1200],\n          \"max_depth\": [10, 12],\n          \"min_samples_split\": [6, 12],\n          \"min_samples_leaf\": [20, 22]}\n\n\nLRGS = GridSearchCV(LogisticRegression(),param_grid = LGCV, cv = 5, verbose =True)\n\nRFGS = GridSearchCV(RandomForestClassifier(), param_grid = RFGCV, cv =5, verbose = True)\n\nLRGS.fit(x_train,y_train).best_params_, RFGS.fit(x_train, y_train).best_params_\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LRGS.score(x_test, y_test), RFGS.score(x_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Different metrics"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, plot_roc_curve\nfrom sklearn.metrics import confusion_matrix, classification_report\ny_pred = LRGS.predict(x_test)\n\ny_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc_curve(LRGS, x_test, y_test);\nplot_roc_curve(RFGS, x_test, y_test);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(font_scale = 1.5)\ndef plot_conf_mat(y_test,y_pred):\n    fig, ax = plt.subplots(figsize= (5,5))\n    ax = sns.heatmap(confusion_matrix(y_test, y_pred),\n                    annot = True,\n                    cbar = False)\n    plt.xlabel(\"True label\")\n    plt.ylabel(\"Predictedlabel\")\n    \nplot_conf_mat(y_test, y_pred)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"est = LogisticRegression(solver =\"liblinear\", C = 0.23357214690901212)\n\n\ncvs_p = cross_val_score(est, X, Y, cv = 10, scoring = \"precision\")\ncvs_p = np.mean(cvs_p)\ncvs_p\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The recall_score can be increased with more data. so that there are no false negetives i.e: there are no missing medical condition who has heart_disease**"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}