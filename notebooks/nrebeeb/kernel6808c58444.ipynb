{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"Tweet= pd.read_csv(\"/kaggle/input/twitter-airline-sentiment/Tweets.csv\")\nTweet.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Tweet.count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(Tweet['airline_sentiment'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del Tweet['airline_sentiment_gold']\ndel Tweet['negativereason_gold']\ndel Tweet['retweet_count']\ndel Tweet['tweet_coord']\n#we dont need them","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nMood_count=Tweet['airline_sentiment'].value_counts()\nIndex = [1,2,3]\nplt.bar(Index,Mood_count)\nplt.xticks(Index,['negative','neutral','positive'],rotation=45)\nplt.ylabel('Mood Count')\nplt.xlabel('Mood')\nplt.title('Count of Moods')\n#study this","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gensim\nfrom gensim.utils import simple_preprocess\nfrom gensim.parsing.preprocessing import STOPWORDS\nimport nltk\nfrom nltk.stem import WordNetLemmatizer, SnowballStemmer\nfrom nltk.stem.porter import *\n\n\n\nnltk.download('wordnet')\nstemmer = SnowballStemmer(\"english\")\n\ndef lemmatize_stemming(text):\n    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n\n# Tokenize and lemmatize\ndef preprocess(text):\n    result=[]\n    for token in gensim.utils.simple_preprocess(text) :\n        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n            result.append(lemmatize_stemming(token))\n            \n    return result\ndoc_sample = \"I don't know how to use my new laptop, any advice?\"\nprint(preprocess(doc_sample))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preporcessd_words = []\nall_data_together = []\ndef preprocess_data (tweet_text):\n    preporcessd_words = []\n    for example in tweet_text:\n        example_words = []\n        for word in example.split(' '):\n            preporcessd_word = preprocess(word)\n            if preporcessd_word:\n                for word in preporcessd_word:\n                    example_words.append(word)\n                    #all_data_together.append(word)\n        #print example_words\n        preporcessd_words.append(example_words)\n    return preporcessd_words","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#change value from \"positive, nigative\" to 0,1\nTweet['sentiment']=Tweet['airline_sentiment'].apply(lambda x: 0 if x=='negative' else 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sklearn\nfrom sklearn.model_selection import train_test_split\ntrain,test = train_test_split(Tweet,test_size=0.2,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_tweets = preprocess_data(train['text'])\ntest_tweets = preprocess_data(test['text'])\n#print(test_tweets)\ndictionary = gensim.corpora.Dictionary(preporcessd_words)\ntrain_tweets_test = np.array(train_tweets)\n#print (type(np.asarray(bow_corpus)))\nbow_corpus = [train_tweets_test.doc2bow(doc) for doc in train_tweets]\n#print (type(bow_corpus))\nfrom sklearn.feature_extraction.text import CountVectorizer\nv = CountVectorizer(analyzer = \"word\")\ntrain_features= v.fit_transform(bow_corpus)\n#test_features=v.transform(test_tweets)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(test_tweets)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\n\nClassifiers = [SVC(kernel=\"rbf\", C=0.025, probability=True), DecisionTreeClassifier()]\nAccuracy=[]\nModel=[]\nfor classifier in Classifiers:\n\n    fit = classifier.fit(train_features,train['sentiment'])\n    pred = fit.predict(test_features)\n    accuracy = accuracy_score(pred,test['sentiment'])\n    Accuracy.append(accuracy)\n    Model.append(classifier.__class__.__name__)\n    print('Accuracy of '+classifier.__class__.__name__+'is '+str(accuracy))\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}