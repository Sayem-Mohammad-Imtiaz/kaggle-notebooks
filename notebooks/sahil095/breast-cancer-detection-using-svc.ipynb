{"cells":[{"metadata":{},"cell_type":"markdown","source":"Importing necessary libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# For basic data manipulation\nimport numpy as np # linear algebra\nimport pandas as pd  # data preprocessing","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#For Data Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('fivethirtyeight')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reading Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# reading the data\ndata = pd.read_csv('../input/data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Shapre of data\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# printing few lines\ndata.head(10) # first 10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# describing the data\ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting the info\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# As we can see the last column contains all null values, so we can remove it\ndata = data.drop('Unnamed: 32', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check if dataset contains any null value\ndata.isnull().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# the id values are all unique and won't be required in computation\n# so we can remove it\n\ndata = data.drop('id', axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data Visualizations"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Some Data Visualization for better understanding\n# Here B refers to Benign which means cells are safe from cancer and M means Malignant \n# which means cells are poisonous and can lead to cancer\n\n\n# 1. Bar Chart\nd = data.diagnosis\nax = sns.countplot(d, label='Count')\nB, M = d.value_counts()\nprint('Number of Benign:', B)\nprint('Number of Malignant:', M)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2. Percentage \n# plotting a pie chart \n\nlabels = 'Benign', 'Malignant'\ncolors = ['Red', 'Green']\nexplode = [0, 0.1]\nplt.rcParams['figure.figsize'] = (6,6)\nplt.pie(d.value_counts(), colors = colors, labels = labels,explode = explode, autopct = '%.1f%%')\nplt.title('Cell Types', fontsize = 18)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation Matrix\n\ncorrelation = data.corr()\n\n# tick labels\nmatrix_cols = correlation.columns.tolist()\n\n# convert to array\ncorr_array = np.array(correlation)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting Correlation heatmap\n\nf, ax = plt.subplots(figsize =(20, 15))\nsns.heatmap(correlation, mask=np.zeros_like(correlation, dtype=np.bool), cmap=sns.diverging_palette(220,20,as_cmap=True), square=True, ax=ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Pairplot"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Box Plots"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Box Plots for mean\n\n# box plots are useful for seeing outliers\n\nplt.rcParams['figure.figsize'] = (18,16)\n\nplt.subplot(2,2,1)\nsns.boxplot(x = 'diagnosis', y='radius_mean', data=data, palette='Blues')\nplt.title('Diagnosis vs radius_mean', fontsize=16)\n\n\nplt.subplot(2,2,2)\nsns.boxplot(x = 'diagnosis', y='texture_mean', data=data, palette='bright')\nplt.title('Diagnosis vs texture_mean', fontsize=16)\n\n\nplt.subplot(2,2,3)\nsns.boxplot(x = 'diagnosis', y='perimeter_mean', data=data, palette='spring')\nplt.title('Diagnosis vs perimeter_mean', fontsize=16)\n\n\nplt.subplot(2,2,4)\nsns.boxplot(x = 'diagnosis', y='area_mean', data=data, palette='deep')\nplt.title('Diagnosis vs area_mean', fontsize=16)\n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Boxen Plots"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Boxen Plots for Smoothness\n\n# box plots are useful for seeing outliers\n\nplt.rcParams['figure.figsize'] = (18,16)\n\nplt.subplot(2,2,1)\nsns.boxenplot(x = 'diagnosis', y='smoothness_mean', data=data, palette='Blues')\nplt.title('Diagnosis vs smoothness_mean', fontsize=16)\n\n\nplt.subplot(2,2,2)\nsns.boxenplot(x = 'diagnosis', y='compactness_mean', data=data, palette='bright')\nplt.title('Diagnosis vs compactness_mean', fontsize=16)\n\n\nplt.subplot(2,2,3)\nsns.boxenplot(x = 'diagnosis', y='concavity_mean', data=data, palette='spring')\nplt.title('Diagnosis vs concavity_mean', fontsize=16)\n\n\nplt.subplot(2,2,4)\nsns.boxenplot(x = 'diagnosis', y='concave points_mean', data=data, palette='deep')\nplt.title('Diagnosis vs concave points_mean', fontsize=16)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Strip Plots"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Strip Plots\n\nplt.rcParams['figure.figsize'] = (18,16)\n\nplt.subplot(2,2,1)\nsns.stripplot(x = 'diagnosis', y='concavity_se', data=data, palette='Blues')\nplt.title('Diagnosis vs concavity_se', fontsize=16)\n\n\nplt.rcParams['figure.figsize'] = (18,16)\nplt.subplot(2,2,2)\nsns.stripplot(x = 'diagnosis', y='concave points_se', data=data, palette='bright')\nplt.title('Diagnosis vs concave points_se', fontsize=16)\n\n\nplt.rcParams['figure.figsize'] = (18,16)\nplt.subplot(2,2,3)\nsns.stripplot(x = 'diagnosis', y='symmetry_se', data=data, palette='spring')\nplt.title('Diagnosis vs symmetry_se', fontsize=16)\n\n\nplt.rcParams['figure.figsize'] = (18,16)\nplt.subplot(2,2,4)\nsns.stripplot(x = 'diagnosis', y='fractal_dimension_se', data=data, palette='deep')\nplt.title('Diagnosis vs fractal_dimension_se', fontsize=16)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Label encoding for dependent variable\n\n# importing label encoder\n\nfrom sklearn.preprocessing import LabelEncoder\n\n# performing label encoding\n\nle = LabelEncoder()\ndata['diagnosis'] = le.fit_transform(data['diagnosis'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['diagnosis'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# splitting the dependent and independent variables from the dataset\n\nx = data.iloc[:, 1:]\ny = data.iloc[:, 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x.shape)\nprint(y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# splitting the dataset into training and testing dataset\n\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x_train.shape)\nprint(y_train.shape)\nprint(x_test.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# standard Scaling\n\nfrom sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\n                   \nx_train = sc.fit_transform(x_train)\nx_test = sc.fit_transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Modelling"},{"metadata":{},"cell_type":"markdown","source":"Decision Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing libraries for calculating prediction scores\n\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.model_selection import GridSearchCV, cross_val_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Logistic Regression\n\nfrom sklearn.tree import DecisionTreeClassifier\n# create the model\nmodel = DecisionTreeClassifier()\n\n# feed the training data into model\nmodel.fit(x_train, y_train)\n\n# predict the test result \ny_pred = model.predict(x_test)\n\n# Calculating the accuracy\nprint('Training accuracy: ', model.score(x_train, y_train))\nprint('Test Accuracy: ', model.score(x_test, y_test))\n\n# classification report\ncr = classification_report(y_test, y_pred)\nprint(cr)\n\n# confusion matrix\nplt.rcParams['figure.figsize']= (5, 5)\ncm = confusion_matrix(y_test, y_pred)\nsns.heatmap(cm, annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature importance of decision tree\n\nfeatures = data.columns\nimp = model.feature_importances_\nindices = np.argsort(imp)\n\nplt.rcParams['figure.figsize']=(15,15)\nplt.barh(range(len(indices)), imp[indices])\nplt.yticks(range(len(indices)), features[indices])\nplt.title('Feature importance for Decision Tree', fontsize=25)\nplt.grid()\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random Forest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random Forest Classifier\n\nfrom sklearn.ensemble import RandomForestClassifier\n\n# creating a model\nmodel = RandomForestClassifier()\n\n# feeding the training data\nmodel.fit(x_train, y_train)\n\n# predcit the test results\ny_pred = model.predict(x_test)\n\n# Calculating the accuracy\nprint('Training accuracy: ', model.score(x_train, y_train))\nprint('Test accuracy: ', model.score(x_test, y_test))\n\n# Classification report\ncr = classification_report(y_test, y_pred)\nprint(cr)\n\n# confusion matrix\nplt.rcParams['figure.figsize'] = (5, 5)\ncm = confusion_matrix(y_test, y_pred)\nsns.heatmap(cm, annot=True, cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature importance for random forest\nfeatures = data.columns\nimportance = model.feature_importances_\nindices = np.argsort(importance)\n\nplt.rcParams['figure.figsize'] = (15, 15)\nplt.barh(range(len(indices)), importance[indices])\nplt.yticks(range(len(indices)), features[indices])\nplt.title('Feature Importance for Random Forest', fontsize = 30)\nplt.grid()\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Support Vector Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Support Vector classfier\n\nfrom sklearn.svm import SVC\n\n# Create a model\nmodel = SVC()\n\n# feed the training data\nmodel.fit(x_train, y_train)\n\n# predicting test results\ny_pred = model.predict(x_test)\n\n# Claculating the accuracy\nprint('Training accuracy: ', model.score(x_train, y_train))\nprint('Test accuracy: ', model.score(x_test, y_test))\n\n# Classification repot\ncr = classification_report(y_test, y_pred)\nprint(cr)\n\n# confusion matrix\nplt.rcParams['figure.figsize'] = (5,5)\ncm = confusion_matrix(y_test, y_pred)\nsns.heatmap(cm, annot=True, cmap = 'Greens')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Support Vector Classifiers show the best results."},{"metadata":{},"cell_type":"markdown","source":"Thanks for reading the kernel."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}