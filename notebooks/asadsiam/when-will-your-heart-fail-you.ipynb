{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Project Specific Libraries are imported (2)\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score\nimport statistics\nfrom sklearn.model_selection import train_test_split, KFold\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-03T17:55:53.448354Z","iopub.execute_input":"2021-08-03T17:55:53.448801Z","iopub.status.idle":"2021-08-03T17:55:54.729667Z","shell.execute_reply.started":"2021-08-03T17:55:53.44871Z","shell.execute_reply":"2021-08-03T17:55:54.728649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Dataset for heart attack prediction is read and put into the dataframe structure. (3)\n#The following data is considered as the train set \n#The first 10 values are displayed (4)\ndf= pd.read_csv('../input/heart-attack-analysis-prediction-dataset/heart.csv')\ndisplay(df.head (10))\nprint(\"\\n\\n\")\nprint(df.shape)\n     ","metadata":{"execution":{"iopub.status.busy":"2021-08-03T19:14:47.332202Z","iopub.execute_input":"2021-08-03T19:14:47.332571Z","iopub.status.idle":"2021-08-03T19:14:47.430899Z","shell.execute_reply.started":"2021-08-03T19:14:47.332541Z","shell.execute_reply":"2021-08-03T19:14:47.429829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#The train dataset is split to form another dataset where the \n#output column(likeliness of heart attack) is dropped as seen below to create\n#test dataset which consistes of all the other columns except the output column \n#In the test set X variables are the the other characterstics variables and based on\n# these the target variable output which is the Y variable will do the supervised \n#machine learning. (1)\n\nfeatures_num = [\"age\", \"trtbps\",\"chol\",\"thalachh\",\"oldpeak\"]\n\nfeatures_cat = ['sex','exng','caa','cp','fbs','restecg','slp','thall']\n\nscaler = StandardScaler()\nohe = OneHotEncoder(sparse = False)\n\nscaled_columns = scaler.fit_transform(df[features_num]) \nencoded_columns = ohe.fit_transform(df[features_cat])\n\nX = np.concatenate([scaled_columns, encoded_columns], axis = 1)\ny = df['output']\n\n#This part specifically splits the dataset to train and test sets. \n#The data divided by the split is based on the relationship\n#75% as our training data and test our model on the remaining 25%. \n#The Scikit-learn's train_test_split function enables this.\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 4)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T16:21:49.955567Z","iopub.execute_input":"2021-08-03T16:21:49.955982Z","iopub.status.idle":"2021-08-03T16:21:49.982619Z","shell.execute_reply.started":"2021-08-03T16:21:49.955947Z","shell.execute_reply":"2021-08-03T16:21:49.981325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pff = pd.DataFrame({'output': X_test[:, 29]})\ndisplay(pff)\n\n#pff.to_csv('testpff.csv')","metadata":{"execution":{"iopub.status.busy":"2021-08-03T16:21:55.729845Z","iopub.execute_input":"2021-08-03T16:21:55.73021Z","iopub.status.idle":"2021-08-03T16:21:55.744567Z","shell.execute_reply.started":"2021-08-03T16:21:55.730181Z","shell.execute_reply":"2021-08-03T16:21:55.743552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#A single column (output coulmn in this case) is accessed from the train set and viewed \nprint(df['output']) #access data frame specific column in this way OR\nprint(df.output) #access data frame this way \nprint(df.output.value_counts()) #counts the unique different values in the column","metadata":{"execution":{"iopub.status.busy":"2021-08-03T16:21:59.672803Z","iopub.execute_input":"2021-08-03T16:21:59.673221Z","iopub.status.idle":"2021-08-03T16:21:59.685951Z","shell.execute_reply.started":"2021-08-03T16:21:59.673181Z","shell.execute_reply":"2021-08-03T16:21:59.684577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking to see if anny columns have any data missing and it shows no \n#missing entries in any column as no NaN. (5,12,13,14)\ndf.isnull().sum() ","metadata":{"execution":{"iopub.status.busy":"2021-08-03T16:22:05.068544Z","iopub.execute_input":"2021-08-03T16:22:05.068944Z","iopub.status.idle":"2021-08-03T16:22:05.079462Z","shell.execute_reply.started":"2021-08-03T16:22:05.068909Z","shell.execute_reply":"2021-08-03T16:22:05.077996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info() #information of the dataframe presented ((5,12,13,14))\n","metadata":{"execution":{"iopub.status.busy":"2021-08-03T16:22:08.926429Z","iopub.execute_input":"2021-08-03T16:22:08.926881Z","iopub.status.idle":"2021-08-03T16:22:08.948006Z","shell.execute_reply.started":"2021-08-03T16:22:08.926841Z","shell.execute_reply":"2021-08-03T16:22:08.946636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# boxplot and outlier detection for the training dataset is done using seaborn (6,7)\nfig, (subplot1,subplot2)=plt.subplots(1,2) #1 row 2 column row created\n#input argument is defined as df(which is the dataframe here)\n#x=cp/exng is considered for the boxplot (where cp is divided into \n#3 bxplts and exng is divided into 2 bxplts as they have these specified in their data)\n#y=age is taken from the df (dataframe) for botht eh boxplots\n\nsns.boxplot(x='cp', y='age', data=df, ax=subplot1)#chest pains\n\nsns.boxplot(x='exng', y='age', data=df, ax=subplot2) #exercise induced angina\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-03T16:22:12.843916Z","iopub.execute_input":"2021-08-03T16:22:12.844275Z","iopub.status.idle":"2021-08-03T16:22:13.353662Z","shell.execute_reply.started":"2021-08-03T16:22:12.844244Z","shell.execute_reply":"2021-08-03T16:22:13.351971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Previously it was seen in the boxplot for \n#exercise induced angima  and age that people with age over 70 had outlier these are\n#shown here. (6,7)\ndf.loc[df.age>70] \n","metadata":{"execution":{"iopub.status.busy":"2021-08-03T19:14:52.775799Z","iopub.execute_input":"2021-08-03T19:14:52.776213Z","iopub.status.idle":"2021-08-03T19:14:52.829574Z","shell.execute_reply.started":"2021-08-03T19:14:52.776177Z","shell.execute_reply":"2021-08-03T19:14:52.828581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#The data types are checked initially.\n#Correlation matrix is created for the training\n#to show which of the columns are more dependent on the \n#other from which as idea can be generated to understand which \n#values lead to be the more influential. (8)\n\nprint(df.dtypes)\nprint(\"\\n\\n\")\nTrainingDataset_NumericalOnly=df.select_dtypes(include=['int64','float64'])\ncorr_mat=TrainingDataset_NumericalOnly.corr()\n\ncorr_mat.head(n=5) #first 5 values are checked","metadata":{"execution":{"iopub.status.busy":"2021-08-03T19:20:26.977731Z","iopub.execute_input":"2021-08-03T19:20:26.978242Z","iopub.status.idle":"2021-08-03T19:20:27.008212Z","shell.execute_reply.started":"2021-08-03T19:20:26.978211Z","shell.execute_reply":"2021-08-03T19:20:27.007087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#The heat map for the training dataset is created which is technically the visual representation \n#of the correlation matrix where the more dependent columns show a higher heat/ warmer\n#color referring to the more dependency on each other.(9)\n\nplt.figure(figsize=(17, 10))\nsns.heatmap(\n    corr_mat,\n    cmap=plt.cm.RdBu,\n    vmax=1,\n    linewidth=0.1,\n    linecolor='white',\n    square=True,\n    annot=True\n            )","metadata":{"execution":{"iopub.status.busy":"2021-08-03T16:22:23.217518Z","iopub.execute_input":"2021-08-03T16:22:23.217912Z","iopub.status.idle":"2021-08-03T16:22:24.624315Z","shell.execute_reply.started":"2021-08-03T16:22:23.217879Z","shell.execute_reply":"2021-08-03T16:22:24.623505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Pairplot shows pairwise relationship between each column in the training dataset.\n#This results in creating a grid of  axes so that each numeric value\n#is shared across the x and y axis. The diagonal plots here act differently \n#it shows a univariate distribution plot is drawn \n#to show  the marginal distribution of each data for the respective columns. (10)\n#Data for output(heart attack) is in blue\n\nplt.figure(figsize=(20,20))\nsns.pairplot(TrainingDataset_NumericalOnly, hue='output') \n","metadata":{"execution":{"iopub.status.busy":"2021-08-03T16:22:29.52495Z","iopub.execute_input":"2021-08-03T16:22:29.525552Z","iopub.status.idle":"2021-08-03T16:23:22.289805Z","shell.execute_reply.started":"2021-08-03T16:22:29.525501Z","shell.execute_reply":"2021-08-03T16:23:22.288299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The countplot shows the specifics data for a column in divided \n# manner based on the individual outcomes for that column\n# In the training set of how many males/females are likely to have a heart attack is shown in\n# this count plotplot.The blue color mean more likey to heart failure. (11)\nsns.countplot(x ='sex', data = df,hue='output')\nplt.xticks(ticks=[0, 1], labels = [\"female\", \"male\"])\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-08-03T16:26:43.65814Z","iopub.execute_input":"2021-08-03T16:26:43.65869Z","iopub.status.idle":"2021-08-03T16:26:43.846242Z","shell.execute_reply.started":"2021-08-03T16:26:43.658638Z","shell.execute_reply":"2021-08-03T16:26:43.845161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Supervised machine learning model created using Logistic regression to predict the output cloumn(heart attack chances)\n#using the test set that was created based using the training model.\n#The model accuracy is also generated herefrom the newly established test dataset.\n#The new output generated from the test set is put into a dataframe and shown.\n# A 5-fold cross validation is done also over the logistic regressive model which ensures to take 5 different layers\n#of data from test and train dataset to create the target column in test dataset.\n#This ensures to produce different accuracy results based off the different spliting of the dataset\n# as a result producing an array of 5 scores based on which average accuracy score and mean is \n#taken for the model results\n\n\nX = df.iloc[:, :-1]\ny = df.iloc[:, -1]\nk = 5\nkf = KFold(n_splits=k, random_state=None)\nmodel = LogisticRegression(solver='liblinear')\n\nacc_score = []\npred_val_stack = []\nfor train_index, test_index in kf.split(X):\n    X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n    y_train, y_test = y[train_index], y[test_index]\n\n    model.fit(X_train, y_train)\n    pred_values = model.predict(X_test)\n    ptt = np.transpose(pred_values)\n    conv_ptt = pd.DataFrame(ptt,columns=['output'])\n    display(conv_ptt)\n    \n    acc = accuracy_score(pred_values, y_test)\n    acc_score.append(acc)\n\navg_acc_score = sum(acc_score) / k\nstd_div = statistics.stdev(acc_score)\n\nprint('accuracy of each fold - {}'.format(acc_score))\nprint('Avg accuracy : {}'.format(avg_acc_score))\nprint('Standard Deviation : {}'.format(std_div))\n\n","metadata":{"execution":{"iopub.status.busy":"2021-08-03T16:27:09.350868Z","iopub.execute_input":"2021-08-03T16:27:09.351424Z","iopub.status.idle":"2021-08-03T16:27:09.461282Z","shell.execute_reply.started":"2021-08-03T16:27:09.351377Z","shell.execute_reply":"2021-08-03T16:27:09.45998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conv_ptt.to_csv('heart_out_prediction.csv', mode='a', header=True)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-03T16:27:17.987467Z","iopub.execute_input":"2021-08-03T16:27:17.987911Z","iopub.status.idle":"2021-08-03T16:27:17.997928Z","shell.execute_reply.started":"2021-08-03T16:27:17.987873Z","shell.execute_reply":"2021-08-03T16:27:17.996788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conv_ptt.to_excel('output.xlsx')\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-08-03T14:53:16.410589Z","iopub.execute_input":"2021-08-03T14:53:16.411131Z","iopub.status.idle":"2021-08-03T14:53:16.448466Z","shell.execute_reply.started":"2021-08-03T14:53:16.411096Z","shell.execute_reply":"2021-08-03T14:53:16.446852Z"},"trusted":true},"execution_count":null,"outputs":[]}]}