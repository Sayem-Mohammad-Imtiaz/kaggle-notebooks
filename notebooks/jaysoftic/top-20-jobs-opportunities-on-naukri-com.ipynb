{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport plotly.express as px\n%matplotlib inline\nimport re\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/jobs-on-naukricom/home/sdf/marketing_sample_for_naukri_com-jobs__20190701_20190830__30k_data.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# replace space with underscore in column name for quick access\ndata.columns = data.columns.str.replace(\" \", \"_\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Job Opportunities in Top 20 cities","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# filter and find unique() cities from data set\n\ndata.Location = data.Location.str.upper()\nnew_location =data.Location.str.strip().str.split(\",\", expand = True)[0].str.split(\" \", expand = True)[0].value_counts().reset_index()\nnew_location.columns = [\"Location\", \"Job_Opportunities\"]\ntop_20_new_location = new_location[:20]\ntop_20_new_location.style.background_gradient(cmap = \"Reds\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12, 8))\nplt.bar(top_20_new_location.Location, top_20_new_location.Job_Opportunities, color = \"r\")\nplt.xlabel(\"Locations\")\nplt.ylabel(\"Job Opportunities\")\nplt.xticks(top_20_new_location.Location, rotation = \"60\")\nplt.title(\"Job Opportunities in Top 20 Locations\", fontdict={\"fontsize\" :20})\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Job Opportunities in Top 20 Industries","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# filter and find unique Industry from data set\n\nnew_Industry = pd.DataFrame(data.Industry.str.split(\",\", expand = True).values.ravel(\"f\"),columns = [\"Industry\"])\nnew_Industry = new_Industry.dropna()\nnew_Industry.Industry = new_Industry.Industry.str.upper()\nnew_Industry.Industry = new_Industry.Industry.apply(lambda x: re.sub(\"[^A-Za-z0-9 -]+\", \",\", x))\nnew_Industry = pd.DataFrame(new_Industry.Industry.str.split(\",\", expand = True).values.ravel(\"f\"), columns = [\"Industry\"])\nnew_Industry = new_Industry.dropna()\nnew_Industry.Industry = new_Industry.Industry.str.lstrip().str.rstrip()\n# pure 20 Industry\nnew_Industry = new_Industry.Industry.value_counts().reset_index()\nnew_Industry.columns =[\"Industry\", \"Job_Opportunities\"]\ntop_20_new_Industry = new_Industry[:20]\ntop_20_new_Industry.style.background_gradient(cmap = \"Blues\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12, 8))\nplt.bar(top_20_new_Industry.Industry, top_20_new_Industry.Job_Opportunities, color = \"b\")\nplt.xlabel(\"Industries\")\nplt.ylabel(\"Job Opportunities\")\nplt.xticks(top_20_new_Industry.Industry, rotation = \"vertical\")\nplt.title(\"Job Opportunities in Top 20 Industries\", fontdict={\"fontsize\" :20})\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Top 20 Job Category","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"new_Role_Category = data.Role_Category.str.lstrip().str.rstrip().value_counts().reset_index()\nnew_Role_Category.columns = [\"Role_Category\", \"Job_Opportunities\"]\ntop_20_new_Role_Category = new_Role_Category[:20]\ntop_20_new_Role_Category.style.background_gradient(cmap = \"Greens\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12, 8))\nplt.bar(top_20_new_Role_Category.Role_Category, top_20_new_Role_Category.Job_Opportunities, color = \"g\")\nplt.xlabel(\"Job Catergories\")\nplt.ylabel(\"Job Opportunities\")\nplt.xticks(top_20_new_Role_Category.Role_Category, rotation = \"vertical\")\nplt.title(\"Top 20 Job Categories\", fontdict={\"fontsize\" :20})\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Top 20 Job Role","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"new_Job_Role = data.Role.str.lstrip().str.rstrip().value_counts().reset_index()\nnew_Job_Role.columns = [\"Role\", \"Job_Opportunities\"]\ntop_20_new_Job_Role = new_Job_Role[:20]\ntop_20_new_Job_Role.style.background_gradient(cmap = \"Purples\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12, 8))\nplt.bar(top_20_new_Job_Role.Role, top_20_new_Job_Role.Job_Opportunities, color = \"purple\")\nplt.xlabel(\"Job Role\")\nplt.ylabel(\"Job Opportunities\")\nplt.xticks(top_20_new_Job_Role.Role, rotation = \"90\")\nplt.title(\"Top 20 Job Role\", fontdict={\"fontsize\" :20})\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##  Top 5 Location for Top 20 Indusries","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"city_industries = pd.DataFrame({\"Location\": data.Location.str.split(\",\", expand = True)[0],\n                                \"Industry\": data.Industry.str.split(\",\", expand = True)[0]})\ncity_industries.dropna(inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_CT_IND = pd.crosstab(city_industries.Location, city_industries.Industry).reset_index()\nnew_CT_IND = new_CT_IND.melt(id_vars = \"Location\", value_name = \"Job_Opportunities\")\nnew_CT_IND = new_CT_IND.sort_values(by = [\"Industry\", \"Job_Opportunities\"], ascending = False).reset_index(drop = True)\nnew_CT_IND = new_CT_IND.dropna()\nnew_CT_IND = new_CT_IND.sort_values(by = \"Job_Opportunities\", ascending = False).reset_index(drop = True)\n\n# in classy data frame is only for getting top 20 Industry Name\nclassy = new_CT_IND.groupby(\"Industry\").sum().reset_index().sort_values(by = \"Job_Opportunities\", ascending = False)[:20]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# saved industry name in list for fetching only 5 same name industry or only five Location of particular indusry\nIndustry_20_lst = classy.Industry.reset_index(drop = True)\nlimit = 0\npure_loc_Ind = pd.DataFrame(columns=[\"Location\", \"Industry\", \"Job_Opportunities\"])\nfor j in range(20):\n    limit = 0\n    for i in range (new_CT_IND.size):\n        if limit == 5:\n            break\n        if Industry_20_lst[j] == new_CT_IND.loc[i, \"Industry\"]:\n            pure_loc_Ind = pure_loc_Ind.append(new_CT_IND.loc[i], ignore_index = True)\n            limit += 1\n# yeeeah i did it :)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot pie chart of top 5 location of top 20 Industry\nfor i in Industry_20_lst:\n    classy = pure_loc_Ind.loc[pure_loc_Ind.Industry == i, [\"Location\", \"Job_Opportunities\"]]\n    fig = px.pie(classy, names = \"Location\", values = \"Job_Opportunities\", color = \"Location\",\n                 title = \"Top 5 Location for \" + i + \" Industry\")\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Skills required for various job categories","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"new_job_skills = data[[\"Role_Category\", \"Key_Skills\"]].copy()\nnew_job_skills.Key_Skills = new_job_skills.Key_Skills.str.upper()\nclassy = new_job_skills.Key_Skills.str.split(\"|\", expand = True) # split keys\nclassy = pd.concat([new_job_skills, classy], axis = 1) # concat splited keys columns\nclassy = classy.melt(id_vars = [\"Role_Category\", \"Key_Skills\"], var_name = \"Job_Opportunities\", value_name = \"Skills\")\n# transform Key skills using melt\nclassy = classy.dropna() \nclassy.Job_Opportunities = 1 # assign job opportunites value 1 for counting purpose\nclassy = classy.groupby([\"Role_Category\", \"Skills\"]).Job_Opportunities.sum().reset_index()\n# group by role and skills and find sum of job opportunities\nclassy = classy.sort_values(by = \"Job_Opportunities\", ascending = False).reset_index(drop = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pure_skills_job_cat = pd.DataFrame(columns = [\"Role_Category\", \"Skills\", \"Job_Opportunities\"])\nrole_category_lst = top_20_new_Role_Category.Role_Category\nlimit = 0\nfor i in range(20):\n    limit = 0\n    for j in range(classy.size):\n        if limit == 10:\n            break\n        if role_category_lst[i] == classy.loc[j, \"Role_Category\"]:\n            pure_skills_job_cat = pure_skills_job_cat.append(classy.loc[j])\n            limit += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"px.sunburst(data_frame = pure_skills_job_cat, values = \"Job_Opportunities\", path = [\"Role_Category\", \"Skills\"],\n            color = \"Role_Category\", title = \"Skills Required for various Job Categories\",height = 600)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Average salary get in top 10 cities","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"new_salary_loc = data[[\"Job_Salary\", \"Location\"]].copy()\nnew_salary_loc[\"New_Location\"] = new_salary_loc.Location.str.strip().str.split(\",\", expand = True)[0]\n\nclassy = new_salary_loc.Job_Salary.apply(lambda x: re.sub(\"[^0-9 -]\", \"\", str(x)))\nnew_salary_loc[\"Min_Salary\"] = classy.str.strip().str.split(\"-\", expand = True)[0]\nnew_salary_loc[\"Max_Salary\"] = classy.str.strip().str.split(\"-\", expand = True)[1]\nnew_salary_loc.dropna(inplace = True)\n\n# remove space between digits\nnew_salary_loc.Min_Salary = new_salary_loc.Min_Salary.str.replace(\" \", \"\")\nnew_salary_loc.Max_Salary = new_salary_loc.Max_Salary.str.replace(\" \", \"\")\n\n# put 0 where value is totally empty\nnew_salary_loc.loc[new_salary_loc.Max_Salary == \"\", \"Max_Salary\"] = \"0\"\nnew_salary_loc.loc[new_salary_loc.Min_Salary == \"\", \"Min_Salary\"] = \"0\"\n\n# convert it into \nnew_salary_loc.Min_Salary = new_salary_loc.Min_Salary.astype(\"int64\")\nnew_salary_loc.Max_Salary = new_salary_loc.Max_Salary.astype(\"int64\")\nnew_salary_loc.drop(columns = [\"Location\", \"Job_Salary\"], inplace = True) # drop old columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classy = new_salary_loc.groupby(\"New_Location\").median().reset_index() # find average of salary\n\ntop_20_location_salary = pd.DataFrame()\nloc_list = top_20_new_location.Location\nfor i in range(20):\n    for j in range(classy.New_Location.size):\n        if loc_list[i] == classy.loc[j, \"New_Location\"]:\n            top_20_location_salary = top_20_location_salary.append(classy.loc[j])\n            break\n\ntop_20_location_salary = top_20_location_salary.reset_index(drop = True)\ntop_10_location_salary = top_20_location_salary[:10].copy() # find top 10 \ntop_10_location_salary.rename(columns = {\"New_Location\": \"Location\"}, inplace = True)\ntop_10_location_salary.Max_Salary = top_10_location_salary.Max_Salary.astype(\"int64\")\ntop_10_location_salary.Min_Salary = top_10_location_salary.Min_Salary.astype(\"int64\")\ntop_10_location_salary = top_10_location_salary[top_10_location_salary.columns[[2, 1, 0]]] # change column order\ntop_10_location_salary.style.background_gradient(cmap = \"Reds\", subset = \"Min_Salary\").\\\n                            background_gradient(cmap = \"Greens\", subset = \"Max_Salary\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12, 8))\nax = plt.subplot(111)\nax.bar(top_10_location_salary.index - 0.2, top_10_location_salary.Min_Salary, color = \"r\", width = 0.4, label = \"Min Salary\")\nax.bar(top_10_location_salary.index +0.2, top_10_location_salary.Max_Salary, color = \"g\", width = 0.4, label = \"Max Salary\")\nplt.xlabel(\"Location\")\nplt.ylabel(\"Average Salary\")\nplt.xticks([i for i in top_10_location_salary.index] ,top_10_location_salary.Location)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Average salary of top 10 Industry in top 5 location","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"new_avg_sal_ind = data[[\"Location\", \"Industry\", \"Job_Salary\"]].copy() # preparing data\nnew_avg_sal_ind.Location = new_avg_sal_ind.Location.str.split(\",\", expand = True)[0] # preparing location\nnew_avg_sal_ind.Industry = new_avg_sal_ind.Industry.str.split(\",\", expand = True)[0] # preparing industry\nnew_avg_sal_ind.Job_Salary = new_avg_sal_ind.Job_Salary.apply(lambda x: re.sub(\"[^0-9 -]\", \"\", str(x))) # salary\nnew_avg_sal_ind[\"Min_Salary\"] = new_avg_sal_ind.Job_Salary.str.split(\"-\", expand = True)[0] # min salary\nnew_avg_sal_ind[\"Max_Salary\"] = new_avg_sal_ind.Job_Salary.str.split(\"-\", expand = True)[1] # max salary\nnew_avg_sal_ind.Min_Salary = new_avg_sal_ind.Min_Salary.str.replace(\" \", \"\")\nnew_avg_sal_ind.Max_Salary = new_avg_sal_ind.Max_Salary.str.replace(\" \", \"\")\nnew_avg_sal_ind.loc[new_avg_sal_ind.Min_Salary == \"\", \"Min_Salary\"] = \"0\"\nnew_avg_sal_ind.loc[new_avg_sal_ind.Max_Salary == \"\", \"Max_Salary\"] = \"0\"\nnew_avg_sal_ind.dropna(inplace = True)\nnew_avg_sal_ind.Min_Salary = new_avg_sal_ind.Min_Salary.astype(\"int64\")\nnew_avg_sal_ind.Max_Salary = new_avg_sal_ind.Max_Salary.astype(\"int64\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classy = new_avg_sal_ind.groupby([\"Industry\", \"Location\"]).median().reset_index()\n# group industry and location and find average of salary\nclassy.Industry = classy.Industry.str.upper() # convert upper case of industry\nlst_Industry = new_Industry.Industry[:25] # get 25 top industry\nlst_Location = top_20_new_location.Location # get 20 top industry\nlimit = 0\ntop_10_avg_sal_industry_location = pd.DataFrame(columns = [\"Industry\", \"Location\", \"Max_Salary\", \"Min_Salary\"])\n# creating empty data frame for storing filtering data\nfor i in range(25):\n    limit = 0\n    dummy_df = classy.loc[classy.Industry == lst_Industry[i]].reset_index(drop = True)\n    # creating dummy df for top 10 industry\n    for j in range(20):\n        if limit == 5:\n            break\n        else:\n            for k in range(dummy_df.Location.size):\n                if lst_Location[j] == dummy_df.loc[k, \"Location\"]:\n                    # append top 5 country and it's average salary of top 10 industry\n                    top_10_avg_sal_industry_location = top_10_avg_sal_industry_location.append(dummy_df.loc[k])\n                    limit += 1\n                    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classy = top_10_avg_sal_industry_location.melt(id_vars = [\"Industry\", \"Location\"], var_name = \"Salaries\")\npx.sunburst(data_frame = classy, path = [\"Industry\", \"Location\", \"Salaries\"],\n            values = \"value\", title = \"Average salary of top 10 Industry in top 5 Location\", height = 600)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}