{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First, we will import several libraries. `scikit-learn` (**sklearn**) contains helpful statistical models, and we'll use the `matplotlib.pyplot` library for visualizations. Of course, we will use `numpy` and `pandas` for data manipulation throughout.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import r2_score\n\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/tmdb-movie-metadata/tmdb_5000_movies.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will define the regression and classification outcomes. Specifically, we will use the `revenue` column as the target for regression. For classification, we will construct an indicator of profitability for each movie.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['profitable'] = df.revenue > df.budget\ndf['profitable'] = df['profitable'].astype(int)\n\nregression_target = 'revenue'\nclassification_target = 'profitable'\n\ndf['profitable'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For simplicity, we will proceed by analyzing only the rows without any missing data. Now, we will remove rows with any infinite or missing values.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.replace([np.inf, -np.inf], np.nan)\ndf = df.dropna(how=\"any\")\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some variables in the dataset are already numeric and perhaps useful for regression and classification. In this exercise, we will store the names of these variables for future use. We will also take a look at some of the continuous variables and outcomes by plotting each pair in a scatter plot. Finally, we will evaluate the skew of each variable.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"continuous_covariates = ['budget', 'popularity', 'runtime', 'vote_count', 'vote_average']\noutcomes_and_continuous_covariates = continuous_covariates + [regression_target, classification_target]\nplotting_variables = ['budget', 'popularity', regression_target]\n\naxes = pd.plotting.scatter_matrix(df[plotting_variables], alpha=0.15, \\\n       color=(0,0,0), hist_kwds={\"color\":(0,0,0)}, facecolor=(1,0,0))\nplt.show()\nprint(df[outcomes_and_continuous_covariates].skew())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It appears that the variables `budget`, `popularity`, `runtime`, `vote_count`, and `revenue` are all right-skewed. In this exercise, we will transform these variables to eliminate this skewness. Specifically, we will use the `np.log10()` method. Because some of these variable values are exactly 0, we will add a small positive value to each to ensure it is defined; this is necessary because log(0) is negative infinity.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for covariate in ['budget', 'popularity', 'runtime', 'vote_count', 'revenue']:\n    df[covariate] = df[covariate].apply(lambda x: np.log10(1+x))\nprint(df[outcomes_and_continuous_covariates].skew())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's now save our dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_csv(\"movies_clean.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\ndf = pd.read_csv('movies_clean.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this part, we will primarily use the two models we recently discussed: linear/logistic regression and random forests to perform prediction and classification. We will use these methods to predict revenue, and we will use logistic regression to classify whether a movie was profitable.\n\nNow, we will instantiate regression and classification models. Code is provided that prepares the covariates and outcomes we will use for data analysis.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define all covariates and outcomes from `df`.\nregression_target = 'revenue'\nclassification_target = 'profitable'\nall_covariates = ['budget', 'popularity', 'runtime', 'vote_count', 'vote_average']\n\nregression_outcome = df[regression_target]\nclassification_outcome = df[classification_target]\ncovariates = df[all_covariates]\n\n# Instantiate all regression models and classifiers.\nlinear_regression = LinearRegression()\nlogistic_regression = LogisticRegression()\nforest_regression = RandomForestRegressor(max_depth=4, random_state=0)\nforest_classifier = RandomForestClassifier(max_depth=4, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will now create two functions that compute a model's score. For regression models, we will use correlation as the score. For classification models, we will use accuracy as the score.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def correlation(estimator, X, y):\n    predictions = estimator.fit(X, y).predict(X)\n    return r2_score(y, predictions)\n    \ndef accuracy(estimator, X, y):\n    predictions = estimator.fit(X, y).predict(X)\n    return accuracy_score(y, predictions)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we will compute the cross-validated performance for the linear and random forest regression models.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nlinear_regression_scores = cross_val_score(linear_regression, covariates, regression_outcome, cv=10, scoring=correlation)\nforest_regression_scores = cross_val_score(forest_regression, covariates, regression_outcome, cv=10, scoring=correlation)\n\n# Plot Results\nplt.axes().set_aspect('equal', 'box')\nplt.scatter(linear_regression_scores, forest_regression_scores)\nplt.plot((0, 1), (0, 1), 'k-')\n\nplt.xlim(0, 1)\nplt.ylim(0, 1)\nplt.xlabel(\"Linear Regression Score\")\nplt.ylabel(\"Forest Regression Score\")\n\n# Show the plot.\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will compute cross-validated performance for the linear and random forest classification models.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"logistic_regression_scores = cross_val_score(logistic_regression, covariates, classification_outcome, cv=10, scoring=accuracy)\nforest_classification_scores = cross_val_score(forest_classifier, covariates, classification_outcome, cv=10, scoring=accuracy)\n\n# Plot Results\nplt.axes().set_aspect('equal', 'box')\nplt.scatter(logistic_regression_scores, forest_classification_scores)\nplt.plot((0, 1), (0, 1), 'k-')\n\nplt.xlim(0, 1)\nplt.ylim(0, 1)\nplt.xlabel(\"Linear Classification Score\")\nplt.ylabel(\"Forest Classification Score\")\n\n# Show the plot.\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We saw that predicting revenue was only moderately successful. It might be the case that predicting movies that generated precisely no revenue is difficult. In the next three exercises, we will exclude these movies, and rerun the analyses to determine if the fits improve. In this exercise, we will rerun the regression analysis for this subsetted dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"positive_revenue_df = df[df[\"revenue\"] > 0]\n\nregression_outcome = positive_revenue_df[regression_target]\nclassification_outcome = positive_revenue_df[classification_target]\ncovariates = positive_revenue_df[all_covariates]\n\nlinear_regression = LinearRegression()\nlogistic_regression = LogisticRegression()\nforest_regression = RandomForestRegressor(max_depth=4, random_state=0)\nforest_classifier = RandomForestClassifier(max_depth=4, random_state=0)\nlinear_regression_scores = cross_val_score(linear_regression, covariates, regression_outcome, cv=10, scoring=correlation)\nforest_regression_scores = cross_val_score(forest_regression, covariates, regression_outcome, cv=10, scoring=correlation)\nlogistic_regression_scores = cross_val_score(logistic_regression, covariates, classification_outcome, cv=10, scoring=accuracy)\nforest_classification_scores = cross_val_score(forest_classifier, covariates, classification_outcome, cv=10, scoring=accuracy)\n\nnp.mean(forest_regression_scores)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will compute the cross-validated performance for the linear and random forest regression models for positive revenue movies only.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"logistic_regression_scores = cross_val_score(logistic_regression, covariates, classification_outcome, cv=10, scoring=accuracy)\nforest_classification_scores = cross_val_score(forest_classifier, covariates, classification_outcome, cv=10, scoring=accuracy)\n\nplt.axes().set_aspect('equal', 'box')\nplt.scatter(logistic_regression_scores, forest_classification_scores)\nplt.plot((0, 1), (0, 1), 'k-')\nplt.xlim(0, 1)\nplt.ylim(0, 1)\nplt.xlabel(\"Linear Regression Score\")\nplt.ylabel(\"Forest Regression Score\")\n\nplt.show();\n\nforest_classifier.fit(positive_revenue_df[all_covariates], positive_revenue_df[classification_target])\nsorted(list(zip(all_covariates, forest_classifier.feature_importances_)), key=lambda tup: tup[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will compute cross-validated performance for the linear and random forest classification models for positive revenue movies only.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"logistic_regression_scores = cross_val_score(logistic_regression, covariates, classification_outcome, cv=10, scoring=accuracy)\nforest_classification_scores = cross_val_score(forest_classifier, covariates, classification_outcome,cv=10, scoring=accuracy)\n\n# Plot Results\nplt.axes().set_aspect('equal', 'box')\nplt.scatter(logistic_regression_scores, forest_classification_scores)\nplt.plot((0, 1), (0, 1), 'k-')\n\nplt.xlim(0, 1)\nplt.ylim(0, 1)\nplt.xlabel(\"Linear Classification Score\")\nplt.ylabel(\"Forest Classification Score\")\n\n# Show the plot.\nplt.show()\n# Print the importance of each covariate in the random forest classification.\nforest_classifier.fit(positive_revenue_df[all_covariates], classification_outcome)\nfor row in zip(all_covariates, forest_classifier.feature_importances_,):\n        print(row)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}