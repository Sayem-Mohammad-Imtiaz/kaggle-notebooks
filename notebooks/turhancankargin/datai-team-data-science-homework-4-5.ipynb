{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns  # visualization tool\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our aim is to examine Pandas Foundation and Manipulating Data Frames with Pandas","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/suicide-rates-overview-1985-to-2016/master.csv')\ndata.head()  # see first 5 rows","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's build data frames from scratch\n* We can build data frames from csv as we did above.\n* Also we can build dataframe from dictionaries\n* We can use zip() method to returns a list of tuples, where the i-th tuple contains the i-th element from each of the argument sequences or iterables.\n* Adding new column\n* Broadcasting: Create new column and assign a value to entire column","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's create three different lists.\nteam = [\"Fenerbahce\",\"Galatasaray\"]\nteam_value = [\"150M\",\"180M\"]\nlist_label = [\"team\",\"team_value\"]\nlist_col = [team,team_value]\nzipped = list(zip(list_label,list_col))\ndata_dict = dict(zipped)\ndf = pd.DataFrame(data_dict)\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can add new columns.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add new columns\ndf[\"Player_Number\"] = [\"25\",\"23\"]\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Broadcasting\ndf[\"Expenses\"] = 100000000 #Broadcasting entire column\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's visualise our dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting all data \ndata1 = data.loc[:,[\"suicides_no\",\"population\"]]\ndata1.plot()\nplt.show()\n# So confusing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# subplots\ndata1.plot(subplots = True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# scatter plot  \ndata1.plot(kind = \"scatter\",x=\"population\",y = \"suicides_no\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# hist plot  \ndata1.plot(kind = \"hist\",y = \"suicides_no\",range= (0,500),bins = 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=2,ncols=1)\ndata1.plot(kind = \"hist\",y = \"suicides_no\",bins = 50,range= (0,500),ax = axes[0])\ndata1.plot(kind = \"hist\",y = \"suicides_no\",bins = 50,range= (0,500),ax = axes[1],cumulative = True)\nplt.savefig('graph.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"STATISTICAL EXPLORATORY DATA ANALYSIS","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"INDEXING PANDAS TIME SERIES","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"time_list = [\"1985-01-01\",\"2016-12-31\"]\nprint(type(time_list[1])) # As you can see date is string\n# however we want it to be datetime object\ndatetime_object = pd.to_datetime(time_list)\nprint(type(datetime_object))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# close warning\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# In order to practice lets take head of pokemon data and add it a time list\ndata2 = data.head()\ndate_list = [\"1987-01-01\",\"1987-02-01\",\"1987-03-01\",\"1987-04-01\",\"1987-05-01\"]\ndatetime_object = pd.to_datetime(date_list)\ndata2[\"date\"] = datetime_object\n# lets make date as index\ndata2= data2.set_index(\"date\")\ndata2 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data2.loc[\"1987-01-01\"])\nprint(data2.loc[\"1987-01-01\":\"1987-03-01\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RESAMPLING PANDAS TIME SERIES\n* Resampling: statistical method over different time intervals\n* Needs string to specify frequency like \"M\" = month or \"A\" = year\n* Downsampling: reduce date time rows to slower frequency like from daily to weekly\n* Upsampling: increase date time rows to faster frequency like from daily to hourly\n* Interpolate: Interpolate values according to different methods like ‘linear’, ‘time’ or index’","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will use data2 that we create at previous part\ndata2.resample(\"A\").mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets resample with month\ndata2.resample(\"M\").mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# In real life (data is real. Not created from us like data2) we can solve this problem with interpolate\n# We can interpolete from first value\ndata2.resample(\"M\").first().interpolate(\"linear\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Or we can interpolate with mean()\ndata2.resample(\"M\").mean().interpolate(\"linear\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's manipulate DATA FRAMES WITH PANDAS","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# read data\ndata = pd.read_csv('/kaggle/input/suicide-rates-overview-1985-to-2016/master.csv')\ndata= data.set_index(\"year\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# indexing using square brackets\ndata[\"sex\"][1987]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using column attribute and row label\ndata.sex[1987]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using loc accessor\ndata.loc[1987,[\"sex\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Selecting only some columns\ndata[[\"sex\",\"age\"]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"SLICING DATA FRAME","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Difference between selecting columns: series and dataframes\nprint(type(data[\"sex\"]))     # series\nprint(type(data[[\"sex\"]]))   # data frames","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Slicing and indexing series\ndata.loc[:,\"sex\":\"suicides_no\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.loc[::-1,\"sex\":\"suicides_no\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"FILTERING DATA FRAMES","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"boolean = data.suicides_no > 100\ndata[boolean]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"first_filter = data.suicides_no > 200\nsecond_filter = data.population > 1000000\ndata[first_filter & second_filter]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"TRANSFORMING DATA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plain python functions\ndef div(n):\n    return n/2\ndata.suicides_no.apply(div)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Or we can use lambda function\ndata.suicides_no.apply(lambda n : n/2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining column using other columns\ndata[\"Ratio\"] = data.population / data.suicides_no\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# our index name is this:\nprint(data.index.name)\n# lets change it\ndata.index.name = \"index_name\"\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"HIERARCHICAL INDEXING","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets read data frame one more time to start from beginning\ndata = pd.read_csv('/kaggle/input/suicide-rates-overview-1985-to-2016/master.csv')\ndata.head()\n# As you can see there is index. However we want to set one or more column to be index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setting index : type 1 is outer type 2 is inner index\ndata1 = data.set_index([\"country\",\"sex\"]) \ndata1.head(100)\n# data1.loc[\"Fire\",\"Flying\"] # howw to use indexes","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}