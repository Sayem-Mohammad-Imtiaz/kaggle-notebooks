{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip3 install -U segmentation-models\n%env SM_FRAMEWORK=tf.keras\nimport segmentation_models as sm\nimport tensorflow as tf\ntf.keras.backend.set_image_data_format('channels_last')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-09T12:37:33.20993Z","iopub.execute_input":"2021-08-09T12:37:33.21052Z","iopub.status.idle":"2021-08-09T12:37:51.163518Z","shell.execute_reply.started":"2021-08-09T12:37:33.210412Z","shell.execute_reply":"2021-08-09T12:37:51.162104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nimport os\nimport glob\nimport random\nimport time\n\nimport numpy as np\nimport pandas as pd\n\nimport cv2\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nfrom sklearn.model_selection import train_test_split\nfrom segmentation_models import Unet, Linknet, PSPNet, FPN\nimport keras\nfrom segmentation_models.utils import set_trainable\nfrom torch.utils.data import Dataset","metadata":{"execution":{"iopub.status.busy":"2021-08-09T13:08:00.117988Z","iopub.execute_input":"2021-08-09T13:08:00.118512Z","iopub.status.idle":"2021-08-09T13:08:00.125644Z","shell.execute_reply.started":"2021-08-09T13:08:00.118471Z","shell.execute_reply":"2021-08-09T13:08:00.124799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Path to all data\nDATA_PATH = \"/kaggle/input/lgg-mri-segmentation/kaggle_3m/\"\n\n# File path line length images for later sorting\nBASE_LEN = 89 # len(/kaggle/input/lgg-mri-segmentation/kaggle_3m/TCGA_DU_6404_19850629/TCGA_DU_6404_19850629_ <-!!!43.tif)\nEND_IMG_LEN = 4 # len(/kaggle/input/lgg-mri-segmentation/kaggle_3m/TCGA_DU_6404_19850629/TCGA_DU_6404_19850629_43 !!!->.tif)\nEND_MASK_LEN = 9 # (/kaggle/input/lgg-mri-segmentation/kaggle_3m/TCGA_DU_6404_19850629/TCGA_DU_6404_19850629_43 !!!->_mask.tif)\n\n# img size\nIMG_SIZE = 256","metadata":{"execution":{"iopub.status.busy":"2021-08-09T13:08:09.129738Z","iopub.execute_input":"2021-08-09T13:08:09.130377Z","iopub.status.idle":"2021-08-09T13:08:09.134623Z","shell.execute_reply.started":"2021-08-09T13:08:09.130338Z","shell.execute_reply":"2021-08-09T13:08:09.133777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Raw data\ndata_map = []\nfor sub_dir_path in glob.glob(DATA_PATH+\"*\"):\n    if os.path.isdir(sub_dir_path):\n        dirname = sub_dir_path.split(\"/\")[-1]\n        for filename in os.listdir(sub_dir_path):\n            image_path = sub_dir_path + \"/\" + filename\n            data_map.extend([dirname, image_path])\n    else:\n        print(\"This is not a dir:\", sub_dir_path)\n        \n        \ndf = pd.DataFrame({\"dirname\" : data_map[::2],\n                  \"path\" : data_map[1::2]})\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-09T12:53:18.665308Z","iopub.status.idle":"2021-08-09T12:53:18.666203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Dataframe Size: \", len(df))","metadata":{"execution":{"iopub.status.busy":"2021-08-09T11:46:32.466489Z","iopub.execute_input":"2021-08-09T11:46:32.466939Z","iopub.status.idle":"2021-08-09T11:46:32.471842Z","shell.execute_reply.started":"2021-08-09T11:46:32.466908Z","shell.execute_reply":"2021-08-09T11:46:32.471064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Masks/Not masks\ndf_imgs = df[~df['path'].str.contains(\"mask\")]\ndf_masks = df[df['path'].str.contains(\"mask\")]\n\n# Data sorting\nimgs = sorted(df_imgs[\"path\"].values, key=lambda x : int(x[BASE_LEN:-END_IMG_LEN]))\nmasks = sorted(df_masks[\"path\"].values, key=lambda x : int(x[BASE_LEN:-END_MASK_LEN]))\n\n# Sorting check\nidx = random.randint(0, len(imgs)-1)\nprint(\"Path to the Image:\", imgs[idx], \"\\nPath to the Mask:\", masks[idx])","metadata":{"execution":{"iopub.status.busy":"2021-08-09T11:46:32.473103Z","iopub.execute_input":"2021-08-09T11:46:32.473657Z","iopub.status.idle":"2021-08-09T11:46:32.50568Z","shell.execute_reply.started":"2021-08-09T11:46:32.473627Z","shell.execute_reply":"2021-08-09T11:46:32.504683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"length of images: \", len(df_imgs))\nprint(\"length of masks: \", len(df_masks))","metadata":{"execution":{"iopub.status.busy":"2021-08-09T11:46:32.506769Z","iopub.execute_input":"2021-08-09T11:46:32.507045Z","iopub.status.idle":"2021-08-09T11:46:32.511908Z","shell.execute_reply.started":"2021-08-09T11:46:32.507019Z","shell.execute_reply":"2021-08-09T11:46:32.511253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Final dataframe\ndf = pd.DataFrame({\"patient\": df_imgs.dirname.values,\n                       \"image_path\": imgs,\n                   \"mask_path\": masks})\n\n\n# Adding A/B column for diagnosis\ndef positiv_negativ_diagnosis(mask_path):\n    value = np.max(cv2.imread(mask_path))\n    if value > 0 : return 1\n    else: return 0\n\ndf[\"diagnosis\"] = df[\"mask_path\"].apply(lambda m: positiv_negativ_diagnosis(m))\ndf","metadata":{"execution":{"iopub.status.busy":"2021-08-09T11:46:32.513757Z","iopub.execute_input":"2021-08-09T11:46:32.514255Z","iopub.status.idle":"2021-08-09T11:47:00.204994Z","shell.execute_reply.started":"2021-08-09T11:46:32.514179Z","shell.execute_reply":"2021-08-09T11:47:00.204034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot\nax = df.diagnosis.value_counts().plot(kind='bar',\n                                      stacked=True,\n                                      figsize=(10, 6),\n                                     color=[\"violet\", \"lightseagreen\"])\n\n\nax.set_xticklabels([\"Positive\", \"Negative\"], rotation=45, fontsize=12);\nax.set_ylabel('Total Images', fontsize = 12)\nax.set_title(\"Distribution of data grouped by diagnosis\",fontsize = 18, y=1.05)\n\n# Annotate\nfor i, rows in enumerate(df.diagnosis.value_counts().values):\n    ax.annotate(int(rows), xy=(i, rows-12), \n                rotation=0, color=\"white\", \n                ha=\"center\", verticalalignment='bottom', \n                fontsize=15, fontweight=\"bold\")\n    \nax.text(1.2, 2550, f\"Total {len(df)} images\", size=15,\n        color=\"black\",\n         ha=\"center\", va=\"center\",\n         bbox=dict(boxstyle=\"round\",\n                   fc=(\"lightblue\"),\n                   ec=(\"black\"),\n                   )\n         );","metadata":{"execution":{"iopub.status.busy":"2021-08-09T11:47:00.206792Z","iopub.execute_input":"2021-08-09T11:47:00.207367Z","iopub.status.idle":"2021-08-09T11:47:00.439527Z","shell.execute_reply.started":"2021-08-09T11:47:00.207324Z","shell.execute_reply":"2021-08-09T11:47:00.438513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_ben_color(path, sigmaX=10):\n    image = cv2.imread(path)\n    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n    #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    #image = crop_image_from_gray(image)\n    #image=cv2.addWeighted(image,4, cv2.GaussianBlur( image , (0,0) , sigmaX) ,-4 ,128)\n        \n    return image","metadata":{"execution":{"iopub.status.busy":"2021-08-09T11:55:40.430853Z","iopub.execute_input":"2021-08-09T11:55:40.431246Z","iopub.status.idle":"2021-08-09T11:55:40.435932Z","shell.execute_reply.started":"2021-08-09T11:55:40.431214Z","shell.execute_reply":"2021-08-09T11:55:40.435258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data\nsample_yes_df = df[df[\"diagnosis\"] == 1].sample(5).image_path.values\nsample_no_df = df[df[\"diagnosis\"] == 0].sample(5).image_path.values\n\nsample_imgs = []\nfor i, (yes, no) in enumerate(zip(sample_yes_df, sample_no_df)):\n    yes = cv2.resize(cv2.imread(yes), (IMG_SIZE, IMG_SIZE))\n    no = cv2.resize(cv2.imread(no), (IMG_SIZE, IMG_SIZE))\n    sample_imgs.extend([yes, no])\n\n\nsample_yes_arr = np.vstack(np.array(sample_imgs[::2]))\nsample_no_arr = np.vstack(np.array(sample_imgs[1::2]))\n\n# Plot\nfig = plt.figure(figsize=(25., 25.))\ngrid = ImageGrid(fig, 111,  # similar to subplot(111)\n                 nrows_ncols=(1, 4),  # creates 2x2 grid of axes\n                 axes_pad=0.1,  # pad between axes in inch.\n                 )\n\n\ngrid[0].imshow(sample_yes_arr)\ngrid[0].set_title(\"Positive\", fontsize=15)\ngrid[0].axis(\"off\")\ngrid[1].imshow(sample_no_arr)\ngrid[1].set_title(\"Negative\", fontsize=15)\ngrid[1].axis(\"off\")\n\ngrid[2].imshow(sample_yes_arr[:,:,0], cmap=\"hot\")\ngrid[2].set_title(\"Positive\", fontsize=15)\ngrid[2].axis(\"off\")\ngrid[3].imshow(sample_no_arr[:,:,0], cmap=\"hot\")\ngrid[3].set_title(\"Negative\", fontsize=15)\ngrid[3].axis(\"off\")#set_title(\"No\", fontsize=15)\n\n# annotations\nplt.figtext(0.36,0.90,\"Original\", va=\"center\", ha=\"center\", size=20)\nplt.figtext(0.66,0.90,\"With hot colormap\", va=\"center\", ha=\"center\", size=20)\nplt.suptitle(\"Brain MRI Images for Brain Tumor Detection\\nLGG Segmentation Dataset\", y=.95, fontsize=30, weight=\"bold\")\n\n# save and show\nplt.savefig(\"dataset.png\", bbox_inches='tight', pad_inches=0.2, transparent=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-09T11:47:00.446884Z","iopub.execute_input":"2021-08-09T11:47:00.447332Z","iopub.status.idle":"2021-08-09T11:47:03.132689Z","shell.execute_reply.started":"2021-08-09T11:47:00.447303Z","shell.execute_reply":"2021-08-09T11:47:03.131519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data\nsample_df = df[df[\"diagnosis\"] == 1].sample(5).values\nsample_imgs = []\nfor i, data in enumerate(sample_df):\n    #print(data)\n    img = cv2.resize(cv2.imread(data[1]), (IMG_SIZE, IMG_SIZE))\n    mask = cv2.resize(cv2.imread(data[2]), (IMG_SIZE, IMG_SIZE))\n    sample_imgs.extend([img, mask])\n\n\nsample_imgs_arr = np.hstack(np.array(sample_imgs[::2]))\nsample_masks_arr = np.hstack(np.array(sample_imgs[1::2]))\n\n# Plot\nfig = plt.figure(figsize=(25., 25.))\ngrid = ImageGrid(fig, 111,  # similar to subplot(111)\n                 nrows_ncols=(2, 1),  # creates 2x2 grid of axes\n                 axes_pad=0.1,  # pad between axes in inch.\n                 )\n\n\ngrid[0].imshow(sample_imgs_arr)\ngrid[0].set_title(\"Images\", fontsize=15)\ngrid[0].axis(\"off\")\ngrid[1].imshow(sample_masks_arr)\ngrid[1].set_title(\"Masks\", fontsize=15, y=0.9)\ngrid[1].axis(\"off\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-09T11:47:03.134534Z","iopub.execute_input":"2021-08-09T11:47:03.134962Z","iopub.status.idle":"2021-08-09T11:47:03.768076Z","shell.execute_reply.started":"2021-08-09T11:47:03.134922Z","shell.execute_reply":"2021-08-09T11:47:03.766977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data\nsample_df = df[df[\"diagnosis\"] == 1].sample(5).values\nsample_imgs = []\nfor i, data in enumerate(sample_df):\n    #print(data)\n    img = load_ben_color(data[1])\n    mask = cv2.resize(cv2.imread(data[2]), (IMG_SIZE, IMG_SIZE))\n    sample_imgs.extend([img, mask])\n\n\nsample_imgs_arr = np.hstack(np.array(sample_imgs[::2]))\nsample_masks_arr = np.hstack(np.array(sample_imgs[1::2]))\n\n# Plot\nfig = plt.figure(figsize=(25., 25.))\ngrid = ImageGrid(fig, 111,  # similar to subplot(111)\n                 nrows_ncols=(2, 1),  # creates 2x2 grid of axes\n                 axes_pad=0.1,  # pad between axes in inch.\n                 )\n\n\ngrid[0].imshow(sample_imgs_arr)\ngrid[0].set_title(\"Images\", fontsize=15)\ngrid[0].axis(\"off\")\ngrid[1].imshow(sample_masks_arr)\ngrid[1].set_title(\"Masks\", fontsize=15, y=0.9)\ngrid[1].axis(\"off\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-09T11:47:03.76966Z","iopub.execute_input":"2021-08-09T11:47:03.77008Z","iopub.status.idle":"2021-08-09T11:47:04.444164Z","shell.execute_reply.started":"2021-08-09T11:47:03.77004Z","shell.execute_reply":"2021-08-09T11:47:04.443007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split df into train_df and val_df\ntrain_df, val_df = train_test_split(df, stratify=df.diagnosis, test_size=0.1, shuffle=True)\ntrain_df = train_df.reset_index(drop=True)\nval_df = val_df.reset_index(drop=True)\n\n# Split train_df into train_df and test_df\ntrain_df, test_df = train_test_split(train_df, stratify=train_df.diagnosis, test_size=0.15)\ntrain_df = train_df.reset_index(drop=True)\n\n#train_df = train_df[:1000]\nprint(f\"Train: {train_df.shape} \\nVal: {val_df.shape} \\nTest: {test_df.shape}\")","metadata":{"execution":{"iopub.status.busy":"2021-08-09T11:47:04.4473Z","iopub.execute_input":"2021-08-09T11:47:04.447678Z","iopub.status.idle":"2021-08-09T11:47:04.467868Z","shell.execute_reply.started":"2021-08-09T11:47:04.447642Z","shell.execute_reply":"2021-08-09T11:47:04.466869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def normalizing(img):\n    norm = cv2.normalize(img, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n    return norm","metadata":{"execution":{"iopub.status.busy":"2021-08-09T11:47:04.469388Z","iopub.execute_input":"2021-08-09T11:47:04.469691Z","iopub.status.idle":"2021-08-09T11:47:04.474346Z","shell.execute_reply.started":"2021-08-09T11:47:04.469656Z","shell.execute_reply":"2021-08-09T11:47:04.47353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations.pytorch.transforms import ToTensor","metadata":{"execution":{"iopub.status.busy":"2021-08-09T11:47:04.475497Z","iopub.execute_input":"2021-08-09T11:47:04.47593Z","iopub.status.idle":"2021-08-09T11:47:05.356274Z","shell.execute_reply.started":"2021-08-09T11:47:04.475872Z","shell.execute_reply":"2021-08-09T11:47:05.355513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATCH_SIZE = 256\n\nstrong_transforms = A.Compose([\n    A.RandomResizedCrop(width = PATCH_SIZE, height = PATCH_SIZE, p=1.0),\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.5),\n    A.RandomRotate90(p=0.5),\n    A.Transpose(p=0.5),\n    A.ShiftScaleRotate(shift_limit=0.01, scale_limit=0.04, rotate_limit=0, p=0.25),\n    \n    # Pixels\n    A.RandomBrightnessContrast(p=0.5),\n    A.RandomGamma(p=0.25),\n    A.IAAEmboss(p=0.25),\n    A.Blur(p=0.01, blur_limit = 3),\n    \n    # Affine\n    A.OneOf([\n        A.ElasticTransform(p=0.5, alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n        A.GridDistortion(p=0.5),\n        A.OpticalDistortion(p=1, distort_limit=2, shift_limit=0.5)                  \n    ], p=0.8),\n    \n    \n    A.Normalize(p=1.0),\n    #https://albumentations.readthedocs.io/en/latest/api/pytorch.html?highlight=ToTensor#albumentations.pytorch.transforms.ToTensor\n    ToTensorV2(),\n])\n\n\ntransforms = A.Compose([\n    A.Resize(width = PATCH_SIZE, height = PATCH_SIZE, p=1.0),\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.5),\n    A.RandomRotate90(p=0.5),\n    A.Transpose(p=0.5),\n    A.ShiftScaleRotate(shift_limit=0.01, scale_limit=0.04, rotate_limit=0, p=0.25),\n\n    \n    \n    #A.Normalize(p=1.0),\n])","metadata":{"execution":{"iopub.status.busy":"2021-08-09T11:47:05.357382Z","iopub.execute_input":"2021-08-09T11:47:05.357792Z","iopub.status.idle":"2021-08-09T11:47:05.370122Z","shell.execute_reply.started":"2021-08-09T11:47:05.357751Z","shell.execute_reply":"2021-08-09T11:47:05.36924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Dataloder(keras.utils.Sequence):\n    \"\"\"Load data from dataset and form batches\n    \n    Args:\n        dataset: instance of Dataset class for image loading and preprocessing.\n        batch_size: Integet number of images in batch.\n        shuffle: Boolean, if `True` shuffle image indexes each epoch.\n    \"\"\"\n    \n    def __init__(self, dataset, batch_size=1, shuffle=False):\n        self.dataset = dataset\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.indexes = np.arange(len(dataset))\n\n        self.on_epoch_end()\n\n    def __getitem__(self, i):\n        \n        # collect batch data\n        start = i * self.batch_size\n        stop = (i + 1) * self.batch_size\n        data = []\n        for j in range(start, stop):\n            data.append(self.dataset[j])\n        \n        # transpose list of lists\n        batch = [np.stack(samples, axis=0) for samples in zip(*data)]\n        \n        # newer version of tf/keras want batch to be in tuple rather than list\n        return tuple(batch)\n    \n    def __len__(self):\n        \"\"\"Denotes the number of batches per epoch\"\"\"\n        return len(self.indexes) // self.batch_size\n    \n    def on_epoch_end(self):\n        \"\"\"Callback function to shuffle indexes each epoch\"\"\"\n        if self.shuffle:\n            self.indexes = np.random.permutation(self.indexes)","metadata":{"execution":{"iopub.status.busy":"2021-08-09T11:47:05.371699Z","iopub.execute_input":"2021-08-09T11:47:05.372137Z","iopub.status.idle":"2021-08-09T11:47:05.382549Z","shell.execute_reply.started":"2021-08-09T11:47:05.372095Z","shell.execute_reply":"2021-08-09T11:47:05.381486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BrainMriDataset(Dataset):\n    def __init__(self, df, transforms, preprocessing=None):\n        \n        self.df = df\n        self.transforms = transforms\n        self.preprocessing = preprocessing\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        image = load_ben_color(self.df.iloc[idx, 1])\n        mask = cv2.imread(self.df.iloc[idx, 2], 0)\n        mask = normalizing(mask)\n        \n        if self.preprocessing:\n            image = self.preprocessing(image)\n            \n        augmented = self.transforms(image=image, \n                                    mask=mask)\n \n        image = augmented['image']\n        mask = augmented['mask']\n        \n        \n        \n        return image, mask","metadata":{"execution":{"iopub.status.busy":"2021-08-09T11:55:56.902814Z","iopub.execute_input":"2021-08-09T11:55:56.903391Z","iopub.status.idle":"2021-08-09T11:55:56.911124Z","shell.execute_reply.started":"2021-08-09T11:55:56.903358Z","shell.execute_reply":"2021-08-09T11:55:56.910109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# helper function for data visualization\ndef visualize(**images):\n    \"\"\"PLot images in one row.\"\"\"\n    n = len(images)\n    plt.figure(figsize=(16, 5))\n    for i, (name, image) in enumerate(images.items()):\n        plt.subplot(1, n, i + 1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.title(' '.join(name.split('_')).title())\n        plt.imshow(image)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-09T11:55:57.875686Z","iopub.execute_input":"2021-08-09T11:55:57.876156Z","iopub.status.idle":"2021-08-09T11:55:57.882094Z","shell.execute_reply.started":"2021-08-09T11:55:57.876128Z","shell.execute_reply":"2021-08-09T11:55:57.881378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BACKBONE = 'resnext50'\npreprocess_input = sm.get_preprocessing(BACKBONE)\n\n# define network parameters\nn_classes = 1 # case for binary and multiclass segmentation\nactivation = 'sigmoid'\n\n#create model\nmodel = sm.Unet(BACKBONE, classes=n_classes, activation=activation, encoder_weights=None, encoder_freeze=True)\n\n# define optomizer\noptim = keras.optimizers.Adam(0.001)\n\n# Segmentation models losses can be combined together by '+' and scaled by integer or float factor\n#dice_loss = sm.losses.DiceLoss()\n#focal_loss = sm.losses.BinaryFocalLoss()\n#total_loss = dice_loss + (1 * focal_loss)\n\n# actulally total_loss can be imported directly from library, above example just show you how to manipulate with losses\ntotal_loss = sm.losses.binary_focal_dice_loss # or sm.losses.categorical_focal_dice_loss \n\nmetrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n\n# compile keras model with defined optimozer, loss and metrics\nmodel.compile(optim, total_loss, metrics)","metadata":{"execution":{"iopub.status.busy":"2021-08-09T11:55:59.034422Z","iopub.execute_input":"2021-08-09T11:55:59.03479Z","iopub.status.idle":"2021-08-09T11:56:05.735778Z","shell.execute_reply.started":"2021-08-09T11:55:59.03476Z","shell.execute_reply":"2021-08-09T11:56:05.734743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train\ntrain_dataset = BrainMriDataset(df=train_df, transforms=transforms, preprocessing=preprocess_input)\ntrain_dataloader = Dataloder(train_dataset, batch_size=26, shuffle=True)\n\n# val\nval_dataset = BrainMriDataset(df=val_df, transforms=transforms, preprocessing=preprocess_input)\nval_dataloader = Dataloder(val_dataset, batch_size=26, shuffle=True)\n\n#test\ntest_dataset = BrainMriDataset(df=test_df, transforms=transforms, preprocessing=preprocess_input)\ntest_dataloader = Dataloder(test_dataset, batch_size=26, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-09T11:56:05.737346Z","iopub.execute_input":"2021-08-09T11:56:05.73772Z","iopub.status.idle":"2021-08-09T11:56:05.74639Z","shell.execute_reply.started":"2021-08-09T11:56:05.737679Z","shell.execute_reply":"2021-08-09T11:56:05.743404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-08-09T11:54:07.94869Z","iopub.execute_input":"2021-08-09T11:54:07.949273Z","iopub.status.idle":"2021-08-09T11:54:07.960479Z","shell.execute_reply.started":"2021-08-09T11:54:07.94923Z","shell.execute_reply":"2021-08-09T11:54:07.959685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train model\nhistory = model.fit(\n    train_dataloader, \n    steps_per_epoch=len(train_dataloader), \n    epochs=40, \n    validation_data=val_dataloader, \n    validation_steps=len(val_dataloader),\n)","metadata":{"execution":{"iopub.status.busy":"2021-08-09T12:00:06.566179Z","iopub.execute_input":"2021-08-09T12:00:06.566556Z","iopub.status.idle":"2021-08-09T12:01:44.989463Z","shell.execute_reply.started":"2021-08-09T12:00:06.566528Z","shell.execute_reply":"2021-08-09T12:01:44.987347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot training & validation iou_score values\nplt.figure(figsize=(30, 5))\nplt.subplot(121)\nplt.plot(history.history['iou_score'])\nplt.plot(history.history['val_iou_score'])\nplt.title('Model iou_score')\nplt.ylabel('iou_score')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\n\n# Plot training & validation loss values\nplt.subplot(122)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = model.evaluate(test_dataloader)\n\nprint(\"Loss: {:.5}\".format(scores[0]))\nfor metric, value in zip(metrics, scores[1:]):\n    print(\"mean {}: {:.5}\".format(metric.__name__, value))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_weights(\"weights-BrainMriSegmentation-UNet+ResNext50.hdf5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.save('UNet+ResNext50_history.npy',history.history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model.load_weights('')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n = 5\nids = np.random.choice(np.arange(len(test_dataset)), size=n)\n\nfor i in ids:\n    \n    image, gt_mask = test_dataset[i]\n    image = np.expand_dims(image, axis=0)\n    pr_mask = model.predict(image).round()\n    \n    visualize(\n        image=image.squeeze(),\n        gt_mask=gt_mask.squeeze(),\n        pr_mask=pr_mask.squeeze(),\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BACKBONE = 'resnet50'\npreprocess_input = sm.get_preprocessing(BACKBONE)\n\n# define network parameters\nn_classes = 1 # case for binary and multiclass segmentation\nactivation = 'sigmoid'\n\n#create model\nmodel = sm.Unet(BACKBONE, classes=n_classes, activation=activation, encoder_weights=None, encoder_freeze=True)\n\n# define optomizer\noptim = keras.optimizers.Adam(0.001)\n\n# Segmentation models losses can be combined together by '+' and scaled by integer or float factor\n#dice_loss = sm.losses.DiceLoss()\n#focal_loss = sm.losses.BinaryFocalLoss()\n#total_loss = dice_loss + (1 * focal_loss)\n\n# actulally total_loss can be imported directly from library, above example just show you how to manipulate with losses\ntotal_loss = sm.losses.binary_focal_dice_loss # or sm.losses.categorical_focal_dice_loss \n\nmetrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n\n# compile keras model with defined optimozer, loss and metrics\nmodel.compile(optim, total_loss, metrics)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train\ntrain_dataset = BrainMriDataset(df=train_df, transforms=transforms, preprocessing=preprocess_input)\ntrain_dataloader = Dataloder(train_dataset, batch_size=26, shuffle=True)\n\n# val\nval_dataset = BrainMriDataset(df=val_df, transforms=transforms, preprocessing=preprocess_input)\nval_dataloader = Dataloder(val_dataset, batch_size=26, shuffle=True)\n\n#test\ntest_dataset = BrainMriDataset(df=test_df, transforms=transforms, preprocessing=preprocess_input)\ntest_dataloader = Dataloder(test_dataset, batch_size=26, shuffle=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train model\nhistory = model.fit(\n    train_dataloader, \n    steps_per_epoch=len(train_dataloader), \n    epochs=40, \n    validation_data=val_dataloader, \n    validation_steps=len(val_dataloader),\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot training & validation iou_score values\nplt.figure(figsize=(30, 5))\nplt.subplot(121)\nplt.plot(history.history['iou_score'])\nplt.plot(history.history['val_iou_score'])\nplt.title('Model iou_score')\nplt.ylabel('iou_score')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\n\n# Plot training & validation loss values\nplt.subplot(122)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = model.evaluate(test_dataloader)\n\nprint(\"Loss: {:.5}\".format(scores[0]))\nfor metric, value in zip(metrics, scores[1:]):\n    print(\"mean {}: {:.5}\".format(metric.__name__, value))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_weights(\"weights-BrainMriSegmentation-UNet+ResNet50.hdf5\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.save('UNet+ResNet50_history.npy',history.history)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n = 5\nids = np.random.choice(np.arange(len(test_dataset)), size=n)\n\nfor i in ids:\n    \n    image, gt_mask = test_dataset[i]\n    image = np.expand_dims(image, axis=0)\n    pr_mask = model.predict(image).round()\n    \n    visualize(\n        image=image.squeeze(),\n        gt_mask=gt_mask.squeeze(),\n        pr_mask=pr_mask.squeeze(),\n    )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BACKBONE = 'inceptionv3'\npreprocess_input = sm.get_preprocessing(BACKBONE)\n\n# define network parameters\nn_classes = 1 # case for binary and multiclass segmentation\nactivation = 'sigmoid'\n\n#create model\nmodel = sm.Unet(BACKBONE, classes=n_classes, activation=activation, encoder_weights=None, encoder_freeze=True)\n\n# define optomizer\noptim = keras.optimizers.Adam(0.001)\n\n# Segmentation models losses can be combined together by '+' and scaled by integer or float factor\n#dice_loss = sm.losses.DiceLoss()\n#focal_loss = sm.losses.BinaryFocalLoss()\n#total_loss = dice_loss + (1 * focal_loss)\n\n# actulally total_loss can be imported directly from library, above example just show you how to manipulate with losses\ntotal_loss = sm.losses.binary_focal_dice_loss # or sm.losses.categorical_focal_dice_loss \n\nmetrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n\n# compile keras model with defined optimozer, loss and metrics\nmodel.compile(optim, total_loss, metrics)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train\ntrain_dataset = BrainMriDataset(df=train_df, transforms=transforms, preprocessing=preprocess_input)\ntrain_dataloader = Dataloder(train_dataset, batch_size=26, shuffle=True)\n\n# val\nval_dataset = BrainMriDataset(df=val_df, transforms=transforms, preprocessing=preprocess_input)\nval_dataloader = Dataloder(val_dataset, batch_size=26, shuffle=True)\n\n#test\ntest_dataset = BrainMriDataset(df=test_df, transforms=transforms, preprocessing=preprocess_input)\ntest_dataloader = Dataloder(test_dataset, batch_size=26, shuffle=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train model\nhistory = model.fit(\n    train_dataloader, \n    steps_per_epoch=len(train_dataloader), \n    epochs=40, \n    validation_data=val_dataloader, \n    validation_steps=len(val_dataloader),\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot training & validation iou_score values\nplt.figure(figsize=(30, 5))\nplt.subplot(121)\nplt.plot(history.history['iou_score'])\nplt.plot(history.history['val_iou_score'])\nplt.title('Model iou_score')\nplt.ylabel('iou_score')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\n\n# Plot training & validation loss values\nplt.subplot(122)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = model.evaluate(test_dataloader)\n\nprint(\"Loss: {:.5}\".format(scores[0]))\nfor metric, value in zip(metrics, scores[1:]):\n    print(\"mean {}: {:.5}\".format(metric.__name__, value))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_weights(\"weights-BrainMriSegmentation-UNet+InceptionV3.hdf5\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.save('UNet+InceptionV3_history.npy',history.history)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n = 5\nids = np.random.choice(np.arange(len(test_dataset)), size=n)\n\nfor i in ids:\n    \n    image, gt_mask = test_dataset[i]\n    image = np.expand_dims(image, axis=0)\n    pr_mask = model.predict(image).round()\n    \n    visualize(\n        image=image.squeeze(),\n        gt_mask=gt_mask.squeeze(),\n        pr_mask=pr_mask.squeeze(),\n    )","metadata":{},"execution_count":null,"outputs":[]}]}