{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import mean_absolute_error\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/ibm-hr-analytics-attrition-dataset/WA_Fn-UseC_-HR-Employee-Attrition.csv')\nNum_val = {'Yes':1, 'No':0}\ndata['Attrition'] = data['Attrition'].apply(lambda x: Num_val[x])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nfrom matplotlib import pyplot as plt\ncorr = data.corr()\nplt.figure(figsize=(17,17))\n\nax = sns.heatmap(\n    corr, vmin=-1, vmax = 1, center = 0, cmap=sns.diverging_palette(2,220,n=200),\n    square = True)\nax.set_xticklabels(\n    ax.get_xticklabels(), \n    rotation = 45,\n    horizontalalignment='right')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop([], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nfrom matplotlib import pyplot as plt\ncorr = data.corr()\nplt.figure(figsize=(17,17))\n\nax = sns.heatmap(corr, vmin=-1, vmax = 1, center = 0, cmap=sns.diverging_palette(2,220,n=200),square = True)\nax.set_xticklabels(\n    ax.get_xticklabels(), \n    rotation = 45,\n    horizontalalignment='right')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dependent = data.Attrition\ndata = data.drop(['Attrition'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('nr columns: '+str(len(data.columns)))\nprint('nr rows:' + str(len(data)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_data = data.select_dtypes(include='object')\ncategorical_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.linear_model import LogisticRegression\n\n# Function for comparing different approaches\ndef score_dataset_random_forest(X_train, X_valid, y_train, y_valid):\n    model = RandomForestRegressor(n_estimators=100, random_state=0)\n    model.fit(X_train, y_train)\n    preds = model.predict(X_valid)\n    return mean_absolute_error(y_valid, preds)\n\ndef score_dataset_XG_boost(X_train, X_valid, y_train, y_valid):\n    model = XGBRegressor(n_estimators=1000, learning_rate=0.05, n_jobs=4)\n    model.fit(X_train, y_train, \n             early_stopping_rounds=5, \n             eval_set=[(X_valid, y_valid)], \n             verbose=False)\n    preds = model.predict(X_valid)\n    return mean_absolute_error(y_valid, preds)\n\ndef score_dataset_logistic(X_train, X_valid, y_train, y_valid):\n    model = LogisticRegression(verbose = 3)\n    model.fit(X_train, y_train)\n    preds = model.predict(X_valid)\n    return mean_absolute_error(y_valid, preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_valid_full, y_train, y_valid_full = train_test_split(data, dependent, train_size=0.8, test_size=0.2,\n                                                                random_state=0)\n\nX_valid, X_test, y_valid, y_test = train_test_split(X_valid_full, y_valid_full, train_size=0.5, test_size=0.5,\n                                                                random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_cols = [cname for cname in X_train.columns if\n                    X_train[cname].nunique() < 10 and \n                    X_train[cname].dtype == \"object\"]\n\n# Select numerical columns\nnumerical_cols = [cname for cname in X_train.columns if \n                X_train[cname].dtype in ['int64', 'float64']]\n\nnumerical_transformer = SimpleImputer(strategy = 'constant')\n\ncategorical_transformer = Pipeline(steps = [\n    ('imputer', SimpleImputer(strategy = 'most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown = 'ignore'))\n])\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, numerical_cols),\n        ('cat', categorical_transformer, categorical_cols)\n    ])\n\nmodel = LogisticRegression(max_iter = 1000, verbose = 3)\n\nmy_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                             ('model', model)\n                             ])\n\nmy_pipeline.fit(X_train, y_train)\npreds = my_pipeline.predict(X_valid)\nscore = mean_absolute_error(y_valid, preds)\nprint('MAE: ', score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_pipeline.score(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_pipeline.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\n\npredictions=my_pipeline.predict(X_test)\nprint(classification_report(y_test,predictions))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport numpy as np\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n        print(cm)\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0])\n                                  , range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")    \n        plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')#Generating the Confusion Matrix\n\n    \nplt.figure()\ncm = np.array([[252, 1], [31, 10]])\nplot_confusion_matrix(confusion_matrix(y_test,predictions), \n                      classes=[0,1], normalize=True, title='Normalized Confusion Matrix')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve\nfrom sklearn.metrics import auc\nimport pylab as pl\n\ny_roc = np.array(y_test)\nfpr, tpr, thresholds = roc_curve(y_roc, my_pipeline.decision_function(X_test))\nroc_auc = auc(fpr, tpr)\npl.clf()\npl.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\npl.plot([0, 1], [0, 1], 'k--')\npl.xlim([0.0, 1.0])\npl.ylim([0.0, 1.0])\npl.xlabel('False Positive Rate')\npl.ylabel('True Positive Rate')\npl.legend(loc=\"lower right\")\npl.show() # Output shown below","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}