{"cells":[{"metadata":{"_cell_guid":"b91a74ba-85f4-486e-b5f9-d0898f0626bf","_uuid":"6ac53f18b4f4ec0fc44348cedb5d1c319fa127c0"},"cell_type":"markdown","source":"Welcome to day 1 of the 5-Day Data Challenge! Today, we're going to be looking at how to deal with missing values. To get started, click the blue \"Fork Notebook\" button in the upper, right hand corner. This will create a private copy of this notebook that you can edit and play with. Once you're finished with the exercises, you can choose to make your notebook public to share with others. :)\n\nHere's what we're going to do today:\n\n* [Take a first look at the data](#Take-a-first-look-at-the-data)\n* [See how many missing data points we have](#See-how-many-missing-data-points-we-have)\n* [Figure out why the data is missing](#Figure-out-why-the-data-is-missing)\n* [Drop missing values](#Drop-missing-values)\n* [Filling in missing values](#Filling-in-missing-values)\n\nLet's get started!"},{"metadata":{"_cell_guid":"5cd5061f-ae30-4837-a53b-690ffd5c5830","_uuid":"9d82bf13584b8e682962fbb96131f2447d741679"},"cell_type":"markdown","source":"# Take a first look at the data\n________\n\nThe first thing we'll need to do is load in the libraries and datasets we'll be using. For today, I'll be using a dataset of events that occured in American Football games for demonstration, and you'll be using a dataset of building permits issued in San Francisco.\n\n> **Important!** Make sure you run this cell yourself or the rest of your code won't work!"},{"metadata":{"_cell_guid":"135a7804-b5f5-40aa-8657-4a15774e3666","_uuid":"835cbe0834b935fb0fd40c75b9c39454836f4d5f","scrolled":true,"trusted":true},"cell_type":"code","source":"# modules we'll use\nimport pandas as pd\nimport numpy as np\n\n# read in all our data\n#nfl_data = pd.read_csv(\"../input/nflplaybyplay2009to2016/NFL Play by Play 2009-2017 (v4).csv\") This is demo data set, comments it\nsf_permits = pd.read_csv(\"../input/building-permit-applications-data/Building_Permits.csv\")\n\n# set seed for reproducibility\nnp.random.seed(0) \nprint(sf_permits.shape)","execution_count":61,"outputs":[]},{"metadata":{"_uuid":"6c7332315206170eb7e3c5c14ad3cf8548eaf404"},"cell_type":"markdown","source":"Note: \n   The San Francisco Building Permits data set has:\n    1. 198,900 rows(or call samples)\n    2. 43 columns( or call features )\n    It is first glance of the dataset. we know how big the dataset is."},{"metadata":{"_cell_guid":"8dca377c-95be-40ec-87dc-61a8fca750e2","_uuid":"e389495bb2e5d27ab632d5f3648ca1f912c94706","trusted":true},"cell_type":"code","source":"# your turn! Look at a couple of rows from the sf_permits dataset. Do you notice any missing data?\nsf_permits.sample(5)\n# your code goes here :)","execution_count":9,"outputs":[]},{"metadata":{"_cell_guid":"33656c2b-a74e-4b76-9af2-d7ecd518577b","_uuid":"400b025f618cc76a39fec2537193f28ba1e49168"},"cell_type":"markdown","source":"# See how many missing data points we have\n___\n\nOk, now we know that we do have some missing values. Let's see how many we have in each column. "},{"metadata":{"_cell_guid":"f20a9474-41ee-4ecd-a2f4-1ab147fc8655","_uuid":"64487760aa1afaaa8b8a4d1f95206773759db101","trusted":true},"cell_type":"code","source":"# your turn! Find out what percent of the sf_permits dataset is missing\nsf_col_missing_count = sf_permits.isnull().sum()\nsf_col_nomissing_count = sf_permits.notnull().sum()\nsf_col_count = pd.DataFrame({\"Valid\":sf_col_nomissing_count,\"Missing\":sf_col_missing_count})","execution_count":288,"outputs":[]},{"metadata":{"_uuid":"6b43377d8f96458f7a629e748ed0d9f64009929b"},"cell_type":"markdown","source":"# Understanding the missing data percentage by picture\n"},{"metadata":{"trusted":true,"_uuid":"7c8d4173441662bfd53efc0b0748a724c16738ac"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_context(\"poster\")\n\nfig,ax = plt.subplots(1,2,figsize=(20,5))\nsf_col_count.sum().plot.pie(autopct='%.2f',ax=ax[0]) #show the missing celss percentage\nax[0].set_title(\"Missing data percentage in cell's qty\")\n\n\nIsMissingData_cols = sf_col_count.Missing>0\nsns.countplot(IsMissingData_cols,ax=ax[1])\n#tmp_col_counter = (sf_col_count>0).sum()  #get the columns number which missing data\n#tmp_col_counter.plot.pie(autopct='%.2f',ax=ax[1]) #show the percentage of columns with missing data vs total columns\nax[1].set_title(\"Missing data column's qty\")\nprint(\"Missing Data columns qty is {0}\".format(IsMissingData_cols.sum()))\n","execution_count":110,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"f276080502c65ae1b39c525eff3089edee085535"},"cell_type":"code","source":"\nax = sf_col_count.sort_values(by=\"Missing\",ascending =False).plot.bar(stacked=True,figsize = (20,5),rot=-30)\nax.set_title(\"Dataset Missing numbers - San Francisco Building Permits \")","execution_count":220,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b29a7e72743279a92c742f6f06d0067f6343cc93"},"cell_type":"code","source":"    sf_col_count[\"Missing\"].sort_values().tail(5)","execution_count":228,"outputs":[]},{"metadata":{"_uuid":"ddfbf9b33edc0d60a8848733952a715496e183a5"},"cell_type":"markdown","source":"Note: \n\n* . **26% cells** are missing data in total 189,900 * 43 cells.\n* .** 31 columns** contains missing data in total 43 columsn\n      * the top 5 missing columns are:  \"TIDF Compliance\",\" Voluntary Soft-Story Retrofit\", \"Unit Suffix\", \"Street Number Suffix\", \"Site Permit\". They are almost all missing value    \n         \n\n\n**Next action:**\nconsideration the missing data percentage is higher than 10%. It could not be drop directly.\n\n**Reference from Multivariate Data Analysis  chapter 2 : examining your data**\n**How Much Missing Data Is Too Much?**\n* Missing data **under 10 percent **for an individual case or observation can generally be ignored,  **except** when the missing data occurs in a **specific nonrandom fashion** (e.g., concentration in a specific set of questions, attrition at the end of the questionnaire, etc.) [19, 20]\n* The number of cases with no missing data **must be sufficient for the selected analysis technique** if replacement values will not be substituted (imputed) for the missing data"},{"metadata":{"_cell_guid":"62b9f021-5b80-43e2-bf60-8e0d5e22d572","_uuid":"032a618abb98a28e60ab84376cf21402178f995d"},"cell_type":"markdown","source":"# Figure out why the data is missing\n____\n \n> **Is this value missing becuase it wasn't recorded or becuase it dosen't exist?**"},{"metadata":{"_uuid":"ce36a9a363aa7995cfb50583d34271106d6c2329"},"cell_type":"markdown","source":"## Your turn!\n\n* Look at the columns `Street Number Suffix` and `Zipcode` from the `sf_permits` datasets. Both of these contain missing values. Which, if either, of these are missing because they don't exist? Which, if either, are missing because they weren't recorded?"},{"metadata":{"trusted":true,"_uuid":"a094ada4ecdb2dab9e3a5ef653770293a0a4a2ca"},"cell_type":"code","source":"check_cols =[\"Street Number Suffix\",\"Zipcode\"]\nsf_permits[check_cols].sample(5)","execution_count":134,"outputs":[]},{"metadata":{"_uuid":"541b8a6fc54dd74ea123f66ac39ebb75ee8557c5"},"cell_type":"markdown","source":"Note：  Per randome sampling, we found \n* almost all \"Street Number Suffix\" is NaN. That means missing Value. \n* (almost, depends ) No missing value found in zipcode sample.(for this time)\n\nNext actions:\n## check the  extent of missing data"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"trusted":true,"_uuid":"c1df34de3e961f654862f13cb7c699b2cd3888a3"},"cell_type":"code","source":"fig,ax = plt.subplots(1,1,figsize = (10,5))\nax =sf_col_count.loc[check_cols].T.plot.pie(subplots=True,legend=False,\n                                        autopct='%.2f',fontsize=10,                                        \n                                       #labels=[\"\",\"\"],\n                                       startangle=90,ax=ax)","execution_count":268,"outputs":[]},{"metadata":{"_uuid":"7f531f637f7e59fd0ec8da236c2e9075b2fb8a25"},"cell_type":"markdown","source":"Note:\n1. Stree number Suffix column has more than 99% data missing\n2. Zipcode columns has less than 0.9% data missing\n\nTo explore the missing data, the first step is to know if the missing date is ignorabe or Non-ignorable: \n* **ignorable missing data,** they are often  expected to be missing and in the control of  research design.  considering the almost all missing of \"Street number Suffix\", it might be ignorable missing data. \n* **non-ignorable missing data**, they are procedural factors, for example, data entry error, failure to complete all questionair, restriction and etc. Considering the tiny part missing data of \"Zipcod\", it might be non-ignorable missing data \nAnyway, we need to check data dictionary to verify assumption above. \n\nNext Action: \n\n## check the data dictionary"},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"6cd5c8cb7c76810c9dd556bc668fa948a257d9c5"},"cell_type":"code","source":"Data_Dictionary = pd.read_excel(\"../input/building-permit-applications-data/DataDictionaryBuildingPermit.xlsx\")\n\nmask = Data_Dictionary[\"Column name\"].isin( check_cols)\nprint(Data_Dictionary[mask])","execution_count":133,"outputs":[]},{"metadata":{"_uuid":"83d4bd02154d0ed6b6cfe1792c57b35eb96a1973"},"cell_type":"markdown","source":"Note：\nPer check dictionalry description,\n* ”Street Number Suffix“  is derived from address feature. In my understanding, it like 2nd level of feature engineering. It might not has result. \n* \"Zipcode\" is zipcode of building address. It should be 1st level of feature. Usually, it should be filled. Missing data might lead by entry error or lack of information. It could be filled by copy from nearest building zipcode."},{"metadata":{"_cell_guid":"ea022b62-6419-47e7-973e-c3e707e2795f","_uuid":"3f72f46f2464c7cd12f5eb2a752746ce1cd0b5a7"},"cell_type":"markdown","source":"\n\n# Drop missing values\n___\n\nIf you're in a hurry or don't have a reason to figure out why your values are missing, one option you have is to just remove any rows or columns that contain missing values. (Note: I don't generally recommend this approch for important projects! It's usually worth it to take the time to go through your data and really look at all the columns with missing values one-by-one to really get to know your dataset.)  \n\nIf you're sure you want to drop rows with missing values, pandas does have a handy function, `dropna()` to help you do this. Let's try it out on our NFL dataset!"},{"metadata":{"_cell_guid":"0fe94654-7dad-4e8d-bbbb-e65e2bb2f767","_uuid":"8207912f74712835283f7e1b30dad0471ee2e1fc","trusted":true},"cell_type":"code","source":"# Your turn! Try removing all the rows from the sf_permits dataset that contain missing values. How many are left?\nsf_permits.dropna()\n","execution_count":271,"outputs":[]},{"metadata":{"_uuid":"4fe2a18fa979be38fe3b8f7be0f23c3557695793"},"cell_type":"markdown","source":"**Note:**\n*     All data gone after direclty drop all rows with missing data.\n*     It is not a applicable way. \n\n**Next actions: **\n   * try drop missing data per columns"},{"metadata":{"_cell_guid":"7ec643e1-abba-4683-b794-a1924e657501","_uuid":"f804c0448b18b6d411ddf8452d15abba8292fffa","trusted":true},"cell_type":"code","source":"# Now try removing all the columns with empty values. Now how much of your data is left?\ncolumns_with_na_dropped_sf =sf_permits.dropna(axis=1)\n#columns_with_na_dropped_sf.head()\n# just how much data did we lose?\nprint(\"Columns in original dataset: %d \\n\" % sf_permits.shape[1])\nprint(\"Columns with na's dropped: %d\" % columns_with_na_dropped_sf.shape[1])","execution_count":277,"outputs":[]},{"metadata":{"_uuid":"05b3bee27fe31e47e816535f40a013f1df30e47b"},"cell_type":"markdown","source":"**Note:  **\n    1.  12 of 43 columns remained.  Looks drop missing data by columns is better than drop by row\n    However,  we can do it better. \n  \n  **Next actions: **"},{"metadata":{"_cell_guid":"1dbe153d-7b30-4ad8-80ad-a4c7fb53928e","_uuid":"eb1ef8d47d9ebed77c3d21eca24708708ed4d45f"},"cell_type":"markdown","source":"# Filling in missing values automatically\n_____\n"},{"metadata":{"_cell_guid":"527c8703-4b29-459d-af7d-5505da36016b","_uuid":"f8cfe916904af3265d8ecc4f791f9f62e34ff458"},"cell_type":"markdown","source":"We can use the Panda's fillna() function to fill in missing values in a dataframe for us. One option we have is to specify what we want the `NaN` values to be replaced with. Here, I'm saying that I would like to replace all the `NaN` values with 0."},{"metadata":{"_cell_guid":"1103b725-c823-4f40-9bda-e97997856339","_uuid":"bec603202c6bfaae7a49b4a4042f37019ad1d801"},"cell_type":"markdown","source":"I could also be a bit more savvy and replace missing values with whatever value comes directly after it in the same column. (This makes a lot of sense for datasets where the observations have some sort of logical order to them.)"},{"metadata":{"_cell_guid":"980e5d67-7e9c-41a3-b17e-51d87e9da9cf","_uuid":"1f8ac8b52f2933612e315f06a53185e164e6c5bc"},"cell_type":"markdown","source":"Filling in missing values is also known as \"imputation\", and you can find more exercises on it [in this lesson, also linked under the \"More practice!\" section](https://www.kaggle.com/dansbecker/handling-missing-values). First, however, why don't you try replacing some of the missing values in the sf_permit dataset?"},{"metadata":{"_cell_guid":"da426397-7e17-40ce-a0d4-ca6d39e47498","_uuid":"f7d403c19eaf31ee0a4e04b9e1119eda96a9f95c","trusted":true},"cell_type":"code","source":"# Your turn! Try replacing all the NaN's in the sf_permits data with the one that\n\n# comes directly after it and then \nsf_permits_autofillna = sf_permits.fillna(method=\"bfill\",axis=0).fillna(0)\n","execution_count":284,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fa82e111a33658cb436c2f1debdc88cb45d7e81b"},"cell_type":"code","source":"sf_permits_autofillna.isnull().sum().sum()","execution_count":286,"outputs":[]},{"metadata":{"_uuid":"f8bdd42703a4d8031998e1a3ab5ffe18b2c234e2"},"cell_type":"markdown","source":"**Note: **\n0 Missing data now. \nBy fillna foreward and backward and fillna with 0, the missing data issues seem solved.\n* fillna functions has bfill and ffill methos. We just take bfill as example. \n\nHowever, \n* bfill or ffill is just for time series related data. We need fill it by more speficific way.\n* It will be the work of tomorrow.\n\nNext actions:\n1.  Fill missing data with appropriate way.\n  * Fill data using sklearn imputer.\n      benefit： sklearn imputer could be a components of pipeline.  With pipeline, we can get machine learn \n          * be more abstractive,  focused on process instead of coding\n          * be more easy to tuning hypter parameter, one pipeline do all thins\n          * be more safe.  Avoid missing preprocessing for testing data and lead to wrong results. \n  \n  * Fill data using external databset as reference.\n      benefit: \n        Fill missing value & find outlier contribute key values to feature engineering"},{"metadata":{"_cell_guid":"b4f37fce-4d08-409e-bbbd-6a26c3bbc6ee","_uuid":"52b0af56e3c77db96056e9acd785f8f435f7caf5"},"cell_type":"markdown","source":"# More practice! (TBD)\n___\n\nIf you're looking for more practice handling missing values, check out these extra-credit\\* exercises:\n\n* [Handling Missing Values](https://www.kaggle.com/dansbecker/handling-missing-values): In this notebook Dan shows you several approaches to imputing missing data using scikit-learn's imputer. \n* Look back at the `Zipcode` column in the `sf_permits` dataset, which has some missing values. How would you go about figuring out what the actual zipcode of each address should be? (You might try using another dataset. You can search for datasets about San Fransisco on the [Datasets listing](https://www.kaggle.com/datasets).) \n\n\\* no actual credit is given for completing the challenge, you just learn how to clean data real good :P"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}