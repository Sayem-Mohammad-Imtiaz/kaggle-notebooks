{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 0. Imports"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\npd.options.mode.chained_assignment = None  # default='warn'\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport matplotlib.pyplot as plt\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Hyper Parameters"},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"SAMPLES = 1000\nEDA = True\nTOP_TAGS = 100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Load Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"os.system(\"echo Data loading: \"+str(SAMPLES)+\"...\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Le dataset porte sur plus de 2 millions d'images, pour accélérer la phase de développement et debug on va limiter la quantité de données chargée."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"if SAMPLES > 0:\n    df_raw = pd.read_csv('/kaggle/input/safebooru/all_data.csv', nrows=SAMPLES)\nelse:\n    df_raw = pd.read_csv('/kaggle/input/safebooru/all_data.csv')\ndf_raw","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df_raw.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check thumbnail size : 150x113\n#df_raw[\"preview_url\"][101]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Feature Engineering"},{"metadata":{},"cell_type":"markdown","source":"## 3.1 Feature Selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"os.system(\"echo Feature Selection...\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Supression des colonnes inutile dans notre cas."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"useless = [\"id\", \"created_at\", \"rating\", \"score\", \"sample_width\", \"sample_height\", \"preview_url\"]\nusefull = [i for i in df_raw.columns if i not in useless]\nusefull","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df_clean = df_raw[usefull]\ndf_clean","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.2 Tags extraction"},{"metadata":{"trusted":true},"cell_type":"code","source":"os.system(\"echo Tags Extraction and Count...\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On extrait et on compte les occurences de chacun des tags présent dans la colonne *tags*. Par exemple en utilisant un mapping *dict* donnant pour chaque tag son occurence."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"if EDA:\n    tags = dict()\n    total = 0\n    pct = 0\n    for line in df_clean.tags:\n        tokens = line.split()\n        for token in tokens:\n            if token in tags:\n                tags[token] += 1\n            else:\n                tags[token] = 1\n        total += 1\n        if total % int(0.1*df_clean.shape[0]) == 0:\n            pct += 10\n            print(pct,\"% extracted\")\n            os.system(\"echo \"+str(pct)+\"% extracted\")\n    print(\"There is\",len(tags),\"different tags\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Suppressions des tags à faible occurence (définit en hyperparamètre)."},{"metadata":{},"cell_type":"markdown","source":"On ordonne nos tags en décroissant et on peut maintenant jeter un oeil aux tags les plus fréquents en produisant un histogramme. On peut extraire les élements de notre *dict* avec *items()* pour ordonner les pair key/value selon les valeurs."},{"metadata":{"trusted":true},"cell_type":"code","source":"os.system(\"echo Tags Sort and Plot...\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if EDA:\n    import matplotlib.pyplot as plt\n    import seaborn as sns\n    \n    # Data to plot\n    sorted_tags_count = sorted(tags.items(), key = lambda kv:(kv[1], kv[0]), reverse=True)\n    \n    # Style\n    sns.set(style=\"whitegrid\")\n    sns.set_color_codes(\"pastel\")\n    \n    # Initialize the matplotlib figure\n    f, ax = plt.subplots(figsize=(20, 50))\n\n    # Chart\n    sns.barplot(x=[j for (i,j) in sorted_tags_count[:TOP_TAGS]], y=[i for (i,j) in sorted_tags_count[:TOP_TAGS]], color='b', label=\"Occurences\")\n\n    # Legend and informative axis label\n    ax.legend(ncol=1, loc=\"lower right\", frameon=True)\n    ax.set(ylabel=\"Tags\",\n           xlabel=\"Occurences\")\n    sns.despine(left=True, bottom=True)\n    \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On observe dans les top tags *tagme* qui semble identifier les images sans tags et avec peu de tags. On a *solo* qui semble identifier des personnage seul. On voit aussi *1girl* qui peut indiquer une seule fille sur l'image, on peut s'attendre à avoir un tag *1boy*. On a le tag *male* qui doit identifier la présence de personnage masculin."},{"metadata":{},"cell_type":"markdown","source":"Aussi dans les tops tags on trouve *long_hair* et *short_hair* ça pourrait être une classification possible à apprendre à partir de ces données. De même pour les couleurs de cheveux et les type de vêtements. On observe aussi différents nom de série d'anime."},{"metadata":{"trusted":true},"cell_type":"code","source":"if EDA:\n    print(\"Occurences: \")\n    selected_tags = [\"solo\", \"1girl\", \"1boy\", \"girl\", \"female\", \"loli\", \"boy\", \"male\", \"man\", \"shota\", \"trap\", \"reverse_trap\"]\n    for tag in selected_tags:\n        if tag in tags:\n            print(tag, tags[tag])\n        else:\n            print(tag,\" \",0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Les tags retenu pour identifier des personnages féminin ou masculin seul seront :\n- tags 1 personnage :\n    - solo\n- tags féminins :\n    - 1girl\n    - girl\n    - female\n    - loli\n- tags masculins :\n    - 1boy\n    - boy\n    - male\n    - man\n    - shota\n- tags trap :\n    - trap\n    - reverse_trap"},{"metadata":{},"cell_type":"markdown","source":"On peut maintenant isoler les images contenant un seul personnage et dont le genre est connu. On va créer un nouvelle colonne *target* dans notre dataset *df_eng* suivant cet encodage:\n* \"?\" indiquera le fait que l'image n'est pas identifiable aux tags présents (on peut pas déterminer si personnage seul ou le genre)\n* \"girl\" indiquera une image de personnage féminin seule\n* \"boy\" indiquera une image de personnage masculin seul"},{"metadata":{"trusted":true},"cell_type":"code","source":"os.system(\"echo Target creation...\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def appears_in(l1,l2):\n    for tag in l1:\n        if tag in l2:\n            return True\n    return False\n\n# Selected tags\nsolo_tags = [\"solo\"]#, \"1girl\", \"1boy\"]\ngirl_tags = [\"1girl\", \"girl\", \"female\", \"loli\"]\nboy_tags = [\"1boy\", \"boy\", \"male\", \"man\" \"shota\"]\ntrap_tags = [\"trap\",\"reverse_trap\"]\n\n# Tags detections\ntagged_solo = [appears_in(solo_tags,i.split())  for i in df_clean.tags]\ntagged_girl = [appears_in(girl_tags,i.split()) for i in df_clean.tags]\ntagged_boy = [appears_in(boy_tags,i.split()) for i in df_clean.tags]\ntagged_trap = [appears_in(trap_tags,i.split()) for i in df_clean.tags]\n\n# Target conversion\ntarget = []\n\nfor i in range(0,len(df_clean)):\n    value = \"?\" # encode not valid sample\n    if tagged_solo[i] and (tagged_girl[i] != tagged_boy[i]) and (not tagged_trap[i]):\n        if tagged_girl[i]:\n            value = \"girl\" # 1 encode girl sample\n        else:\n            value = \"boy\" # 2 encode boy sample\n    target.append(value)\n\ndf_clean[\"target\"] = target\ndf_clean","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Suppression des images non exploitables et de colonnes devenu inutiles"},{"metadata":{"trusted":true},"cell_type":"code","source":"os.system(\"echo Cleaning non class image...\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df_clean = df_clean[df_clean.target != \"?\"]\ndf_clean.drop(['tags'], axis=1, inplace=True)\ndf_clean","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Reduced dataset:\")\nprint(\"Number of images:\", df_clean.shape[0])\nprint(\"Number of girls:\", df_clean[df_clean.target==1].shape[0])\nprint(\"Number of boys:\", df_clean[df_clean.target==2].shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.system(\"echo Reduced dataset:\")\nos.system(\"echo Number of images:\"+str(df_clean.shape[0]))\nos.system(\"echo Number of girls:\"+str(df_clean[df_clean.target==1].shape[0]))\nos.system(\"echo Number of boys:\"+str(df_clean[df_clean.target==2].shape[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.3 Images Extraction"},{"metadata":{"trusted":true},"cell_type":"code","source":"os.system(\"echo Downloading \"+str(df_clean.shape[0])+ \" images...\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On va devoir récupérer les images directement sur les serveurs de *sanbooru.org* à partir des urls contenu dans le dataframe pour consituer notre dataset d'image en local."},{"metadata":{},"cell_type":"markdown","source":"On commence par créer le dossier *images* où seront stocker nos images."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"!mkdir \"images\"\n!ls","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On créer une fonction permettant de télécharger une image depuis une *url* et qui la stock dans *images/*. Une façon de faire est d'utiliser *request* comme dans https://www.quickprogrammingtips.com/python/how-to-download-multiple-files-concurrently-in-python.html"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import requests\n \ndef download_url(url):\n  #print(\"downloading: \",url)\n  # assumes that the last segment after the / represents the file name\n  # if url is abc/xyz/file.txt, the file name will be file.txt\n  file_name_start_pos = url.rfind(\"/\") + 1\n  file_name = \"images/\" + url[file_name_start_pos:]\n \n  r = requests.get(url, stream=True)\n  if r.status_code == requests.codes.ok:\n    with open(file_name, 'wb') as f:\n      for data in r:\n        f.write(data)\n  return file_name","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On récupère la liste de toutes les url d'images depuis le dataframe *df_clean*."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"urls = [\"http:\"+i for i in df_clean.sample_url]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On utilise notre fonction *download_url* pour chaque image. On pourra utiliser *ThreadPool* pour faire un téléchargement groupé. En effet si les serveur de *sanbooru* on moins d'upload qu'on a de download on perdra du temps à les faire 1 par 1."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from multiprocessing.pool import ThreadPool\npd.options.mode.chained_assignment = None\n\n# Run 5 multiple threads. Each call will take the next element in urls list\nresult = ThreadPool(5).imap_unordered(download_url, urls)\ntotal = 0\npct =0\nfor r in result:\n    total += 1\n    if total % int(0.01*df_clean.shape[0]) == 0:\n        pct = round(100/df_clean.shape[0] * total)\n        print(pct,\"% downloaded\")\n        os.system(\"echo \"+str(pct)+\"% downloaded\")\n    if total % 1000 == 0:\n        print(total,\"/\",df_clean.shape[0],\" downloaded\")\n        os.system(\"echo \"+str(total)+\"/\"+str(df_clean.shape[0])+\" downloaded\")\n        pct = round(100/df_clean.shape[0] * total)\n        os.system(\"echo \"+str(pct)+\"% downloaded\")\n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On peut maintenant créer la nouvelle colonne et supprimer *sample_url*. *urls* nous assure l'ordre des images dans le dataset et puisqu'on utilise la fin d'url comme nom de fichier on peut la récupérer en tronquant de la même façon."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"images_path = [url[url.rfind(\"/\") + 1:] for url in urls]\nimages_path[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On remplace la colonne *sample_url* par une nouvelle colonne donnant le path des images à présent téléchargées."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df_clean[\"file\"] = images_path\ndf_clean.drop(['sample_url'], axis=1, inplace=True)\ndf_clean","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Suppression des images dont le download a échoué."},{"metadata":{"trusted":true},"cell_type":"code","source":"os.system(\"echo Delete failed downloaded entries...\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"size_before = df_clean.shape[0]\nfor index, row in df_clean.iterrows():\n    if not os.path.isfile(\"images/\"+str(row[\"file\"])):\n        df_clean.drop(index, inplace=True)\ndf_clean","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.system(\"echo Failed Download: \"+str(df_clean.shape[0]-size_before))\nprint(\"echo Failed Download: \"+str(size_before-df_clean.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Suppressions des images corrompues"},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image\nsize_before = df_clean.shape[0]\nfor index, row in df_clean.iterrows():\n    try:\n        img = Image.open(\"images/\"+row[\"file\"]) # open the image file\n    except (IOError, SyntaxError) as e:\n        print('Bad file:', \"images/\"+row[\"file\"]) # print out the names of corrupt files\n        os.remove(\"images/\"+row[\"file\"])\n        df_clean.drop(index, inplace=True)\ndf_clean","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from os import listdir\nfrom PIL import Image\n\nbad_count = 0\nfor directory in [\"images/\"]:\n    for filename in listdir(directory):\n        try:\n            img = Image.open(directory+filename) # open the image file\n        except (IOError, SyntaxError) as e:\n            print('Bad file:', directory+filename) # print out the names of corrupt files\n            os.remove(directory+filename)\n            df_clean.drop()\n            bad_count += 1\n    print(bad_count,\" error files\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plus qu'a afficher un petit expample des image récupérées."},{"metadata":{},"cell_type":"markdown","source":"Un peu stylisé avec du ipywidget."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import ipywidgets as widgets\nfrom IPython.display import display\n\n# Define a useful function\ndef get_image(f_path):\n    '''\n    Returns the image from a path\n    '''\n    img_labs = ['jpg','png']\n    if any(x in img_labs for x in f_path.split('.')):\n        image = open(f_path,'rb').read()\n        return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"some_girls = df_clean[df_clean.target == 1].head(20).file\n\nimages = [get_image(\"images/\"+x) for x in some_girls]\nchildren = [widgets.Image(value = img) for img in images if str(type(img)) != '<class \\'NoneType\\'>']\nlabels = ['{}'.format(i) for i in range(len(children))]\n\n# Customize your layout here:\nbox_layout = widgets.Layout(\n    display='flex',\n    flex_flow='column',\n    align_items='stretch',\n    border='solid',\n    width='50%')\n\n# Create the widget\ntab = widgets.Tab()\ntab.children = children\n\n# Label em'!\nfor i in range(len(children)):\n    tab.set_title(i,labels[i])\n\ndisplay(tab)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"some_boys = df_clean[df_clean.target == 2].head(20).file\n\nimages = [get_image(\"images/\"+x) for x in some_boys]\nchildren = [widgets.Image(value = img) for img in images if str(type(img)) != '<class \\'NoneType\\'>']\nlabels = ['{}'.format(i) for i in range(len(children))]\n\n# Customize your layout here:\nbox_layout = widgets.Layout(\n    display='flex',\n    flex_flow='column',\n    align_items='stretch',\n    border='solid',\n    width='25%')\n\n# Create the widget\ntab = widgets.Tab()\ntab.children = children\n\n# Label em'!\nfor i in range(len(children)):\n    tab.set_title(i,labels[i])\n\ndisplay(tab)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Dataset output"},{"metadata":{"trusted":true},"cell_type":"code","source":"os.system(\"echo Save to csv...\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Sauvegarde du dataframe en csv."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clean.to_csv(\"sanboru_gender_dataset.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Regroupement des images en un seul fichier zip."},{"metadata":{"trusted":true},"cell_type":"code","source":"os.system(\"echo Zip images...\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import shutil\nshutil.make_archive(\"sanboru_gender_dataset\", 'zip', \"images\")\n!rm images/*\n!rm -d \"images\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Affichage de nos fichiers créés."},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.system(\"echo Generated dataset: sanboru_gender_dataset.zip\")\nos.system(\"echo Number of images:\"+str(df_clean.shape[0]))\nos.system(\"echo Number of girls:\"+str(df_clean[df_clean.target==1].shape[0]))\nos.system(\"echo Number of boys:\"+str(df_clean[df_clean.target==2].shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Generated dataset: sanboru_gender_dataset.zip\")\nprint(\"Number of images:\", df_clean.shape[0])\nprint(\"Number of girls:\", df_clean[df_clean.target==1].shape[0])\nprint(\"Number of boys:\", df_clean[df_clean.target==2].shape[0])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}