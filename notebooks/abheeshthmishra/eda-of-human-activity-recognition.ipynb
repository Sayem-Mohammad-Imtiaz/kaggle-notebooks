{"cells":[{"metadata":{},"cell_type":"markdown","source":"# HumanActivityRecognition\n\n<br>\n\n\nThis project is to build a model that predicts the human activities such as Walking, Walking_Upstairs, Walking_Downstairs, Sitting, Standing or Laying.\n\nThis dataset is collected from 30 persons(referred as subjects in this dataset), performing different activities with a smartphone to their waists. The data is recorded with the help of sensors (accelerometer and Gyroscope) in that smartphone. This experiment was video recorded to label the data manually.\n\n## How data was recorded\n\nBy using the sensors(Gyroscope and accelerometer) in a smartphone, they have captured '3-axial linear acceleration'(_tAcc-XYZ_) from accelerometer and '3-axial angular velocity' (_tGyro-XYZ_) from Gyroscope with several variations. \n\n> prefix 't' in those metrics denotes time.\n\n> suffix 'XYZ' represents 3-axial signals in X , Y, and Z directions.\n\n### Feature names\n\n1. These sensor signals are preprocessed by applying noise filters and then sampled in fixed-width windows(sliding windows) of 2.56 seconds each with 50% overlap. ie., each window has 128 readings. \n\n2. From Each window, a feature vector was obtianed by calculating variables from the time and frequency domain.\n> In our dataset, each datapoint represents a window with different readings \n3. The accelertion signal was saperated into Body and Gravity acceleration signals(___tBodyAcc-XYZ___ and ___tGravityAcc-XYZ___) using some low pass filter with corner frequecy of 0.3Hz.\n\n4. After that, the body linear acceleration and angular velocity were derived in time to obtian _jerk signals_ (___tBodyAccJerk-XYZ___ and ___tBodyGyroJerk-XYZ___). \n\n5. The magnitude of these 3-dimensional signals were calculated using the Euclidian norm. This magnitudes are represented as features with names like _tBodyAccMag_, _tGravityAccMag_, _tBodyAccJerkMag_, _tBodyGyroMag_ and _tBodyGyroJerkMag_.\n\n6. Finally, We've got frequency domain signals from some of the available signals by applying a FFT (Fast Fourier Transform). These signals obtained were labeled with ___prefix 'f'___ just like original signals with ___prefix 't'___. These signals are labeled as ___fBodyAcc-XYZ___, ___fBodyGyroMag___ etc.,.\n\n7. These are the signals that we got so far.\n\t+ tBodyAcc-XYZ\n\t+ tGravityAcc-XYZ\n\t+ tBodyAccJerk-XYZ\n\t+ tBodyGyro-XYZ\n\t+ tBodyGyroJerk-XYZ\n\t+ tBodyAccMag\n\t+ tGravityAccMag\n\t+ tBodyAccJerkMag\n\t+ tBodyGyroMag\n\t+ tBodyGyroJerkMag\n\t+ fBodyAcc-XYZ\n\t+ fBodyAccJerk-XYZ\n\t+ fBodyGyro-XYZ\n\t+ fBodyAccMag\n\t+ fBodyAccJerkMag\n\t+ fBodyGyroMag\n\t+ fBodyGyroJerkMag\n\n8. We can esitmate some set of variables from the above signals. ie., We will estimate the following properties on each and every signal that we recoreded so far.\n\n\t+ ___mean()___: Mean value\n\t+ ___std()___: Standard deviation\n\t+ ___mad()___: Median absolute deviation \n\t+ ___max()___: Largest value in array\n\t+ ___min()___: Smallest value in array\n\t+ ___sma()___: Signal magnitude area\n\t+ ___energy()___: Energy measure. Sum of the squares divided by the number of values. \n\t+ ___iqr()___: Interquartile range \n\t+ ___entropy()___: Signal entropy\n\t+ ___arCoeff()___: Autorregresion coefficients with Burg order equal to 4\n\t+ ___correlation()___: correlation coefficient between two signals\n\t+ ___maxInds()___: index of the frequency component with largest magnitude\n\t+ ___meanFreq()___: Weighted average of the frequency components to obtain a mean frequency\n\t+ ___skewness()___: skewness of the frequency domain signal \n\t+ ___kurtosis()___: kurtosis of the frequency domain signal \n\t+ ___bandsEnergy()___: Energy of a frequency interval within the 64 bins of the FFT of each window.\n\t+ ___angle()___: Angle between to vectors.\n\n9. We can obtain some other vectors by taking the average of signals in a single window sample. These are used on the angle() variable'\n`\n\t+ gravityMean\n\t+ tBodyAccMean\n\t+ tBodyAccJerkMean\n\t+ tBodyGyroMean\n\t+ tBodyGyroJerkMean\n\n\n###  Y_Labels(Encoded)\n+ In the dataset, Y_labels are represented as numbers from 1 to 6 as their identifiers.\n\n\t- WALKING as __1__\n\t- WALKING_UPSTAIRS as __2__\n\t- WALKING_DOWNSTAIRS as __3__\n\t- SITTING as __4__\n\t- STANDING as __5__\n\t- LAYING as __6__\n    \n## Train and test data were saperated\n - The readings from ___70%___ of the volunteers were taken as ___trianing data___ and remaining ___30%___ subjects recordings were taken for ___test data___\n \n## Data\n\n* All the data is present in 'UCI_HAR_dataset/' folder in present working directory.\n     - Feature names are present in 'UCI_HAR_dataset/features.txt'\n     - ___Train Data___\n         - 'UCI_HAR_dataset/train/X_train.txt'\n         - 'UCI_HAR_dataset/train/subject_train.txt'\n         - 'UCI_HAR_dataset/train/y_train.txt'\n     - ___Test Data___\n         - 'UCI_HAR_dataset/test/X_test.txt'\n         - 'UCI_HAR_dataset/test/subject_test.txt'\n         - 'UCI_HAR_dataset/test/y_test.txt'\n         \n\n## Data Size :\n> 27 MB\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" "},{"metadata":{},"cell_type":"markdown","source":" "},{"metadata":{},"cell_type":"markdown","source":" "},{"metadata":{},"cell_type":"markdown","source":"# Quick overview of the dataset :\n"},{"metadata":{},"cell_type":"markdown","source":"\n* Accelerometer and Gyroscope readings are taken from 30 volunteers(referred as subjects) while performing the following 6 Activities.\n\n    1. Walking     \n    2. WalkingUpstairs \n    3. WalkingDownstairs \n    4. Standing \n    5. Sitting \n    6. Lying.\n\n\n* Readings are divided into a window of 2.56 seconds with 50% overlapping. \n\n* Accelerometer readings are divided into gravity acceleration and body acceleration readings,\n  which has x,y and z components each.\n\n* Gyroscope readings are the measure of angular velocities which has x,y and z components.\n\n* Jerk signals are calculated for BodyAcceleration readings.\n\n* Fourier Transforms are made on the above time readings to obtain frequency readings.\n\n* Now, on all the base signal readings., mean, max, mad, sma, arcoefficient, engerybands,entropy etc., are calculated for each window.\n\n* We get a feature vector of 561 features and these features are given in the dataset.\n\n* Each window of readings is a datapoint of 561 features.\n\n## Problem Framework\n\n* 30 subjects(volunteers) data is randomly split to 70%(21) test and 30%(7) train data.\n* Each datapoint corresponds one of the 6 Activities.\n"},{"metadata":{},"cell_type":"markdown","source":"## Problem Statement\n\n + Given a new datapoint we have to predict the Activity"},{"metadata":{},"cell_type":"markdown","source":" "},{"metadata":{},"cell_type":"markdown","source":"## Obtain the  train data "},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ntrain = pd.read_csv('../input/human-activity-recognition-with-smartphones/train.csv')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Obtain the  test data "},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(\"/kaggle/input/human-activity-recognition-with-smartphones/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" "},{"metadata":{"collapsed":true},"cell_type":"markdown","source":"# Data Cleaning"},{"metadata":{},"cell_type":"markdown","source":"## 1. Check for Duplicates"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print('No of duplicates in train: {}'.format(sum(train.duplicated())))\nprint('No of duplicates in test : {}'.format(sum(test.duplicated())))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see there are no duplicates in the train and test dataset"},{"metadata":{},"cell_type":"markdown","source":"## 2. Checking for NaN/null values"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('We have {} NaN/Null values in train'.format(train.isnull().values.sum()))\nprint('We have {} NaN/Null values in test'.format(test.isnull().values.sum()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this this dataset we should not be worried about null values because there are no null values   "},{"metadata":{},"cell_type":"markdown","source":"## 3. Check for data imbalance"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import libraries for visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set_style('whitegrid')\nplt.rcParams['font.family'] = 'Dejavu Sans'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,8))\nplt.title('Data provided by each user', fontsize=20)\nsns.countplot(x='subject',hue='Activity', data = train)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see We have got almost same number of reading from all the subjects means there are not sygnificant difference in reading then we should not worry about it"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"plt.title('No of Datapoints per Activity', fontsize=15)\nsns.countplot(train.Activity)\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Observation\nOur data is well balanced (almost)"},{"metadata":{},"cell_type":"markdown","source":"## 4. Changing feature names "},{"metadata":{},"cell_type":"markdown","source":"we will remove the commas and brackets to out features so that we can apply directly"},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = train.columns\n\n# Removing '()' from column names\ncolumns = columns.str.replace('[()]','')\ncolumns = columns.str.replace('[-]', '')\ncolumns = columns.str.replace('[,]','')\n\ntrain.columns = columns\ntest.columns = columns\n\ntest.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. Save this dataframe in a csv files"},{"metadata":{},"cell_type":"markdown","source":"save our data to csv file for future prediction ,we will use these files when we will do predictions in the next notebook"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.to_csv('f_train.csv', index=False)\ntest.to_csv('f_test.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" "},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis"},{"metadata":{},"cell_type":"markdown","source":"\"___Without domain knowledge EDA has no meaning, without EDA a problem has no soul.___\""},{"metadata":{},"cell_type":"markdown","source":"### 1. Featuring Engineering from Domain Knowledge \n"},{"metadata":{},"cell_type":"markdown","source":"\n\n+ __Static and Dynamic Activities__\n\n    - In static activities (sit, stand, lie down) motion information will not be very useful.\n\t- In the dynamic activities (Walking, WalkingUpstairs,WalkingDownstairs) motion info will be significant.\n\n\n"},{"metadata":{},"cell_type":"markdown","source":"### 2. Stationary and Moving activities are completely different"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_palette(\"Set1\", desat=0.80)\nfacetgrid = sns.FacetGrid(train, hue='Activity', size=6,aspect=2)\nfacetgrid.map(sns.distplot,'tBodyAccMagmean', hist=False)\\\n    .add_legend()\nplt.annotate(\"Stationary Activities\", xy=(-0.956,17), xytext=(-0.9, 23), size=20,\\\n            va='center', ha='left',\\\n            arrowprops=dict(arrowstyle=\"simple\",connectionstyle=\"arc3,rad=0.1\"))\n\nplt.annotate(\"Moving Activities\", xy=(0,3), xytext=(0.2, 9), size=20,\\\n            va='center', ha='left',\\\n            arrowprops=dict(arrowstyle=\"simple\",connectionstyle=\"arc3,rad=0.1\"))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nAs we can clearly see the difference between stationary activities and Moving Activities\n\nas per above pdf distribution we can look closer by dividing these pdfs "},{"metadata":{"trusted":true},"cell_type":"code","source":"# for plotting purposes taking datapoints of each activity to a different dataframe\ndf1 = train[train['Activity']==1]\ndf2 = train[train['Activity']==2]\ndf3 = train[train['Activity']==3]\ndf4 = train[train['Activity']==4]\ndf5 = train[train['Activity']==5]\ndf6 = train[train['Activity']==6]\n\n\n\nplt.figure(figsize=(12,8))\nplt.subplot(1,2,1)\nplt.title(\"Static Activities(closer view)\")\nsns.distplot(train[train[\"Activity\"]==\"SITTING\"]['tBodyAccMagmean'],hist = False, label = 'Sitting')\nsns.distplot(train[train[\"Activity\"]==\"STANDING\"]['tBodyAccMagmean'],hist = False,label = 'Standing')\nsns.distplot(train[train[\"Activity\"]==\"LAYING\"]['tBodyAccMagmean'],hist = False, label = 'Laying')\nplt.axis([-1.02, -0.5, 0, 35])\nplt.subplot(1,2,2)\nplt.title(\"Dynamic Activities(closer view)\")\nsns.distplot(train[train[\"Activity\"]==\"WALKING\"]['tBodyAccMagmean'],hist = False, label = 'Sitting')\nsns.distplot(train[train[\"Activity\"]==\"WALKING_DOWNSTAIRS\"]['tBodyAccMagmean'],hist = False,label = 'Standing')\nsns.distplot(train[train[\"Activity\"]==\"WALKING_UPSTAIRS\"]['tBodyAccMagmean'],hist = False, label = 'Laying')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. Magnitude of an acceleration can saperate it well"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(7,7))\nsns.boxplot(x='Activity', y='tBodyAccMagmean',data=train, showfliers=False, saturation=1)\nplt.ylabel('Acceleration Magnitude mean')\nplt.axhline(y=-0.7, xmin=0.1, xmax=0.9,dashes=(5,5), c='g')\nplt.axhline(y=-0.05, xmin=0.4, dashes=(5,5), c='m')\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__ Observations__:\n- If tAccMean is < -0.8 then the Activities are either Standing or Sitting or Laying.\n- If tAccMean is > -0.6 then the Activities are either Walking or WalkingDownstairs or WalkingUpstairs.\n- If tAccMean > 0.0 then the Activity is WalkingDownstairs.\n- We can classify 75% the Acitivity labels with some errors."},{"metadata":{},"cell_type":"markdown","source":"### 4. Position of GravityAccelerationComponants also matters "},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='Activity', y='angleXgravityMean', data=train)\nplt.axhline(y=0.08, xmin=0.1, xmax=0.9,c='m',dashes=(5,3))\nplt.title('Angle between X-axis and Gravity_mean', fontsize=15)\nplt.xticks(rotation = 40)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__ Observations__:\n* If angleX,gravityMean > 0 then Activity is Laying.\n* We can classify all datapoints belonging to Laying activity with just a single if else statement."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='Activity', y='angleYgravityMean', data = train, showfliers=False)\nplt.title('Angle between Y-axis and Gravity_mean', fontsize=15)\nplt.xticks(rotation = 40)\nplt.axhline(y=-0.22, xmin=0.1, xmax=0.8, dashes=(5,3), c='m')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" "},{"metadata":{},"cell_type":"markdown","source":"# Apply t-sne on the data "},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom sklearn.manifold import TSNE\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we will see these datapoints in 2 dimensions and try to observe the behaviour of the datapoints"},{"metadata":{"trusted":true},"cell_type":"code","source":"# performs t-sne with different perplexity values and their repective plots..\n\ndef perform_tsne(X_data, y_data, perplexities, n_iter=1000, img_name_prefix='t-sne'):\n        \n    for index,perplexity in enumerate(perplexities):\n        # perform t-sne\n        print('\\nperforming tsne with perplexity {} and with {} iterations at max'.format(perplexity, n_iter))\n        X_reduced = TSNE(verbose=2, perplexity=perplexity).fit_transform(X_data)\n        print('Done..')\n        \n        # prepare the data for seaborn         \n        print('Creating plot for this t-sne visualization..')\n        df = pd.DataFrame({'x':X_reduced[:,0], 'y':X_reduced[:,1] ,'label':y_data})\n        \n        # draw the plot in appropriate place in the grid\n        sns.lmplot(data=df, x='x', y='y', hue='label', fit_reg=False, size=8,\\\n                   palette=\"Set1\",markers=['^','v','s','o', '1','2'])\n        plt.title(\"perplexity : {} and max_iter : {}\".format(perplexity, n_iter))\n        img_name = img_name_prefix + '_perp_{}_iter_{}.png'.format(perplexity, n_iter)\n        print('saving this plot as image in present working directory...')\n        plt.savefig(img_name)\n        plt.show()\n        print('Done')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_pre_tsne = train.drop(['subject', 'Activity'], axis=1)\ny_pre_tsne = train['Activity']\nperform_tsne(X_data = X_pre_tsne,y_data=y_pre_tsne, perplexities =[5,10,20])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ***Conclusion***\n\n-->As we can see all the features except standing and sitting can be seperated very easily \n\n--> Model will probably be confused between standing and sitting"},{"metadata":{},"cell_type":"markdown","source":" "},{"metadata":{},"cell_type":"markdown","source":"## Predictions in the Next Notebook....."},{"metadata":{},"cell_type":"markdown","source":" "},{"metadata":{},"cell_type":"markdown","source":" "},{"metadata":{},"cell_type":"markdown","source":" "},{"metadata":{},"cell_type":"markdown","source":" "},{"metadata":{},"cell_type":"markdown","source":" "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}