{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import warnings; warnings.filterwarnings('ignore')\nimport pandas as pd,numpy as np,pylab as pl\nimport keras as ks,tensorflow as tf\nimport h5py,cv2; from tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing import image as kimage\nfrom keras.utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint,EarlyStopping\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.models import Sequential,load_model\nfrom keras.layers import BatchNormalization,Conv2D,Dense\nfrom keras.layers import LSTM,Flatten,Activation,Dropout\nfrom keras.layers.advanced_activations import PReLU,LeakyReLU\nfrom keras.layers import MaxPooling2D,GlobalMaxPooling2D\nfrom keras.layers import GlobalAveragePooling2D\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.applications.inception_v3 import preprocess_input as iv3pi\nfpath='../input/flower-color-images/flower_images/flower_images/'\nfw='weights.best.flowers.hdf5'\nfrom keras import __version__\nprint('keras version:', __version__)\nprint('tensorflow version:', tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def history_plot(fit_history):\n    pl.figure(figsize=(12,9));pl.subplot(211)\n    pl.plot(fit_history.history['loss'],\n            color='slategray',label='train')\n    pl.plot(fit_history.history['val_loss'],\n            color='#ff355e',label='valid')\n    pl.xlabel(\"Epochs\"); pl.ylabel(\"Loss\")\n    pl.legend(); pl.grid()\n    pl.title('Loss Function')      \n    pl.subplot(212)\n    pl.plot(fit_history.history['acc'],\n            color='slategray',label='train')\n    pl.plot(fit_history.history['val_acc'], \n            color='#ff355e',label='valid')\n    pl.xlabel('Epochs'); pl.ylabel('Accuracy')    \n    pl.legend(); pl.title('Accuracy')\n    pl.grid(); pl.show()\ndef path_to_tensor(img_path,fpath=fpath):\n    img=kimage.load_img(fpath+img_path, \n                        target_size=(128,128))\n    x=kimage.img_to_array(img)\n    return np.expand_dims(x,axis=0)\ndef paths_to_tensor(img_paths):\n    tensor_list=[path_to_tensor(img_path) \n                 for img_path in tqdm(img_paths)]\n    return np.vstack(tensor_list)\nfrom PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES=True ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"flowers=pd.read_csv(fpath+\"flower_labels.csv\")\nflower_files=flowers['file']\nflower_labels=flowers['label'].values\nnames=['phlox','rose','calendula','iris',\n       'max chrysanthemum','bellflower','viola',\n       'rudbeckia laciniata','peony','aquilegia']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n=np.random.randint(0,210,1)[0]\nprint('Label: ',flower_labels[n],\n      names[flower_labels[n]])\nimg=cv2.imread(fpath+flower_files[n])\nrgb_img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\npl.figure(figsize=(3,3))\npl.imshow(rgb_img);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"flower_images=paths_to_tensor(flower_files)/255\nflower_labels=to_categorical(flower_labels,10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,x_test,y_train,y_test=\\\ntrain_test_split(flower_images,flower_labels,\n                 test_size=.2,random_state=1)\nm=int(len(x_test)/2)\nx_valid,y_valid=x_test[:m],y_test[:m]\nx_test,y_test=x_test[m:],y_test[m:]\n[x_train.shape,x_test.shape,x_valid.shape,\n y_train.shape,y_test.shape,y_valid.shape]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n=np.random.randint(0,168,1)[0]\nprint('Label: ',y_train[n],\n      names[np.argmax(y_train[n])])\npl.figure(figsize=(3,3))\npl.imshow((x_train[n]));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mlp_model():\n    model=Sequential()    \n    model.add(Dense(128,activation='relu',\n                    input_shape=(128*128*3,)))\n    model.add(BatchNormalization())    \n    model.add(Dense(256,activation='relu'))\n    model.add(BatchNormalization())    \n    model.add(Dense(512,activation='relu'))\n    model.add(BatchNormalization())   \n    model.add(Dense(1024, activation='relu'))\n    model.add(Dropout(.2))     \n    model.add(Dense(10, activation='softmax'))\n    model.compile(optimizer='adam',\n                  loss='categorical_crossentropy',metrics=['accuracy'])\n    return model\nmlp_model=mlp_model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"early_stopping=EarlyStopping(monitor='val_loss',patience=20,verbose=2)\ncheckpointer=ModelCheckpoint(filepath=fw,save_best_only=True,verbose=2)\nlr_reduction=ReduceLROnPlateau(monitor='val_loss',verbose=2,\n                               patience=5,factor=.8)\nhistory=mlp_model.fit(x_train.reshape(-1,128*128*3),y_train,\n                      epochs=100,batch_size=64,verbose=2,\n                      validation_data=(x_valid.reshape(-1,128*128*3),y_valid),\n                      callbacks=[checkpointer,early_stopping,lr_reduction])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_plot(history)\nmlp_model.load_weights(fw)\nmlp_model.evaluate(x_test.reshape(-1,128*128*3),y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cnn_model():\n    model=Sequential()\n    model.add(Conv2D(32,(5,5),padding='same',\n                     input_shape=x_train.shape[1:]))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(Dropout(.25))\n    model.add(Conv2D(96,(5,5)))\n    model.add(Activation('relu'))    \n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(Dropout(.25))\n    model.add(GlobalAveragePooling2D())    \n    model.add(Dense(512,activation='tanh'))\n    model.add(Dropout(.25))     \n#    model.add(Dense(256,activation='tanh'))\n#    model.add(Dropout(.25))     \n    model.add(Dense(128,activation='tanh'))\n    model.add(Dropout(.25)) \n    model.add(Dense(10))\n    model.add(Activation('softmax'))\n    model.compile(loss='categorical_crossentropy',\n                  optimizer='nadam',metrics=['accuracy'])    \n    return model\ncnn_model=cnn_model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"early_stopping=EarlyStopping(monitor='val_loss',patience=20,verbose=2)\ncheckpointer=ModelCheckpoint(filepath=fw,save_best_only=True,verbose=2)\nlr_reduction=ReduceLROnPlateau(monitor='val_loss',verbose=2,\n                               patience=5,factor=.8)\nhistory=cnn_model.fit(x_train,y_train,epochs=100,batch_size=16,\n                      verbose=2,validation_data=(x_valid,y_valid),\n                      callbacks=[checkpointer,early_stopping,lr_reduction])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_plot(history)\ncnn_model.load_weights(fw)\ncnn_model.evaluate(x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_predict=cnn_model.predict_classes(x_test)\nfig=pl.figure(figsize=(14,7))\nrandch=np.random.choice(x_test.shape[0],size=8,replace=False)\nfor i,idx in enumerate(randch):\n    ax=fig.add_subplot(2,4,i+1,xticks=[],yticks=[])\n    ax.imshow(np.squeeze(x_test[idx]))\n    pred_idx=y_test_predict[idx]\n    true_idx=np.argmax(y_test[idx])\n    ax.set_title(\"{}\\n({})\".format(names[pred_idx],names[true_idx]),\n                 color=(\"#4876ff\" if pred_idx==true_idx else \"darkred\"))\npl.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}