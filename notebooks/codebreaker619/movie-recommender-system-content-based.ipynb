{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"credits = pd.read_csv(\"/kaggle/input/tmdb-movie-metadata/tmdb_5000_credits.csv\")\nmovies = pd.read_csv(\"/kaggle/input/tmdb-movie-metadata/tmdb_5000_movies.csv\")\n\ncredits.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movies.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(credits.shape)\nprint(movies.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"credits = credits.rename(index=str, columns={\"movie_id\": \"id\"})\ncredits.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_merge = movies.merge(credits, on=\"id\")\ndf_merge.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cleaned = df_merge.drop(columns=[\"homepage\", \"title_x\", \"title_y\", \"status\", \"production_countries\"])\ndf_cleaned.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cleaned.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cleaned.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating Content Based Recommendations based on movie plot summary in \"overview\" column\n\n### Recommend movies that have similar plot summaries\n> For each and every movie - we create a vector of matrix<br>\n> Applying a recommendation system => Usually based on pair-wise similarity<br>\n> To find this similarity => we need to represent each and every movie summary as a vector<br>\n> We will used NLP Concept of TFidf Vectorizer which will help us creating a document matrix.<br>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cleaned['overview'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfv = TfidfVectorizer(\n    min_df = 3,\n    max_features = None,\n    strip_accents = \"unicode\",\n    analyzer = \"word\",\n    token_pattern = r'\\w{1,}',\n    ngram_range = (1, 3),         # Taking combinations of 1-3 different kind of words\n    stop_words = \"english\"        # Remove the unnecessary stopword characters\n)\n\ndf_cleaned['overview'] = df_cleaned['overview'].fillna('')   # Removing NaN values\n\ntfv_matrix = tfv.fit_transform(df_cleaned['overview'])   # => Sparse Matrix(vectors) => most of the values in matrix = 0\ntfv_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfv_matrix.shape\n# 4803 records  and 10417 => features(based on the combinations of words(ngram=(1, 3)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics.pairwise import sigmoid_kernel\n# Sigmoid => Responsible for transforming input between 0 to 1\n# Passing the summary vectors in the sigmoid function => Will get values between 0 and 1\n\nsig = sigmoid_kernel(tfv_matrix, tfv_matrix)    # Combination of the same matrix\nsig[0]\n# Overview 1 related to overview 1, overview 1 related to overview 2, overview 1 related to overview 3, and so on","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Mapping of Indices and Corresponding Movie Titles in the dataset\nindices = pd.Series(df_cleaned.index, index=df_cleaned['original_title']).drop_duplicates()\nindices","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Movie Index for the movie \"Shanghai Calling\"\nprint(indices['Shanghai Calling'])\nprint(sig[4801])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting the range of the sigmoid values to a list along with respective indices using the enumerate function\n# [(Index, Score)]\nlist(enumerate(sig[indices['Shanghai Calling']]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sorting according to the scores in the list\nsorted(list(enumerate(sig[indices['Shanghai Calling']])), key=lambda x: x[1], reverse=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Creating a Function to get recommendations for a movie based on the summaries\n> Step 1 - get corresponding index of the movie title<br>\n> Step 2 - get pairwise similarity scores<br>\n> Step 3 - Sort the movies<br>\n> Step 4 - Find the scores of 10 most similar movies<br>\n> Step 5 - get the movie indices of those top 10 movies<br>\n> Step 6 - Return the top 10 most similar movies<br>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Give movie title as input and based on the movie title we apply the object created in the sigmoid kernal\n# Doing the same thing as above but putting it in the fuction\ndef give_recommendation(title, sig=sig):\n    idx = indices[title]\n    sig_scores = list(enumerate(sig[idx]))\n    sig_scores = sorted(sig_scores, key=lambda x: x[1], reverse=True)\n    \n    # Getting Top 10 scores(index, scores)\n    sig_scores = sig_scores[1:11]\n    movie_indices = [i[0] for i in sig_scores]\n    return df_cleaned['original_title'].iloc[movie_indices]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"give_recommendation('Shanghai Calling')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"give_recommendation('Avatar')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}