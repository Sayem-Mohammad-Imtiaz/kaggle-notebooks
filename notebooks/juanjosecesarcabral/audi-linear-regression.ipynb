{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata = pd.read_csv('../input/used-car-dataset-ford-and-mercedes/audi.csv')\n","metadata":{"execution":{"iopub.status.busy":"2021-06-29T04:09:03.928937Z","iopub.execute_input":"2021-06-29T04:09:03.92969Z","iopub.status.idle":"2021-06-29T04:09:03.957365Z","shell.execute_reply.started":"2021-06-29T04:09:03.929645Z","shell.execute_reply":"2021-06-29T04:09:03.956402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2021-06-29T04:09:03.958823Z","iopub.execute_input":"2021-06-29T04:09:03.959348Z","iopub.status.idle":"2021-06-29T04:09:03.989138Z","shell.execute_reply.started":"2021-06-29T04:09:03.959307Z","shell.execute_reply":"2021-06-29T04:09:03.987436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-29T04:09:03.991653Z","iopub.execute_input":"2021-06-29T04:09:03.992228Z","iopub.status.idle":"2021-06-29T04:09:04.008264Z","shell.execute_reply.started":"2021-06-29T04:09:03.992183Z","shell.execute_reply":"2021-06-29T04:09:04.006649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LOOKING AT LINEAR RELATIONS","metadata":{}},{"cell_type":"code","source":"data.plot(kind=\"scatter\",x=\"mileage\",y=\"price\")","metadata":{"execution":{"iopub.status.busy":"2021-06-29T04:09:04.010364Z","iopub.execute_input":"2021-06-29T04:09:04.010798Z","iopub.status.idle":"2021-06-29T04:09:04.237757Z","shell.execute_reply.started":"2021-06-29T04:09:04.010761Z","shell.execute_reply":"2021-06-29T04:09:04.236306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.plot(kind=\"scatter\",x=\"tax\",y=\"price\")","metadata":{"execution":{"iopub.status.busy":"2021-06-29T04:09:04.239504Z","iopub.execute_input":"2021-06-29T04:09:04.23987Z","iopub.status.idle":"2021-06-29T04:09:04.454566Z","shell.execute_reply.started":"2021-06-29T04:09:04.239836Z","shell.execute_reply":"2021-06-29T04:09:04.453431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.plot(kind=\"scatter\",x=\"mpg\",y=\"price\")","metadata":{"execution":{"iopub.status.busy":"2021-06-29T04:09:04.456106Z","iopub.execute_input":"2021-06-29T04:09:04.456528Z","iopub.status.idle":"2021-06-29T04:09:04.680056Z","shell.execute_reply.started":"2021-06-29T04:09:04.456488Z","shell.execute_reply":"2021-06-29T04:09:04.678553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.plot(kind=\"scatter\",x=\"year\",y=\"price\")","metadata":{"execution":{"iopub.status.busy":"2021-06-29T04:09:04.682074Z","iopub.execute_input":"2021-06-29T04:09:04.682659Z","iopub.status.idle":"2021-06-29T04:09:04.87318Z","shell.execute_reply.started":"2021-06-29T04:09:04.682604Z","shell.execute_reply":"2021-06-29T04:09:04.871886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.plot(kind=\"scatter\",x=\"engineSize\",y=\"price\")","metadata":{"execution":{"iopub.status.busy":"2021-06-29T04:09:04.876057Z","iopub.execute_input":"2021-06-29T04:09:04.876358Z","iopub.status.idle":"2021-06-29T04:09:05.070661Z","shell.execute_reply.started":"2021-06-29T04:09:04.87633Z","shell.execute_reply":"2021-06-29T04:09:05.069263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.plot(kind=\"scatter\",x=\"model\",y=\"price\")","metadata":{"execution":{"iopub.status.busy":"2021-06-29T04:09:05.073249Z","iopub.execute_input":"2021-06-29T04:09:05.073703Z","iopub.status.idle":"2021-06-29T04:09:05.378165Z","shell.execute_reply.started":"2021-06-29T04:09:05.073664Z","shell.execute_reply":"2021-06-29T04:09:05.376653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.groupby(\"price\").mean()","metadata":{"execution":{"iopub.status.busy":"2021-06-29T04:09:05.380089Z","iopub.execute_input":"2021-06-29T04:09:05.380559Z","iopub.status.idle":"2021-06-29T04:09:05.404865Z","shell.execute_reply.started":"2021-06-29T04:09:05.380511Z","shell.execute_reply":"2021-06-29T04:09:05.404135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CORRELATION MATRIX","metadata":{}},{"cell_type":"code","source":"def corr(dataframe,target_variable):\n    import seaborn as sns\n    import matplotlib.pyplot as plt\n    fig, ax = plt.subplots(figsize=(10,10))\n    correlation_matrix = dataframe.corr().round(2)\n    sns.heatmap(data=correlation_matrix, annot=True)\n    \n    correlation = data.corr()[target_variable].abs().sort_values(ascending = False)\n    return correlation\n\n\ncorr(data,\"price\")","metadata":{"execution":{"iopub.status.busy":"2021-06-29T04:09:05.405911Z","iopub.execute_input":"2021-06-29T04:09:05.406329Z","iopub.status.idle":"2021-06-29T04:09:06.021898Z","shell.execute_reply.started":"2021-06-29T04:09:05.4063Z","shell.execute_reply":"2021-06-29T04:09:06.020671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**NOT THE BEST WAY TO ENCODE LABELS I KNOW**","metadata":{}},{"cell_type":"code","source":"data2=data\ndata2=data2.drop([\"year\"],axis=1)\ndata2=data2.drop([\"mileage\"],axis=1)\ndata2=data2.drop([\"tax\"],axis=1)\ndata2=data2.drop([\"mpg\"],axis=1)\ndata2=data2.drop([\"engineSize\"],axis=1)\ndata2=data2.drop([\"price\"],axis=1)\n\nfrom sklearn import preprocessing \ndata2=data2.apply(preprocessing.LabelEncoder().fit_transform)\n\ndata=data.drop([\"transmission\"],axis=1)\ndata=data.drop([\"fuelType\"],axis=1)\ndata=data.drop([\"model\"],axis=1)\n\n\ndata=pd.concat([data,data2],axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T04:09:06.023353Z","iopub.execute_input":"2021-06-29T04:09:06.023723Z","iopub.status.idle":"2021-06-29T04:09:06.058306Z","shell.execute_reply.started":"2021-06-29T04:09:06.023691Z","shell.execute_reply":"2021-06-29T04:09:06.056949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Having encoded the object variables we have now a better Correlation Matrix","metadata":{}},{"cell_type":"code","source":"corr(data,\"price\")","metadata":{"execution":{"iopub.status.busy":"2021-06-29T04:09:06.059784Z","iopub.execute_input":"2021-06-29T04:09:06.060095Z","iopub.status.idle":"2021-06-29T04:09:06.749128Z","shell.execute_reply.started":"2021-06-29T04:09:06.060068Z","shell.execute_reply":"2021-06-29T04:09:06.747661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Importance from RandomForestRegressor (i recomend it , is very useful)","metadata":{}},{"cell_type":"code","source":"def feature_importance(dataframe,target_variable):\n    from sklearn.ensemble import RandomForestRegressor\n    import seaborn as sns\n    v=12\n    w=6\n    considered_features=[]\n    for x in dataframe.columns.values.tolist():\n        if x==target_variable:\n            pass\n        else:\n            considered_features.append(x)\n    col_to_consider=[]\n    for x in considered_features:\n        col_to_consider.append(x)\n    X= dataframe[col_to_consider]\n    Y= dataframe[target_variable]\n    random_forest= RandomForestRegressor(n_estimators=100, max_depth=5, min_samples_leaf=20, min_samples_split=40).fit(X,Y)\n    feature_importances_=random_forest.feature_importances_\n    feature_importances=pd.DataFrame({'Feature_name':col_to_consider, 'Feature_importance':feature_importances_})\n    if len(considered_features)>15:\n        v=32\n        w=24\n    elif len(considered_features)>30:\n        v=64\n        w=48\n    else:\n        pass\n    fig, ax=plt.subplots(1, figsize=(v,w))\n    sns.barplot(x='Feature_name', y='Feature_importance', data=feature_importances, ax=ax)\n    plt.xticks(fontsize=10, rotation=90);\n    plt.yticks(fontsize=12);\n    plt.xlabel('Feature name',fontsize=v)\n    plt.ylabel('Feature importance',fontsize=v)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-06-29T04:09:06.750953Z","iopub.execute_input":"2021-06-29T04:09:06.751415Z","iopub.status.idle":"2021-06-29T04:09:06.76416Z","shell.execute_reply.started":"2021-06-29T04:09:06.75135Z","shell.execute_reply":"2021-06-29T04:09:06.762807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_importance(data,\"price\")","metadata":{"execution":{"iopub.status.busy":"2021-06-29T04:09:06.76552Z","iopub.execute_input":"2021-06-29T04:09:06.765818Z","iopub.status.idle":"2021-06-29T04:09:08.01199Z","shell.execute_reply.started":"2021-06-29T04:09:06.76579Z","shell.execute_reply":"2021-06-29T04:09:08.010583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  As the correlation of Transmission and FuelType with the target variable (price) is too low, we wont use them","metadata":{}},{"cell_type":"markdown","source":"# VIF","metadata":{}},{"cell_type":"code","source":"chosen_col=[\"year\",\"mileage\",\"tax\",\"mpg\",\"engineSize\",\"model\"]\ndef VIF(dataframe,chosen_col):\n    from statsmodels.stats.outliers_influence import variance_inflation_factor as VIF\n    from statsmodels.tools.tools import add_constant\n    X=dataframe[chosen_col]\n    X=add_constant(X)\n    vif_data=pd.DataFrame()\n    vif_data[\"feature\"]=X.columns\n    vif_data[\"VIF\"]=[VIF(X.values, i) for i in range(len(X.columns))]\n    return vif_data","metadata":{"execution":{"iopub.status.busy":"2021-06-29T04:09:08.01352Z","iopub.execute_input":"2021-06-29T04:09:08.013817Z","iopub.status.idle":"2021-06-29T04:09:08.022065Z","shell.execute_reply.started":"2021-06-29T04:09:08.013789Z","shell.execute_reply":"2021-06-29T04:09:08.020961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"VIF(data,chosen_col)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T04:09:08.023438Z","iopub.execute_input":"2021-06-29T04:09:08.023804Z","iopub.status.idle":"2021-06-29T04:09:08.096895Z","shell.execute_reply.started":"2021-06-29T04:09:08.02376Z","shell.execute_reply":"2021-06-29T04:09:08.095369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Looking for outliers","metadata":{}},{"cell_type":"code","source":"def Outliers(dataframe,chosen_cols):\n    import plotly.graph_objects as go\n    from plotly.subplots import make_subplots\n    numeric_col2=[]\n    for x in cols:\n        numeric_col2.append(x)\n\n    fig=make_subplots(rows=1, cols=len(cols))\n\n    for i,col in enumerate(numeric_col2):\n        fig.add_trace(go.Box(y=dataframe[col].values, name=dataframe[col].name), row=1, col=i+1)\n\n    return fig.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-29T04:09:08.09902Z","iopub.execute_input":"2021-06-29T04:09:08.099847Z","iopub.status.idle":"2021-06-29T04:09:08.111802Z","shell.execute_reply.started":"2021-06-29T04:09:08.099792Z","shell.execute_reply":"2021-06-29T04:09:08.10931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols=[\"year\",\"mileage\",\"tax\",\"mpg\",\"engineSize\",\"model\"]\nOutliers(data,cols)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T04:09:08.114898Z","iopub.execute_input":"2021-06-29T04:09:08.116593Z","iopub.status.idle":"2021-06-29T04:09:08.596586Z","shell.execute_reply.started":"2021-06-29T04:09:08.116496Z","shell.execute_reply":"2021-06-29T04:09:08.595494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=data[~(data[\"year\"]<2000)]\ndata=data[~(data[\"mileage\"]>=168017)]\ndata=data[~(data[\"tax\"]>=515)]\ndata=data[~(data[\"tax\"]<45)]\ndata=data[~(data[\"mpg\"]>=117.7)]\ndata=data[~(data[\"engineSize\"]>=4.1)]\ndata=data[~(data[\"model\"]>=22)]","metadata":{"execution":{"iopub.status.busy":"2021-06-29T04:09:08.598629Z","iopub.execute_input":"2021-06-29T04:09:08.599427Z","iopub.status.idle":"2021-06-29T04:09:08.624452Z","shell.execute_reply.started":"2021-06-29T04:09:08.599347Z","shell.execute_reply":"2021-06-29T04:09:08.622998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Linear Prediction","metadata":{}},{"cell_type":"code","source":"def linear_model(dataframe,feature_cols,target_variable):\n    from sklearn.linear_model import LinearRegression\n    X=dataframe[feature_cols]\n    Y=dataframe[target_variable]\n    lm= LinearRegression()\n    lm.fit(X,Y)\n    dataframe[\"Predict\"]=lm.predict(X)\n    dataframe[\"RSE\"]= (dataframe[target_variable] - dataframe[\"Predict\"])**2\n    SSD= sum(dataframe[\"RSE\"])\n    RSE= np.sqrt(SSD/(len(dataframe)-len(feature_cols) -1 ))\n    target_mean= np.mean(dataframe[target_variable])\n    error= RSE/target_mean\n    print(f\"The intercept is {lm.intercept_}\\n\")\n    print(f\"The coefs are: {list(zip(feature_cols,lm.coef_))}\\n\")\n    print(f\"The R2 is: {lm.score(X,Y)}\\n\")\n    print(f\"The SSD is: {SSD}\\n\")\n    print(f\"The RSE is: {RSE}\\n\")\n    print(f\"The {target_variable} mean is: {target_mean}\\n\")\n    print(f\"The error is: {error}\\n\")\n    if len(feature_cols)==1:\n        %matplotlib inline\n        plt.plot(X,Y,\"go\")\n        plt.plot(X,lm.predict(X),color=\"red\")\n        for x in feature_cols:\n            plt.xlabel(x)\n            plt.title(f\"{target_variable} vs {x}\")\n        plt.ylabel(target_variable)\n    else:\n        pass\n","metadata":{"execution":{"iopub.status.busy":"2021-06-29T04:09:08.626085Z","iopub.execute_input":"2021-06-29T04:09:08.626493Z","iopub.status.idle":"2021-06-29T04:09:08.645241Z","shell.execute_reply.started":"2021-06-29T04:09:08.626456Z","shell.execute_reply":"2021-06-29T04:09:08.643642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_cols=[\"year\",\"mileage\",\"tax\",\"mpg\",\"engineSize\",\"model\"]\nlinear_model(data,feature_cols,\"price\")","metadata":{"execution":{"iopub.status.busy":"2021-06-29T04:09:08.647655Z","iopub.execute_input":"2021-06-29T04:09:08.648091Z","iopub.status.idle":"2021-06-29T04:09:08.705778Z","shell.execute_reply.started":"2021-06-29T04:09:08.648041Z","shell.execute_reply":"2021-06-29T04:09:08.703939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The relation between price and all the variables is not linear so we will try a cuadratic model","metadata":{}},{"cell_type":"code","source":"def cuadratic_model(dataframe,feature_cols,target_variable):\n    from sklearn.linear_model import LinearRegression\n    X=dataframe[feature_cols]**2\n    Y=dataframe[target_variable]\n    lm= LinearRegression()\n    lm.fit(X,Y)\n    dataframe[\"Cuadratic_Predict\"]=lm.predict(X)\n    dataframe[\"Cuadratic_RSE\"]= (dataframe[target_variable] - dataframe[\"Cuadratic_Predict\"])**2\n    SSD= sum(dataframe[\"Cuadratic_RSE\"])\n    RSE= np.sqrt(SSD/(len(dataframe)-len(feature_cols) -1 ))\n    target_mean= np.mean(dataframe[target_variable])\n    error= RSE/target_mean\n    print(f\"The intercept is {lm.intercept_}\\n\")\n    print(f\"The coefs are: {list(zip(feature_cols,lm.coef_))}\\n\")\n    print(f\"The R2 is: {lm.score(X,Y)}\\n\")\n    print(f\"The SSD is: {SSD}\\n\")\n    print(f\"The RSE is: {RSE}\\n\")\n    print(f\"The {target_variable} mean is: {target_mean}\\n\")\n    print(f\"The error is: {error}\\n\")\n    if len(feature_cols)==1:\n        %matplotlib inline\n        plt.plot(X,Y,\"go\")\n        plt.plot(X,lm.predict(X),color=\"red\")\n        for x in feature_cols:\n            plt.xlabel(x)\n            plt.title(f\"{target_variable} vs {x}\")\n        plt.ylabel(target_variable)\n    else:\n        pass","metadata":{"execution":{"iopub.status.busy":"2021-06-29T04:09:08.71258Z","iopub.execute_input":"2021-06-29T04:09:08.713286Z","iopub.status.idle":"2021-06-29T04:09:08.768969Z","shell.execute_reply.started":"2021-06-29T04:09:08.713232Z","shell.execute_reply":"2021-06-29T04:09:08.766219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cuadratic_model(data,feature_cols,\"price\")","metadata":{"execution":{"iopub.status.busy":"2021-06-29T04:09:08.772627Z","iopub.execute_input":"2021-06-29T04:09:08.77331Z","iopub.status.idle":"2021-06-29T04:09:08.828553Z","shell.execute_reply.started":"2021-06-29T04:09:08.773248Z","shell.execute_reply":"2021-06-29T04:09:08.82671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We can see a small increase and decrease of R2 and the error**","metadata":{}},{"cell_type":"markdown","source":"# Now we will try a polynomial model at the same time, using different degrees to see whom  suits better","metadata":{}},{"cell_type":"code","source":"def polynomial_model(dataframe,feature_cols,target_variable,degree_number):\n    from sklearn.preprocessing import PolynomialFeatures\n    from sklearn import linear_model\n    poly= PolynomialFeatures(degree=degree_number)\n    X= poly.fit_transform(dataframe[feature_cols])\n    Y= dataframe[target_variable]\n    lm= linear_model.LinearRegression()\n    lm.fit(X,Y)\n    dataframe[\"Cuadratic_Linear_Predict\"]=lm.predict(X)\n    dataframe[\"Cuadratic_Linear_RSE\"]= (dataframe[target_variable] - dataframe[\"Cuadratic_Linear_Predict\"])**2\n    SSD= sum(dataframe[\"Cuadratic_Linear_RSE\"])\n    RSE= np.sqrt(SSD/(len(dataframe)-len(feature_cols) -1 ))\n    target_mean= np.mean(dataframe[target_variable])\n    error= RSE/target_mean\n    print(f\"The intercept is {lm.intercept_}\\n\")\n    print(f\"The coefs are: {lm.coef_}\\n\")\n    print(f\"The R2 is: {lm.score(X,Y)}\\n\")\n    print(f\"The SSD is: {SSD}\\n\")\n    print(f\"The RSE is: {RSE}\\n\")\n    print(f\"The {target_variable} mean is: {target_mean}\\n\")\n    print(f\"The error is: {error}\\n\")\n   ","metadata":{"execution":{"iopub.status.busy":"2021-06-29T04:09:08.831876Z","iopub.execute_input":"2021-06-29T04:09:08.83255Z","iopub.status.idle":"2021-06-29T04:09:08.858467Z","shell.execute_reply.started":"2021-06-29T04:09:08.832497Z","shell.execute_reply":"2021-06-29T04:09:08.856524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"polynomial_model(data,feature_cols,\"price\",3)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T04:09:08.860752Z","iopub.execute_input":"2021-06-29T04:09:08.861258Z","iopub.status.idle":"2021-06-29T04:09:08.973931Z","shell.execute_reply.started":"2021-06-29T04:09:08.861205Z","shell.execute_reply":"2021-06-29T04:09:08.969535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# We got an R2 of 92% and an error of 12%. Which is good. But now, we will use a func that increases the degrees to see wich one is better","metadata":{}},{"cell_type":"code","source":"def degree_increase(dataframe,feature_cols,target_variable,Max_Degree_Number):\n    from sklearn.linear_model import LinearRegression\n    from sklearn.preprocessing import PolynomialFeatures\n    from sklearn import linear_model\n    for d in range(2,Max_Degree_Number+1):\n        poly= PolynomialFeatures(degree=d)\n        X= poly.fit_transform(dataframe[feature_cols])\n        Y= dataframe[target_variable]\n        lm= linear_model.LinearRegression()\n        lm.fit(X,Y)\n        dataframe[\"Cuadratic_Linear_Predict\"]=lm.predict(X)\n        dataframe[\"Cuadratic_Linear_RSE\"]= (dataframe[target_variable] - dataframe[\"Cuadratic_Linear_Predict\"])**2\n        SSD= sum(dataframe[\"Cuadratic_Linear_RSE\"])\n        RSE= np.sqrt(SSD/(len(dataframe)-len(feature_cols) -1 ))\n        target_mean= np.mean(dataframe[target_variable])\n        error= RSE/target_mean\n        print(f\"For the regression of degree {d}:\\nThe R2 is {lm.score(X,Y)}\")\n        print(f\"The intercept is: {lm.intercept_}\")\n        print(f\"The coefs are: {lm.coef_}\")\n        print(f\"The error is {error}\")\n        print(f\"The SSD is {SSD}\")\n        print(f\"The RSE is {RSE}\")\n        print()\n        ","metadata":{"execution":{"iopub.status.busy":"2021-06-29T04:09:08.97617Z","iopub.execute_input":"2021-06-29T04:09:08.976646Z","iopub.status.idle":"2021-06-29T04:09:08.993119Z","shell.execute_reply.started":"2021-06-29T04:09:08.976602Z","shell.execute_reply":"2021-06-29T04:09:08.992014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We will set a maximum degree of 6**","metadata":{}},{"cell_type":"code","source":"degree_increase(data,feature_cols,\"price\",6)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T04:09:08.994807Z","iopub.execute_input":"2021-06-29T04:09:08.995618Z","iopub.status.idle":"2021-06-29T04:09:10.945191Z","shell.execute_reply.started":"2021-06-29T04:09:08.99557Z","shell.execute_reply":"2021-06-29T04:09:10.94408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* We see that 3 is the best degree. \n* This is my first Kaggle Notebook and i am super new to ML. So i would love some feedback. \n* Thx for Watching","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}