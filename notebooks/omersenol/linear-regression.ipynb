{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ****Include DataSet****"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/videogamesales/vgsales.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Delete Unnecessary Variables For Data Science"},{"metadata":{},"cell_type":"markdown","source":"We will not use \"Rank\", \"Name\", \"Year\", \"Publisher\" variables in this data set. So we will delete these variables from the data set using the \"drop\" function.\n\nIn this function, the \"axis\" parameter determines whether it will be a row or a column. If we set \"axis = 1\", the column will be deleted.\n\nThe \"inplace\" parameter is marked as \"False\" in the default setting. If we change this to \"True\", changes will be automatically saved in the data set.\n\n\nIf we do not use the \"inplace\" parameter, we will have to do it \"\"\"df = df.drop ([\"Rank\", \"Name\", \"Year\", \"Publisher\"], axis = 1)\"\"\""},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop([\"Rank\",\"Name\",\"Year\",\"Publisher\"],axis=1,inplace=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Converting Categorical Variables To Numeric variables"},{"metadata":{},"cell_type":"markdown","source":"\nCategorical variables are transformed with the \"get_dummies\" function in pandas."},{"metadata":{"trusted":true},"cell_type":"code","source":"dums = pd.get_dummies(df[[\"Platform\",\"Genre\"]])\ndums.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After the categorical variables are converted, any transformed new variable belonging to each variable is selected and deleted.\n\nBecause the value of the deleted variable can be understood by looking at the other transformed variables already remaining.\n\n\nFor example, if all non-deleted variables are 0, it means that the deleted variable must be 1."},{"metadata":{"trusted":true},"cell_type":"code","source":"dums.drop([\"Platform_2600\",\"Genre_Misc\"],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nThen, a new data set is created by combining the data set with the newly created variables. The old categorical variables that have been transformed are removed from the data set because they are no longer needed."},{"metadata":{"trusted":true},"cell_type":"code","source":"final_df= pd.concat([df,dums],axis=1)\nfinal_df.drop([\"Platform\",\"Genre\"],axis=1,inplace=True)\nfinal_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nThis data set is now ready to be used. Let's start."},{"metadata":{},"cell_type":"markdown","source":"# Simple Linear Regression"},{"metadata":{},"cell_type":"markdown","source":"### Outlier Control"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\ng = sns.regplot(final_df.Global_Sales,final_df.EU_Sales,ci=None,scatter_kws= {\"color\":\"r\",\"s\":9});\nplt.xlim(-2,85)\nplt.ylim(bottom=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see, there is 1 extreme outlier in the variable \"EU_Sales\", so let's eliminate this value."},{"metadata":{"trusted":true},"cell_type":"code","source":"final_df.EU_Sales[df.EU_Sales>15]\n#this value is in index 0.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_outlier = final_df.drop([0],axis=0) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\ng = sns.regplot(df_outlier.Global_Sales,df_outlier.EU_Sales,ci=None,scatter_kws= {\"color\":\"r\",\"s\":9});\nplt.xlim(-2,45)\nplt.ylim(bottom=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's choose dependent and independent variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"x = df_outlier[[\"EU_Sales\"]]\ny = df_outlier[\"Global_Sales\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nTo process the data, let's create the model and fit this model with X and Y variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"reg = LinearRegression()\nmodel = reg.fit(x,y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nLet's look at the score of the model we created."},{"metadata":{"trusted":true},"cell_type":"code","source":"model.score(x,y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nAfter creating the model, let's make it guess by giving certain values. (It predicts the \"Global_Sales\" variable according to the \"EU_Sales\" variable.)"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.predict([[15]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"est = [[12],[30],[50]]\nmodel.predict(est)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Multiple Linear Regression"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"\nIn multiple linear regression, this difference is selected as dependent on one variable and all remaining variables are selected as independent variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"x=final_df.drop(\"Global_Sales\",axis =1)\ny = final_df.Global_Sales","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we need to divide our data set into \"test\" and \"train\". Because after training our program from the \"train\" set, we will test it with our \"test\" set to see the error value.\n\nFor this we will use the **\"train_test_split\"** function in the **\"scikit-learn\"** module."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.20,random_state = 13)\n#test_size = \"selects what percentage of the data set will get as \"test\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x_train.shape)\nprint(y_train.shape)\nprint(x_test.shape)\nprint(y_test.shape)\n#Let's look at the shape information","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lm = LinearRegression()\nmodel = lm.fit(x_train,y_train)\n#Let's create our model and train \"x_train\" and \"y_train\" sets.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nAfter training our model, let's look at the total error squares (margin of error) with the \"mean_squared_error\" method in the scikit-learn module.\n\n\nThe model is provided to generate estimates by using the \"x_test\" set. It is then checked how close this generated prediction is to the \"y_test\" set.\n\nThe number becomes readable by inserting it into the squaring function in the numpy module."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\ny_pred = model.predict(x_test)\nnp.sqrt(mean_squared_error(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}