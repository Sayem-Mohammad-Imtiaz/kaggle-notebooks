{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"ed8bffe1-4a77-7785-3e1b-769987301672"},"source":"Hello guys,\n\nAt this moment, I've found **average Accident Count per month is increased after oil price falling**. I suspect the one reason is that maintenance personnel and cost are decreased in difficult situation in the industry."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2a7a65ac-101b-93bb-7e9c-c176f18b2440"},"outputs":[],"source":"#handling datarame\nimport pandas as pd\nfrom pandas import Series ,DataFrame\nimport numpy as np\n\n#drawing charts\nimport matplotlib.pyplot as plt\n#plt.xkcd()\nimport seaborn as sns\n%matplotlib inline\n\nimport datetime\ndf = pd.read_csv('../input/database.csv')\ndf.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"30d227fe-f7a6-c7a9-cf0a-cf94a7602f1d"},"source":"**Overview** \n\n'info' shows column names and that some of columns have null data. \n\nIt's challenging to analyze the data-set which includes various data, such as Time, Location, Production type and unfortunate Injuries / Fatalities..."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e69ca8ce-bdb6-0c7c-ca7a-bb0a94adbc07"},"outputs":[],"source":"df.info()"},{"cell_type":"markdown","metadata":{"_cell_guid":"7e34362a-6826-ad4e-f6f6-1033a20688a8"},"source":"**Time dependence of accident.**\n\n**Year**\nTrouble increase from 2013 to 2015. Meanwhile, oil prices kept high range and the industory had high activity. On the other hand, the maintenance might be enough.\nprice data can be referred 'WTI Cushing Oklahoma' from http://www.eia.gov/dnav/pet/pet_pri_spt_s1_d.htm\n\n**Month**\nJanuary may have something affects occurrence. However, I have no idea at this moment.\n\n**Day/Date**\nDay affects occurrence, compared to Date. There are trouble at random from the view of Day. However, weekend has less accidents than weekday.\n\n**Time slot**\nDaytime has more troubles than nighttime. It's necessary to inspect, repair etc as usual tasks in daytime. Workers just monitor facility in nighttime. Usually, human error may cause accident."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"76b2c891-0e3d-0480-9e3f-61679e160c36"},"outputs":[],"source":"def myDateTime (date):\n    time_format = '%m/%d/%Y %I:%M %p'\n    date_obj = datetime.datetime.strptime(date, time_format)\n    return date_obj\n\ndef Weekday(date):\n    wday_dum = date.weekday()\n    if wday_dum is 0:\n        wday = 'Mon'\n    elif wday_dum is 1:\n        wday = 'Tue'\n    elif wday_dum is 2:\n        wday = 'Wed'\n    elif wday_dum is 3:\n        wday = 'Thu'\n    elif wday_dum is 4:\n        wday = 'Fri'\n    elif wday_dum is 5:\n        wday = 'Sat'\n    else:\n        wday = 'Sun'\n    return wday\n\nHour = lambda x: x.hour\nDay = lambda x: x.day\nMonth = lambda x: x.month\nYear = lambda x: x.year\n\ndf['Time_obj'] = df['Accident Date/Time'].apply(myDateTime)\n\ncat = [Year,Month,Day,Hour]\nnum = len(cat)\n\nplt.figure(figsize=(10,10))\nfor (i, c) in enumerate(cat):\n    plt.subplot(num+1,1,i+1)\n    sns.countplot(df['Time_obj'].apply(c))\n    plt.xlabel('')\n    plt.ylabel('accident cnt')\n\nplt.subplot(num+1,1,5)\nsns.countplot(df['Time_obj'].apply(Weekday),order=['Mon','Tue','Wed','Thu','Fri','Sat','Sun'])\nplt.xlabel('')\nplt.ylabel('accident cnt')\nplt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0, hspace=0.5)"},{"cell_type":"markdown","metadata":{"_cell_guid":"ba5f189f-a5a2-8033-7ddb-2a568ed16ac7"},"source":"**Compare with Oil Price**\n\nI've looked at Oil Price data, such as 'WTI Cushing Oklahoma' from http://www.eia.gov/dnav/pet/pet_pri_spt_s1_d.htm\nDownload the price data and computed average by month.\n\nThe price data was grouped by month, that shown falling down of oil price caused October-December 2014, sharply. And, after Dec. 2014, the average price never goes up above 60 USD/bbl  \n\nFrom here, analysis is proceeded with Accident Count per month, All Costs averaged by Accident Count, Net Loss averaged by Accident Count, Injuries per month, Fatalities per month.\n\nIn the DataFrame which includes monthly data generated below, index 59 is identified as Dec 2014. So, the data will split into two group at index 58/59. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6c9aed65-a47a-c3d2-4792-8f0bce7b9958"},"outputs":[],"source":"# Price data is referred 'WTI Cushing Oklahoma' from http://www.eia.gov/dnav/pet/pet_pri_spt_s1_d.htm\n# the data is averaged by month and pasted here\n\n'''\nprice = pd.read_csv('Spot_Prices.csv')\nprice.columns = ['Day', 'Cushing']\n\ndef myDate (date):\n    time_format = '%m/%d/%Y'\n    date_obj = datetime.datetime.strptime(date, time_format)\n    return date_obj\n\nprice['Day_obj'] = price['Day'].apply(myDate)\n\nY = np.arange(2010,2017,1)\nM = np.arange(1,13,1)\n\ndummy = np.zeros([len(Y),len(M)])\n\nfor (i,y) in enumerate(Y):\n    for (j,m) in enumerate(M):\n        dummy[i,j] =  price[price['Day_obj'].apply(Year)==y][price['Day_obj'].apply(Month)==m].mean()\n\nprice_month = Series(dummy.reshape([len(Y)*len(M)]))\n'''\n\nprice_month = Series([ 78.32578947,   76.38736842,   81.20347826,   84.29285714,\n         73.7435    ,   75.33590909,   76.31952381,   76.59909091,\n         75.24190476,   81.89285714,   84.25285714,   89.14590909,\n         89.1705    ,   88.57842105,  102.85652174,  109.5325    ,\n        100.90047619,   96.26409091,   97.3035    ,   86.33304348,\n         85.5152381 ,   86.32238095,   97.16047619,   98.56285714,\n        100.2735    ,  102.204     ,  106.15772727,  103.321     ,\n         94.65454545,   82.30333333,   87.8952381 ,   94.13130435,\n         94.51368421,   89.49130435,   86.53142857,   87.8595    ,\n         94.75666667,   95.30894737,   92.9385    ,   92.02136364,\n         94.50954545,   95.7725    ,  104.67090909,  106.57272727,\n        106.2895    ,  100.53826087,   93.864     ,   97.6252381 ,\n         94.61714286,  100.81736842,  100.80380952,  102.06904762,\n        102.17714286,  105.79428571,  103.58863636,   96.53619048,\n         93.314     ,   83.77952381,   75.78947368,   59.29045455,\n         47.219     ,   50.58421053,   47.82363636,   54.45285714,\n         59.265     ,   59.81954545,   51.16304348,   42.86761905,\n         45.50409091,   46.22363636,   42.3852381 ,   37.20652174,\n         31.9555    ,   30.323     ,   37.54636364,   40.7552381 ,\n         46.71238095,   48.75727273,   44.6515    ,   44.72434783,\n         45.14636364,   49.7752381 ,   45.66095238,   51.97047619])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"78c82fff-febb-1741-e206-dcd2924e7d37"},"outputs":[],"source":"Y = np.arange(2010,2017,1)\nM = np.arange(1,13,1)\n\ndummy = np.zeros([len(Y),len(M)])\n\nfor (i,y) in enumerate(Y):\n    for (j,m) in enumerate(M):\n        dummy[i,j] =  df[df['Time_obj'].apply(Year)==y][df['Time_obj'].apply(Month)==m]['Report Number'].count()\ncount_month = Series(dummy.reshape([len(Y)*len(M)]))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4e06c6ce-dcb0-ed8a-f7e8-187e9879497a"},"outputs":[],"source":"dummy = np.zeros([len(Y),len(M)])\nfor (i,y) in enumerate(Y):\n    for (j,m) in enumerate(M):\n        #dummy[i,j] =  np.log10(df[df['Time_obj'].apply(Year)==y][df['Time_obj'].apply(Month)==m]['All Costs'].sum())\n        dummy[i,j] =  df[df['Time_obj'].apply(Year)==y][df['Time_obj'].apply(Month)==m]['All Costs'].sum()\ncost_month = Series(dummy.reshape([len(Y)*len(M)]))\ncost_month_ave = cost_month/count_month\ncost_month_ave_log = np.log10(cost_month_ave)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a5a2c350-0e9b-52c9-47ab-61e1bbe9b56f"},"outputs":[],"source":"dummy = np.zeros([len(Y),len(M)])\nfor (i,y) in enumerate(Y):\n    for (j,m) in enumerate(M):\n        #dummy[i,j] =  np.log10(df[df['Time_obj'].apply(Year)==y][df['Time_obj'].apply(Month)==m]['Net Loss (Barrels)'].sum())\n        dummy[i,j] =  df[df['Time_obj'].apply(Year)==y][df['Time_obj'].apply(Month)==m]['Net Loss (Barrels)'].sum()\nloss_month = Series(dummy.reshape([len(Y)*len(M)]))\nloss_month_ave = loss_month/count_month\nloss_month_ave_log = np.log10(loss_month_ave)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0505838d-d9f6-f827-08e1-6b82f82d355b"},"outputs":[],"source":"dummy = np.zeros([len(Y),len(M)])\nfor (i,y) in enumerate(Y):\n    for (j,m) in enumerate(M):\n        dummy[i,j] =  df[df['Time_obj'].apply(Year)==y][df['Time_obj'].apply(Month)==m]['All Injuries'].sum()\n\ninjury_month = Series(dummy.reshape([len(Y)*len(M)]))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"32af9c7e-cf35-b914-51e9-1be0ae8ccf77"},"outputs":[],"source":"dummy = np.zeros([len(Y),len(M)])\nfor (i,y) in enumerate(Y):\n    for (j,m) in enumerate(M):\n        dummy[i,j] =  df[df['Time_obj'].apply(Year)==y][df['Time_obj'].apply(Month)==m]['All Fatalities'].sum()\n\nfatality_month = Series(dummy.reshape([len(Y)*len(M)]))"},{"cell_type":"markdown","metadata":{"_cell_guid":"0ce6746c-4ba6-361f-7577-ca5fc2a3af40"},"source":"**Merge the above**\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e7914bcf-37aa-c39c-082a-03fc882e5dcd"},"outputs":[],"source":"dummy = [None for col in range(len(M)*len(Y))]\nfor (i,y) in enumerate(Y):\n    for (j,m) in enumerate(M):\n        dummy[j+len(M)*i] = str(y) +'-' + str(m) \n\nMonthly = pd.DataFrame([price_month, count_month,cost_month_ave_log, loss_month_ave_log, injury_month, fatality_month]).T\nMonthly.columns = ['Oil Price', 'Accident Count','All Cost Ave. (log10)', 'Net Loss Ave. (log10)', 'Injury', 'Fatality']\nMonthly.index = dummy\n\nMonthly.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"c7d433af-24e3-a7c1-2ae7-3886a1c1edb7"},"source":"\n\n**Accident count per month**\n\nAccident count is grouped by month from original data-set. The moving seems to be flat or slightly increasing.\n\n**All Cost**\n\nAll Costs data is grouped by month, taken average and in log10. All Cost Average seems to be at random in a range. But, huge value strongly affect on the average sometimes. \n\n**Net Loss**\n\nNet Loss data is grouped by month, taken average and in log10. Net Loss Average seems to be at random. But, there is more variance than All Cost Average. I think, some accident doesn't have relation to oil spill. \n\n**Injuries**\n\nInjuries happen regularly, unfortunately. Its distribution seems to be a Poisson Distribution from chi2-test.\n\n**Fatality**\n\nFatalities happen regularly, unfortunately. Its distribution seems to be a Poisson Distribution from chi2-test."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2b436e04-4f88-364a-8cc4-7e909b1a63f4"},"outputs":[],"source":"num = len(Monthly.columns)\n\nplt.figure(figsize=(10,12))\nfor (i,c) in enumerate(Monthly.columns):\n    plt.subplot(num+1,1,i+1)\n    Monthly[c].plot()\n    plt.ylabel(c)\n    \nplt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0, hspace=0.3)"},{"cell_type":"markdown","metadata":{"_cell_guid":"04c3251a-08e7-fbbc-aa5e-90f276723c64"},"source":"**Scatter matrix**\n\nThe correlations seems to be small from scatter plot each other.\n\nHonestly, I've expected a large correlation between All Cost and Net Loss because, for example, serious damage on property supposes to cause large amount of loss."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f141d249-1bc9-066a-b902-e643db9ad7c9"},"outputs":[],"source":"from pandas.tools.plotting import scatter_matrix\nscatter_matrix(Monthly, alpha=1, figsize=(10, 10), diagonal='kde')"},{"cell_type":"markdown","metadata":{"_cell_guid":"3070f64b-d49b-9f9c-ab2a-af6041d3cb71"},"source":"**t-test for averages**\n\nt-tests are carried out for monthly data to find difference between oil price falling around Nov. / Dec. 2014\n\nThe test shows that Accident Count has difference at 0.05 of level of significance. The others seems to be same each other between the price falling. \n\nIn other words, Accident Count increased after the oil price falling. But, other point of view such as Cost, Net Loss for each accident didn't change after the falling. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ad667f0b-a8f4-31b5-c019-42ccbfe82a0e"},"outputs":[],"source":"# to find difference between before/after oil price falling\n# compare average by t-test\n# Injury and Fatality are skipped for the t-test since these seem not normal distribution\n\nfrom scipy import stats\ncat = Monthly.columns.drop(['Oil Price', 'Injury', 'Fatality'])\nthreshold = 60\n\nfor c in cat:\n    print('='*30)\n    print('category: [',c,']')\n    ave_high = Monthly[Monthly['Oil Price']>threshold][c].mean()\n    ave_low = Monthly[Monthly['Oil Price']<threshold][c].mean()\n\n    print('ave. befor price falling is ', ave_high)\n    print('ave. after price falling is ', ave_low)\n\n    #F-test for variances are equal or not\n    f = np.var(Monthly[Monthly['Oil Price']>threshold][c]) / np.var(Monthly[Monthly['Oil Price']<threshold][c])\n    if f < 1:\n        f = 1/f\n    dfx = len(Monthly[Monthly['Oil Price']>threshold][c]) - 1\n    dfy = len(Monthly[Monthly['Oil Price']<threshold][c]) - 1\n    p_value = stats.f.cdf(f, dfx, dfy)\n    print('F_value is ', f, ' and p_value of the F is ', p_value)\n\n    # t-test (welch) for averages are equal or not\n    t, p = stats.ttest_ind(Monthly[Monthly['Oil Price']>threshold][c], Monthly[Monthly['Oil Price']<threshold][c], equal_var = True)\n    print('t_value is ', t,' p_value of t is ', p)"},{"cell_type":"markdown","metadata":{"_cell_guid":"6f322df4-2cbc-7970-3250-cd8e9f7243ed"},"source":"**Chi2-test for distributions**\n\nThe test shows that both Injury and Fatality seems to be Poisson Distribution.\nThen, the number of victim by can be expected probabilistically."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"385b8ff4-2e15-29d3-6cfd-fc0ec1b070ba"},"outputs":[],"source":"import numpy.random as rd\n#theoretical values of poisson distribution for 84 months\nx = Series(rd.poisson(Monthly['Injury'].mean(),100000)).value_counts()*len(Monthly)/100000\ny = Monthly['Injury'].value_counts()\nz = pd.concat([x,y],axis=1).fillna(0)\n\nx2, p, dof, expected = stats.chi2_contingency(z)\n\nprint(\"chi2_value %(x2)s\" %locals() )\nprint(\"p_value %(p)s\" %locals() )"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a7ef7f16-3b74-fbf9-4435-4b2ab4d6f2dc"},"outputs":[],"source":"x = Series(rd.poisson(Monthly['Fatality'].mean(),100000)).value_counts()*len(Monthly)/100000\ny = Monthly['Fatality'].value_counts()\nz = pd.concat([x,y],axis=1).fillna(0)\n\nx2, p, dof, expected = stats.chi2_contingency(z)\n\nprint(\"chi2_value %(x2)s\" %locals() )\nprint(\"p_value %(p)s\" %locals() )"},{"cell_type":"markdown","metadata":{"_cell_guid":"d4469b06-bd17-a465-16ed-485311fdebbc"},"source":"**All Cost & Location**\n\nIn addition, Accident locations are mapped with All Cost.\nThere seems to have no relation between Location and All Costs."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7ed9e4ea-5886-45f0-c8ea-1eaf5480837c"},"outputs":[],"source":"# plot locations of accidents with cost information\n# but, accidents occur these costs are random regardless of location\nimport plotly.plotly as py\nimport plotly.graph_objs as go\nfrom plotly import tools\nfrom plotly.offline import iplot, init_notebook_mode\ninit_notebook_mode()\n\ntraces = []\n\ncost = []\nfor i in range(9):\n    cost.append(10**i)\n\ncolors = ['rgb(0, 0, 0)', 'rgb(102, 102, 102)', 'rgb(102, 153, 204)',\n          'rgb(102, 153, 255)', 'rgb(153, 255, 255)','rgb(204, 255, 0)',\n          'rgb(255, 204, 0)', 'rgb(255, 102, 0)','rgb(255, 0, 0)']\n    \nfor (i,c) in enumerate(cost):\n    traces.append(dict(\n        type = 'scattergeo',\n        locationmode = 'USA-states',\n        lon = df[(df['All Costs']<(c*10)) & (df['All Costs']>c)]['Accident Longitude'],\n        lat = df[(df['All Costs']<(c*10)) & (df['All Costs']>c)]['Accident Latitude'],\n        mode = 'markers',\n        hoverinfo = 'text+name',\n        name = str(c) +\" < All Costs < \"+ str(c*10),\n        marker = dict( \n            opacity = 0.85,\n            color = colors[i],\n            line = dict(color = 'rgb(0, 0, 0)', width = 1)\n        )\n    ))\n\nlayout = dict(\n         title = 'Pipeline accidents in USA<br>'\n                 '<sub>Click Legend to Display or Hide Categories</sub>',\n         showlegend = True,\n         legend = dict(\n             x = 0.85, y = 0.4\n         ),\n         geo = dict(\n             scope = 'usa',\n             projection = dict(type = 'albers usa'),\n             showland = True,\n             landcolor = 'rgb(250, 250, 250)',\n             subunitwidth = 1,\n             subunitcolor = 'rgb(217, 217, 217)',\n             countrywidth = 1,\n             countrycolor = 'rgb(217, 217, 217)',\n             showlakes = True,\n             lakecolor = 'rgb(255, 255, 255)')\n        )\n\nfigure = dict(data = traces, layout = layout)\niplot(figure)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}