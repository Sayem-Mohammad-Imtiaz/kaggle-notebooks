{"cells":[{"metadata":{},"cell_type":"markdown","source":"## California Housing Price\n- predict median price per district\n- model: binary classification/labeled supervised learning\n- dataset: https://github.com/ageron/handson-ml2/tree/master/datasets/housing"},{"metadata":{},"cell_type":"markdown","source":"### 1. Read Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport tensorflow as tf\nfrom tensorflow import feature_column\nfrom tensorflow.keras import layers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv(\"../input/california-housing-prices/housing.csv\")\ndf['median_house_value']/=1000\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()\n#total_badrooms 207/20640 is missing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df.dropna()\ndf.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Data Exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Take away:\n- comparing to 75%, max for `total_rooms`, `population`, `households` need a further check.\n- abnormal data for target col `median_house_value`."},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df[(df.total_rooms<=5000)&(df.total_bedrooms<=1000)&(df.population<=2500)&(df.households<=1000)&\n      (df.median_income<=8)&(df.median_house_value<500)]\n\n#df.median_house_value.hist(bins=100)\n#df.total_bedrooms.hist(bins=100)\n#df.median_income.hist(bins=100)\n#df.total_rooms.hist(bins=100)\n#df.population.hist(bins=100)\n#df.households.hist(bins=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler=StandardScaler()\nscaled_df=scaler.fit_transform(df.loc[:,df.columns!='ocean_proximity']) \nscaled_df=pd.DataFrame(scaled_df,columns=df.columns.values[0:-1])\nscaled_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaled_df.hist(bins=100,figsize=(15,10))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"# binary classification, if over threshold, label as 1, otherwise, label as 0.\nthreshold= 1.0 \nscaled_df[\"median_house_value_is_high\"] = (scaled_df[\"median_house_value\"] > threshold).astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_columns = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#location\nresolution_in_degrees = 0.4 \n\nlatitude_num = tf.feature_column.numeric_column(\"latitude\")\nlatitude_bins = list(np.arange(int(min(train_df['latitude'])), int(max(train_df['latitude'])), resolution_in_degrees))\nlatitude = tf.feature_column.bucketized_column(latitude_num, latitude_bins)\n\nlongitude_num = tf.feature_column.numeric_column(\"longitude\")\nlongitude_bins = list(np.arange(int(min(train_df['longitude'])), int(max(train_df['longitude'])), resolution_in_degrees))\nlongitude = tf.feature_column.bucketized_column(longitude_num, longitude_bins)\n\nlat_x_lon = tf.feature_column.crossed_column([latitude, longitude], hash_bucket_size=100)\ncrossed_location = tf.feature_column.indicator_column(lat_x_lon)\nfeature_columns.append(crossed_location)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.ocean_proximity.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ocean proximity\nocean_prox= tf.feature_column.categorical_column_with_vocabulary_list(\n      'ocean_proximity', ['<1H OCEAN', 'INLAND','NEAR OCEAN','NEAR BAY','ISLAND'])\n\n#ocean_prox_ohe = feature_column.indicator_column(ocean_prox)\nfeature_columns.append(ocean_prox)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#demographic\nmed_income = tf.feature_column.numeric_column(\"median_income\")\nfeature_columns.append(med_income)\n\npopulation = tf.feature_column.numeric_column(\"population\")\nfeature_columns.append(population)\n\nhouseholds = tf.feature_column.numeric_column(\"households\")\nfeature_columns.append(households)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#house\nhouse_age=tf.feature_column.numeric_column(\"housing_median_age\")\nfeature_columns.append(house_age)\n\nttl_room=tf.feature_column.numeric_column(\"total_rooms\")\nfeature_columns.append(ttl_room)\n\nttl_bedroom=tf.feature_column.numeric_column(\"total_bedrooms\")\nfeature_columns.append(ttl_bedroom)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_layer = layers.DenseFeatures(feature_columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train/Test Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_df, test_df= train_test_split(scaled_df,test_size=0.22, random_state=123)\nprint(\"Total df size: %i\\n train_df size: %i \\n test_df size: %i\"\\\n%(df.shape[0],train_df.shape[0],test_df.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4. Modeling"},{"metadata":{},"cell_type":"markdown","source":"### 4.1 Define functions that build and train a model\n- build_model(learning_rate), which builds a randomly-initialized model.\n- train_model(model, feature, label, epochs), which trains the model from the examples (feature and label) you pass."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Define the functions that create and train a model.\ndef create_model(my_learning_rate, feature_layer, my_metrics): #add one more var\n  model = tf.keras.models.Sequential()\n\n  model.add(feature_layer)\n  model.add(tf.keras.layers.Dense(units=1, input_shape=(1,),\n                                  activation=tf.sigmoid),)\n\n  model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=my_learning_rate),                                                   \n                loss=tf.keras.losses.BinaryCrossentropy(), #binaryloss vs rmse\n                metrics=my_metrics) #my_metrics\n  return model        \n\n\ndef train_model(model, dataset, epochs, label_name,\n                batch_size=None, shuffle=True):\n    \n  features = {name:np.array(value) for name, value in dataset.items()}\n  label = np.array(features.pop(label_name)) \n  history = model.fit(x=features, y=label, batch_size=batch_size,\n                      epochs=epochs, shuffle=shuffle)\n  \n  epochs = history.epoch\n  hist = pd.DataFrame(history.history) #hist vs rmse\n\n  return epochs, hist  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.2 Define plotting functions\n- a loss curve"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Define the plotting function.\ndef plot_curve(epochs, hist, list_of_metrics):\n  plt.figure()\n  plt.xlabel(\"Epoch\")\n  plt.ylabel(\"Value\")\n\n  for m in list_of_metrics:\n    x = hist[m]\n    plt.plot(epochs[1:], x[1:], label=m)\n\n  plt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.3 Call the model functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Hyperparameters.\nlearning_rate = 0.001\nepochs = 20\nbatch_size = 100\nlabel_name = \"median_house_value_is_high\"\nthreshold = 0.35\n\n# Establish the metrics the model will measure.\nMETRICS = [\n           tf.keras.metrics.BinaryAccuracy(name='accuracy', threshold=threshold),\n           tf.keras.metrics.Precision(name='precision',thresholds=threshold),\n           tf.keras.metrics.Recall(name='recall',thresholds=threshold),\n           #tf.keras.metrics.AUC(name='auc',thresholds=threshold)\n          ]\n\nmy_model = create_model(learning_rate, feature_layer, METRICS)\n\nepochs, hist = train_model(my_model, train_df, epochs, \n                           label_name, batch_size)\n\nlist_of_metrics_to_plot = ['accuracy','precision','recall'] \n\nplot_curve(epochs, hist, list_of_metrics_to_plot)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# change thresholds\nlearning_rate = 0.001\nepochs = 20\nbatch_size = 100\nlabel_name = \"median_house_value_is_high\"\nthreshold = 0.52\n\n# Establish the metrics the model will measure.\nMETRICS = [\n           tf.keras.metrics.BinaryAccuracy(name='accuracy', threshold=threshold),\n           tf.keras.metrics.Precision(name='precision',thresholds=threshold),\n           tf.keras.metrics.Recall(name='recall',thresholds=threshold),\n           #tf.keras.metrics.AUC(name='auc',thresholds=threshold)\n          ]\n\nmy_model = create_model(learning_rate, feature_layer, METRICS)\n\nepochs, hist = train_model(my_model, train_df, epochs, \n                           label_name, batch_size)\n\nlist_of_metrics_to_plot = ['accuracy','precision','recall'] \n\nplot_curve(epochs, hist, list_of_metrics_to_plot)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- A `threshold` of slightly over 0.5 appears to produce the highest accuracy (about 83%). \n- Raising the `threshold` to 0.9 drops accuracy by about 5%.\n- Lowering the `threshold` to 0.3 drops accuracy by about 3%. "},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"\\n: Evaluate the new model on the test set:\")\ntest_features = {name:np.array(value) for name, value in test_df.items()}\ntest_label = np.array(test_features.pop(label_name))\nmy_model.evaluate(x=test_features, y=test_label, batch_size=batch_size)\n#87%","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#AUC\nlearning_rate = 0.001\nepochs = 20\nbatch_size = 100\nlabel_name = \"median_house_value_is_high\"\n\nMETRICS = [\n      tf.keras.metrics.AUC(num_thresholds=100, name='auc'),\n]\n\n# Establish the model's topography.\nmy_model = create_model(learning_rate, feature_layer, METRICS)\n\n# Train the model on the training set.\nepochs, hist = train_model(my_model, train_df, epochs, \n                           label_name, batch_size)\n\n# Plot metrics vs. epochs\nlist_of_metrics_to_plot = ['auc'] \nplot_curve(epochs, hist, list_of_metrics_to_plot)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"\\n: Evaluate the new model on the test set:\")\ntest_features = {name:np.array(value) for name, value in test_df.items()}\ntest_label = np.array(test_features.pop(label_name))\nmy_model.evaluate(x=test_features, y=test_label, batch_size=batch_size)\n#AUC:0.9059","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}