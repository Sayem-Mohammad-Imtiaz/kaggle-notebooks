{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt #graphs, etc.\nimport math\nimport time\nfrom sklearn.model_selection import RandomizedSearchCV, train_test_split\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nimport datetime\nimport operator\n\n# LSTM for international airline passengers problem with regression framing\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nplt.style.use('seaborn')\n%matplotlib inline\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#This project is for Covid-19 Forecasting\n#Using a bubble graph to show spread of Covid-19\n#We will start off with Bucks County and then move on","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import stuff\n\nconfirmed_totalcases = pd.read_csv('/kaggle/input/novel-corona-virus-2019-dataset/time_series_covid_19_confirmed.csv')\ntotaldeaths_reported = pd.read_csv('/kaggle/input/novel-corona-virus-2019-dataset/time_series_covid_19_deaths.csv')\nrecovered_cases = pd.read_csv('/kaggle/input/novel-corona-virus-2019-dataset/time_series_covid_19_deaths.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Death Rate - Machine Learning","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"deaths_reported = pd.read_csv('/kaggle/input/novel-corona-virus-2019-dataset/time_series_covid_19_deaths.csv')\ndeath_report_cols = deaths_reported.keys()\ndeaths_reported[120:140]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dool_deaths_reported = pd.read_csv('/kaggle/input/novel-corona-virus-2019-dataset/time_series_covid_19_deaths.csv')\ndool_death_report_cols = dool_deaths_reported.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Copy of dataframe\ndeath_report_1 = deaths_reported\n\n# Making a list of all rows to delete\ndroppings = death_report_1[death_report_1['Country/Region'] != 'US'].index\n\n# Delete these row indexes from dataFrame\ndeath_report_1.drop(droppings, inplace=True)\ndeaths_china = death_report_1\ndeaths_china_cols = deaths_china.keys()\n# fulltable_us.info()\ndeaths_china.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#start\ndeaths = deaths_china.loc[:, deaths_china_cols[12]:deaths_china_cols[-1]]\ndeaths.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"deaths_diff_sum = deaths.agg(\"sum\", axis=\"rows\")\nprint(deaths_diff_sum)\n\n#get the diff\ndeaths_diff_sum_diff = deaths_diff_sum.diff()\ndeaths_diff_sum_diff.fillna(0, inplace=True)\nprint(deaths_diff_sum_diff)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Copy of dataframe\ndool_death_report_1 = dool_deaths_reported\n\n# Making a list of all rows to delete\ndroppable = dool_death_report_1[dool_death_report_1['Country/Region'] != 'Italy'].index\n\n# Delete these row indexes from dataFrame\ndool_death_report_1.drop(droppable, inplace=True)\ndeaths_italy = dool_death_report_1\ndeaths_italy_cols = deaths_italy.keys()\n# fulltable_us.info()\ndeaths_italy.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#start\ndool_deaths = deaths_italy.loc[:, deaths_italy_cols[12]:deaths_italy_cols[-1]]\ndool_deaths.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"deaths_sum = dool_deaths.agg(\"sum\", axis=\"rows\")\nprint(deaths_sum)\n\n#get the diff\ntraining = deaths_sum.diff()\ntraining.fillna(0, inplace=True)\nprint(training)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot the changes in death\nplt.plot(deaths_diff_sum_diff)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dates = deaths.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fu# Convert all dates and cases into the form of a numpy array\n\ndays_since_1_22 = np.array([i for i in range(len(dates))]).reshape(-1, 1)\n# world_cases = np.array(world_cases).reshape(-1, 1)\ndeath_rate = np.array(deaths_diff_sum_diff).reshape(-1, 1)\n# total_recovered = np.array(total_recovered).reshape(-1, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"days_since_1_22","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Future forecasting for next 10 days\n\ndays_in_future = 0\nfuture_forecast = np.array([i for i in range(len(dates) + days_in_future)]).reshape(-1, 1)\nadjusted_dates = future_forecast[:-10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import gang\n\nfrom sklearn.model_selection import train_test_split\n# X_train_confirmed, X_test_confirmed, y_train_confirmed, y_test_confirmed = train_test_split(days_since_1_22, death_rate, test_size=0.15, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Building the SVM model\n\n\"\"\"kernel = ['poly', 'sigmoid', 'rbf']\nc = [0.01, 0.1, 1, 10]\ngamma = [0.01, 0.1, 1]\nepsilon = [0.01, 0.1, 1]\nshrinking = [True, False]\nsvm_grid = {'kernel': kernel, 'C': c, 'gamma' : gamma, 'epsilon': epsilon, 'shrinking' : shrinking}\n\nsvm = SVR()\nsvm_search = RandomizedSearchCV(svm, svm_grid, scoring='neg_mean_squared_error', cv=3, return_train_score=True, n_jobs=-1, n_iter=40, verbose=1)\nsvm_search.fit(X_train_confirmed, y_train_confirmed)\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# svm_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# svm_confirmed = svm_search.best_estimator_\n# svm_pred = svm_confirmed.predict(future_forecast)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# svm_confirmed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# svm_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check against testing data\n\n\"\"\"svm_test_pred = svm_confirmed.predict(X_test_confirmed)\nplt.plot(svm_test_pred)\nplt.plot(y_test_confirmed)\nprint('MAE:', mean_absolute_error(svm_test_pred, y_test_confirmed))\nprint('MSE:', mean_squared_error(svm_test_pred, y_test_confirmed))\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# total number of cases over time\n\n\"\"\"plt.figure(figsize=(20, 12))\nplt.plot(adjusted_dates, deaths_diff_sum_diff)\nplt.title('Number of Coronavirus Cases Over Time', size=30)\nplt.xlabel('Days since 1/22/2020', size=30)\nplt.ylabel('Number of Cases', size=30)\nplt.xticks(size=15)\nplt.yticks(size=15)\nplt.show()\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert an array of values into a dataset matrix\ndef create_dataset(dataset, look_back=1):\n\tdataX, dataY = [], []\n\tfor i in range(len(dataset)-look_back-1):\n\t\ta = dataset[i:(i+look_back), 0]\n\t\tdataX.append(a)\n\t\tdataY.append(dataset[i + look_back, 0])\n\treturn numpy.array(dataX), numpy.array(dataY)\n\n# fix random seed for reproducibility\n# numpy.random.seed(7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load the dataset\n# dataframe = read_csv('airline-passengers.csv', usecols=[1], engine='python')\n# dataset = dataframe.values\ndataset = death_rate.astype('float64')\ndataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# normalize the dataset\nscaler = MinMaxScaler(feature_range=(0, 1))\ndataset = scaler.fit_transform(dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_1 = np.array(training).reshape(-1, 1)\n# split into train and test sets\ntrain_size= int(len(training_1) * 0.67)\ntest_size = len(training_1) - train_size\ntrain, test = training_1[0:train_size,:], training_1[train_size:len(training_1),:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reshape into X=t and Y=t+1\nlook_back = 1\ntrainX, trainY = \ntestX, testY = \n\n# reshape input to be [samples, time steps, features]\ntrainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\ntestX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create and fit the LSTM network\nmodel = Sequential()\nmodel.add(LSTM(4, input_shape=(1, look_back)))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam')\nmodel.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)\n\n# make predictions\ntrainPredict = model.predict(trainX)\ntestPredict = model.predict(testX)\n\n# invert predictions\ntrainPredict = scaler.inverse_transform(trainPredict)\ntrainY = scaler.inverse_transform([trainY])\ntestPredict = scaler.inverse_transform(testPredict)\ntestY = scaler.inverse_transform([testY])\n\n# calculate root mean squared error\ntrainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\nprint('Train Score: %.2f RMSE' % (trainScore))\ntestScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\nprint('Test Score: %.2f RMSE' % (testScore))\n\n# shift train predictions for plotting\ntrainPredictPlot = numpy.empty_like(dataset)\ntrainPredictPlot[:, :] = numpy.nan\ntrainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n\n# shift test predictions for plotting\ntestPredictPlot = numpy.empty_like(dataset)\ntestPredictPlot[:, :] = numpy.nan\ntestPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot baseline and predictions\nplt.plot(scaler.inverse_transform(dataset))\nplt.plot(trainPredictPlot)\nplt.plot(testPredictPlot)\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}