{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"---\n## Heart Attack Prediction\n---\n### Aurthor: Avinash Bagul\n##### MSc Artificial Intelligence (University of Aberdeen)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas_profiling as profile","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/heart-attack-analysis-prediction-dataset/heart.csv')\ndf.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe().T","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import missingno as msno\nn = msno.bar(df,color=\"gray\")\nprint(n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"profile.ProfileReport(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x=\"output\",data = df)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,10))\nsns.boxplot(data = df,palette = \"Set1\")\nplt.xticks(rotation=90)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def removeOutlier(att, df):\n\n    lowerbound = att.mean() - 3 * att.std()\n    upperbound = att.mean() + 3 * att.std()\n\n    print('lowerbound: ',lowerbound,' -------- upperbound: ', upperbound )\n\n    df1 = df[(att > lowerbound) & (att < upperbound)]\n\n    print((df.shape[0] - df1.shape[0]), ' number of outliers from ', df.shape[0] )\n    print(' ******************************************************')\n    \n    df = df1.copy()\n\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = removeOutlier(df.trtbps, df)\ndf = removeOutlier(df.chol, df)\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corrmat = df.corr()\ntop_corr_features = corrmat.index\nplt.figure(figsize=(20,10))\ng = sns.heatmap(df[top_corr_features].corr(),annot = True,cmap = \"RdYlGn\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.output.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.utils import resample\n\n# Separate Target Classes\ndf_1 = df[df.output==1]\ndf_2 = df[df.output==0]\n \n# Upsample minority class\ndf_upsample_1 = resample(df_2, \n                                 replace=True,     # sample with replacement\n                                 n_samples=163,    # to match majority class\n                                 random_state=123) # reproducible results\n\n# Combine majority class with upsampled minority class\ndf_upsampled = pd.concat([df_1, df_upsample_1])\n \n# Display new class counts\ndf_upsampled.output.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = df_upsampled.drop('output', axis = 1)\ny = df_upsampled['output'] \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split as tts\n\nx_train,x_test, y_train, y_test = tts(x,y, test_size = 0.3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\nx_train = scaler.fit_transform(x_train)\nx_test = scaler.transform(x_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to Evaluate\n\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score,confusion_matrix,roc_auc_score\nfrom sklearn.preprocessing import LabelBinarizer\nfrom mlxtend.plotting import plot_confusion_matrix\n\ndef evaluator(y_test, y_pred):    \n    \n    # Accuracy:\n    print('Accuracy is: ', accuracy_score(y_test,y_pred))\n    print('')\n    # Classification Report:\n    print('Classification Report: \\n',classification_report(y_test,y_pred))\n\n    # Area Under The Curve Score:\n\n    lb = LabelBinarizer()\n    y_test1 = lb.fit_transform(y_test)\n    y_pred1 =lb.transform(y_pred)\n    print('AUC_ROC Score: ',roc_auc_score(y_test1,y_pred1,average='macro'),'\\n\\n')\n\n    print('Confusion Matrix: \\n\\n')\n    plt.style.use(\"ggplot\")\n    cm = confusion_matrix(y_test,y_pred)\n    plot_confusion_matrix(conf_mat = cm,figsize=(8,6),show_normed=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrf_classifier = RandomForestClassifier()\n\nrf_classifier.fit(x_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_rf = rf_classifier.predict(x_test)\n\nevaluator(y_test, pred_rf)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from catboost import CatBoostClassifier\n\ncat_classifier = CatBoostClassifier(iterations=1000, verbose = 0)\n\ncat_classifier.fit(x_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_cat = cat_classifier.predict(x_test)\n\nevaluator(y_test, pred_cat)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"important_features = pd.DataFrame({'Features': x.columns, \n                                   'Importance': rf_classifier.feature_importances_})\n\n# sort the dataframe in the descending order according to the feature importance\nimportant_features = important_features.sort_values('Importance', ascending = False)\n\n# create a barplot to visualize the features based on their importance\nsns.barplot(x = 'Importance', y = 'Features', data = important_features)\n\n# add plot and axes labels\n# set text size using 'fontsize'\nplt.title('Feature Importance', fontsize = 15)\nplt.xlabel('Importance', fontsize = 15)\nplt.ylabel('Features', fontsize = 15)\n\n# display the plot\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Checking for overfitting","metadata":{}},{"cell_type":"code","source":"from sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom matplotlib import pyplot\n# define lists to collect scores\ntrain_scores, test_scores = list(), list()\n# define the tree depths to evaluate\nvalues = [i for i in range(1, 21)]\n# evaluate a decision tree for each depth\nfor i in values:\n    # configure the model\n    model = DecisionTreeClassifier(max_depth=i)\n    # fit model on the training dataset\n    model.fit(x_train, y_train)\n    # evaluate on the train dataset\n    train_yhat = model.predict(x_train)\n    train_acc = accuracy_score(y_train, train_yhat)\n    train_scores.append(train_acc)\n    # evaluate on the test dataset\n    test_yhat = model.predict(x_test)\n    test_acc = accuracy_score(y_test, test_yhat)\n    test_scores.append(test_acc)\n    # summarize progress\n    print('>%d, train: %.3f, test: %.3f' % (i, train_acc, test_acc))\n# plot of train and test scores vs tree depth\npyplot.plot(values, train_scores, '-o', label='Train')\npyplot.plot(values, test_scores, '-o', label='Test')\npyplot.legend()\npyplot.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}