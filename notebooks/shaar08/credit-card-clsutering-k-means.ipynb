{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Step 1 (Importing Libraries and Data)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"credit_df = pd.read_csv(\"/kaggle/input/ccdata/CC GENERAL.csv\")\ndf = credit_df.copy()\ncredit_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step 2: EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"credit_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(credit_df.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We can see that attributes CREDIT_LIMIT and MINIMUM_PAYMENTS are missing values. Lets look at same."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(credit_df.isna().sum()) # To Check the no. of unavailable instances.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's first check out the distribution of CREDIT_LIMIT and MINIMUM_PAYMENTS to get an idea which method to use for filling null values."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nplt.subplot(1,2,1)\nsns.distplot(credit_df.MINIMUM_PAYMENTS.dropna(), color='#fdc029')\nplt.subplot(1,2,2)\nsns.distplot(credit_df.CREDIT_LIMIT.dropna(), color='#fdc029')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We can see that distribution is skewed so we will use Median to fill these values."},{"metadata":{"trusted":true},"cell_type":"code","source":"credit_df['MINIMUM_PAYMENTS'].fillna(credit_df['MINIMUM_PAYMENTS'].mean(), inplace=True)\ncredit_df['CREDIT_LIMIT'].fillna(credit_df['CREDIT_LIMIT'].mean(), inplace=True)\n\nprint(credit_df[['MINIMUM_PAYMENTS','CREDIT_LIMIT']].isna().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Now we are set with missing Values."},{"metadata":{"trusted":true},"cell_type":"code","source":"credit_df.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(45,7))\nsns.boxplot(data=credit_df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### When we observe the boxplot we find the presence of many outliers but it's better not to handle outliers because we want to analyse all types of customers so better not to handle them."},{"metadata":{"trusted":true},"cell_type":"code","source":"credit_df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's derive some KPI's\n     1)  Monthly average purchase->(month_avg_purchase)-> PURCHASE/(PURCHASE_FREQUENCY*TENURE)\n     2)  Cash advance amount->(cash_advance_amt)-> CASH_ADVANCE/(PURCHASE_FREQUENCY*TENURE)"},{"metadata":{"trusted":true},"cell_type":"code","source":"credit_df['month_avg_purchase'] = credit_df['PURCHASES']/(credit_df['TENURE'])\ncredit_df['cash_advance_amt'] = credit_df['CASH_ADVANCE']/(credit_df['TENURE'])\ncredit_df[['month_avg_purchase','cash_advance_amt']].head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### 3) Purchase_type\n    In data there are two type of purchases i.e oneoff_purchase and installments_purchase. We will check if there is any relation between these two fields. "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,4))\nsns.lineplot(credit_df['BALANCE'],credit_df['ONEOFF_PURCHASES'],label='Oneoff')\nsns.lineplot(credit_df['BALANCE'],credit_df['INSTALLMENTS_PURCHASES'],label=\"Installment\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(credit_df[(credit_df['ONEOFF_PURCHASES'] == 0) & (credit_df['INSTALLMENTS_PURCHASES']==0)].shape)\nprint(credit_df[(credit_df['ONEOFF_PURCHASES']==0) & (credit_df['INSTALLMENTS_PURCHASES']>0)].shape)\nprint(credit_df[(credit_df['ONEOFF_PURCHASES']>0) & (credit_df['INSTALLMENTS_PURCHASES']==0)].shape)\nprint(credit_df[(credit_df['ONEOFF_PURCHASES']>0) & (credit_df['INSTALLMENTS_PURCHASES']>0)].shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### When we add all these rows we get is 8950 i.e total no. of rows so we can infer following things:\n        1) Customer prefering One-Off Purchases.\n        2) Customer prefering Installments Purchases.\n        3) Customers preferring both.\n        4) Customers preferring none."},{"metadata":{"trusted":true},"cell_type":"code","source":"def purchase_by_type(credit_df):\n    if (credit_df['ONEOFF_PURCHASES']==0) & (credit_df['INSTALLMENTS_PURCHASES']==0):\n        return 'none'\n    if (credit_df['ONEOFF_PURCHASES']>0) & (credit_df['INSTALLMENTS_PURCHASES']>0):\n         return 'dual'\n    if (credit_df['ONEOFF_PURCHASES']>0) & (credit_df['INSTALLMENTS_PURCHASES']==0):\n        return 'oneoff'\n    if (credit_df['ONEOFF_PURCHASES']==0) & (credit_df['INSTALLMENTS_PURCHASES']>0):\n        return 'installment'\n\ncredit_df['purchase_by_type'] = credit_df.apply(purchase_by_type,axis=1)\ncredit_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"credit_df['limit_usage'] = credit_df['BALANCE']/credit_df['CREDIT_LIMIT']\ncredit_df['minimum_payment'] = credit_df['PAYMENTS']/credit_df['MINIMUM_PAYMENTS']\ncredit_df[['limit_usage','minimum_payment']].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"credit_df.drop(['CUST_ID'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### As we need to define marketing strategy, let's think how a bank will get  benefits. I believe a bank makes money from roping people in for longer amounts of time as well as making purchases. I think purchases, balance, and payments are the best play because they exemplify the baseline services of a bank (getting people to have more with the bank, pay them more, and spend more overall to have to pay back) without those key problems."},{"metadata":{"trusted":true},"cell_type":"code","source":"def scatter_tenure(field):\n    plt.figure(figsize=(8,4))\n    sns.lineplot(x='TENURE',y=field,data=credit_df)\n    plt.show()\nscatter_tenure('PURCHASES')\nsns.lineplot(x='TENURE',y='PURCHASES',data=credit_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### We can see that as tenure increases the purchase amount also increases."},{"metadata":{"trusted":true},"cell_type":"code","source":"scatter_tenure('BALANCE')\nscatter_tenure('PAYMENTS')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Same phenomena is observed here."},{"metadata":{"trusted":true},"cell_type":"code","source":"ratio = credit_df.groupby('purchase_by_type').apply(lambda x: np.mean(x['minimum_payment']))\nratio.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax=plt.subplots()\nax.barh(y=range(len(ratio)),width=ratio.values)\nax.set(yticks=np.arange(len(ratio)),yticklabels=ratio.index)\nplt.title(\"Minimum_payment ratio for each purchase type\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(y='CREDIT_LIMIT',x='purchase_by_type',data=credit_df)\nplt.show()\nsns.lineplot(y='CREDIT_LIMIT',x='purchase_by_type',data=credit_df,color='black')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Customers who do installment purchases have good credit scores."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='purchase_by_type',y='CASH_ADVANCE',data=credit_df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Customers who don't dealt with either  installment or oneoff purchases generally takes more cash in advance."},{"metadata":{},"cell_type":"markdown","source":"## 3 Step (Transformation)"},{"metadata":{"trusted":true},"cell_type":"code","source":"credit_df.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### As, only 'purchase_by_type' field is of object type so we will create dummy variable for it."},{"metadata":{"trusted":true},"cell_type":"code","source":"credit_df=pd.get_dummies(credit_df)\ncredit_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(credit_df.corr())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Now as collinearity between variables is too much we will be using PCA to trim down some attributes."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\n#Standarize Data\nscaler = StandardScaler()\nscaler_credit_df = scaler.fit_transform(credit_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\nratio_arr = {}\nfor i in range(4,15):\n    pca=PCA(n_components=i)\n    pca_data = pca.fit(scaler_credit_df)\n    ratio_arr[i]=sum(pca_data.explained_variance_ratio_)\nprint(ratio_arr)\npd.Series(ratio_arr).plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### We can see that 9 components are explaining more than 80% variance so we select 9 components."},{"metadata":{"trusted":true},"cell_type":"code","source":"pc = PCA(n_components=9).fit(scaler_credit_df)\npca_reduced_final = pc.fit_transform(scaler_credit_df)\n\nfinal_df = pd.DataFrame(pca_reduced_final)\nprint(final_df.shape)\ncol_list = credit_df.columns\ncol_list\n\n#pc.explained_variance_ratio_\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(pc.components_.T,columns=['Component_'+str(i) for i in range(9)],index=col_list)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### We will be using Kmeans algo. for clustering and be using Elbow method for verifying number of clusters."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import silhouette_score\nn_clusters = 10\ncost = []\n\n\nfor i in range(1,10):\n    kmeans = KMeans(i)\n    kmeans.fit(pca_reduced_final)\n    cost.append(kmeans.inertia_)\nplt.plot(cost,'bx-')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Elbow point is at 5. So cluster choose is 5"},{"metadata":{"trusted":true},"cell_type":"code","source":"score=0\nkm = KMeans(5)\nkm.fit(pca_reduced_final)\nscore=silhouette_score(pca_reduced_final,km.labels_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col_kpi=['BALANCE', 'BALANCE_FREQUENCY', 'PURCHASES', 'ONEOFF_PURCHASES',\n       'INSTALLMENTS_PURCHASES', 'CASH_ADVANCE', 'PURCHASES_FREQUENCY',\n       'ONEOFF_PURCHASES_FREQUENCY', 'PURCHASES_INSTALLMENTS_FREQUENCY',\n       'CASH_ADVANCE_FREQUENCY', 'CASH_ADVANCE_TRX', 'PURCHASES_TRX',\n       'CREDIT_LIMIT', 'PAYMENTS', 'MINIMUM_PAYMENTS', 'PRC_FULL_PAYMENT',\n       'TENURE', 'month_avg_purchase', 'cash_advance_amt', 'limit_usage',\n       'minimum_payment', 'purchase_by_type_dual',\n       'purchase_by_type_installment', 'purchase_by_type_none',\n       'purchase_by_type_oneoff']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Here we see that number of clusters suggested is 5 . The PCA transformation provides us better results. So we are creating a pipeline with Standard Scaler, PCA and KMeans together."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\n\npreprocess = Pipeline(\n    [(\"scaler\",StandardScaler()),\n    (\"pca\",PCA(n_components=9,random_state=42))\n    ]\n)\n\ncluster = Pipeline(\n    [\n        ('km',KMeans(n_clusters=5,init='k-means++',n_init=50,random_state=42))\n    ]\n)\n\npipe = Pipeline(\n    [\n        (\"preprocess\",preprocess),\n        (\"cluster\",cluster)\n    ]\n)\n\npipe.fit(credit_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocessed_data = pipe['preprocess'].transform(credit_df)\npredicted_labels = pipe['cluster']['km'].labels_\nsilhouette_score(preprocessed_data,predicted_labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### N_components=9 and Cluster=5"},{"metadata":{"trusted":true},"cell_type":"code","source":"cluster_df = pd.concat([credit_df[col_kpi],pd.Series(pipe['cluster']['km'].labels_,name=\"Cluster\")],axis=1)\ncluster_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"five_cluster=cluster_df.groupby('Cluster').apply(lambda x: x[col_kpi].mean()).T\nfive_cluster","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax=plt.subplots(figsize=(15,10))\nindex=np.arange(len(five_cluster.columns))\n\ncash_advance=np.log(five_cluster.loc['cash_advance_amt',:].values)\ncredit_score=(five_cluster.loc['limit_usage',:].values)\npurchase= np.log(five_cluster.loc['month_avg_purchase',:].values)\npayment=five_cluster.loc['minimum_payment',:].values\ninstallment=five_cluster.loc['purchase_by_type_installment',:].values\none_off=five_cluster.loc['purchase_by_type_oneoff',:].values\n\n\nbar_width=.10\nb1=plt.bar(index,cash_advance,color='b',label='cash_advance_amt',width=bar_width)\nb2=plt.bar(index+bar_width,credit_score,color='m',label='Credit_score',width=bar_width)\nb3=plt.bar(index+2*bar_width,purchase,color='k',label='Avg purchase',width=bar_width)\nb4=plt.bar(index+3*bar_width,payment,color='c',label='Payment-minpayment ratio',width=bar_width)\nb5=plt.bar(index+4*bar_width,installment,color='r',label='installment',width=bar_width)\nb6=plt.bar(index+5*bar_width,one_off,color='g',label='One_off purchase',width=bar_width)\n\nplt.xlabel(\"Cluster\")\nplt.title(\"Insights\")\nplt.xticks(index + bar_width, ('Cl-0', 'Cl-1', 'Cl-2', 'Cl-3','Cl-4'))\n\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Cluster0:\n    This group is performing best among all as cutomers are maintaining good credit score and paying dues on time. -- Giving rewards point will make them perform more purchases.\n### Cluster1:\n    This group is a risky group as percent of full payment paid by user is not much.\n### Cluster2:\n    This group has minimum paying ratio and using card for both transactions.Also, have highest cash advance amount. This group is a risky group.\n### Cluster3:\n    They are potential customers who are paying dues and doing purchases and maintaining comparatively good credit score.\n### Cluster4:\n    This group of users have maintained good credit score can be lured by offering more incentives for the installment purchases."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}