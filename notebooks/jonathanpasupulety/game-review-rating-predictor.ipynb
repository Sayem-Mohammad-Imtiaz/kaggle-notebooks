{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Loading important packages"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport pickle\nimport re\nimport nltk\nimport string\nfrom nltk.tokenize import TreebankWordTokenizer\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import sent_tokenize, word_tokenize \nimport matplotlib.pyplot as plt\nfrom nltk.stem import WordNetLemmatizer \nfrom nltk.stem import PorterStemmer\nfrom nltk.tag import pos_tag\nimport numpy as np\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import RandomizedSearchCV\nimport matplotlib.pyplot as plt\nfrom pandas import DataFrame","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"df2 = pd.read_csv('/kaggle/input/boardgamegeek-reviews/bgg-15m-reviews.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dropping columns which are not required."},{"metadata":{},"cell_type":"markdown","source":"Use once"},{"metadata":{"trusted":true},"cell_type":"code","source":"del df2['Unnamed: 0']\ndel df2['ID']\ndel df2['name']\ndel df2['user']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dropping rows with NaN values."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df2.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['rating'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decimals = pd.Series([0], index=['rating'])\ndf = df.round(decimals)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['rating'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Rounding up the ratings for better efficieny of the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def rating_enhancement(rating):\n    if rating == 10.0:\n        return int(10)\n    elif rating >=9.5 and rating <10:\n        return int(10)\n    elif rating <9.5 and rating >=9:\n        return int(9)\n    elif rating >=8.5 and rating <9:\n        return int(9)\n    elif rating <8.5 and rating >=8:\n        return int(8)\n    elif rating >=7.5 and rating <8:\n        return int(8)\n    elif rating <7.5 and rating >=7:\n        return int(7)\n    elif rating >=6.5 and rating <7:\n        return int(7)\n    elif rating <6.5 and rating >=6:\n        return int(6)\n    elif rating >=5.5 and rating <6:\n        return int(6)\n    elif rating <5.5 and rating >=5:\n        return int(5)\n    elif rating >=4.5 and rating <5:\n        return int(5)\n    elif rating <4.5 and rating >=4:\n        return int(4)\n    elif rating >=3.5 and rating <4:\n        return int(4)\n    elif rating <3.5 and rating >=3:\n        return int(3)\n    elif rating >=2.5 and rating <3:\n        return int(3)\n    elif rating <2.5 and rating >=2:\n        return int(2)\n    elif rating >=1.5 and rating <2:\n        return int(2)\n    elif rating <1.5 and rating >=1:\n        return int(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['rating'] = df['rating'].apply(rating_enhancement)\ndf['rating'] = df['rating'].apply(rating_enhancement)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['rating'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cleaning the comments"},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_comments(text):\n    text = re.sub(r'<.*?>', ' ', text)\n    text = re.sub(r\"won't\", \"will not\", text)\n    text = re.sub(r\"can't\", \"can not\", text)\n    text = re.sub(r\"n't\", \" not\", text)\n    text = re.sub(r\"'ve\", \" have\", text)\n    text = re.sub(r\"'ll\", \" will\", text)\n    text = re.sub(r\"'re\", \" are\", text)\n\n    text = re.sub(r\"[0-9]+\", ' ', text)\n    text = re.sub(r\"-\", ' ', text)\n    \n    \n    text = text.strip().lower()\n    \n\n    default_stop_words = set(stopwords.words('english'))\n    default_stop_words.difference_update({'no', 'not', 'nor', 'too', 'any'})\n    stop_words = default_stop_words.union({\"'m\", \"n't\", \"'d\", \"'re\", \"'s\",\n                                           'would','must',\"'ve\",\"'ll\",'may'})\n\n    word_list = word_tokenize(text)\n    filtered_list = [w for w in word_list if not w in stop_words]\n    text = ' '.join(filtered_list)\n    \n    text = re.sub(r\"'\", ' ', text)\n    \n   \n    filters='!\"\\'#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n    translate_dict = dict((i, \" \") for i in filters)\n    translate_map = str.maketrans(translate_dict)\n    text = text.translate(translate_map)\n    \n\n    text = ' '.join([w for w in text.split() if len(w)>1])\n\n    # Replace multiple space with one space\n    text = re.sub(' +', ' ', text)\n    \n    text = ''.join(text)\n\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ndf['clean_comment'] = df['comment'].apply(clean_comments)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_train1 = pd.Series(' '.join(df['clean_comment']).split()).value_counts()\nless_five_freq_train1 = freq_train1[(freq_train1 <10)]\nprint('Words occuring less than 5 are: ')\nprint('')\nprint(less_five_freq_train1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ndf['clean_comment'] = df['clean_comment'].apply(lambda x: ' '.join(x for x in x.split() if x not in less_five_freq_train1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def NormalizeWithPOS(text):\n    # Lemmatization & Stemming according to POS tagging\n\n    word_list = word_tokenize(text)\n    rev = []\n    lemmatizer = WordNetLemmatizer() \n    stemmer = PorterStemmer() \n    for word, tag in pos_tag(word_list):\n        if tag.startswith('J'):\n            w = lemmatizer.lemmatize(word, pos='a')\n        elif tag.startswith('V'):\n            w = lemmatizer.lemmatize(word, pos='v')\n        elif tag.startswith('N'):\n            w = lemmatizer.lemmatize(word, pos='n')\n        elif tag.startswith('R'):\n            w = lemmatizer.lemmatize(word, pos='r')\n        else:\n            w = word\n        w = stemmer.stem(w)\n        rev.append(w)\n    review = ' '.join(rev)\n    return review","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ndf['clean_comment'] = df['clean_comment'].apply(NormalizeWithPOS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset =df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rating_num_set = {}\nfor rating in (10-dataset['rating'].unique()):\n    new_comment_rating = dataset.loc[dataset['rating'] >= (rating - 0.5)]\n    new_comment_rating = new_comment_rating.loc[new_comment_rating['rating'] <= (rating + 0.5)]\n    new_comment_rating = new_comment_rating.sample(frac = 1).reset_index(drop = True)\n    rating_num_set[rating] = new_comment_rating\n\nfor rating in rating_num_set:\n    print(\"rating: \", rating, \"rating num:\",  len(rating_num_set[rating]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rating_list = []\nfor rating in rating_num_set: \n    rating_list.append(len(rating_num_set[rating]))\nplt.bar(range(len(rating_list)), rating_list)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"A review example of dataset before cleaning:\")\nprint(dataset.iloc[0]['comment'], end='\\n\\n')\n\nprint(\"clean_text:\")\nprint(dataset.iloc[0]['clean_comment'], end=\"\\n\\n\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train and Test Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(dataset['clean_comment'], dataset['rating'], test_size=0.25, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.index = [x for x in range(1, len(X_train.values)+1)]\nX_test.index = [x for x in range(1, len(X_test.values)+1)]\ny_train.index = [x for x in range(1, len(y_train.values)+1)]\ny_test.index = [x for x in range(1, len(y_test.values)+1)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create Bag of Words"},{"metadata":{"trusted":true},"cell_type":"code","source":"vectorizer = CountVectorizer(stop_words='english')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ntraining_features = vectorizer.fit_transform(X_train)\ntesting_features = vectorizer.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_features.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testing_features.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Multinomial Naive Bayes"},{"metadata":{},"cell_type":"markdown","source":"# Model creation"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = MultinomialNB()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nmodel.fit(training_features, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_total = model.predict(testing_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_total","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"y_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Hyperparameter Tuning"},{"metadata":{},"cell_type":"markdown","source":"# Choosing mean squared error as my accuracy metric."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model.get_params())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"alpha = np.linspace(0,1,100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_grid = {'alpha': alpha,\n              'fit_prior': [True,False]}\nprint(random_grid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_random = RandomizedSearchCV(estimator = model, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_random.fit(training_features, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_random.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(model, test_features, test_labels):\n    predictions = model.predict(test_features)\n    errors = abs(predictions - test_labels)\n    MSE = mean_squared_error(test_labels,predictions)\n    accuracy = accuracy_score(test_labels,predictions)*100\n    print('Model Performance')\n    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n    print('Accuracy = {:0.2f}%.'.format(accuracy))\n    print('MSE = {:0.2f}.'.format(MSE))\n    \n    return accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model = MultinomialNB(alpha = 0.5)\nbase_model.fit(training_features, y_train)\nbase_accuracy = evaluate(base_model, testing_features, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_random = model_random.best_estimator_\nrandom_accuracy = evaluate(best_random, testing_features, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meanSquaredError1 = []\nhyper_cond1 = []\nalpha = np.linspace(0,1,100)\nfor i in alpha:\n    nb_model = MultinomialNB(alpha = i)\n    nb_model.fit(training_features, y_train)\n    predictions = nb_model.predict(testing_features)\n    MSE = mean_squared_error(y_test,predictions)\n    meanSquaredError1.append(MSE)\n    hyper_cond1.append(''+str(i))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure()\nax = fig.add_axes([0,0,1,1])\nax.plot(hyper_cond1, meanSquaredError1, color = 'b', label ='model')\nax.set_ylabel('MSE')\nax.set_xlabel('Random Forest Parameters')\nax.set_title('MSE for Naives with different alphas')\n# ax.set_xticks(random_forest)\n# plt.ylim((0,100))\nplt.grid(True)\nplt.legend(loc = 'upper right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# From the above we can conclude that alpha value of 0 gives me the least mean squared error."},{"metadata":{},"cell_type":"markdown","source":"# Model post Hyperparameter tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"final_model_multinomial = MultinomialNB(alpha = 0.9797979797979799)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfinal_model_multinomial.fit(training_features, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_total = final_model_multinomial.predict(testing_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_squared_error(y_test,predict_total)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}