{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Big Five Personality Traits","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"According to Wikipedia, \n> In psychological trait theory, the Big Five personality traits, also known as the five-factor model (FFM) and the OCEAN model, is a suggested taxonomy, or grouping, for personality traits.\n>\n> The theory identifies five factors:\n>\n> * openness to experience (inventive/curious vs. consistent/cautious)\n> * conscientiousness (efficient/organized vs. extravagant/careless)\n> * extraversion (outgoing/energetic vs. solitary/reserved)\n> * agreeableness (friendly/compassionate vs. challenging/callous)\n> * neuroticism (sensitive/nervous vs. resilient/confident)\n\n![](https://upload.wikimedia.org/wikipedia/commons/thumb/0/0c/Wiki-grafik_peats-de_big_five_ENG.png/493px-Wiki-grafik_peats-de_big_five_ENG.png)\nsource: https://en.wikipedia.org/wiki/File:Wiki-grafik_peats-de_big_five_ENG.png","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Dataset","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"According to the codebook supplied with the dataset:\n\n>This data was collected (2016-2018) through an interactive on-line personality test.\n>The personality test was constructed with the \"Big-Five Factor Markers\" from the IPIP. https://ipip.ori.org/newBigFive5broadKey.htm\nParticipants were informed that their responses would be recorded and used for research at the beginning of the test, and asked to confirm their consent at the end of the test.\n\nThe interactive on-line personality test can be found here: https://openpsychometrics.org/tests/IPIP-BFFM/. The test was presented as a single web page, containing 50 questions (10 per trait) and the user had to rate on a five points scale using radio buttons.\n\nThe dataset has 1,015,342 rows. Answers and time spent on each question are provided in the dataset. In addition to this, some user's device information have been collected: \n* timestamp when the survey was started\n* device's screen width and height\n* location information: country, approximate latitude and approximate longitude.\n\n**Let's give a try hacking into this dataset throughout some EDA.**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Data Importation","execution_count":null},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"!pip install country-converter\n!pip install pycountry-convert","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport country_converter as coco\nimport pycountry_convert as pycoco\nsns.set_style(\"darkgrid\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data = pd.read_csv(\"../input/big-five-personality-test/IPIP-FFM-data-8Nov2018/data-final.csv\", sep = \"\\t\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dataset information","execution_count":null},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"print(\"Dataset shape:\", data.shape)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"data.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data quality","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Missing values","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"s = data.isnull().sum()\nprint(s[s != 0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are missing values in 105 out of 110 columns. It appears that the missing values come from the same observations.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"print(s[s != 0].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can afford to discard these rows because we have more than one million rows in the dataset.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"data = data.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(\"Dataset (new) shape:\", data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"s = data.isnull().sum()\nprint(s[s != 0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Rows with missing values have been discarded successfully.\n\nLet's pay attention to the type of columns.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Columns type","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Main columns containing answers (EXT1, etc.) are supposed to be integers since the scale contains 5 steps (from 1 to 5).\n\nLet's figure out if those columns don't contain floating values.\n\nFirst of all, we're going to create a list of column names containing the answers from the test. Personality traits are labeled as:\n\n* EXT: Extroversion\n* EST: Neuroticism\n* AGR: Agreeableness\n* CSN: Conscientiousness\n* OPN: Openness\n\nAnd each trait is figured out through ten questions each.","execution_count":null},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"personality_traits = [\"EXT\", \"AGR\", \"CSN\", \"EST\", \"OPN\"]\nanswer_columns = [trait + str(number) for trait in personality_traits for number in range(1, 11)]\nprint(answer_columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see if there's a difference between values represented as integers and as floats.","execution_count":null},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"(data[answer_columns] != data[answer_columns].astype(int)).sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Values can be converted to integers without any difference. This will save a lot of memory and the EDA will be cleaner later.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"data[answer_columns] = data[answer_columns].astype(int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"According to the codebook, given latitudes and longitudes (`lat_appx_lots_of_err` and `long_appx_lots_of_err` columns) are very inaccurate, so both columns will be dropped. User location will be based on countries (`country` column, using the ISO 3166-1 alpha-2 standard).","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"data.drop([\"lat_appx_lots_of_err\", \"long_appx_lots_of_err\"], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Outliers handling","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let's give a look to answers given to the 50 questions.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"data[answer_columns].apply(pd.Series.value_counts)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The questions scale goes from 1 to 5. The zero value isn't supposed to exist, it probably means that the question hasn't been answered: the user didn't click on any radio button from the respective row. \n\nObservations containing at least a \"0\" from these columns will be discarded.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"data = data[(data[answer_columns] != 0).all(axis = 1)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The time spent on each question (xxxx_E columns) is recorded in milliseconds, let's convert it to seconds.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"answer_columns_time = [trait + str(number) + \"_E\" for trait in personality_traits for number in range(1, 11)]\nprint(answer_columns_time)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data[answer_columns_time] = data[answer_columns_time].apply(lambda x: x / 1000)\ndata[answer_columns_time].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some values are very high, which can be assumed as outliers: users took a break in the middle of the test or there was a technical issue while tracking mouse clicks. \n\nEither way, let's discard outliers using arbitrary limits. If the time spent on a question is above 30 seconds, the row will be deleted. More over, if there's a negative time, the row will also be removed. \n\nThe resulting dataset will only be used for the next section, otherwise, the entire (cleaned till this cell) dataset will be used.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"data_time = data[((data[answer_columns_time] < 30) & (data[answer_columns_time] > 0)).all(axis = 1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(\"Dataset (new) shape:\", data_time.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Response time analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"To begin this EDA, let's study the response time per question. We're going to use the restricted dataset (response time below 30 seconds).","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"df_response = pd.melt(data_time[answer_columns_time])\ndf_response[\"trait\"] = df_response[\"variable\"].str.slice(0, 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fig, axs = plt.subplots(ncols = 2, nrows = 3, figsize = (18, 18))\n\nsns.boxplot(x = \"variable\", y = \"value\", data = df_response[df_response[\"trait\"] == \"EXT\"], \n            showfliers = False, ax = axs[0, 0]).set_title(\"Extroversion\")\nsns.boxplot(x = \"variable\", y = \"value\", data = df_response[df_response[\"trait\"] == \"AGR\"], \n            showfliers = False, ax = axs[0, 1]).set_title(\"Agreeableness\")\nsns.boxplot(x = \"variable\", y = \"value\", data = df_response[df_response[\"trait\"] == \"CSN\"], \n            showfliers = False, ax = axs[1, 0]).set_title(\"Conscientiousness\")\nsns.boxplot(x = \"variable\", y = \"value\", data = df_response[df_response[\"trait\"] == \"EST\"], \n            showfliers = False, ax = axs[1, 1]).set_title(\"Neuroticism\")\nsns.boxplot(x = \"variable\", y = \"value\", data = df_response[df_response[\"trait\"] == \"OPN\"], \n            showfliers = False, ax = axs[2, 0]).set_title(\"Openness\")\n\nfig.delaxes(axs[2, 1])\n\nfor ax in axs.flat:\n    ax.set(xlabel = None, ylabel = \"Response time (seconds)\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Overall, the average response time is pretty much the same for most of the questions.\n\nThe EXT1 question (`I am the life of the party.`) has very high response times because it is the first question in the list. So users are probably taking time to discover how the test works and are scrolling throught the list first.\n\nA higher average response time for other questions can be explained by comprehension issues or simply longer sentences. Let's find the correlation between the average response time and the number of words in the question.","execution_count":null},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"with open(\"../input/big-five-personality-test/IPIP-FFM-data-8Nov2018/codebook.txt\") as f:\n    lines = f.readlines()\nquestions = lines[7:57]\nquestions = [x.replace(\"\\n\", \"\").split(\"\\t\") for x in questions]\nquestions = pd.DataFrame.from_records(questions, columns = [\"code\", \"question\"])\nquestions[\"wc\"] = [len(x) for x in questions[\"question\"].str.split()]\nquestions[\"lc\"] = [len(x) for x in questions[\"question\"]]\nprint(questions.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's merge both dataframes now.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"mean_response_time = data_time[answer_columns_time].mean()\ndf_mean_response_time = pd.DataFrame({\"time\": mean_response_time})\ndf_mean_response_time[\"code\"] = df_mean_response_time.index.str.replace(\"_E\", \"\")\n\ndf_mean_response_time = df_mean_response_time.merge(questions, on = \"code\")\nprint(df_mean_response_time.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Obviously, the first question (`EXT1`) is removed because the response times are biased as said earlier.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"print(\"Pearson correlation coefficient between response time and words count:\\n\",\n      np.corrcoef(df_mean_response_time[\"time\"][1:], df_mean_response_time[\"wc\"][1:])[0, 1])\nprint(\"Pearson correlation coefficient between response time and letters count:\\n\",\n      np.corrcoef(df_mean_response_time[\"time\"][1:], df_mean_response_time[\"lc\"][1:])[0, 1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The correlation coefficient is pretty high, no surprise here. However, we can try to figure out if there were any questions that caused problems that may have held users (incomprehension issues) by looking at observations far over from a simple OLS regression line.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The following plot represents the evolution of response times from the beginning to the end.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize = (20, 10))\n\nfor i in range(0, 41, 10):\n    # plotting a vertical line for each personality trait\n    plt.axvline(x = i, color = \"black\", alpha = 0.5)\n    \nsns.lineplot(data = mean_response_time, sort = False, linewidth = 4, drawstyle = \"steps-pre\")\n\nplt.xticks(rotation = 90)\nplt.grid(axis = \"y\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here's some funny pattern from `EST5` to `EST9` questions. If you pay attention to the corresponding questions, those are all positive keyed and are simple questions, almost asking redundant information from the user.\n\nThe response times analysis ends here. The specific dataset will be discarded now.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"del data_time","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Location analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let's find out where the respondents are coming from.\n\nWe have country codes in the `country` column from the dataset. Let's convert those from ISO-2 standard to ISO-3 (i.e. `FR` becomes `FRA`) to be able to match countries with their location in a plotly map without using GPS information.\n\nAdditional columns will be created:\n\n* `country_name`: contains the country short name (i.e. France)\n* `continent`: contains the continent name where the country belongs to (this information will be used later).\n\nReplacement dictionaries will be used to convert standards.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"iso2 = list(data[\"country\"].unique())\n\nunknown_iso2 = [\"NONE\", \"SX\", \"TL\", \"AQ\"]\n\niso3 = coco.convert(names = iso2, to = \"ISO3\")\ncontinent = pd.Series(iso2)[~pd.Series(iso2).isin(unknown_iso2)].apply(lambda x: pycoco.country_alpha2_to_continent_code(x))\nshort_name = coco.convert(names = iso2, to = \"name_short\")\n\ndict_continent_name = {\n    'NA': 'North America',\n    'SA': 'South America', \n    'AS': 'Asia',\n    'OC': 'Oceania',\n    'EU': 'Europe',\n    'AF': 'Africa'\n}\n\ncontinent = continent.replace(dict_continent_name)\ndict_country = dict(zip(iso2, iso3))\ndict_short_name = dict(zip(iso3, short_name))\ndict_continent = dict(zip(iso2, continent))\n\ndata[\"country_iso2\"] = data[\"country\"].replace(dict_country)\ndata[\"country_iso3\"] = data[\"country\"].replace(dict_country)\ndata[\"country_name\"] = data[\"country_iso3\"].replace(dict_short_name)\ndata[\"continent\"] = data[\"country\"].replace(dict_continent)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Then, the number of observation per country is computed, in order to display them on a choropleth map.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"country_table = data[\"country_iso3\"].value_counts()\ncountry_table = country_table.to_frame(\"count\")\ncountry_table[\"country_iso3\"] = country_table.index\ncountry_table[\"country_name\"] = country_table[\"country_iso3\"].replace(dict_short_name)\ncountry_table[\"hover_text\"] = country_table[\"country_name\"] + '<br>' + \\\n    country_table[\"count\"].apply(\"{:,}\".format) + \" obs.\"\nprint(country_table)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fig = go.Figure(data = go.Choropleth(\n    locations = country_table.index,\n    z = np.log(country_table[\"count\"]),\n    text = country_table[\"hover_text\"],\n    showscale = False,\n    colorscale = \"Reds\",\n    hoverinfo = \"text\",\n    marker_line_color = \"darkgray\"\n))\n\nfig.update_layout(title = \"Number of responses per country (logarithmic color scale)\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"(Do not hesitate to move your mouse over the map in order to see the exact number of responses).\n\nThe main country which responded the most to the test are the United States (471,912 obs). Africa has a low coverage rate.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Personality traits analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Trait global score","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Personality traits score can be obtained by aggregating answers. According to the test documentation, questions can be positive keyed or negative keyed.\n\n| Code  | Question                                                 | Key |    | Code  | Question                                                 | Key |\n|-------|:---------------------------------------------------------|-----|----|-------|:---------------------------------------------------------|-----|\n| EXT1\t| I am the life of the party.                              | (+) | \\| | EST1  | I get stressed out easily.                               | (+) |\n| EXT2\t| I don't talk a lot.                                      | (-) | \\| | EST2  | I am relaxed most of the time.                           | (-) |\n| EXT3\t| I feel comfortable around people.                        | (+) | \\| | EST3  | I worry about things.                                    | (+) |\n| EXT4\t| I keep in the background.                                | (-) | \\| | EST4  | I seldom feel blue.                                      | (-) |\n| EXT5\t| I start conversations.                                   | (+) | \\| | EST5  | I am easily disturbed.                                   | (+) |\n| EXT6\t| I have little to say.                                    | (-) | \\| | EST6  | I get upset easily.                                      | (+) |\n| EXT7\t| I talk to a lot of different people at parties.          | (+) | \\| | EST7  | I change my mood a lot.                                  | (+) |\n| EXT8\t| I don't like to draw attention to myself.                | (-) | \\| | EST8  | I have frequent mood swings.                             | (+) |\n| EXT9\t| I don't mind being the center of attention.              | (+) | \\| | EST9  | I get irritated easily.                                  | (+) |\n| EXT10\t| I am quiet around strangers.                             | (-) | \\| | EST10 | I often feel blue.                                       | (+) |\n\n\n| Code  | Question                                                 | Key |    | Code  | Question                                                 | Key |\n|-------|:---------------------------------------------------------|-----|----|-------|:---------------------------------------------------------|-----|\n| AGR1\t| I feel little concern for others.                        | (-) | \\| | CSN1  | I am always prepared.                                    | (+) |\n| AGR2\t| I am interested in people.                               | (+) | \\| | CSN2  | I leave my belongings around.                            | (-) |\n| AGR3\t| I insult people.                                         | (-) | \\| | CSN3  | I pay attention to details.                              | (+) |\n| AGR4\t| I sympathize with others' feelings.                      | (+) | \\| | CSN4  | I make a mess of things.                                 | (-) |\n| AGR5\t| I am not interested in other people's problems.          | (-) | \\| | CSN5  | I get chores done right away.                            | (+) |\n| AGR6\t| I have a soft heart.                                     | (+) | \\| | CSN6  | I often forget to put things back in their proper place. | (-) |\n| AGR7\t| I am not really interested in others.                    | (-) | \\| | CSN7  | I like order.                                            | (+) |\n| AGR8\t| I take time out for others.                              | (+) | \\| | CSN8  | I shirk my duties.                                       | (-) |\n| AGR9\t| I feel others' emotions.                                 | (+) | \\| | CSN9  | I follow a schedule.                                     | (+) |\n| AGR10\t| I make people feel at ease.                              | (+) | \\| | CSN10 | I am exacting in my work.                                | (+) |\n\n\n| Code  | Question                                              | Key |\n|-------|:---------------------------------------------------------|-----|\n| OPN1\t| I have a rich vocabulary.                                | (+) |\n| OPN2\t| I have difficulty understanding abstract ideas.          | (-) |\n| OPN3\t| I have a vivid imagination.                              | (+) |\n| OPN4\t| I am not interested in abstract ideas.                   | (-) |\n| OPN5\t| I have excellent ideas.                                  | (+) |\n| OPN6\t| I do not have a good imagination.                        | (-) |\n| OPN7\t| I am quick to understand things.                         | (+) |\n| OPN8\t| I use difficult words.                                   | (-) |\n| OPN9\t| I spend time reflecting on things.                       | (+) |\n| OPN10\t| I am full of ideas.                                      | (+) |","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"First, let's rescale values (1, ..., 5) to (-2, ..., 2). So we can compare traits scores together.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"data[answer_columns] = data[answer_columns].apply(lambda x: x - 3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Then, let's aggregate values to get a score for each personality treat, according to positive or negative keys listed in the tables above.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"data[\"EXT\"] = data[\"EXT1\"] - data[\"EXT2\"] + data[\"EXT3\"] - data[\"EXT4\"] + \\\n    data[\"EXT5\"] - data[\"EXT6\"] + data[\"EXT7\"] - data[\"EXT8\"] + data[\"EXT9\"] - data[\"EXT10\"]\n\ndata[\"EST\"] = data[\"EST1\"] - data[\"EST2\"] + data[\"EST3\"] - data[\"EST4\"] + \\\n    data[\"EST5\"] + data[\"EST6\"] + data[\"EST7\"] + data[\"EST8\"] + data[\"EST9\"] + data[\"EST10\"]\n\ndata[\"AGR\"] = - data[\"AGR1\"] + data[\"AGR2\"] - data[\"AGR3\"] + data[\"AGR4\"] - \\\n    data[\"AGR5\"] + data[\"AGR6\"] - data[\"AGR7\"] + data[\"AGR8\"] + data[\"AGR9\"] + data[\"AGR10\"]\n\ndata[\"CSN\"] = data[\"CSN1\"] - data[\"CSN2\"] + data[\"CSN3\"] - data[\"CSN4\"] + \\\n    data[\"CSN5\"] - data[\"CSN6\"] + data[\"CSN7\"] - data[\"CSN8\"] + data[\"CSN9\"] + data[\"CSN10\"]\n\ndata[\"OPN\"] = data[\"OPN1\"] - data[\"OPN2\"] + data[\"OPN3\"] - data[\"OPN4\"] + \\\n    data[\"OPN5\"] - data[\"OPN6\"] + data[\"OPN7\"] - data[\"OPN8\"] + data[\"OPN9\"] + data[\"OPN10\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can plot the score distributions for each personality trait.","execution_count":null},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"fig, axs = plt.subplots(ncols = 2, nrows = 3, figsize = (18, 18))\nsns.distplot(data[\"EXT\"], bins = 40, kde = False, \n             ax = axs[0, 0], color = sns.color_palette()[0]).set_title(\"Extroversion\")\nsns.distplot(data[\"EST\"], bins = 40, kde = False, \n             ax = axs[0, 1], color = sns.color_palette()[1]).set_title(\"Neuroticism\")\nsns.distplot(data[\"AGR\"], bins = 40, kde = False, \n             ax = axs[1, 0], color = sns.color_palette()[2]).set_title(\"Agreeableness\")\nsns.distplot(data[\"CSN\"], bins = 40, kde = False, \n             ax = axs[1, 1], color = sns.color_palette()[3]).set_title(\"Conscientiousness\")\nsns.distplot(data[\"OPN\"], bins = 40, kde = False, \n             ax = axs[2, 0], color = sns.color_palette()[4]).set_title(\"Openness\")\n\nfig.delaxes(axs[2, 1])\nfor ax in axs.flat:\n    ax.set(xlabel = None, ylabel = \"Count\")\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Correlations","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Are personality traits correlated?","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"correlation = data[personality_traits].corr()\nprint(correlation)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"mask = np.zeros_like(correlation)\nmask[np.triu_indices_from(mask)] = True\nwith sns.axes_style(\"white\"):\n    sns.heatmap(correlation, mask = mask, vmax = .3, cmap = \"RdYlBu\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Extroversion and Agreeableness go in the same direction (+0.30). However, Neuroticism has a negative correlation with Extroversion and Conscientiousness (-0.22 and -0.23).","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Values pattern","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Do some questions have specific patterns (mostly extreme values? neutral? ...)?","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"df_answers = pd.melt(data[answer_columns])\ndf_answers[\"trait\"] = df_answers[\"variable\"].str.slice(0, 3)\ndf_answers = df_answers.groupby([\"variable\", \"value\"]).count()\ndf_answers.reset_index(inplace = True)\ndf_answers = df_answers.rename(columns = {\"trait\": \"count\"})\ndf_answers[\"trait\"] = df_answers[\"variable\"].str.slice(0, 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fig, axs = plt.subplots(ncols = 2, nrows = 3, figsize = (18, 18))\n\nsns.scatterplot(x = \"variable\", y = \"value\", size = \"count\", \n                color = sns.color_palette()[0], data = df_answers[df_answers[\"trait\"] == \"EXT\"], \n                sizes = (100, 700), ax = axs[0, 0], legend = None).set_title(\"Extroversion\")\n\nsns.scatterplot(x = \"variable\", y = \"value\", size = \"count\", \n                color = sns.color_palette()[1], data = df_answers[df_answers[\"trait\"] == \"EST\"], \n                sizes = (100, 700), ax = axs[0, 1], legend = None).set_title(\"Neuroticism\")\n\nsns.scatterplot(x = \"variable\", y = \"value\", size = \"count\", \n                color = sns.color_palette()[2], data = df_answers[df_answers[\"trait\"] == \"AGR\"], \n                sizes = (100, 700), ax = axs[1, 0], legend = None).set_title(\"Agreeableness\")\n\nsns.scatterplot(x = \"variable\", y = \"value\", size = \"count\", \n                color = sns.color_palette()[3], data = df_answers[df_answers[\"trait\"] == \"CSN\"], \n                sizes = (100, 700), ax = axs[1, 1], legend = None).set_title(\"Conscientiousness\")\n\nsns.scatterplot(x = \"variable\", y = \"value\", size = \"count\", \n                color = sns.color_palette()[4], data = df_answers[df_answers[\"trait\"] == \"OPN\"], \n                sizes = (100, 700), ax = axs[2, 0], legend = None).set_title(\"Openness\")\n\nfig.delaxes(axs[2, 1])\n\nfor ax in axs.flat:\n    ax.set(xlabel = None, ylabel = \"Value\")\n\nplt.setp(axs, yticks = range(-2, 3))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Regarding Agreeableness and Openness traits, people are able to feel concerned about the questions: they barely stay neutral and prefer ticking extreme values on the scale. Both traits had a distribution following some left-skewed Gaussian curve. The trend is more noisy for the other traits.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Continental analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let's try to figure out if there are difference in personality traits between continents.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"fig, axs = plt.subplots(ncols = 2, nrows = 3, figsize = (18, 18))\nlist_continent = [\"Asia\", \"Africa\", \"Oceania\", \"North America\", \"South America\", \"Europe\"]\nfor continent in list_continent:\n    g = sns.distplot(data[data[\"continent\"] == continent][\"EXT\"], bins = 40,\n                     hist = False, ax = axs[0, 0], label = continent).set_title(\"Extroversion\")\n    g = sns.distplot(data[data[\"continent\"] == continent][\"EST\"], bins = 40, \n                     hist = False, ax = axs[0, 1], label = continent).set_title(\"Neuroticism\")\n    g = sns.distplot(data[data[\"continent\"] == continent][\"AGR\"], bins = 40, \n                     hist = False, ax = axs[1, 0], label = continent).set_title(\"Agreeableness\")\n    g = sns.distplot(data[data[\"continent\"] == continent][\"CSN\"], bins = 40, \n                     hist = False, ax = axs[1, 1], label = continent).set_title(\"Conscientiousness\")\n    g = sns.distplot(data[data[\"continent\"] == continent][\"OPN\"], bins = 40, \n                     hist = False, ax = axs[2, 0], label = continent).set_title(\"Openness\")\n\nfig.delaxes(axs[2, 1])\nfor ax in axs.flat:\n    ax.set(xlabel = None)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Asia stands out on every plot. Little differences can be noticed from Europe.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Time analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"First of all, let's see how many users tested themselves per day. The dataset starts from March 2016 and stops at November 2018. ","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"data[\"date\"] = data[\"dateload\"].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\")).apply(lambda x: x.date())\ndata[\"year\"] = data[\"date\"].apply(lambda x: x.year)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"date_table = data[\"date\"].value_counts()\n\nplt.figure(figsize = (12, 10))\nsns.lineplot(x = date_table.index, y = date_table)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are a few huge spikes, but there's no point trying to figure out the reason behind. In any case, the amount of responses didn't change much from 2016/05 to 2017/01. However, an increasing trend appeared starting from 2018.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Is there any significant shift from users over time?","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"fig, axs = plt.subplots(ncols = 2, nrows = 3, figsize = (18, 18))\nfor year in [2016, 2017, 2018]:\n    g = sns.distplot(data[data[\"year\"] == year][\"EXT\"], bins = 40, \n                 hist = False, label = str(year), ax = axs[0, 0]).set_title(\"Extroversion\")\n    g = sns.distplot(data[data[\"year\"] == year][\"EST\"], bins = 40, \n                 hist = False, label = str(year), ax = axs[0, 1]).set_title(\"Neuroticism\")\n    g = sns.distplot(data[data[\"year\"] == year][\"AGR\"], bins = 40, \n                 hist = False, label = str(year), ax = axs[1, 0]).set_title(\"Agreeableness\")\n    g = sns.distplot(data[data[\"year\"] == year][\"CSN\"], bins = 40, \n                 hist = False, label = str(year), ax = axs[1, 1]).set_title(\"Conscientiousness\")\n    g = sns.distplot(data[data[\"year\"] == year][\"OPN\"], bins = 40, \n                 hist = False, label = str(year), ax = axs[2, 0]).set_title(\"Openness\")\n    \nfig.delaxes(axs[2, 1])\n\nfor ax in axs.flat:\n    ax.set(xlabel = None)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nothing important to report. The 2016-2018 period was very calm in the world. It would've been interesting to compare the situation before and after any kind of world crisis. People may be more nervous, being less open, etc.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Country analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Finally, let's plot the average of each personality trait on a map for each country.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"traits_per_country = data.groupby(\"country_iso3\").agg({\"EXT\": \"mean\",\n                                                      \"EST\": \"mean\",\n                                                      \"AGR\": \"mean\",\n                                                      \"CSN\": \"mean\",\n                                                      \"OPN\": [\"mean\", \"size\"]})\ntraits_per_country.columns = traits_per_country.columns.map(\"_\".join)\ntraits_per_country.columns = personality_traits + [\"count\"]\ntraits_per_country[\"country_iso3\"] = traits_per_country.index\ntraits_per_country[\"country_name\"] = traits_per_country[\"country_iso3\"].replace(dict_short_name)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Countries with less than 50 answers will be discarded to prevent from disturbing results.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"traits_per_country = traits_per_country[traits_per_country[\"count\"] > 50]","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"fig = go.Figure(data = go.Choropleth(\n    locations = traits_per_country.index,\n    z = traits_per_country[\"EXT\"],\n    text = traits_per_country[\"country_name\"],\n    colorscale = px.colors.diverging.Portland_r,\n    marker_line_color = \"darkgray\"\n))\n\nfig.update_layout(title = \"Extrovertion (higher means more extrovert)\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It would be interesting to combine those data with socio-demographic data (living conditions, ...).","execution_count":null},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"fig = go.Figure(data = go.Choropleth(\n    locations = traits_per_country.index,\n    z = traits_per_country[\"EST\"],\n    text = traits_per_country[\"country_name\"],\n    colorscale = px.colors.diverging.Portland_r,\n    marker_line_color = \"darkgray\"\n))\n\nfig.update_layout(title = \"Neuroticism (higher means more stressed)\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"South America seems to be highly impacted by neuroticism.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"fig = go.Figure(data = go.Choropleth(\n    locations = traits_per_country.index,\n    z = traits_per_country[\"AGR\"],\n    text = traits_per_country[\"country_name\"],\n    colorscale = px.colors.diverging.Portland_r,\n    marker_line_color = \"darkgray\"\n))\n\nfig.update_layout(title = \"Agreeableness (higher means more agreeable)\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Surprisingly, Canada has a pretty low average score on Agreeableness. However, it is important to note that each region of the world has his own point of view. Canadians are known to be very friendly and nice from the rest of the world but they might think they're average because they're used to it.","execution_count":null},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"fig = go.Figure(data = go.Choropleth(\n    locations = traits_per_country.index,\n    z = traits_per_country[\"CSN\"],\n    text = traits_per_country[\"country_name\"],\n    colorscale = px.colors.diverging.Portland_r,\n    marker_line_color = \"darkgray\"\n))\n\nfig.update_layout(title = \"Conscientiousness (higher means more conscientious)\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"fig = go.Figure(data = go.Choropleth(\n    locations = traits_per_country.index,\n    z = traits_per_country[\"OPN\"],\n    text = traits_per_country[\"country_name\"],\n    colorscale = px.colors.diverging.Portland_r,\n    marker_line_color = \"darkgray\"\n))\n\nfig.update_layout(title = \"Openness (higher means more open)\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There's a significant separation between Eastern and Western population. The Western world think themselves as more open, unlike Eastern countries where the openness score is globaly lower.\n\nOnce again, it is important to keep in mind that each country or region has a different level of scale.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Conclusion","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Through this EDA, we studied the dataset in different aspects: response times, time series, geographical analysis (continents, countries). Furthermore, comparisons have been made between countries, continents and years for each personality trait.\n\nWe can explore more and exploit better the information in this dataset by matching socio-demographic data. Regressions can be done in that case.\n\nMoreover, unsupervised algorithms could be applied to this dataset in order to find out clusters. According to the results obtained, we would be able to give a description of each cluster so people can see themselves through the results.\n\nIf you've enjoyed this notebook, do not hesitate to upvote it and feel free to ask questions or give a feedback or new ideas.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}