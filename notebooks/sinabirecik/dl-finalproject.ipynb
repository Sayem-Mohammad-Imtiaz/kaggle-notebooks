{"cells":[{"metadata":{"_uuid":"9d8d13ac-d0b5-4e27-8a34-d49fe3c94600","_cell_guid":"dd026ecb-2bff-4cf9-9e09-0bc741bb86bf","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport numpy as np\nimport pandas as pd\nsns.set()\nimport numpy as np # linear algebra\n # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import  *\nfrom tensorflow.keras.optimizers import Adam, SGD, RMSprop\nfrom tensorflow.keras.applications import DenseNet121, VGG19, ResNet50\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport PIL.Image\nimport matplotlib.pyplot as mpimg\nimport os\nimport ssl\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array\nfrom tensorflow.keras.preprocessing import image\n\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.utils import shuffle\n\n#    CL1 Verinin hazırlanması\n#    CL2 ANN Modelinin hazırlanması, ANN Eğitilmesi, Tahmin\n#    CL3 Sonuçlar","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataPrep(object):\n    total_data = None\n    \n    def __init__(self):\n        self.covid_for_test = None\n        self.train_data = None\n        self.test_data = None\n        self.merged_test_data = None\n        self.final_test_data = None\n        self.final_train_data = None\n        self.y_train = None\n        self.train_arrays = None\n        self.test_arrays = None\n        self.corona_augmented = None\n    \n    def getData(self):\n        input_df = pd.read_csv('../input/coronahack-chest-xraydataset/Chest_xray_Corona_Metadata.csv')\n        input_ratio = 0.725\n        self.total_data = input_df.shape[0]\n        train_data = input_df[input_df['Dataset_type'] == 'TRAIN']\n        train_data = train_data.sample(int(train_data.shape[0]*input_ratio))\n        test_data = input_df[input_df['Dataset_type'] == 'TEST']\n        test_data = test_data.sample(int(test_data.shape[0]*input_ratio))\n        #assert train_data.shape[0] + test_data.shape[0] == input_df.shape[0]\n        print(f\"Shape of train data : {train_data.shape}\")\n        print(f\"Shape of test data : {test_data.shape}\")\n        moving_ratio = 0.17\n        \n        covid_path = train_data[train_data['Label_2_Virus_category']=='COVID-19'] #['X_ray_image_name'].values     \n        #covid_path = pd.DataFrame(covid_path)\n        print(\"covid_path shape: \", covid_path.shape)\n        covid_for_test = covid_path.sample(int(round(len(covid_path)*moving_ratio,0)))\n        print(\"covid_for_test shape:\",covid_for_test.shape)\n        print(type(covid_for_test))\n        def flatten(l):\n            try:\n                return flatten(l[0]) + (flatten(l[1:]) if len(l) > 1 else []) if type(l) is list else [l]\n            except IndexError:\n                return []\n        #covid_for_test = covid_for_test.values.tolist()\n        #covid_for_test = flatten(covid_for_test)\n        #print(covid_for_test)\n        \n        print(len(train_data))\n        self.train_data = train_data[~train_data['X_ray_image_name'].isin(covid_for_test['X_ray_image_name'].values)]\n        #train_data.drop(train_data[train_data[\"X_ray_image_name\"] in buffer], inplace = True)\n        print(\"shape traindata\",self.train_data.shape)\n        \n        # Defining the path to Train and Test directories\n        #training_data_path = '../input/coronahack-chest-xraydataset/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/train'\n        #testing_data_path = '../input/coronahack-chest-xraydataset/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/test'\n        self.covid_for_test = covid_for_test\n        self.test_data = test_data\n        \n        \n    def classifyData(self):\n        test_img_dir = '/kaggle/input/coronahack-chest-xraydataset/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/test'\n        train_img_dir = '/kaggle/input/coronahack-chest-xraydataset/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/train'\n        #covid_for_test_full_path = list(map(lambda x: os.path.join(train_img_dir, x), self.covid_for_test))\n        #print(covid_for_test_full_path)\n        self.merged_test_data = self.test_data.append(self.covid_for_test)\n        print(\"self.merged_test_data shape:\", self.test_data.shape)\n        \n        # add a target and class feature\n        self.train_data['class'] = self.train_data.Label_2_Virus_category.apply(lambda x: 1 if x=='COVID-19' else 0)\n        print(self.train_data)\n        self.merged_test_data['class'] = self.merged_test_data.Label_2_Virus_category.apply(lambda x: 1 if x=='COVID-19' else 0)\n        #print(\"birleştirilmiş test setindeki covidliler: \", self.test_data[['Label_2_Virus_category']=='COVID-19'])\n        print(self.merged_test_data[self.merged_test_data['Label_2_Virus_category']=='COVID-19'])\n\n        #get the important features\n        self.final_train_data = self.train_data[['X_ray_image_name', 'class']]\n        self.final_test_data = self.merged_test_data[['X_ray_image_name', 'class']]\n        \n        print(\"shape of self.final_test_data:\", self.final_test_data.shape)\n        print(self.final_train_data.shape)\n    def visualization(self):\n        pass\n    \n    def augmentation(self):\n        #create a imagegenerator for for augmentation\n        datagen =  ImageDataGenerator(shear_range=0.2, zoom_range=0.2)\n        train_img_dir = '/kaggle/input/coronahack-chest-xraydataset/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/train'\n        test_img_dir = '/kaggle/input/coronahack-chest-xraydataset/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/test'    \n        def read_img(filename, size, path):\n            img = keras.preprocessing.image.load_img(os.path.join(path, filename), target_size=size)\n            \n            #convert image to array\n            img = img_to_array(img) / 255\n            return img\n        #augment the images labeled with covid-19 to balance the data\n        corona_df = self.final_train_data[self.final_train_data['class'] == 1 ]\n        self.corona_augmented = []\n\n        #create a function for augmentation\n        def augment(name):\n            img = read_img(name, (255,255), train_img_dir)\n            i = 0\n            for batch in tqdm(datagen.flow(tf.expand_dims(img, 0), batch_size=32)):\n                self.corona_augmented.append(tf.squeeze(batch).numpy())\n                if i == 20:\n                    break\n                i =i+1\n\n        #apply the augment function       \n        corona_df['X_ray_image_name'].apply(augment)\n        print(\"Türetilen veri:\", len(self.corona_augmented))\n        \n        # extract the image from training data and test data, then convert them as array\n        self.train_arrays = []\n        self.final_train_data['X_ray_image_name'].apply(lambda x: self.train_arrays.append(read_img(x, (255,255), train_img_dir)))\n        \n        self.test_arrays = []\n        self.test_data['X_ray_image_name'].apply(lambda x: self.test_arrays.append(read_img(x, (255,255), test_img_dir)))\n        self.covid_for_test['X_ray_image_name'].apply(lambda x: self.test_arrays.append(read_img(x, (255,255), train_img_dir)))\n        \n        print(\"train_arrays length:\",len(self.train_arrays))  \n        print(\"test_arrays length:\",len(self.test_arrays))  \n        print(\"shape:\", self.train_arrays[0].shape)\n        \n        #concatenate the training data labels and the labels for augmented images\n        self.y_train = np.concatenate((np.int64(self.final_train_data['class'].values), np.ones(len(self.corona_augmented), dtype=np.int64)))\n    \nif __name__ == \"__main__\":\n    prep = DataPrep()\n    prep.getData()\n    prep.classifyData()\n    prep.augmentation()\n    #print(prep.total_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Net(object):\n    def __init__(self, train_arrays, test_arrays, y_train,\n                final_test_data, corona_augmented):\n        self.train_tensors = tf.convert_to_tensor(np.concatenate((np.array(train_arrays), np.array(corona_augmented))))\n        self.test_tensors  = tf.convert_to_tensor(np.array(test_arrays))\n        \n        self.y_train_tensor = tf.convert_to_tensor(y_train)\n        self.y_test_tensor = tf.convert_to_tensor(final_test_data['class'].values)\n        \n        train_dataset = tf.data.Dataset.from_tensor_slices((self.train_tensors, self.y_train_tensor))\n        test_dataset = tf.data.Dataset.from_tensor_slices((self.test_tensors, self.y_test_tensor))\n        \n        batch_size = 16\n        sh_buffer = 1773\n\n        self.train_batches = train_dataset.shuffle(sh_buffer).batch(batch_size)\n        self.test_batches = test_dataset.batch(batch_size)\n        \n    def start(self): \n        ssl._create_default_https_context = ssl._create_unverified_context\n        #define input shape\n        inp_shape = (255,255,3)\n        #get the pretrained model\n        \n        base_model = tf.keras.applications.ResNet50(input_shape = inp_shape,\n                                            include_top = False,\n                                            weights='imagenet')\n        base_model.trainable = False\n        \n        # Construct the model\n        model = Sequential()\n        model.add(base_model)\n        model.add(GlobalAveragePooling2D())\n        model.add(Dense(128))\n        model.add(Dropout(0.2))\n        model.add(Dense(1, activation = 'sigmoid'))\n        \n        #add a earlystopping callback to stop the training if the model is not learning anymore\n        callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n        \n        # Define optimizer, loss function and performance metric for the training.\n        model.compile(optimizer='adam',\n              loss = 'binary_crossentropy',\n              metrics=['accuracy'])\n        # Train the model\n        model.fit(self.train_batches, epochs=10, validation_data=self.test_batches, callbacks=[callbacks])\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net = Net(prep.train_arrays, prep.test_arrays, prep.y_train, prep.final_test_data, prep.corona_augmented)\nprep = None\nnet.start()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(len(net.train_tensors))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Training(object):\n    pass\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Results(object):\n    pass\n    ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}