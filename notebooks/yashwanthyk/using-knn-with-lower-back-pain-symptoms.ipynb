{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler  #scale the data \nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import LabelEncoder  # Encode the target variables\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n#Tuning the model\nfrom sklearn.model_selection import GridSearchCV  \nfrom sklearn.model_selection import RandomizedSearchCV\nimport seaborn as sns\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#Read the data from csv file\ndata_set= pd.read_csv('../input/Dataset_spine.csv')\nprint(data_set.head())\n#cannot see all the columns?? set the display(Pandas) to show all columns\npd.set_option('display.expand_frame_repr', False)\nprint(data_set.head()) #ok all you see is numbers except Class_att and Unnamed:13","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"_uuid":"fa609d737876eed8d79b0bc2eabc19e29e627101"},"cell_type":"markdown","source":"#Examine the columns and observe the datatype and see if any missing values\n\n"},{"metadata":{"trusted":true,"_uuid":"92c66e5ef4a1b29c89d561b833556dede2e09562"},"cell_type":"code","source":"data_set.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5f67cb5adc31fb67de99af2c1e74f91c68779e30"},"cell_type":"markdown","source":"Lets first encode the Target Variable to numeric values by using Sklearn Label encoder.\n* Either you can use for loop to set 0 or 1 in target column but i used  label encoder because what if target variable has multiple ordinal categorical features like ('abnormal', 'normal', 'x','y','z') label encoder will be easy"},{"metadata":{"trusted":true,"_uuid":"4417d7644dd54844c26877971e40069a534eba5d"},"cell_type":"code","source":"print('Before:{}'.format(data_set['Class_att'].unique()))\nlbl= LabelEncoder()\ndata_set['Class_att']=lbl.fit_transform(data_set['Class_att'])\nprint('After:{}'.format(data_set['Class_att'].unique()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"803882ee0fc4fd6911ac11cb92fa7db676d92ca1"},"cell_type":"markdown","source":"Fine !!\n\nObserve the info() table there are 14 columns and 310 rows out of which 12 are float and 2 are object datatype.. 1 column Unname:13 has just 14 entries.\n\n*Lets first figure out what Unnamed:13 is ? and see whether its useful for calculating target column Class_att\nSometimes even null values have some meaning - lets find it in below step.\nfirst fill null values with some 'Unknown' and plot\n"},{"metadata":{"trusted":true,"_uuid":"e4cb2207b8856274585a85e8cdcaae1771d0bad4"},"cell_type":"code","source":"data_set['Unnamed: 13']=data_set['Unnamed: 13'].fillna('Unknown')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3895bab856bbbba99712d41fc666286f8f3eb8c4"},"cell_type":"markdown","source":"Now that we have filled missing values, lets compare with Target data"},{"metadata":{"trusted":true,"_uuid":"af662affca19aea147707edba8f406ddf204f90e"},"cell_type":"code","source":"print(data_set.groupby('Class_att')['Unnamed: 13'].count())   ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5e1262ccd1b4876e975c6c157ec67df0fedf0ffd"},"cell_type":"markdown","source":"Now that from above we have found that the columns Unnamed:13 has 210 features contributing to Abnormal(0) , 100 contributing to normal(1).\n\nLets plot using Seaborn just these two columns"},{"metadata":{"trusted":true,"_uuid":"f0bdcb26d55a58f3f01e666dd5a195062d95aa53"},"cell_type":"code","source":"sns.stripplot(x='Class_att', y='Unnamed: 13', data=data_set)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c2b523e41bcaf046d1fddb3ff6d47cbf4514e712"},"cell_type":"markdown","source":"Ok, from the above figure missing('Unknown') values has both target values 0  and 1, and 14 other values all contribute to Abnormal.. i dont think this will be useful to determine abnormal or normal because missing('unknown') values have both. \n\nLets delete this column from our dataset"},{"metadata":{"trusted":true,"_uuid":"8fca891eb5c1e9e888334459750c397f196bbf87"},"cell_type":"code","source":"data_set= data_set.drop('Unnamed: 13', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"92b14864d6eb23377e21e733453099957676b222"},"cell_type":"markdown","source":"Ok , great. Now that we have all numeric 13 columns. lets observe the contribution of feature columns (12 columns ) with target column (1 columns - Class_att) by using Seaborn Pair plot"},{"metadata":{"trusted":true,"_uuid":"c6a5992437520f69bd89eaba9ffa9eaac22bc876"},"cell_type":"code","source":"sns.pairplot(data_set, y_vars='Class_att', x_vars=data_set.columns.drop('Class_att'), hue='Class_att')\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cebb1515de56467c73956a2a9d118098c6e5ceb3"},"cell_type":"markdown","source":"Ok to visualize it is little small..but if you zoom it this provides a great explanation each columns contribution with Target variable (Y-axis).\n\nAlso observe carefully that col2 and col6 has negative values. But the min max difference is good for Col2 which is fine..but see for col6 min max difference is huge compare to other columns. So lets scale the data using Sklearn Min max scaler"},{"metadata":{"trusted":true,"_uuid":"87342180f5325a0ce74a37a0ef414b6aae780eb8"},"cell_type":"code","source":"scaler=MinMaxScaler()\n\ndata_set['Col6']=scaler.fit_transform(data_set['Col6'].values.reshape(-1,1))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"725508c8f1a695c77971718c113d3f80e778f335"},"cell_type":"markdown","source":"Now time to train and test the Data and to choose model we did scale and encode the data, the benefit would be applied for non tree based models. So i choosed KNearestNeighbors"},{"metadata":{"trusted":true,"_uuid":"2cbc1a92ed725293d361f2b8700fde246dfdf213"},"cell_type":"code","source":"\nX= data_set.drop('Class_att', axis=1)\ny= data_set['Class_att']\n\n\nX_train, X_test, y_train, y_test= train_test_split(X,y,test_size=0.2,random_state=42)\nknn=KNeighborsClassifier()\nknn.fit(X_train, y_train)\ny_pred= knn.predict(X_test)\nprint('knn score:{}'.format(knn.score(X_test,y_test)))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b88a3b3bcbc5e9dc59b75eee9ef440196ef0f444"},"cell_type":"markdown","source":"Tuning your model by using GridSearchCV and  Randomized Search CV"},{"metadata":{"trusted":true,"_uuid":"288dca88775591965a6025b117f4ee626b817309"},"cell_type":"code","source":"param_grid={'n_neighbors':range(1,10)}\nGS=GridSearchCV(knn, param_grid, cv=5)\nGS.fit(X_train, y_train)\nprint(GS.best_params_)\nprint(GS.best_score_)\n\n\nparam_grid={'n_neighbors':range(1,10)}\nknn=KNeighborsClassifier()\nknn_cv=RandomizedSearchCV(estimator=knn, param_distributions=param_grid, cv=4, n_iter=9)\nknn_cv.fit(X_train, y_train)\nprint(knn_cv.best_params_)\nprint(knn_cv.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4ddbf9444bc43022e1c1ad2e0691b9170d3664c0"},"cell_type":"markdown","source":"Ok So basically n_neighbors=5 (which was default in our model) yields better results.\n\nNow lets see what classification report say."},{"metadata":{"trusted":true,"_uuid":"1db101c20b0c442b8ae76bf3a5464bd66f8651a5"},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_test,y_pred))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"75169e00b70228e6d372c38a203566715ae61512"},"cell_type":"code","source":"Finally lets plot ROC curve.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b94cacc192e9d0c328e2d1f01694a428be50edd"},"cell_type":"code","source":"from sklearn.metrics import roc_curve\nfpr, tpr,_ = roc_curve(y_test, y_pred)\n\nplt.plot(fpr,tpr)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0c030f3687da273d2dc4bf3bc39fba6e492702be"},"cell_type":"markdown","source":"**Thank you all for watching!!. I will be happy if you find any mistakes or feed back on this. Then only i can learn!**"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}