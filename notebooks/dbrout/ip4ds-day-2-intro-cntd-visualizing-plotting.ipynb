{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Table of Contents\n- **<a href='#saving'>Saving Data and Objects</a>**<br>\n- **<a href='#numpy'>Numpy Continued</a>**<br>\n- **<a href='#matplotlib'>Plotting Library 1 - Matplotlib</a>**<br>\n- **<a href='#exercise1'>Exercise: 70's & 80's Automotive Data</a>**<br>\n- **<a href='#exercise2'>Exercise: Acceleration of the Universe</a>**<br>\n- **<a href='#geo'>Geographical Data</a>**<br>\n- **<a href='#images'>Images</a>**<br>\n- **<a href='#sound'>Sound</a>**<br>\n- **<a href='#pandas'>Other Plotting Libraries I: Pandas</a>**<br>\n- **<a href='#time'>Time Series</a>**<br>\n- **<a href='#seaborn'>Other Plotting Libraries II: Seaborn</a>**<br>\n- **<a href='#afternoon1'>Afternoon Project I: SDSS Galaxy Images</a>**<br>\n- **<a href='#afternoon2'>Afternoon Geo Projects II: US Wildfire Data or Uber Ride History</a>**<br>\n- **<a href='#afternoon3'>Afternoon Project III: Germany Energy Consumption</a>**<br>\n- **<a href='#afternoon4'>Afternoon Project IV: Stock Trading Strategy</a>**<br>\n"},{"metadata":{},"cell_type":"markdown","source":"<a id='saving'></a>\n# Saving Data and Objects"},{"metadata":{},"cell_type":"markdown","source":"### Compressed Numpy Files"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lots_of_data1 = np.arange(10)*2/57\nlots_of_data2 = np.linspace(0,11,777)**2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#save your hard work (maybe something that was computationally intensive)\nnp.savez('save_my_progress.npz',mydata1=lots_of_data1,mydata2=lots_of_data2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#you can come back later and re-load those right back in\nreloaded = np.load('save_my_progress.npz')\nreloaded['mydata1']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Pickle-ing"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's make a class to pickle\nclass Vehicle:\n    def __init__(\n        self, \n        name = None,\n        number_of_wheels = None,\n        top_speed = None,\n        ):\n        \n        self.name = name\n        self.nwheels = number_of_wheels\n        self.topspeed = top_speed\n        self.currentspeed = 0\n        \n    def accelerate(self,how_much=1):\n        self.currentspeed += how_much\n        print('vroooooommmm')\n        \nmustang = Vehicle(\n            name = 'Elanor',\n            number_of_wheels = 4,\n            top_speed = 200)\nprint(mustang.name)\nmustang.accelerate()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#reminder that you may not be creating classes but you are definitely using them. For example:\narr = np.ones((100,2))\nprint(arr.dtype)\nprint(arr.sum(axis=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\n\n#We can pickle the class though, and get back what we put in\noutfile = open('vehicle.pkl','wb') #lets python know we're about to write bytes (not string)\npickle.dump(mustang,outfile)\noutfile.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"myReadInOldVehichle = pickle.load(open('vehicle.pkl','rb'))\nprint(myReadInOldVehichle.name)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Saving in a human readable format = JSON"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dictionary\npets_info = {\n    'cat':{'color':'black','weight':10,'toys':['string','box','squeaky']},\n    'dog':{'color':'white','weight':40,'toys':['ball','frisbee','squeaky']}\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\nprint(json.dumps(pets_info, indent=4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outfile = open('pets.json','w')\noutfile.write(json.dumps(pets_info, indent=4))\noutfile.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"readbackin =open('pets.json','r').read()\ndictionary_read_back_in = json.loads(readbackin)\ndictionary_read_back_in['dog']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='numpy'></a>"},{"metadata":{},"cell_type":"markdown","source":"# Numpy Continued..."},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = np.zeros((2,2))   # Create an array of all zeros\nprint('zeros\\n',a)              # Prints \"[[ 0.  0.]\n                      #          [ 0.  0.]]\"\n\nb = np.ones((1,2))    # Create an array of all ones\nprint('ones\\n',b)              # Prints \"[[ 1.  1.]]\"\n\nc = np.array([[1,1],[2,2]])  # Create a matrix\nprint('matrix\\n',c)               \n                       \nd = np.eye(2)         # Create a 2x2 identity matrix\nprint('identity\\n',d)              # Prints \"[[ 1.  0.]\n                      #          [ 0.  1.]]\"\n\nrando = np.random.random((5,3))  # Create an array filled with random values\nprint('random\\n',rando)                     \n                            \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#you can set some/all elements at once\nrando[3,:] = 0\nprint(rando)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#you can specify a list of rows/columns\nrando[[1,2],:] = 0\nprint(rando)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(rando.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = np.array([[1,2],[3,4]], dtype=np.float64)\ny = np.array([[5,6],[7,8]], dtype=np.float64)\n\n# Elementwise sum; both produce the array\n# [[ 6.0  8.0]\n#  [10.0 12.0]]\nprint(x + y)\nprint(np.add(x, y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"v = np.array([9,10])\nw = np.array([11, 12])\n\n# Inner product of vectors; both produce 219\nprint(v.dot(w))\nprint(np.dot(v, w))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = np.array([[1,2],[3,4]])\nv = np.array([9,10])\n\n# Matrix / vector product; both produce the rank 1 array [29 67]\nprint(x.dot(v))\nprint(np.dot(x, v))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = np.array([[1,2],[3,4]])\ny = np.array([[5,6],[7,8]])\n\n# Matrix / matrix product; both produce the rank 2 array\nprint(x.dot(y))\nprint(np.dot(x, y))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Numpy will compute many quantities along any specified axis"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = np.array([[1,2],[3,4]])\n\nprint(np.sum(x))  # Compute sum of all elements; prints \"10\"\nprint(np.sum(x, axis=0))  # Compute sum of each column; prints \"[4 6]\"\nprint(np.sum(x, axis=1))  # Compute sum of each row; prints \"[3 7]\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='plotting'></a>\n# Plotting Library 1 - Matplotlib"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = np.linspace(0, 10, 100)\n\nfig = plt.figure()\nplt.plot(x, np.sin(x), '-')\nplt.plot(x, np.cos(x), '--');\n#plt.savefig('test.pdf')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig.canvas.get_supported_filetypes()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"plt.savefig('test1.pdf')\n!ls","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Marker Styling"},{"metadata":{"trusted":true},"cell_type":"code","source":"rng = np.random.RandomState(0)\nplt.figure(figsize=(12,8))\nfor marker in ['o', '.', ',', 'x', '+', 'v', '^', '<', '>', 's', 'd']:\n    plt.plot(rng.rand(5), rng.rand(5), marker, ms=13,\n             label=\"marker=%s\"%(marker))\nplt.legend()\nplt.xlim(0, 1.8);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Colors and sizes"},{"metadata":{"trusted":true},"cell_type":"code","source":"rng = np.random.RandomState(0)\nx = rng.randn(100)\ny = rng.randn(100)\ncolors = rng.rand(100)\nsizes = 1000 * rng.rand(100)\n\nplt.figure(figsize=(12,8))\nplt.scatter(x, y, c=colors, s=sizes, alpha=0.3,\n            cmap='viridis')\nplt.colorbar();  # show color scale\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Error Bars"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = np.linspace(0, 10, 50)\ndy = 0.8\ny = np.sin(x) + dy * np.random.randn(50)\n\nplt.figure(figsize=(12,8))\nplt.errorbar(x, y, yerr=dy, fmt='o', color='black',\n             ecolor='lightgray', elinewidth=3, capsize=3);\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Matlab style interface"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now lets read in some vehicle data\ndata = np.genfromtxt('../input/mpg-data/Auto.txt', names=True, usecols=range(7))\nprint(type(data))\nprint(data.dtype)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14,11))  # create a plot figure\n\n# create the first of two panels and set current axis\nplt.subplot(2, 1, 1) # (rows, columns, panel number)\nplt.scatter(data['horsepower'], data['acceleration'],color='blue',s=4)\nplt.xlabel('Horespower')\nplt.ylabel('Acceleration')\n\n# create the second panel and set current axis\nplt.subplot(2, 1, 2)\nplt.scatter(data['horsepower'], data['mpg'],color='orange',s=4)\nplt.xlabel('Horespower')\nplt.ylabel('Miles Per Gallon');\n\n# plt.subplot(3, 1, 3)\n# plt.scatter(data['horsepower'], data['weight'])\n# plt.xlabel('Horespower')\n# plt.ylabel('Weight')\n# #plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Object Oriented Interface"},{"metadata":{"trusted":true},"cell_type":"code","source":"# First create a grid of plots\n# ax will be an array of two Axes objects\nfig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10,8))\nprint(type(axes))\nprint(axes.shape)\naxes[0,0].scatter(data['horsepower'], data['acceleration'])\naxes[0,0].set_xlabel('Horsepower');\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='exercise1'></a>\n# Exercise: 70's & 80's Automotive Data \n- Plot a 7x7 grid of all possible combinations of features (columns) of automotive data (scatter plots)\n- color the data points red if the car was built before '77 and green if built in or after '77\n- on the diagonal, plot histograms.\n- add a legend of the years to the plot\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#your code here","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## More Plotting"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = np.linspace(0, 10, num=11, endpoint=True)\ny = np.cos(-x**2/9.0)\nplt.plot(x,y);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.interpolate import interp1d\nf = interp1d(x, y) # default is linear\nf2 = interp1d(x, y, kind='cubic')\n#notice that f and f2 are now functions!\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f(5);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f([2,3,4]);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xnew = np.linspace(0, 10, num=99) # lets make it smooth now\nplt.figure(figsize=(10,6))\nplt.plot(x, y, 'o', label='data')\nplt.plot(xnew, f(xnew), '-', label='linear')\nplt.plot(xnew, f2(xnew), '--', label='cubic')\nplt.legend(loc='best', fontsize=16);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='exercise2'></a>\n# Exercise: Measuring the accelerating universe"},{"metadata":{"trusted":true},"cell_type":"code","source":"#This is the most recent dataset of Supernovae from the UPenn affiliated Dark Energy Survey\ndata = np.genfromtxt('../input/des-supernova-data-and-model/DARK_ENERGY_SURVEY_SUPERNOVA.txt', names=True)\nxdat = data['zHD'] #velocity\nydat = data['MU'] #distance\nydaterr = data['MUERR']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,7))\nplt.scatter(xdat,ydat,s=10)\nplt.xlabel('Velocity',fontsize=20)\nplt.ylabel('Distance',fontsize=20);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## In this exercise I want you to (in groups of 2 people):\n\n- make two plots stacked on top of each other.\n- TOP: plot the x and y datapoints as a scatter plot with error bars\n- TOP: plot the model of the universe\n- Bottom: Plot the residuals between the data and the accelerating model\n- Bottom: plot a horizontal line at zero\n- Bottom: plot the residuals between the accelerating model and the decelerating model\n- Bottom: place a legend that designates which model is which\n- BOTH: color the datapoints by their value in the column *SURVEY* (which indicates which telescope took the data)\n- Top: place a legend that designates which *SURVEY* is which color\n- Bottom: place a legend that designates each model (matter and accel) and shows the chi squared between the data and the model.\n![image.png](attachment:image.png)\n","attachments":{"image.png":{"image/png":"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"}}},{"metadata":{"trusted":true},"cell_type":"code","source":"#This is a model for the universe that is decelerating (no dark energy)\nmatter_only_universe = np.genfromtxt('../input/des-supernova-data-and-model/decelerating_universe.txt', names=True, delimiter=',')\nxmatter = matter_only_universe['zHD']\nymatter = matter_only_universe['MU']\n\n#This is a model for the universe that is accelerating (yes dark energy)\ndark_energy_filled_universe_model = np.genfromtxt('../input/des-supernova-data-and-model/accelerating_universe.txt', names=True, delimiter=',')\nxaccel = dark_energy_filled_universe_model['zHD']\nyaccel = dark_energy_filled_universe_model['MU']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#your code here","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='histograms'></a>\n# Histograms"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = np.random.normal(size=1000)\n\nfig, ax = plt.subplots()\n\nH = ax.hist(x, bins=50, alpha=0.5, histtype='stepfilled')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots()\n\nH = ax.hist(x, bins=np.arange(-3,4,1), alpha=0.5, histtype='step',linewidth=4, density=True) #density=normalized\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2D Histograms"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.datasets.samples_generator import make_blobs\nn_components = 3\nDATA, _ = make_blobs(n_samples=2000, centers=n_components, \n                      cluster_std = [5, 2.5, 2], \n                      random_state=42)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Extract x and y\nx = DATA[:,0]\ny = DATA[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(x, y, s=10)\nplt.title(f\"Example of a mixture of {n_components} distributions\")\nplt.xlabel(\"x\")\nplt.ylabel(\"y\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a figure with 6 plot areas\nfig, axes = plt.subplots(ncols=3, nrows=1, figsize=(18, 5))\n \n# Everything sarts with a Scatterplot\naxes[0].set_title('Scatterplot')\naxes[0].scatter(x, y,s=10,color='black')\n# As you can see there is a lot of overplottin here!\n \n# Thus we can cut the plotting window in several hexbins\nnbins = 20\naxes[1].set_title('Hexbin')\naxes[1].hexbin(x, y, gridsize=nbins, cmap=plt.cm.BuGn_r)\n \n# 2D Histogram\naxes[2].set_title('2D Histogram')\naxes[2].hist2d(x, y, bins=nbins, cmap=plt.cm.BuGn_r);\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='contours'></a>\n# Contour Plots"},{"metadata":{"trusted":true},"cell_type":"code","source":"def f1(x,y):\n    from scipy.stats import norm\n    Z = norm.pdf(X)*norm.pdf(Y)\n    return Z","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = np.linspace(-3, 3, 100)\ny = np.linspace(-3, 3, 100)\n\nX, Y = np.meshgrid(x, y)\n\nZ = f1(X, Y)\n\n#plt.contourf(X, Y, Z, alpha=.3)\nplt.contour(X, Y, Z)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.contour(X, Y, Z, levels = [.01, .05, .1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\nfrom mpl_toolkits.mplot3d import Axes3D\n%matplotlib notebook\n\n# Create a surface plot and projected filled contour plot under it.\nfig = plt.figure(figsize=(10,6))\nax = fig.gca(projection='3d')\n\nax.plot_surface(X, Y, Z, \n                cmap=cm.viridis)\n\ncset = ax.contourf(X, Y, Z, zdir='z', offset=-0.15, cmap=cm.viridis)\n\n# Adjust the limits, ticks and view angle\nax.set_zlim(-0.15,0.2);\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='geo'></a>\n\n# Plotting Geographical Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline \n#we have to reset because I dont want any more interactive plots\nfrom mpl_toolkits.basemap import Basemap\nimport matplotlib.pyplot as plt\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1. Draw the map background\nfig = plt.figure(figsize=(8, 8))\n#philadelphia\ncenterlat = 39.95\ncenterlon = -75.16\nm = Basemap(projection='lcc', #resolution='h', \n            lat_0=centerlat, lon_0=centerlon,\n            width=1E6, height=1.2E6)\nm.shadedrelief()\nm.drawcoastlines(color='gray')\nm.drawstates(color='gray')\nm.scatter(centerlon,centerlat,s=1000,c='blue',latlon=True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exercise: Just plot the locations of populations >200,000 and make the size of each point is the square_root(population-200,000). Add a legend."},{"metadata":{"trusted":true},"cell_type":"code","source":"cities = np.genfromtxt('../input/california-cities/california_cities.csv',names=True,delimiter=',')\n\n# Extract the data we're interested in\nlat = cities['latd']\nlon = cities['longd']\npopulation = cities['population_total']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#your code here","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='images'></a>\n# Plotting images"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\n#raw files are extremely efficient (binary data)\nim = np.fromfile('../input/ctscan/ct.raw',dtype=np.uint16).reshape((512,512)) #need to specify the size and dtype to recover the original image\n\n\nplt.figure(figsize=(8,8))\n\nextent = (0, 10, 0, 10) #you get to define the axes\n_ = plt.imshow(im, cmap=plt.cm.hot, extent=extent)\n\nplt.scatter(6.8, 6, facecolors='none', edgecolors='blue', s=500)\nplt.scatter(6.4, 5.9, facecolors='none', edgecolors='blue', s=500)\nplt.text(5.8, 7.,'Something Bad?',color='white',rotation=30,fontsize=12);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets do some edge detection for fun\nfrom skimage import feature\nedges1 = feature.canny(im.astype(float), sigma=8)\nplt.imshow(edges1, cmap=plt.cm.gray)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='sound'></a>\n# Sound"},{"metadata":{"trusted":true},"cell_type":"code","source":"fname = '../input/freesound/jazzy.wav'\nimport IPython.display as ipd  # To play sound in the notebook\nipd.Audio(fname)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using scipy\nfrom scipy.io import wavfile\nrate, data = wavfile.read(fname)\nprint(\"Sampling (frame) rate = \", rate)\nprint(\"Total samples (frames) = \", data.shape);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"five_seconds = rate*5\nplt.plot(data[:five_seconds,0]);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.specgram(data[:five_seconds,0], Fs=rate, cmap=plt.get_cmap('jet'));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='pandas'></a>\n# Other plotting frameworks I: Pandas\n### It is built on top of matplotlib (so knowledge of matplot lib is helpful!)."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!head -10 ../input/mpg-data/Auto.txt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets read in that old Auto data into a dataframe\ndf = pd.read_csv('../input/mpg-data/Auto.txt',delimiter='\\t')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dataframes are useful for a number of reasons. First of all, they're pretty.\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['horsepower'].plot.hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('year').mean()\n#This is a new table that we can plot!","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('year').mean()['horsepower'].plot(figsize=(10,7))\nplt.ylabel('horsepower');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('year').mean()['acceleration'].plot(figsize=(10,7))\nplt.ylabel('acceleration');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.plotting.scatter_matrix(df, alpha=0.2, figsize=(16, 12), diagonal='hist');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"color_palette = {0: \"red\", 1: \"green\"}\nmycolors = [color_palette[int(c)] for c in df['year']>=75]   \npd.plotting.scatter_matrix(df, alpha=0.2, figsize=(16, 12), diagonal='kde', color=mycolors);\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='time'></a>\n## Pandas Time Series"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nprint(pd.to_datetime('2018-01-15 3:45pm'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas_datareader.data as web\nimport datetime\n\n# We will look at stock prices over the past year, starting at January 1, 2016\nstart = datetime.datetime(2018,1,1)\nend = datetime.date.today()\n \n# Let's get Apple stock data; Apple's ticker symbol is AAPL\n# First argument is the series we want, second is the source (\"yahoo\" for Yahoo! Finance), third is the start date, fourth is the end date\napple = web.DataReader(\"AAPL\", \"yahoo\", start, end)\nprint(apple.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"apple['Close'].plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"google = web.DataReader(\"GOOG\", \"yahoo\", start, end)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets make a new dataframe with all our stocks\nstocks = pd.DataFrame({\"AAPL\": apple[\"Close\"],\n                      \"GOOG\": google[\"Close\"]})\n ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### lets say I want to compare the percentage increase between Apple and Google"},{"metadata":{"trusted":true},"cell_type":"code","source":"def percent_increase(stock):\n    return stock/stock[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stock_return = stocks.apply(percent_increase)\nstock_return.head()#look we have a new dataframe where our function was applied","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stock_return.plot(figsize=(10,6));\nplt.axhline(1,color='k',linestyle='--')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"<a id='seaborn'></a>\n# Other Plotting Frameworks II: Seaborn\n\n### Seaborn is great tool for visualizing high dimesional data, especially from pandas dataframes. So knowledge of Pandas is essential.\n\nHere's a link to the documentation: https://seaborn.pydata.org/"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We'll use a built in dataset from seaborn\n# this requires that your kernel is connected to the internet\ntitanic = sns.load_dataset('titanic')\ntitanic.head()\n#oh look its a pandas dataframe!","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's start with a histogram of a single variable\nsns.distplot(titanic['fare'],kde=False,color=\"red\",bins=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# You can also joint plots: essentially histograms with two variables\nsns.jointplot(x=\"fare\",y=\"age\",data=titanic,kind=\"scatter\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot(x=\"fare\",y=\"age\", data=titanic, kind='kde')\n#sns.jointplot(x=\"fare\",y=\"age\", data=titanic, kind='kde', xlim=[0,60]);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Easily visualize categorical variables with boxplots, violin plots, or swarm plots\nsns.boxplot(x=\"class\",y=\"age\", data=titanic);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make heatmaps - note that you need to transform your data into a matrix form first.\n# The pandas fuction corr will make correlation matrices of numerical variables\nplt.figure(figsize=(14,10))\nsns.heatmap(titanic.corr(),cmap=\"coolwarm\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# One epecially useful plot for exploratory data analysis is a pair plot,\n# which shows you distributions and scatterplots for all your variables\n\n# we're going to select only a few variables so it is easier to see\ntitanic_subset = titanic[[\"survived\",\"age\",\"fare\",\"sex\",\"alone\"]]\nsns.pairplot(titanic_subset,hue='survived',palette='coolwarm');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot_kws (keword args) allows us to change just about anything that can be changed in matplotib\nsns.pairplot(titanic_subset,hue='survived',palette='coolwarm',plot_kws={\"s\": 3}); ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Lets go back to the now familiar Automotive data..."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/mpg-data/Auto.txt',delimiter='\\t')\ng = sns.FacetGrid(df, col=\"origin\") #lets set up a grid of plots grouping by origin\ng.map(sns.distplot, \"horsepower\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.FacetGrid(df, col=\"origin\") #lets set up a grid of plots grouping by origin\ng.map(sns.kdeplot, \"horsepower\", \"acceleration\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.FacetGrid(df, col=\"origin\") #lets set up a grid of plots grouping by origin\ng.map(plt.scatter, \"horsepower\", \"acceleration\", s=10);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# R-style plotting (ggplot)\n\nhttps://nipunbatra.github.io/blog/2017/50-ggplot-python-1.html"},{"metadata":{},"cell_type":"markdown","source":"# Last but not least. The notebook Viewer!"},{"metadata":{},"cell_type":"markdown","source":"https://nbviewer.jupyter.org"},{"metadata":{},"cell_type":"markdown","source":"<a id='afternoon1'></a>\n# Afternoon Project I: SDSS Galaxy Data\n### Please dont forget to make your kernel public so the whole class can see.\nhttps://www.kaggle.com/dbrout/sdss-galaxies-visualization"},{"metadata":{},"cell_type":"markdown","source":"<a id='afternoon2'></a>\n# Afternoon Geo Projects II: US Wildfire Data or Uber Trips in NYC\n### Please dont forget to make your kernel public so the whole class can see.\n\nhttps://www.kaggle.com/dbrout/us-wildfires-project\n\nhttps://www.kaggle.com/dbrout/uber-trips-project\n"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"<a id='afternoon3'></a>\n# Afternoon Project III: Germany Energy Consumption\n### Please dont forget to make your kernel public so the whole class can see.\n\nhttps://www.kaggle.com/dbrout/germany-power-consumption-project"},{"metadata":{},"cell_type":"markdown","source":"<a id='afternoon4'></a>\n# Afternoon Project IV: Stock Trading Strategy\n### Please dont forget to make your kernel public so the whole class can see.\n\nhttps://www.kaggle.com/dbrout/stock-trading-project"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}