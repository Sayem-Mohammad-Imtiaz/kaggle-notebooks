{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/massive-stock-news-analysis-db-for-nlpbacktests/analyst_ratings_processed.csv\",error_bad_lines=False)\ndata.sample(5).head(5)\ndata = data.drop_duplicates()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getUniqueness(dataset):\n    for (columnName, columnData) in dataset.iteritems():\n        print(f\"unique values in [{columnName}]: {columnData.nunique()}\")\n\n    print(f\"total rows: {len(dataset.index)}\")\ngetUniqueness(data)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"stockseries =data[\"stock\"].value_counts()[:400].index.tolist()\ndata = data[data[\"stock\"].isin(stockseries)]\ngetUniqueness(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import requests\ndef sendRequest(stock):\n    url = \"https://apidojo-yahoo-finance-v1.p.rapidapi.com/stock/v2/get-chart\"\n\n    querystring = {\"interval\":\"1d\",\"symbol\":stock,\"range\":\"10y\",\"region\":\"US\"}\n\n    headers = {\n        'x-rapidapi-key': \"45d667af06msheb5f2732d2eef1bp1352f5jsn5b6c64d88be2\",\n        'x-rapidapi-host': \"apidojo-yahoo-finance-v1.p.rapidapi.com\"\n        }\n\n    response = requests.request(\"GET\", url, headers=headers, params=querystring)\n    if response.status_code==200:\n        return response.text\n    else:\n        return None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\ndef getHistData(stock):\n    response = sendRequest(stock)\n    histdata = pd.DataFrame()\n    if response == None:\n        return histdata\n    else:\n        try:\n            jsondata = json.loads(response)\n\n            #print(data2['chart'][\"result\"][0][\"indicators\"][\"quote\"][0])\n            timestamps = pd.Series(jsondata['chart'][\"result\"][0][\"timestamp\"])\n            high = pd.Series(jsondata['chart'][\"result\"][0][\"indicators\"][\"quote\"][0][\"high\"])\n            low = pd.Series(jsondata['chart'][\"result\"][0][\"indicators\"][\"quote\"][0][\"low\"])\n            close = pd.Series(jsondata['chart'][\"result\"][0][\"indicators\"][\"adjclose\"][0][\"adjclose\"])\n            columns = {\"timestamps\":timestamps,\"high\":high,\"low\":low,\"close\":close,\"stock\":stock}\n            histdata = pd.DataFrame(columns)\n            return histdata\n        except:\n            print(stock)\n            print(response)\n            return pd.DataFrame()\n            \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stocks = [\"NFLX\",\"BBRY\",\"EBAY\"]\nframes = []\ncount = 0\nfor stock in stockseries:\n    histData = getHistData(stock)\n    if not histData.empty:\n        frames.append(histData)\nallstocks = pd.concat(frames)\nprint(len(allstocks))\nallstocks.sample(20).head(20)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"allstocks.to_csv(\"stockhistory.csv\",index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}