{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# Background\nThis project focuses on the Exploratory Data Analysis, including data exploration, data preparation, and data cleaning. The dataset of interest here is the training dataset of [Loan Prediction Problem Dataset](https://www.kaggle.com/altruistdelhite04/loan-prediction-problem-dataset). The original problem is to predict customers' loan eligiblity based on their application details. This project does not cover the Loan Prediction steps nor the Machine Learning algorithms.\n\n**Data Dictionary:**\n-           Loan_ID: Unique Loan ID\n-            Gender: Male/Female\n-           Married: Applicant married Y/N\n-        Dependents: Number of dependents\n-         Education: Graduate/Undergrad\n-     Self_Employed: Y/N\n-   ApplicantIncome: Applicant Income\n- CoapplicantIncome: Coapplicant Income\n-        LoanAmount: Loan amount in thousands\n-  Loan_Amount_Term: Term of loan in months\n-    Credit_History: 1 for meeting the guidelines, 0 for not meeting the guidelines\n-     Property_Area: Urban/Semi Urban/Rural\n-       Loan_Status: Loan approved Y/N"},{"metadata":{},"cell_type":"markdown","source":"## Loading Dataset\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nfrom scipy.stats import chi2_contingency\nfrom statsmodels.stats import weightstats as stests\nimport matplotlib.pyplot as plt\ndf = pd.read_csv('../input/loan-prediction-problem-dataset/train_u6lujuX_CVtuZ9i.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Exploration and Preparation\n## Variable Identification"},{"metadata":{},"cell_type":"markdown","source":"Although we are not going to solve the original Loan Prediction problem here, it is generally helpful to keep the orginal problem in mind while performing the data exploration analysis.\nThus the types of variables can be defined as following:\n\n**(Possible) Predictor Variable:**\n- Gender\n- Married\n- Dependents\n- Education\n- Self_Employed\n- ApplicantIncome\n- CoapplicationIncome\n- LoanAmount\n- Loan_Amount_Term\n- Credit_History\n- Property_Area\n\n**Target Variable:**\n- Loan_Status"},{"metadata":{"trusted":true},"cell_type":"code","source":"# dataset comprises of 614 observations and 13 charateristics\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Section Summary\n\nThe dataset can be separated into the following two variable categories:\n\n**Categorical:**\n- Gender\n- Married\n- Education\n- Self_Employed\n- Loan_Amount_Term\n- Credit_History\n- Property_Area\n- Loan_Status\n\n**Continuous:**\n- ApplicantIncome\n- CoapplicantIncome\n- LoanAmount"},{"metadata":{},"cell_type":"markdown","source":"## Univariate Analysis\n### Categorical Variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_tbl1 = df.groupby(['Gender','Married','Education','Self_Employed'])\nfreq_tbl1.size()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_tbl2 = df.groupby(['Credit_History','Property_Area','Loan_Amount_Term'])\nfreq_tbl2.size()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Loan_Status.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are more loans approved than rejected."},{"metadata":{},"cell_type":"markdown","source":"### Continuous Variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[['ApplicantIncome','CoapplicantIncome','LoanAmount']].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observations:**\n1. there are missing values on the latter characteristic\n2. there is notably a large difference between the 75th percentile and max values of all three variables\n\nThus two observations suggest that there are missing values and outliers in our data set, treatments should be applied in order to avoid building a biased predictive model. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# indeed we found there are quite a few outliers\nsns.boxplot(df['ApplicantIncome'])\nsns.despine()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IQR_app = df.ApplicantIncome.quantile(0.75) - df.ApplicantIncome.quantile(0.25)\nupper_limit_app = df.ApplicantIncome.quantile(0.75) + (IQR_app*1.5)\nupper_limit_extreme_app = df.ApplicantIncome.quantile(0.75) + (IQR_app*2)\nupper_limit_app, upper_limit_extreme_app","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outlier_count_app = len(df[(df['ApplicantIncome'] > upper_limit_app)])\noutlier_count_app","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# the ApplicantIncome distribution is right skewed \nfig=plt.figure()\nax=fig.add_subplot(1,1,1)\nax.hist(df['ApplicantIncome'], bins=30)\nplt.title('ApplicantIncome Distribution')\nplt.xlabel('Applicant Income')\nplt.ylabel('Frequency')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(df['CoapplicantIncome'])\nsns.despine()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IQR_coapp = df.CoapplicantIncome.quantile(0.75) - df.CoapplicantIncome.quantile(0.25)\nupper_limit_coapp = df.CoapplicantIncome.quantile(0.75) + (IQR_coapp*1.5)\nupper_limit_extreme_coapp = df.CoapplicantIncome.quantile(0.75) + (IQR_coapp*2)\nupper_limit_coapp, upper_limit_extreme_coapp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outlier_count_coapp = len(df[(df['CoapplicantIncome'] > upper_limit_coapp)])\noutlier_count_coapp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(df['LoanAmount'])\nsns.despine()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IQR_loanAmt = df.LoanAmount.quantile(0.75) - df.LoanAmount.quantile(0.25)\nupper_limit_loanAmt = df.LoanAmount.quantile(0.75) + (IQR_loanAmt*1.5)\nupper_limit_extreme_loanAmt = df.LoanAmount.quantile(0.75) + (IQR_loanAmt*2)\nupper_limit_loanAmt, upper_limit_extreme_loanAmt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outlier_count_loanAmt = len(df[(df['LoanAmount'] > upper_limit_loanAmt)])\noutlier_count_loanAmt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# the LoanAmount distribution is right skewed \nfig=plt.figure()\nax=fig.add_subplot(1,1,1)\nax.hist(df['LoanAmount'], bins=100)\nplt.title('Loan Amount Distribution')\nplt.xlabel('Loan Amount')\nplt.ylabel('Frequency')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Section Summary\n\n**Variables with missing values:**\n- Gender (13 or 2.1%)\n- Married (3 or 0.5%)\n- Dependents (15 or 2.4%)\n- Self_Employed (32 or 5.2%)\n- LoanAmount (22 or 3.6%)\n- Loan_Amount_Term (14 or 2.3%)\n- Credit_History (50 or 8.1%)\n\n**Variables with outliers:**\n- ApplicantIncome (43 outliers exceeding its maximum value)\n- CoapplicantIncome ( 17 outliers exceeding its maximum value)\n- LoanAmount (30 outliers exceeding its maximum value)\n\n*where \"Maximum\" refers to 75th Percentile + 1.5$*$(Interqartile Range)*"},{"metadata":{},"cell_type":"markdown","source":"## Bivariate Analysis\n### Categorical and Categorical\n#### Loan_Status and Gender"},{"metadata":{"trusted":true},"cell_type":"code","source":"tbl = pd.crosstab(index = df['Loan_Status'], columns = df['Gender'])\ntbl.index = ['Not Approved','Approved']\ntbl","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Pearson's Chi-square Test**\n\nThe chi-square test statistic for a test of independence of two categorical variables is as follows:\n$$\n\\begin{aligned}\n\\chi^2 = \\sum{(O - E)^2 / E} \\;, \\;Where\\:O \\:is \\:the \\:observed \\:frequency \\:and \\\\\\:E \\:is \\:the \\:expected \\:frequency\n\\end{aligned}\n$$\n\n$\n\\\\\nH_0: \\:There \\:is \\:no \\:relationship \\:between \\:Loan\\:Status \\:and \\:Gender\n\\\\H_1: \\:There \\:is \\:a \\:significant \\:relation \\:between \\:the \\:two\n$"},{"metadata":{},"cell_type":"markdown","source":"**Calculated chi-square value (orginal frequency table excluding missing values)**\n\nThe calculated $\\chi^2$ value is 0.2369751, where the degree of freedom is 1.\nThe critical value of the $\\chi^2$ distribution with df of 1 is 3.841. \n\nHence:\n\n$$\n\\begin{aligned}\ncritical\\:value\\:of\\:\\chi^2\\: >=\\:calculated\\:value\\:of\\:\\chi^2\n\\end{aligned}\n$$\n\n\nTherefore $H_0$ is Accepted"},{"metadata":{"trusted":true},"cell_type":"code","source":"# performing the test using Python\n# frequency table without missing values\nstat, p, dof, expected = chi2_contingency(tbl)\nalpha = 0.05\nprint(\"p value is \" + str(p))\nif p <= alpha:\n    print('Dependent (reject H_0)')\nelse:\n    print('Independent (H_0 holds true)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# How would the table look like if we include counts of missing-value obersvations?\ntbl2 = tbl\ndf_new = df[df['Gender'].isnull()]\ntbl_tp = df_new.groupby('Loan_Status')\ntbl_tp.size()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tbl2['NaN_val'] = [5,8]\ntbl2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tbl2.plot.bar(xlabel = 'Loan Status', rot = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above bar plot does not provide much evidence to show that there is a significant relationship between *Loan_Status* and *Gender*. "},{"metadata":{},"cell_type":"markdown","source":"**Calculated chi-square value (modified frequency table including counts of missing values)**\n\nThe calculated $\\chi^2$ value is 5.66887, where the degree of freedom is 2.\nThe critical value of the $\\chi^2$ distribution with df of 2 is 5.991. \n\nHence:\n\n$$\n\\begin{aligned}\ncritical\\:value\\:of\\:\\chi^2\\: >=\\:calculated\\:value\\:of\\:\\chi^2\n\\end{aligned}\n$$\n\n\nTherefore $H_0$ is Accepted"},{"metadata":{"trusted":true},"cell_type":"code","source":"# performing the test using Python\n# frequency table with missing values\nstat, p, dof, expected = chi2_contingency(tbl2)\nalpha = 0.05\nprint(\"p value is \" + str(p))\nif p <= alpha:\n    print('Dependent (reject H_0)')\nelse:\n    print('Independent (H_0 holds true)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Both $\\chi^2$ tests reject the $H_0$, sugguesting that there is no significant relationship between *Loan_Status* and *Gender*."},{"metadata":{},"cell_type":"markdown","source":"#### Loan_Status and Married"},{"metadata":{"trusted":true},"cell_type":"code","source":"tbl_marrd = pd.crosstab(index = df['Loan_Status'], columns = df['Married'])\ntbl_marrd.index = ['Not Approved','Approved']\ntbl_marrd.columns = ['Not Married','Married']\ntbl_marrd","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Chi-square Test**\n\n$\nH_0: \\:There \\:is \\:no \\:relationship \\:between \\:variables\\:Loan\\:Status\\:and\\:Married\n\\\\H_1:\\: Negation\\:of\\:H_0\n$"},{"metadata":{"trusted":true},"cell_type":"code","source":"stat, p, dof, exptected = chi2_contingency(tbl_marrd)\nalpha = 0.05\nprint(\"p value is \" + str(p))\nif p <= alpha:\n    print('Dependent (reject H_0)')\nelse:\n    print('Independent (H_0 holds true)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Loan_Status and Education"},{"metadata":{"trusted":true},"cell_type":"code","source":"tbl_ed = pd.crosstab(df['Loan_Status'],df['Education'])\ntbl_ed.index = ['Not Approved','Approved']\ntbl_ed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tbl_ed.plot.bar(xlabel = 'Loan Status', rot = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Chi-square Test**\n\n$\nH_0: \\:There \\:is \\:no \\:relationship \\:between \\:Loan\\:Status\\:and\\:Education\n\\\\H_1:\\: Negation\\:of\\:H_0\n$"},{"metadata":{"trusted":true},"cell_type":"code","source":"stat, p, dof, exptected = chi2_contingency(tbl_ed)\nalpha = 0.05\nprint(\"p value is \" + str(p))\nif p <= alpha:\n    print('Dependent (reject H_0)')\nelse:\n    print('Independent (H_0 holds true)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above probability indicates that the relationship between *Loan_Status* and *Education* is significant at 95% confidence."},{"metadata":{},"cell_type":"markdown","source":"#### Loan_Status and Self_Employed"},{"metadata":{"trusted":true},"cell_type":"code","source":"tbl_emp = pd.crosstab(index = df['Loan_Status'], columns = df['Self_Employed'])\ntbl_emp.index = ['Not Approved','Approved']\ntbl_emp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tbl_emp.plot.bar(xlabel = 'Loan Status',rot = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Chi-square Test**\n\n$\nH_0: \\:There \\:is \\:no \\:relationship \\:between \\:Loan\\:Status\\:and\\:Self\\_Employed\n\\\\H_1:\\: Negation\\:of\\:H_0\n$"},{"metadata":{"trusted":true},"cell_type":"code","source":"stat, p, dof, expected = chi2_contingency(tbl_emp)\nalpha = 0.05\nprint(\"p value is \" + str(p))\nif p <= alpha:\n    print('Dependent (reject H_0)')\nelse:\n    print('Independent (H_0 holds true)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Chi-square test sugguests that there is no significant relationship between *Loan_Status* and *Self_Employed*."},{"metadata":{},"cell_type":"markdown","source":"#### Loan_Status and Loan_Amount_Term"},{"metadata":{"trusted":true},"cell_type":"code","source":"tbl_term = pd.crosstab(index = df['Loan_Status'], columns = df['Loan_Amount_Term'])\ntbl_term.index = ['Not Approved','Approved']\ntbl_term","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stat, p, dof, exptected = chi2_contingency(tbl_term)\nalpha = 0.05\nprint(\"p value is \" + str(p))\nif p <= alpha:\n    print('Dependent (reject H_0)')\nelse:\n    print('Independent (H_0 holds true)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Loan_Status and Credit_History"},{"metadata":{"trusted":true},"cell_type":"code","source":"tbl_crt = pd.crosstab(index = df['Loan_Status'], columns = df['Credit_History'])\ntbl_crt.index = ['Not Approved','Approved']\ntbl_crt.columns = ['Guidelines Not Met', 'Guidelines Met'] \ntbl_crt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- *Credit_History* has 50 missing values\n- It seems to suggest that there are relatively more loans approved when the applicants' credit meets the guidelines"},{"metadata":{"trusted":true},"cell_type":"code","source":"tbl_crt.plot.bar(xlabel = 'Loan_Status', rot = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Chi-square Test**\n\n$\nH_0: \\:There \\:is \\:no \\:relationship \\:between \\:Loan\\:Status\\:and\\:Credit\\_History\n\\\\H_1:\\: Negation\\:of\\:H_0\n$"},{"metadata":{"trusted":true},"cell_type":"code","source":"stat, p, dof, expected = chi2_contingency(tbl_crt)\nalpha = 0.05\nprint(\"p value is \" + str(p))\nif p <= alpha:\n    print('Dependent (reject H_0)')\nelse:\n    print('Independent (H_0 holds true)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Loan_Status and Property_Area"},{"metadata":{"trusted":true},"cell_type":"code","source":"tbl_area = pd.crosstab(index = df['Loan_Status'], columns = df['Property_Area'])\ntbl_area.index = ['Not Approved','Approved']\ntbl_area","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tbl_area.plot.bar(xlabel = 'Loan Status', rot = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Chi-square Test**\n\n$\nH_0: \\:There \\:is \\:no \\:relationship \\:between \\:Loan\\:Status\\:and\\:Property\\_Area\n\\\\H_1:\\: Negation\\:of\\:H_0\n$"},{"metadata":{"trusted":true},"cell_type":"code","source":"stat, p, dof, exptected = chi2_contingency(tbl_area)\nalpha = 0.05\nprint(\"p value is \" + str(p))\nif p <= alpha:\n    print('Dependent (reject H_0)')\nelse:\n    print('Independent (H_0 holds true)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Categorical and Continuous\n#### Loan_Status and ApplicantIncome"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['ApplicantIncome'].groupby(df['Loan_Status']).describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data set of Loan_Status Not Approved\ntbl_appN = df[(df['Loan_Status'] == 'N')]\ntbl_appN = tbl_appN['ApplicantIncome']\ntbl_appN ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data set of Loan_Status Approved\ntbl_appY = df[(df['Loan_Status'] == 'Y')]\ntbl_appY = tbl_appY['ApplicantIncome']\ntbl_appY","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Two sample Z-Test (ApplicantIncome splitted by Loan_Status)**\n\n$$\nH_0: \\:\\mu_{N_{income}} =\\:\\mu_{Y_{income}}\n\\\\H_1:\\: Negation\\:of\\:H_0\n$$\n\nAssuming two levels of samples are independent."},{"metadata":{"trusted":true},"cell_type":"code","source":"ztest, pval = stests.ztest(tbl_appN,tbl_appY,value = 0, alternative = 'two-sided')\nalpha = 0.05\nprint(\"p value is \" + str(pval))\nif pval <= alpha:\n    print('Two population means are not equal (reject H_0)')\nelse:\n    print('Two population means are equal (H_0 holds true)')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusion**\n\nThere is no evidence that the difference in Applicant income will have an impact on loan eligibility."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (6,5))\ndf.boxplot(column = 'ApplicantIncome', by = 'Loan_Status', ax = ax, grid = False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Loan_Status and LoanAmount"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['LoanAmount'].groupby(df['Loan_Status']).describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tbl_amtN = df[(df['Loan_Status'] == 'N')]\ntbl_amtN = tbl_amtN['LoanAmount'].dropna() # we know there are missing values\ntbl_amtN ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tbl_amtY = df[(df['Loan_Status'] == 'Y')]\ntbl_amtY = tbl_amtY['LoanAmount'].dropna() # missing values dropped\ntbl_amtY ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Two sample Z-Test (LoanAmount splitted by Loan_Status)**\n\n$$\nH_0: \\:\\mu_{N_{LoanAmt}} =\\:\\mu_{Y_{LoanAmt}}\n\\\\H_1:\\: Negation\\:of\\:H_0\n$$\n\nAssuming two levels of samples are independent."},{"metadata":{"trusted":true},"cell_type":"code","source":"ztest, pval = stests.ztest(tbl_amtN,tbl_amtY,value = 0, alternative = 'two-sided')\nalpha = 0.05\nprint(\"p value is \" + str(pval))\nif pval <= alpha:\n    print('Two population means are not equal (reject H_0)')\nelse:\n    print('Two population means are equal (H_0 holds true)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusion**\n\nThere is no evidence that the difference in Loan Amount will result in lower/higher loan acceptance rate."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (6,5))\ndf.boxplot(column = 'LoanAmount', by = 'Loan_Status', ax = ax, grid = False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Continuous and Contintuous\n#### ApplicantIncome vs. LoanAmount"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure()\nax = fig.add_subplot(1,1,1)\nax.scatter(df['ApplicantIncome'],df['LoanAmount'])\nplt.title('ApplicantIncome and LoanAmount Distribution')\nplt.xlabel('Applicant Income')\nplt.ylabel('Loan Amount')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above scatter plot, it looks like there is a positive correlation between 'LoanAmount' and 'ApplicantIncome'. Yet here we have not performed any missing data nor outlier treatment, thus it is too early to make a conclusion."},{"metadata":{},"cell_type":"markdown","source":"#### CoapplicantIncome vs. LoanAmount"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure()\nax = fig.add_subplot(1,1,1)\nax.scatter(df['CoapplicantIncome'],df['LoanAmount'])\nplt.title('CoapplicantIncome and LoanAmount Distribution')\nplt.xlabel('Coapplicant Income')\nplt.ylabel('Loan Amount')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is hard to make any conclusion from the above scatter plot, but it looks like a portion of the points sugguests the positive correlation. Ideally to double check, we would calculate the correlation coefficient, but due to difference in two variables' shapes, we have to perform missing values treatment in order to proceed with correlation calculation."},{"metadata":{},"cell_type":"markdown","source":"### Section Summary (where the missing values are simply ignored)\n\nPredictor variables that are observed to have a statistacally significant association with the Target varialbe are as follows:\n- Married\n- Education\n- Credit_History\n- Property_Area"},{"metadata":{},"cell_type":"markdown","source":"# Missing value Treatment"},{"metadata":{},"cell_type":"markdown","source":"From previous analysis, we know most of the variables have at least one missing value, below will examine the possible cause of the occurence of the missing values, in my opinion, for each variable.\n\n- Gender: Most likely be missing completely at random(MCAR)\n- Married: MCAR\n- Dependents: MCAR\n- Self_Employed: MCAR\n- LoanAmount: MCAR\n- Loan_Amount_Term: MCAR\n- Credit_History: Missing at random. Applicants who do not meeting credit guidelines tend to have higher missing value compare to those whose credit met the guidelines.\n\nStatistically speaking, if the number of missing observations is less than 5% of the sample, we can drop them. In addition, if the missing value is determined to be MCAR, we can safely perform deletion of missing value cases. With that said, missing observations of *Gender, Married, Dependents, Self_Employed, LoanAmount and Loan_Amount_Term* can be dropped. \n\nAs for *Credit_History*, imputation will be conducted to replace the missing ones."},{"metadata":{},"cell_type":"markdown","source":"## Credit_History Imputation\n\nBefore the actual imputation, we should examine if there's any correlation between *Credit_History* and other variables."},{"metadata":{},"cell_type":"markdown","source":"### Credit_history vs Gender\n\n**Chi-square Test**\n\n$\nH_0: \\:There \\:is \\:no \\:relationship \\:between \\:variables\\:Credit\\_History\\:and\\:Gender\n\\\\H_1:\\: Negation\\:of\\:H_0\n$"},{"metadata":{"trusted":true},"cell_type":"code","source":"tbl_cGender = pd.crosstab(df['Credit_History'],df['Gender'])\nstat, p, dof, exptected = chi2_contingency(tbl_cGender)\nalpha = 0.05\nprint(\"p value is \" + str(p))\nif p <= alpha:\n    print('Dependent (reject H_0)')\nelse:\n    print('Independent (H_0 holds true)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Credit_History vs Married\n\n**Chi-square Test**\n\n$\nH_0: \\:There \\:is \\:no \\:relationship \\:between \\:variables\\:Credit\\_History\\:and\\:Married\n\\\\H_1:\\: Negation\\:of\\:H_0\n$"},{"metadata":{"trusted":true},"cell_type":"code","source":"tbl_cMarried = pd.crosstab(df['Credit_History'],df['Married'])\nstat, p, dof, exptected = chi2_contingency(tbl_cMarried)\nalpha = 0.05\nprint(\"p value is \" + str(p))\nif p <= alpha:\n    print('Dependent (reject H_0)')\nelse:\n    print('Independent (H_0 holds true)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Credit_History vs Education\n\n**Chi-square Test**\n\n$\nH_0: \\:There \\:is \\:no \\:relationship \\:between \\:variables\\:Credit\\_History\\:and\\:Education\n\\\\H_1:\\: Negation\\:of\\:H_0\n$"},{"metadata":{"trusted":true},"cell_type":"code","source":"tbl_cEd = pd.crosstab(df['Credit_History'],df['Education'])\nstat, p, dof, exptected = chi2_contingency(tbl_cEd)\nalpha = 0.05\nprint(\"p value is \" + str(p))\nif p <= alpha:\n    print('Dependent (reject H_0)')\nelse:\n    print('Independent (H_0 holds true)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Credit_History vs Self_Employed\n\n**Chi-square Test**\n\n$\nH_0: \\:There \\:is \\:no \\:relationship \\:between \\:variables\\:Credit\\_History\\:and\\:Self\\_Employed\n\\\\H_1:\\: Negation\\:of\\:H_0\n$"},{"metadata":{"trusted":true},"cell_type":"code","source":"tbl_cEmp = pd.crosstab(df['Credit_History'],df['Self_Employed'])\nstat, p, dof, exptected = chi2_contingency(tbl_cEmp)\nalpha = 0.05\nprint(\"p value is \" + str(p))\nif p <= alpha:\n    print('Dependent (reject H_0)')\nelse:\n    print('Independent (H_0 holds true)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Credit_History vs Property_Area\n\n**Chi-square Test**\n\n$\nH_0: \\:There \\:is \\:no \\:relationship \\:between \\:variables\\:Credit\\_History\\:and\\:Property\\_Area\n\\\\H_1:\\: Negation\\:of\\:H_0\n$"},{"metadata":{"trusted":true},"cell_type":"code","source":"tbl_cArea = pd.crosstab(df['Credit_History'],df['Property_Area'])\nstat, p, dof, exptected = chi2_contingency(tbl_cArea)\nalpha = 0.05\nprint(\"p value is \" + str(p))\nif p <= alpha:\n    print('Dependent (reject H_0)')\nelse:\n    print('Independent (H_0 holds true)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Credit_History vs ApplicantIncome\n\n**Two sample Z-Test (ApplicantIncome splitted by Loan_Status)**\n\n$$\nH_0: \\:\\mu_{N_{applicantIncome}} =\\:\\mu_{Y_{applicantIncome}}\n\\\\H_1:\\: Negation\\:of\\:H_0\n$$"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['ApplicantIncome'].groupby(df['Credit_History']).describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tbl_incomeN = df[(df['Credit_History'] == 0.0)]\ntbl_incomeN = tbl_incomeN['ApplicantIncome']\ntbl_incomeN ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tbl_incomeY = df[(df['Credit_History'] == 1.0)]\ntbl_incomeY = tbl_incomeY['ApplicantIncome']\ntbl_incomeY ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ztest, pval = stests.ztest(tbl_incomeN,tbl_incomeY,value = 0, alternative = 'two-sided')\nalpha = 0.05\nprint(\"p value is \" + str(pval))\nif pval <= alpha:\n    print('Two population means are not equal (reject H_0)')\nelse:\n    print('Two population means are equal (H_0 holds true)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observation:**\nThere isn't any correlation between *Credit_History* and other predictor variables."},{"metadata":{},"cell_type":"markdown","source":"## Imputation using Most Frequent values"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom sklearn.impute import SimpleImputer\nimr = SimpleImputer(missing_values = np.nan,strategy = 'most_frequent')\nimr = imr.fit(df[['Credit_History']])\ndf['Credit_History'] = imr.transform(df[['Credit_History']]).ravel()\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Deletion\nFor simplicity, we will delete observations where any of the variables is missing due to MCAR."},{"metadata":{"trusted":true},"cell_type":"code","source":"# if proceed with dropping NaN before imputation\n# the sample size will reduce down to 480\n# yet if we drop observations where missing values are found after imputation\n# the sample size is reduced to 523 rather\ndf = df.dropna()\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Outlier Treatment\nFrom previous analysis, where we ignored the missing-value observations, variables *ApplicantIncome, CoapplicantIncome,* and *LoanAmount* are found to have univariate outliers in the upper boundaries. Now let's see if there's any changes on outliers after our missing value treatment. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df[['ApplicantIncome','CoapplicantIncome','LoanAmount']].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(df['ApplicantIncome'])\nsns.despine()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IQR_1 = df.ApplicantIncome.quantile(0.75) - df.ApplicantIncome.quantile(0.25)\nupper_limit_1 = df.ApplicantIncome.quantile(0.75) + (IQR_1*1.5)\nupper_limit_extreme_1 = df.ApplicantIncome.quantile(0.75) + (IQR_1*2)\nupper_limit_1, upper_limit_extreme_1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outlier_count_1 = len(df[(df['ApplicantIncome'] > upper_limit_1)])\noutlier_count_1 \n# notice the number of the outliers did not change after missing-value treatment","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Trimming\nWe will use Trimming here as our outlier treatment method."},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('mode.chained_assignment', None)\nindex_1 = df[(df['ApplicantIncome'] >= upper_limit_1)].index\n#index_1\ndf.drop(index_1, inplace = True)\noutlier_ct_1 = len(df[(df['ApplicantIncome'] > upper_limit_1)])\noutlier_ct_1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(df['CoapplicantIncome'])\nsns.despine()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IQR_2 = df.CoapplicantIncome.quantile(0.75) - df.CoapplicantIncome.quantile(0.25)\nupper_limit_2 = df.CoapplicantIncome.quantile(0.75) + (IQR_2*1.5)\nupper_limit_extreme_2 = df.CoapplicantIncome.quantile(0.75) + (IQR_2*2)\nupper_limit_2, upper_limit_extreme_2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outlier_count_2 = len(df[(df['CoapplicantIncome'] > upper_limit_2)])\noutlier_count_2 \n# number of outliers reduced from 17 to 16 after missing-value treatment","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pd.set_option('mode.chained_assignment', None)\nindex_2 = df[(df['CoapplicantIncome'] >= upper_limit_2)].index\n#index_2\ndf.drop(index_2, inplace = True)\noutlier_ct_2 = len(df[(df['CoapplicantIncome'] > upper_limit_2)])\noutlier_ct_2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(df['LoanAmount'])\nsns.despine()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IQR_3 = df.LoanAmount.quantile(0.75) - df.LoanAmount.quantile(0.25)\nupper_limit_3 = df.LoanAmount.quantile(0.75) + (IQR_3*1.5)\nupper_limit_extreme_3 = df.LoanAmount.quantile(0.75) + (IQR_3*2)\nupper_limit_3, upper_limit_extreme_3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outlier_count_3 = len(df[(df['LoanAmount'] > upper_limit_3)])\noutlier_count_3 \n# number of outliers reduced from 30 to 23 after missing-value treatment","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pd.set_option('mode.chained_assignment', None)\nindex_3 = df[(df['LoanAmount'] >= upper_limit_3)].index\n#index_3\ndf.drop(index_3, inplace = True)\noutlier_ct_3 = len(df[(df['LoanAmount'] > upper_limit_3)])\noutlier_ct_3","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Variable Correlations After Data Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"#encoding to numeric data type\ncode_numeric = {'Male':1, 'Female':2,\n               'Yes': 1, 'No':2,\n                'Graduate':1, 'Not Graduate':2,\n                'Urban':1, 'Semiurban':2, 'Rural':3,\n                'Y':1, 'N':0,\n                '3+':3 }\ndf = df.applymap(lambda i: code_numeric.get(i) if i in code_numeric else i)\ndf['Dependents'] = pd.to_numeric(df.Dependents)\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix = np.triu(df.corr())\nfig, ax = plt.subplots(figsize = (10,10))\nsns.heatmap(df.corr(), annot = True, mask = matrix, linewidths = .5, ax = ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion\n\nDepending on different methods of missing-value and/or outlier treatments, the level of data loss might have impact on prediction models which are used to solve the original problem. This project is only to explore the dataset and to describe dataset characterizations through data visualization and statistical techniques. Below shows how much each variable correlates with the target variable."},{"metadata":{"trusted":true},"cell_type":"code","source":"m = matrix[:,11]\nm = pd.DataFrame(m)\nm1 = np.transpose(m)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m1.columns = (df.columns[1:])\nm2 = np.transpose(m1)\nnew_col = ['corr_to_Loan_Status']\nm2.columns =new_col","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sort predictor variables by their correlation strength to the Target variable\nm2['corr_to_Loan_Status'] = m2['corr_to_Loan_Status'].abs()\nm2.sort_values(by = new_col, ascending = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}