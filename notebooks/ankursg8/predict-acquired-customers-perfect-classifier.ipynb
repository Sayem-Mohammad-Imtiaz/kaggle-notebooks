{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Data Dictionary\n\n1 - age (numeric)\n\n2 - job : type of job (categorical: \"admin.\",\"unknown\",\"unemployed\",\"management\",\"housemaid\",\"entrepreneur\",\"student\",\n\"blue-collar\",\"self-employed\",\"retired\",\"technician\",\"services\") \n\n3 - marital : marital status (categorical: \"married\",\"divorced\",\"single\"; note: \"divorced\" means divorced or widowed)\n\n4 - education (categorical: \"unknown\",\"secondary\",\"primary\",\"tertiary\")\n\n5 - default: has credit in default? (binary: \"yes\",\"no\")\n\n6 - balance: average yearly balance, in euros (numeric) \n\n7 - housing: has housing loan? (binary: \"yes\",\"no\")\n\n8 - loan: has personal loan? (binary: \"yes\",\"no\")\n\n**related with the last contact of the current campaign:**\n\n9 - contact: contact communication type (categorical: \"unknown\",\"telephone\",\"cellular\") \n\n10 - day: last contact day of the month (numeric)\n\n11 - month: last contact month of year (categorical: \"jan\", \"feb\", \"mar\", â€¦, \"nov\", \"dec\")\n\n12 - duration: last contact duration, in seconds (numeric)\n\n**other attributes:**\n\n13 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n\n14 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric, -1 means client was not previously contacted)\n\n15 - previous: number of contacts performed before this campaign and for this client (numeric)\n\n16 - poutcome: outcome of the previous marketing campaign (categorical: \"unknown\",\"other\",\"failure\",\"success\")\n\n**Output variable (desired target):**\n\n17 - y - has the client subscribed a term deposit? (binary: \"yes\",\"no\")"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import recall_score, make_scorer, confusion_matrix, classification_report, fbeta_score\n\n# Define seed for repeatability\nSEED = 42\nnp.random.seed(SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read in train data\ntrain_df = pd.read_csv('/kaggle/input/banking-dataset-marketing-targets/train.csv', \n                       sep=\";\")\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read in test data\ntest_df = pd.read_csv('/kaggle/input/banking-dataset-marketing-targets/test.csv', \n                      sep=\";\")\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Explore training data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have no missing information. According to the data dictionary missing values are labeled as `unknown`."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['age'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['age'].plot.hist(bins=30, density=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['job'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['marital'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['education'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['default'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['balance'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['balance'].plot.hist(bins=50, density=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['balance'].plot.box()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We do have outliers in the balance column. There are a few ways to deal with the outliers:\n- We set a maximum value, say at 90 percentile. Additionally, create a new column that indicates the balance value is greater than the threshold.\n- We let the values be and hope the model is robust to the outliers."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['housing'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['loan'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['contact'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['day'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['day'].value_counts(normalize=True).describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['month'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Customers are rarely contacted in the month of `December`. This makes sense, it is the holiday season and customers would not like to be bothered during this time of the year. But given December is a festive month, are customers more likely to say yes during this time?"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['duration'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['duration'].plot.hist(bins=50, density=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['duration'].plot.box()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The distribution of duration is similar to that of balance. We can clip the outliers and create an additional column to record this information."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Investigate duration values that are 0\ntrain_df[train_df['duration'] == 0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If the customer was contacted but never answered his/her phone the `duration` value can be `0`"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['campaign'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['campaign'].plot.hist(bins=30, density=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['pdays'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Investigate first time contact\nprint(train_df.loc[train_df['pdays'] == -1, 'pdays'].count())\nprint(train_df.loc[train_df['pdays'] == -1, 'pdays'].count()/train_df.shape[0]*100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"81% of customers were contacted for the first time."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Investigate repeat contacts\ntrain_df.loc[train_df['pdays'] != -1, 'pdays'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.loc[train_df['pdays'] != -1, 'pdays'].plot.hist(bins=20, density=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['previous'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Majority of the values are 0. This matches with what we found with `pdays`. \n- One customer was contacted 275 times. This looks like a data error. We will replace this value with the mean of non-zero values."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.loc[train_df['previous'] == 275, 'previous'] = train_df.loc[train_df['previous'] != 0, 'previous'].median()\ntrain_df['previous'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.percentile(train_df.loc[train_df['previous'] != 0, 'previous'], q=95)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.loc[train_df['previous'] >= 9, 'y'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['poutcome'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.groupby(['poutcome', 'y'])['y'].count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Build a machine learning model using the data as it is. After we set a baseline we apply feature engineering techniques to try and improve the performance of the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create train_x dataframe\ntrain_x = train_df.iloc[:, :-1]\ntrain_x.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create train_y dataframe\ntrain_y = train_df[['y']]\ntrain_y.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get a list of columns for one-hot encoding\nohe_cols = list(train_x.select_dtypes(include='object').columns.values)\n\n# We want to label encode education\nle_col = ['education']\n\n# Drop education \nohe_cols.remove('education')\nohe_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x = pd.get_dummies(train_x, prefix=ohe_cols, columns=ohe_cols, drop_first=True)\ntrain_x.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Perform label encoding on education\ned_cat = {'unknown': 0, \n          'primary': 1,\n          'secondary': 2,\n          'tertiary': 3}\ntrain_x['education'] = train_x['education'].replace(ed_cat)\ntrain_x['education'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encode target variable\ny_cat = {'no': 0, \n         'yes': 1}\ntrain_y['y'] = train_y['y'].replace(y_cat)\ntrain_y['y'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create the test_x dataframe\ntest_x = test_df.iloc[:, :-1]\n\n# Create train_y dataframe\ntest_y = test_df[['y']]\n\n# One-hot encode columns\ntest_x = pd.get_dummies(test_x, prefix=ohe_cols, columns=ohe_cols, drop_first=True)\n\n# Label encode education\ntest_x['education'] = test_x['education'].replace(ed_cat)\n\n# Encode target variable\ntest_y['y'] = test_y['y'].replace(y_cat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_x.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_y.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decision Tree Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define the model\ndc = DecisionTreeClassifier(max_depth=30, min_samples_split=10, min_samples_leaf=10,\n                            random_state=SEED, class_weight=\"balanced\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define a scorer\nrs = make_scorer(recall_score)\n\n# Cross validation\ncv = cross_val_score(dc, train_x, train_y, cv=10, n_jobs=-1, scoring=rs)\nprint(\"Cross validation scores: {}\".format(cv))\nprint(\"%0.2f recall with a standard deviation of %0.2f\" % (cv.mean(), cv.std()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit the model on the complete train dataset\ndc.fit(train_x, train_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get predictions from the train dataset\npred = dc.predict(train_x)\nprint(\"The train recall score is {}\".format(np.round(recall_score(train_y, pred), 2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title(\"Confusion matrix on Train set\")\nax = sns.heatmap(confusion_matrix(train_y, pred), annot=True, fmt='d')\nbottom, top = ax.get_ylim()\nax.set_ylim(bottom + 0.5, top - 0.5)\nplt.yticks(rotation=0)\nplt.xlabel(\"Predicted Labels\")\nplt.ylabel(\"Actual Labels\")\nplt.show()\nprint(classification_report(train_y, pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get predictions from the test dataset\npred = dc.predict(test_x)\nprint(\"The test recall score is {}\".format(np.round(recall_score(test_y, pred), 2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title(\"Confusion matrix on Test set\")\nax = sns.heatmap(confusion_matrix(test_y, pred), annot=True, fmt='d')\nbottom, top = ax.get_ylim()\nax.set_ylim(bottom + 0.5, top - 0.5)\nplt.yticks(rotation=0)\nplt.xlabel(\"Predicted Labels\")\nplt.ylabel(\"Actual Labels\")\nplt.show()\nprint(classification_report(test_y, pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(n_jobs=-1, random_state=SEED, class_weight=\"balanced_subsample\")\n\n# Define a scorer\nrs = make_scorer(recall_score)\n\n# Cross validation\ncv = cross_val_score(rf, train_x, train_y, cv=10, n_jobs=-1, scoring=rs)\nprint(\"Cross validation scores: {}\".format(cv))\nprint(\"%0.2f recall with a standard deviation of %0.2f\" % (cv.mean(), cv.std()))\n\n# Fit the model on the complete train dataset\nrf.fit(train_x, train_y)\n\n# Get predictions from the train dataset\npred = rf.predict(train_x)\nprint(\"The train recall score is {}\".format(np.round(recall_score(train_y, pred), 2)))\n\nplt.title(\"Confusion matrix on Train set\")\nax = sns.heatmap(confusion_matrix(train_y, pred), annot=True, fmt='d')\nbottom, top = ax.get_ylim()\nax.set_ylim(bottom + 0.5, top - 0.5)\nplt.yticks(rotation=0)\nplt.xlabel(\"Predicted Labels\")\nplt.ylabel(\"Actual Labels\")\nplt.show()\nprint(classification_report(train_y, pred))\n\n# Get predictions from the test dataset\npred = rf.predict(test_x)\nprint(\"The test recall score is {}\".format(np.round(recall_score(test_y, pred), 2)))\n\nplt.title(\"Confusion matrix on Test set\")\nax = sns.heatmap(confusion_matrix(test_y, pred), annot=True, fmt='d')\nbottom, top = ax.get_ylim()\nax.set_ylim(bottom + 0.5, top - 0.5)\nplt.yticks(rotation=0)\nplt.xlabel(\"Predicted Labels\")\nplt.ylabel(\"Actual Labels\")\nplt.show()\nprint(classification_report(test_y, pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Great! We achieved a perfect classifier on the test set! The best part is, we did not have to perform complex feature engineering. Just the basic one-hot encoding and label encoding on categorical variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Determine the maximum permissible balance value\n# balance_thresh = np.percentile(train_df['balance'], q=90)\n\n# # Create a new column that indicates balance > threshold\n# train_df['balance_outliers'] = np.where(train_df['balance'] > balance_thresh, 1, 0)\n# train_df['balance_outliers'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Clip balance values with the threshold\n# train_df['balance'].clip(upper=balance_thresh, inplace=True)\n# train_df['balance'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Check balance values that are negative\n# train_df.loc[train_df.balance < 0, 'balance'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Determine the maximum permissible value for duration\n# duration_thresh = np.percentile(train_df['duration'], 90)\n\n# # Create a new column that indicates duration > threshold\n# train_df['duration_outliers'] = np.where(train_df['duration'] > duration_thresh, 1, 0)\n# train_df['duration_outliers'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Clip the values\n# train_df['duration'].clip(upper=duration_thresh, inplace=True)\n# train_df['duration'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Determine the maximum permissible value for duration\n# campaign_thresh = np.percentile(train_df['campaign'], 90)\n\n# # Create a new column that indicates duration > threshold\n# train_df['campaign_outliers'] = np.where(train_df['campaign'] > campaign_thresh, 1, 0)\n# train_df['campaign_outliers'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Clip the values\n# train_df['campaign'].clip(upper=campaign_thresh, inplace=True)\n# train_df['campaign'].describe()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}