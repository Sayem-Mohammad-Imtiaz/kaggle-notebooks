{"cells":[{"metadata":{},"cell_type":"markdown","source":"Required packages and modules"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings; warnings.filterwarnings(action='once')\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import tree\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\nfrom sklearn.gaussian_process import GaussianProcessClassifier","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Importing and cleaning data"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"df = pd.read_csv('../input/dataset-of-songs-in-spotify/genres_v2.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(columns = ['type', 'id', 'uri', 'track_href', 'analysis_url', 'time_signature', 'song_name', \n                   'Unnamed: 0', 'title'], inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.genre.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.genre.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_slim = df.loc[df['genre'].isin(['Underground Rap', 'Rap', 'RnB', 'Pop', 'Hiphop', 'dnb', 'Emo'])]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"EDA and Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Draw Plot\nplt.figure(figsize=(13,10), dpi= 80)\nsns.violinplot(x='genre', y='duration_ms', data=df_slim, scale='width', inner='quartile')\n\n# Decoration\nplt.title('Violin Plots of Song Duration by Genre', fontsize=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_slim.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_slim[['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness',\n       'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',\n       'duration_ms']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"X is a dataframe of predictors"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df_slim[['genre']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"y is a vector of the dependent/target variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We split the data into train and test on the ratio 80/20"},{"metadata":{},"cell_type":"markdown","source":"Supervised ML algorithms - classifiers"},{"metadata":{},"cell_type":"markdown","source":"1. Decision Tree Classification"},{"metadata":{},"cell_type":"markdown","source":"First we train the model by feeding it our X and y training sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = tree.DecisionTreeClassifier()\nclf = clf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we use our remaining X values in the test set to predict some y's"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If the model had 100% classification accuracy then all non-diagonals in the confusion matrix would be zero. \nSome good and expected results here: \nClassified dnb with 96% accuracy and Emo with 62%.\nPop had the worst accuracy with 14% - no clear pattern? \nRemaining genres are all very similar so high accuracy was unexpected."},{"metadata":{},"cell_type":"markdown","source":"2. K-Nearest Neighbours"},{"metadata":{},"cell_type":"markdown","source":"First we need to find the optimal k based on our training data. \nThis for loop goes through a range for k and runs KNN on the training sets, makes y predictions using the X test set and records accuracy.\nWe plot below to find the optimal k, i.e. with the highest accuracy."},{"metadata":{"trusted":true},"cell_type":"code","source":"range_k = range(1,40)\nscores = {}\nscores_list = []\n\nfor k in range_k:\n   classifier = KNeighborsClassifier(n_neighbors = k)\n   classifier.fit(X_train, y_train.values.ravel())\n   y_pred = classifier.predict(X_test)\n   scores[k] = metrics.accuracy_score(y_test,y_pred)\n   scores_list.append(metrics.accuracy_score(y_test,y_pred))\nresult = metrics.confusion_matrix(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 5), dpi=80)\n\nplt.plot(range_k,scores_list)\nplt.xlabel(\"Value of K\")\nplt.ylabel(\"Accuracy\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The accuracy hits 40% with k = 7 and seems to increase and flatten out at 42% at the highest."},{"metadata":{},"cell_type":"markdown","source":"This is a different for loop to measure mean error "},{"metadata":{"trusted":true},"cell_type":"code","source":"error = []\n\n# Calculating error for K values between 1 and 40\n\nfor i in range(1, 40):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train, y_train.values.ravel())\n    pred_i = knn.predict(X_test).reshape(3592,1)\n    error.append(np.mean(pred_i != y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nplt.plot(range(1, 40), error, color='cornflowerblue', linestyle='dashed', marker='o',\n         markerfacecolor='cornflowerblue', markersize=10)\nplt.title('Error Rate K Value')\nplt.xlabel('K Value')\nplt.ylabel('Mean Error')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Shows the same pattern as above. \nSo we go ahead and apply KNN with k= 7"},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = KNeighborsClassifier(n_neighbors = 7)\nclassifier.fit(X_train, y_train.values.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = classifier.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Poor accuracy all round, with dnb and Underground Rap the only two more likely to be correctly classified than not"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}