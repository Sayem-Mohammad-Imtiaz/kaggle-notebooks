{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import FuncFormatter\nvgsales_dirty = pd.read_csv('../input/videogamesales/vgsales.csv')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Check dataset on null cells","execution_count":null},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"\nvgsales_dirty.isnull().sum(axis = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vgsales = vgsales_dirty.dropna(subset=['Year', 'Publisher'])\nvgsales = vgsales.iloc[:, 2:]\nvgsales.Year = vgsales.Year.astype(np.int64)\nvgsales.isnull().any()\nvgsales.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plan\n1. Analize dataset\n2. Try to predict missed release years of games\n3. Create sales prediction ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Let's look at the data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x=\"Platform\", kind=\"count\", data=vgsales, aspect=3, order = vgsales.Platform.value_counts().index);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" grouped_single = vgsales.groupby([\"Year\", \"Genre\"]).agg({'Other_Sales': ['count']}).reset_index()\npiv = pd.pivot_table(data=vgsales,\n                    index='Year',\n                    values='Other_Sales',\n                    columns='Genre', aggfunc='count') \nfig, ax = plt.subplots(figsize=(20,20))\nax = sns.heatmap(piv, annot=True, fmt=\".0f\", square=1,ax=ax)\nloc, labels = plt.yticks()\nax.set_yticklabels(rotation=0, labels=labels)\nplt.title('Heatmap of genre per year', fontsize = 20) # title with fontsize 20\nplt.xlabel('Genre', fontsize = 15) # x-axis label with fontsize 15\nplt.ylabel('Year', fontsize = 15) # y-axis label with fontsize 15\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"disneyInteractiveStudios = vgsales[vgsales.Publisher == \"Disney Interactive Studios\"]\ndisneyInteractiveStudios = disneyInteractiveStudios[disneyInteractiveStudios.Platform == \"X360\"]\nsns.catplot(x=\"Year\", y=\"Genre\", data=disneyInteractiveStudios, aspect=3, estimator=np.sum );\nsns.catplot(x=\"Year\", y=\"Platform\", data=disneyInteractiveStudios, aspect=3, estimator=np.sum );\nsns.catplot(x=\"Genre\", kind=\"count\", data=disneyInteractiveStudios, aspect=2);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas.plotting import scatter_matrix\nfrom sklearn import preprocessing\nle = preprocessing.LabelEncoder()\ntransformedCT = vgsales.iloc[:,:]\ntransformedCT.Platform = le.fit_transform(transformedCT.Platform)\ntransformedCT.Year = le.fit_transform(transformedCT.Year)\ntransformedCT.Genre = le.fit_transform(transformedCT.Genre)\ntransformedCT.Publisher = le.fit_transform(transformedCT.Publisher)\ntransformedCT.head()\nscatter_matrix(vgsales, alpha=0.05, figsize=(20, 20));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transformedCT.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we see there is no correlation, except sales. Anyway, let's predict year and Global sales.\n\n# Try to predict year\n\nPreparing data:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.model_selection import train_test_split\ndf = pd.get_dummies(vgsales, columns=[\"Genre\", \"Publisher\", \"Platform\"], drop_first=True)\nX = df.iloc[:, 1:].values\ny = df.iloc[:, 0].values\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(criterion = 'entropy', n_estimators=10, random_state=0)\nclassifier.fit(X_train, y_train)\ny_pred = classifier.predict(X_test)\nfrom sklearn.metrics import accuracy_score\naccuracy_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"0.21973974957034126 - isn't best rusult. Expected.\n\n# Try to predict Global Sales.\n\nI suggest to exclude EU_Sales and JP_Sales columns because there is no sense at prediction, we can sum all sales and get Global.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y = vgsales.iloc[:, -1:].values\nX = vgsales.drop(columns = ['EU_Sales', 'JP_Sales', 'Global_Sales']).values\nX = pd.get_dummies(vgsales, columns=[\"Genre\", \"Publisher\", \"Platform\", \"Year\"], drop_first=True)\n\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX = sc.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVR\nregressor = SVR(kernel = 'rbf')\nregressor.fit(X_train, y_train.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting a new result\ny_pred = regressor.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import explained_variance_score\nexplained_variance_score(y_test, y_pred)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"0.7813348615339388 - not bad","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}