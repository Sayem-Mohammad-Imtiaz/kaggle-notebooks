{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**This dataset contains 5 different classes.**\n\n    0) N means \"Normal beat\"\n    \n    1) S means \"Supraventricular premature beat\"\n    \n    2) V means \"Premature ventricular contraction\"\n    \n    3) F means \"Fusion of ventricular and normal beat\"\n    \n    4) Q means \"Unclassifiable beat\""},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import layers\nfrom keras.layers import Input, Dense, Dropout, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, Embedding, Add\nfrom keras.layers import Conv1D, GlobalAveragePooling1D, AveragePooling2D, MaxPooling2D, MaxPool1D, ZeroPadding1D, GlobalMaxPooling2D, GlobalAveragePooling2D, LSTM, SpatialDropout1D\nfrom keras.models import Sequential, Model\nfrom keras.preprocessing import image\nfrom keras.utils import plot_model\nfrom keras.applications.inception_v3 import InceptionV3\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nfrom keras.layers.merge import concatenate","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Simple ANN"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"mit_test_data = pd.read_csv('/kaggle/input/heartbeat/mitbih_test.csv', header=None)\nmit_train_data = pd.read_csv('/kaggle/input/heartbeat/mitbih_train.csv', header=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import to_categorical\nX, y = mit_train_data.iloc[: , :-1], mit_train_data.iloc[: , -1]\nX, valX, y, valy= train_test_split(X,y,test_size=0.2)\ntestX, testy = mit_test_data.iloc[: , :-1], mit_test_data.iloc[: , -1]\ny = to_categorical(y)\ntesty = to_categorical(testy)\nvaly=to_categorical(valy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"X shape=\" +str(X.shape))\nprint(\"y shape=\" +str(y.shape))\nprint(\"valX shape=\" +str(valX.shape))\nprint(\"valy shape=\" +str(valy.shape))\nprint(\"testX shape=\" +str(testX.shape))\nprint(\"testy shape=\" +str(testy.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ann_model = Sequential()\nann_model.add(Dense(50, activation='relu', input_shape=(187,)))\nann_model.add(Dense(50, activation='relu'))\nann_model.add(Dense(50, activation='relu'))\nann_model.add(Dense(50, activation='relu'))\nann_model.add(Dense(5, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ann_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ann_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(ann_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ann_model_history = ann_model.fit(X, y,validation_data=(valX, valy), epochs=20)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(ann_model_history.history['accuracy'])\nplt.plot(ann_model_history.history['val_accuracy'])\nplt.legend([\"accuracy\",\"val_accuracy\"])\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(ann_model_history.history['loss'])\nplt.plot(ann_model_history.history['val_loss'])\nplt.legend([\"loss\",\"val_loss\"])\nplt.xlabel('Epoch')\nplt.ylabel('Loss')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_true=[]\nfor element in testy:\n    y_true.append(np.argmax(element))\nprediction_proba=ann_model.predict(testX)\nprediction=np.argmax(prediction_proba,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ann_model_cf_matrix = confusion_matrix(y_true, prediction)\nsns.heatmap(ann_model_cf_matrix/np.sum(ann_model_cf_matrix), annot=True,fmt='.3%', cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CNN"},{"metadata":{},"cell_type":"markdown","source":"# LENET-5"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils import shuffle\nmit_train_data[187] = mit_train_data[187].astype('int32')\nmit_test_data[187] = mit_test_data[187].astype('int32')\nX_train = np.array(mit_train_data.iloc[:, :187])\nX_test = np.array(mit_test_data.iloc[:, :187])\ny_train = np.array(mit_train_data[187])\ny_test = np.array(mit_test_data[187])\nX_train, y_train = shuffle(X_train, y_train, random_state = 101)\nX_test, y_test = shuffle(X_test, y_test, random_state = 101)\nX_train = np.expand_dims(X_train, 2)\nX_test = np.expand_dims(X_test, 2)\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lenet_5_model=Sequential()\n\nlenet_5_model.add(Conv1D(filters=6, kernel_size=3, padding='same', activation='relu', input_shape=(187,1)))\nlenet_5_model.add(BatchNormalization())\nlenet_5_model.add(MaxPool1D(pool_size=2, strides=2, padding='same'))\n\nlenet_5_model.add(Conv1D(filters=16, strides=1, kernel_size=5, activation='relu'))\nlenet_5_model.add(BatchNormalization())\nlenet_5_model.add(MaxPool1D(pool_size=2, strides=2, padding='same'))\n\nlenet_5_model.add(Flatten())\n\nlenet_5_model.add(Dense(64, activation='relu'))\n\nlenet_5_model.add(Dense(32, activation='relu'))\n\nlenet_5_model.add(Dense(5, activation = 'softmax'))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lenet_5_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(lenet_5_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lenet_5_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lenet_5_model_history = lenet_5_model.fit(X_train, y_train, epochs = 20, batch_size = 100, validation_data = (X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(lenet_5_model_history.history['accuracy'])\nplt.plot(lenet_5_model_history.history['val_accuracy'])\nplt.legend([\"accuracy\",\"val_accuracy\"])\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(lenet_5_model_history.history['loss'])\nplt.plot(lenet_5_model_history.history['val_loss'])\nplt.legend([\"loss\",\"val_loss\"])\nplt.xlabel('Epoch')\nplt.ylabel('Loss')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_true=[]\nfor element in y_test:\n    y_true.append(np.argmax(element))\nprediction_proba=lenet_5_model.predict(X_test)\nprediction=np.argmax(prediction_proba,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lenet_5_model_cf_matrix = confusion_matrix(y_true, prediction)\nsns.heatmap(lenet_5_model_cf_matrix/np.sum(lenet_5_model_cf_matrix), annot=True,fmt='.3%', cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# AlexNet"},{"metadata":{"trusted":true},"cell_type":"code","source":"alexNet_model=Sequential()\n\nalexNet_model.add(Conv1D(filters=96, activation='relu', kernel_size=11, strides=4, input_shape=(187,1)))\nalexNet_model.add(BatchNormalization())\nalexNet_model.add(MaxPool1D(pool_size=2, strides=2, padding='same'))\n\nalexNet_model.add(Conv1D(filters=256, kernel_size=5, padding='same', activation='relu'))\nalexNet_model.add(BatchNormalization())\nalexNet_model.add(MaxPool1D(pool_size=2, strides=2, padding='same'))\n\nalexNet_model.add(Conv1D(filters=384, padding='same', kernel_size=3, activation='relu'))\nalexNet_model.add(Conv1D(filters=384, kernel_size=3, activation='relu'))\nalexNet_model.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\nalexNet_model.add(BatchNormalization())\nalexNet_model.add(MaxPool1D(pool_size=2, strides=2, padding='same'))\n\nalexNet_model.add(Flatten())\nalexNet_model.add(Dense(4096, activation='relu'))\nalexNet_model.add(Dropout(0.4))\nalexNet_model.add(Dense(4096, activation='relu'))\nalexNet_model.add(Dropout(0.4))\nalexNet_model.add(Dense(5, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"alexNet_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(alexNet_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"alexNet_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"alexNet_model_history = alexNet_model.fit(X_train, y_train, epochs = 20, batch_size = 100, validation_data = (X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(alexNet_model_history.history['accuracy'])\nplt.plot(alexNet_model_history.history['val_accuracy'])\nplt.legend([\"accuracy\",\"val_accuracy\"])\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(alexNet_model_history.history['loss'])\nplt.plot(alexNet_model_history.history['val_loss'])\nplt.legend([\"loss\",\"val_loss\"])\nplt.xlabel('Epoch')\nplt.ylabel('Loss')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_true=[]\nfor element in y_test:\n    y_true.append(np.argmax(element))\nprediction_proba=alexNet_model.predict(X_test)\nprediction=np.argmax(prediction_proba,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"alexNet_model_cf_matrix = confusion_matrix(y_true, prediction)\nsns.heatmap(alexNet_model_cf_matrix/np.sum(alexNet_model_cf_matrix), annot=True,fmt='.3%', cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# VGG-16"},{"metadata":{"trusted":true},"cell_type":"code","source":"vgg_16_model=Sequential()\n\nvgg_16_model.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='relu',  input_shape=(187,1)))\nvgg_16_model.add(BatchNormalization())\nvgg_16_model.add(Conv1D(filters=64, kernel_size=3, activation='relu', padding='same'))\nvgg_16_model.add(BatchNormalization())\nvgg_16_model.add(MaxPool1D(pool_size=2, strides=2, padding='same'))\n\nvgg_16_model.add(Conv1D(filters=128, kernel_size=3, activation='relu', padding='same'))\nvgg_16_model.add(BatchNormalization())\nvgg_16_model.add(Conv1D(filters=128, kernel_size=3, activation='relu', padding='same'))\nvgg_16_model.add(BatchNormalization())\nvgg_16_model.add(MaxPool1D(pool_size=2, strides=2, padding='same'))\n\nvgg_16_model.add(Conv1D(filters=256, kernel_size=3, activation='relu', padding='same'))\nvgg_16_model.add(BatchNormalization())\nvgg_16_model.add(Conv1D(filters=256, kernel_size=3, activation='relu', padding='same'))\nvgg_16_model.add(BatchNormalization())\nvgg_16_model.add(Conv1D(filters=256, kernel_size=3, activation='relu', padding='same'))\nvgg_16_model.add(BatchNormalization())\nvgg_16_model.add(MaxPool1D(pool_size=2, strides=2, padding='same'))\n\nvgg_16_model.add(Conv1D(filters=512, kernel_size=3, activation='relu', padding='same'))\nvgg_16_model.add(BatchNormalization())\nvgg_16_model.add(Conv1D(filters=512, kernel_size=3, activation='relu', padding='same'))\nvgg_16_model.add(BatchNormalization())\nvgg_16_model.add(Conv1D(filters=512, kernel_size=3, activation='relu', padding='same'))\nvgg_16_model.add(BatchNormalization())\nvgg_16_model.add(MaxPool1D(pool_size=2, strides=2, padding='same'))\n\nvgg_16_model.add(Conv1D(filters=512, kernel_size=3, activation='relu', padding='same'))\nvgg_16_model.add(BatchNormalization())\nvgg_16_model.add(Conv1D(filters=512, kernel_size=1, activation='relu', padding='same'))\nvgg_16_model.add(BatchNormalization())\nvgg_16_model.add(Conv1D(filters=512, kernel_size=1, activation='relu', padding='same'))\nvgg_16_model.add(BatchNormalization())\nvgg_16_model.add(MaxPool1D(pool_size=2, strides=2, padding='same'))\n\nvgg_16_model.add(Flatten())\nvgg_16_model.add(Dense(4096, activation='relu'))\nvgg_16_model.add(Dropout(0.4))\nvgg_16_model.add(Dense(4096, activation='relu'))\nvgg_16_model.add(Dropout(0.4))\nvgg_16_model.add(Dense(5, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vgg_16_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(vgg_16_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vgg_16_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vgg_16_model_history = vgg_16_model.fit(X_train, y_train, epochs = 20, batch_size = 100, validation_data = (X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(vgg_16_model_history.history['accuracy'])\nplt.plot(vgg_16_model_history.history['val_accuracy'])\nplt.legend([\"accuracy\",\"val_accuracy\"])\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(vgg_16_model_history.history['loss'])\nplt.plot(vgg_16_model_history.history['val_loss'])\nplt.legend([\"loss\",\"val_loss\"])\nplt.xlabel('Epoch')\nplt.ylabel('Loss')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_true=[]\nfor element in y_test:\n    y_true.append(np.argmax(element))\nprediction_proba=vgg_16_model.predict(X_test)\nprediction=np.argmax(prediction_proba,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vgg_16_model_cf_matrix = confusion_matrix(y_true, prediction)\nsns.heatmap(vgg_16_model_cf_matrix/np.sum(vgg_16_model_cf_matrix), annot=True,fmt='.3%', cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ResNet50"},{"metadata":{"trusted":true},"cell_type":"code","source":"def identity_block(X, f, filters):\n    F1, F2, F3 = filters\n    \n    X_shortcut = X\n    \n    X = Conv1D(filters = F1, kernel_size = 1, activation='relu', strides = 1, padding = 'valid')(X)\n    X = BatchNormalization()(X)\n    \n    X = Conv1D(filters = F2, kernel_size = f, activation='relu', strides = 1, padding = 'same')(X)\n    X = BatchNormalization()(X)\n\n    X = Conv1D(filters = F3, kernel_size = 1, activation='relu', strides = 1, padding = 'valid')(X)\n    X = BatchNormalization()(X)\n\n    X = Add()([X,X_shortcut])\n    X = Activation('relu')(X)\n    \n    return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convolutional_block(X, f, filters, s = 2):\n    F1, F2, F3 = filters\n    \n    X_shortcut = X\n\n    X = Conv1D(F1, 1, activation='relu', strides = s)(X)\n    X = BatchNormalization()(X)\n    \n    X = Conv1D(F2, f, activation='relu', strides = 1,padding = 'same')(X)\n    X = BatchNormalization()(X)\n\n    X = Conv1D(F3, 1, strides = 1)(X)\n    X = BatchNormalization()(X)\n\n    X_shortcut = Conv1D(F3, 1, strides = s)(X_shortcut)\n    X_shortcut = BatchNormalization()(X_shortcut)\n    \n    X = Add()([X,X_shortcut])\n    X = Activation('relu')(X)\n    \n    return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ResNet50(input_shape = (187,1)):\n    \n    X_input = Input(input_shape)\n\n    X = ZeroPadding1D(3)(X_input)\n    \n    X = Conv1D(64, 7, activation='relu', strides = 2)(X)\n    X = BatchNormalization()(X)\n    X = MaxPool1D(pool_size=2, strides=2, padding='same')(X)\n\n    X = convolutional_block(X, f = 3, filters = [64, 64, 256], s = 1)\n    X = identity_block(X, 3, [64, 64, 256])\n    X = identity_block(X, 3, [64, 64, 256])\n\n    X = convolutional_block(X, f = 3, filters = [128,128,512], s = 2)\n    X = identity_block(X, 3, [128,128,512])\n    X = identity_block(X, 3, [128,128,512])\n    X = identity_block(X, 3, [128,128,512])\n\n    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], s = 2)\n    X = identity_block(X, 3, [256, 256, 1024])\n    X = identity_block(X, 3, [256, 256, 1024])\n    X = identity_block(X, 3, [256, 256, 1024])\n    X = identity_block(X, 3, [256, 256, 1024])\n    X = identity_block(X, 3, [256, 256, 1024])\n\n    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], s = 2)\n    X = identity_block(X, 3, [512, 512, 2048])\n    X = identity_block(X, 3, [512, 512, 2048])\n\n    X = MaxPool1D(pool_size=2, strides=2, padding='same')(X)\n    \n    X = Flatten()(X)\n    X = Dense(5,activation='softmax')(X)\n    \n    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resNet50_model = ResNet50(input_shape = (187,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resNet50_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(resNet50_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resNet50_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resNet50_model_history = resNet50_model.fit(X_train, y_train, epochs = 20, batch_size = 100, validation_data = (X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(resNet50_model_history.history['accuracy'])\nplt.plot(resNet50_model_history.history['val_accuracy'])\nplt.legend([\"accuracy\",\"val_accuracy\"])\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(resNet50_model_history.history['loss'])\nplt.plot(resNet50_model_history.history['val_loss'])\nplt.legend([\"loss\",\"val_loss\"])\nplt.xlabel('Epoch')\nplt.ylabel('Loss')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_true=[]\nfor element in y_test:\n    y_true.append(np.argmax(element))\nprediction_proba=resNet50_model.predict(X_test)\nprediction=np.argmax(prediction_proba,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resNet50_model_cf_matrix = confusion_matrix(y_true, prediction)\nsns.heatmap(resNet50_model_cf_matrix/np.sum(resNet50_model_cf_matrix), annot=True,fmt='.3%', cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Inception"},{"metadata":{"trusted":true},"cell_type":"code","source":"def inception_block(prev_layer):\n    \n    conv1=Conv1D(filters = 64, kernel_size = 1, activation='relu', padding = 'same')(prev_layer)\n    \n    conv3=Conv1D(filters = 64, kernel_size = 1, activation='relu', padding = 'same')(prev_layer)\n    conv3=Conv1D(filters = 64, kernel_size = 3, activation='relu', padding = 'same')(conv3)\n    \n    conv5=Conv1D(filters = 64, kernel_size = 1, activation='relu', padding = 'same')(prev_layer)\n    conv5=Conv1D(filters = 64, kernel_size = 5, activation='relu', padding = 'same')(conv5)\n    \n    pool= MaxPool1D(pool_size=3, strides=1, padding='same')(prev_layer)\n    convmax=Conv1D(filters = 64, kernel_size = 1, activation='relu', padding = 'same')(pool)\n    \n    layer_out = concatenate([conv1, conv3, conv5, convmax], axis=1)\n    return layer_out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def inception_model(input_shape):\n    X_input=Input(input_shape)\n    \n    X = Conv1D(filters = 64, kernel_size = 7, activation='relu', padding = 'same')(X_input)\n    X = MaxPool1D(pool_size=3, strides=2, padding='same')(X)\n    \n    X = Conv1D(filters = 64, kernel_size = 1, activation='relu', padding = 'same')(X)\n    \n    X = inception_block(X)\n    X = inception_block(X)\n    X = inception_block(X)\n    X = inception_block(X)\n    \n    X = MaxPool1D(pool_size=7, strides=2, padding='same')(X)\n    \n    X = Flatten()(X)\n    X = Dense(5,activation='softmax')(X)\n    \n    model = Model(inputs = X_input, outputs = X, name='Inception')\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inception_model = inception_model(input_shape = (187,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inception_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(inception_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inception_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inception_model_history = inception_model.fit(X_train, y_train, epochs = 1, batch_size = 100, validation_data = (X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_true=[]\nfor element in y_test:\n    y_true.append(np.argmax(element))\nprediction_proba=inception_model.predict(X_test)\nprediction=np.argmax(prediction_proba,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inception_model_cf_matrix = confusion_matrix(y_true, prediction)\nsns.heatmap(inception_model_cf_matrix/np.sum(inception_model_cf_matrix), annot=True,fmt='.3%', cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# RNN"},{"metadata":{},"cell_type":"markdown","source":"# LSTM"},{"metadata":{"trusted":true},"cell_type":"code","source":"lstm_model = Sequential()\nlstm_model.add(LSTM(64, input_shape=(187,1)))\nlstm_model.add(Dense(128, activation = 'relu'))\nlstm_model.add(Dropout(0.3))\nlstm_model.add(Dense(5, activation = 'softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lstm_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(lstm_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lstm_model_history = lstm_model.fit(X_train, y_train, epochs = 20, batch_size = 100, validation_data = (X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(lstm_model_history.history['accuracy'])\nplt.plot(lstm_model_history.history['val_accuracy'])\nplt.legend([\"accuracy\",\"val_accuracy\"])\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(lstm_model_history.history['loss'])\nplt.plot(lstm_model_history.history['val_loss'])\nplt.legend([\"loss\",\"val_loss\"])\nplt.xlabel('Epoch')\nplt.ylabel('Loss')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_true=[]\nfor element in y_test:\n    y_true.append(np.argmax(element))\nprediction_proba=lstm_model.predict(X_test)\nprediction=np.argmax(prediction_proba,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lstm_model_cf_matrix = confusion_matrix(y_true, prediction)\nsns.heatmap(lstm_model_cf_matrix/np.sum(lstm_model_cf_matrix), annot=True,fmt='.3%', cmap='Blues')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}