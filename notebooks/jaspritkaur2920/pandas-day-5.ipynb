{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Pandas Tutorial : Day 5\nHere's is what we are going to learn today : \n* [Drop not-null data](#1)\n 1. [Drop columns](#2)\n 2. [Drop a row by index](#3)\n 3. [Drop columns and/or rows of MultiIndex DataFrame](#4)\n* [Drop null data](#5)\n 1. [Drop the rows where at least one element is missing](#6)\n 2. [Drop the columns where atleast one element is missing](#7)\n 3. [Drop the rows where all the elements are missing](#8)\n 4. [Keep only the rows with atleast 2 non-NA values](#9)\n 5. [Define in which columns to look for missing values](#10)\n 6. [Keep the DataFrame with valid entries in the same variable](#11)\n* [Convert data types](#12)\n 1. [Cast all the columns to one data type](#13)\n 2. [Cast single column to data type](#14)\n* [apply function](#15)\n 1. [Method 1](#16)\n 2. [Method 2](#17)\n\nLet's get started!\n\n[Data for daily news for stock market prediction](https://www.kaggle.com/aaron7sun/stocknews)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# import library\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport numpy as np\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import data\ndf = pd.read_csv('/kaggle/input/stocknews/upload_DJIA_table.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# look at the top 5 rows in the data\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Drop not-null Data<a id='1'></a>\nDrop specified labels from rows or columns.\n\nRemove rows or columns by specifying label names and corresponding axis, or by specifying directly index or column names. When using a multi-index, labels on different levels can be removed by specifying the level."},{"metadata":{},"cell_type":"markdown","source":"### 1. Drop columns<a id='2'></a>\nSyntax 1: `df.drop(['column_name1', 'column_name2', ...], axis = 1)`\n\nIf you permanently want to drop column use `inplace = true`. The default value of inplace is False\n\nSyntax 2 : `df.drop(columns = ['column_name1', 'column_name2', ...])`"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# let's drop date column by syntax 1\ndf.drop(['Date'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's drop open column by syntax 2\ndf.drop(columns = ['Open'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check for the condition if Dataframe\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Drop a row by index<a id='3'></a>\nSyntax : `df.drop(['index'])`"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop([0, 1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The first two rows are dropped."},{"metadata":{},"cell_type":"markdown","source":"### 3. Drop columns and/or rows of MultiIndex DataFrame<a id='4'></a>\nSyntax 1: `df.drop(index = 'first_index', columns = 'column_name')`\n\nSyntax 2 : `df.drop(index = 'second_index', level = 1)`"},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's make a multiIndex Dataframe\nmidx = pd.MultiIndex(levels=[['lama', 'cow', 'falcon'],\n                             ['speed', 'weight', 'length']],\n                     codes=[[0, 0, 0, 1, 1, 1, 2, 2, 2],\n                            [0, 1, 2, 0, 1, 2, 0, 1, 2]])\ndf1 = pd.DataFrame(index=midx, columns=['big', 'small'],\n                  data=[[45, 30], [200, 100], [1.5, 1], [30, 20],\n                        [250, 150], [1.5, 0.8], [320, 250],\n                        [1, 0.8], [0.3, 0.2]])\ndf1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to drop the whole 'cow' row and 'small' column\ndf1.drop(index='cow', columns='small')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to drop the subindex 'length'\ndf1.drop(index='length', level=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Drop null data<a id='5'></a>\nLet's see how to remove missing values from tha dataset. \n\n**Note :** We don't have any missing values in this dataset. Therefore we'll use our own data that has missing values."},{"metadata":{"trusted":true},"cell_type":"code","source":"df2 = pd.DataFrame({\"name\": ['Alfred', 'Batman', 'Catwoman'],\n                   \"toy\": [np.nan, 'Batmobile', 'Bullwhip'],\n                   \"born\": [pd.NaT, \"1940-04-25\",\n                            pd.NaT]})\ndf2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1. Drop the rows where at least one element is missing<a id='6'></a>\nSyntax : `df.dropna()`"},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.dropna()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Drop the columns where atleast one element is missing<a id='7'></a>\nSyntax : `df.dropna(axis = 'columns')`"},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.dropna(axis = 'columns')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. Drop the rows where all the elements are missing<a id='8'></a>\nSyntax : `df.dropna(how = 'all')`"},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.dropna(how = 'all')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4. Keep only the rows with atleast 2 non-NA values<a id='9'></a>\nSyntax : `df.dropna(thresh = 2)`"},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.dropna(thresh = 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5. Define in which columns to look for missing values<a id='10'></a>\nSyntax : `df.dropna(subset = ['column_name'])`"},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.dropna(subset=['name', 'born'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 6. Keep the DataFrame with valid entries in the same variable<a id='11'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.dropna(inplace = True)\ndf2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Convert Data types<a id='12'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's see the datatype of each column\ndf.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1. Cast all the columns to one data type<a id='13'></a>\nSyntax : `df.astype('data_type').dtypes`"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {'col1': [1, 2], 'col2': [3, 4]}\ndf3 = pd.DataFrame(data=d)\ndf3.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df3.astype('int32').dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Cast single column to data type<a id='14'></a>\nSyntax : `df.astype({'column_name' : 'datatype'}).dtypes`"},{"metadata":{"trusted":true},"cell_type":"code","source":"df3.astype({'col1': 'float'}).dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Apply Function<a id='15'></a>\nPandas.apply allow the users to pass a function and apply it on every single value of the Pandas series. It comes as a huge improvement for the pandas library as this function helps to segregate data according to the conditions required due to which it is efficiently used in data science and machine learning.\n\nSyntax : `s.apply(func, convert_dtype=True, args=())`\n\nParameters:\n\n* **func:** .apply takes a function and applies it to all values of pandas series.\n* **convert_dtype:** Convert dtype as per the functionâ€™s operation.\n* **args=():** Additional arguments to pass to function instead of series.\n* **Return Type:** Pandas Series after applied function/operation."},{"metadata":{},"cell_type":"markdown","source":"### Method 1<a id='16'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def method1(x):\n    return x * 2\ndf.Open.apply(method1).head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Method 2<a id='17'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Open.apply(lambda x : x * 2).head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Yeahhhh!!! Here we finish our tutorial in pandas! So far we have learnt many things. So keep practicing guys! "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}