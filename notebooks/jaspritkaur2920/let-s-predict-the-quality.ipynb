{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Let's check your red wine quality...\nWe have given various features (like fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates, alcohol) which will help us in predicting the quality of wine.\n\n<img src = \"https://www.calaiswine.co.uk/wp/wp-content/uploads/2015/12/wine-gif-2.gif\" width=500px >"},{"metadata":{},"cell_type":"markdown","source":"**Problem Statement : ** Predicting red wine quality using various features of red wine.\n\n**Solution to the problem : **\n\n1. [Import Libraries](#1)\n2. [Load Data](#2)\n    * [Checking the information about each data column](#3)     \n3. [Data Visualuzation](#4)\n    * [Barplot between `quality` and `fixed acidity`](#5)\n    * [Barplot between `quality` and `volatile acidity`](#6)\n    * [Barpolt between `quality` and `citric acid`](#7)\n    * [Barplot between `quality` and `residual sugar`](#8)\n    * [Barplot between `quality` and `chlorides`](#9)\n    * [Barplot between `quality` and `free sulfur dioxide`](#10)\n    * [Barplot between `quality` and `total sulfur dioxide`](#11)\n    * [Barplot between `quality` and `sulphates`](#12)\n    * [Barplot between `quality` and `alcohol`](#13)\n    * [Conclusion by visualization](#14)\n4. [Data Preprocessing](#15)\n    * [Creating new column `review`](#16)\n    * [Checking unique values for column `review`](#17)\n    * [Scaling the data using StandardScaler for PCA](#18)\n    * [Viewing the data using StandardScaler](#19)\n    * [Proceed to perform PCA](#20)\n    * [Ploting the graph to find the principal components](#21)\n5. [Splitting data into Train and Test](#22)\n    * [Checking for shape of splitted data](#23)\n6. [Data Modelling](#24)\n    * [Logistic Regression](#25)\n    * [Decision Trees](#26)\n    * [Naive Bayes](#27)\n    * [Random Forests](#28)\n    * [SVM](#29) \n    * [Accuracy for different algorithms](#30)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"## 1. Import Libraries<a id=\"1\"></a>"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Load Data <a id=\"2\"></a>"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"wine = pd.read_csv(\"../input/red-wine-quality-cortez-et-al-2009/winequality-red.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's check how the data is distributed\nwine.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Checking the information about each data column<a id=\"3\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"wine.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Data Visualization<a id=\"4\"></a>\nNow, I am going to visualize this data to see how the data is distributed."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='quality',data=wine)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Barplot between `quality` and `fixed acidity`<a id=\"5\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (10,6))\nsns.barplot(x='quality', y='fixed acidity', data=wine)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here, we see that `fixed acidity` does not give any specification to classify the `quality`."},{"metadata":{},"cell_type":"markdown","source":"### Barplot between `quality` and `volatile acidity`<a id=\"6\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (10,6))\nsns.barplot(x='quality', y='volatile acidity', data=wine)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here, we see that it's quite a downing trend in the `volatile acidity` as we go higher the `quality`."},{"metadata":{},"cell_type":"markdown","source":"### Barpolt between `quality` and `citric acid`<a id=\"7\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (10,6))\nsns.barplot(x='quality', y='citric acid', data=wine)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here, we see the increasing trend of `citric acid`. That is, as we go higher in `quality` of wine the composition of `citric acid` in wine also increases."},{"metadata":{},"cell_type":"markdown","source":"### Barplot between `quality` and `residual sugar`<a id=\"8\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (10,6))\nsns.barplot(x='quality', y='residual sugar', data=wine)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Well, there is no significant effect of `residual sugar` on `quality` of wine."},{"metadata":{},"cell_type":"markdown","source":"### Barplot between `quality` and `chlorides`<a id=\"9\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (10,6))\nsns.barplot(x='quality', y='chlorides', data=wine)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here, we see the decreasing trend of `chlorides` with the increase in the `quality` of wine."},{"metadata":{},"cell_type":"markdown","source":"### Barplot between `quality` and `free sulfur dioxide`<a id=\"10\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (10,6))\nsns.barplot(x='quality', y='free sulfur dioxide', data=wine)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Barplot between `quality` and `total sulfur dioxide`<a id=\"11\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (10,6))\nsns.barplot(x='quality', y='total sulfur dioxide', data=wine)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Both the `free sulphur dioxide` and `total sulphur dioxide` are comparatively more in the 5th and 6th `quality` wine."},{"metadata":{},"cell_type":"markdown","source":"### Barplot between `quality` and `sulphates`<a id=\"12\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (10,6))\nsns.barplot(x='quality', y='sulphates', data=wine)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ohh yeah, here we the the increasing trend of `sulphates` as we go higher in `quality` of wine."},{"metadata":{},"cell_type":"markdown","source":"### Barplot between `quality` and `alcohol`<a id=\"13\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (10,6))\nsns.barplot(x='quality', y='alcohol', data=wine)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here, is also a increasing trend found between `quality` and `alcohol`."},{"metadata":{},"cell_type":"markdown","source":"### Overall conclusion by examining data.<a id=\"14\"></a>\nSome features have great impact on `quality` of wine and some does not have any sigificant effect in the `quality`.\n\n**Trends**\n1. fixed acidity : No significant effect\n2. volatile acidity : Decreasing\n3. citric acid : Increasing\n4. residual sugar : No significant effect\n5. chlorides : Decreasing\n6. free sulphur dioxide : No significant effect\n7. total sulphur dioxide : No significant effect\n8. sulphates : Increasing\n9. alcohol : Increasing"},{"metadata":{},"cell_type":"markdown","source":"## 4. Data Preprocessing<a id=\"15\"></a>"},{"metadata":{},"cell_type":"markdown","source":"### Creating new column `review`<a id=\"16\"></a>"},{"metadata":{},"cell_type":"markdown","source":">Now, we will create a new column called review. This column will contain the values of 1, 2 and 3 and will be split in the following way.\n* review ==> quality ==> meaning\n* 1 ==> 1, 2, 3 ==>Bad\n* 2 ==> 4, 5, 6, 7 ==> Average\n* 3 ==> 8, 9, 10 ==> Excellent"},{"metadata":{"trusted":true},"cell_type":"code","source":"reviews = []\nfor i in wine['quality']:\n    if i >= 1 and i <= 3:\n        reviews.append('1')\n    elif i >= 4 and i <= 7:\n        reviews.append('2')\n    elif i >= 8 and i <= 10:\n        reviews.append('3')\nwine['Reviews'] = reviews","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wine.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Checking unique values for column `review`<a id=\"17\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"wine['Reviews'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Counter(wine['Reviews'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = wine.iloc[:,:11]\ny = wine['Reviews']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Scaling the data using StandardScaler for PCA<a id=\"18\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX = sc.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Viewing the data using StandardScaler<a id=\"19\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Proceed to perform PCA<a id=\"20\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\npca = PCA()\nX_pca = pca.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Ploting the graph to find the principal components<a id=\"21\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(5,5))\nplt.plot(np.cumsum(pca.explained_variance_ratio_), 'ro-')\nplt.grid()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#As per the graph, we can see that 8 principal components attribute for 90% of variation in the data. \n#we shall pick the first 8 components for our prediction.\npca_new = PCA(n_components=8)\nX_new = pca_new.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_new)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. Splitting the dataset into train and test data.<a id=\"22\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.25)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Checking for shape of splitted data<a id=\"23\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6. Data Modelling<a id=\"24\"></a>\nWe will use the following algorithms ==>\n1. Logistic Regression\n2. Decision Trees\n3. Naive Bayes\n4. Random Forests\n5. SVM"},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression<a id=\"25\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nlr = LogisticRegression()\nlr.fit(X_train, y_train)\nlr_predict = lr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print confusion matrix and accuracy score\nlr_confusion_matrix = confusion_matrix(y_test, lr_predict)\nlr_accuracy_score = accuracy_score(y_test, lr_predict)\nprint(lr_confusion_matrix)\nprint(lr_accuracy_score*100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"98.5% accuracy with Logistic Regression! Let's see of Decision Trees give us a better accuracy."},{"metadata":{},"cell_type":"markdown","source":"### Decision Tree<a id=\"26\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier()\ndt.fit(X_train,y_train)\ndt_predict = dt.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print confusion matrix and accuracy score\ndt_confusion_matrix = confusion_matrix(y_test, dt_predict)\ndt_accuracy_score = accuracy_score(y_test, dt_predict)\nprint(dt_confusion_matrix)\nprint(dt_accuracy_score*100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"97% accuracy with Decision Tree! Let's use NaiveBayes"},{"metadata":{},"cell_type":"markdown","source":"### Naive Bayes<a id=\"27\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb.fit(X_train, y_train)\nnb_predict = nb.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print confusion matrix and accuracy score\nnb_confusion_matrix = confusion_matrix(y_test, nb_predict)\nnb_accuracy_score = accuracy_score(y_test, nb_predict)\nprint(nb_confusion_matrix)\nprint(nb_accuracy_score*100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"97.75% accuracy with Naive Bayes."},{"metadata":{},"cell_type":"markdown","source":"### Random Forest Classifier<a id=\"28\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier()\nrf.fit(X_train, y_train)\nrf_predict = rf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print confusion matrix and accuracy score\nrf_confusion_matrix = confusion_matrix(y_test, rf_predict)\nrf_accuracy_score = accuracy_score(y_test, rf_predict)\nprint(rf_confusion_matrix)\nprint(rf_accuracy_score*100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"98.25% accuracy with Random forest."},{"metadata":{},"cell_type":"markdown","source":"### Support Vector Machine (SVM)<a id=\"29\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nsvc = SVC()\nsvc.fit(X_train, y_train)\nsvc_predict = svc.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print confusion matrix and accuracy score\nsvc_confusion_matrix = confusion_matrix(y_test, rf_predict)\nsvc_accuracy_score = accuracy_score(y_test, rf_predict)\nprint(svc_confusion_matrix)\nprint(svc_accuracy_score*100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Accuracy for different algorithms:<a id=\"30\"></a>\n\n* Logistic Regression = 98.5% accuracy  \n* Decision Trees = 97% accuracy\n* Naive Bayes = 97.75% accuracy\n* Random Forest = 98.25% accuracy\n* SVM = 98.25% accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"wine1 = [[7.8, 0.760, 0.04, 2.3, 0.092, 15.0, 54.0, 0.99700]]\nprint(\"Decision Tree : \",dt.predict(wine1))\nprint(\"Logistic Regression : \",lr.predict(wine1))\nprint(\"Naive Bayes : \",nb.predict(wine1))\nprint(\"Random forest : \",rf.predict(wine1))\nprint(\"SVM : \",svc.predict(wine1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Well, Naive Bayes did wrong prediction! Therefore, in this way we can predict the quality of red wine using **Logistic regression** because it gives highest accuracy."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}