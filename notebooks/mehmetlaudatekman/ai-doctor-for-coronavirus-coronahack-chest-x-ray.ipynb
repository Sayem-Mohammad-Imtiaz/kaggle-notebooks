{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\nHey,community! It's been a lot since I've written my last kernel and I've missed to write kernels in Kaggle a lot.  Before starting, I want to share my excitement, in all of those science fiction books and movies, we've been seeing the effects of artifical intelligince to our health. Some robots and AIs were detecting problems and creating solutions. And now we're living that age, we can determine coronavirus using chest x-rays and artifical intelligince.\n\nIn this kernel I'm going to show you how to create a image classifier from scratch using Pytorch and how to train it as well.\n\n# Table of Content\n1. Preparing Dataset\n1. Creating Model Architecture\n1. Training Model\n1. Checking Results\n1. Conclusion","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"# Basic data manipulations\nimport pandas as pd\nimport numpy as np\n\n# Handling images\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\n# Handling paths\nfrom glob import glob\n\nimport time\n\n# Pytorch essentials\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\n\n# Pytorch essentials for datasets.\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\n\n# Pytorch way of data augmentation.\nimport torchvision\nimport torchvision.transforms as trfs","metadata":{"execution":{"iopub.status.busy":"2021-06-22T09:36:35.572074Z","iopub.execute_input":"2021-06-22T09:36:35.572525Z","iopub.status.idle":"2021-06-22T09:36:35.579784Z","shell.execute_reply.started":"2021-06-22T09:36:35.572491Z","shell.execute_reply":"2021-06-22T09:36:35.578613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preparing Dataset\nIn this section we're gonna prepare our dataset, we'll create a class inherited by Dataset class of Pytorch. Also we'll create a sampler and combine them in a data loader.\n\nBut first, let's check our metadata.","metadata":{}},{"cell_type":"code","source":"meta_data = pd.read_csv('../input/coronahack-chest-xraydataset/Chest_xray_Corona_Metadata.csv')\nmeta_data.drop(\"Unnamed: 0\",axis=1,inplace=True)\nmeta_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-22T09:36:35.610521Z","iopub.execute_input":"2021-06-22T09:36:35.61089Z","iopub.status.idle":"2021-06-22T09:36:35.645356Z","shell.execute_reply.started":"2021-06-22T09:36:35.610857Z","shell.execute_reply":"2021-06-22T09:36:35.643946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Now let's create our data class.","metadata":{}},{"cell_type":"code","source":"class CoronaHackDataset(Dataset):\n    \n    def __init__(self,image_paths,image_labels,image_size,transforms_):\n        self.image_paths = image_paths\n        self.image_labels = image_labels\n        self.image_size = image_size\n        \n        # We'll use transforms for data augmentation and converting PIL images to torch tensors.\n        self.transforms_ = transforms_\n        \n    def __len__(self):\n        return len(self.meta_data)\n    \n    def __getitem__(self,index):\n        img = Image.open(self.image_paths[index]).resize(self.image_size).convert(\"LA\")\n        transformed_img = self.transforms_(img)\n        return transformed_img,self.image_labels[index]\n        ","metadata":{"execution":{"iopub.status.busy":"2021-06-22T09:36:35.648102Z","iopub.execute_input":"2021-06-22T09:36:35.648615Z","iopub.status.idle":"2021-06-22T09:36:35.658101Z","shell.execute_reply.started":"2021-06-22T09:36:35.64857Z","shell.execute_reply":"2021-06-22T09:36:35.65638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* As you can see we need paths to make this class usefull. Now we'll concatenate paths and get labels.","metadata":{}},{"cell_type":"code","source":"TRAIN_IMAGE_FOLDER_PATH = \"../input/coronahack-chest-xraydataset/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/train/\"\nTEST_IMAGE_FOLDER_PATH = \"../input/coronahack-chest-xraydataset/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/test/\"\n\ntrain_image_paths = [TRAIN_IMAGE_FOLDER_PATH+meta_data.iloc[i][\"X_ray_image_name\"] for i in range(len(meta_data)) if meta_data.iloc[i][\"Dataset_type\"] == \"TRAIN\"]\ntest_image_paths = [TEST_IMAGE_FOLDER_PATH+meta_data.iloc[i][\"X_ray_image_name\"] for i in range(len(meta_data)) if meta_data.iloc[i][\"Dataset_type\"] == \"TEST\"]","metadata":{"execution":{"iopub.status.busy":"2021-06-22T09:36:35.661752Z","iopub.execute_input":"2021-06-22T09:36:35.662304Z","iopub.status.idle":"2021-06-22T09:36:37.596866Z","shell.execute_reply.started":"2021-06-22T09:36:35.662227Z","shell.execute_reply":"2021-06-22T09:36:37.595673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* And now let's check an image per set by showing them.","metadata":{}},{"cell_type":"code","source":"plt.imshow(Image.open(train_image_paths[0]))\nplt.axis(\"off\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-22T09:36:37.599944Z","iopub.execute_input":"2021-06-22T09:36:37.600386Z","iopub.status.idle":"2021-06-22T09:36:37.858434Z","shell.execute_reply.started":"2021-06-22T09:36:37.600343Z","shell.execute_reply":"2021-06-22T09:36:37.857192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(Image.open(test_image_paths[0]))\nplt.axis(\"off\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-22T09:36:37.860207Z","iopub.execute_input":"2021-06-22T09:36:37.860874Z","iopub.status.idle":"2021-06-22T09:36:38.375468Z","shell.execute_reply.started":"2021-06-22T09:36:37.860831Z","shell.execute_reply":"2021-06-22T09:36:38.373903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Alright, now let's get our labels, but before getting them we'll encode them.","metadata":{}},{"cell_type":"code","source":"np.unique(meta_data[\"Label\"])","metadata":{"execution":{"iopub.status.busy":"2021-06-22T09:36:38.377983Z","iopub.execute_input":"2021-06-22T09:36:38.378597Z","iopub.status.idle":"2021-06-22T09:36:38.393074Z","shell.execute_reply.started":"2021-06-22T09:36:38.378551Z","shell.execute_reply":"2021-06-22T09:36:38.391581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# I know, those comprehensions are kind of annoying if you're a new in Python, it simply checks data whether it's in train set\n# If it's in train set and label is Normal it appends a 0, else it appends a 1\ntrain_labels = [0 if meta_data.iloc[i][\"Label\"] == \"Normal\" else 0 for i in range(len(meta_data)) if meta_data.iloc[i][\"Dataset_type\"] == \"TRAIN\"]\n\ntest_labels = [0 if meta_data.iloc[i][\"Label\"] == \"Normal\" else 0 for i in range(len(meta_data)) if meta_data.iloc[i][\"Dataset_type\"] == \"TEST\"]","metadata":{"execution":{"iopub.status.busy":"2021-06-22T09:36:38.399098Z","iopub.execute_input":"2021-06-22T09:36:38.399528Z","iopub.status.idle":"2021-06-22T09:36:40.354902Z","shell.execute_reply.started":"2021-06-22T09:36:38.399495Z","shell.execute_reply":"2021-06-22T09:36:40.353757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Even though there are specified test and train set, now I'll concatenate them and recreate those sets.","metadata":{}},{"cell_type":"code","source":"image_paths = train_image_paths + test_image_paths\nimage_labels = train_labels + test_labels\n\nprint(\"Number of image paths\",len(image_paths))\nprint(\"Number of image labels\",len(image_labels))\n","metadata":{"execution":{"iopub.status.busy":"2021-06-22T09:36:40.357119Z","iopub.execute_input":"2021-06-22T09:36:40.357549Z","iopub.status.idle":"2021-06-22T09:36:40.365813Z","shell.execute_reply.started":"2021-06-22T09:36:40.357506Z","shell.execute_reply":"2021-06-22T09:36:40.36354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* It seems okay, now we'll split images indices as train and test set.\n\nSuch as index \"0\" might be the part of train set, and \"32\" might be the part of test set.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_indices,test_indices = train_test_split(list(range(len(image_paths))),test_size=0.25,random_state=42)\n\nprint(\"Number of train samples\",len(train_indices))\nprint(\"Number of test samples\",len(test_indices))","metadata":{"execution":{"iopub.status.busy":"2021-06-22T09:36:40.368559Z","iopub.execute_input":"2021-06-22T09:36:40.369123Z","iopub.status.idle":"2021-06-22T09:36:40.389422Z","shell.execute_reply.started":"2021-06-22T09:36:40.369076Z","shell.execute_reply":"2021-06-22T09:36:40.387032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_indices[:5]","metadata":{"execution":{"iopub.status.busy":"2021-06-22T09:36:40.393424Z","iopub.execute_input":"2021-06-22T09:36:40.393897Z","iopub.status.idle":"2021-06-22T09:36:40.402142Z","shell.execute_reply.started":"2021-06-22T09:36:40.393852Z","shell.execute_reply":"2021-06-22T09:36:40.400328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Images in those indices will be in train set.\n* Our train and test indices, image paths and labels are determined. We're ready to create our sampler.\n\n**Briefly, data sampler will sample random data from the indices given.**","metadata":{}},{"cell_type":"code","source":"train_sampler = SubsetRandomSampler(train_indices)\ntest_sampler = SubsetRandomSampler(test_indices)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T09:36:40.404525Z","iopub.execute_input":"2021-06-22T09:36:40.405111Z","iopub.status.idle":"2021-06-22T09:36:40.411783Z","shell.execute_reply.started":"2021-06-22T09:36:40.405064Z","shell.execute_reply":"2021-06-22T09:36:40.41039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* And now we're gonna combine our sampler and dataset class in a data loader.\n\nI want to explain it more detailed. Data loader will iterate the data we use in training and testing.\n\nFirst, it'll get random indices from **data sampler**, then it'll send those indices to the **dataset class** and get images,labels. Then it'll return them and we use them :)","metadata":{}},{"cell_type":"code","source":"# You can find all transforms in:\n# https://pytorch.org/vision/stable/transforms.html\n\ntransforms_ = trfs.Compose([\n    # This will make PIL Images Pytorch tensors.\n    trfs.ToTensor(),\n    trfs.RandomHorizontalFlip(),\n    trfs.RandomVerticalFlip()\n])\n","metadata":{"execution":{"iopub.status.busy":"2021-06-22T09:36:40.414074Z","iopub.execute_input":"2021-06-22T09:36:40.414645Z","iopub.status.idle":"2021-06-22T09:36:40.423472Z","shell.execute_reply.started":"2021-06-22T09:36:40.414598Z","shell.execute_reply":"2021-06-22T09:36:40.421963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = CoronaHackDataset(image_paths,image_labels,(224,224),transforms_)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T09:36:40.425766Z","iopub.execute_input":"2021-06-22T09:36:40.426348Z","iopub.status.idle":"2021-06-22T09:36:40.434799Z","shell.execute_reply.started":"2021-06-22T09:36:40.426302Z","shell.execute_reply":"2021-06-22T09:36:40.43337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# In each iteration there will be 128 images.\nBATCH_SIZE = 128\n\ntrain_loader = DataLoader(dataset, batch_size=BATCH_SIZE, \n                                           sampler=train_sampler)\ntest_loader = DataLoader(dataset, batch_size=BATCH_SIZE,\n                                                sampler=test_sampler)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T09:36:40.437313Z","iopub.execute_input":"2021-06-22T09:36:40.438001Z","iopub.status.idle":"2021-06-22T09:36:40.446152Z","shell.execute_reply.started":"2021-06-22T09:36:40.437955Z","shell.execute_reply":"2021-06-22T09:36:40.444848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Ahoyy, our data is ready to use, now we can start to build our deep learning model using nn module of Pytorch.","metadata":{}},{"cell_type":"markdown","source":"# Creating Model Architecture\nIn this section we're gonna create our model architecture. In Pytorch, things are generally based on **Object Oriented Programming**, so we generally create classes and use objects. \n\nNow we'll create our model class which is inherited by nn.Module class.","metadata":{}},{"cell_type":"code","source":"class NetworkCNN(nn.Module):\n    \n    def __init__(self):\n        super(NetworkCNN,self).__init__()\n        \"\"\"\n        We've defined our layers as attributes here.\n        \"\"\"\n        self.conv1 = nn.Conv2d(2,32,kernel_size=3,stride=2,padding=1)\n        self.conv2 = nn.Conv2d(32,128,kernel_size=3,stride=2,padding=1)\n        self.batch_norm1= nn.BatchNorm2d(128)\n        \n        self.conv3 = nn.Conv2d(128,256,kernel_size=3,stride=2,padding=1)\n        self.conv4 = nn.Conv2d(256,512,kernel_size=3,stride=2,padding=1)\n        self.batch_norm2 = nn.BatchNorm2d(512)\n        \n        self.max_pool = nn.MaxPool2d(2,2)\n        self.fc1 = nn.Linear(512 * 3 * 3,2)\n        \n    def forward(self,x):\n        \"\"\"\n        When we send values to the model, this function will work.\n        \"\"\"\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = self.batch_norm1(x)\n        x = self.max_pool(x)\n        \n        x = F.relu(self.conv3(x))\n        x = F.relu(self.conv4(x))\n        x = self.batch_norm2(x)\n        x = self.max_pool(x)\n        \n        # Flattening | layer.Flatten() equal of Keras.\n        x = x.view(-1, 512 * 3 * 3)\n        x = self.fc1(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2021-06-22T09:36:40.448631Z","iopub.execute_input":"2021-06-22T09:36:40.44918Z","iopub.status.idle":"2021-06-22T09:36:40.465091Z","shell.execute_reply.started":"2021-06-22T09:36:40.4491Z","shell.execute_reply":"2021-06-22T09:36:40.463964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* And yeah, our model class is ready, but we still need to define some objects ","metadata":{}},{"cell_type":"code","source":"# We'll use GPU on training so\ndevice = torch.device(\"cuda\" if torch.cuda.is_available else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2021-06-22T09:36:40.46734Z","iopub.execute_input":"2021-06-22T09:36:40.468111Z","iopub.status.idle":"2021-06-22T09:36:40.483907Z","shell.execute_reply.started":"2021-06-22T09:36:40.468064Z","shell.execute_reply":"2021-06-22T09:36:40.482461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = NetworkCNN().to(device)\n\n# Loss function\ncriterion = nn.CrossEntropyLoss()\n\n# Optimizer which will use gradients to train model.\noptimizer = optim.RMSprop(model.parameters(),lr=1e-3)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T09:36:40.485763Z","iopub.execute_input":"2021-06-22T09:36:40.48624Z","iopub.status.idle":"2021-06-22T09:36:40.511368Z","shell.execute_reply.started":"2021-06-22T09:36:40.486193Z","shell.execute_reply":"2021-06-22T09:36:40.510318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Our model is ready to use as well, now we can start to train our model :)","metadata":{}},{"cell_type":"markdown","source":"# Training Model\nIn this section we're gonna train our model.","metadata":{}},{"cell_type":"code","source":"#I've added this to stop the other part of kernel :D\ninput()","metadata":{"execution":{"iopub.status.busy":"2021-06-22T09:36:40.513153Z","iopub.execute_input":"2021-06-22T09:36:40.51361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCH_NUMBER = 5\nTRAIN_LOSS = []\nTRAIN_ACCURACY = []\n\nfor epoch in range(1,EPOCH_NUMBER + 1):\n    epoch_loss = 0.0\n    correct = 0\n    total = 0\n    \n    for (data_,target_) in train_loader:\n        \n        target_ = target_.to(device)\n        data_ = data_.to(device)\n        \n        # First we'll clean the cache of optimizer\n        optimizer.zero_grad()\n        \n        # Forward propagation\n        outputs = model(data_)\n        \n        # Computing loss \n        loss = criterion(outputs,target_)\n        \n        # Backward propagation\n        loss.backward()\n        \n        # Optimizing model\n        optimizer.step()\n        \n        # Computing statistics.\n        epoch_loss = epoch_loss + loss.item()\n        _,pred = torch.max(outputs,dim=1)\n        correct = correct + torch.sum(pred == target_).item()\n        total += target_.size(0)\n        \n    # Appending stats to the lists.\n    TRAIN_LOSS.append(epoch_loss)\n    TRAIN_ACCURACY.append(100 * correct / total)\n    print(f\"Epoch {epoch}: Accuracy: {100 * correct/total}, Loss: {epoch_loss}\")\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* For now I dont have enough time to train this cute model, so I'll pass this section, but if you have time you can fork and train :)","metadata":{}},{"cell_type":"markdown","source":"# Final Test\nIn this section we're gonna test our model using our test loader.","metadata":{}},{"cell_type":"code","source":"total_val_loss = 0\ncorrect = 0\ntotal = len(test_sampler)\n\n# This means make all require_grad flags False\nwith torch.no_grad():\n    \n    # This will disable backward propagation\n    model.eval()\n    for data_,target_ in test_loader:\n        \n        data_ = data_.to(device)\n        target_ = target_.to(device)\n        \n        # Forward propagation\n        outputs = model(data_)\n        \n        # Computing loss\n        loss = criterion(outputs,target_).item()\n        total_val_loss += loss\n        \n        # Computing accuracy\n        _,preds = torch.max(outputs,dim=1)\n        true = torch.sum(preds == target_).item()\n        total_true += true\n\nvalidation_accuracy = round(100 * total_true / total,2)\nprint(f\"Validation accuracy: {validation_accuracy}%\")\nprint(f\"Validation loss: {round(total_val_loss,2)}%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion\nIt has been a lot since I did not write any kernel but now I've written this kernel and feel freshed. If you liked this kernel and upvoted I've been glad. \n\nHave a good day!","metadata":{}}]}