{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\nHello people, welcome to this kernel! In this kernel I will predict genders of students according their exams. Before starting let's take a look at our content\n\n# Notebook Content\n1. Importing Data and Libraries \n1. Data Overview\n1. Simple Data Analyses \n    * Gender Countplot\n    * Race Countplot\n    * Parental Level Of Education Countplot\n    * Lunch Countplot\n    * Test Preparation Course Countplot\n    * Math Score\n    * Reading Score\n    * Writing Score\n1. Detailed Data Analyses\n    * Correlation Heatmap\n    * Relation Between Gender - Math Score\n    * Relation Between Gender - Writing Score\n    * Relation Between Gender - Reading Score\n    * Relation Between Race - Math Score\n    * Relation Between Race - Writing Score\n    * Relation Between Race - Reading Score\n1. Data Preprocessing\n1. Building Model Using Pytorch\n1. Fitting Model Using Pytorch\n1. Evaulating Results\n1. Conclusion\n\n"},{"metadata":{},"cell_type":"markdown","source":"# Importing Data and Libraries\n\nIn this section I am going to import libraries and the data that I wil use. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nimport torch.nn as nn\n\nfrom sklearn.model_selection import train_test_split\n\nimport warnings as wrn\n\nwrn.filterwarnings('ignore') # Filter unrelevant warnings\nsns.set_style(\"darkgrid\")\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Importing data\ndata = pd.read_csv('/kaggle/input/students-performance-in-exams/StudentsPerformance.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Overview\nIn this section I am going to take look at the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* There are eight features in the dataset. 5 of them are categorical and 3 of them are numerical."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Simple Data Analyses\nIn this section I am going to do some simple EDA. "},{"metadata":{},"cell_type":"markdown","source":"## Countplots/Histograms of Features\n\n### Gender Countplot"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"gender\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(figsize=(8,6))\nsns.countplot(data[\"gender\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Although female entries are a bit more, our data is balanced.\n* We should convert this feature into integer."},{"metadata":{},"cell_type":"markdown","source":"### Race Countplot"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"race/ethnicity\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(figsize=(8,6))\nsns.countplot(data[\"race/ethnicity\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Most of the dataset's group is group D.\n* Entries of this feature is unbalanced. \n* We should convert this feature into categorical, and after that we should encode it."},{"metadata":{},"cell_type":"markdown","source":"### Parental Level Of Education Countplot"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"parental level of education\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(figsize=(8,6))\nsns.countplot(data[\"parental level of education\"])\nplt.xticks(rotation=60)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* We should convert this feature into categorical and then we should encode it."},{"metadata":{},"cell_type":"markdown","source":"### Lunch Countplot"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"lunch\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(figsize=(8,6))\nsns.countplot(data[\"lunch\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* This feature is definetely unbalanced.\n* We should convert this feature into categorical and after that we should encode it."},{"metadata":{},"cell_type":"markdown","source":"### Test Preparation Course Countplot"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"test preparation course\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(figsize=(8,6))\nsns.countplot(data[\"test preparation course\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Don't be confused because of the \"none\" label. It does not mean it is a missing value. \n* We should convert and encode this feature."},{"metadata":{},"cell_type":"markdown","source":"### Math Score Histogram"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(figsize=(8,6))\nsns.distplot(data[\"math score\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Most of the students took score between 50 and 100.\n* Although there are scores between 0 and 40, they are so rare.\n* I am wondering the relation between math score and gender but it is not the subject of this section, we will examine that in Detailed Data Analyses."},{"metadata":{},"cell_type":"markdown","source":"### Writing Score Histogram"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(figsize=(8,6))\nsns.distplot(data[\"writing score\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* This plot is very similar with the previous plot.\n* I can't say anything new, everything is same with the math score."},{"metadata":{},"cell_type":"markdown","source":"### Reading Score Histogram"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(figsize=(8,6))\nsns.distplot(data[\"reading score\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Detailed Data Analyses\n\nIn previous section we've examined the distrubiton of dataset, and now We are going to examine the relations between feautures, especially relations between gender and other features. Let's start with the heatmap"},{"metadata":{},"cell_type":"markdown","source":"## Correlation Heatmap"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(figsize=(6,6))\nsns.heatmap(data.corr(),annot=True,fmt=\"0.2f\",linewidths=1.5)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* All of the features are correlated with each others. "},{"metadata":{},"cell_type":"markdown","source":"## Relation Between Gender - Math Score "},{"metadata":{"trusted":true},"cell_type":"code","source":"gender_math = data.groupby(\"gender\")[\"math score\"].mean()\ngender_math","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(gender_math.index,gender_math.values)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Although scores are close, male's score is better.\n"},{"metadata":{},"cell_type":"markdown","source":"## Relation Between Gender - Writing Score"},{"metadata":{"trusted":true},"cell_type":"code","source":"gender_writing = data.groupby(\"gender\")[\"writing score\"].mean()\ngender_writing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(gender_writing.index,gender_writing.values)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Unlike the previous feature, scores are far. \n* We can say that, women are better in writing exam"},{"metadata":{},"cell_type":"markdown","source":"## Relation Between Gender - Reading Score"},{"metadata":{"trusted":true},"cell_type":"code","source":"gender_reading = data.groupby(\"gender\")[\"reading score\"].mean()\ngender_reading","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(gender_reading.index,gender_reading.values)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Like the writing score, women are better in writing exam."},{"metadata":{},"cell_type":"markdown","source":"## Relation Between Race - Math Score\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"race_math = data.groupby(\"race/ethnicity\")[\"math score\"].mean()\nrace_math","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(race_math.index,race_math.values)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Bad to good teams:\n\n\n1. Group A\n1. Group B\n1. Group C\n1. Group D\n1. Group E"},{"metadata":{},"cell_type":"markdown","source":"## Relation Between Race - Writing Score"},{"metadata":{"trusted":true},"cell_type":"code","source":"race_writing = data.groupby(\"race/ethnicity\")[\"writing score\"].mean()\nrace_writing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(race_writing.index,race_writing.values)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Like the math score, the sequence of groups is the same."},{"metadata":{},"cell_type":"markdown","source":"## Relation Between Race - Reading Score"},{"metadata":{"trusted":true},"cell_type":"code","source":"race_reading = data.groupby(\"race/ethnicity\")[\"reading score\"].mean()\nrace_reading","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(race_reading.index,race_reading.values)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing\n\nWe analysed the data and now we are ready for processing the data. In this section I will follow these steps:\n\n* Converting Label Into Int64\n* Creating X and Y\n* One Hot Encoding\n* X Normalization\n* Train Test Split"},{"metadata":{},"cell_type":"markdown","source":"## Converting Label Into Int64"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data.values[0])\ndata[\"gender\"] = [1 if each == \"female\" else 0 for each in data[\"gender\"]]\ndata.head(1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating X and Y"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = data.drop(\"gender\",axis=1)\ny = data.gender\nx.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## One Hot Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_encoded = pd.get_dummies(x,columns=[\"race/ethnicity\",\"parental level of education\",\"lunch\",\"test preparation course\"])\nx_encoded.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## X Normalization"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler(feature_range=(0,1))\n\nx_scaled = scaler.fit_transform(x_encoded)\nx_scaled[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_scaled.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,x_test,y_train,y_test = train_test_split(x_scaled,y,test_size=0.2,random_state=1)\nprint(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building Model Using Pytorch\n\nOur data is ready, so in this section We are going to build a simple ANN model using pytorch. I know, I can use traditional machine learning algorithms for processing this data, but I will use pytorch for exercising. \n\nWe'll use a simple model like that:\n\n1. Input Layer\n1. Hidden Layer 1\n1. Output Layer\n\nAnd I will use Adam as optimizer and Cross Entropy as loss."},{"metadata":{"trusted":true},"cell_type":"code","source":"class ANN(nn.Module):\n    \n    def __init__(self):\n        \n        super(ANN,self).__init__()\n        \n        # Linear function 1\n        self.linear1 = nn.Linear(18,10) # 18 to 10\n        self.tanh1 = nn.Tanh()\n        \n        # Linear function 2\n        self.linear2 = nn.Linear(10,6) # 10 to 6\n        self.tanh2 = nn.Tanh()\n        \n        # Linear function 3\n        self.linear3 = nn.Linear(6,2) # 6 to output\n        \n    \n    def forward(self,x):\n        \n        out = self.linear1(x)\n        out = self.tanh1(out)\n        \n        out = self.linear2(out)\n        out = self.tanh2(out)\n        \n        out = self.linear3(out)\n        return out\n    \n\nmodel = ANN()\noptimizer = torch.optim.Adam(model.parameters(),lr=0.01)\nerror = nn.CrossEntropyLoss()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fitting Model Using Pytorch\n\nOur frame of model is ready, and now let's train it."},{"metadata":{"trusted":true},"cell_type":"code","source":"# But before fitting, we must convert numpy arrays into torch tensors\n\nx_train = torch.Tensor(x_train)\nx_test = torch.Tensor(x_test)\ny_train = torch.Tensor(y_train).type(torch.LongTensor)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 200\nfor epoch in range(epochs):\n    \n    # Clearing gradients\n    optimizer.zero_grad()\n    \n    # Forward propagation\n    outs = model(x_train)\n    \n    # Computing loss\n    loss = error(outs,y_train)\n    \n    # Backward propagation\n    loss.backward()\n    \n    # Updating parameters\n    optimizer.step()\n    \n    if epoch%50 == 0:\n        print(f\"Cost after iteration {epoch} is {loss}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaulating Results\n\nWe trained our model in previous section. And now in this section we will predict x_test and after that we will evaulete the results."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n# Predicting \ny_head = model(x_test)\nprint(y_head[0])\n\n\n# Converting predictions into labels\ny_pred = torch.max(y_head,-1)[1]\nprint(y_pred[0])\n\nprint(\"Accuracy of model is \",accuracy_score(y_pred,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion\n\nThanks for your attention, if you have any questions in your mind, please ask. "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}