{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Below are all of the packages I imported for this notebook\n#My main goal was to classify the main research goals for Task 4 - Vaccines and Therapeutics using NLTK natural language processing\n#I focused my analysis on the Title and Abstract only, as I wanted to capture what the researcher was doing specifically without the noise of other citations etc in the body of a paper\n\nimport pandas as pd \nimport numpy as np\nfrom collections import Counter\nimport nltk\nimport string\nfrom collections import Counter\nfrom nltk.probability import FreqDist\nfrom io import StringIO\nimport datetime\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_selection import chi2\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"covid = pd.read_csv('../input/CORD-19-research-challenge/metadata.csv', sep=',')\nprint(type(covid))\ncovid.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#here I wanted to obtain specifically the First Author-main researcher and the Last Author- Professor so the user can see which labs are most active for a given topic \ncovid['first_author'] = covid['authors'].str.split(';').str[0]\ncovid['last_author'] = covid['authors'].str.split(';').str[-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#the goal here was to create a new column called Text Analysis which would be used to train the language processor and perform searches\ncovid['text_analysis'] = covid['title'] + covid['abstract'] + covid['first_author'] + covid['last_author']\ncovid['text_analysis'] = covid['text_analysis'].str.lower()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#the purpose of below was to simplify the date format and also to tokenize the Text Analysis comment before applying stopwords\ncovid['date_format'] =  pd.to_datetime(covid['publish_time'])\ncovid['month_year'] = covid['date_format'].dt.to_period('M')\ncovid['text_analysis'] = covid['text_analysis'] .astype(str)\ncovid['text_tokenize'] = covid['text_analysis'].apply(nltk.word_tokenize)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"string.punctuation\nuseless_words = nltk.corpus.stopwords.words(\"english\") + list(string.punctuation)\ncovid['clean_tokenize'] = covid['text_tokenize'].apply(lambda x: [item for item in x if item not in useless_words])\ncovid['clean_tokenize'] = covid['clean_tokenize'] .astype(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('total papers', covid['title'].nunique())\nprint('unique first authors', covid['first_author'].nunique())\nprint('unique last authors', covid['last_author'].nunique())\nprint('unique PMCID', covid['pmcid'].nunique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Defining the questions**\n\nBecause the natural language processor is trained using a text sample, it is important to ensure what is being fed during training is as targeted as possible. Currently there aren't too many papers specifically targeted at COVID-19, however I expect this number exponentially grow with time, and the goal is to prevent the processor from capturing too many articles as being within scope. Below are the text filteres I used to filter journals for training.\n\nTask 4- \n**Question 1- Effectiveness of drugs being developed and tried to treat COVID-19 patients.\n**Clinical and bench trials to investigate less common viral inhibitors against COVID-19 such as naproxen, clarithromycin, and minocyclinethat that may exert effects on viral replication.\n\n'corona','inhibit','replication'\n\n**Question 2- Methods evaluating potential complication of Antibody-Dependent Enhancement (ADE) in vaccine recipients\n\n'antibody','vaccine','corona'\n\n**Question 3- Exploration of use of best animal models and their predictive value for a human vaccine\n\n'trial','predict'\n\n**Question 4- Capabilities to discover a therapeutic (not vaccine) for the disease, and clinical effectiveness studies to discover therapeutics, to include antiviral agents.\n\n'therapeutics','antiviral','covid-19'\n\n**Unrelated- Papers which didn't include any of the above text filter, or anything related to COVID-19\n\n**Doesn't contain** \n'covid19','inhibit','replication','antibody','vaccine','corona','therapeutics','antiviral','animal','predictive','virus','sars','airborne','respitory','mers','nan', and papers for 2018 (to reduce the number)"},{"metadata":{"trusted":true},"cell_type":"code","source":"covid['question1'] = covid['text_analysis'].str.contains('corona')&covid['text_analysis'].str.contains('inhibit')&covid['text_analysis'].str.contains('replication')\ncovid['question2'] = covid['text_analysis'].str.contains('antibody')&covid['text_analysis'].str.contains('vaccine')& covid['text_analysis'].str.contains('corona')\ncovid['question3'] = covid['text_analysis'].str.contains('trial')&covid['text_analysis'].str.contains('predict')\ncovid['question4'] = covid['text_analysis'].str.contains('therapeutics')&covid['text_analysis'].str.contains('antiviral')&covid['text_analysis'].str.contains('covid-19')\ncovid['unrelated'] = ~covid['text_analysis'].str.contains('covid-19') & ~covid['text_analysis'].str.contains('inhibit')& ~covid['text_analysis'].str.contains('replication') & ~covid['text_analysis'].str.contains('antibody') & ~covid['text_analysis'].str.contains('vaccine') & ~covid['text_analysis'].str.contains('corona')&~covid['text_analysis'].str.contains('therapeutics')&~covid['text_analysis'].str.contains('antiviral')&~covid['text_analysis'].str.contains('animal') & ~covid['text_analysis'].str.contains('predictive')&~covid['text_analysis'].str.contains('virus')& ~covid['text_analysis'].str.contains('sars')& ~covid['text_analysis'].str.contains('airborne')& ~covid['text_analysis'].str.contains('respitory')& ~covid['text_analysis'].str.contains('mers')& covid['publish_time'].str.contains('2018')& ~covid['text_analysis'].str.contains('nan')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Below changes resopnse from True/False\ncovid['question1'] = np.where(covid['question1'], 'Question1', 'N')\ncovid['question2'] = np.where(covid['question2'], 'Question2', 'N')\ncovid['question3'] = np.where(covid['question3'], 'Question3', 'N')\ncovid['question4'] = np.where(covid['question4'], 'Question4', 'N')\ncovid['unrelated'] = np.where(covid['unrelated'], 'Unrelated', 'N')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#The goal here is to factorize the questions into different categories for the NLTK\ncovid['not_question'] = covid['question1'].str.contains('N')& covid['question2'].str.contains('N') & covid['question3'].str.contains('N') & covid['question4'].str.contains('N') & covid['unrelated'].str.contains('N')\ncovid['category_id'] = covid[['question1','question2','question3','question4','unrelated']].max(axis=1)\ncovid['category_id_num'] = covid['category_id'].factorize()[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#The final step is to create my training datafram\ntrain_df=covid[~covid['category_id'].str.contains('N')]\ncategory_id_df = train_df[['category_id', 'category_id_num']].drop_duplicates().sort_values('category_id_num')\ncategory_to_id = dict(category_id_df.values)\ntrain_df.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Below is using a Scikit Learn to calculate a vector for each of the narratives\ntfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')\ntrain_df_features = tfidf.fit_transform(train_df['clean_tokenize']).toarray()\nlabels = train_df['category_id_num']\ntrain_df_features.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Below obtains the most correlated unigrams and bigrams\nN = 2\nfor Product, category_id_num in sorted(category_to_id.items()):\n  features_chi2 = chi2(train_df_features, labels == category_id_num)\n  indices = np.argsort(features_chi2[0])\n  feature_names = np.array(tfidf.get_feature_names())[indices]\n  unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n  bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#The final step is to train the Naive Bayes Classifier\nX_train, X_test, y_train, y_test = train_test_split(train_df['title'], train_df['category_id'], random_state = 0)\ncount_vect = CountVectorizer()\nX_train_counts = count_vect.fit_transform(X_train)\ntfidf_transformer = TfidfTransformer()\nX_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\nclf = MultinomialNB().fit(X_train_tfidf, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Paste title in the square brackets\nprint(clf.predict(count_vect.transform(['Long-Term Persistence of Robust Antibody and Cytotoxic T Cell Responses in Recovered Patients Infected with SARS Coronavirus'])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(clf.predict(count_vect.transform(['Practical fluid therapy and treatment modalities for field conditions for horses and foals with gastrointestinal problems'])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}