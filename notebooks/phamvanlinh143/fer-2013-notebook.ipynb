{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom matplotlib import pyplot\nfrom math import sqrt \nimport numpy as np \nimport scipy.misc \nfrom IPython.display import display \nfrom keras.utils import np_utils\nfrom keras.preprocessing.image import ImageDataGenerator \nfrom keras.utils import plot_model\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.optimizers import Adam, SGD\nfrom keras.regularizers import l1, l2\nfrom matplotlib import pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n%matplotlib inline\ndata= pd.read_csv('../input/fer2013.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9747ec111b84d59523991febdf88f94bfb9876cd"},"cell_type":"code","source":"from pylab import rcParams\nrcParams['figure.figsize'] = 15, 10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"73867bf44a012e4c966616fc7cbfc2cb2eff9fe8"},"cell_type":"code","source":"data.emotion.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"29ef4814d4323333088baae02d1a96f83db1c3f4"},"cell_type":"code","source":"num_classes = 7\nwidth = 48\nheight = 48\nemotion_labels = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"]\nclasses=np.array((\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4526572ff9f2f53ae8cf101c3ecfcf63cfcdcafa"},"cell_type":"code","source":"data.Usage.value_counts() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"15d98d711962aeab1d12478d9b3a9b8419cc49c5"},"cell_type":"code","source":"depth = 1\nheight = int(sqrt(len(data.pixels[0].split()))) \nwidth = int(height)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"461f923af7acd9e06b1204a3642cefa75e2ff72f"},"cell_type":"code","source":"for i in range(0, 5): \n    array = np.mat(data.pixels[i]).reshape(height, width) \n    image = scipy.misc.toimage(array, cmin=0.0) \n    display(image)\n    #plt.imshow(image)\n    print(emotion_labels[data.emotion[i]]) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2a7111d3045580ae1ff21b7ae770c4be7abeebbe"},"cell_type":"code","source":"train_set = data[(data.Usage == 'Training')] \nval_set = data[(data.Usage == 'PublicTest')]\ntest_set = data[(data.Usage == 'PrivateTest')] \nX_train = np.array(list(map(str.split, train_set.pixels)), np.float32) \nX_val = np.array(list(map(str.split, val_set.pixels)), np.float32) \nX_test = np.array(list(map(str.split, test_set.pixels)), np.float32) \nX_train = X_train.reshape(X_train.shape[0], 48, 48, 1) \nX_val = X_val.reshape(X_val.shape[0], 48, 48, 1)\nX_test = X_test.reshape(X_test.shape[0], 48, 48, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"afa2e2922ad58ba02230f21ea04dd2111ba6d7f3"},"cell_type":"code","source":"num_train = X_train.shape[0]\nnum_val = X_val.shape[0]\nnum_test = X_test.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8f3e1f9dd92afb91a6a5e11379a52b63009e5cc9"},"cell_type":"code","source":"y_train = train_set.emotion \ny_train = np_utils.to_categorical(y_train, num_classes) \ny_val = val_set.emotion \ny_val = np_utils.to_categorical(y_val, num_classes) \ny_test = test_set.emotion \ny_test = np_utils.to_categorical(y_test, num_classes) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cd67c48062a9306d8305bc28bc541f6de8e28f0a"},"cell_type":"code","source":"datagen = ImageDataGenerator( \n    rescale=1./255,\n    rotation_range = 10,\n    horizontal_flip = True,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    fill_mode = 'nearest')\n\ntestgen = ImageDataGenerator( \n    rescale=1./255\n    )\ndatagen.fit(X_train)\nbatch_size = 64","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bb80295851d45b120743d33f592f4163b43b6ad7"},"cell_type":"code","source":"for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9):\n    for i in range(0, 9): \n        pyplot.axis('off') \n        pyplot.subplot(330 + 1 + i) \n        pyplot.imshow(X_batch[i].reshape(48, 48), cmap=pyplot.get_cmap('gray'))\n    pyplot.axis('off') \n    pyplot.show() \n    break ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"da9fc7ec9dbaab6954faa22a0a1dfdfd95bc27a1"},"cell_type":"code","source":"train_flow = datagen.flow(X_train, y_train, batch_size=batch_size) \nval_flow = testgen.flow(X_val, y_val, batch_size=batch_size) \ntest_flow = testgen.flow(X_test, y_test, batch_size=batch_size) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def FER_Model(input_shape=(48,48,1)):\n    # first input model\n    visible = Input(shape=input_shape, name='input')\n    num_classes = 7\n    #the 1-st block\n    conv1_1 = Conv2D(64, kernel_size=3, activation='relu', padding='same', name = 'conv1_1')(visible)\n    conv1_1 = BatchNormalization()(conv1_1)\n    conv1_2 = Conv2D(64, kernel_size=3, activation='relu', padding='same', name = 'conv1_2')(conv1_1)\n    conv1_2 = BatchNormalization()(conv1_2)\n    pool1_1 = MaxPooling2D(pool_size=(2,2), name = 'pool1_1')(conv1_2)\n    drop1_1 = Dropout(0.3, name = 'drop1_1')(pool1_1)\n\n    #the 2-nd block\n    conv2_1 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_1')(drop1_1)\n    conv2_1 = BatchNormalization()(conv2_1)\n    conv2_2 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_2')(conv2_1)\n    conv2_2 = BatchNormalization()(conv2_2)\n    conv2_3 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_3')(conv2_2)\n    conv2_2 = BatchNormalization()(conv2_3)\n    pool2_1 = MaxPooling2D(pool_size=(2,2), name = 'pool2_1')(conv2_3)\n    drop2_1 = Dropout(0.3, name = 'drop2_1')(pool2_1)\n\n    #the 3-rd block\n    conv3_1 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_1')(drop2_1)\n    conv3_1 = BatchNormalization()(conv3_1)\n    conv3_2 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_2')(conv3_1)\n    conv3_2 = BatchNormalization()(conv3_2)\n    conv3_3 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_3')(conv3_2)\n    conv3_3 = BatchNormalization()(conv3_3)\n    conv3_4 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_4')(conv3_3)\n    conv3_4 = BatchNormalization()(conv3_4)\n    pool3_1 = MaxPooling2D(pool_size=(2,2), name = 'pool3_1')(conv3_4)\n    drop3_1 = Dropout(0.3, name = 'drop3_1')(pool3_1)\n\n    #the 4-th block\n    conv4_1 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_1')(drop3_1)\n    conv4_1 = BatchNormalization()(conv4_1)\n    conv4_2 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_2')(conv4_1)\n    conv4_2 = BatchNormalization()(conv4_2)\n    conv4_3 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_3')(conv4_2)\n    conv4_3 = BatchNormalization()(conv4_3)\n    conv4_4 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_4')(conv4_3)\n    conv4_4 = BatchNormalization()(conv4_4)\n    pool4_1 = MaxPooling2D(pool_size=(2,2), name = 'pool4_1')(conv4_4)\n    drop4_1 = Dropout(0.3, name = 'drop4_1')(pool4_1)\n\n    #the 5-th block\n    conv5_1 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_1')(drop4_1)\n    conv5_1 = BatchNormalization()(conv5_1)\n    conv5_2 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_2')(conv5_1)\n    conv5_2 = BatchNormalization()(conv5_2)\n    conv5_3 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_3')(conv5_2)\n    conv5_3 = BatchNormalization()(conv5_3)\n    conv5_4 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_4')(conv5_3)\n    conv5_3 = BatchNormalization()(conv5_3)\n    pool5_1 = MaxPooling2D(pool_size=(2,2), name = 'pool5_1')(conv5_4)\n    drop5_1 = Dropout(0.3, name = 'drop5_1')(pool5_1)\n\n    #Flatten and output\n    flatten = Flatten(name = 'flatten')(drop5_1)\n    ouput = Dense(num_classes, activation='softmax', name = 'output')(flatten)\n\n    # create model \n    model = Model(inputs =visible, outputs = ouput)\n    # summary layers\n    print(model.summary())\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = FER_Model()\nopt = Adam(lr=0.0001, decay=1e-6)\nmodel.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy']) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2f8e528c62477436ec78c1466ce639362600e89c"},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint\nfilepath=\"weights_min_loss.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\ncallbacks_list = [checkpoint]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"78da0c9ed84cd3443e15c268165295098c1e37dd"},"cell_type":"code","source":"num_epochs = 200 # we iterate 200 times over the entire training set \nhistory = model.fit_generator(train_flow, \n                    steps_per_epoch=len(X_train) / batch_size, \n                    epochs=num_epochs,  \n                    verbose=2,  \n                    callbacks=callbacks_list,\n                    validation_data=val_flow,  \n                    validation_steps=len(X_val) / batch_size) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"af0a29045f22083852990e823c8472f0c9b96afa"},"cell_type":"code","source":"# visualizing losses and accuracy\n%matplotlib inline\n\ntrain_loss=history.history['loss']\nval_loss=history.history['val_loss']\ntrain_acc=history.history['acc']\nval_acc=history.history['val_acc']\n\nepochs = range(len(train_acc))\n\nplt.plot(epochs,train_loss,'r', label='train_loss')\nplt.plot(epochs,val_loss,'b', label='val_loss')\nplt.title('train_loss vs val_loss')\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs,train_acc,'r', label='train_acc')\nplt.plot(epochs,val_acc,'b', label='val_acc')\nplt.title('train_acc vs val_acc')\nplt.xlabel('epoch')\nplt.ylabel('accuracy')\nplt.legend()\nplt.figure()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"00f5794435957e12ce1f8756e373e7216d41482b"},"cell_type":"code","source":"loss = model.evaluate_generator(test_flow, steps=len(X_test) / batch_size) \nprint(\"Test Loss \" + str(loss[0]))\nprint(\"Test Acc: \" + str(loss[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f2752392088897e7bfa24f4615456467219128f4"},"cell_type":"code","source":"model.save('Fer2013.hdf5') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1332d6dac80ae367cc66ea1e7736d53a65d391eb"},"cell_type":"code","source":"loss = model.evaluate(X_test/255., y_test) \nprint(\"Test Loss \" + str(loss[0]))\nprint(\"Test Acc: \" + str(loss[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b275f8a23c504797fe0d1ad63872eb968f5c6a8"},"cell_type":"code","source":"loss = model.evaluate(X_val/255., y_val) \nprint(\"Test Loss \" + str(loss[0]))\nprint(\"Test Acc: \" + str(loss[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_confusion_matrix(y_test, y_pred, classes,\n                          normalize=False,\n                          title='Unnormalized confusion matrix',\n                          cmap=plt.cm.Blues):\n    cm = confusion_matrix(y_test, y_pred)\n    \n    if normalize:\n        cm = np.round(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], 2)\n        \n    np.set_printoptions(precision=2)\n        \n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    thresh = cm.min() + (cm.max() - cm.min()) / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True expression')\n    plt.xlabel('Predicted expression')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_ = model.predict(X_test/255., verbose=1)\ny_pred = np.argmax(y_pred_, axis=1)\nt_te = np.argmax(y_test, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plot_confusion_matrix(y_test=t_te, y_pred=y_pred,\n                      classes=classes,\n                      normalize=True,\n                      cmap=plt.cm.Greys,\n                      title='Average accuracy: ' + str(np.sum(y_pred == t_te)/len(t_te)) + '\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}