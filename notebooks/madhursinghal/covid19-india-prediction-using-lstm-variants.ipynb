{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport pandas as pd\n\n\n%matplotlib inline \n\nimport matplotlib\nimport matplotlib.pyplot as plt \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ndf= pd.read_csv('/kaggle/input/covid19data/owid-covid-data.csv')\ndf\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_in=df.loc[df['location'] == \"India\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndata_in[\"date\"]= pd.to_datetime(data_in[\"date\"]) \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_in.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_in.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_in.drop(['total_deaths','new_deaths','gdp_per_capita','extreme_poverty','cardiovasc_death_rate','diabetes_prevalence','female_smokers','male_smokers','handwashing_facilities','hospital_beds_per_thousand','life_expectancy','human_development_index','iso_code', 'continent','total_cases_per_million','new_cases_per_million','new_cases_smoothed_per_million','total_deaths_per_million','new_tests_smoothed_per_thousand','tests_per_case','positive_rate','population','population_density','tests_units','new_deaths_smoothed_per_million', 'new_deaths_per_million','total_tests','total_tests_per_thousand','new_tests_per_thousand','new_tests_smoothed','stringency_index','median_age','aged_65_older','weekly_hosp_admissions_per_million','hosp_patients_per_million','weekly_hosp_admissions','weekly_icu_admissions_per_million','weekly_icu_admissions','reproduction_rate','hosp_patients','icu_patients_per_million','icu_patients','aged_70_older','new_tests'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_in","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df  = data_in[data_in['date']>'2020-03-18']\ndf = df[df['date']<'2020-10-28']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['location'],axis = 1,inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.reset_index(drop=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['new_cases_smoothed','total_cases'],axis =1,inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['new_cases'].plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(100,50))\nplt.plot(df['date'],df['new_cases'])\nplt.xlabel(\"date\")\nplt.ylabel(\"case\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = df['new_cases']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocessing(data , days=14):\n    X, Y = [], []\n    for i in range(len(data)-days-1):\n        a = data[i:(i+days), 0]\n        X.append(a)\n        Y.append(data[i + days, 0])\n    return np.array(X), np.array(Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndata = np.array(data)\ndata = data.reshape(len(data),1)\nprint(data.shape)\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=(0, 1))\ndata = scaler.fit_transform(data)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \ntrain, test= np.split(data, [int(.8*len(data))])\ntrain = train.reshape(len(train) , 1)\ntest = test.reshape(len(test) , 1)\nprint(test.shape)\nprint(train.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,Y_train =preprocessing(train)\nX_test,Y_test =preprocessing(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_train = Y_train.reshape(len(Y_train),1)\nY_test = Y_test.reshape(len(Y_test),1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train.reshape(X_train.shape[0] , 1 ,X_train.shape[1])\nX_test = X_test.reshape(X_test.shape[0] , 1 ,X_test.shape[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy\nimport matplotlib.pyplot as plt\nimport pandas\nimport math\nfrom keras.models import Sequential\nfrom keras.layers import Dense , BatchNormalization , Dropout , Activation\nfrom keras.layers import LSTM , GRU\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom keras import optimizers\ndays =14\nmodel = Sequential()\nmodel.add(GRU(256 , input_shape = (1 , days) , return_sequences=True))\nmodel.add(Dropout(0.3))\nmodel.add(LSTM(256))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(64 ,  activation = 'relu'))\nmodel.add(Dense(1))\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = optimizers.Adam(lr=0.01)\nfrom keras.callbacks import ReduceLROnPlateau\nmodel.compile(loss='mean_squared_error', optimizer=optimizer , metrics = ['mean_squared_error'])\nhistory = model.fit(X_train, Y_train, epochs=150 , batch_size = 64 , \n           validation_data = (X_test,Y_test))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\ndef model_score(model, X_train, y_train, X_test, y_test):\n    trainScore = model.evaluate(X_train, y_train, verbose=0)\n    print('Train Score: %.5f MSE (%.5f RMSE)' % (trainScore[0], math.sqrt(trainScore[0])))\n    testScore = model.evaluate(X_test, y_test, verbose=0)\n    print('Test Score: %.5f MSE (%.5f RMSE)' % (testScore[0], math.sqrt(testScore[0])))\n    return trainScore[0], testScore[0]\n\nmodel_score(model, X_train, Y_train , X_test, Y_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(X_train)\npred = scaler.inverse_transform(pred)\ny_test = Y_train.reshape(Y_train.shape[0] , 1)\ny_test = scaler.inverse_transform(y_test)\nprint(\"Red - Predicted,  Blue - Actual\")\nplt.rcParams[\"figure.figsize\"] = (15,7)\nplt.plot(y_test , 'b')\nplt.plot(pred , 'r')\nplt.xlabel('Time')\nplt.ylabel('Stock Prices')\nplt.grid(True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X,Y = preprocessing(data)\nY = Y.reshape(len(Y),1)\nX = X.reshape(X.shape[0] , 1 ,X.shape[1])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_graph(X,model,Y):\n    pred = model.predict(X)\n    pred = scaler.inverse_transform(pred)\n    y_test = Y.reshape(Y.shape[0] , 1)\n    y_test = scaler.inverse_transform(y_test)\n    print(\"Red - Predicted,  Blue - Actual\")\n    plt.rcParams[\"figure.figsize\"] = (15,7)\n    plt.plot(y_test , 'b')\n    plt.plot(pred , 'r')\n    plt.xlabel('Time in days')\n    plt.ylabel('Daily new deaths')\n    plt.title(\"stacked LSTM for Daily new deaths prediction\")\n    plt.grid(True)\n    plt.show()\n    return\nmodel_graph(X,model,Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import LSTM\nfrom keras.layers import Dense\nfrom keras.layers import Bidirectional\nmodel_b = Sequential()\nmodel_b.add(Bidirectional(LSTM(256, activation='relu',return_sequences = True), input_shape=(21,1)))\nmodel_b.add(Dropout(0.2))\nmodel_b.add(Dense(256 ,  activation = 'relu'))\nmodel_b.add(Dense(128 ,  activation = 'relu'))\nmodel_b.add(Dense(16 ,  activation = 'relu'))\nmodel_b.add(Dense(1 ,  activation = 'relu'))\n\n\nprint(model_b.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_sequence(sequence, n_steps_in, n_steps_out):\n    X, y = list(), list()\n    for i in range(len(sequence)):\n        # find the end of this pattern\n        end_ix = i + n_steps_in\n        out_end_ix = end_ix + n_steps_out\n        # check if we are beyond the sequence\n        if out_end_ix > len(sequence):\n            break\n        # gather input and output parts of the pattern\n        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n        X.append(seq_x)\n        y.append(seq_y)\n    return np.array(X), np.array(y)\nX_train,Y_train =split_sequence(train,21,1)\nX_test,Y_test =split_sequence(test,21,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = optimizers.Adam(lr=0.01)\nfrom keras.callbacks import ReduceLROnPlateau\nmodel_b.compile(loss='mean_squared_error', optimizer=optimizer , metrics = ['mean_squared_error'])\nhistory_b = model_b.fit(X_train, Y_train, epochs=4, batch_size = 64, \n           validation_data = (X_test,Y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(history_b.history['loss'])\nplt.plot(history_b.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel_score(model_b, X_train, Y_train , X_test, Y_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p = X_test[-1,:,0].reshape(1,21,1)\npred = model_b.predict(p)\npred = pred.reshape(21,1)\ntotal = np.append(Y,pred)\nprint(total.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprint(\"Red - Predicted,  Blue - Actual\")\nplt.rcParams[\"figure.figsize\"] = (15,7)\nplt.plot(total , 'b')\nplt.plot(Y , 'r')\nplt.xlabel('Time in days')\nplt.axvline(train.shape[0], color='g')\nplt.ylabel('Daily new Cases')\nplt.title(\"stacked LSTM for Daily new cases prediction\")\nplt.grid(True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"arr = np.array(X_test[-1,:,:]).reshape(1,1,7)\nprint(data)\nprint(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = model_b.predict(arr)\nnew_data = arr[:,:,1:]\nnew_data = np.append(new_data,25)\nprint(new_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(data,days = 100):\n    final = np.array([])\n    for day in range(0,days):\n        result = model_b.predict(data)\n        new_data = data[:,:,1:]\n        new_data = np.append(new_data,result)\n        data = new_data\n        data = data.reshape(1,1,7)\n        final = np.append(final,result[0,0,0])\n    return final\nfinal = predict(arr)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}