{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Predicting Poisonous Mushrooms","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Highlights:**\n> 1. Correlation analysis using Cramer's V\n>\n> 2. Results for each ML algorithm are presented after performing 5-fold cross validation based on F1-score","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* [1. Data Munging](#data-munging)\n    * [1.1. Checking for null values in the dataset](#checking-for-null-values-in-the-dataset)\n    * [1.2. Search for categorical columns and cast them to `pd.Categorical`](#search-for-categorical-columns-and-cast-them-to-%60pd.categorical%60)\n    * [1.3. Delete `veil-type` column](#delete-%60veil-type%60-column)\n    * [1.4. Reordering Columns](#reordering-columns)\n* [2. Correlations in the data](#correlations-in-the-data)\n* [3. Data Visualization](#data-visualization)\n    * [3.1. Frequency distribution](#frequency-distribution)\n    * [3.2. Distribution among different habitat](#distribution-among-different-habitat)\n    * [3.3. Distribution among different populations types](#distribution-among-different-populations-types)\n    * [3.4. Distribution among different habitat and population types taken together](#distribution-among-different-habitat-and-population-types-taken-together)\n* [4. Data Preprocessing](#data-preprocessing)\n    * [4.1. Train-Test split](#train-test-split)\n    * [4.2. One-hot Encoding](#one-hot-encoding)\n* [5. Data Modeling](#data-modeling)\n    * [5.1. Utility Functions](#utility-functions)\n    * [5.2. Naive Bayes](#naive-bayes)\n    * [5.3. Logistic Regression](#logistic-regression)\n    * [5.4. K-Nearest Neighbors](#k-nearest-neighbors)\n    * [5.5. Decision Tree](#decision-tree)\n    * [5.6. Decision Trees with Bagging](#decision-trees-with-bagging)\n    * [5.7. Random Forests](#random-forests)\n    * [5.8. Decision Trees with AdaBoost](#decision-trees-with-adaboost)\n    * [5.9. Linear SVC](#linear-svc)\n    * [5.10. SVM with RBF kernel](#svm-with-rbf-kernel)\n    * [5.11. XGBoost](#xgboost)\n    * [5.12. CatBoost](#catboost)\n* [6. Model Comparison](#model-comparison)\n    * [6.1. Evaluation Metrics](#evaluation-metrics)\n    * [6.2. ROC and PR Curves](#roc-and-pr-curves)","execution_count":null},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"import os, sys, json\n\nimport numpy as np\nfrom scipy.stats import chi2_contingency\nimport pandas as pd\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get full labels from JSON file\nwith open('/kaggle/input/mushroom-labels/full_labels.json', 'r') as fp:\n    full_labels = json.load(fp)","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/mushroom-classification/mushrooms.csv')","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"df.head(2)","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"df = df.apply(func=lambda ser: ser.replace(to_replace=full_labels[ser.name]),\n              axis=0)","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","toc-hr-collapsed":true,"toc-nb-collapsed":true},"cell_type":"markdown","source":"<a id=\"data-munging\"></a>\n# 1. Data Munging","execution_count":null},{"metadata":{"Collapsed":"false","toc-hr-collapsed":true,"toc-nb-collapsed":true},"cell_type":"markdown","source":"<a id=\"checking-for-null-values-in-the-dataset\"></a>\n## 1.1. Checking for null values in the dataset\nThere are no null values in the dataset.","execution_count":null},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"df[df.isnull().any(axis=1)]","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","toc-hr-collapsed":true,"toc-nb-collapsed":true},"cell_type":"markdown","source":"<a id=\"search-for-categorical-columns-and-cast-them-to-%60pd.categorical%60\"></a>\n## 1.2. Search for categorical columns and cast them to `pd.Categorical`\nWe need to manually identify categorical columns in the data before casting them to `pd.Categorical`. Casting categorical columns from the detected *object* type to *categorical* will ease visualization.","execution_count":null},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"def summarize_categoricals(df, show_levels=False):\n    \"\"\" Display uniqueness in each column \"\"\"\n    df_temp = pd.DataFrame([[df[col].unique(), len(df[col].unique()), df[col].isnull().sum()] for col in df.columns],\n                           index=df.columns, columns=['Levels', \n                                                      'No. of Levels',\n                                                      'No. of Missing Values'])\n    return df_temp.iloc[:, 0 if show_levels else 1:]\n\n\ndef find_categorical(df, cutoff=10):\n    \"\"\" Function to find categorical columns in the dataframe. \"\"\"\n    cat_cols = []\n    for col in df.columns:\n        if len(df[col].unique()) <= cutoff:\n            cat_cols.append(col)\n    return cat_cols\n\n\ndef to_categorical(columns, df):\n    \"\"\" Converts the columns passed in `columns` to categorical datatype. \"\"\"\n    for col in columns:\n        df[col] = df[col].astype('category')\n    return df","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"summarize_categoricals(df, show_levels=True)","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"df = to_categorical(find_categorical(df, cutoff=12), df)\n\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","toc-hr-collapsed":true,"toc-nb-collapsed":true},"cell_type":"markdown","source":"<a id=\"delete-%60veil-type%60-column\"></a>\n## 1.3. Delete `veil-type` column\nSince `veil-type` feature does not have any variance, it does not have any discriminative power. In otherwords, since `veil-type` feature has the same value for all the samples (see section 1.2 categorical summary table), it holds no information that facilitates differentiating/ separating the target classes. Therefore, we can delete this features without losing any information.","execution_count":null},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"df.drop(labels=['veil-type'], axis=1, inplace=True)\n\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"true"},"cell_type":"markdown","source":"<a id=\"reordering-columns\"></a>\n## 1.4. Reordering Columns","execution_count":null},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"# Moving the target column to the end\nnew_order = list(df.columns)\nnew_order.append(new_order.pop(0))\ndf = df[new_order]\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","toc-hr-collapsed":true,"toc-nb-collapsed":true},"cell_type":"markdown","source":"<a id=\"correlations-in-the-data\"></a>\n# 2. Correlations in the data","execution_count":null},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"df.describe().T","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"`Cramer's V` is more appropriate than Pearson correlation to find correlation between two nominal variables. Here, the `Cramer's V` metric is implemented.","execution_count":null},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"def cramers_corrected_stat(contingency_table):\n    \"\"\"\n        Computes corrected Cramer's V statistic for categorial-categorial association\n        Taken from here:\n        https://stackoverflow.com/questions/20892799/using-pandas-calculate-cram%C3%A9rs-coefficient-matrix\n    \"\"\"\n    chi2 = chi2_contingency(contingency_table)[0]\n    n = contingency_table.sum().sum()\n    phi2 = chi2/n\n    \n    r, k = contingency_table.shape\n    r_corrected = r - (((r-1)**2)/(n-1))\n    k_corrected = k - (((k-1)**2)/(n-1))\n    phi2_corrected = max(0, phi2 - ((k-1)*(r-1))/(n-1))\n    \n    return (phi2_corrected / min( (k_corrected-1), (r_corrected-1)))**0.5","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"def categorical_corr_matrix(df):\n    \"\"\"\n        Computes corrected Cramer's V statistic between all the categorical variables in the dataframe\n    \"\"\"\n    df = df.select_dtypes(include='category')\n    cols = df.columns\n    n = len(cols)\n    corr_matrix = pd.DataFrame(np.zeros(shape=(n, n)), index=cols, columns=cols)\n    \n    for col1 in cols:\n        for col2 in cols:\n            if col1 == col2:\n                corr_matrix.loc[col1, col2] = 1\n                break\n            df_crosstab = pd.crosstab(df[col1], df[col2], dropna=False)\n            corr_matrix.loc[col1, col2] = cramers_corrected_stat(df_crosstab)\n    \n    # Flip and add to get full correlation matrix\n    corr_matrix += np.tril(corr_matrix, k=-1).T\n    return corr_matrix","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15, 10))\nsns.heatmap(categorical_corr_matrix(df), annot=True, cmap='coolwarm', \n            cbar_kws={'aspect': 50}, square=True, ax=ax)\nplt.xticks(rotation=30, ha='right');\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"***Inference:*** There is a very high correlation (0.97) between the `color` of a mushroom and whether it is poisonous or not. This means we can correctly predict the class for almost 97% of the samples using just the `color` feature.","execution_count":null},{"metadata":{"Collapsed":"false","toc-hr-collapsed":true,"toc-nb-collapsed":true},"cell_type":"markdown","source":"<a id=\"data-visualization\"></a>\n# 3. Data Visualization","execution_count":null},{"metadata":{"Collapsed":"true"},"cell_type":"markdown","source":"<a id=\"frequency-distribution\"></a>\n## 3.1. Frequency distribution","execution_count":null},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(nrows=8, ncols=3, figsize=(15, 20))\nax_title_pairs = zip(axs.flat, list(df.columns))\n\nfor ax, title in ax_title_pairs:\n    sns.countplot(x=title, data=df, palette='Pastel2', ax=ax)\n    ax.set_title(title.title())\n    ax.set_xticklabels(ax.get_xticklabels(), rotation=30)\n    ax.set_xlabel('')\n\naxs[7][1].set_axis_off()\naxs[7][2].set_axis_off()\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"***Inference:*** The dataset is almost balanced.","execution_count":null},{"metadata":{"Collapsed":"true"},"cell_type":"markdown","source":"<a id=\"distribution-among-different-habitat\"></a>\n## 3.2. Distribution among different habitat","execution_count":null},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"display(pd.crosstab(df['class'], df['habitat'], dropna=False))\nsns.countplot(x='class', hue='habitat', data=df, palette='Pastel2')\n\n# Put the legend out of the figure\nplt.legend(title='Habitat', bbox_to_anchor=(1, 1))","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"true"},"cell_type":"markdown","source":"<a id=\"distribution-among-different-populations-types\"></a>\n## 3.3. Distribution among different populations types","execution_count":null},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"display(pd.crosstab(df['class'], df['population'], dropna=False))\nsns.countplot(x='class', hue='population', data=df, palette='Pastel2')\n\n# Put the legend out of the figure\nplt.legend(title='population', bbox_to_anchor=(1, 1))","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"true"},"cell_type":"markdown","source":"<a id=\"distribution-among-different-habitat-and-population-types-taken-together\"></a>\n## 3.4. Distribution among different habitat and population types taken together\nModifying seaborn countplot make it work with FacetGrid when all 3 arguments (`hue`, `row`, and `col`) are used.","execution_count":null},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"def modified_countplot(**kargs):\n    \"\"\"\n        Assumes that columns to be plotted are in of pandas dtype='CategoricalDtype'\n    \"\"\"\n    facet_gen = kargs['facet_generator']    ## Facet generator over facet data\n    curr_facet, facet_data = None, None\n    \n    while True:\n        ## Keep yielding until non-empty dataframe is found\n        curr_facet = next(facet_gen)            ## Yielding facet genenrator\n        df_rows = curr_facet[1].shape[0]\n        \n        ## Skip the current facet if its corresponding dataframe empty\n        if df_rows:\n            facet_data = curr_facet[1]\n            break\n    \n    x_hue = (kargs.get('x'), kargs.get('hue'))\n    cols = [col for col in x_hue if col]\n    col_categories = [facet_data[col].dtype.categories if col else None for col in x_hue]\n    \n    palette = kargs['palette'] if 'palette' in kargs.keys() else 'Pastel2'\n    sns.countplot(x=cols[0], hue=x_hue[1], \n                  order=col_categories[0], hue_order=col_categories[1],\n                  data=facet_data.loc[:, cols], palette=palette)","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"facet = sns.FacetGrid(df, row='habitat', col='class', \n                      sharex=False, sharey=False, margin_titles=True)\nfacet.map(modified_countplot, x='population',\n          palette='Pastel2', facet_generator=facet.facet_data())\nfacet.set_xlabels('Population')\nfacet.set_ylabels('Count')\nfacet.set_xticklabels(df['population'].dtype.categories, rotation=30)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"<a id=\"data-preprocessing\"></a>\n# 4. Data Preprocessing\nData needs to be one-hot-encoded before applying machine learning models.","execution_count":null},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"x = df.iloc[:, :-1]\ny = df['class']\n\nfeature_names = list(x.select_dtypes(include='category').columns)","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"<a id=\"train-test-split\"></a>\n## 4.1. Train-Test split\nCatBoost classifier does not require any knd of preprocessing while Naive bayes requires a different kind of preprocesing. Therefore, we will use raw/ unmodified data (`x_train_cat, x_test_cat, y_train_cat, y_test_cat`) for CatBoost and preprocessed data (`x_train, x_test, y_train, y_test`) for all other classifiers. For Naive Bayes, we will use the raw data (`x_train_cat, x_test_cat, y_train_cat, y_test_cat`) and preprocess it as required in the Naive Bayes section.","execution_count":null},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndata_splits = train_test_split(x, y, test_size=0.25, random_state=0,\n                               shuffle=True, stratify=y)\nx_train, x_test, y_train, y_test = data_splits\n\n# For CatBoost and Naive Bayes\ndata_splits = train_test_split(x, y, test_size=0.25, random_state=0,\n                               shuffle=True, stratify=y)\nx_train_cat, x_test_cat, y_train_cat, y_test_cat = data_splits\n\nlist(map(lambda x: x.shape, [x, y, x_train, x_test, y_train, y_test]))","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"pd.Series(y_test).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"sns.countplot(x=y_test)","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"<a id=\"one-hot-encoding\"></a>\n## 4.2. One-hot Encoding","execution_count":null},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n\n## Column Transformer\nx_trans = ColumnTransformer([('one_hot_encoder',\n                              OneHotEncoder(drop='first',dtype='int'),\n                              feature_names)],\n                            remainder='passthrough')\n\nx_train = x_trans.fit_transform(x_train)\nx_test = x_trans.transform(x_test)\n\n## Save feature names after one-hot encoding for feature importances plots\nfeature_names = list(x_trans.named_transformers_['one_hot_encoder'] \\\n                            .get_feature_names(input_features=feature_names))\n\n## Label encoder\ny_trans = LabelEncoder()\ny_train = y_trans.fit_transform(y_train)\ny_test = y_trans.transform(y_test)\n\ny_trans.transform(['poisonous', 'edible'])","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"<a id=\"data-modeling\"></a>\n# 5. Data Modeling\nSince the dataset is imbalanced we will be using class-weighted/ cost-sensitive learning. In cost-sensitive learning, a weighted cost function is used. Therefore, misclassifying a sample from the minority class will cost the classifiers more than misclassifying a sample from the majority class. In most of the Sklearn classifiers, cost-sensitive learning can be enabled by setting `class_weight='balanced'`.","execution_count":null},{"metadata":{"Collapsed":"false","toc-hr-collapsed":true,"toc-nb-collapsed":true},"cell_type":"markdown","source":"<a id=\"utility-functions\"></a>\n## 5.1. Utility Functions","execution_count":null},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"import timeit\nimport pickle\nimport sys\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, \\\n                            precision_recall_curve, roc_curve, accuracy_score\nfrom sklearn.exceptions import NotFittedError","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"def confusion_plot(matrix, labels=None):\n    \"\"\" Display binary confusion matrix as a Seaborn heatmap \"\"\"\n    \n    labels = labels if labels else ['Negative (0)', 'Positive (1)']\n    \n    fig, ax = plt.subplots(nrows=1, ncols=1)\n    sns.heatmap(data=matrix, cmap='Blues', annot=True, fmt='d',\n                xticklabels=labels, yticklabels=labels, ax=ax)\n    ax.set_xlabel('PREDICTED')\n    ax.set_ylabel('ACTUAL')\n    ax.set_title('Confusion Matrix')\n    plt.close()\n    \n    return fig","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"def roc_plot(y_true, y_probs, label, compare=False, ax=None):\n    \"\"\" Plot Receiver Operating Characteristic (ROC) curve \n        Set `compare=True` to use this function to compare classifiers. \"\"\"\n    \n    fpr, tpr, thresh = roc_curve(y_true, y_probs, drop_intermediate=False)\n    auc = round(roc_auc_score(y_true, y_probs), 2)\n    \n    fig, axis = (None, ax) if ax else plt.subplots(nrows=1, ncols=1)\n    label = ' '.join([label, f'({auc})']) if compare else None\n    sns.lineplot(x=fpr, y=tpr, ax=axis, label=label)\n    \n    if compare:\n        axis.legend(title='Classifier (AUC)', loc='lower right')\n    else:\n        axis.text(0.72, 0.05, f'AUC = { auc }', fontsize=12,\n                  bbox=dict(facecolor='green', alpha=0.4, pad=5))\n            \n        # Plot No-Info classifier\n        axis.fill_between(fpr, fpr, tpr, alpha=0.3, edgecolor='g',\n                          linestyle='--', linewidth=2)\n        \n    axis.set_xlim(0, 1)\n    axis.set_ylim(0, 1)\n    axis.set_title('ROC Curve')\n    axis.set_xlabel('False Positive Rate [FPR]\\n(1 - Specificity)')\n    axis.set_ylabel('True Positive Rate [TPR]\\n(Sensitivity or Recall)')\n    \n    plt.close()\n    \n    return axis if ax else fig","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"def precision_recall_plot(y_true, y_probs, label, compare=False, ax=None):\n    \"\"\" Plot Precision-Recall curve.\n        Set `compare=True` to use this function to compare classifiers. \"\"\"\n    \n    p, r, thresh = precision_recall_curve(y_true, y_probs)\n    p, r, thresh = list(p), list(r), list(thresh)\n    p.pop()\n    r.pop()\n    \n    fig, axis = (None, ax) if ax else plt.subplots(nrows=1, ncols=1)\n    \n    if compare:\n        sns.lineplot(r, p, ax=axis, label=label)\n        axis.set_xlabel('Recall')\n        axis.set_ylabel('Precision')\n        axis.legend(loc='lower left')\n    else:\n        sns.lineplot(thresh, p, label='Precision', ax=axis)\n        axis.set_xlabel('Threshold')\n        axis.set_ylabel('Precision')\n        axis.legend(loc='lower left')\n\n        axis_twin = axis.twinx()\n        sns.lineplot(thresh, r, color='limegreen', label='Recall', ax=axis_twin)\n        axis_twin.set_ylabel('Recall')\n        axis_twin.set_ylim(0, 1)\n        axis_twin.legend(bbox_to_anchor=(0.24, 0.18))\n    \n    axis.set_xlim(0, 1)\n    axis.set_ylim(0, 1)\n    axis.set_title('Precision Vs Recall')\n    \n    plt.close()\n    \n    return axis if ax else fig","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"def feature_importance_plot(importances, feature_labels, ax=None):\n    fig, axis = (None, ax) if ax else plt.subplots(nrows=1, ncols=1, figsize=(5, 10))\n    sns.barplot(x=importances, y=feature_labels, ax=axis)\n    axis.set_title('Feature Importance Measures')\n    \n    plt.close()\n    \n    return axis if ax else fig","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"def train_clf(clf, x_train, y_train, sample_weight=None, refit=False):\n    train_time = 0\n    \n    try:\n        if refit:\n            raise NotFittedError\n        y_pred_train = clf.predict(x_train)\n    except NotFittedError:\n        start = timeit.default_timer()\n        \n        if sample_weight is not None:\n            clf.fit(x_train, y_train, sample_weight=sample_weight)\n        else:\n            clf.fit(x_train, y_train)\n        \n        end = timeit.default_timer()\n        train_time = end - start\n        \n        y_pred_train = clf.predict(x_train)\n    \n    train_acc = accuracy_score(y_train, y_pred_train)\n    return clf, y_pred_train, train_acc, train_time","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"def model_memory_size(clf):\n    return sys.getsizeof(pickle.dumps(clf))","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"def report(clf, x_train, y_train, x_test, y_test, sample_weight=None,\n           refit=False, importance_plot=False, confusion_labels=None,\n           feature_labels=None, verbose=True):\n    \"\"\" Trains the passed classifier if not already trained and reports\n        various metrics of the trained classifier \"\"\"\n    \n    dump = dict()\n    \n    ## Train if not already trained\n    clf, train_predictions, \\\n    train_acc, train_time = train_clf(clf, x_train, y_train,\n                                                     sample_weight=sample_weight,\n                                                     refit=refit)\n    ## Testing\n    start = timeit.default_timer()\n    test_predictions = clf.predict(x_test)\n    end = timeit.default_timer()\n    test_time = end - start\n    \n    test_acc = accuracy_score(y_test, test_predictions)\n    y_probs = clf.predict_proba(x_test)[:, 1]\n    \n    roc_auc = roc_auc_score(y_test, y_probs)\n    \n    \n    ## Model Memory\n    model_mem = round(model_memory_size(clf) / 1024, 2)\n    \n    print(clf)\n    print(\"\\n=============================> TRAIN-TEST DETAILS <======================================\")\n    \n    ## Metrics\n    print(f\"Train Size: {x_train.shape[0]} samples\")\n    print(f\" Test Size: {x_test.shape[0]} samples\")\n    print(\"------------------------------------------\")\n    print(f\"Training Time: {round(train_time, 3)} seconds\")\n    print(f\" Testing Time: {round(test_time, 3)} seconds\")\n    print(\"------------------------------------------\")\n    print(\"Train Accuracy: \", train_acc)\n    print(\" Test Accuracy: \", test_acc)\n    print(\"------------------------------------------\")\n    print(\" Area Under ROC: \", roc_auc)\n    print(\"------------------------------------------\")\n    print(f\"Model Memory Size: {model_mem} kB\")\n    print(\"\\n=============================> CLASSIFICATION REPORT <===================================\")\n    \n    ## Classification Report\n    clf_rep = classification_report(y_test, test_predictions, output_dict=True)\n    \n    print(classification_report(y_test, test_predictions,\n                                target_names=confusion_labels))\n    \n    \n    if verbose:\n        print(\"\\n================================> CONFUSION MATRIX <=====================================\")\n    \n        ## Confusion Matrix HeatMap\n        display(confusion_plot(confusion_matrix(y_test, test_predictions),\n                               labels=confusion_labels))\n        print(\"\\n=======================================> PLOTS <=========================================\")\n\n\n        ## Variable importance plot\n        fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(14, 10))\n        roc_axes = axes[0, 0]\n        pr_axes = axes[0, 1]\n        importances = None\n\n        if importance_plot:\n            if not feature_labels:\n                raise RuntimeError(\"'feature_labels' argument not passed \"\n                                   \"when 'importance_plot' is True\")\n\n            try:\n                importances = pd.Series(clf.feature_importances_,\n                                        index=feature_labels) \\\n                                .sort_values(ascending=False)\n            except AttributeError:\n                try:\n                    importances = pd.Series(clf.coef_.ravel(),\n                                            index=feature_labels) \\\n                                    .sort_values(ascending=False)\n                except AttributeError:\n                    pass\n\n            if importances is not None:\n                # Modifying grid\n                grid_spec = axes[0, 0].get_gridspec()\n                for ax in axes[:, 0]:\n                    ax.remove()   # remove first column axes\n                large_axs = fig.add_subplot(grid_spec[0:, 0])\n\n                # Plot importance curve\n                feature_importance_plot(importances=importances.values,\n                                        feature_labels=importances.index,\n                                        ax=large_axs)\n                large_axs.axvline(x=0)\n\n                # Axis for ROC and PR curve\n                roc_axes = axes[0, 1]\n                pr_axes = axes[1, 1]\n            else:\n                # remove second row axes\n                for ax in axes[1, :]:\n                    ax.remove()\n        else:\n            # remove second row axes\n            for ax in axes[1, :]:\n                ax.remove()\n\n\n        ## ROC and Precision-Recall curves\n        clf_name = clf.__class__.__name__\n        roc_plot(y_test, y_probs, clf_name, ax=roc_axes)\n        precision_recall_plot(y_test, y_probs, clf_name, ax=pr_axes)\n\n        fig.subplots_adjust(wspace=5)\n        fig.tight_layout()\n        display(fig)\n    \n    ## Dump to report_dict\n    dump = dict(clf=clf, train_acc=train_acc, train_time=train_time,\n                train_predictions=train_predictions, test_acc=test_acc,\n                test_time=test_time, test_predictions=test_predictions,\n                test_probs=y_probs, report=clf_rep, roc_auc=roc_auc,\n                model_memory=model_mem)\n    \n    return clf, dump","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"def compare_models(y_test=None, clf_reports=[], labels=[]):\n    \"\"\" Compare evaluation metrics for the True Positive class [1] of \n        binary classifiers passed in the argument and plot ROC and PR curves.\n        \n        Arguments:\n        ---------\n        y_test: to plot ROC and Precision-Recall curves\n        \n        Returns:\n        -------\n        compare_table: pandas DataFrame containing evaluated metrics\n                  fig: `matplotlib` figure object with ROC and PR curves \"\"\"\n\n    \n    ## Classifier Labels\n    default_names = [rep['clf'].__class__.__name__ for rep in clf_reports]\n    clf_names =  labels if len(labels) == len(clf_reports) else default_names\n    \n    \n    ## Compare Table\n    table = dict()\n    index = ['Train Accuracy', 'Test Accuracy', 'Overfitting', 'ROC Area',\n             'Precision', 'Recall', 'F1-score', 'Support']\n    for i in range(len(clf_reports)):\n        train_acc = round(clf_reports[i]['train_acc'], 3)\n        test_acc = round(clf_reports[i]['test_acc'], 3)\n        clf_probs = clf_reports[i]['test_probs']\n        roc_auc = clf_reports[i]['roc_auc']\n        \n        # Get metrics of True Positive class from sklearn classification_report\n        true_positive_metrics = list(clf_reports[i]['report'][\"1\"].values())\n        \n        table[clf_names[i]] = [train_acc, test_acc,\n                               test_acc < train_acc, roc_auc] + true_positive_metrics\n    \n    table = pd.DataFrame(data=table, index=index)\n    \n    \n    ## Compare Plots\n    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n    \n    # ROC and Precision-Recall\n    for i in range(len(clf_reports)):\n        clf_probs = clf_reports[i]['test_probs']\n        roc_plot(y_test, clf_probs, label=clf_names[i],\n                 compare=True, ax=axes[0])\n        precision_recall_plot(y_test, clf_probs, label=clf_names[i],\n                              compare=True, ax=axes[1])\n    # Plot No-Info classifier\n    axes[0].plot([0,1], [0,1], linestyle='--', color='green')\n        \n    fig.tight_layout()\n    plt.close()\n    \n    return table.T, fig","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"naive-bayes\"></a>\n## 5.2. Naive Bayes\nThe fundamental assumption made by Naive Bayes regarding the data is ***class conditional independence of features***. Sklearn provides different variants of Naive Bayes depending on whether the features follow a categorical distribution (CategoricalNB), normal distribution (GaussianNB), bernoulli distribution (BernoulliNB), multinomial distribution (MultinomialNB).\n\nSince majority of the features are categorical and follow a categorical distribution, we will use CategoricalNB. Continuous features will be discretized.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import CategoricalNB, GaussianNB \nfrom sklearn.preprocessing import KBinsDiscretizer, OrdinalEncoder\n\nconfusion_lbs = ['Edible', 'Poisonous']\n\nnb_trans = [('ordinal', OrdinalEncoder(dtype=np.int64),\n             list(x_train_cat.columns))]\nnb_col_trans = ColumnTransformer(nb_trans, remainder='passthrough')\n\n## Applying Column Transformer\nx_train_nb = nb_col_trans.fit_transform(x_train_cat)\nx_test_nb = nb_col_trans.transform(x_test_cat)\n\nnb_clf = CategoricalNB()\n\nnb_clf, nb_report = report(nb_clf, x_train_nb, y_train,\n                           x_test_nb, y_test, refit=True,\n                           confusion_labels=confusion_lbs)","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"<a id=\"logistic-regression\"></a>\n## 5.3. Logistic Regression","execution_count":null},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegressionCV\nfrom sklearn.model_selection import GridSearchCV\n\nconfusion_lbs = ['Edible', 'Poisonous']\n\nlogit_cv = LogisticRegressionCV(class_weight='balanced', cv=5,\n                                penalty='l2', random_state=0,\n                                n_jobs=-1, refit=True,\n                                scoring='f1', solver='liblinear')\n\nlogit_cv, logit_report = report(logit_cv, x_train, y_train,\n                                x_test, y_test,\n                                importance_plot=True,\n                                feature_labels=feature_names,\n                                confusion_labels=confusion_lbs)","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"<a id=\"k-nearest-neighbors\"></a>\n## 5.4. K-Nearest Neighbors","execution_count":null},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(metric='minkowski', n_neighbors=69,\n                           p=1, weights='distance', n_jobs=-1)\n\nknn, knn_report = report(knn, x_train, y_train,\n                         x_test, y_test,\n                         importance_plot=True,\n                         feature_labels=feature_names,\n                         confusion_labels=confusion_lbs)","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"<a id=\"decision-tree\"></a>\n## 5.5. Decision Tree","execution_count":null},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\ndecision_tree = DecisionTreeClassifier(ccp_alpha=0.0, class_weight='balanced',\n                                       criterion='entropy', max_depth=4,\n                                       random_state=0)\n\ndecision_tree, decision_tree_report = report(decision_tree, x_train, y_train,\n                                             x_test, y_test,\n                                             importance_plot=True,\n                                             feature_labels=feature_names,\n                                             confusion_labels=confusion_lbs)","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"<a id=\"decision-trees-with-bagging\"></a>\n## 5.6. Decision Trees with Bagging","execution_count":null},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"from sklearn.ensemble import BaggingClassifier\n\nbagging_dtree = DecisionTreeClassifier(ccp_alpha=0.0, class_weight='balanced',\n                                       criterion='entropy', max_depth=5,\n                                       random_state=0)\n\nbagging_clf = BaggingClassifier(base_estimator=bagging_dtree,\n                                max_samples=0.05, n_estimators=110, n_jobs=-1,\n                                random_state=0)\n\nbagging_clf, bagging_clf_report = report(bagging_clf, x_train, y_train,\n                                         x_test, y_test,\n                                         feature_labels=feature_names,\n                                         confusion_labels=confusion_lbs)","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"<a id=\"random-forests\"></a>\n## 5.7. Random Forests","execution_count":null},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrandom_forest = RandomForestClassifier(class_weight='balanced', criterion='entropy',\n                                       max_depth=8, max_samples=0.7,\n                                       n_estimators=230,\n                                       n_jobs=-1, random_state=0)\n\nrandom_forest, random_forest_report = report(random_forest, x_train, y_train,\n                                             x_test, y_test,\n                                             importance_plot=True,\n                                             feature_labels=feature_names,\n                                             confusion_labels=confusion_lbs)","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"<a id=\"decision-trees-with-adaboost\"></a>\n## 5.8. Decision Trees with AdaBoost\nThe default base estimator for `AdaBoostClassifier` is `DecisionTreeClassifier(max_depth=1)`","execution_count":null},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\n\nboosting_dtree = DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n                                        max_depth=1, random_state=0)\nadaboot = AdaBoostClassifier(base_estimator=boosting_dtree,\n                             n_estimators=390, learning_rate=0.095,\n                             random_state=0)\n\nadaboot, adaboot_report = report(adaboot, x_train, y_train,\n                                 x_test, y_test,\n                                 importance_plot=True,\n                                 feature_labels=feature_names,\n                                 confusion_labels=confusion_lbs)","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"<a id=\"linear-svc\"></a>\n## 5.9. Linear SVC","execution_count":null},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\nlinear_svc = SVC(kernel='linear', probability=True,\n                 class_weight='balanced', random_state=0)\n\nlinear_svc, linear_svc_report = report(linear_svc, x_train, y_train,\n                                       x_test, y_test,\n                                       importance_plot=True,\n                                       feature_labels=feature_names,\n                                       confusion_labels=confusion_lbs)","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"<a id=\"svm-with-rbf-kernel\"></a>\n## 5.10. SVM with RBF kernel","execution_count":null},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"rbf_svc = SVC(kernel='rbf', probability=True, class_weight='balanced', random_state=0)\n\nrbf_svc, rbf_svc_report = report(rbf_svc, x_train, y_train,\n                                 x_test, y_test,\n                                 importance_plot=True,\n                                 feature_labels=feature_names,\n                                 confusion_labels=confusion_lbs)","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"<a id=\"xgboost\"></a>\n## 5.11. XGBoost","execution_count":null},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn.utils import class_weight\n\ncls_weight = (y_train.shape[0] - np.sum(y_train)) / np.sum(y_train)\n\nxgb_clf = XGBClassifier(learning_rate=0.01, random_state=0,\n                        scale_pos_weight=cls_weight, n_jobs=-1)\nxgb_clf.fit(x_train, y_train)\n\nxgb_clf, xgb_report = report(xgb_clf, x_train, y_train,\n                             x_test, y_test,\n                             importance_plot=True,\n                             feature_labels=feature_names,\n                             confusion_labels=confusion_lbs)","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"<a id=\"catboost\"></a>\n## 5.12. CatBoost\nCat boost performs better without One-hot encoding because it performs an internal categorical encoding that is similar to Leave One Out Encoding (LOOE). So, we can give the dataframe as input to the catboost classifier.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost import CatBoostClassifier\n\ncat_feature_lbs = list(x_train_cat.columns)\n\ncatboost_clf = CatBoostClassifier(cat_features=cat_feature_lbs,\n                                  l2_leaf_reg=120, depth=6,\n                                  auto_class_weights='Balanced',\n                                  iterations=200, learning_rate=0.16,\n                                  use_best_model=True,\n                                  early_stopping_rounds=150,\n                                  eval_metric='F1', random_state=0)\n\ncatboost_clf.fit(x_train_cat, y_train, \n                 eval_set=(x_train_cat, y_train),\n                 verbose=False)\n\ncatboost_clf, catboost_report = report(catboost_clf, x_train_cat, y_train,\n                                       x_test_cat, y_test,\n                                       importance_plot=True,\n                                       feature_labels=cat_feature_lbs,\n                                       confusion_labels=confusion_lbs)","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"true"},"cell_type":"markdown","source":"<a id=\"model-comparison\"></a>\n# 6. Model Comparison\nSince input data format for Naive Bayes and CatBoost are different, we will add them to the comparison manually.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"report_list = [nb_report, logit_report, knn_report, decision_tree_report,               \n               bagging_clf_report, random_forest_report, adaboot_report,\n               xgb_report, linear_svc_report, rbf_svc_report, catboost_report]\nclf_labels = [rep['clf'].__class__.__name__ for rep in report_list]\nclf_labels[-3], clf_labels[-2] = 'Linear SVC', 'RBF SVC'","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","toc-hr-collapsed":true,"toc-nb-collapsed":true},"cell_type":"markdown","source":"<a id=\"evaluation-metrics\"></a>\n## 6.1. Evaluation Metrics","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"compare_table, compare_plot = compare_models(y_test, clf_reports=report_list, labels=clf_labels)\n\ncompare_table.sort_values(by=['Overfitting', 'F1-score'],\n                          ascending=[True, False])","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","toc-hr-collapsed":true,"toc-nb-collapsed":true},"cell_type":"markdown","source":"<a id=\"roc-and-pr-curves\"></a>\n## 6.2. ROC and PR Curves","execution_count":null},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"compare_plot","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Thank You!!***","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}