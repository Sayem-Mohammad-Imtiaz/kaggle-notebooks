{"cells":[{"metadata":{"trusted":false},"cell_type":"code","source":"#Importing libraries\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom string import punctuation\nfrom nltk.corpus import stopwords, wordnet\nfrom nltk import pos_tag\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize,sent_tokenize\nfrom wordcloud import WordCloud\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression,SGDClassifier, LinearRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import SVC\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df = pd.read_csv('C:/Users/PUKHRAJ/Desktop/INTERNSHIPS/Datasets/Corona_NLP_train.csv',encoding='latin-1')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df1 = df.iloc[:,4:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df1","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.Sentiment.unique() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Pre-processing"},{"metadata":{"trusted":false},"cell_type":"code","source":"# making list stopwords for removing stopwords from our text \n\nstop = set(stopwords.words('english'))\nstop.update(punctuation)\nprint(stop)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# this function return the part of speech of a word.\ndef get_simple_pos(tag):\n    if tag.startswith('J'):\n        return wordnet.ADJ\n    elif tag.startswith('V'):\n        return wordnet.VERB\n    elif tag.startswith('N'):\n        return wordnet.NOUN\n    elif tag.startswith('R'):\n        return wordnet.ADV\n    else:\n        return wordnet.NOUN","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Function to clean our text.\nlemmatizer = WordNetLemmatizer()\ndef clean_review(OriginalTweet):\n    clean_text = []\n    for w in word_tokenize(OriginalTweet):\n        if w.lower() not in stop:\n            pos = pos_tag([w])\n            new_w = lemmatizer.lemmatize(w, pos=get_simple_pos(pos[0][1]))\n            clean_text.append(new_w)\n    return clean_text\n\ndef join_text(OriginalTweet):\n    return \" \".join(OriginalTweet)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df1.OriginalTweet = df1.OriginalTweet.apply(clean_review)\ndf1.OriginalTweet = df1.OriginalTweet.apply(join_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# splitting data.\nx_train,x_test,y_train,y_test = train_test_split(df1.OriginalTweet,df1.Sentiment,test_size = 0.3 , random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"x_train.shape, y_train.shape, x_test.shape, y_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Visualization"},{"metadata":{"trusted":false},"cell_type":"code","source":"pos = x_train[y_train[y_train=='Positive'].index]\nex_pos = x_train[y_train[y_train=='Extremely Positive'].index]\nneg = x_train[y_train[y_train=='Negative'].index]\nex_neg = x_train[y_train[y_train=='Extremely Negative'].index]\nneutral = x_train[y_train[y_train=='Neutral'].index]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize = (18,24)) # Text Reviews with positive Ratings\nwordcloud = WordCloud(min_font_size = 3,  max_words = 2500 , width = 1200 , height = 800).generate(\" \".join(pos))\nplt.imshow(wordcloud,interpolation = 'bilinear')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize = (18,24)) # Text Reviews with extreame positive Ratings\nwordcloud = WordCloud(min_font_size = 3,  max_words = 2500 , width = 1200 , height = 800).generate(\" \".join(ex_pos))\nplt.imshow(wordcloud,interpolation = 'bilinear')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize = (18,24)) # Text Reviews with negative Ratings\nwordcloud = WordCloud(min_font_size = 3,  max_words = 2500 , width = 1200 , height = 800).generate(\" \".join(neg))\nplt.imshow(wordcloud,interpolation = 'bilinear')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize = (18,24)) # Text Reviews with Extreame negative Ratings\nwordcloud = WordCloud(min_font_size = 3,  max_words = 2500 , width = 1200 , height = 800).generate(\" \".join(ex_neg))\nplt.imshow(wordcloud,interpolation = 'bilinear')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize = (18,24)) # Text Reviews with neutral Ratings\nwordcloud = WordCloud(min_font_size = 3,  max_words = 2500 , width = 1200 , height = 800).generate(\" \".join(neutral))\nplt.imshow(wordcloud,interpolation = 'bilinear')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### From above plots we can see few words like company and http are common to all five sentiments so we should remove these from our texts as they dont provide any information."},{"metadata":{"trusted":false},"cell_type":"code","source":"# creating a variable for count vectorizer which gives us features using the whole text of data.\ncount_vec = CountVectorizer(max_features=4000, ngram_range=(1,2), max_df=0.9, min_df=0)\n# max_df insures to remove most frequent words as we discussed earlier.\n# ngram_range is used to select words at a time like 1 or 2 like if a sentence have 'not happy' in text then it can mean two things if we pick the word 'happy' and pick the words 'not happy' both.","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"x_train_features = count_vec.fit_transform(x_train).todense()\nx_test_features = count_vec.transform(x_test).todense()\nx_train_features.shape, x_test_features.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prediction"},{"metadata":{},"cell_type":"markdown","source":"### 1.Logistic Regression"},{"metadata":{"trusted":false},"cell_type":"code","source":"lr = LogisticRegression()\nlr.fit(x_train_features, y_train)\ny_pred = lr.predict(x_test_features)\nprint(accuracy_score(y_test,y_pred)*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Multinomial NaiveBayes"},{"metadata":{"trusted":false},"cell_type":"code","source":"nb_clf = MultinomialNB()\nnb_clf.fit(x_train_features, y_train)\ny_pred = nb_clf.predict(x_test_features)\nprint(accuracy_score(y_test,y_pred)*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Random Forest"},{"metadata":{"trusted":false},"cell_type":"code","source":"\nfrom sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier(n_estimators=100)\nmodel = model.fit(x_train_features,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom sklearn import metrics\n\ny_pred = model.predict(x_test_features)\n\ncm = confusion_matrix(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(\"Classification Report:\");print(metrics.classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}