{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"'''import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2\n\nimport os\n\nimgs = []\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        pth = os.path.join(dirname, filename)\n        if 'test' in filename or 'extra-image' in filename:\n            imgs.append(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\ndf = pd.DataFrame(imgs,columns = ['path'])'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''import cv2\n\ndf['shape'] = df.path.apply(lambda x:cv2.imread(x).shape)'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''df['use'] = df['shape'].apply(lambda x:x[0]>=500 and x[1] >= 500)'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df= df[df['use']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv('../input/cassava-leaf-disease-merged/merged.csv')\ndf['path'] = '../input/cassava-leaf-disease-merged/train/'+df['image_id']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-30T15:32:49.204025Z","iopub.status.busy":"2021-01-30T15:32:49.200079Z","iopub.status.idle":"2021-01-30T15:32:53.384946Z","shell.execute_reply":"2021-01-30T15:32:53.383924Z"},"papermill":{"duration":4.205901,"end_time":"2021-01-30T15:32:53.385059","exception":false,"start_time":"2021-01-30T15:32:49.179158","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"from PIL import Image\nfrom albumentations.core.composition import Compose\nfrom albumentations.pytorch import ToTensorV2\nfrom collections import defaultdict, deque\n# from efficientnet_pytorch import EfficientNet\nfrom pytorch_lightning import Callback\nfrom pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\nfrom sklearn import metrics\nfrom sklearn.model_selection import StratifiedKFold\nfrom torch import nn\nfrom torch.autograd import Variable\n\n\n\n\nfrom torch.utils.data import Dataset, TensorDataset, DataLoader\nfrom torchvision.transforms import functional as F\nfrom typing import Any, Dict, List, Union, Optional\nimport albumentations as A\nimport ast\nimport collections\nimport copy\nimport cv2\nimport datetime\nimport importlib\nimport json\nimport math\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport pandas as pd\nimport pickle\n# import pretrainedmodels\nimport pytorch_lightning as pl\n%matplotlib inline\nimport random\nimport seaborn as sns\nimport shutil\nimport tempfile\nimport time\nimport torch\nimport torch.distributed as dist\nimport torch.nn.functional as F\nimport torch.utils.data\nimport pandas as pd\nimport torchvision\nfrom tqdm.notebook import tqdm\nsns.set_style('darkgrid')\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\npath = '/kaggle/input/cassava-leaf-disease-classification/'","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-30T15:32:53.414263Z","iopub.status.busy":"2021-01-30T15:32:53.413079Z","iopub.status.idle":"2021-01-30T15:32:53.415551Z","shell.execute_reply":"2021-01-30T15:32:53.415985Z"},"papermill":{"duration":0.022223,"end_time":"2021-01-30T15:32:53.416087","exception":false,"start_time":"2021-01-30T15:32:53.393864","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"hparams ={}\nhparams['sizes'] = [384]\nhparams['path'] = ['../input/one-more-time/epoch20-metric0.8932.ckpt'\n                   ]\nhparams['aug'] = A.Compose([\n\n    A.CenterCrop(500,500),\n    A.Resize(height=hparams['sizes'][0], width=hparams['sizes'][0], p=1.0),\n    A.Normalize(),\n    ToTensorV2(),\n])\n\n#'../input/leafclassification-modificated-size-cfe02b/model/last.ckpt'","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.execute_input":"2021-01-30T15:32:53.446245Z","iopub.status.busy":"2021-01-30T15:32:53.445508Z","iopub.status.idle":"2021-01-30T15:32:53.448472Z","shell.execute_reply":"2021-01-30T15:32:53.448042Z"},"papermill":{"duration":0.023751,"end_time":"2021-01-30T15:32:53.448555","exception":false,"start_time":"2021-01-30T15:32:53.424804","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"class ImageClassificationDataset(Dataset):\n    def __init__(\n        self,\n        image_names,\n        aug: Compose,\n        labels: Optional[List[int]],\n        img_path: str = '',\n        mode: str = 'train',\n        labels_to_ohe: bool = False,\n        n_classes: int = 5,\n    ):\n        \"\"\"\n        Image classification dataset.\n\n        Args:\n            df: dataframe with image id and bboxes\n            mode: train/val/test\n            img_path: path to images\n            transforms: albumentations\n        \"\"\"\n        self.df = image_names\n        self.mode = mode\n        self.aug = aug\n        self.img_path = img_path\n        self.image_names = image_names\n        if labels is not None:\n            if not labels_to_ohe:\n                self.labels = np.array(labels)\n            else:\n                self.labels = np.zeros((len(labels), n_classes))\n                self.labels[np.arange(len(labels)), np.array(labels)] = 1\n\n    def __getitem__(self, idx: int) -> Dict[str, np.array]:\n        image_path = self.df.loc[idx]['path']#self.img_path + self.image_names[idx]\n        '''image = cv2.imread(f'{image_path}', cv2.IMREAD_COLOR)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)'''\n        image = cv2.imread(f'{image_path}')[:,:,::-1]\n        if image is None:\n            raise FileNotFoundError(image_path)\n        target = self.labels[idx]\n\n        img = self.aug(image=image)['image']\n        sample = {'image_path': image_path, 'image': img, 'target': np.array(target).astype('int64'),'shape':(image.shape[0],image.shape[1])}\n\n        return sample\n\n    def __len__(self) -> int:\n        return len(self.image_names)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-30T15:32:53.479754Z","iopub.status.busy":"2021-01-30T15:32:53.479048Z","iopub.status.idle":"2021-01-30T15:32:53.481896Z","shell.execute_reply":"2021-01-30T15:32:53.481357Z"},"papermill":{"duration":0.024406,"end_time":"2021-01-30T15:32:53.481989","exception":false,"start_time":"2021-01-30T15:32:53.457583","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import torchvision\nclass ModelCassava(nn.Module):\n\n    def __init__(self):\n        super().__init__()\n\n        model = torchvision.models.resnext50_32x4d(pretrained=False)#.children()))[:-1]\n       \n        self.start = nn.Sequential(*[model.conv1,model.bn1,model.relu,model.maxpool])\n        self.layer1 = model.layer1\n        self.layer2 = model.layer2\n        self.layer3 = model.layer3\n        self.layer4 = model.layer4\n        self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n        \n        self.out1 = nn.Linear(1024,5)\n        self.out2 = nn.Linear(2048,5)\n    def forward(self,image):\n        \n        out0 = self.layer3(self.layer2(self.layer1(self.start(image))))\n        out1 = self.out1(self.avg_pool(out0).squeeze(2).squeeze(2))\n        out2 = self.out2(self.avg_pool(self.layer4(out0)).squeeze(2).squeeze(2))\n        \n        #loss = (self.config.loss(out1, y) + self.config.loss(out2, y))/2\n        \n        y_hat = (out1.softmax(axis=1) + out2.softmax(axis=1))/2\n        return y_hat\n   \nimport torch\nimport pytorch_lightning as pl\n\nclass Model(pl.LightningModule):\n    def __init__(self,model):\n        super().__init__()\n        self.loss = F.cross_entropy#LabelSmoothSoftmaxCEV1()\n        self.model = model\n    def forward(self, x):\n        return self.model(x)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-30T15:32:53.505817Z","iopub.status.busy":"2021-01-30T15:32:53.505298Z","iopub.status.idle":"2021-01-30T15:32:53.526663Z","shell.execute_reply":"2021-01-30T15:32:53.526212Z"},"papermill":{"duration":0.036292,"end_time":"2021-01-30T15:32:53.526756","exception":false,"start_time":"2021-01-30T15:32:53.490464","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"df.drop([21419, 21697, 21743, 21932, 21982, 22036, 22125, 22308, 22832,\n            22850, 23219, 24104, 24496, 24592, 24897, 24959, 25080, 25270,\n            25319, 25510, 25771, 25882, 25898, 25964, 25988, 26274, 26301],inplace=True)\ndf = df.reset_index(drop=True)\nsub =df\n\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-30T15:32:53.550166Z","iopub.status.busy":"2021-01-30T15:32:53.549419Z","iopub.status.idle":"2021-01-30T15:32:53.552328Z","shell.execute_reply":"2021-01-30T15:32:53.551868Z"},"papermill":{"duration":0.016718,"end_time":"2021-01-30T15:32:53.552407","exception":false,"start_time":"2021-01-30T15:32:53.535689","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"\nvalid_augs = hparams['aug']\ntest_dataset = ImageClassificationDataset(image_names=df,\n                                                        aug=valid_augs,\n                                                        labels=df['label'].values,\n                                                        img_path='',\n                                                        mode='test',\n                                                        labels_to_ohe=False,\n                                                        n_classes=5)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lit_model = Model(ModelCassava())   \n\nlit_model.load_state_dict(torch.load(hparams['path'][0])['state_dict'])\nlit_model.net = lit_model.model.eval().to(torch.device('cuda'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef get_spm(input,target,conf,model):\n\n    imgsize = (conf.cropsize,conf.cropsize)\n    bs = input.size(0)\n    with torch.no_grad():\n        output,fms,_ = model(input)\n        if 'inception' in conf.netname:\n            clsw = model.module.fc\n        else:\n            clsw = model.module.classifier\n        weight = clsw.weight.data\n        bias = clsw.bias.data\n        weight = weight.view(weight.size(0),weight.size(1),1,1)\n        fms = F.relu(fms)\n        poolfea = F.adaptive_avg_pool2d(fms,(1,1)).squeeze()\n        clslogit = F.softmax(clsw.forward(poolfea))\n        logitlist = []\n        for i in range(bs):\n            logitlist.append(clslogit[i,target[i]])\n        clslogit = torch.stack(logitlist)\n\n        out = F.conv2d(fms, weight, bias=bias)\n\n        outmaps = []\n        for i in range(bs):\n            evimap = out[i,target[i]]\n            outmaps.append(evimap)\n\n        outmaps = torch.stack(outmaps)\n        if imgsize is not None:\n            outmaps = outmaps.view(outmaps.size(0),1,outmaps.size(1),outmaps.size(2))\n            outmaps = F.interpolate(outmaps,imgsize,mode='bilinear',align_corners=False)\n\n        outmaps = outmaps.squeeze()\n\n        for i in range(bs):\n            outmaps[i] -= outmaps[i].min()\n            outmaps[i] /= outmaps[i].sum()\n\n\n    return outmaps,clslogit","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_mask(model, img, shape):\n    res=model.net.layer4(lit_model.net.layer3(lit_model.net.layer2(lit_model.net.layer1(lit_model.net.start(img.to(torch.device('cuda'))))))).sum(axis=1)[0]\n    res=F.interpolate(res.unsqueeze(0).unsqueeze(0),size=shape,mode='bilinear',align_corners=False)\n\n    res = res-res.min()\n    #res = res/res.sum()\n    return res[0][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res=extract_mask(lit_model, test_dataset[7]['image'].unsqueeze(0), (500,500))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res=res.cpu().detach().numpy()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(res)#>700)*255)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(test_dataset[7]['image'].permute(1,2,0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plt.hist(res.cpu().detach().numpy().flatten())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def crop(size1,size2):\n    width, height = size1   # Get dimensions\n    new_width, new_height = size2\n    left = (width - new_width)/2\n    top = (height - new_height)/2\n    right = (width + new_width)/2\n    bottom = (height + new_height)/2\n    return int(left),int(top),int(right),int(bottom)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataset[0]['image_path'].split('/')[-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.mkdir('masks')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.mkdir('masks_zip')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm_notebook\ni=0\nfor x in tqdm_notebook(test_dataset):\n    mask = extract_mask(lit_model, x['image'].unsqueeze(0), (500,500)).cpu().detach().numpy()\n    left,top,right,bottom = crop(x['shape'],(500,500))\n    save_img = np.zeros(x['shape'])\n    save_img[left:right,top:bottom] = mask\n    cv2.imwrite('masks/'+x['image_path'].split('/')[-1],(255*(save_img/save_img.max())).astype(np.uint8))    \n    '''if i ==2:\n        break\n    i+=1'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(save_img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('masks')[:7]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import zipfile\n\ndef zip_and_remove(path):\n    ziph = zipfile.ZipFile(f'{path}.zip', 'w', zipfile.ZIP_DEFLATED)\n    \n    for file in tqdm(os.listdir('masks')):\n            file_path = os.path.join('masks', file)\n            ziph.write(file_path)\n            os.remove(file_path)\n    \n    ziph.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"zip_and_remove('masks_zip')","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-30T15:32:53.581192Z","iopub.status.busy":"2021-01-30T15:32:53.580481Z","iopub.status.idle":"2021-01-30T15:32:53.583339Z","shell.execute_reply":"2021-01-30T15:32:53.582841Z"},"papermill":{"duration":0.021949,"end_time":"2021-01-30T15:32:53.583418","exception":false,"start_time":"2021-01-30T15:32:53.561469","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"'''def test_pred(hparams,test_dataset):\n    res = 0\n\n    for path in hparams['path']:\n        lit_model = Model(ModelCassava())   \n\n        lit_model.load_state_dict(torch.load(path)['state_dict'])\n        lit_model.net = lit_model.model.eval().to(torch.device('cuda'))\n        print('==========================')\n        for size in hparams['sizes']:\n            res_size = []\n            test_dataset.aug =  A.Compose([ A.CenterCrop(500,500),A.Resize(height=size, width=size, p=1.0),A.Normalize(),ToTensorV2()])\n            for batch in  torch.utils.data.DataLoader(\n                test_dataset,\n                batch_size=2,\n                num_workers=4,\n                shuffle=False,\n            ):\n\n                image = batch['image'].to('cuda')\n                target = batch['target'].to('cuda')\n                with torch.no_grad():\n                    outputs = lit_model.net(image)\n                    preds = outputs.softmax(axis=1).detach().cpu()\n\n                    res_size.append(preds)\n            res = res + torch.cat(res_size)\n    return res'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-30T15:32:53.617468Z","iopub.status.busy":"2021-01-30T15:32:53.616812Z","iopub.status.idle":"2021-01-30T15:33:03.312409Z","shell.execute_reply":"2021-01-30T15:33:03.311352Z"},"papermill":{"duration":9.72012,"end_time":"2021-01-30T15:33:03.312525","exception":false,"start_time":"2021-01-30T15:32:53.592405","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"#predictions = test_pred(hparams,test_dataset)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-30T15:33:03.338Z","iopub.status.busy":"2021-01-30T15:33:03.337285Z","iopub.status.idle":"2021-01-30T15:33:03.347306Z","shell.execute_reply":"2021-01-30T15:33:03.346889Z"},"papermill":{"duration":0.024856,"end_time":"2021-01-30T15:33:03.347393","exception":false,"start_time":"2021-01-30T15:33:03.322537","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"'''predictions = []\n\nfor batch in test_loader:\n\n    image = batch['image'].to('cuda')\n    target = batch['target'].to('cuda')\n    with torch.no_grad():\n        outputs = lit_model.net(image)\n        preds = outputs.argmax(1).detach().cpu().numpy()\n\n        predictions.append(preds)'''\n#sub['label'] = predictions.argmax(1)\n#sub['prob'] = predictions.max(1)[0]\n#sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sub[sub.prob>0.8].shape[0]/sub.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-30T15:33:03.371016Z","iopub.status.busy":"2021-01-30T15:33:03.370449Z","iopub.status.idle":"2021-01-30T15:33:03.517025Z","shell.execute_reply":"2021-01-30T15:33:03.516233Z"},"papermill":{"duration":0.159756,"end_time":"2021-01-30T15:33:03.517129","exception":false,"start_time":"2021-01-30T15:33:03.357373","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"#sub.to_csv('submission.csv', index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-30T15:33:03.540591Z","iopub.status.busy":"2021-01-30T15:33:03.54005Z","iopub.status.idle":"2021-01-30T15:33:03.544039Z","shell.execute_reply":"2021-01-30T15:33:03.543602Z"},"papermill":{"duration":0.016702,"end_time":"2021-01-30T15:33:03.544121","exception":false,"start_time":"2021-01-30T15:33:03.527419","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# 0.8827","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}