{"cells":[{"metadata":{"_active":false,"_uuid":"08a19c35c92e3b5abce7c16a599cee0b183903f0","_cell_guid":"501c97fd-4854-bbbd-5f8c-4c10bdd59f36"},"cell_type":"markdown","source":"# Introduction:\nThe main purpose of this notebook is to create a predictor for the punctuation feature in movie_metadata.csv\n\nThe summary is:\n\n 1. Load data and packages\n 1. Clean the database\n 1. Analysis\n\nI have considered two different tasks in the database cleaning. Reuse genre feature and extrapolate NAN's values in gross variable."},{"metadata":{"_active":false,"_uuid":"8292a3ee4cf77ad9ec42538af7fd0f6d82572edd","_cell_guid":"cd4ecfb8-d853-8adf-6d0f-775efbc4070a"},"cell_type":"markdown","source":"# 1. Load data and packages."},{"cell_type":"code","metadata":{"_execution_state":"idle","_active":false,"_uuid":"a5ff2a0d69c7b5a1d8168e472449b85f58cee897","trusted":true,"_cell_guid":"8c35c7da-4f17-e525-bd19-d9055d0eccb2"},"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","outputs":[],"execution_count":1},{"cell_type":"code","metadata":{"_execution_state":"idle","_uuid":"ae43f7a54372b93ecfed77e5204a95d38ef665cb","trusted":true,"_cell_guid":"1b54e181-0901-4fc7-9586-c3c0a0b825bb"},"source":"x = pd.read_csv('../input/movie_metadata.csv', delimiter=',')\nx=pd.DataFrame(x)#Cargamos los datos","outputs":[],"execution_count":2},{"cell_type":"code","metadata":{"_execution_state":"idle","_active":false,"_uuid":"462f8c93675a82e36d778aa2a624a2dbfc13db56","trusted":true,"_cell_guid":"34a7071b-061c-dd68-1a40-390ce9d527b6"},"source":"#Hacemos un chqeueo general para conocer qué tipo de datos tenemos.\nx.info()","outputs":[],"execution_count":3},{"metadata":{"_active":false,"_uuid":"79fdc3448d8d3dcd44212039ca73edeb3ee25c5a","_cell_guid":"2eb2e5f6-77db-6ae3-3167-440c9521c9f8"},"cell_type":"markdown","source":"##  2 Filtrar base de datos."},{"cell_type":"code","metadata":{"_execution_state":"idle","_active":false,"_uuid":"ea9a11399a8eae9dfc440406949c14fd3e11e832","trusted":false,"_cell_guid":"129b461d-09ac-0f72-72e0-9983ec03f802"},"source":"#x = x.dropna(how='any')#Eliminamos la filas con NAN'\nprint(x.shape[0])","outputs":[],"execution_count":null},{"metadata":{"_execution_state":"idle","_uuid":"21a87f9c808a050107d044d60c0936a0155cd0e6","_cell_guid":"7c3734d4-2149-4e46-b397-88b9bcd1e1d2"},"cell_type":"markdown","source":"### Aprovechamiento de la variable genero."},{"cell_type":"code","metadata":{"_execution_state":"idle","_uuid":"75e0e985870e39b610d54da0a2f0d45b74146e0c","trusted":false,"_cell_guid":"f737c7fd-ecc0-4bd6-8e60-bc5cd61f0824"},"source":"#Ahora queremos extraer información útil dela variable genres.\n#Para ello necesitamos depurar la información que aparece.\n#En primer lugar nos centramos en obtener el total de géneros que existen.\ntotal_gen=list(set(x[\"genres\"]))#Reducimos duplicados\ntotal_gen='|'.join(total_gen)#Construimos un string a partir de la lista anterior separando por'|'.\ntotal_gen= set(total_gen.split(\"|\"))#Construimos una lista, entendiendo '|' como separadores.\n#y aplicamos el conjunto para cargarnos duplicados.\ntotal_gen=list(total_gen)#Ya tenemos los diferentes generos, ahora de nuevo pasamosa lista.\n#Ahora buscamos defnir para cada film una variable para cada genero, que tome valor 1 o 0 en\n#función de si el film pertenece al genero. En primer lugar necesitamos la siguiente función.\ndef list_str_cont(x,g): #Funciona con strings, y verifica si x está contenido en g\n    return 1*(g in x)\nfor gen in total_gen: #Ahora para cada genero creamos una nueva variable como queríamos.\n    x[gen]=x[\"genres\"].apply(list_str_cont,g=gen)#Aplicamos la funcion anerior a la lista de genres\nx.drop([\"genres\"],axis=1,inplace=True)#Borramos la variable antigua","outputs":[],"execution_count":null},{"cell_type":"code","metadata":{"_execution_state":"idle","_uuid":"e982f6c838251dca797e4554498117756f2d3372","trusted":false,"_cell_guid":"da477230-e8f5-4789-bb0a-f9f11df4dc8d"},"source":"x.ix[:,-len(list(total_gen)):].head(2)#Vemos las nuveas columnas añadidas.","outputs":[],"execution_count":null},{"metadata":{"_execution_state":"idle","_uuid":"b032bf0b7e439ce94baccf2cdddc7fcc89a70e2c","_cell_guid":"578c80d9-dd2d-4dbf-b2fc-1704369036b3"},"cell_type":"markdown","source":"Extraigo aquellas nuevas variables con mayor correlación con \"imdb_score\"."},{"cell_type":"code","metadata":{"_execution_state":"idle","_uuid":"0c82c5fdec483fa2f256511cc077585605a4e6bf","trusted":false,"_cell_guid":"2dc8191c-3960-41c4-9d93-0a33e564c872"},"source":"gen_corr_mat=x.corr(method=\"pearson\")#matriz de correlación\ngen_corr=gen_corr_mat[\"imdb_score\"][-len(list(total_gen)):]#restrinjo a las ultimas variables y me quedo con imdbscore\ngen_corr_index=gen_corr.index[abs(gen_corr)>0.07]#me quedo con las de mayor correlación\nnot_gen_corr_index=[i for i in x.columns[-len(list(total_gen)):] if(i not in gen_corr_index)]\nnot_gen_corr_index#almaceno las de menor correlación para borrarlas (las borro justo antes de la fase de análisis)","outputs":[],"execution_count":null},{"metadata":{"_execution_state":"idle","_uuid":"f1027736b48d3afad2757d052f83d113d5c8d96c","_cell_guid":"a2792899-b0d7-4b1e-956a-463205b49ca0"},"cell_type":"markdown","source":"### A continuación elimino variables que considero que no son  útiles."},{"metadata":{"_execution_state":"idle","_uuid":"1978d7764fe1093cd351f467aa7023da2f1d39fe","_cell_guid":"dd9ad53d-7d46-4323-968f-07ca9a83e6e9"},"cell_type":"markdown","source":"Elimino las que no son numéricas."},{"cell_type":"code","metadata":{"_execution_state":"idle","_uuid":"a7b390e2f82d40f7c3e1fd2ca9510d834eaab8ca","trusted":false,"_cell_guid":"e7ad241c-76af-4279-a372-05e0903dfecf"},"source":"x=x.select_dtypes([np.number])#Selecionamos solo las variables que son numéricas.","outputs":[],"execution_count":null},{"cell_type":"code","metadata":{"_execution_state":"idle","_uuid":"4dcf5ccd4ab8fe2947bdea8b12044ce6a3abd795","trusted":false,"_cell_guid":"86981724-f702-430a-af07-60f884d8c605"},"source":"x.head()","outputs":[],"execution_count":null},{"metadata":{"_execution_state":"idle","_uuid":"d003fc88ba72c787bab2782e4c652185d2534153","_cell_guid":"889c3c8d-b64d-4f69-a900-adb5de4ae798"},"cell_type":"markdown","source":"Elimino aquellas que tinenen poca correlación"},{"cell_type":"code","metadata":{"_execution_state":"idle","_uuid":"411e2f84d197956c1f1eda2c25389784c0630070","trusted":false,"_cell_guid":"757e3a0e-2ce4-470e-a06c-5a2a12641eab"},"source":"x.ix[:,:-len(gen_corr_index)].columns","outputs":[],"execution_count":null},{"cell_type":"code","metadata":{"_execution_state":"idle","_uuid":"5e93dde23c1c3be62c44ab30f04b8065e344bb4d","trusted":false,"_cell_guid":"e62ddce9-f2d5-4244-a625-fb13274cf0b6"},"source":"corr_mat=x.ix[:,:-len(total_gen)].corr(method='pearson')#Hacemos la correlación con las variables iniciales.\ncorr_mat=abs(corr_mat[\"imdb_score\"]).sort_values()\nnoncorrelated_index=corr_mat[corr_mat<0.07].index#Extraemos aquellas que tienen baja correlación.\nprint(noncorrelated_index)\nx.drop(noncorrelated_index,axis=1,inplace=True)","outputs":[],"execution_count":null},{"metadata":{"_execution_state":"idle","_uuid":"3dca65ae73e8989d8038e2d0150e5aba215dc69e","_cell_guid":"af310e45-cf72-4642-9377-3b6ea9876d83"},"cell_type":"markdown","source":"## Valores NAN"},{"cell_type":"code","metadata":{"_execution_state":"idle","_uuid":"277c08febd9794969785fcf7cd0a1b767502971f","trusted":false,"_cell_guid":"f939f92d-c639-44a8-9a0a-6fec2a8ce75b"},"source":"np.sum(x.isnull())#número de nans para cada variable","outputs":[],"execution_count":null},{"cell_type":"code","metadata":{"_execution_state":"idle","_uuid":"3e554ab608b5caa27cc9717a471dd8f6428a87c6","trusted":false,"_cell_guid":"d3192d84-7a12-432d-bf2f-a0e14afb6232"},"source":"x.corr(method='pearson')[\"imdb_score\"].head()","outputs":[],"execution_count":null},{"metadata":{"_execution_state":"idle","_uuid":"e204b5e69bd237887bc1de70c2ebb92b553c302c","_cell_guid":"43a46b94-6c95-4fd1-a3a7-fc93840502f4"},"cell_type":"markdown","source":"Vemos que gross presenta una gran correlación con \"imdb_score\" y tiene muchos NAN así que vamos a tratar de extrapolarlos para poder aprovechar esta variable.\n## Extrapolación valores gross.\nLo que vamos a hace es extrapolar aquellos valores NaN de gross, utilizando el método de ML RandomForestRegressor."},{"cell_type":"code","metadata":{"_execution_state":"idle","_uuid":"758d4d30a2d3476d28afba3696ce605b3ee4b13b","trusted":false,"_cell_guid":"46d91e76-fc63-4727-86ee-0be968874bd8"},"source":"x_nnan=x.dropna(how='any')#Creamos una variable auxiliar para borrar nan's y poder montar un modelo para\n# extapolar gross","outputs":[],"execution_count":null},{"cell_type":"code","metadata":{"_execution_state":"idle","_uuid":"9b47479ea74167ef2b725fcd0773365586d25a91","trusted":false,"_cell_guid":"23ebcfbb-7f4b-4c16-9f4a-2ca588446fd5"},"source":"from sklearn.ensemble import RandomForestRegressor #libreria del modelo que diseñamos.\ndt = RandomForestRegressor()\n\nxtrain=x_nnan.drop([\"gross\"],axis=1) #variables\nytrain=x_nnan[\"gross\"] #variables respuesta\ndt.fit(xtrain,ytrain) #modelo","outputs":[],"execution_count":null},{"metadata":{"_execution_state":"idle","_uuid":"607d2a23ef7e5843c269d586c2240d9c67e3a063","_cell_guid":"9337611f-ed67-46e4-a299-bb2be1ce8071"},"cell_type":"markdown","source":"Limpiamos la muestra de NaN's a excepción de aquellos que están en la variable gross."},{"cell_type":"code","metadata":{"_execution_state":"idle","_uuid":"9c598d3d86e116af2fbb53cc22221dba86fa62c7","trusted":false,"_cell_guid":"350b501b-b529-408b-b42b-92a634170f0b"},"source":"x.columns.drop(\"gross\")","outputs":[],"execution_count":null},{"cell_type":"code","metadata":{"_execution_state":"idle","_uuid":"ad39b2e081744d6c3f88458e222793ce94942586","trusted":false,"_cell_guid":"ba5b4f93-467a-4f9c-8fec-089dc1347c77"},"source":"#Ahora hacemos la perdicción para los NAN's de gross.\nx_gross=x[sum([ 1*x[i].isnull() for i in x.columns.drop(\"gross\")])==0]\nx_gross[\"gross\"][x_gross[\"gross\"].isnull()]=dt.predict(x_gross.drop([\"gross\"],axis=1)[x_gross[\"gross\"].isnull()])","outputs":[],"execution_count":null},{"cell_type":"code","metadata":{"_execution_state":"idle","_uuid":"08c04a423b54c8640437d8f16261edff4483ce71","trusted":false,"_cell_guid":"f7f60e74-40a9-45f4-84a5-82e87f5c2df9"},"source":"x_gross.info() #vemos que ya tenemos una muestra sin NAN'S y mucho mayor\n#que la que hubiera resultado de eliminar todos los NAN'S de gross.","outputs":[],"execution_count":null},{"cell_type":"code","metadata":{"_execution_state":"idle","_uuid":"72c8372bb629fb61a0f0b6489390f9482cc87931","trusted":false,"_cell_guid":"897d88d4-50b9-43d4-8c4f-44802a9fd141"},"source":"xx=x_gross.drop(not_gen_corr_index,axis=1) #Guardamos en xx la base de datos definitiva que vamos a usar.\n#y borramos las variables de genero que no tienen gran correlación.","outputs":[],"execution_count":null},{"metadata":{"_execution_state":"idle","_uuid":"b09e4aeb20ce6914930e5fbe3f3354f197809d30","_cell_guid":"e69ababc-792d-47f6-b81a-0cfb63817309"},"cell_type":"markdown","source":"## Análisis."},{"metadata":{"_execution_state":"idle","_uuid":"1a32d146ac5a8a760a97915ed84a3aed9ef70a01","_cell_guid":"1eabaddf-4265-4664-aa7b-b1e2983caa9b"},"cell_type":"markdown","source":"### Dividimos la muestra en entrenamiento y test"},{"cell_type":"code","metadata":{"_execution_state":"idle","_uuid":"d66b33c4e66b85f6ae3000f82bc5523c14c2f270","trusted":false,"_cell_guid":"24b55ba0-9429-4a72-96a9-c60ee450a0a7"},"source":"np.random.seed(111)\nx_shouffle=xx.sample(frac=1)\nx_train=x_shouffle[:-300] #seleccionamos todas menos las 300 finales para train\nx_test=x_shouffle[-300:] # seleccionamos las 300 finales para test\ny_test=x_test[\"imdb_score\"] # extraemos la variable respuesta\nx_test=x_test.drop([\"imdb_score\"],axis=1)# quitamos la variable respuesta\ny_train=x_train[\"imdb_score\"]\nx_train=x_train.drop([\"imdb_score\"],axis=1)","outputs":[],"execution_count":null},{"cell_type":"code","metadata":{"_execution_state":"idle","_uuid":"4accf138868e15f3fa575809ada82cb954864eed","trusted":false,"_cell_guid":"31659776-dad0-4d62-80af-aad80f79ed1e"},"source":"print(x_train.shape[1],x_test.shape[1])","outputs":[],"execution_count":null},{"cell_type":"code","metadata":{"_execution_state":"idle","_uuid":"dc1f2f4b937b7c59a17f4db80b4d67269118485e","trusted":false,"_cell_guid":"225f6b6b-d987-4f34-bd66-62ce43d40eab"},"source":"print(x_train.shape[0],x_test.shape[0])","outputs":[],"execution_count":null},{"cell_type":"code","metadata":{"_execution_state":"idle","_uuid":"3e68b2d1f6329710259352a5ad6cb3d11f82ecf8","trusted":false,"_cell_guid":"c7e9da35-8007-4606-9732-a4e1077d4fa6"},"source":"#Ajustamos el predictor a los datos. Utilizamos el modelo RandomForestRegressor.\nfrom sklearn.ensemble import RandomForestRegressor\ndt = RandomForestRegressor()\ndt.fit(x_train, y_train)\n#Calculamos scores.\ndt_score_train = dt.score(x_train, y_train)\ndt_score_train = dt.score(x_train, y_train)\nprint(\"Training score: \",dt_score_train)\ndt_score_test = dt.score(x_test, y_test)\nprint(\"Testing score: \",dt_score_test)","outputs":[],"execution_count":null},{"cell_type":"code","metadata":{"_execution_state":"idle","_uuid":"81367eb6de38302e289450974cd13722ed162036","trusted":false,"_cell_guid":"268ebadf-da3b-4bf5-a4f3-b65247fe0974"},"source":"sum(abs(dt.predict(x_test)-y_test))/len(y_test)#media de los errores.","outputs":[],"execution_count":null},{"cell_type":"code","metadata":{"_execution_state":"idle","_uuid":"32865446d7b8ba5f13bea001f528493372fb394b","trusted":false,"_cell_guid":"51c21d99-61c3-4338-a344-209632642a55"},"source":"","outputs":[],"execution_count":null}],"nbformat":4,"metadata":{"language_info":{"pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.3","mimetype":"text/x-python","name":"python","file_extension":".py","nbconvert_exporter":"python"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat_minor":1}