{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1ff595737583ecbab1414c3f89bccbf5fc438f7b"},"cell_type":"markdown","source":"2 popular classification techniqes were applied to this dataset \"Simple logistic regression\" & \"Simple random forest with hyper-parameter tuning\".\n\nThe second technique is a bit challangeing, but it is a good opportunity to try."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/Dataset_spine.csv')\nprint(df.shape)\nprint(df.head(10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"727f9ec2bfbc38367fb5e364195d04a3beec3b38"},"cell_type":"code","source":"df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b84e07170b60fa3397afb678936226dbc01e821d"},"cell_type":"code","source":"df.drop(columns='Unnamed: 13',inplace=True)\ncol_name = ['pelvic_incidnece','pelvic_tilt','lumbar_lordosis_angle','sacral_slope','pelvic_radius','degree_spondylolisthesis',\n           'pelvic_slope','Direct_tilt','thoracic_slope','cervical_tilt','sacrum_angle','scoliosis_slope','Class_att']\ndf.columns = col_name\n\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ba3fa1aa38c4aff09aba31ed87f3da3e8544ede"},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c65870295d790963d76c4f51ffbaf9784e87a0d"},"cell_type":"code","source":"dummies = pd.get_dummies(df['Class_att'],drop_first=True)\ndf = pd.concat([df,dummies],axis=1)\ndf.drop(columns=\"Class_att\",inplace=True)\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4231f992b6b0cd3c1acfae68a72e2312a79ad063"},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\ncorr = df.corr()\nplt.figure(figsize=(10,8))\nsns.heatmap(corr,annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ff92773b62e303894d7619a600a4d119cbd70698"},"cell_type":"code","source":"#Split to training & testing dataset\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\n\nx = df.drop(columns='Normal')\ny = np.array(df['Normal'])\n\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=15)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7df8ba670759313b7eac930cff4288e1da961dbc"},"cell_type":"code","source":"# Logistic regression model\nlog_model = LogisticRegression()\n\nlog_model.fit(x_train,y_train)\n\nprediction = log_model.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5a4dd4f96c1196266cdaf478a9a4320e83c31822"},"cell_type":"code","source":"#Check its accuracy\nfrom sklearn.metrics import accuracy_score,confusion_matrix\n\n#Check overall accuracy\nlog_acc_score = accuracy_score(y_test,prediction)\nprint('accuracy score of logistic model is: {}'.format(log_acc_score))\n\n#Print confusion matrix\npd.DataFrame(confusion_matrix(y_test,prediction),columns=['Abmormal','Normal'],index=['Abnormal','Normal'])\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"304cc017884aa5383c30e83114251fd25cb830a9"},"cell_type":"markdown","source":"One importance point of logistic regression is to evaluate confusion matrix. Overall accuracy score may not be sufficient in real world. One dataset could be used to produce several logistic models which give us different performance. We cannot jude immediately that a model is better than other one unless confusion matrix is attached. What the matrix tells us? Mainly, true positive, false negative, true negative, false negative, in short, these indicators allow us to compare models in every angles, and let us properly select a right model depending on situation."},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"2594519b696553c66e5009ba2c3b64ff3ebc55f8"},"cell_type":"code","source":"#Random Forest technique\n\nfrom sklearn.ensemble import RandomForestClassifier\n\n#One question that we commonly think of\n#How many trees should we use?\n#Let's tune this hyperparameter\n\n#Techniquely, the more trees we use, the precise outcome we would get\nx_train2,x_test2,y_train2,y_test2 = train_test_split(x,y,test_size=0.3,random_state=15)\n\n\n#Generate forests containing 10(default), 50, 100, 200, 300 trees\nn_trees = [10,50,100,200,300]\nfor i in n_trees:\n    ran_for = RandomForestClassifier(n_estimators=i)\n    ran_for.fit(x_train2,y_train2)\n    pred = ran_for.predict(x_test2)\n    \n    print('n of trees: {}'.format(i))\n    #Each time of prediction,the accuracy is measured\n    correct_pred = 0\n    for j,k in zip(y_test2,pred):\n        if j == k:\n            correct_pred += 1\n    print('correct predictions: {}'.format(correct_pred/len(y_test2) *100))\n    matrix = pd.DataFrame(confusion_matrix(y_test2,pred),columns=['Abmormal','Normal'],index=['Abnormal','Normal'])\n    print(matrix)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"608cd8d519d1a71eae8d4cdfbe969bb3aaf0b2e3"},"cell_type":"markdown","source":"**Adding confusion matrix tells us something**\nAs the accuracy score of random forests show, its accuracy score increases as we suspected. However, the score strats to remain constant, and drop at some point. What does this imply? It tells us a number of tree (hyper-parameter) is needed consideration. Higher amount of trees may not the best solution. This is why confusion matries are attached, which give us very useful information. It is not necessary to pick 300 trees, but 50 or 100 tress are acceptable. Why? Obviously, it is hard to tell difference in accuracy score, true positive, false negative, true negative, and false negative."},{"metadata":{"_uuid":"fd8ac1ff6a00deb2f2678ac96d786acb2d071a7e"},"cell_type":"markdown","source":"\n***This work inspired by \"AnthonyRidding\" and \"Siraj Raval\"***\nAnthonyRidding's kernal is amazing and a goog model to study for anyone who starts exploring Kaggle. For Siraj Raval, he is a great Youtuber explaining maching learning and data science's stuff in a way everyone could understand."},{"metadata":{"trusted":true,"_uuid":"56c20f141ebb7d11c58f224e2834a9965dfcb503"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}