{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-05T12:55:46.615862Z","iopub.execute_input":"2021-07-05T12:55:46.616501Z","iopub.status.idle":"2021-07-05T12:55:46.63084Z","shell.execute_reply.started":"2021-07-05T12:55:46.616396Z","shell.execute_reply":"2021-07-05T12:55:46.629971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ## Essential Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\n%matplotlib inline\n","metadata":{"execution":{"iopub.status.busy":"2021-07-05T12:56:10.051382Z","iopub.execute_input":"2021-07-05T12:56:10.051794Z","iopub.status.idle":"2021-07-05T12:56:11.377114Z","shell.execute_reply.started":"2021-07-05T12:56:10.051759Z","shell.execute_reply":"2021-07-05T12:56:11.376114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#resd csv file\ndf=pd.read_csv('/kaggle/input/mushroom-classification/mushrooms.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-05T12:56:06.125061Z","iopub.execute_input":"2021-07-05T12:56:06.125428Z","iopub.status.idle":"2021-07-05T12:56:06.206149Z","shell.execute_reply.started":"2021-07-05T12:56:06.125392Z","shell.execute_reply":"2021-07-05T12:56:06.205364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#check null values in Dataset\ndf.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-07-05T12:56:20.262732Z","iopub.execute_input":"2021-07-05T12:56:20.263094Z","iopub.status.idle":"2021-07-05T12:56:20.291133Z","shell.execute_reply.started":"2021-07-05T12:56:20.263065Z","shell.execute_reply":"2021-07-05T12:56:20.290232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ## Features Encoding using One Hot Encoding Technique","metadata":{}},{"cell_type":"code","source":"dummies = pd.get_dummies(df, drop_first=True)\ndummies.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-05T12:56:23.488679Z","iopub.execute_input":"2021-07-05T12:56:23.48921Z","iopub.status.idle":"2021-07-05T12:56:23.552363Z","shell.execute_reply.started":"2021-07-05T12:56:23.489169Z","shell.execute_reply":"2021-07-05T12:56:23.551393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split data features into dependent and independent\n# X is Independent variables\n# y is dependent variables\nX = dummies.iloc[:,1:]\ny = dummies.iloc[:,0]","metadata":{"execution":{"iopub.status.busy":"2021-07-05T12:56:26.255433Z","iopub.execute_input":"2021-07-05T12:56:26.255857Z","iopub.status.idle":"2021-07-05T12:56:26.263744Z","shell.execute_reply.started":"2021-07-05T12:56:26.255822Z","shell.execute_reply":"2021-07-05T12:56:26.26258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ## Feature Selection","metadata":{}},{"cell_type":"code","source":"model = ExtraTreesClassifier()\nmodel.fit(X,y)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T12:56:29.568837Z","iopub.execute_input":"2021-07-05T12:56:29.569205Z","iopub.status.idle":"2021-07-05T12:56:30.000243Z","shell.execute_reply.started":"2021-07-05T12:56:29.569173Z","shell.execute_reply":"2021-07-05T12:56:29.999203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### feature Score","metadata":{}},{"cell_type":"code","source":"model.feature_importances_","metadata":{"execution":{"iopub.status.busy":"2021-07-05T12:56:31.622826Z","iopub.execute_input":"2021-07-05T12:56:31.623317Z","iopub.status.idle":"2021-07-05T12:56:31.646555Z","shell.execute_reply.started":"2021-07-05T12:56:31.62326Z","shell.execute_reply":"2021-07-05T12:56:31.645361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 25))\nfeature_rank = pd.Series(model.feature_importances_, index = X.columns)\nfeature_rank.nlargest(95).plot(kind = \"barh\")","metadata":{"execution":{"iopub.status.busy":"2021-07-05T12:56:35.555401Z","iopub.execute_input":"2021-07-05T12:56:35.555746Z","iopub.status.idle":"2021-07-05T12:56:37.710412Z","shell.execute_reply.started":"2021-07-05T12:56:35.555716Z","shell.execute_reply":"2021-07-05T12:56:37.709372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### In above Grraph We include, First 17 Columns have less importance so Drop this columns","metadata":{}},{"cell_type":"code","source":"drop_column = feature_rank.nsmallest(17).index\nX.drop(drop_column, axis = 1, inplace=True )","metadata":{"execution":{"iopub.status.busy":"2021-07-05T12:56:48.723725Z","iopub.execute_input":"2021-07-05T12:56:48.724104Z","iopub.status.idle":"2021-07-05T12:56:48.749322Z","shell.execute_reply.started":"2021-07-05T12:56:48.724072Z","shell.execute_reply":"2021-07-05T12:56:48.74742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ## Model Building","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression","metadata":{"execution":{"iopub.status.busy":"2021-07-05T12:58:09.063237Z","iopub.execute_input":"2021-07-05T12:58:09.063779Z","iopub.status.idle":"2021-07-05T12:58:09.067545Z","shell.execute_reply.started":"2021-07-05T12:58:09.063746Z","shell.execute_reply":"2021-07-05T12:58:09.06667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\nlogistic = LogisticRegression()\n\nlogistic.fit(X_train, y_train)\n#To display the fitting function attributes such as coef,intercept etc..\nprint(logistic.coef_)\nprint(logistic.intercept_)\n#prediction from the test data\nprediction=logistic.predict(X_test)\nprint(\"Logistic Regression 20 classified values:\")\nprint(prediction[0:20])\n","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:00:09.226925Z","iopub.execute_input":"2021-07-05T13:00:09.227314Z","iopub.status.idle":"2021-07-05T13:00:09.386109Z","shell.execute_reply.started":"2021-07-05T13:00:09.227284Z","shell.execute_reply":"2021-07-05T13:00:09.384859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ## Check Accurracy of Model","metadata":{}},{"cell_type":"code","source":"#model evaluation using classification metrics\n#confusion metrics - To display correctly classified data \n#and wrongly classified data\n#importing performance metrics\nfrom sklearn.metrics import accuracy_score,confusion_matrix\nconfus_matrix=confusion_matrix(y_test,prediction)\nprint(\"Confusion matrix\")\nprint(confus_matrix)\n#Calculate the accuracy\naccu_score=accuracy_score(y_test,prediction)\nprint(\"Accuracy\")\nprint(accu_score)\n#To display missclassified values from the prediction\nprint(\"Missclassified\")\nprint((y_test!=prediction).sum())","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:01:34.263531Z","iopub.execute_input":"2021-07-05T13:01:34.263925Z","iopub.status.idle":"2021-07-05T13:01:34.294886Z","shell.execute_reply.started":"2021-07-05T13:01:34.26389Z","shell.execute_reply":"2021-07-05T13:01:34.293823Z"},"trusted":true},"execution_count":null,"outputs":[]}]}