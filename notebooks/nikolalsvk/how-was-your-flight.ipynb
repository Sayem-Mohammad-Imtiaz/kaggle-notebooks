{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cb48fb85-d86d-edb8-5d49-57cddca88f9d"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom collections import Counter\n%matplotlib inline\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\ndata = pd.read_csv(\"../input/Tweets.csv\")\ndata.head(20)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"34a73447-0635-3103-c0e3-a3803769e155"},"outputs":[],"source":"# Check the ratio of positive and negative tweets for each airline\ndata['countval'] = 1\ngroupby_object = data[['airline','airline_sentiment','countval']] \\\n                 .groupby(['airline','airline_sentiment']).aggregate(sum)\ngroupby_object.unstack(level=1).plot(kind='bar')\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d869750b-6918-045d-58ea-91e529e215a8"},"outputs":[],"source":"data['dow'] = data.tweet_created.dt.dayofweek\n\ng = sb.FacetGrid(data, row = 'airline_sentiment', \n                 hue = 'airline', legend_out = True,\n                 aspect = 4, size = 2.5)\ng.map(sb.distplot, 'dow', hist = False)\ng.add_legend()\ng.axes.flat[0].set_xlim(0,6)\ng.axes.flat[2].set_xlabel('Day of Week')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8cba545c-5dd1-2119-701e-dea00f580372"},"outputs":[],"source":"from nltk.corpus import stopwords\nfrom nltk import PorterStemmer\nfrom nltk.stem.snowball import SnowballStemmer\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nimport re\n\n# Define number of classes and number of tweets per class\nn_class = 3\nn_tweet = 10000\nstemmer_name = \"snowball\"\n\n# Set stemmer\nif stemmer_name == \"snowball\":\n    stemmer = SnowballStemmer(\"english\")\nelse:\n    stemmer = PorterStemmer()\n\n# Divide into number of classes\nif n_class == 2:\n    df_pos = data.copy()[data.airline_sentiment == 'positive'][:n_tweet]\n    df_neg = data.copy()[data.airline_sentiment == 'negative'][:n_tweet]\n    df_neu = pd.DataFrame()\n    df = pd.concat([df_pos, df_neg], ignore_index=True).reset_index(drop=True)\nelif n_class == 3:\n    df_pos = data.copy()[data.airline_sentiment == 'positive'][:n_tweet]\n    df_neg = data.copy()[data.airline_sentiment == 'negative'][:n_tweet]\n    df_neu = data.copy()[data.airline_sentiment == 'neutral'][:n_tweet]\n    df = pd.concat([df_pos, df_neg, df_neu], ignore_index=True).reset_index(drop=True)\n\ndef tweet_to_words( raw_review ):\n    # Function to convert a raw review to a string of words\n    # The input is a single string (a raw tweet), and \n    # the output is a single string (a preprocessed tweet)\n    #\n    # 1. Emoticons to text\n    review_text = raw_review  \n    # sad_emoticons = {\":-(\", \":(\", \":-|\", \";-(\", \";-<\", \"|-{\"}\n    # happy_emoticons = {\":-)\", \":)\", \":o)\", \":-}\", \";-}\", \":->\", \";-)\"}\n    \n    # review_text = [\"HAPPY\" for word in review_text if word in happy_emoticons]\n    # review_text = [\"SAD\" for word in review_text if word in sad_emoticons]\n    #\n    # 2. Remove non-letters\n    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text)\n    #\n    # 3. Convert to lower case, split into individual words\n    words = letters_only.lower().split()                             \n    #\n    # 4. In Python, searching a set is much faster than searching\n    #   a list, so convert the stop words to a set\n    stops = set(stopwords.words(\"english\"))                  \n    # \n    # 5. Remove stop words and stem them\n    meaningful_words = [stemmer.stem(w) for w in words if not w in stops]\n    #  \n    # 6. Join the words back into one string separated by space, \n    # and return the result.\n    return(\" \".join( meaningful_words ))\n\nprocessed_tweets = []\nfor tweet in data['text']:\n    processed = tweet_to_words(tweet)\n    processed_tweets.append(processed)\n\ndata[\"text\"] = processed_tweets\n\nvect = CountVectorizer(ngram_range=(1, 3))\nprocessed_text = vect.fit_transform(data[\"text\"])\n\n# For cloud words\n# idf = vect._tfidf.idf_\n# wordDict=dict(zip(vect.get_feature_names(), idf))\n# print(processed_text)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"09305ddf-6702-7232-845a-03f4577d196c"},"outputs":[],"source":"X_train, X_test, y_train, y_test = train_test_split(data['text'], data['airline_sentiment'], test_size=0.33, random_state=0)\n\ndf_train = pd.DataFrame()\ndf_test = pd.DataFrame()\n\ndf_train['text'] = X_train\ndf_train['airline_sentiment'] = y_train\ndf_train = df_train.reset_index(drop=True)\n\ndf_test['text'] = X_test\ndf_test['airline_sentiment'] = y_test\ndf_test = df_test.reset_index(drop=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1c188bc-7c72-7802-a69b-37a3002f5d26"},"outputs":[],"source":"class TweetNBClassifier(object):\n\n    def __init__(self, df_train):\n        self.df_train = df_train\n        self.df_pos = df_train.copy()[df_train.airline_sentiment == 'positive']\n        self.df_neg = df_train.copy()[df_train.airline_sentiment == 'negative']\n        self.df_neu = df_train.copy()[df_train.airline_sentiment == 'neutral']\n\n    def fit(self):\n        Pr_pos = df_pos.shape[0]/self.df_train.shape[0]\n        Pr_neg = df_neg.shape[0]/self.df_train.shape[0]\n        Pr_neu = df_neu.shape[0]/self.df_train.shape[0]\n        self.Prior  = (Pr_pos, Pr_neg, Pr_neu)\n\n        self.pos_words = ' '.join(self.df_pos['text'].tolist()).split()\n        self.neg_words = ' '.join(self.df_neg['text'].tolist()).split()\n        self.neu_words = ' '.join(self.df_neu['text'].tolist()).split()\n\n        all_words = ' '.join(self.df_train['text'].tolist()).split()\n\n        self.vocab = len(Counter(all_words))\n\n        wc_pos = len(' '.join(self.df_pos['text'].tolist()).split())\n        wc_neg = len(' '.join(self.df_neg['text'].tolist()).split())\n        wc_neu = len(' '.join(self.df_neu['text'].tolist()).split())\n        self.word_count = (wc_pos, wc_neg, wc_neu)\n        return self\n\n\n    def predict(self, df_test):\n        class_choice = ['positive', 'negative', 'neutral']\n\n        classification = []\n        for tweet in df_test['text']:\n            text = tweet.split()\n\n            val_pos = np.array([])\n            val_neg = np.array([])\n            val_neu = np.array([])\n            for word in text:\n                tmp_pos = np.log((self.pos_words.count(word)+1)/(self.word_count[0]+self.vocab))\n                tmp_neg = np.log((self.neg_words.count(word)+1)/(self.word_count[1]+self.vocab))\n                tmp_neu = np.log((self.neu_words.count(word)+1)/(self.word_count[2]+self.vocab))\n                val_pos = np.append(val_pos, tmp_pos)\n                val_neg = np.append(val_neg, tmp_neg)\n                val_neu = np.append(val_neu, tmp_neu)\n\n            val_pos = np.log(self.Prior[0]) + np.sum(val_pos)\n            val_neg = np.log(self.Prior[1]) + np.sum(val_neg)\n            val_neu = np.log(self.Prior[2]) + np.sum(val_neu)\n\n            probability = (val_pos, val_neg, val_neu)\n            classification.append(class_choice[np.argmax(probability)])\n        return classification\n\n\n    def score(self, feature, target):\n\n        compare = []\n        for i in range(0,len(feature)):\n            if feature[i] == target[i]:\n                tmp ='correct'\n                compare.append(tmp)\n            else:\n                tmp ='incorrect'\n                compare.append(tmp)\n        r = Counter(compare)\n        accuracy = r['correct']/(r['correct']+r['incorrect'])\n        return accuracy"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"eeaeaa4e-0747-b13c-855d-a753a67c808c"},"outputs":[],"source":"# Naive Bayes Classificator\ntnb = TweetNBClassifier(df_train)\n# tnb = tnb.fit()\n# predict = tnb.predict(df_test)\n# score = tnb.score(predict,df_test.airline_sentiment.tolist())\n# print(score)\n\n# Naive Bayes"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}