{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Projeto final de aprendizado de máquina - classificador de imagens\n\n**Estudante:** João Gabriel de Oliveira Bicalho\n\n**Matrícula:** 2017015134"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom PIL import Image\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nimport tensorflow as tf\nfrom tensorflow.keras import datasets, layers, models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\nfrom sklearn.ensemble import AdaBoostClassifier\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Introdução\n\nO objetivo deste trabalho é criar um classificador para dois datasets de imagens. O primeiro dataset (Chinese MNIST) contém imagens de 15 números chineses manuscritos. Já o segundo (Fashion MNIST) contém imagens de 10 classes de produtos de moda. O objetivo do classificador é atribuir corretamente essas labels às imagens.\n\nNeste trabalho serão implementados dois classificadores: o primeiro utilizando um método de boosting na imagem achatada, e o segundo utilizando uma CNN _(Convolutional Neural Network)_. O intuito é utilizar a mesma CNN para ambos os datasets, apenas adequando o tamanho das camadas de entrada e saída. No final os resultados dos dois classificadores serão comparados."},{"metadata":{},"cell_type":"markdown","source":"# Datasets\n\n## Chinese MNIST\n\nEste dataset possui 15000 images de 64x64 pixels em escala de cinzas representando números em chinês. No total, o dataset possui 15 classes a serem categorizadas, e cada imagem possui apenas uma delas. As classes são mostradas na tabela abaixo, que apresenta os ideograma a serem identificados e os seus respectivos valores no sistema numérico decimal:"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"dfc = pd.read_csv('/kaggle/input/chinese-mnist/chinese_mnist.csv')\nimages = np.array([np.asarray(Image.open('/kaggle/input/chinese-mnist/data/data/input_%d_%d_%d.jpg'%(x['suite_id'], x['sample_id'], x['code']))) for x in dfc.iloc])\npd.DataFrame(zip([9,10,100,1000,10000,100000000,0,1,2,3,4,5,6,7,8],dfc['character'].unique()), columns=['valor', 'caractere']).sort_values(by='valor')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fashion MNIST\n\nEste dataset possui 60000 images de treino e 10000 imagens de teste, cada uma com 28x28 pixels em escala de cinzas representando vestimentas ou acessórios de moda. Cada imagem está associada a uma classe. Existem 10 classes dentro deste dataset, que são mostradas na tabela abaixo (coluna valor), junto com a sua label associada (coluna classe):"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame([[0, 'T-shirt/top'],\n[1, 'Trouser'],\n[2, 'Pullover'],\n[3, 'Dress'],\n[4, 'Coat'],\n[5, 'Sandal'],\n[6, 'Shirt'],\n[7, 'Sneaker'],\n[8, 'Bag'],\n[9, 'Ankle boot']], columns=['classe', 'valor'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tratamento dos dados\n\nApós o carregamento de cada um dos datasets, fez-se o tratamento de seus dados. As imagens de entrada foram normalizadas de forma que o valor de cada pixel esteja entre 0.0 e 1.0. Em seguida, foi atribuído uma label numérica para cada uma das classes de cada dataset. Para o dataset _Fashion MNIST_ estas labels já vieram do dataset. Para o dataset _Chinese MNIST_ as labels foram extraídas usando a classe _LabelEncoder_ do sklearn. Para o classificador com CNN as labels foram depois codificadas em um vetor categórico usando a técnica de one-hot-encoding (isto é, um vetor de dimensão igual ao número de classes com todas as posições zeradas, exceto a que representa sua classe, que tem 1)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalização e etiquetação Chinese MNIST\n\nxc = images/255.0\nxc = xc.reshape((-1, 64, 64, 1)) # Apenas para ficar no formado que a CNN prefere\n\nyc = np.array(dfc['value'])\nlec = preprocessing.LabelEncoder()\nyc_int=lec.fit_transform(yc)\nyc=to_categorical(yc_int)\nn_cclasses=len(yc[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Carregamento e normalização Fashion MNIST\n\ndata_train = pd.read_csv('../input/fashionmnist/fashion-mnist_train.csv')\ndata_test = pd.read_csv('../input/fashionmnist/fashion-mnist_test.csv')\n\nimg_rows, img_cols = 28, 28\ninput_shape = (img_rows, img_cols, 1)\n\nxf_train = np.array(data_train.iloc[:, 1:], dtype='float32')/255.0\nyf_train_int = np.array(data_train.iloc[:, 0])\nyf_train = to_categorical(yf_train_int)\n\nxf_test = np.array(data_test.iloc[:, 1:], dtype='float32')/255.0\nyf_test_int = np.array(data_test.iloc[:, 0])\nyf_test = to_categorical(yf_test_int)\n\nxf_train = xf_train.reshape((len(xf_train), 28, 28, 1))\nxf_test = xf_test.reshape((len(xf_test), 28, 28, 1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Separação de conjuntos de treino e teste\n\nApós o preprocessamento dos dados, o dataset _Chinese MNIST_ foi dividido em uma parte para treino e outra para teste. Foi decidido utilizar 20% dos dados para o teste e o restante para o treino. O dataset _Fashion MNIST_ já veio separado nestes dois conjuntos."},{"metadata":{"trusted":true},"cell_type":"code","source":"xc_train, xc_test, yc_train, yc_test, yc_train_int, yc_test_int = train_test_split(xc, yc, yc_int, test_size=0.2, random_state=8)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Treinamento dos modelos para o _Chinese MNIST_\n\n## AdaBoosting\n\nA primeira abordagem utilizada foi utilizar uma técnica de boosting para a classificação. Foram testados alguns algoritmos e, por fim, foi decidido utilizar o AdaBoosting, já que os outros facilmente ficavam com overfitting. Para usar este classificador, a imagem foi achatada em um vetor de $64*64=4096$ posições. \n\nAtravés de experimentação foi decidido definir o número de estimadores usados pelo AdaBoosting como 50, pois o algoritmo ficava melhor com a adição de mais estimadores. Para validação foi utilizado k-fold com k=5.\n\nOs resultados são apresentados logo após as células de implementação."},{"metadata":{"trusted":true},"cell_type":"code","source":"xc_train_ada = xc_train.reshape((len(xc_train), -1))\nxc_test_ada = xc_test.reshape((len(xc_test), -1))\n\nxc_ada_fold = KFold(n_splits=5, random_state=9, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ada = AdaBoostClassifier(n_estimators=50)\n\nresults = []\nacc=[]\nfor train_index, val_index in xc_ada_fold.split(xc_train_ada):\n    print('Fold %d...' % (len(results)+1))\n    my_x_train = xc_train_ada[train_index]\n    my_y_train = yc_train_int[train_index]\n    my_x_val = xc_train_ada[val_index]\n    my_y_val = yc_train_int[val_index]\n    \n    ada.fit(my_x_train, my_y_train)\n    my_y_pred = ada.predict(my_x_val)\n    prfs = precision_recall_fscore_support(my_y_val, my_y_pred, average='micro')\n    facc = accuracy_score(my_y_val, my_y_pred)\n    results.append(prfs[:-1])\n    acc.append(facc)\n\nprint('Concluído. Média dos resultados no treino:')\nprint('precisão, revocação, fscore')\nresults = np.array(results).mean(axis=0)\nprint(results)\nprint('acurácia: ', np.array(acc).mean());","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ada.fit(xc_train_ada, yc_train_int)\nyc_pred_ada = ada.predict(xc_test_ada)\nc_prfs_ada = precision_recall_fscore_support(yc_test_int, yc_pred_ada, average='micro')\nc_acc_ada = accuracy_score(yc_test_int, yc_pred_ada)\nprint('Resultados no teste')\nprint('precisão, revocação, fscore')\nprint(c_prfs_ada[:-1])\nprint('acurácia: ', c_acc_ada);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Resultados\n\nComo é possível notar na saída das últimas duas células, os resultados nos conjuntos de treino e teste ficaram bem parecidos, e ambos ficaram ruins, apresentando uma acurácia em torno de 20%. Apesar disto, o resultado ficou dentro do esperado, já que o dado de entrada (imagem) é um dado não estruturado, e classificadores geralmente não funcionam bem nesse tipo de dado."},{"metadata":{},"cell_type":"markdown","source":"## CNN\n\nEm busca de tentar obter um modelo com maior acurácia foi criada uma Rede Neural Convolucional. Esse tipo de rede geralmente obtém melhores resultados com imagens, já que ela consegue trabalhar com dados de mais de uma dimensão e, através de convoluções, consegue extrair informações dos pixels considerando localidade espacial.\n\nConforme já mencionado, para treinar esta rede as labels associadas às imagens foram codificadas como um vetor one-hot-encoding.\n\nA rede criada recebe uma entrada de dimensão (64, 64, 1) e possui 2 camadas de convolução com 16 filtros (3, 3) cada, seguida por uma camada de MaxPooling (2, 2), uma camada de Dropout (com 50% de probabilidade), mais 2 camadas de convolução com 16 filtros (3, 3) cada, mais uma camada de Dropout (0.5), uma camada de achatamento e uma camada densa com 15 perceptrons para saída do vetor de classificação. Em todas as camadas de convolução foi utilizada a função de ativação ReLU, já na camada densa de saída foi utilizado softmax.\n\nAs camadas de Max Pooling foram introduzidas para diminuir a dimensionalidade da saída das camadas anteriores através de um down-sampling. Dessa forma é possível fazer assunções melhores sobre as características contidas nas subregiões agregadas pelo pooling. Já as camadas de Dropout tentam evitar que o modelo criado sofra de overfitting, desabilitando aleatoriamente partes das outras camadas da rede.\n\nFoi utilizado o otimizador Adam, o loss foi calculado através de entropia cruzada categórica, e a métrica de avaliação foi a acurácia.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"modelc = models.Sequential()\nmodelc.add(layers.Conv2D(16, (3, 3), activation='relu', input_shape=(64, 64, 1)))\nmodelc.add(layers.Conv2D(16, (3, 3), activation='relu'))\nmodelc.add(layers.MaxPooling2D((2, 2)))\nmodelc.add(layers.Dropout(0.5))\nmodelc.add(layers.Conv2D(16, (3, 3), activation='relu'))\nmodelc.add(layers.Conv2D(16, (3, 3), activation='relu'))\nmodelc.add(layers.Dropout(0.5))\nmodelc.add(layers.Flatten())\nmodelc.add(layers.Dense(n_cclasses, activation='softmax'))\nmodelc.summary()\n\nmodelc.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"O modelo da rede neural foi treinado utilizando 50 épocas e dividindo o dado de treino em treino e validação. Esta divisão dos dados foi realizada automaticamente pelo Keras no momento do _fit_ , como pode ser visto na célula abaixo."},{"metadata":{"trusted":true},"cell_type":"code","source":"cepochs = 50\nhistoryc = modelc.fit(xc_train, yc_train, epochs=cepochs, batch_size=32,\n                    validation_split=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(list(range(cepochs)), historyc.history['loss'], label='treino')\nplt.plot(list(range(cepochs)), historyc.history['val_loss'], label='validação')\nplt.legend()\nplt.title('loss')\nplt.xlabel('número da época')\nplt.show()\nplt.plot(list(range(cepochs)), historyc.history['accuracy'], label='treino')\nplt.plot(list(range(cepochs)), historyc.history['val_accuracy'], label='validação')\nplt.title('accurácia')\nplt.xlabel('número da época')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Resultados\n\nOs resultados obtidos da CNN foram muito bons, obtendo uma ótima acurácia (próxima de 100%) tanto no conjunto de treino quanto no conjunto de validação, e também mantendo a diminuição do loss durante o treinamento. O modelo não parece apresentar overfitting.\nApós a finalização da mudança dos parâmetros e a geração dos gráficos acima, foi realizado o teste do modelo no conjunto de teste, que manteve uma excelente acurácia, conforme pode ser observado abaixo."},{"metadata":{"trusted":true},"cell_type":"code","source":"yc_pred_test = modelc.predict(xc_test)\n\nyc_pred_test_argmax = np.argmax(yc_pred_test, axis=1)\nprint('acurácia no teste: ', accuracy_score(yc_test_int, yc_pred_test_argmax))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Exemplos de classificação correta\n\nNa imagem abaixo é possível ver vários exemplos de classificações corretas do classificador. No título de cada sub-figura tem-se a previsão realizada."},{"metadata":{"trusted":true},"cell_type":"code","source":"meus_x = xc_test[yc_pred_test_argmax == yc_test_int].reshape((-1,64,64))\nmeus_y = lec.inverse_transform(yc_test_int[yc_pred_test_argmax == yc_test_int])\n\nfig=plt.figure(figsize=(8, 8))\ncolumns = 5\nrows = 5\nfor i in range(1, columns*rows +1):\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(meus_x[i])\n    plt.title(meus_y[i])\n    plt.axis('off')\nplt.subplots_adjust(hspace=0.25)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Exemplos de classificação incorreta\n\nNa imagem abaixo é possível ver vários exemplos de classificações incorretas do classificador. No título de cada sub-figura tem-se a previsão realizada e a correta, sendo que a correta está entre parênteses."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Valores preditos (valores reais)')\nmeus_x = xc_test[yc_pred_test_argmax != yc_test_int].reshape((-1,64,64))\nmeus_y = lec.inverse_transform(yc_pred_test_argmax[yc_pred_test_argmax != yc_test_int])\nreais_y = lec.inverse_transform(yc_test_int[yc_pred_test_argmax != yc_test_int])\n\nfig=plt.figure(figsize=(8, 8))\ncolumns = 5\nrows = 5\nfor i in range(1, columns*rows +1):\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(meus_x[i])\n    plt.title(\"%d (%d)\" % (meus_y[i], reais_y[i]))\n    plt.axis('off')\nplt.subplots_adjust(hspace=0.25, wspace=0.5)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Treinamento dos modelos para o _Fashion MNIST_\n\nDiante dos resultados do dataset anterior, para este dataset apenas foi treinado o modelo CNN, já que ele obteve uma acurácia muito maior que o AdaBoosting.\n\n## CNN\n\nPara treinar a CNN para o _Fashion MNIST_ foi utilizada a mesma arquitetura da CNN do _Chinese MNIST_ , com exceção do tamanho da camada de entrada e de saída, que foram definidas de acordo com os dados deste dataset: (28, 28, 1) e 10, respectivamente."},{"metadata":{"trusted":true},"cell_type":"code","source":"nf_classes = len(yf_train[0])\nmodelf = models.Sequential()\nmodelf.add(layers.Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 1)))\nmodelf.add(layers.Conv2D(16, (3, 3), activation='relu'))\nmodelf.add(layers.MaxPooling2D((2, 2)))\nmodelf.add(layers.Dropout(0.5))\nmodelf.add(layers.Conv2D(16, (3, 3), activation='relu'))\nmodelf.add(layers.Conv2D(16, (3, 3), activation='relu'))\nmodelf.add(layers.Dropout(0.5))\nmodelf.add(layers.Flatten())\nmodelf.add(layers.Dense(nf_classes, activation='softmax'))\nmodelf.summary()\n\nmodelf.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"O modelo da rede neural foi treinado utilizando 50 épocas e dividindo o dado de treino em treino e validação. Esta divisão dos dados foi realizada automaticamente pelo Keras no momento do _fit_ , como pode ser visto na célula abaixo."},{"metadata":{"trusted":true},"cell_type":"code","source":"fepochs = 50\nhistoryf = modelf.fit(xf_train, yf_train, epochs=fepochs, batch_size=32,\n                    validation_split=0.2, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(list(range(fepochs)), historyf.history['loss'], label='treino')\nplt.plot(list(range(fepochs)), historyf.history['val_loss'], label='teste')\nplt.legend()\nplt.title('loss')\nplt.show()\nplt.plot(list(range(fepochs)), historyf.history['accuracy'], label='treino')\nplt.plot(list(range(fepochs)), historyf.history['val_accuracy'], label='teste')\nplt.title('accuracy')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Resultados\n\nOs resultados obtidos da CNN foram muito bons, obtendo uma ótima acurácia (próxima de 90%) tanto no conjunto de treino quanto no conjunto de validação, e também mantendo a diminuição do loss durante o treinamento. O modelo não parece apresentar overfitting.\nApós a finalização da mudança dos parâmetros e a geração dos gráficos acima, foi realizado o teste do modelo no conjunto de teste, que manteve uma excelente acurácia, conforme pode ser observado abaixo."},{"metadata":{"trusted":true},"cell_type":"code","source":"yf_pred_test = modelf.predict(xf_test)\n\nyf_pred_test_argmax = np.argmax(yf_pred_test, axis=1)\nprint('acurácia no teste: ', accuracy_score(yf_test_int, yf_pred_test_argmax))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_lef = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Exemplos de classificação correta\n\nNa imagem abaixo é possível ver vários exemplos de classificações corretas do classificador. No título de cada sub-figura tem-se a previsão realizada."},{"metadata":{"trusted":true},"cell_type":"code","source":"meus_x = xf_test[yf_pred_test_argmax == yf_test_int].reshape((-1,28,28))\nmeus_y = yf_test_int[yf_pred_test_argmax == yf_test_int]\n\nfig=plt.figure(figsize=(8, 8))\ncolumns = 5\nrows = 5\nfor i in range(1, columns*rows +1):\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(meus_x[i])\n    plt.title(my_lef[meus_y[i]])\n    plt.axis('off')\nplt.subplots_adjust(hspace=0.25)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Exemplos de classificação incorreta\n\nNa imagem abaixo é possível ver vários exemplos de classificações incorretas do classificador. No título de cada sub-figura tem-se a previsão realizada e a correta, sendo que a correta está entre parênteses."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Valores preditos (valores reais)')\nmeus_x = xf_test[yf_pred_test_argmax != yf_test_int].reshape((-1,28,28))\nmeus_y = yf_pred_test_argmax[yf_pred_test_argmax != yf_test_int]\nreais_y = yf_test_int[yf_pred_test_argmax != yf_test_int]\n\nfig=plt.figure(figsize=(8, 8))\ncolumns = 5\nrows = 5\nfor i in range(1, columns*rows +1):\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(meus_x[i])\n    plt.title(\"%s\\n(%s)\" % (my_lef[meus_y[i]], my_lef[reais_y[i]]))\n    plt.axis('off')\nplt.subplots_adjust(hspace=0.6, wspace=0.5)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Discussão dos resultados\n\n\nComo pôde ser observado, a rede neural convolucional performou muito melhor do que o método de boosting durantes os testes no dataset Chinese MNIST, possuindo uma acurácia muito maior. Isso ajuda a demonstrar a capacidade de CNNs para classificação de imagens, além de mostrar que classificadores clássicos realmente não trabalham bem com dados não estruturados. Além disso, foi possível conferir que a arquitetura de CNN apresentada funcionou adequadamente para os dois datasets testados, não apresentando overfitting e tendo ótima acurácia. O uso de uma rede relativamente pequena e de dropouts provavelmente colaborou para que isso fosse possível.\n\nAlém disso, as entradas serem bem comportadas (apenas uma coisa na imagem, mesma dimensão e bem consistentes) também foi excelente para fazer com que o classificador obtivesse acurácia elevada.\n\nNas imagens abaixo é possível ver as matrizes de confusão do classificador AdaBoosting e CNN para o dataset _Chinese MNIST_ , e do CNN para o _Fashion MNIST_ , nesta ordem. É possível perceber que os classificadores CNN conseguem separar as classes muito bem, ao passo que o AdaBoosting não é bom, se confundindo muito em quase todas as classes.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Matriz de confusão dataset Chinese MNIST adaboosting\ncf_matrix=confusion_matrix(yc_test_int, yc_pred_ada)\nfig, ax = plt.subplots(figsize=(12,10))\nsns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n            fmt='.2%', cmap='Blues')\nplt.title('Matriz de confusão das previsões no conjunto de teste do dataset Chinese MNIST (AdaBoosting)')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Matriz de confusão dataset Chinese MNIST cnn\ncf_matrix=confusion_matrix(yc_test_int, yc_pred_test_argmax)\nfig, ax = plt.subplots(figsize=(12,10))\nsns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n            fmt='.2%', cmap='Blues')\nplt.title('Matriz de confusão das previsões no conjunto de teste do dataset Chinese MNIST (CNN)')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Matriz de confusão dataset Fashion MNIST\ncf_matrix=confusion_matrix(yf_test_int, yf_pred_test_argmax)\nfig, ax = plt.subplots(figsize=(8,7))\nsns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n            fmt='.2%', cmap='Blues')\nplt.title('Matriz de confusão das previsões no conjunto de teste do dataset Fashion MNIST')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusão\n\nFoi possível implementar adequadamente todos os classificadores, assim como compará-los. Os classificadores CNN obtiveram ótima performance, enquanto o classificador AdaBoosting teve uma performance ruim. Em geral, os resultados foram satisfatórios e dentro do esperado."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}