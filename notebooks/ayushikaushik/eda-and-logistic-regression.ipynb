{"cells":[{"metadata":{},"cell_type":"markdown","source":"> ## *Please upvote if you like my efforts and provide valuable suggestions!*","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"\n**About the dataset:** Columns description-\n* Sex: male or female(Nominal)\n* Age: Age of the patient;(Continuous - Although the recorded ages have been truncated to whole numbers, the concept of age is continuous)\nBehavioral\n* Current Smoker: whether or not the patient is a current smoker (Nominal)\n* Cigs Per Day: the number of cigarettes that the person smoked on average in one day.(can be considered continuous as one can have any number of cigarettes, even half a cigarette.)\nMedical( history)\n* BP Meds: whether or not the patient was on blood pressure medication (Nominal)\n* Prevalent Stroke: whether or not the patient had previously had a stroke (Nominal)\n* Prevalent Hyp: whether or not the patient was hypertensive (Nominal)\n* Diabetes: whether or not the patient had diabetes (Nominal)\nMedical(current)\n* Tot Chol: total cholesterol level (Continuous)\n* Sys BP: systolic blood pressure (Continuous)\n* Dia BP: diastolic blood pressure (Continuous)\n* BMI: Body Mass Index (Continuous)\n* Heart Rate: heart rate (Continuous - In medical research, variables such as heart rate though in fact discrete, yet are considered continuous because of large number of possible values.)\n* Glucose: glucose level (Continuous)\nPredict variable (desired target)\n* 10 year risk of coronary heart disease CHD (binary: “1”, means “Yes”, “0” means “No”)","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Importing libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno\n%matplotlib inline\nimport warnings      #to avoid warnings\nwarnings.filterwarnings('ignore')\n# importing data\ndata = pd.read_csv('../input/heart-disease-prediction-using-logistic-regression/framingham.csv')\nprint(f\"Let's see first 5 rows of the dataset.\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"I will use **pandas_profiling** library to understand the data.\nIt is a nice alternative to using .info and .describe methods. Infact, it gives much more useful informations like % of mising values, mean, maximum, minimum, heatmap depicting correlation, etc.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas_profiling\ndata.profile_report()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusions-**\n- Our data contains 4238 rows and 16 columns.\n- Seems like this data is already preprocessed as there is no categorical columns. Those features have been encoded already.\nNow, let's see missing values.\n- Columns having mising values are: 'education'(2.5%), 'cigsPerDay'(0.7%), 'BPMeds'(1.3%), 'totChol'(1.2%) and 'glucose'(**9.2%**).\nExcept the feature glucose all other missing values are less than 2% of data. We can drop all other missing values but in this project I choose to use SimpleImputer to impute them with most frequent value.\nAs for feature glucose, notice in heatmap that glucose is highly correlated with diabetes. So, I will use feature diabetes to fill missing values in glucose.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"sns.set(style=\"whitegrid\",palette='Set2')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print(\"Distribution of boolean variables\")\nprint(' “1” means “Yes”, “0” means “No”')\nfig,axes = plt.subplots(nrows=2,ncols=3,figsize=(12,8))\nsns.countplot(data.TenYearCHD,ax=axes[0,0])\nsns.countplot(data.male,ax=axes[0,1])\naxes[0,1].set_xlabel(\"0 is female and 1 is male\")\nsns.countplot(data.currentSmoker,ax=axes[0,2])\nsns.countplot(data.BPMeds,ax=axes[1,0])\nsns.countplot(data.prevalentStroke,ax=axes[1,1])\nsns.countplot(data.prevalentHyp,ax=axes[1,2])\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"sns.set(style=\"darkgrid\",palette='Set1')\nprint(\"Distribution of continuous variables\")\nfig,axes = plt.subplots(nrows=4,ncols=2,figsize=(12,8))\nsns.distplot(data.age,ax=axes[0,0])\nsns.distplot(data.BMI,ax=axes[0,1])\nsns.distplot(data.glucose,ax=axes[1,0])\nsns.distplot(data.cigsPerDay,ax=axes[1,1])\nsns.distplot(data.sysBP,ax=axes[2,0])\nsns.distplot(data.diaBP,ax=axes[2,1])\nsns.distplot(data.totChol,ax=axes[3,0])\nsns.distplot(data.heartRate,ax=axes[3,1])\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#Plotting a linegraph to check the relationship between age and cigsPerDay, totChol, glucose.\ngraph_3 = data.groupby(\"age\").cigsPerDay.mean()\ngraph_4 = data.groupby(\"age\").totChol.mean()\ngraph_5 = data.groupby(\"age\").glucose.mean()\n\nplt.figure(figsize=(10,6))\nsns.lineplot(data=graph_3, label=\"cigsPerDay\")\nsns.lineplot(data=graph_4, label=\"totChol\")\nsns.lineplot(data=graph_5, label=\"glucose\")\nplt.title(\"Graph showing totChol and cigsPerDay in every age group.\",{'fontsize':18})\nplt.xlabel(\"age\", size=20)\nplt.ylabel(\"count\", size=20)\nplt.xticks(size=12)\nplt.yticks(size=12);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"graph = data.groupby(\"age\",as_index=False).currentSmoker.sum()\nplt.figure(figsize=(10,6))\nsns.barplot(x=graph[\"age\"], y=graph[\"currentSmoker\"])\nplt.title(\"Graph showing which age group has more smokers.\",{'fontsize':18});","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Handling missing values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's have a visual look at missing data\nmsno.matrix(data);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby('diabetes').mean()['glucose']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def impute_glucose(cols):\n    dia=cols[0]\n    glu=cols[1]\n    if pd.isnull(glu):\n        if dia == 0:\n            return 79\n        else:\n            return 170\n    else:\n        return glu\n\ndata['glucose'] = data[['diabetes','glucose']].apply(impute_glucose,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Another way to visualize missing data\nsns.heatmap(data.isnull(),yticklabels=False,cbar=False,cmap='summer');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, glucose feature has no missing data now.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.impute import SimpleImputer\nimputer = SimpleImputer(strategy='most_frequent')\nimputer.fit(data)\nimputed_data = imputer.transform(data)\nimputed_data = pd.DataFrame(imputed_data,columns=data.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"just to cross-check all missing data is gone!\")\nmsno.bar(imputed_data);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Libraries needed for model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score\nfrom sklearn.model_selection import cross_val_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#First split the data\nX_train, X_test, y_train, y_test = train_test_split(imputed_data.drop('TenYearCHD',axis=1), \n                                                    imputed_data['TenYearCHD'], test_size=0.30, \n                                                    random_state=101)\nlogmodel = LogisticRegression()\nlogmodel.fit(X_train,y_train)\npredictions = logmodel.predict(X_test)\nprint(classification_report(y_test,predictions))\nprint(confusion_matrix(y_test,predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, predictions)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Cross-validation** is a technique for evaluating ML models by training several ML models on subsets of the available input data and evaluating them on the complementary subset of the data. In k-fold cross-validation, you split the input data into k subsets of data (also known as folds). You train an ML model on all but one (k-1) of the subsets, and then evaluate the model on the subset that was not used for training. This process is repeated k times, with a different subset reserved for evaluation (and excluded from training) each time.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"score=cross_val_score(LogisticRegression(),imputed_data.drop('TenYearCHD',axis=1),imputed_data['TenYearCHD'],cv=10)\nprint(f\"After k-fold cross validation score is {score.mean()}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Using GridSearchCV","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nparameters = [{'penalty':['l1','l2']}, \n              {'C':[1, 10, 100, 1000]}]\ngrid_search = GridSearchCV(estimator = logmodel,  \n                           param_grid = parameters,\n                           scoring = 'accuracy',\n                           cv = 5,\n                           verbose=0)\ngrid_search.fit(X_train, y_train)\n# best score achieved during the GridSearchCV\nprint('GridSearch CV best score : {:.4f}\\n'.format(grid_search.best_score_))\n# print parameters that give the best results\nprint(f'Parameters that give the best results : {grid_search.best_params_}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score2=cross_val_score(grid_search,imputed_data.drop('TenYearCHD',axis=1),imputed_data['TenYearCHD'],cv=10)\nprint(f\"After k-fold cross validation score is {score2.mean()}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CONCLUSION:\n\n- Model accuracy score for logistic regression after cross-validation is 84.9% which is quite nice.\n- Using GridSearchCV does not improve accuracy on this particular data.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}