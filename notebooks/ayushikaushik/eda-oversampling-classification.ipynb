{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Task: Predict Health Insurance Owners' who will be interested in Vehicle Insurance\n\nAn insurance company has provided Health Insurance to its customers now they want a model to predict whether the policyholders (customers) from past year will also be interested in Vehicle Insurance provided by the company.\n\nBefore building model, let's explore the dataset and get some insights from data."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score,roc_auc_score\n%matplotlib inline\n\ntrain=pd.read_csv('../input/health-insurance-cross-sell-prediction/train.csv')\n#test=pd.read_csv('../input/health-insurance-cross-sell-prediction/test.csv')\n\nprint(\"First five rows of training dataset are:\")\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Information about columns:\n\n* id  -\tUnique ID for the customer\n* Gender  -\tGender of the customer\n* Age  - \tAge of the customer\n* Driving_License  - \t0 : Customer does not have DL, 1 : Customer already has DL\n* Region_Code  -\tUnique code for the region of the customer\n* Previously_Insured  -\t1 : Customer already has Vehicle Insurance, 0 : Customer doesn't have Vehicle Insurance\n* Vehicle_Age  -\tAge of the Vehicle\n* Vehicle_Damage  -  1 : Customer got his/her vehicle damaged in the past. 0 : Customer didn't get his/her vehicle damaged in the past.\n* Annual_Premium  -\tThe amount customer needs to pay as premium in the year\n* PolicySalesChannel  -\tAnonymized Code for the channel of outreaching to the customer ie.,Different Agents, Over Mail, Over Phone, In Person, etc.\n* Vintage  -\tNumber of Days, Customer has been associated with the company\n* Response  -\t1 : Customer is interested, 0 : Customer is not interested\n"},{"metadata":{},"cell_type":"markdown","source":"We are given two csv files in this dataset: train and test. For EDA, I will use only train set.\n\nLet's have a look at data types of different columns."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print(f\"Train set has {train.shape[0]} rows and {train.shape[1]} columns.\")\nprint(f\"Missing values are present in data: {train.isnull().sum().any()}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA\n\nFeatures Response, Driving_License and Previously_Insured are alreadyencoded in data. For EDA purpose, I am converting these into object type for easy understanding in visualizations."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_eda = train.copy()\ncols=['Driving_License','Previously_Insured','Response']\nfor col in cols:\n    train_eda[col] = train_eda[col].map({0:'No',1:'Yes'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Target variable: Response"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"sns.countplot(train_eda['Response'],palette='rocket')\nplt.title(\"Target variable Distribution in data\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* So, our data is highly imbalanced.\n\n> I made two notebooks showing 2 ways to handle imbalanced data. Give them a look:\n    [down-sampling-majority-class-6-classification-algo](https://www.kaggle.com/ayushikaushik/down-sampling-majority-class-6-classification-algo)\n    and\n    [up-sampling-to-tackle-unbalanced-dataset](https://www.kaggle.com/ayushikaushik/up-sampling-to-tackle-unbalanced-dataset)\n\n> [Here](https://www.analyticsvidhya.com/blog/2017/03/imbalanced-data-classification/) is a good article to understand problems caused by imbalanced article and ways to handle them.\n\n## Gender"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"sns.countplot(train_eda['Gender'],palette='summer')\nplt.title(\"Gender Distribution in data\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* There are more samples of gender male.\n* Seems as if males are more concerned about health risks.  ;)\n\n## Age"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print(\"Age distribution according to Response\")\nfacetgrid = sns.FacetGrid(train_eda,hue=\"Response\",aspect = 4)\nfacetgrid.map(sns.kdeplot,\"Age\",shade = True)\nfacetgrid.set(xlim = (0,train_eda[\"Age\"].max()))\nfacetgrid.add_legend();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Young people below 30 are not interested in vehicle insurance. Reasons could be lack of experience, less maturity level and they don't have expensive vehicles yet.\n* People aged between 30-60 are more likely to be interested.\n\n## Driving License"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(train_eda['Response'], train_eda['Driving_License'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ***You should always have driving license while driving***\n\n* Here also majority observations have a driving license.\n\n\n## Region-wise Distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_eda['Region_Code'].value_counts().plot(kind='barh',cmap='Accent',figsize=(12,10));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Meaning of these codes has not been provided.\n* Most of the data is collected from people living in region with code 28\n\n## Previously-insured"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"pd.crosstab(train_eda['Response'], train_eda['Previously_Insured'])","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"pd.crosstab(train_eda['Response'], train_eda['Previously_Insured']).plot(kind='bar');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Those who already have an insurance are not interested. This was obvious man!\n\n\n## Vehicle Age"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize']=(6,8)\ncolor = ['yellowgreen','gold',\"lightskyblue\"]\ntrain_eda['Vehicle_Age'].value_counts().plot.pie(y=\"Vehicle_Age\",colors=color,explode=(0.02,0,0.3),startangle=50,shadow=True,autopct=\"%0.1f%%\")\nplt.axis('on');","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"sns.countplot(train_eda['Vehicle_Age'],hue=train_eda['Response'],palette='autumn');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* More than half of the data (52%) has samples with vehicle age between 1-2 years.\n* We can't say from second graph that people with vehicle age between 1-2 years are more interested because other category '>2 years' has very few observations.\n\n\n## Vehicle Damage"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"pd.crosstab(train_eda['Response'], train_eda['Vehicle_Damage']).plot(kind='bar');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*  Customers who got his/her vehicle damaged in the past is more likely to be interested in insurance. May be because he has first-hand experience of its pros and cons.\n* Ah! I want a version of 'Prevention is better than cure' for this situation.\n\n## Annual Premium"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print(\"Annual Premium distribution according to Response\")\nfacetgrid = sns.FacetGrid(train_eda,hue=\"Response\",aspect = 4)\nfacetgrid.map(sns.kdeplot,\"Annual_Premium\",shade = True)\nfacetgrid.set(xlim = (0,train_eda[\"Annual_Premium\"].max()))\nfacetgrid.add_legend();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* I don't think it gives much knowledge.\n* Outliers can be present in this feature.\n\n## PolicySalesChannel\n\nAnonymized Code for the channel of outreaching to the customer ie. Different Agents, Over Mail, Over Phone, In Person, etc."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print(\"Policy_Sales_Channel distribution according to Response\")\nfacetgrid = sns.FacetGrid(train_eda,hue=\"Response\",aspect = 4)\nfacetgrid.map(sns.kdeplot,\"Policy_Sales_Channel\",shade = True)\nfacetgrid.set(xlim = (0,train_eda[\"Policy_Sales_Channel\"].max()))\nfacetgrid.add_legend();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* This graph seems interesting. But to clearly extract insights we need meaning of these codes.\n\n## Vintage\n\nNumber of Days, Customer has been associated with the company"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print(\"Vintage feature according to Response\")\nfacetgrid = sns.FacetGrid(train_eda,hue=\"Response\",aspect = 4)\nfacetgrid.map(sns.kdeplot,\"Vintage\",shade = True)\nfacetgrid.set(xlim = (0,train_eda[\"Vintage\"].max()))\nfacetgrid.add_legend();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Our target variable is not much affected by this feature. It can be dropped."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print(\"Correlation matrix-\")\nplt.rcParams['figure.figsize']=(8,6)\nsns.heatmap(train.corr(),cmap='Spectral');","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"train.corr()[:-1]['Response'].sort_values().round(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I will remove least correlated features for modelling.\n\n# Creating classification Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating a checkpoint\ndf4model = train.copy()\n#dropping Vintage column as suggested by EDA\ndf4model.drop(['id','Vintage'],axis=1,inplace=True)\n#checking target variable\ndf4model.Response.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To make this data balanced let's upsample the minority class using sklearn library resample.\n\nTo prevent any data leakage I will first split into train and test subsets and then do upsampling as suggested by [@antaresnyc](https://www.kaggle.com/antaresnyc)."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(df4model.drop(['Response'], axis = 1), \n                                                    df4model['Response'], test_size = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Target variable disribution in train set: \\n{y_train.value_counts()}\\n\\nand in test set: \\n{y_test.value_counts()}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Up-sampling"},{"metadata":{"trusted":true},"cell_type":"code","source":"#combining train features and target\ndf = pd.concat([X_train,y_train],axis=1)\n\nfrom sklearn.utils import resample,shuffle\ndf_majority = df[df['Response']==0]\ndf_minority = df[df['Response']==1]\ndf_minority_upsampled = resample(df_minority,replace=True,n_samples=y_train.value_counts()[0],random_state = 123)\nbalanced_df = pd.concat([df_minority_upsampled,df_majority])\nbalanced_df = shuffle(balanced_df)\nbalanced_df.Response.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, I will convert categorical columns into numerical ones."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OrdinalEncoder\nencoder= OrdinalEncoder()\ncat_cols=['Gender','Vehicle_Damage']\nbalanced_df[cat_cols] = encoder.fit_transform(balanced_df[cat_cols])\nX_test[cat_cols] = encoder.transform(X_test[cat_cols])\n\ndummy = pd.get_dummies(balanced_df['Vehicle_Age'],drop_first=True)\nfeatures = pd.concat([dummy,balanced_df],axis=1)\nfeatures.drop('Vehicle_Age',axis=1,inplace=True)\n\nfeatures.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#to get uniform output\nfeatures = features.astype('float64')\nX_train = features.drop('Response',axis=1)\ny_train = features['Response']\n\n#creating dummies in test set\ndummy1 = pd.get_dummies(X_test['Vehicle_Age'],drop_first=True)\nX_test = pd.concat([dummy1,X_test],axis=1)\nX_test.drop('Vehicle_Age',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"logisticRegression = LogisticRegression(max_iter = 10000)\nlogisticRegression.fit(X_train, y_train)\npredictions = logisticRegression.predict(X_test)\nprint(f\"Accuracy score is {100*accuracy_score(y_test,predictions).round(2)}\\nROC-AUC score is {100*roc_auc_score(y_test,predictions).round(2)}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(n_estimators=100)\nrfc.fit(X_train, y_train)\nrfc_pred = rfc.predict(X_test)\nprint(f\"Accuracy score is {100*accuracy_score(y_test,rfc_pred).round(2)}\\nROC-AUC score is {100*roc_auc_score(y_test,rfc_pred).round(2)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc_preds = rfc.predict_proba(X_test)\nprint(\"AUC score after taking probabilities predictions and not classes predictions is\")\nroc_auc_score(y_test, rfc_preds[:,1], average = 'weighted')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.columns= ['less than 1 Year','greater than 2 Years', 'Gender', 'Age','Driving_License',\n                  'Region_Code', 'Previously_Insured', 'Vehicle_Damage', 'Annual_Premium','Policy_Sales_Channel']\nX_test.columns= ['less than 1 Year','greater than 2 Years', 'Gender', 'Age','Driving_License',\n                  'Region_Code', 'Previously_Insured', 'Vehicle_Damage', 'Annual_Premium','Policy_Sales_Channel']\n\nfrom xgboost import XGBClassifier\nxgb = XGBClassifier()\nxgb.fit(X_train, y_train)\nxgb_pred = xgb.predict(X_test)\nprint(f\"Accuracy score is {100*accuracy_score(y_test,xgb_pred).round(2)}\\nROC-AUC score is {100*roc_auc_score(y_test,xgb_pred).round(2)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_preds = xgb.predict_proba(X_test)\nroc_auc_score(y_test, xgb_preds[:,1], average = 'weighted')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}