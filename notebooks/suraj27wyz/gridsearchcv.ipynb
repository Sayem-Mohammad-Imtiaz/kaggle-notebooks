{"cells":[{"metadata":{"_uuid":"95120598675bb56be44f988cd1257d78c91d1505"},"cell_type":"markdown","source":"# **GridSearchCV on RandomForestClassifier**\n\n### In this kernel we will be appplying GridSearch for Hyperparameter Tuning for a classifier\n\n>*I will be using RandomForestClassifier but any Classsifier can be used*"},{"metadata":{"trusted":false,"_uuid":"5ef4904c736fbbe66ab3afc8396f3cc2008bbc64"},"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport numpy as np\n\nfrom pprint import pprint\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"b3eb9621f1c0877f2e98b4f959a724b701d956bc"},"cell_type":"code","source":"data = pd.read_csv('../input/data.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0a23110a337b4c518fae97ad3d39f8edc2327ff8"},"cell_type":"markdown","source":"### Checking for columns for Nan \n\nWe will check and remove any column that is not required."},{"metadata":{"trusted":false,"_uuid":"427548e79300f7f3a38711a2bf238ba84ec633dc"},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b3d1e932f36ad7272bd83c68a573f12a61203af7"},"cell_type":"markdown","source":"### Dropping Columns\n\nColumn : id, Unnamed: 32 will be dropped\n\nid is not required for classification and Unnamed: 32 has Nan"},{"metadata":{"trusted":false,"_uuid":"e1634016fda8325a518593672a205bc3a1212e55"},"cell_type":"code","source":"df = data.drop(['Unnamed: 32','id'], axis=1)\n\nprint(\"Final Columns in Dataset\")\nprint('='*50)\nprint(df.isnull().sum())\nprint('='*50)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e94b791c1bf902e9e2a4e7c67a51b50739092e33"},"cell_type":"markdown","source":"### Spliting the data for train and test\n\nWe changed the target column that is diagnosis to binary 0 and 1.\n\n* X -> attributes or features that will help predict out target column diagnosis\n* y -> Target column"},{"metadata":{"trusted":false,"_uuid":"a9018c880518eb153a451f842b8ca2a0267fff07"},"cell_type":"code","source":"X = df.iloc[:,1:]\ny = np.where(df['diagnosis']=='M', 1,0).astype(int)\n\nX_train, X_test, y_Train, y_Test = train_test_split(X, y, test_size =0.2, random_state =5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c3984174ba1917689f10ada1286ebb4e5d5970c6"},"cell_type":"markdown","source":"### Classifier RandomForest\n\nI will be using RandomForestClassifier for demo. You can choose any classsifier on which parameter tuning is required.\n\nThe default parameters are also displayed"},{"metadata":{"trusted":false,"_uuid":"040e6eb04705eeef393a9eeaf8efefe9b0534ea5"},"cell_type":"code","source":"model = RandomForestClassifier()\n\nprint(\"Default Parameters \")\nprint('='*50)\n\npprint(model.get_params())\n\nprint('='*50)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aa6490e19c3265039ba39d5c30cdd609a619a1a6"},"cell_type":"markdown","source":"### Parameters of classifier and their possible values for tuning\n\n*These are based on RandomForestClassifier.*\n>I will be applying GridSearch for tuning bootstrap, n_estimators, criterion, min_samples_leaf, max_features.\n\nYou should use your paramteres as per classifier."},{"metadata":{"trusted":false,"_uuid":"fbf4911b4dfb82651aecb51e200bcd23ab620ca8"},"cell_type":"code","source":"bootstrap_v = [True, False]\nn_estimators_v = list(range(100,2000,200))\ncriterion = ['gini', 'entropy']\nmin_sample_leaf_v = list(range(1,5,2))\nmax_features_v = ['sqrt', 'log2']\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"03539ae5ae88562f5beffa04c60baa335eb9647f"},"cell_type":"markdown","source":">Building the set of parameters to pass as variable to gridsearch"},{"metadata":{"trusted":false,"_uuid":"4eb3dacf780a379392dd0780e6b23f3cdeb7feee"},"cell_type":"code","source":"grid_params  = {\n    'bootstrap' : bootstrap_v,\n    'n_estimators' : n_estimators_v,\n    'criterion' : criterion,\n    'min_samples_leaf' : min_sample_leaf_v,\n    'max_features' : max_features_v\n}\n\nprint(\"Tuning Parameters\")\nprint('='*50)\n\npprint(grid_params)\nprint('='*50)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d89921bed335f0b6efccdd5bd1b1f08dfeb4fe9d"},"cell_type":"markdown","source":"## Applying gridSearch on model and fitting it\n\n >We passed our classifier as  estimator.\n\n* estimator = model to apply gridSearch\n* param_grid = the parameter set for tuning the classifier\n* cv = the cross-validation factor.\n* verbose = the intensity of background work that gets printed while fitting"},{"metadata":{"trusted":false,"_uuid":"c0ccb4412b9b6d3f2620dc51fc7655898bf6626f"},"cell_type":"code","source":"grid_search = GridSearchCV(estimator=model, param_grid=grid_params, cv=3, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"f10cb6fdf5202d52fe36f41913dc43880cff73cd"},"cell_type":"code","source":"grid_search.fit(X_train, y_Train)\n\nprint('Best Parameters for our classsifier')\nprint('='*50)\nprint(grid_search.best_params_)\nprint('='*50)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0fb2859c1429e21ad55d7d4609ae83eced0dcc38"},"cell_type":"markdown","source":"## Function that will evaluate the working of our Classifier on test set\n\n>It prints the parameters of classsifier, Classification report and Accuracy Score"},{"metadata":{"trusted":false,"_uuid":"a0d8a0d3d513ddff7f19d288c519c6ac62ba049f"},"cell_type":"code","source":"def evaluate(model, X, y):\n    \n    pprint(model.get_params())\n    print('=='*50)\n    predictions = model.predict(X)\n    report = classification_report(y, predictions)\n    \n    score = accuracy_score(y_true= y, y_pred= predictions)\n    \n    print(report)\n    print('=='*50)\n    print(\"{} {:0.2f}%\".format(\"Accuracy Score :: \", score*100))\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a2f413d5ab637f0e6fac34608d40cf23c2da2762"},"cell_type":"markdown","source":"### Evaluation of our best Estimator Selected from GridSearchCV"},{"metadata":{"trusted":false,"_uuid":"506d199019b0a7e890b881cb7d26a1cec4c07e0f"},"cell_type":"code","source":"evaluate(grid_search.best_estimator_, X_test, y_Test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9a08820031ecdb003244db6b14242f6fd67ff69f"},"cell_type":"markdown","source":"### Evaluation of our base Model"},{"metadata":{"trusted":false,"_uuid":"4a580360d34b5317cac875af5052583c86ceab1b"},"cell_type":"code","source":"model.fit(X_train, y_Train)\nevaluate(model, X_test, y_Test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2fb9f98066d128317d8ee9f6e445ad3333b57613"},"cell_type":"markdown","source":"## Conclusion\n\n>Our **Base Model accuracy was 97.37%** but after *hyperparameter tuning* our accuracy increased to **98.25% on Tuned Model**.\n\nThis is a significant increase in accuracy.\n\n*Score when i ran the kernel, but the accuracy will improve on paramter tuning in most cases*"},{"metadata":{"_uuid":"6aeeb466f7ddb23b13a50e094ad036c99d4596a8"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"7711b6b4dafe93d8c188d3766de95bb65e0a37eb"},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}