{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Packages Required"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"!pip3 install ktrain","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport missingno as msno\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport plotly.graph_objects as go\n#import plotly.express as px\nimport matplotlib.pyplot as plt\nimport spacy\nimport tensorflow as tf\nfrom wordcloud import WordCloud, STOPWORDS \nimport ktrain\nfrom ktrain import text\n\nfrom collections import Counter\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/trip-advisor-hotel-reviews/tripadvisor_hotel_reviews.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum().any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Sentiment Visualisation"},{"metadata":{"trusted":true},"cell_type":"code","source":"pos = [4, 5]\nneg = [1, 2]\nneu = [3]\n\ndef sentiment(rating):\n  if rating in pos:\n    return 2\n  elif rating in neg:\n    return 0\n  else:\n    return 1  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Sentiment'] = df['Rating'].apply(sentiment)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure([go.Bar(x=df.Sentiment.value_counts().index, y=df.Sentiment.value_counts().tolist())])\nfig.update_layout(\n    title=\"Values in each Sentiment\",\n    xaxis_title=\"Sentiment\",\n    yaxis_title=\"Values\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here,\n\n2 - Positive (4, 5)<br>\n1 - Neutral (3)<br>\n0 - Negative (1, 2)\n\nReview distrubution seems more inclined in the positive than the negative. The reason I am not going to neutral is cause that is just one rating whereas positive and negative have two ratings."},{"metadata":{},"cell_type":"markdown","source":"## Wordclouds of each Sentiment\n\nLet us now look at the word distribution overrall and for each sentiment."},{"metadata":{"trusted":true},"cell_type":"code","source":"nlp = spacy.load('en')\n\ndef normalize(msg):\n    \n    doc = nlp(msg)\n    res = []\n    \n    for token in doc:\n        if(token.is_stop or token.is_punct or token.is_space):\n            pass\n        else:\n            res.append(token.lemma_.lower())\n            \n    return res","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Review'] = df['Review'].apply(normalize)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"words_collection = Counter([item for sublist in df['Review'] for item in sublist])\nfreq_word_df = pd.DataFrame(words_collection.most_common(15))\nfreq_word_df.columns = ['frequently_used_word','count']\n\nfreq_word_df.style.background_gradient(cmap='PuBuGn', low=0, high=0, axis=0, subset=None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Overrall Wordcloud of Reviews "},{"metadata":{"trusted":true},"cell_type":"code","source":"word_list = [item for sublist in df['Review'] for item in sublist]\nword_string = \" \".join(word_list)\n\nwordcloud = WordCloud(stopwords=STOPWORDS,\n                          background_color='white', \n                      max_words=60000, \n                      width=1000,\n                      height=650\n                         ).generate(word_string)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As expected, it is a mixture of some good words and not much of the bad reviews. Let's break it down with each sentiment."},{"metadata":{},"cell_type":"markdown","source":"## Positive Sentiment Wordcloud"},{"metadata":{"trusted":true},"cell_type":"code","source":"pos_df = df[df['Sentiment'] == 2]\nwords_collection = Counter([item for sublist in pos_df['Review'] for item in sublist])\nfreq_word_df = pd.DataFrame(words_collection.most_common(15))\nfreq_word_df.columns = ['frequently_used_word','count']\n\nfreq_word_df.style.background_gradient(cmap='PuBuGn', low=0, high=0, axis=0, subset=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word_list_pos = [item for sublist in pos_df['Review'] for item in sublist]\nword_string_pos = \" \".join(word_list)\n\nwordcloud = WordCloud(stopwords=STOPWORDS,\n                          background_color='white', \n                      max_words=40000, \n                      width=1000,\n                      height=650\n                         ).generate(word_string_pos)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Positive words like \"good\", \"love\", \"great\" can be seen from this wordcloud"},{"metadata":{},"cell_type":"markdown","source":"## Neutral Sentiment Wordcloud"},{"metadata":{"trusted":true},"cell_type":"code","source":"neu_df = df[df['Sentiment'] == 1]\nwords_collection = Counter([item for sublist in neu_df['Review'] for item in sublist])\nfreq_word_df = pd.DataFrame(words_collection.most_common(15))\nfreq_word_df.columns = ['frequently_used_word','count']\n\nfreq_word_df.style.background_gradient(cmap='PuBuGn', low=0, high=0, axis=0, subset=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word_list_neu = [item for sublist in neu_df['Review'] for item in sublist]\nword_string_neu = \" \".join(word_list)\n\nwordcloud = WordCloud(stopwords=STOPWORDS,\n                          background_color='white', \n                      max_words=6000, \n                      width=1000,\n                      height=650\n                         ).generate(word_string_neu)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ah it seems \"problem\" sticks out a little here in the neutral reviews. Another word I managed to look into is \"expensive\". Maybe in future versions we can probably remove the obvious words like hotel and resort.  "},{"metadata":{},"cell_type":"markdown","source":"## Negative Sentiment Wordcloud"},{"metadata":{"trusted":true},"cell_type":"code","source":"neg_df = df[df['Sentiment'] == 0]\nwords_collection = Counter([item for sublist in neg_df['Review'] for item in sublist])\nfreq_word_df = pd.DataFrame(words_collection.most_common(15))\nfreq_word_df.columns = ['frequently_used_word','count']\n\nfreq_word_df.style.background_gradient(cmap='PuBuGn', low=0, high=0, axis=0, subset=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word_list_neg = [item for sublist in neg_df['Review'] for item in sublist]\nword_string_neg = \" \".join(word_list)\n\nwordcloud = WordCloud(stopwords=STOPWORDS,\n                          background_color='white', \n                      max_words=10000, \n                      width=1000,\n                      height=650\n                         ).generate(word_string_neg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some obvious words like \"bad\", \"problem\" can be seen in this wordcloud. Maybe when we expand the vocabulary we can clean the text a little better."},{"metadata":{},"cell_type":"markdown","source":"The model I am going to be using is the BERT model from the ktrain module. Before we get into the model, we need to turn the lists into strings."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Review'] = df['Review'].apply(lambda m: \" \".join(m))\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training BERT model"},{"metadata":{"trusted":true},"cell_type":"code","source":"(x_train, y_train), (x_test, y_test), preproc = text.texts_from_df(df, \n                                                                    'Review',\n                                                                    label_columns=['Sentiment'],\n                                                                    preprocess_mode='bert')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = text.text_classifier(name='bert',\n                             train_data=(x_train, y_train),\n                             preproc=preproc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learner = ktrain.get_learner(model=model,\n                             train_data=(x_train, y_train),\n                             val_data=(x_test, y_test),\n                             batch_size=6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learner.fit_onecycle(lr=2e-5,\n                     epochs=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Final Notes\n\nSlightly lower accuracy when dealing with more clean data in BERT with 83.81% in Training and 86.1% in Validation. <br>\n\nThat's it for now in this notebook. <br><br> Upvotes will be greatly appreciated :)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}