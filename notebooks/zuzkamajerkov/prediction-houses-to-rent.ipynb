{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**1. Importing Libraries**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/brasilian-houses-to-rent/houses_to_rent.csv')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(data.shape)\ndata.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2. Dropping index values as it's a duplicate column","metadata":{}},{"cell_type":"code","source":"data.drop(data.columns[0], axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head(13)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"3. Converting strings into numerical values","metadata":{}},{"cell_type":"code","source":"data['floor'].replace(to_replace='-', value=0, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['animal'].replace(to_replace='not acept', value=0, inplace=True)\ndata['animal'].replace(to_replace='acept', value=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['furniture'].replace(to_replace='not furnished', value=0, inplace=True)\ndata['furniture'].replace(to_replace='furnished', value=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in ['hoa', 'rent amount', 'property tax', 'fire insurance', 'total']:\n    data[col].replace(to_replace='R\\$', value='', regex=True, inplace=True)\n    data[col].replace(to_replace=',', value='', regex=True, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"4. Converting data types into int64.\n\nModels works in general better with integer than strings.","metadata":{}},{"cell_type":"code","source":"data = data.astype(dtype=np.int64)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"5. Getting rid of Sem info & Incluso from data set","metadata":{}},{"cell_type":"code","source":"data['hoa'].replace(to_replace='Sem info', value='0', inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['hoa'].replace(to_replace='Incluso', value='0', inplace=True)\ndata['property tax'].replace(to_replace='Incluso', value='0', inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isin(['Sem info']).any()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isin(['Incluso']).any()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"6. Shuffle data to not affect Model performance","metadata":{}},{"cell_type":"code","source":"data = data.sample(frac=1).reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = data['city']\nX = data.drop('city', axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**7. Modelling**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"7.1 Normalize values in dataset\n\nBefore we split data into train & test, we want to make sure that are prepared for modelling.\n\nFor the best performance of model prediction, we have to normalize values between 0 and 1. ","metadata":{}},{"cell_type":"code","source":"#Normalizing values in dataset\n\nscaler = MinMaxScaler()  #creating an object\nscaler.fit(X) #fitting it to the data, finding them in Max\nX = scaler.transform(X) #changing X to be new value between 0-1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"7.2 Perform split to train & text","metadata":{}},{"cell_type":"code","source":"\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"7.3 Choosing & Training models","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"log_model = LogisticRegression(penalty='l2', verbose=1)\nsvm_model = SVC(kernel='rbf', verbose=1)\nnn_model = MLPClassifier(hidden_layer_sizes=(16, 16), activation='relu', solver='adam', verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I have 3 models which I'm going to fit into data and see how they perform.","metadata":{}},{"cell_type":"code","source":"log_model.fit(X_train, y_train)\nsvm_model.fit(X_train, y_train)\nnn_model.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**8. Score of models**","metadata":{}},{"cell_type":"code","source":"print(log_model.score(X_test, y_test))\nprint(svm_model.score(X_test, y_test))\nprint(nn_model.score(X_test, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#to get number positive examples devided by the total number of examples\n\ndata[data.columns[0]].sum()/data.shape[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"86 % of our dataset is clasified as positive example. That mean that previous accuracy number (number of correct predictions over the total number of predictions) is not telling us very much. \n\nLet's say we predicted y=1 for every single example. then 86 % of time we will be right. So the accuracy metric is only good if we have equal number of positive and negative examples.\n\nThis is what we call \"skewed data\", where zeros and ones are not in equal proportion.\n\nWe are going to use different proportion, so we're going to use a different metric called \"F Score\".\n\n**F Score combines two metrics and gives you information about both of them **","metadata":{}},{"cell_type":"markdown","source":"**9. F-score**","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import f1_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"log_predictions = log_model.predict(X_test)\nsvm_predictions = svm_model.predict(X_test)\nnn_predictions = nn_model.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f1_score(log_predictions, y_test))\nprint(f1_score(svm_predictions, y_test))\nprint(f1_score(nn_predictions, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. Logistic regression model and Support Vector machine have almost identical values.\n2. Neural network model performed slightly better","metadata":{}}]}