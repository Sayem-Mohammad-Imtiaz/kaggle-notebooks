{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Saving Telco Customer Churn\n\nIn telecommunications, customers retention is way cheaper than seeking for new customers. \n\nIn order to lead the most valuable retention program, we will determine through Exploratory data analysis who are the more valuable customers by performing a segmentation of the customer database.\n\nAfter a thorough analysis of the provided data set, we will develop an interpretable machine learning model to predict churn. \n\nThis will allow us to target customers who are more likely to churn and use the insights developed during EDA to propose different strategies for the company to investigate for a potential retention program.\n\n#### Table of contents\n* [1. Exploratory Data Analysis](#EDA)\n * [1.2 Data Description](#EDA2)\n * [1.3 Descriptive analysis](#EDA3)\n    * [1.3.1 Charges and tenure](#EDA3.1)\n    * [1.3.2 Phone services and contracts](#EDA3.2)\n    * [1.3.3 Customers segmentation](#EDA3.3)\n* [2. Detecting Churn](#ML)\n * [2.1 One-hot encoding](#ML2)\n * [2.2 Data normalization](#ML3)\n * [2.3 Naive Classifiers](#ML4)\n * [2.4 Choice of metric](#ML5)\n * [2.5 Improving the classifier](#ML6)\n * [2.6 Feature Importances](#ML7) \n\n\n* [3. Saving Churn problem](#BM)\n * [3.1 Program strategies](#BM2) \n * [3.2 Simple Business model : simulation](#BM3) \n\n* [4. Conclusion](#Concl)"},{"metadata":{},"cell_type":"markdown","source":"## 1. Exploratory Data Analysis <a class=\"anchor\" id=\"EDA\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style=\"ticks\", color_codes=True)\npd.set_option('display.max_columns', None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.2 Data Description <a class=\"anchor\" id=\"EDA2\"></a>"},{"metadata":{},"cell_type":"markdown","source":"The given data set contains informations about Telco customers where each row represents a unique customers and the columns are informations regarding customers'services. The column \"Churn\" indcate whether the customer left the company within the last month.\n\nThe source data set can be found here : https://www.kaggle.com/blastchar/telco-customer-churn"},{"metadata":{"trusted":true},"cell_type":"code","source":"#customers_df = pd.read_csv('Telco-Customer-Churn.csv')\ncustomers_df = pd.read_csv('../input/WA_Fn-UseC_-Telco-Customer-Churn.csv')\ncustomers_df = customers_df[customers_df['TotalCharges'] != ' ']\ncustomers_df.TotalCharges = customers_df.TotalCharges.astype('float')\nnb_customers = len(customers_df.index)\nprint('There are a total of %s customers in the dataset among which %s left within the last month.' %(nb_customers, customers_df[customers_df['Churn'] == \"Yes\"].shape[0]))\nchurnNB = customers_df['Churn'].value_counts()[1]\nchurnrate = float(churnNB) / nb_customers\nprint('The churn rate is {:.2f}%'.format(churnrate*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customers_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some statistics regarding numerical values in the data set."},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"customers_df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All features are categorical variables except MonthlyCharges, TotalCharges and tenure which are continuous variables.\n\nWe observe that SeniorCitizen as been listed as a continuous variable by pandas while it contains only 1's and 0's. Hence, we decide to convert it to a categorical variable."},{"metadata":{"trusted":true},"cell_type":"code","source":"customers_df.SeniorCitizen = customers_df.SeniorCitizen.astype('category')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.3 Descriptive analysis <a class=\"anchor\" id=\"EDA3\"></a>"},{"metadata":{},"cell_type":"markdown","source":"In order to determine services/features which discriminate loyal customers from the others, we will split the data set and run our analysis separately. \nThroughout this notebook, we will use blue-shaded colors for loyal customers and red-shaded for disloyal ones."},{"metadata":{"trusted":true},"cell_type":"code","source":"loyal_customers = customers_df[customers_df['Churn'] == \"No\"]\ndisloyal_customers = customers_df[customers_df['Churn'] == \"Yes\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**1.3.1 Charges and tenure** <a class=\"anchor\" id=\"EDA3.1\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"dims = (20, 10)\nfig, ax =plt.subplots(2,3,figsize=dims)\nplt.suptitle('Histograms of charges and tenure between loyal (first row) and disloyal customers (second row) ')\n#loyal customers\nsns.distplot(loyal_customers.MonthlyCharges, ax=ax[0, 0])\nsns.distplot(loyal_customers.TotalCharges, ax=ax[0, 1])\nsns.distplot(loyal_customers.tenure, ax=ax[0,2])\n#disloyal customers\nsns.distplot(disloyal_customers.MonthlyCharges, ax=ax[1, 0], color='red')\nsns.distplot(disloyal_customers.TotalCharges, ax=ax[1, 1], color='red')\nsns.distplot(disloyal_customers.tenure, ax=ax[1,2], color='red')\nplt.savefig('charges_and_tenure.jpg')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- **Monthly Charges** : We observe that for loyal customers, an important proportion of customers bring between \\\\$20 and \\\\$25 each month while disloyal ones tend to pay more important charges, i.e, between \\\\$50 and \\\\$100. These figures may indicate that cheap packages are a proxy for customer retention. It may be interesting to determine if they mostly represent students or teenagers rather than Senior citizens as they represent a proportion of the population with lower income.\n\n- **TotalCharges and tenure** : both distribution are heavyskewed. We notice that most of the customers have paid quite low Total amount of Charges. \nIn the **first case**, it may be due to the fact that we categorized loyal customers as low-costs ones, mostly. We observe customers with low tenure (less than 12 months = 1 year) which may denote new customers. \nIn the **second case**, it may be explained by the fact that most customers leave the company really early (very low tenure).\n\nThe histogram highlights that max(tenure) = 72 months (6 years) with a peak frequency on this value. It suggests that the dataset considers that long run customers with tenure > 72 months are included in the dataset with tenure = 72 months. Hence, people with the maximum tenure are considered as acquired customers and retention should not be focused on them. "},{"metadata":{},"cell_type":"markdown","source":"**1.3.2 Phone services and contracts** <a class=\"anchor\" id=\"EDA3.2\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"dims = (20, 10)\nfig, ax =plt.subplots(2,3,figsize=dims)\nplt.suptitle('Pie charts of contracts and phone services between loyal (first row) and disloyal customers (second row) ')\n#loyal customers\nloyal_customers.Contract.value_counts().plot(kind='pie',shadow=True,autopct='%1.1f%%', ax=ax[0,0], colors = ['blue', 'purple', 'green'])\nloyal_customers.InternetService.value_counts().plot(kind='pie',shadow=True,autopct='%1.1f%%', ax=ax[0,1], colors = ['blue', 'purple', 'green'])\nloyal_customers.PhoneService.value_counts().plot(kind='pie',shadow=True,autopct='%1.1f%%', ax=ax[0,2], colors = ['blue', 'purple', 'green'])\n#disloyal customers\ndisloyal_customers.Contract.value_counts().plot(kind='pie',shadow=True,autopct='%1.1f%%', ax=ax[1,0], colors = ['red', 'pink', 'orange'])\ndisloyal_customers.InternetService.value_counts().plot(kind='pie',shadow=True,autopct='%1.1f%%', ax=ax[1,1], colors = ['red', 'pink', 'orange'])\ndisloyal_customers.PhoneService.value_counts().plot(kind='pie',shadow=True,autopct='%1.1f%%', ax=ax[1,2], colors = ['red', 'pink', 'orange'])\nplt.savefig('services and contracts.jpg')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- **Contract** : Loyal customers contracts are quite balanced between month-to-month, One-year and Two-year while a huge proportion (**88.6%**) of disloyal customers chose month-to-month contracts. These are non-binding contracts allowing the customer to leave the company whenever it fits to him. While it may denote something negative, it may also describe two category of customers. First of all, they may represent tourists passing through with the sole need/purpose to use the phone company services for a limited amount of time **or** represent customers in search of a new phone company who try several for a short time. Therefore, it may be worthwhile designing an effective strategy to capture these customers by being more competitive than other telephone companies.\n\n- **Internet Service** : Similarly, internet services are quite balanced among loyal customers while most disloyal ones tend to prefer the Fiber optic option, which is probably the most expensive option, explaining why disloyal customers tend to pay more monthly charges than loyal ones. Furthermore, it is reasonable to think that passing through tourists put more emphasis on the Internet service provided rather than other ones, explaining this choice. An opportunity may be seized at this level.\n\n- **Phone Service** : As expected there is no significant difference regarding the choice of using a phone service or not between the two type of customers since Telco is a phone company, hence most customers requests this company for its phone services mainly."},{"metadata":{},"cell_type":"markdown","source":"**1.3.3  Customers Segmentation** <a class=\"anchor\" id=\"EDA3.3\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"dims = (20, 10)\nfig, ax =plt.subplots(2,4,figsize=dims)\nplt.suptitle('Customers segmentation between loyal (first row) and disloyal customers (second row) ')\n#loyal customers\nsns.catplot(x=\"PhoneService\", y=\"MonthlyCharges\", kind=\"box\", hue=\"Partner\", data=loyal_customers, ax=ax[0,0], palette = ['blue', 'purple', 'green'])\nloyal_customers[loyal_customers['Partner'] == 'Yes'].MultipleLines.value_counts().plot(kind='pie',shadow=True,autopct='%1.1f%%', ax=ax[0,1], title='Customers with a partner', colors = ['blue', 'purple', 'green'])\nloyal_customers[loyal_customers['MonthlyCharges'] < 40].SeniorCitizen.value_counts().plot(kind='pie',shadow=True,autopct='%1.1f%%', ax=ax[0,2], title='Low Cost customers', colors = ['blue', 'purple', 'green'])\nloyal_customers[loyal_customers['MonthlyCharges'] > 70].SeniorCitizen.value_counts().plot(kind='pie',shadow=True,autopct='%1.1f%%', ax=ax[0,3], title='Premium customers', colors = ['blue', 'purple', 'green'])\n#disloyal customers\nsns.catplot(x=\"PhoneService\", y=\"MonthlyCharges\", kind=\"box\", hue=\"Partner\", data=disloyal_customers, ax=ax[1,0], palette = ['red', 'pink', 'orange'])\ndisloyal_customers[disloyal_customers['Partner'] == 'Yes'].MultipleLines.value_counts().plot(kind='pie',shadow=True,autopct='%1.1f%%', ax=ax[1,1], title='Customers with a partner', colors = ['red', 'pink', 'orange'])\ndisloyal_customers[disloyal_customers['MonthlyCharges'] < 40].SeniorCitizen.value_counts().plot(kind='pie',shadow=True,autopct='%1.1f%%', ax=ax[1,2], title='Low Cost customers', colors = ['red', 'pink', 'orange'])\ndisloyal_customers[disloyal_customers['MonthlyCharges'] > 70].SeniorCitizen.value_counts().plot(kind='pie',shadow=True,autopct='%1.1f%%', ax=ax[1,3], title='Premium customers', colors = ['red', 'pink', 'orange'])\nplt.close(2)\nplt.close(3)\nplt.close(4)\nplt.close(5)\nplt.savefig('multi_variate.jpg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Proportion of senior citizen in whole database %s\" %(customers_df.SeniorCitizen.value_counts().values / customers_df.shape[0]))\nprint(\"Proportion of senior citizen among loyal customers %s\" %(loyal_customers.SeniorCitizen.value_counts().values / loyal_customers.shape[0]))\nprint(\"Proportion of senior citizen among disloyal customers %s\" %(disloyal_customers.SeniorCitizen.value_counts().values / disloyal_customers.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- **Effect of having a partner and/or a phone services on monthly charges** : On a first hand, we observe that **among loyal customers**, subscribing to a phone service increases monthly charges. Furthermore, it seems that the charges are higher (comparing the median values) when the customer has a client, however the variance is higher when subscribing to a phone service. It is may be explained by the fact that having a Phone service (main service for the company) just service as a basis, and customers monthly charges differenciate themselves from others depending on extra services they choose. We also notice that customers who have a partner tend to pay more than the one who do not. It may be explained by the fact that it may exist some discount family packages rather than individual subscriptions. It is observed in the pie plot, as half of the customers with a partner tend to have multiples lines. On the other hand, we observe the same effects **among disloyal customers** with the slight difference in the fact that the variance is much lower.\n\n\n\n- **Which social status are represented by low-cost and premium customers ?** Most low-cost customers are senior citizens in both cases, with a lower proportion among disloyal customers. This may be explained by the fact that young people tend to be more volatile than older ones. Similarly, most premium customers are senior citizens too with a lower proportion among disloyal customers. It is importante to note that the proportion of senior citizen (**83.76%**) in the whole Telco database explains mostly this observation. Furthermore, the difference is not significant between the two subgroups."},{"metadata":{},"cell_type":"markdown","source":"## 2. Detecting Churn ! <a class=\"anchor\" id=\"EDA\"></a>"},{"metadata":{},"cell_type":"markdown","source":"In this part we will develop a ML model to predict customers who are potential *Churn* candidates, in order to take action to change this behavior.\n\nHere is an outline of the successive steps we will take :\n\n- one hot encoding of categorical variables to obtain \"machine readable\" data.\n- Data scaling/normalization/standardization to avoid weights from its dimensions affecting the results\n- dimensionnality reduction : we will perform Principal Component Analysis (PCA) here."},{"metadata":{},"cell_type":"markdown","source":"### 2.1 One-hot encoding <a class=\"anchor\" id=\"ML2\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = customers_df.copy()\n\n#Convert gender to binary and drop redundant column\ndata[\"Male\"]=data['gender'].map(lambda x : 1  if x =='Male' else 0)\ndata = data.drop(columns=\"gender\")\n\n#Convert internetService to binary : 1 if there is any, else 0. Then we create a column for fiber optic,\n# the negative option will automatically imply DSL. Hence we can remove internet service column\ndata[\"InternetYes\"]= data['InternetService'].map(lambda x :0  if x =='No' else 1)\ndata[\"FiberOptic\"]= data[\"InternetService\"].map(lambda x : 1  if x =='Fiber optic' else 0)\ndata = data.drop(columns=\"InternetService\")\n\n#Convert target variable to binary\ndata[\"Churn\"]= data['Churn'].map(lambda x : 0  if x =='No' else 1)\n\nbinary_columns=[\"Partner\",\"Dependents\",\"PhoneService\",\"MultipleLines\",\"PaperlessBilling\",\"OnlineSecurity\",\n                \"OnlineBackup\",\"DeviceProtection\",\"TechSupport\",\"StreamingTV\",\"StreamingMovies\"]\n\nfor c in binary_columns:\n    data[c] = data[c].map(lambda x : 1  if x =='Yes' else 0)\n    \n#Create dummies for the remaining categorical columns and drop redundant original column\ndata = pd.concat([data, pd.get_dummies(data[\"Contract\"],prefix=\"Contract\")], axis=1)\ndata = data.drop(columns=\"Contract\")\n\ndata = pd.concat([data, pd.get_dummies(data[\"PaymentMethod\"],prefix=\"Pay\")], axis=1)\ndata= data.drop(columns=\"PaymentMethod\")\n\n#finally drop customerID columns as it is irrelevant information for the model\ndata = data.drop(columns=\"customerID\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.2 Data Normalization <a class=\"anchor\" id=\"ML3\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\ndata = pd.DataFrame(scaler.fit_transform(data),columns=data.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.3 Naive classifiers <a class=\"anchor\" id=\"ML4\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_recall_curve, f1_score, recall_score, accuracy_score, precision_score, confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_confusion_matrix(y_test, y_pred) :   \n    \n    conf_matrix = pd.DataFrame(confusion_matrix(y_test,y_pred,labels=[1,0]), columns = ['Churn Yes', 'Churn No'])\n    conf_matrix.index = ['Churn Yes', 'Churn No']\n    \n    print(\"Accuracy Score:\",accuracy_score(y_test,y_pred))\n    print(\"Recall Score:\",recall_score(y_test,y_pred,labels=[1,0]))\n    print(\"Precision Score:\",precision_score(y_test,y_pred,labels=[1,0]))\n    print(\"Confusion Matrix:\")\n    \n    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"YlGnBu\")\n    plt.xlabel('Predicted Labels')\n    plt.ylabel('True labels')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(data.drop(columns=\"Churn\"), data[\"Churn\"], stratify=data[\"Churn\"], random_state=42)\nX_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test, stratify=y_test, random_state=42)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"everyone_churn = np.ones_like(y_test)\nprint_confusion_matrix(y_test, everyone_churn)\nplt.savefig('everyone_churn.png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A naive classifier which always output \"Yes\" is not good at all as we will have to spend money on a business strategy to keep each customer in a database which is too expensive, i.e, 323 out of 440 were not churning customers but we spent money on them."},{"metadata":{"trusted":true},"cell_type":"code","source":"nobody_churn = np.zeros_like(y_test)\nprint_confusion_matrix(y_test, nobody_churn)\nplt.savefig('nobody_churn.png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Similarly, another classifier which always output \"No\" is still not good enough as our main problem stated that customer retention is less expensive than capturing new customers. With this strategy, we lose too many customers, i.e, 117 out of 440 were actually churning customers but our classifier missed to spot them. We would need to spend extra money to replace these 117 lost customers."},{"metadata":{},"cell_type":"markdown","source":"### 2.4 Choice of metric <a class=\"anchor\" id=\"ML5\"></a>"},{"metadata":{},"cell_type":"markdown","source":"We need to decide which metric to use for our model.\n\nThe **Confusion Matrix** summarizes the test results from a supervised model. The results of a prediction from a test set, where we know the actual (true) and predicted labels are put in two axis. On one axis we have the True labels, as given by the test set, on the other, the predictions as given by the model. Here, we see the true positives (TP), true negatives (TN) - correctly predicted values - and the false positives (FP) and false negatives (FN) - incorrectly predicted values.\n\n**Accuracy** measures how well our model predicts all the classes, regardless of balance. It is the ratio of \"correctly predicted\" results, versus the entire sample, defined by : (TP + TN)/(TP + TN + FP + FN)\n\n**Precision** is the fraction of predictions that are correctly predicted. Hence, it is the probability that a (randomly selected) customer is actually about to churn : TP / (TP + FP)\n\n**Recall** is measure the share of true values that have been correctly predicted. It is the probability that a (randomly selected) \"about to Churn\"-customer is retrieved in a search : TP / (TP + FN)\n\n**F1** is the harmonic mean of Precision and Recall, usually a good metric of the balance between the two metrics.\n\n\nIn our scenario, **we are more interested in recall** as we want to make sure we capture as many churning customers as possible even though we may raise too many false alarms (false negative, i.e, people who don't churn) as retaining a customer is less expensive than capturing a new one. \n\nOf course, we do not want a naive classifier which will always says \"yes\" otherwise it will be too expensive to target a business strategy on each customer. Hence, we will make sure to choose a threshold such that the precision score is not too low neither."},{"metadata":{},"cell_type":"markdown","source":"### 2.5 Improving the classifier <a class=\"anchor\" id=\"ML6\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nimport matplotlib.ticker","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = {'penalty' : ['l1', 'l2'],\n    'C' : np.logspace(-1, 1, 10),\n    'solver' : ['liblinear']}\n\nclf = LogisticRegression()\ngs = GridSearchCV(clf, param_grid, cv=5, n_jobs=-1, verbose=0, scoring=\"recall\")\ngs.fit(X_train, y_train)\n\ny_score = gs.decision_function(X_valid)\n\nprecision, recall, thresholds = precision_recall_curve(y_valid, y_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(thresholds, precision[:len(precision)-1], label='precision', ls = 'dashed')\nplt.plot(thresholds, recall[:len(recall)-1], label='recall', ls = 'dashed')\nplt.legend()\nplt.title('Precision and Recall scores as a function of the decision threshold')\nplt.xlabel('Threshold')\nplt.ylabel('Metrics value')\nplt.grid()\n\n#axes\nax=plt.gca()\n\nf = lambda x,pos: str(x).rstrip('0').rstrip('.')\nax.xaxis.set_major_locator(matplotlib.ticker.MultipleLocator(0.5))\nax.xaxis.set_major_formatter(matplotlib.ticker.FuncFormatter(f))\nplt.savefig('precision_recall_threshold.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We want the recall as high possible while making sure precision is not too low. When looking at the precision and recall curve, a threshold = -1.5 allows us to reach a score of more than 80% while making sure precision is not too low (minimum 40%)."},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_threshold = (gs.decision_function(X_test) >= -1.5).astype(bool) #this computes a new set of y_pred based on a different threshold, which we set on the decision function \n\nprint_confusion_matrix(y_test,y_pred_threshold)\nplt.xlabel('Predicted Labels')\nplt.ylabel('True labels')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our new classifier reached a recall score of **90.60%** with a precision score of **47.75%**. It allowed us to to spot 106 out of the 117 churning customers. Hence we would only need to **spend extra money to replace 11 customers** in comparison to the previous cases.\nFurthermore, 116 out of the 323 non-churning customers were classified as churning ones by our classifier which is still better than the previous model."},{"metadata":{},"cell_type":"markdown","source":"### 2.6 Feature Importances <a class=\"anchor\" id=\"ML7\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"estimator = gs.best_estimator_\nclass_labels = gs.classes_\nweights = estimator.coef_[0]\nweights_index = np.argsort(weights)[::-1]\n\n\n#take 5 most important feature in each class\nweights = np.sort(weights)[::-1]\n\n#about to churn\npositive_class = weights_index[:5]\npositive_feature = X_train.columns[positive_class].values\ncoeff_pos = weights[:5]\n\n\n\nnegative_class = weights_index[-5:][::-1]\nnegative_feature = X_train.columns[negative_class].values\ncoeff_neg = weights[-5:][::-1]\n\n\ntop5_class1 = list(zip(coeff_pos, positive_feature))\ntop5_class2 = list(zip(coeff_neg, negative_feature))\n\nprint(\"Most important feature used to predict churn with their weights\")\nprint('--------------------------------------')\n\nfor w, n in top5_class1 :\n    print(\"{} : {}\".format(n, w))\n    \nprint('-----------')\n    \nfor w, n in top5_class2 :\n    print(\"{} : {}\".format(n, w))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Saving  Churn problem ! <a class=\"anchor\" id=\"BM\"></a>"},{"metadata":{},"cell_type":"markdown","source":"During the first part, we presented Telco Churn problem and gained insights regarding features that separate churning customers from loyal customers using descriptive analysis. \nIn the second part, we proposed a ML model as a solution to predict Churn in order to detect potential customers about to Churn and design specific targeted strategies to keep those customers in our company.\n\nIn the following, we will get back to the business problem. \nFirst of all, we will use all discoveries found in the previous parts and propose strategies to Telco Company owners as a solution to keep their customers.\nIn the second part, we are gonna present a simple business model and determine how much money the ML tool we designed may allow Telco owners to save."},{"metadata":{},"cell_type":"markdown","source":"### 3.1 Program strategies <a class=\"anchor\" id=\"BM2\"></a>"},{"metadata":{},"cell_type":"markdown","source":"Regarding Telco's actual business, the following may be taken into account.\n\n- **Charges** : Low-cost customer represents a huge part of loyal ones. Even though, low charges are a proxy for loyal customers, it may be one of the most sensitive factor to change as it impacts directly the income of Telco Company. However, we noticed that customers with a partner do pay more than the others, hence it may be interesting to offer family packages with discount or goodies to justify the high prices.\n\n- **Contracts** : We observed that most churning customers were offered short-term contract, i.e month-to-month. This is not good for Telco as it allows the customers to be always tempted by new offers from the concurrent. A solution would be to either remove these short-term contract and offer only long-term ones, or promote/value long-term contract with lower monthly charges than in short ones and create a loyalty program with bonus points. The longer you stay in the company, the higher the discount on new devices, smartphones and subscriptions.\n\n- **Premium Services** : Internet and video-streaming services seems to be the most costly, hence the most valuable ones for the company. However, they seem to represent the most requested services by passing through tourists. It may be interesting to change their pricing as \"an exchange\" for loyalty. The owners may offer *significant differences in price* for Fiber optic for example depending on the type of contract you choose. It allow to balance the loss of these passing through clients (tourists), as it impossible to keep them in the business, by making a huge profit at once.\n"},{"metadata":{},"cell_type":"markdown","source":"### 3.2 Simple Business model : simulation <a class=\"anchor\" id=\"BM3\"></a>"},{"metadata":{},"cell_type":"markdown","source":"Let's design a simple simulation. \n\n**New clients strategy** : We make the assumption that for each churning customer, Telco would invest **\\\\$200** in Marketing, ads, targeting emails and campaings to replace him. \n\n**Retaining customers strategy** : On the other hand, they would invest only **\\\\$50** to retain a customer already in the database, by allowing him discount on some services for example."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of customers : %s\" % y_test.shape[0])\nprint(\"Number of churning customers : %s\" % sum(y_test == 1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We compare here the three models studied earlier :\n- **Nobody churn** : Our model miss 117 churning customers -> We need to capture 117 new clients.\n- **Everybody churn** : We miss no customers, but we need to invest on all of them. (440)\n- **Our Logit Model** : We spot 106 out of 117 churning customers, we need to replace 11 of them. Furthermore, 116 were classified as churning customers when they were not, we need to invest in them."},{"metadata":{"trusted":true},"cell_type":"code","source":"def cost(clients_to_retain, clients_to_obtain) :\n    return 50*clients_to_retain + 200*clients_to_obtain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nobody_churn = cost(0, 117)\neveryone_churn = cost(440, 0)\nlogit_model = cost(106, 11)\n\nstrategies = [(nobody_churn, \"No action taken\"), (everyone_churn, \"Retain all customers\"), (logit_model, \"Our model\")]\n\nall_costs = pd.DataFrame(strategies, columns=[\"Cost ($)\", \"Strategy\"])\nall_costs.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x=\"Strategy\", y=\"Cost ($)\", kind=\"bar\", data=all_costs, palette=[\"red\", \"yellow\", \"green\"])\nplt.title(\"Associated cost for each strategy taken\")\nplt.savefig(\"strategies_cost.png\")\nplt.grid()\n\nax=plt.gca()\nf = lambda x,pos: str(x).rstrip('0').rstrip('.')\nax.yaxis.set_major_locator(matplotlib.ticker.MultipleLocator(2000))\nax.yaxis.set_major_formatter(matplotlib.ticker.FuncFormatter(f))\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Conclusion <a class=\"anchor\" id=\"Concl\"></a>"},{"metadata":{},"cell_type":"markdown","source":"During our analysis, we managed to identify key factors identifying a potential churning customers. \n\nWe proposed a Logistic regression model with a recall at **90.60%** to minimize Telco's company cost for customer retention. \n\nOur strategy in comparison to the current state of affairs has allowed Telco to save **\\\\$15900**."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}