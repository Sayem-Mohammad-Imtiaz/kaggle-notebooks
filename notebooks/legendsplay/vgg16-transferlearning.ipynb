{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport pathlib\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, array_to_img, load_img\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\nfrom tensorflow.keras.models import Sequential\n\nimport pandas as pd\n\nimport cv2\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfrom sklearn.metrics import accuracy_score\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import datasets, layers, models\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization\nfrom tensorflow.keras.callbacks import TensorBoard\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom PIL import Image \nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom tensorflow.keras.layers import Conv2D , MaxPool2D , Flatten\n\nfrom tensorflow.keras.layers import Input, Lambda, Dense, Flatten\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\nfrom tensorflow.keras.models import Sequential","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_data = []\nimage_labels = []\ntotal_classes = 43\nheight = 64\nwidth = 64\nchannels = 3\ninput_path = '/kaggle/input/gtsrb-german-traffic-sign/'\n\nfor i in range(total_classes):\n    path = input_path + 'Train/' + str(i)\n    print(path)\n    images = os.listdir(path)\n\n    for img in images:\n        try:\n            image = cv2.imread(path + '/' + img)\n            image_fromarray = Image.fromarray(image, 'RGB')\n            resize_image = image_fromarray.resize((height, width))\n            image_data.append(np.array(resize_image))\n            image_labels.append(i)\n        except:\n            print(\"Error - Image loading\")\n\n#Converting lists into numpy arrays\n#Converting lists into numpy arrays\nimage_data = np.array(image_data)\nimage_labels = np.array(image_labels)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dir = '../input/gtsrb-german-traffic-sign'\n    \nplt.figure(figsize=(10, 10))\nfor i in range (0,43):\n    plt.subplot(7,7,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    path = dir + \"/meta/{0}.png\".format(i)\n    img = plt.imread(path)\n    plt.imshow(img)\n    plt.xlabel(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#shuffling data\nshuffle_indexes = np.arange(image_data.shape[0])\nnp.random.shuffle(shuffle_indexes)\nimage_data = image_data[shuffle_indexes]\nimage_labels = image_labels[shuffle_indexes]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Splitting training and testing dataset\nX_train, X_valid, y_train, y_valid = train_test_split(image_data, image_labels, test_size=0.2, random_state=42, shuffle=True)\n\nX_train = X_train/255 \nX_valid = X_valid/255\n\nprint(\"X_train.shape\", X_train.shape)\nprint(\"X_valid.shape\", X_valid.shape)\nprint(\"y_train.shape\", y_train.shape)\nprint(\"y_valid.shape\", y_valid.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting the labels into one hot encoding\ny_train = keras.utils.to_categorical(y_train, total_classes)\ny_valid = keras.utils.to_categorical(y_valid, total_classes)\n\nprint(y_train.shape)\nprint(y_valid.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nvgg16 = VGG16(input_shape=(64,64,3), weights='imagenet', include_top=False)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# don't train existing weights\nfor layer in vgg16.layers:\n    layer.trainable = False\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"add_model = Sequential()\nadd_model.add(Flatten(input_shape=vgg16.output_shape[1:]))\n\nadd_model.add(Dense(1024, activation='relu'))\n\n\n\nadd_model.add(Dense(y_train.shape[1], activation='softmax'))\n\nmodel = Model(inputs=vgg16.input, outputs=add_model(vgg16.output))\nlearning_rate = 0.0001\ndef results(model):\n  adam = Adam(lr=learning_rate)\n# tell the model what cost and optimization method to use\nmodel.compile(\n  loss='categorical_crossentropy',\n  optimizer='adam',\n  metrics=['accuracy']\n)\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 3\nhistory = model.fit(X_train, y_train, batch_size=128, epochs=epochs,\nvalidation_data=(X_valid, y_valid))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(history.history).plot(figsize=(8, 5))\nplt.grid(True)\nplt.gca().set_ylim(0, 1) # setting limits for y-axis\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#testing accuracy on test dataset\nfrom sklearn.metrics import accuracy_score\n\ntest = pd.read_csv(input_path + '/Test.csv')\n\nlabels = test[\"ClassId\"].values\ntest_imgs = test[\"Path\"].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#testing accuracy on test dataset\nfrom sklearn.metrics import accuracy_score\n\ntest = pd.read_csv(input_path + '/Test.csv')\n\nlabels = test[\"ClassId\"].values\ntest_imgs = test[\"Path\"].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dictionary to label all traffic signs class.\nclasses = { 1:'Speed limit (20km/h)',\n            2:'Speed limit (30km/h)', \n            3:'Speed limit (50km/h)', \n            4:'Speed limit (60km/h)', \n            5:'Speed limit (70km/h)', \n            6:'Speed limit (80km/h)', \n            7:'End of speed limit (80km/h)', \n            8:'Speed limit (100km/h)', \n            9:'Speed limit (120km/h)', \n            10:'No passing', \n            11:'No passing veh over 3.5 tons', \n            12:'Right-of-way at intersection', \n            13:'Priority road', \n            14:'Yield', \n            15:'Stop', \n            16:'No vehicles', \n            17:'Veh > 3.5 tons prohibited', \n            18:'No entry', \n            19:'General caution', \n            20:'Dangerous curve left', \n            21:'Dangerous curve right', \n            22:'Double curve', \n            23:'Bumpy road', \n            24:'Slippery road', \n            25:'Road narrows on the right', \n            26:'Road work', \n            27:'Traffic signals', \n            28:'Pedestrians', \n            29:'Children crossing', \n            30:'Bicycles crossing', \n            31:'Beware of ice/snow',\n            32:'Wild animals crossing', \n            33:'End speed + passing limits', \n            34:'Turn right ahead', \n            35:'Turn left ahead', \n            36:'Ahead only', \n            37:'Go straight or right', \n            38:'Go straight or left', \n            39:'Keep right', \n            40:'Keep left', \n            41:'Roundabout mandatory', \n            42:'End of no passing', \n            43:'End no passing veh > 3.5 tons' }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}