{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> This dataset has information about bank customers and is a binary classification problem. The problem statement is to predict if the customer exits the banks(stops using bank services/products) or continues being a customer. We will look into the dataset now.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df= pd.read_csv('/kaggle/input/churn-modelling/Churn_Modelling.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> We have 10000 observations with 14 columns in our dataset.\n> Our target variable is 'Exited' which has two values 0 & 1, where 0 means not exited and 1 means exited.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.options.display.max_rows=None\npd.options.display.max_columns=None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport scipy.stats\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> There are no null values in our dataset.\n> Next, we will drop some columns which are not required for analysis and modeling purpose.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['RowNumber', 'CustomerId','Surname'], axis=1, inplace=True )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> We will look at some statistical details like mean, min, max & percentile values.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Univariate Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_features= df[['CreditScore','Age', 'Balance', 'EstimatedSalary']]\nfor i in numerical_features.columns:\n    sns.distplot(df[i])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['CreditScore'], hist=False)\nplt.show()\nscipy.stats.norm.interval(0.50, df['CreditScore'].mean(), df['CreditScore'].std() )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"> The above graph illustrates distribution of credit score. \n50% of the customers are having credit score between 585 and 715 which is fair to good as per credit score ranges. \nSo, the people having low credit score need to improve their credit score in order to help improve their financial situation.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df['Geography'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Most of the data is of banks operating in France alone and the rest data is approximately equal for banks operating in Spain and Germany.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['HasCrCard'].value_counts().plot(kind='bar')\nplt.title('Credit Card')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Majority of customers have bank credit cards.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df['NumOfProducts'])\nplt.title('Number of products')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Most of the customers have either one or two products.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['IsActiveMember'].value_counts().plot(kind='bar')\nplt.title('Active member')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> We have approximately equal number of active and inactive customers.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Bivariate Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes= plt.subplots(1,2, figsize=(10,5))\nsns.countplot(df['Gender'], ax=axes[0])\nprops = (df.groupby(\"Gender\")['Exited'].value_counts(normalize=True).unstack())*100\nprops.plot(kind='bar', stacked='True', ax=axes[1])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Though, males are more in number than females as per left graph, right graph shows that the churn rate of females is higher than that of males.\nThus, females are more likely to churn wheras males are more likely to open accounts and continue being the customer of the bank.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x= df['Exited'], y=df['Age'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> We can observe that people between age 40-52 seem to exit banks more frequently than the other age group people. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes= plt.subplots(1,2, figsize=(15,6))\nsns.countplot(df['Geography'], hue=df['Exited'], ax=axes[0])\nprops = (df.groupby(\"Geography\")['Exited'].value_counts(normalize=True)*100).unstack()\nprops.plot(kind='bar', stacked='True', ax=axes[1])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Even though most of the customers are from France as can be seen from left graph, the right graph shows that the number of customers leaving the business in France as well as Spain are almost equal while that for Germany is comparatively higher.\nThus, Germany customers are more likely to churn than France and Spain customers.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"props = (df.groupby(\"IsActiveMember\")['Exited'].value_counts(normalize=True).unstack())*100\nprops.plot(kind='bar', stacked='True')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Inactive members are more likely to churn than Active members.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"props = (df.groupby(\"Tenure\")['Exited'].value_counts(normalize=True).unstack())*100\nprops.plot(kind='bar', stacked='True')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> As churn rate is almost similar for all classes, we can say that tenure has no significant difference on churn rate.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"props = (df.groupby(\"HasCrCard\")['Exited'].value_counts(normalize=True).unstack())*100\nprops.plot(kind='bar', stacked='True')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Having credit card does not really impact the churn.\nAs churn rate for both classes is approximarely equal, we can see that this feature is not a good predictor of target variable.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Data preparation","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Outlier treatment","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig=plt.subplots(figsize=(15,15))\nfor i, j in enumerate(numerical_features):\n    plt.subplot(8, 2, i+1)\n    plt.subplots_adjust(hspace = 1.0)\n    sns.boxplot(x=j,data = df)\n    plt.xticks(rotation=90)\n    #plt.title(\"Telecom\")\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of outliers in each feature\n\n\noutliers=[]\nfor i in numerical_features.columns:\n    q1 = numerical_features[i].describe()['25%']\n    q3 = numerical_features[i].describe()['75%']\n    iqr = q3-q1\n    data = numerical_features[(numerical_features[i] > (q1 - 1.5*iqr)) &\n            (numerical_features[i] < (q3 + 1.5*iqr))]\n    outliers.append(numerical_features.shape[0]-data.shape[0])\noutlier= pd.DataFrame()\noutlier['features']=numerical_features.columns\noutlier['number']=outliers\n\noutlier","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will remove outliers present in 'Credit Score' and 'Age'.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#removing outliers:\n\ndef outliers(df,i):\n    q1=df[i].quantile(0.25)\n    q3=df[i].quantile(0.75)\n    iqr=q3-q1\n    ul=q3+(1.5*iqr)\n    ll=q1-(1.5*iqr)\n    clean_data= df.loc[(df[i]<ul) & (df[i]>ll)]\n    return clean_data\n\nclean_df=outliers(df, 'CreditScore')\nclean_df=outliers(df, 'Age')\n\nclean_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Pre-processing","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We have some categorical features so we will encode them first.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating dummies for categorical features\n\ncategorical_features= clean_df.select_dtypes(include='O')\n\nclean_df= pd.get_dummies(clean_df, prefix=categorical_features.columns , drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clean_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Scaling\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sc = MinMaxScaler(feature_range=(0, 1))\nscaler = sc.fit_transform(clean_df[numerical_features.columns])\ndf_scaled = pd.DataFrame(scaler, columns=numerical_features.columns)\n\nclean_df.drop(['CreditScore', 'Age', 'Balance', 'EstimatedSalary'], axis=1, inplace=True)\n\nclean_df= pd.concat([df_scaled.reset_index(drop=True), clean_df.reset_index(drop= True)], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clean_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting the data in train and test sets\nX = clean_df.drop('Exited', axis=1)\nY = clean_df['Exited']\nx_train,x_test,y_train,y_test = train_test_split(X, Y ,test_size = 0.3,random_state = 25)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before moving ahead to modeling, let us check whether the data is balanced or not.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"(df['Exited'].value_counts(normalize= True)*100).plot(kind='bar')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that data is imbalanced with approx 80% of one class and 20% of the other class.\n\nIf such data is fed to the model as input, the classifier may make it biased w.r.t majority class as it was not provided with enough data of minority class to learn.\n\nSo, to deal with this situation, we will apply one of the sampling techniques i.e SMOTE(Synthetic Minority Over-Sampling Technique) and check the results with imbalanced data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import classification_report, f1_score, precision_score,recall_score,confusion_matrix\nfrom sklearn import metrics\nfrom sklearn import model_selection\nfrom imblearn.over_sampling import SMOTE\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Smote Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"smt = SMOTE()\nX_smo,Y_smo = smt.fit_sample(x_train ,y_train)\n\nnp.bincount(Y_smo)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Hyperparameter tuning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#hyperparameter\n\n# Random Forest\nrfc= RandomForestClassifier(random_state=0)\nhyper={'n_estimators':range(100,700,100), 'criterion':['gini','entropy']}\nrfc_grid=GridSearchCV(estimator= rfc, param_grid=hyper, verbose=True)\nrfc_grid.fit(X_smo, Y_smo)\nrfc_grid.best_params_\n\n\n#Decision Tree\ndt= DecisionTreeClassifier(random_state=0)\ndt_params= {'max_depth': np.arange(1,50), 'min_samples_leaf': np.arange(2,15)}\nGS_dt= GridSearchCV(dt,dt_params, cv=5)\n\nGS_dt.fit(X_smo, Y_smo)\n\nGS_dt.best_params_\n\n#gradient_boost\ngb=GradientBoostingClassifier( random_state=0)\ngb_params = {'max_depth':range(5,16,2), 'min_samples_split':range(200,1001,200)}\n\ngsearch2 = GridSearchCV(gb,gb_params, scoring='roc_auc',iid=False, cv=5)\n\ngsearch2.fit(X_smo, Y_smo)\ngsearch2.best_params_\n\n#knn\nparam_grid = { 'n_neighbors': np.arange(1,25), \"metric\" : [ \"minkowski\" , \"manhattan\" , \"jaccard\"] }\nknn = KNeighborsClassifier(n_neighbors=7)\nknn_grid = GridSearchCV ( knn , param_grid, cv = 5 , return_train_score = True )\nknn_grid.fit(X_smo, Y_smo)\nknn_grid.best_params_\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model building","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Models on smote data\nseed= 0\n\nRF= RandomForestClassifier(**rfc_grid.best_params_, random_state=seed)\ndt= DecisionTreeClassifier(**GS_dt.best_params_, random_state=seed)\nlr= LogisticRegression(max_iter=15000, random_state=seed)\nbg= BaggingClassifier(random_state=seed)\nadb= AdaBoostClassifier(random_state=seed)\ngb= GradientBoostingClassifier(**gsearch2.best_params_, random_state=seed)\nknn = KNeighborsClassifier(**knn_grid.best_params_)\n\nmodels=[lr,RF, dt,knn, adb, bg, gb]\n\ndef score_ensemble_model(xtrain,ytrain,xtest,ytest):\n    mod_columns=[]\n    mod=pd.DataFrame(columns=mod_columns)\n    i=0\n    #read model one by one\n    for model in models:\n        model.fit(xtrain,ytrain)\n        y_pred=model.predict(xtest)\n        \n        #compute metrics\n        train_accuracy=model.score(xtrain,ytrain)\n        test_accuracy=model.score(xtest,ytest)\n        \n        p_score=metrics.precision_score(ytest,y_pred)\n        r_score=metrics.recall_score(ytest,y_pred)\n        f1_score=metrics.f1_score(ytest,y_pred)\n        # calculate the fpr and tpr for all thresholds of the classification\n        probs = model.predict_proba(xtest)\n        preds = probs[:,1]\n        fp, tp, th = metrics.roc_curve(ytest, preds)\n        \n        #insert in dataframe\n        mod.loc[i,\"Model_Name\"]=model.__class__.__name__\n        mod.loc[i,\"Precision\"]=round(p_score,2)\n        mod.loc[i,\"Recall\"]=round(r_score,2)\n        mod.loc[i,\"Train_Accuracy\"]=round(train_accuracy,2)\n        mod.loc[i,\"Test_Accuracy\"]=round(test_accuracy,2)\n        mod.loc[i,\"F1_Score\"]=round(f1_score,2)\n        mod.loc[i,'AUC'] = metrics.auc(fp, tp)\n        \n        i+=1\n    \n    #sort values by accuracy\n    mod.sort_values(by=['AUC'],ascending=False,inplace=True)\n    return(mod)\n\nreport=score_ensemble_model(X_smo, Y_smo, x_test, y_test)\nreport","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that the evaluation metrics are not so good after performing smote so we will apply models on original data and check if we are getting better results.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Models on origial data\n\nseed= 0\nlr= LogisticRegression(max_iter=15000, random_state=seed)\nRF= RandomForestClassifier(random_state=seed)\ndt= DecisionTreeClassifier(random_state=seed)\nbg= BaggingClassifier(random_state=seed)\nadb= AdaBoostClassifier(random_state=seed)\ngb= GradientBoostingClassifier(random_state=seed)\nknn = KNeighborsClassifier()\n\nmodels=[lr,RF, dt,knn, adb, bg, gb]\n\n\ndef score_ensemble_model(xtrain,ytrain,xtest,ytest):\n    mod_columns=[]\n    mod=pd.DataFrame(columns=mod_columns)\n    i=0\n    #read model one by one\n    for model in models:\n        model.fit(xtrain,ytrain)\n        y_pred=model.predict(xtest)\n        \n        #compute metrics\n        train_accuracy=model.score(xtrain,ytrain)\n        test_accuracy=model.score(xtest,ytest)\n        \n        p_score=metrics.precision_score(ytest,y_pred)\n        r_score=metrics.recall_score(ytest,y_pred)\n        f1_score=metrics.f1_score(ytest,y_pred)\n        # calculate the fpr and tpr for all thresholds of the classification\n        probs = model.predict_proba(xtest)\n        preds = probs[:,1]\n        fp, tp, th = metrics.roc_curve(ytest, preds)\n        \n        #insert in dataframe\n        mod.loc[i,\"Model_Name\"]=model.__class__.__name__\n        mod.loc[i,\"Precision\"]=round(p_score,2)\n        mod.loc[i,\"Recall\"]=round(r_score,2)\n        mod.loc[i,\"Train_Accuracy\"]=round(train_accuracy,2)\n        mod.loc[i,\"Test_Accuracy\"]=round(test_accuracy,2)\n        mod.loc[i,\"F1_Score\"]=round(f1_score,2)\n        mod.loc[i,'AUC'] = metrics.auc(fp, tp)\n        \n        i+=1\n    \n    #sort values by accuracy\n    mod.sort_values(by=['AUC'],ascending=False,inplace=True)\n    return(mod)\n\nreport=score_ensemble_model(x_train, y_train, x_test, y_test)\nreport","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The results of original data are better than those of smote data. So will check robustness of models using k-fold with the help of bias and variance.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluate each model in turn\nx= clean_df.drop('Exited', axis=1)\ny= clean_df['Exited']\nresults = []\nnames = []\n\nmodels = []\nmodels.append(('MVLR', lr))\nmodels.append(('decision tree', dt))\nmodels.append(('RF', RF))\nmodels.append(('Adaboost', adb))\nmodels.append(('bagging', bg))\nmodels.append(('gradient', gb))\nmodels.append(('knn', knn))\n\nprint('name ',' bias ',' variance')\nfor name, model in models:\n    kfold = model_selection.KFold(shuffle=True,n_splits=5,random_state=0)\n    cv_results = model_selection.cross_val_score(model,x,y ,cv=kfold, scoring='roc_auc')\n    results.append(cv_results)\n    names.append(name)\n    print(\"%s: %f (%f)\" % (name, 1- np.mean(cv_results),np.var(cv_results,ddof=1)))\n\n# bias calculation\nbias= []\nfor i in list(results):\n    bias.append(1- i)\n    \n\n# boxplot algorithm comparison\nfig = plt.figure()\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(111)\nplt.boxplot(bias)\nax.set_xticklabels(names)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Confusion matrix and classification report for Random Forest\n\nRF= RandomForestClassifier(random_state=0)\nRF.fit(x_train, y_train)\n\ny_pred=  RF.predict(x_test)\n\nprint(confusion_matrix(y_test, y_pred))\n      \nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Confusion matrix and classification report for Ada boost\n\nadb= AdaBoostClassifier(random_state=0)\nadb.fit(x_train, y_train)\n\ny_pred=  adb.predict(x_test)\n\nprint(confusion_matrix(y_test, y_pred))\n      \nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Confusion matrix and classification report for gradient boost\n\ngb.fit(x_train, y_train)\n\ny_pred=  gb.predict(x_test)\n\nprint(confusion_matrix(y_test, y_pred))\n      \nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}