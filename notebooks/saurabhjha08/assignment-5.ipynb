{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport struct\nfrom array import array\nfrom os.path  import join\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\nfrom sklearn.metrics import accuracy_score, mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom scipy.special import logit, expit\nimport matplotlib.pyplot as plt \nfrom matplotlib.pyplot import figure","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Part A: MNIST Dataset"},{"metadata":{},"cell_type":"markdown","source":"### Dataset Prep"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"class MnistDataloader(object):\n    def __init__(self, training_images_filepath,training_labels_filepath,\n                 test_images_filepath, test_labels_filepath):\n        self.training_images_filepath = training_images_filepath\n        self.training_labels_filepath = training_labels_filepath\n        self.test_images_filepath = test_images_filepath\n        self.test_labels_filepath = test_labels_filepath\n    \n    def read_images_labels(self, images_filepath, labels_filepath):        \n        labels = []\n        with open(labels_filepath, 'rb') as file:\n            magic, size = struct.unpack(\">II\", file.read(8))\n            if magic != 2049:\n                raise ValueError('Magic number mismatch, expected 2049, got {}'.format(magic))\n            labels = array(\"B\", file.read())        \n        \n        with open(images_filepath, 'rb') as file:\n            magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n            if magic != 2051:\n                raise ValueError('Magic number mismatch, expected 2051, got {}'.format(magic))\n            image_data = array(\"B\", file.read())        \n        images = []\n        for i in range(size):\n            images.append([0] * rows * cols)\n        for i in range(size):\n            img = np.array(image_data[i * rows * cols:(i + 1) * rows * cols])\n            img = img.reshape(28, 28)\n            images[i][:] = img            \n        \n        return images, labels\n            \n    def load_data(self):\n        x_train, y_train = self.read_images_labels(self.training_images_filepath, self.training_labels_filepath)\n        x_test, y_test = self.read_images_labels(self.test_images_filepath, self.test_labels_filepath)\n        return (x_train, y_train),(x_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_path = '../input/mnist-dataset'\ntraining_images_filepath = join(input_path, 'train-images-idx3-ubyte/train-images-idx3-ubyte')\ntraining_labels_filepath = join(input_path, 'train-labels-idx1-ubyte/train-labels-idx1-ubyte')\ntest_images_filepath = join(input_path, 't10k-images-idx3-ubyte/t10k-images-idx3-ubyte')\ntest_labels_filepath = join(input_path, 't10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte')\n\nmnist_dataloader = MnistDataloader(training_images_filepath, training_labels_filepath, test_images_filepath, test_labels_filepath)\n(x_train, y_train), (x_test, y_test) = mnist_dataloader.load_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\nimport matplotlib.pyplot as plt\ndef show_images(images, title_texts):\n    cols = 5\n    rows = int(len(images)/cols) + 1\n    plt.figure(figsize=(30,20))\n    index = 1    \n    for x in zip(images, title_texts):        \n        image = x[0]        \n        title_text = x[1]\n        plt.subplot(rows, cols, index)        \n        plt.imshow(image, cmap=plt.cm.gray)\n        if (title_text != ''):\n            plt.title(title_text, fontsize = 15);        \n        index += 1\n        \nimages_2_show = []\ntitles_2_show = []\nfor i in range(0, 10):\n    r = random.randint(1, 60000)\n    images_2_show.append(x_train[r])\n    titles_2_show.append('training image [' + str(r) + '] = ' + str(y_train[r]))    \n\nfor i in range(0, 5):\n    r = random.randint(1, 10000)\n    images_2_show.append(x_test[r])        \n    titles_2_show.append('test image [' + str(r) + '] = ' + str(y_test[r]))    \n\nshow_images(images_2_show, titles_2_show)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(np.unique(y_train,return_counts=True))\nprint(np.unique(y_test,return_counts=True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MnistDataProcessor:\n    def __init__(self, pos_class, neg_class, training_samples=2000):\n        input_path = '../input/mnist-dataset'\n        training_images_filepath = join(input_path, 'train-images-idx3-ubyte/train-images-idx3-ubyte')\n        training_labels_filepath = join(input_path, 'train-labels-idx1-ubyte/train-labels-idx1-ubyte')\n        test_images_filepath = join(input_path, 't10k-images-idx3-ubyte/t10k-images-idx3-ubyte')\n        test_labels_filepath = join(input_path, 't10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte')\n        mnist_dataloader = MnistDataloader(training_images_filepath, training_labels_filepath, test_images_filepath, test_labels_filepath)\n        (self.__x_train, self.__y_train), (self.__x_test, self.__y_test) = mnist_dataloader.load_data()\n        self.__train_pos_class = np.where(self.__y_train == np.uint8(pos_class))[0]\n        self.__train_neg_class = np.where(self.__y_train == np.uint8(neg_class))[0]\n        self.__test_pos_class = np.where(self.__y_test == np.uint8(pos_class))[0]\n        self.__test_neg_class = np.where(self.__y_test == np.uint8(neg_class))[0]\n        self.__train_samples = training_samples\n    \n    def train_data(self):\n        random.shuffle(self.__train_pos_class)\n        random.shuffle(self.__train_neg_class)\n        train_positive_class_idx = self.__train_pos_class[:self.__train_samples]\n        train_negative_class_idx = self.__train_neg_class[:self.__train_samples]\n        _train_vector = np.array([self.__x_train[i] for i in train_positive_class_idx] + [self.__x_train[i] for i in train_negative_class_idx])\n        nsamples, nx, ny = _train_vector.shape\n        train_vector = _train_vector.reshape((nsamples,nx*ny))\n        train_label = [1]*len(train_positive_class_idx) + [-1]*len(train_negative_class_idx)\n        return train_vector, train_label\n    \n    def test_data(self):\n        random.shuffle(self.__test_pos_class)\n        random.shuffle(self.__test_neg_class)\n        _test_vector = np.array([self.__x_test[i] for i in self.__test_pos_class] + [self.__x_test[i] for i in self.__test_neg_class])\n        nsamples, nx, ny = _test_vector.shape\n        test_vector = _test_vector.reshape((nsamples,nx*ny))\n        test_label = [1]*len(self.__test_pos_class) + [-1]*len(self.__test_neg_class)\n        return test_vector, test_label","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Classification using linear regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_arr = []\ndataset = MnistDataProcessor(3, 8)\nfor i in range(5):\n    X,y = dataset.train_data()\n    reg = LinearRegression().fit(X, y)\n    X_test,y_test = dataset.test_data()\n    y_pred = reg.predict(X_test)\n    y_pred_1 = [1 if i >= 0 else -1 for i in y_pred ]\n    accuracy_arr.append(accuracy_score(y_pred_1, y_test))\nlist(zip(range(1,6), accuracy_arr))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Average accuracy: {}\".format(np.mean(accuracy_arr)))\nprint(\"Standard deviation: {}\".format(np.std(accuracy_arr)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Classification using logistic regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_arr = []\ndataset = MnistDataProcessor(3, 8)\nfor i in range(5):\n    X,y = dataset.train_data()\n    reg = LogisticRegression(random_state=0, max_iter = 1000).fit(X, y)\n    X_test,y_test = dataset.test_data()\n    y_pred = reg.predict(X_test)\n    accuracy_arr.append(accuracy_score(y_pred, y_test))\nlist(zip(range(1,6), accuracy_arr))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Average accuracy: {}\".format(np.mean(accuracy_arr)))\nprint(\"Standard deviation: {}\".format(np.std(accuracy_arr)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Part B: California housing prices"},{"metadata":{},"cell_type":"markdown","source":"### Dataset Prep"},{"metadata":{"trusted":true},"cell_type":"code","source":"class HousingDataLoader:\n    def __init__(self):\n        raw_data = pd.read_csv('../input/california-housing-prices/housing.csv')\n        raw_data = raw_data.fillna(1)\n        self.raw_data = raw_data.drop(columns=['longitude', 'latitude'])\n    \n    def get_data(self):\n        X_cols = ['housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income']\n        Y_col = 'median_house_value'\n        data = self.raw_data.sample(frac=1).reset_index(drop=True)\n        return train_test_split(data[X_cols], data[Y_col], test_size=0.25, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Median house price prediction using Linear regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"sq_error_arr = []\ndataset = HousingDataLoader()\nfor i in range(5):\n    X_train, X_test,y_train, y_test = dataset.get_data()\n    reg = LinearRegression().fit(X_train, y_train)\n    y_pred = reg.predict(X_test)\n    df = pd.DataFrame({'actual': y_test.to_numpy(), 'predicted': y_pred})\n    df.plot(kind='line', y=['actual','predicted'], figsize=(20,5), title='Iteration {}'.format(i+1))\n    sq_error_arr.append(mean_squared_error(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(list(zip(range(1,6), sq_error_arr)))\nprint(\"Average mean squared error: {}\".format(np.mean(sq_error_arr)))\nprint(\"Standard deviation: {}\".format(np.std(sq_error_arr)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Median house price prediction using Logistic regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"def transform_label(arr):\n    normalized_label = np.divide(arr, 1000000)\n    return logit(normalized_label)\n\ndef extract_label(arr):\n    exp_label = expit(arr)\n    return np.multiply(exp_label, 1000000)\n\nsq_error_arr = []\ndataset = HousingDataLoader()\nfor i in range(5):\n    X_train, X_test,y_train, y_test = dataset.get_data()\n    reg = LinearRegression().fit(X_train, transform_label(y_train))\n    y_pred = extract_label(reg.predict(X_test))\n    df = pd.DataFrame({'actual': y_test.to_numpy(), 'predicted': y_pred})\n    df.plot(kind='line', y=['actual','predicted'], figsize=(20,5), title='Iteration {}'.format(i+1))\n    sq_error_arr.append(mean_squared_error(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(list(zip(range(1,6), sq_error_arr)))\nprint(\"Average mean squared error: {}\".format(np.mean(sq_error_arr)))\nprint(\"Standard deviation: {}\".format(np.std(sq_error_arr)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}