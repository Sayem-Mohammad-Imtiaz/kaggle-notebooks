{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport random\nfrom sklearn.cluster import KMeans\nfrom scipy.spatial import distance\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import figure","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dataset prep"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"app_data = pd.read_csv('/kaggle/input/loan-defaulter/application_data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(list(app_data.columns))\napp_data.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### For this assignment, I'll be taking the first 10k records and use the 25 numerical columns with most number of non-null values."},{"metadata":{"trusted":true},"cell_type":"code","source":"input_data = app_data[['TARGET', 'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'DAYS_BIRTH', 'DAYS_EMPLOYED', \n                        'OWN_CAR_AGE', 'CNT_FAM_MEMBERS', 'REGION_RATING_CLIENT', 'REGION_POPULATION_RELATIVE', \n                        'DAYS_LAST_PHONE_CHANGE', 'FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_3', 'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', \n                        'FLAG_DOCUMENT_6', 'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9', 'AMT_REQ_CREDIT_BUREAU_HOUR', \n                        'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_WEEK', 'AMT_REQ_CREDIT_BUREAU_MON', \n                        'AMT_REQ_CREDIT_BUREAU_QRT', 'AMT_REQ_CREDIT_BUREAU_YEAR']].fillna(0).head(10000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Part A: Soft leader clustering"},{"metadata":{"trusted":true},"cell_type":"code","source":"class SoftLeaderClustering:\n    def __init__(self,data: pd.DataFrame, threshold: float):\n        self.__data = data\n        self.__threshold = threshold\n        self.__data_matrix = data.to_numpy()\n        self.__cluster_repr_matrix = None\n        self.__assignment_matrix = None\n        self.__product_matrix = None\n        self.__error = None\n    \n    def shuffle_data(self):\n        random.shuffle(self.__data_matrix)\n        \n    def do_clustering(self):\n        self.__build_cluster_repr_matrix()\n        self.__build_assignment_matrix()\n        self.__build_product_matrix()\n        self.__calculate_error()\n    \n    def get_error(self) -> float:\n        return self.__error\n    \n    def get_number_of_clusters(self) -> int:\n        return len(self.__cluster_repr_matrix)\n    \n    def __build_cluster_repr_matrix(self):\n        cluster_leaders = []\n        for data_point in self.__data_matrix:\n            if len(cluster_leaders) == 0:\n                cluster_leaders.append(data_point)\n                continue\n            else:\n                is_new_leader = True\n                for leader in cluster_leaders:\n                    distance_from_leader = distance.euclidean(leader, data_point)\n                    if distance_from_leader < self.__threshold: \n                        is_new_leader = False\n                        break\n                if is_new_leader: \n                    cluster_leaders.append(data_point)\n        self.__cluster_repr_matrix = cluster_leaders\n        \n    def __build_assignment_matrix(self):\n        assignment_matrix = []\n        for data_point in self.__data_matrix:\n            distance_arr = [np.exp(-distance.euclidean(data_point, p)) for p in self.__cluster_repr_matrix]\n            sum_val = np.sum(list(filter(lambda d: d < self.__threshold, distance_arr)))\n            if(sum_val != 0):\n                assignment_matrix.append(np.array([np.true_divide(p, sum_val)*(1 if p < self.__threshold else 0) for p in distance_arr]))\n            else:\n                assignment_matrix.append(np.array(list(map(lambda v: 1 if np.array_equal(v,data_point) else 0, distance_arr))))\n        self.__assignment_matrix = assignment_matrix\n    \n    def __build_product_matrix(self):\n        self.__product_matrix = np.dot(self.__assignment_matrix, self.__cluster_repr_matrix)\n    \n    def __calculate_error(self):\n        row_length = len(self.__data_matrix)\n        col_length = len(self.__data_matrix[0])\n        error_val = 0\n        for row in range(row_length):\n            for col in range(col_length):\n                error_val += np.square(self.__data_matrix[row][col] - self.__product_matrix[row][col])\n        self.__error = error_val\n        \n        \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"threshold_vals = [100000,200000,300000,400000,500000,600000,700000,800000,900000,1000000]\ncluster_count = []\nerror_val_for_thresholds = []\nfor threshold in threshold_vals:\n    soft_cluster = SoftLeaderClustering(input_data, threshold)\n    soft_cluster.do_clustering()\n    cluster_count.append(soft_cluster.get_number_of_clusters())\n    error_val_for_thresholds.append(soft_cluster.get_error())\ncluster_count_df = pd.DataFrame({'threshold_val': threshold_vals, 'cluster_count': cluster_count, 'error': error_val_for_thresholds})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cluster_count_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cluster_count_df.plot(x='threshold_val', y = 'cluster_count', kind=\"line\", figsize=(5,4))\ncluster_count_df.plot(x='threshold_val', y = 'error', kind=\"line\", figsize=(5,4))\ncluster_count_df.plot(x='cluster_count', y = 'error', kind=\"line\", figsize=(5,4))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Based on the above values, let's take 200000 as the threshold value for different permutations of this data"},{"metadata":{"trusted":true},"cell_type":"code","source":"soft_cluster = SoftLeaderClustering(input_data, 200000)\nnum_clusters = []\nerror_vals = []\nfor shuffle_num in range(10):\n    soft_cluster.shuffle_data()\n    soft_cluster.do_clustering()\n    num_clusters.append(soft_cluster.get_number_of_clusters())\n    error_vals.append(soft_cluster.get_error())\nsoft_leader_clustering_results = pd.DataFrame({'shuffle_num': list(range(1,11)), 'num_clusters': num_clusters, \n                                               'error_vals': error_vals})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"soft_leader_clustering_results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"soft_leader_clustering_results.plot(x='num_clusters', y = 'error_vals', kind=\"line\", figsize=(5,4))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Part B: K-Means clustering"},{"metadata":{"trusted":true},"cell_type":"code","source":"class KMeansClustering:\n    def __init__(self, data: pd.DataFrame, k: int):\n        self.__data = data\n        self.__k_value = k\n        self.__data_matrix = data.to_numpy()\n        self.__cluster_repr_matrix = None\n        self.__assignment_matrix = None\n        self.__product_matrix = None\n        self.__error = None\n    \n    def do_clustering(self):\n        kmeans = KMeans(n_clusters=self.__k_value, init='k-means++', random_state=0).fit(self.__data_matrix)\n        self.__cluster_repr_matrix = kmeans.cluster_centers_\n        self.__build_assignment_matrix(kmeans.labels_)\n        self.__build_product_matrix()\n        self.__calculate_error()\n    \n    def get_error(self) -> float:\n        return self.__error\n        \n    \n    def __build_assignment_matrix(self, labels):\n        assignment_matrix = []\n        for label in labels:\n            label_arr = [0]*self.__k_value\n            label_arr[label] = 1\n            assignment_matrix.append(label_arr)\n        self.__assignment_matrix = assignment_matrix\n        \n        \n    def __build_product_matrix(self):\n        self.__product_matrix = np.dot(self.__assignment_matrix, self.__cluster_repr_matrix)\n    \n    def __calculate_error(self):\n        row_length = len(self.__data_matrix)\n        col_length = len(self.__data_matrix[0])\n        error_val = 0\n        for row in range(row_length):\n            for col in range(col_length):\n                error_val += np.square(self.__data_matrix[row][col] - self.__product_matrix[row][col])\n        self.__error = error_val","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k_values = [2, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\nkmeans_error_vals = []\nfor k in k_values:\n    kmeans_cluster = KMeansClustering(input_data, k)\n    kmeans_cluster.do_clustering()\n    kmeans_error_vals.append(kmeans_cluster.get_error())\nkmeans_clustering_results = pd.DataFrame({'k_value': k_values, 'error': kmeans_error_vals})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans_clustering_results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans_clustering_results.plot(x='k_value', y = 'error', kind=\"line\", figsize=(5,4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}