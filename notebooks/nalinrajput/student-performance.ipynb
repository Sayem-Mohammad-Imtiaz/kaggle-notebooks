{"cells":[{"metadata":{},"cell_type":"markdown","source":"# PREDICTING STUDENT PERFORMANCE IN EXAMS USING REGRESSION ALGORITHMS"},{"metadata":{},"cell_type":"markdown","source":"This dataset consists of data related to students of a particular grade and their scores in Maths, Reading and Writing specified out of 100. I will be using various regression algorithms to predict math score by using the features available in the dataset."},{"metadata":{},"cell_type":"markdown","source":"# VARIABLE DESCRIPTIONS:\n\n1) gender: specifies gender of the student(male/female)\n\n2) race: specifies race of the student(group A,group B,group C)\n\n3) parental level of education: specifies highest educational qualification of any parent of each student\n\n4) lunch_type: standard/reduced,the type of lunch package selected for the student\n\n5) test_prep: specifies if the test preparation course was completed by the student or not\n\n6) math_score: specifies score in math(our target variable)\n\n7) reading_score: specifies score in reading\n\n8) writing_score: specifies score in writing\n\nAll scores are taken out of 100."},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom numpy import random\nrandom.seed(12345)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nfrom sklearn.metrics import r2_score\nimport sklearn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import RidgeCV\nfrom sklearn.model_selection import RepeatedKFold\nfrom sklearn.linear_model import Lasso","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%config InlineBackend.figure_format = 'png'\nsns.set()\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport plotly\nimport plotly.graph_objs as go\nfrom scipy.stats import chi2_contingency\nfrom sklearn.linear_model import Ridge\n\ninit_notebook_mode(connected=True)\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split,StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%config InlineBackend.figure_format = 'retina'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data=pd.read_csv(\"/kaggle/input/students-performance-in-exams/StudentsPerformance.csv\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dataset has zero null values with 8 columns and 1000 rows."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Renaming Columns**"},{"metadata":{"trusted":true},"cell_type":"code","source":"columns1={'gender':'gender','race/ethnicity':'race','parental level of education':'parent_ed_level','lunch':'lunch_type','test preparation course':'test_prep','math score':'math','reading score':'reading','writing score':'writing'}\ndata.rename(columns=columns1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Wrangling**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['total']=data['math']+data['reading']+data['writing']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['parent_ed_level'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see \"some high school\" and \"high school\" represent the same level of education, we can replace the former with a single value namely \"high school\"."},{"metadata":{"trusted":true},"cell_type":"code","source":"data['parent_ed_level']=data['parent_ed_level'].replace(['some high school'],'high school')\ndata['parent_ed_level'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['lunch_type']=data['lunch_type'].replace(['free/reduced'],'reduced')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**VISUAL DATA ANALYSIS**"},{"metadata":{},"cell_type":"markdown","source":"# UNIVARIATE ANALYSIS"},{"metadata":{},"cell_type":"markdown","source":"In this we look at one feature at a time. Finding out the distribution of that feature while ignoring other features is usually done here."},{"metadata":{"trusted":true},"cell_type":"code","source":"data[['math','reading','writing','total']].hist(figsize=(12,9))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Every distribution plotted above is Left-Skewed."},{"metadata":{},"cell_type":"markdown","source":"BOXPLOTS"},{"metadata":{"trusted":true},"cell_type":"code","source":"#function to create a boxplot\ndef boxplot(column,dataf):\n    plt.figure(figsize=(10,4))\n    sns.boxplot(x=column,data=dataf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nums=['math','reading','writing','total']\nfor i in nums:\n    boxplot(i,data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Interpreting boxplots"},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_list=['gender','lunch_type','test_prep']\nfor col in cat_list:\n    plt.figure(figsize=(8,5))\n    sns.countplot(x=col,data=data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,5))\nplt.xticks(rotation=45)\nsns.countplot(x='parent_ed_level',data=data,order=['high school','some college',\"associate's degree\",\"bachelor's degree\",\"master's degree\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,5))\nplt.xticks(rotation=45)\nsns.countplot(x='race',data=data,order=['group C','group D',\"group B\",\"group E\",\"group A\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MULTIVARIATE ANALYSIS"},{"metadata":{"trusted":true},"cell_type":"code","source":"def hue(a,b):\n    plt.figure(figsize=(8,5))\n    if a=='parent_ed_level':\n        plt.xticks(rotation=45)\n    sns.countplot(x=a,data=data,hue=b)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hue('parent_ed_level','gender')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hue('parent_ed_level','race')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix=data[nums].corr()\nplt.figure(figsize=(8,5))\nsns.heatmap(corr_matrix,annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Correlation of \"total\" with \"Reading\" and \"writing\" is very high so we drop the total column."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(['total'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now for feature engineering and feature selection to predict math score of students, I will create a copy of the original dataset and manipulate features there."},{"metadata":{"trusted":true},"cell_type":"code","source":"new_data=data.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_data.drop(['writing'],inplace=True,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hue_list=['gender','lunch_type','test_prep']\nfor hue in hue_list:\n    plt.figure(figsize=(12,5))\n    sns.lmplot(x='reading',y='math',data=new_data,hue=hue,fit_reg=True,markers=['o','x'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the scatterplot that has hue parameter set as gender, we can see that male students typically have higher math scores than female students. This could be used to One Hot encode the gender feature later."},{"metadata":{},"cell_type":"markdown","source":"Out of the 3 scatterplots with different classification bases, gender and lunch_type seem the most effective on getting a good math score. So I will eliminate test_prep as one of the predicting features and go ahead with gender and lunch_type."},{"metadata":{},"cell_type":"markdown","source":"# CHI-SQUARE TEST FOR FEATURE SELECTION"},{"metadata":{},"cell_type":"markdown","source":"Here we consider two features at a time and test the null hypothesis which assumes that the 2 features are independent against the alternative hypothesis that those 2 features are dependent."},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating a function to execute chisq test for independence\ndef chisq(col1,col2):\n    #create a contingency table\n    table=pd.crosstab(new_data[col1],new_data[col2])\n    #get chi_Sq statistics,p-value,degrees of freedom and expected frequencies.\n    stat, p, dof, expected = chi2_contingency(table)\n    #set significance level\n    alpha=0.05\n    if p<=0.05:\n        print('Features are associated')\n    else:\n        print('Features are not associated')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"chisq('gender','lunch_type')\nchisq('gender','parent_ed_level')\nchisq('gender','race')\nchisq('gender','test_prep')\nchisq('lunch_type','test_prep')\nchisq('lunch_type','parent_ed_level')\nchisq('lunch_type','race')\nchisq('parent_ed_level','race')\nchisq('parent_ed_level','test_prep')\nchisq('race','test_prep')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since every pair of categorical features is independent we do not eliminate any of these for our feature selection process."},{"metadata":{"trusted":true},"cell_type":"code","source":"new_data.drop(['test_prep'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Encoding the categorical features"},{"metadata":{"trusted":true},"cell_type":"code","source":"label=LabelEncoder()\ncat_list=['gender','race','lunch_type','parent_ed_level']\nfor col in cat_list:\n    new_data[col]=label.fit_transform(new_data[col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_data['race'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=new_data['math']\nnew_data.drop(['math'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_data['reading']=new_data['reading']/100.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=y/100.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix=new_data.corr()\nsns.heatmap(corr_matrix,annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"By correlation coefficient we can conclude that there is no high-level of correlation between any of the features."},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating a function that prints all relevant regression metrics when called\ndef reg_metrics(actual,predicted):\n    mae=metrics.mean_absolute_error(actual,predicted)\n    mse=metrics.mean_squared_error(actual,predicted)\n    rmse=np.sqrt(metrics.mean_squared_error(actual,predicted))\n    r2=r2_score(actual,predicted)\n    print(\"MAE:\",mae)\n    print(\"MSE:\",mse)\n    print(\"RMSE:\",rmse)\n    print(\"R2:\",r2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating a function to plot a histogram of the residual values.\ndef residual_plot(actual,predicted):\n    plt.figure(figsize=(10,6))\n    plt.xlabel('Residual error value')\n    plt.title('Residual Plot',size=13)\n    plt.hist(actual-predicted)\n#plotting the residual error plot","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LINEAR REGRESSION"},{"metadata":{"trusted":true},"cell_type":"code","source":"#training algorithm with the dataset containing outliers\nX_train, X_holdout, y_train, y_holdout = train_test_split(new_data.values,y,test_size=0.3,random_state=17)\nreg=LinearRegression(normalize=True)\nreg.fit(X_train,y_train)\npred=reg.predict(X_holdout)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"coef_df = pd.DataFrame(reg.coef_, new_data.columns, columns=['coefficients'])\ncoef_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"intercept=reg.intercept_\nintercept","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"residual_plot(y_holdout,pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\nplt.xlabel('predicted')\nplt.ylabel('actual')\nsns.scatterplot(pred,y_holdout)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg_metrics(y_holdout,pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Defining the metrics obtained above:\n\n1) MAE is just the Mean Absolute Error, ie the mean of residual errors mathematically given by sum(abs(Y(actual)-Y(pred)))/no.of predictions\n\n2) MSE is the Mean Square Error, ie the square of the MAE.\n\n3) RMSE is the square root of MSE.\n\n4) R2 score returns a value that tells you how much of the variation in the target variable has been captured by the features used to predict said target variable."},{"metadata":{},"cell_type":"markdown","source":"# RIDGE REGRESSION"},{"metadata":{},"cell_type":"markdown","source":"CROSS VALIDATION ON THE TRAINING DATASET TO DETERMINE ALPHA VALUE"},{"metadata":{"trusted":true},"cell_type":"code","source":"ridge=Ridge()\ncv=RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\ngrid=dict()\ngrid['alpha']=np.arange(0.0,1.0,0.01)\nsearch=GridSearchCV(ridge, grid, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1,refit=False)\nresult=search.fit(X_train,y_train)\nprint('MAE: %.3f' % result.best_score_)\nprint('Config: %s' % result.best_params_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The best evaluation metrics for predicting marks would be the MAE because a student's grade in any subject can change by even 1 mark. So we will consider MAE and RMSE to be our top priorities to ensure closest possible predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"ridge=Ridge(alpha=0.04)\nridge.fit(X_train,y_train)\npred1=ridge.predict(X_holdout)\nreg_metrics(y_holdout,pred1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"residual_plot(y_holdout,pred1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Ridge regression model performed slightly worse than the Linear regression model."},{"metadata":{},"cell_type":"markdown","source":"# LASSO REGRESSION"},{"metadata":{"trusted":true},"cell_type":"code","source":"lasso=Lasso(normalize=True)\ncv=RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\ngrid=dict()\ngrid['alpha']=np.arange(0.0,2.0,0.01)\nsearch=GridSearchCV(lasso,grid, scoring='neg_root_mean_squared_error', cv=cv, n_jobs=-1,refit=False)\nresult=search.fit(X_train,y_train)\nprint('MAE: %.3f' % result.best_score_)\nprint('Config: %s' % result.best_params_)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lasso=Lasso(normalize=True,alpha=0)\nlasso.fit(X_train,y_train)\npred2=lasso.predict(X_holdout)\nreg_metrics(y_holdout,pred2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lasso and Ridge regression performed slightly worse than the Linear Regression model. Hence I choose my Linear Regression model to predict future unseen data. It manages to explain around 84% of the variance in the data with a MAE of around 5 marks.\n\nUpdations will be made to the notebook."},{"metadata":{},"cell_type":"markdown","source":"# **RANDOM FOREST REGRESSOR**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forest=RandomForestRegressor(n_estimators=100)\nforest.fit(X_train,y_train)\npred3=forest.predict(X_holdout)\nreg_metrics(y_holdout,pred3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Without applying techniques to improve the regressor model, the RandomForest regressor performs worse than the Lasso and Linear regression models, giving an MAE of about 5.7 marks and an R2 score of 0.786.\n\nI will now apply GridSearchCV to figure out the best parameters to predict Math score."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = {\n    'bootstrap': [True],\n    'max_depth': [3,4,5],\n    'max_features': [3,4,5],\n    'min_samples_leaf': [3,4,5],\n    'min_samples_split': [8,10],\n    'n_estimators': [100, 200]\n}\nforest_cv=RandomForestRegressor(criterion='mae')\n# Instantiate the grid search model\ngrid=GridSearchCV(estimator=forest_cv, param_grid=param_grid, cv=6, n_jobs=-1, verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forest_cv=RandomForestRegressor(criterion='mae',bootstrap=True,max_depth=5,max_features=4,min_samples_leaf=3,min_samples_split=10,n_estimators=100)\nforest_cv.fit(X_train,y_train)\npred4=forest_cv.predict(X_holdout)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg_metrics(y_holdout,pred4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see,Hyperparameter tuning improved the performance of the model on unseen data. But it is still slightly better in performance than Linear regression. "},{"metadata":{"trusted":true},"cell_type":"code","source":"residual_plot(y_holdout,pred4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ONE HOT ENCODING CATEGORICAL FEATURES.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"X1_train, X1_holdout, y1_train, y1_holdout = train_test_split(new_data,y,test_size=0.3,random_state=17)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ohe=OneHotEncoder(sparse=False,handle_unknown='ignore')\nOH_cols_train = pd.DataFrame(ohe.fit_transform(X1_train[['gender']]))\nOH_cols_holdout = pd.DataFrame(ohe.transform(X1_holdout[['gender']]))\n\nOH_cols_train.index = X1_train.index\nOH_cols_holdout.index = X1_holdout.index\n\nnum_X_train = X1_train.drop(['gender'], axis=1)\nnum_X_holdout = X1_holdout.drop(['gender'], axis=1)\n\nOH_X_train = pd.concat([num_X_train, OH_cols_train],axis=1)\nOH_X_holdout = pd.concat([num_X_holdout, OH_cols_holdout],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LINEAR REGRESSION IN ONE-HOT ENCODED DATASET"},{"metadata":{"trusted":true},"cell_type":"code","source":"reg_ohe=LinearRegression(normalize=True)\nreg_ohe.fit(OH_X_train,y_train)\npred_ohe=reg_ohe.predict(OH_X_holdout)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg_metrics(y_holdout,pred_ohe)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# RANDOM FOREST REGRESSOR ON ONE HOT ENCODED DATA"},{"metadata":{"trusted":true},"cell_type":"code","source":"forest_ohe=RandomForestRegressor(n_estimators=100)\nforest_ohe.fit(OH_X_train,y_train)\npred_ohe1=forest_ohe.predict(OH_X_holdout)\nreg_metrics(y_holdout,pred_ohe1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hyperparameter tuning:\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid_ohe = {\n    'bootstrap': [True],\n    'max_depth': [4,5],\n    'max_features': [4,5,6],\n    'min_samples_leaf': [3,4,5],\n    'min_samples_split': [8,10],\n    'n_estimators': [100, 200]\n}\nforest_cv_ohe=RandomForestRegressor(criterion='mae')\n# Instantiate the grid search model\ngrid_ohe=GridSearchCV(estimator=forest_cv_ohe, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_ohe.fit(OH_X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_ohe.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for_cv_ohe=RandomForestRegressor(bootstrap=True,max_depth=5,max_features=5,min_samples_leaf=4,min_samples_split=10,n_estimators=100)\nfor_cv_ohe.fit(OH_X_train,y_train)\npred6=for_cv_ohe.predict(OH_X_holdout)\nreg_metrics(y_holdout,pred6)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In both cases gridsearch has improved model performance but still Linear regression gives the maximum R2 score and the least MAE."},{"metadata":{},"cell_type":"markdown","source":"CONCLUSION: LINEAR REGRESSION MODEL WILL BE USED TO MAKE PREDICTIONS OF MATH SCORE OF STUDENTS"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}