{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Aprendendo a usar o Kaggle\n\nOlá, seja bem vindo ao Workshop de classificadores de ML do Iris Data Science. Nós preparamos esse notebook para que você possa aprender do 0 até o conhecimento básico de uso de ML. Esse material é baseado em dados de competições e nas aulas do Prof. Pascal Yim (E.C. Lille). Os slides da apresentação estão disponíveis [aqui](https://docs.google.com/presentation/d/1_tE7RopalM4mJ96sh-ZBx7KKVsOyTRndLNh5KJrTjL0/edit?usp=sharing).\n\nSe você nunca utilizou o Kaggle, crie sua conta e clique em \"Copy and Edit\" neste notebook e começe a programar!\n\nSe você é iniciante, comece aqui pelo começo e siga as instruções. Se você já possui experiência, pode seguir a frente e tentar os desafios!"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"import matplotlib.pyplot as matplotlib\nimport seaborn\nimport pandas\nimport numpy\n%matplotlib inline\n\n# Função para fazer reshape de listas 1D\ndef reshape(list1D):\n     return numpy.array(list1D).reshape(-1,1)\n    \n# Função para imprimir nosso modelo de Regressão Logistica\ndef plot_ours(model):\n    x = numpy.linspace(0,1,50)\n    y = model.predict(reshape(x))\n    matplotlib.figure(figsize=(4,4))\n    matplotlib.plot(x, y, color=\"red\")\n    matplotlib.suptitle('Our Logistic model')\n    matplotlib.xlabel('x')\n    matplotlib.ylabel('y')\n    matplotlib.show()\n    \n# Função para imprimir o modelo \"padrão\" de Regressão Logistica \ndef plot_lr():\n    logistical = lambda x: numpy.exp(x)/(1+numpy.exp(x))   \n    x = numpy.linspace(-10,10,50)\n    y = logistical(x)\n    matplotlib.figure(figsize=(4,4))\n    matplotlib.plot(x, y, color=\"red\")\n    matplotlib.suptitle('Logisitc Regression model')\n    matplotlib.xlabel('x')\n    matplotlib.ylabel('y')\n    matplotlib.show()\n\nplot_lr()\n# Apresentar o que é um notebook a = 1, ...","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ok, neste começo iremos apresentar o que é um modelo, o que é x, y, labels/test, fit e predict. Lembre-se que toda Inteligência Artificial é um modelo matemático para y = f(x), onde x serão os dados de entrada, y os dados de resposta, e f a nossa função. No caso estamos estudando uma função da forma ```f(x) = exp(x)/(1+numpy.exp(x))```. Nós não iremos entrar na matemática por trás disso mas basta entender que ele é uma curva.\n\nO que faremos a seguir é um \"arredondador\", ou um classificador de 0's e 1's. Queremos que ele faça 0.00231 -> 0 e 0.7987 -> 1, e assim em diante."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nx = [0.0, 0.01, 0.1, 0.123, 0.12345, 0.234, 0.432, 0.6535, 0.6457457, 0.7, 0.71, 0.07, 0.8, 0.9, 1]\ny = [0  , 0   , 0  , 0    , 0      , 0    , 0    , 1     , 1        , 1  , 1   , 0   , 1  , 1  , 1]\n\nmodel = LogisticRegression()\nmodel.fit(reshape(x),y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Agora que sabemos como fazer o _fit_ do nosso modelo, vamos ver como ele se parece graficamente. E vamos colocar alguns números de entrada para ele tentar adivinhar!"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_ours(model)\n\ntest = [0.001431256, 0.136882, 0.6345345345, 0.81234791874]\n\nresult = model.predict(reshape(test))\nprint(result)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ok, só que você nunca encontrará na sua vida os dados dessa forma. Eles normalmente estão armazenados em datasets que podem ser acessados por dataframes. A forma mais comum de acessar um dataset é utilizando a biblioteca pandas. Vamos ver esse dataset de dataset de \\[0,1\\]  que possui mais 10.000 números. (Atenção, por volta de 10% das respostas estão erradas!)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix\nimport random\n\n# Uma função para criar um dataset com 10.000 números entre 0 e 1 classificados como 0 ou 1 (as vezes errado)\ndef create_dataset():\n    x = [random.random() for i in range(10000)]\n    classify = lambda i: int(i > 0.5) if random.random() > 0.1 else int(not i > 0.5)\n    dataset = pandas.DataFrame(x,columns=['x'])\n    dataset['y'] = dataset['x'].apply(classify)\n    return dataset \n    \ndataset = create_dataset()\ndataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Veja só como os dados se parecem:"},{"metadata":{"trusted":true},"cell_type":"code","source":"seaborn.scatterplot(data=dataset,x='x',y='y', alpha=0.01)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vamos aplicar novamente o que já sabemos."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.model_selection import train_test_split\n\nx = dataset['x']\ny = dataset['y']\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\nmodel = LogisticRegression()\nmodel.fit(reshape(x_train),y_train)\n\nresult = model.predict(reshape(x_test))\nprint(accuracy_score(result, y_test))\nprint(confusion_matrix(result, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Mexendo com dados reais (Cancer de Mama)\n\n\n"},{"metadata":{},"cell_type":"markdown","source":"Vamos predizer cancer! O dataset a seguir é sobre cancêr de mama no estado de Wisconsin. Na coluna do 'diagnosis' podemos ver os dois diagnósticos para cancer de mama: Maligno e Benigno. Vamos tentar adivinhar o diagnóstico baseado apenas nas informações médicas que temos."},{"metadata":{"trusted":true},"cell_type":"code","source":"import tree\n# Aqui mapeia os dois tipos de diagnósticos no espaço\ndef plot_cancer_sizes(df):\n    matplotlib.figure(figsize=(12,12))\n    seaborn.kdeplot(df[df['diagnosis']=='M'].perimeter_worst, df[df['diagnosis']=='M'].area_worst, cmap=\"Reds\",  shade=True, alpha=0.3, shade_lowest=False)\n    seaborn.kdeplot(df[df['diagnosis']=='B'].perimeter_worst, df[df['diagnosis']=='B'].area_worst, cmap=\"Greens\", shade=True, alpha=0.3, shade_lowest=False)\n    matplotlib.show()\n\n# Faz um plot do perimeter_worst para os dois diagnósticos\ndef plot_cancer_perimeter(df):\n    fig = seaborn.FacetGrid(df, hue=\"diagnosis\", aspect=3)\n    fig.map(seaborn.kdeplot, \"perimeter_worst\", shade=True)\n    fig.add_legend()\n    matplotlib.show()\n\n# Faz um plot da árvore de decisões\ndef plot_tree(model,x_train):\n    matplotlib.figure(figsize=(15,15))\n    tree.plot_tree(model, feature_names=x_train.columns, class_names=['benigno','maligno'], fontsize=14, filled=True)\n    matplotlib.show()\n\n# Faz um plot das importâncias para um Random Forest\ndef plot_importances(model,df):\n    importances = model.feature_importances_\n    indices = numpy.argsort(importances)\n    matplotlib.figure(figsize=(12,8))\n    matplotlib.barh(range(len(indices)), importances[indices], color='b', align='center')\n    matplotlib.yticks(range(len(indices)), df.columns[indices])\n    matplotlib.suptitle('Importância das características')\n    matplotlib.show()\n\ncancer = pandas.read_csv('../input/breast-cancer-wisconsin-data/data.csv')\ncancer","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Primeiro passo: Tire a coluna inútil no final!"},{"metadata":{"trusted":true},"cell_type":"code","source":"cancer = cancer.drop(['Unnamed: 32'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Agora, vamos visualizar como o tamanho do perímetro e tamanho da área se comportam para o tipo maligno e benigno"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_cancer_sizes(cancer)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ok, faça x com todas as colunas menos o diagnóstico, e y como diagnóstico! Lembre de separar os dados e aplicar a Regressão Logística"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = cancer.drop(['diagnosis'],axis=1)\ny = cancer['diagnosis']\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n\nmodel = LogisticRegression()\nmodel.fit(x_train,y_train)\n\nresult = model.predict(x_test)\nprint(accuracy_score(result, y_test))\nprint(confusion_matrix(result, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A acurácia foi ruim, como você pode ver. O que aconteceu? Será que tem alguma coluna que está fazendo nossos dados tendenciosos? (dica: tem sim)"},{"metadata":{"trusted":true},"cell_type":"code","source":"cancer = cancer.drop(['id'], axis=1)\nx = cancer.drop(['diagnosis'],axis=1)\ny = cancer['diagnosis']\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n\nmodel = LogisticRegression()\nmodel.fit(x_train,y_train)\n\nresult = model.predict(x_test)\nprint(accuracy_score(result, y_test))\nprint(confusion_matrix(result, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lembre-se sempre da aplicação de IA: classificar coisas! Imagine que eu sou um médico com um paciente com essas condições. O câncer é maligno ou benigno?"},{"metadata":{"trusted":true},"cell_type":"code","source":"nosso_cancer = list({\n 'radius_mean': 17.99,\n 'texture_mean': 10.38,\n 'perimeter_mean': 122.8,\n 'area_mean': 1001.0,\n 'smoothness_mean': 0.1184,\n 'compactness_mean': 0.2776,\n 'concavity_mean': 0.3001,\n 'concave points_mean': 0.1471,\n 'symmetry_mean': 0.2419,\n 'fractal_dimension_mean': 0.07871,\n 'radius_se': 1.095,\n 'texture_se': 0.9053,\n 'perimeter_se': 8.589,\n 'area_se': 153.4,\n 'smoothness_se': 0.006399,\n 'compactness_se': 0.04904,\n 'concavity_se': 0.05372999999999999,\n 'concave points_se': 0.01587,\n 'symmetry_se': 0.03003,\n 'fractal_dimension_se': 0.006193,\n 'radius_worst': 25.38,\n 'texture_worst': 17.33,\n 'perimeter_worst': 184.6,\n 'area_worst': 2019.0,\n 'smoothness_worst': 0.1622,\n 'compactness_worst': 0.6656,\n 'concavity_worst': 0.7119,\n 'concave points_worst': 0.2654,\n 'symmetry_worst': 0.4601,\n 'fractal_dimension_worst': 0.1189\n}.values())\n\nmodel.predict(reshape(nosso_cancer).transpose())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ok, cansamos de usar Logistic Regression. Queremos modelos diferentes para fazer aprendizado de máquina! Vamos tentar utilizar uma árvore de decisões, é o mesmo \"modelo\" que o Akinator funcionava!"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn import tree\n\nmodel = DecisionTreeClassifier(max_depth = 3, min_samples_leaf = 20)\nmodel.fit(x_train,y_train)\n\nresult = model.predict(x_test)\nprint(accuracy_score(result, y_test))\nprint(confusion_matrix(result, y_test))\nplot_tree(model,x_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ok, agora vamos ver outro tipo de modelo chamado RandomForestClassifier. Veja que o modelo de aplicação no código é o mesmo!"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier()\nmodel.fit(x_train,y_train)\n\nresult = model.predict(x_test)\nprint(accuracy_score(result, y_test))\nprint(confusion_matrix(result, y_test))\nplot_importances(model,cancer)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"E agora vamos aprender um pouco sobre classificação, como precisão, recall, f1-score, e **LOSS**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, result))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# IRIS\n\nIris, o desafio que deu nome ao nome do nosso grupo, é um dataset do tipo de flor Iris (e não o olho!). Nele, há três tipos de espécies, com as informações sobre sépalas e pétalas."},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_iris(df):\n    seaborn.pairplot(df, hue=\"Species\")\n    matplotlib.show()\n\niris = pandas.read_csv('../input/iris/Iris.csv')\niris","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vamos ver como cada informação se comporta para cada espécie."},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_iris(iris)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vamos aplicar nossa regressão logística."},{"metadata":{"trusted":true},"cell_type":"code","source":"x = iris.drop(['Species'],axis=1)\ny = iris['Species']\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n\nmodel = LogisticRegression()\nmodel.fit(x_train,y_train)\n\nresult = model.predict(x_test)\nprint(accuracy_score(result, y_test))\nprint(confusion_matrix(result, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Desafio 1: Titanic\n\nO seu objetivo é descobrir, dado as informações de um passageiro no navio Titanic, se ele sobreviveu ou não o acidente (coluna survived). Neste caso, você perceberá que algumas colunas podem deixar seu aprendizado pior. Outro ponto importante é que há varias informações faltantes (NaN).\n\n**Objetivos**\n- Você consegue preencher as informações faltantes de alguma forma? Como?\n- Tente ultrapassar 80% de precisão.\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"titanic_train = pandas.read_csv(\"../input/titanic/train.csv\")\ntitanic_test = pandas.read_csv(\"../input/titanic/test.csv\")\ntitanic_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Desafio 2: IMDB"},{"metadata":{},"cell_type":"markdown","source":"Ok, o seu desafio agora é utilizar Machine Learning para fazer uma Análise de Sentimentos nas reviews de filmes do IMDB. Neste dataset você possui 50.000 reviews de filmes classificadas como \"positiva\" e \"negativa\". Neste dataset, seu modelo pode demorar bastante (coisa de 5 minutos para cima). O quê você precisa fazer:\n\n- Limpar as reviews (use a função clear_sentence para cada string do dataset)\n- Separe o treinamento e teste.\n- Vetorizar as palavras (pode usar o HashingVectorizer()). Procure no google como aplicar isso.\n- Coloque em um Machine Learning.\n\n**Objetivos**\n- Qual é o melhor tipo de modelo de ML para esse NLP? (Dica: pense em modelos que trabalham com vetores)\n- Ultrapasse 90% de precisão neste dataset demorando menos de 1 minuto para rodar (utilize time.time() para pegar os tempos.\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import string\nimport time\n\nfrom sklearn.feature_extraction.text import HashingVectorizer\n\ndef clear_sentence(sentence):\n    sentence = sentence.replace('<br />', ' ')\n    sentence = sentence.translate(str.maketrans(string.punctuation, ' ' * len(string.punctuation)))\n    sentence = sentence.lower()\n    return sentence\n\nimdb = pandas.read_csv(\"../input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\")\nimdb","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Desafio 3: Diabetes\nO dataset a seguir possui dados sobre a incidência de diabetes na população do povo Pima. Seu desafio é descobrir a coluna outcome baseado nos outros dados. Seu desafio é ultrapassar 82% de precisão."},{"metadata":{"trusted":true},"cell_type":"code","source":"diabetes = pandas.read_csv(\"/kaggle/input/pima-indians-diabetes-database/diabetes.csv\")\ndiabetes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Desafio 4: MNIST - Digit Recognizer\nDataset com dígitos escritos à mão e seus respectivos valores. Cada linha dos datasets (tanto de treino quanto de teste) está estruturada da seguinte forma:\n\n| Digito representado | pixel 1x1 | ... | pixel 28x28 |\n|:-----------------:|:---------:|:---:|:----------:|\n|5|0|...|0|\n\nComo temos uma imagem 28x28 temos 784 valores de pixel por coluna, todos valores binários:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plt_digit_from_row(row):\n    label, image = mnist_train.values[row,0], mnist_train.values[row,1:]\n    matplotlib.imshow(image.reshape(28,28), cmap='hot')\n    matplotlib.title(\"Label: %s\"%label)\n    matplotlib.show()\n\nmnist_train = pandas.read_csv(\"../input/mnist-in-csv/mnist_train.csv\")\nmnist_test = pandas.read_csv(\"../input/mnist-in-csv/mnist_test.csv\")\nmnist_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Conseguimos ver como é a imagem redimensionando o a matriz `1x784` para uma `28x28`:"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt_digit_from_row(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mnist_train_labels, mnist_train_values = mnist_train.values[:,0], mnist_train.values[:,1:]\nmnist_test_labels, mnist_test_values = mnist_test.values[:,0], mnist_test.values[:,1:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Você vai precisar fazer o escalamento das imagens para poder "},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LogisticRegression()\n\nmodel.fit(mnist_train_values, mnist_train_labels)\n\n\nprediction = model.predict(mnist_test_values)\n\nprint(classification_report(prediction, mnist_test_labels))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Desafio 5: Fashion MNIST\nDataset com desenhos de tipos de roupa classificadas com labels\nCada linha dos datasets (tanto de treino quanto de teste) está estruturada da seguinte forma:\n\n\n| Label de cada roupa | pixel 1x1 | ... | pixel 28x28 |\n|:-----------------:|:---------:|:---:|:----------:|\n|5|0|...|0|\n\nComo temos uma imagem 28x28 temos 784 valores de pixel por coluna, todos valores binários:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plt_clothes_from_row(row):\n    label, image = fashion_mnist_train.values[row,0], fashion_mnist_train.values[row,1:]\n    matplotlib.imshow(image.reshape(28,28), cmap='gray')\n    matplotlib.title(\"Label: %s\"%label)\n    matplotlib.show()\n    \nfashion_mnist_train, fashion_mnist_test = pandas.read_csv(\"../input/fashionmnist/fashion-mnist_train.csv\"), pandas.read_csv(\"../input/fashionmnist/fashion-mnist_test.csv\")\nfashion_mnist_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt_clothes_from_row(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fashion_mnist_train_labels, fashion_mnist_train_values = fashion_mnist_train.values[:,0], fashion_mnist_train.values[:,1:]\nfashion_mnist_test_labels, fashion_mnist_test_values = fashion_mnist_test.values[:,0], fashion_mnist_test.values[:,1:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LogisticRegression()\n\nmodel.fit(fashion_mnist_train_values, fashion_mnist_train_labels)\n\nprediction = model.predict(fashion_mnist_test_values)\n\nprint(classification_report(prediction, mnist_test_labels))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Desafio Final: Predizer eleições com Tweets\n\nDessa vez nem preparamos o dataset para você. Utilizando o dataset das eleições australianas, você consegue predizer que regiões da Austrália apoiam qual partido? Tente treinar seu modelo em algum dataset classificado com positivo e negativo e então faça o .fit() no dataset das eleições. Você pode utilizar a função a seguir para plotar seus dados."},{"metadata":{"trusted":true},"cell_type":"code","source":"from mpl_toolkits.basemap import Basemap\n\n# Precisa ter as colunas 'lat' e 'long'. Retorna o mesmo dataframe com apenas os tweets na região da austrália.\ndef pegar_tweets_na_australia(dataframe):\n    bot_lat, top_lat, left_lon, right_lon = -44,-10,109,156\n    top = dataframe.lat <= top_lat\n    bot = dataframe.lat >= bot_lat\n    left = dataframe.long >= left_lon\n    right = dataframe.long <= right_lon\n    index = top&bot&left&right \n    return dataframe[index]\n\n# Passe seu dataframe com os dados que você quer plotar e uma legenda (como string).\ndef plotar_mapa(dataframe,legenda):\n    Australia_map = Basemap(llcrnrlat=-44,urcrnrlat=-10,llcrnrlon=109,urcrnrlon=156)\n    matplotlib.figure(figsize=(12,10))\n    Australia_map.bluemarble(alpha=0.9)\n    seaborn.scatterplot(x='long', y='lat', data=dataframe, alpha=1, s=200, label=legenda)\n    matplotlib.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}