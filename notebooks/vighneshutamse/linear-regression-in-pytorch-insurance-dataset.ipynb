{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"cell_type":"markdown","source":"# Insurance cost prediction using linear regression\n\nIn this assignment we're going to use information like a person's age, sex, BMI, no. of children and smoking habit to predict the price of yearly medical bills. This kind of model is useful for insurance companies to determine the yearly insurance premium for a person. The dataset for this problem is taken from: https://www.kaggle.com/mirichoi0218/insurance\n\nWe will create a model with the following steps:\n1. Download and explore the dataset\n2. Prepare the dataset for training\n3. Create a linear regression model\n4. Train the model to fit the data\n5. Make predictions using the trained model\n\nTry to experiment with the hypeparameters to get the lowest loss.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torchvision\nimport torch.nn as nn\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nfrom torchvision.datasets.utils import download_url\nfrom torch.utils.data import DataLoader, TensorDataset, random_split","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 1: Download and explore the data\n\nLet us begin by downloading the data. We'll use the `download_url` function from PyTorch to get the data as a CSV (comma-separated values) file. ","execution_count":null},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"DATASET_URL = \"https://hub.jovian.ml/wp-content/uploads/2020/05/insurance.csv\"\nDATA_FILENAME = \"insurance.csv\"\ndownload_url(DATASET_URL, '.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To load the dataset into memory, we'll use the `read_csv` function from the `pandas` library. The data will be loaded as a Pandas dataframe. See this short tutorial to learn more: https://data36.com/pandas-tutorial-1-basics-reading-data-files-dataframes-data-selection/","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataframe_raw = pd.read_csv(DATA_FILENAME)\ndataframe_raw.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We're going to do a slight customization of the data, so that you every participant receives a slightly different version of the dataset. We will fill a name below as a string (at least 5 characters)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"your_name = \"Vighnesh\" # at least 5 characters","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The `customize_dataset` function will customize the dataset slightly using your name as a source of random numbers.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def customize_dataset(dataframe_raw, rand_str):\n    dataframe = dataframe_raw.copy(deep=True)\n    # drop some rows\n    dataframe = dataframe.sample(int(0.95*len(dataframe)), random_state=int(ord(rand_str[0])))\n    # scale input\n    dataframe.bmi = dataframe.bmi * ord(rand_str[1])/100.\n    # scale target\n    dataframe.charges = dataframe.charges * ord(rand_str[2])/100.\n    # drop column\n    if ord(rand_str[3]) % 2 == 1:\n        dataframe = dataframe.drop(['region'], axis=1)\n    return dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataframe = customize_dataset(dataframe_raw, your_name)\ndataframe.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let us answer some basic questions about the dataset. \n\n\n**Q: How many rows does the dataset have?**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"num_rows = len(dataframe)\nprint(num_rows)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Q: How many columns doe the dataset have**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"num_cols = len(dataframe.columns)\nprint(num_cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Q: What are the column titles of the input variables?**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"input_cols = list(dataframe.drop('charges',axis=1).columns)\ninput_cols","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Q: Which of the input columns are non-numeric or categorial variables ?**\n\nHint: `sex` is one of them. List the columns that are not numbers.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_cols = list(dataframe.select_dtypes(include='object').columns)\ncategorical_cols","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Q: What are the column titles of output/target variable(s)?**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"output_cols = [dataframe.columns[-1]]\noutput_cols","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Q: (Optional) What is the minimum, maximum and average value of the `charges` column? Can you show the distribution of values in a graph?**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Write your answer here\nimport numpy as np\n# min_charge = np.min(dataframe.charges)\nmin_charge = dataframe.charges.min()\nprint(\"Minimum charge = \",min_charge)\n# max_charge = np.max(dataframe.charges)\nmax_charge = dataframe.charges.max()\nprint(\"Maximum charge = \",max_charge)\n# avg_charge = np.mean(dataframe.charges)\navg_charge = dataframe.charges.mean()\nprint(\"Average charge = \",avg_charge)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the distribution of 'charges' column\nimport seaborn as sns\nfig, axs = plt.subplots(ncols=2)\nsns.set_style(\"darkgrid\")\nplt.rcParams['font.size'] = 14\nplt.rcParams['figure.figsize'] = (9, 5)\n#plt.title(\"Distribution of charges\")\nsns.distplot(dataframe.charges, ax=axs[0]) # Skewed data\nsns.distplot(np.log(dataframe.charges),ax=axs[1]) # Trying to make data normal using log transformation","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 2: Prepare the dataset for training\n\nWe need to convert the data from the Pandas dataframe into a PyTorch tensors for training. To do this, the first step is to convert it numpy arrays. If you've filled out `input_cols`, `categorial_cols` and `output_cols` correctly, this following function will perform the conversion to numpy arrays.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def dataframe_to_arrays(dataframe):\n    # Make a copy of the original dataframe\n    dataframe1 = dataframe.copy(deep=True)\n    # Convert non-numeric categorical columns to numbers\n    for col in categorical_cols:\n        dataframe1[col] = dataframe1[col].astype('category').cat.codes\n    # Extract input & outupts as numpy arrays\n    #inputs_array = np.array(dataframe1[input_cols])\n    inputs_array = dataframe1.drop('charges',axis=1).values\n    #targets_array = np.array(dataframe1[output_cols])\n    targets_array = dataframe1[['charges']].values\n    return inputs_array, targets_array","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Read through the [Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html) to understand how we're converting categorical variables into numbers.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs_array, targets_array = dataframe_to_arrays(dataframe)\nprint(inputs_array.shape, targets_array.shape)\ninputs_array, targets_array","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Q: Convert the numpy arrays `inputs_array` and `targets_array` into PyTorch tensors. Make sure that the data type is `torch.float32`.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs = torch.from_numpy(inputs_array).to(torch.float32)\ntargets = torch.from_numpy(targets_array).to(torch.float32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs.dtype, targets.dtype","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print(inputs,targets)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, we need to create PyTorch datasets & data loaders for training & validation. We'll start by creating a `TensorDataset`.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = TensorDataset(inputs, targets)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Q: Pick a number between `0.1` and `0.2` to determine the fraction of data that will be used for creating the validation set. Then use `random_split` to create training & validation datasets. ***","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"val_percent = 0.1 # between 0.1 and 0.2\nval_size = int(num_rows * val_percent)\nprint(val_size)\ntrain_size = num_rows - val_size\nprint(train_size)\n\ntrain_ds, val_ds = random_split(dataset,[train_size, val_size]) # Use the random_split function to split dataset into 2 parts of the desired length","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(train_ds))\nprint(len(val_ds))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally, we can create data loaders for training & validation.\n\n**Q: Pick a batch size for the data loader.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 64 # Try to experiment with different batch sizes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader = DataLoader(train_ds, batch_size, shuffle=True)\nval_loader = DataLoader(val_ds, batch_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's look at a batch of data to verify everything is working fine so far.","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"for xb, yb in train_loader:\n    print(\"inputs:\", xb)\n    print(\"targets:\", yb)\n    break","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 3: Create a Linear Regression Model\n\nOur model itself is a fairly straightforward linear regression.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"input_size = len(input_cols)\nprint(input_size)\noutput_size = len(output_cols)\nprint(output_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class InsuranceModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linear = nn.Linear(input_size,output_size) \n        \n    def forward(self, xb):\n        out = self.linear(xb)                          \n        return out\n    \n    def training_step(self, batch):\n        inputs, targets = batch \n        # Generate predictions\n        out = self(inputs)          \n        # Calcuate loss\n        loss = F.l1_loss(out, targets)                \n        return loss\n    \n    def validation_step(self, batch):\n        inputs, targets = batch\n        # Generate predictions\n        out = self(inputs)\n        # Calculate loss\n        loss = F.l1_loss(out, targets)                    \n        return {'val_loss': loss.detach()}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        return {'val_loss': epoch_loss.item()}\n    \n    def epoch_end(self, epoch, result, num_epochs):\n        # Print result every 20th epoch\n        if (epoch+1) % 500 == 0 or epoch == num_epochs-1:\n            print(\"Epoch [{}], val_loss: {:.4f}\".format(epoch+1, result['val_loss']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let us create a model using the `InsuranceModel` class. You may need to come back later and re-run the next cell to reinitialize the model, in case the loss becomes `nan` or `infinity`.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = InsuranceModel()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's check out the weights and biases of the model using `model.parameters`.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"list(model.parameters())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 4: Train the model to fit the data\n\nTo train our model, we'll use the same `fit` function explained in the lecture. That's the benefit of defining a generic training loop - you can use it for any problem.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(model, val_loader):\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        for batch in train_loader:\n            loss = model.training_step(batch)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        model.epoch_end(epoch, result, epochs)\n        history.append(result)\n    return history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = evaluate(model, val_loader) # Use the the evaluate function\nprint(result)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nWe are now ready to train the model. You may need to run the training loop many times, for different number of epochs and with different learning rates, to get a good result. Also, if your loss becomes too large (or `nan`), you may have to re-initialize the model by running the cell `model = InsuranceModel()`. Experiment with this for a while, and try to get to as low a loss as possible.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = InsuranceModel() # In case of re-initialization","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Q: Train the model 4-5 times with different learning rates & for different number of epochs.**\n\nHint: Vary learning rates by orders of 10 (e.g. `1e-2`, `1e-3`, `1e-4`, `1e-5`, `1e-6`) to figure out what works.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 1000\nlr = 0.001\nhistory1 = fit(epochs, lr, model, train_loader, val_loader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 1500\nlr = 0.05\nhistory2 = fit(epochs, lr, model, train_loader, val_loader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 2000\nlr = 0.1\nhistory3 = fit(epochs, lr, model, train_loader, val_loader)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"epochs = 2500\nlr = 0.4\nhistory4 = fit(epochs, lr, model, train_loader, val_loader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 3000\nlr = 0.8\nhistory5 = fit(epochs, lr, model, train_loader, val_loader)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Q: What is the final validation loss of your model?**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"val_loss = history5[-1]\nval_loss","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now scroll back up, re-initialize the model, and try different set of values for batch size, number of epochs, learning rate etc.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Step 5: Make predictions using the trained model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_single(input, target, model):\n    inputs = input.unsqueeze(0)\n    predictions = model(inputs)               \n    prediction = predictions[0].detach()\n    print(\"Input:\", input)\n    print(\"Target:\", target)\n    print(\"Prediction:\", prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input, target = val_ds[0]\npredict_single(input, target, model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input, target = val_ds[10]\npredict_single(input, target, model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input, target = val_ds[13]\npredict_single(input, target, model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input, target = val_ds[54]\npredict_single(input, target, model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input, target = val_ds[87]\npredict_single(input, target, model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Are you happy with your model's predictions? Try to improve them further.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}