{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-11T11:53:54.97567Z","iopub.execute_input":"2021-09-11T11:53:54.975999Z","iopub.status.idle":"2021-09-11T11:53:54.988258Z","shell.execute_reply.started":"2021-09-11T11:53:54.975965Z","shell.execute_reply":"2021-09-11T11:53:54.987028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Installing","metadata":{}},{"cell_type":"code","source":"# ! pip install https://github.com/pandas-profiling/pandas-profiling/archive/master.zip\n# !pip install tweet-preprocessor\n!wget --quiet https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:53:54.995782Z","iopub.execute_input":"2021-09-11T11:53:54.996098Z","iopub.status.idle":"2021-09-11T11:53:55.99877Z","shell.execute_reply.started":"2021-09-11T11:53:54.996067Z","shell.execute_reply":"2021-09-11T11:53:55.997725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Library**","metadata":{}},{"cell_type":"code","source":"import datetime, os, random, re, nltk, tokenization\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nimport tensorflow_hub as hub\nsns.set_style('darkgrid')\nfrom pandas_profiling import ProfileReport\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow import keras\nfrom sklearn import preprocessing\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom transformers import TFRobertaForSequenceClassification, RobertaTokenizer\nfrom sklearn.metrics import precision_score, accuracy_score, recall_score, classification_report\nfrom keras.utils import to_categorical","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:53:56.000678Z","iopub.execute_input":"2021-09-11T11:53:56.001051Z","iopub.status.idle":"2021-09-11T11:54:04.257446Z","shell.execute_reply.started":"2021-09-11T11:53:56.001011Z","shell.execute_reply":"2021-09-11T11:54:04.256593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Load Data**","metadata":{}},{"cell_type":"code","source":"train_full = pd.read_csv('/kaggle/input/covid-19-nlp-text-classification/Corona_NLP_train.csv')\ntest = pd.read_csv('/kaggle/input/covid-19-nlp-text-classification/Corona_NLP_test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:04.261375Z","iopub.execute_input":"2021-09-11T11:54:04.261679Z","iopub.status.idle":"2021-09-11T11:54:04.57302Z","shell.execute_reply.started":"2021-09-11T11:54:04.261654Z","shell.execute_reply":"2021-09-11T11:54:04.572215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_full.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:04.574609Z","iopub.execute_input":"2021-09-11T11:54:04.574964Z","iopub.status.idle":"2021-09-11T11:54:04.600947Z","shell.execute_reply.started":"2021-09-11T11:54:04.574929Z","shell.execute_reply":"2021-09-11T11:54:04.600146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:04.603506Z","iopub.execute_input":"2021-09-11T11:54:04.603754Z","iopub.status.idle":"2021-09-11T11:54:04.617036Z","shell.execute_reply.started":"2021-09-11T11:54:04.60373Z","shell.execute_reply":"2021-09-11T11:54:04.616286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Development data: {train_full.shape}')\nprint(f'Unseen data: {test.shape}')","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:04.61848Z","iopub.execute_input":"2021-09-11T11:54:04.618807Z","iopub.status.idle":"2021-09-11T11:54:04.626965Z","shell.execute_reply.started":"2021-09-11T11:54:04.618774Z","shell.execute_reply":"2021-09-11T11:54:04.626207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Understanding**","metadata":{}},{"cell_type":"code","source":"# profile = ProfileReport(train_full, title = 'Corona Tweets Report', explorative = True)\n# display(profile)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:04.628291Z","iopub.execute_input":"2021-09-11T11:54:04.628616Z","iopub.status.idle":"2021-09-11T11:54:04.633753Z","shell.execute_reply.started":"2021-09-11T11:54:04.628581Z","shell.execute_reply":"2021-09-11T11:54:04.632787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Train data has 41157 rows and 6 columns.\n\nColumns explanation:\n- UserName: Index of the user\n- ScreenName: Index of the user's screen\n- Location: country of the user\n- TweetAt: Date of the tweets\n- OriginialTweet: Contents of the tweets\n- Sentiment: Sentiment of the user\n\nUnderstanding about the data:\n- Has two numerical and four categorical\n- UserName and ScreenName have unique values.\n- Location has high cardinality and missing values.\n- TweetAt is highly correlated with UserName and ScreenName\n- Sentiment has only 5 unique values which is Positive, Negative, Neutral, Extremely Positive, and Extremely Negative","metadata":{}},{"cell_type":"markdown","source":"# **Exploratory Data Analysis**\n\nSince it's EDA, I'll only use train data. First, I'm going to split train full data into 80% train data and 20% validation data.","metadata":{}},{"cell_type":"code","source":"train, valid = train_test_split(train_full, test_size = 0.2, random_state = 100)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:04.636903Z","iopub.execute_input":"2021-09-11T11:54:04.637272Z","iopub.status.idle":"2021-09-11T11:54:04.651036Z","shell.execute_reply.started":"2021-09-11T11:54:04.637239Z","shell.execute_reply":"2021-09-11T11:54:04.650344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:04.652815Z","iopub.execute_input":"2021-09-11T11:54:04.653192Z","iopub.status.idle":"2021-09-11T11:54:04.664029Z","shell.execute_reply.started":"2021-09-11T11:54:04.653158Z","shell.execute_reply":"2021-09-11T11:54:04.663232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:04.665296Z","iopub.execute_input":"2021-09-11T11:54:04.665825Z","iopub.status.idle":"2021-09-11T11:54:04.68003Z","shell.execute_reply.started":"2021-09-11T11:54:04.665788Z","shell.execute_reply":"2021-09-11T11:54:04.679042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Training data: {train.shape}')\nprint(f'Validation data: {valid.shape}')","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:04.681398Z","iopub.execute_input":"2021-09-11T11:54:04.68172Z","iopub.status.idle":"2021-09-11T11:54:04.686628Z","shell.execute_reply.started":"2021-09-11T11:54:04.681688Z","shell.execute_reply":"2021-09-11T11:54:04.685738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To prevent the train data changed while EDA, I will pass it into a new dataframe.","metadata":{}},{"cell_type":"code","source":"df = train.copy()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:04.688041Z","iopub.execute_input":"2021-09-11T11:54:04.688599Z","iopub.status.idle":"2021-09-11T11:54:04.696032Z","shell.execute_reply.started":"2021-09-11T11:54:04.688564Z","shell.execute_reply":"2021-09-11T11:54:04.69523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:04.697481Z","iopub.execute_input":"2021-09-11T11:54:04.697877Z","iopub.status.idle":"2021-09-11T11:54:04.709592Z","shell.execute_reply.started":"2021-09-11T11:54:04.697842Z","shell.execute_reply":"2021-09-11T11:54:04.708697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:04.710976Z","iopub.execute_input":"2021-09-11T11:54:04.711564Z","iopub.status.idle":"2021-09-11T11:54:04.718407Z","shell.execute_reply.started":"2021-09-11T11:54:04.71153Z","shell.execute_reply":"2021-09-11T11:54:04.717524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## UserName and ScreenName Columns\n\nAt data understanding, I've mentioned that UserName and ScreenName columns has unique values. If I'm going to plot these, I won't get any insights too. I think it's better to ignore these columns. Also, at data preprocessing, it's better to drop these columns since they're not useful for data analysis.","metadata":{}},{"cell_type":"markdown","source":"## Location\n\nSince Location has high cardinality, let's check the unique values.","metadata":{}},{"cell_type":"code","source":"df['Location'].nunique()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:04.719755Z","iopub.execute_input":"2021-09-11T11:54:04.720453Z","iopub.status.idle":"2021-09-11T11:54:04.736746Z","shell.execute_reply.started":"2021-09-11T11:54:04.720414Z","shell.execute_reply":"2021-09-11T11:54:04.736026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Location'].value_counts(dropna = False)[:20]","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:04.738046Z","iopub.execute_input":"2021-09-11T11:54:04.738396Z","iopub.status.idle":"2021-09-11T11:54:04.759125Z","shell.execute_reply.started":"2021-09-11T11:54:04.738363Z","shell.execute_reply":"2021-09-11T11:54:04.758092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We could see the values are inconsistent. Let's fix this!","metadata":{}},{"cell_type":"code","source":"df['Location'] = df['Location'].str.split(',').str[0]\ndf.loc[df['Location'] == 'UK' ,'Location'] = 'United Kingdom'\ndf.loc[df['Location'] == 'USA', 'Location'] = 'United States'\ndf.loc[df['Location'] == 'US', 'Location'] = 'United States'\ndf.loc[df['Location'] == 'The United States of America', 'Location'] = 'United States'\ndf.loc[df['Location'] == 'United States of America', 'Location'] = 'United States'\ndf.loc[df['Location'] == 'America', 'Location'] = 'United States'\ndf.loc[df['Location'] == 'United States ', 'Location'] = 'United States'","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:04.761109Z","iopub.execute_input":"2021-09-11T11:54:04.761655Z","iopub.status.idle":"2021-09-11T11:54:04.846052Z","shell.execute_reply.started":"2021-09-11T11:54:04.76162Z","shell.execute_reply":"2021-09-11T11:54:04.845266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Location'].nunique()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:04.847289Z","iopub.execute_input":"2021-09-11T11:54:04.847629Z","iopub.status.idle":"2021-09-11T11:54:04.861188Z","shell.execute_reply.started":"2021-09-11T11:54:04.847596Z","shell.execute_reply":"2021-09-11T11:54:04.859889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Location'].value_counts(dropna = False)[:20]","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:04.862385Z","iopub.execute_input":"2021-09-11T11:54:04.862716Z","iopub.status.idle":"2021-09-11T11:54:04.882252Z","shell.execute_reply.started":"2021-09-11T11:54:04.862682Z","shell.execute_reply":"2021-09-11T11:54:04.881201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we could see, the location contains missing values. If I drop the rows that contains missing data, it maybe could affect our EDA so let's pass it into new dataframe rather than take a risk by dropping it!","metadata":{}},{"cell_type":"code","source":"df2 = df.copy()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:04.883823Z","iopub.execute_input":"2021-09-11T11:54:04.884184Z","iopub.status.idle":"2021-09-11T11:54:04.889661Z","shell.execute_reply.started":"2021-09-11T11:54:04.88415Z","shell.execute_reply":"2021-09-11T11:54:04.888754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Dataframe with missing values: {df.shape}')\nprint(f'Dataframe without missing values: {df2.shape}')","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:04.893498Z","iopub.execute_input":"2021-09-11T11:54:04.894041Z","iopub.status.idle":"2021-09-11T11:54:04.899061Z","shell.execute_reply.started":"2021-09-11T11:54:04.894006Z","shell.execute_reply":"2021-09-11T11:54:04.898147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It's copied well since both dataframes have the same shape.","metadata":{}},{"cell_type":"code","source":"df2.dropna(axis = 0, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:04.900765Z","iopub.execute_input":"2021-09-11T11:54:04.901308Z","iopub.status.idle":"2021-09-11T11:54:04.935929Z","shell.execute_reply.started":"2021-09-11T11:54:04.901241Z","shell.execute_reply":"2021-09-11T11:54:04.935201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:04.940342Z","iopub.execute_input":"2021-09-11T11:54:04.940617Z","iopub.status.idle":"2021-09-11T11:54:04.95242Z","shell.execute_reply.started":"2021-09-11T11:54:04.94059Z","shell.execute_reply":"2021-09-11T11:54:04.951515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Expected rows after dropping: {df.shape[0] - 6910}')\nprint(f'True rows after dropping: {df2.shape[0]}')","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:04.955737Z","iopub.execute_input":"2021-09-11T11:54:04.956012Z","iopub.status.idle":"2021-09-11T11:54:04.961039Z","shell.execute_reply.started":"2021-09-11T11:54:04.95597Z","shell.execute_reply":"2021-09-11T11:54:04.960007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It's dropped well since both dataframes have the same shape.","metadata":{}},{"cell_type":"code","source":"df2['Location'].value_counts()[:50]","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:04.962745Z","iopub.execute_input":"2021-09-11T11:54:04.963238Z","iopub.status.idle":"2021-09-11T11:54:04.983643Z","shell.execute_reply.started":"2021-09-11T11:54:04.963185Z","shell.execute_reply":"2021-09-11T11:54:04.982716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We could see that the location contains countries or cities. So let's plot top 10 countries and top 10 cities in different plots.","metadata":{}},{"cell_type":"code","source":"city = ['London', 'New York', 'Washington', 'Los Angeles', 'Toronto', \n        'Chicago', 'Sydney', 'San Francisco', 'Melbourne', 'New Delhi']\n\ncountry = ['United States', 'United Kingdom', 'England', 'India', 'Australia', \n           'Canada', 'Scotland', 'Singapore', 'South Africa']\n\nstates = ['Texas', 'Florida', 'California', 'New Jersey']","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:04.984862Z","iopub.execute_input":"2021-09-11T11:54:04.985208Z","iopub.status.idle":"2021-09-11T11:54:04.990935Z","shell.execute_reply.started":"2021-09-11T11:54:04.985174Z","shell.execute_reply":"2021-09-11T11:54:04.989847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"color = ['#F2B138', '#29AB87', '#C21807', '#0B6623', '#7C0A02']\n\nplt.figure(figsize = (20, 8))\nplt.title('Top 10 Cities that has the most tweets', size = 20)\ncplot = sns.countplot(x = 'Location', hue = 'Sentiment', data = df2, order = city, palette = color)\n\nfor p in cplot.patches:\n    cplot.annotate(format(p.get_height(), '.0f'), \n                   (p.get_x() + p.get_width() / 2, p.get_height()), \n                   ha = 'center', va = 'center', \n                   xytext = (0, 9), \n                   textcoords = 'offset points')\n    \nplt.xlabel('City', fontsize = 18)\nplt.ylabel('Count', fontsize = 18)\nplt.xticks(fontsize = 14)\nplt.legend(prop = {'size': 13})\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:04.992315Z","iopub.execute_input":"2021-09-11T11:54:04.992862Z","iopub.status.idle":"2021-09-11T11:54:06.534887Z","shell.execute_reply.started":"2021-09-11T11:54:04.992828Z","shell.execute_reply":"2021-09-11T11:54:06.534058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can conclude that top 10 cities tend to have more positive sentiment especially San Francisco that has extremely positive sentiment. Only New Delhi that has more neutral sentiment.","metadata":{}},{"cell_type":"code","source":"color = ['#F2B138', '#29AB87', '#C21807', '#0B6623', '#7C0A02']\n\nplt.figure(figsize = (20, 8))\nplt.title('Top 10 Countries that has the most tweets', size = 20)\ncplot = sns.countplot(x = 'Location', hue = 'Sentiment', data = df2, order = country, palette = color)\n\nfor p in cplot.patches:\n    cplot.annotate(format(p.get_height(), '.0f'), \n                   (p.get_x() + p.get_width() / 2, p.get_height()), \n                   ha = 'center', va = 'center', \n                   xytext = (0, 9), \n                   textcoords = 'offset points')\n    \nplt.xlabel('Country', fontsize = 18)\nplt.ylabel('Count', fontsize = 18)\nplt.xticks(fontsize = 14)\nplt.legend(prop = {'size': 13})\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:06.536096Z","iopub.execute_input":"2021-09-11T11:54:06.538979Z","iopub.status.idle":"2021-09-11T11:54:07.343865Z","shell.execute_reply.started":"2021-09-11T11:54:06.538937Z","shell.execute_reply":"2021-09-11T11:54:07.34308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can conclude that top 9 countries tend to have more positive sentiment. Only India that has more negative sentiment. Besides that, only Canada that has more neutral sentiment.","metadata":{}},{"cell_type":"code","source":"color = ['#F2B138', '#29AB87', '#C21807', '#0B6623', '#7C0A02']\n\nplt.figure(figsize = (20, 8))\nplt.title('Top 4 States that has the most tweets', size = 20)\ncplot = sns.countplot(x = 'Location', hue = 'Sentiment', data = df2, order = states, palette = color)\n\nfor p in cplot.patches:\n    cplot.annotate(format(p.get_height(), '.0f'), \n                   (p.get_x() + p.get_width() / 2, p.get_height()), \n                   ha = 'center', va = 'center', \n                   xytext = (0, 9), \n                   textcoords = 'offset points')\n    \nplt.xlabel('Country', fontsize = 18)\nplt.ylabel('Count', fontsize = 18)\nplt.xticks(fontsize = 14)\nplt.legend(prop = {'size': 13})\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:07.345054Z","iopub.execute_input":"2021-09-11T11:54:07.345389Z","iopub.status.idle":"2021-09-11T11:54:07.732361Z","shell.execute_reply.started":"2021-09-11T11:54:07.34536Z","shell.execute_reply":"2021-09-11T11:54:07.731573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sentiment","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"code","source":"def encoded_cat(df):\n    df['Labels'] = df['Sentiment'].astype('category').cat.codes\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:07.735085Z","iopub.execute_input":"2021-09-11T11:54:07.735364Z","iopub.status.idle":"2021-09-11T11:54:07.739618Z","shell.execute_reply.started":"2021-09-11T11:54:07.735338Z","shell.execute_reply":"2021-09-11T11:54:07.738846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_full = encoded_cat(train_full)\ntrain = encoded_cat(train)\nvalid = encoded_cat(valid)\ntest = encoded_cat(test)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:07.741202Z","iopub.execute_input":"2021-09-11T11:54:07.741742Z","iopub.status.idle":"2021-09-11T11:54:07.763472Z","shell.execute_reply.started":"2021-09-11T11:54:07.741703Z","shell.execute_reply":"2021-09-11T11:54:07.762647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_full['Labels'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:07.764567Z","iopub.execute_input":"2021-09-11T11:54:07.764893Z","iopub.status.idle":"2021-09-11T11:54:07.773784Z","shell.execute_reply.started":"2021-09-11T11:54:07.764855Z","shell.execute_reply":"2021-09-11T11:54:07.772503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['Labels'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:07.775579Z","iopub.execute_input":"2021-09-11T11:54:07.775923Z","iopub.status.idle":"2021-09-11T11:54:07.785026Z","shell.execute_reply.started":"2021-09-11T11:54:07.77589Z","shell.execute_reply":"2021-09-11T11:54:07.783965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid['Labels'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:07.78655Z","iopub.execute_input":"2021-09-11T11:54:07.787054Z","iopub.status.idle":"2021-09-11T11:54:07.79503Z","shell.execute_reply.started":"2021-09-11T11:54:07.787018Z","shell.execute_reply":"2021-09-11T11:54:07.794121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['Labels'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:07.796489Z","iopub.execute_input":"2021-09-11T11:54:07.797142Z","iopub.status.idle":"2021-09-11T11:54:07.806028Z","shell.execute_reply.started":"2021-09-11T11:54:07.797096Z","shell.execute_reply":"2021-09-11T11:54:07.805021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X, y = train_full['OriginalTweet'].to_list(), train_full['Labels'].to_list()\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.2, stratify = y, random_state = 100)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:07.807244Z","iopub.execute_input":"2021-09-11T11:54:07.807595Z","iopub.status.idle":"2021-09-11T11:54:07.875669Z","shell.execute_reply.started":"2021-09-11T11:54:07.807559Z","shell.execute_reply":"2021-09-11T11:54:07.87495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test, y_test = test['OriginalTweet'].to_list(), test['Labels'].to_list()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:07.876745Z","iopub.execute_input":"2021-09-11T11:54:07.877075Z","iopub.status.idle":"2021-09-11T11:54:07.881858Z","shell.execute_reply.started":"2021-09-11T11:54:07.877041Z","shell.execute_reply":"2021-09-11T11:54:07.880838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convert_to_dfX(df):\n    df = pd.DataFrame(df, columns = ['OriginalTweet'])\n    return df\n\ndef convert_to_dfy(df):\n    df = pd.DataFrame(df, columns = ['Labels'])\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:07.883241Z","iopub.execute_input":"2021-09-11T11:54:07.883631Z","iopub.status.idle":"2021-09-11T11:54:07.891454Z","shell.execute_reply.started":"2021-09-11T11:54:07.883593Z","shell.execute_reply":"2021-09-11T11:54:07.890532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_X_train = convert_to_dfX(X_train)\ndf_X_valid = convert_to_dfX(X_valid)\ndf_X_test = convert_to_dfX(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:07.892766Z","iopub.execute_input":"2021-09-11T11:54:07.893161Z","iopub.status.idle":"2021-09-11T11:54:07.908166Z","shell.execute_reply.started":"2021-09-11T11:54:07.893108Z","shell.execute_reply":"2021-09-11T11:54:07.907426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_X_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:07.910947Z","iopub.execute_input":"2021-09-11T11:54:07.911237Z","iopub.status.idle":"2021-09-11T11:54:07.923056Z","shell.execute_reply.started":"2021-09-11T11:54:07.911212Z","shell.execute_reply":"2021-09-11T11:54:07.92189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_X_valid.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:07.924567Z","iopub.execute_input":"2021-09-11T11:54:07.924938Z","iopub.status.idle":"2021-09-11T11:54:07.935078Z","shell.execute_reply.started":"2021-09-11T11:54:07.924905Z","shell.execute_reply":"2021-09-11T11:54:07.93397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_X_test.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:07.936432Z","iopub.execute_input":"2021-09-11T11:54:07.936865Z","iopub.status.idle":"2021-09-11T11:54:07.947677Z","shell.execute_reply.started":"2021-09-11T11:54:07.936831Z","shell.execute_reply":"2021-09-11T11:54:07.946775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_y_train = convert_to_dfy(y_train)\ndf_y_valid = convert_to_dfy(y_valid)\ndf_y_test = convert_to_dfy(y_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:07.948902Z","iopub.execute_input":"2021-09-11T11:54:07.949346Z","iopub.status.idle":"2021-09-11T11:54:07.975145Z","shell.execute_reply.started":"2021-09-11T11:54:07.949313Z","shell.execute_reply":"2021-09-11T11:54:07.974355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_y_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:07.976412Z","iopub.execute_input":"2021-09-11T11:54:07.977063Z","iopub.status.idle":"2021-09-11T11:54:07.989501Z","shell.execute_reply.started":"2021-09-11T11:54:07.977027Z","shell.execute_reply":"2021-09-11T11:54:07.988661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_y_valid.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:07.992646Z","iopub.execute_input":"2021-09-11T11:54:07.992953Z","iopub.status.idle":"2021-09-11T11:54:08.001311Z","shell.execute_reply.started":"2021-09-11T11:54:07.992921Z","shell.execute_reply":"2021-09-11T11:54:08.000409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_y_test.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:08.002468Z","iopub.execute_input":"2021-09-11T11:54:08.002821Z","iopub.status.idle":"2021-09-11T11:54:08.013259Z","shell.execute_reply.started":"2021-09-11T11:54:08.002778Z","shell.execute_reply":"2021-09-11T11:54:08.012194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Training Data')\nprint(X_train[:15])\nprint(y_train[:15])\nprint('\\nValidation Data')\nprint(X_valid[:15])\nprint(y_valid[:15])\nprint('\\nUnseen Data')\nprint(X_test[:15])\nprint(y_test[:15])","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:08.014562Z","iopub.execute_input":"2021-09-11T11:54:08.014933Z","iopub.status.idle":"2021-09-11T11:54:08.024339Z","shell.execute_reply.started":"2021-09-11T11:54:08.014897Z","shell.execute_reply":"2021-09-11T11:54:08.023224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stopword = nltk.corpus.stopwords.words(\"english\")","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:08.025828Z","iopub.execute_input":"2021-09-11T11:54:08.026397Z","iopub.status.idle":"2021-09-11T11:54:08.035874Z","shell.execute_reply.started":"2021-09-11T11:54:08.02636Z","shell.execute_reply":"2021-09-11T11:54:08.035098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean(text):\n    #     remove urls\n    text = re.sub(r'http\\S+', \" \", text)\n    #     remove mentions\n    text = re.sub(r'@\\w+',' ',text)\n    #     remove hastags\n    text = re.sub(r'#\\w+', ' ', text)\n    #     remove digits\n    text = re.sub(r'\\d+', ' ', text)\n    #     remove html tags\n    text = re.sub('r<.*?>',' ', text)\n    # Removes symbols\n    text = re.sub(r'&[A-Za-z0-9]+', ' ', text)\n    \n    # Removes uniques characters\n    text = re.sub(r'[^a-zA-Z ]',' ', text)\n    \n    # Remove all extra spaces\n    text = re.sub(r'( +)',' ', text)\n    text = text.strip()\n    \n    # Changes characters to lowercase\n    text = text.lower()\n    \n    # remove stop words \n    text = text.split()\n    text = \" \".join([word for word in text if not word in stopword])\n    \n    return text","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:08.037279Z","iopub.execute_input":"2021-09-11T11:54:08.037727Z","iopub.status.idle":"2021-09-11T11:54:08.044924Z","shell.execute_reply.started":"2021-09-11T11:54:08.037691Z","shell.execute_reply":"2021-09-11T11:54:08.043951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_copy = df_X_train.copy()\nX_valid_copy = df_X_valid.copy()\nX_test_copy = df_X_test.copy()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:08.046497Z","iopub.execute_input":"2021-09-11T11:54:08.046948Z","iopub.status.idle":"2021-09-11T11:54:08.054617Z","shell.execute_reply.started":"2021-09-11T11:54:08.046904Z","shell.execute_reply":"2021-09-11T11:54:08.053681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_copy.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:08.056505Z","iopub.execute_input":"2021-09-11T11:54:08.056775Z","iopub.status.idle":"2021-09-11T11:54:08.0672Z","shell.execute_reply.started":"2021-09-11T11:54:08.056749Z","shell.execute_reply":"2021-09-11T11:54:08.06622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_clean_X_train = X_train_copy['OriginalTweet'].apply(lambda x: clean(x)).to_list()\nnew_clean_X_valid = X_valid_copy['OriginalTweet'].apply(lambda x: clean(x)).to_list()\nnew_clean_X_test = X_test_copy['OriginalTweet'].apply(lambda x: clean(x)).to_list()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:08.069788Z","iopub.execute_input":"2021-09-11T11:54:08.070236Z","iopub.status.idle":"2021-09-11T11:54:11.883443Z","shell.execute_reply.started":"2021-09-11T11:54:08.070208Z","shell.execute_reply":"2021-09-11T11:54:11.882568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Training Data')\nprint(new_clean_X_train[16:20])\nprint(y_train[:15])\nprint('\\nValidation Data')\nprint(new_clean_X_valid[16:20])\nprint(y_valid[:15])\nprint('\\nUnseen Data')\nprint(new_clean_X_test[16:20])\nprint(y_test[10:15])","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:11.884783Z","iopub.execute_input":"2021-09-11T11:54:11.885163Z","iopub.status.idle":"2021-09-11T11:54:11.894792Z","shell.execute_reply.started":"2021-09-11T11:54:11.885112Z","shell.execute_reply":"2021-09-11T11:54:11.893854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Baseline Model","metadata":{}},{"cell_type":"code","source":"text_clf = Pipeline([\n    ('vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('clf', MultinomialNB()),\n])\n\ntext_clf.fit(new_clean_X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:11.895887Z","iopub.execute_input":"2021-09-11T11:54:11.896144Z","iopub.status.idle":"2021-09-11T11:54:12.662586Z","shell.execute_reply.started":"2021-09-11T11:54:11.896104Z","shell.execute_reply":"2021-09-11T11:54:12.661612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = text_clf.predict(new_clean_X_test)\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:12.664102Z","iopub.execute_input":"2021-09-11T11:54:12.664466Z","iopub.status.idle":"2021-09-11T11:54:12.761231Z","shell.execute_reply.started":"2021-09-11T11:54:12.664426Z","shell.execute_reply":"2021-09-11T11:54:12.760313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Accuracy Score: {accuracy_score(y_test, y_pred)}\")","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:12.76239Z","iopub.execute_input":"2021-09-11T11:54:12.762701Z","iopub.status.idle":"2021-09-11T11:54:12.772308Z","shell.execute_reply.started":"2021-09-11T11:54:12.762676Z","shell.execute_reply":"2021-09-11T11:54:12.77122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modelling","metadata":{}},{"cell_type":"code","source":"MODEL_NAME = 'roberta-base'\n\ntokenizer = RobertaTokenizer.from_pretrained(MODEL_NAME)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:12.773846Z","iopub.execute_input":"2021-09-11T11:54:12.774266Z","iopub.status.idle":"2021-09-11T11:54:17.374195Z","shell.execute_reply.started":"2021-09-11T11:54:12.77423Z","shell.execute_reply":"2021-09-11T11:54:17.373336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_clean_X_train[:5]","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:17.375565Z","iopub.execute_input":"2021-09-11T11:54:17.376092Z","iopub.status.idle":"2021-09-11T11:54:17.382395Z","shell.execute_reply.started":"2021-09-11T11:54:17.376054Z","shell.execute_reply":"2021-09-11T11:54:17.381381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label = preprocessing.LabelEncoder()\ny_train_categorical = label.fit_transform(train['Sentiment'])\ny_train_categorical = to_categorical(y_train_categorical)\nprint(y_train_categorical[:5])","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:17.383777Z","iopub.execute_input":"2021-09-11T11:54:17.384231Z","iopub.status.idle":"2021-09-11T11:54:17.405997Z","shell.execute_reply.started":"2021-09-11T11:54:17.384191Z","shell.execute_reply":"2021-09-11T11:54:17.404615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_valid_categorical = label.fit_transform(valid['Sentiment'])\ny_valid_categorical = to_categorical(y_valid_categorical)\nprint(y_valid_categorical[:5])","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:17.40769Z","iopub.execute_input":"2021-09-11T11:54:17.408214Z","iopub.status.idle":"2021-09-11T11:54:17.417008Z","shell.execute_reply.started":"2021-09-11T11:54:17.408177Z","shell.execute_reply":"2021-09-11T11:54:17.415981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2'\nbert_layer = hub.KerasLayer(m_url, trainable = True)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:17.418554Z","iopub.execute_input":"2021-09-11T11:54:17.419269Z","iopub.status.idle":"2021-09-11T11:54:33.322611Z","shell.execute_reply.started":"2021-09-11T11:54:17.419232Z","shell.execute_reply":"2021-09-11T11:54:33.321774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\ndo_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\ntokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:33.323919Z","iopub.execute_input":"2021-09-11T11:54:33.324261Z","iopub.status.idle":"2021-09-11T11:54:33.443722Z","shell.execute_reply.started":"2021-09-11T11:54:33.324227Z","shell.execute_reply":"2021-09-11T11:54:33.442921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def bert_encode(texts, tokenizer, max_len=512):\n    all_tokens = []\n    all_masks = []\n    all_segments = []\n    \n    for text in texts:\n        text = tokenizer.tokenize(text)\n        \n        text = text[:max_len-2]\n        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n        pad_len = max_len-len(input_sequence)\n        \n        tokens = tokenizer.convert_tokens_to_ids(input_sequence) + [0] * pad_len\n        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n        segment_ids = [0] * max_len\n        \n        all_tokens.append(tokens)\n        all_masks.append(pad_masks)\n        all_segments.append(segment_ids)\n        \n    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:33.444945Z","iopub.execute_input":"2021-09-11T11:54:33.445471Z","iopub.status.idle":"2021-09-11T11:54:33.452645Z","shell.execute_reply.started":"2021-09-11T11:54:33.445429Z","shell.execute_reply":"2021-09-11T11:54:33.451754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_len = 250\n\nX_train_full_encoded = bert_encode(new_clean_X_train, tokenizer, max_len)\nX_train_encoded = bert_encode(new_clean_X_train, tokenizer, max_len)\nX_valid_encoded = bert_encode(new_clean_X_valid, tokenizer, max_len)\nX_test_encoded = bert_encode(new_clean_X_test, tokenizer, max_len)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T11:54:33.454252Z","iopub.execute_input":"2021-09-11T11:54:33.454981Z","iopub.status.idle":"2021-09-11T11:55:19.902344Z","shell.execute_reply.started":"2021-09-11T11:54:33.45494Z","shell.execute_reply":"2021-09-11T11:55:19.901422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model(bert_layer, max_len=512):\n    input_word_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n    input_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n    segment_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n    \n    pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n    \n    clf_output = sequence_output[:, 0, :]\n    \n    lay = tf.keras.layers.Dense(32, activation='relu')(clf_output)\n    lay = tf.keras.layers.Dropout(0.2)(lay)\n    lay = tf.keras.layers.Dense(16, activation='relu')(lay)\n    lay = tf.keras.layers.Dropout(0.2)(lay)\n    out = tf.keras.layers.Dense(5, activation='softmax')(lay)\n    \n    model = tf.keras.models.Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n    model.compile(tf.keras.optimizers.Adam(lr=2e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-09-11T15:41:41.727638Z","iopub.execute_input":"2021-09-11T15:41:41.727973Z","iopub.status.idle":"2021-09-11T15:41:41.736683Z","shell.execute_reply.started":"2021-09-11T15:41:41.727942Z","shell.execute_reply":"2021-09-11T15:41:41.735698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = build_model(bert_layer, max_len=max_len)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T15:41:42.114427Z","iopub.execute_input":"2021-09-11T15:41:42.114697Z","iopub.status.idle":"2021-09-11T15:41:42.260111Z","shell.execute_reply.started":"2021-09-11T15:41:42.114673Z","shell.execute_reply":"2021-09-11T15:41:42.259328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = tf.keras.callbacks.ModelCheckpoint('my_model.h5', save_best_only = True)\nearlystopping = tf.keras.callbacks.EarlyStopping(patience = 10)\n\nhistory = model.fit(\n    X_train_encoded, y_train_categorical,\n    validation_data = (X_valid_encoded, y_valid_categorical),\n    epochs = 20,\n    callbacks = [checkpoint, earlystopping],\n    batch_size = 16)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T15:41:42.642457Z","iopub.execute_input":"2021-09-11T15:41:42.642728Z","iopub.status.idle":"2021-09-11T16:21:03.00243Z","shell.execute_reply.started":"2021-09-11T15:41:42.642703Z","shell.execute_reply":"2021-09-11T16:21:03.000085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def convert_sentence_to_features(dataset):\n#     return tokenizer(\n#         dataset,\n#         add_special_tokens = True,\n#         return_attention_mask = True, # roberta doesn't need attention mask\n#         truncation = True,\n#         padding = True)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T14:53:29.403161Z","iopub.status.idle":"2021-09-11T14:53:29.403741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_train_encoded = convert_sentence_to_features(new_clean_X_train)\n# X_valid_encoded = convert_sentence_to_features(new_clean_X_valid)\n# X_test_encoded = convert_sentence_to_features(new_clean_X_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T13:17:05.860936Z","iopub.status.idle":"2021-09-11T13:17:05.861507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_train_encoded.keys()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T13:17:05.862778Z","iopub.status.idle":"2021-09-11T13:17:05.863352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# len(X_train_encoded['input_ids'])","metadata":{"execution":{"iopub.status.busy":"2021-09-11T13:17:05.864538Z","iopub.status.idle":"2021-09-11T13:17:05.865083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# len(y_train)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T13:17:05.86627Z","iopub.status.idle":"2021-09-11T13:17:05.866824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def build_model(bert_layer, max_len=512):\n#     input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n#     input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n#     segment_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n\n#     _, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n#     clf_output = sequence_output[:, 0, :]\n#     out = Dense(1, activation='sigmoid')(clf_output)\n    \n#     model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n#     model.compile(Adam(lr=2e-6), loss='binary_crossentropy', metrics=['accuracy'])\n    \n#     return model","metadata":{"execution":{"iopub.status.busy":"2021-09-11T13:17:05.867891Z","iopub.status.idle":"2021-09-11T13:17:05.868471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def tensor_slices(X, y):\n#     return tf.data.Dataset.from_tensor_slices((dict(X), y))","metadata":{"execution":{"iopub.status.busy":"2021-09-11T13:17:05.869666Z","iopub.status.idle":"2021-09-11T13:17:05.870228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# batch_size = 32\n# shuffle_buffer_size = 17000\n\n# train_encoded = tensor_slices(X_train_encoded, y_train).shuffle(shuffle_buffer_size).batch(batch_size)\n# valid_encoded = tensor_slices(X_valid_encoded, y_valid).batch(batch_size)\n# test_encoded = tensor_slices(X_test_encoded, y_test).batch(batch_size)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T13:17:05.871381Z","iopub.status.idle":"2021-09-11T13:17:05.871925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for message, label in train_encoded.take(1):\n    print(message, label)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T13:17:05.873694Z","iopub.status.idle":"2021-09-11T13:17:05.874399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for message, label in valid_encoded.take(1):\n    print(message, label)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T13:17:05.87543Z","iopub.status.idle":"2021-09-11T13:17:05.876104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for message, label in test_encoded.take(1):\n    print(message, label)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T13:17:05.877149Z","iopub.status.idle":"2021-09-11T13:17:05.877844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def build_roberta_model(learning_rate = 1e-5):\n#     roberta_model = TFRobertaForSequenceClassification.from_pretrained(MODEL_NAME, \n#                                                                        num_labels = 5, \n#                                                                        num_hidden_layers = 10)\n    \n#     optimizer = keras.optimizers.Adam(learning_rate = learning_rate, epsilon = 1e-8)\n#     roberta_model.compile(loss = 'sparse_categorical_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n#     return roberta_model","metadata":{"execution":{"iopub.status.busy":"2021-09-11T13:17:05.878874Z","iopub.status.idle":"2021-09-11T13:17:05.879582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# roberta_model = build_roberta_model()\n# roberta_model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T13:17:05.880632Z","iopub.status.idle":"2021-09-11T13:17:05.881343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%load_ext tensorboard\n\nlogdir = os.path.join('logs', 'my_baseline_model')\ntensorboard_cb = tf.keras.callbacks.TensorBoard(logdir, histogram_freq = 1)\ncheckpoint_cb = keras.callbacks.ModelCheckpoint(\"my_baseline_model.h5\", save_best_only = True)\nearly_stopping_cb = keras.callbacks.EarlyStopping(patience = 10)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T13:17:05.882378Z","iopub.status.idle":"2021-09-11T13:17:05.883068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# history = roberta_model.fit(train_encoded, epochs = 25,\n#                                   validation_data = valid_encoded,\n#                                   callbacks = [checkpoint_cb, early_stopping_cb, tensorboard_cb])","metadata":{"execution":{"iopub.status.busy":"2021-09-11T13:17:05.884103Z","iopub.status.idle":"2021-09-11T13:17:05.884812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %tensorboard --logdir logs","metadata":{"execution":{"iopub.status.busy":"2021-09-11T13:17:05.885832Z","iopub.status.idle":"2021-09-11T13:17:05.886546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y_pred = text_clf.predict(X_test)\n# print(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-09-11T13:17:05.887577Z","iopub.status.idle":"2021-09-11T13:17:05.888276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(f\"Accuracy Score: {accuracy_score(y_test, y_pred)}\")\n# print(f\"Precision Score: {precision_score(y_test, y_pred)}\")\n# print(f\"Recall Score: {recall_score(y_test, y_pred)}\")","metadata":{"execution":{"iopub.status.busy":"2021-09-11T13:17:05.889323Z","iopub.status.idle":"2021-09-11T13:17:05.890008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}