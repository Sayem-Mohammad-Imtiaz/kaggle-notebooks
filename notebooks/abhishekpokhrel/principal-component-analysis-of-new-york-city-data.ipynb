{"metadata":{"language_info":{"file_extension":".py","version":"3.5.4","nbconvert_exporter":"python","codemirror_mode":{"version":3,"name":"ipython"},"name":"python","mimetype":"text/x-python","pygments_lexer":"ipython3"},"kernelspec":{"language":"python","name":"Python [Root]","display_name":"Python [Root]"}},"cells":[{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","source":"# Handle table-like data and matrices\nimport numpy as np\nimport pandas as pd\n\n# Visualisation\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\nimport seaborn as sns\n\n# Configure visualisations\n%matplotlib inline\nmpl.style.use( 'ggplot' )\nsns.set_style( 'white' )\npylab.rcParams[ 'figure.figsize' ] = 8 , 6","execution_count":1},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","source":"#Setup Helper Functions\ndef plot_histograms( df , variables , n_rows , n_cols ):\n    fig = plt.figure( figsize = ( 16 , 12 ) )\n    for i, var_name in enumerate( variables ):\n        ax=fig.add_subplot( n_rows , n_cols , i+1 )\n        df[ var_name ].hist( bins=10 , ax=ax )\n        ax.set_title( 'Skew: ' + str( round( float( df[ var_name ].skew() ) , ) ) ) # + ' ' + var_name ) #var_name+\" Distribution\")\n        ax.set_xticklabels( [] , visible=False )\n        ax.set_yticklabels( [] , visible=False )\n    fig.tight_layout()  # Improves appearance a bit.\n    plt.show()\n\ndef plot_distribution( df , var , target , **kwargs ):\n    row = kwargs.get( 'row' , None )\n    col = kwargs.get( 'col' , None )\n    facet = sns.FacetGrid( df , hue=target , aspect=4 , row = row , col = col )\n    facet.map( sns.kdeplot , var , shade= True )\n    facet.set( xlim=( 0 , df[ var ].max() ) )\n    facet.add_legend()\n\ndef plot_categories( df , cat , target , **kwargs ):\n    row = kwargs.get( 'row' , None )\n    col = kwargs.get( 'col' , None )\n    facet = sns.FacetGrid( df , row = row , col = col )\n    facet.map( sns.barplot , cat , target )\n    facet.add_legend()\n\ndef plot_correlation_map( df ):\n    corr = df.corr()\n    _ , ax = plt.subplots( figsize =( 12 , 10 ) )\n    cmap = sns.diverging_palette( 220 , 10 , as_cmap = True )\n    _ = sns.heatmap(\n        corr, \n        cmap = cmap,\n        square=True, \n        cbar_kws={ 'shrink' : .9 }, \n        ax=ax, \n        annot = True, \n        annot_kws = { 'fontsize' : 12 }\n    )\n\ndef describe_more( df ):\n    var = [] ; l = [] ; t = []\n    for x in df:\n        var.append( x )\n        l.append( len( pd.value_counts( df[ x ] ) ) )\n        t.append( df[ x ].dtypes )\n    levels = pd.DataFrame( { 'Variable' : var , 'Levels' : l , 'Datatype' : t } )\n    levels.sort_values( by = 'Levels' , inplace = True )\n    return levels\n\ndef plot_variable_importance( X , y ):\n    tree = DecisionTreeClassifier( random_state = 99 )\n    tree.fit( X , y )\n    plot_model_var_imp( tree , X , y )\n    \ndef plot_model_var_imp( model , X , y ):\n    imp = pd.DataFrame( \n        model.feature_importances_  , \n        columns = [ 'Importance' ] , \n        index = X.columns \n    )\n    imp = imp.sort_values( [ 'Importance' ] , ascending = True )\n    imp[ : 10 ].plot( kind = 'barh' )\n    print (model.score( X , y ))","execution_count":2},{"metadata":{},"cell_type":"markdown","source":"# Loading Data and Basic Exploration"},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","source":"data = pd.read_csv(\"../input/pollution_us_2000_2016.csv\")","execution_count":3},{"metadata":{},"outputs":[],"cell_type":"code","source":"data.shape","execution_count":4},{"metadata":{},"outputs":[],"cell_type":"code","source":"data.columns","execution_count":5},{"metadata":{},"outputs":[],"cell_type":"code","source":"data.head(3)","execution_count":6},{"metadata":{},"cell_type":"markdown","source":"# Extracting Data for New York City and Preprocessing and Exploring"},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","source":"NY_mask = data['City'].str.contains('New York')\nny = data[NY_mask]","execution_count":7},{"metadata":{},"outputs":[],"cell_type":"code","source":"ny.head(2)","execution_count":8},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","source":"del ny['State']\ndel ny['Unnamed: 0']\ndel ny['State Code']\ndel ny['City']\ndel ny['Address']","execution_count":9},{"metadata":{},"outputs":[],"cell_type":"code","source":"ny.head()","execution_count":10},{"metadata":{},"outputs":[],"cell_type":"code","source":"ny.shape","execution_count":11},{"metadata":{},"outputs":[],"cell_type":"code","source":"ny.info()","execution_count":12},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","source":"del ny['NO2 Units']\ndel ny['NO2 1st Max Hour']\ndel ny['O3 Units']\ndel ny['O3 1st Max Hour']\ndel ny['SO2 Units']\ndel ny['SO2 1st Max Hour']\ndel ny['CO Units']\ndel ny['CO 1st Max Hour']","execution_count":13},{"metadata":{},"outputs":[],"cell_type":"code","source":"ny.head(2)","execution_count":14},{"metadata":{},"outputs":[],"cell_type":"code","source":"ny.shape","execution_count":15},{"metadata":{},"outputs":[],"cell_type":"code","source":"ny.describe()","execution_count":16},{"metadata":{},"outputs":[],"cell_type":"code","source":"plot_correlation_map(ny)","execution_count":17},{"metadata":{},"cell_type":"markdown","source":"# Creating New data frame by removing unnecessary columns. Then using interpolate() and dropna() to treat NaN and NA values."},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","source":"newdata = pd.DataFrame(ny, columns = ['NO2 Mean', 'NO2 1st Max Value', 'NO2 AQI', 'O3 Mean', 'O3 1st Max Value', 'O3 AQI', 'SO2 Mean', 'SO2 1st Max Value', 'SO2 AQI', 'CO Mean', 'CO 1st Max Value', 'CO AQI']) ","execution_count":18},{"metadata":{},"outputs":[],"cell_type":"code","source":"newdata.isnull().any()","execution_count":19},{"metadata":{},"outputs":[],"cell_type":"code","source":"newdata.shape","execution_count":20},{"metadata":{},"outputs":[],"cell_type":"code","source":"X = newdata.interpolate()\nX.shape","execution_count":21},{"metadata":{},"outputs":[],"cell_type":"code","source":"X.isnull().any()","execution_count":22},{"metadata":{},"outputs":[],"cell_type":"code","source":"X = X.dropna()\nX.shape","execution_count":23},{"metadata":{},"cell_type":"markdown","source":"# Creating new dataset free of NaN values and exploring."},{"metadata":{},"outputs":[],"cell_type":"code","source":"x_before_pca = pd.DataFrame(X)\nx_before_pca.describe()","execution_count":24},{"metadata":{},"outputs":[],"cell_type":"code","source":"x_before_pca.shape","execution_count":25},{"metadata":{},"outputs":[],"cell_type":"code","source":"plot_correlation_map(x_before_pca)","execution_count":26},{"metadata":{},"cell_type":"markdown","source":"# Using PCA to reduce variables."},{"metadata":{},"cell_type":"markdown","source":"### First we apply PCA for all the 12 variables (n_components = 12), i.e., we create 12 PCs. Then we see the amount of variance that each PC explains and plot that. Based on that, we select the number of PCs that we need."},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","source":"from sklearn.decomposition import PCA, RandomizedPCA","execution_count":27},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","source":"pca = PCA(n_components=12)","execution_count":28},{"metadata":{},"outputs":[],"cell_type":"code","source":"pca.fit(x_before_pca)","execution_count":29},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","source":"#The amount of variance that each PC explains\nvar = pca.explained_variance_ratio_","execution_count":30},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","source":"#Cumulative Variance explains\nvar1 = np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)","execution_count":31},{"metadata":{},"outputs":[],"cell_type":"code","source":"var1","execution_count":32},{"metadata":{},"outputs":[],"cell_type":"code","source":"plt.plot(var1)","execution_count":33},{"metadata":{},"cell_type":"markdown","source":"### So we will have 3 (although the ideal is 2) PCs."},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","source":"x_pca = PCA(n_components=3)","execution_count":34},{"metadata":{},"outputs":[],"cell_type":"code","source":"x_pca.fit(x_before_pca)","execution_count":35},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","source":"x = x_pca.fit_transform(x_before_pca)","execution_count":36},{"metadata":{},"outputs":[],"cell_type":"code","source":"type(x[:,0])","execution_count":37},{"metadata":{},"outputs":[],"cell_type":"code","source":"x.shape","execution_count":38},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","source":"d = {'pc1': x[:,0], 'pc2': x[:, 1], 'pc3': x[:,2]}\nx_df = pd.DataFrame(d)","execution_count":39},{"metadata":{},"cell_type":"markdown","source":"### x_df is the principal component data frame. Each column represents a principal component, and each row represents the set of PCs that explains that specific training example."},{"metadata":{},"outputs":[],"cell_type":"code","source":"x_df.shape","execution_count":40},{"metadata":{},"outputs":[],"cell_type":"code","source":"x_df.head(3)","execution_count":41},{"metadata":{},"outputs":[],"cell_type":"code","source":"x_df.describe()","execution_count":42},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","source":"x_new_ndarray = x_pca.inverse_transform(x_df)\nx_new = pd.DataFrame(x_new_ndarray)\nx_new.columns = ['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10', 'x11', 'x12']","execution_count":43},{"metadata":{},"cell_type":"markdown","source":"\n### x_new is the reconstructed data from the PC data frame x_df."},{"metadata":{},"outputs":[],"cell_type":"code","source":"x_new.shape","execution_count":44},{"metadata":{},"outputs":[],"cell_type":"code","source":"x_new.head(3)","execution_count":45},{"metadata":{},"outputs":[],"cell_type":"code","source":"x_before_pca.head(3)","execution_count":46},{"metadata":{},"outputs":[],"cell_type":"code","source":"plt.scatter(x_df['pc1'], x_df['pc2'], color = 'blue')","execution_count":47},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","source":"from mpl_toolkits.mplot3d import Axes3D","execution_count":48},{"metadata":{"scrolled":true},"outputs":[],"cell_type":"code","source":"fig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nax.scatter(xs = x_df['pc1'], ys = x_df['pc2'], zs= x_df['pc3'], zdir='z')","execution_count":49},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","source":"","execution_count":null}],"nbformat_minor":1,"nbformat":4}