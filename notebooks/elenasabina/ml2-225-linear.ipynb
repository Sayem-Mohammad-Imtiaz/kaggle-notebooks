{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n\n\n#import libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # plotting library for and its numerical mathematics extension NumPy\nimport seaborn as sns #library for making statistical graphics \nimport mpl_toolkits # 3D plotting \n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\ndf = pd.read_csv('/kaggle/input/housesalesprediction/kc_house_data.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\n#Data processing\ndf.isnull().sum()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Data visualization\nsns.set(rc={'figure.figsize':(11.7,8.27)})\nsns.distplot(df['sqft_living'], bins=30)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create a correlation matrix to measure linear relationships between variables\n#using corr function and heatmap function from the seaborn library to plot the correlation matrix\n\ncorrelation_matrix = df.corr().round(2)\n# annot = True to print the values inside the square\nsns.heatmap(data=correlation_matrix, annot=True)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#we can notice that price and bedroom have a high correlation with the target sqft_living\n#based on that, we will consider those features as our X variables and using a scatter plot we'll check how them vary with sqft_living\n\nplt.figure(figsize=(20, 5))\n\nfeatures = ['price', 'bedrooms']\ntarget = df['sqft_living']\n\nfor i, col in enumerate(features):\n    plt.subplot(1, len(features) , i+1)\n    x = df[col]\n    y = target\n    plt.scatter(x, y, marker='o')\n    plt.title(col)\n    plt.xlabel(col)\n    plt.ylabel('sqft_living')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#preparing the data for training the model\nX = pd.DataFrame(np.c_[df['price'], df['bedrooms']], columns = ['price','bedrooms'])\nY = df['sqft_living']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#preparing the data for training the model\nX = pd.DataFrame(np.c_[df['price'], df['bedrooms']], columns = ['price','bedrooms'])\nY = df['sqft_living']\n\n\n#Splitting the data into training and testing sets -- we use 80% of the samples to train the model and 20% to test it\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state=5)\nprint(X_train.shape)\nprint(X_test.shape)\nprint(Y_train.shape)\nprint(Y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Training and testing the model\n#We use scikit-learnâ€™s LinearRegression to train our model on both the training and test sets\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nlin_model = LinearRegression()\nlin_model.fit(X_train, Y_train)\n\n\n#Model evaluation -- will evaluate our model using RMSE and R2-score\n\n\ny_train_predict = lin_model.predict(X_train)\nrmse = (np.sqrt(mean_squared_error(Y_train, y_train_predict)))\nr2 = r2_score(Y_train, y_train_predict)\n\nprint(\"model performance for training set\")\nprint(\"--------------------------------------\")\nprint('RMSE is {}'.format(rmse))\nprint('R2 score is {}'.format(r2))\nprint(\"\\n\")\n\n# model evaluation for testing set\n\ny_test_predict = lin_model.predict(X_test)\n# root mean square error of the model\nrmse = (np.sqrt(mean_squared_error(Y_test, y_test_predict)))\n\n# r-squared score of the model\nr2 = r2_score(Y_test, y_test_predict)\n\nprint(\"The model performance for testing set\")\nprint(\"--------------------------------------\")\nprint('RMSE is {}'.format(rmse))\nprint('R2 score is {}'.format(r2))\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting the y_test vs y_pred\n# ideally should have been a straight line\nplt.scatter(Y_test, y_test_predict)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}