{"cells":[{"cell_type":"markdown","metadata":{},"source":"# Analysing \"How ISIS Uses Twitter\" using social network cluster analysis\n## Approach\nThe general approach will be to extract each unique user by their username to act as a node. \nThe username has been chosen as the associated data on each node as it is unique unlike names which\nmight not be. The scale of the node will be influenced by the a combination of the number of \nfollowers and the number of tweets they produce. This combination will ensure that active and \npopular users are identified rather than identifying those who tweet a lot and have a small amount \nof followers or vice versa.\n\nCurrently the relation between each user is yet to be decided, as well as the number of followers, \nwho those followers are would be useful to identify the relation between different users. \nOne relation criteria might be to scrape the tweets of users for mentions and then link nodes via \nthis metric with numerous mentions increasing the weight of an edge between two users. In this \ncontext two types of mentions could be identified, those that result in direct communication with \na user and those mentions that come from retweeting a user. The former could be combined with \nlanguage processing to determine the emotive qualities of the tweets to see if there are inner \nhostilities between ISIS supporters.\n\n## First Steps\nMatplotlib, as always, will be used to provide visualizations of statistics gathered from the data. \nNetworkX is a useful graph library which allows for the visualization of graphs, its draw functions\nare directly linked to matplotlib allowing for similar looking visualizations to be created."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport networkx as nx\nimport pandas as pd\nimport re\nimport numpy as np\nfrom collections import Counter\n\ndataset = pd.read_csv(\"../input/tweets.csv\")"},{"cell_type":"markdown","metadata":{},"source":"The first interesting stat to find would be how many users in the dataset tweet each other? \nThe first two print commands are to check that there are no duplicate tweets which would skew \nresults. The only disadvantage is that this relies on an exact string match, if retweets have been \npreceeded by an RT then this would not pick up duplicates.\n\nUsing a regex expression we can catch those tweets that contain \"RT\" at the start of the tweet \n(indicating a retweet) and count them. Compared to the previous check we can see roughly 6000 \ntweets are not actually useful due to them being retweets. Despite this they are useful for future \nreference in testing what relation criteria to use."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"print(\"Unique tweets: {}\".format(len(dataset['tweets'].unique())))\nprint(\"All tweets: {}\".format(len(dataset['tweets'])))\n\nretweets = []\nactual_tweets = []\nfor user, tweet in zip(dataset['username'], dataset['tweets']):\n    match = re.search(r'^\\bRT\\b', tweet)\n    if match == None:\n        actual_tweets.append([user,tweet])\n    else:\n        retweets.append([user,tweet])   \n\nactual_tweets = np.array(actual_tweets)\nretweets = np.array(retweets)\n\nplt.bar([1,2], [len(actual_tweets[:,1]), len(retweets[:,1])], align='center')\nax = plt.gca()\nax.set_xticks([1,2])\nax.set_xticklabels(['Actual Tweets', 'Retweets'])"},{"cell_type":"markdown","metadata":{},"source":"## Who talks about who?\nNow we have seperated the retweets and actual tweets and grouped them with their usernames we can \nproceed to perform some analysis on who is talking about who! \n\nFirstly we iterate through each tweet\nand scrape mentioned usernames from them. These usernames are then determined to either be users \nfrom within tweets.csv or not within tweets.csv. It is clear to see from the below bar chart that \nthe majority of users mentioned are outside the scope of the dataset. This opens up another avenue \nfor producing the social graph where a graph of all users mentioned can be constructed with colour \ndefining those that are known (within the dataset) and those that aren't known (not within the \ndataset). For now we'll focus on those contained only within the dataset as this is a smaller set \nof users to work with.\n\nThe second chart shows how many users in tweets.csv have been mentioned by other users within\ntweets.csv. There seems to be a reasonable amount of communication between the users but what this\ncommunication is, is yet to be seen."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"in_set = []\nnot_in_set = []\nfor record in actual_tweets:\n    match = re.findall(r'@\\w*', record[1])\n    if match != []:\n        for name in match:\n            if name[1:] in dataset['username'].unique():\n                in_set.append([record[0], name])\n            else:\n                not_in_set.append([record[0], name])\n\nin_set = np.array(in_set)\nnot_in_set = np.array(not_in_set)\n\nfig, ax = plt.subplots(1,2)\n\nax[0].bar([1,2], [len(np.unique(in_set[:,1])), len(np.unique(not_in_set[:,1]))], align='center')\nax[0].set_xticks([1,2])\nax[0].set_xticklabels(['In', 'Not in'])\nax[0].set_title('Users in vs. not in tweets.csv', fontsize=9)\n\nax[1].bar([1,2], [len(np.unique(in_set[:,1])), len(dataset['username'].unique())], align='center')\nax[1].set_xticks([1,2])\nax[1].set_xticklabels(['Mentioned', 'Total'])\nax[1].set_title('Mentioned vs. Total in tweets.csv', fontsize=9)"},{"cell_type":"markdown","metadata":{},"source":"To map out the most influential (most tweeted) users we need to count how many times they are \nmentioned. This is done via counting the in_set list, as can be seen below the most tweeted user \ncurrently (and by a large amount) is WarReporter1."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"user_count = Counter(in_set[:,1])\ntop_5 = user_count.most_common(5)\nprint(top_5)"},{"cell_type":"markdown","metadata":{},"source":"What are these top 5 all about? By grabbing their descriptions we can see they are mostly \"unbiased\"\nnews sites."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"for name, _ in top_5:\n    print(\"Username: {} - {}\\n\".format(name,\n            dataset[dataset['username'] == name[1:]]['description'].dropna().unique()[0]))"},{"cell_type":"markdown","metadata":{},"source":"After going on a tangent and looking at \"the top 5\", let's map these \"most tweeted\" to a graph! \n(albeit no edges yet). For the time being these nodes will remain in a circle, the usernames \nhaven't been added as labels yet as it looks hecka messy."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"graph = nx.Graph()\ngraph.add_nodes_from(user_count.keys())\nnx.draw(graph, node_size = [size*2 for key, size in user_count.items()])\nplt.show()"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}