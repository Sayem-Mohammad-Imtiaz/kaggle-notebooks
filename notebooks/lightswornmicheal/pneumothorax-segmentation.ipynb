{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport glob\n\nimport cv2\nimport albumentations as A \n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.utils import resample\n\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch import optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision\nfrom torchvision import models\n\n%matplotlib inline\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Global variables\nIMAGE_SIZE = 512\nBATCH_SIZE = 8\nLEARNING_RATE = 0.075\nLEARNING_RATE_SCHEDULE_FACTOR = 0.1           # Parameter used for reducing learning rate\nLEARNING_RATE_SCHEDULE_PATIENCE = 5           # Parameter used for reducing learning rate\nIMAGENET_MEAN = [0.485, 0.456, 0.406]         # Mean of ImageNet dataset (used for normalization)\nIMAGENET_STD = [0.229, 0.224, 0.225]          # Std of ImageNet dataset (used for normalization)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Utility functions"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"def run_length_decode(rle, height=1024, width=1024, fill_value=1):\n    component = np.zeros((height, width), np.float32)\n    component = component.reshape(-1)\n    rle = np.array([int(s) for s in rle.strip().split(' ')])\n    rle = rle.reshape(-1, 2)\n    start = 0\n    for index, length in rle:\n        start = start+index\n        end = start+length\n        component[start: end] = fill_value\n        start = end\n    component = component.reshape(width, height).T\n    return component"},{"metadata":{},"cell_type":"markdown","source":"## Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read image folder directory\ntrain_dir = '../input/siim-png-images/train_png/'\ntest_dir = '../input/siim-png-iamges/test_png/'\nmask_dir = '../input/siim-mask-png/mask_png'\n\n# Read dataframe from csv file\ntrain_df = pd.read_csv('../input/siim-segment-csv/train.csv')\nval_df = pd.read_csv('../input/siim-segment-csv/val.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define list of image transformations\ndef get_transforms(phase, size=IMAGE_SIZE, mean=IMAGENET_MEAN, std=IMAGENET_STD, normalization=False):\n    # Define list of image transformations\n    image_transformation = [A.Resize(height=size, width=size, p=1.0)]\n        \n    if(phase == 'train'):\n        image_transformation.append(A.HorizontalFlip(p=0.5))\n        image_transformation.append(A.OneOf([A.RandomContrast(), A.RandomGamma(), A.RandomBrightness(),], p=0.3))\n        # image_transformation.append(A.OneOf([A.ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n        #                             A.GridDistortion(), A.OpticalDistortion(distort_limit=2, shift_limit=0.5)], p=0.3))\n        image_transformation.append(A.ShiftScaleRotate(shift_limit=0.01, scale_limit=0.3, rotate_limit=10, border_mode=cv2.BORDER_CONSTANT, p=0.4))\n    \n    if normalization:\n            image_transformation.append(A.Normalize(mean=mean, std=std)) # Normalization with mean and std from ImageNet\n            \n    image_transformation = A.Compose(image_transformation)\n    \n    return image_transformation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Impelement Dataset Loader\nclass SIIMDataset(Dataset):\n    \n    def __init__(self, df, folder_dir, mask_dir, phase, normalization):\n        self.df = df\n        self.folder_dir = folder_dir\n        self.mask_dir = mask_dir\n        self.aug_transform = get_transforms(phase, normalization=normalization)\n        self.positive_num = len(self.df[self.df['has_mask'] == 1])\n        self.negative_num = len(self.df) - self.positive_num\n        self.labels = []\n        \n        for index in range(len(self.df)):\n            self.labels.append(self.df['has_mask'][index])\n            \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        image_id = self.df['ImageId'][index]\n        image_path = os.path.join(self.folder_dir, image_id + \".png\")\n        img_data = cv2.imread(image_path)\n        img_data = cv2.cvtColor(img_data, cv2.COLOR_BGR2RGB) # Convert image to RGB channels\n        \n        image_label = [self.df['has_mask'][index]] \n        if image_label[0] == 1:\n            mask_path = os.path.join(self.mask_dir, image_id + \".png\")\n            mask_data = cv2.imread(mask_path)[:, :, 0]\n        else: \n            mask_data = np.zeros([1024, 1024])\n        mask_data = (mask_data/255).astype(np.float32)\n        \n        augmented_data = self.aug_transform(image=img_data, mask=mask_data) # Apply transformation to image and mask\n        img_data = augmented_data['image']\n        mask_data = augmented_data['mask']\n        \n        return torch.FloatTensor(img_data), torch.FloatTensor(image_label), torch.FloatTensor(mask_data) # Covert image and mask to torch tensor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create training dataset and training data loader\ntrain_dataset = SIIMDataset(train_df, train_dir, mask_dir, phase='train', normalization=True)\ntrain_dl = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle = True, num_workers=8, pin_memory=True)\n\nval_dataset = SIIMDataset(val_df, train_dir, mask_dir, phase='val', normalization=True)\nval_dl = DataLoader(dataset = val_dataset, batch_size = BATCH_SIZE, shuffle = True, num_workers=8, pin_memory=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Show images and masks in first batch of train dataloader\ndef show_aug(inputs, nrows=1, ncols=8, image=True):\n    plt.figure(figsize=(3*ncols, 3*nrows))\n    plt.subplots_adjust(wspace=0., hspace=0.)\n    i_ = 0\n    \n    if len(inputs) > 8:\n        inputs = inputs[:8]\n        \n    for idx in range(len(inputs)):\n        img = inputs[idx].numpy().astype(np.float32)\n        \n        plt.subplot(nrows, ncols, i_+1)\n        if image:\n            plt.imshow(img[:,:,0], cmap='bone')\n        else:\n            plt.imshow(img)\n        plt.axis('off')\n        \n        i_ += 1\n \n    return plt.show()\n\n    \nimages, _, masks = next(iter(train_dl))\n\nshow_aug(images)\nshow_aug(masks, image=False)"},{"metadata":{},"cell_type":"markdown","source":"## Define network and architecture"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get backbone model and its needed layers' information\ndef get_backbone(name, pretrained=False):\n\n    \"\"\" Loading backbone, defining names for skip-connections and encoder output. \"\"\"\n    \n    # Loading backbone model\n    if name == 'resnet18':\n        backbone = models.resnet18(pretrained=pretrained)\n    elif name == 'resnet34':\n        backbone = models.resnet34(pretrained=pretrained)\n    elif name == 'resnet50':\n        backbone = models.resnet50(pretrained=pretrained)\n    elif name == 'resnet101':\n        backbone = models.resnet101(pretrained=pretrained)\n    elif name == 'resnet152':\n        backbone = models.resnet152(pretrained=pretrained)\n    elif name == 'vgg16':\n        backbone = models.vgg16_bn(pretrained=pretrained).features\n    elif name == 'vgg19':\n        backbone = models.vgg19_bn(pretrained=pretrained).features\n    elif name == 'densenet121':\n        backbone = models.densenet121(pretrained=pretrained).features\n    elif name == 'densenet161':\n        backbone = models.densenet161(pretrained=pretrained).features\n    elif name == 'densenet169':\n        backbone = models.densenet169(pretrained=pretrained).features\n    elif name == 'densenet201':\n        backbone = models.densenet201(pretrained=pretrained).features\n    elif name == 'unet_encoder':\n        from unet_backbone import UnetEncoder\n        backbone = UnetEncoder(3)\n    else:\n        raise NotImplemented('{} backbone model is not implemented so far.'.format(name))\n\n    # Specifying skip feature and output names\n    if name.startswith('resnet'):\n        feature_names = [None, 'relu', 'layer1', 'layer2', 'layer3']\n        backbone_output = 'layer4'\n    elif name == 'vgg16':\n        feature_names = ['5', '12', '22', '32', '42']\n        backbone_output = '43'\n    elif name == 'vgg19':\n        feature_names = ['5', '12', '25', '38', '51']\n        backbone_output = '52'\n    elif name.startswith('densenet'):\n        feature_names = [None, 'relu0', 'denseblock1', 'denseblock2', 'denseblock3']\n        backbone_output = 'denseblock4'\n    elif name == 'unet_encoder':\n        feature_names = ['module1', 'module2', 'module3', 'module4']\n        backbone_output = 'module5'\n    else:\n        raise NotImplemented('{} backbone model is not implemented so far.'.format(name))\n\n    return backbone, feature_names, backbone_output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Implements upsample blocks in UNet architecture\nclass UpsampleBlock(nn.Module):\n    \n    def __init__(self, ch_in, ch_out=None, skip_in=0):\n        \"\"\"\n        Init upsample block architecture\n        \n        Parameters\n        ----------\n        ch_in: int\n            number of input's channels\n        ch_out: int\n            number of output's channels\n        skip_in: \n            number of skip connection input's channels\n        \"\"\"\n        super().__init__()\n        \n        # Define upsample block layers:\n        \n        # Up convolution\n        self.up_conv = nn.ConvTranspose2d(in_channels=ch_in, out_channels=ch_out, kernel_size=(4, 4),\n                                          stride=2, padding=1, output_padding=0, bias=False) \n        self.bn = nn.BatchNorm2d(ch_out)\n        self.skipbn = nn.BatchNorm2d(skip_in)\n        \n        # First convolution\n        conv1_in = skip_in + ch_out \n        self.conv1 = nn.Conv2d(in_channels=conv1_in, out_channels=ch_out, kernel_size=(3, 3),\n                               stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(ch_out)\n        \n        # Second convolution\n        conv2_in = ch_out \n        self.conv2 = nn.Conv2d(in_channels=conv2_in, out_channels=ch_out, kernel_size=(3, 3),\n                               stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(ch_out)\n        \n        # ReLU layer\n        self.relu = nn.ReLU(inplace=True)\n        \n        # Dropout layer\n        # self.dropout = nn.Dropout(p=0.5, inplace=True)\n        \n    def forward(self, x, skip_connection):\n        # print('Input:', x.shape)\n        x = self.up_conv(x)\n        x = self.bn(x)\n        x = self.relu(x)\n        # print('After upconv:', x.shape)\n        \n        if skip_connection is not None:\n            skip_connection = self.skipbn(skip_connection)\n            skip_connection = self.relu(skip_connection)\n            # print('Skip connection:', skip_connection.shape)\n            x = torch.cat([x, skip_connection], dim=1)\n            # x = self.dropout(x)\n            # print(\"After concat:\", x.shape, '\\n')\n        \n        # Double convolution\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        \n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = self.relu(x)\n        \n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Implements upsample blocks in UNet architecture\nclass UpsampleBlockWithSERes(nn.Module):\n    \n    def __init__(self, ch_in, ch_out=None, skip_in=0):\n        \"\"\"\n        Init upsample block architecture\n        \n        Parameters\n        ----------\n        ch_in: int\n            number of input's channels\n        ch_out: int\n            number of output's channels\n        skip_in: \n            number of skip connection input's channels\n        \"\"\"\n        super().__init__()\n        \n        # Define upsample block layers:\n        \n        # Up convolution\n        self.up_conv = nn.Sequential(\n            nn.ConvTranspose2d(in_channels=ch_in, out_channels=ch_out, kernel_size=(4, 4), \n                               stride=2, padding=1, output_padding=0, bias=False),\n            nn.BatchNorm2d(ch_out),\n            nn.ReLU(inplace=True)\n        )\n        \n        self.skipbn = nn.BatchNorm2d(skip_in)\n        \n        # First convolution (bottleneck) \n        conv1_in = skip_in + ch_out \n        self.bottle_neck = nn.Sequential(\n            nn.Conv2d(in_channels=conv1_in, out_channels=ch_out, kernel_size=(1, 1),stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(ch_out),\n            nn.ReLU(inplace=True)\n        )\n        \n        # Residual module\n        self.res = nn.Sequential(\n            nn.Conv2d(in_channels=ch_out, out_channels=ch_out, kernel_size=(3, 3), stride=1, padding=1, bias=False),\n            nn.BatchNorm2d(ch_out),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_channels=ch_out, out_channels=ch_out, kernel_size=(1, 1), stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(ch_out),\n            nn.ReLU(inplace=True)\n        )\n        \n        # Squeeze and excitation module\n        r = 8\n        self.se = nn.Sequential(\n            nn.AdaptiveAvgPool2d((1,1)),\n            nn.Flatten(),\n            nn.Linear(ch_out, int(ch_out/r), bias=False),\n            nn.ReLU(inplace=True),\n            nn.Linear(int(ch_out/r), ch_out, bias=False),\n            nn.Sigmoid()\n        )\n    \n        \n    def forward(self, x, skip_connection):\n        # Up convolution\n        # print('Input:', x.shape)\n        x = self.up_conv(x)\n        # print('After upconv:', x.shape)\n        \n        if skip_connection is not None:\n            skip_connection = self.skipbn(skip_connection)\n            skip_connection = nn.ReLU(inplace=True)(skip_connection)\n            # print('Skip connection:', skip_connection.shape)\n            x = torch.cat([x, skip_connection], dim=1)\n            # x = self.dropout(x)\n            # print(\"After concat:\", x.shape, '\\n')\n        \n        # Pass through bottleneck\n        bottle_neck_output = self.bottle_neck(x)\n        \n        # Pass through residual module\n        res_output = self.res(bottle_neck_output)\n        # print(res_output.shape)\n        \n        # Passs through squeeze and excitation module\n        se_output = self.se(res_output)\n        \n        # Merge output of residual module and se module (multiplication)\n        x = torch.mul(res_output, se_output.unsqueeze(-1).unsqueeze(-1))\n        \n        # Add skip connection from bottle neck\n        x = x + bottle_neck_output\n        \n        del skip_connection, bottle_neck_output, res_output, se_output\n        if torch.cuda.is_available(): torch.cuda.empty_cache()\n        \n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Implement UNet with backbone model (two classes)\nclass UNet(nn.Module):\n    \n    def __init__(self, \n                 backbone_name='densenet121', \n                 pretrained=False, \n                 encoder_freeze=False,\n                 upsample_out_chs=(1024, 512, 256, 64, 32)):\n        \n        \"\"\"\n        Init UNet architecture with backbone model\n        \n        Parameters\n        ----------\n        backbone_name: string\n            name of backbone model \n        pretrained: bool\n            whether using pretrained model from ImageNet or not\n        encoder_freeze: bool \n            whether freezing encoder's parameters\n        decoder_filters: tuple\n            tuple contains decoder filters' size\n        \"\"\"\n        \n        super().__init__()\n        \n        # Get backbone model information\n        self.backbone, self.skip_feature_names, self.bb_out_name = get_backbone(backbone_name, pretrained=pretrained)\n        skip_chs, bb_out_ch = self.infer_skip_channels() # Getting the number of channels at skip connections and at the output of the encoder\n        if encoder_freeze: \n            self.freeze_encoder() # Freezing encoder parameters\n        \n        # Build upsample component\n        self.upsample_component = nn.ModuleList() # List of upsample blocks\n        upblock_out_chs = upsample_out_chs[:len(self.skip_feature_names)]  # Avoiding having more blocks than skip connections\n        upblock_in_chs = [bb_out_ch] + list(upblock_out_chs[:-1]) # Number of decoder filters' input channels\n        num_blocks = len(self.skip_feature_names) # Number of upsample block\n        \n        for i, [upblock_in_ch, upblock_out_ch] in enumerate(zip(upblock_in_chs, upblock_out_chs)):\n            # print('upsample_blocks[{}] in: {}  skip: {}  out: {}'.format(i, upblock_in_ch, skip_chs[num_blocks-i-1], upblock_out_ch))\n            self.upsample_component.append(UpsampleBlockWithSERes(upblock_in_ch, upblock_out_ch, skip_in=skip_chs[num_blocks-i-1]))\n            \n        # Final convolution layer\n        self.final_conv = nn.Conv2d(upblock_out_chs[-1], 1, kernel_size=(1, 1)) # Two classes segmentation\n        self.sigmoid = nn.Sigmoid()\n        \n    \n    def infer_skip_channels(self):\n        \n        \"\"\" Getting the number of channels at skip connections and at the output of the encoder. \"\"\"\n        \n        x = torch.zeros(1, 3, IMAGE_SIZE, IMAGE_SIZE)\n        skip_chs = [0] \n\n        # forward run in backbone to count channels \n        for name, child in self.backbone.named_children():\n            x = child(x)\n            if name in self.skip_feature_names:\n                skip_chs.append(x.shape[1])\n            if name == self.bb_out_name:\n                bb_out_ch = x.shape[1]\n                break\n                \n        return skip_chs, bb_out_ch\n    \n    \n    def freeze_encoder(self):\n\n        \"\"\" Freezing encoder parameters, the newly initialized decoder parameters are remaining trainable. \"\"\"\n\n        for param in self.backbone.parameters():\n            param.requires_grad = False\n    \n    \n    def forward_backbone(self, x):\n        \n        \"\"\" Forward propagation in backbone encoder network.  \"\"\"\n        \n        features = {None:None}\n        for name, child in self.backbone.named_children():\n            x = child(x)\n            if name in self.skip_feature_names:\n                features[name] = x\n            if name == self.bb_out_name: \n                break\n        \n        return x, features\n    \n    def forward(self, *input):\n        \n        \"\"\" Forward propagation in U-Net. \"\"\"\n\n        x, features = self.forward_backbone(*input)\n        \n        for skip_feature_name, upsample_block in zip(self.skip_feature_names[::-1], self.upsample_component):\n            skip_feature = features[skip_feature_name]\n            x = upsample_block(x, skip_feature)\n        \n        x = self.final_conv(x)\n        x = self.sigmoid(x)\n        \n        return x","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define loss and metric"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loss function\ndef Dice_Loss(preds, targets):\n    assert(preds.shape == targets.shape)\n    smooth = 0.1\n    intersection = 2.0 * ((targets * preds).sum(axis=(1,2,3))) + smooth\n    union = preds.sum(axis=(1,2,3)) + targets.sum(axis=(1,2,3)) + smooth\n\n    return 1 - (intersection / union)\n\ndef Dice_BCE_Loss(preds, targets):\n    dice_loss = Dice_Loss(preds, targets)\n    bce_loss = nn.BCELoss()\n    bce_loss = bce_loss(preds, targets)\n    \n    return dice_loss.mean() + bce_loss\n\n# Define loss function for model\nloss_func = nn.BCELoss()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Metric\ndef IoU(preds, targets, eps=1e-5):\n    intersection = (targets * preds).sum(axis=(1,2,3))\n    union = targets.sum(axis=(1,2,3)) + preds.sum(axis=(1,2,3)) - intersection\n    return ((intersection+eps)/(union+eps)).mean()\n\ndef Dice(preds, targets, eps=1e-5):\n    intersection = 2*(targets * preds).sum(axis=(1,2,3))\n    union = targets.sum(axis=(1,2,3)) + preds.sum(axis=(1,2,3)) \n    return ((intersection+eps)/(union+eps)).mean()\n\n# Define metric for model\nmetric = IoU","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check GPU available\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(device)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load model from saved checkpoint\ndef load_model_from_checkpoint(filepath, encoder_freeze=False):\n    checkpoint = torch.load(filepath)\n    model = checkpoint['model']\n    \n    for parameter in model.parameters():\n        parameter.requires_grad = True\n    \n    if encoder_freeze:\n        for param in model.backbone.parameters():\n            param.requires_grad = False\n    \n    return model"},{"metadata":{},"cell_type":"markdown","source":"# Learning rate range test (Linear)\ndef lr_range_test(train_dl, device, loss_func, base_lr, end_lr, num_iter, num_epoch):\n    \"\"\"\n    Learning rate range test\n\n    Paramteters\n    -----------\n    train_dl: Dataset\n      data loader for training\n    device: str\n      \"cpu\" or \"cuda\"\n    loss_func: loss function\n      loss function used for training\n    base_lr: float\n        base learning rate\n    end_lr: float\n        end learning rate\n    num_iter: int\n        number of iterations to update learning rate\n    num_epoch: int\n        number of epochs for implementing learning range test\n\n    Returns\n    -------\n    list\n      learning rates and training losses\n    \"\"\"\n    \n    # model = load_model_from_checkpoint('../input/siim-segment-cp/checkpoint_57eps.pth', False)\n    model = UNet(backbone_name='densenet121', pretrained=True, \n                 encoder_freeze=False, upsample_out_chs=(128, 64, 32, 16, 8)).to(device) # Init model to eval (UNet)\n    optimizer = optim.SGD(model.parameters(), lr=base_lr, momentum=0.9, nesterov=True, weight_decay=1e-6) # Optimizer\n    total_iter = num_epoch * len(train_dl) # Total number of iterations for training num_epoch\n    losses = [] # List of training loss\n    lrs = []    # List of learning rate\n    training_loss = 0 # Total training loss of num_iter iterations\n    \n    for epoch in range(num_epoch):\n        \n        # Upsample minority class\n        df = train_df\n        df_minor = df[df['has_mask']==1]\n        df_major = df[df['has_mask']==0]\n        df_minor_upsample = resample(df_minor, replace=True, n_samples = len(df_major), random_state=69)\n        df = pd.concat([df_major, df_minor_upsample]).reset_index()\n        train_dataset.df = df\n        \n        for index, (inputs, _, targets) in enumerate(train_dl):\n            if (epoch * len(train_dl) + index) % num_iter == 0: \n                training_loss = 0\n            # Move X, Y  to device (GPU)\n            inputs = inputs.permute(0,3,1,2).to(device)\n            targets = targets.unsqueeze(1).to(device)\n            \n            # Clear previous gradient\n            optimizer.zero_grad()\n\n            # Feed forward the model\n            preds = model(inputs)\n            \n            # Caculate loss\n            loss = loss_func(preds, targets)\n            training_loss += loss\n\n            # Back propagation\n            loss.backward()\n\n            # Update parameters\n            optimizer.step()\n            \n            del inputs, targets, preds\n            if torch.cuda.is_available(): torch.cuda.empty_cache()\n            \n            # Update learning rate\n            if (epoch * len(train_dl) + index) % num_iter == num_iter - 1:\n                # Update list of learning rates\n                lrs.append(optimizer.param_groups[0]['lr']) \n                \n                # Update list of training losses\n                losses.append(training_loss/num_iter) \n                print(optimizer.param_groups[0]['lr'], training_loss/num_iter)\n                \n                # Increase learning rate linearly between base_lr and end_lr after num_iter iterations\n                #lr = base_lr * (end_lr/base_lr)**((epoch * len(train_dl) + index) / total_iter) # Exponential\n                lr = base_lr + (end_lr - base_lr)*((epoch * len(train_dl) + index) / total_iter) \n                \n                # Update current learning rate of optimizer\n                optimizer.param_groups[0]['lr'] = lr \n                \n    return lrs, losses"},{"metadata":{},"cell_type":"markdown","source":"# Perform learning rate range test (Linear)\nnum_epoch = 2\nnum_iter = 100\nbase_lr = 1e-6\nend_lr = 0.1\nlrs, losses = lr_range_test(train_dl, device, loss_func, base_lr, end_lr, num_iter, num_epoch)\n# print (lrs,'\\n')\n# print (losses)"},{"metadata":{},"cell_type":"markdown","source":"# Create model and check model architecture\n# model = load_model_from_checkpoint('../input/siim-segment-checkpoint/checkpoint_57eps.pth', True)\nmodel = UNet(backbone_name='densenet121', pretrained=True, encoder_freeze=False, upsample_out_chs=(128, 64, 32, 16, 8)).to(device) \n# print(model)\n# upsample_out_chs=(1024, 512, 256, 64, 32)\n\n# Check number of trainable parameters\nsum(p.numel() for p in model.parameters() if p.requires_grad)"},{"metadata":{},"cell_type":"markdown","source":"# Optimizer\noptimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9, nesterov=True, weight_decay=1e-6)\n\n# Learning rate scheduler\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=LEARNING_RATE_SCHEDULE_FACTOR, \n                                                 patience=LEARNING_RATE_SCHEDULE_PATIENCE, verbose=True)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training one epoch on training dataset\ndef epoch_training(epoch, model, train_dl, device, loss_func, metric, optimizer, sigmoid_threshold=0.5):\n    \"\"\"\n    Epoch training\n\n    Paramteters\n    -----------\n    epoch: int\n      epoch number\n    model: torch Module\n      model to train\n    train_dl: Dataset\n      data loader for training\n    device: str\n      \"cpu\" or \"cuda\"\n    loss_func: loss function\n      loss function used for training\n    optimizer: torch optimizer\n      optimizer used for training\n    metric: metric function\n        metric function used for evaluating\n    sigmoid_threshold: float\n        threshold for sigmoid function\n    \n    Returns\n    -------\n    float\n      training loss\n    float\n      train_iou\n    \"\"\"\n    # Switch model to training mode\n    model.train()\n    \n    training_loss = 0 # Storing sum of training losses\n    train_iou = 0 # Storing sum of training iou\n   \n    # For each batch\n    for (inputs, _, targets) in train_dl:\n        \n        # Move X, Y  to device (GPU)\n        inputs = inputs.permute(0,3,1,2).to(device)\n        targets = targets.unsqueeze(1).to(device)\n        \n        # Clear previous gradient\n        optimizer.zero_grad()\n\n        # Feed forward the model\n        preds = model(inputs)\n        loss = loss_func(preds, targets)\n\n        # Back propagation\n        loss.backward()\n\n        # Update parameters\n        optimizer.step()\n\n        # Update training loss after each batch\n        training_loss += loss.item()\n        \n        # Caculate metric score\n        preds = (preds >= sigmoid_threshold).float().to(device)\n        train_iou += metric(preds, targets).item()\n    \n    # Clear memory\n    del inputs, targets, preds\n    if torch.cuda.is_available(): torch.cuda.empty_cache()\n    \n    # return training loss and metric score\n    return training_loss/len(train_dl), train_iou/len(train_dl) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate model in the validation dataset\ndef evaluating(epoch, model, val_dl, device, loss_func, metric, optimizer, sigmoid_threshold=0.5):\n    \"\"\"\n    Validate model on validation dataset\n    \n    Parameters\n    ----------\n    epoch: int\n        epoch number\n    model: torch Module\n        model used for validation\n    val_dl: Dataset\n        data loader of validation set\n    device: str\n        \"cuda\" or \"cpu\"\n    loss_func: loss function\n      loss function used for training\n    optimizer: torch optimizer\n      optimizer used for training\n    metric: metric function\n        metric function used for evaluating\n    sigmoid_threshold: float\n        threshold for sigmoid function\n  \n    Returns\n    -------\n    float\n        loss on validation set\n    float\n        val_iou\n    \"\"\"\n\n    # Switch model to evaluation mode\n    model.eval()\n\n    val_loss = 0    # Total loss of model on validation set\n    val_iou  = 0    # Total iou of model on validation set\n    \n    with torch.no_grad(): # Turn off gradient\n        # For each batch\n        for (inputs, _, targets) in val_dl:\n        \n            # Move X, Y  to device (GPU)\n            inputs = inputs.permute(0,3,1,2).to(device)\n            targets = targets.unsqueeze(1).to(device)\n\n            # Feed forward the model\n            preds = model(inputs)\n            loss = loss_func(preds, targets)\n            \n            # Update validation loss after each batch\n            val_loss += loss.item()\n            \n            # Caculate metric score\n            preds = (preds >= sigmoid_threshold).float().to(device)\n            val_iou += metric(preds, targets).item()\n    \n    # Clear memory\n    del inputs, targets, preds\n    if torch.cuda.is_available(): torch.cuda.empty_cache()\n        \n    # return validation loss and metric score\n    return val_loss/len(val_dl), val_iou/len(val_dl)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Initialize before training\ntrain_losses = []\nval_losses = []\ntrain_ious = []\nval_ious = []"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define loading function from saving filepath, lock backbone\ndef load_checkpoint(filepath, encoder_freeze=False):\n    checkpoint = torch.load(filepath)\n    model = checkpoint['model']\n    optimizer = checkpoint['optimizer']\n    scheduler = checkpoint['scheduler']\n    train_losses = checkpoint['train_losses']\n    val_losses = checkpoint['val_losses']\n    train_ious = checkpoint['train_ious']\n    val_ious = checkpoint['val_ious']\n    \n    for parameter in model.parameters():\n        parameter.requires_grad = True\n        \n    if encoder_freeze:\n        for param in model.backbone.parameters():\n            param.requires_grad = False\n\n    return model, optimizer, scheduler, train_losses, val_losses, train_ious, val_ious","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Load from checkpoint \nmodel, optimizer, scheduler, train_losses, val_losses, train_ious, val_ious = load_checkpoint(\"../input/siim-segment-checkpoint/checkpoint_20eps.pth\")\nmodel.to(device)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fully training the model\n\n# Training each epoch\nfor epoch in range(7):\n    # Upsample minority class\n    df = train_df\n    df_minor = df[df['has_mask']==1]\n    df_major = df[df['has_mask']==0]\n    df_minor_upsample = resample(df_minor, replace=True, n_samples = len(df_major), random_state=69)\n    df = pd.concat([df_major, df_minor_upsample]).reset_index()\n    train_dataset.df = df    \n    \n    # Training\n    train_loss, train_iou = epoch_training(epoch, model, train_dl, device, loss_func, metric, optimizer)\n    train_losses.append(train_loss)\n    train_ious.append(train_iou)\n\n    # Evaluating\n    val_loss, val_iou = evaluating(epoch, model, val_dl, device, loss_func, metric, optimizer)\n    val_losses.append(val_loss)\n    val_ious.append(val_iou)\n    \n    # Update learning rate\n    scheduler.step(train_loss)\n    \n    # Define checkpoint\n    checkpoint = {'model': model,\n                  'optimizer': optimizer,\n                  'scheduler': scheduler,\n                  'train_losses': train_losses,\n                  'val_losses': val_losses,\n                  'train_ious': train_ious,\n                  'val_ious': val_ious}\n\n    # Save model\n    torch.save(checkpoint, '/kaggle/working/checkpoint_'+str(epoch+29)+'eps.pth')\n    \n    print(\"Epoch:\", epoch+29, '\\n', \n          \"Train loss:\", train_loss, \"T-IoU:\", train_iou, '\\n',\n          \"Val loss:\", val_loss, \"V-IoU:\" , val_iou, '\\n')"},{"metadata":{},"cell_type":"markdown","source":"# Plot Validation IoU vs Training IoU in saved checkpoint\nplt.figure(figsize=(10,5))\nx = [i for i in range(1,51)]\nprint(train_ious)\nprint(val_ious)\nplt.plot(x, train_ious, 'b', label='Training IoU')\nplt.plot(x, val_ious, 'r', label='Validation IoU')\n# ticks = [x for x in range(1,31)]\n# plt.xticks(ticks, ticks)\nplt.title('IoU and epoch')\nplt.xlabel('Epoch')\nplt.ylabel('IoU')\nplt.legend()\nplt.show()"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Inspect information from saved epoch\nprint('Min train losses:', min(train_losses), 'at epoch: ', train_losses.index(min(train_losses))+1)\nprint('Min val losses:', min(val_losses), 'at epoch: ', val_losses.index(min(val_losses))+1)\nprint('Max train iou:', max(train_ious), 'at epoch: ', train_ious.index(max(train_ious))+1)\nprint('Max val iou:', max(val_ious), 'at epoch: ', val_ious.index(max(val_ious))+1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Post processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Post processing with connected components\ndef pp_with_connected_components(pred):\n    pred = (pred.squeeze(1).squeeze(0)>=0.5).float()\n    pred = pred.data.cpu().numpy().astype(np.uint8)\n        \n    _, thresh = cv2.threshold(pred,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n    num_labels, labels , stats, centroids = cv2.connectedComponentsWithStats(thresh , connectivity , cv2.CV_32S)\n        \n    for idx, stat in enumerate(stats):\n        x, y, w, h, c = stat\n            \n        if w == pred.shape[1] or h == pred.shape[0]:\n            continue\n            \n        THRESHOLD = 900\n            \n        if c < THRESHOLD:\n            pred[labels == idx] = 0\n            \n    pred = torch.FloatTensor(pred).unsqueeze(0).unsqueeze(1)\n    \n    return pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Post processing with connected components and evaluation in validation set \nconnectivity = 8  # You need to choose 4 or 8 for connectivity type\nsigmoid_threshold = [0.1, 0.3, 0.5, 0.7]\nval_dice  = [0, 0, 0 ,0]    # Total dice of model on validation set\nval_iou = [0, 0, 0, 0]      # Total iou of model on validation set\npost_processing = True\nmodel.eval()\n\nwith torch.no_grad():\n    for index in range(len(val_dataset)):\n        image, _, target = val_dataset[index]\n        image = image.unsqueeze(0).permute(0,3,1,2).to(device)\n        target = target.unsqueeze(0).unsqueeze(1).to(device)\n        pred = model(image)\n        \n        if post_processing:\n            pred = pp_with_connected_components(pred)\n        \n        # Caculate metric score\n        for i in range(len(sigmoid_threshold)):\n            pred_thres = (pred >= sigmoid_threshold[i]).float().to(device)\n            val_dice[i] += Dice(pred_thres, target).item()\n            val_iou[i] += IoU(pred_thres, target).item()\n    \nfor i in range(len(sigmoid_threshold)):\n    print('Threshold: ', sigmoid_threshold[i], 'IoU: ', val_iou[i]/len(val_dataset), 'Dice: ', val_dice[i]/len(val_dataset))"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test time augmentation and dis-augmentation\ndef test_time_aug(input_img):\n    aug_list = []\n    \n    trans_list = [A.HorizontalFlip(p=1)]\n    \n    for transform in trans_list:\n        augmented_data = transform(image=input_img.numpy())\n        img_data = augmented_data['image']\n        aug_list.append(torch.FloatTensor(img_data))\n\n    return aug_list\n\ndef test_time_dis_aug(aug_pred_list):\n    dis_aug_pred_list = []\n    \n    dis_trans_list = [A.HorizontalFlip(p=1)]\n    \n    for i in range(len(aug_pred_list)):\n        augmented_data = dis_trans_list[i](image=aug_pred_list[i].squeeze(1).squeeze(0).cpu().numpy())\n        img_data = augmented_data['image']\n        dis_aug_pred_list.append(img_data)\n        \n    return dis_aug_pred_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate validation set with test time augmentation\nmodel.eval()\n\nsigmoid_threshold = [0.1, 0.3, 0.5, 0.7]\nval_dice  = [0, 0, 0 ,0]    # Total dice of model on validation set\nval_iou = [0, 0, 0, 0]      # Total iou of model on validation set\n    \nwith torch.no_grad(): # Turn off gradient\n    # For each batch\n    for index in range(len(val_dataset)):\n        image, _, target = val_dataset[index]\n        target = target.unsqueeze(0).unsqueeze(1).to(device)\n        \n        # Test time augmentation\n        aug_list = test_time_aug(image)\n\n        # Feed forward the model to prediction\n        pred = model(image.unsqueeze(0).permute(0,3,1,2).to(device)).squeeze(1).squeeze(0)\n    \n        aug_pred_list = []\n        for aug_image in aug_list:\n            aug_pred_list.append(model(aug_image.unsqueeze(0).permute(0,3,1,2).to(device)))\n        \n        # Dis_augmentation\n        dis_aug_pred_list = test_time_dis_aug(aug_pred_list)\n        dis_aug_pred_list.append(pred.squeeze(1).squeeze(0))\n    \n        # Merge\n        pred = torch.FloatTensor(dis_aug_pred_list).mean(axis=0).to(device).unsqueeze(0).unsqueeze(1)\n        \n        # Caculate metric score\n        for i in range(len(sigmoid_threshold)):\n            pred_thres = (pred >= sigmoid_threshold[i]).float().to(device)\n            val_dice[i] += Dice(pred_thres, target).item()\n            val_iou[i] += IoU(pred_thres, target).item()\n    \nfor i in range(len(sigmoid_threshold)):\n    print('Threshold: ', sigmoid_threshold[i], 'IoU: ', val_iou[i]/len(val_dataset), 'Dice: ', val_dice[i]/len(val_dataset))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"def show_aug(inputs, nrows=1, ncols=8, image=True):\n    plt.figure(figsize=(3*ncols, 3*nrows))\n    plt.subplots_adjust(wspace=0., hspace=0.)\n    i_ = 0\n    \n    if len(inputs) > 8:\n        inputs = inputs[:8]\n        \n    for idx in range(len(inputs)):\n        img = inputs[idx].numpy().astype(np.float32)\n        \n        plt.subplot(nrows, ncols, i_+1)\n        if image:\n            plt.imshow(img[:,:,0], cmap='bone')\n        else:\n            plt.imshow(img)\n        plt.axis('off')\n        \n        i_ += 1\n \n    return plt.show()"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"def show_aug(inputs, nrows=1, ncols=8, image=True):\n    plt.figure(figsize=(3*ncols, 3*nrows))\n    plt.subplots_adjust(wspace=0., hspace=0.)\n    i_ = 0\n    \n    if len(inputs) > 8:\n        inputs = inputs[:8]\n        \n    for idx in range(len(inputs)):\n        img = inputs[idx].numpy().astype(np.float32)\n        \n        plt.subplot(nrows, ncols, i_+1)\n        if image:\n            plt.imshow(img[:,:,0], cmap='bone')\n        else:\n            plt.imshow(img)\n        plt.axis('off')\n        \n        i_ += 1\n \n    return plt.show()"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Show some model predictions\nimages, _, masks = next(iter(val_dl))\n\nmodel.eval()\nwith torch.no_grad():\n    inputs = images.permute(0,3,1,2).to(device)\n    preds = model(inputs)\n    preds = ((preds.squeeze(1))>=0.5).float()\n    preds = preds.cpu()\n    \nshow_aug(images)\nshow_aug(preds, image=False)\nshow_aug(masks, image=False)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}