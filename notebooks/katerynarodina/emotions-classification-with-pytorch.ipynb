{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# import modules\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sbn\n%matplotlib inline\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nimport torch.nn as nn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_default_device():\n    '''Pick gpu if available else pick cpu'''\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    '''Move tensors to choosen device'''\n    if isinstance(data, (list, tuple)):\n        return [to_device(d, device) for d in data]\n    return data.to(device, non_blocking=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# init device\ndevice = get_default_device()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"# read the data\ndata = pd.read_csv('../input/eeg-brainwave-dataset-feeling-emotions/emotions.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### First look at the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### How many data points and features?"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First observations:\n- there are many more features then data points\n- it is not entirely clear where the features come from, but we know that the data was collected from two people for three minutes per 3 states plus 6 minutes rest time.\n- the waves are described mathematically\n- there are a and b postfix, which could be data from 2 responders."},{"metadata":{},"cell_type":"markdown","source":"#### Is data complete? Are the duplicates in the data?"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.loc[data.isnull().any(axis=1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.duplicated().any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are no duplicates and empty values in the dataset."},{"metadata":{},"cell_type":"markdown","source":"#### Is data balanced? "},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = data['label'].value_counts()\nlabels","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Does it look like time series?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# take a sample\nsample = data.loc[5, 'fft_0_a':'fft_479_a']\n\nplt.figure(figsize=(20, 7))\nplt.plot(range(len(sample)), sample)\nplt.title('Features range fft_0_a - fft_479_a for one data point')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are not completely sure, but it looks like time is incorporated in this plot hence into the data as well. "},{"metadata":{},"cell_type":"markdown","source":"#### What are the principal components?"},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(10).fit(data.drop('label', axis=1))\nexplained_variance = pca.explained_variance_ratio_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot\nplt.plot(np.cumsum(explained_variance))\nplt.xlabel('number of components')\nplt.ylabel('cumulative explained variance')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The plot clearly indicates that first two components contain the maximum information within the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"first_c = pca.components_[0]\nsecond_c = pca.components_[1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# do not change original dataset\ndata_copy = data.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# label encoding\ndata['label'] = data['label'].astype('category').cat.codes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split data into training and test dataset\nX_train, X_test, y_train, y_test = train_test_split(data.drop('label', axis=1), data['label'], random_state=42, test_size=0.2, stratify=data['label'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert test to numpy\ny_test = y_test.to_numpy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Build a model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert to numpy arrays\ninputs_array = X_train.to_numpy()\ntargets_array = y_train.to_numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert to tensors\ninputs = to_device(torch.FloatTensor(inputs_array),device)\ntargets = to_device(torch.FloatTensor(targets_array), device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dataset = torch.utils.data.TensorDataset(inputs, targets)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define batch size\nbatch_size = 64","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# build a model\nclass Model(nn.Module):\n    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n        super(Model, self).__init__()\n\n        self.hidden_dim = hidden_dim\n        self.n_layers = n_layers\n\n        self.gru = nn.GRU(input_size, hidden_dim, n_layers, batch_first=True, dropout=0.2)\n        self.fc = nn.Linear(hidden_dim, output_size).float()\n        self.relu = nn.ReLU()\n        \n    def forward(self, x):\n        out, h = self.gru(x)\n        out = self.fc(self.relu(out))\n        return out, h\n    \n    def init_hidden(self, batch_size):\n        weight = next(self.parameters()).data\n        hidden = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_()\n        return hidden","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_size = len(X_train.columns)\noutput_size = len(y_train.unique())\nhidden_dim = 128\nn_layers = 2\n# init hyperparameters\nn_epochs = 430\n# init model\nmodel = Model(input_size, output_size, hidden_dim, n_layers)\nto_device(model, device)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"#define loss and otimizer\nlosses = []\nl_rates = [1e-1, 1e-2, 1e-3, 1e-4]\nl_r_i = 2\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), l_rates[l_r_i])\n# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.01)\nfor epoch in range(1, n_epochs + 1):\n    optimizer.zero_grad() \n    output, hidden = model(inputs.unsqueeze(0))\n    loss = criterion(output.squeeze(0).float(), targets.long())\n    loss_detached = loss.detach().cpu().clone().numpy()\n    losses.append(loss_detached)\n\n    loss.backward() \n    optimizer.step()\n#     scheduler.step(loss)\n\n    if epoch%10 == 0:\n        print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n        print(\"Loss: {:.4f}\".format(loss.item()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = to_device(torch.FloatTensor(X_test.to_numpy()).unsqueeze(0), device)\noutput = model(test_data)[0]\noutput = output.squeeze(0)\noutput_ = output.detach().cpu().clone()\npredictions = np.array(torch.argmax(output_, 1, keepdim=True))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"c_m = confusion_matrix(predictions, y_test)\n\nplt.figure(figsize=(10, 10))\nsbn.heatmap(c_m, annot=True, cmap='YlGnBu', fmt='g', yticklabels=list(labels.index), xticklabels=list(labels.index))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# build a classification report\nprint(classification_report(y_test, predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}