{"cells":[{"metadata":{"_uuid":"67aca23f40bfc7775a2665ff65cc477299e83b17"},"cell_type":"markdown","source":"# Summary\nWe have done a Exploratory Data Analysis and we have tried two different kind of explanatory machine learning models (Linear regression and Trees) to understand what are the variables with more influence in the outcome. This models are very helpful because, although they are not the more accurate ones, they aren't black boxes and the knwoledge that provide permits to act over the relevant variables to have influence over the outcome. We have tried also a Random Forest which also provides info about feature importance."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"import warnings\nimport os\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nwarnings.filterwarnings('ignore')","execution_count":32,"outputs":[]},{"metadata":{"_uuid":"c74f38bc58ccd3da1c5923a9eb33b56cd159f007"},"cell_type":"markdown","source":"#Â Exploratory Data Analysis "},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/insurance.csv')","execution_count":33,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"882af2c358d3e850d54c22a28f238add5f8f47aa"},"cell_type":"code","source":"data.head()","execution_count":34,"outputs":[]},{"metadata":{"_uuid":"2f9f388818f136733f824fcbafe8d97c5f66861b"},"cell_type":"markdown","source":"Let's check if there are any missing value:"},{"metadata":{"trusted":true,"_uuid":"363d8c600cb33ef8e2533cecb689d88e40eb8e25"},"cell_type":"code","source":"data.isnull().any()","execution_count":35,"outputs":[]},{"metadata":{"_uuid":"a57f6e875e6d7e4c720cfc76bc3661fb79fcfc02"},"cell_type":"markdown","source":"Some summary statistics to see if there are outliers:"},{"metadata":{"trusted":true,"_uuid":"0df1a9c08db33bead54c5fc7bfa1089b2969ec34"},"cell_type":"code","source":"data.describe()","execution_count":36,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c9925a582e6fe8c101a64db658af9b083ebf98e"},"cell_type":"code","source":"data.info()","execution_count":37,"outputs":[]},{"metadata":{"_uuid":"07a93169140d96eaeb9c729d644cd23981689fdd"},"cell_type":"markdown","source":"This are categorical variables:"},{"metadata":{"trusted":true,"_uuid":"6141dbbaca120a42293e7f7dcc558c47590b1b6f","collapsed":true},"cell_type":"code","source":"data['sex'] = pd.Categorical(data['sex'])\ndata['smoker'] = pd.Categorical(data['smoker'])\ndata['region'] = pd.Categorical(data['region'])","execution_count":38,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5388f7c177e0a8a4ea46fdb9cd3466bd7e62d9b0"},"cell_type":"code","source":"data.info()","execution_count":39,"outputs":[]},{"metadata":{"_uuid":"339735ee852497cc3b18acb0ba9e73395c10efce"},"cell_type":"markdown","source":"Let's create some graphs to understand the data:"},{"metadata":{"trusted":true,"_uuid":"01aba355abfee18a45735542bda183d9824a8c0e"},"cell_type":"code","source":"plt.figure(figsize=(18, 6))\nplt.subplot(131)\nsns.distplot(data['age']).set_title(\"Age\")\nplt.subplot(132)\nsns.distplot(data['bmi']).set_title(\"Bmi\")\nplt.subplot(133)\nsns.distplot(data['charges']).set_title(\"Charges\")\nplt.show()","execution_count":40,"outputs":[]},{"metadata":{"_uuid":"bff74c816d8bac7570d98d767f9a6d7abbf0a4c1"},"cell_type":"markdown","source":"Bmi follows a normal distribution and charges is right skewed. "},{"metadata":{"trusted":true,"_uuid":"940e6ff55427fbaa53dd27522694304ad0ef1540","collapsed":true},"cell_type":"code","source":"corr = data.corr()","execution_count":41,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4017abf5f5ae903c69830c9d8075535febfdd982"},"cell_type":"code","source":"sns.heatmap(corr, annot=True, linewidths=.5, fmt= '.3f', cmap=\"YlGnBu\")\nplt.show()","execution_count":42,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4051efae47370654e8c0fb6b7cce8b66218d8451","collapsed":true},"cell_type":"markdown","source":"The following graphs will help us to see the relation between variables:"},{"metadata":{"trusted":true,"_uuid":"ce64b7bfd0c75dcb3ec705b370bb8b5ed95fe954"},"cell_type":"code","source":"sns.pairplot(data, kind=\"reg\")\nplt.show()","execution_count":43,"outputs":[]},{"metadata":{"_uuid":"a1c7aa6ae1d2e9751ee5dc5441b1541b98ef1a70"},"cell_type":"markdown","source":"It looks like that: age, bmi and children have a positive correlation with charges. \n\nLet's see the influence of the categorical variables (sex, region and smoker):"},{"metadata":{"trusted":true,"_uuid":"8a22e6e6cc662871773f00e4e6c3abf8fdf236ea"},"cell_type":"code","source":"plt.figure(figsize=(18, 6))\nplt.subplot(131)\nsns.boxplot(x='sex', y='charges', data=data)\nplt.subplot(132)\nsns.boxplot(x='region', y='charges', data=data)\nplt.subplot(133)\nsns.boxplot(x='smoker', y='charges', data=data)\nplt.show()","execution_count":44,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a68c27ff939be0644b1387b5894a3c31f67ccf38"},"cell_type":"code","source":"data.groupby('sex')['charges'].mean()","execution_count":45,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fd2c87aace91ae1e7c4125859a51656d0c8fc780"},"cell_type":"code","source":"data.groupby('smoker')['charges'].mean()","execution_count":46,"outputs":[]},{"metadata":{"_uuid":"82d12b293d74b6df66838eb137f7fc9731623038"},"cell_type":"markdown","source":"It looks like that men are responsible of more charges than women and it is pretty clear than smokers charges more than non smokers."},{"metadata":{"_uuid":"b930b32a860cb25a64b2479ea10b3e190e887bdd"},"cell_type":"markdown","source":"People who smoke charges quite more. "},{"metadata":{"_uuid":"3bbb34e9ad4656a370e78a8a8fb4a6adb570a046"},"cell_type":"markdown","source":"# Models\nWe are going to try two different explanatory data models to understand the influence of each variable in the outcome (charges)"},{"metadata":{"trusted":true,"_uuid":"203ed094e9221e252f99c5eb87c316cfed8dce9b","collapsed":true},"cell_type":"markdown","source":"## Linear regression"},{"metadata":{"trusted":true,"_uuid":"a20af9caccf64fb30e80efe264b4df3d4ce49279","collapsed":true},"cell_type":"code","source":"import statsmodels.api as sm\nfrom sklearn.preprocessing import MinMaxScaler","execution_count":47,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9991307b8cad7477ffc421232086744f567c204f","collapsed":true},"cell_type":"code","source":"y = data['charges']\nX = data.drop('charges', axis=1)\nX = pd.get_dummies(X, drop_first=True, prefix = ['sex', 'smoker', 'region'])\n\nscaler = MinMaxScaler()\nX[['age', 'bmi', 'children']] = scaler.fit_transform(X[['age', 'bmi', 'children']])","execution_count":48,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d959f389076c2cfacc06deb60ccc52f50fbb3745"},"cell_type":"code","source":"np.random.seed(1)\nX_2 = sm.add_constant(X)\nmodel_lr = sm.OLS(y, X_2)\nlinear = model_lr.fit()\nprint(linear.summary())","execution_count":49,"outputs":[]},{"metadata":{"_uuid":"8d793493f328ef45ba65789c09ab012cf36b1496"},"cell_type":"markdown","source":"We see that the only variables who are statistically significant (p-value < 0.05) are: smoker, bmi, age, children.\n\nThe influence of the variables takes that order: smoker is what affect the most to the outcome and it is followed by bmi, age and children."},{"metadata":{"_uuid":"44645ceb75b7085a630157a6c2d358db69dc9982"},"cell_type":"markdown","source":"## Trees\nWe are going to try now a different kind of model: a classification Tree. This is not the most accurate model but it helps to explain the influence of the variables in the outcome."},{"metadata":{"trusted":true,"_uuid":"87b998aa8a053e6c0d0f48fecd228ab0dcae4998","collapsed":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor","execution_count":50,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6796e612a90363b6b33407c317c5148f00bad29d","collapsed":true},"cell_type":"code","source":"model = DecisionTreeRegressor(random_state = 100)","execution_count":51,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"89a6f0352eff25d967719eb5568df88ad6e8fec8","collapsed":true},"cell_type":"code","source":"y = data['charges']\nX = data.drop('charges', axis=1)","execution_count":52,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"145e48eeba24ff9dded01b7e861c84a9fe141733","collapsed":true},"cell_type":"code","source":"X['sex'] = X['sex'].cat.codes\nX['smoker'] = X['smoker'].cat.codes\nX['region'] = X['region'].cat.codes","execution_count":53,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"87b4a7d0326208fa2ceb8f881aff93ba8c0b52f0"},"cell_type":"code","source":"model.fit(X, y)","execution_count":54,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d5e28e38105c344d2385800777b292ddc969d8c4"},"cell_type":"code","source":"sns.barplot(x=X.columns, \n            y=model.feature_importances_, \n            order=X.columns[np.argsort(model.feature_importances_)[::-1]])\nplt.show()","execution_count":55,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"010e8c9397531e1e8f5de827702cd4f4fca161fa","collapsed":true},"cell_type":"markdown","source":"This model produces similar results to the linear regression model. The variables with more influence are: smoker, bmi, age"},{"metadata":{"_uuid":"260fb4cc608cb25af92349ebb1150e11d4a98398"},"cell_type":"markdown","source":"## Random Forest\nLet's try a more accurate model"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"4b4a095297e2e8067db75b1ed6fca3a81073d469"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics.regression import mean_squared_error","execution_count":100,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"95096c93248545e8623cb996685d9a83cdbe76ad"},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)","execution_count":109,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0cb0fa237e6c0f0c6f2895b16fc9f6bb6648c507"},"cell_type":"code","source":"model_rf = RandomForestRegressor(n_estimators=200, random_state=1)\nscores = cross_val_score(model_rf, X_train, y_train, cv=5, scoring=\"neg_mean_squared_error\")\nscores = np.sqrt(-scores)\nprint(\"validation RMSE: {:0.4f} (+/- {:0.4f})\".format(np.mean(scores), np.std(scores)))","execution_count":110,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a4c95db3a06cb4d5ab75e53914606a297e64fcaa"},"cell_type":"code","source":"model_rf.fit(X_train, y_train)\ny_pred = model_rf.predict(X_test)\nrmse = np.sqrt(mean_squared_error(y_test, y_pred))\nrmse","execution_count":112,"outputs":[]},{"metadata":{"_uuid":"3d09cc8e006dafc09dbdf0c052efac9a63ebbf1f"},"cell_type":"markdown","source":"Let's see how predictions and reality are related:"},{"metadata":{"trusted":true,"_uuid":"36c806b11c9f3041447446061f7f15c865ab2b93"},"cell_type":"code","source":"y_train_pred = model_rf.predict(X_train)\nsns.regplot(x=y_train, y=y_train_pred)\nplt.title(\"Predicted vs Real\")\nplt.show()","execution_count":115,"outputs":[]},{"metadata":{"_uuid":"a4bf7cebcbe66626ed6fa2cdf5c0031c104df98c"},"cell_type":"markdown","source":"Rnadom Forest is a more precise than the previous models and also helps us to understand the importance of each feature. The results we obtain are aligned with our previous results: "},{"metadata":{"trusted":true,"_uuid":"3106f56f4729bc48807ca20b2dc0768d2fd1d3da"},"cell_type":"code","source":"importances = model_rf.feature_importances_\nindices = np.argsort(importances)[::-1]\n\n# Plot the feature importances of the forest\nplt.figure()\nplt.title(\"Feature importances\")\nplt.bar(range(X.shape[1]), importances[indices], align=\"center\")\nplt.xticks(range(X.shape[1]), X.columns[indices])\nplt.xlim([-1, X.shape[1]])\nplt.show()","execution_count":114,"outputs":[]},{"metadata":{"_uuid":"4a10275b4fd4b75956be21ee63fb3e20c865c537"},"cell_type":"markdown","source":"# Conclusion"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"fd2e800e305e6706bff3141339a11051924911bc"},"cell_type":"markdown","source":"We have identified with graphs and with two different machine learning models (Linear regression and Trees) that the more relevant variables related to a person which affect their medical costs are, for this order: smoker, bmi, age. This results are aligned with what we obtain when using Random Forest.\n\nAs expected, the data confirm that a health insurance company should charge more to people who smoke, are fat an old. "}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}