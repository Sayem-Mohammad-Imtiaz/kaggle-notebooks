{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport functools\nimport os\n\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Original paper of how to deal with structured data and csv data with tensorflow:\nhttps://www.tensorflow.org/tutorials/load_data/csv  \nThis is just my experiment with drug200 dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('ggplot')\ntf.get_logger().setLevel('ERROR')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data overview "},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/drug-classification/drug200.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, we have:\n* Few observations (200)\n* No missing values\n* Two numerical features\n* Three categorical features\n* Categorical target column"},{"metadata":{},"cell_type":"markdown","source":"### Creating tf dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"TARGET_COLUMN = \"Drug\"\nBATCH_SIZE = 4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_labels = data.Drug.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On the one hand, we can't just pass strings as features to the model. On the other hand, we don't want to make another csv dataset with encoded target column. So we create mapping function. In tensorflow we use StringLookup for this purposes."},{"metadata":{"trusted":true},"cell_type":"code","source":"drugs_ind = tf.keras.layers.experimental.preprocessing.StringLookup(\n                        vocabulary=list(target_labels), num_oov_indices=0, mask_token=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds = tf.data.experimental.make_csv_dataset(\n      \"../input/drug-classification/drug200.csv\",\n      batch_size=BATCH_SIZE,\n      label_name=TARGET_COLUMN,\n      na_value=\"?\",\n      num_epochs=1,\n      ignore_errors=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_batch(dataset):\n    for batch, label in dataset.take(1):\n        for key, value in batch.items():\n            print(\"{:20s}: {}\".format(key,value.numpy()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_batch(ds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ok, let's define numerical and categorical features"},{"metadata":{"trusted":true},"cell_type":"code","source":"NUMERIC_FEATURES = ['Age','Na_to_K']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CATEGORIES = {k: data[k].unique().tolist() for k in data if k not in NUMERIC_FEATURES}\nCATEGORIES","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_labels = CATEGORIES.pop(\"Drug\")\ntarget_labels","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we have to preprocess features"},{"metadata":{"trusted":true},"cell_type":"code","source":"class PreprocessFeatures(object):\n    def __init__(self, names, labels_map):\n        self.names = names\n        self.labels_map = labels_map\n\n    def __call__(self, features, labels):\n        numeric_freatures = [features.pop(name) for name in self.names]\n        numeric_features = [tf.cast(feat, tf.float32) for feat in numeric_freatures]\n        numeric_features = tf.stack(numeric_features, axis=-1)\n        features['numeric'] = numeric_features\n        labels = self.labels_map(labels)\n        return features, labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds = ds.map(PreprocessFeatures(NUMERIC_FEATURES,drugs_ind))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Handle numerical features"},{"metadata":{"trusted":true},"cell_type":"code","source":"desc = data[NUMERIC_FEATURES].describe()\ndesc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MEAN = np.array(desc.T['mean'])\nSTD = np.array(desc.T['std'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def normalize_numeric_data(data, mean, std):\n    return (data-mean)/std","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"normalizer = functools.partial(normalize_numeric_data, mean=MEAN, std=STD)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numeric_column = tf.feature_column.numeric_column('numeric', normalizer_fn=normalizer, shape=[len(NUMERIC_FEATURES)])\nnumeric_columns = [numeric_column]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Handle categorical features"},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_columns = []\nfor feature, vocab in CATEGORIES.items():\n    cat_col = tf.feature_column.categorical_column_with_vocabulary_list(\n        key=feature, vocabulary_list=vocab)\n    categorical_columns.append(tf.feature_column.indicator_column(cat_col))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Creating preprocessing layers"},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocessing_layer = tf.keras.layers.DenseFeatures(categorical_columns + numeric_columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Define model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.Sequential([\n  preprocessing_layer,\n  tf.keras.layers.Dense(128, activation='relu'),\n  tf.keras.layers.Dense(128, activation='relu'),\n  tf.keras.layers.Dense(len(target_labels), activation='sigmoid'),\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(\n    loss=tf.losses.SparseCategoricalCrossentropy(),\n    optimizer=tf.keras.optimizers.Adam(),\n    metrics=tf.keras.metrics.SparseCategoricalAccuracy())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train test split"},{"metadata":{"trusted":true},"cell_type":"code","source":"N = data.shape[0]\ntrain_size = 0.8\nn_train = int(N*train_size)\ntake_train = n_train // BATCH_SIZE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ds = ds.take(take_train)\ntest_ds = ds.skip(take_train) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fit the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(train_ds, \n                    validation_data=test_ds,\n                    epochs=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rows, cols = 1, 2\nfig, axs = plt.subplots(rows, cols, figsize=(10,5))\n\naxs[0].plot(history.history['loss'])\naxs[0].plot(history.history['val_loss'])\naxs[0].set_title('Loss')\naxs[0].legend(['train_loss','val_loss'])\n\naxs[1].plot(history.history['sparse_categorical_accuracy'])\naxs[1].plot(history.history['val_sparse_categorical_accuracy'])\naxs[1].set_title('Accuracy')\naxs[1].legend(['Train accuracy','Test accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Pred: \\t   True:\")\nfor X, y in test_ds:\n    pred = model(X)\n    print(f\"{tf.argmax(pred,axis=1)}  {y}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}