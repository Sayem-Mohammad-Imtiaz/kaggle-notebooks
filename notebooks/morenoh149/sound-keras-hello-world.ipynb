{"cells":[{"metadata":{"_uuid":"302e5dbcf6814010c831aa16be779af10536ee8f"},"cell_type":"markdown","source":"# Sound Keras Hello World\nThis kernel attempts to provide a minimal Convolutional Neural Network trained on sound files.\nWe use the Keras api for our model definition.\nWe use the [British Birdsong dataset](https://www.kaggle.com/rtatman/british-birdsong-dataset) because it has more than 2 categories and is easily available in Kaggle Kernels.\n\nIt will generate a spectrogram from the sound, and will use typical 2d image processing techniques on this representation. This is a common path.\n\nFuture versions may stick to only the 1D signal and convolutions thereof (this is in some sense a purer approach but I'm less experienced with it)."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nfrom keras.optimizers import SGD\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"597cdedd86ce450d7b118d15f4d4ee2c4be8ed95","collapsed":true},"cell_type":"code","source":"# install in kaggle kernel\n# if your sound files are .wav, scipy.io.wavfile is more reliable\n# this module sometimes prevents us from using kaggle GPU's\nimport soundfile as sf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c773d8f867dd559b29b1158a6e1eed1c5e49d247","collapsed":true},"cell_type":"code","source":"train_dir = '../input/songs/songs'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9db4729710df68c46e852eb70c971fccb6dbf76b"},"cell_type":"code","source":"df = pd.read_csv('../input/birdsong_metadata.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cd81982baadd7edd48720d22a5079776bc680c70"},"cell_type":"code","source":"# find NaNs in metadata\ndf[df.isnull().any(axis=1)]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"813002acd192b745e7ffd369f36c1178ddef8fe4"},"cell_type":"markdown","source":"Looks like some samples are missing lat lon values. For our task this is not an issue so we will not be handling the missing data."},{"metadata":{"trusted":true,"_uuid":"4b06cc01315c1e9616a083322a8c97f89ec11047"},"cell_type":"code","source":"# num of samples\nlen(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"50705e95586f8382b62415d9bcc387c1efa6fd93"},"cell_type":"code","source":"df[['genus', 'species']].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8ab340480a2e77ab71938a7835fc5776ed89acf3"},"cell_type":"code","source":"# load sounds from disk\n# takes 1 minute\npaths = [os.path.join(train_dir, x) for x in os.listdir(train_dir)]\ndataset = []\nfor p in tqdm(paths):\n    audio, _ = sf.read(p)\n    dataset.append(audio)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"88207d13daf841918dfd02c4a5f57e75f73b04e7"},"cell_type":"code","source":"dataset[1].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"42e53b5172405789f44801e88958584be50e5172"},"cell_type":"code","source":"# TODO zeropad samples to max length, without converting away from numpy array\ndataset = keras.preprocessing.sequence.pad_sequences(dataset)\ndataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"135d65fad73dbc293c0ecef6bda89f9201a7d509","collapsed":true},"cell_type":"code","source":"# convert list of numpy arrays into single numpy array for consumption\nx_train = np.array(dataset)\nx_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"52704fcef92b3b427d7c976f263ed0bfa079badc","collapsed":true},"cell_type":"code","source":"# naive label object to get keras model to compile.\n# TODO convert np.array of sample labels into one-hot-vector-label\ny_train = keras.utils.to_categorical([0, 1, 2], num_classes=3)\ny_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb07739c04c51283abb0a629af35d440d377f086","collapsed":true},"cell_type":"code","source":"# Define model\nmodel = Sequential()\nmodel.add(Dense(32, activation='relu', input_shape=x_train[0].shape))\nmodel.add(Dense(3, activation='softmax'))\nmodel.compile(optimizer='rmsprop',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7699cac8d5efe350fa5e23467cb04ff6ac7521e4","collapsed":true},"cell_type":"code","source":"# Train model\nmodel.fit(x_train, y_train, epochs=10, batch_size=32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6a55eaebf5e26424d5e2fdee800fbbecb48c1f7c"},"cell_type":"code","source":"# TODO use model to predict category on test set","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}