{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Well this is the first time I am trying my hands on Audio Classification.In this task we will going to classify ten different audios.I will going to make both machine learning and deep learning model.The different category that we have are:\n- disco \n- metal \n- reggae \n- blues\n- rock\n- classical\n- jazz\n- hiphop \n- country\n- pop","metadata":{}},{"cell_type":"markdown","source":"#### About the data\n- **genres original** - A collection of 10 genres with 100 audio files each, all having a length of 30 seconds (the famous GTZAN dataset, the MNIST of sounds)\n- **images original** - A visual representation for each audio file. One way to classify data is through neural networks. Because NNs (like CNN, what we will be using today) usually take in some sort of image representation, the audio files were converted to Mel Spectrograms to make this possible (we'll be talking about this more in depth later)\n- **2 CSV files** - Containing features of the audio files. One file has for each song (30 seconds long) a mean and variance computed over multiple features that can be extracted from an audio file (more in depth later). The other file has the same structure, but the songs were split before into 3 seconds audio files (this way increasing 10 times the amount of data we fuel into our classification models). With data, more is always better.","metadata":{}},{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"markdown","source":"First of all let's import all the libraries","metadata":{}},{"cell_type":"code","source":"!pip install librosa","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport librosa\nimport librosa.display\nimport IPython.display as ipd\nfrom scipy.io import wavfile as wav\nimport pandas as pd\nimport os\nimport numpy as np\nimport seaborn as sns\n\n\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import SGDClassifier, LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom xgboost import XGBClassifier, XGBRFClassifier\nimport catboost as cb\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping,ModelCheckpoint,LearningRateScheduler\nimport tensorflow.keras as keras\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import *","metadata":{"execution":{"iopub.status.busy":"2021-06-03T04:12:16.027454Z","iopub.execute_input":"2021-06-03T04:12:16.027768Z","iopub.status.idle":"2021-06-03T04:12:19.121364Z","shell.execute_reply.started":"2021-06-03T04:12:16.027738Z","shell.execute_reply":"2021-06-03T04:12:19.120521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's see all the classes that we have","metadata":{}},{"cell_type":"code","source":"path = '../input/gtzan-dataset-music-genre-classification/Data'\nprint(list(os.listdir(f'{path}/genres_original/')))","metadata":{"execution":{"iopub.status.busy":"2021-06-03T04:25:35.71679Z","iopub.execute_input":"2021-06-03T04:25:35.717133Z","iopub.status.idle":"2021-06-03T04:25:35.725706Z","shell.execute_reply.started":"2021-06-03T04:25:35.717104Z","shell.execute_reply":"2021-06-03T04:25:35.724699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Explore Audio Data","metadata":{}},{"cell_type":"markdown","source":"Now we are going to make a function which will plot waveplot","metadata":{}},{"cell_type":"code","source":"def plot_sound(path):\n    plt.figure(figsize=(14, 5))\n    x, sr = librosa.load(path)\n    print(\"length {}, sample-rate {}\".format(x.shape, sr))\n    librosa.display.waveplot(x, sr=sr)\n    \n    return x","metadata":{"execution":{"iopub.status.busy":"2021-06-03T03:58:31.034965Z","iopub.execute_input":"2021-06-03T03:58:31.035322Z","iopub.status.idle":"2021-06-03T03:58:31.040529Z","shell.execute_reply.started":"2021-06-03T03:58:31.035295Z","shell.execute_reply":"2021-06-03T03:58:31.039445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Take one audio from  blues, rock and pop songs ","metadata":{}},{"cell_type":"code","source":"blues_path = '../input/gtzan-dataset-music-genre-classification/Data/genres_original/blues/blues.00000.wav'\nblues_audio = plot_sound(blues_path)\nipd.Audio(blues_path)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T03:59:17.390316Z","iopub.execute_input":"2021-06-03T03:59:17.390637Z","iopub.status.idle":"2021-06-03T03:59:17.745722Z","shell.execute_reply.started":"2021-06-03T03:59:17.390606Z","shell.execute_reply":"2021-06-03T03:59:17.744848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rock_path = '../input/gtzan-dataset-music-genre-classification/Data/genres_original/rock/rock.00001.wav'\nrock_audio = plot_sound(rock_path)\nipd.Audio(rock_path)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T03:59:17.924141Z","iopub.execute_input":"2021-06-03T03:59:17.924463Z","iopub.status.idle":"2021-06-03T03:59:18.319155Z","shell.execute_reply.started":"2021-06-03T03:59:17.924432Z","shell.execute_reply":"2021-06-03T03:59:18.318308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pop_path = '../input/gtzan-dataset-music-genre-classification/Data/genres_original/pop/pop.00001.wav'\npop_audio = plot_sound(pop_path)\nipd.Audio(pop_path)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T03:59:18.464356Z","iopub.execute_input":"2021-06-03T03:59:18.46469Z","iopub.status.idle":"2021-06-03T03:59:18.8715Z","shell.execute_reply.started":"2021-06-03T03:59:18.464661Z","shell.execute_reply":"2021-06-03T03:59:18.870564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wave_sample_rate, wave_audio = wav.read(rock_path)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T04:01:25.830166Z","iopub.execute_input":"2021-06-03T04:01:25.830492Z","iopub.status.idle":"2021-06-03T04:01:25.83878Z","shell.execute_reply.started":"2021-06-03T04:01:25.830465Z","shell.execute_reply":"2021-06-03T04:01:25.838005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wave_sample_rate","metadata":{"execution":{"iopub.status.busy":"2021-06-03T04:01:33.854797Z","iopub.execute_input":"2021-06-03T04:01:33.855142Z","iopub.status.idle":"2021-06-03T04:01:33.860108Z","shell.execute_reply.started":"2021-06-03T04:01:33.85511Z","shell.execute_reply":"2021-06-03T04:01:33.859294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wave_audio","metadata":{"execution":{"iopub.status.busy":"2021-06-03T01:57:27.849527Z","iopub.execute_input":"2021-06-03T01:57:27.850052Z","iopub.status.idle":"2021-06-03T01:57:27.856696Z","shell.execute_reply.started":"2021-06-03T01:57:27.850018Z","shell.execute_reply":"2021-06-03T01:57:27.855689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plot Spectrogram\n\nA spectrogram is a visual way of representing the signal loudness, of a signal over time at various frequencies present in a particular waveform. Not only can one see whether there is more or less energy at, for example, 2 Hz vs 10 Hz, but one can also see how energy levels vary over time.","metadata":{}},{"cell_type":"code","source":"x, sr = librosa.load(pop_path)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T04:01:43.184636Z","iopub.execute_input":"2021-06-03T04:01:43.184962Z","iopub.status.idle":"2021-06-03T04:01:43.193089Z","shell.execute_reply.started":"2021-06-03T04:01:43.184931Z","shell.execute_reply":"2021-06-03T04:01:43.192375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = librosa.stft(x)\nXdb = librosa.amplitude_to_db(abs(X))\nplt.figure(figsize=(14, 6))\nlibrosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')\nplt.colorbar()","metadata":{"execution":{"iopub.status.busy":"2021-06-03T04:02:19.262166Z","iopub.execute_input":"2021-06-03T04:02:19.262599Z","iopub.status.idle":"2021-06-03T04:02:20.139794Z","shell.execute_reply.started":"2021-06-03T04:02:19.262565Z","shell.execute_reply":"2021-06-03T04:02:20.138839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The vertical axis represents frequencies (from 0 to 10kHz), and the horizontal axis represents the time of the clip.","metadata":{}},{"cell_type":"markdown","source":"# Load Dataset\n","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/gtzan-dataset-music-genre-classification/Data/features_3_sec.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-03T04:12:20.696487Z","iopub.execute_input":"2021-06-03T04:12:20.696816Z","iopub.status.idle":"2021-06-03T04:12:20.861776Z","shell.execute_reply.started":"2021-06-03T04:12:20.696787Z","shell.execute_reply":"2021-06-03T04:12:20.861079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We should first see how big our dataset is","metadata":{}},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-03T04:12:46.647043Z","iopub.execute_input":"2021-06-03T04:12:46.647361Z","iopub.status.idle":"2021-06-03T04:12:46.652646Z","shell.execute_reply.started":"2021-06-03T04:12:46.647331Z","shell.execute_reply":"2021-06-03T04:12:46.65172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's check whther our dataset is balanced or not","metadata":{}},{"cell_type":"code","source":"df['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-06-03T04:13:29.007143Z","iopub.execute_input":"2021-06-03T04:13:29.007459Z","iopub.status.idle":"2021-06-03T04:13:29.017298Z","shell.execute_reply.started":"2021-06-03T04:13:29.007431Z","shell.execute_reply":"2021-06-03T04:13:29.016185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So our dataset is balanced dataset","metadata":{}},{"cell_type":"markdown","source":"#### Correlation Heatmap for feature means","metadata":{}},{"cell_type":"code","source":"# Computing the Correlation Matrix\nspike_cols = [col for col in df.columns if 'mean' in col]\ncorr = df[spike_cols].corr()\n\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=np.bool))\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(16, 11));\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(0, 25, as_cmap=True, s = 90, l = 45, n = 5)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n\nplt.title('Correlation Heatmap (for the MEAN variables)', fontsize = 20)\nplt.xticks(fontsize = 10)\nplt.yticks(fontsize = 10);","metadata":{"execution":{"iopub.status.busy":"2021-06-03T04:16:12.957357Z","iopub.execute_input":"2021-06-03T04:16:12.957672Z","iopub.status.idle":"2021-06-03T04:16:13.721634Z","shell.execute_reply.started":"2021-06-03T04:16:12.957641Z","shell.execute_reply":"2021-06-03T04:16:13.72077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Box Plot for Genres Distributions","metadata":{}},{"cell_type":"code","source":"x = df[[\"label\", \"tempo\"]]\n\nfig, ax = plt.subplots(figsize=(16, 8));\nsns.boxplot(x = \"label\", y = \"tempo\", data = x, palette = 'husl');\n\nplt.title('BPM Boxplot for Genres', fontsize = 20)\nplt.xticks(fontsize = 14)\nplt.yticks(fontsize = 10);\nplt.xlabel(\"Genre\", fontsize = 15)\nplt.ylabel(\"BPM\", fontsize = 15)\nplt.savefig(\"BPM_Boxplot.png\")","metadata":{"execution":{"iopub.status.busy":"2021-06-03T04:16:33.087046Z","iopub.execute_input":"2021-06-03T04:16:33.087427Z","iopub.status.idle":"2021-06-03T04:16:33.444424Z","shell.execute_reply.started":"2021-06-03T04:16:33.087397Z","shell.execute_reply":"2021-06-03T04:16:33.443445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"Let's convert the **label** values into integers","metadata":{}},{"cell_type":"code","source":"from sklearn import preprocessing\nlabel_encoder = preprocessing.LabelEncoder()\ndf['label'] = label_encoder.fit_transform(df['label'])","metadata":{"execution":{"iopub.status.busy":"2021-06-03T03:31:01.214192Z","iopub.execute_input":"2021-06-03T03:31:01.214518Z","iopub.status.idle":"2021-06-03T03:31:01.224947Z","shell.execute_reply.started":"2021-06-03T03:31:01.214488Z","shell.execute_reply":"2021-06-03T03:31:01.224197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Independent and dependent variables**","metadata":{}},{"cell_type":"code","source":"X = df.drop(['label','filename'],axis=1)\ny = df['label'] ","metadata":{"execution":{"iopub.status.busy":"2021-06-03T04:18:46.301079Z","iopub.execute_input":"2021-06-03T04:18:46.301399Z","iopub.status.idle":"2021-06-03T04:18:46.311452Z","shell.execute_reply.started":"2021-06-03T04:18:46.30137Z","shell.execute_reply":"2021-06-03T04:18:46.310694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We are going to normalize our data","metadata":{}},{"cell_type":"code","source":"cols = X.columns\nmin_max_scaler = preprocessing.MinMaxScaler()\nnp_scaled = min_max_scaler.fit_transform(X)\n\n# new data frame with the new scaled data. \nX = pd.DataFrame(np_scaled, columns = cols)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T04:18:47.716248Z","iopub.execute_input":"2021-06-03T04:18:47.716567Z","iopub.status.idle":"2021-06-03T04:18:47.733843Z","shell.execute_reply.started":"2021-06-03T04:18:47.716538Z","shell.execute_reply":"2021-06-03T04:18:47.733117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train-Test Split","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=111)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-03T03:31:07.829718Z","iopub.execute_input":"2021-06-03T03:31:07.830041Z","iopub.status.idle":"2021-06-03T03:31:07.84562Z","shell.execute_reply.started":"2021-06-03T03:31:07.830012Z","shell.execute_reply":"2021-06-03T03:31:07.844611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build ML Models","metadata":{}},{"cell_type":"markdown","source":"Below code is taken from this [link](https://www.kaggle.com/andradaolteanu/work-w-audio-data-visualise-classify-recommend)","metadata":{}},{"cell_type":"code","source":"def model_assess(model, title = \"Default\"):\n    model.fit(X_train, y_train)\n    preds = model.predict(X_test)\n    #print(confusion_matrix(y_test, preds))\n    print('Accuracy', title, ':', round(accuracy_score(y_test, preds), 5), '\\n')","metadata":{"execution":{"iopub.status.busy":"2021-06-03T02:47:35.59418Z","iopub.execute_input":"2021-06-03T02:47:35.594518Z","iopub.status.idle":"2021-06-03T02:47:35.599169Z","shell.execute_reply.started":"2021-06-03T02:47:35.594489Z","shell.execute_reply":"2021-06-03T02:47:35.598364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will going to make 11 models and then choose the best model","metadata":{}},{"cell_type":"code","source":"# Naive Bayes\nnb = GaussianNB()\nmodel_assess(nb, \"Naive Bayes\")\n\n# Stochastic Gradient Descent\nsgd = SGDClassifier(max_iter=5000, random_state=0)\nmodel_assess(sgd, \"Stochastic Gradient Descent\")\n\n# KNN\nknn = KNeighborsClassifier(n_neighbors=19)\nmodel_assess(knn, \"KNN\")\n\n# Decission trees\ntree = DecisionTreeClassifier()\nmodel_assess(tree, \"Decission trees\")\n\n# Random Forest\nrforest = RandomForestClassifier(n_estimators=1000, max_depth=10, random_state=0)\nmodel_assess(rforest, \"Random Forest\")\n\n# Support Vector Machine\nsvm = SVC(decision_function_shape=\"ovo\")\nmodel_assess(svm, \"Support Vector Machine\")\n\n# Logistic Regression\nlg = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial')\nmodel_assess(lg, \"Logistic Regression\")\n\n# Neural Nets\nnn = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5000, 10), random_state=1)\nmodel_assess(nn, \"Neural Nets\")\n\n# catboost\ncbc = cb.CatBoostClassifier(verbose=0, eval_metric='Accuracy', loss_function='MultiClass')\nmodel_assess(cbc,\"Cat Boost Classifier\")\n\n# Cross Gradient Booster\nxgb = XGBClassifier(n_estimators=1000, learning_rate=0.05)\nmodel_assess(xgb, \"Cross Gradient Booster\")\n\n# Cross Gradient Booster (Random Forest)\nxgbrf = XGBRFClassifier(objective= 'multi:softmax')\nmodel_assess(xgbrf, \"Cross Gradient Booster (Random Forest)\")","metadata":{"execution":{"iopub.status.busy":"2021-06-03T02:59:38.454733Z","iopub.execute_input":"2021-06-03T02:59:38.455132Z","iopub.status.idle":"2021-06-03T03:10:52.89116Z","shell.execute_reply.started":"2021-06-03T02:59:38.455098Z","shell.execute_reply":"2021-06-03T03:10:52.890191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So we got highest accuracy with catboost model.Let's print the confusion matrix of it","metadata":{}},{"cell_type":"code","source":"# Final model\ncbc = cb.CatBoostClassifier(verbose=0, eval_metric='Accuracy', loss_function='MultiClass')\ncbc.fit(X_train, y_train)\n\n\npreds = cbc.predict(X_test)\n\nprint('Accuracy', ':', round(accuracy_score(y_test, preds), 5), '\\n')\n\n# Confusion Matrix\nconfus_mat = confusion_matrix(y_test, preds) \nplt.figure(figsize = (10, 5))\nsns.heatmap(confus_mat)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T03:17:24.63387Z","iopub.execute_input":"2021-06-03T03:17:24.634216Z","iopub.status.idle":"2021-06-03T03:18:35.586653Z","shell.execute_reply.started":"2021-06-03T03:17:24.634188Z","shell.execute_reply":"2021-06-03T03:18:35.585558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Deep Learning Model","metadata":{}},{"cell_type":"markdown","source":"Now it's time to build our deep learning model,so let's go ahead","metadata":{}},{"cell_type":"code","source":"X_train.shape[1]","metadata":{"execution":{"iopub.status.busy":"2021-06-03T03:40:54.475457Z","iopub.execute_input":"2021-06-03T03:40:54.475767Z","iopub.status.idle":"2021-06-03T03:40:54.480786Z","shell.execute_reply.started":"2021-06-03T03:40:54.475738Z","shell.execute_reply":"2021-06-03T03:40:54.480009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Flatten(input_shape=(58,)))\nmodel.add(Dense(512, activation='relu', kernel_regularizer = keras.regularizers.l2(0.001)))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(256, activation='relu', kernel_regularizer = keras.regularizers.l2(0.003)))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(64, activation='relu', kernel_regularizer = keras.regularizers.l2(0.01)))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dense(10, activation='softmax'))\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-03T03:44:00.771067Z","iopub.execute_input":"2021-06-03T03:44:00.771441Z","iopub.status.idle":"2021-06-03T03:44:00.834317Z","shell.execute_reply.started":"2021-06-03T03:44:00.771408Z","shell.execute_reply":"2021-06-03T03:44:00.833579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In order to prevent our model from overfitting we wll use callbacks","metadata":{}},{"cell_type":"code","source":"early_stopping= EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=5) \ncheck_pointer = ModelCheckpoint(filepath = 'clf-resnet-checkpoint.hdf5',verbose=1,save_best_only=True) \nreduce_lr = ReduceLROnPlateau(monitor='val_loss',mode='min',verbose=1,patience=5,min_delta = 0.0001,factor=0.2) \ncallbacks = [check_pointer,early_stopping,reduce_lr]","metadata":{"execution":{"iopub.status.busy":"2021-06-03T03:53:02.224379Z","iopub.execute_input":"2021-06-03T03:53:02.224701Z","iopub.status.idle":"2021-06-03T03:53:02.232221Z","shell.execute_reply.started":"2021-06-03T03:53:02.224673Z","shell.execute_reply":"2021-06-03T03:53:02.231527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# compile the model\nadam = keras.optimizers.Adam(lr=1e-4)\nmodel.compile(optimizer=adam,\n             loss=\"sparse_categorical_crossentropy\",\n             metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2021-06-03T04:22:45.287265Z","iopub.execute_input":"2021-06-03T04:22:45.28759Z","iopub.status.idle":"2021-06-03T04:22:45.314933Z","shell.execute_reply.started":"2021-06-03T04:22:45.28756Z","shell.execute_reply":"2021-06-03T04:22:45.31337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Wuhhoo our model is ready let's train our model,let's run for 100 epochs","metadata":{}},{"cell_type":"code","source":"hist = model.fit(X_train, y_train,\n                 validation_data = (X_test,y_test),\n                 epochs = 100,\n                 batch_size = 32, callbacks = [check_pointer,early_stopping])","metadata":{"execution":{"iopub.status.busy":"2021-06-03T03:53:33.374292Z","iopub.execute_input":"2021-06-03T03:53:33.374615Z","iopub.status.idle":"2021-06-03T03:53:36.383431Z","shell.execute_reply.started":"2021-06-03T03:53:33.374586Z","shell.execute_reply":"2021-06-03T03:53:36.382718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_error, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\nprint(f\"Test accuracy: {test_accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2021-06-03T03:53:40.674358Z","iopub.execute_input":"2021-06-03T03:53:40.674682Z","iopub.status.idle":"2021-06-03T03:53:40.909727Z","shell.execute_reply.started":"2021-06-03T03:53:40.674653Z","shell.execute_reply":"2021-06-03T03:53:40.908452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plot Accuracy and Loss","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,15))\nfig, axs = plt.subplots(2)\n\n# accuracy \naxs[0].plot(hist.history[\"accuracy\"], label=\"train accuracy\")\naxs[0].plot(hist.history[\"val_accuracy\"], label=\"test accuracy\")    \naxs[0].set_ylabel(\"Accuracy\")\naxs[0].legend(loc=\"lower right\")\naxs[0].set_title(\"Accuracy eval\")\n    \n# Error \naxs[1].plot(hist.history[\"loss\"], label=\"train error\")\naxs[1].plot(hist.history[\"val_loss\"], label=\"test error\")    \naxs[1].set_ylabel(\"Error\")\naxs[1].set_xlabel(\"Epoch\")\naxs[1].legend(loc=\"upper right\")\naxs[1].set_title(\"Error eval\")\n    \nplt.show()","metadata":{},"execution_count":null,"outputs":[]}]}