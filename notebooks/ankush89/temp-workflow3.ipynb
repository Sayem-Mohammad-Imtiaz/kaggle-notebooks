{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.feature_selection import SelectFpr, f_regression\nfrom sklearn.cluster import MeanShift","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:18:59.230281Z","iopub.execute_input":"2021-08-27T06:18:59.230938Z","iopub.status.idle":"2021-08-27T06:18:59.347537Z","shell.execute_reply.started":"2021-08-27T06:18:59.230874Z","shell.execute_reply":"2021-08-27T06:18:59.346497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/california-housing-prices/housing.csv')","metadata":{"execution":{"iopub.status.busy":"2021-08-27T04:41:01.527735Z","iopub.execute_input":"2021-08-27T04:41:01.52828Z","iopub.status.idle":"2021-08-27T04:41:01.704384Z","shell.execute_reply.started":"2021-08-27T04:41:01.528247Z","shell.execute_reply":"2021-08-27T04:41:01.703362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# High-level view of the data\n\ndata.head().T\ndata.info()","metadata":{"execution":{"iopub.status.busy":"2021-08-27T04:45:36.41217Z","iopub.execute_input":"2021-08-27T04:45:36.412541Z","iopub.status.idle":"2021-08-27T04:45:36.434709Z","shell.execute_reply.started":"2021-08-27T04:45:36.412509Z","shell.execute_reply":"2021-08-27T04:45:36.433054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Formatting the columns: Not required","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting the data\ny_col = ['median_house_value']\ndata_x = data.loc[:, [col for col in data.columns if col not in y_col]]\ndata_y = data.loc[:, [col for col in data.columns if col in y_col]]\ntrain_x, test_x, train_y, test_y = train_test_split(\n    data_x,\n    data_y,\n    test_size = 0.25,\n    random_state = 42,\n    shuffle = True)\nall_cols = list(data_x.columns)\nnumeric_cols = [col for col in all_cols if data_x[col].dtypes != object]\ncat_cols = [col for col in all_cols if data_x[col].dtypes == object]","metadata":{"execution":{"iopub.status.busy":"2021-08-27T04:49:36.581761Z","iopub.execute_input":"2021-08-27T04:49:36.582276Z","iopub.status.idle":"2021-08-27T04:49:36.602688Z","shell.execute_reply.started":"2021-08-27T04:49:36.582242Z","shell.execute_reply":"2021-08-27T04:49:36.601482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Derive additional features: Manual\n\ndatasets = [train_x, test_x]\ncolname = 'pop_per_household'\nfor data in datasets:\n    data[colname] = data['households'] / data['population']\nnumeric_cols += [colname]","metadata":{"execution":{"iopub.status.busy":"2021-08-27T04:53:54.243938Z","iopub.execute_input":"2021-08-27T04:53:54.244294Z","iopub.status.idle":"2021-08-27T04:53:54.272796Z","shell.execute_reply.started":"2021-08-27T04:53:54.244263Z","shell.execute_reply":"2021-08-27T04:53:54.27204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Derive additional features: Systematic: Kernel-based: None\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Derive additional features: Systematic: Non Kernel-based: None","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Exploratory Data Analysis: Univariate\n\ndef return_outlier_perc(ser, threshold = 3):\n    nm_mask = ~pd.isna(ser)\n    ser_nm = ser.loc[nm_mask]\n    z_ser_nm = (ser_nm - ser_nm.mean()) / ser_nm.std()\n    outliers = ~z_ser_nm.apply(lambda x: True if -threshold < x < +threshold else False)\n    return outliers.sum() / ser_nm.shape[0]\ndef return_negatives_perc(ser):\n    nm_mask = ~pd.isna(ser)\n    ser_nm = ser.loc[nm_mask]\n    neg_mask = ser_nm.apply(lambda x: True if x < 0 else False)\n    return neg_mask.sum() / ser_nm.shape[0]\ndef return_positives_perc(ser):\n    nm_mask = ~pd.isna(ser)\n    ser_nm = ser.loc[nm_mask]\n    pos_mask = ser_nm.apply(lambda x: True if x > 0 else False)\n    return pos_mask.sum() / ser_nm.shape[0]\nunivariate_numeric = train_x.loc[:, numeric_cols].describe().T\nunivariate_numeric['perc_missing'] = 1 - univariate_numeric['count'] / train_x.shape[0]\nunivariate_numeric['skew'] = [train_x[col].skew() for col in univariate_numeric.index]\nunivariate_numeric['kurt'] = [train_x[col].kurt() for col in univariate_numeric.index]\nunivariate_numeric['cov'] = univariate_numeric['std'] / univariate_numeric['mean']\nunivariate_numeric['perc_outliers'] = [return_outlier_perc(train_x[col]) for col in univariate_numeric.index]\nunivariate_numeric['perc_negatives'] = [return_negatives_perc(train_x[col]) for col in univariate_numeric.index]\nunivariate_numeric['perc_positives'] = [return_positives_perc(train_x[col]) for col in univariate_numeric.index]\n\nunivariate_categorical = train_x.loc[:, cat_cols].describe().T\nunivariate_categorical['perc_missing'] = 1 - univariate_categorical['count'] / train_x.shape[0]\nunivariate_categorical['top_freq'] = univariate_categorical['freq'] / univariate_categorical['count']","metadata":{"execution":{"iopub.status.busy":"2021-08-27T05:20:14.894196Z","iopub.execute_input":"2021-08-27T05:20:14.894565Z","iopub.status.idle":"2021-08-27T05:20:15.167288Z","shell.execute_reply.started":"2021-08-27T05:20:14.894534Z","shell.execute_reply":"2021-08-27T05:20:15.16617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"univariate_numeric","metadata":{"execution":{"iopub.status.busy":"2021-08-27T05:23:29.407234Z","iopub.execute_input":"2021-08-27T05:23:29.407621Z","iopub.status.idle":"2021-08-27T05:23:29.437884Z","shell.execute_reply.started":"2021-08-27T05:23:29.407586Z","shell.execute_reply":"2021-08-27T05:23:29.436852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prepare data for bivariate and row-wise analysis\n\ntrain_x_temp = train_x.copy(deep = False)\nmissing_cols = []\nconstant_cols = []\nirrelevant_cols = []\ncols_to_remove = missing_cols + constant_cols + irrelevant_cols\ntrain_x_temp = train_x_temp.loc[:, [col for col in train_x_temp.columns if col not in cols_to_remove]]\nnm_mask = ~(pd.isna(train_x_temp).any(axis = 1))\ntrain_x_temp = train_x_temp.loc[nm_mask, :]\nidentifier = train_x_temp.index\nall_cols_temp = list(train_x_temp.columns)\nnumeric_cols_temp = [col for col in numeric_cols if col not in cols_to_remove]\ncat_cols_temp = [col for col in cat_cols if col not in cols_to_remove]\nnumeric_data = train_x_temp.loc[:, [col for col in train_x_temp.columns if col in numeric_cols_temp]]\ncat_data = train_x_temp.loc[:, [col for col in train_x_temp.columns if col in cat_cols_temp]]\nohe = OneHotEncoder(sparse = False)\ncat_ohe_data = pd.DataFrame(ohe.fit_transform(X = cat_data.values), index = identifier, columns = ohe.get_feature_names()) \ntrain_x_analysis = pd.concat(\n    objs = (numeric_data, cat_ohe_data),\n    axis = 1,\n    join = 'outer',\n    ignore_index = False,\n    copy = True)\ntrain_x_analysis.index = identifier","metadata":{"execution":{"iopub.status.busy":"2021-08-27T05:56:27.798341Z","iopub.execute_input":"2021-08-27T05:56:27.798686Z","iopub.status.idle":"2021-08-27T05:56:27.829551Z","shell.execute_reply.started":"2021-08-27T05:56:27.798658Z","shell.execute_reply":"2021-08-27T05:56:27.828449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Exploratory Data Analysis: Bivariate\ntrain_y_analysis = train_y.loc[nm_mask]\ndef return_scores(y):\n    fs_fpr = SelectFpr(\n        score_func = f_regression,\n        alpha = 0.05)\n    fs_fpr.fit(X = train_x_analysis, y = y)\n    return fs_fpr.scores_\nbivariate_x_y = pd.DataFrame(return_scores(y = train_y_analysis), index = train_x_analysis.columns, columns = ['Importances'])\nbivariate_x_y.sort_values(\n    by = 'Importances',\n    axis = 0,\n    ascending = False,\n    inplace = True)\nbivariate_x_x = pd.DataFrame(\n    [return_scores(y = train_x_analysis[col]) for col in train_x_analysis], \n    index = train_x_analysis.columns,\n    columns = train_x_analysis.columns)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:16:11.150841Z","iopub.execute_input":"2021-08-27T06:16:11.151223Z","iopub.status.idle":"2021-08-27T06:16:11.262065Z","shell.execute_reply.started":"2021-08-27T06:16:11.15119Z","shell.execute_reply":"2021-08-27T06:16:11.260928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Exploratory Data Analysis: Row-wise analysis\n\ntrain_x_normalized = pd.DataFrame(\n    StandardScaler().fit_transform(X = train_x_analysis.values), \n    index = identifier, \n    columns = train_x_analysis.columns)\ngroups = MeanShift().fit_predict(X = train_x_analysis)","metadata":{},"execution_count":null,"outputs":[]}]}