{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Following algorithm undertaken to solve the problem\n\nFormatting the columns: X\n1. Num -> Cat: EmployeeNumber\n2. Cat -> Num: None\n3. Cat -> Date: None\n4. Num -> Date: None\n5. Others: Attrition ()\n\nFormatting the columns: y\n1. Num -> Cat: EmployeeNumber\n2. Cat -> Num: None\n3. Cat -> Date: None\n4. Num -> Date: None\n5. Others: Encoded Attrition: 1 if Yes else 0\n\nIncluding additional features:\n1. Manual: None\n2. Kernel-based: None\n\nExploratory Data Analysis: Col-wise: Univariate\n\n1. Numeric Columns\na. Mean, Median, Percentiles: Done. Used standard formula\nb. Higher-order moments: Done. Used standard formula\nc. Outlier: Done. Used IQR to find % of outliers and outliers mask\nd. perc_negatives, perc_positives\ne. perc_missing\n\n2. Categorical Columns\na. Count, Unique, Mode, Freq of Mode,\nb. Missing_perc\nc. Mode_freq_perc\n\nPreparing data for bivariate exploratory analysis and row-wise exploratory analysis:\na. Cols removed\nb. Rows removed\nc. Cat -> Num\n\nExploratory Data Analysis: Col-wise: Bivariate\n\n1. Numeric ~ y. Used sklearn.feature_selection.chi2 since all features are non-negative\n2. Categorical ~ y. Same as above\n3. Numeric ~ Numeric. Used correlation\n4. Numeric ~ Categorical. Same as above\n5. Categorical ~ Categorical. Same as above\n\nExploratory Data Analysis: Row-wise:\n\n1. Missing rows: Where 50% of cols is missing\n2. Clustering: Used KMeans with default parameters to determine the clusters\n3. Outlier Detection: Unsupervised Outlier Detection using DBScan Clustering\n4. Exploratory Data Analysis: Overall\na. Linearity (For regression problem)\nb. Linearly separable (For classification problem)\n\nPreparing the data for modeling: Dimensionality Reduction: Excluding rows and irrelevant columns\n\n1. Excluding irrelevant features: features having high missing values or relatively constant or perfectly correlated features\n2. Excluding rows: outlier rows\n3. Preparing the data for modeling: Imputing missing values: None\na. Basis Mean: None\nb. Basis Median: None\nc. Basis Mode: None\nd. Custom: None\n\nPreparing the data for modeling: Reducing dimensionality\n\n1. Manual Feature Selection: None\n2. Algorithmic: Used PCA\n\nSelecting a performance measure: Chose accuracy_score\n\nSelecting candidate models and parameters: \n1. Standalone models: \n1.a. Unsupervised approach: Nearest Neighbor approach\n1.b. Supervised approach: Logistic Regression, Ridge Classifier, SGD Classifier with default parameters\n2. Ensemble models: None\n\n\nSelecting fitting strategy and fit the models: Non-Iterative fitting strategy\n\nEvaluation and selecting the best model: SGD classifier\n\nSubmitting the results","metadata":{}},{"cell_type":"code","source":"!pip install pingouin","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:58:02.733503Z","iopub.execute_input":"2021-08-26T08:58:02.734048Z","iopub.status.idle":"2021-08-26T08:58:23.628156Z","shell.execute_reply.started":"2021-08-26T08:58:02.733934Z","shell.execute_reply":"2021-08-26T08:58:23.626965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom scipy.stats import iqr\nimport math\nfrom pingouin import multivariate_normality\nfrom scipy.stats import mode\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import chi2\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler \nfrom sklearn.cluster import KMeans, DBSCAN\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.neighbors import NearestNeighbors\nfrom sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-26T08:58:23.630026Z","iopub.execute_input":"2021-08-26T08:58:23.630328Z","iopub.status.idle":"2021-08-26T08:58:25.865017Z","shell.execute_reply.started":"2021-08-26T08:58:23.630296Z","shell.execute_reply":"2021-08-26T08:58:25.863954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/ibm-hr-analytics-attrition-dataset/WA_Fn-UseC_-HR-Employee-Attrition.csv')\ndata_model, data_submission = train_test_split(\n    data,\n    test_size = 0.25,\n    random_state = 42,\n    stratify = data.loc[:, 'Attrition'])","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:58:25.867409Z","iopub.execute_input":"2021-08-26T08:58:25.867756Z","iopub.status.idle":"2021-08-26T08:58:25.920785Z","shell.execute_reply.started":"2021-08-26T08:58:25.867723Z","shell.execute_reply":"2021-08-26T08:58:25.919831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_model.head().T","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:58:25.922266Z","iopub.execute_input":"2021-08-26T08:58:25.922555Z","iopub.status.idle":"2021-08-26T08:58:25.955577Z","shell.execute_reply.started":"2021-08-26T08:58:25.922526Z","shell.execute_reply":"2021-08-26T08:58:25.954901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_model.info()","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:58:25.956794Z","iopub.execute_input":"2021-08-26T08:58:25.957313Z","iopub.status.idle":"2021-08-26T08:58:25.978514Z","shell.execute_reply.started":"2021-08-26T08:58:25.95728Z","shell.execute_reply":"2021-08-26T08:58:25.977729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"convert_num_to_cat = ['EmployeeNumber']\n\n# 1. Numeric -> Categorical\ndef convert_to_categorical(x):\n    return x.astype(object)\ndata_model['Attrition'] = data_model['Attrition'].apply(lambda x: 0 if x == 'No' else 1)\ndata_submission['Attrition'] = data_submission['Attrition'].apply(lambda x: 0 if x == 'No' else 1)\n\nfor col in convert_num_to_cat:\n    data_model[col] = data_model.loc[:, [col]].apply(convert_to_categorical)","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:58:25.980064Z","iopub.execute_input":"2021-08-26T08:58:25.980701Z","iopub.status.idle":"2021-08-26T08:58:26.003875Z","shell.execute_reply.started":"2021-08-26T08:58:25.980666Z","shell.execute_reply":"2021-08-26T08:58:26.001686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_model.info()","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:58:26.005222Z","iopub.execute_input":"2021-08-26T08:58:26.005514Z","iopub.status.idle":"2021-08-26T08:58:26.024258Z","shell.execute_reply.started":"2021-08-26T08:58:26.005485Z","shell.execute_reply":"2021-08-26T08:58:26.022968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = ['Attrition']\ndata_x = data_model.loc[:, [col for col in data_model.columns if col not in y]]\ndata_y = data_model.loc[:, ['Attrition']]\nsubmission_x = data_submission.loc[:, [col for col in data_submission.columns if col not in y]]\nsubmission_y = data_submission.loc[:, ['Attrition']]\ntrain_x, test_x, train_y, test_y = train_test_split(\n    data_x,\n    data_y,\n    test_size = 0.25,\n    random_state = 42,\n    stratify = data_y.loc[:, 'Attrition'])\nall_cols = list(data_x.columns)\nnumeric_cols = [col for col in all_cols if data_x[col].dtypes != object]\ncat_cols = [col for col in all_cols if data_x[col].dtypes == object]\nlen(numeric_cols + cat_cols) == len(all_cols)","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:58:26.028453Z","iopub.execute_input":"2021-08-26T08:58:26.028998Z","iopub.status.idle":"2021-08-26T08:58:26.052923Z","shell.execute_reply.started":"2021-08-26T08:58:26.028961Z","shell.execute_reply":"2021-08-26T08:58:26.051704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking if the stratified split has happened or not\nprint(data_y.loc[:, 'Attrition'].sum() / data_y.loc[:, 'Attrition'].count())\nprint(train_y.loc[:, 'Attrition'].sum() / train_y.loc[:, 'Attrition'].count())\nprint(test_y.loc[:, 'Attrition'].sum() / test_y.loc[:, 'Attrition'].count())\nprint(submission_y.loc[:, 'Attrition'].sum() / submission_y.loc[:, 'Attrition'].count())","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:58:26.054728Z","iopub.execute_input":"2021-08-26T08:58:26.055024Z","iopub.status.idle":"2021-08-26T08:58:26.067422Z","shell.execute_reply.started":"2021-08-26T08:58:26.054994Z","shell.execute_reply":"2021-08-26T08:58:26.066175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Exploratory Data Analysis: Col-wise\n\ndef derive_outlier_perc(ser, iqr_width = 1.5):\n    q1, q3 = ser.quantile(q = 0.25,\n      interpolation = 'linear'), ser.quantile(q = 0.75,\n      interpolation = 'linear')\n    width = iqr_width * (q3 - q1)\n    down_, up_ = q1 - width, q3 + width\n    mask = ser.apply(lambda x: 0 if down_ <= x <= up_ else 1)\n    return mask.sum() / mask.shape[0]\ndef derive_negative_perc(ser, threshold = 0):\n    mask = ser.apply(lambda x: 1 if x < threshold else 0)\n    return mask.sum() / mask.shape[0]\ndef derive_positive_perc(ser, threshold = 0):\n    mask = ser.apply(lambda x: 1 if x >= threshold else 0)\n    return mask.sum() / mask.shape[0]\n    \nunivariate_numeric = train_x.loc[:, numeric_cols].describe().T\nunivariate_categorical = train_x.loc[:, cat_cols].describe().T\nunivariate_numeric['perc_missing'] = 1 - univariate_numeric['count'] / train_x.shape[0]\nunivariate_numeric['skew'] = [train_x[col].skew() for col in univariate_numeric.index]\nunivariate_numeric['kurt'] = [train_x[col].kurt() for col in univariate_numeric.index]\nunivariate_numeric['perc_outliers'] = [derive_outlier_perc(train_x[col]) for col in univariate_numeric.index]\nunivariate_numeric['perc_negatives'] = [derive_negative_perc(train_x[col]) for col in univariate_numeric.index]\nunivariate_numeric['perc_positives'] = [derive_positive_perc(train_x[col]) for col in univariate_numeric.index]\nunivariate_categorical['perc_missing'] = 1 - univariate_categorical['count'] / train_x.shape[0]\nunivariate_categorical['mode_freq'] = univariate_categorical['freq'] / univariate_categorical['count']","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:58:26.068801Z","iopub.execute_input":"2021-08-26T08:58:26.069128Z","iopub.status.idle":"2021-08-26T08:58:26.309651Z","shell.execute_reply.started":"2021-08-26T08:58:26.069097Z","shell.execute_reply":"2021-08-26T08:58:26.308656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preparing data for bivariate and row-wise analysis\n\nmissing_cols = []\nirrelevant_cols = ['EmployeeNumber', 'EmployeeCount']\nconstant_cols = ['Over18']\ncols_to_remove = missing_cols + irrelevant_cols + constant_cols\ntrain_x_copy = train_x.loc[:, [col for col in train_x.columns if col not in cols_to_remove]]\ntrain_x_nm_mask_full = ~pd.isna(train_x_copy)\ntrain_x_nm_mask = (train_x_nm_mask_full.any(axis = 1))\nidentifier = train_x_copy.loc[train_x_nm_mask, :].index\nall_cols = list(train_x_copy.columns)\nnumeric_cols = [col for col in all_cols if train_x_copy[col].dtypes != object]\ncat_cols = [col for col in all_cols if train_x_copy[col].dtypes == object]\nlen(numeric_cols + cat_cols) == len(all_cols)\nnumeric_data, cat_data = train_x_copy.loc[train_x_nm_mask, numeric_cols], train_x_copy.loc[train_x_nm_mask, cat_cols]\nohe = OneHotEncoder(sparse = False)\nohe_data_array = ohe.fit_transform(cat_data.values)\ncat_ohe = pd.DataFrame(ohe_data_array, columns = ohe.get_feature_names(), index = identifier)\ntrain_x_analysis = pd.concat(\n    objs = (numeric_data, cat_ohe),\n    axis = 1,\n    join = 'outer',\n    ignore_index = False,\n    copy = True)\ntrain_x_analysis.index = identifier","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:58:26.310857Z","iopub.execute_input":"2021-08-26T08:58:26.311151Z","iopub.status.idle":"2021-08-26T08:58:26.337591Z","shell.execute_reply.started":"2021-08-26T08:58:26.311123Z","shell.execute_reply":"2021-08-26T08:58:26.336533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Exploratory Data Analysis: Bivariate Analysis\n\n# X ~ y\n_, pvals = chi2(X = train_x_analysis, y = train_y)\nbivariate_x_y = pd.DataFrame(pvals, index = train_x_analysis.columns, columns = ['chi2_pvals'])\nbivariate_x_y.sort_values(by = 'chi2_pvals', ascending = False, inplace = True)\n\n# X ~ X\nbivariate_x_x = train_x_analysis.corr()","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:58:26.338958Z","iopub.execute_input":"2021-08-26T08:58:26.339243Z","iopub.status.idle":"2021-08-26T08:58:26.363057Z","shell.execute_reply.started":"2021-08-26T08:58:26.339215Z","shell.execute_reply":"2021-08-26T08:58:26.362269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Exploratory Data Analysis: Row-wise analysis\n\n# Missing\nthreshold_perc_n_missing = 0.50\nthreshold_n_missing = math.ceil(train_x_nm_mask_full.shape[1] * threshold_perc_n_missing)\ntrain_x_nm_count = train_x_nm_mask_full.sum(axis = 1)\nmissing_ = train_x_nm_count < threshold_n_missing\n\n# Grouping\ncluster_data = pd.concat(\n    objs = (train_x_analysis, train_y),\n    axis = 1,\n    join = 'outer',\n    ignore_index = False,\n    copy = True)\ncluster_data_standardized = pd.DataFrame(\n    StandardScaler().fit_transform(X = cluster_data.values), \n    index = cluster_data.index, \n    columns = cluster_data.columns)\ndef return_inertia(n_clusters):\n    kmeans = KMeans(\n        n_clusters = n_clusters,\n        init = 'k-means++',\n        n_init = 10,\n        max_iter = 300,\n        verbose = 0,\n        random_state = 42,\n        copy_x = True,\n        algorithm = 'auto')\n    kmeans.fit(X = cluster_data.values)\n    return kmeans.inertia_\ninertias = list(map(return_inertia, np.arange(10, 15)))\nop_n_cluster = np.argmin(np.array(inertias)) + 1\nkmeans = KMeans(\n    n_clusters = op_n_cluster,\n    init = 'k-means++',\n    n_init = 10,\n    max_iter = 300,\n    verbose = 0,\n    random_state = 42,\n    copy_x = True,\n    algorithm = 'auto')\nkmeans.fit(X = cluster_data.values)\ngroup = pd.DataFrame(kmeans.labels_, index = identifier) #This excludes the rows where there are missing values\n\n# Outlier Detection\ndb = DBSCAN(eps = 7.5) #Chosen this to get the desired no of outliers\ncluster_pred = pd.Series(db.fit_predict(X = cluster_data_standardized), index = cluster_data_standardized.index)\noutlier = cluster_pred.apply(lambda x: True if x < 0 else False)\noutlier.sum() / outlier.shape[0]","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:58:26.364089Z","iopub.execute_input":"2021-08-26T08:58:26.364478Z","iopub.status.idle":"2021-08-26T08:58:55.49457Z","shell.execute_reply.started":"2021-08-26T08:58:26.364447Z","shell.execute_reply":"2021-08-26T08:58:55.493745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Exploratory Data Analysis: Overall\n\n# Testing for normality\nresult = multivariate_normality(X = cluster_data_standardized.values, alpha = 0.05)\npval = result.pval","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:58:55.495988Z","iopub.execute_input":"2021-08-26T08:58:55.496721Z","iopub.status.idle":"2021-08-26T08:58:55.63846Z","shell.execute_reply.started":"2021-08-26T08:58:55.496674Z","shell.execute_reply":"2021-08-26T08:58:55.63679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preparing the data for modeling: Excluding columns\ndataset = dict(\n    train_x_model = train_x,\n    test_x_model = test_x,\n    train_y_model = train_y,\n    test_y_model = test_y,\n    submission_x_model = submission_x,\n    submission_y_model = submission_y)\nexclude_datanames = ['train_y_model', 'test_y_model', 'submission_y_model']\nfor data_name in dataset:\n    if data_name in exclude_datanames:\n        continue\n    data = dataset[data_name].copy(deep = False)\n    data = data.loc[:, [col for col in data.columns if col not in cols_to_remove]]\n    dataset.update({data_name: data})","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:58:55.64114Z","iopub.execute_input":"2021-08-26T08:58:55.644369Z","iopub.status.idle":"2021-08-26T08:58:55.678755Z","shell.execute_reply.started":"2021-08-26T08:58:55.644317Z","shell.execute_reply":"2021-08-26T08:58:55.67778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preparing the data for modeling: Excluding rows\nexclude_datanames = ['test_x_model', 'submission_x_model', 'test_y_model', 'submission_y_model']\nfor data_name in dataset:\n    if data_name in exclude_datanames:\n        continue\n    data = dataset[data_name].copy(deep = False)\n    data = data.loc[~outlier.values, :]\n    dataset.update({data_name: data})","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:58:55.680144Z","iopub.execute_input":"2021-08-26T08:58:55.680749Z","iopub.status.idle":"2021-08-26T08:58:55.688792Z","shell.execute_reply.started":"2021-08-26T08:58:55.680703Z","shell.execute_reply":"2021-08-26T08:58:55.687961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preparing the data for modeling: Imputing missing values: None as there are no missing values","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:58:55.690171Z","iopub.execute_input":"2021-08-26T08:58:55.690885Z","iopub.status.idle":"2021-08-26T08:58:55.699496Z","shell.execute_reply.started":"2021-08-26T08:58:55.690839Z","shell.execute_reply":"2021-08-26T08:58:55.698683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preparing the data for modeling: OneHotEncode the categorical features\n\nnumeric_cols = [col for col in dataset['train_x_model'].columns if dataset['train_x_model'][col].dtypes != object]\ncat_cols = [col for col in dataset['train_x_model'].columns if dataset['train_x_model'][col].dtypes == object]\nlen(numeric_cols + cat_cols) == len(all_cols)\ndef ohe_data(data):\n    identifier = data.index\n    numeric_data, cat_data = data.loc[:, numeric_cols], data.loc[:, cat_cols]\n    ohe = OneHotEncoder(sparse = False)\n    ohe_data_array = ohe.fit_transform(cat_data.values)\n    cat_ohe = pd.DataFrame(ohe_data_array, columns = ohe.get_feature_names(), index = identifier)\n    c_data = pd.concat(\n        objs = (numeric_data, cat_ohe),\n        axis = 1,\n        join = 'outer',\n        ignore_index = False,\n        copy = True)\n    return c_data\nexclude_datanames = ['train_y_model', 'test_y_model', 'submission_y_model']\nfor data_name in dataset:\n    if data_name in exclude_datanames:\n        continue\n    data = dataset[data_name].copy(deep = False)\n    data_ = ohe_data(data = data)\n    dataset.update({data_name: data_})","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:58:55.70102Z","iopub.execute_input":"2021-08-26T08:58:55.701771Z","iopub.status.idle":"2021-08-26T08:58:55.734726Z","shell.execute_reply.started":"2021-08-26T08:58:55.701725Z","shell.execute_reply":"2021-08-26T08:58:55.733888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preparing the data for modeling: Reducing dimensionality: Manual feature selection: None","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:58:55.736296Z","iopub.execute_input":"2021-08-26T08:58:55.736982Z","iopub.status.idle":"2021-08-26T08:58:55.742493Z","shell.execute_reply.started":"2021-08-26T08:58:55.736937Z","shell.execute_reply":"2021-08-26T08:58:55.741739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preparing the data for modeling: Reducing dimensionality: Algorithmic feature selection\n\n# Determine the n_components\npca = PCA(n_components = 2)\npca.fit(X = dataset['train_x_model'].values)\npca.explained_variance_ratio_\nopt_n_components = 2\n\n# Reduce the data using the opt_n_components\nopt_pca = PCA(n_components = opt_n_components)\ndef reduce_data(data):\n    data = opt_pca.fit_transform(data.values)\n    return data\nexclude_datanames = ['train_y_model', 'test_y_model', 'submission_y_model']\nfor data_name in dataset:\n    if data_name in exclude_datanames:\n        continue\n    data = dataset[data_name].copy(deep = False)\n    data_ = reduce_data(data = data)\n    dataset.update({data_name: data_})","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:58:55.745965Z","iopub.execute_input":"2021-08-26T08:58:55.748004Z","iopub.status.idle":"2021-08-26T08:58:55.824104Z","shell.execute_reply.started":"2021-08-26T08:58:55.747955Z","shell.execute_reply":"2021-08-26T08:58:55.82273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Select a performance measure\n\neval_metric = accuracy_score","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:58:55.833966Z","iopub.execute_input":"2021-08-26T08:58:55.838366Z","iopub.status.idle":"2021-08-26T08:58:55.851Z","shell.execute_reply.started":"2021-08-26T08:58:55.8383Z","shell.execute_reply":"2021-08-26T08:58:55.849745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Selecting the standalone models:\n# 1.a. Unsupervised approach: Nearest Neighbor approach\n# 1.b. Supervised approach: Logistic Regression, Ridge Classifier, SGD Classifier with default parameters\n\nmodels = []\nmodels.append(NearestNeighbors(n_neighbors = 5))\nmodels.append(LogisticRegression())\nmodels.append(RidgeClassifier())\nmodels.append(SGDClassifier())\n\n# Prediction functions\n# NN Model\ndef predict_and_score_from_nn_model(train_x, test_x, train_y, test_y, model, return_pred = False):\n    for data in [train_x, test_x, train_y, test_y]:\n        data = data.values if isinstance(data, pd.DataFrame) else data\n    model.fit(X = train_x, y = None)\n    _, indices = model.kneighbors(X = test_x)\n    y_pred = []\n    for neighbors in indices:\n        pred_point = mode(train_y.values[neighbors, -1])[0][0]\n        y_pred.append(pred_point)\n    if return_pred:\n        return y_pred\n    return eval_metric(y_true = test_y.values, y_pred = y_pred)\ndef predict_and_score_from_other_models(train_x, test_x, train_y, test_y, model, return_pred = False):\n    model = LogisticRegression()\n    model.fit(X = train_x, y = train_y.values)\n    y_pred = model.predict(X = test_x)\n    if return_pred:\n        return y_pred\n    return eval_metric(y_true = test_y.values, y_pred = y_pred)\npredict_and_score = []\npredict_and_score.append(predict_and_score_from_nn_model)\npredict_and_score += [predict_and_score_from_other_models] * 3","metadata":{"execution":{"iopub.status.busy":"2021-08-26T09:29:40.225841Z","iopub.execute_input":"2021-08-26T09:29:40.226223Z","iopub.status.idle":"2021-08-26T09:29:40.238708Z","shell.execute_reply.started":"2021-08-26T09:29:40.226188Z","shell.execute_reply":"2021-08-26T09:29:40.237231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Selecting the ensemble models: None","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:58:55.91124Z","iopub.execute_input":"2021-08-26T08:58:55.91338Z","iopub.status.idle":"2021-08-26T08:58:55.923165Z","shell.execute_reply.started":"2021-08-26T08:58:55.91331Z","shell.execute_reply":"2021-08-26T08:58:55.921733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fitting strategy: Non-iterative fitting strategy\n\nscores = []\nfor model_, pred_score in zip(models, predict_and_score):\n    scores.append(pred_score(\n        train_x = dataset['train_x_model'],\n        test_x = dataset['test_x_model'],\n        train_y = dataset['train_y_model'],\n        test_y = dataset['test_y_model'],\n        model = model_))","metadata":{"execution":{"iopub.status.busy":"2021-08-26T09:29:43.611053Z","iopub.execute_input":"2021-08-26T09:29:43.611436Z","iopub.status.idle":"2021-08-26T09:29:43.693205Z","shell.execute_reply.started":"2021-08-26T09:29:43.611402Z","shell.execute_reply":"2021-08-26T09:29:43.692186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Selecting the best model and submitting the predictions\n\nbest_index = 0\nsubmission = predict_and_score[best_index](\n    train_x = dataset['train_x_model'],\n    test_x = dataset['submission_x_model'],\n    train_y = dataset['train_y_model'],\n    test_y = None,\n    model = models[best_index],\n    return_pred = True)","metadata":{"execution":{"iopub.status.busy":"2021-08-26T09:29:46.055758Z","iopub.execute_input":"2021-08-26T09:29:46.056135Z","iopub.status.idle":"2021-08-26T09:29:46.109693Z","shell.execute_reply.started":"2021-08-26T09:29:46.056101Z","shell.execute_reply":"2021-08-26T09:29:46.108886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"execution":{"iopub.status.busy":"2021-08-26T09:29:49.632801Z","iopub.execute_input":"2021-08-26T09:29:49.633349Z","iopub.status.idle":"2021-08-26T09:29:49.647485Z","shell.execute_reply.started":"2021-08-26T09:29:49.633313Z","shell.execute_reply":"2021-08-26T09:29:49.646525Z"},"trusted":true},"execution_count":null,"outputs":[]}]}