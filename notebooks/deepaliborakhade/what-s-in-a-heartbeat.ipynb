{"cells":[{"metadata":{"_cell_guid":"7e5b5802-f908-ac4e-87f6-89d37edfeeed"},"cell_type":"markdown","source":"A Keras CNN to classify set A. As many files lacked classification, and I wasn't happy with the classification on the other files, I re-labelled all files and obtained decent results. I learnt a lot in the process, not least about the difficulties in using human perception as ground truth, and how data quality is more important than the algorithm. "},{"metadata":{"_cell_guid":"a4164221-e4cd-a4b6-3105-728b92b79402","trusted":false},"cell_type":"code","source":"import numpy as np\nfrom scipy.io import wavfile\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport pandas as pd\nfrom scipy.signal import decimate\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6a96e14a-3452-34f1-f32d-8a29bf4688cd","trusted":false},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv1D, MaxPool1D, GlobalAvgPool1D, Dropout, BatchNormalization, Dense\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\nfrom keras.utils import np_utils\nfrom keras.regularizers import l2","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f392b235-02db-97d1-c2d6-869f7689d8a6","trusted":false},"cell_type":"code","source":"INPUT_LIB = '../input/'\nSAMPLE_RATE = 44100\nCLASSES = ['artifact', 'normal', 'murmur']\nCODE_BOOK = {x:i for i,x in enumerate(CLASSES)}   \nNB_CLASSES = len(CLASSES)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"84fc95d4-fd22-0b18-b1ad-ad518fd1ecb6"},"cell_type":"markdown","source":"## Load the data\nWe will need to preprocess the unclassified data, as they are marked NaN and also have incorrect file names. For now, we will also make all time series have equal length. We will do all this by defining element wise functions, that we can pass to Pandas."},{"metadata":{"_cell_guid":"80517cc2-4829-6638-d9aa-3f32f3e48a70","trusted":false},"cell_type":"code","source":"def clean_filename(fname, string):   \n    file_name = fname.split('/')[1]\n    if file_name[:2] == '__':        \n        file_name = string + file_name\n    return file_name","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3b8b23a9-99b7-5d2a-3866-500735fa07ca","trusted":false},"cell_type":"code","source":"def load_wav_file(name, path):\n    _, b = wavfile.read(path + name)\n    assert _ == SAMPLE_RATE\n    return b","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"100cf856-64e3-678d-f4bb-96bb072b2d77","trusted":false},"cell_type":"code","source":"def repeat_to_length(arr, length):\n    \"\"\"Repeats the numpy 1D array to given length, and makes datatype float\"\"\"\n    result = np.empty((length, ), dtype = 'float32')\n    l = len(arr)\n    pos = 0\n    while pos + l <= length:\n        result[pos:pos+l] = arr\n        pos += l\n    if pos < length:\n        result[pos:length] = arr[:length-pos]\n    return result","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9abd650c-ebc1-d5ae-9dbd-0417ffbea338","trusted":false},"cell_type":"code","source":"df = pd.read_csv(INPUT_LIB + 'set_a.csv')\ndf['fname'] = df['fname'].apply(clean_filename, string='Aunlabelledtest')\ndf['label'].fillna('unclassified')\ndf['time_series'] = df['fname'].apply(load_wav_file, path=INPUT_LIB + 'set_a/')    \ndf['len_series'] = df['time_series'].apply(len)\nMAX_LEN = max(df['len_series'])\ndf['time_series'] = df['time_series'].apply(repeat_to_length, length=MAX_LEN) ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3b7bfb65-be64-3c58-3cf3-cdac499de4a3"},"cell_type":"markdown","source":"## Convert data to numpy arrays\nLet's leave the unclassified files for validation, and make a training set of the others. We will zero-pad the time series at the end to make the all the same length, then collect all in 2D numpy arrays, that can be used for neural network training."},{"metadata":{"_cell_guid":"f2c182b6-d33f-a7e6-bf92-74fd546e1cd5","trusted":false},"cell_type":"code","source":"x_data = np.stack(df['time_series'].values, axis=0)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"806b3e25-65e5-842a-3be5-72b75af27530"},"cell_type":"markdown","source":"Now, as explained in another [notebook][1], I will not use the classification from new_info['target'] but instead my own labels, with three classes 0=artifact, 1=normal/extrahls, and 2=murmur.\n\n\n  [1]: https://www.kaggle.com/toregil/d/kinguistics/heartbeat-sounds/misclassified-files-in-set-a/editnb \"notebook\""},{"metadata":{"_cell_guid":"535b3480-0cbb-21cb-a7bb-6d687a4719b1","trusted":false},"cell_type":"code","source":"new_labels =[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1,\n             1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 1, 1, 2, 1, \n             2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, \n             2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, \n             1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 0, 2, 2, 1, 1, 1, 1, 1, \n             0, 1, 0, 1, 1, 1, 2, 1, 0, 1, 1, 1, 1, 1, 2, 0, 0, 0, 0, 0, 0, 0, \n             1, 0, 0, 0, 0, 0, 0, 1, 0, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\nnew_labels = np.array(new_labels, dtype='int')\ny_data = np_utils.to_categorical(new_labels)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"dda2dd6d-d6a2-0db1-3a7c-18b3d2f65c7d","trusted":false},"cell_type":"code","source":"x_train, x_test, y_train, y_test, train_filenames, test_filenames = \\\n    train_test_split(x_data, y_data, df['fname'].values, test_size=0.25)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"56def171-ceb8-45af-dd85-baff3fea46e6"},"cell_type":"markdown","source":"We now downsample the data with what is in effect a very aggressive low pass filter. This is not needed for computational time, but it seems to improve generalization on this dataset. With more data, we should remove or reduce this step and instead add 2-5 extra convolution layers. The reason this works is probably that what you hear in the stethoscope is almost exclusively low frequency sounds, especially murmurs."},{"metadata":{"_cell_guid":"a267d4df-9ddd-f866-cdd4-cff2097218f7","trusted":false},"cell_type":"code","source":"x_train = decimate(x_train, 8, axis=1, zero_phase=True)\nx_train = decimate(x_train, 8, axis=1, zero_phase=True)\nx_train = decimate(x_train, 4, axis=1, zero_phase=True)\nx_test = decimate(x_test, 8, axis=1, zero_phase=True)\nx_test = decimate(x_test, 8, axis=1, zero_phase=True)\nx_test = decimate(x_test, 4, axis=1, zero_phase=True)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"968b5f27-8fbe-77c6-2d9b-4bfd9481132e","trusted":false},"cell_type":"code","source":"#Scale each observation to unit variance, it should already have mean close to zero.\nx_train = x_train / np.std(x_train, axis=1).reshape(-1,1)\nx_test = x_test / np.std(x_test, axis=1).reshape(-1,1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"00e5e67f-4f2c-842b-4326-e28dba46a31b"},"cell_type":"markdown","source":"Keras wants the data two have a channel dimension, analogous to RGB for image recognition. Let's add this."},{"metadata":{"_cell_guid":"717c27bf-4639-e607-b9ca-e23c58ab80c1","trusted":false},"cell_type":"code","source":"x_train = x_train[:,:,np.newaxis]\nx_test = x_test[:,:,np.newaxis]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e3f3cf03-ee0e-5db8-382b-ec69ce47c7c5"},"cell_type":"markdown","source":"##Train the model"},{"metadata":{"_cell_guid":"75ca2f52-9bc3-2f65-15c6-279b31bc823c","trusted":false},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv1D(filters=4, kernel_size=9, activation='relu',\n                input_shape = x_train.shape[1:],\n                kernel_regularizer = l2(0.025)))\nmodel.add(MaxPool1D(strides=4))\nmodel.add(BatchNormalization())\nmodel.add(Conv1D(filters=4, kernel_size=9, activation='relu',\n                kernel_regularizer = l2(0.05)))\nmodel.add(MaxPool1D(strides=4))\nmodel.add(BatchNormalization())\nmodel.add(Conv1D(filters=8, kernel_size=9, activation='relu',\n                 kernel_regularizer = l2(0.1)))\nmodel.add(MaxPool1D(strides=4))\nmodel.add(BatchNormalization())\nmodel.add(Conv1D(filters=16, kernel_size=9, activation='relu'))\nmodel.add(MaxPool1D(strides=4))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\nmodel.add(Conv1D(filters=64, kernel_size=4, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Conv1D(filters=32, kernel_size=1, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.75))\nmodel.add(GlobalAvgPool1D())\nmodel.add(Dense(3, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f1551e66-8131-db8e-22f1-6f8300293adf"},"cell_type":"markdown","source":"This version of the net has 5.000 parameters, and it could easily overfit our dataset of 125 time series if we let it run too long."},{"metadata":{"_cell_guid":"7d39e984-ed9c-c3c3-1941-418fd00421c8","trusted":false},"cell_type":"code","source":"def batch_generator(x_train, y_train, batch_size):\n    \"\"\"\n    Rotates the time series randomly in time\n    \"\"\"\n    x_batch = np.empty((batch_size, x_train.shape[1], x_train.shape[2]), dtype='float32')\n    y_batch = np.empty((batch_size, y_train.shape[1]), dtype='float32')\n    full_idx = range(x_train.shape[0])\n    \n    while True:\n        batch_idx = np.random.choice(full_idx, batch_size)\n        x_batch = x_train[batch_idx]\n        y_batch = y_train[batch_idx]\n    \n        for i in range(batch_size):\n            sz = np.random.randint(x_batch.shape[1])\n            x_batch[i] = np.roll(x_batch[i], sz, axis = 0)\n     \n        yield x_batch, y_batch","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"15bf1459-d424-cf33-150d-25b13bf78fe8","trusted":false},"cell_type":"code","source":"weight_saver = ModelCheckpoint('set_a_weights.h5', monitor='val_loss', \n                               save_best_only=True, save_weights_only=True)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"595b4563-28a1-b467-c078-d2e5f00dd426","trusted":false},"cell_type":"code","source":"model.compile(optimizer=Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\nannealer = LearningRateScheduler(lambda x: 1e-4 * 0.8**x)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f5a1e08c-d013-e145-8037-a5381bc379ab","trusted":false},"cell_type":"code","source":"hist = model.fit_generator(batch_generator(x_train, y_train, 8),\n                   epochs=30, steps_per_epoch=1000,\n                   validation_data=(x_test, y_test),\n                   callbacks=[weight_saver, annealer],\n                   verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"37c61291-51d4-3441-2e11-8708bef2051c"},"cell_type":"markdown","source":"Let's bring back the best weights, in case we overfitted."},{"metadata":{"_cell_guid":"d4767dbc-923a-0677-eb54-842bb3f077d3","trusted":false},"cell_type":"code","source":"model.load_weights('set_a_weights.h5')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"14b1b34a-d6c1-b015-9395-f582b6b1b5cc"},"cell_type":"markdown","source":"## Evaluation"},{"metadata":{"_cell_guid":"d4172b5d-bc2d-9c01-2f7c-8956047a6596","trusted":false},"cell_type":"code","source":"plt.plot(hist.history['loss'], color='b')\nplt.plot(hist.history['val_loss'], color='r')\nplt.show()\nplt.plot(hist.history['acc'], color='b')\nplt.plot(hist.history['val_acc'], color='r')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"85a84d48-2357-8f7f-1598-c27108ff539e","trusted":false},"cell_type":"code","source":"y_hat = model.predict(x_test)\nnp.set_printoptions(precision=2, suppress=True)\nfor i in range(3):\n    plt.plot(y_hat[:,i], c='r')\n    plt.plot(y_test[:,i], c='b')\n    plt.show()\n    print(CLASSES[i])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"26f8f49d-79d2-7430-f04f-895598e9047d","trusted":false},"cell_type":"code","source":"y_pred = np.argmax(y_hat, axis=1)\ny_true = np.argmax(y_test, axis=1)\nfor i in range(len(y_true)):\n    if y_pred[i] != y_true[i]:\n        print(\"File: {}, Pred: {}, True: {}\".format(\n            test_filenames[i],\n            CLASSES[y_pred[i]], CLASSES[y_true[i]]))\n        plt.plot(x_test[i])\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0b44d7f7-9df9-eeed-7ec1-8a9cc38508ec"},"cell_type":"markdown","source":"Not too bad. It found the artifacts and the mistakes were non-obvious ones.   If this dataset really comes from an iPhone app, it is truly impressive.\n\n I'd be really grateful if someone could double check my labelling, both on training and test set. Check the \"New labels for set A\" [notebook][1].\n\n\n  [1]: https://www.kaggle.com/toregil/d/kinguistics/heartbeat-sounds/new-labels-for-set-a"},{"metadata":{"_cell_guid":"7b7a673b-b8dc-52a8-4fd9-bb7c6c4c0681"},"cell_type":"markdown","source":"I'll be back with an analysis of set B."},{"metadata":{"_cell_guid":"71120b26-32d4-ff9e-828b-5b082796b118","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"544aaf9e-fe32-51e9-fef0-b8daeaba9f80","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}