{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom scipy import sparse\nfrom scipy.sparse import csr_matrix\nfrom sklearn.metrics import pairwise_distances\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data generation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# path=[]\n# for i in range(1,5):\n#     file='../input/netflix-prize-data/combined_data_'+str(i)+'.txt'\n#     path.append(file)\n# path","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# if not os.path.isfile('data.csv'):\n#     # Create a file 'data.csv' before reading it\n#     # Read all the files in netflix and store them in one big file('data.csv')\n#     # We re reading from each of the four files and appendig each rating to a global file 'train.csv'\n#     data = open('data.csv', mode='w')\n    \n#     row = list()\n#     files=path\n#     for file in files:\n#         print(\"Reading ratings from {}...\".format(file))\n#         with open(file) as f:\n#             for line in f: \n#                 del row[:] # you don't have to do this.\n#                 line = line.strip()\n#                 if line.endswith(':'):\n#                     # All below are ratings for this movie, until another movie appears.\n#                     movie_id = line.replace(':', '')\n#                 else:\n#                     row = [x for x in line.split(',')]\n#                     row.insert(0, movie_id)\n#                     data.write(','.join(row))\n#                     data.write('\\n')\n#         print(\"Done.\\n\")\n#     data.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# path=[]\n# for i in range(1,5):\n#     file='../input/netflix-prize-data/combined_data_'+str(i)+'.txt'\n#     path.append(file)\n# path","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# if not os.path.isfile('data.csv'):\n#     # Create a file 'data.csv' before reading it\n#     # Read all the files in netflix and store them in one big file('data.csv')\n#     # We re reading from each of the four files and appendig each rating to a global file 'train.csv'\n#     data = open('data.csv', mode='w')\n    \n#     row = list()\n#     files=path\n#     for file in files:\n#         print(\"Reading ratings from {}...\".format(file))\n#         with open(file) as f:\n#             for line in f: \n#                 del row[:] # you don't have to do this.\n#                 line = line.strip()\n#                 if line.endswith(':'):\n#                     # All below are ratings for this movie, until another movie appears.\n#                     movie_id = line.replace(':', '')\n#                 else:\n#                     row = [x for x in line.split(',')]\n#                     row.insert(0, movie_id)\n#                     data.write(','.join(row))\n#                     data.write('\\n')\n#         print(\"Done.\\n\")\n#     data.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from scipy import sparse\n# from scipy.sparse import csr_matrix\n# train=pd.read_csv('./data.csv',sep=',',names=['movies','user','rating','timestamp'])\n# sparse.save_npz('sparse movie-user.npz',csr_matrix((train.rating.values,(train.movies.values,train.user.values))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Mf techniques","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# NMF","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import NMF\ndata=sparse.load_npz('../input/netflix-movie-prediciton-using-mf/sparse movie-user.npz')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"components=12\nnmf=NMF(n_components=components,init='random',random_state=42,alpha=0.1,l1_ratio=1e-5)\nW=nmf.fit_transform(data)# [rows(movies),components] using this you can find movie movie similarity","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movies=pd.read_csv('../input/netflix-prize-data/movie_titles.csv', encoding = \"ISO-8859-1\", header = None, names = ['Movie_Id', 'Year', 'Name'])\nmovies.set_index('Movie_Id',inplace=True)\nmovies.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# POC","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('data shape:',data.shape,'movie_vector_shape :',W.shape)\nquery_movie=27# the movie for which you want recommendation\nno_results=5# no of recommendations\nprint('These movies are recommended beacuse you watched :',movies.loc[query_movie,'Name'])\npairwise_dist=pairwise_distances(W,W[query_movie].reshape(1,-1))\nindices=np.argsort(pairwise_dist.flatten())[:no_results]\ndist=np.sort(pairwise_dist.flatten())[:no_results]\nfor i in indices:\n    print(movies['Name'].loc[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"H=nmf.components_# [components,cols(users)] using this you can find user-user similarity \n# have not calculated user-user similarity because that' useless at this point of time","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transformed_data=np.matmul(W,H)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}