{"cells":[{"metadata":{},"cell_type":"markdown","source":"This is My first EDA Notebook , So give a comment if i have done any mistakes in this EDA. \nYour client is an Insurance company that has provided Health Insurance to its customers now they need your help in building a model to predict whether the policyholders (customers) from past year will also be interested in Vehicle Insurance provided by the company."},{"metadata":{},"cell_type":"markdown","source":"## *Hypothesis*\n* Are customers with **low annual premium**,   **Interested** in insurance ?  \n* Are **vintage customers** intersted in insurance?\n* Are **Licensed customers** **interested** in insurance\n* Are customers **interested** in insurance  **when vehicle has a damage**\n* Are Customers **interested** in insurance when **vehicle age <1 year(new bike)**\n* Are **previously insured** customers, **not interested** in insurance\n"},{"metadata":{},"cell_type":"markdown","source":"# Exploratory  Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# load the libraries\nimport pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler,OneHotEncoder\nfrom sklearn.model_selection import StratifiedKFold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# read data\nrawdf = pd.read_csv(\"/kaggle/input/health-insurance-cross-sell-prediction/train.csv\")\ntest  = pd.read_csv(\"/kaggle/input/health-insurance-cross-sell-prediction/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#see the head of data\nrawdf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Varriable Identification and TypeCasting"},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the data types of all features\nrawdf.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Integer Data type"},{"metadata":{"trusted":true},"cell_type":"code","source":"#get integer data types\nrawdf.dtypes[rawdf.dtypes==\"int64\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Driving_License, Previously_Insured,Response is a categorical varriable so we convert it into category\nrawdf[\"Driving_License\"] = rawdf[\"Driving_License\"].astype(\"category\") \nrawdf[\"Previously_Insured\"] = rawdf[\"Previously_Insured\"].astype(\"category\") \nrawdf[\"Driving_License\"] = rawdf[\"Driving_License\"].astype(\"category\") \nrawdf[\"Response\"] = rawdf[\"Response\"].astype(\"category\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Float data type"},{"metadata":{"trusted":true},"cell_type":"code","source":"# get float data types \nrawdf.dtypes[rawdf.dtypes == \"float64\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Region code , Policy Sales Channel are categorical varriables\nrawdf[\"Region_Code\"] = rawdf[\"Region_Code\"].astype(\"category\")\nrawdf[\"Policy_Sales_Channel\"] = rawdf[\"Policy_Sales_Channel\"].astype(\"category\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Object data type"},{"metadata":{"trusted":true},"cell_type":"code","source":"#vehicle age and vehicle damage is object varriable\nrawdf.dtypes[rawdf.dtypes==\"object\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# gender, vehicle age , vehicle damage are categorical varriables\nrawdf[\"Gender\"] = rawdf[\"Gender\"].astype(\"category\")\nrawdf[\"Vehicle_Age\"] = rawdf[\"Vehicle_Age\"].astype(\"category\")\nrawdf[\"Vehicle_Damage\"] = rawdf[\"Vehicle_Damage\"].astype(\"category\")","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# check all features data types after conversion\nrawdf.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Univariate Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# describe of all numeric values\nrawdf.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Univariate Analysis Integer"},{"metadata":{"trusted":true},"cell_type":"code","source":"def UVA_numeric(data, var_group):\n  ''' \n  Univariate_Analysis_numeric\n  takes a group of variables (INTEGER and FLOAT) and plot/print all the descriptives and properties along with KDE.\n\n  Runs a loop: calculate all the descriptives of i(th) variable and plot/print it\n  '''\n\n  size = len(var_group)\n  plt.figure(figsize = (7*size,3), dpi = 100)\n  \n  #looping for each variable\n  for j,i in enumerate(var_group):\n    \n    # calculating descriptives of variable\n    mini = data[i].min()\n    maxi = data[i].max()\n    ran = data[i].max()-data[i].min()\n    mean = data[i].mean()\n    median = data[i].median()\n    st_dev = data[i].std()\n    skew = data[i].skew()\n    kurt = data[i].kurtosis()\n\n    # calculating points of standard deviation\n    points = mean-st_dev, mean+st_dev\n\n    #Plotting the variable with every information\n    plt.subplot(1,size,j+1)\n    sns.kdeplot(data[i], shade=True)\n    sns.lineplot(points, [0,0], color = 'black', label = \"std_dev\")\n    sns.scatterplot([mini,maxi], [0,0], color = 'orange', label = \"min/max\")\n    sns.scatterplot([mean], [0], color = 'red', label = \"mean\")\n    sns.scatterplot([median], [0], color = 'blue', label = \"median\")\n    plt.xlabel('{}'.format(i), fontsize = 20)\n    plt.ylabel('density')\n    plt.title('std_dev = {}; kurtosis = {};\\nskew = {}; range = {}\\nmean = {}; median = {}'.format((round(points[0],2),round(points[1],2)),\n                                                                                                   round(kurt,2),\n                                                                                                   round(skew,2),\n                                                                                                   (round(mini,2),round(maxi,2),round(ran,2)),\n                                                                                                   round(mean,2),\n                                                                                                   round(median,2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get numeric varriables\nrawdf.select_dtypes(include=['int64','float64','Int64']).dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Segregating varriables into groups\ncustomer_details = [\"Age\",\"Vintage\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"UVA_numeric(rawdf,customer_details)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"UVA_numeric(rawdf,[\"Annual_Premium\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### summary\n* Most of the customers Age between 20 to 30 and 40 to 50 some peak there.\n* vintage is normaly distributed. Average vintage value is 150\n* Annual Premium is Highly skewed and also more kurtosis value so it has a extreme outliers "},{"metadata":{},"cell_type":"markdown","source":"### Univariate Analysis - Category"},{"metadata":{"trusted":true},"cell_type":"code","source":"def UVA_category(data, var_group):\n\n  '''\n  Univariate_Analysis_categorical\n  takes a group of variables (category) and plot/print all the value_counts and barplot.\n  '''\n  # setting figure_size\n  size = len(var_group)\n  plt.figure(figsize = (7*size,5), dpi = 100)\n\n  # for every variable\n  for j,i in enumerate(var_group):\n    n_uni = data[i].nunique()\n    if n_uni > 20:\n        norm_count1 = data[i].value_counts(normalize = True)\n        norm_count = norm_count1.sort_values().tail(20) \n    else:\n        norm_count = data[i].value_counts(normalize = True)\n    \n\n  #Plotting the variable with every information\n    plt.subplot(1,size,j+1)\n    sns.barplot(norm_count, norm_count.index , order = norm_count.index)\n    plt.xlabel('fraction/percent', fontsize = 20)\n    plt.ylabel('{}'.format(i), fontsize = 20)\n    plt.title('n_uniques = {} \\n value counts \\n {};'.format(n_uni,norm_count))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rawdf.select_dtypes(include=[\"category\"]).dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# top 53 region code are taken\nUVA_category(rawdf,[\"Gender\",\"Driving_License\",\"Region_Code\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### summary\n* Male customers higher than Female\n* 99 % customers has a License\n* Region Code 28 has a high number of customers\n* Region Code 8, 46, 41 has a second high number of customers"},{"metadata":{"trusted":true},"cell_type":"code","source":"UVA_category(rawdf,[\"Vehicle_Age\",\"Vehicle_Damage\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### summary\n* 95% Vechicle's age \"within 2 years\"\n* Vehicle Damage is equally splitted"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"UVA_category(rawdf,[\"Policy_Sales_Channel\",\"Previously_Insured\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### summary\n* Most used ploicy sales channel code(152,26,124,160,156,122,157,154)\n* Previously Insured people was less"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"UVA_category(rawdf,[\"Response\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"markdown","source":"#### summary\n* Most of the customers not interested in insurance\n* 99% customers are licensed  and 87% customers are not interested in insurance. so hyposthesis \" **licensed customer** **interested** in insurance\" is false   \n* Imbalanced target Varriable "},{"metadata":{},"cell_type":"markdown","source":"# Univariate - Missing Values and Outlier Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"rawdf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# custom function for easy outlier analysis\n\ndef UVA_outlier(data, var_group, include_outlier = True):\n  '''\n  Univariate_Analysis_outlier:\n  takes a group of variables (INTEGER and FLOAT) and plot/print boplot and descriptives\\n\n  Runs a loop: calculate all the descriptives of i(th) variable and plot/print it \\n\\n\n\n  data : dataframe from which to plot from\\n\n  var_group : {list} type Group of Continuous variables\\n\n  include_outlier : {bool} whether to include outliers or not, default = True\\n\n  '''\n\n  size = len(var_group)\n  plt.figure(figsize = (7*size,4), dpi = 100)\n  \n  #looping for each variable\n  for j,i in enumerate(var_group):\n    \n    # calculating descriptives of variable\n    quant25 = data[i].quantile(0.25)\n    quant75 = data[i].quantile(0.75)\n    IQR = quant75 - quant25\n    med = data[i].median()\n    whis_low = med-(1.5*IQR)\n    whis_high = med+(1.5*IQR)\n\n    # Calculating Number of Outliers\n    outlier_high = len(data[i][data[i]>whis_high])\n    outlier_low = len(data[i][data[i]<whis_low])\n\n    if include_outlier == True:\n      #Plotting the variable with every information\n      plt.subplot(1,size,j+1)\n      sns.boxplot(data[i], orient=\"v\")\n      plt.ylabel('{}'.format(i))\n      plt.title('With Outliers\\nIQR = {}; Median = {} \\n 2nd,3rd  quartile = {};\\n Outlier (low/high) = {} \\n'.format(\n                                                                                                   round(IQR,2),\n                                                                                                   round(med,2),\n                                                                                                   (round(quant25,2),round(quant75,2)),\n                                                                                                   (outlier_low,outlier_high)\n                                                                                                   ))\n      \n    else:\n      # replacing outliers with max/min whisker\n      data2 = data[var_group][:]\n      data2[i][data2[i]>whis_high] = whis_high+1\n      data2[i][data2[i]<whis_low] = whis_low-1\n      \n      # plotting without outliers\n      plt.subplot(1,size,j+1)\n      sns.boxplot(data2[i], orient=\"v\")\n      plt.ylabel('{}'.format(i))\n      plt.title('Without Outliers\\nIQR = {}; Median = {} \\n 2nd,3rd  quartile = {};\\n Outlier (low/high) = {} \\n'.format(\n                                                                                                   round(IQR,2),\n                                                                                                   round(med,2),\n                                                                                                   (round(quant25,2),round(quant75,2)),\n                                                                                                   (outlier_low,outlier_high)\n                                                                                                   ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"UVA_outlier(rawdf,[\"Annual_Premium\",\"Age\",\"Vintage\"] )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### summary\n* Annual premium has a extreme outlier"},{"metadata":{},"cell_type":"markdown","source":"# Bivariate Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_data = rawdf.select_dtypes(include=[\"int64\",\"Int64\",\"float64\"])\nnumerical_data.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting heatmap usill all methods for all transaction variables\nplt.figure(figsize=(36,6), dpi=140)\nfor j,i in enumerate(['pearson']):\n  plt.subplot(1,3,j+1)\n  correlation = numerical_data.dropna().corr(method=i)\n  sns.heatmap(correlation, linewidth = 2)\n  plt.title(i, fontsize=18)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### summary\n\n* Features dont have a strong correlation\n\n"},{"metadata":{},"cell_type":"markdown","source":"### ScatterPlot"},{"metadata":{"trusted":true},"cell_type":"code","source":"# scatter plot for all numerical varriables\nplt.figure(dpi=140)\nsns.pairplot(numerical_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Bivariate Analysis: Continuous-Categorical variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"def TwoSampZ(X1, X2, sigma1, sigma2, N1, N2):\n  '''\n  takes mean, standard deviation, and number of observations and returns p-value calculated for 2-sampled Z-Test\n  '''\n  from numpy import sqrt, abs, round\n  from scipy.stats import norm\n  ovr_sigma = sqrt(sigma1**2/N1 + sigma2**2/N2)\n  z = (X1 - X2)/ovr_sigma\n  pval = 2*(1 - norm.cdf(abs(z)))\n  return pval","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def TwoSampT(X1, X2, sd1, sd2, n1, n2):\n  '''\n  takes mean, standard deviation, and number of observations and returns p-value calculated for 2-sample T-Test\n  '''\n  from numpy import sqrt, abs, round\n  from scipy.stats import t as t_dist\n  ovr_sd = sqrt(sd1**2/n1 + sd2**2/n2)\n  t = (X1 - X2)/ovr_sd\n  df = n1+n2-2\n  pval = 2*(1 - t_dist.cdf(abs(t),df))\n  return pval","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Bivariate_cont_cat(data, cont, cat, category):\n  #creating 2 samples\n  x1 = data[cont][data[cat]==category][:]\n  x2 = data[cont][~(data[cat]==category)][:]\n  \n  #calculating descriptives\n  n1, n2 = x1.shape[0], x2.shape[0]\n  m1, m2 = x1.mean(), x2.mean()\n  std1, std2 = x1.std(), x2.mean()\n  \n  #calculating p-values\n  t_p_val = TwoSampT(m1, m2, std1, std2, n1, n2)\n  z_p_val = TwoSampZ(m1, m2, std1, std2, n1, n2)\n\n  #table\n  table = pd.pivot_table(data=data, values=cont, columns=cat, aggfunc = np.mean)\n\n  #plotting\n  plt.figure(figsize = (15,6), dpi=140)\n  \n  #barplot\n  plt.subplot(1,2,1)\n  sns.barplot([str(category),'not {}'.format(category)], [m1, m2])\n  plt.ylabel('mean {}'.format(cont))\n  plt.xlabel(cat)\n  plt.title('t-test p-value = {} \\n z-test p-value = {}\\n {}'.format(t_p_val,\n                                                                z_p_val,\n                                                                table))\n\n  # boxplot\n  plt.subplot(1,2,2)\n  sns.boxplot(x=cat, y=cont, data=data)\n  plt.title('categorical boxplot')\n  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Are **vintage customers** interested in insurance?"},{"metadata":{"trusted":true},"cell_type":"code","source":"Bivariate_cont_cat(rawdf, 'Vintage', 'Response', 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"markdown","source":"### summary\n* No significant difference in vintage customers . so reject this hypothesis \n* both interested and no interested customers mean vintage is approxiamately same. no significant difference is there.so vintage has no impact on customer interest\n* No outliers "},{"metadata":{},"cell_type":"markdown","source":"### Are aged customers interested in insurance?"},{"metadata":{"trusted":true},"cell_type":"code","source":"Bivariate_cont_cat(rawdf, 'Age', 'Response', 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ### Inference\n * Interested Customers age between 35 to 52.\n * Uninterested Customers age between 25 to 48.\n * p-value of z and t tests  is 0 , so significant difference there. It indicates age makes a impact on customer interest\n \n "},{"metadata":{},"cell_type":"markdown","source":"### Are customers with **low annual premium**,   **Interested** in insurance ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"Bivariate_cont_cat(rawdf, 'Annual_Premium', 'Response', 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Inference\n* Annual premium mean for interested customer is 30419\n* Annual premium mean for not interested customer is 31604\n* Annual Premium makes impact on customer interest\n"},{"metadata":{},"cell_type":"markdown","source":"## Bivariate Analysis(categorical categorical)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def BVA_categorical_plot(data, tar, cat):\n  '''\n  take data and two categorical variables,\n  calculates the chi2 significance between the two variables \n  and prints the result with countplot & CrossTab\n  '''\n  #isolating the variables\n  data = data[[cat,tar]][:]\n\n  #forming a crosstab\n  table = pd.crosstab(data[tar],data[cat],)\n  f_obs = np.array([table.iloc[0][:].values,\n                    table.iloc[1][:].values])\n\n  #performing chi2 test\n  from scipy.stats import chi2_contingency\n  chi, p, dof, expected = chi2_contingency(f_obs)\n  \n  #checking whether results are significant\n  if p<0.05:\n    sig = True\n  else:\n    sig = False\n\n  #plotting grouped plot\n  sns.countplot(x=cat, hue=tar, data=data)\n  plt.title(\"p-value = {}\\n difference significant? = {}\\n\".format(round(p,8),sig))\n\n  #plotting percent stacked bar plot\n#   sns.catplot(ax, kind='stacked')\n  ax1 = data.groupby(cat)[tar].value_counts(normalize=True).unstack()\n  ax1.plot(kind='bar', stacked='True',title=str(ax1))\n  int_level = data[cat].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Are licensed customer has a more interest?"},{"metadata":{"trusted":true},"cell_type":"code","source":"BVA_categorical_plot(rawdf, \"Response\",\"Driving_License\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Inference\n* significant differnece is there.But 99%(univariate analysis) customers has a license, In that only 1 % customers are interested others are not interested  "},{"metadata":{"trusted":true},"cell_type":"code","source":"BVA_categorical_plot(rawdf, \"Response\",\"Previously_Insured\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Inference\n* Previously Insured customers not interested in insurance"},{"metadata":{"trusted":true},"cell_type":"code","source":"BVA_categorical_plot(rawdf, \"Response\",\"Vehicle_Damage\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Inference\n* Vehicle damaged customers has a interest in insurance "},{"metadata":{"trusted":true},"cell_type":"code","source":"BVA_categorical_plot(rawdf, \"Response\",\"Vehicle_Age\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Inference\n* Overall vehicle Age 1-2 year category , interested customer's count is high.but\n* In >2 year Age category, Interested customers percentage is high when compared to other category   "},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"BVA_categorical_plot(rawdf, \"Response\",\"Gender\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Male customers has more interest in insurance. "},{"metadata":{},"cell_type":"markdown","source":"### Bivariate Analysis - Policy_Sales_Channel vs Response"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sales Channel wise Total Customers Count\npsc_total = rawdf.groupby(\"Policy_Sales_Channel\")[\"Response\"].count()\\\n                          .reset_index(name='count') \\\n                             .sort_values(['count'], ascending=False)\npsc_total","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### summary\n* In univarite Analysis, Already we have seen Policy sales channel 152 has a more entry"},{"metadata":{"trusted":true},"cell_type":"code","source":"# filter interested customers count \nFormattedData = rawdf[rawdf[\"Response\"]==1].groupby(\"Policy_Sales_Channel\")[\"Response\"].count()\\\n                          .reset_index(name='count') \\\n                             .sort_values(['count'], ascending=False) \n\nFormattedData[\"total_count\"] = psc_total[\"count\"]\nFormattedData[\"success_rate\"] = (FormattedData[\"count\"]/FormattedData[\"total_count\"])*100 \nFormattedData[FormattedData[\"total_count\"]>500].sort_values(\"success_rate\",ascending=False).head(50)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### summary\n* policy sales channel 155 has high success rate(32%) when compared to other channels.\n* policy sales channel 26 has a more intersted customers. but success rate is 19%\n"},{"metadata":{},"cell_type":"markdown","source":"### Bivariate Analysis(Region_code vs Response)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sales Channel wise Total Customers Count\npsc_total = rawdf.groupby(\"Region_Code\")[\"Response\"].count()\\\n                          .reset_index(name='count') \\\n                             .sort_values(['count'], ascending=False)\npsc_total.head(25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# filter interested customers count \nFormattedData = rawdf[rawdf[\"Response\"]==1].groupby(\"Region_Code\")[\"Response\"].count()\\\n                          .reset_index(name='count') \\\n                             .sort_values(['count'], ascending=False) \n\nFormattedData[\"total_count\"] = psc_total[\"count\"]\nFormattedData[\"success_rate\"] = (FormattedData[\"count\"]/FormattedData[\"total_count\"])*100 \nFormattedData[FormattedData[\"total_count\"]>500].sort_values(\"success_rate\",ascending=False).head(25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FormattedData[FormattedData[\"total_count\"]>10000].sort_values(\"success_rate\",ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# average success rate is less\nFormattedData[\"success_rate\"].mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### summary\n*  High total customers and succes rate place code is 28\n*  low success rate and high customers count, places(50,15,30,8,9) \n* Region code affects the customer interest but average success rate of all region is less."},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering and Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = rawdf\ntrainY = rawdf[\"Response\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nnum_feature = [\"Age\",\"Vintage\",\"Annual_Premium\"]\ncat_feature = [\"Gender\",\"Driving_License\",\"Region_Code\",\"Previously_Insured\",\"Vehicle_Age\",\"Vehicle_Damage\",\"Policy_Sales_Channel\"]\ntrain[\"Age_Cat\"]= pd.cut(train[\"Age\"],bins=[10,20,30,40,50,60,70,80,90,100],labels=[1,2,3,4,5,6,7,8,9])\ntrain[\"Policy_Sales_Channel\"] = train[\"Policy_Sales_Channel\"].astype(\"int\")\ntrain[\"Region_Code\"] = train[\"Region_Code\"].astype(\"int\")\n\nohe = OneHotEncoder(sparse=False)        \ntransformed_train_data = ohe.fit_transform(train[[\"Age_Cat\",\"Gender\",\"Vehicle_Age\",\"Previously_Insured\",\"Driving_License\",\"Vehicle_Damage\"]])\n\n# # the above transformed_data is an array so convert it to dataframe\nencoded_train_data = pd.DataFrame(transformed_train_data, index=train.index)        \ntrain_data = pd.concat([train, encoded_train_data], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainX = train_data.drop([\"id\",\"Age\",\"Age_Cat\",\"Gender\",\"Vehicle_Age\",\"Driving_License\",\"Previously_Insured\",\"Vehicle_Damage\",\"Response\"], axis=1)\ntrainX.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import roc_auc_score,confusion_matrix\nlogreg = LogisticRegression(random_state=0)\nmodels = {\n    \"Logistic Regression\":logreg,\n#     \"RandomForestClassifier\":rf\n}\nfeatures = [\"Gender\",\"Driving_License\",\"Previously_Insured\",\"Vehicle_Age\",\"Vehicle_Damage\"]\nskf = StratifiedKFold(n_splits=5, shuffle=True)\nfor model_name,model in models.items():\n    scores = []\n    train_scores = []\n    for train_indx,val_indx in skf.split(X=trainX,y=trainY):\n        #get train and test data     \n        X_train,X_val = trainX.loc[train_indx],trainX.loc[val_indx]\n        Y_train,Y_val = trainY[train_indx],trainY[val_indx]\n        sc = StandardScaler()\n        train_sc = sc.fit_transform(X_train)\n        val_sc  = sc.fit_transform(X_val)\n        #train a model\n        model.fit(train_sc,Y_train)\n        #make a prediction\n        Y_predict = model.predict_proba(val_sc)\n        accuracy = roc_auc_score(Y_val,Y_predict[:,1])\n        Ytrain_predict = model.predict_proba(train_sc)\n        train_accuracy = roc_auc_score(Y_train,Ytrain_predict[:,1])        \n        print(\"train\",train_accuracy)\n        print(\"test\",accuracy)\n        scores.append(accuracy)\n        train_scores.append(train_accuracy)\n    print(\"Mean Accurracy of test {0} is {1}\".format(model_name,np.mean(scores)))\n    print(\"Mean Accurracy of train {0} is {1}\".format(model_name,np.mean(train_scores)))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntest[\"Age_Cat\"]= pd.cut(test[\"Age\"],bins=[10,20,30,40,50,60,70,80,90,100],labels=[1,2,3,4,5,6,7,8,9])\ntest[\"Policy_Sales_Channel\"] = test[\"Policy_Sales_Channel\"].astype(\"int\")\ntest[\"Region_Code\"] = test[\"Region_Code\"].astype(\"int\")\n\nohe = OneHotEncoder(sparse=False)        \ntransformed_test_data = ohe.fit_transform(test[[\"Age_Cat\",\"Gender\",\"Vehicle_Age\",\"Previously_Insured\",\"Driving_License\",\"Vehicle_Damage\"]])\n\n# # the above transformed_data is an array so convert it to dataframe\nencoded_test_data = pd.DataFrame(transformed_test_data, index=test.index)        \ntest_data = pd.concat([test, encoded_test_data], axis=1)\ntestX = test_data.drop([\"id\",\"Age\",\"Age_Cat\",\"Gender\",\"Vehicle_Age\",\"Previously_Insured\",\"Driving_License\",\"Vehicle_Damage\"],axis=1)\nsc = StandardScaler()\ntestt = sc.fit_transform(testX)\n#predict\npredictions = logreg.predict(testt)\noutput = pd.DataFrame({'id': test.id, 'Response': predictions})\nprint(output[\"Response\"].value_counts())\noutput.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}