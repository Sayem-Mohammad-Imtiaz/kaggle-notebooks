{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) \nimport pandas as pd\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Read Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/Tweets.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Analysis\n## Some Insights"},{"metadata":{"trusted":true},"cell_type":"code","source":"sentiment_counts = df.airline_sentiment.value_counts()\nnumber_of_tweets = df.tweet_id.count()\nprint(sentiment_counts)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dff = df.groupby([\"airline\", \"airline_sentiment\" ]).count()[\"name\"]\ndff['American']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Converting sentiments of indivual airline into percentages"},{"metadata":{"trusted":true},"cell_type":"code","source":"airlines=df.airline.unique()\npositive_percentage = []\nnegative_percentage = []\nneutral_percentage = []\nfor i in airlines:\n    positive_percentage.append((dff[i].positive/dff[i].sum())*100)\n    negative_percentage.append((dff[i].negative/dff[i].sum())*100)\n    neutral_percentage.append((dff[i].neutral/dff[i].sum())*100)\npercentage_data = [positive_percentage,negative_percentage,neutral_percentage]\npercentage_data = np.array(percentage_data)\npercentage_data=percentage_data.reshape(6,3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_series = pd.DataFrame(data=percentage_data, index =airlines)\nmy_series[0] = positive_percentage\nmy_series[1] = negative_percentage\nmy_series[2] = neutral_percentage\nmy_series","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Chart displays the sentiment of each airline in percentage"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.style\n%matplotlib inline\nimport matplotlib.style\nfrom matplotlib.pyplot import subplots\n\nfig, ax = subplots()\nmy_colors =['blue','red','green']\nmy_series.plot(kind='bar', stacked=False, ax=ax, color=my_colors, figsize=(14, 7), width=0.8)\nax.legend([\"Postive Percentage\",\"Negative Percentage\",\"Neutral Percentage\"])\nplt.title(\"Percentages of Sentiments, Tweets Sentiments Analysis Airlines, 2017\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"## As we are interested in only 2 columns for our purpose of classfication, we are taking subset of whole data frame"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = df[['text','airline_sentiment']]\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Converting labels into integers \n### neutral = 0\n### positive = 1\n### negative = 2"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.loc[:,('airline_sentiment')] = data.airline_sentiment.map({'neutral':0, 'positive':1,'negative':2})\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Seperating rows based on their labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"positive_sentiment_words = ''\nnegative_sentiment_words = ''\nneutral_sentiment_words = ''\nneutral = data[data.airline_sentiment == 0]\npositive = data[data.airline_sentiment ==1]\nnegative = data[data.airline_sentiment ==2]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tokenizing, Lematizing and removing stop words from data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk,re\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\n\nstop_words = set(stopwords.words('english'))\nwordnet_lemmatizer = WordNetLemmatizer()\nfor val in neutral.text:\n    text = val.lower()\n    only_letters = re.sub(\"[^a-zA-Z]\", \" \",text) \n    tokens = nltk.word_tokenize(only_letters )[2:]\n    for word in tokens:\n        if word not in stop_words:\n            word = wordnet_lemmatizer.lemmatize(word)\n            neutral_sentiment_words =  neutral_sentiment_words + word + ' '\n            \nfor val in positive.text:\n    text = val.lower()\n    only_letters = re.sub(\"[^a-zA-Z]\", \" \",text) \n    tokens = nltk.word_tokenize(only_letters )[2:]\n    for word in tokens:\n        if word not in stop_words:\n            word = wordnet_lemmatizer.lemmatize(word)\n            positive_sentiment_words =  positive_sentiment_words + word + ' '\n            \nfor val in negative.text:\n    text = val.lower()\n    only_letters = re.sub(\"[^a-zA-Z]\", \" \",text) \n    tokens = nltk.word_tokenize(only_letters )[2:]\n    for word in tokens:\n        if word not in stop_words:\n            word = wordnet_lemmatizer.lemmatize(word)\n            negative_sentiment_words =  negative_sentiment_words + word + ' '\n            \n            \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# WordCloud"},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud\nneutral_wordcloud = WordCloud(width=600, height=400).generate(neutral_sentiment_words)\npositive_wordcloud = WordCloud(width=600, height=400).generate(positive_sentiment_words)\nnegative_wordcloud = WordCloud(width=600, height=400).generate(negative_sentiment_words)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Neutral Sentiments Wordcloud"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure( figsize=(10,8), facecolor='k')\nplt.imshow(neutral_wordcloud)\nplt.axis(\"off\")\nplt.tight_layout(pad=0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Positive Sentiments WordCloud"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure( figsize=(10,8), facecolor='k')\nplt.imshow(positive_wordcloud)\nplt.axis(\"off\")\nplt.tight_layout(pad=0)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Negative Sentiments WordCloud"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure( figsize=(10,8), facecolor='k')\nplt.imshow(negative_wordcloud)\nplt.axis(\"off\")\nplt.tight_layout(pad=0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classification"},{"metadata":{},"cell_type":"markdown","source":"## Converting sentences into vectors in order to feed it to Naive Bayes and SVM\n## Splitting data into training and test data ( test_size = 0.2 )"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report\ndata['text'] = data['text'].apply(lambda x: x.lower())\ndata['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\nX_train,X_test,y_train,y_test = train_test_split(data[\"text\"],data[\"airline_sentiment\"], test_size = 0.2, random_state = 10)\nprint(\"train tuples\",X_train.shape)\nprint(\"test tuples\",X_test.shape)\nprint(\"train labels\",y_train.shape)\nprint(\"test labels\",y_test.shape)\nvect = CountVectorizer()\nvect.fit(X_train)\nX_train_df = vect.transform(X_train)\nX_test_df = vect.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model 1 - Naive Bayes"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nmodel = MultinomialNB()\nmodel.fit(X_train_df,y_train)\nresult=model.predict(X_test_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Accuracy = 76.09%"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy Score:\",accuracy_score(y_test,result))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model 2 - SVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import svm\nclf = svm.SVC(kernel='rbf')\nclf.fit(X_train_df,y_train)\nresult=clf.predict(X_test_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Accuracy = 60.82%"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy Score:\",accuracy_score(y_test,result))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model 3 - LSTM"},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Embedding, LSTM, SpatialDropout1D\nfrom keras.callbacks import ModelCheckpoint\nimport os\nfrom sklearn.metrics import roc_auc_score\nfrom keras.preprocessing.text import Tokenizer\nmax_fatures = 2000\ntokenizer = Tokenizer(num_words=max_fatures, split=' ')\ntokenizer.fit_on_texts(data['text'].values)\nX = tokenizer.texts_to_sequences(data['text'].values)\nX = pad_sequences(X)\n\nembed_dim = 128\nlstm_out = 196\n\nmodel = Sequential()\nmodel.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1]))\nmodel.add(Dropout(0.5))\nmodel.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\nmodel.add(Dense(3,activation='softmax'))\nmodel.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\nprint(model.summary())\n\nY = pd.get_dummies(data['airline_sentiment']).values\nX_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.2, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fitting Model\n### Accuracy Achieved = 81.11%"},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 256\nhistory = model.fit(X_train, \n                    Y_train, \n                    epochs = 10, \n                    batch_size=batch_size, \n                    validation_data=(X_test, Y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model 3 - Accuracy Graph"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Results"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"models = ['Naive Bayes','SVM','LSTM']\naccuracy = [76.09,60.82,81.11]\nresult_frame = pd.DataFrame(data = accuracy,index = models)\n\nfig, ax = subplots()\nmy_colors =['blue','red','green']\nresult_frame.plot(kind='bar', stacked=False, ax=ax, color=my_colors, figsize=(12, 4), width=0.4)\nax.legend([\"Percentage\"])\nplt.title(\"Comparison of different models on Twitter Sentiments\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Conclusion\nAs we can see from graph that deep learning model (LSTM) outperforms other two models in terms of accuracy"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"}},"nbformat":4,"nbformat_minor":1}