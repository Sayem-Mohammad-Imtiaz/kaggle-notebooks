{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport albumentations # Library to do augmentation on images\nimport time\nimport os\nimport PIL\nfrom PIL import Image\n\n# Graphs\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# Sk Learn\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.model_selection import GridSearchCV\n\n# Preprocessing\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom torch.utils.data import TensorDataset\n\n#SciKit Learn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics, model_selection\nimport torch\nfrom torchvision.datasets.utils import download_url\n\n# Metrics\nfrom sklearn.metrics import mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATASET_URL = \"https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv\"\nDATA_FILENAME = \"BostonHousing.csv\"\ndownload_url(DATASET_URL, '.')\n# dataframe = pd.read_csv(\"../input/bostonhoustingmlnd/housing.csv\")\ndf = pd.read_csv(DATA_FILENAME)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# df = pd.read_csv(\"../input/bostonhoustingmlnd/housing.csv\")\n# df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# inputs = df[['RM','LSTAT','PTRATIO']].values\n# print(inputs)\n# targets = df['MEDV'].values\n\n\ninputs = df.drop('medv', axis=1).values\ntargets = df[['medv']].values\n\ninputs = torch.tensor(inputs,dtype=torch.float32)\ntargets = torch.tensor(targets,dtype=torch.float32)\n\nprint(inputs.shape)\nprint(targets.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_ds = TensorDataset(inputs[:10], targets[:10])\nfrom torch.utils.data import DataLoader, TensorDataset, random_split\n\ndataset = TensorDataset(inputs,targets)\ntrain_ds, val_ds = random_split(dataset, [406, 100])\nbatch_size = 64\nval_loader = DataLoader(val_ds, batch_size*2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data import DataLoader\ntrain_loader = DataLoader(train_ds, batch_size, shuffle=True)\ninput_size = 13\noutput_size= 1\n\n# for x,y in train_b1:\n#     print(x)\n#     print(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.nn as nn\n\nclass StoneModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linear = nn.Linear(input_size, output_size)\n        \n    def forward(self, xb):\n        out = self.linear(xb)\n        return out\n    \n    def training_step(self, batch):\n        inputs, targets = batch \n        out = self(inputs)                 # Generate predictions\n        loss = F.mse_loss(out, targets)    # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        inputs, targets = batch \n        out = self(inputs)                 # Generate predictions\n        loss = F.mse_loss(out, targets)    # Calculate loss\n        return {'val_loss': loss.detach()}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        return {'val_loss': epoch_loss.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], val_loss: {:.4f}\".format(epoch, result['val_loss']))\n    \n\nmodel = StoneModel()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.nn.functional as F\nloss_fn = F.mse_loss\nlist(model.parameters())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lrate=5e-7\nopt = torch.optim.SGD(model.parameters(), lr=lrate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(model,)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fits(model,opt,epoch):\n    \n    for i in range (epoch):\n        for x in train_loader:\n            loss = model.training_step(x)\n            loss.backward()\n            opt.step()\n            opt.zero_grad()\n            print(loss.item())            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"fits(model,opt,4000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(model, val_loader):\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        for batch in train_loader:\n            loss = model.training_step(batch)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = evaluate(model, val_loader)\nresult","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"history = fit(10, lrate, model, train_loader, val_loader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"losses = [r['val_loss'] for r in [result] + history]\nplt.plot(losses, '-x')\nplt.xlabel('epoch')\nplt.ylabel('val_loss')\nplt.title('val_loss vs. epochs');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}