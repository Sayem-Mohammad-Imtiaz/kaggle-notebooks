{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport plotly.express as px\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn import svm\n\nC=1e+03\ngamma=1e-05\nclf = svm.SVC(C=C, gamma=gamma, kernel='rbf', probability=True)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Clean data by dropping NaN values in each set.\n\nTraining data:","metadata":{}},{"cell_type":"code","source":"# Read and quick clean of training data\naug_train = \"../input/hr-analytics-job-change-of-data-scientists/aug_train.csv\"\ntrain = pd.read_csv(aug_train)\ntrain_df = train.dropna()\ntest_df = train.tail(100)\ntrain_df.columns[:14] # Shows 14 attributs we have","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Test data:","metadata":{}},{"cell_type":"code","source":"# Read and quick clean of test data\n#aug_test = \"../input/hr-analytics-job-change-of-data-scientists/aug_test.csv\"\n#test = pd.read_csv(aug_test)\n#test_df = test.dropna()\n#test_df.info() # Displays dtypes of attributes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Graphical representation of training data attributes to total number of candidates grouped by target attribute value using histograms.","metadata":{}},{"cell_type":"code","source":"# City\nfig = px.histogram(train_df.dropna(), x = \"city\", color = \"target\")\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# City development index (CDI)\nfig = px.histogram(train_df.dropna(), x = \"city_development_index\", color = \"target\")\nfig.show()","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Gender\nfig = px.histogram(train_df.dropna(), x = \"gender\", color = \"target\")\nfig.show()","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Relevent Experience\nfig = px.histogram(train_df.dropna(), x = \"relevent_experience\", color = \"target\")\nfig.show()","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Enrolled University\nfig = px.histogram(train_df.dropna(), x = \"enrolled_university\", color = \"target\")\nfig.show()","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Education Level\nfig = px.histogram(train_df.dropna(), x = \"education_level\", color = \"target\")\nfig.show()","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Major\nfig = px.histogram(train_df.dropna(), x = \"major_discipline\", color = \"target\")\nfig.show()","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Experience\nfig = px.histogram(train_df.dropna(), x = \"experience\", color = \"target\")\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Code taken from StackOverflow thread: \n# https://stackoverflow.com/questions/24458645/label-encoding-across-multiple-columns-in-scikit-learn\n\nclass MultiColumnLabelEncoder:\n    def __init__(self,columns = None):\n        self.columns = columns # array of column names to encode\n\n    def fit(self,X,y=None):\n        return self # not relevant here\n\n    def transform(self,X):\n        '''\n        Transforms columns of X specified in self.columns using\n        LabelEncoder(). If no columns specified, transforms all\n        columns in X.\n        '''\n        output = X.copy()\n        if self.columns is not None:\n            for col in self.columns:\n                output[col] = LabelEncoder().fit_transform(output[col])\n        else:\n            for colname,col in output.iteritems():\n                output[colname] = preprocessing.LabelEncoder().fit_transform(col)\n        return output\n\n    def fit_transform(self,X,y=None):\n        return self.fit(X,y).transform(X)\n    \n# Stores categorical attribute columns as names as a list      \nstring_attributes = train_df.select_dtypes(['object']).columns.to_list()\n\n# use MultiColumnLabelEncoder class to choose columns to encode\n# No need to worry about missing data since it has already been handled\ntrain_df_transform = MultiColumnLabelEncoder(columns = string_attributes).fit_transform(train_df)\ntest_df_transform = MultiColumnLabelEncoder(columns = string_attributes).fit_transform(test_df)\n\n# Display updated dataframe\ndisplay(train_df_transform)\ndisplay(test_df_transform)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use transformed dataframes to predict\nclf = clf.fit(train_df_transform.iloc[:,0:13], train_df_transform.iloc[:,13])\ny_pred = clf.predict(test_df_transform.iloc[:,0:13]) \ny_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix #let's see how good we did\ny_true = test_df_transform.iloc[:,13]\ntn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\ntn, fp, fn, tp ","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}