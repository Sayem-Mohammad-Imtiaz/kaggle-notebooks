{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n\n#<LIBRERIAS>\n\n#Para manipular y análisar datos\nimport pandas as pd# data processing, CSV file I/O (e.g. pd.read_csv)\n\n#Es un metaestimador que se ajusta a varios clasificadores de árboles de decisión\n#en varias submuestras del conjunto de datos y usa promedios para mejorar la precisión\n#predictiva y controlar el sobreajuste.\nfrom sklearn.ensemble import RandomForestClassifier\n\n#Implementa el algoritmo Gaussiano Naive Bayes para datos distribuidos multinomialmente.\nfrom sklearn.naive_bayes import GaussianNB\n\n#Evaluar una puntuación mediante validación cruzada\nfrom sklearn.model_selection import cross_val_score\n\n#Proporciona índices de entrenamiento / prueba\n#para dividir datos en conjuntos random\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\n#Red neuronal\nfrom sklearn.neural_network import MLPClassifier\n\n#Arbol de decision\nfrom sklearn import tree\n\n#</LIBRERIAS>\n\n\n#importar data-set\ndata = pd.read_csv(\"/kaggle/input/heart-failure-clinical-data/heart_failure_clinical_records_dataset.csv\")\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DATA CLEANING"},{"metadata":{},"cell_type":"markdown","source":"*Verificamos la lectura de los datos*"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Contar valores perdidos en columna*"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Podemos trabajar con los datos*"},{"metadata":{},"cell_type":"markdown","source":"media, varianza, min, max, ..."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Para los datos etiquetados X: age, anaemia, creatinine_phosphokinase, diabetes, ejection_fraction, high_blood_pressure, platelets, serum_creatinine, serum_sodium, sex, smoking\ndescartamos time, DEATH_EVENT"},{"metadata":{"trusted":true},"cell_type":"code","source":"X=data.iloc[:,:-2]\nX.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Para nuestra clase no etiquetada y: Columna de EVENTO DE MUERTE"},{"metadata":{"trusted":true},"cell_type":"code","source":"y=data.DEATH_EVENT\ny.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# PROCESAMIENTO DE DATOS"},{"metadata":{},"cell_type":"markdown","source":"*Proporciona indices de entrenamiento/prueba random para dividir datos en entrenamiento/prueba; splits=10  ;evaluar 10 veces consecutivas(con diferentes divisiones); tamaño de prueba 20%*"},{"metadata":{"trusted":true},"cell_type":"code","source":"cv = StratifiedShuffleSplit(n_splits=10, test_size=0.20, random_state=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Genere índices para dividir los datos en conjuntos de entrenamiento y prueba*"},{"metadata":{"trusted":true},"cell_type":"code","source":"iter_for_prediction = cv.split(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#columna indice, (conjunto de indices de entrenamiento, conjunto de indices de prueba)\nfor index, (train_index, test_index) in enumerate(iter_for_prediction):\n    #número de split\n    print(index)\n\n    #RandomForestClassifier\n    #Es un metaestimador que se ajusta a varios clasificadores de árboles de decisión\n    #en varias submuestras del conjunto de datos y usa promedios para mejorar la precisión\n    #predictiva y controlar el sobreajuste.\n\n    #Controla tanto la aleatoriedad del bootstrapping de las muestras utilizadas\n    #al construir árboles.\n    #Utilice un nuevo generador de números aleatorios sembrado por el entero dado.\n    #El uso de un int producirá los mismos resultados en diferentes llamadas.\n    #Sin embargo, puede valer la pena comprobar que los resultados sean estables\n    #en varias semillas aleatorias distintas. \n    randomf = RandomForestClassifier(random_state=0)\n    \n    #Implementa el algoritmo Gaussiano Naive Bayes para datos distribuidos multinominalmente.\n    gnb = GaussianNB()\n\n    #>>>MLP Classifier[Red neuronal]<<<\n    #\"Lbfgs\" es un optimizador basado en métodos cuasi-Newtonianos.\n    #\"Logistic\", la función sigmoidea logística, devuelve f (x) = 1 / (1 + exp (-x)).\n    #\"verbose\", imprimir mensajes de progreso en stdout.\n    #\"alpha\", L2 penalty (regularization term) parameter.\n    #\"hidden_layer_sizes\", El i-ésimo elemento representa el número de neuronas en la i-ésima capa oculta.\n    mlp=MLPClassifier(solver = 'lbfgs', activation='logistic', verbose=False, alpha=1e-4, tol = 1e-3, hidden_layer_sizes=(150, 2))\n\n\n    #Arbol de decision\n    arbol = tree.DecisionTreeClassifier(random_state=0)\n\n    #Regresion lineal\n    #lr = linear_model.LinearRegression()\n    #no puedo usarlo porque mi salida es boolean\n\n\n    sk_clasificador = {'GaussianNB':gnb,\n                       'RandomForest':randomf,\n                       'MLPCassifier': mlp,\n                       'Arbol': arbol}\n                       #'lineal': lr}\n    #i=1\n\n    #itera entre GaussianNB y RandomForest\n    for clasifier in sk_clasificador:\n        print(clasifier)\n        #print(i, \": \", clasifier)\n        #i = i+1\n\n        estimador = sk_clasificador[clasifier]\n\n        #Validación cruzada: evaluación del desempeño del estimador \n        #estimador: objeto estimador que implementa 'ajuste'. El objeto que se utilizará para ajustar los datos.\n        #X: dato a ajustar\n        #y: La variable objetivo para intentar predecir en el caso del aprendizaje supervisado.\n\n        #scoring: exactitud\n        score = cross_val_score(estimador, X, y, scoring='accuracy', cv=[(train_index, test_index)])\n        print(\"SCORE\")\n        #print(estimador, score) #score: numpy.ndarray\n        print(score)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}