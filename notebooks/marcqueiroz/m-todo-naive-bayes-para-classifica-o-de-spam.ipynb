{"cells":[{"metadata":{"_cell_guid":"71937b91-6de7-bfcf-0865-0f0157d3bce6"},"cell_type":"markdown","source":"** Método Naive Bayes para classificação de spam usando a lista Tabu (Traduzido para o português)**\n====================================================\nImplementado por Clyde Wang, 17 de fevereiro de 2017\n\nEsse classificador de spam é implementado pelo Naive Bayes Model, uma solução simples, mas muito eficiente no problema de classificação de spam. Em resumo, o Naive Bayes trata todos os recursos independentemente um do outro, tornando a inferência muito eficiente. Você pode consultar [Naive Bayes] [1] para mais detalhes. Este artigo apresenta brevemente o processo de seleção da lista de tabus e criação do algoritmo de aprendizado. Espero que você goste.\n\nEsse código funciona muito bem com a precisão de 98,31% na amostra de treinamento e 97,81% na amostra de teste.\nEspero que alguém possa melhorá-lo e melhorar seu desempenho. E aqui vamos nós!\n\n   [1]: https://en.wikipedia.org/wiki/Naive_Bayes_classifier"},{"metadata":{"_cell_guid":"f0e046f7-a766-6dfa-f05c-3d8ba49f1e2a"},"cell_type":"markdown","source":"## 1. Configuração do ambiente ##\nAntes de começarmos, precisamos configurar o ambiente, verifique se esses pacotes estão instalados no seu computador quando você copia esse código no arquivo local."},{"metadata":{"_cell_guid":"100e1654-dc9c-3ff7-51b9-4ca782dfbbfc","trusted":true},"cell_type":"code","source":"#coding:utf-8\nimport pandas as pd\nimport numpy as np\nimport re\nfrom sklearn.naive_bayes import BernoulliNB","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b98cf320-7a0c-a003-dce5-b2f794244212"},"cell_type":"markdown","source":"2. Leia o arquivo de dados\n-----------------\nA primeira tarefa é ler dados do arquivo .csv, e aqui podemos tirar proveito do `pandas.DataFrame` para armazenar e processar os dados brutos. (veja [aqui] [1]) Observe que precisamos dividir nossos dados brutos em duas partes para testar a capacidade de generalização do nosso modelo. Aqui está o código:\n\n\n   [1]: http://pandas.pydata.org/pandas-docs/stable/10min.html"},{"metadata":{"_cell_guid":"2b46f245-3cb2-7cea-6d32-132cf6b7108f","trusted":true},"cell_type":"code","source":"def readData():\n\tSMS_df = pd.read_csv('../input/spam.csv',usecols=[0,1],encoding='latin-1')\n\tSMS_df.columns=['label','content']\n\tn = int(SMS_df.shape[0])\n    # split into training data and test data\n\treturn SMS_df.iloc[:int(n/2)], SMS_df.iloc[int(n/2):]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3. Gere uma lista de tabu\n--------------------\nA ** tabu list ** é uma lista desses indicadores significativos de spam por SMS. Aqui, selecionamos TF-IDF como o princípio da geração de lista.\n\nFrequência de termos (TF) é a frequência de uma palavra em um determinado tipo de documento. Se houver um artigo de 50 palavras com 2 'dados', o TF dos 'dados' será dado por '2/50 = 0,01'.\n\nNo entanto, existem algumas palavras de alta frequência em inglês, como 'a', 'is', 'are' etc. Temos que remover essas palavras da nossa lista. E aqui vem o IDF.\n\nA Frequência inversa de documentos (IDF) é o indicador para refletir a importância de uma palavra relacionada a algum tópico específico. É dado por `log (#total de artigos / # artigos contendo w)`, por exemplo, se tivermos 5 artigos, apenas um terá a palavra 'gene' com frequência de termo de 0,002, mas todos os cinco artigos contêm a palavra 'tecnologia' da frequência do termo de 0,5, o IDF do 'gene' é `log (5/1)> 0`, mas o IDF da 'tecnologia' é` log (5/5) = 0`.\n\nTF-IDF é o produto de TF e IDF: no exemplo acima, `TFIDF ('gene') = 0,002 * log (5/1)> 0` enquanto` TFIDF ('tecnologia') = 0,5 * log (5 / 5) = 0`, portanto, neste caso, 'gene' é um indicador melhor que 'tecnologia'.\n\nNo meu código, eu calculo o TF-IDF de cada palavra para 'spam' e 'ham' e calculo a diferença entre elas; assim, posso selecionar as palavras que são as mais representativas para a classe 'spam'.\n\nAqui está o código:"},{"metadata":{"_cell_guid":"e7a4eada-c2cc-e24f-4c82-39f4ba8739e4","trusted":true},"cell_type":"code","source":"def generate_tabu_list(path, tabu_size=200,ignore=3):\n\ttrain_df,_ = readData()\n\tspam_TF_dict = dict()\n\tham_TF_dict = dict()\n\tIDF_dict = dict()\n\n\t# ignore all other than letters.\n\tfor i in range(train_df.shape[0]):\n\t\tfinds = re.findall('[A-Za-z]+', train_df.iloc[i].content)\n\t\tif train_df.iloc[i].label == 'spam':\n\t\t\tfor find in finds:\n\t\t\t\tif len(find)<ignore: continue\n\t\t\t\tfind = find.lower()\n\t\t\t\ttry:\n\t\t\t\t\tspam_TF_dict[find] = spam_TF_dict[find] + 1\n\t\t\t\texcept:\t\n\t\t\t\t\tspam_TF_dict[find] = spam_TF_dict.get(find,1)\n\t\t\t\t\tham_TF_dict[find] = ham_TF_dict.get(find,0)\n\t\telse:\n\t\t\tfor find in finds:\n\t\t\t\tif len(find)<ignore: continue\n\t\t\t\tfind = find.lower()\n\t\t\t\ttry:\n\t\t\t\t\tham_TF_dict[find] = ham_TF_dict[find] + 1\n\t\t\t\texcept:\t\n\t\t\t\t\tspam_TF_dict[find] = spam_TF_dict.get(find,0)\n\t\t\t\t\tham_TF_dict[find] = ham_TF_dict.get(find,1)\n\t\t\n\t\tword_set = set()\n\t\tfor find in finds:\n\t\t\tif len(find)<ignore: continue\n\t\t\tfind = find.lower()\n\t\t\tif not(find in word_set):\n\t\t\t\ttry:\n\t\t\t\t\tIDF_dict[find] = IDF_dict[find] + 1\n\t\t\t\texcept:\t\n\t\t\t\t\tIDF_dict[find] = IDF_dict.get(find,1)\n\t\t\tword_set.add(find)\n\n\tword_df = pd.DataFrame(list(zip(ham_TF_dict.keys(),ham_TF_dict.values(),spam_TF_dict.values(),IDF_dict.values())))\n\tword_df.columns = ['keyword','ham_TF','spam_TF','IDF']\n\tword_df['ham_TF'] = word_df['ham_TF'].astype('float')/train_df[train_df['label']=='ham'].shape[0]\n\tword_df['spam_TF'] = word_df['spam_TF'].astype('float')/train_df[train_df['label']=='spam'].shape[0]\n\tword_df['IDF'] = np.log10(train_df.shape[0]/word_df['IDF'].astype('float'))\n\tword_df['ham_TFIDF'] = word_df['ham_TF']*word_df['IDF']\n\tword_df['spam_TFIDF'] = word_df['spam_TF']*word_df['IDF']\n\tword_df['diff']=word_df['spam_TFIDF']-word_df['ham_TFIDF']\n\n\tselected_spam_key = word_df.sort_values('diff',ascending=False)\n\n\tprint('>>>Generating Tabu List...\\n  Tabu List Size: {}\\n  File Name: {}\\n  The words shorter than {} are ignored by model\\n'.format(tabu_size, path, ignore))\n\tfile = open(path,'w')\n\tfor word in selected_spam_key.head(tabu_size).keyword:\n\t\tfile.write(word+'\\n')\n\tfile.close()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"4. Leia a Lista Tabu e converta SMS\n-----------------------------------\nComo a mensagem é de tamanho variável, não é fácil para a implementação do algoritmo de aprendizado. Portanto, definimos uma Função acima, gerando uma lista de tabu e armazenando-a no arquivo local. E podemos usar esse arquivo para converter um SMS expresso em string em um vetor de comprimento fixo expresso em valor binário.\n\nA ideia é dada assim: Se tivermos uma lista de tabu, poderemos encontrar essas palavras na lista e representá-las por um índice. Assim, uma string pode ser convertida em uma matriz de int. Além disso, poderíamos definir uma matriz preenchida com zeros com o mesmo comprimento da lista de tabu. se este str contiver a palavra na lista tabu, poderíamos atribuir 1 ao elemento correspondente da matriz que representa 'message contains word w'. (dicas: a consulta de `python.dict` é de tempo constante, muito mais rápida que` python.list`)\n\nAo executar esta etapa, poderíamos converter nossos dados brutos de comprimento de variante em dados numéricos de comprimento fixo.\n\nEstas duas funções são dadas abaixo:"},{"metadata":{"_cell_guid":"46534282-54e9-4786-aabb-45df63148b66","trusted":true},"cell_type":"code","source":"def read_tabu_list():\n\tfile = open('tabu.txt','r')\n\tkeyword_dict = dict()\n\ti = 0\n\tfor line in file:\n\t\tkeyword_dict.update({line.strip():i})\n\t\ti+=1\n\treturn keyword_dict\n\ndef convert_Content(content, tabu):\n\tm = len(tabu)\n\tres = np.int_(np.zeros(m))\n\tfinds = re.findall('[A-Za-z]+', content)\n\tfor find in finds:\n\t\tfind=find.lower()\n\t\ttry:\n\t\t\ti = tabu[find]\n\t\t\tres[i]=1\n\t\texcept:\n\t\t\tcontinue\n\treturn res","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"5. Aprendendo, testando e prevendo\n-----------------------------------\nDepois de gerar nossa lista de tabu e as funções de suporte, agora estamos bem preparados para a parte de aprendizado desse problema. E aqui podemos usar a biblioteca `sklearn.naive_bayes import BernoulliNB`. Isso nos ajudará a treinar esse modelo.\n\nAntes desta parte, vamos revisar nossos dados: nossa entrada de recurso X é uma matriz * m, onde X [i, j] = 1 significa que a amostra #i contém a palavra j na lista de guias e o rótulo supervisionado Y é um * 1 vetor onde Y [i] = 1 representando para um spam e 0 para um presunto.\n\nVamos preparar os materiais para o algoritmo de aprendizado."},{"metadata":{"_cell_guid":"35051cb6-93f5-cc38-bab3-c94b1fb5ed91","trusted":true},"cell_type":"code","source":"def learn():\n\tglobal tabu, m\n\ttrain,_ = readData()\n\tn = train.shape[0]\n\tX = np.zeros((n,m)); Y=np.int_(train.label=='spam')\n\tfor i in range(n):\n\t\tX[i,:] = convert_Content(train.iloc[i].content, tabu)\n\n\tNaiveBayes = BernoulliNB()\n\tNaiveBayes.fit(X, Y)\n\n\tY_hat = NaiveBayes.predict(X)\n\tprint('>>>Learning...\\n  Learning Sample Size: {}\\n  Accuracy (Training sample): {:.2f}％\\n'.format(n,sum(np.int_(Y_hat==Y))*100./n))\n\treturn NaiveBayes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A Função acima retorna um objeto Naive Bayes Model bem treinado, e poderíamos usá-lo para fazer previsões."},{"metadata":{"_cell_guid":"c98127ed-e089-9edd-eae0-97828efaad31","trusted":true},"cell_type":"code","source":"def test(NaiveBayes):\n\tglobal tabu, m\n\t_,test = readData()\n\tn = test.shape[0]\n\tX = np.zeros((n,m)); Y=np.int_(test.label=='spam')\n\tfor i in range(n):\n\t\tX[i,:] = convert_Content(test.iloc[i].content, tabu)\n\tY_hat = NaiveBayes.predict(X)\n\tprint ('>>>Cross Validation...\\n  Testing Sample Size: {}\\n  Accuracy (Testing sample): {:.2f}％\\n'.format(n,sum(np.int_(Y_hat==Y))*100./n))\n\treturn\n\ndef predictSMS(SMS):\n\tglobal NaiveBayes, tabu, m\n\tX = convert_Content(SMS, tabu)\n\tY_hat = NaiveBayes.predict(X.reshape(1,-1))\n\tif int(Y_hat) == 1:\n\t\tprint ('SPAM: {}'.format(SMS))\n\telse:\n\t\tprint ('HAM: {}'.format(SMS))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"6. Montagem Geral\n-------------------\nDepois de definirmos todos os módulos que precisamos neste problema, poderemos integrá-los em uma parte inteira.**"},{"metadata":{"_cell_guid":"f4b028ff-859f-0977-2bc0-804ee5364504","trusted":true},"cell_type":"code","source":"print('UCI SMS SPAM CLASSIFICATION PROBLEM SET\\n  -- implemented by Bernoulli Naive Bayes Model\\n')\ntabu_file = 'tabu.txt'          # user defined tabu file\ntabu_size = 300                 # how many features are used to classify spam\nword_len_ignored = 3            # ignore those words shorter than this variable\n# build a tabu list based on the training data\ngenerate_tabu_list(tabu_file,tabu_size, word_len_ignored)\n\ntabu = read_tabu_list()\nm = len(tabu)\n# train the Naive Bayes Model using training data\nNaiveBayes=learn()\n# Test Model using testing data\ntest(NaiveBayes)\nprint('>>>Testing')\n# I select two messages from the test data here.\npredictSMS('Ya very nice. . .be ready on thursday')\npredictSMS('Had your mobile 10 mths? Update to the latest Camera/Video phones for FREE. KEEP UR SAME NUMBER, Get extra free mins/texts. Text YES for a call')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ok, funciona! Uma precisão de 98,28% no conjunto de treinamento e 97,77% é aceitável para mim.\n\nPor favor, não hesite em me perguntar, se você tiver alguma dúvida. E se você gosta deste guia, faça um voto positivo, Muito obrigado.\n\n--Clyde Wang"},{"metadata":{"trusted":true},"cell_type":"code","source":"train, _ = readData()\nn = train.shape[0]\nX = np.zeros((n,m))\nY=np.int_(train.label=='spam')\nfor i in range(n):\n    X[i,:] = convert_Content(train.iloc[i].content, tabu)\nY_hat = NaiveBayes.predict(X)\nfrom sklearn.metrics import classification_report\nprint(classification_report(Y,Y_hat))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a87737be-8382-cb09-6c15-80c7ae135e6a"},"cell_type":"markdown","source":"   "}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":1}