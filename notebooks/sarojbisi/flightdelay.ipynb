{"cells":[{"metadata":{},"cell_type":"markdown","source":"**DESCRIPTION**\n\n**Problem Statement**\n\nThis is the flight delay prediction for the month of January. \n\nThis data is collected from the Bureau of Transportation Statistics, Govt. of the USA. This data is open-sourced under U.S. Govt. Works. This dataset contains all the flights in the month of January 2019 and January 2020. There are more than 400,000 flights in the month of January itself throughout the United States. \n\nThis data could well be used to predict the flight delay at the destination airport specifically for the month of January in upcoming years as the data is for January only.\n\nThis file contains all the flights starting from 1st January 2019 till 31st January 2019. There are around 400,000 rows in this file and 21 feature columns indicating the features of the flight including information about origin airport, destination airport, airplane information, departure time and arrival time.\n\nDownlod the **data sets** from _**[here](https://www.kaggle.com/divyansh22/flight-delay-prediction)**_."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import f1_score,classification_report,confusion_matrix\n        \n\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom xgboost import XGBRFClassifier,XGBClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\n\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.multiclass import OneVsRestClassifier\n\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"traindata0119=pd.read_csv('/kaggle/input/flight-delay-prediction/Jan_2019_ontime.csv')\ntraindata0120=pd.read_csv('/kaggle/input/flight-delay-prediction/Jan_2020_ontime.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traindata0119.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traindata0120.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Merge both the dataset\ntraindata0=pd.concat([traindata0119,traindata0120])\n#traindata0=traindata0.iloc[:,np.arange(21)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traindata0.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#let us figure out the redundant attributes\ntraindata0.OP_UNIQUE_CARRIER.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traindata0.OP_CARRIER_AIRLINE_ID.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traindata0.OP_CARRIER.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#From above resuls we can conclude that OP_UNIQUE_CARRIER , OP_CARRIER_AIRLINE_ID, OP_CARRIER are redundant features.\n# Hence we can remove OP_UNIQUE_CARRIER, OP_CARRIER and retain only the numerical feature OP_CARRIER_AIRLINE_ID\n# similarly ORIGIN_AIRPORT_ID, ORIGIN_AIRPORT_SEQ_ID and ORIGIN are redundant features and hence we can retain ONLY ORIGIN_AIRPORT_ID \n# similarly DEST_AIRPORT_ID, DEST_AIRPORT_SEQ_ID and DEST are redundant features and hence we can retain ONLY DEST_AIRPORT_ID\n# Also we dont want CANCELLED and DIVERTED CASES\n#ARR_TIME and ARR_DEL15 can be considered as target variables, We can drop ARR_TIME since we have consedered ARR_DEL15 as target  \n\ntraindata1=traindata0.drop(columns=['OP_UNIQUE_CARRIER','OP_CARRIER','ORIGIN_AIRPORT_SEQ_ID',\n                                    'ORIGIN','DEST_AIRPORT_SEQ_ID','DEST',\n                                   'CANCELLED','DIVERTED','ARR_TIME','Unnamed: 21','TAIL_NUM'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traindata1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traindata1.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the percentage of null values across each attributes\ntraindata1.isnull().sum()/len(traindata1)*100   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#As the the null value percentage are very less we can drop the null records instead of NULL value imputation\ntraindata1.dropna(inplace=True)\ntraindata1.reset_index(drop=True,inplace=True)\ntraindata1.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets analyze the Catagorical variables DEP_TIME_BLK\ntraindata1.DEP_TIME_BLK.value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We can do a quick check if these two categorical variables have any influence on the target variable.\n#This can be tested using Chisquare Test of independence: H0: There is no dependency between Feature and Target Ha:There is dependency\nfrom scipy.stats import chi2_contingency\ncategorical_columns=['DEP_TIME_BLK']\nchi2_check = []\nfor i in categorical_columns:\n    ch2 , p_value , df, exp_freq=chi2_contingency(pd.crosstab(traindata1[i],traindata1['ARR_DEL15']))\n    if p_value < 0.05:\n        chi2_check.append('Reject Null Hypothesis: Retain the Feature:'+i)\n    else:\n        chi2_check.append('Fail to Reject Null Hypothesis: Drop the Feature:')\nchi2_check","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#From Chisquare test it seems that we need to retain the the above categorical featuture\n# DEP_TIME_BLK can be filled with numeric value\ntraindata1.DEP_TIME_BLK.replace(['0600-0659','0700-0759','0800-0859','1700-1759','1200-1259','1100-1159','1500-1559',\n                                 '1000-1059','1400-1459','0900-0959','1600-1659','1800-1859','1300-1359','1900-1959',\n                                 '2000-2059','2100-2159','0001-0559','2200-2259','2300-2359'],\n                               [6,7,8,17,12,11,15,10,14,9,16,18,13,19,20,21,1,22,23],inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traindata1.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets check the correlation among the variables\ntraindata1.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#From above correlation matrix its evident that there are some muticoliniarity variables\n#Example:\n# 1. There is a very strong correlation between DEP_TIME_BLK and DEP_TIME (96%)\n# 2. There is also noticiable corrlelation between OP_CARRIER_AIRLINE_ID and OP_CARRIER_FL_NUM\n# Hence we can try dropping DEP_TIME_BLK and OP_CARRIER_AIRLINE_ID\n\ntraindata2=traindata1.drop(columns=['DEP_TIME_BLK','OP_CARRIER_AIRLINE_ID'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features=['DAY_OF_MONTH','DAY_OF_WEEK','OP_CARRIER_FL_NUM','ORIGIN_AIRPORT_ID']\n\n#Lets do pair plot and visualize the class separability\n\n\n#plt.subplot(2,4,1)\nsns.pairplot(traindata2,x_vars=features,y_vars=features,kind='scatter',hue='DEP_DEL15')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features=['DEST_AIRPORT_ID','DEP_TIME','DISTANCE']\n\n#Lets do pair plot and visualize the class separability\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n#plt.subplot(2,4,1)\nsns.pairplot(traindata2,x_vars=features,y_vars=features,kind='scatter',hue='DEP_DEL15')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# From above pair plots it seems that Target variables are not linearly saparable with most ofthe features except Dep_time\n# Extract the features and label\ntraindata2.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features=traindata2.drop(columns=['ARR_DEL15']).values\nlabel=traindata2['ARR_DEL15'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check for data balance\nsns.countplot(x=label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Split the data into Train and Test\nfrom sklearn.model_selection import train_test_split\nX_train,X_test_final,y_train,y_test_final=train_test_split(features,label,test_size=0.2,random_state=12)\nprint('the shape of X_train and  y_train: ', X_train.shape, y_train.shape)\nprint('the shape of X_test and  y_test: ', X_test_final.shape,y_test_final.shape)\n\n\n## Verify the performance of different models using Stratified-KFold Cross Validation\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import f1_score,classification_report,confusion_matrix\n#from sklearn import metrics\n\ndef stratified_K_fold_validation(model_obj, model_name, process, n_splits, X, y):\n    global df_model_selection\n    \n    skf = StratifiedKFold(n_splits, random_state=12,shuffle=True)\n    \n    weighted_f1_score = []\n    #print(skf.split(X,y))\n    for train_index, test_index in skf.split(X,y):\n        X_train, X_test = X[train_index], X[test_index] \n        y_train, y_test = y[train_index], y[test_index]\n        \n        \n        model_obj.fit(X_train, y_train)##### HERE ###\n        test_ds_predicted = model_obj.predict( X_test ) ##### HERE ####   \n        #print( metrics.classification_report( y_test, test_ds_predicted ) )    \n        weighted_f1_score.append(round(f1_score(y_true=y_test, y_pred=test_ds_predicted , average='weighted'),2))\n        \n    sd_weighted_f1_score = np.std(weighted_f1_score, ddof=1)\n    range_of_f1_scores = \"{}-{}\".format(min(weighted_f1_score),max(weighted_f1_score))    \n    df_model_selection = pd.concat([df_model_selection,pd.DataFrame([[process,model_name,sorted(weighted_f1_score),range_of_f1_scores,sd_weighted_f1_score]], columns =COLUMN_NAMES) ])\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nCOLUMN_NAMES = [\"Process\",\"Model Name\", \"F1 Scores\",\"Range of F1 Scores\",\"Std Deviation of F1 Scores\"]\ndf_model_selection = pd.DataFrame(columns=COLUMN_NAMES)\n\nprocess='Stratified-KFold'\nn_splits = 10\nX=sc.fit_transform(X_train)\ny=y_train\n\n# Logistic Regression\nmodel_LR=LogisticRegression()\nmodel_obj=model_LR\nmodel_name='Logistic Regression'\nstratified_K_fold_validation(model_obj, model_name, process, n_splits, X, y)\n\n# Decesion Tree Classifier\nmodel_DTC=DecisionTreeClassifier()\nmodel_obj=model_DTC\nmodel_name='Decesion Tree Classifier'\nstratified_K_fold_validation(model_obj, model_name, process, n_splits, X, y)\n\n# Random Forest Classifier\nmodel_RFC=RandomForestClassifier()\nmodel_obj=model_RFC\nmodel_name='Random Forest Classifier'\nstratified_K_fold_validation(model_obj, model_name, process, n_splits, X, y)\n\n# XGBoost Classifier\nmodel_XGBC=XGBClassifier()\nmodel_obj=model_XGBC\nmodel_name='XGBoost Classifier'\nstratified_K_fold_validation(model_obj, model_name, process, n_splits, X, y)\n\n# Gradient Boosting Classifier\nmodel_GBC=GradientBoostingClassifier()\nmodel_obj=model_GBC\nmodel_name='Gradient Boosting Classifier'\nstratified_K_fold_validation(model_obj, model_name, process, n_splits, X, y)\n\n# XGBoost Random Forest Classifier\n#model_XGBRFC=XGBRFClassifier()\n#model_obj=model_XGBRFC\n#model_name='XGBoost Random Forest Classifier'\n#stratified_K_fold_validation(model_obj, model_name, process, n_splits, X, y)\n\n# 8.Support Vector Machine Classifier\n#model_SVC=SVC()\n#model_obj=model_SVC\n#model_name='Support Vector Machine Classifier'\n#stratified_K_fold_validation(model_obj, model_name, process, n_splits, X, y)\n\n\n# 9.SGD Classifier\n#model_sgd = OneVsRestClassifier(SGDClassifier())\n#model_obj=model_sgd\n#model_name='Stochastic Gradient Descent Classifier'\n#stratified_K_fold_validation(model_obj, model_name, process, n_splits, X, y)\n\n\n#11.KNeighborsClassifier\n#model_KNNC=KNeighborsClassifier()\n#model_obj=model_KNNC\n#model_name='K Nearst Neighbour Classifier'\n#stratified_K_fold_validation(model_obj, model_name, process, n_splits, X, y)\n\n#12 Linear Discriminant Analysis\n#model_LDA=LinearDiscriminantAnalysis()\n#model_obj=model_LDA\n#model_name='Linear Discriminant Analysis'\n#stratified_K_fold_validation(model_obj, model_name, process, n_splits, X, y)\n\n#Exporting the results to csv\n#df_model_selection.to_csv(\"Model_statistics.csv\",index = False)\ndf_model_selection","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nProcess\tModel Name\tF1 Scores\tRange of F1 Scores\tStd Deviation of F1 Scores\n0\tStratified-KFold\tLogistic Regression\t[0.92, 0.92, 0.92, 0.92, 0.92, 0.92, 0.92, 0.9...\t0.92-0.93\t3.162278e-03\n0\tStratified-KFold\tDecesion Tree Classifier\t[0.88, 0.88, 0.88, 0.88, 0.88, 0.88, 0.88, 0.8...\t0.88-0.88\t1.170278e-16\n0\tStratified-KFold\tRandom Forest Classifier\t[0.92, 0.92, 0.92, 0.92, 0.92, 0.92, 0.92, 0.9...\t0.92-0.93\t3.162278e-03\n0\tStratified-KFold\tXGBoost Classifier\t[0.92, 0.92, 0.92, 0.92, 0.92, 0.92, 0.92, 0.9...\t0.92-0.93\t3.162278e-03","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets get the best samples out of 10 splits\n\n# Now lets try to get the Scores using StratifiedKFold Cross Validation\n\n#Initialize the algo\nmodel=LogisticRegression()\n\n#Initialize StratifiedKFold Method\nfrom sklearn.model_selection import StratifiedKFold\nkfold = StratifiedKFold(n_splits=10, \n              random_state=1,\n              shuffle=True)\n\n#Initialize For Loop \n\ni=0\nfor train,test in kfold.split(X,y):\n    i = i+1\n    X_train,X_test = X[train],X[test]\n    y_train,y_test = y[train],y[test]\n    \n    model.fit(X_train,y_train)\n    test_ds_predicted=model.predict(X_test)\n    train_ds_predicted=model.predict(X_train)\n    \n    test_f1_score=round(f1_score(y_true=y_test, y_pred=test_ds_predicted , average='weighted'),2)\n    train_f1_score=round(f1_score(y_true=y_train, y_pred=train_ds_predicted , average='weighted'),2)\n    \n    #print(\"Train Score: {}, Test score: {}, for Sample Split: {}\".format(model.score(X_train,y_train),model.score(X_test,y_test),i))\n    print(\"Train f1-Score: {}, Test f1-score: {}, for Sample Split: {}\".format(train_f1_score,test_f1_score,i))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets extract the Train and Test sample for split 9\nfrom sklearn.model_selection import StratifiedKFold\nkfold = StratifiedKFold(n_splits=10, #n_splits should be equal to no of cv value in cross_val_score\n              random_state=1,\n              shuffle=True)\ni=0\nfor train,test in kfold.split(X,y):\n    i = i+1\n    if i == 9:\n        X_train,X_test,y_train,y_test = X[train],X[test],y[train],y[test]\n\n#Final Model\nfinalModel=LogisticRegression()\nfinalModel.fit(X_train,y_train)\n\ntest_ds_predicted=model.predict(X_test)\ntrain_ds_predicted=model.predict(X_train)\n\ntest_f1_score=round(f1_score(y_true=y_test, y_pred=test_ds_predicted , average='weighted'),2)\ntrain_f1_score=round(f1_score(y_true=y_train, y_pred=train_ds_predicted , average='weighted'),2)\nprint(\"Train f1-Score: {}, Test f1-score: {}\".format(train_f1_score,test_f1_score))\n\n\ntrain_score=np.round(finalModel.score(X_train,y_train),2)\ntest_score=np.round(finalModel.score(X_test,y_test),2)\nprint('Train Accuracy Score is:{} and  Test Accuracy Score:{}'.format(train_score,test_score))\n\n#Classification Report\ncr=classification_report(y_true=y_test,y_pred=finalModel.predict(X_test))\nprint(cr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets test the model in unknown dataset: X_test_final and y_test_final\nX_test_final=sc.fit_transform(X_test_final)\ncr=classification_report(y_true=y_test_final,y_pred=finalModel.predict(X_test_final))\nprint(cr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Lets try out Neural Network\nimport tensorflow as tf\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dropout, Dense","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#Build a sequential model\ntf.keras.backend.clear_session()\n\n#Initialize Sequential model\nmodel_NN = tf.keras.models.Sequential()\n#Input Layer\nmodel_NN.add(tf.keras.layers.Reshape((8,),input_shape=(8,)))\n#Normalize the data\nmodel_NN.add(tf.keras.layers.BatchNormalization())\n\n#Add 1st hidden layer\nmodel_NN.add(tf.keras.layers.Dense(100, activation='relu'))\n#Dropout layer\n#model_NN.add(tf.keras.layers.Dropout(0.5))\n#Normalize the data\nmodel_NN.add(tf.keras.layers.BatchNormalization())\n\n#Add 2nd hidden layer\nmodel_NN.add(tf.keras.layers.Dense(50, activation='relu'))\n#Dropout layer\n#model_NN.add(tf.keras.layers.Dropout(0.3))\n#Normalize the data\nmodel_NN.add(tf.keras.layers.BatchNormalization())\n\n#Add OUTPUT layer\nmodel_NN.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n\n#Create optimizer with non-default learning rate\n#sgd_optimizer = tf.keras.optimizers.SGD(lr=1.0)\n#model_NN.compile(optimizer=sgd_optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n\n#Compile the model\nmodel_NN.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n#model_NN.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nmodel_NN.fit(X_train,y_train,          \n          validation_data=(X_test,y_test),\n          epochs=10,\n          batch_size=32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Observation from Neural Net: There is not much of improvement in accuracy as compared to logistic regression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# As the Data is imbalance , we can try using Oversampling technique() and see if we can improve the model performance\n# Databalancing technique can be applied onöy on Train dataset\n\n#Split the data into Train, Valdation and Test Set\nfrom sklearn.model_selection import train_test_split\nX_train,X_test_final,y_train,y_test_final=train_test_split(features,label,test_size=0.2,random_state=12)\nprint('the shape of X_train and  y_train: ', X_train.shape, y_train.shape)\nprint('the shape of X_test and  y_test: ', X_test_final.shape,y_test_final.shape)\n\n\nfrom imblearn.over_sampling import SMOTE\nprint('length of X_train and y_train before Oversampling',len(X_train),len(y_train))\n\nOS=SMOTE(random_state=42)\nX_train_OS,y_train_OS=OS.fit_resample(X_train,y_train)\n\nprint('length of X_train and y_train after Oversampling',len(X_train_OS),len(y_train_OS))\n\n#Check for data balance\nsns.countplot(x=y_train_OS)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# We can now apply cross validation \n#Initialize the algo\nmodel=LogisticRegression()\n\nX_train_OS=sc.fit_transform(X_train_OS) # scale the data\n\n#Initialize StratifiedKFold Method\nfrom sklearn.model_selection import StratifiedKFold\nkfold = StratifiedKFold(n_splits=10, \n              random_state=1,\n              shuffle=True)\n\n#Initialize For Loop \n\ni=0\nfor train,test in kfold.split(X_train_OS,y_train_OS):\n    i = i+1\n    X_train,X_test = X_train_OS[train],X_train_OS[test]\n    y_train,y_test = y_train_OS[train],y_train_OS[test]\n    \n    model.fit(X_train,y_train)\n    test_ds_predicted=model.predict(X_test)\n    train_ds_predicted=model.predict(X_train)\n    \n    test_f1_score=round(f1_score(y_true=y_test, y_pred=test_ds_predicted , average='weighted'),2)\n    train_f1_score=round(f1_score(y_true=y_train, y_pred=train_ds_predicted , average='weighted'),2)\n    \n    #print(\"Train Score: {}, Test score: {}, for Sample Split: {}\".format(model.score(X_train,y_train),model.score(X_test,y_test),i))\n    print(\"Train f1-Score: {}, Test f1-score: {}, for Sample Split: {}\".format(train_f1_score,test_f1_score,i))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets extract the Train and Test sample for split 2\nfrom sklearn.model_selection import StratifiedKFold\nkfold = StratifiedKFold(n_splits=10, #n_splits should be equal to no of cv value in cross_val_score\n              random_state=1,\n              shuffle=True)\ni=0\nfor train,test in kfold.split(X_train_OS,y_train_OS):\n    i = i+1\n    if i == 2:\n        X_train,X_test,y_train,y_test = X_train_OS[train],X_train_OS[test],y_train_OS[train],y_train_OS[test]\n\n#Final Model\nfinalModel=LogisticRegression()\nfinalModel.fit(X_train,y_train)\n\ntest_ds_predicted=model.predict(X_test)\ntrain_ds_predicted=model.predict(X_train)\n\ntest_f1_score=round(f1_score(y_true=y_test, y_pred=test_ds_predicted , average='weighted'),2)\ntrain_f1_score=round(f1_score(y_true=y_train, y_pred=train_ds_predicted , average='weighted'),2)\nprint(\"Train f1-Score: {}, Test f1-score: {}\".format(train_f1_score,test_f1_score))\n\n\ntrain_score=np.round(finalModel.score(X_train,y_train),2)\ntest_score=np.round(finalModel.score(X_test,y_test),2)\nprint('Train Accuracy Score is:{} and  Test Accuracy Score:{}'.format(train_score,test_score))\n\n#Classification Report\ncr=classification_report(y_true=y_test,y_pred=finalModel.predict(X_test))\nprint(cr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets test the model in unknown dataset: X_test_final and y_test_final\nX_test_final=sc.fit_transform(X_test_final)\ncr=classification_report(y_true=y_test_final,y_pred=finalModel.predict(X_test_final))\nprint(cr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Conclusion: \n#As we can see from above test results on the unknown dataset, \n#The model performance between Balance and Imbalance dataset is very much similar.\n# Precession is around 77% and Recall is around 74% and F-1 score is 86%.\n# Next Action would be to improve the model performance with Hyperparameter tuning.","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}