{"cells":[{"metadata":{},"cell_type":"markdown","source":"### What is Customer Churn?\n#### Customer churn means a customer leaving a product subscription or a service. All Companies want to grow their Customer base but while doing this they would want the existing customers to keep using their service. Hence companies build churn models to detect potentially churning out customers and trying to retain them by talking to them, giving offers/rewards, etc. In this notebook we try to predict churn on a customer data.","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Load the dataset","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv', sep=',')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Get to know the size of data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rows = df.shape[0]\ncols = df.shape[1]\nprint(\"Rows: {}, cols:{} \".format(rows, cols))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Check for null values (Although the below statements doesn't catch empty strings. Null and \"\" are different)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum().values.sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Finding unique values in each column","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Look at values in columns like MultipleLines, OnlineSecurity, etc. Values like No Phone Service/No Internet Service can be replaced by \"No\" in their respective columns. Try to look your data in excel and you will get to know why we are doing this.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['MultipleLines'] = df['MultipleLines'].replace({'No phone service': 'No'})\ndf['MultipleLines'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"replace_cols = ['OnlineSecurity', 'OnlineBackup', 'OnlineBackup', \n                'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']\nfor col in replace_cols:\n    print(\"Col:{}, unique: {} \".format(col, df[col].unique()))\n    df[col].replace({'No internet service': 'No'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### check column types and change type if required","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.dtypes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"TotalCharges\"] = df[\"TotalCharges\"].astype(float)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Type conversion to float filled since TotalCharges column has few empty strings in it. Remove them and then try","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['TotalCharges'] = df[\"TotalCharges\"].replace(\" \",np.nan)\ndf = df.reset_index()[df.columns]\nprint(\"Number of null values in Totalcharges: {}\".format(len(df) - df['TotalCharges'].count()))\n\ndf = df[df['TotalCharges'].notnull()]\ndf[\"TotalCharges\"] = df[\"TotalCharges\"].astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bin_labels_5 = ['Tenure1', 'Tenure2', 'Tenure3', 'Tenure4', 'Tenure5']\ndf['TenureBin'] = pd.qcut(df['tenure'],\n                              q=[0, .2, .4, .6, .8, 1],\n                              labels=bin_labels_5)\n\ndf = df.drop('tenure', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"churn = df[df['Churn']=='Yes']\nnon_churn = df[df['Churn']=='No']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"churn_values = df['Churn'].value_counts().values.tolist()\nchurn_keys = df['Churn'].value_counts().keys().tolist()\n\nprint(\"labels are \", churn_values)\nprint(\"values are \", churn_keys)\n\nfig1, ax1 = plt.subplots()\nax1.pie(churn_values, explode=(0, 0.1), labels=churn_keys, autopct='%1.1f%%',\n        shadow=True)\nax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\nplt.legend(['Non Churn', 'Churn'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_pie(col):\n    labels = churn[col].value_counts().keys().tolist()\n    churn_val = churn[col].value_counts().values.tolist()\n    nonchurn_val = non_churn[col].value_counts().values.tolist()\n\n    f, (ax1, ax2) = plt.subplots(1, 2, figsize = (5,5))\n    ax1.pie(churn_val, explode=(0, 0.1), labels=labels, autopct='%1.1f%%',\n            shadow=True)\n    ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n    ax1.set_title('Churn')\n\n    ax2.pie(nonchurn_val, explode=(0, 0.1), labels=labels, autopct='%1.1f%%',\n            shadow=True)\n    ax2.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n    ax2.set_title('Non churn')\n\n    f.suptitle(col)\n    plt.legend(['Non Churn', 'Churn'], loc= 'best')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_pie('SeniorCitizen')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Senior Citizens have a higher tendency to churn","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_pie('gender')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Gender as a univariate feature is neutral towards churning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_pie('Partner')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Those who have partner tend to churn out less. Companies should help their customers get a partner right? XD","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_pie('Dependents')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Customers with dependents churn out less\n#### Similarly we can analyze other binary features ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsns.scatterplot(df['MonthlyCharges'], df['TotalCharges'], hue=df['Churn'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### we see that customers whose monthly charges are high tend to churn the most","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(7,7))\nsns.scatterplot(df['MonthlyCharges'], df['TotalCharges'], hue=df['TenureBin'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Customers tend to churn more in the beginning than in the later part. This pattern is used by companies where they try to retain new customers and make them stick to it.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Data Processing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop('customerID', 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"binary_cols = [col for col in df.columns.tolist() if df[col].nunique()==2]\n\ncategorical_cols = [col for col in df.columns.tolist() if df[col].nunique() < 6]\ncategorical_cols = [col for col in categorical_cols if col not in binary_cols]\n\ntarget_col = ['Churn']\n\nnumerical_cols = [col for col in df.columns.tolist() if col not in binary_cols+categorical_cols+target_col]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\n\nle = LabelEncoder()\nfor col in binary_cols :\n    df[col] = le.fit_transform(df[col])\n    \ndf = pd.get_dummies(data=df, columns=categorical_cols)\n\nscaler = StandardScaler()\ndf[numerical_cols] = scaler.fit_transform(df[numerical_cols])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f = plt.figure(figsize=(19, 15))\nplt.matshow(df.corr(), fignum=f.number)\nplt.xticks(range(df.shape[1]), df.columns, fontsize=14, rotation=90)\nplt.yticks(range(df.shape[1]), df.columns, fontsize=14)\ncb = plt.colorbar()\ncb.ax.tick_params(labelsize=14)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model building","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.offline as py#visualization\npy.init_notebook_mode(connected=True)#visualization\nimport plotly.graph_objs as go#visualization\nimport plotly.tools as tls#visualization\nimport plotly.figure_factory as ff#visualization","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,accuracy_score,classification_report\nfrom sklearn.metrics import roc_auc_score,roc_curve,scorer\nfrom sklearn.metrics import f1_score\nimport statsmodels.api as sm\nfrom sklearn.metrics import precision_score,recall_score\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from numpy import mean\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.ensemble import RandomForestClassifier\nfrom imblearn.ensemble import BalancedRandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target = df['Churn']\ntrain = df.drop('Churn', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# target = target.to_numpy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Split dataset into train and test","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test,y_train,y_test = train_test_split(train, target, test_size=0.15, shuffle = True, stratify=target )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def grid_search(params, model):\n    grid_search = GridSearchCV(model, params, scoring='f1')\n    model = grid_search.fit(X_train, y_train)\n    print ('Best score: %0.3f' % grid_search.best_score_)\n\n    best_parameters = model.best_estimator_\n    print ('Best parameters set:', best_parameters)\n    return model\n\ndef print_classification_report(model):\n    predictions = model.predict(X_test)\n    # conf_matrix = confusion_matrix(y_test,predictions)\n    target_names = ['Not churn', 'Churn']\n    print(\"\\n\")\n    print(classification_report(y_test, predictions, target_names = target_names))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Use Logistic Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters = {'C': (0.1, 0.5,1)}\nlogit = grid_search(parameters, LogisticRegression())\nprint_classification_report(logit)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Using weighted XGboost(Since data is imbalanced i.e number of data points in one class is much greater than the other)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### calculate weight of positive class (we will give more weight to the churn class since it has less number of samples. Hence loss would be high for the classifier if it predicts incorrectly for churn class samples)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"churn_values = df['Churn'].value_counts().values.tolist()\npos_weight = churn_values[0]/churn_values[1]\nprint(\"pos_weight is \", pos_weight)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters = {'max_depth': (5, 8, 10), 'n_estimators': (70, 100, 150)}\nxgb_model = grid_search(parameters, XGBClassifier(scale_pos_weight=pos_weight))\nprint_classification_report(xgb_model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Weighted Random forests","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters = {'n_estimators': (15, 20, 50), 'max_depth': (5,10,12)}\nrf_clf = grid_search(parameters, RandomForestClassifier(class_weight='balanced_subsample'))\nprint_classification_report(rf_clf)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Similarly, you can try a lot of other models. You can also try out different techniques like PCA (actually helpful when there are a lot of dimensions but can be used here to vusualize), SMOTE (instead of using weighted models, we can oversample the churn class by using this technique), plot AUC metric, etc. I have tried to make this notebook not too complex so that you can start easily.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Please comment below if there are any suggestions. I would be happy to consider it. \n#### Like the notebook if you found it helpful. Thanks!!","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}