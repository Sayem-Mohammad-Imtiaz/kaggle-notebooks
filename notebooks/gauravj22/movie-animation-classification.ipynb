{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Classification of Movies \n\nClassifying the movie as animated or not animated on the basis of crew job titles.\nThis is the inspiration of this dataset (as described in the data description)\n\nFirstly, preprocessed data and prepared it. Then used NLP and classification models for accomplishing the task."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfrom sklearn.model_selection import train_test_split\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loading the Dataset as pandas.DataFrame"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_credits = pd.read_csv('../input/tmdb-movie-metadata/tmdb_5000_credits.csv')\ndf_movies = pd.read_csv('../input/tmdb-movie-metadata/tmdb_5000_movies.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_credits.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_movies.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_credits.rename(columns = {'movie_id':'id'}, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The column 'title' and 'original_title' are equivalent\nSo dropping the 'original_title' column"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_movies.drop('original_title', axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Merging the Datasets\n\nMerging the 2 datasets on the columns 'id' and 'title' as primary key "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_merged = pd.merge(df_credits, df_movies, on = ['id','title'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Handling the Json Columns\n\nApplying the literal_eval function of ast on all the json columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"from ast import literal_eval\n\njson_cols = ['cast', 'crew', 'genres', 'keywords','production_companies', 'production_countries','spoken_languages']\n\nfor col in json_cols:\n    df_merged[col] = df_merged[col].apply(literal_eval)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Extracting the features from Json Columns\n\n1. Genres list (from Genres column)\n2. Jobs (from Crew column)\n3. Percentage of voice artists among total cast (from cast column)"},{"metadata":{},"cell_type":"markdown","source":"#### Helper Functions for the same"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_genre(x):\n    if(isinstance(x, list)):\n        genre = [i['name'] for i in x]\n    \n    return genre\n\ndef get_jobs(x):\n    if(isinstance(x, list)):\n        jobs = [i['job'] for i in x]\n    return jobs\n\ndef get_characternames(x):\n    if(isinstance(x, list)):\n        chr_name = [i['character'] for i in x]\n        countc = 0\n        for j in chr_name:\n            if('(voice)' in j):\n                countc += 1\n        if(len(chr_name)!=0):\n            return (countc/len(chr_name))\n        else:\n            return 0\n        \ndef get_labels(x):\n    if(len(x)==0):\n        return np.nan\n    elif('Animation' in x):\n        return 1\n    else:\n        return 0\n\ndef get_costume_labels(x):\n    if 'Costume Design' in x:\n        return 1\n    else:\n        return 0\n    \ndef get_genre_cd(x):\n    if(isinstance(x, list)):\n        dept = [i['department'] for i in x]\n    if 'Lighting' in dept:\n        return 0\n    else:\n        return 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_merged['genres'] = df_merged['genres'].apply(get_genre)\ndf_merged['crew_jobs'] = df_merged['crew'].apply(get_jobs)\ndf_merged['percent_of_voice_artists'] = df_merged['cast'].apply(get_characternames)\ndf_merged['labels'] = df_merged['genres'].apply(get_labels)\ndf_merged['costume'] = df_merged['crew_jobs'].apply(get_costume_labels)\ndf_merged['lighting_dept'] = df_merged['crew'].apply(get_genre_cd)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Rounding off the percentage to 3 decimal places"},{"metadata":{"trusted":true},"cell_type":"code","source":"for x in range(0,len(df_merged['percent_of_voice_artists'])):\n    df_merged['percent_of_voice_artists'][x] = np.round(df_merged['percent_of_voice_artists'][x],3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dropping the movies which are labelled as None\n\nThere are 28 such movies"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_merged.labels.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idxsc = df_merged[((df_merged.labels != 1) & (df_merged.labels != 0))].index\ndf_merged.drop(idxsc, inplace = True)\ndf_merged.reset_index(drop= True, inplace= True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_merged.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"AnimatedMoviesCount = np.sum(df_merged['labels'] == 1)\nNotAnimatedMoviesCount = np.sum(df_merged['labels'] == 0)\n\nprint(\"Number of Animated Movies are: \", AnimatedMoviesCount)\nprint(\"Number of Not Animated Movies are: \", NotAnimatedMoviesCount)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_merged.costume.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_merged.lighting_dept.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c = np.where(df_merged.labels==1)[0]\nsum_budget = 0\nfor x in c:\n    sum_budget += df_merged.budget[x]\navg_budget = sum_budget/len(c)\nprint(\"Average Budget of Animated Movie: \",str(avg_budget))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Taking into account only those movies having atleast 7 crew members\n\nSo as to handle the quality of training data\nTested for multiple values, but 7 yielded best result"},{"metadata":{"trusted":true},"cell_type":"code","source":"idx=[]\nfor x in range(0,df_merged.shape[0]):\n    if len(df_merged.crew_jobs[x])>7:\n        idx.append(x)\nprint(\"Number of Movies with more than 7 crew members: \",str(len(idx)))\n\ndf = df_merged.iloc[idx,:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"AnimatedMoviesCount2 = np.sum(df['labels'] == 1)\nNotAnimatedMoviesCount2 = np.sum(df['labels'] == 0)\n\nprint(\"Number of Animated Movies are: \", AnimatedMoviesCount2)\nprint(\"Number of Not Animated Movies are: \", NotAnimatedMoviesCount2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Converting 'crew_jobs' from list to string (in lower form) via join function"},{"metadata":{"trusted":true},"cell_type":"code","source":"def join_strings(x):\n    return \", \".join(x)\n\ndef str_lower(x):\n    return x.lower()\n\ndf['crew_jobs'] = df['crew_jobs'].apply(join_strings)\ndf['crew_jobs'] = df['crew_jobs'].apply(str_lower)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['labels'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model to classify Movie \n\nClassifying a movie as animated or not based on the crew job titles (using the data prepared above)"},{"metadata":{"trusted":true},"cell_type":"code","source":"X1 = df['crew_jobs']\nY1 = df['labels']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train1, X_test1, y_train1, y_test1 = train_test_split(X1, Y1, test_size=0.20, random_state=53)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nfrom sklearn.metrics import accuracy_score, recall_score\nimport seaborn as sns\nimport matplotlib.pyplot as plt \n\ndef score_output(y_test, y_pred):\n    \n    cm = metrics.confusion_matrix(y_test, y_pred)\n    clf_report = metrics.classification_report(y_test, y_pred)\n    print(cm)\n    print(clf_report)\n    accuracy = accuracy_score(y_test, y_pred)\n    print('The Accuracy on The Test Set is: %s' % accuracy)\n\n    ax= plt.subplot()\n    sns.heatmap(cm, annot=True, ax = ax, fmt='d', cmap = 'inferno'); #annot=True to annotate cells\n\n    # labels, title and ticks\n    ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n    ax.set_title('Confusion Matrix'); \n    ax.xaxis.set_ticklabels(['Non-Animated', 'Animated']); ax.yaxis.set_ticklabels(['Non-Animated', 'Animated']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import spacy\nnlp = spacy.load('en_core_web_sm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from spacy.lang.en import STOP_WORDS\nstop_words_str = \" \".join(STOP_WORDS)\nstop_words_lemma = set(word.lemma_ for word in nlp(stop_words_str))\n\nadditional_words = ['editor', 'director', 'producer', 'writer', 'assistant', 'sound']\n\nfor word in additional_words:\n    stop_words_lemma = stop_words_lemma.union({word})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def lemmatizer(text):\n     return [word.lemma_ for word in nlp(text)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Without Stop Words**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer,TfidfTransformer\nfrom sklearn.svm import SVC\nfrom sklearn.pipeline import Pipeline\n\nbow = TfidfVectorizer(ngram_range = (1,1))\n\npipe = Pipeline([('bag_of_words', bow),('classifier', SVC())])\npipe.fit(X_train1,y_train1)\n\nprint(\"Without Stop Words\")\nprint('Training accuracy: {}'.format(pipe.score(X_train1,y_train1)))\ny_pred = pipe.predict(X_test1)\nscore_output(y_test1, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"**With Stop Words**"},{"metadata":{"trusted":true},"cell_type":"code","source":"bow = TfidfVectorizer(ngram_range = (1,1), stop_words = stop_words_lemma)\n\npipe2 = Pipeline([('bag_of_words', bow),('classifier', SVC())])\npipe2.fit(X_train1,y_train1)\n\n\nprint(\"With Stop Words\")\nprint('Training accuracy: {}'.format(pipe2.score(X_train1,y_train1)))\ny_pred2 = pipe2.predict(X_test1)\nscore_output(y_test1, y_pred2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is evident from above results, SVM without stop words yields better resultd in terms of Recall, F1 score and Accuracy (Taking into count class imbalance and overfitting issues)\n\nThus, we can continue with SVM without stop words"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}