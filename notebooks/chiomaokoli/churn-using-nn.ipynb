{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**In this project, we aim to predict the churn for a bank, i.e, given a Bank customer, can we build a classifier which can determine whether they will leave or not using Neural networks**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom sklearn import metrics \n%matplotlib inline\nfrom sklearn.model_selection import train_test_split \n\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import datafile\ndf = pd.read_csv('../input/bank-customer-churn-modeling/Churn_Modelling.csv')\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop unique columns such as row number and id \ndf1= df.drop(['RowNumber','CustomerId','Surname'], axis=1)\ndf1.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **EXPLORATORY DATA ANALYSIS**"},{"metadata":{"trusted":true},"cell_type":"code","source":"(df1==0).sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Bi-variate Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pairplot using sns\nimport seaborn as sns\nsns.pairplot(df1 , diag_kind = 'kde')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = abs(df1.corr()) # correlation matrix\nlower_triangle = np.tril(corr, k = -1)  # select only the lower triangle of the correlation matrix\nmask = lower_triangle == 0  # to mask the upper triangle in the following heatmap\n\nplt.figure(figsize = (15,8))  # setting the figure size\nsns.set_style(style = 'white')  # Setting it to white so that we do not see the grid lines\nsns.heatmap(lower_triangle, center=0.5, cmap= 'Blues', annot= True, xticklabels = corr.index, yticklabels = corr.columns,\n            cbar= False, linewidths= 1, mask = mask)   # Da Heatmap\nplt.xticks(rotation = 50)   # Aesthetic purposes\nplt.yticks(rotation = 20)   # Aesthetic purposes\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.drop(['IsActiveMember'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.countplot('Exited', data=df1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.boxplot(x='Exited', y='EstimatedSalary', data=df1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1['Exited'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Changing categorical data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"catcals = ['Geography', 'Gender','NumOfProducts', 'HasCrCard']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in catcals:\n    df1[col] = df1[col].astype('category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating dummies for the categorical datatypes\ndf1 = pd.get_dummies(df1, columns=catcals)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Distinguishing the feature and target dataset**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separating dependent and independent variables\nx = df1.drop('Exited',axis=1)\ny = df1['Exited']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting the data into train and test\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Normalizing the train and test data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Normalize\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nx_train= scaler.fit_transform(x_train)\nx_test = scaler.fit_transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Initialize and build model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Initializing the model\nmodel = Sequential()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define model architecture\n\nmodel.add(Dense(9, input_dim=16,activation='relu'))\nmodel.add(Dense(9, activation ='relu'))\nmodel.add(Dense(1,activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(x_train, y_train, epochs=200, batch_size=200, verbose=1) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss, acc = model.evaluate(x_test, y_test, verbose=0)\nprint('Accuracy: %.3f'  % acc)\nprint('Loss: %.3f' % loss)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Predict the result using 0.5 threshold"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predict = model.predict(x_test)       #default threshold of model.predict is 0.5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predict = (y_predict > 0.5)\nprint(y_predict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = []\nfor val in y_predict:\n    y_pred.append(np.argmax(val))\n#print(y_pred)    \n#convert 0 1 to 1 and 1 0 as 0\ncm = metrics.confusion_matrix(y_test,y_pred)\nprint(cm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = ((cm[0][0]+cm[1][1])*100)/(cm[0][0]+cm[1][1]+cm[0][1]+cm[1][0])\nprint(acc,'% of testing was classified correctly')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cr=metrics.classification_report(y_test,y_pred)\nprint(cr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Optimizing the model**\n\nTo optimize the model we can consider some parameters, such as \n\n- The type of Architecture \n- Number of Layers \n- Number of neurons\n- Regularization parameters \n- Learning Rate\n- Weight sharing \n- Dropout rate \nTuning these parameters can/would give us a better accuracy score. \n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}