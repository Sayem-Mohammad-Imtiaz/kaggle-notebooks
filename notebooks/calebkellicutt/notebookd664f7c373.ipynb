{"cells":[{"metadata":{},"cell_type":"markdown","source":"The goal of this project is to build out a term risk classifier. You give the classifier a one word term and it will output whether that term is associated with a higher or lower risk for Covid-19. In order to build this out, we use term frequencyâ€“inverse document frequency to retrieve documents, and provided document embeddings as our input to a Linear Discriminant Analysis classifier."},{"metadata":{},"cell_type":"markdown","source":"First bring in all of the libraries we will need for our project"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pickle\nimport pandas as pd\nfrom collections import defaultdict\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem.porter import PorterStemmer\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we begin by reading in all of the data in metadata.csv and setting up our tf-idf helper functions and structures"},{"metadata":{"trusted":true},"cell_type":"code","source":"meta_df = pd.read_csv(\"/kaggle/input/CORD-19-research-challenge/metadata.csv\")\nnum = len(meta_df)\n\nporter = PorterStemmer()\n \ndef getalpha(string):\n    res = ''\n    for s in string:\n        if s.isalpha():\n            res += s\n    return res\n \ndef get_frequency(abstract):\n    words = word_tokenize(abstract)\n    words = [getalpha(k).lower() for k in words if len(getalpha(k)) > 0]\n    words = [porter.stem(k) for k in words]\n    freq = defaultdict(lambda: 0)\n    for i in words:\n        freq[i] += 1\n    return freq\n \nterm_frequency = {} # map from document -> word -> frequency\ndoc_frequency = defaultdict(lambda: 0) # map from word -> frequency","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Supposing you have already have some of the data processed, you can use this next section of code to pick up from where you left off"},{"metadata":{"trusted":true},"cell_type":"code","source":"with open(\"/kaggle/working/result.pkl\", \"rb\") as f:\n    term_frequency, doc_frequency = pickle.load(f)\n    doc_frequency = defaultdict(lambda: 0, doc_frequency) # map from word -> frequency","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Whether you have some data processed, or none at all, you will use the next section of code to process all of the remaining data. When running, for every 1000 documents processed, it will print the fraction of documents processed/ total number of documents. Note that because the abstract of some of the documents are null, only about 69% of the documents will actually be processed and used. Once this is complete, the data can be saved to a pickle file in the next step for future use."},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"for i, row in meta_df[[\"cord_uid\", \"abstract\"]].iterrows():\n    if row.cord_uid in term_frequency:\n        continue\n    if len(term_frequency) % 1000 == 1:\n        print(len(term_frequency) / num)\n    if type(row.abstract) is not str:\n        continue\n    freqs = get_frequency(row.abstract)\n    term_frequency[row.cord_uid] = {}\n    tot = sum(freqs.values())\n    \n    for k in freqs:\n        term_frequency[row.cord_uid][k] = freqs[k] / tot\n        doc_frequency[k] += 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can now save however much data was processed in the step above"},{"metadata":{"trusted":true},"cell_type":"code","source":"with open(\"/kaggle/working/result-test.pkl\", \"wb\") as f:\n    pickle.dump((term_frequency, dict(doc_frequency)), f)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We now load in the data from the saved pickle file and set up our function that will return the TF-IDF for any given term for each document that it appears in. Note that we have a built in threshold (thresh) so that we will only return documents with high enough TF-IDFs, indicating that the term is of some importance within the returned documents."},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('/kaggle/working/result.pkl', \"rb\") as f:\n    tf, dfa = pickle.load(f)\n\ndef get_tfidf_term(term):\n    thresh = .05\n    porter = PorterStemmer()\n    term = porter.stem(term.lower())\n    idf = np.log(len(tf) / dfa[term])\n    tfidf = {\n        doc: tf[doc][term] * idf for doc in tf if term in tf[doc]\n    }\n    tfidf={doc: tfidf[doc] for doc in tfidf if tfidf[doc] > thresh}\n    return tfidf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below we have a simple check to see what different stemmed terms we have in our documents. We can use this to further fine tune our classification algorithm by including words we see here with an associated level of risk in either the 'good' or 'bad' risk terms. Note that these stemmed terms may look strange or incomplete because they are representations of different words that fall into the same idea, for example smoke, smoking, and smoker may all be represented in this data as 'smok'."},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"dfa","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We know use terms known to be associated with high risk patients and terms known to be associated with low risk patients to get a set of documents that contain these terms with relatively high frequency."},{"metadata":{"trusted":true},"cell_type":"code","source":"bad_terms = [\"Cancer\",\"compromise\", \"Senior\", \"Pulmonary\",\"Pregnancy\",\"Old\", \"Death\",\"Obesity\",\"Sickle\",\"Smoking\",\"Diabetes\",\"Complication\",\"Disease\", \"issue\"]\n\ngood_terms = [\"immune\", \"success\", \"aid\", \"Recover\", \"prevent\", \"recovery\",\"Healthy\",\"Thin\",\"Athletic\",\"Young\",\"Fit\", \"good\", \"D\", \"Well\", \"Help\"]\nbad_docs = []\ngood_docs = []\n\nfor term in bad_terms:\n    bad_docs.extend(get_tfidf_term(term).keys())\n    \nfor term in good_terms:\n    good_docs.extend(get_tfidf_term(term).keys())\n    \nbad_docs = set(bad_docs)\ngood_docs = set(good_docs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below we check on a couple of things to get more information about the documents we retrieved above:\n1. We find the ratio of document intersection for good and bad docs and the minimum between the two. This tells us how separated the smaller set is from the larger set\n2. We find the ration of intersection vs union of the good and bad sets. This tells us something very similar to the first, but with more regard to the dataset as a whole\n3. We find the total number of docs in our good set\n4. We find the total number of docs in our bad set"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(bad_docs.intersection(good_docs))/min(len(bad_docs), len(good_docs)))\nprint(len(bad_docs.intersection(good_docs))/len(bad_docs.union(good_docs)))\n\nprint(len(good_docs))\nprint(len(bad_docs))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we load in the data for document embeddings that have already been provided by Kaggle"},{"metadata":{"trusted":true},"cell_type":"code","source":"embeddings = pd.read_csv('/kaggle/input/CORD-19-research-challenge/cord_19_embeddings/cord_19_embeddings_2021-01-18.csv', sep=',')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After loading in the embeddings we take the subset of embeddings for good docs and for bad docs. These embeddings are what our algorithm will be training on. The idea is that documents containing information about low risk terms will have similar document embeddings and that high risk terms will also have similar document embeddings. Using this assumption we can build a classifier that will classify based on the average document embedding of documents associated with any given term."},{"metadata":{"trusted":true},"cell_type":"code","source":"good = embeddings[embeddings.ug7v899j.isin(good_docs)].drop(\"ug7v899j\", axis=1)\nbad = embeddings[embeddings.ug7v899j.isin(bad_docs)].drop(\"ug7v899j\", axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We now more specifically separate our document data into good (0) and bad (1) document embeddings"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.concatenate((np.array(good), np.array(bad)))\nY = [0 if i < len(good) else 1 for i in range(len(X))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We split our data below into train and test data to train and see the accuracy on our 'ground truth' documents. "},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(\nX, Y, test_size=0.15)\n\nclf = LinearDiscriminantAnalysis()\nclf.fit(X_train, Y_train)\nclf.score(X_test, Y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We now introduce a function that will take in a term and output the mean associated risk of all of the documents that the term has high frequency with."},{"metadata":{"trusted":true},"cell_type":"code","source":"def pred(term):\n    encodings = embeddings[embeddings.ug7v899j.isin(get_tfidf_term(term).keys())].drop(\"ug7v899j\", axis=1)\n    predictions = clf.predict(encodings)\n    mean_pred = np.mean(predictions)\n    risk_assessment = \"Higher Risk\"\n    if(mean_pred < .5):\n        risk_assessment = \"Lower Risk\"\n    return mean_pred, risk_assessment","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here below you can now put through different terms to see how they rank between high risk and low risk along with the actual mean value between 0 and 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred(\"elderly\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The classifier performs fairly well given the prior knowledge of high and low risk terms that we had given the program. A good extension and next step of this project would be to make this a semi surpervised model that finds terms that classify strongly with higher or lower risk and then including them in the terms used for training."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}