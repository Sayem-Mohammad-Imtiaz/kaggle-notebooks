{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/weather-dataset-rattle-package/weatherAUS.csv\", parse_dates = ['Date'])\nprint(df.shape)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe(include = 'all').T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#amount empty data\ncol_empty = df.apply(lambda x: f'{(x.isnull().sum()/df.shape[0]).round(2)} %').sort_values()\ncol_empty","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop columns with empty data > 10%\ndf.drop(col_empty.index.to_list()[-4:], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check columns\ndf.columns.to_list()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.iloc[0,:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# add new columns \ndef get_season(n):\n    if n in  [12,1,2]: return 1\n    elif n in [3,4,5]:  return 2\n    elif n in [6,7,8]:  return 3\n    else: return 4\n    \n\ndf['month'] = df['Date'].dt.month\ndf['Season'] = df['month'].apply(lambda x: get_season(x))\ndf['delta_temp'] = df['MaxTemp'] - df['MinTemp']\ndf['new_wind'] = np.sqrt(df['WindSpeed3pm'] * df['WindGustSpeed'] * df['WindSpeed9am'])\ndf['new_humidity'] = np.sqrt(df['Humidity9am'] * df['Humidity3pm'])\ndf['new_pressure'] = np.sqrt(df['Pressure9am'] * df['Pressure3pm'])\n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns.shape # all correct","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[[ 'RainTomorrow']].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_cols(df) -> list:\n    '''\n    function return list of name numbers and categorials columns\n    '''\n    categorical_feature_mask = df.dtypes == object\n    number_feature_mask = df.dtypes != object\n    numbers_cols = df.columns[number_feature_mask].tolist()\n    categorical_cols = df.columns[categorical_feature_mask].tolist()\n    return [numbers_cols, categorical_cols]\n\nnum_cols, cat_cols = get_cols(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fill na data\nfrom sklearn.impute import SimpleImputer\n\n\nimp_mean_num = SimpleImputer(strategy='mean')\nimp_mean_cat = SimpleImputer(strategy='most_frequent')\n\nfor col in df.columns.to_list():\n    if col in num_cols:\n        df[col] = imp_mean_num.fit_transform(df[[col]])\n    else:\n        df[col] = imp_mean_cat.fit_transform(df[[col]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check previous step\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n\nle = LabelEncoder()\ndf[['RainToday', 'RainTomorrow']] = df[['RainToday', 'RainTomorrow']].apply(lambda x: le.fit_transform(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# show correlations\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize = (15,6))\nsns.heatmap(df.corr(), annot = True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = df[num_cols].columns.to_list()\ndt = df[num_cols]\n\nfor i,v in enumerate(cols):\n    for t in range(i, len(cols)):\n        if v != cols[t]:\n            if dt.corr()[v][cols[t]] > 0.85:\n                print(v, cols[t], dt.corr()[v][cols[t]].round(2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#delete columns \ndf.drop(['Temp9am', 'Temp3pm', 'new_humidity', 'Pressure3pm', 'new_pressure'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr()['RainTomorrow'].abs().sort_values()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**New column have a good correlation with target, drop unnecessary columns (corr < 0.1 with target) **"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['month', 'Date', 'Season', 'MinTemp', 'WindSpeed3pm', 'WindSpeed9am'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Try to split WindGustDir and WindDir9am **"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['WindGust_W'] = [1 if 'W' in list(i) else 0 for i in df['WindGustDir']]\ndf['WindGust_N'] = [1 if 'N' in list(i) else 0 for i in df['WindGustDir']]\ndf['WindGust_S'] = [1 if 'S' in list(i) else 0 for i in df['WindGustDir']]\ndf['WindGust_E'] = [1 if 'E' in list(i) else 0 for i in df['WindGustDir']]\n\ndf['WindDir9am_W'] = [1 if 'W' in list(i) else 0 for i in df['WindDir9am']]\ndf['WindDir9am_N'] = [1 if 'N' in list(i) else 0 for i in df['WindDir9am']]\ndf['WindDir9am_S'] = [1 if 'S' in list(i) else 0 for i in df['WindDir9am']]\ndf['WindDir9am_E'] = [1 if 'E' in list(i) else 0 for i in df['WindDir9am']]\n\ndf['WindDir3pm_W'] = [1 if 'W' in list(i) else 0 for i in df['WindDir3pm']]\ndf['WindDir3pm_N'] = [1 if 'W' in list(i) else 0 for i in df['WindDir3pm']]\ndf['WindDir3pm_S'] = [1 if 'W' in list(i) else 0 for i in df['WindDir3pm']]\ndf['WindDir3pm_E'] = [1 if 'W' in list(i) else 0 for i in df['WindDir3pm']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (15,6))\nsns.heatmap(df.corr(), annot = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_cols, cat_cols = get_cols(df)\n\ncols = df[num_cols].columns.to_list()\ndt = df[num_cols]\n\nfor i,v in enumerate(cols):\n    for t in range(i, len(cols)):\n        if v != cols[t]:\n            if dt.corr()[v][cols[t]] > 0.85:\n                print(v, cols[t], dt.corr()[v][cols[t]].round(2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Drop unnecessary columns\ndf.drop(['WindDir3pm_N', 'WindDir3pm_S', 'WindDir3pm_E'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (15,6))\nsns.heatmap(df.corr(), annot = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr()['RainTomorrow'].abs().sort_values()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**unfortunately, our hypothesis turned out to be incorrect, so we delete the columns (except WindGust_E)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['WindGust_S', 'WindGust_N', 'WindDir3pm_W', \n         'WindDir9am_S', 'WindDir9am_N', 'WindDir9am_W',\n         'WindDir9am_E', 'WindGust_W'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# work with categorial data\nnum_cols, cat_cols = get_cols(df)\n\nenc = LabelEncoder()\ndf[cat_cols] = df[cat_cols].apply(lambda x: le.fit_transform(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# work with number data\nfrom sklearn.preprocessing import Normalizer\n\nscaler = Normalizer()\ndf[num_cols] = df[num_cols].apply(lambda x: le.fit_transform(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = df.drop(['RainTomorrow'], axis = 1)\ny = df['RainTomorrow']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify = df['RainTomorrow'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ****KNeighborsClassifier****"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.model_selection import GridSearchCV\n\n\nmodel = KNeighborsClassifier(n_neighbors = 20, weights = 'distance')\nmodel.fit(X_train,y_train)\n\naccuracy_score(y_test, model.predict(X_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### KNN best score = 81,8%"},{"metadata":{},"cell_type":"markdown","source":"# LogisticRegression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression()\nmodel.fit(X_train,y_train)\n\naccuracy_score(y_test, model.predict(X_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params ={\n    'C': np.logspace(-2,2,10),\n    'solver': ['lbfgs', 'liblinear', 'sag', 'saga']\n}\n\ngrid = GridSearchCV(LogisticRegression(random_state = 0), params, scoring = 'accuracy')\ngrid.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(y_test, grid.predict(X_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### LogisticRegression best score = 83,9%"},{"metadata":{},"cell_type":"markdown","source":"# RandomForestClassifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\n\nparams ={\n    'criterion': ['entropy'],\n    'max_depth': [16],\n    'n_estimators': range(10,101,10)\n}\n\ngrid = GridSearchCV(RandomForestClassifier(random_state = 0), params, scoring = 'accuracy')\ngrid.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(y_test, grid.predict(X_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### RandomForestClassifier best score = 84,8%"},{"metadata":{},"cell_type":"markdown","source":"# Conclusion"},{"metadata":{},"cell_type":"markdown","source":"# The best model - RandomForestClassifier "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}