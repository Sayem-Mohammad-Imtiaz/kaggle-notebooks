{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **News Category Classification using LSTM**\n**News categories included in this dataset include business; science and technology; entertainment; and health.** \n\n**Different news articles that refer to the same news item (e.g., several articles about recently released employment statistics) are also categorized together.**","metadata":{}},{"cell_type":"code","source":"#importing libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport re\nfrom tensorflow import keras\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.corpus import stopwords\nfrom tensorflow.keras.preprocessing.text import one_hot\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.layers import Embedding,LSTM,Dense,Dropout\nfrom tensorflow.keras.models import Sequential\nfrom keras.utils.np_utils import to_categorical","metadata":{"execution":{"iopub.status.busy":"2021-07-08T18:27:22.986931Z","iopub.execute_input":"2021-07-08T18:27:22.9873Z","iopub.status.idle":"2021-07-08T18:27:22.992726Z","shell.execute_reply.started":"2021-07-08T18:27:22.987265Z","shell.execute_reply":"2021-07-08T18:27:22.991881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#importing the dataset\ndir = pd.read_csv('../input/news-aggregator-dataset/uci-news-aggregator.csv')\npd.set_option('display.max_columns', None)\ndir.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-08T18:27:23.00017Z","iopub.execute_input":"2021-07-08T18:27:23.000437Z","iopub.status.idle":"2021-07-08T18:27:24.33925Z","shell.execute_reply.started":"2021-07-08T18:27:23.000413Z","shell.execute_reply":"2021-07-08T18:27:24.338303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**WE HAVE ONLY TWO FEATURES OF USE**\n\n1. **TITLE**\n2. **CATEGORY**","metadata":{}},{"cell_type":"code","source":"#creating a new dataset with only relevant features.\nds = dir[['TITLE','CATEGORY']]\nds.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-08T18:27:24.340835Z","iopub.execute_input":"2021-07-08T18:27:24.341181Z","iopub.status.idle":"2021-07-08T18:27:24.361142Z","shell.execute_reply.started":"2021-07-08T18:27:24.341144Z","shell.execute_reply":"2021-07-08T18:27:24.360338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**HERE YOU CAN SEE THAT ALL CATEGORIES ARE IN ORDER(ALL B's TOGETHER AND SO ON), THEREFORE SHUFFLING THEM FOR OUR CONVENIENCE**","metadata":{}},{"cell_type":"code","source":"#shuffling rows with the help of sample, here (frac = 1) means return all rows\nds = ds.sample(frac=1).reset_index(drop=True)\nds.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-08T18:27:24.362948Z","iopub.execute_input":"2021-07-08T18:27:24.363328Z","iopub.status.idle":"2021-07-08T18:27:24.465345Z","shell.execute_reply.started":"2021-07-08T18:27:24.363291Z","shell.execute_reply":"2021-07-08T18:27:24.464563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**DATASET IS NOW SHUFFLED**","metadata":{}},{"cell_type":"code","source":"#checking for null values\nds.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-07-08T18:27:24.467042Z","iopub.execute_input":"2021-07-08T18:27:24.467404Z","iopub.status.idle":"2021-07-08T18:27:24.570996Z","shell.execute_reply.started":"2021-07-08T18:27:24.467366Z","shell.execute_reply":"2021-07-08T18:27:24.570058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n**NO NULL VALUES FOUND**","metadata":{}},{"cell_type":"code","source":"#plotting graph for categories\nsns.countplot(x = 'CATEGORY',data = ds)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T18:27:24.57255Z","iopub.execute_input":"2021-07-08T18:27:24.572934Z","iopub.status.idle":"2021-07-08T18:27:25.080321Z","shell.execute_reply.started":"2021-07-08T18:27:24.572896Z","shell.execute_reply":"2021-07-08T18:27:25.07936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**THERE ARE FOUR TYPES OF CATEGORIES-**\n1. **b : business (~115000)**\n2. **t : science and technology (~110000)**\n3. **e : entertainment (~150000)**\n4. **m : health (~40000)**\n","metadata":{}},{"cell_type":"markdown","source":"**NOW MOVING ONTO CLEANING AND PREPROCESSING OF THE TEXT DATA**","metadata":{}},{"cell_type":"code","source":"#cleaning and preprocessing the text\n\ncleaned = []\nfor i in range(0,len(ds)):\n    \n    #removing any other words than (a-z) and (A-Z)\n    msg = re.sub('[^a-zA-Z]',' ',ds['TITLE'][i])\n    \n    #converting all texts to lower case\n    msg = msg.lower()\n    \n    #tokenizing\n    msg = msg.split()\n    \n    #stemming and removing stopwords\n    ps = PorterStemmer()\n    msg = [ps.stem(words) for words in msg if not words in set(stopwords.words('english'))]\n    msg = ' '.join(msg)\n    cleaned.append(msg)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T18:27:25.082194Z","iopub.execute_input":"2021-07-08T18:27:25.082832Z","iopub.status.idle":"2021-07-08T18:37:28.055533Z","shell.execute_reply.started":"2021-07-08T18:27:25.082792Z","shell.execute_reply":"2021-07-08T18:37:28.054695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#cleaned data with no punctuations,stopwords and all texts in lowercase.\ncleaned[:5]","metadata":{"execution":{"iopub.status.busy":"2021-07-08T18:37:28.056985Z","iopub.execute_input":"2021-07-08T18:37:28.057317Z","iopub.status.idle":"2021-07-08T18:37:28.064471Z","shell.execute_reply.started":"2021-07-08T18:37:28.057282Z","shell.execute_reply":"2021-07-08T18:37:28.063642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#taking dictionary size 5000\ndict_size = 5000\n\n#one hot encoding\none_hot_mat = [one_hot(words,dict_size) for words in cleaned]\n\n#now for input as an embedding layer length of all rows should be equal therefore applying padding\n#this will make size of all rows equal by adding 0 at starting of the shorter rows\n#size of each row will be equal to length of longest row.\nembedded_layer = pad_sequences(one_hot_mat,padding = 'pre',maxlen = 150)\nembedded_layer","metadata":{"execution":{"iopub.status.busy":"2021-07-08T18:37:28.066952Z","iopub.execute_input":"2021-07-08T18:37:28.067299Z","iopub.status.idle":"2021-07-08T18:37:35.912565Z","shell.execute_reply.started":"2021-07-08T18:37:28.067263Z","shell.execute_reply":"2021-07-08T18:37:35.911785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#now creating independent and dependent features\nx = embedded_layer\ny = np.array(ds['CATEGORY'])","metadata":{"execution":{"iopub.status.busy":"2021-07-08T18:37:35.914137Z","iopub.execute_input":"2021-07-08T18:37:35.91449Z","iopub.status.idle":"2021-07-08T18:37:35.920297Z","shell.execute_reply.started":"2021-07-08T18:37:35.914454Z","shell.execute_reply":"2021-07-08T18:37:35.919426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#converting categorical values of y using OneHotEncoding\nle = LabelEncoder()\ny = le.fit_transform(y)\ny = to_categorical(y,4)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T18:37:35.9216Z","iopub.execute_input":"2021-07-08T18:37:35.922133Z","iopub.status.idle":"2021-07-08T18:37:36.059601Z","shell.execute_reply.started":"2021-07-08T18:37:35.922096Z","shell.execute_reply":"2021-07-08T18:37:36.058743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y[:10]","metadata":{"execution":{"iopub.status.busy":"2021-07-08T18:37:36.060857Z","iopub.execute_input":"2021-07-08T18:37:36.061389Z","iopub.status.idle":"2021-07-08T18:37:36.068342Z","shell.execute_reply.started":"2021-07-08T18:37:36.061346Z","shell.execute_reply":"2021-07-08T18:37:36.06722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#splitting the Dataset into Train and Test set\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\nprint(x_train.shape,y_train.shape)\nprint(x_test.shape,y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T18:37:36.069896Z","iopub.execute_input":"2021-07-08T18:37:36.070293Z","iopub.status.idle":"2021-07-08T18:37:36.215788Z","shell.execute_reply.started":"2021-07-08T18:37:36.070252Z","shell.execute_reply":"2021-07-08T18:37:36.214927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creating model using LSTM\nmodel = Sequential()\n\n#taking number features as 50\nmodel.add(Embedding(dict_size,50,input_length = len(x[0])))\nmodel.add(Dropout(0.2))\n\n#adding LSTM layers with 100 neurons\nmodel.add(LSTM(100))\n\n#adding output layer \nmodel.add(Dense(4,activation=\"softmax\"))\n\n#compiling the model\nmodel.compile(loss=\"categorical_crossentropy\",optimizer='adam',metrics=[\"accuracy\"])\n\n#summary of model\nmodel.summary()\n\n#training the model\nrnn = model.fit(x_train, y_train, validation_data = (x_test,y_test), epochs = 10, batch_size = 256)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T18:37:36.217006Z","iopub.execute_input":"2021-07-08T18:37:36.217376Z","iopub.status.idle":"2021-07-08T18:42:32.711511Z","shell.execute_reply.started":"2021-07-08T18:37:36.217338Z","shell.execute_reply":"2021-07-08T18:42:32.710552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#evaluating our model\nmodel.evaluate(x_test,y_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T18:42:32.712997Z","iopub.execute_input":"2021-07-08T18:42:32.71335Z","iopub.status.idle":"2021-07-08T18:42:45.437761Z","shell.execute_reply.started":"2021-07-08T18:42:32.713313Z","shell.execute_reply":"2021-07-08T18:42:45.436952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#making predictions\npred = model.predict(x_test)\n\n#saving index of maximum value of pred in preds (because in pred probabilities will come)\npreds = []\nfor i in range(0,len(pred)):\n    preds.append(pred[i].argmax())\n\n#saving index of maximum value of y_test in actual\nactual = []\nfor i in range(0,len(y_test)):\n    actual.append(y_test[i].argmax())\n","metadata":{"execution":{"iopub.status.busy":"2021-07-08T18:42:45.438969Z","iopub.execute_input":"2021-07-08T18:42:45.439323Z","iopub.status.idle":"2021-07-08T18:42:54.363938Z","shell.execute_reply.started":"2021-07-08T18:42:45.439285Z","shell.execute_reply":"2021-07-08T18:42:54.363039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#classification report\nfrom sklearn import metrics\nreport = metrics.classification_report(actual, preds, target_names = ['b','t','e','m'])\nprint(report)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T18:42:54.365296Z","iopub.execute_input":"2021-07-08T18:42:54.365646Z","iopub.status.idle":"2021-07-08T18:42:54.579238Z","shell.execute_reply.started":"2021-07-08T18:42:54.365595Z","shell.execute_reply":"2021-07-08T18:42:54.578356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking category of a text\ntxt = [\"An apple a day keeps doctor away.\"]\n\n#cleaning and preprocessing the text\ncleaned = []\nfor i in range(0,len(txt)):\n    msg = re.sub('[^a-zA-Z]',' ',txt[i])\n    msg = msg.lower()\n    msg = msg.split()\n    ps = PorterStemmer()\n    msg = [ps.stem(words) for words in msg if not words in set(stopwords.words('english'))]\n    msg = ' '.join(msg)\n    cleaned.append(msg)\n\n#one hot encoding and embedding layer\none_hot_mat = [one_hot(words,dict_size) for words in cleaned]\nembedded_layer = pad_sequences(one_hot_mat,padding = 'pre',maxlen = 150)\nembedded_layer\n\n#prediction\npred = model.predict(embedded_layer)\ncat = ['Business','Science','Entertainment','Health']\nprint(pred, cat[np.argmax(pred)])","metadata":{"execution":{"iopub.status.busy":"2021-07-08T18:42:54.580563Z","iopub.execute_input":"2021-07-08T18:42:54.580921Z","iopub.status.idle":"2021-07-08T18:42:54.711029Z","shell.execute_reply.started":"2021-07-08T18:42:54.580884Z","shell.execute_reply":"2021-07-08T18:42:54.710133Z"},"trusted":true},"execution_count":null,"outputs":[]}]}