{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## MLP sobre dados de Sintomas da Lombalgia","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, plot_confusion_matrix, confusion_matrix","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Para esse projeto, usaremos redes MLPs em cima do conjunto de dados de Sintomas de Lombalgia com o objetivo de identificar pessoas que podem ter a doença a partir de determinadas caracteristicas. Começaremos importando o dataset e dando uma olhada nos seus dados:","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/lower-back-pain-symptoms-dataset/Dataset_spine.csv')\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Nesse conjunto, vemos a presença de uma coluna com o nome \"Unnamed: 13\" que não nos passa nenhum tipo de informação. Por isso, vamos retirá-la do dataset para que não nos atrapalhe","metadata":{}},{"cell_type":"code","source":"df = df.drop(['Unnamed: 13'], axis=1)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Com esse conjunto de dados, vamos separar o X (atributos) e o y (labels) e dividi-lo em conjunto de treino e de teste com uma proporção de 80/20, ou seja, 80% dos dados disponíveis serão usados no treino do MLP e os outros 20% para testar o modelo","metadata":{}},{"cell_type":"code","source":"y = df['Class_att']\nX = df.drop(['Class_att'], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 13)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Rede MLP com parâmetros padrões","metadata":{}},{"cell_type":"markdown","source":"Agora, vamos criar o modelo usando a biblioteca SKLearn. Para um primeiro teste, usaremos os parâmetros que estão como padrão na implementação que são dados abaixo:","metadata":{}},{"cell_type":"code","source":"clf_default = MLPClassifier(random_state = 13, verbose = True)\nclf_default.get_params()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Com tais parâmetros, vamos treinar o modelo usando o nosso X_test e y_test","metadata":{}},{"cell_type":"code","source":"clf_default.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = clf_default.predict(X_test)\nclf_default.score(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_report = classification_report(y_test, y_pred)\nprint(class_report)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Com esses parâmetros, obtemos uma acurácia de 83%. Além disso, podemos tirar mais alguns dados do classification report que calculamos:\n\n1. **Precisão (porcentagem dos classificados como X que eram realmente X)**   \nAqui, tivemos 92% para *abnormal* e 71% para *normal*, ou seja, vemos que o nosso modelo classificou muitas pessoas como *normal* e que na verdade essas pessoas eram *abnormal*. A chance de uma pessoa ser classificada erroneamente como saudável, quando na verdade é doente, é de 29%.\n\n2. **Recall (quando realmente é da classe X, o quão frequente você classifica como X)**   \nObtemos 83% para *abnormal* e 85% para *normal*. Dessa forma, 15% das pessoas saudáveis foram erroneamente classificadas como doentes. Essa taxa aumenta para 17% no caso dos doentes.\n","metadata":{}},{"cell_type":"markdown","source":"Dando uma olhada nos nossos dados novamente, vemos que existe quase o dobro de amostras referentes a *abnormal* em comparação com *normal*. Isso pode ser uma explicação do porquê uma maior porcentagem de pessoas saudáveis está sendo classificada erroneamente como doentes.","metadata":{}},{"cell_type":"code","source":"y.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Rede MLP com parâmetros alterados","metadata":{}},{"cell_type":"markdown","source":"Para melhorar a performance dos experimentos vamos tentar compreender a relevância de cada coluna para o classificador e remover as colunas que tenham valores que possam atrapalhar o processo de aprendizado e classificação, para isso vamos tentar buscar por características que nos apontem problemas com uma dada informação como sua variância por grupo","metadata":{}},{"cell_type":"code","source":"mask = df['Class_att'] == 'Abnormal'\nabnormal_df = df[mask]\nnormal_df = df[~mask]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"abnormal_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"normal_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Agora vamos computar a variância as colunas de cada subconjunto","metadata":{}},{"cell_type":"code","source":"normal_df.var()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"abnormal_df.var()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Podemos notar algumas colunas muito próximas e muito discrepantes, podemos encontrar nelas informações interessantes para continuar nossa análise, vamos partir desse ponto...","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.style.use('classic')\n%matplotlib inline\nimport seaborn as sns\n\nsns.set()\nsns.set_theme()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for key in normal_df:\n    if key == 'Class_att':\n        continue\n    print(key)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for key in df:\n    if key == 'Class_att':\n        continue\n    sns.displot(data=df,x=key, hue='Class_att', kde=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Podemos visualizar graficamente assim as variáveis que não falam muito sobre o problema, o que também parece falar sobre uma tendência de aumento de valores para algumas variáveis, essas variáveis que podem causar grande mudança são as que devemos focar e tentar combiná-las de forma que seja possível construir uma melhor distribuição de dados, que torne mais clara a diferença, construindo um parâmetro ou um conjunto combinado de parâmetros que melhore o resultado, mudar as metodologias também para visualizar quais parâmetros que tem maior influência nos dados. \n\nDessa forma vamos focar exclusivamente nas colunas de 1 a 6.","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\ndef f(x):\n    return np.exp(1 + (x['Col5'] - x['Col6'])/max(x['Col5'], x['Col6']))\n\ndf1 = df.assign(Col13 = df[['Col5', 'Col6']].apply(f, axis=1))\ndf1.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.displot(data=df1,x='Col13', hue='Class_att', kde=True)\nsns.displot(data=df1,x='Col6', hue='Class_att', kde=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modified_df = df1[['Col1', 'Col2', 'Col3', 'Col4', 'Col5', 'Col6', 'Col13']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Agora vamos montar o classificador com dados diferentes para encontrar o maior valor possível.","metadata":{}},{"cell_type":"code","source":"clf_mod = MLPClassifier(hidden_layer_sizes=(100,100,100), \n                            random_state = 21, \n                            activation='relu', \n                            verbose = True,\n                           early_stopping=True,\n                           validation_fraction=0.2)\nclf_mod.get_params()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_mod = modified_df\nY_mod = df['Class_att']\nX_train_mod, X_valid_mod, y_train_mod, y_valid_mod = train_test_split(X, y, test_size = 0.1, random_state = 21)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf_mod.fit(X_train_mod, y_train_mod)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = clf_mod.predict(X_valid_mod)\nclf_mod.score(X_valid_mod, y_valid_mod)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_report = classification_report(y_valid_mod, y_pred)\nprint(class_report)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}