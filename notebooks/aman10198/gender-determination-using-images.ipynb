{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport cv2\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport os\nprint(os.listdir(\"../input\"))\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/celeba-dataset/list_attr_celeba.csv\")\nextracted = pd.read_csv(\"../input/extracted/face_align.csv\")\nprint(\"shape of data>\",data.shape)\nprint(\"shape of extracted>\", extracted.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"import cv2\nface_classifier = cv2.CascadeClassifier('../input/opencvhaarcascades/Haarcascades/haarcascade_frontalface_default.xml')<br>\nface_align = np.zeros((dataset.shape[0], 4), dtype = np.int16)<br>\n\n### an array on all the images and extracting faces from the image\nfor i in range(dataset.shape[0]):<br>\n    position = dataset['image_id'][i]<br>\n    curr_image = cv2.imread(\"../input/celeba-dataset/img_align_celeba/img_align_celeba/\"+position)<br>\n    \n    face = face_classifier.detectMultiScale(curr_image, 1.3,5)<br>\n    \n    # if facial dimension are found in the image\n    if face is not ():<br>\n        x,y,w,h = face[0]<br>\n        face_align[i,0] = x<br>\n        face_align[i,1] = y<br>\n        face_align[i,2] = w<br>\n        face_align[i,3] = h<br>"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data[['image_id', 'Male']]\ndata = data.replace(-1,0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## above is data"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = data.iloc[150000:200000,:].values\nface_info = extracted.iloc[150000:200000,:].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils import shuffle\ndataset, face_info = shuffle(dataset, face_info, random_state=32)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Template\nx,y,w,h = face_info[['x','y','w','h']].iloc[1].values<br>\nprint(x,y,w,h)<br>\nimg = cv2.imread(\"../input/celeba-dataset/img_align_celeba/img_align_celeba/\"+dataset.iloc[0,0],0)<br>\nplt.imshow(img[int(y):int(y)+int(h),int(x):int(x)+int(w)])"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataX = []\ndataY = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(dataset.shape[0]):\n    x,y,w,h = face_info[i,:]\n    \n    if w != 0 and h != 0:\n        img = cv2.imread(\"../input/celeba-dataset/img_align_celeba/img_align_celeba/\"+dataset[i,0],0)\n        dataX.append(cv2.resize(img[int(y):int(y)+int(h),int(x):int(x)+int(w)] , (112,112)))\n        dataY.append(dataset[i,1])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nx = len(dataX)\nny = len(dataY)\nprint(nx,ny)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.array(dataX[:int(nx*0.9)]).reshape(int(nx*0.9), 112,112,1)\nY_train = dataY[:int(nx*0.9)]\n\nX_val = np.array(dataX[int(nx*0.9):]).reshape(nx-int(nx*0.9), 112,112,1)\n\nY_val = dataY[int(nx*0.9):]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import optimizers\nfrom keras import layers\nfrom keras import models\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom time import time\n\n\n################### neural network ######################\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, (3,3), activation=\"relu\", input_shape=(112,112,1)))\nmodel.add(layers.MaxPooling2D(2,2))\nmodel.add(layers.Conv2D(64, (3,3), activation=\"relu\"))\nmodel.add(layers.MaxPooling2D(2,2))\nmodel.add(layers.Conv2D(128, (3,3), activation=\"relu\"))\nmodel.add(layers.MaxPooling2D(2,2))\nmodel.add(layers.Conv2D(64, (3,3), activation=\"relu\"))\nmodel.add(layers.MaxPooling2D(2,2))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(512, activation=\"relu\"))\nmodel.add(layers.Dense(1, activation=\"sigmoid\"))\n\nmodel.compile(loss=\"mean_squared_error\", optimizer=optimizers.Adam(learning_rate=0.00001), metrics=['acc'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights(\"model_weights3.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale = 1./255,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\n\ntest_datagen = ImageDataGenerator(rescale = 1./255)\n\n\nBATCH_SIZE = 32\ntrain_generator = train_datagen.flow(X_train, Y_train, batch_size = BATCH_SIZE)\ntest_generator = test_datagen.flow(X_val, Y_val, batch_size=BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ntrain = X_train.shape[0]\nnval = X_val.shape[0]\nhistory = model.fit_generator(train_generator, steps_per_epoch = ntrain//BATCH_SIZE,\n                              epochs = 64,\n                              validation_data = test_generator,\n                              validation_steps = nval//BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save_weights('model_weights4.h5')\n\n#model.save('model_keras.h5')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('model_keras.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.DataFrame(history.history)\n\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.to_csv(\"hist4.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del  data, extracted, dataX, dataY, X_train, X_val, Y_train, Y_val","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}