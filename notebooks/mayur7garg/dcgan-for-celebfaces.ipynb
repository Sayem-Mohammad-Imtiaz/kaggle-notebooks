{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Deep Convolutional Generative Adversarial Network","metadata":{}},{"cell_type":"code","source":"!cp -a ../input/dcgan-for-celebfaces-models-and-checkpoints/. ./","metadata":{"execution":{"iopub.status.busy":"2021-07-31T09:46:06.69427Z","iopub.execute_input":"2021-07-31T09:46:06.694752Z","iopub.status.idle":"2021-07-31T09:46:17.282838Z","shell.execute_reply.started":"2021-07-31T09:46:06.694608Z","shell.execute_reply":"2021-07-31T09:46:17.280944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport time\nfrom matplotlib import pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.train import Checkpoint, CheckpointManager\nfrom tensorflow.data import Dataset\nfrom tensorflow.data.experimental import AUTOTUNE\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.metrics import Mean\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.initializers import TruncatedNormal, RandomNormal\nfrom tensorflow.keras.layers import Input, Dense, Reshape, BatchNormalization, Conv2D, Conv2DTranspose, \\\n        LeakyReLU, Flatten, SpatialDropout2D, Dropout, MaxPool2D, GlobalAvgPool2D, Concatenate, LayerNormalization\n\nfrom IPython import display\n\nprint(tf.__version__)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-31T09:46:17.286507Z","iopub.execute_input":"2021-07-31T09:46:17.286954Z","iopub.status.idle":"2021-07-31T09:46:23.230516Z","shell.execute_reply.started":"2021-07-31T09:46:17.286903Z","shell.execute_reply":"2021-07-31T09:46:23.229276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.get_logger().setLevel('ERROR')","metadata":{"execution":{"iopub.status.busy":"2021-07-31T09:46:23.237501Z","iopub.execute_input":"2021-07-31T09:46:23.238327Z","iopub.status.idle":"2021-07-31T09:46:23.245117Z","shell.execute_reply.started":"2021-07-31T09:46:23.238218Z","shell.execute_reply":"2021-07-31T09:46:23.242985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BASE_PATH = r'../input/celeba-dataset/img_align_celeba/img_align_celeba'\nRANDOM_STATE = 7\nSHUFFLE_BUFFER = 32_000\nIMAGE_SIZE = (192, 160)\nBATCH_SIZE = 64\nGEN_NOISE_SHAPE = (6, 5, 8)\nPREDICT_COUNT = 9","metadata":{"execution":{"iopub.status.busy":"2021-07-31T09:46:23.247196Z","iopub.execute_input":"2021-07-31T09:46:23.247712Z","iopub.status.idle":"2021-07-31T09:46:23.263343Z","shell.execute_reply.started":"2021-07-31T09:46:23.247666Z","shell.execute_reply":"2021-07-31T09:46:23.262179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"GEN_LR = 4e-6\nGEN_BETA_1 = 0.5\nDISC_LR = 1e-6\nDISC_BETA_1 = 0.9\nGEN_RELU_ALPHA = 0.2\nDISC_RELU_ALPHA = 0.3\nEPOCHS = 50\nDISC_LABEL_SMOOTHING = 0.25\nPLOTS_DPI = 150\nRETRAIN = os.path.isfile('./ckpt/checkpoint')","metadata":{"execution":{"iopub.status.busy":"2021-07-31T09:46:23.264542Z","iopub.execute_input":"2021-07-31T09:46:23.268153Z","iopub.status.idle":"2021-07-31T09:46:23.276219Z","shell.execute_reply.started":"2021-07-31T09:46:23.268121Z","shell.execute_reply":"2021-07-31T09:46:23.27484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nimage_names = Dataset.list_files(os.path.join(BASE_PATH, '*.jpg'), seed = RANDOM_STATE)\nimage_count = image_names.cardinality().numpy()\nprint(f\"\\nTotal number of image files: {image_count}\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-07-31T09:46:23.278102Z","iopub.execute_input":"2021-07-31T09:46:23.278855Z","iopub.status.idle":"2021-07-31T09:48:24.156474Z","shell.execute_reply.started":"2021-07-31T09:46:23.278808Z","shell.execute_reply":"2021-07-31T09:48:24.155285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_image_data(filename):\n    img = tf.io.read_file(filename)\n    img = tf.io.decode_jpeg(img, channels = 3)\n    img = tf.image.resize(img, IMAGE_SIZE)\n    return (img - 127.5)/127.5\n\ntrain_ds = image_names.cache() \\\n        .shuffle(SHUFFLE_BUFFER) \\\n        .map(load_image_data, num_parallel_calls = AUTOTUNE) \\\n        .batch(BATCH_SIZE, drop_remainder = True) \\\n        .prefetch(buffer_size = AUTOTUNE)\n\ntrain_ds","metadata":{"execution":{"iopub.status.busy":"2021-07-31T09:48:24.160668Z","iopub.execute_input":"2021-07-31T09:48:24.161031Z","iopub.status.idle":"2021-07-31T09:48:24.277856Z","shell.execute_reply.started":"2021-07-31T09:48:24.160998Z","shell.execute_reply":"2021-07-31T09:48:24.276376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(nrows = 3, ncols = 3, figsize = (9, 11))\n\nsample_images = [i for i in train_ds.take(1)][0].numpy()\n\nfor i, ax in enumerate(axes.flatten()):\n    ax.imshow((sample_images[i] * 0.5) + 0.5)\n    ax.axis(False)\n    ax.grid(False)\n\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-07-31T09:48:24.280838Z","iopub.execute_input":"2021-07-31T09:48:24.28133Z","iopub.status.idle":"2021-07-31T09:48:26.422101Z","shell.execute_reply.started":"2021-07-31T09:48:24.281283Z","shell.execute_reply":"2021-07-31T09:48:26.420709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.random.set_seed(RANDOM_STATE)\nseed_noise = tf.random.normal([PREDICT_COUNT, *GEN_NOISE_SHAPE], seed = RANDOM_STATE)\n\nfig, axes = plt.subplots(nrows = PREDICT_COUNT, ncols = GEN_NOISE_SHAPE[2], figsize = (10, 14))\n\nfor i in range(PREDICT_COUNT):\n    for j in range(GEN_NOISE_SHAPE[2]):\n        axes[i][j].imshow(seed_noise[i, :, :, j], cmap = 'gray')\n        axes[i][j].axis(False)\n        axes[i][j].grid(False)\n        axes[i][j].set_title(f\"Img {i + 1}, Ch {j + 1}\")\n        \nplt.suptitle(f'Input Seed data. Shape: {seed_noise.shape}', fontsize = 20)\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-07-31T09:48:26.423547Z","iopub.execute_input":"2021-07-31T09:48:26.423929Z","iopub.status.idle":"2021-07-31T09:48:31.116583Z","shell.execute_reply.started":"2021-07-31T09:48:26.423888Z","shell.execute_reply":"2021-07-31T09:48:31.115404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generator_model():\n    weight_init = TruncatedNormal(mean = 0.0, stddev = 0.02)\n\n    input_layer = Input(shape = GEN_NOISE_SHAPE, name = 'Gen_Input')\n    flatten = Flatten(name = 'Gen_Flatten')(input_layer)\n    dense = Dense(6 * 5 * 512, use_bias = False, kernel_initializer = weight_init, \n                activation = LeakyReLU(GEN_RELU_ALPHA), name = 'Gen_Dense')(flatten)\n    reshape = Reshape((6, 5, 512), name = 'Gen_Reshape')(dense)\n    sp_dropout_1 = SpatialDropout2D(0.2, name = 'Gen_SD_1')(reshape)\n\n\n    conv_T_1 = Conv2DTranspose(512, (3, 3), padding = 'same', activation = LeakyReLU(GEN_RELU_ALPHA), use_bias = False,\n                               kernel_initializer = weight_init, name = 'Gen_Conv_T_1')(sp_dropout_1) \n    conv_T_2 = Conv2DTranspose(256, (3, 3), padding = 'same', strides = (2, 2), use_bias = False,\n                               kernel_initializer = weight_init, name = 'Gen_Conv_T_2')(conv_T_1)\n    bn_1 = BatchNormalization(name = 'Gen_BN_1')(conv_T_2)\n    lr_1 = LeakyReLU(GEN_RELU_ALPHA, name = 'Gen_LR_1')(bn_1)   \n\n\n    conv_T_3 = Conv2DTranspose(128, (4, 4), padding = 'same', activation = LeakyReLU(GEN_RELU_ALPHA), use_bias = False, \n                               kernel_initializer = weight_init, name = 'Gen_Conv_T_3')(lr_1) \n    conv_T_4 = Conv2DTranspose(64, (4, 4), padding = 'same', strides = (2, 2), use_bias = False, \n                               kernel_initializer = weight_init, name = 'Gen_Conv_T_4')(conv_T_3)\n    bn_2 = BatchNormalization(name = 'Gen_BN_2')(conv_T_4)\n    lr_2 = LeakyReLU(GEN_RELU_ALPHA, name = 'Gen_LR_2')(bn_2)\n    sp_dropout_2 = SpatialDropout2D(0.2, name = 'Gen_SD_2')(lr_2)\n\n\n    conv_T_5 = Conv2DTranspose(16, (5, 5), padding = 'same', strides = (2, 2), use_bias = False,\n                               kernel_initializer = weight_init, name = 'Gen_Conv_T_5')(sp_dropout_2)\n    bn_3 = BatchNormalization(name = 'Gen_BN_3')(conv_T_5)\n    lr_3 = LeakyReLU(GEN_RELU_ALPHA, name = 'Gen_LR_3')(bn_3)   \n    sp_dropout_3 = SpatialDropout2D(0.15, name = 'Gen_SD_3')(lr_3)\n\n\n    conv_T_6 = Conv2DTranspose(8, (6, 6), padding = 'same', strides = (2, 2), use_bias = False, \n                               kernel_initializer = weight_init, name = 'Gen_Conv_T_6')(sp_dropout_3)\n    bn_4 = BatchNormalization(name = 'Gen_BN_4')(conv_T_6)\n    lr_4 = LeakyReLU(GEN_RELU_ALPHA, name = 'Gen_LR_4')(bn_4)\n    sp_dropout_4 = SpatialDropout2D(0.15, name = 'Gen_SD_4')(lr_4)\n\n\n    conv_T_7 = Conv2DTranspose(8, (7, 7), padding = 'same', activation = LeakyReLU(GEN_RELU_ALPHA), use_bias = False,\n                               kernel_initializer = weight_init, strides = (2, 2), name = 'Gen_Conv_T_7')(sp_dropout_4)\n    conv_T_8 = Conv2DTranspose(3, (5, 5), padding = 'same', kernel_initializer = weight_init, use_bias = False,\n                               activation = 'tanh', name = 'Gen_Conv_T_8')(conv_T_7)\n    \n    return Model(inputs = input_layer, outputs = conv_T_8, name = 'Generator')\n    \ngenerator = generator_model()\ngenerator.summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-31T09:48:31.11836Z","iopub.execute_input":"2021-07-31T09:48:31.11881Z","iopub.status.idle":"2021-07-31T09:48:31.375777Z","shell.execute_reply.started":"2021-07-31T09:48:31.118764Z","shell.execute_reply":"2021-07-31T09:48:31.37469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(generator, to_file = 'Generator.jpg', show_shapes = True, dpi = PLOTS_DPI)","metadata":{"execution":{"iopub.status.busy":"2021-07-31T09:48:31.378263Z","iopub.execute_input":"2021-07-31T09:48:31.378735Z","iopub.status.idle":"2021-07-31T09:48:32.146628Z","shell.execute_reply.started":"2021-07-31T09:48:31.378687Z","shell.execute_reply":"2021-07-31T09:48:32.145272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def discriminator_model():\n    input_layer = Input(shape = (*IMAGE_SIZE, 3), name = 'Disc_Input')\n    \n    conv_1 = Conv2D(32, (4, 4), activation = LeakyReLU(DISC_RELU_ALPHA), padding = 'same', name = 'Disc_Conv_1')(input_layer)\n    max_pool_1 = MaxPool2D(2, name = 'Disc_MP_1')(conv_1)\n    conv_2 = Conv2D(64, (4, 4), activation = LeakyReLU(DISC_RELU_ALPHA), padding = 'same', name = 'Disc_Conv_2')(max_pool_1)\n    max_pool_2 = MaxPool2D(2, name = 'Disc_MP_2')(conv_2)\n    global_pool_1 = GlobalAvgPool2D(name = 'Disc_GAP_1')(max_pool_2)\n    \n    sp_dropout_1 = SpatialDropout2D(0.2, name = 'Disc_SD_1')(max_pool_2)\n    conv_3 = Conv2D(128, (3, 3), activation = LeakyReLU(DISC_RELU_ALPHA), padding = 'same', name = 'Disc_Conv_3')(sp_dropout_1)\n    max_pool_3 = MaxPool2D(2, name = 'Disc_MP_3')(conv_3)\n    conv_4 = Conv2D(256, (3, 3), activation = LeakyReLU(DISC_RELU_ALPHA), padding = 'same', name = 'Disc_Conv_4')(max_pool_3)\n    max_pool_4 = MaxPool2D(2, name = 'Disc_MP_4')(conv_4)\n    global_pool_2 = GlobalAvgPool2D(name = 'Disc_GAP_2')(max_pool_4)\n    \n    sp_dropout_2 = SpatialDropout2D(0.2, name = 'Disc_SD_2')(max_pool_4)\n    conv_5 = Conv2D(512, (2, 2), activation = LeakyReLU(DISC_RELU_ALPHA), padding = 'same', name = 'Disc_Conv_5')(sp_dropout_2)\n    max_pool_5 = MaxPool2D(2, name = 'Disc_MP_5')(conv_5)\n    global_pool_3 = GlobalAvgPool2D(name = 'Disc_GAP_3')(max_pool_5)\n    \n    concat = Concatenate(name = 'Disc_Concat')([global_pool_1, global_pool_2, global_pool_3])\n    dropout = Dropout(0.2, name = 'Disc_Dropout')(concat)\n    dense_1 = Dense(32, activation = LeakyReLU(DISC_RELU_ALPHA), name = 'Disc_Dense_1')(dropout)\n    dense_2 = Dense(1, name = 'Disc_Dense_2')(dense_1)\n    \n    return Model(inputs = input_layer, outputs = dense_2, name = 'Discriminator')\n    \ndiscriminator = discriminator_model()\ndiscriminator.summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-31T09:48:32.148715Z","iopub.execute_input":"2021-07-31T09:48:32.149703Z","iopub.status.idle":"2021-07-31T09:48:32.310721Z","shell.execute_reply.started":"2021-07-31T09:48:32.14965Z","shell.execute_reply":"2021-07-31T09:48:32.309622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(discriminator, to_file = 'Discriminator.jpg', show_shapes = True, dpi = PLOTS_DPI)","metadata":{"execution":{"iopub.status.busy":"2021-07-31T09:48:32.31253Z","iopub.execute_input":"2021-07-31T09:48:32.313034Z","iopub.status.idle":"2021-07-31T09:48:32.691328Z","shell.execute_reply.started":"2021-07-31T09:48:32.312987Z","shell.execute_reply":"2021-07-31T09:48:32.690151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cross_entropy = BinaryCrossentropy(from_logits = True)\ngen_mean_loss = Mean(name = \"Generator mean loss\")\ndisc_mean_loss = Mean(name = \"Discriminator mean loss\")\ngenerator_optimizer = Adam(GEN_LR, beta_1 = GEN_BETA_1)\ndiscriminator_optimizer = Adam(DISC_LR, beta_1 = DISC_BETA_1)","metadata":{"execution":{"iopub.status.busy":"2021-07-31T09:48:32.693452Z","iopub.execute_input":"2021-07-31T09:48:32.694299Z","iopub.status.idle":"2021-07-31T09:48:32.722779Z","shell.execute_reply.started":"2021-07-31T09:48:32.694235Z","shell.execute_reply":"2021-07-31T09:48:32.721479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_dir = './ckpt'\n\ncheckpoint = Checkpoint(\n    step = tf.Variable(1),\n    generator_optimizer = generator_optimizer,\n    discriminator_optimizer = discriminator_optimizer,\n    generator = generator,\n    discriminator = discriminator)\n\nckpt_manager = CheckpointManager(checkpoint, checkpoint_dir, max_to_keep = 5)\n\nEPOCH_START = 1\nif RETRAIN:\n    checkpoint.restore(ckpt_manager.latest_checkpoint)\n    EPOCH_START = checkpoint.step.numpy()\n\nprint(f\"Starting training from Epoch {EPOCH_START}\")","metadata":{"execution":{"iopub.status.busy":"2021-07-31T09:48:32.724552Z","iopub.execute_input":"2021-07-31T09:48:32.725093Z","iopub.status.idle":"2021-07-31T09:48:32.956373Z","shell.execute_reply.started":"2021-07-31T09:48:32.725044Z","shell.execute_reply":"2021-07-31T09:48:32.955085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_images(seed, save = False, epoch = None):\n    pred = generator(seed, training = False)\n\n    fig, axes = plt.subplots(nrows = 3, ncols = 3, figsize = (9, 11))\n\n    for i, ax in enumerate(axes.flatten()):\n        ax.imshow((pred[i] * 0.5) + 0.5)\n        ax.axis(False)\n        ax.grid(False)\n\n    plt.suptitle('Generator Predictions', fontsize = 20)\n    \n    plt.tight_layout()\n\n    if save:\n        plt.savefig(f'Pred_Epoch_{epoch:04d}.png', dpi = PLOTS_DPI, facecolor = 'white', \n                transparent = False, bbox_inches = 'tight')\n        plt.close()\n    \ngenerate_images(seed_noise)","metadata":{"execution":{"iopub.status.busy":"2021-07-31T09:48:32.958151Z","iopub.execute_input":"2021-07-31T09:48:32.958823Z","iopub.status.idle":"2021-07-31T09:48:40.890738Z","shell.execute_reply.started":"2021-07-31T09:48:32.958775Z","shell.execute_reply":"2021-07-31T09:48:40.883304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"discriminator(generator(seed_noise, training = False), training = False).numpy()","metadata":{"execution":{"iopub.status.busy":"2021-07-31T09:48:40.892776Z","iopub.execute_input":"2021-07-31T09:48:40.893219Z","iopub.status.idle":"2021-07-31T09:48:41.028244Z","shell.execute_reply.started":"2021-07-31T09:48:40.893173Z","shell.execute_reply":"2021-07-31T09:48:41.026876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def discriminator_loss(real_output, fake_output):\n    pos_labels = tf.ones_like(real_output) - (tf.random.uniform(real_output.shape) * DISC_LABEL_SMOOTHING)\n    neg_labels = tf.zeros_like(fake_output) + (tf.random.uniform(fake_output.shape) * DISC_LABEL_SMOOTHING)\n    real_loss = cross_entropy(pos_labels, real_output)\n    fake_loss = cross_entropy(neg_labels, fake_output)\n    total_loss = real_loss + fake_loss\n    return total_loss\n\ndef generator_loss(fake_output):\n    return cross_entropy(tf.ones_like(fake_output), fake_output)","metadata":{"execution":{"iopub.status.busy":"2021-07-31T09:48:41.030323Z","iopub.execute_input":"2021-07-31T09:48:41.030765Z","iopub.status.idle":"2021-07-31T09:48:41.038304Z","shell.execute_reply.started":"2021-07-31T09:48:41.030721Z","shell.execute_reply":"2021-07-31T09:48:41.036961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef train_step(images):\n    noise = tf.random.normal([BATCH_SIZE, *GEN_NOISE_SHAPE])\n\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n        generated_images = generator(noise, training = True)\n\n        real_output = discriminator(images, training = True)\n        fake_output = discriminator(generated_images, training = True)\n\n        gen_loss = generator_loss(fake_output)\n        disc_loss = discriminator_loss(real_output, fake_output)\n\n    gen_mean_loss(gen_loss)\n    disc_mean_loss(disc_loss)\n\n    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n\n    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))","metadata":{"execution":{"iopub.status.busy":"2021-07-31T09:48:41.040014Z","iopub.execute_input":"2021-07-31T09:48:41.040762Z","iopub.status.idle":"2021-07-31T09:48:41.052837Z","shell.execute_reply.started":"2021-07-31T09:48:41.040717Z","shell.execute_reply":"2021-07-31T09:48:41.051695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gen_losses = []\ndisc_losses = []\n\ndef train(dataset, epochs):\n    for epoch in range(epochs):\n        start = time.time()\n\n        gen_mean_loss.reset_states()\n        disc_mean_loss.reset_states()\n        \n        print(f\"\\nTraining Epoch {epoch + EPOCH_START}\\n\")\n        \n        for batch_ind, image_batch in enumerate(dataset):\n            train_step(image_batch)\n\n            if (batch_ind + 1) % 10 == 0:\n                print(\". \", end = '')\n            if (batch_ind + 1) % 250 == 0:\n                print(f\"{batch_ind + 1}\")\n        \n        checkpoint.step.assign_add(1)\n\n        display.clear_output(wait = True)\n        \n        generate_images(seed_noise, True, epoch + EPOCH_START)\n\n        if (epoch + EPOCH_START) % 5 == 0:\n            ckpt_manager.save()\n            \n        gen_losses.append(gen_mean_loss.result())\n        disc_losses.append(disc_mean_loss.result())\n\n        print(f\"\\nEpoch: {epoch + EPOCH_START}\\n\")\n        print(f'Generator Loss: {gen_mean_loss.result():.4f}')\n        print(f'Discriminator Loss: {disc_mean_loss.result():.4f}')\n        print (f'Time elapsed: {time.time() - start:.2f} s')\n\n    display.clear_output(wait = True)","metadata":{"execution":{"iopub.status.busy":"2021-07-31T09:48:41.054242Z","iopub.execute_input":"2021-07-31T09:48:41.055631Z","iopub.status.idle":"2021-07-31T09:48:41.069347Z","shell.execute_reply.started":"2021-07-31T09:48:41.055582Z","shell.execute_reply":"2021-07-31T09:48:41.068026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\ntrain(train_ds, EPOCHS)\n\nprint(f'Final Generator Loss: {gen_mean_loss.result()}')\nprint(f'Final Discriminator Loss: {disc_mean_loss.result()}')","metadata":{"execution":{"iopub.status.busy":"2021-07-31T09:48:41.072091Z","iopub.execute_input":"2021-07-31T09:48:41.072892Z","iopub.status.idle":"2021-07-31T09:50:01.363237Z","shell.execute_reply.started":"2021-07-31T09:48:41.072845Z","shell.execute_reply":"2021-07-31T09:50:01.362098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generate_images(seed_noise)","metadata":{"execution":{"iopub.status.busy":"2021-07-31T09:50:01.368863Z","iopub.execute_input":"2021-07-31T09:50:01.369201Z","iopub.status.idle":"2021-07-31T09:50:02.414764Z","shell.execute_reply.started":"2021-07-31T09:50:01.369169Z","shell.execute_reply":"2021-07-31T09:50:02.407806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epoch_range = range(EPOCH_START, EPOCHS + EPOCH_START)\nplt.figure(figsize = (20, 8))\n\nplt.subplot(1, 2, 1)\nplt.plot(epoch_range, gen_losses)\nplt.xticks(epoch_range)\nplt.title('Generator loss', fontsize = 18)\n\nplt.subplot(1, 2, 2)\nplt.plot(epoch_range, disc_losses)\nplt.xticks(epoch_range)\nplt.title('Discriminator loss', fontsize = 18)\n\nplt.suptitle('Loss per epoch', fontsize = 24)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-31T09:50:02.416634Z","iopub.execute_input":"2021-07-31T09:50:02.417138Z","iopub.status.idle":"2021-07-31T09:50:02.66687Z","shell.execute_reply.started":"2021-07-31T09:50:02.41708Z","shell.execute_reply":"2021-07-31T09:50:02.664122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator.save(\"generator\")\ndiscriminator.save(\"discriminator\")","metadata":{"execution":{"iopub.status.busy":"2021-07-31T09:50:02.667826Z","iopub.status.idle":"2021-07-31T09:50:02.668313Z"},"trusted":true},"execution_count":null,"outputs":[]}]}