{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <h1 align=\"center\">Modelo NLP para el análisis de sentimiento en review's de hoteles</h1>","metadata":{"id":"pkC-Kdw_Z5MG"}},{"cell_type":"markdown","source":"#### [Enlace al conjunto de datos (kaggle)](https://www.kaggle.com/jiashenliu/515k-hotel-reviews-data-in-europe)","metadata":{"id":"V-ZM2ZQvaBD1"}},{"cell_type":"markdown","source":"   ### Índice:\n   \n       1. Importación de librerías \n       \n       2. Carga de los datos\n\n       3. Creación de funciones\n       \n       4. Análisis preliminar\n       \n       5. Exploración y transformación de los datos\n       \n           5.1. Creación del campo 'Is_Positive_Review' \n           5.2. Selección de variables\n           5.3. Longitud de palabras y de caracteres\n           5.4. Distribución de longitud de las reviews según si son positivas o negativas\n           5.5. Nube de palabras\n           5.6. Normalización\n           5.7. Análisis de sentimiento\n               \n               5.7.1. Con Vader\n               5.7.2. Con TextBlob\n               \n       6. Vectorización del texto\n       \n       7. Exploración previa al modelado\n       \n       8. Construcción del modelo\n       \n           8.1. Balanceo de los datos\n           8.2. Regresión logística\n           8.3. Mejora del modelo\n           \n       9. Guardar modelo","metadata":{"id":"9muwDkh5Z5MK"}},{"cell_type":"markdown","source":"## 1. Importación de librerías y datos","metadata":{"id":"SgsGiYhlZ5MK"}},{"cell_type":"code","source":"# Instalacion previa de librerias empleadas\n!pip install wordcloud # Generador de nube de palabras\n!pip install textblob # Procesamiento de texto","metadata":{"id":"pYNwzwYUZ5MK","execution":{"iopub.status.busy":"2021-09-15T16:48:52.757793Z","iopub.execute_input":"2021-09-15T16:48:52.758761Z","iopub.status.idle":"2021-09-15T16:49:10.29414Z","shell.execute_reply.started":"2021-09-15T16:48:52.75863Z","shell.execute_reply":"2021-09-15T16:49:10.293055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Basicas\nimport pandas as pd # Analisis y manipulacion de datos\nimport numpy as np # Tratamiento de matrices\nimport matplotlib.pyplot as plt # Graficos\nimport seaborn as sns # Visualizacion de datos\n\n### NLTK\nimport nltk # Procesamiento del lenguaje natural\nnltk.download('averaged_perceptron_tagger') # Etiquetar las palabras\nnltk.download('vader_lexicon') # Analisis de sentimiento\nnltk.download('wordnet') # Categorizacion de las palabras\nnltk.download('stopwords') # Quitar palabras comunes\nfrom nltk.corpus import wordnet\nfrom nltk import pos_tag # Clasificacion de palabras\nfrom nltk.corpus import stopwords # Eliminar palabras vacias\nfrom nltk.tokenize import WhitespaceTokenizer # Tokenizar\nfrom nltk.stem import WordNetLemmatizer # Lematizar\nfrom nltk.stem.wordnet import WordNetLemmatizer # Lematizar\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer # Analisis de sentimiento\n\n### TRATAMIENTO DE TEXTO\nfrom wordcloud import WordCloud # Nube de palabras\nimport string # Operaciones de cadenas de caracteres\nfrom textblob import TextBlob # Procesamiento del lenguaje\n\n### SKLEARN\nfrom sklearn.feature_extraction.text import TfidfVectorizer # Codificacion de documentos, segun frecuenca de las palabras\nfrom sklearn.model_selection import train_test_split # Dividir los datos en entrenamiento y validacion\nfrom imblearn.over_sampling import SMOTE # Balanceo de los datos\nfrom sklearn.linear_model import LogisticRegression # Clasificador\nfrom sklearn.ensemble import RandomForestClassifier # Clasificador\nfrom sklearn.metrics import classification_report # Metricas para valoracion del modelo\nfrom sklearn.metrics import f1_score, confusion_matrix # Metricas para valoracion del modelo\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score # Metricas para valoracion del modelo\nfrom sklearn.metrics import plot_confusion_matrix # Metricas para valoracion del modelo\nfrom sklearn.model_selection import GridSearchCV # Ajuste de hiper-parametros\n\nimport pickle # Guardar modelo\n\n### ADICIONALES\nimport warnings # Control de advertencias\nwarnings.filterwarnings('ignore')\nfrom tqdm import tqdm \ntqdm.pandas(desc='Processing Dataframe') # Barra de progreso","metadata":{"id":"5wC5PZPNZ5ML","execution":{"iopub.status.busy":"2021-09-15T17:00:14.627053Z","iopub.execute_input":"2021-09-15T17:00:14.627435Z","iopub.status.idle":"2021-09-15T17:00:16.995752Z","shell.execute_reply.started":"2021-09-15T17:00:14.627398Z","shell.execute_reply":"2021-09-15T17:00:16.994772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Carga de los datos","metadata":{"id":"zoot8yKhZ5MM"}},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2021-09-15T17:00:31.47941Z","iopub.execute_input":"2021-09-15T17:00:31.47971Z","iopub.status.idle":"2021-09-15T17:00:31.496995Z","shell.execute_reply.started":"2021-09-15T17:00:31.479679Z","shell.execute_reply":"2021-09-15T17:00:31.495798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cargar dataset\ndf = pd.read_csv(\"/kaggle/input/515k-hotel-reviews-data-in-europe/Hotel_Reviews.csv\")","metadata":{"id":"d7OO6b1NZ5MN","execution":{"iopub.status.busy":"2021-09-15T17:04:40.270214Z","iopub.execute_input":"2021-09-15T17:04:40.270546Z","iopub.status.idle":"2021-09-15T17:04:45.917724Z","shell.execute_reply.started":"2021-09-15T17:04:40.270513Z","shell.execute_reply":"2021-09-15T17:04:45.916941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Creación de las funciones que se utilizarán","metadata":{"id":"5anxtWKPZ5MN"}},{"cell_type":"code","source":"# Función para limpiar el texto\ndef limpiar_texto(texto):\n    # Poner el texto en minúsculas\n    texto = texto.lower()\n    # Tokenizar el texto y quitar los signos de puntuación\n    texto = [word.strip(string.punctuation) for word in texto.split(\" \")]\n    # Quitar las palabras que contengan números\n    texto = [word for word in texto if not any(c.isdigit() for c in word)]\n    # Quitar las stop words\n    stop = stopwords.words('english')\n    texto = [x for x in texto if x not in stop]\n    # Quitar los tokens vacíos\n    texto = [t for t in texto if len(t) > 0]\n    # Pos tags\n    pos_tags = pos_tag(texto)\n    # Lematizar el texto\n    texto = [WordNetLemmatizer().lemmatize(t[0], get_wordnet_pos(t[1])) for t in pos_tags]\n    # Quitar las palabras con sólo una letra\n    texto = [t for t in texto if len(t) > 1]\n    # Unir todo\n    texto = \" \".join(texto)\n    return(texto)\n\n# Función para dibujar la nube de palabras\ndef show_wordcloud(data, title = None):\n    wordcloud = WordCloud(\n        background_color = 'white',\n        max_words = 200,\n        max_font_size = 40, \n        scale = 3,\n        random_state = 42\n    ).generate(str(data))\n\n    fig = plt.figure(1, figsize = (20, 20))\n    plt.axis('off')\n    if title: \n        fig.suptitle(title, fontsize = 20)\n        fig.subplots_adjust(top = 2.3)\n\n    plt.imshow(wordcloud)\n    plt.show()\n    \n\n# Etiquetado de nombres, verbos, adjetivos o adverbios\ndef get_wordnet_pos(pos_tag):\n    if pos_tag.startswith('J'):\n        return wordnet.ADJ\n    elif pos_tag.startswith('V'):\n        return wordnet.VERB\n    elif pos_tag.startswith('N'):\n        return wordnet.NOUN\n    elif pos_tag.startswith('R'):\n        return wordnet.ADV\n    else:\n        return wordnet.NOUN\n    \n# Para el train_validate_test_split (para probar los modelos y mejorarlos)\ndef train_validate_test_split(df, train_percent=.6, validate_percent=.2, seed=101):\n    np.random.seed(seed)\n    perm = np.random.permutation(df.index)\n    m = len(df.index)\n    train_end = int(train_percent * m)\n    validate_end = int(validate_percent * m) + train_end\n    train = df.loc[perm[:train_end]]\n    validate = df.loc[perm[train_end:validate_end]]\n    test = df.loc[perm[validate_end:]]\n    return train, validate, test","metadata":{"id":"wmbv1X8XZ5MN","execution":{"iopub.status.busy":"2021-09-15T17:04:52.319749Z","iopub.execute_input":"2021-09-15T17:04:52.320086Z","iopub.status.idle":"2021-09-15T17:04:52.338884Z","shell.execute_reply.started":"2021-09-15T17:04:52.320054Z","shell.execute_reply":"2021-09-15T17:04:52.338138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Análisis preliminar","metadata":{"id":"skbebNjZZ5MO"}},{"cell_type":"code","source":"print(\"El df tiene un total de {} columnas y un total de {} registros\".format(df.shape[1], df.shape[0]))","metadata":{"id":"qVilzc7dZ5MO","outputId":"d829236f-2094-46ae-dec5-0e9cbe7cfeb4","execution":{"iopub.status.busy":"2021-09-15T17:04:54.939187Z","iopub.execute_input":"2021-09-15T17:04:54.939616Z","iopub.status.idle":"2021-09-15T17:04:54.944782Z","shell.execute_reply.started":"2021-09-15T17:04:54.939585Z","shell.execute_reply":"2021-09-15T17:04:54.94384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Columnas df1\ndf.columns","metadata":{"id":"OKkMu95VZ5MP","outputId":"176993cc-7062-470f-e335-6f537df5878c","execution":{"iopub.status.busy":"2021-09-15T17:04:56.422915Z","iopub.execute_input":"2021-09-15T17:04:56.423401Z","iopub.status.idle":"2021-09-15T17:04:56.431543Z","shell.execute_reply.started":"2021-09-15T17:04:56.423345Z","shell.execute_reply":"2021-09-15T17:04:56.43067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Analisis preliminar df**\n\nEl dataframe tiene la columna \"Negative_Review\", que recoge las reviews negativas y \"Positive_Review\", que recoge las reviews positivas. Por lo tanto, para recoger todas estas reviews habría que unirlas en un nuevo campo, el cual se llamará \"Reviews\".\n\nAdemás, se creará el campo Is_Positive_Review donde si es 1, es que la review ha recibido un 5 o más, y, por lo tanto, es positiva, mientras que si es 0 es que la review ha recibido menos de un 5 de score y por lo tanto es negativa. Esto es porque en este dataframe las puntuaciones van del 0 al 10.","metadata":{"id":"TbHzwjrCZ5MP"}},{"cell_type":"markdown","source":"## 5. Exploración y transformación de los datos","metadata":{"id":"97dbxEkjZ5MP"}},{"cell_type":"markdown","source":"#### 5.1 Creación del campo 'Is_Positive_Review' ","metadata":{"id":"_dcBrYBWZ5MP"}},{"cell_type":"markdown","source":"Se crea el campo Is_Positive_Review (si es positiva = 1, si es negativa = 0)","metadata":{"id":"EHf1JbKEZ5MP"}},{"cell_type":"code","source":"df","metadata":{"id":"am1PmZUNZ5MQ","outputId":"29c6a9c4-0707-447a-aaa9-3be38895df19","execution":{"iopub.status.busy":"2021-09-15T17:05:02.291635Z","iopub.execute_input":"2021-09-15T17:05:02.29248Z","iopub.status.idle":"2021-09-15T17:05:02.334722Z","shell.execute_reply.started":"2021-09-15T17:05:02.292419Z","shell.execute_reply":"2021-09-15T17:05:02.333876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# En Reviews se añaden los dos tipos de Review concatenadas con un espacio\ndf[\"Reviews\"] = df[\"Positive_Review\"] + \" \" + df[\"Negative_Review\"]\n\n# Se quitan los \"No Negative\" y \"No Positive\" de las reviews\ndf[\"Reviews\"] = df[\"Reviews\"].astype(str)\ndf[\"Reviews\"] = df[\"Reviews\"].apply(lambda x: x.replace(\"No Negative\", \"\").replace(\"No Positive\", \"\"))\n\n# Se crea la columna \"Is_Positive_Review\" para aquellas Review cuyo score es mayor a 5. \ndf['Is_Positive_Review'] = df['Reviewer_Score'].progress_apply(lambda x: 1 if x >= 5 else 0)","metadata":{"id":"pywSalB_Z5MQ","outputId":"89aea577-9f61-41a9-ceaf-ef2b6ada6a51","execution":{"iopub.status.busy":"2021-09-15T17:05:03.223771Z","iopub.execute_input":"2021-09-15T17:05:03.224446Z","iopub.status.idle":"2021-09-15T17:05:05.250376Z","shell.execute_reply.started":"2021-09-15T17:05:03.224397Z","shell.execute_reply":"2021-09-15T17:05:05.249076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"El df tiene un conjunto de {} opiniones positivas y un conjunto de {} opiniones negativas\".format(df[\"Is_Positive_Review\"].value_counts()[1], df[\"Is_Positive_Review\"].value_counts()[0]))\nprint(\"En porcentaje, el {0:.2f}% de las reviews son positivas y el {1:.2f}% de las reviews son negativas\".format(df[\"Is_Positive_Review\"].value_counts(normalize=True)[1]*100, df[\"Is_Positive_Review\"].value_counts(normalize=True)[0]*100))","metadata":{"id":"MBXYDs7bZ5MQ","outputId":"3fe6232f-a172-4488-fc45-d5dd21feaf86","execution":{"iopub.status.busy":"2021-09-15T17:05:06.928924Z","iopub.execute_input":"2021-09-15T17:05:06.929865Z","iopub.status.idle":"2021-09-15T17:05:06.953232Z","shell.execute_reply.started":"2021-09-15T17:05:06.929799Z","shell.execute_reply":"2021-09-15T17:05:06.952169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Como se puede observar, el dataset está claramente desbalanceado, cuestión que será importante y que hay que tener en cuenta al entrenar el modelo.","metadata":{"id":"pTbObdtfZ5MQ"}},{"cell_type":"markdown","source":"#### 5.2 Selección de variables","metadata":{"id":"7DO7FKuxZ5MQ"}},{"cell_type":"markdown","source":"Las variables que se van a seleccionar para el dataframe van a ser las siguientes: Reviews, Is_Positive_Review.","metadata":{"id":"ES0cKR7jZ5MR"}},{"cell_type":"code","source":"# Selección de las variables de interés\ndf = df.loc[:, ['Reviews', 'Is_Positive_Review']]\n\nprint(\"Dimensiones de df1: {}\".format(df.shape))","metadata":{"id":"zchoK8MrZ5MR","outputId":"9cbcc1b7-646b-4d1e-9dd8-dad43008bbdb","execution":{"iopub.status.busy":"2021-09-15T17:05:09.916922Z","iopub.execute_input":"2021-09-15T17:05:09.917239Z","iopub.status.idle":"2021-09-15T17:05:10.170813Z","shell.execute_reply.started":"2021-09-15T17:05:09.917208Z","shell.execute_reply":"2021-09-15T17:05:10.169766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 5.3 Longitud de palabras y de caracteres","metadata":{"id":"Bg6rjxqrZ5MR"}},{"cell_type":"code","source":"# Añadir número de caracteres\ndf[\"Caracteres_len\"] = df[\"Reviews\"].progress_apply(lambda x: len(x))\n\n# Añadir número de palabras\ndf[\"Palabras_len\"] = df[\"Reviews\"].progress_apply(lambda x: len(x.split(\" \")))","metadata":{"id":"tqqKK24jZ5MR","outputId":"1856a9c7-9742-492a-e905-1129bb064666","execution":{"iopub.status.busy":"2021-09-15T17:05:11.265691Z","iopub.execute_input":"2021-09-15T17:05:11.266739Z","iopub.status.idle":"2021-09-15T17:05:14.384191Z","shell.execute_reply.started":"2021-09-15T17:05:11.266692Z","shell.execute_reply":"2021-09-15T17:05:14.383296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 5.4 Distribución de longitud de las reviews según si son positivas o negativas","metadata":{"id":"hdFrhB3jZ5MR"}},{"cell_type":"code","source":"# Para el número de caracteres\nfig = plt.figure(figsize=(10,6))\nplt1 = sns.distplot(df[df[\"Is_Positive_Review\"]==0].Caracteres_len, hist=True)\nplt2 = sns.distplot(df[df[\"Is_Positive_Review\"]==1].Caracteres_len, hist=True)\nfig.legend(labels=['Review negativa','Review positiva'])\nplt.show()","metadata":{"id":"HN4RiTrnZ5MR","outputId":"df0f77f8-9f99-4aa6-b8cf-6f60a888aea8","execution":{"iopub.status.busy":"2021-09-15T17:05:15.676681Z","iopub.execute_input":"2021-09-15T17:05:15.676967Z","iopub.status.idle":"2021-09-15T17:05:18.461535Z","shell.execute_reply.started":"2021-09-15T17:05:15.676938Z","shell.execute_reply":"2021-09-15T17:05:18.460688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Para el número de palabras\nfig = plt.figure(figsize=(10,6))\nplt1 = sns.distplot(df[df[\"Is_Positive_Review\"]==0].Palabras_len, hist=True)\nplt2 = sns.distplot(df[df[\"Is_Positive_Review\"]==1].Palabras_len, hist=True)\nfig.legend(labels=['Review negativa','Review positiva'])\nplt.show()","metadata":{"id":"VA-pYijhZ5MS","outputId":"5745e784-3151-4739-ef9a-3d686fa9136e","execution":{"iopub.status.busy":"2021-09-15T17:05:20.286787Z","iopub.execute_input":"2021-09-15T17:05:20.287518Z","iopub.status.idle":"2021-09-15T17:05:23.032369Z","shell.execute_reply.started":"2021-09-15T17:05:20.287477Z","shell.execute_reply":"2021-09-15T17:05:23.03126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Como se puede observar no hay mucha diferencia en cuanto a longitud (tanto de caracteres como de palabras) en las reviews negativas y positivas. Por el motivo citado, no se incorporarán estas variable en el modelo, puesto que no parecen ayudar a ditinguir entre valoraciones positivas y negativas.","metadata":{"id":"rsA6lmapZ5MS"}},{"cell_type":"markdown","source":"#### 5.5 Nube de palabras","metadata":{"id":"xdrsf0YmZ5MS"}},{"cell_type":"code","source":"# Se imprime la nube de palabras con la función cargada anteriormente\nshow_wordcloud(df[\"Reviews\"])","metadata":{"id":"kG6umSsJZ5MS","outputId":"b3eb161b-b088-4a32-eebd-fe81aa98680e","execution":{"iopub.status.busy":"2021-09-15T17:05:25.880628Z","iopub.execute_input":"2021-09-15T17:05:25.88095Z","iopub.status.idle":"2021-09-15T17:05:26.289006Z","shell.execute_reply.started":"2021-09-15T17:05:25.880917Z","shell.execute_reply":"2021-09-15T17:05:26.288117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 5.6 Normalización","metadata":{"id":"ZVZXJnsXZ5MS"}},{"cell_type":"markdown","source":"Para este apartado se aplicará la función definida previamente de limpieza de texto. Aplicando esa función al conjunto de datos, lo que se hará será:\n\n- Poner el texto en minúscula\n- Tokenizar el texto\n- Quitar las palabras que contengan números\n- Quitar las stop words\n- Quitar los tokens vacíos\n- Lematizar el texto\n- Quitar las palabras con una letra","metadata":{"id":"hpReOh--Z5MS"}},{"cell_type":"code","source":"# Se aplica la función anterior\ndf['Reviews_procesadas'] = df['Reviews'].progress_apply(lambda x: limpiar_texto(x))","metadata":{"id":"R8yocm4BZ5MS","outputId":"2c1f9d3c-102b-46e1-94f4-96c62716144b","execution":{"iopub.status.busy":"2021-09-15T17:05:28.59368Z","iopub.execute_input":"2021-09-15T17:05:28.594537Z","iopub.status.idle":"2021-09-15T17:22:23.540488Z","shell.execute_reply.started":"2021-09-15T17:05:28.594498Z","shell.execute_reply":"2021-09-15T17:22:23.539492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 5.7 Análisis de sentimiento","metadata":{"id":"dJOO987IZ5MS"}},{"cell_type":"markdown","source":"El análisis de sentimiento, para que sea más completo, se va a realizar con dos librerías diferentes. La primera va a ser con Vader, del módulo nltk. Vader proporciona cuatro nuevos campos (score positivo, score negativo, score neutro y un score llamado compound que integra todos los score anteriores, esto es, que cuanto más positivo, más positiva es la review mientras que cuanto más negativo, más negativa será la review). La segunda librería será la de TextBlob. TextBlob proporciona una tupla con dos: polaridad y subjetividad. La polaridad va del valor -1 hasta el 1. Si es negativa significa que tiene sentimientos negativos mientras que si es positiva significa que tiene sentimientos positivos. La subjetividad va entre 0 y 1, y cuantifica la opinión personal contenida en el texto. Una mayor subjetividad significa que el texto contiene mucha más opinión personal que una información objetiva.\n\nPara extraer el sentimiento se utilizarán las reviews sin procesar.","metadata":{"id":"_OjgB28BZ5MS"}},{"cell_type":"markdown","source":"#### 5.7.1 Con Vader","metadata":{"id":"BR_DSPCvZ5MT"}},{"cell_type":"code","source":"# Con Vader, del módulo nltk. Este módulo añade un score positivo, negativo, neutro y una integración de todas las anteriores\nanalizador = SentimentIntensityAnalyzer()\ndf[\"Sentimiento\"] = df[\"Reviews\"].progress_apply(lambda x: analizador.polarity_scores(x))\ndf = pd.concat([df.drop(['Sentimiento'], axis=1), df['Sentimiento'].apply(pd.Series)], axis=1)","metadata":{"id":"wG9UwUrUZ5MT","outputId":"8c90adbf-ab87-4ba8-cb06-b01bb391e867","execution":{"iopub.status.busy":"2021-09-15T17:22:28.221553Z","iopub.execute_input":"2021-09-15T17:22:28.222182Z","iopub.status.idle":"2021-09-15T17:29:50.376722Z","shell.execute_reply.started":"2021-09-15T17:22:28.222139Z","shell.execute_reply":"2021-09-15T17:29:50.375908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 5.7.2 Con TextBlob","metadata":{"id":"lLl24vYuZ5MT"}},{"cell_type":"code","source":"# Con TextBlob\ndf['Polaridad'] = df['Reviews'].progress_apply(lambda x: TextBlob(x).sentiment.polarity) \ndf['Subjetividad'] = df['Reviews'].progress_apply(lambda x: TextBlob(x).sentiment.subjectivity) ","metadata":{"id":"6AG75D8_Z5MT","outputId":"8368cf44-f525-4e45-97f0-dd0cb5eedce8","execution":{"iopub.status.busy":"2021-09-15T17:29:50.378705Z","iopub.execute_input":"2021-09-15T17:29:50.379073Z","iopub.status.idle":"2021-09-15T17:36:44.497017Z","shell.execute_reply.started":"2021-09-15T17:29:50.379028Z","shell.execute_reply":"2021-09-15T17:36:44.49608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6. Vectorización del texto","metadata":{"id":"N1Kq_xzMZ5MT"}},{"cell_type":"markdown","source":"Se van a extraer las características del texto utilizando TFIDFVectorizer. En este caso se quiere:\n\n- Utilizar como máximo 200 características\n- Unigramas, bigramas, trigramas y cuatrigramas\n- Que el sistema ignore los elemenos que al menos no aparezcan en 3 reviews\n- Que, puesto que el texto ya está tokenizado, no utilice la función tokenizadora de Scikit-Learn","metadata":{"id":"JXU4HevSZ5MT"}},{"cell_type":"code","source":"vectorizador = TfidfVectorizer(ngram_range = (1,4), min_df = 3, max_features = 200,\n                               use_idf = True, smooth_idf = True, norm = 'l2') \n\nvector_corpus = vectorizador.fit_transform(df['Reviews_procesadas'].to_list()) \n\ntype(vector_corpus) # Ya está transformado el texto.","metadata":{"id":"Fsi44JykZ5MT","outputId":"251272c9-b345-40cf-cf95-8942ca6deea8","execution":{"iopub.status.busy":"2021-09-15T17:37:01.142339Z","iopub.execute_input":"2021-09-15T17:37:01.142635Z","iopub.status.idle":"2021-09-15T17:39:36.966288Z","shell.execute_reply.started":"2021-09-15T17:37:01.142606Z","shell.execute_reply":"2021-09-15T17:39:36.965405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7. Exploración previa al modelado","metadata":{"id":"nGcjg7NKZ5MT"}},{"cell_type":"markdown","source":"Como se ha comentado previamente, al realizar el primer análisis exploratorio, el texto está desbalanceado. Sin embargo, además de esa conclusión se pueden sacar otras conclusiones mediante la exploración de los resultados que tenemos actualmente antes de construir cualquier modelo.","metadata":{"id":"nvlezkrPZ5MU"}},{"cell_type":"code","source":"# Reviews con positividad más alta en cuanto a sentimientos según Vader (más de 10 palabras)\ndf[df[\"Palabras_len\"] >= 10].sort_values(\"pos\", ascending = False)[[\"Reviews\", \"pos\"]].head(10)","metadata":{"id":"Mgj77h4gZ5MU","outputId":"90f16418-b520-4c78-92b1-66d92b30a1dd","execution":{"iopub.status.busy":"2021-09-15T17:39:48.301791Z","iopub.execute_input":"2021-09-15T17:39:48.302142Z","iopub.status.idle":"2021-09-15T17:39:48.671238Z","shell.execute_reply.started":"2021-09-15T17:39:48.302106Z","shell.execute_reply":"2021-09-15T17:39:48.670257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reviews con negatividad más alta en cuanto a sentimientos según Vader (más de 10 palabras)\ndf[df[\"Palabras_len\"] >= 10].sort_values(\"neg\", ascending = False)[[\"Reviews\", \"neg\"]].head(10)","metadata":{"id":"l4srcX8CZ5MU","outputId":"44453e15-03ec-4013-bfdf-6189debf4daa","execution":{"iopub.status.busy":"2021-09-15T17:39:51.555788Z","iopub.execute_input":"2021-09-15T17:39:51.556119Z","iopub.status.idle":"2021-09-15T17:39:51.777213Z","shell.execute_reply.started":"2021-09-15T17:39:51.556088Z","shell.execute_reply":"2021-09-15T17:39:51.776263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Se puede observar que Vader interpreta 'no' y 'nothing' como negativo, mientras que muchas veces no significa algo negativo. Por ejemplo si se comenta que no se ha tenido ningún problema con el hotel. Sin embargo, afortunadamente, la gran mayoría de reviews son negativas de verdad.","metadata":{"id":"hNNa-4UFZ5MU"}},{"cell_type":"markdown","source":"## 8. Construcción del modelo","metadata":{"id":"sfVUg34cZ5MU"}},{"cell_type":"code","source":"# Selección de variables para la construcción del modelo (en resumen, sólo nos quedamos con los campos numéricos)\ntarget = 'Is_Positive_Review'\ncampos_ignorar = ['Reviews', 'Reviews_procesadas', 'Caracteres_len', 'Palabras_len']\ncampos_features = [i for i in df.columns if i not in campos_ignorar]\n\n# División en conjuntos de test, validate y train\ntrain, validate, test = train_validate_test_split(df[campos_features])\nX_train = train.drop('Is_Positive_Review',1)\ny_train = train['Is_Positive_Review']\nX_validation = validate.drop('Is_Positive_Review', 1)\ny_validation = validate['Is_Positive_Review']\nX_test = test.drop('Is_Positive_Review', 1)\ny_test = test['Is_Positive_Review']","metadata":{"id":"ZtZsZspPZ5MU","execution":{"iopub.status.busy":"2021-09-15T17:39:54.312191Z","iopub.execute_input":"2021-09-15T17:39:54.312484Z","iopub.status.idle":"2021-09-15T17:39:54.410174Z","shell.execute_reply.started":"2021-09-15T17:39:54.312454Z","shell.execute_reply":"2021-09-15T17:39:54.409388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"campos_features","metadata":{"id":"qCxJndhZZ5MU","outputId":"16d904b4-79ff-4b35-ce88-42cecce641ac","execution":{"iopub.status.busy":"2021-09-15T17:39:58.281307Z","iopub.execute_input":"2021-09-15T17:39:58.281581Z","iopub.status.idle":"2021-09-15T17:39:58.286917Z","shell.execute_reply.started":"2021-09-15T17:39:58.281552Z","shell.execute_reply":"2021-09-15T17:39:58.286345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 8.1 Balanceo de los datos\n\nYa se ha visto que están desbalanceados, con muchas más reviews positivas que negativas. Los datos se balancearán con la librería SMOTE. ","metadata":{"id":"-3DLpu3OZ5MU"}},{"cell_type":"code","source":"# SMOTE para balancear los datos (se aplica sólo en el conjunto de entrenamiento)\nbalancear = SMOTE(random_state = 41)\nX_train_balanceado, y_train_balanceado = balancear.fit_resample(X_train, y_train) # Se aplica al conjunto de train\n\n# Se crean los dataframes con los conjuntos balanceados\nX_train_balanceado = pd.DataFrame(data = X_train_balanceado, columns = X_train.columns) # X_train_balanceado\nY_train_balanceado = pd.DataFrame(data= y_train_balanceado, columns = ['Is_Positive_Review'])","metadata":{"id":"GX64LzxVZ5MU","execution":{"iopub.status.busy":"2021-09-15T17:40:00.621732Z","iopub.execute_input":"2021-09-15T17:40:00.622056Z","iopub.status.idle":"2021-09-15T17:40:00.917193Z","shell.execute_reply.started":"2021-09-15T17:40:00.622025Z","shell.execute_reply":"2021-09-15T17:40:00.916247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 8.2 Regresión logística","metadata":{"id":"BDHdh1ZwZ5MU"}},{"cell_type":"code","source":"# Regresión logística\nreg_logistica = LogisticRegression()\nreg_logistica.fit(X_train_balanceado, Y_train_balanceado)","metadata":{"id":"-EQwCFjCZ5MV","outputId":"49c54fce-bf91-4837-f5a4-356c4336d972","execution":{"iopub.status.busy":"2021-09-15T17:40:03.075139Z","iopub.execute_input":"2021-09-15T17:40:03.075886Z","iopub.status.idle":"2021-09-15T17:40:06.853071Z","shell.execute_reply.started":"2021-09-15T17:40:03.075826Z","shell.execute_reply":"2021-09-15T17:40:06.85206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predicción\ny_pred = reg_logistica.predict(X_test)\n\nprint('Precisión de la regresión logística en el test: {:.2f}'.format(reg_logistica.score(X_test, y_test)))","metadata":{"id":"iC8XHqUSZ5MV","outputId":"dde7d64a-5c55-480a-e77e-f026becc97af","execution":{"iopub.status.busy":"2021-09-15T17:40:08.843506Z","iopub.execute_input":"2021-09-15T17:40:08.844003Z","iopub.status.idle":"2021-09-15T17:40:08.871246Z","shell.execute_reply.started":"2021-09-15T17:40:08.843957Z","shell.execute_reply":"2021-09-15T17:40:08.870389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Matriz de confusión\nplot_confusion_matrix(reg_logistica, X_test, y_test, normalize = None)\n\nprint(classification_report(y_test,y_pred))\nprint(confusion_matrix(y_test,y_pred)) # Por si no se ve bien en el dibujo","metadata":{"id":"C0my9cE-Z5MV","outputId":"31027f14-e7e4-4c0b-ba31-fcf0b2cacda7","execution":{"iopub.status.busy":"2021-09-15T17:40:11.098426Z","iopub.execute_input":"2021-09-15T17:40:11.09872Z","iopub.status.idle":"2021-09-15T17:40:11.862477Z","shell.execute_reply.started":"2021-09-15T17:40:11.09869Z","shell.execute_reply":"2021-09-15T17:40:11.861522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ROC\ny_pred = [x[1] for x in reg_logistica.predict_proba(X_test)]\nfpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label = 1)\n\nroc_auc = auc(fpr, tpr)\n\nplt.figure(1, figsize = (15, 10))\nlw = 2\nplt.plot(fpr, tpr, color='darkorange',\n         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], lw=lw, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic example')\nplt.legend(loc=\"lower right\")\nplt.show()","metadata":{"id":"7v6ANmhJZ5MV","outputId":"51bdf154-19b1-4026-fcf6-78be1cbdc39e","execution":{"iopub.status.busy":"2021-09-15T17:40:14.568319Z","iopub.execute_input":"2021-09-15T17:40:14.56863Z","iopub.status.idle":"2021-09-15T17:40:14.946564Z","shell.execute_reply.started":"2021-09-15T17:40:14.568601Z","shell.execute_reply":"2021-09-15T17:40:14.945534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 8.3 Mejora del modelo","metadata":{"id":"xtF92q6TZ5MV"}},{"cell_type":"code","source":"# Mejorar las características de la regresión con otros parámetros. \n# En este caso se sacarán los mejores valores para, sobre todo, threshold. En regresión logística el valor predeterminado es\n# de 0.5\n\nfpr, tpr, thresholds = roc_curve(y_validation, reg_logistica.predict_proba(X_validation)[:,1])\ni = np.arange(len(tpr)) \nroc = pd.DataFrame({'fpr' : pd.Series(fpr, index=i),\n                    'tpr' : pd.Series(tpr, index = i), \n                    '1-fpr' : pd.Series(1-fpr, index = i), \n                    'tf' : pd.Series(tpr - (1-fpr), index = i), \n                    'thresholds' : pd.Series(thresholds, index = i)})\n\nroc.iloc[(roc.tf-0).abs().argsort()[:1]]","metadata":{"id":"XtuP8StkZ5MW","outputId":"a9af7217-ba0d-4fc2-e6c5-5506bbe9df0f","execution":{"iopub.status.busy":"2021-09-15T17:40:17.973772Z","iopub.execute_input":"2021-09-15T17:40:17.974255Z","iopub.status.idle":"2021-09-15T17:40:18.074372Z","shell.execute_reply.started":"2021-09-15T17:40:17.97421Z","shell.execute_reply":"2021-09-15T17:40:18.073328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"En las regresiones logísticas, el parámetro threshold viene predeterminado con un valor de 0.5. En este caso, según lo anterior, el óptimo es 0.482. Vamos a probar con este parámetro, a ver si mejora la precisión.","metadata":{"id":"2sAugkx1Z5MW"}},{"cell_type":"code","source":"# Threshold = 0.467\nthreshold = 0.467\npreds = np.where(reg_logistica.predict_proba(X_test)[:,1] > threshold, 1, 0)\nprint('Precisión: {:.2f}'.format(reg_logistica.score(X_test, preds)))","metadata":{"id":"HxTCZAdVZ5MW","outputId":"f1a5213b-bc50-4a37-b753-936cfafb48af","execution":{"iopub.status.busy":"2021-09-15T17:40:20.625276Z","iopub.execute_input":"2021-09-15T17:40:20.625557Z","iopub.status.idle":"2021-09-15T17:40:20.659217Z","shell.execute_reply.started":"2021-09-15T17:40:20.62553Z","shell.execute_reply":"2021-09-15T17:40:20.65808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Se ha mejorado muchísimo la precisión (ahora es 0.99). Se va a intentar mejorar más aún el modelo con el tuneo de los hiperparámetros (GridSearch)","metadata":{"id":"t8kAChimZ5MW"}},{"cell_type":"code","source":"# GridSearch\n\ngrid = {\"C\":np.array([0.001,0.01,0.1,1,10]), \"penalty\":[\"l1\",\"l2\"]}\n\nreg_logistica_gridsearchcv = GridSearchCV(reg_logistica, grid, cv=10)\n\nreg_logistica_gridsearchcv.fit(X_validation, y_validation)\nprint('Mejor Penalty:', reg_logistica_gridsearchcv.best_estimator_.get_params()['penalty'])\nprint('Mejor C:', reg_logistica_gridsearchcv.best_estimator_.get_params()['C'])","metadata":{"id":"n-bZZal1Z5MW","outputId":"bf22239a-c30a-4ced-81a9-b90792bd1c50","execution":{"iopub.status.busy":"2021-09-15T17:40:22.379566Z","iopub.execute_input":"2021-09-15T17:40:22.380283Z","iopub.status.idle":"2021-09-15T17:40:44.335508Z","shell.execute_reply.started":"2021-09-15T17:40:22.38023Z","shell.execute_reply":"2021-09-15T17:40:44.334457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Aplicación del GridSearch y del Threshold óptimo\n\nregr_log = LogisticRegression(penalty='l2', C=0.01) # Se ponen el mejor penalty y el mejor C calculados previamente\n\nregr_log.fit(X_train_balanceado, y_train_balanceado) # Entrenamos el modelo con los datos balanceados\n\nthreshold = 0.482 # óptimo, ya guardado previamente\nprediccion = np.where(regr_log.predict_proba(X_test)[:,1] > threshold, 1, 0) # Predicción con los valores óptimos\n\nprint(classification_report(y_test, prediccion))\nprint('Precisión de la regresión logística en el test: {:.2f}'.format(regr_log.score(X_test, prediccion)))","metadata":{"id":"MBwiRsyaZ5MW","outputId":"ccea47a8-2288-4d5f-df95-9ae4c994207e","execution":{"iopub.status.busy":"2021-09-15T17:40:51.54657Z","iopub.execute_input":"2021-09-15T17:40:51.548603Z","iopub.status.idle":"2021-09-15T17:40:55.815145Z","shell.execute_reply.started":"2021-09-15T17:40:51.548564Z","shell.execute_reply":"2021-09-15T17:40:55.814193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Matriz de confusión\nplot_confusion_matrix(regr_log, X_test, y_test, normalize = None)\n\nprint(classification_report(y_test, prediccion))\nprint(confusion_matrix(y_test, prediccion))","metadata":{"id":"RupZw5liZ5MW","outputId":"dfb05e32-5256-464c-b130-24e949eebda3","execution":{"iopub.status.busy":"2021-09-15T17:40:58.44681Z","iopub.execute_input":"2021-09-15T17:40:58.448771Z","iopub.status.idle":"2021-09-15T17:40:59.250973Z","shell.execute_reply.started":"2021-09-15T17:40:58.448708Z","shell.execute_reply":"2021-09-15T17:40:59.25006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ROC\ny_pred = [x[1] for x in regr_log.predict_proba(X_test)]\nfpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label = 1)\n\nroc_auc = auc(fpr, tpr)\n\nplt.figure(1, figsize = (15, 10))\nlw = 2\nplt.plot(fpr, tpr, color='darkorange',\n         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], lw=lw, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic example')\nplt.legend(loc=\"lower right\")\nplt.show()","metadata":{"id":"QC6FoI1qZ5MW","outputId":"1cf43638-a0f7-4645-a1e8-f61f195a4cd7","execution":{"iopub.status.busy":"2021-09-15T17:41:02.017243Z","iopub.execute_input":"2021-09-15T17:41:02.017562Z","iopub.status.idle":"2021-09-15T17:41:02.487858Z","shell.execute_reply.started":"2021-09-15T17:41:02.017526Z","shell.execute_reply":"2021-09-15T17:41:02.486961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 9. Guardar modelo","metadata":{"id":"LBa5AvvfZ5MW"}},{"cell_type":"code","source":"# Guardar el modelo (descomentar para guardarlo en formato .pkl)\n\"\"\"\nwith open(\"./model_sentiment_analysis.pkl\", 'wb') as f:\n    pickle.dump(regr_log, f)\n\"\"\"","metadata":{"id":"keLXGCHRZ5MX"},"execution_count":null,"outputs":[]}]}