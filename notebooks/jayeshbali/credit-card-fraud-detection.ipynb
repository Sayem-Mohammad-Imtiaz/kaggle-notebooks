{"cells":[{"metadata":{"trusted":false},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nimport seaborn as sns\nimport numpy as np\nfrom collections import Counter\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import ExtraTreesClassifier\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"### Read data\n\ndf = pd.read_csv('../input/creditcard.csv')\nprint(df.head())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"### Time and Amount are not scaled , so scaling it\nsc = StandardScaler()\ndf['Amount']=sc.fit_transform(df['Amount'].values.reshape(-1,1))\ndf['Time']=sc.fit_transform(df['Time'].values.reshape(-1,1))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"##Separate features and o/p class\nX = df.iloc[:,:-1]\ny = df.iloc[:,-1]\nsns.countplot(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"##Separate data into train and test\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=40, stratify=y)\nprint('Labels counts in y:', np.bincount(y))\nprint('Labels counts in y_train:', np.bincount(y_train))\nprint('Labels counts in y_test:', np.bincount(y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"##Feature selection excercise\n\nmodel = ExtraTreesClassifier()\nmodel.fit(X,y)\nprint(model.feature_importances_)\nfeat_importances = pd.Series(model.feature_importances_, index=X.columns)\nfeat_importances.nlargest(15).plot(kind='barh')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"##Correlation against each feature\n\ncorr = df.corr()\ncorr.round(2)\nplt.figure(figsize=(28,28))\nsns.heatmap(corr,annot=True,cmap='coolwarm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn import discriminant_analysis\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.model_selection import StratifiedKFold\n\nlda = discriminant_analysis.LinearDiscriminantAnalysis()#SVC(kernel=\"linear\")\n\nrfecv = RFECV(estimator=lda, step=1, cv=StratifiedKFold(3),scoring='accuracy')\nrfecv.fit(X_train, y_train)\n\nrfecv.n_features_\n# Numbers of features selected\nplt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\nrfecv.grid_scores_\n\nrfecv.support_\n\nX_train.columns.values[rfecv.support_]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"##Check for distribution of each feature on each class\n##Used for feature selection\n\ngs = gridspec.GridSpec(28,1)\nplt.figure(figsize=(6,28*4))\nfor i,col in enumerate(df[df.iloc[:,0:28].columns]):\n    ax = plt.subplot(gs[i])\n    sns.distplot(df[col][df.Class ==1],bins=50,color='r')\n    sns.distplot(df[col][df.Class ==0],bins=50,color='g')\n    ax.set_title('feature '+str(col))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"### Import all models that will be needed\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import f1_score\nfrom sklearn import metrics\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.datasets import make_classification\nfrom sklearn.feature_selection import SelectFromModel , RFE\nimport statsmodels.api as sm\nfrom sklearn.metrics import roc_curve, auc , confusion_matrix , classification_report\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn import svm","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model = LogisticRegression()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nprint(\"Normal Logistic Regression with all columns as features\")\nprint(\"F1 score is {}\".format(f1_score(y_test, y_pred)))\nfpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\nprint(\"AUC is {}\".format(metrics.auc(fpr, tpr)))\nprint(\"Recall is {}\".format(metrics.recall_score(y_test, y_pred)))\nprint(\"Precision is {}\".format(metrics.precision_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"clf = RandomForestClassifier()\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint(\"Random Forest with all columns as features\")\nprint(\"F1 score is {}\".format(f1_score(y_test, y_pred)))\nfpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\nprint(\"AUC is {}\".format(metrics.auc(fpr, tpr)))\nprint(\"Recall is {}\".format(metrics.recall_score(y_test, y_pred)))\nprint(\"Precision is {}\".format(metrics.precision_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"## For over and under sampling\nfrom imblearn.over_sampling import RandomOverSampler , SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#rus = RandomOverSampler(sampling_strategy=0.01)\nrus = SMOTE(sampling_strategy=0.01)\nX_res,y_res=rus.fit_resample(X_train, y_train)\nprint('Labels counts in y_train:', np.bincount(y_train))\nprint('Labels counts in y_res:', np.bincount(y_res))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model = LogisticRegression()\nmodel.fit(X_res, y_res)\ny_pred = model.predict(X_test)\nprint(\"Logisitic Regression with Random Sampling and sampling strategy and all columns as features\")\nprint(\"F1 score is {}\".format(f1_score(y_test, y_pred)))\nfpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\nprint(\"AUC is {}\".format(metrics.auc(fpr, tpr)))\nprint(\"Recall is {}\".format(metrics.recall_score(y_test, y_pred)))\nprint(\"Precision is {}\".format(metrics.precision_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"clf = RandomForestClassifier()\nclf.fit(X_res, y_res)\ny_pred = clf.predict(X_test)\nprint(\"Random Forest with Random Sampling and sampling strategy and all columns as features\")\nprint(\"F1 score is {}\".format(f1_score(y_test, y_pred)))\nfpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\nprint(\"AUC is {}\".format(metrics.auc(fpr, tpr)))\nprint(\"Recall is {}\".format(metrics.recall_score(y_test, y_pred)))\nprint(\"Precision is {}\".format(metrics.precision_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"### Hyper parameter tuning\n\nclf.get_params()\nfrom sklearn.model_selection import RandomizedSearchCV\nn_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\nmax_features = ['auto', 'log2']\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\nmin_samples_split = [2, 5, 10]\nmin_samples_leaf = [1, 2, 4]\nbootstrap = [True, False]\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\nprint(random_grid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"''' **** CAUTION - can take 10 hrs to run\nEither reduce number of parameters or no of values you want the gridsearch to go through\n\nrf = RandomForestClassifier()\nrf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\nrf_random.fit(X_res, y_res)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#rf_random.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"clf = RandomForestClassifier(n_estimators= 1000,min_samples_split= 2,min_samples_leaf= 1,max_features= 'auto',max_depth= 50,bootstrap= True)\nclf.fit(X_res, y_res)\n#clf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint(\"Random Forest with all columns as features\")\nprint(\"F1 score is {}\".format(f1_score(y_test, y_pred)))\nfpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\nprint(\"AUC is {}\".format(metrics.auc(fpr, tpr)))\nprint(\"Recall is {}\".format(metrics.recall_score(y_test, y_pred)))\nprint(\"Precision is {}\".format(metrics.precision_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_prob = clf.fit(X_res, y_res).predict_proba(X_test)[::,1]\n#print (y_prob)\nfpr, tpr, _ = metrics.roc_curve(y_test,  y_prob)\nauc = metrics.roc_auc_score(y_test, y_prob)\nplt.plot(fpr,tpr,label=\"data 1 + auc \"+str(auc))\nplt.legend(loc=4)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}