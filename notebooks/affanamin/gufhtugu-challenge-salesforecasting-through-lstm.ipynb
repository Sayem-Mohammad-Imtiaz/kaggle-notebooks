{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Sales Forecasting For Gufhtugu Publishers"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Importing all Necessary libraries For EDA\n\nimport numpy as np\nimport pandas as pd\npd.set_option(\"display.max_columns\",None)\npd.set_option(\"display.max_rows\",None)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set()\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\n# univariate lstm example\nimport numpy as np\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Flatten","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Reading Required Data\n\ndf = pd.read_csv(\"../input/gufhtugu-publications-dataset-challenge/GP Orders - 4.csv\",encoding=\"utf-8\", delimiter=',')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"statistics_of_data = []\nfor col in df.columns:\n  statistics_of_data.append((col,\n                             df[col].nunique(),\n                             df[col].isnull().sum()*100/df.shape[0],\n                             df[col].value_counts(normalize=True, dropna=False).values[0] * 100, \n                             df[col].dtype\n                             ))\nstats_df = pd.DataFrame(statistics_of_data, columns=['Feature', 'Uniq_val', 'missing_val', 'val_biggest_cat', 'type'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stats_df.sort_values('Uniq_val', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Renaming columns name\ndf1 = df1.rename(columns={'Order Number': 'Ord_num','Order Date':'Ord_Date','City (Billing)':'City',\n                          'Book Name':'Book_Name','Order Status':'Ord_Status'\n                         \n                         })\ndf1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Shout out muhammadismail99 for this function\n\nfrom itertools import chain\n\n# return list from series of comma-separated strings\ndef chainer(s):\n    return list(chain.from_iterable(s.str.split('/')))\n\n# calculate lengths of splits\ndf2 = df1.copy()\nlens = df2['Book_Name'].str.split('/').map(len)\n\n# create new dataframe, repeating or chaining as appropriate\ndf2 = pd.DataFrame({'Ord_num': np.repeat(df2['Ord_num'], lens),\n                    'Ord_Status': np.repeat(df2['Ord_Status'], lens),\n                    'Book_Name': chainer(df2['Book_Name']),\n                    'Ord_Date': np.repeat(df2['Ord_Date'], lens),\n                    'City': np.repeat(df2['City'], lens)})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2['City'] = df2['City'].str.lower()\ndf2['City'] = df2['City'].apply(lambda x: x.strip(''))\ncity_stats = df2['City'].value_counts(ascending=False)\ncity_stats.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ReplaceString(searchterm,replacedWith,data):\n    search_terms = searchterm\n    matches = []\n    for memo_string in data:#df['City (Billing)']:\n        for word in search_terms.split(\" \"):\n            if word not in memo_string:\n                break\n            else:\n                #df['City (Billing)'].replace(memo_string,'karachi',inplace=True)\n                data.replace(memo_string,replacedWith,inplace=True)\n                matches.append(memo_string) # triggers when the for loop doesn't break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df3 = df2.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ReplaceString('karachi','karachi',df3['City'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ReplaceString('lahore','lahore',df3['City'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ReplaceString('islamabad','islamabad',df3['City'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ReplaceString('rawalpindi','rawalpindi',df3['City'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ReplaceString('faisalabad','faisalabad',df3['City'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ReplaceString('multan','multan',df3['City'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ReplaceString('hyderabad','hyderabad',df3['City'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ReplaceString('????? ??? ??? ???? ??????','unknown',df3['City'])\nReplaceString('???????','unknown',df3['City'])\nReplaceString('??? ???','unknown',df3['City'])\nReplaceString('????????','unknown',df3['City'])\nReplaceString('?????','unknown',df3['City'])\nReplaceString('????','unknown',df3['City'])\nReplaceString('??????','unknown',df3['City'])\nReplaceString('???????','unknown',df3['City'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df3.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df3['City'].unique()) ## Everything ('2869') is validated till here","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df4 = df3.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Cities having orders less than 12 cardinality are termed as others\n\ncity_stats_less_than_12 = city_stats[city_stats<=12]\n\ndf4['City'] =df4['City'].apply(lambda x: 'other' if x in city_stats_less_than_12 else x)\nlen(df4['City'].unique()) ##Everything ('195') is validated till here","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Formatting Order Status Feature\ndf5 = df4.copy()\ncombine = [df5]\ntitlemapping = {'Canceled':0, 'Completed':1,'Returned':2}\nfor row in combine:\n    row[\"Ord_Status\"] = row[\"Ord_Status\"].map(titlemapping)\n    row['Ord_Status'] = row['Ord_Status'].fillna(0)\n    row['Ord_Status'] = row['Ord_Status'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df5.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df6 = df5.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #Thanks to @hussainsaddam12 & @mnavaidd for this codeblock idea\ndf6[\"Ord_Date\"] = pd.DatetimeIndex(df6[\"Ord_Date\"])\ndf6['date'] = df6['Ord_Date'].dt.date\ndf6['time'] = df6['Ord_Date'].dt.time\ndf6[\"Day_Name\"] = df6[\"Ord_Date\"].dt.day_name()\ndf6[\"Month_Name\"] = df6[\"Ord_Date\"].dt.month_name()\ndf6['year'] = df6[\"Ord_Date\"].dt.year","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df6.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df6.shape  ## 5 columns added ## Everything till here is validated (33091,10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df6['Book_Name'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets take an average of 500 rupees (PKR) as cost of each book\ndf6['Avgprice'] = 500\ndf6.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Average sale per month\n\n#Books Sold in jan\ndf7 = df6.copy()\ndf7 =df7[['Month_Name','Avgprice','Book_Name','Ord_Status','year']]\ndf7.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df7['Month_Name'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def AvgSale(df, month,year):\n    df = df[(df['Month_Name'] == month) & (df['Ord_Status'] == 1) & (df['year'] == year)] ##Order status = success\n    AvgSale22 = 500*len(df)\n    return AvgSale22\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Testing\njan2020_AvgSale = AvgSale(df7,'January',2020)\njan2020_AvgSale ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"jan2019_AvgSale = AvgSale(df7,'January',2019)\nfeb2019_AvgSale = AvgSale(df7,'February',2019)\nmar2019_AvgSale = AvgSale(df7,'March',2019)\napr2019_AvgSale = AvgSale(df7,'April',2019)\nmay2019_AvgSale = AvgSale(df7,'May',2019)\njune2019_AvgSale = AvgSale(df7,'June',2019)\njuly2019_AvgSale = AvgSale(df7,'July',2019)\naug2019_AvgSale = AvgSale(df7,'August',2019)\nsept2019_AvgSale = AvgSale(df7,'September',2019)\noct2019_AvgSale = AvgSale(df7,'October',2019)\nnov2019_AvgSale = AvgSale(df7,'November',2019)\ndec2019_AvgSale = AvgSale(df7,'December',2019)\n\n\n\njan2020_AvgSale = AvgSale(df7,'January',2020)\nfeb2020_AvgSale = AvgSale(df7,'February',2020)\nmar2020_AvgSale = AvgSale(df7,'March',2020)\napr2020_AvgSale = AvgSale(df7,'April',2020)\nmay2020_AvgSale = AvgSale(df7,'May',2020)\njune2020_AvgSale = AvgSale(df7,'June',2020)\njuly2020_AvgSale = AvgSale(df7,'July',2020)\naug2020_AvgSale = AvgSale(df7,'August',2020)\nsept2020_AvgSale = AvgSale(df7,'September',2020)\noct2020_AvgSale = AvgSale(df7,'October',2020)\nnov2020_AvgSale = AvgSale(df7,'November',2020)\ndec2020_AvgSale = AvgSale(df7,'December',2020)\n\n\njan2021_AvgSale = AvgSale(df7,'January',2021)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {'Month': ['2019-01-01', '2019-02-01','2019-03-01','2019-04-01','2019-05-01',\n               '2019-06-01','2019-07-01','2019-08-01','2019-09-01','2019-10-01',\n               '2019-11-01','2019-12-01',\n               \n               '2020-01-01', '2020-02-01','2020-03-01','2020-04-01','2020-05-01',\n               '2020-06-01','2020-07-01','2020-08-01','2020-09-01','2020-10-01',\n               '2020-11-01','2020-12-01',\n               \n               '2021-01-01'], 'AvgSales': [jan2019_AvgSale,feb2019_AvgSale, mar2019_AvgSale,apr2019_AvgSale,may2019_AvgSale,\n                                       \n                                       june2019_AvgSale,july2019_AvgSale,aug2019_AvgSale,sept2019_AvgSale,oct2019_AvgSale,\n                                        \n                                       nov2019_AvgSale,dec2019_AvgSale,\n                                        \n                                        jan2020_AvgSale,feb2020_AvgSale,mar2020_AvgSale,apr2020_AvgSale,may2020_AvgSale,\n                                        \n                                        june2020_AvgSale,july2020_AvgSale,aug2020_AvgSale,sept2020_AvgSale,oct2020_AvgSale,\n                                        nov2020_AvgSale,dec2020_AvgSale,jan2021_AvgSale\n                                        \n                                       ]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df8 = pd.DataFrame(data=d)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df8.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df8.tail(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df8.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualizing data\n\ndf8.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Yup, Growth is amazing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# preparing independent and dependent features\ndef prepare_data(timeseries_data, n_features):\n\tX, y =[],[]\n\tfor i in range(len(timeseries_data)):\n\t\t# find the end of this pattern\n\t\tend_ix = i + n_features\n\t\t# check if we are beyond the sequence\n\t\tif end_ix > len(timeseries_data)-1:\n\t\t\tbreak\n\t\t# gather input and output parts of the pattern\n\t\tseq_x, seq_y = timeseries_data[i:end_ix], timeseries_data[end_ix]\n\t\tX.append(seq_x)\n\t\ty.append(seq_y)\n\treturn np.array(X), np.array(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define input sequence\ntimeseries_data = df8['AvgSales']\n# choose a number of time steps\nn_steps = 3\n# split into samples\nX, y = prepare_data(timeseries_data, n_steps)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X),print(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## reshaping\n\nn_features = 1\nX = X.reshape((X.shape[0],X.shape[1],n_features))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Building LSTM Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# define model\nmodel = Sequential()\nmodel.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\nmodel.add(LSTM(50, activation='relu'))\nmodel.add(Dense(1))\nmodel.compile(optimizer='adam', loss='mse')\n# fit model\nmodel.fit(X, y, epochs=300, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# demonstrate prediction for next 10 Months\nx_input = np.array([1722000, 2404000, 3136000])\ntemp_input=list(x_input)\nlst_output=[]\ni=0\nwhile(i<10):\n    \n    if(len(temp_input)>3):\n        x_input=np.array(temp_input[1:])\n        print(\"{} Months input {}\".format(i,x_input))\n        #print(x_input)\n        x_input = x_input.reshape((1, n_steps, n_features))\n        #print(x_input)\n        yhat = model.predict(x_input, verbose=0)\n        print(\"{} Month output {}\".format(i,yhat))\n        temp_input.append(yhat[0][0])\n        temp_input=temp_input[1:]\n        #print(temp_input)\n        lst_output.append(yhat[0][0])\n        i=i+1\n    else:\n        x_input = x_input.reshape((1, n_steps, n_features))\n        yhat = model.predict(x_input, verbose=0)\n        print(yhat[0])\n        temp_input.append(yhat[0][0])\n        lst_output.append(yhat[0][0])\n        i=i+1\n    \n\nprint(lst_output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"timeseries_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(timeseries_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lst_output","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualizaing The Output"},{"metadata":{"trusted":true},"cell_type":"code","source":"lst_output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"day_new=np.arange(1,26)\nday_pred=np.arange(26,36)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"timeseries_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"day_new","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"day_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(day_new,timeseries_data)\nplt.plot(day_pred,lst_output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lst_output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Above is the sale prediction of gufhtugu publishers for next 10 months (From Feb 2021 - Nov 2021)"},{"metadata":{},"cell_type":"markdown","source":"Thats all for Average sales prediction (Taking an average of 500 PKR per Book) for Gufhtugu Publishers, Up vote it if you liked it."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}