{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"c9b0c7e7-85bf-cd39-f3da-6c8e8148cdad"},"source":"Crowdflower's [post](https://www.crowdflower.com/using-machine-learning-to-predict-gender/) on this dataset is pretty lacking in details about what kind of model they used to predict Twitter user gender. All they say about it is \"we ran the tweets through our AI feature\", and that they achieved about 60% accuracy on their three-way (male, female, brand/organization) classification task.\n\nLet's see how well we can do in a quick run-through.\n\nI'm going to crib a lot of code from [my notebook on classifying types of news](https://www.kaggle.com/kinguistics/d/uciml/news-aggregator-dataset/classifying-news-headlines-with-scikit-learn)."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7b039c5f-8f85-27ab-d378-316822cd4e73"},"outputs":[],"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# we'll want this for plotting\nimport matplotlib.pyplot as plt\n\n# we'll want this for text manipulation\nimport re\n\n# for quick and dirty counting\nfrom collections import defaultdict\n\n# the Naive Bayes model\nfrom sklearn.naive_bayes import MultinomialNB\n# function to split the data for cross-validation\nfrom sklearn.model_selection import train_test_split\n# function for transforming documents into counts\nfrom sklearn.feature_extraction.text import CountVectorizer\n# function for encoding categories\nfrom sklearn.preprocessing import LabelEncoder\n\n# have to use latin1 even though it results in a lot of dead characters\ntwigen = pd.read_csv(\"../input/gender-classifier-DFE-791531.csv\", encoding='latin1')\ntwigen.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"67c516df-2b1d-7368-08c0-c703ad2e7ac1"},"outputs":[],"source":"def normalize_text(s):\n    # just in case\n    s = str(s)\n    s = s.lower()\n    \n    # remove punctuation that is not word-internal (e.g., hyphens, apostrophes)\n    s = re.sub('\\s\\W',' ',s)\n    s = re.sub('\\W\\s',' ',s)\n    \n    # make sure we didn't introduce any double spaces\n    s = re.sub('\\s+',' ',s)\n    \n    return s\n\ntwigen['text_norm'] = [normalize_text(s) for s in twigen['text']]\ntwigen['description_norm'] = [normalize_text(s) for s in twigen['description']]\n"},{"cell_type":"markdown","metadata":{"_cell_guid":"85c37765-50d9-fc8d-e955-eba6e53d2189"},"source":"Let's grab some info about the gold standard and about the dataset's confidence in its gender classifications so we have some idea of what would be good to train on."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"89ab3525-95ba-a8fd-9014-622176c85519"},"outputs":[],"source":"\n# how many observations are gold standard?\ngold_values = defaultdict(int)\nfor val in twigen._golden:\n    gold_values[val] += 1\nprint(gold_values)\n\n# what does the confidence look like?\nprint(np.any(np.isnan(twigen['gender:confidence'])))\n# we've got at least one NaN, so let's remove\ngender_confidence = twigen['gender:confidence'][np.where(np.invert(np.isnan(twigen['gender:confidence'])))[0]]\nprint(len(gender_confidence))\ngender_nonones = gender_confidence[np.where(gender_confidence < 1)[0]]\nprint(len(gender_nonones))"},{"cell_type":"markdown","metadata":{"_cell_guid":"18b37850-d415-84bc-d5ed-2c741596251e"},"source":"About 30% of the observations have less than 100% confidence in the gender classification, so we'll ignore those."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"030e3477-1b9a-1eb9-07ab-250caf6699f5"},"outputs":[],"source":"twigen_confident = twigen[twigen['gender:confidence']==1]\ntwigen_confident.shape"},{"cell_type":"markdown","metadata":{"_cell_guid":"e5e89758-003c-505f-2a53-38b6b0e9a570"},"source":"Okay, now let's see how well a Naive Bayes classifier can do by just looking at the words in the randomly chosen tweet."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fd7f2412-6c0e-287e-314e-fd687982840e"},"outputs":[],"source":"# pull the data into vectors\nvectorizer = CountVectorizer()\nx = vectorizer.fit_transform(twigen_confident['text_norm'])\n\nencoder = LabelEncoder()\ny = encoder.fit_transform(twigen_confident['gender'])\n\n# split into train and test sets\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n\n# take a look at the shape of each of these\nprint(x_train.shape)\nprint(y_train.shape)\nprint(x_test.shape)\nprint(y_test.shape)\n"},{"cell_type":"markdown","metadata":{"_cell_guid":"7119e588-cee1-d929-4cfa-ede86f19b803"},"source":"Alright, let's make the classifier"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"919277c6-af20-5939-1565-90241504508f"},"outputs":[],"source":"nb = MultinomialNB()\nnb.fit(x_train, y_train)\n\nprint(nb.score(x_test, y_test))"},{"cell_type":"markdown","metadata":{"_cell_guid":"e53c7f06-17f4-2f64-f4fb-4a768dc1e4ad"},"source":"So we get about 58% accuracy on the \"best\" observations, using only tweet text.\n\nLet's try a couple more features. Specifically, let's add the description text by concatenating it to the tweet text."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c9c0e7c4-3770-7a61-fcc6-64270c12cc33"},"outputs":[],"source":"twigen['all_features'] = twigen['text_norm'].str.cat(twigen['description_norm'], sep=' ')\n\ntwigen_confident = twigen[twigen['gender:confidence']==1]\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"08031ef1-96f7-eb15-d798-553c489af683"},"outputs":[],"source":"# pull the data into vectors\nvectorizer = CountVectorizer()\nx = vectorizer.fit_transform(twigen_confident['text_norm'])\n\nencoder = LabelEncoder()\ny = encoder.fit_transform(twigen_confident['gender'])\n\n# split into train and test sets\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n\nnb = MultinomialNB()\nnb.fit(x_train, y_train)\n\nprint(nb.score(x_test, y_test))"},{"cell_type":"markdown","metadata":{"_cell_guid":"c1a400f2-557c-28ba-1113-23a423125eaf"},"source":"Cool, so we gain about 2-3 percentage points in accuracy just by adding description text alongside tweet text.\n\nYou can use this kind of procedure to play around with adding more features, or try a different type of model and see how accurately you can predict gender. (Maybe also try including the less-confident observations; my exclusion of them was probably anti-conservative)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}