{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction"},{"metadata":{},"cell_type":"markdown","source":"Hello guys, this code is part of Maven analytics challenge. EDA will be performed in PowerBI, but iÂ´d like to create simple predictive model using XGBoost to spice things up!\n\nLink to challenge: \n\nhttps://www.mavenanalytics.io/blog/maven-marketing-challenge?utm_source=linkedin&utm_campaign=marketingchallenge_li_maven"},{"metadata":{},"cell_type":"markdown","source":"# Importing neccessary libraries "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nimport xgboost as xgb\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows',50)\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.metrics import confusion_matrix, classification_report, make_scorer\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RandomizedSearchCV","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reading and exploring basic information"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.read_csv(\"../input/marketing-data/marketing_data.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#renaming column\ndataset.rename(columns={\" Income \": \"Income\"}, inplace = True )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.isnull().sum() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking unique values\ndataset['Education'].unique().tolist()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['Marital_Status'].unique().tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['Country'].unique().tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking if target data are balanced\ndataset['Response'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocessing(dataset):\n    dataset = dataset.copy()\n    \n    \n    #filling nans and converting to numeric\n    dataset[\"Income\"] = dataset[\"Income\"].replace('[$,]', '', regex=True).astype(float)\n    dataset[\"Income\"] = dataset[\"Income\"].fillna(dataset[\"Income\"].mean())\n    \n    \n    #converting Dt_customer to date time\n    dataset[\"Dt_Customer\"] =  pd.to_datetime(dataset[\"Dt_Customer\"])\n    dataset[\"Year\"]=dataset[\"Dt_Customer\"].dt.year\n    dataset[\"Month\"]=dataset[\"Dt_Customer\"].dt.month\n    dataset[\"Day\"]= dataset[\"Dt_Customer\"].dt.day\n    dataset = dataset.drop(\"Dt_Customer\", axis = 1)\n    \n    \n    #replacing 2nd cycle in Education column\n    dataset[\"Education\"] = dataset[\"Education\"].str.replace('2n Cycle','Master')\n    \n    #replacing marital statuses\n    dataset[\"Marital_Status\"] = dataset[\"Marital_Status\"].str.replace('Alone','Single')\n    dataset[\"Marital_Status\"] = dataset[\"Marital_Status\"].str.replace('YOLO','Other')\n    dataset[\"Marital_Status\"] = dataset[\"Marital_Status\"].str.replace('Absurd','Other')\n    \n    #dropping ID\n    dataset = dataset.drop(\"ID\", axis=1)\n    \n    #getting dummies\n    dataset = pd.get_dummies(data=dataset, columns=['Education', \"Marital_Status\", \"Country\"])\n    #X, y split\n    X = dataset.drop(\"Response\", axis=1)\n    y = dataset[\"Response\"]\n    \n    #scaling\n    sc = StandardScaler()\n    X = pd.DataFrame(sc.fit_transform(X), index=X.index, columns=X.columns)\n    \n    #train, test split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=123)\n    \n    #balacing data\n    sm = SMOTE(random_state=2)\n    X_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel())\n    \n    return X_train_res, X_test, y_train_res, y_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_res, X_test, y_train_res, y_test = preprocessing(dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fitting into XGBoost and evaluatin results before tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"xg = xgb.XGBClassifier()\nxg.fit(X_train_res, y_train_res)\ny_pred = xg.predict(X_test)\ny_pred_train = xg.predict(X_train_res)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Model Accuracy : ', accuracy_score(y_test, y_pred) *  100)\nprint('Model Recall : ', recall_score(y_test, y_pred) *  100)\nprint('Model Precision : ', precision_score(y_test, y_pred) *  100)\nprint(\"F1 Score: \", f1_score(y_test, y_pred) * 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics_before_tune = (\"Accuracy before tune\", \"Recall  before tune\", \"Precision  before tune\", \"F1  before tune\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eval_before_tune = pd.DataFrame(xg, index=metrics_before_tune, columns=[\"Score\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eval_before_tune.loc[\"Recall  before tune\", \"Score\"] = recall_score(y_test, y_pred)\neval_before_tune.loc[\"Accuracy before tune\", \"Score\"] =  accuracy_score(y_test, y_pred)\neval_before_tune.loc[\"Precision  before tune\", \"Score\"] = precision_score(y_test, y_pred)\neval_before_tune.loc[\"F1  before tune\", \"Score\"] = f1_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eval_before_tune","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Model Accuracy : ', accuracy_score(y_train_res, y_pred_train) *  100)\nprint('Model Recall : ', recall_score(y_train_res, y_pred_train) *  100)\nprint('Model Precision : ', precision_score(y_train_res, y_pred_train) *  100)\nprint(\"F1 Score: \", f1_score(y_train_res, y_pred_train) * 100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cheking which features are important for model"},{"metadata":{"trusted":true},"cell_type":"code","source":"name = X_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"importance = pd.DataFrame(xg.feature_importances_, index = name, columns = [\"Score\"]).sort_values(\"Score\", ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"importance","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Checking correlation among features"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n#Using Pearson Correlation\nplt.figure(figsize=(12,10))\ncor = X_train.corr()\nsns.heatmap(cor, annot=True, cmap=plt.cm.CMRmap_r)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Parameter tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters = {\n        'learning_rate': [0.01, 0.5],\n        'max_depth': [3, 5, 7, 10,50],\n        'min_child_weight': [1, 3, 5, 10],\n        'subsample': [0.1, 0.7],\n        'colsample_bytree': [0.5, 0.9],\n        'n_estimators' : [1, 20, 50],\n        'objective': ['reg:squarederror']\n    }\nscorer = make_scorer(accuracy_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scorer_accuracy = make_scorer(accuracy_score)\nscorer_recall = make_scorer(recall_score)\nscorer_precision = make_scorer(precision_score)\nscorer_f1 = make_scorer(f1_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_xg_from_search(xg, parameters, scorer, X, y):\n    search_obj = RandomizedSearchCV(xg, parameters, scoring=scorer)\n    fit_obj = search_obj.fit(X, y)\n    best_xg = fit_obj.best_estimator_\n    return best_xg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = cross_val_score(best_xg, X_train_res, y_train_res, cv=5, scoring= \"accuracy\")\nscores.mean()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scorer_recall = cross_val_score(best_xg, X_train_res, y_train_res, cv=5, scoring= \"recall\")\nscorer_accuracy = cross_val_score(best_xg, X_train_res, y_train_res, cv=5, scoring= \"accuracy\")\nscorer_precision = cross_val_score(best_xg, X_train_res, y_train_res, cv=5, scoring= \"precision\")\nscorer_f1_score = cross_val_score(best_xg, X_train_res, y_train_res, cv=5, scoring= \"f1_macro\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics_after_tune = (\"Accuracy after tuning\", \"Recall after tuning\", \"Precision after tuning\", \"F1 after tuning\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eval_after_tune = pd.DataFrame(make_scorer, index=metrics_after_tune, columns=[\"Score\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eval_after_tune.loc[\"Recall after tuning\", \"Score\"] = (scorer_recall.mean() * 100)\neval_after_tune.loc[\"Accuracy after tuning\", \"Score\"] = (scorer_accuracy.mean()*100)\neval_after_tune.loc[\"Precision after tuning\", \"Score\"] = (scorer_f1_score.mean()*100)\neval_after_tune.loc[\"F1 after tuning\", \"Score\"] = (scorer_precision.mean()*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eval_after_tune","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}