{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"In this study, we will try to see if we can predict the Avocado’s Average Price based on different features.  . The features are different (Total Bags,Date,Type,Year,Region…).\n\nThe variables of the dataset are the following:\n\n* Categorical: ‘region’,’type’\n* Date: ‘Date’\n* Numerical:‘Unamed: 0’,’Total Volume’, ‘4046’, ‘4225’, ‘4770’, ‘Total Bags’, ‘Small Bags’,’Large Bags’,’XLarge Bags’,’Year’\n* Target:‘AveragePrice’\n\nThe unclear numerical variables terminology is explained in the next section:\n\n* ‘Unamed: 0’ : Its just a useless index feature that will be removed later\n* ,’Total Volume’ : Total sales volume of avocados\n* ‘4046’ : Total sales volume of  Small/Medium Hass Avocado\n* ‘4225’ : Total sales volume of Large Hass Avocado\n* ‘4770’ : Total sales volume of Extra Large Hass Avocado\n* ‘Total Bags’: Total number of Bags sold\n* ‘Small Bags’: Total number of Small Bags sold\n* Large Bags’: Total number of Large Bags sold\n* ‘XLarge Bags’: Total number of XLarge Bags sold\n\n**So lets start by importing our usual suspects !!**\n"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1998755ef10683262b29765345cff1c1c7d10b15"},"cell_type":"markdown","source":"Read in the Avocado Prices csv file as a DataFrame called df"},{"metadata":{"trusted":true,"_uuid":"55d0e719eb8b91d763c1eacaf0f51ee0586486fc"},"cell_type":"code","source":"df= pd.read_csv(\"../input/avocado.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a9ab8bd9cece4171c0640c34638f75719765ee6a"},"cell_type":"markdown","source":"Lets check our data head:"},{"metadata":{"trusted":true,"_uuid":"281603de055065082289e0f8f3bcfc0ddaa93c56"},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"434e0457f550e2200424e5ec26162e1aa5904005"},"cell_type":"markdown","source":"The Feature \"Unnamed:0\" is just a representation of the indexes, so it's useless to keep it, lets remove it !"},{"metadata":{"trusted":true,"_uuid":"9875398e37728dc3141fed4228be337a4735beb6"},"cell_type":"code","source":"df.drop('Unnamed: 0',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"94771e266cde18798efb66676d2eb94ef1d661ed"},"cell_type":"markdown","source":"Lets check our data head again to make sure that the Feature Unnamed:0 is removed"},{"metadata":{"trusted":true,"_uuid":"20ec64f768e5e814884ff71068ca3429a1dd7167"},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"139fe6013e407e86bf19ff8372c4b80265983d22"},"cell_type":"markdown","source":"Great! now lets use the info() methode to get an a general idea about our data:"},{"metadata":{"trusted":true,"_uuid":"7be56bde1eb340b94105dafc597cfa0473320516"},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"12e94ad381e4cb8d2c8a9bbe08ce07ab5d49c040"},"cell_type":"markdown","source":"well as a first observation we can see that we are lucky, we dont have any missing values (18249 complete data) and 13 columns.\nNow let's do some Feature Engineering on the Date Feature so we can be able to use the day and the month columns in building our machine learning model later. ( I didn't mention the year because its already there in data frame)"},{"metadata":{"trusted":true,"_uuid":"f031639ce794656e877484d1c9c356df7028177f"},"cell_type":"code","source":"df['Date']=pd.to_datetime(df['Date'])\ndf['Month']=df['Date'].apply(lambda x:x.month)\ndf['Day']=df['Date'].apply(lambda x:x.day)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a3f844eb243f3c5c7464a5132e76c9b38ccb0964"},"cell_type":"markdown","source":"Lets check the head to see what we have done:"},{"metadata":{"trusted":true,"_uuid":"0b152157c7ac7523d6a5814b583545775d4d611f"},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ca18cf05536a864290d288b1b2bbd52058d898fc"},"cell_type":"markdown","source":"Now lets do some plots!! \nI'll start by plotting the Avocado's Average Price  through the Date column"},{"metadata":{"trusted":true,"_uuid":"d0c04f2845bee8595559476bf1112d43a017517c"},"cell_type":"code","source":"byDate=df.groupby('Date').mean()\nplt.figure(figsize=(12,8))\nbyDate['AveragePrice'].plot()\nplt.title('Average Price')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c4062e9e3f59c58151967cd0dba2963036a92f3a"},"cell_type":"markdown","source":"Cool right? now lets have an idea about the relationship between our Features(Correlation)"},{"metadata":{"trusted":true,"_uuid":"e4a38390b6366903efcc7c01dd41f743f16071a8"},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.heatmap(df.corr(),cmap='coolwarm',annot=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"71f0984e0be001d678591dd40ca55309c561bbdc"},"cell_type":"markdown","source":"As we can from the heatmap above, all the Features are not corroleted with the Average Price column, instead most of them are correlated with each other.\nSo now I am bit worried because that will not help us get a good model. Lets try and see.\nFirst we have to do some Feature Engineering on the categorical Features : region and type"},{"metadata":{"trusted":true,"_uuid":"be05c2454a097bbac193e1779fc24d59f5daad38"},"cell_type":"code","source":"df['region'].nunique()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"127196099a336320b7ac3dc0bd64f08770cb3e38"},"cell_type":"code","source":"df['type'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ebdcac9924ce3e366fd3a75170682f7113385b7a"},"cell_type":"markdown","source":"as we can see we have 54 regions and 2 unique types, so it's going to be easy to to transform the type feature to dummies, but for the region its going to be a bit complexe so I decided to drop the entire column.\nI will drop the Date Feature as well because I already have 3 other columns for the Year, Month and Day."},{"metadata":{"trusted":true,"_uuid":"a798682da34327b731ef262985fd50ba68e06460"},"cell_type":"code","source":"df_final=pd.get_dummies(df.drop(['region','Date'],axis=1),drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fff404c710690a5289720657e2b3bfc1474409b8"},"cell_type":"code","source":"df_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f33b797fe093729604c4906fd05031629b61cc3"},"cell_type":"code","source":"df_final.tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8b74a6b88cb3e9b3e1d1e987e061048f203c7364"},"cell_type":"markdown","source":"Now our data are ready! lets apply our model which is going to be the Linear Regression because our Target variable 'AveragePrice'is continuous.\nLet's now begin to train out regression model! We will need to first split up our data into an X array that contains the features to train on, and a y array with the target variable"},{"metadata":{"trusted":true,"_uuid":"830591f99de9715241e688bf9ce265e979401ff5"},"cell_type":"code","source":"X=df_final.iloc[:,1:14]\ny=df_final['AveragePrice']\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ea730c77a31cde9de98263079a189accb8b5772b"},"cell_type":"markdown","source":"Creating and Training the Model"},{"metadata":{"trusted":true,"_uuid":"32ab47e730313e86a72f2dbaab06f9531353322b"},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlr=LinearRegression()\nlr.fit(X_train,y_train)\npred=lr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"27c363c229d5f5913f09d4dc76eb88f4ca750a17"},"cell_type":"code","source":"from sklearn import metrics\nprint('MAE:', metrics.mean_absolute_error(y_test, pred))\nprint('MSE:', metrics.mean_squared_error(y_test, pred))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, pred)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a5c389f8dbdcf26b56a4e9afd211345052a4d9d9"},"cell_type":"markdown","source":"The RMSE is low so we can say that we do have a good model, but lets check to be more sure.\nLets plot the y_test vs the predictions"},{"metadata":{"trusted":true,"_uuid":"cabe20193e02e42774b97af0476d19ab44ff4b10"},"cell_type":"code","source":"plt.scatter(x=y_test,y=pred)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"feb211733c7010b8674410c5e9097fd96dd3095f"},"cell_type":"markdown","source":"As we can see that we dont have a straigt line so I am not sure that this is the best model we can apply on our data"},{"metadata":{"_uuid":"c7304a407610f49a05931c54f2884c14c3098f73"},"cell_type":"markdown","source":"Lets try working with the  DecisionTree Regressor model\n"},{"metadata":{"trusted":true,"_uuid":"02a8e013ce494ffac56ce0e0ab85c98b024de251"},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\ndtr=DecisionTreeRegressor()\ndtr.fit(X_train,y_train)\npred=dtr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"53c1c575b04ef606d23f162b5a26ed8736390274"},"cell_type":"code","source":"plt.scatter(x=y_test,y=pred)\nplt.xlabel('Y Test')\nplt.ylabel('Predicted Y')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"90b343a7f2c69b479048cac52918b7c840fa21b8"},"cell_type":"markdown","source":"Nice, here we can see that we nearly have a straigt line, in other words its better than the Linear regression model, and to be more sure lets check the RMSE"},{"metadata":{"trusted":true,"_uuid":"eaeaad541bb690b9c290afc32d96d07d1886d8f1"},"cell_type":"code","source":"print('MAE:', metrics.mean_absolute_error(y_test, pred))\nprint('MSE:', metrics.mean_squared_error(y_test, pred))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, pred)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d0b2c3fc64b83590764eb35e95d2d7a494799059"},"cell_type":"markdown","source":"Very Nice, our RMSE is lower than the previous one we got with Linear Regression. ok now I am going to try one last model to see if I can improve my predictions for this data which is the RandomForestRegressor"},{"metadata":{"trusted":true,"_uuid":"eb37015e78974e5fd2ae7e13d065c8ab0a9c6948"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nrdr = RandomForestRegressor()\nrdr.fit(X_train,y_train)\npred=rdr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7ed5b8d4e8abb44a4b548c13ac9fb2d65227d1c5"},"cell_type":"code","source":"print('MAE:', metrics.mean_absolute_error(y_test, pred))\nprint('MSE:', metrics.mean_squared_error(y_test, pred))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, pred)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c1e40f4c0cdfa43ac99ced67e7bd902887c4946c"},"cell_type":"markdown","source":"Well as we can see the RMSE is lower than the two previous models, so the RandomForest Regressor is the best model in this case."},{"metadata":{"trusted":true,"_uuid":"c96f0ee4cc5bb8bc1ad240c6d3da2f418c21fe0a"},"cell_type":"code","source":"sns.distplot((y_test-pred),bins=50)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"703c4963d4bf9d12de3ccba81eb614ec083ff041"},"cell_type":"markdown","source":"Notice here that our residuals looked to be normally distributed and that's really a good sign which means that our model was a correct choice for the data. "},{"metadata":{"trusted":true,"_uuid":"f88f8bee44ec8c9d9e769bf60696525ff45e6dbd"},"cell_type":"code","source":"data = pd.DataFrame({'Y Test':y_test , 'Pred':pred},columns=['Y Test','Pred'])\nsns.lmplot(x='Y Test',y='Pred',data=data,palette='rainbow')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d575459e3cfb429dfcf4855902e67354f1a4ac3c"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}