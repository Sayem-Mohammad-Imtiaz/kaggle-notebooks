{"cells":[{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"!pip install tensorflow-gpu==2.0.0-beta1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport gc\nimport tensorflow as tf\nimport tensorflow_probability as tfp\nfrom tensorflow.keras import Model, Sequential\nfrom functools import partial\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Conv2DTranspose,\\\n                                    Reshape, ReLU, LeakyReLU,BatchNormalization, Lambda, \\\n                                    UpSampling2D, Softmax, Input, Dropout, AvgPool2D, Concatenate, \\\n                                    LocallyConnected2D, SpatialDropout2D, Activation, InputLayer\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Variational Ladder AutoEncoder with MMD\nPaper link: https://arxiv.org/abs/1702.08396 <br>\nWhile the paper implementation uses as regularizer between $ p(z) $ and $ p(x|z)$  the KL-Leibler divergence with warm up, my personal implementation use Maximum Mean Discrepancy with a rbf kernel\n### VLAE representation as graphical model\n![](https://i.ibb.co/yp7gwwT/vlae.png)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.__version__","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data loading and preprocessing\nI've loaded the MNIST dataset (train and test), separated pixels from labels then normalized in a $[0,1]$ scale"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/mnist-in-csv/mnist_train.csv')\ntest = pd.read_csv('../input/mnist-in-csv/mnist_test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_class = data.iloc[:, 0].copy()\nimages = data.iloc[:, 1:].copy()\ndel data\ngc.collect()\ntest_image_class = test.iloc[:, 0].copy()\ntest_images = test.iloc[:, 1:].copy()\ndel test\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images = images.astype('float32')\nimages = images.values / images.max().max()\ntest_images = test_images.astype('float32')\ntest_images = test_images.values / test_images.max().max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in np.random.randint(0,  len(test_images)-1, 5):\n    plt.imshow(test_images[i].reshape((28,28)), cmap='gray_r')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# VLAE Definition"},{"metadata":{},"cell_type":"markdown","source":"## Normal Stocastic layer\nThis custom layer implements the variational layer with Normal distribution following the [original paper of VAE](https://arxiv.org/abs/1312.6114) <br>\nDown below the graph representation of this layer\n![](https://i.ibb.co/5MVC3Yg/normal-variational.png) \nThe class constructor allows to:\n- specify the size of the multivariate normal\n- set prior mean and variance\n- add to loss kl divergence and its coefficient\n- add to loss MMD (Maximum Mean Discrepancy), its coefficient and the kernel (by default rbf). The class implements itself yet both linear and rbf kernel ([implementation taken from InfoVAE authors](https://ermongroup.github.io/blog/a-tutorial-on-mmd-variational-autoencoders))\n- show as metric mean posterior $\\mu$ and $\\sigma^2$ to check if the regularization part works well"},{"metadata":{"trusted":true},"cell_type":"code","source":"class NormalVariational(tf.keras.layers.Layer):\n    \n    def __init__(self, size, mu_prior=0., sigma_prior=1., add_kl=True, coef_kl = 1.0, add_mmd=False, lambda_mmd=1.0, kernel_f=None, name=None, show_posterior=True):\n        super().__init__(name=name)\n        self.mu_layer = tf.keras.layers.Dense(size)\n        self.sigma_layer = tf.keras.layers.Dense(size)\n        self.add_kl = add_kl\n        self.mu_prior = tf.constant(mu_prior, dtype=tf.float32, shape=(size,))\n        self.sigma_prior = tf.constant(sigma_prior, dtype=tf.float32, shape=(size,))\n        self.show_posterior = show_posterior\n        self.coef_kl = tf.Variable(coef_kl, trainable=False, name='coef_kl')\n        self.add_mmd = add_mmd\n        if kernel_f is None:\n            self.kernel_f = self._rbf\n        else:\n            self.kernel_f = kernel_f\n        self.lambda_mmd = lambda_mmd\n            \n    def _rbf(self, x, y):\n        x_size = tf.shape(x)[0]\n        y_size = tf.shape(y)[0]\n        dim = tf.shape(x)[1]\n        tiled_x = tf.tile(tf.reshape(x, tf.stack([x_size, 1, dim])), tf.stack([1, y_size, 1]))\n        tiled_y = tf.tile(tf.reshape(y, tf.stack([1, y_size, dim])), tf.stack([x_size, 1, 1]))\n        return tf.exp(-tf.reduce_mean(tf.square(tiled_x - tiled_y), axis=2) / tf.cast(dim, tf.float32))\n    \n    def _linear(self, x,y):\n        return tf.reduce_sum(tf.multiply(x,y))\n        \n    def add_kl_divergence(self, mu1, sigma1, mu2, sigma2):\n            logsigma1, logsigma2 = tf.math.log(sigma1), tf.math.log(sigma2)\n            mu_diff = mu1 - mu2\n            kl = self.coef_kl * \\\n                tf.reduce_sum(logsigma1 - logsigma2 - 1. + (sigma2 + tf.square(mu_diff)) / sigma1, axis=1)\n            kl = tf.reduce_mean(kl)\n            self.add_loss(kl)\n            self.add_metric(kl, 'mean', 'kl_divergence')\n\n    def call(self, inputs):\n        mu = self.mu_layer(inputs)\n        log_sigma =  self.sigma_layer(inputs)\n        sigma_square = tf.exp(log_sigma)\n        if self.add_kl:\n            self.add_kl_divergence(mu, sigma_square, self.mu_prior, self.sigma_prior)\n        if self.show_posterior:\n            self.add_metric(mu, 'mean', 'mu_posteror')\n            self.add_metric(sigma_square, 'mean', 'sigma^2_posterior')\n        z = mu + sigma_square * tf.random.normal(tf.shape(sigma_square))\n        if self.add_mmd:\n            z_prior = tfp.distributions.MultivariateNormalDiag(self.mu_prior, self.sigma_prior).sample(tf.shape(z)[0])\n            print(z_prior)\n            print(z)\n            k_prior = self.kernel_f(z_prior, z_prior)\n            k_post = self.kernel_f(z, z)\n            k_prior_post = self.kernel_f(z_prior, z)\n            mmd = tf.reduce_mean(k_prior) + tf.reduce_mean(k_post) - 2 * tf.reduce_mean(k_prior_post)\n            mmd = tf.multiply(self.lambda_mmd,  mmd, name='mmd')\n            self.add_loss(mmd)\n            self.add_metric(mmd, 'mean', 'mmd')\n        return z\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"tf.keras.backend.clear_session()\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Network definition\n1. Layers between the input, $h_1, h_2, h_3$ are sequences of a convolutional layer, batch normalization and relu. \n2. Sometimes there is a SpatialDroput layer to make the model more robust\n3. The encoder part output $h_1, h_2, h_3$ that are given in input respectively to $z_1, z_2, z_3$, three normal stochastic layers\n4. Then $\\widetilde{z}_3$ is obtained from $z_3$ with three Dense/BN/Relu with size 1024\n5. $\\widetilde{z}_2$ receive in input the concatenation of $[\\widetilde{z}_3, g(z_2)]$ where $g(\\cdot)$ is a neural network; <br>\nin my case is a single Dense layer with relu activation\n5. $\\widetilde{z}_1$ receive in input the concatenation of $[\\widetilde{z}_2, g(z_1)]$ where $g(\\cdot)$ is a neural network; <br>\nin my case is a single Dense layer with relu activation\n6. From $\\widetilde{z}_1$ starts the effective decoder part, that increase the size until the original one. Differently from the original paper, i've used UpSampling2D/Conv2D instead of Transpose convolution because produce less artifacts  <br><br>\nNote: Since the learnable params of batch norm gives every training NaN values into it i've virtually removed setting trainable=False into every BatchNorm layer; honestly i don't understood exactly the NaN reason, maybe the stochasticity of this neural network "},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_encoder(latent_size):\n    droput_rate = 0.05\n    inputs = Input((28,28,1))\n    with tf.name_scope('h_1'):\n        h_1_layers = Sequential([ \n            Input((28, 28, 1)),\n            Conv2D(8, 3),\n            BatchNormalization(trainable=False),\n            ReLU(),\n            Conv2D(16, 3),\n            BatchNormalization(trainable=False),\n            SpatialDropout2D(droput_rate),\n            ReLU()], name='h_1')\n        h_1 = h_1_layers(inputs)\n        h_1_flatten = Flatten()(h_1)\n    with tf.name_scope('h_2'):\n        h_2_layers = Sequential([ \n            Conv2D(16, 3),\n            BatchNormalization(trainable=False),\n            ReLU(),\n            Conv2D(16, 3),\n            BatchNormalization(trainable=False),\n            SpatialDropout2D(droput_rate),\n            ReLU()], name='h_2')\n        h_2 = h_2_layers(h_1)\n        h_2_flatten = Flatten()(h_2)\n    with tf.name_scope('h_3'):\n        h_3_layers = Sequential([ \n            Conv2D(16, 3),\n            BatchNormalization(trainable=False),\n            ReLU(),\n            Conv2D(16, 3),\n            BatchNormalization(trainable=False),\n            SpatialDropout2D(droput_rate),\n            ReLU()], name='h_3')\n        h_3 = h_3_layers(h_2)\n        h_3_flatten = Flatten()(h_3)\n    return Model(inputs, [h_1_flatten, h_2_flatten, h_3_flatten], name='encoder')\n        \ndef make_decoder(latent_dim1, latent_dim2, latent_dim3):\n    z_1_input, z_2_input, z_3_input = Input((latent_dim1,), name='z_1'), Input((latent_dim2,), name='z_2'), Input((latent_dim3,), name='z_3')\n    \n    with tf.name_scope('z_tilde_3'):\n        z_3 = Dense(1024, activation='relu')(z_3_input)\n        z_tilde_3_layers = Sequential([\n            Dense(1024),\n            BatchNormalization(trainable=False),\n            ReLU()] * 3, name='z_tilde_3')\n        z_tilde_3 = z_tilde_3_layers(z_3)\n        \n    with tf.name_scope('z_tilde_2'):\n        z_2 = Dense(128, activation='relu')(z_2_input)\n        z_tilde_2_layers = Sequential([\n            Dense(128),\n            BatchNormalization(trainable=False),\n             ReLU()] * 3, name='z_tilde_2')\n        input_z_tilde_2 = Concatenate()([z_tilde_3, z_2])\n        z_tilde_2 =  z_tilde_2_layers(input_z_tilde_2)\n    \n    with tf.name_scope('z_tilde_1'):\n        z_1 = Dense(128, activation='relu')(z_1_input)\n        z_tilde_1_layers = Sequential([\n            Dense(128),\n            BatchNormalization(trainable=False),\n             ReLU()] * 3, name='z_tilde_1')\n        input_z_tilde_1 = Concatenate()([z_tilde_2, z_1])\n        z_tilde_1 =  z_tilde_1_layers(input_z_tilde_1)\n        \n    with tf.name_scope('decoder'):\n        decoder = Reshape((2,2,32))(z_tilde_1)\n        decoder = UpSampling2D(2)(decoder) #4x4\n        decoder = Conv2D(32, 3)(decoder) #2x2\n        decoder = BatchNormalization(trainable=False)(decoder)\n        decoder = Activation(tf.nn.crelu)(decoder)\n        decoder = UpSampling2D(4)(decoder) #8x8\n        decoder = Conv2D(16, 3)(decoder) #6x6\n        decoder = BatchNormalization(trainable=False)(decoder)\n        decoder = Activation(tf.nn.crelu)(decoder)\n        decoder = UpSampling2D(2)(decoder) #12x12\n        decoder = Conv2D(8, 3)(decoder) #10x10\n        decoder = BatchNormalization(trainable=False)(decoder)\n        decoder = Activation(tf.nn.crelu)(decoder)\n        decoder = UpSampling2D(2)(decoder) #20x20\n        decoder = Conv2D(4, 5)(decoder) #16x16\n        decoder = BatchNormalization(trainable=False)(decoder)\n        decoder = LeakyReLU()(decoder)\n        decoder = UpSampling2D(2)(decoder) #32x32\n        decoder = Conv2D(1, 5)(decoder) #28x28\n        decoder = Activation('sigmoid')(decoder)\n    return Model([z_1_input, z_2_input, z_3_input], decoder, name='decoder')\n\ndef make_vlae(latent_size):\n    with tf.name_scope('encoder'):\n        encoder = make_encoder(latent_size)\n    with tf.name_scope('decoder'):\n        decoder = make_decoder(latent_size, latent_size, latent_size)\n    inputs = Input((28,28,1))\n    h_1, h_2, h_3 = encoder(inputs)\n    z_1 = NormalVariational(latent_size, add_kl=False, coef_kl=0.0, add_mmd=True, lambda_mmd=1., name='z_1_latent')(h_1)\n    z_2 = NormalVariational(latent_size, add_kl=False, coef_kl=0.0, add_mmd=True, lambda_mmd=1., name='z_2_latent')(h_2)\n    z_3 = NormalVariational(latent_size, add_kl=False, coef_kl=0.0, add_mmd=True, lambda_mmd=10., name='z_3_latent')(h_3)\n    \n    decoded = decoder([z_1, z_2, z_3])\n    vlae = Model(inputs, decoded, name='vlae')\n    return vlae","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"latent_size = 2\nvlae = make_vlae(latent_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"vlae.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def flatten_binary_crossentropy(x,xhat):\n    return 10 * tf.losses.binary_crossentropy(Flatten()(x), Flatten()(xhat))\n\nvlae.compile(tf.keras.optimizers.Adam(), flatten_binary_crossentropy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### KL Warm Up\n\nKeras Callback that implements KL Warm Up for stocastic layers. <br>\nUnfortunately the current implementation of this callback is code dependent because use the pre-defined names of stochastic layers to find they\n<br>\nBasically the KL Warm Up constist in set the coefficient before KL divergence to 0 on the first epochs in order to allow the model to properly learn the encoder/decoder part. Then after a specified epoch the coefficient starts to increase until a maximum<br>\nAll this parameters can be setted in the constructor of this class"},{"metadata":{"trusted":true},"cell_type":"code","source":"class KLWarmUp(tf.keras.callbacks.Callback):\n    \n    def __init__(self, vlae, start_epoch = 1, max_value = 1.0, delta = 0.05):\n        self.start_epoch = start_epoch\n        self.max_value = 1.0\n        self.delta = delta \n        self.epoch = 0\n        self.vlae = vlae\n        \n    def on_epoch_end(self, *args, **kwargs):\n        self.epoch += 1\n        if self.start_epoch <= self.epoch:\n            coefs = [self.vlae.get_layer(f'z_{i+1}_latent').coef_kl for i in range(3)]\n            for coef in coefs:\n                if coef <= self.max_value:\n                    coef.assign_add(self.delta)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training\n* If you create a kernel from the output of this one you can use tensorboard to visualize the learning of the model\n* The learning rate is log uniform between 0.0012 and 0.00001; before i've tried higher lr but the convergence was worse\n* EarlyStopping if the validation loss doesn't improve for 15 epochs of 0.001\n* 200 epochs, batch_size=256"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.callbacks import TensorBoard, LearningRateScheduler, EarlyStopping\ntb = TensorBoard(write_grads=True, write_images=False, write_graph=True, histogram_freq=2)\nes = EarlyStopping(min_delta=0.001, patience=15)\n# klwarmup = KLWarmUp(vlae, start_epoch=30, max_value=0.33)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 200\nlr_epochs = 10 ** np.linspace(-2.9, -4, epochs)\nlrsched = LearningRateScheduler(lambda i: lr_epochs[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images = images.reshape((-1, 28, 28, 1))\ntest_images = test_images.reshape((-1, 28, 28, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vlae.fit(images, images, batch_size=256, epochs=epochs, callbacks=[lrsched, tb, es], validation_data=(test_images, test_images))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"tf.saved_model.save(vlae, 'mikedev_vlae')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Generation\nIn order to generate is sufficient sample from the prior (in my case a N(0,1)) three times because there are three latent variable in this model <br>\nThen feed into the VLAE-decoder this three random sampled values "},{"metadata":{"trusted":true},"cell_type":"code","source":"sample = [np.random.multivariate_normal([0] * latent_size, np.diag([1] * latent_size), 20)] * 3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generated = vlae.get_layer('decoder').predict(sample)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generated = generated.reshape((20, 28, 28))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(20):\n    img = generated[i, :, :]\n    plt.imshow(img, cmap='gray_r')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Future improvements\n* Use the label as additional information to improve the recostruction"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}