{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h4> The goal of this kernal is basicly to scrutinize articles to asses similaries between sentences containing vaccines and/therapeutics by following steps bellow:</h4>\n\n> Import required libraries\n\n> Import universal sentence encoder\n\n> Import the data\n\n> Data cleansing and preprocessing\n\n> Computing sentence similarity-matrix\n\n**Import required libraries and universal sentence encoder**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport json\nimport os\nfrom tqdm import tqdm\ndata_dir = '/kaggle/input/CORD-19-research-challenge'\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nimport nltk\nimport tensorflow.compat.v1 as tf\ntf.disable_v2_behavior()\n\nimport tensorflow_hub as hub\nimport matplotlib.pyplot as plt\nmodule_url = \"https://tfhub.dev/google/universal-sentence-encoder/1?tf-hub-format=compressed\"\nembed = hub.Module(module_url)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Import the data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_json_data(folder):\n    text  =  \"\"\n    #title = \"\"\n    data = []\n    for txt in os.listdir(folder):\n        if not txt.startswith('.') and txt in ['biorxiv_medrxiv','comm_use_subset','custom_license','noncomm_use_subset']:\n            for filename in tqdm(os.listdir(f\"{folder}/{txt}/{txt}\")):\n                if not filename.startswith('.'):\n                    json_data =  json.load(open(f\"{folder}/{txt}/{txt}/{filename}\",'rb'))\n                    for t in json_data['body_text']:            \n                        text += t['text']+'\\n\\n'\n\n    return text\ntxt_data = get_json_data(data_dir)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data cleansing and preprocessing**\n\nFor better understanding the data is crisual to make the data clean by removing stopwords and choosing sentences containing vaccines and/ therapeutics"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('sentences containing vaccines or therapeutics ...')\ndoc = \"\"\nfor sentnece in txt_data.split('\\n'):\n    if('vaccines' in sentnece) or ('therapeutics' in sentnece):\n        #word_tokens = word_tokenize(sentnece)\n        doc +=sentnece \n\nprint('Removing stopwords ...')\n\nstop_words = set(stopwords.words('english'))\ntext = \"\"\nfor i in doc.split(' '):\n    if i not in stop_words:\n        text += ' ' + i.lower()\nCorpus = []\nprint('Focusing on short sentences for visualization  ...')\nfor i in text.split(','):\n    if ('vaccines' in i) or ('therapeutics' in i): \n        if len(i.split(' ')) < 15:\n            Corpus.append(i)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Computing sentence similarity-matrix**\n\nTo simplify and better visualize the result the first 10 sentences are choosen feel free to increase sentences."},{"metadata":{"trusted":true},"cell_type":"code","source":"messages2 = Corpus[:10]\nsimilarity_input_placeholder = tf.placeholder(tf.string, shape=(None))\nsimilarity_message_encodings = embed(similarity_input_placeholder)\nwith tf.compat.v1.Session()  as session:\n    session.run(tf.global_variables_initializer())\n    session.run(tf.tables_initializer())\n    message_embeddings_ = session.run(similarity_message_encodings, feed_dict={similarity_input_placeholder: messages2})\n\n    corr = np.inner(message_embeddings_, message_embeddings_)\n    print(corr)\n    def heatmap(x_labels, y_labels, values):\n        fig, ax = plt.subplots()\n        im = ax.imshow(values)\n        # We want to show all ticks...\n        ax.set_xticks(np.arange(len(x_labels)))\n        ax.set_yticks(np.arange(len(y_labels)))\n        # ... and label them with the respective list entries\n        ax.set_xticklabels(x_labels)\n        ax.set_yticklabels(y_labels)\n        # Rotate the tick labels and set their alignment.\n        plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", fontsize=10,\n             rotation_mode=\"anchor\")\n        # Loop over data dimensions and create text annotations.\n        for i in range(len(y_labels)):\n            for j in range(len(x_labels)):\n                text = ax.text(j, i, \"%.2f\"%values[i, j],\n                               ha=\"center\", va=\"center\", color=\"w\", fontsize=6)\n\n        fig.tight_layout()\n        plt.show()\n    heatmap(messages2, messages2, corr)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}