{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfor dirname, _, filenames in os.walk('/kaggle/input/glass/glass.csv'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"os.path.isfile('/kaggle/input/glass/glass.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Input=pd.read_csv('/kaggle/input/glass/glass.csv')\nInput.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Input.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Input.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_values = Input.isnull()\nmissing_values.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(data = missing_values, yticklabels=False, cbar=False, cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Input.Type.value_counts().sort_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Input.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.pairplot(Input)\n#Comparision of different graphs\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask = np.zeros_like(Input.corr(), dtype=np.bool) \nmask[np.triu_indices_from(mask)] = True \nf, ax = plt.subplots(figsize=(16, 12))\nplt.title('Pearson Correlation Matrix',fontsize=25)\nsns.heatmap(Input.corr(),linewidths=0.25,vmax=0.7,square=True,cmap=\"BuGn\", \n            #\"BuGn_r\" to reverse \n            linecolor='w',annot=True,annot_kws={\"size\":8},mask=mask,cbar_kws={\"shrink\": .9});","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Input['Output'] = Input.Type.map({1:0, 2:0, 3:0, 5:1, 6:1, 7:1})\n#Output is for good and bad classification\nInput.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(Input.Al, Input.Output)\nplt.xlabel('Al')\nplt.ylabel('Output')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.regplot(x='Al', y='Output', data=Input, logistic=True, color='b')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = Input[['Al']]\n#Dependent variable\nY = Input['Type']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Split training and testing data\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X.shape)\n#print(X_test.head())\n#print(Y_train.head())\nprint(Y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Run the model\n# Import model for fitting\nfrom sklearn.linear_model import LogisticRegression\n# Create instance (i.e. object) of LogisticRegression\n#model = LogisticRegression()\n\n#You can try follwoing variation on above model, above is just default one\nmodel = LogisticRegression()\n# Fit the model using the training data\n# X_train -> parameter supplies the data features\n# Y_train -> parameter supplies the target labels\noutput_model=model.fit(X,Y)\n#output =X_test\n#output['vehicleTypeId'] = Y_test\noutput_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import linear_model\nimport pickle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LogisticRegression()\noutput_model=model.fit(X_train, Y_train)\noutput_model\npkl_filename = \"pickle_model.pkl\"\nwith open(pkl_filename, 'wb') as file:\n    pickle.dump(model, file)\n\n# Load from file\nwith open(pkl_filename, 'rb') as file:\n    pickle_model = pickle.load(file)\n\n# Calculate the accuracy score and predict target values\nscore = pickle_model.score(X_test, Y_test)\nprint(\"Test score: {0:.2f} %\".format(100 * score))\nYpredict = pickle_model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix \nfrom sklearn.metrics import accuracy_score \nfrom sklearn.metrics import classification_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_pred = model.predict(X_test)\n\n#Confusion matrix\nresults = confusion_matrix(Y_test, Y_pred)\nprint(results)\n\n#Accuracy score\naccuracy = accuracy_score(Y_test, Y_pred)\nprint(\"Accuracy rate : {0:.2f} %\".format(100 * accuracy))\n\n#Classification report\nreport = classification_report(Y_test, Y_pred)\nprint(report)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame({'Actual': Y_test, 'Predicted': Ypredict.flatten()})\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nfrom sklearn import metrics\nprint('Mean Absolute Error:', metrics.mean_absolute_error(Y_test, Ypredict))  \nprint('Mean Squared Error:', metrics.mean_squared_error(Y_test, Ypredict))  \nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(Y_test, Ypredict)))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = plt.axes()\nax.scatter(X, Y)\nplt.title(\"Input Data and regression line \") \nax.plot(X_test, Ypredict, color ='Red')\nax.set_xlabel('X')\nax.set_ylabel('Y')\nax.axis('tight')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\n\npredictions = model.predict(X_test)\nplt.style.use('fivethirtyeight') \n  \n## plotting residual errors in training data \nplt.scatter(model.predict(X_train), model.predict(X_train) - Y_train, \n            color = \"green\", s = 1, label = 'Train data' ,linewidth = 5) \n  \n## plotting residual errors in test data \nplt.scatter(model.predict(X_test), model.predict(X_test) - Y_test, \n            color = \"blue\", s = 1, label = 'Test data' ,linewidth = 4) \n  \n## plotting line for zero residual error \nplt.hlines(y = 0, xmin = 0, xmax = 4, linewidth = 2) \n  \n## plotting legend \nplt.legend(loc = 'upper right') \n  \n## plot title \nplt.title(\"Residual errors\") \n  \n## function to show plot \nplt.show() \n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}