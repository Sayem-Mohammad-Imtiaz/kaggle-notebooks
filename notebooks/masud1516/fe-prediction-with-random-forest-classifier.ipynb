{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# # For Data reading \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# For data visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n# For Feature Scaling & Feature Importance\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.ensemble import ExtraTreesRegressor\n\n# For model building & scoreing\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\n\n\n# others\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Read Dataset"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/av-healthcare-analytics-ii/healthcare/train_data.csv')\ntest_df = pd.read_csv('../input/av-healthcare-analytics-ii/healthcare/test_data.csv')\ntrain_dict = pd.read_csv('../input/av-healthcare-analytics-ii/healthcare/train_data_dictionary.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Let's Encoded dependent Feature (\"Stay\" column)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's find unique values of dependent feature\ntrain_df[\"Stay\"].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# Let's create a dictionary for dependent feature\nencode = {\n    '0-10' : 1, '11-20' : 2, '21-30' : 3, '31-40' : 4, '41-50' : 5, '51-60' : 6, '61-70' : 7, '71-80' : 8,\n    '81-90' : 9, '91-100' : 10, 'More than 100 Days' : 11\n}\ntrain_df['Stay'] = train_df['Stay'].map(encode)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Handle Missing value of features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check missing values\nprint('Train Dataset:::::::::::::::')\nprint(train_df.isnull().sum())\nprint(\"=========================================\")\nprint('Test Dataset::::::::::::::::')\nprint(test_df.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find features of missing values \ndef NaNFeature(df):\n    nan_feature = [n for n in df.columns if df[n].isnull().sum()>=1]\n    return nan_feature","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's fill missing values of train detaset \nnan_features_train = NaNFeature(train_df)\nfor fillnan in nan_features_train:\n    train_df[fillnan].fillna(train_df[fillnan].mode()[0], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's fill missing values of test detaset \nnan_features_test = NaNFeature(test_df)\nfor fillnan in nan_features_test:\n    test_df[fillnan].fillna(test_df[fillnan].mode()[0], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets check missing values percentage\nprint('Train Dataset:::::::::::::::')\nprint(np.round(train_df.isnull().sum() * 100 / len(train_df), 4))\nprint(\"=========================================\")\nprint('Test Dataset:::::::::::::::')\nprint(np.round(test_df.isnull().sum() * 100 / len(test_df), 4))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Handle Categorical Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's Find out categorical features through a function\ndef CatFeatures(df):\n    features = [feature for feature in df.columns if df[feature].dtypes == \"O\"]\n    return features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# categorical features of train dataset\ncat_features_train = CatFeatures(train_df)\ncat_features_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check unique value of categorical features of train data\nfor i in cat_features_train:\n    print(train_df[i].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# categorical features of test dataset\ncat_features_test = CatFeatures(test_df)\ncat_features_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in cat_features_test:\n    print(test_df[i].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Let's create a function to handle categorical features \ndef CatToNumaric():\n    # Handle categorical feature of train dataset\n    for n in cat_features_train:\n        num_data = dict(zip(train_df[n].unique(), range(len(train_df[n].unique()))))\n        train_df[n] = train_df[n].map(num_data) # or train_df[n].replace(num_data, inplace=True)\n        \n    # Handle categorical features of test dataset\n    for n in cat_features_test:\n        num_data = dict(zip(test_df[n].unique(), range(len(test_df[n].unique()))))\n        test_df[n] = test_df[n].map(num_data) # or test_df[n].replace(num_data, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check features data types\nCatToNumaric()\nprint('Train Dataset:::::::::::::::')\nprint(train_df.dtypes)\nprint(\"=====================================\")\nprint('Test Dataset:::::::::::::::')\nprint(test_df.dtypes)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Clean unused features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's see the train dictionary data to drop un necessary features\ntrain_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets drop features those are necessary so much\ndef DropFeatures(df):\n    drop_features = {'case_id', 'Hospital_code', 'Hospital_type_code', 'patientid'}\n    df.drop(drop_features, axis=1, inplace=True)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show train dataset\ntrain_data = DropFeatures(train_df)\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show test dataset\ntest_data = DropFeatures(test_df)\ntest_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Scaling (MinMax Scaler)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# create X_train & X_test for feature scaling \nX_train = train_data.iloc[: , :-1]\nX_test = test_data\n\n# y_train (depended feature)\ny_train = train_data.iloc[: , -1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create function for scaling X_ data \ndef FeatureScaler(df):\n    min_max = MinMaxScaler()\n    df = pd.DataFrame(min_max.fit_transform(df), columns=df.columns)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's show final train dataset\nX_train_final = FeatureScaler(X_train)\nX_train_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's show final test dataset\nX_test_final = FeatureScaler(X_test)\nX_test_final.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Find Feature Importance\n    Find best 10 features from datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's call Extra Trees Regressor function\nfeature_imp = ExtraTreesRegressor()\nfeature_imp.fit(X_train_final, y_train)\n# Let's show the list of feature importance\nfeature_imp.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's show a plot of ten (10) features\nfeature_importance = pd.Series(feature_imp.feature_importances_, index=X_train_final.columns)\nfeature_importance.nlargest(10).plot(kind='barh')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create Model with Random Forest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create model\nstay_predict = RandomForestClassifier()\nstay_predict.fit(X_train_final, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Model Testing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's test the model\ny_test = stay_predict.predict(X_test_final)\ny_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For submission file we need 'case_id' so read sample_submission file\nsample_sub_df = test_df = pd.read_csv('../input/av-healthcare-analytics-ii/healthcare/sample_sub.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Decode Prediction data"},{"metadata":{"trusted":true},"cell_type":"code","source":"predection_df = pd.DataFrame()\npredection_df['case_id'] = sample_sub_df['case_id'] \npredection_df['Stay'] = y_test\n\ndecode_prediction = { 1 : '0-10', 2 : '11-20', 3 : '21-30', 4 : '31-40', 5 : '41-50', 6 : '51-60', 7 : '61-70'\n            ,8 : '71-80', 9 : '81-90', 10 : '91-100', 11 : 'More than 100 Days'}\n\npredection_df['Stay'] = predection_df['Stay'].map(decode_prediction)\npredection_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Scoring & Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model score\nstay_predict.score(X_train_final, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cross Validation \nscore = cross_val_score(stay_predict, X_train_final, y_train.ravel(), cv=10)\nscore.mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Create a submission File"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = predection_df.copy()\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Thanks\nWish to get comments from all."},{"metadata":{},"cell_type":"markdown","source":"Source Code on github-  https://github.com/sheikhmasudrana/ML_Practice/tree/master/Healthcare%20Analytics(stay%20days%20prediction)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}