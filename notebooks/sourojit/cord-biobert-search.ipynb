{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction"},{"metadata":{},"cell_type":"markdown","source":"**This notebook has links to 10 other notebooks where, each notebook finds the top reserch papers for each task in the CORD challenge. For each subtask in a task, the top K research papers corresponding to that subtask is evaluated. To find out the top research papers related to a subtask, the subtasks have been broken down into multiple shorter queries. The evaluation is done by calculating the cosine similarity between the vector embeddings of the research papers(title + abstract) and the vector embeddings of the queries. The embeddings have been produced using the biobert pretrained weights.**\n\n**The search for research papers for a query is done using two approaches :**\n* **In the first approach, the search for the research papers are done a set of clusters and not the whole corpus. These clusters have been developed using the Ego-splitting Framework**  [https://www.kaggle.com/debasmitadas/unsupervised-clustering-covid-research-papers/](http://www.kaggle.com/debasmitadas/unsupervised-clustering-covid-research-papers/)\n\n* **In the second approach, the search for the research papers are done on the whole corpus.**\n\n**Using each approach the top K research papers are returned for each query.**"},{"metadata":{},"cell_type":"markdown","source":"# Data Sources"},{"metadata":{},"cell_type":"markdown","source":"* **CORD Research Papers**   [https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge](http://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge)\n\n* **BioBert Pretrained Weights**  [https://www.kaggle.com/jdparsons/biobert-pretrained](http://www.kaggle.com/jdparsons/biobert-pretrained)\n\n* **For cluster-research paper mapping, cluster-subtask mapping, query-subtask mapping and query-question mapping**  [https://www.kaggle.com/shashankdubeypeace/task1-results](http://www.kaggle.com/shashankdubeypeace/task1-results)\n\n* **BioBert embeddings research paper(title+abstract)**  [https://www.kaggle.com/sourojit/biobertembeddings-datafile-biobertweights](http://www.kaggle.com/sourojit/biobertembeddings-datafile-biobertweights)"},{"metadata":{},"cell_type":"markdown","source":"# Notebook Links For Searching of Research Papers"},{"metadata":{},"cell_type":"markdown","source":"* **What is known about transmission, incubation, and environmental stability?**    [https://www.kaggle.com/sourojit/search-code-task1](http://www.kaggle.com/sourojit/search-code-task1)\n\n* **What do we know about COVID-19 risk factors?**   [https://www.kaggle.com/sourojit/search-code-task2](http://www.kaggle.com/sourojit/search-code-task2)\n\n* **What do we know about virus genetics, origin, and evolution?**   [https://www.kaggle.com/sourojit/search-code](http://www.kaggle.com/sourojit/search-code)\n\n* **What do we know about vaccines and therapeutics?**    [https://www.kaggle.com/sourojit/search-code-task4](http://www.kaggle.com/sourojit/search-code-task4)\n\n* **What has been published about medical care?**      [https://www.kaggle.com/sourojit/search-code-task5](http://www.kaggle.com/sourojit/search-code-task5)\n\n* **What do we know about non-pharmaceutical interventions?**   [https://www.kaggle.com/sourojit/search-code-task6](http://www.kaggle.com/sourojit/search-code-task6)\n\n* **Sample task with sample submission**   [https://www.kaggle.com/sourojit/search-code-task8](http://www.kaggle.com/sourojit/search-code-task8)\n\n* **What do we know about diagnostics and surveillance?**  [https://www.kaggle.com/sourojit/search-code-task7](http://www.kaggle.com/sourojit/search-code-task7)\n\n* **What has been published about ethical and social science considerations?**  [https://www.kaggle.com/sourojit/search-code-task9](http://www.kaggle.com/sourojit/search-code-task9)\n\n* **What has been published about information sharing and inter-sectoral collaboration?**  [https://www.kaggle.com/sourojit/search-code-task10](http:///www.kaggle.com/sourojit/search-code-task10)"},{"metadata":{},"cell_type":"markdown","source":"# DEMO"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from scipy.spatial.distance import cdist\nimport subprocess\n\nimport matplotlib.pyplot as plt\nimport pickle\n\n\n!pip install tensorflow==1.15\n# Install bert-as-service\n!pip install bert-serving-server==1.10.0\n!pip install bert-serving-client==1.10.0\n!cp /kaggle/input/biobert-pretrained /kaggle/working -r\n%mv /kaggle/working/biobert-pretrained/biobert_v1.1_pubmed/model.ckpt-1000000.index /kaggle/working/biobert-pretrained/biobert_v1.1_pubmed/bert_model.ckpt.index\n%mv /kaggle/working/biobert-pretrained/biobert_v1.1_pubmed/model.ckpt-1000000.data-00000-of-00001 /kaggle/working/biobert-pretrained/biobert_v1.1_pubmed/bert_model.ckpt.data-00000-of-00001\n%mv /kaggle/working/biobert-pretrained/biobert_v1.1_pubmed/model.ckpt-1000000.meta /kaggle/working/biobert-pretrained/biobert_v1.1_pubmed/bert_model.ckpt.meta","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\n# Start the BERT server\nbert_command = 'bert-serving-start -model_dir /kaggle/working/biobert-pretrained/biobert_v1.1_pubmed -max_seq_len=512 -max_batch_size=32 -num_worker=2'\nprocess = subprocess.Popen(bert_command.split(), stdout=subprocess.PIPE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\n\n# biobert embeddings of the research papers based on title+abstract\n\nwith open('/kaggle/input/biobertembeddings-datafile-biobertweights/embeddings_final.pickle', 'rb') as handle:\n    temp_embeddings = pickle.load(handle)\n\n# metadata about these research papers    \n\ntemp_title_abstract=pd.read_csv(\"/kaggle/input/biobertembeddings-datafile-biobertweights/title_abstract.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# metadata on the whole corpus of research papers from the CORD challenge\nmetadata=pd.read_csv(\"/kaggle/input/CORD-19-research-challenge/metadata.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_embeddings=temp_embeddings.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embeddings=[]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# selecting only those research papers which have a body text present and the length of title+abstract is greater than 40\n\n\ndef check_length(text,abstract):\n    if pd.isna(text)==True:\n        return len(abstract)\n    else:\n        val=text+\" \"+abstract\n        return len(val)\n\ntitle_abstract=pd.DataFrame(columns=['cord_uid','sha','title','abstract'])\nfor i,row in temp_title_abstract.iterrows():\n    cid=temp_title_abstract.loc[i,'cord_uid']\n    ind_list=metadata.index[metadata['cord_uid']==cid].tolist()\n    if len(ind_list)==0:\n        continue\n    ind=ind_list[0]\n    pdf=metadata.loc[ind,'has_pdf_parse']\n    pmc=metadata.loc[ind,'has_pmc_xml_parse']\n    if pdf==False and pmc==False:\n        continue\n    else:\n        title12=temp_title_abstract.loc[i,'title']\n        abstract12=temp_title_abstract.loc[i,'abstract']\n        sha=temp_title_abstract.loc[i,'sha']\n        length_text=check_length(title12,abstract12)\n        if length_text>=40:\n            title_abstract=title_abstract.append({'cord_uid':cid,'sha':sha,'title':title12,'abstract':abstract12},ignore_index=True)\n            embeddings.append(temp_embeddings[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embeddings=np.array(embeddings)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"title_abstract.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embeddings.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from bert_serving.client import BertClient\nbc = BertClient()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"query_subtask_mapping2=pd.DataFrame(columns=['Queries ', 'Subtask mapping ', 'Question form of queries '])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nThe next three cells contain a list of queries, a list of subtasks and a list of questions\nq1 is a list of queries generated from the subtasks\ns1 is a list of subtasks corresponding to the queries\nq2 is a list of questions corresponding to the queries\n\nq2 has been generated for a question-answer system\n\nmore information regarding these can be found in the task1-results/archive (2)/Covid19_queries_questions_subtasks.xlsx file\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q1=['data standards and nomenclature',\n'information sharing and inter-sectoral collaboration',\n'governmental public health',\n'communicating with high-risk populations',\n'clarify community measures',\n'equity considerations and problems of inequity',\n'data-gathering with standardized nomenclature',\n'planners, providers response', \n'barriers to information-sharing',\n'mitigating barriers to information-sharing',\n'coverage policies related to testing',\n'coverage policies related to treatment',\n'coverage policies related to care',\n'Mitigating threats to incarcerated',\n'assuring access to diagnosis treatment', \n'reach marginalized and disadvantaged populations',\n'gaps and problems of inequity in the Nation’s public health capability, capacity',\n'funding for all citizens', \n'Misunderstanding around containment and mitigation',\n'Communication for potential risk of disease',\n'Risk communication and guidelines',\n'targeting at risk populations’ families',\n'communicating with target elderly',\n'communicating with health workers',\n'communicating with target high-risk populations', \n'investments in baseline public health response infrastructure',\n'Integration of public health surveillance systems',\n'integration of federal and state',\n'recruit and support local expertise', \n'coordinate public, private, commercial and non-profit and academic'\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s1=['What has been published about data standards and nomenclature?',\n'What has been published about information sharing and inter-sectoral collaboration?', \n'What has been published about governmental public health?', \n'What has been published about communicating with high-risk populations?',\n'What has been published to clarify community measures?',\n'What has been published about equity considerations and problems of inequity?',\n'Methods for coordinating data-gathering with standardized nomenclature.',\n'Sharing response information among planners, providers, and others.',\n'Understanding and mitigating barriers to information-sharing.',\n'Understanding and mitigating barriers to information-sharing.',\n'Understanding coverage policies (barriers and opportunities) related to testing, treatment, and care',\n'Understanding coverage policies (barriers and opportunities) related to testing, treatment, and care',\n'Understanding coverage policies (barriers and opportunities) related to testing, treatment, and care',\n'Mitigating threats to incarcerated people from COVID-19, assuring access to information, prevention, diagnosis, and treatment.',\n'Mitigating threats to incarcerated people from COVID-19, assuring access to information, prevention, diagnosis, and treatment.',\n'Measures to reach marginalized and disadvantaged populations.',\n'Action plan to mitigate gaps and problems of inequity in the Nation’s public health capability, capacity, and funding to ensure all citizens in need are supported and can access information, surveillance, and treatment.',\n'Action plan to mitigate gaps and problems of inequity in the Nation’s public health capability, capacity, and funding to ensure all citizens in need are supported and can access information, surveillance, and treatment.',\n'Misunderstanding around containment and mitigation.',\n'Communication that indicates potential risk of disease to all population groups.',\n'Communication that indicates potential risk of disease to all population groups.',\n'Risk communication and guidelines that are easy to understand and follow (include targeting at risk populations’ families too).',\n'Modes of communicating with target high-risk populations (elderly, health care workers).',\n'Modes of communicating with target high-risk populations (elderly, health care workers).',\n'Modes of communicating with target high-risk populations (elderly, health care workers).',\n'Value of investments in baseline public health response infrastructure preparedness',\n'Integration of federal/state/local public health surveillance systems.',\n'Integration of federal/state/local public health surveillance systems.',\n'How to recruit, support, and coordinate local (non-Federal) expertise and capacity relevant to public health emergency response (public, private, commercial and non-profit, including academic).',\n'How to recruit, support, and coordinate local (non-Federal) expertise and capacity relevant to public health emergency response (public, private, commercial and non-profit, including academic).'\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q2=['data standards and nomenclature',\n'information sharing and inter-sectoral collaboration',\n'governmental public health',\n'communicating with high-risk populations',\n'clarify community measures',\n'equity considerations and problems of inequity',\n'data-gathering with standardized nomenclature',\n'planners, providers response',\n'barriers to information-sharing',\n'mitigating barriers to information-sharing',\n'coverage policies related to testing',\n'coverage policies related to treatment',\n'coverage plocies related to care',\n'Mitigating threats to incarcerated',\n'assuring access to diagnosis treatment',\n'reach marginalized and disadvantaged populations',\n'gaps and problems of inequity in the Nation’s public health capability, capacity',\n'funding for all citizens',\n'What are misunderstanding around containment and mitigation',\n'Communication for potential risk of disease',\n'Risk communication and guidelines',\n'targeting at risk populations’ families',\n'communicating with target elderly',\n'communicating with health workers',\n'communicating with target high-risk populations',\n'investments in baseline public health response infrastructure',\n'Integration of public health surveillance systems',\n'integration of federal and state',\n'recruit and support local expertise',\n'How to coordinate public, private, commercial and non-profit and academic?'\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"query_subtask_mapping2['Queries ']=q1\nquery_subtask_mapping2['Subtask mapping ']=s1\nquery_subtask_mapping2['Question form of queries ']=q2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"query_subtask_mapping2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# subtask to cluster mapping\n\nsubtask_cluster_mapping=pd.read_excel(\"/kaggle/input/task1-results/archive (2)/Mapping_To_Clusters_Updated_08042020.xlsx\",sheet_name=\"Query Matching\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# paper to cluster mapping\n\npaper_cluster_mapping=pd.read_excel(\"/kaggle/input/task1-results/archive (2)/Final_Clusters_Keywords_UID.xlsx\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import ast\nquery_subtask_mapping2['Clusters']=\"\"\nfor i,row in query_subtask_mapping2.iterrows():\n    subtask=query_subtask_mapping2.loc[i,'Subtask mapping ']\n    clust_ind=[]\n    sub_ind=subtask_cluster_mapping.index[subtask_cluster_mapping['subtasks']==subtask].tolist()\n    if len(sub_ind)>0:\n        ind=sub_ind[0]\n        clust_ind=ast.literal_eval(subtask_cluster_mapping.loc[ind,'Important_Clusters'])\n    query_subtask_mapping2.at[i,'Clusters']=clust_ind","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"query_subtask_mapping2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"queries=list(query_subtask_mapping2['Queries '])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# biobert embeddings of the queries\nquery_embeddings=bc.encode(queries)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"query_subtask_mapping2.columns=['Queries','Subtask mapping','Question form of queries','Clusters']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# return the top k research papers from both cluster and the whole corpus\n\nimport scipy.spatial\ndef get_top_results(query_embed,cluster_search_embedding,cluster_search_list_temp,k):\n    closest_n = min(len(cluster_search_embedding),k)\n    distances = scipy.spatial.distance.cdist([query_embed], cluster_search_embedding, \"cosine\")[0]\n    results = zip(range(len(distances)), distances)\n    results = sorted(results, key=lambda x: x[1])\n    ret_dict={}\n    for idx, distance in results[0:closest_n]:\n        cid=cluster_search_list_temp[idx]\n        val=1-distance\n        ret_dict[cid]=val\n    return ret_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_frame=pd.DataFrame(columns=['Queries','Subtask mapping','Question form of queries','Clusters','cord_uid','title','abstract','similarity','cluster','total'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i,row in query_subtask_mapping2.iterrows():\n    query=query_subtask_mapping2.loc[i,'Queries']\n    subtask_mapping=query_subtask_mapping2.loc[i,'Subtask mapping']\n    ques=query_subtask_mapping2.loc[i,'Question form of queries']\n    query_embed=list(query_embeddings[i])\n    clusters=query_subtask_mapping2.loc[i,'Clusters']\n    total_search_dict={}\n    cluster_search_list_temp=[]\n    cluster_search_dict={}\n    for j in clusters:\n        paper_list=paper_cluster_mapping.index[paper_cluster_mapping['Cluster_Names']==j].tolist()\n        if len(paper_list)>0:\n            for k in paper_list:\n                cid=\"\"\n                if pd.isna(paper_cluster_mapping.loc[k,'cord_uid'])==True:\n                    title=paper_cluster_mapping.loc[k,'Title']\n                    plist=title_abstract.index[title_abstract['title']==title].tolist()\n                    if len(plist)>0:\n                        p=plist[0]\n                        cid=title_abstract.loc[p,'cord_uid']\n                else:\n                    tid=paper_cluster_mapping.loc[k,'cord_uid']\n                    tlist=title_abstract.index[title_abstract['cord_uid']==tid].tolist()\n                    if len(tlist)>0:\n                        cid=tid\n                if cid!=\"\":\n                    cluster_search_list_temp.append(cid)\n    cluster_search_embedding=[]\n    for j in cluster_search_list_temp:\n        id1_list=title_abstract.index[title_abstract['cord_uid']==j].tolist()\n        if len(id1_list)>0:\n            id1=id1_list[0]\n            emb=list(embeddings[id1])\n            cluster_search_embedding.append(emb)\n    if len(cluster_search_embedding)>0:\n        returned_dict=get_top_results(query_embed,cluster_search_embedding,cluster_search_list_temp,30)\n        for o in returned_dict:\n            cluster_search_dict[o]=returned_dict[o]\n    total_search_embedding=embeddings.tolist()\n    total_search_list_temp=list(title_abstract['cord_uid'])\n    total_search_dict=get_top_results(query_embed,total_search_embedding,total_search_list_temp,30)\n    combined_list_cid=[]\n    for t in cluster_search_dict:\n        combined_list_cid.append(t)\n    for t in total_search_dict:\n        combined_list_cid.append(t)\n    combined_list_cid=list(set(combined_list_cid))\n    for t in combined_list_cid:\n        flag=0\n        flag1=0\n        similar=0\n        if t in cluster_search_dict:\n            flag=1\n            similar=cluster_search_dict[t]\n        if t in total_search_dict:\n            flag1=1\n            similar=total_search_dict[t]\n        id12=title_abstract.index[title_abstract['cord_uid']==t].tolist()[0]\n        title2=title_abstract.loc[id12,'title']\n        if pd.isna(title2)==True:\n            title2=\"\"\n        abstract2=title_abstract.loc[id12,'abstract']\n        new_frame=new_frame.append({'Queries':query,'Subtask mapping':subtask_mapping,'Question form of queries':ques,'Clusters':clusters,'cord_uid':t,'title':title2,'abstract':abstract2,'similarity':similar,'cluster':flag,'total':flag1},ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_frame.to_csv(\"task__results.csv\",index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}