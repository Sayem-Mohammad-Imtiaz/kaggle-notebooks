{"cells":[{"metadata":{"_uuid":"adbb914cc1466a3652d51972988e26cf2b309a90","_cell_guid":"9e989304-ca31-4ed6-af3b-75e59c6a0999"},"cell_type":"markdown","source":"# **Bitcoin Time Series Prediction with LSTM**"},{"metadata":{"_uuid":"998bc1be9e33074e35114ff479c91a8fdba35d0f","_cell_guid":"660f58b8-64df-4932-8866-2a7468cecbd1"},"cell_type":"markdown","source":"## *Import necessary libraries needed for the model training*"},{"metadata":{"_uuid":"124a1f6d7d906ede16ee8c759bd70d924d25beba","_cell_guid":"1a872b10-351e-453b-8e3e-2e59ce70b53c","trusted":true},"cell_type":"code","source":"from math import sqrt\nfrom numpy import concatenate\nfrom matplotlib import pyplot\nimport pandas as pd\nfrom datetime import datetime\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import mean_squared_error\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport plotly.offline as py\nimport plotly.graph_objs as go\nimport numpy as np\nimport seaborn as sns\npy.init_notebook_mode(connected=True)\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"910ebe956b1740ec5831482ab179538df6d32b49","_cell_guid":"7ef19ece-0947-4006-97f4-052aa6f62f52"},"cell_type":"markdown","source":"## *Read the Data Set*"},{"metadata":{"_uuid":"37738a19100d498fa63ad2401e66edc3d917b121","_cell_guid":"a18cd3ab-5312-4f8d-b6f9-3ba3c24a6f2a","trusted":true,"scrolled":false},"cell_type":"code","source":"data = pd.read_csv(filepath_or_buffer=\"../input/btcusdkraken/BTCUSDKRAKEN\", index_col=\"Date\")\n\n# Get the number of columns of the dataframe\nprint(\"Columns : \" + str(data.columns.values))\n# Get the shape of the dataframe\nprint(\"Shape : \" + str(data.shape))\n# Get the head(), here the first 5 elements of the dataframe\nprint(data.head(5))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d846d35a894a4b8f7f514708364a44e72aea382a","_cell_guid":"246ce6ce-c93b-405a-87d8-0b590cb95adb"},"cell_type":"markdown","source":"## *Fill value 0 data points on `Weighted Price` with NAN and then use ffill method to fill values*"},{"metadata":{"_uuid":"9f3be8345c5888078ee1bf14fe96f0e02dc0206f","_cell_guid":"3a513b31-fb03-430c-b477-04a2954e8fdf","trusted":true},"cell_type":"code","source":"data['Weighted Price'].replace(0, np.nan, inplace=True)\ndata['Weighted Price'].fillna(method='ffill', inplace=True)\n\n# Get the head(), here the first 5 elements of the dataframe\nprint(data.head(5))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d986032a8c0d87513bd0ec3d5cb26c91906695a5","_cell_guid":"40133528-c852-4ebe-b262-ddc553394ad3"},"cell_type":"markdown","source":"## *Use `Weighted Price` as a feature to train the LSTM model and Use MinMaxScaler to normalize `Weighted Price` to range from 0 to 1*"},{"metadata":{"_uuid":"f284c809e79eaaa8d231415f90316bb9fe6cb504","_cell_guid":"23dad7d9-c9dd-422d-b9be-3fdf17631277","trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nvalues = data['Weighted Price'].values.reshape(-1,1)\nprint(values[0])\nvalues = values.astype('float32')\nprint(values[0])\nscaler = MinMaxScaler(feature_range=(0, 1))\nscaled = scaler.fit_transform(values)\n\n# Get the type of the new item scaled\nprint(type(scaled))\n\n# Get the length of the new item scaled\nprint(\"Length of the new datframe : \" + str(len(scaled)))\n\n# Get the first 5 elements from the scaled dataframe\nprint(scaled[0:5,])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"28ff135df254c60c16f201664f70095366b7c876","_cell_guid":"8ec96ba5-4005-444a-ac65-a6211417d370"},"cell_type":"markdown","source":"## *Split 70% of data for training and 30% for testing*"},{"metadata":{"_uuid":"9ee003e139d523e695c07370ecc057e61be183dc","_cell_guid":"52fe887e-e707-48f5-afb3-27a0cedf38fa","trusted":true},"cell_type":"code","source":"train_size = int(len(scaled) * 0.7)\nprint(\"Train Size : \" + str(train_size))\ntest_size = len(scaled) - train_size\nprint(\"Test Size : \" + str(test_size))\n# print(scaled[0,])\ntrain, test = scaled[0:train_size,:], scaled[train_size:len(scaled),:]\nprint(\"Length of training data : \" + str(len(train)))\nprint(\"Length of testing data : \" + str(len(test)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"79bcf4ebd0b148eb04625b1bb8167aab61e1892e","_cell_guid":"c0b1a2fe-93e1-4dad-a121-2e132aa20f83"},"cell_type":"markdown","source":"# *Create function for creating dataset with look back*"},{"metadata":{"_uuid":"1c2d33296f3cbf17939a0f56b01e0bea007f8614","_cell_guid":"2f95fc03-1418-455c-b5ed-a1a6e22e97a7","trusted":true},"cell_type":"code","source":"def create_dataset(dataset, look_back=1):\n    dataX, dataY = [], []\n    for i in range(len(dataset) - look_back):\n        a = dataset[i:(i + look_back), 0]\n        dataX.append(a)\n        dataY.append(dataset[i + look_back, 0])\n    return np.array(dataX), np.array(dataY)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2f54261c39e80a64371754ae35f4d043dbb16974","_cell_guid":"da2d7810-5ddd-4f66-a288-a7ad4276bca3"},"cell_type":"markdown","source":"## *Generate dataset for trainX, trainY, testX, testY*"},{"metadata":{"_uuid":"74236b094646cd0fa1d9b56ca31ff26b3c1ef79a","_cell_guid":"d414263e-260e-4dc0-88b4-a5c5052c2551","trusted":true},"cell_type":"code","source":"look_back = 1\ntrainX, trainY = create_dataset(train, look_back)\ntestX, testY = create_dataset(test, look_back)\n\nprint(trainX.shape)\nprint(trainY.shape)\nprint(testX.shape)\nprint(testY.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"86d330b8044e090cbc71316d4f33a78907742c79","_cell_guid":"d5553396-ea30-42fd-8754-b7f2da6d0e57"},"cell_type":"markdown","source":"## *Reshape X for model training*"},{"metadata":{"_uuid":"b19a891be9692af149ca50ca8472700110287adc","_cell_guid":"c35247b2-058e-4f48-bf1d-93a4c1c2d6d5","trusted":true},"cell_type":"code","source":"trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\ntestX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n\nprint(trainX.shape)\nprint(testX.shape)\n\n# print(trainX)\n# print(trainY)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e385ad7589183e6bbedd32df0bcb457cba860ece","_cell_guid":"670f6dc3-18cd-46c7-a0e9-f6c32c0e7cbb"},"cell_type":"markdown","source":"# *Running the LSTM model with 300 epochs*"},{"metadata":{"_uuid":"f8398f9b7d19f8bd3da30cd855a463399019d654","_cell_guid":"bf2d6bd2-4490-4fac-bfb3-77c9727a3082","trusted":true},"cell_type":"code","source":"# Initialise the sequential model\nmodel = Sequential()\n# Add the LSTM hidden layer with 100 units\nmodel.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n# Add the output layer\nmodel.add(Dense(1))\n# Compile the model with Mean Absolute Error as the loss factor and ADAM as the optimiser\nmodel.compile(loss='mae', optimizer='adam')\n# Fit the model using the training and testing data\nhistory = model.fit(trainX, trainY, epochs=300, batch_size=100, validation_data=(testX, testY), verbose=1, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4748a9eabd2a3f71d3b3491a862b977e1da038b7","_cell_guid":"346dc856-2beb-4409-a7dd-2f5ea4abe55c"},"cell_type":"markdown","source":"## *Plot line graph to show amount loss according to the epoch*"},{"metadata":{"_uuid":"b0d148c334d28a6728a1d1437ff79c3faed01e47","_cell_guid":"0b1ba0ae-d20b-4fb2-af53-28c013c13dd1","trusted":true},"cell_type":"code","source":"pyplot.plot(history.history['loss'], label='train')\npyplot.plot(history.history['val_loss'], label='test')\npyplot.legend()\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ffaee208ae1088d9c3c83a8cb433eb811209bd5a","_cell_guid":"e7b0f4f0-558d-4fa4-a49a-54f47d7fbe5a"},"cell_type":"markdown","source":"## *Make prediction using textX and plotting line graph against testY*"},{"metadata":{"_uuid":"99c245ddefc779f24fa6ef077309d3fb5ad222eb","_cell_guid":"953f11ca-a00e-44ef-ad66-889007b1faf7","trusted":true},"cell_type":"code","source":"yhat = model.predict(testX) # Here yhat is the predicted value from the test set (y_pred)\nprint(yhat.shape)\nprint(yhat[0])\n\npyplot.plot(yhat, label='predict')\npyplot.plot(testY, label='true')\npyplot.legend()\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"099a70f2b58c7af5432dbaf88e89392a5a0ad6d3","_cell_guid":"0efdd9bb-1367-48cf-8f25-7af211c7a34c"},"cell_type":"markdown","source":"## *Scaler Inverse Y back to normal value*"},{"metadata":{"_uuid":"c97f1a6826f7286277a37a7993f72bcdbc8a0229","_cell_guid":"a4ccceee-0d5a-4e39-a75c-e856e215362e","trusted":true},"cell_type":"code","source":"# scaler = MinMaxScaler(feature_range=(0, 1)) as used before for fit_transform and MinMaxScaler\nyhat_inverse = scaler.inverse_transform(yhat.reshape(-1, 1))\ntestY_inverse = scaler.inverse_transform(testY.reshape(-1, 1))\n\nprint(yhat_inverse.shape)\nprint(testY_inverse.shape)\n\nprint(yhat_inverse[0])\nprint(testY_inverse[0])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2972db934026a61a6d11411443dff95dd734600b","_cell_guid":"b51c1c6c-cfeb-4683-9965-eaffb9045ddc"},"cell_type":"markdown","source":"## *RMSE*"},{"metadata":{"_uuid":"d4ec1bc2342f2ec215c83a817eb0e1980cadc023","_cell_guid":"3bdde533-1d5c-4d9f-8ee2-8867a7f9434f","trusted":true},"cell_type":"code","source":"rmse = sqrt(mean_squared_error(testY_inverse, yhat_inverse))\nprint('Test RMSE: %.3f' % rmse)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3d93e1c74042684723566bc3a5bde324ffd3159b","_cell_guid":"144efbdc-9c05-434a-a46d-2e5ca3625ce1"},"cell_type":"markdown","source":"## *Plot line graph with Y as USD*"},{"metadata":{"_uuid":"ab4797992d846a0bb03fcf057b206bf59d49a5fa","_cell_guid":"912fe352-6aab-4703-ad18-79de70e0d19b","trusted":true},"cell_type":"code","source":"pyplot.plot(yhat_inverse, label='predict')\npyplot.plot(testY_inverse, label='actual', alpha=0.5)\npyplot.legend()\npyplot.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}