{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Importing Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import PowerTransformer\nfrom sklearn.pipeline import Pipeline\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, classification_report,confusion_matrix\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA "},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.read_csv('../input/pima-indians-diabetes-database/diabetes.csv')\nprint(f\"shape of the Diabetes dataset :- {dataset.shape}\")\nprint(\"\\n ***************************** \\n\")\nprint(f\"Sample Dataset :- \\n {dataset.head()}\")\n## null values checking \nprint(\"\\n ***************************** \\n\")\nprint(f\"checking for null values :- \\n {dataset.isnull().sum()}\")\nprint(\"\\n ***************************** \\n\")\n## checking for whether dataset have duplicate values or not\nprint(f\"Number of Duplicate values :- {len(dataset.loc[dataset.duplicated()])}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"## count plot for target veriable\nsns.countplot(dataset['Outcome'], palette=['green', 'red'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.heatmap(dataset.corr(), annot=True, annot_kws={'size':10}, cmap='RdYlGn')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Preprocessing & Preparing Data for model"},{"metadata":{"trusted":true},"cell_type":"code","source":"## separate dataset of independent and dependent variables\nX = dataset.drop(['Outcome'], axis=1)\ny = dataset['Outcome']\n\ncol_names = list(X.columns)\n## craete pipe line with feature scaling\npipeline = Pipeline([\n                     ('std_scale', PowerTransformer(method='yeo-johnson'))\n])\n\nX = pd.DataFrame(pipeline.fit_transform(X), columns=col_names)\n\nprint(X.head())\n## split dataset into train and test datasets\nX_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.1, random_state=42)\n\nprint(f\"Size Of The Train Dataset :- {len(X_train)}\")\nprint(f\"Size Of The Test Dataset :- {len(X_test)}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Building"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_scores = []\ntest_scores = []\n\nfor i in range(1, 25):\n  knn_clf = KNeighborsClassifier(n_neighbors=i)\n  knn_clf.fit(X_train, y_train)\n\n  train_scores.append(knn_clf.score(X_train, y_train))\n  test_scores.append(knn_clf.score(X_test, y_test))\n\nprint(f\"Max score of Train dataset at K = {train_scores.index(max(train_scores)) + 1} and score :- {max(train_scores)*100}%\")\nprint(f\"Max score of Test dataset at K = {test_scores.index(max(test_scores)) + 1} and score :- {round(max(test_scores)*100, 2)}%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## training history graph \nplt.figure(figsize=(12,5))\np = sns.lineplot(range(1,25),train_scores,marker='*',label='Train Score')\np = sns.lineplot(range(1,25),test_scores,marker='o',label='Test Score')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## best score on test data at k = 5\n\nknn_clf = KNeighborsClassifier(n_neighbors=5)\nknn_clf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"## predict X_test \ny_pred = knn_clf.predict(X_test)\nprint(\"\\n ***************************** \\n\")\nprint(f\"Accuracy :- \\n {accuracy_score(y_test, y_pred)*100}\")\nprint(\"\\n ***************************** \\n\")\nprint(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, y_pred)}\")\nprint(\"\\n ***************************** \\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, y_pred)}\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}