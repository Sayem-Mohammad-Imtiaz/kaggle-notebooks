{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\nThis database contains 76 attributes, but all published experiments refer to using a subset of 14 of them. In particular, the Cleveland database is the only one that has been used by ML researchers to\nthis date.The \"target\" field refers to the presence of heart disease in the patient. It is integer valued 0 = no/less chance of heart attack and 1 = more chance of heart attack\n\n<font color = \"lightblue\">\n    Content :\n\n1. [Load and Check Data](#1)\n1. [Variable Describtion](#2)\n      * [Univariate Variable Analysis](#3)\n          * [Chatagorical Variable:](#4)\n          * [Numerical Variable:](#5)\n1. [Basic Data Analysis](#6)\n1. [Outlier Detection](#7)\n1. [Missing Value](#8)\n    * [Find Missing Value](#9)\n1. [Vissualization](#10)\n    * [Corelation between all features](#11)\n    * [thalach -- target](#12)\n    * [cp -- target](#13)\n    * [exang -- target](#14)\n    * [ca -- target](#15)\n    * [slope -- target](#16)\n    * [thal -- target](#17)\n    * [cp -- exang -- target](#18)\n    * [cp -- exang -- target -- sex](#19)\n1. [Feature Engineering](#20)\n1. [Modelling](#21)\n    * [Train - Test Split](#22)\n    * [Simple Logistic Regression](#23)\n    * [Hyper Parameter -- Grid Search -- Cross Validation](#24)\n    * [Ensemble Modelling](#25)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\nimport matplotlib.pyplot as plt\nplt.style.use(\"seaborn-whitegrid\")  # plt.style.available => if you write this you can see the other styles\n\n\nimport seaborn as sns\n\nfrom collections import Counter\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"1\"></a><br>\n# Load and Check Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/health-care-data-set-on-heart-attack-possibility/heart.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Data has 303 feature.\n* I split 70 feature before I analysis the data. I will use this test data."},{"metadata":{"trusted":true},"cell_type":"code","source":"test = data.iloc[140:210]\ntest[\"target\"].value_counts()\ndata.drop(index=range(140,211), axis=0, inplace=True)\nlen_train = len(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"2\"></a><br>\n## Variable Describtion\n\n1. age\n1. sex\n1. cp: chest pain type (4 values)\n1. trestbps : resting blood pressure\n1. chol : serum cholestoral in mg/dl\n1. fbs : fasting blood sugar > 120 mg/dl\n1. restecg : resting electrocardiographic results (values 0,1,2)\n1. thalach : maximum heart rate achieved\n1. exang : exercise induced angina\n1. oldpeak : ST depression induced by exercise relative to rest\n1. slope : the slope of the peak exercise ST segment\n1. ca : number of major vessels (0-3) colored by flourosopy\n1. thal :  0 = normal; 1 = fixed defect; 2 = reversable defect\n1. target : 0= less chance of heart attack 1= more chance of heart attack"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"data = data.astype({\"sex\":\"int64\",\n             \"cp\":\"category\",\n            \"fbs\":\"category\",\n            \"restecg\":\"category\",\n            \"exang\":\"category\",\n            \"slope\":\"category\",\n            \"ca\":\"category\",\n            \"thal\":\"category\",\n            \"target\":\"int64\"})\ndata.info()"},{"metadata":{},"cell_type":"markdown","source":"* int64(4): age, trestbps, chol, thalach\n* float64(1): oldpeak\n* category(9): sex, cp, fbs, restecg, exang, slope, ca, thal, target"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"3\"></a><br>\n## Univariate Variable Analysis\n* Catagorical Variable\n* Numerical Variable"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4\"></a><br>\n## Catagorical Variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"def bar_plot(variable):\n    \"\"\"\n    input: variable ex: sex\n    output: barplot & value count\n    \"\"\"\n    # get features\n    var = data[variable]\n    # count number of categorical variable (value/sample)\n    varValue = var.value_counts()\n    # visualize\n    plt.figure(figsize=(9,3))\n    plt.bar(varValue.index, varValue)\n    plt.xticks(varValue.index, varValue.index.values)\n    plt.ylabel(\"Frequanc\")\n    plt.title(variable)\n    plt.show()\n    \n    print(\"{}\\n{}\".format(variable, varValue))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical = [\"sex\", \"cp\", \"fbs\", \"restecg\", \"exang\", \"slope\", \"ca\", \"thal\", \"target\"]\nfor c in categorical:\n    bar_plot(c)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"5\"></a><br>\n## Numerical Variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_hist(variable):\n    plt.figure(figsize=(9,3))\n    plt.hist(data[variable], bins=40)\n    plt.xlabel(variable)\n    plt.ylabel(\"Frequancy\")\n    plt.title(\"{} distribution with histogram\".format(variable))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numericVar = [\"age\", \"trestbps\", \"chol\", \"thalach\", \"oldpeak\"]\nfor n in numericVar:\n    plot_hist(n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"6\"></a><br>\n## Basic Data Analysis\n* sex vs target\n* cp vs target\n* fbs vs target\n* restecg vs target\n* exang vs target\n* slope vs target\n* ca vs target\n* thal vs target"},{"metadata":{"trusted":true},"cell_type":"code","source":"# sex vs target\ndata[[\"sex\",\"target\"]].groupby([\"sex\"], as_index=False).mean().sort_values(by=\"target\", ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cp vs target\ndata[[\"cp\",\"target\"]].groupby([\"cp\"], as_index=False).mean().sort_values(by=\"target\", ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fbs vs target\ndata[[\"fbs\",\"target\"]].groupby([\"fbs\"], as_index=False).mean().sort_values(by=\"target\", ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# restecg vs target\ndata[[\"restecg\",\"target\"]].groupby([\"restecg\"], as_index=False).mean().sort_values(by=\"target\", ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# exang vs target\ndata[[\"exang\",\"target\"]].groupby([\"exang\"], as_index=False).mean().sort_values(by=\"target\", ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# slope vs target\ndata[[\"slope\",\"target\"]].groupby([\"slope\"], as_index=False).mean().sort_values(by=\"target\", ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ca vs target\ndata[[\"ca\",\"target\"]].groupby([\"ca\"], as_index=False).mean().sort_values(by=\"target\", ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# thal vs target\ndata[[\"thal\",\"target\"]].groupby([\"thal\"], as_index=False).mean().sort_values(by=\"target\", ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"7\"></a><br>\n## Outlier Detection"},{"metadata":{"trusted":true},"cell_type":"code","source":"def outlier_detection(df,features):\n    outlier_indices = []\n    \n    for c in features:\n        # 1st Quantile\n        Q1 = np.percentile(df[c],25)\n        # 3rd quartile\n        Q3 = np.percentile(df[c],75)\n        # IQR\n        IQR = Q3 - Q1\n        # Outlier step\n        outlier_step = IQR * 1.5\n        # Detect outlier and their indices\n        outlier_indices_col = df[(df[c] < Q1 - outlier_step) | (df[c] > Q3 + outlier_step)].index\n        \n        # store indices\n        outlier_indices.extend(outlier_indices_col)\n    \n    outlier_indices = Counter(outlier_indices)\n    multiple_outlier = list(i for i, v in outlier_indices.items() if v >= 2)\n    \n    return multiple_outlier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.loc[outlier_detection(data, [\"age\", \"trestbps\", \"chol\", \"thalach\", \"oldpeak\"])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop outliers\ndata = data.drop(outlier_detection(data, [\"age\", \"trestbps\", \"chol\", \"thalach\", \"oldpeak\"]), axis=0).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"8\"></a><br>\n## Missing Value\n* Find Missing Value\n* Fill Missing Value"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.concat([data,test], axis=0).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"9\"></a><br>\n## Find Missing Value"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns[data.isnull().any()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* There is no missing vallue so I'm passing this step"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"10\"></a><br>\n## Vissualization"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"11\"></a><br>\n### Corelation between all features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# age sex cp trestbps chol fbs restecg  thalach\texang oldpeak slope\tca thal\ttarget\nlist1 = [\"age\",\"sex\",\"trestbps\",\"chol\",\"thalach\",\"oldpeak\", \"cp\", \"fbs\", \"restecg\", \"exang\", \"slope\", \"ca\", \"thal\", \"target\"]\nplt.figure(figsize=(15,10))\nsns.heatmap(data[list1].corr(), annot=True, fmt=\".2f\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"thalach, oldpeak, cp(chest pain), exang(exercies induced angina), ca, slope and thal are corelated with tharget"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"12\"></a><br>\n## thalach -- target"},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.FacetGrid(data, col=\"target\")\ng.map(sns.distplot, \"thalach\", bins=40)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.factorplot(x=\"thalach\", y=\"target\", data=data, kind=\"bar\", size=6, orient=\"h\")\ng.set_ylabels(\"Heart Attack Probability\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If thalach is higher than 140, they have more heart attack risk"},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.FacetGrid(data, col=\"target\")\ng.map(sns.distplot, \"oldpeak\", bins=40)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"12\"></a><br>\n## oldpeak -- target"},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.factorplot(x=\"oldpeak\", y=\"target\", data=data, kind=\"bar\", size=6, orient=\"h\")\ng.set_ylabels(\"Heart Attack Probability\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If oldpeak is lower than 0.50, they have more heart attack risk"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"13\"></a><br>\n## cp -- target"},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.factorplot(x=\"cp\", y=\"target\", data=data, kind=\"bar\", size=6)\ng.set_ylabels(\"Heart Attack Probability\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If cp value is equals 1,2,3 , they have more harth attack risk"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"14\"></a><br>\n## exang -- target"},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.factorplot(x=\"exang\", y=\"target\", data=data, kind=\"bar\", size=6)\ng.set_ylabels(\"Heart Attack Probability\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If exangina value equal 0, they have more heart attack risk"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"15\"></a><br>\n## ca -- target"},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.factorplot(x=\"ca\", y=\"target\", data=data, kind=\"bar\", size=6)\ng.set_ylabels(\"Heart Attack Probability\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If ca value equals 0 or 4, they have more heart attack risk"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"16\"></a><br>\n## slope -- target"},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.factorplot(x=\"slope\", y=\"target\", data=data, kind=\"bar\", size=6)\ng.set_ylabels(\"Heart Attack Probability\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If slope value equal 2, they have more heart attack risk"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"17\"></a><br>\n## thal -- target"},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.factorplot(x=\"thal\", y=\"target\", data=data, kind=\"bar\", size=6)\ng.set_ylabels(\"Heart Attack Probability\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If thal value equal 2, thay have more heart attack risk"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"18\"></a><br>\n## cp -- exang -- target"},{"metadata":{"trusted":true},"cell_type":"code","source":"#cp -- exang -- target\ng = sns.FacetGrid(data, col=\"target\", row=\"exang\")\ng.map(plt.hist, \"cp\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"19\"></a><br>\n## cp -- exang -- target -- sex"},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.FacetGrid(data, col=\"cp\", size=3)\ng.map(sns.pointplot, \"exang\", \"target\", \"sex\")\ng.add_legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* black=male\n* blue=female"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"20\"></a><br>\n## Feature Engineering"},{"metadata":{},"cell_type":"markdown","source":"kategorical feature ları ayır ve 0 ve 1 den oluştur"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"21\"></a><br>\n## Modelling"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"22\"></a><br>\n## Train - Test Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"len_train = len_train-1 # I dropped 1 feature that outlier one. This is wht ı do this\ntrain = data[:len_train]\ntest = data[len_train:]\ntest_x = test.drop([\"target\"], axis=1)\ntest_y = test[\"target\"]\nprint(\"train len : \",len(train))\nprint(\"test len : \", len(test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train.drop([\"target\"] , axis=1)\nY_train = train[\"target\"]\nx_train, x_test, y_train, y_test = train_test_split(X_train,Y_train, test_size=0.2, random_state=42)\nprint(\"x_train len:\", len(x_train))\nprint(\"x_test len:\", len(x_test))\nprint(\"y_train len:\", len(y_train))\nprint(\"y_test len:\", len(y_test))\nprint(\"test len:\", len(test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"23\"></a><br>\n## Simple Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression()\nlr.fit(x_train,y_train)\ny_head = lr.predict(x_test)\nacc_log_train = round(lr.score(x_train, y_train)*100,2)\nacc_log_test = round(lr.score(x_test,y_test)*100,2)\nprint(\"Logistic Regression Train Accuracy: %\", acc_log_train)\nprint(\"Logistic Regression Test Accuracy: %\", acc_log_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"24\"></a><br>\n## Hyper Parameter -- Grid Search -- Cross Validation\nWe will compare 5 ml classifier and evaluate mean accuracy of each of them by stratified cross validation.\n\n* DecisionTree\n* SVM\n* RandomForest\n* KNN\n* LogisticRegression"},{"metadata":{"trusted":true},"cell_type":"code","source":"random_state = 42\nclassifier = [DecisionTreeClassifier(random_state=random_state),\n             SVC(random_state=random_state),\n             RandomForestClassifier(random_state=random_state),\n             LogisticRegression(random_state=random_state),\n             KNeighborsClassifier()]\n\ndt_param_grid = {\"min_samples_split\":range(10,500,20),\n                \"max_depth\":range(1,20,2)}\n\nsvc_param_grid = {\"kernel\":[\"rbf\"],\n                 \"gamma\":[0.001,0.01,0.1,1],\n                 \"C\":[1,10,50,100,200,300,1000]}\n\nrf_param_grid = {\"max_features\":[1.3,10],\n                \"min_samples_split\":[2,3,10],\n                \"min_samples_leaf\":[1,3,10],\n                \"bootstrap\":[False],\n                \"n_estimators\":[100,300],\n                \"criterion\":[\"gini\"]}\n\nlr_param_grid = {\"C\":np.logspace(-3,3,7),\n                \"penalty\":[\"l1\",\"l2\"]}\n\nknn_param_grid = {\"n_neighbors\":np.linspace(1,19,10, dtype=int).tolist(),\n                 \"weights\":[\"uniform\",\"distance\"],\n                 \"metric\":[\"euclidean\",\"manhattan\"]}\n\nclassifier_param = [dt_param_grid,\n                   svc_param_grid,\n                   rf_param_grid,\n                   lr_param_grid,\n                   knn_param_grid]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_names=[\"DecisionTree :\", \"SVC : \", \"RandomForest : \", \"LogisticRegression : \", \"KNN : \"]\ncv_result = []\nbest_estimators = []\nfor i in range(len(classifier)):\n    clf = GridSearchCV(classifier[i], param_grid=classifier_param[i], cv=StratifiedKFold(n_splits=10), scoring=\"accuracy\", n_jobs=-1, verbose=1)\n    clf.fit(x_train,y_train)\n    cv_result.append(clf.best_score_)\n    best_estimators.append(clf.best_estimator_)\n    print(model_names[i], cv_result[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(cv_result)\ncv_results = pd.DataFrame({\"Cross Validation Means\":cv_result, \"ML Models\":[\"DecisionTreeClassifier\", \"SVC\", \"RandomForestClassifier\", \"LogisticRegression\", \"KNeigborsClassifier\"]})\n\ng = sns.barplot(x=\"Cross Validation Means\", y = \"ML Models\", data=cv_results)\ng.set_xlabel(\"Means Accuracy\")\ng.set_title(\"Cross Validation Scores\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"25\"></a><br>\n## Ensemble Modelling"},{"metadata":{"trusted":true},"cell_type":"code","source":"votingC = VotingClassifier(estimators=[(\"rf\", best_estimators[2]),\n                                      (\"lr\", best_estimators[3])],\n                          voting=\"soft\", n_jobs=-1)\nvotingC = votingC.fit(x_train, y_train)\nprint(\"Accuracy :\", accuracy_score(votingC.predict(x_test), y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And last , I use first test data for prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy :\",accuracy_score(votingC.predict(test_x), test_y))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}