{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Sentiment Prediction Using Deep Learning - Artificial Neural Network","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"In this section, I want to create a Artificial Neural Network (ANN), train, and test it on a dataset retrieved from https://www.kaggle.com/ankurzing/sentiment-analysis-for-financial-news/kernels. This ANN will then fitted to the all 3 given datasets (CNBC, Reuters, and the Guardian) to evaluate whether the headline/preview is positive, neutral, or negative.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom keras.utils import np_utils\nfrom sentiment_module import tokenize_stem\n\ndf = pd.read_csv(\"../input/sentiment-analysis-for-financial-news/all-data.csv\", header = None, encoding='latin-1', names=[\"Sentiment\", \"Headlines\"])\ndf['Sentiment'] = df['Sentiment'].replace(\"negative\",0).replace(\"neutral\",1).replace(\"positive\",2)\n\ncorpus = []\nfor item in df['Headlines']:\n    corpus.append(tokenize_stem(item))\n\nfrom sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer()\nX = cv.fit_transform(corpus).toarray()\ny = df.iloc[:, 0].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X.shape)\nprint(y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# transform column y to categorical data\ny = np_utils.to_categorical(y, num_classes=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting into training sets and validation sets\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create an Artificial Neural Network","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Embedding\nfrom keras.utils import np_utils\n\nmodel = Sequential()\nmodel.add(Dense(128, input_dim=(X_train.shape[1]), activation='relu'))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(16, activation='relu'))\nmodel.add(Dense(8, activation='relu'))\nmodel.add(Dense(3, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nmodel.fit(X_train, y_train, epochs=20, batch_size=32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(x=X_test, y=y_test, batch_size=None, verbose=1, sample_weight=None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fitting the model to generate sentiment predictions","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Import data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from part1_cleaning import get_clean_data\ndf1, df2, df3 = get_clean_data()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## CNBC Headlines and Previews","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sentiment_module import tokenize_stem\n\n# Predicting Headlines\ncorpus_hl1 = []\nfor item in df1['Headlines']:\n    corpus_hl1.append(tokenize_stem(item))\npred_hl1 = cv.transform(corpus_hl1).toarray()\ny_pred_hl1 = model.predict(pred_hl1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_pred_hl1.shape)\nprint(y_pred_hl1[0:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sentiment_module import cluster_extraction\n\n# Clustering Headlines\nhl_sentiment = cluster_extraction(y_pred_hl1)\nhl_sentiment[0:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting Descriptions/Previews\ncorpus_ds1 = []\nfor item in df1['Description']:\n    corpus_ds1.append(tokenize_stem(item))\npred_ds1 = cv.transform(corpus_ds1).toarray()\ny_pred_ds1 = model.predict(pred_ds1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_pred_ds1.shape)\nprint(y_pred_ds1[0:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Clustering Descriptions/Previews\nds_sentiment = cluster_extraction(y_pred_ds1)\nds_sentiment[0:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Combining","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Finally, to determine the sentiment of the article, I am going to evaluate based on both the sentiment of the headline as well as the sentiment of the preview. Firstly, if at least at least 1 out of 2 (headline and preview) is positive and the other isnt negative, the article is assigned as positive. Secondly, if the 2 are both neutral or one is negative, the other is positive and vice versa, the article is assigned as neutral. Thirdly, if at least 1 out of 2 (headline and preview) is negative and the other isnt positive, the article is assigned as negative.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sentiment_module import combine_sentiments\nann_c_sentiment = combine_sentiments(hl_sentiment, ds_sentiment)\nann_c_sentiment[0:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Reuters Headlines and Previews","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Predicting","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Headlines\ncorpus_hl2 = []\nfor item in df2['Headlines']:\n    corpus_hl2.append(tokenize_stem(item))\npred_hl2 = cv.transform(corpus_hl2).toarray()\ny_pred_hl2 = model.predict(pred_hl2)\nprint(y_pred_hl2.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_pred_hl2.shape)\nprint(y_pred_hl2[0:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Clustering Headlines\nhl_sentiment = cluster_extraction(y_pred_hl2)\nhl_sentiment[0:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Descriptions/Previews\ncorpus_ds2 = []\nfor item in df2['Description']:\n    corpus_ds2.append(tokenize_stem(item))\npred_ds2 = cv.transform(corpus_ds2).toarray()\ny_pred_ds2 = model.predict(pred_ds2)\nprint(y_pred_ds2.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_pred_ds2.shape)\nprint(y_pred_ds2[0:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Clustering Descriptions/Previews\nds_sentiment = cluster_extraction(y_pred_ds2)\nds_sentiment[0:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Combining","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Similar to CNBC data, I am going to evaluate each article's sentiment based on both the sentiment of its headline as well as the sentiment of its preview.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sentiment_module import combine_sentiments\nann_r_sentiment = combine_sentiments(hl_sentiment, ds_sentiment)\nann_r_sentiment[0:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The Guardian Headlines and Previews","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Predicting","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Headlines\ncorpus_hl3 = []\nfor item in df3['Headlines']:\n    corpus_hl3.append(tokenize_stem(item))\npred_hl3 = cv.transform(corpus_hl3).toarray()\ny_pred_hl3 = model.predict(pred_hl3)\nprint(y_pred_hl3.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_pred_hl3.shape)\nprint(y_pred_hl3[0:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Clustering Headlines\nhl_sentiment = cluster_extraction(y_pred_hl3)\nhl_sentiment[0:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The Guardian's headline sentiment is the only variavle dictate the sentiment of the Guardian's articles\nann_g_sentiment = hl_sentiment","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}