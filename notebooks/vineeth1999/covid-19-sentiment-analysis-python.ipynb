{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"Thanks to @andradaolteanu for her good sentiment analysis report on covid-19 using R(https://www.kaggle.com/andradaolteanu/covid-19-sentiment-analysis/notebook). This I have done the same thing using Python. Hope you find it useful.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://i.imgur.com/FNi8CFE.png\">\n<center><h1>COVID-19: EDA and Text Analysis</h1></center>\n\n# 1. Introduction\n\n# 2. Imports\n\n### Librariesüìö","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nfrom PIL import Image\nfrom datetime import time,date\nimport nltk\nimport spacy\nimport re","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Color Palette and Custom Themeüé®","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = [[[5,164,192],[133,206,218],[210,167,216]],[[166,123,197],[187,28,139],[220,38,110]],]\nfig = plt.figure(figsize=(5, 5))\nfig.patch.set_visible(False) \nimg = plt.imshow(data,interpolation='nearest')\nimg.set_cmap('hot')\nplt.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"**### DataüìÇ\n\nFirst let's inspect the data to see what we're working with. I'm gonna keep it simple, as we'll make it more complicated soon üòÅ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/coronavirus-2019ncov/covid-19-all.csv')\ndata.rename(columns={\"Country\":\"Country/Region\",\"State\":\"State/Province\"},inplace=True)\ntweets = pd.read_csv('../input/covid19-tweets/covid19_tweets.csv')\n#Inspect Data\ndata.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Inspect Tweet\ntweets.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. What's the situation worldwide? üåçüåéüåè\n\n## Reported Cases in Time üìÖ\n> **üìåNote**: Cases are stable in the first quarter of the year. However, starting April they begin to rise first linearly, then almost exponentialy starting July.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data[['Confirmed','Recovered','Deaths']] = data[['Confirmed','Recovered','Deaths']].fillna(0)\ndata_new = pd.melt(data[['Date','Confirmed','Recovered','Deaths']],id_vars=['Date'],value_vars=['Confirmed','Recovered','Deaths'],var_name='group_var',value_name='Cases')\ndata_new['Date'] = pd.to_datetime(data_new['Date'])\ndata['Date'] = pd.to_datetime(data['Date'])\ndates = data['Date'].unique()\nnew_df = pd.DataFrame(index = pd.date_range(dates.min(), dates.max()),columns=['Confirmed','Recovered','Deaths'])\nnew_df[['Confirmed','Recovered','Deaths']] = new_df.apply(lambda x:data.loc[(data['Date'] == x.name),['Confirmed','Recovered','Deaths']].sum(),axis=1)\nnew_df = new_df.rename_axis('Date').reset_index()\ndata_new = pd.melt(new_df,id_vars=['Date'],value_vars=['Confirmed','Deaths','Recovered'],var_name='group_var',value_name='Cases')\ndata_new = data_new.sort_values(by=['Date','group_var']).reset_index(drop=True)\ndata_new['label'] = data_new['group_var']\nnew_data = data_new.pivot_table(index=['Date'], columns='group_var')\nnew_data.columns = new_data.columns.droplevel().rename(None)\nfig,ax = plt.subplots(1,figsize=(16,8))\nnew_data[['Confirmed','Recovered','Deaths']].plot(ax=ax,fontsize=15)\nplt.title(label='Reported Cases In Time',loc='Left',fontsize='20')\nax.set_ylabel('frequency',fontsize=20)\nax.set_ylim([0,30000000])\nax.set_xlabel('')\nplt.grid()\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Top Countries per Case Type\n\n> **üìåNote**: US has the lead in all cases. *China* is on 18th place in this ranking. Also, it's interesting to see that top 5 countries are from ~different continents; US from North America, Brazil from South America, India from Asia, Russia from Europe and Asia and Spain from Europe.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new = pd.melt(data[['Date','Country/Region','Confirmed','Recovered','Deaths']],id_vars=['Date','Country/Region'],value_vars=['Confirmed','Recovered','Deaths'],var_name='group_var',value_name='Cases')\ndata_new['Date'] = pd.to_datetime(data_new['Date'])\nnew_df = data[['Country/Region','Confirmed','Recovered','Deaths']].groupby(['Country/Region']).sum().reset_index()\ndata_new = pd.melt(new_df,id_vars=['Country/Region'],value_vars=['Confirmed','Deaths','Recovered'],var_name='group_var',value_name='Cases')\ndata_new = data_new.sort_values(by=['Country/Region','group_var']).reset_index(drop=True)\nnew_data = data_new.pivot_table(index=['Country/Region'], columns='group_var')\nnew_data.columns = new_data.columns.droplevel().rename(None)\nfig,ax = plt.subplots(3,figsize=(16,24))\ngroup_labels = ['Confirmed','Deaths','Recovered']\nnew_data.nlargest(5, ['Confirmed']).plot(y='Confirmed',ax=ax[0],kind='bar')\nnew_data.nlargest(5, ['Deaths']).plot(y='Deaths',ax=ax[1],kind='bar')\nnew_data.nlargest(5, ['Recovered']).plot(y='Recovered',ax=ax[2],kind='bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Top States per Case Type\n\n> **üìåNote**: in *Recovered* category, \"Recovered\" state is from US. I will figure the state later in the analysis. There is also an \"Unknown\" state.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Province/State'] = data['Province/State'].fillna('Unknown')\ndata_new = pd.melt(data[['Date','Province/State','Confirmed','Recovered','Deaths']],id_vars=['Date','Province/State'],value_vars=['Confirmed','Recovered','Deaths'],var_name='group_var',value_name='Cases')\ndata_new['Date'] = pd.to_datetime(data_new['Date'])\nnew_df = data[['Province/State','Confirmed','Recovered','Deaths']].groupby(['Province/State']).sum().reset_index()\ndata_new = pd.melt(new_df,id_vars=['Province/State'],value_vars=['Confirmed','Deaths','Recovered'],var_name='group_var',value_name='Cases')\ndata_new = data_new.sort_values(by=['Province/State','group_var']).reset_index(drop=True)\nnew_data = data_new.pivot_table(index=['Province/State'], columns='group_var')\nnew_data.columns = new_data.columns.droplevel().rename(None)\nfig,ax = plt.subplots(3,figsize=(16,24))\ngroup_labels = ['Confirmed','Deaths','Recovered']\nnew_data.nlargest(5, ['Confirmed']).plot(y='Confirmed',ax=ax[0],kind='bar')\nnew_data.nlargest(5, ['Deaths']).plot(y='Deaths',ax=ax[1],kind='bar')\nnew_data.nlargest(5, ['Recovered']).plot(y='Recovered',ax=ax[2],kind='bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Sentiment Analysis üê•üê£\n\n## 4.1 Text Mining üî®üî¶\n\n### #1. Clean Corpus Function\n\nThis predefined function is going to clean the text from:\n* the punctuation - `removePunctuation`\n* extra white space - `stripWhitespace`\n* transforms to lower case - `tolower`\n* stopwords (common words that should be ignored) - `stopwords`\n* numbers - `removeNumbers`","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_corpus(text):\n    text = re.sub(r'[^\\w\\s]', '', text)\n    text = text.strip()\n    text= text.lower()\n    stop_words = set(nltk.corpus.stopwords.words('english'))\n    word_tokens = nltk.tokenize.word_tokenize(text) \n    filtered_sentence = [w for w in word_tokens if not w in stop_words] \n    filtered_sentence = [] \n    for w in word_tokens: \n        if w not in stop_words: \n            filtered_sentence.append(w)\n    text = ' '.join(filtered_sentence)\n    text = \"\".join(filter(lambda x: not x.isdigit(), text))\n    text = text.strip()\n    return text","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Work in Progress... ‚è≥\n<div class=\"alert alert-block alert-info\">\nGrams, Sentiment Analysis, Graphs, {sentimentr}, wordclouds and many more to come ^^\n</div>","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}