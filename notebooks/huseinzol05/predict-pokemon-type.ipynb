{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"cf043495-5823-3379-c9b9-da1d625a55a2"},"source":"**Import dependencies**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ba36f379-4123-1335-502d-a38a7319d584"},"outputs":[],"source":"import tensorflow as tf\nimport numpy as np\nimport time\nfrom sklearn.preprocessing import LabelEncoder\nimport pandas as pd\nfrom sklearn.cross_validation import train_test_split"},{"cell_type":"markdown","metadata":{"_cell_guid":"631ccd54-99eb-a234-ca19-749979eb5c27"},"source":"**Function to fetch our data**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3394ef98-1b32-61d3-d74e-d0502ca732e2"},"outputs":[],"source":"def get_data(data_location, split_dataset):\n    dataset = pd.read_csv(data_location)\n\n    # 0 shape to get total of rows, 1 to get total of columns\n    rows = dataset.shape[0]\n    print (\"there are \", rows, \" rows before cleaning\\n\")\n\n    # removing unimportant columns\n    columns = ['#', 'Name', 'Type 2', 'Generation', 'Legendary', 'Total']\n    for text in columns:\n        del dataset[text]\n\n    # get all data except first column\n    x = dataset.ix[: , 1:].values\n\n    # get all data on first column only\n    y = dataset.ix[: , :1].values\n\n    # split our dataset to reduce overfitting\n    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = split_dataset)\n    \n    return x_train, x_test, y_train, y_test"},{"cell_type":"markdown","metadata":{"_cell_guid":"8717ef15-f704-cc40-e048-096412885da7"},"source":"**Function to return one-hot-label our Y for softmax cross entropy**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c73d5813-775f-e4d3-6c88-b1b56f4e8dca"},"outputs":[],"source":"def return_embedded(x):\n\n    data = np.zeros((x.shape[0], np.unique(x).shape[0]), dtype = np.float32)\n    \n    for i in range(x.shape[0]):\n        data[i][x[i][0]] = 1.0\n    \n    return data"},{"cell_type":"markdown","metadata":{"_cell_guid":"bb77e396-b010-afb1-7ac9-db44bf61d316"},"source":"**Our global variables**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0e9679ac-a63e-4c29-1003-fab873dccef4"},"outputs":[],"source":"data_location = '../input/Pokemon.csv'\n\n# not included input and output layer\n# atleast 1\nnum_layers = 1\nsize_layer = 128\n\nlearning_rate = 0.5\n\nsplit_dataset = 0.5\n\nbiased_node = True\n\nbatch_size = 50\n\nepoch = 1\n\n# got sigmoid, tanh, relu\nactivation = 'sigmoid'"},{"cell_type":"markdown","metadata":{"_cell_guid":"dbc48644-6c93-c282-e3ef-ff747f7fc5a4"},"source":"**Start our session**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ef002572-2e8d-d6a4-25f3-d0abd50b33e5"},"outputs":[],"source":"x_train, x_test, y_train, y_test = get_data(data_location, split_dataset)\n\nlabel = sorted(list(set(y_train[:, 0])))\n\nx_train = x_train.astype(float)\nx_test = x_test.astype(float)\n\ny_train = np.array([LabelEncoder().fit_transform(y_train)]).T\ny_test = np.array([LabelEncoder().fit_transform(y_test)]).T\n\ny_train_ = return_embedded(y_train)\n\nprint (\"Train for \", epoch, \" iteration\")\nprint (\"There are \", x_train.shape[0], \" of rows for training\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"ded74427-2cfc-0a93-9d54-bfdfaefa5fdf"},"source":"**Neural Network Pipelining**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"17689420-5217-e27b-1822-3191cc41c5f9"},"outputs":[],"source":"class Model:\n    \n    def __init__(self, activation, biased_node, learning_rate, num_layers, size_layer, size_x, size_y):\n        \n        if activation == 'sigmoid':\n            self.activation = tf.nn.sigmoid\n        elif activation == 'tanh':\n            self.activation = tf.nn.tanh\n        elif activation == 'relu':\n            self.activation = tf.nn.relu\n        else:\n            raise Exception(\"model type not supported\")\n        \n        self.X = tf.placeholder(\"float\", [None, size_x])\n        self.Y = tf.placeholder(\"float\", [None, size_y])\n        \n        if biased_node:\n            self.biased = tf.Variable(tf.random_normal([size_layer * num_layers], mean = 0.0, stddev = 0.1))\n        \n        self.inner_layer = tf.Variable(tf.random_normal([size_x, size_layer * num_layers], mean = 0.0, stddev = 0.1))\n        \n        output_layer = tf.Variable(tf.random_normal([size_layer * num_layers, size_y], mean = 0.0, stddev = 0.1))\n        \n        if biased_node:\n            batched_layer = self.activation(tf.add(tf.matmul(self.X, self.inner_layer), self.biased))\n            \n        else:\n            batched_layer = self.activation(tf.matmul(self.X, self.inner_layer))\n        \n        self.W = tf.matmul(batched_layer, output_layer)\n        \n        self.b = tf.Variable(tf.random_normal([size_y]))\n                                 \n        self.y = self.W + self.b \n        \n        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = self.y, labels = self.Y))\n        \n        self.optimizer = tf.train.AdamOptimizer(learning_rate).minimize(self.cost)\n        \n        self.final_outputs = self.y\n        "},{"cell_type":"markdown","metadata":{"_cell_guid":"abdc235c-9460-2162-2a4a-3824465aa137"},"source":"**Begins our iteration**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e5d94680-01a4-04cb-8c0a-3e92c3e8b03e"},"outputs":[],"source":"# start the session graph\nsess = tf.InteractiveSession()\n\nmodel = Model(activation, biased_node, learning_rate, num_layers, size_layer, x_train.shape[1], y_train_.shape[1])\n\n# initialize global variables\nsess.run(tf.global_variables_initializer())\n\nfor i in range(epoch):\n    last_time = time.time()\n    total_lost = 0\n    total_accuracy = 0\n    for n in range(0, x_train.shape[0], batch_size):\n        output, _, loss = sess.run([model.final_outputs, model.optimizer, model.cost], \n                                   feed_dict = {model.X: x_train[n : n + batch_size, :], \n                                    model.Y: y_train_[n : n + batch_size, :]})\n        out = output[0].argmax()\n        if out == y_train[n, :][0]:\n            total_accuracy += 1\n        \n        total_lost += loss\n        \n    diff = time.time() - last_time\n    print (\"total accuracy: \", total_accuracy / (x_train.shape[0] * 1.0))\n    print (\"batch: \", i + 1, \", loss: \", total_lost / x_train.shape[0], \", speed: \", diff, \" s / epoch\")\n    total_lost = 0\n    total_accuracy = 0"},{"cell_type":"markdown","metadata":{"_cell_guid":"6a6eeb77-077f-3a75-82b6-4a0996f0924a"},"source":"![Real output][1]\n\n\n  [1]: https://raw.githubusercontent.com/huseinzol05/Predict-Pokemon-Type/master/out1.png"},{"cell_type":"markdown","metadata":{"_cell_guid":"87991f80-76ce-72b1-3db4-2371f2fb3533"},"source":"![output 2][1]\n\n\n  [1]: https://raw.githubusercontent.com/huseinzol05/Predict-Pokemon-Type/master/out2.png"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6b007dd7-e6c8-d80b-1f1e-d9dea4143046"},"outputs":[],"source":"print (\"\\nDone training, Benchmarking ===========================================\\nThere are \", x_test.shape[0],  \" of rows for testing\")\n\n# 0 = bug .. 18 = water\ntotalelement = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n\n# 0 = bug .. 18 = water\nelementfound = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n\ntotal_correct = 0\n\nfor n in range(x_test.shape[0]):\n    \n    output = sess.run([model.final_outputs], feed_dict={model.X: x_test[n : n + 1, :]})\n    \n    # to get index value\n    i,j = np.unravel_index(output[0].argmax(), output[0].shape)\n    \n    if np.where(output[0] == output[0][i][j])[1][0] == y_test[n, :][0]:\n        total_correct += 1\n        elementfound[y_test[n, :][0]] += 1\n    \n    totalelement[y_test[n, :][0]] += 1\n    \n    \naccuracy = (total_correct / (x_test.shape[0] * 1.0))\n\nprint (\"total correct: \", total_correct, \" over \", x_test.shape[0], \" test sets\")\nprint (\"overall accuracy: \", accuracy)\n\nfor i in range(len(totalelement)):\n    print (label[i], \" accuracy: \", elementfound[i] / (totalelement[i] * 1.0))"},{"cell_type":"markdown","metadata":{"_cell_guid":"590874ca-941f-f97c-b160-151cdeddfa27"},"source":"*Output above is not real, I included 2 images, trained using my PC. I do not know why this happens.*"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}