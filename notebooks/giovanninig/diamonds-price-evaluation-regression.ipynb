{"cells":[{"metadata":{},"cell_type":"markdown","source":"***For the Love of God - Damien Hirst***"},{"metadata":{},"cell_type":"markdown","source":"<img style=\"float: left;\" src=\"https://upload.wikimedia.org/wikipedia/en/thumb/6/6d/Hirst-Love-Of-God.jpg/220px-Hirst-Love-Of-God.jpg\" width=\"400px\"/>"},{"metadata":{},"cell_type":"markdown","source":"If you have any advice/suggestion, let me know in the comments and upvote!\nThank you!"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport warnings  \nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom scipy import stats\nfrom scipy.stats import norm, skew \nfrom sklearn import metrics\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error     \nfrom sklearn.metrics import r2_score\n\n\n\ndataset = pd.read_csv(\"../input/diamonds.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ***EDA***"},{"metadata":{},"cell_type":"markdown","source":"***Features***\n\nCarat : Carat weight of the Diamond.\n\nCut : Describe cut quality of the diamond.\n\nColor : Color of the Diamond.\n\nClarity : Diamond Clarity refers to the absence of the Inclusions and Blemishes.\n\nDepth : The Height of a Diamond, measured from the Culet to the table, divided by its average Girdle Diameter.\n\nTable : The Width of the Diamond's Table expressed as a Percentage of its Average Diameter.\n\nPrice : the Price of the Diamond.\n\nX : Length of the Diamond in mm.\n\nY : Width of the Diamond in mm.\n\nZ : Height of the Diamond in mm.\n"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"dataset.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = dataset.drop('Unnamed: 0', axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There's seems to be some min values of x,y,z that are zeros. It can't be possible because x,y,z rapresent volume\naxis. \nIs no possible to have an axis <= 0 , so let's drop 0 values and create a new Volume column : \nVolume column = x * y * z\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset[['x','y','z']] = dataset[['x','y','z']].replace(0,np.NaN)\ndataset.isnull().sum()\ndataset.dropna(inplace=True)\n\n\n\ndataset['volume'] = dataset['x']*dataset['y']*dataset['z']   \ndataset.drop(['x','y','z'], axis=1, inplace= True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(dataset[\"price\"] , fit = norm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x = dataset['price'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***CARAT VS PRICE***"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(dataset[\"carat\"] , fit = norm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot( x = dataset['carat'] , y = dataset['price'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot( x = dataset['carat'])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Eliminate carat > 1.99 to eliminate outliers.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = dataset.drop(dataset[(dataset['carat']>1.99)].index)\n\nsns.boxplot( x = dataset['carat'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(dataset[\"carat\"] , fit = norm)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***VOLUME VS PRICE***"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(dataset[\"volume\"] , fit = norm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x = dataset['volume'] , y = dataset['price'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(dataset['volume'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Eliminate Volume > 299"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = dataset.drop(dataset[(dataset['volume'] > 299)].index)\n\nsns.boxplot(dataset['volume'])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***CUT VS PRICE***"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot( x = dataset['cut'])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***COLOR VS PRICE***"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot( x = dataset['color'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***CLARITY VS PRICE***"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot( x = dataset['clarity'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='clarity', y='price', data=dataset ) \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ***Preprocessing***"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.get_dummies(dataset , drop_first = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = dataset['price'].values\n\nX = dataset.drop(['price'], axis=1)     \n\n\n\nfrom sklearn.preprocessing import RobustScaler \nrb = RobustScaler()\nX_scaled = rb.fit_transform(X)\n\nX_scaled = pd.DataFrame(X_scaled, columns = X.columns)  #--> rename columns after scaling\nX = X_scaled\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check Correlation"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,15))\nplt.title('Correlation Map')\nax=sns.heatmap(dataset.corr(),\n               linewidth=2.1,\n               annot=True,\n               center=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check features variance"},{"metadata":{"trusted":true},"cell_type":"code","source":"for v in X.columns:\n    variance = X.var()\nvariance = variance.sort_values(ascending = False)\n   \nplt.figure(figsize=(12,5))\nplt.plot(variance)  \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"variance","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Train - Test split"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Train - Validation split"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.25, random_state = 42)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ***Regression Models***"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.svm import SVR\n\n\nregressors = [['Linear Regression :' , LinearRegression()],\n       ['Decision Tree Regression :' , DecisionTreeRegressor()],\n       ['Random Forest Regression :' , RandomForestRegressor()],\n       [' XGB :' , XGBRegressor()] ,\n       ['K-Neighbors Regression :', KNeighborsRegressor()],\n       ['Support Vector Regression :', SVR()]   \n       ]\n\nfor name,model in regressors:\n        \n    model = model      \n    \n    model.fit(X_train,y_train)\n    \n    y_pred_train = model.predict(X_train)  \n    \n    y_pred_valid = model.predict(X_valid)\n        \n\n    print('-----------------------------------')\n    print(name)\n    \n    print(' --TRAINING SET --')\n    print('MAE:', mean_absolute_error(y_train , y_pred_train))\n    print('R2 :', r2_score(y_train , y_pred_train))\n\n    print('-----------------------------------')    \n    print(' --VALIDATION SET --')\n    print('MAE:', mean_absolute_error(y_valid, y_pred_valid))\n    print('R2 :', r2_score(y_valid , y_pred_valid))\n    print('---------------------------------')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Features Importance"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = XGBRegressor()\nmodel.fit( X_train , y_train)\n\n\nimportances = model.feature_importances_\nindex = np.argsort(importances)[::-1][0:15]\nfeature_names = X.columns.values\n\nplt.figure(figsize=(10,5))\nsns.barplot(x = feature_names[index], y = importances[index])\nplt.title(\" XGB - Top important features \")\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel = RandomForestRegressor()\nmodel.fit( X_train , y_train)\n\n\nimportances = model.feature_importances_\nindex = np.argsort(importances)[::-1][0:15]\nfeature_names = X.columns.values\n\nplt.figure(figsize=(10,5))\nsns.barplot(x = feature_names[index], y = importances[index])\nplt.title(\" Random Forest - Top important features \")\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ***RandomizedSearchCV*** "},{"metadata":{},"cell_type":"markdown","source":"XGB Hyperparameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\n\n\ncolsample_bylevel = [1 , 0.5]\ncolsample_bytree = [1 , 0.5]\ngamma = [0 , 1 , 5]\nlearning_rate = [  0.01 , 0.0125 , 0.001] \nmax_depth = [ 1 , 5 , 10 ]\nmin_child_weight = [1]\nn_estimators = [ 250 , 500 , 750 , 1000]   \nrandom_state = [42]     \nreg_alpha = [0, 1]\nreg_lambda = [0 , 1]\nscale_pos_weight = [1]\nsubsample = [0.5, 0.8 ,  1 ]\n\n\nparam_distributions = dict(\n                           colsample_bylevel = colsample_bylevel,\n                           colsample_bytree = colsample_bytree,\n                           gamma = gamma, \n                           learning_rate = learning_rate,\n                           max_depth = max_depth,\n                           min_child_weight = min_child_weight,\n                           n_estimators = n_estimators,\n                           random_state = random_state,\n                           reg_alpha = reg_alpha,\n                           reg_lambda = reg_lambda,\n                           scale_pos_weight = scale_pos_weight,\n                           subsample = subsample , \n                           \n                           ) \n\n\n\nestimator = XGBRegressor()     \n\n\nRandomCV = RandomizedSearchCV(\n                            estimator = estimator,         \n                            param_distributions = param_distributions,\n                            n_iter = 10,\n                            cv = 5,\n                            scoring = \"neg_mean_absolute_error\" ,  #'r2', \n                            random_state = 42, \n                            verbose = 1, \n                            n_jobs = -1,\n                            )\n\n\n\nhyper_model = RandomCV.fit(X_train, y_train)      ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"           \nprint('Best Score: ', hyper_model.best_score_)    \n\nprint('Best Params: ', hyper_model.best_params_)\n\n\nhyper_model.best_estimator_.fit(X_train , y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ny_pred_train_hyper = hyper_model.predict(X_train)  \n\ny_pred_valid_hyper = hyper_model.predict(X_valid)  \n\n\n\nprint(' -- HYPER TRAIN --')\nprint('MAE:', mean_absolute_error ( y_train , y_pred_train_hyper))\nprint('R2 :', r2_score ( y_train , y_pred_train_hyper))\n\n\nprint('-----------------------------------')    \nprint(' -- HYPER VALIDATION  --')\nprint('MAE:', mean_absolute_error(y_valid, y_pred_valid_hyper))\nprint('R2 :', r2_score(y_valid , y_pred_valid_hyper))\nprint('---------------------------------')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Final pred on Y test"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_hyper = hyper_model.predict(X_test)  \n\n\nprint('-----------------------------------')    \nprint(' -- HYPER TEST --')\nprint('MAE:', mean_absolute_error(y_test, y_pred_hyper))\nprint('R2 :', r2_score(y_test , y_pred_hyper))\nprint('---------------------------------')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If you have any advice/suggestion, let me know in the comments and upvote!\nThank you!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}