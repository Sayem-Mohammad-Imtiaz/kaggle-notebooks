{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#Importing pandas and numpy\nimport pandas as pd\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Importing the training and test data\ntrain = pd.read_csv('../input/twitter-sentiment-analysis-hatred-speech/train.csv')\ntest = pd.read_csv('../input/twitter-sentiment-analysis-hatred-speech/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Training data info\ntrain.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#first 5 rows\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Info:**\nWe have approx 31K data points and there are no null value presents in the training data"},{"metadata":{"trusted":false},"cell_type":"code","source":"#Test data info\ntest.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#first 5 rows of test data\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Info:**\nWe have approx 17K data points and there are no null value presents in the test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Frequency plot of classes\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nprint(sns.countplot(train['label'],label=True))\nplt.title('Class Distribution')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualizing the classes of train data\nchat_data = train['label'].value_counts()\nplt.pie(chat_data, autopct='%1.1f%%', shadow=True,labels=['Negative Class','Positive Class'])\nplt.title('Class Distribution');\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Unbalanced Data** <br>\nFrom the above representation, we can see data is highly unbalanced. The negative class accounts for 93% of data and on other hand positive class only has 7%  "},{"metadata":{},"cell_type":"markdown","source":"Now let's also have a look at positive and negative tweets seperately"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating the length column for tweet\ntrain['pre_clean_len']=  [len(t) for t in train.tweet]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Box plot of all data\nfig, ax = plt.subplots(figsize=(5, 5))\nplt.boxplot(train.pre_clean_len)\nplt.title('Word length of all tweets ')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Box plot of positive data\nfig, ax = plt.subplots(figsize=(5, 5))\nplt.boxplot(train[train['label']==0].pre_clean_len)\nplt.title('Word Length of Positive Tweets')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Box plot of negative data\nfig, ax = plt.subplots(figsize=(5, 5))\nplt.boxplot(train[train['label']==1].pre_clean_len)\nplt.title('Word Length of Negative Tweets')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Box plot analysis** From the above box plots, we can understand: <br> 1. **Negative class**: There are few outliers and the maximum length of the tweets going beyond 270 <br> 2. **Positive Class**: There are no ouliers and the maximum numbers of words in a tweet are approxx 150"},{"metadata":{"trusted":false},"cell_type":"code","source":"#Let's look at exact numbers of positive and negative tweet length\nprint('\\033[5m'+'Positive Tweets:'+\"\\033[0;0m\")\nprint('Minimum number of words are',train[train['label']==1].pre_clean_len.min())\nprint('Maximum number of words are',train[train['label']==1].pre_clean_len.max())\nprint(' ')\nprint('\\033[5m'+'Negative Tweets:'+\"\\033[0;0m\")\nprint('Minimum number of words are',train[train['label']==0].pre_clean_len.min())\nprint('Maximum number of words are',train[train['label']==0].pre_clean_len.max())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Word cloud of all tweets\nfrom wordcloud import WordCloud\nwordcloud = WordCloud(width=1600, height=800,max_font_size=200).generate(str(train['tweet']))\nplt.figure(figsize=(12,10))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.title('Word Cloud - All tweets',fontsize=20,fontweight='bold')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Word cloud of negative tweets\nfrom wordcloud import WordCloud\nwordcloud = WordCloud(width=1600, height=800,max_font_size=200).generate(str(train[train['label']==0]['tweet']))\nplt.figure(figsize=(12,10))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.title('Word Cloud - Positive tweets',fontsize=20,fontweight='bold')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Word cloud of positive tweets\nfrom wordcloud import WordCloud\nwordcloud = WordCloud(width=1600, height=800,max_font_size=200).generate(str(train[train['label']==1]['tweet']))\nplt.figure(figsize=(12,10))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.title('Word Cloud - Negative tweets',fontsize=20,fontweight='bold')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Cleaning"},{"metadata":{"trusted":false},"cell_type":"code","source":"#Negative tweets\nprint(train[train['label']==1]['tweet'][13])\nprint(train[train['label']==1]['tweet'][77])\nprint(train[train['label']==1]['tweet'][111])\nprint(train[train['label']==1]['tweet'][263])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Positive tweets\nprint(train[train['label']==0]['tweet'][1])\nprint(train[train['label']==0]['tweet'][33])\nprint(train[train['label']==0]['tweet'][31943])\nprint(train[train['label']==0]['tweet'][21])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Cleaning**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# ------------Step 1 - Definig cleaning functions - URLs, Mentions, Negation handling, UF8 (BOM), Special chracters and numbers\n#!pip install bs4\n#!pip install nltk\n#!pip install et_xmlfile\n\n#!pip install lxml\nimport re\nfrom bs4 import BeautifulSoup\nfrom nltk.tokenize import WordPunctTokenizer\nTokenz = WordPunctTokenizer()\nMentions_Removal = r'@[A-Za-z0-9_]+'\nHttp_Removal = r'http(s?)://[^ ]+'\n#HttpS_Removal = r'https://[^ ]+'\nWww_Removal = r'www.[^ ]+'\n\n#Combining the above 3 removals functions\n#Combining_MentnHttp = r'|'.join((Mentions_Removal,Http_Removal))\nCombining_MentnHttp1 = r'|'.join((Http_Removal,Www_Removal))\n\n\n#Creating a negation dictionary because words with apostrophe symbol (') will (Can't > can t) \nNegation_Dictonary = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \n                \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \n                \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \n                \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \n                \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\",\n                \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \n                \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \n                \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\",\n                \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \n                \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \n                \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \n                \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \n                \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\n                \"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\",\n                \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\n                \"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\",\n                \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \n                \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\",\n                \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \n                \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \n                \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \n                \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \n                \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \n                \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\n                 \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"}\nNegation_Joining= re.compile(r'\\b(' + '|'.join(Negation_Dictonary.keys()) + r')\\b')\n\ndef clean_tweet_function(text):\n    BeautifulSoup_assign = BeautifulSoup(text, 'html.parser')\n    Souping = BeautifulSoup_assign.get_text()\n    try:\n        BOM_removal = Souping.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n    except:\n        BOM_removal = Souping\n    Comb_2 = re.sub(Combining_MentnHttp1, '', BOM_removal)\n    #Comb_3 = re.sub(Www_Removal,'',Comb_2)\n    Comb_3 = re.sub(Mentions_Removal,'',Comb_2)\n    LowerCase = Comb_3.lower()\n    Negation_Handling = Negation_Joining.sub(lambda x: Negation_Dictonary[x.group()], LowerCase)\n    Letters_only = re.sub(\"[^a-zA-Z]\", \" \", Negation_Handling)\n    \n    # Removing unneccessary white- Tokenizing and joining together\n    Tokenization = [x for x  in Tokenz.tokenize(Letters_only) if len(x) > 1]\n    return (\" \".join(Tokenization)).strip()\nclean_tweet_function\n\n#Cleaning up the data with step 1\nxrange = range #Defining X range","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Cleaning training data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nxrange = range\nprint (\"Cleaning tweets in train data...\\n\")\nclean_tweet_train = []\nfor i in xrange(0,len(train)):\n    if( (i+1)%100000 == 0 ):\n        \"Reviews %d of %d has been processed\".format( i+1, len(train) )  \n        \n    clean_tweet_train.append(clean_tweet_function(train['tweet'][i]))\n    \n#Changing into dataframe\ntrain['cleaned_tweet'] = clean_tweet_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Cleaning test data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nxrange = range\nprint (\"Cleaning tweets in test data...\\n\")\nclean_tweet_test = []\nfor i in xrange(0,len(test)):\n    if( (i+1)%100000 == 0 ):\n        \"Reviews %d of %d has been processed\".format( i+1, len(test) )  \n        \n    clean_tweet_test.append(clean_tweet_function(test['tweet'][i]))\n    \n#Changing into dataframe\ntest['cleaned_tweet'] = clean_tweet_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Comparision** - Before and after data cleaning in training tweets"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets compare the positive tweets before and after cleaning\nprint('BEFORE - ',train[train['label']==1]['tweet'][13])\nprint('AFTER - ',train[train['label']==1]['cleaned_tweet'][13])\nprint('')\n\nprint('BEFORE - ',train[train['label']==1]['tweet'][77])\nprint('AFTER - ',train[train['label']==1]['cleaned_tweet'][77])\nprint('')\nprint('BEFORE - ',train[train['label']==1]['tweet'][111])\nprint('AFTER - ',train[train['label']==1]['cleaned_tweet'][111])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Comparing - Before and after change in test tweet**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets compare the positive tweets before and after cleaning\nprint('BEFORE - ',train[train['label']==0]['tweet'][1])\nprint('AFTER - ',train[train['label']==0]['cleaned_tweet'][1])\nprint('')\n\nprint('BEFORE - ',train[train['label']==0]['tweet'][33])\nprint('AFTER - ',train[train['label']==0]['cleaned_tweet'][33])\nprint('')\nprint('BEFORE - ',train[train['label']==0]['tweet'][31943])\nprint('AFTER - ',train[train['label']==0]['cleaned_tweet'][31943])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Removing Stopwords**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Importing stop words and removing negative words from it\nfrom nltk.corpus import stopwords\nstopwords = set(stopwords.words('english')) - {'no', 'nor', 'not'} #we don't Stopwords to remove negation from our tweets\n\ndef remove_stopwords(text):\n    return ' '.join([word for word in str(text).split() if word not in stopwords])\n\n#Removing stop words from training and test\ntrain['cleaned_tweet'] = train['cleaned_tweet'].apply(lambda text: remove_stopwords(text))\ntest['cleaned_tweet'] = test['cleaned_tweet'].apply(lambda text: remove_stopwords(text))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Defining x and y\nX = train['cleaned_tweet']\ny = train['label']\n\nX_test = test['cleaned_tweet']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#TFIDF bi-gram \n#from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n'''\ntfidf = TfidfVectorizer(min_df=3,  max_features=None, \n            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n            ngram_range=(1, 2), use_idf=1,smooth_idf=1,sublinear_tf=1,\n            stop_words = 'english').\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# TFIDF tri-gram\n'''\ntfidf = TfidfVectorizer(min_df=3,  max_features=None, \n            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n            ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1,\n            stop_words = 'english')\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Importing TFIDF \nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\ntfidf = TfidfVectorizer(min_df=3,  max_features=None, \n            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n            ngram_range=(1, 4), use_idf=1,smooth_idf=1,sublinear_tf=1,\n            stop_words = 'english')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fitting TFIDF to both training and test\nx_train_tfidf =  tfidf.fit_transform(X) \nx_test_tfidf = tfidf.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Logistic regression**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\nfrom sklearn.metrics import roc_auc_score, f1_score, confusion_matrix, classification_report\nimport time\nstart_time = time.time()\nparam_grid = {'C': np.arange(20,30,2),\n              'max_iter': np.arange(100,1200,100),\n              'penalty': ['l1','l2']}\n\ni=1\nkf = StratifiedKFold(n_splits=10,random_state=1,shuffle=True)\nfor train_index,test_index in kf.split(x_train_tfidf,y):\n    print('\\n{} of kfold {}'.format(i,kf.n_splits))\n    xtr,xvl = x_train_tfidf[train_index],x_train_tfidf[test_index]\n    ytr,yvl = y[train_index],y[test_index]\n    \n    model = RandomizedSearchCV(estimator=LogisticRegression(class_weight='balanced'),param_distributions=param_grid,verbose=0)\n    \n\n    model.fit(xtr, ytr)\n    #print (model.best_params_)\n    pred=model.predict(xvl)\n    print('roc_auc_score',roc_auc_score(yvl,pred))\n    i+=1\n\nprint(\"Execution time: \" + str((time.time() - start_time)) + ' ms')\nprint ('best parameters',model.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"roc_auc_logistic = roc_auc_score(yvl,pred).mean()\nf1_logistic = f1_score(yvl,pred).mean()\nprint('Mean - ROC AUC', roc_auc_logistic)\nprint('F1 Score - ', f1_logistic)\nprint('Confusion Matrix \\n',confusion_matrix(yvl,pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Decision Tree**"},{"metadata":{"trusted":false},"cell_type":"code","source":"#DecisionTree with tuned hyperparameters\nfrom sklearn.tree import DecisionTreeClassifier\nstart_time = time.time()\nparam_grid = {'criterion': ['gini','entropy'],\n             'min_samples_split':[50,70,100,150],\n             'max_features': ['sqrt','log2']}\n\n\ni=1\nkf = StratifiedKFold(n_splits=10,random_state=1,shuffle=True)\nfor train_index,test_index in kf.split(x_train_tfidf,y):\n    print('\\n{} of kfold {}'.format(i,kf.n_splits))\n    xtr,xvl = x_train_tfidf[train_index],x_train_tfidf[test_index]\n    ytr,yvl = y[train_index],y[test_index]\n    \n    model = RandomizedSearchCV(estimator=DecisionTreeClassifier(class_weight={0:1,1:5}),param_distributions=param_grid,verbose=0)\n    \n\n    model.fit(xtr, ytr)\n    #print (model.best_params_)\n    pred=model.predict(xvl)\n    print('roc_auc_score',roc_auc_score(yvl,pred))\n    i+=1\n\nprint(\"Execution time: \" + str((time.time() - start_time)) + ' ms')\nprint ('best parameters',model.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model Accuracy\nroc_auc_dt = roc_auc_score(yvl,pred).mean()\nf1_dt = f1_score(yvl,pred).mean()\nprint('Mean - ROC AUC', roc_auc_dt)\nprint('F1 Score - ', f1_dt)\nprint('Confusion Matrix \\n',confusion_matrix(yvl,pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Random Forest**"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nstart_time = time.time()\nparam_grid = {'criterion': ['entropy'],\n             'min_samples_split':np.arange(10,100,20),\n             'max_features': ['sqrt'],\n             'n_estimators':[10,20,30]}\n\ni=1\nkf = StratifiedKFold(n_splits=10,random_state=1,shuffle=True)\nfor train_index,test_index in kf.split(x_train_tfidf,y):\n    print('\\n{} of kfold {}'.format(i,kf.n_splits))\n    xtr,xvl = x_train_tfidf[train_index],x_train_tfidf[test_index]\n    ytr,yvl = y[train_index],y[test_index]\n    \n    model = RandomizedSearchCV(estimator=RandomForestClassifier(),param_distributions=param_grid,verbose=0)\n    \n\n    model.fit(xtr, ytr)\n    #print (model.best_params_)\n    pred=model.predict(xvl)\n    print('roc_auc_score',roc_auc_score(yvl,pred))\n    i+=1\n\nprint(\"Execution time: \" + str((time.time() - start_time)) + ' ms')\nprint ('best parameters',model.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model Accuracy\nroc_auc_rf = roc_auc_score(yvl,pred).mean()\nf1_rf = f1_score(yvl,pred).mean()\nprint('Mean - ROC AUC', roc_auc_rf)\nprint('F1 Score - ', f1_rf)\nprint('Confusion Matrix \\n',confusion_matrix(yvl,pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Boosting (ensemble learning)***"},{"metadata":{},"cell_type":"markdown","source":"**XG Boost**"},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"from xgboost import XGBClassifier\nstart_time = time.time()\nparams = {\n        'min_child_weight': [1, 5, 10],\n        'gamma': [0.5, 1, 1.5, 2, 5],\n        'subsample': [0.6, 0.8, 1.0],\n        'colsample_bytree': [0.6, 0.8, 1.0],\n        'max_depth': [3, 4, 5],\n        'learning_rate': [0.01,0.1,0.7,1],\n        'eval_metric': ['auc']\n        }\n\n\ni=1\nkf = StratifiedKFold(n_splits=10,random_state=1,shuffle=True)\nfor train_index,test_index in kf.split(x_train_tfidf,y):\n    print('\\n{} of kfold {}'.format(i,kf.n_splits))\n    xtr,xvl = x_train_tfidf[train_index],x_train_tfidf[test_index]\n    ytr,yvl = y[train_index],y[test_index]\n    \n    model = RandomizedSearchCV(estimator=XGBClassifier(min_scale_weight=12,n_estimators=600),param_distributions=params,verbose=0)\n    \n\n    model.fit(xtr, ytr)\n    #print (model.best_params_)\n    pred=model.predict(xvl)\n    print('roc_auc_score',roc_auc_score(yvl,pred))\n    i+=1\n\nprint(\"Execution time: \" + str((time.time() - start_time)) + ' ms')\nprint ('best parameters',model.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model Accuracy\nroc_auc_xg = roc_auc_score(yvl,pred).mean()\nf1_xg = f1_score(yvl,pred).mean()\nprint('Mean - ROC AUC', roc_auc_xg)\nprint('F1 Score - ', f1_xg)\nprint('Confusion Matrix \\n',confusion_matrix(yvl,pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Ada Boosting**"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nstart_time = time.time()\n#params = {'n_estimators':[100,300,600]}\ni=1\nkf = StratifiedKFold(n_splits=10,random_state=42,shuffle=True)\nfor train_index,test_index in kf.split(x_train_tfidf,y):\n    print('\\n{} of kfold {}'.format(i,kf.n_splits))\n    xtr,xvl = x_train_tfidf[train_index],x_train_tfidf[test_index]\n    ytr,yvl = y[train_index],y[test_index]\n    \n    model = AdaBoostClassifier()\n\n    model.fit(xtr, ytr)\n    #print (model.best_params_)\n    pred=model.predict(xvl)\n    print('roc_auc_score',roc_auc_score(yvl,pred))\n    print('Confusion Matrix \\n',confusion_matrix(yvl,pred))\n    i+=1\n\nprint(\"Execution time: \" + str((time.time() - start_time)) + ' ms')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model Accuracy\nroc_auc_ada = roc_auc_score(yvl,pred).mean()\nf1_ada = f1_score(yvl,pred).mean()\nprint('Mean - ROC AUC', roc_auc_ada)\nprint('F1 Score - ', f1_ada)\nprint('Confusion Matrix \\n',confusion_matrix(yvl,pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Light GBM**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\nstart_time = time.time()\nparams = {\n    'boosting_type': 'gbdt',\n    'objective': 'binary',\n    'metric': 'auc',\n    'num_leaves': 31,\n    'learning_rate': 0.05,\n    'feature_fraction': 0.9,\n    'bagging_fraction': 0.8,\n    'bagging_freq': 5,\n    'verbose': 0\n    }\ni=1\nkf = StratifiedKFold(n_splits=10,random_state=42,shuffle=True)\nfor train_index,test_index in kf.split(x_train_tfidf,y):\n    print('\\n{} of kfold {}'.format(i,kf.n_splits))\n    xtr,xvl = x_train_tfidf[train_index],x_train_tfidf[test_index]\n    ytr,yvl = y[train_index],y[test_index]\n    \n    train_set = lgb.Dataset(xtr, label=ytr)\n    val_set = lgb.Dataset(xvl, label=yvl)\n    \n    model = lgb.train(params,train_set, valid_sets=val_set, verbose_eval=500)\n\n    #print (model.best_params_)\n    pred=model.predict(xvl)\n    print('roc_auc_score',roc_auc_score(yvl,pred))\n    #print('Confusion Matrix \\n',confusion_matrix(yvl,pred))\n    i+=1\n\nprint(\"Execution time: \" + str((time.time() - start_time)) + ' ms')\nprint('')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pred_noemb_val_y = model.predict([xvl], batch_size=1024, verbose=1)\nfrom sklearn import metrics\nfor thresh in np.arange(0.1, 0.501, 0.01):\n    thresh = np.round(thresh, 2)\n    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(yvl, (pred>thresh).astype(int))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model accuracy\nroc_auc_lgb = roc_auc_score(yvl,pred).mean()\nprint('Mean - ROC AUC', roc_auc_lgb)\npred1 = np.where(pred > 0.29, 1, 0)\nf1_lgb =  f1_score(yvl,pred1).mean()\nprint('F1 Score - ',f1_lgb)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Comparing results of all the models"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Summary table for all models\n\nresults = pd.DataFrame({\n    'Model': ['Logistic Regression', 'Decision Tree', 'Random Forest','XG Boost', 'Ada Boosting','LGB'],\n    'Mean - ROC AUC Score (Fold=10)': [roc_auc_logistic, roc_auc_dt, roc_auc_rf,roc_auc_xg,roc_auc_ada,roc_auc_lgb],\n    'Mean - F1 Score': [f1_logistic,f1_dt,f1_rf,f1_xg,f1_ada,f1_lgb]})\nresults","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}