{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Analyse de données Titanic\n\n## 1. Visualisation de données en utilisant PowerBI\n![dashboard](https://dochub.com/heiko11/bDa8NX3RdX5jmAER2zA6Ey/bi-png)"},{"metadata":{},"cell_type":"markdown","source":"## 2. Analyse de données en utilisant les librairies de machine learning en python.\n\n### Demarche:\n*   Definir un objectif mesurable : \n> Objectif : prédire si un passager aurait survécu ou pas.\\\n> Métrique : F1 -> 50% et Recall -> 70%. \\\n> Précision : permet de réduire au maximum le nombre de faux positifs.\\\n> Recall (sensibilité) : permet de réduire au maximum le nombre de faux négatifs.\\\n> Score F1.\n\n*   AED (Analyse Exploratoire des Données)\n*   Préparation des données.\n*   Modélisation"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sb\nimport matplotlib.pyplot as plt\nimport scipy.stats as st\nimport statistics\nfrom sklearn.preprocessing import scale\nimport warnings\n\n%matplotlib inline\n\n\npd.options.display.max_columns = None\nwarnings.filterwarnings('ignore')\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Importion des données\ndf = pd.read_csv('/kaggle/input/titanicdataset-traincsv/train.csv')\ndf = df.drop(columns = ['PassengerId'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Analyse de la forme des données."},{"metadata":{"trusted":true},"cell_type":"code","source":"data = df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dans ce jeu des données, il nous manque 177 valeurs dans la colonne 'Age', 687 valeurs de la variable 'Cabin' et 2 valeurs de 'Embarked'."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dtypes.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sb.heatmap(data.isna(), cbar=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(data.isna().sum()/data.shape[0]).sort_values()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Pour la variable **Cabin**, plus de 77% des valeurs sont manquantes et 20% valeurs de la colonne **Age**"},{"metadata":{"trusted":true},"cell_type":"code","source":"Age = data['Age'] # on remplace les valeurs manquantes par la median\nAge[Age.isna() == True] = Age.median()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On remplace les valeurs manquantes de la variable 'Age' par la mediane"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(columns=['Cabin','Name', 'Ticket']) # on supprime les variables inutiles","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Analyse de fond"},{"metadata":{},"cell_type":"markdown","source":"### Histogrammes des variables quantitatives"},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in data.select_dtypes('float64'):\n    plt.figure()\n    sb.distplot(data[col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in data.select_dtypes('object'):\n    print(col, data[col].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in data.select_dtypes('object'):\n    plt.figure()\n    data[col].value_counts().plot.pie()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Relation Target/variable"},{"metadata":{},"cell_type":"markdown","source":"#### Création des sous ensemble : Survi et non survi"},{"metadata":{"trusted":true},"cell_type":"code","source":"survecu = data[data['Survived'] == 1]\nnonsurvecu = data[data['Survived'] ==  0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sb.countplot(x ='Age', hue = 'Survived', data = data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sb.countplot(x ='Fare', hue = 'Survived', data = data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(data['Survived'], data['Embarked'])/data.shape[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Parmi les voyageurs qui ont ambarqué à Southampton, 48% n'ont pas survecu, alors que seuls 24% ont survecu."},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(data['Survived'], data['Sex'])/data.shape[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"D'après cette table de fréquence, on voit que la moitié des voyageurs n'ayant pas survecu étaient des hommes. On remaque aussi une faible mortalité pour le genre féminine."},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(data['Survived'], data['Parch'])/data.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(data['Survived'], data['Pclass'])/data.shape[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Selon la table de probabilité, on voit que les voyageurs de classe 3 n'ont, en majorité pas survecu."},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(data['Survived'], data['SibSp'])/data.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in ['Sex','Embarked','Pclass','Parch','SibSp']:\n    plt.figure()\n    sb.heatmap(pd.crosstab(data['Survived'], data[col]), annot=True, fmt = 'd')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Préparation des données\n- Objectif: Mettre les données dans un format propice au ML\n  -  Train/Test\n  - Encodage\n  - Nettoyage des NaN"},{"metadata":{},"cell_type":"markdown","source":"### Train-Test-Encodage-Nettoyage"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/titanicdataset-traincsv/train.csv')\ndf = df.drop(columns = ['PassengerId'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Age = df['Age']\nAge[Age.isna() == True] = Age.median()\ndf['Age'] = Age","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Embarked = df['Embarked']\nEmbarked[Embarked.isna() == True] = Embarked.mode()\ndf['Embarked'] = Embarked","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On met de côté une partie des données pour tester notre modèle (***test_set***) et une autre partie pour l'entaîner (***training_set***). \n\n*   Le ***training set***, qui va nous permettre d’entraîner notre modèle et sera utilisé par l’algorithme d’apprentissage.\n*  Le **testing_set**, qui permet de mesurer l’erreur du modèle final sur des données qu’il n’a jamais vues. \n\nles données sont séparées avec les proportions suivantes : *80 % pour le training set et 20 % pour le testing set*.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"trainset, testset = train_test_split(df, test_size = 0.2, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainset['Survived'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testset.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop(columns=['Name','Cabin','Ticket'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Encodage"},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in df.select_dtypes('object').columns:\n    print(col)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On définit une fonction encodage, qui nous permet de remplacer les valeurs des variables Embarked et Sex en des valeurs numériques et une fonction preprocessing pour la préparation des données."},{"metadata":{"trusted":true},"cell_type":"code","source":"def encodage(df):\n    \n    code  = {'S':1, \n             'C':2, \n             'Q':3, \n             'female':1,\n             'male':2}\n    for col in df.select_dtypes('object').columns:\n        df[col] = df[col].map(code)  \n        \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocessing(df):\n    \n    df = encodage(df)\n    \n    X = df.drop(columns=['Survived','Cabin','Name','Ticket'], axis = 1)\n    y = df['Survived']\n    print(y.value_counts())\n    return X,y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, y_train = preprocessing(trainset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test, y_test = preprocessing(testset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Age = X_train['Age'] # on remplace les valeurs manquantes par la mediane\nAge[Age.isna() == True] = Age.median()\nX_train['Age'] = Age","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Embarked = X_train['Embarked']\nEmbarked[Embarked.isna() == True] = 1\nX_train['Embarked'] = Embarked","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Modélisation\nOn met en place des modèles de machine learning candidat afin d'en choisir un pour modéliser notre problème."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import PolynomialFeatures, StandardScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocessor = make_pipeline(PolynomialFeatures(2, include_bias=False) ,SelectKBest(f_classif, k = 4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RandomForest = make_pipeline(preprocessor, RandomForestClassifier(random_state=0))\nAdaBoost = make_pipeline(preprocessor, AdaBoostClassifier(random_state=0))\nSVM = make_pipeline(preprocessor, StandardScaler(), SVC(random_state=0))\nKNN = make_pipeline(preprocessor, StandardScaler(), KNeighborsClassifier())\nLogReg = make_pipeline(preprocessor, StandardScaler(), LogisticRegression())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_model = {'RandomForest': RandomForest, 'AdaBoost': AdaBoost, \n              'SVM': SVM, 'KNN': KNN, 'LogisticReg' : LogReg}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score, classification_report, confusion_matrix\nfrom sklearn.model_selection import learning_curve","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluation(model):\n    model.fit(X_train,y_train)\n    ypred = model.predict(X_test)\n    print(confusion_matrix(y_test,ypred))\n    print(classification_report(y_test,ypred))\n    \n    N, train_score, val_score = learning_curve(model, X_train, y_train,\n                                               cv = 4, scoring = 'f1',\n                                               train_sizes = np.linspace(0.1,1,10))\n    plt.figure(figsize=(12,8))\n    plt.plot(N, train_score.mean(axis = 1))\n    plt.plot(N, val_score.mean(axis = 1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Procédure d'évaluation "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score, classification_report, confusion_matrix\nfrom sklearn.model_selection import learning_curve","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluation(model):\n    model.fit(X_train,y_train)\n    ypred = model.predict(X_test)\n    print(confusion_matrix(y_test,ypred))\n    print(classification_report(y_test,ypred))\n    \n    N, train_score, val_score = learning_curve(model, X_train, y_train,\n                                               cv = 4, scoring = 'f1',\n                                               train_sizes = np.linspace(0.1,1,10))\n    plt.figure(figsize=(12,8))\n    plt.plot(N, train_score.mean(axis = 1))\n    plt.plot(N, val_score.mean(axis = 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for name, model in list_model.items():\n    print(name)\n    evaluation(model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Optimisation"},{"metadata":{"trusted":true},"cell_type":"code","source":"SVM","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hyper_param = {'svc__gamma': [1e-3, 1e-4], \n               'svc__C': [1,10,100,1000],\n              'pipeline__polynomialfeatures__degree': [2,3,4]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid = RandomizedSearchCV(SVM, hyper_param, scoring='recall', cv=4, n_iter=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(grid.best_params_)\nypred = grid.predict(X_test)\nprint(classification_report(y_test,ypred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluation(grid.best_estimator_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Précision Recall Curve"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_recall_curve","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"precision, recall, threshold = precision_recall_curve(y_test,grid.best_estimator_.decision_function(X_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"precision, recall, threshold = precision_recall_curve(y_test,grid.best_estimator_.decision_function(X_test))\nplt.plot(threshold,recall[:-1], label = 'precision')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LogReg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_final = LogisticRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param = {'tol' :np.linspace(0.00001,1,5), 'C': [1.0,2,3,4,5]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Grid = RandomizedSearchCV(model_final, param, cv = 4, n_iter=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Grid.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(Grid.best_params_)\nypredL = Grid.predict(X_test)\nprint(classification_report(y_test,ypredL))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test,ypredL)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test,ypred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ypredk = KNN.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test,ypredk)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluation(model_final)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model.predict(X_test))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}