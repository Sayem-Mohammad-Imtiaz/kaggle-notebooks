{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# importing the path\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# importing the preprocessing libraries\nimport numpy as np\nimport pandas as pd\n\n# importing the visualization\nimport matplotlib.pyplot as plt\nplt.rcParams[\"figure.figsize\"] = 14,7\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# importing the Ml libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import confusion_matrix , classification_report\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# importing the dataset\ndataset = pd.read_csv(\"../input/carsdata/cars.csv\" , na_values=\" \")\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking the shape of the dataset\ndataset.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking for any missing values\ndataset.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# replacing the names of the columns\ndataset.columns = [\"mpg\" , \"cylinders\" , \"cubicinches\" , \"hp\" , \"weightlbs\" , \"time-to-60\", \"year\" , \"brand\"]\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Descriptive Stats\ndataset.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# descriptive Stats\ndataset.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Here brand is our target Variable","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# replacing and filling the missing values\ndataset[\"cubicinches\"] = dataset[\"cubicinches\"].replace(np.nan)\ndataset[\"weightlbs\"] = dataset[\"weightlbs\"].replace(np.nan)\n\nmean_cubicinches = dataset[\"cubicinches\"].mean()\nmean_weightlbs = dataset[\"weightlbs\"].mean()\n\ndataset[\"cubicinches\"] = dataset[\"cubicinches\"].replace(np.nan , mean_cubicinches)\ndataset[\"weightlbs\"] = dataset[\"weightlbs\"].replace(np.nan , mean_weightlbs)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# looking at the data\ndataset.info()\n\n\"\"\"thus missing values is filled with mean values\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Changing int64 to float64\ndataset[\"cylinders\"] = dataset[\"cylinders\"].astype(\"float64\")\ndataset[\"hp\"] = dataset[\"hp\"].astype(\"float64\")\ndataset[\"time-to-60\"] = dataset[\"time-to-60\"].astype(\"float64\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking for any outliers\nsns.boxplot(dataset[[\"mpg\"]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(dataset[[\"cylinders\"]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(dataset[[\"cubicinches\"]])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(dataset[[\"hp\"]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(dataset[\"weightlbs\"])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(dataset[\"time-to-60\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing outliers in time-to-60 column by IQR method\nQ1 = dataset[\"time-to-60\"].quantile(0.25)\nQ3 = dataset[\"time-to-60\"].quantile(0.75)\nIQR = Q3 - Q1\nlower_bound = IQR - (1.5 * Q1)\nupper_bound = IQR + (1.5 * Q3)\nprint(\"Lower Bound of Boxplot: \" , lower_bound)\nprint(\"Upper Bound of Boxplot: \" , upper_bound)\n\n# Removing the outliers\ndataset[\"time-to-60\"] = dataset[(dataset[\"time-to-60\"] > lower_bound) & (dataset[\"time-to-60\"] < upper_bound)]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsns.boxplot(dataset[\"time-to-60\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# making the count plot to understand the target variables\nsns.countplot(dataset[\"brand\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# understanding the correration between different features\ncorr_data = dataset.corr()\nsns.heatmap(data = corr_data , annot = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Thus we can see that there is a very high relationship between different features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# changing year column\nprint(dataset[\"year\"].max())\ndataset[\"year\"].min()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# making a new column in a dataset\ndataset[\"old\"] = dataset[\"year\"].max() - dataset[\"year\"]\n\n# Dropping the year column\ndataset.drop([\"year\"] , inplace = True , axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking the correration of the data\nnew_corr = dataset.corr()\nsns.heatmap(data = new_corr , annot = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Target = dataset[\"brand\"]\ndataset.drop([\"brand\"] , axis = 1 , inplace = True)\ndataset[\"Target\"] = Target\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset[\"old\"] = dataset[\"old\"].astype(\"float64\")\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# looking at the dataset\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Now the dataset is perfect for Model Building","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# splitting the dataset into independent(x) and dependent(y) variables\nx = dataset.iloc[: ,: -1].values\ny = dataset.iloc[: , -1].values\nprint(x)\nprint(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()\ny = encoder.fit_transform(y)\nprint(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalizing the x\nx_data = x /x.max()  \nx_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now Splitting the dataset into training and testing dataset\nx_train , x_test , y_train , y_test = train_test_split(x_data , y , test_size = .20 , random_state = None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# applying knearest classifier\nfrom sklearn.ensemble import RandomForestClassifier\nforest_classifier = RandomForestClassifier(random_state = None)\nforest_classifier.fit(x_train , y_train)\n\ny_preg = forest_classifier.predict(x_test) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making the Confusion Matrix and Classification Report\ncm = confusion_matrix(y_test, y_preg)\nsns.heatmap(data =  cm , annot = True , cmap = \"Blues\" , linewidths= 1 , linecolor= \"black\")\n\nreport = classification_report(y_test , y_preg)\nprint(report)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}