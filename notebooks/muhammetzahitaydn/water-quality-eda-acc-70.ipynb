{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\ndf = pd.read_csv(\"../input/water-potability/water_potability.csv\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-02T16:15:24.395426Z","iopub.execute_input":"2021-08-02T16:15:24.395851Z","iopub.status.idle":"2021-08-02T16:15:24.430004Z","shell.execute_reply.started":"2021-08-02T16:15:24.395818Z","shell.execute_reply":"2021-08-02T16:15:24.428904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-08-02T16:15:25.45814Z","iopub.execute_input":"2021-08-02T16:15:25.458598Z","iopub.status.idle":"2021-08-02T16:15:25.469471Z","shell.execute_reply.started":"2021-08-02T16:15:25.458561Z","shell.execute_reply":"2021-08-02T16:15:25.468437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.dropna()\ndf.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-08-02T16:15:25.692715Z","iopub.execute_input":"2021-08-02T16:15:25.69315Z","iopub.status.idle":"2021-08-02T16:15:25.708861Z","shell.execute_reply.started":"2021-08-02T16:15:25.693111Z","shell.execute_reply":"2021-08-02T16:15:25.707437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T16:15:26.321193Z","iopub.execute_input":"2021-08-02T16:15:26.321626Z","iopub.status.idle":"2021-08-02T16:15:26.343207Z","shell.execute_reply.started":"2021-08-02T16:15:26.321591Z","shell.execute_reply":"2021-08-02T16:15:26.341403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nax = sns.countplot(df.Potability,label=\"Count\") \nnot_potable, potable = df.Potability.value_counts()\nprint('Number of Potable: ',potable)\nprint('Number of Not Potable : ',not_potable)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T16:15:26.840521Z","iopub.execute_input":"2021-08-02T16:15:26.841221Z","iopub.status.idle":"2021-08-02T16:15:26.983206Z","shell.execute_reply.started":"2021-08-02T16:15:26.841185Z","shell.execute_reply":"2021-08-02T16:15:26.981902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df.drop(columns = [\"Potability\"])\ny = df.Potability","metadata":{"execution":{"iopub.status.busy":"2021-08-02T16:15:28.199377Z","iopub.execute_input":"2021-08-02T16:15:28.199741Z","iopub.status.idle":"2021-08-02T16:15:28.206801Z","shell.execute_reply.started":"2021-08-02T16:15:28.199711Z","shell.execute_reply":"2021-08-02T16:15:28.205125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dia = y\ndata = X\ndata_n_2 = (data - data.mean()) / (data.std())              \ndata = pd.concat([y,data_n_2.iloc[:,0:10]],axis=1)\ndata = pd.melt(data,id_vars=\"Potability\",\n                    var_name=\"features\",\n                    value_name='value')\nplt.figure(figsize=(10,10))\nsns.violinplot(x=\"features\", y=\"value\", hue=\"Potability\", data=data,split=True, inner=\"quart\")\nplt.xticks(rotation=90)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T16:15:29.411436Z","iopub.execute_input":"2021-08-02T16:15:29.411828Z","iopub.status.idle":"2021-08-02T16:15:29.984527Z","shell.execute_reply.started":"2021-08-02T16:15:29.411796Z","shell.execute_reply":"2021-08-02T16:15:29.983194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**From this figure we can say data not good for training. If we look Sulfate and Organic_carbon feature medians nearly same for both models maybe we can drop this features**","metadata":{}},{"cell_type":"code","source":"#correlation map\nf,ax = plt.subplots(figsize=(18, 18))\nsns.heatmap(X.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T16:15:31.709022Z","iopub.execute_input":"2021-08-02T16:15:31.70945Z","iopub.status.idle":"2021-08-02T16:15:32.535887Z","shell.execute_reply.started":"2021-08-02T16:15:31.709415Z","shell.execute_reply":"2021-08-02T16:15:32.534131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**There is no correlacition between features. Our data not good for training but we can not drop features because we have very less feature**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score,confusion_matrix\nfrom sklearn.metrics import accuracy_score\n\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\naccuricies = []\nn_estimators = []\nmax_acc = 0\nmax_i = 0\nfor i in range(1,100):\n    clf_rf = RandomForestClassifier(random_state=42, n_estimators=i)      \n    clr_rf = clf_rf.fit(x_train,y_train)\n    ac = accuracy_score(y_test,clf_rf.predict(x_test))\n    if ac > max_acc:\n        max_acc = ac\n        max_i = i\n    accuricies.append(ac)\n    n_estimators.append(i)\nplt.plot(n_estimators, accuricies)\nprint(\"Max : \", max_acc, max_i)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T16:15:44.799853Z","iopub.execute_input":"2021-08-02T16:15:44.800205Z","iopub.status.idle":"2021-08-02T16:16:20.478338Z","shell.execute_reply.started":"2021-08-02T16:15:44.800176Z","shell.execute_reply":"2021-08-02T16:16:20.477263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We reached 0.7 accuracy with n = 34. Next, We will try SMOTE beacuse our data unbalanced**","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nax = sns.countplot(y_train,label=\"Count\") \nnot_potable, potable = y_train.value_counts()\nprint('Number of Potable: ',potable)\nprint('Number of Not Potable : ',not_potable)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T16:20:07.117177Z","iopub.execute_input":"2021-08-02T16:20:07.11757Z","iopub.status.idle":"2021-08-02T16:20:07.262304Z","shell.execute_reply.started":"2021-08-02T16:20:07.117537Z","shell.execute_reply":"2021-08-02T16:20:07.261149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nsm = SMOTE(random_state = 42)\nx_train_res, y_train_res = sm.fit_resample(x_train, y_train.ravel())","metadata":{"execution":{"iopub.status.busy":"2021-08-02T16:18:11.361257Z","iopub.execute_input":"2021-08-02T16:18:11.361702Z","iopub.status.idle":"2021-08-02T16:18:11.379036Z","shell.execute_reply.started":"2021-08-02T16:18:11.361662Z","shell.execute_reply":"2021-08-02T16:18:11.377577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nax = sns.countplot(y_train_res,label=\"Count\") \nnot_potable, potable = y_train_res.value_counts()\nprint('Number of Potable: ',potable)\nprint('Number of Not Potable : ',not_potable)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T16:20:26.685026Z","iopub.execute_input":"2021-08-02T16:20:26.685603Z","iopub.status.idle":"2021-08-02T16:20:27.144735Z","shell.execute_reply.started":"2021-08-02T16:20:26.685568Z","shell.execute_reply":"2021-08-02T16:20:27.143293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuricies = []\nn_estimators = []\nmax_acc = 0\nmax_i = 0\nfor i in range(1,100):\n    clf_rf = RandomForestClassifier(random_state=42, n_estimators=i)      \n    clr_rf = clf_rf.fit(x_train_res,y_train_res)\n    ac = accuracy_score(y_test,clf_rf.predict(x_test))\n    if ac > max_acc:\n        max_acc = ac\n        max_i = i\n    accuricies.append(ac)\n    n_estimators.append(i)\nplt.plot(n_estimators, accuricies)\nprint(\"Max : \", max_acc, max_i)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T16:18:19.548124Z","iopub.execute_input":"2021-08-02T16:18:19.548604Z","iopub.status.idle":"2021-08-02T16:19:00.55198Z","shell.execute_reply.started":"2021-08-02T16:18:19.548564Z","shell.execute_reply":"2021-08-02T16:19:00.550811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Conclusion: We reached 0.7 acc but I think this data not appropiriate for classification**","metadata":{}}]}