{"cells":[{"metadata":{"_uuid":"ad759b9e-ed4f-416d-89f4-7ea3c37526be","_cell_guid":"9290e5f3-2c90-453c-8e5d-745a51721d2c","trusted":true},"cell_type":"markdown","source":"  **To have a fully self-driving car, it is necessary for vehicules to understand and follow traffic signs.**"},{"metadata":{"_uuid":"14bb5c23-4eaf-44d8-a568-09f8e81ad2b6","_cell_guid":"fb004b18-0206-45a0-88c2-f89017c8a1bd","trusted":true},"cell_type":"markdown","source":"# This project classify traffic signs present in an image."},{"metadata":{},"cell_type":"markdown","source":"Traffic signs that can be successfully classified are the following : \n* 'Speed limit (20km/h)', \n* 'Speed limit (30km/h)', \n* 'Speed limit (50km/h)', \n* 'Speed limit (60km/h)', \n* 'Speed limit (70km/h)', \n* 'Speed limit (80km/h)', \n* 'End of speed limit (80km/h)', \n* 'Speed limit (100km/h)', \n* 'Speed limit (120km/h)', \n* 'No passing',\n* 'No passing veh over 3.5 tons', \n* 'Right-of-way at intersection', \n* 'Priority road', \n* 'Yield', \n* 'Stop', \n* 'No vehicles', \n* 'Veh > 3.5 tons prohibited', \n* 'No entry', \n* 'General caution', \n* 'Dangerous curve left', \n* 'Dangerous curve right', \n* 'Double curve', \n* 'Bumpy road', \n* 'Slippery road', \n* 'Road narrows on the right', \n* 'Road work', \n* 'Traffic signals', \n* 'Pedestrians', \n* 'Children crossing', \n* 'Bicycles crossing', \n* 'Beware of ice/snow',\n* 'Wild animals crossing', \n* 'End speed + passing limits', \n* 'Turn right ahead', \n* 'Turn left ahead',\n* 'Ahead only', \n* 'Go straight or right', \n* 'Go straight or left', \n* 'Keep right', \n* 'Keep left', \n* 'Roundabout mandatory', \n* 'End of no passing', \n* 'End no passing veh > 3.5 tons'\n\nImages of the traffic signs that can be successfully classified  are present in /kaggle/input/gtsrb-german-traffic-sign/Meta folder"},{"metadata":{"_uuid":"1e798597-557e-4eb5-988a-f6755985cf0c","_cell_guid":"b157142c-f50c-415a-a4b3-17cac9c809ad","trusted":true},"cell_type":"markdown","source":"We **iterate** over all the classes, **open** image content into an **array** with The PIL library . and append **resized** images and their respective labels in the data and labels list"},{"metadata":{"_uuid":"3e4198c1-a044-4d56-982d-35da912e6a24","_cell_guid":"610e2474-1990-45a8-927f-78816a2721ca","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom PIL import Image\nimport glob\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, BatchNormalization\nfrom keras.callbacks import Callback\n\ndata = []\nlabels = []\nsize = (30,30)\nclasses = len(glob.glob('../input/gtsrb-german-traffic-sign/Meta/*.png'))\nfor i in range(classes):\n    path = \"../input/gtsrb-german-traffic-sign/Train/\" +str(i)\n    images = os.listdir(path)\n    for a in images:\n        try:\n            image = Image.open(path + '/'+ a)\n            image = image.resize(size)\n            image = np.array(image) /255.0\n            data.append(image)\n            labels.append(i)\n        except:\n            print(\"Error loading image\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0721fe85-85e7-4dec-8c74-fbcc2c3f660b","_cell_guid":"fd2f63d1-0fdd-4395-978b-971130ebbe77","trusted":true},"cell_type":"markdown","source":"convert the list into numpy to feed to the model.\nthe shape of our data now is (39209, 30, 30, 3)"},{"metadata":{"_uuid":"26fe240d-cd82-4de4-919e-535c53492c7d","_cell_guid":"8ed36a4f-c3e7-4d56-aa61-fbb78983984e","trusted":true},"cell_type":"code","source":"data = np.array(data)\nlabels = np.array(labels)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a2e1a116-1489-45f7-9bc8-2ce9092ab638","_cell_guid":"f3aec8a7-73b4-42b7-9700-ca2969ca8b84","trusted":true},"cell_type":"markdown","source":"we split data to training and validation"},{"metadata":{"_uuid":"548d5ea4-dabb-4985-88c1-273d5dbaf921","_cell_guid":"1bd12094-f087-4fb0-8cc7-52e5af8c4766","trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.1, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b1cd1e22-67de-4ecd-81f4-b4539946d079","_cell_guid":"60b3a1ba-4778-40a6-9b34-85440f30dfd9","trusted":true},"cell_type":"markdown","source":"**building and compiling the model + training**"},{"metadata":{"_uuid":"e35e0eab-fc6f-4ac7-86d6-e2909c104d68","_cell_guid":"0b791d70-05da-4962-b75a-c00f919724cf","trusted":true},"cell_type":"code","source":"#building the model\nimport keras\nmodel = Sequential()\nmodel.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=X_train.shape[1:]))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(rate=0.25))\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(rate=0.5))\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu',))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(rate=0.7))\nmodel.add(Dense(classes, activation='softmax'))\n#Compilation of the model\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5d950eaf-dc03-4298-b567-100d12b37e10","_cell_guid":"9bf568bc-75e2-44e8-a8f0-947e8f81b238","trusted":true},"cell_type":"code","source":"class MyCallback(Callback):\n\n    def on_epoch_end(self, epoch, logs={}):\n        if(logs.get('val_accuracy') > 0.9995  and logs.get('accuracy') > 0.995) :\n                print(\"val_accurcy more than 99.95% and accuracu more than 99.5%\")\n                self.model.stop_training = True\nmcallback = MyCallback()\n\nhistory = model.fit(X_train, y_train, batch_size=32, epochs=20, validation_data=(X_test, y_test), callbacks = [mcallback])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c7a86030-984a-4cf1-bba1-1260bcf17935","_cell_guid":"bc17d24a-4133-4971-9b6a-71a1280a31f6","trusted":true},"cell_type":"markdown","source":"Plotting the graph for accuracy and the loss"},{"metadata":{"_uuid":"a19e2518-8d2a-4fd2-b011-05b9aa52e74f","_cell_guid":"0b94c72a-663d-4042-acba-b1f823489a4b","trusted":true},"cell_type":"code","source":"plt.figure(0)\nplt.plot(history.history['accuracy'], label='training accuracy')\nplt.plot(history.history['val_accuracy'], label='val accuracy')\nplt.title('Accuracy')\nplt.xlabel('epochs')\nplt.ylabel('accuracy')\nplt.legend()\nplt.show()\nplt.figure(1)\nplt.plot(history.history['loss'], label='training loss')\nplt.plot(history.history['val_loss'], label='val loss')\nplt.title('Loss')\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2950c670-a43b-46f3-9ec7-1ad155264aaa","_cell_guid":"aa6c3217-719b-4a60-87ab-6ff0bb685a81","trusted":true},"cell_type":"markdown","source":"In a test.csv file, we have the details related to the image path and their respective class labels. we extract images ane their labels and do the same prepocessing as before"},{"metadata":{"_uuid":"f6f8808b-49e4-424e-ba74-2435e0147725","_cell_guid":"e5db4473-d949-40a1-ac4b-005db18928b3","trusted":true},"cell_type":"code","source":"test_set = pd.read_csv('/kaggle/input/gtsrb-german-traffic-sign/Test.csv')\nlabels = test_set[\"ClassId\"].values\nimgs = test_set[\"Path\"].values\ntest_data=[]\nfor img in imgs:\n    image = Image.open('/kaggle/input/gtsrb-german-traffic-sign/'+img)\n    image = image.resize(size)\n    test_data.append(np.array(image)/255.0)\ntest=np.array(test_data)\npred = model.predict_classes(test)\n#Accuracy with the test data\nfrom sklearn.metrics import accuracy_score\nprint(accuracy_score(labels, pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We achieved a 98.68% (0.9868566904196358) accuracy**"},{"metadata":{"_uuid":"0c3e20a8-d8aa-4dcb-9fa0-05b17f73695c","_cell_guid":"a5ebcbee-e5e1-45c4-98d6-9804385eb89a","trusted":true},"cell_type":"code","source":"#model.save(\"simple_traffic_signs_classifier.h5\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"you can upload yor own images. all you need to do is click on add data (top right) and within tap upload then you can choose as many images as you want (just make sure the images are not over 256*256 for good result). after you successfuly load your images make sure to name the dataset 'testing' or change in the path below"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"from keras.models import load_model\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport glob\nimport numpy\n\nclassifier = load_model('simple_traffic_signs_classifier.h5')\n\nsigns = { 1:'Speed limit (20km/h)',\n            2:'Speed limit (30km/h)', \n            3:'Speed limit (50km/h)', \n            4:'Speed limit (60km/h)', \n            5:'Speed limit (70km/h)', \n            6:'Speed limit (80km/h)', \n            7:'End of speed limit (80km/h)', \n            8:'Speed limit (100km/h)', \n            9:'Speed limit (120km/h)', \n            10:'No passing', \n            11:'No passing veh over 3.5 tons', \n            12:'Right-of-way at intersection', \n            13:'Priority road', \n            14:'Yield', \n            15:'Stop', \n            16:'No vehicles', \n            17:'Veh > 3.5 tons prohibited', \n            18:'No entry', \n            19:'General caution', \n            20:'Dangerous curve left', \n            21:'Dangerous curve right', \n            22:'Double curve', \n            23:'Bumpy road', \n            24:'Slippery road', \n            25:'Road narrows on the right', \n            26:'Road work', \n            27:'Traffic signals', \n            28:'Pedestrians', \n            29:'Children crossing', \n            30:'Bicycles crossing', \n            31:'Beware of ice/snow',\n            32:'Wild animals crossing', \n            33:'End speed + passing limits', \n            34:'Turn right ahead', \n            35:'Turn left ahead', \n            36:'Ahead only', \n            37:'Go straight or right', \n            38:'Go straight or left', \n            39:'Keep right', \n            40:'Keep left', \n            41:'Roundabout mandatory', \n            42:'End of no passing', \n            43:'End no passing veh > 3.5 tons' }\n\nfor filename in glob.glob('../input/testing/*'):\n    img = Image.open(filename)\n    img = img.resize((30,30))\n    plt.imshow(img)\n    plt.show()\n    img = numpy.array(img)\n    img = img[...,:3]\n    img = img/255.0\n    img = numpy.expand_dims(img, axis=0)\n    \n    print('your image shape should be (1, 30, 30, 3)',img.shape)\n    pred = classifier.predict_classes([img])[0]\n    sign = signs[pred+1]\n    print(sign)\n\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}